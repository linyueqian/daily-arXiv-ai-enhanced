{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word.", "AI": {"tldr": "Proposes a resource-efficient method for context embedding in language modeling using Graph Convolution and LSTMs.", "motivation": "Address the high resource demands of current language models by focusing on context embedding.", "method": "Combines Graph Convolution (GNNs) with LSTMs to encode context and predict the next word.", "result": "Works well on a custom Wikipedia corpus with limited resources.", "conclusion": "Demonstrates a viable, resource-efficient alternative for context embedding in language modeling."}}
{"id": "2505.09655", "pdf": "https://arxiv.org/pdf/2505.09655", "abs": "https://arxiv.org/abs/2505.09655", "authors": ["Xiwen Chen", "Wenhui Zhu", "Peijie Qiu", "Xuanzhao Dong", "Hao Wang", "Haiyu Wu", "Huayu Li", "Aristeidis Sotiras", "Yalin Wang", "Abolfazl Razi"], "title": "DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in reinforcement learning for language model post-training,\nsuch as Group Relative Policy Optimization (GRPO), have shown promise in\nlow-resource settings. However, GRPO typically relies on solution-level and\nscalar reward signals that fail to capture the semantic diversity among sampled\ncompletions. This leads to what we identify as a diversity-quality\ninconsistency, where distinct reasoning paths may receive indistinguishable\nrewards. To address this limitation, we propose $\\textit{Diversity-aware Reward\nAdjustment}$ (DRA), a method that explicitly incorporates semantic diversity\ninto the reward computation. DRA uses Submodular Mutual Information (SMI) to\ndownweight redundant completions and amplify rewards for diverse ones. This\nencourages better exploration during learning, while maintaining stable\nexploitation of high-quality samples. Our method integrates seamlessly with\nboth GRPO and its variant DR.~GRPO, resulting in $\\textit{DRA-GRPO}$ and\n$\\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning\nbenchmarks and find that it outperforms recent strong baselines. It achieves\nstate-of-the-art performance with an average accuracy of 58.2%, using only\n7,000 fine-tuning samples and a total training cost of approximately $55. The\ncode is available at https://github.com/xiwenc1/DRA-GRPO.", "AI": {"tldr": "Proposes Diversity-aware Reward Adjustment (DRA) to address diversity-quality inconsistency in GRPO, improving performance in low-resource settings.", "motivation": "GRPO's scalar rewards fail to capture semantic diversity, leading to indistinguishable rewards for diverse reasoning paths.", "method": "DRA uses Submodular Mutual Information (SMI) to adjust rewards, downweighting redundant completions and amplifying diverse ones.", "result": "Achieves state-of-the-art 58.2% accuracy on five benchmarks with only 7,000 samples and $55 training cost.", "conclusion": "DRA enhances GRPO by incorporating semantic diversity, improving exploration and maintaining high-quality exploitation."}}
{"id": "2505.09662", "pdf": "https://arxiv.org/pdf/2505.09662", "abs": "https://arxiv.org/abs/2505.09662", "authors": ["Philipp Schoenegger", "Francesco Salvi", "Jiacheng Liu", "Xiaoli Nan", "Ramit Debnath", "Barbara Fasolo", "Evelina Leivada", "Gabriel Recchia", "Fritz G\u00fcnther", "Ali Zarifhonarvar", "Joe Kwon", "Zahoor Ul Islam", "Marco Dehnert", "Daryl Y. H. Lee", "Madeline G. Reinecke", "David G. Kamper", "Mert Koba\u015f", "Adam Sandford", "Jonas Kgomo", "Luke Hewitt", "Shreya Kapoor", "Kerem Oktar", "Eyup Engin Kucuk", "Bo Feng", "Cameron R. Jones", "Izzy Gainsburg", "Sebastian Olschewski", "Nora Heinzelmann", "Francisco Cruz", "Ben M. Tappin", "Tao Ma", "Peter S. Park", "Rayan Onyonka", "Arthur Hjorth", "Peter Slattery", "Qingcheng Zeng", "Lennart Finke", "Igor Grossmann", "Alessandro Salatiello", "Ezra Karger"], "title": "Large Language Models Are More Persuasive Than Incentivized Human Persuaders", "categories": ["cs.CL", "I.2.7; H.1.2; K.4.1; H.5.2"], "comment": null, "summary": "We directly compare the persuasion capabilities of a frontier large language\nmodel (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an\ninteractive, real-time conversational quiz setting. In this preregistered,\nlarge-scale incentivized experiment, participants (quiz takers) completed an\nonline quiz where persuaders (either humans or LLMs) attempted to persuade quiz\ntakers toward correct or incorrect answers. We find that LLM persuaders\nachieved significantly higher compliance with their directional persuasion\nattempts than incentivized human persuaders, demonstrating superior persuasive\ncapabilities in both truthful (toward correct answers) and deceptive (toward\nincorrect answers) contexts. We also find that LLM persuaders significantly\nincreased quiz takers' accuracy, leading to higher earnings, when steering quiz\ntakers toward correct answers, and significantly decreased their accuracy,\nleading to lower earnings, when steering them toward incorrect answers.\nOverall, our findings suggest that AI's persuasion capabilities already exceed\nthose of humans that have real-money bonuses tied to performance. Our findings\nof increasingly capable AI persuaders thus underscore the urgency of emerging\nalignment and governance frameworks.", "AI": {"tldr": "LLMs outperform humans in persuasive tasks, increasing accuracy when truthful and decreasing it when deceptive, highlighting the need for AI governance.", "motivation": "To compare the persuasion capabilities of LLMs (Claude Sonnet 3.5) against incentivized humans in real-time conversations.", "method": "A preregistered, large-scale experiment where LLMs and humans attempted to persuade quiz takers toward correct or incorrect answers.", "result": "LLMs achieved higher compliance than humans, improving accuracy for truthful persuasion and reducing it for deceptive persuasion.", "conclusion": "AI's persuasion already surpasses incentivized humans, emphasizing the urgency of alignment and governance frameworks."}}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance.", "AI": {"tldr": "The paper introduces bilevel system prompt optimization for LLMs, focusing on robust and transferable system prompts across tasks, using a meta-learning framework.", "motivation": "Existing prompt optimization focuses on task-specific user prompts, neglecting system prompts that can generalize across tasks.", "method": "A meta-learning framework optimizes system prompts over diverse user prompts and datasets, iteratively updating both for synergy.", "result": "Experiments on 14 datasets show the optimized system prompts generalize well and enable rapid adaptation to unseen tasks with fewer steps.", "conclusion": "The approach effectively improves LLM performance by optimizing system prompts for robustness and transferability."}}
{"id": "2505.09936", "pdf": "https://arxiv.org/pdf/2505.09936", "abs": "https://arxiv.org/abs/2505.09936", "authors": ["Chenglong Wang", "Yuhao Kang", "Zhaoya Gong", "Pengjun Zhao", "Yu Feng", "Wenjia Zhang", "Ge Li"], "title": "CartoAgent: a multimodal large language model-powered multi-agent cartographic framework for map style transfer and evaluation", "categories": ["cs.HC", "cs.GR", "cs.MA", "cs.MM"], "comment": "57 pages, 17 figures", "summary": "The rapid development of generative artificial intelligence (GenAI) presents\nnew opportunities to advance the cartographic process. Previous studies have\neither overlooked the artistic aspects of maps or faced challenges in creating\nboth accurate and informative maps. In this study, we propose CartoAgent, a\nnovel multi-agent cartographic framework powered by multimodal large language\nmodels (MLLMs). This framework simulates three key stages in cartographic\npractice: preparation, map design, and evaluation. At each stage, different\nMLLMs act as agents with distinct roles to collaborate, discuss, and utilize\ntools for specific purposes. In particular, CartoAgent leverages MLLMs' visual\naesthetic capability and world knowledge to generate maps that are both\nvisually appealing and informative. By separating style from geographic data,\nit can focus on designing stylesheets without modifying the vector-based data,\nthereby ensuring geographic accuracy. We applied CartoAgent to a specific task\ncentered on map restyling-namely, map style transfer and evaluation. The\neffectiveness of this framework was validated through extensive experiments and\na human evaluation study. CartoAgent can be extended to support a variety of\ncartographic design decisions and inform future integrations of GenAI in\ncartography.", "AI": {"tldr": "CartoAgent, a multi-agent framework using MLLMs, enhances cartography by combining visual aesthetics and geographic accuracy, validated through experiments and human evaluation.", "motivation": "Addressing gaps in artistic map creation and ensuring accuracy, CartoAgent leverages MLLMs to improve cartographic design.", "method": "CartoAgent employs MLLMs in three stages (preparation, design, evaluation) to generate visually appealing and accurate maps, separating style from data.", "result": "Validated through experiments, CartoAgent successfully restyles maps while maintaining geographic accuracy and aesthetic appeal.", "conclusion": "CartoAgent demonstrates potential for broader cartographic applications and future GenAI integration in map design."}}
{"id": "2505.09841", "pdf": "https://arxiv.org/pdf/2505.09841", "abs": "https://arxiv.org/abs/2505.09841", "authors": ["Brooks A. Butler", "Magnus Egerstedt"], "title": "Hamilton's Rule for Enabling Altruism in Multi-Agent Systems", "categories": ["cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper explores the application of Hamilton's rule to altruistic\ndecision-making in multi-agent systems. Inspired by biological altruism, we\nintroduce a framework that evaluates when individual agents should incur costs\nto benefit their neighbors. By adapting Hamilton's rule, we define agent\n``fitness\" in terms of task productivity rather than genetic survival. We\nformalize altruistic decision-making through a graph-based model of multi-agent\ninteractions and propose a solution using collaborative control Lyapunov\nfunctions. The approach ensures that altruistic behaviors contribute to the\ncollective goal-reaching efficiency of the system. We illustrate this framework\non a multi-agent way-point navigation problem, where we show through simulation\nhow agent importance levels influence altruistic decision-making, leading to\nimproved coordination in navigation tasks.", "AI": {"tldr": "The paper applies Hamilton's rule to altruistic decision-making in multi-agent systems, using a graph-based model and collaborative control Lyapunov functions to improve collective efficiency.", "motivation": "Inspired by biological altruism, the study aims to determine when agents should act altruistically to benefit neighbors, adapting Hamilton's rule for task productivity.", "method": "A graph-based model formalizes altruistic decision-making, using collaborative control Lyapunov functions to ensure collective goal efficiency.", "result": "Simulations on a multi-agent navigation task show improved coordination when agent importance levels guide altruistic decisions.", "conclusion": "The framework successfully integrates Hamilton's rule into multi-agent systems, enhancing altruistic decision-making for collective efficiency."}}
{"id": "2505.09972", "pdf": "https://arxiv.org/pdf/2505.09972", "abs": "https://arxiv.org/abs/2505.09972", "authors": ["Anchen Sun", "Tiantian Feng", "Gabriela Gutierrez", "Juan J Londono", "Anfeng Xu", "Batya Elbaum", "Shrikanth Narayanan", "Lynn K Perry", "Daniel S Messinger"], "title": "Who Said What WSW 2.0? Enhanced Automated Analysis of Preschool Classroom Speech", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "8 pages, 2 figures, 5 tables", "summary": "This paper introduces an automated framework WSW2.0 for analyzing vocal\ninteractions in preschool classrooms, enhancing both accuracy and scalability\nthrough the integration of wav2vec2-based speaker classification and Whisper\n(large-v2 and large-v3) speech transcription. A total of 235 minutes of audio\nrecordings (160 minutes from 12 children and 75 minutes from 5 teachers), were\nused to compare system outputs to expert human annotations. WSW2.0 achieves a\nweighted F1 score of .845, accuracy of .846, and an error-corrected kappa of\n.672 for speaker classification (child vs. teacher). Transcription quality is\nmoderate to high with word error rates of .119 for teachers and .238 for\nchildren. WSW2.0 exhibits relatively high absolute agreement intraclass\ncorrelations (ICC) with expert transcriptions for a range of classroom language\nfeatures. These include teacher and child mean utterance length, lexical\ndiversity, question asking, and responses to questions and other utterances,\nwhich show absolute agreement intraclass correlations between .64 and .98. To\nestablish scalability, we apply the framework to an extensive dataset spanning\ntwo years and over 1,592 hours of classroom audio recordings, demonstrating the\nframework's robustness for broad real-world applications. These findings\nhighlight the potential of deep learning and natural language processing\ntechniques to revolutionize educational research by providing accurate measures\nof key features of preschool classroom speech, ultimately guiding more\neffective intervention strategies and supporting early childhood language\ndevelopment.", "AI": {"tldr": "WSW2.0 is an automated framework for analyzing preschool classroom vocal interactions, combining wav2vec2 and Whisper for speaker classification and transcription, achieving high accuracy and scalability.", "motivation": "To enhance accuracy and scalability in analyzing vocal interactions in preschool classrooms using deep learning and NLP techniques.", "method": "Integrates wav2vec2 for speaker classification and Whisper for speech transcription, validated against expert human annotations.", "result": "Achieves high F1 score (.845) and accuracy (.846) for speaker classification, with moderate to high transcription quality (WER .119-.238). Demonstrates scalability on a 1,592-hour dataset.", "conclusion": "WSW2.0 shows promise for revolutionizing educational research by providing accurate measures of classroom speech, aiding intervention strategies and language development."}}
{"id": "2505.09616", "pdf": "https://arxiv.org/pdf/2505.09616", "abs": "https://arxiv.org/abs/2505.09616", "authors": ["Yuqi Li", "Yuanzhong Zheng", "Zhongtian Guo", "Yaoxuan Wang", "Jianjun Yin", "Haojun Fei"], "title": "SpecWav-Attack: Leveraging Spectrogram Resizing and Wav2Vec 2.0 for Attacking Anonymized Speech", "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2.0"], "comment": "2 pages,3 figures,1 chart", "summary": "This paper presents SpecWav-Attack, an adversarial model for detecting\nspeakers in anonymized speech. It leverages Wav2Vec2 for feature extraction and\nincorporates spectrogram resizing and incremental training for improved\nperformance. Evaluated on librispeech-dev and librispeech-test, SpecWav-Attack\noutperforms conventional attacks, revealing vulnerabilities in anonymized\nspeech systems and emphasizing the need for stronger defenses, benchmarked\nagainst the ICASSP 2025 Attacker Challenge.", "AI": {"tldr": "SpecWav-Attack is an adversarial model for detecting speakers in anonymized speech, using Wav2Vec2 and spectrogram resizing, outperforming conventional attacks.", "motivation": "To expose vulnerabilities in anonymized speech systems and highlight the need for stronger defenses.", "method": "Uses Wav2Vec2 for feature extraction, spectrogram resizing, and incremental training.", "result": "Outperforms conventional attacks on librispeech-dev and librispeech-test datasets.", "conclusion": "Reveals weaknesses in anonymized speech systems, urging improved defenses for future challenges like ICASSP 2025."}}
{"id": "2505.09831", "pdf": "https://arxiv.org/pdf/2505.09831", "abs": "https://arxiv.org/abs/2505.09831", "authors": ["Tushar Kataria", "Beatrice Knudsen", "Shireen Y. Elhabian"], "title": "ImplicitStainer: Data-Efficient Medical Image Translation for Virtual Antibody-based Tissue Staining Using Local Implicit Functions", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Hematoxylin and eosin (H&E) staining is a gold standard for microscopic\ndiagnosis in pathology. However, H&E staining does not capture all the\ndiagnostic information that may be needed. To obtain additional molecular\ninformation, immunohistochemical (IHC) stains highlight proteins that mark\nspecific cell types, such as CD3 for T-cells or CK8/18 for epithelial cells.\nWhile IHC stains are vital for prognosis and treatment guidance, they are\ntypically only available at specialized centers and time consuming to acquire,\nleading to treatment delays for patients. Virtual staining, enabled by deep\nlearning-based image translation models, provides a promising alternative by\ncomputationally generating IHC stains from H&E stained images. Although many\nGAN and diffusion based image to image (I2I) translation methods have been used\nfor virtual staining, these models treat image patches as independent data\npoints, which results in increased and more diverse data requirements for\neffective generation. We present ImplicitStainer, a novel approach that\nleverages local implicit functions to improve image translation, specifically\nvirtual staining performance, by focusing on pixel-level predictions. This\nmethod enhances robustness to variations in dataset sizes, delivering\nhigh-quality results even with limited data. We validate our approach on two\ndatasets using a comprehensive set of metrics and benchmark it against over\nfifteen state-of-the-art GAN- and diffusion based models. Full Code and models\ntrained will be released publicly via Github upon acceptance.", "AI": {"tldr": "ImplicitStainer improves virtual staining of H&E images to IHC using local implicit functions, reducing data needs and outperforming GAN/diffusion models.", "motivation": "H&E lacks molecular detail; IHC is slow and limited. Virtual staining via deep learning offers a faster alternative.", "method": "Uses local implicit functions for pixel-level predictions, enhancing robustness with limited data.", "result": "Outperforms 15+ state-of-the-art models, validated on two datasets with comprehensive metrics.", "conclusion": "ImplicitStainer is efficient for virtual staining, even with small datasets, and will be publicly released."}}
{"id": "2505.09746", "pdf": "https://arxiv.org/pdf/2505.09746", "abs": "https://arxiv.org/abs/2505.09746", "authors": ["Xabier Morales", "Ayah Elsayed", "Debbie Zhao", "Filip Loncaric", "Ainhoa Aguado", "Mireia Masias", "Gina Quill", "Marc Ramos", "Ada Doltra", "Ana Garcia", "Marta Sitges", "David Marlevi", "Alistair Young", "Martyn Nash", "Bart Bijnens", "Oscar Camara"], "title": "A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium", "categories": ["cs.CV"], "comment": null, "summary": "The left atrium (LA) plays a pivotal role in modulating left ventricular\nfilling, but our comprehension of its hemodynamics is significantly limited by\nthe constraints of conventional ultrasound analysis. 4D flow magnetic resonance\nimaging (4D Flow MRI) holds promise for enhancing our understanding of atrial\nhemodynamics. However, the low velocities within the LA and the limited spatial\nresolution of 4D Flow MRI make analyzing this chamber challenging. Furthermore,\nthe absence of dedicated computational frameworks, combined with diverse\nacquisition protocols and vendors, complicates gathering large cohorts for\nstudying the prognostic value of hemodynamic parameters provided by 4D Flow\nMRI. In this study, we introduce the first open-source computational framework\ntailored for the analysis of 4D Flow MRI in the LA, enabling comprehensive\nqualitative and quantitative analysis of advanced hemodynamic parameters. Our\nframework proves robust to data from different centers of varying quality,\nproducing high-accuracy automated segmentations (Dice $>$ 0.9 and Hausdorff 95\n$<$ 3 mm), even with limited training data. Additionally, we conducted the\nfirst comprehensive assessment of energy, vorticity, and pressure parameters in\nthe LA across a spectrum of disorders to investigate their potential as\nprognostic biomarkers.", "AI": {"tldr": "The paper introduces an open-source computational framework for analyzing 4D Flow MRI in the left atrium (LA), addressing challenges like low velocities and diverse protocols. It enables accurate hemodynamic parameter analysis and explores their prognostic potential.", "motivation": "Current limitations in understanding LA hemodynamics due to conventional ultrasound constraints and the lack of dedicated computational tools for 4D Flow MRI analysis.", "method": "Development of an open-source framework for qualitative and quantitative analysis of 4D Flow MRI in the LA, tested across diverse datasets.", "result": "High-accuracy automated segmentations (Dice > 0.9, Hausdorff 95 < 3 mm) and comprehensive assessment of hemodynamic parameters (energy, vorticity, pressure) in various disorders.", "conclusion": "The framework enhances LA hemodynamic analysis and identifies potential prognostic biomarkers, demonstrating robustness across diverse data sources."}}
{"id": "2505.09659", "pdf": "https://arxiv.org/pdf/2505.09659", "abs": "https://arxiv.org/abs/2505.09659", "authors": ["Long Chen", "Xiaotian Song", "Yanan Sun"], "title": "LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Spiking Large Language Models (LLMs) have emerged as an energy-efficient\nalternative to conventional LLMs through their event-driven computation. To\neffectively obtain spiking LLMs, researchers develop different ANN-to-SNN\nconversion methods by leveraging pre-trained ANN parameters while inheriting\nthe energy efficiency of SNN. However, existing conversion methods struggle\nwith extreme activation outliers and incompatible nonlinear operations of\nANN-based LLMs. To address this, we propose a loss-less ANN-SNN conversion for\nfully spike-driven LLMs, termed LAS. Specifically, LAS introduces two novel\nneurons to convert the activation outlier and nonlinear operation of ANN-based\nLLMs. Moreover, LAS tailors the spike-equivalent Transformer components for\nspiking LLMs, which can ensure full spiking conversion without any loss of\nperformance. Experimental results on six language models and two\nvision-language models demonstrate that LAS achieves loss-less conversion.\nNotably, on OPT-66B, LAS even improves the accuracy of 2\\% on the WSC task. In\naddition, the parameter and ablation studies further verify the effectiveness\nof LAS. The source code is available at https://github.com/lc783/LAS", "AI": {"tldr": "LAS is a loss-less ANN-to-SNN conversion method for spiking LLMs, addressing activation outliers and nonlinear operations while maintaining performance.", "motivation": "Existing ANN-to-SNN conversion methods struggle with activation outliers and incompatible nonlinear operations in LLMs, limiting their effectiveness.", "method": "LAS introduces two novel neurons for outlier and nonlinear operation conversion, and tailors spike-equivalent Transformer components for full spiking conversion.", "result": "LAS achieves loss-less conversion on six language and two vision-language models, even improving accuracy by 2% on OPT-66B for the WSC task.", "conclusion": "LAS effectively enables full spiking conversion for LLMs without performance loss, validated by experiments and ablation studies."}}
{"id": "2505.09639", "pdf": "https://arxiv.org/pdf/2505.09639", "abs": "https://arxiv.org/abs/2505.09639", "authors": ["Quentin Cohen-Solal"], "title": "Study and improvement of search algorithms in two-players perfect information games", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "Games, in their mathematical sense, are everywhere (game industries,\neconomics, defense, education, chemistry, biology, ...).Search algorithms in\ngames are artificial intelligence methods for playing such games.\nUnfortunately, there is no study on these algorithms that evaluates the\ngenerality of their performance. We propose to address this gap in the case of\ntwo-player zero-sum games with perfect information. Furthermore, we propose a\nnew search algorithm and we show that, for a short search time, it outperforms\nall studied algorithms on all games in this large experiment and that, for a\nmedium search time, it outperforms all studied algorithms on 17 of the 22\nstudied games.", "AI": {"tldr": "The paper evaluates the generality of search algorithms in two-player zero-sum games with perfect information, introduces a new algorithm, and demonstrates its superior performance in short and medium search times.", "motivation": "There is no existing study evaluating the generality of search algorithm performance in games, particularly for two-player zero-sum games with perfect information.", "method": "The authors propose a new search algorithm and compare its performance against other studied algorithms across 22 games, focusing on short and medium search times.", "result": "The new algorithm outperforms all others in short search times across all games and in medium search times for 17 out of 22 games.", "conclusion": "The study fills a gap in evaluating search algorithm generality and demonstrates the effectiveness of the proposed algorithm in two-player zero-sum games."}}
{"id": "2505.09701", "pdf": "https://arxiv.org/pdf/2505.09701", "abs": "https://arxiv.org/abs/2505.09701", "authors": ["Xin Liu", "Lechen Zhang", "Sheza Munir", "Yiyang Gu", "Lu Wang"], "title": "VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel at generating long-form responses, but\nevaluating their factuality remains challenging due to complex inter-sentence\ndependencies within the generated facts. Prior solutions predominantly follow a\ndecompose-decontextualize-verify pipeline but often fail to capture essential\ncontext and miss key relational facts. In this paper, we introduce VeriFact, a\nfactuality evaluation framework designed to enhance fact extraction by\nidentifying and resolving incomplete and missing facts to support more accurate\nverification results. Moreover, we introduce FactRBench , a benchmark that\nevaluates both precision and recall in long-form model responses, whereas prior\nwork primarily focuses on precision. FactRBench provides reference fact sets\nfrom advanced LLMs and human-written answers, enabling recall assessment.\nEmpirical evaluations show that VeriFact significantly enhances fact\ncompleteness and preserves complex facts with critical relational information,\nresulting in more accurate factuality evaluation. Benchmarking various open-\nand close-weight LLMs on FactRBench indicate that larger models within same\nmodel family improve precision and recall, but high precision does not always\ncorrelate with high recall, underscoring the importance of comprehensive\nfactuality assessment.", "AI": {"tldr": "VeriFact is a framework improving factuality evaluation in LLMs by addressing incomplete facts, while FactRBench benchmarks precision and recall in long-form responses.", "motivation": "Existing methods for evaluating LLM factuality often miss context and relational facts, necessitating a better framework.", "method": "Introduces VeriFact for enhanced fact extraction and verification, and FactRBench for evaluating precision and recall.", "result": "VeriFact improves fact completeness and preserves relational facts, while FactRBench shows larger models enhance precision and recall.", "conclusion": "Comprehensive factuality assessment is crucial, as high precision doesn't always mean high recall."}}
{"id": "2505.10101", "pdf": "https://arxiv.org/pdf/2505.10101", "abs": "https://arxiv.org/abs/2505.10101", "authors": ["Jongmin Jung", "Dasaem Jeong"], "title": "LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2", "categories": ["cs.SD", "cs.AI", "cs.GR", "cs.MM", "eess.AS"], "comment": "Paper accepted at ISEA 2025, The 30th International Symposium on\n  Electronic/Emerging Art, Seoul, Republic of Korea, 23 - 29 May 2025", "summary": "This paper introduces LAV (Latent Audio-Visual), a system that integrates\nEnCodec's neural audio compression with StyleGAN2's generative capabilities to\nproduce visually dynamic outputs driven by pre-recorded audio. Unlike previous\nworks that rely on explicit feature mappings, LAV uses EnCodec embeddings as\nlatent representations, directly transformed into StyleGAN2's style latent\nspace via randomly initialized linear mapping. This approach preserves semantic\nrichness in the transformation, enabling nuanced and semantically coherent\naudio-visual translations. The framework demonstrates the potential of using\npretrained audio compression models for artistic and computational\napplications.", "AI": {"tldr": "LAV integrates EnCodec's audio compression with StyleGAN2 to generate dynamic visuals from audio, using latent representations for richer translations.", "motivation": "To explore nuanced audio-visual translations without explicit feature mappings, leveraging pretrained models for artistic applications.", "method": "Uses EnCodec embeddings as latent representations, mapped linearly into StyleGAN2's style space for semantic coherence.", "result": "Produces semantically rich and coherent audio-visual outputs, showcasing pretrained models' potential.", "conclusion": "LAV demonstrates effective audio-driven visual generation, highlighting the utility of pretrained models in creative applications."}}
{"id": "2505.10387", "pdf": "https://arxiv.org/pdf/2505.10387", "abs": "https://arxiv.org/abs/2505.10387", "authors": ["Artem Agafonov", "Konstantin Yakovlev"], "title": "Multi-Agent Path Finding For Large Agents Is Intractable", "categories": ["cs.MA", "cs.AI", "cs.CC"], "comment": null, "summary": "The multi-agent path finding (MAPF) problem asks to find a set of paths on a\ngraph such that when synchronously following these paths the agents never\nencounter a conflict. In the most widespread MAPF formulation, the so-called\nClassical MAPF, the agents sizes are neglected and two types of conflicts are\nconsidered: occupying the same vertex or using the same edge at the same time\nstep. Meanwhile in numerous practical applications, e.g. in robotics, taking\ninto account the agents' sizes is vital to ensure that the MAPF solutions can\nbe safely executed. Introducing large agents yields an additional type of\nconflict arising when one agent follows an edge and its body overlaps with the\nbody of another agent that is actually not using this same edge (e.g. staying\nstill at some distinct vertex of the graph). Until now it was not clear how\nharder the problem gets when such conflicts are to be considered while\nplanning. Specifically, it was known that Classical MAPF problem on an\nundirected graph can be solved in polynomial time, however no complete\npolynomial-time algorithm was presented to solve MAPF with large agents. In\nthis paper we, for the first time, establish that the latter problem is NP-hard\nand, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be\npresented. Our proof is based on the prevalent in the field technique of\nreducing the seminal 3SAT problem (which is known to be an NP-complete problem)\nto the problem at hand. In particular, for an arbitrary 3SAT formula we\nprocedurally construct a dedicated graph with specific start and goal vertices\nand show that the given 3SAT formula is satisfiable iff the corresponding path\nfinding instance has a solution.", "AI": {"tldr": "The paper proves that MAPF with large agents is NP-hard, contrasting with Classical MAPF, which is solvable in polynomial time.", "motivation": "Practical applications like robotics require accounting for agent sizes to ensure safe execution, but the computational complexity of such MAPF variants was unclear.", "method": "The authors reduce the NP-complete 3SAT problem to MAPF with large agents, constructing a graph where 3SAT satisfiability corresponds to path-finding solvability.", "result": "MAPF with large agents is shown to be NP-hard, implying no polynomial-time solution exists unless P=NP.", "conclusion": "The study confirms the increased complexity of MAPF when agent sizes are considered, closing a gap in understanding its computational limits."}}
{"id": "2505.10372", "pdf": "https://arxiv.org/pdf/2505.10372", "abs": "https://arxiv.org/abs/2505.10372", "authors": ["Tong Xiao", "Simon Doclo"], "title": "Spatially Selective Active Noise Control for Open-fitting Hearables with Acausal Optimization", "categories": ["eess.AS", "cs.SD", "cs.SY", "eess.SP", "eess.SY"], "comment": "Forum Acusticum/Euronoise 2025", "summary": "Recent advances in active noise control have enabled the development of\nhearables with spatial selectivity, which actively suppress undesired noise\nwhile preserving desired sound from specific directions. In this work, we\npropose an improved approach to spatially selective active noise control that\nincorporates acausal relative impulse responses into the optimization process,\nresulting in significantly improved performance over the causal design. We\nevaluate the system through simulations using a pair of open-fitting hearables\nwith spatially localized speech and noise sources in an anechoic environment.\nPerformance is evaluated in terms of speech distortion, noise reduction, and\nsignal-to-noise ratio improvement across different delays and degrees of\nacausality. Results show that the proposed acausal optimization consistently\noutperforms the causal approach across all metrics and scenarios, as acausal\nfilters more effectively characterize the response of the desired source.", "AI": {"tldr": "An improved spatially selective active noise control method using acausal relative impulse responses outperforms causal designs in hearables.", "motivation": "Enhance spatial selectivity in hearables by improving noise suppression while preserving desired sounds from specific directions.", "method": "Incorporates acausal relative impulse responses into optimization, evaluated via simulations with open-fitting hearables in an anechoic environment.", "result": "Acausal optimization consistently outperforms causal methods in speech distortion, noise reduction, and SNR improvement.", "conclusion": "Acausal filters better characterize desired source responses, offering superior performance in spatially selective noise control."}}
{"id": "2505.09633", "pdf": "https://arxiv.org/pdf/2505.09633", "abs": "https://arxiv.org/abs/2505.09633", "authors": ["Nick Sunday"], "title": "Detecting Musical Deepfakes", "categories": ["cs.SD", "cs.LG"], "comment": "Submitted as part of coursework at UT Austin. Accompanying code\n  available at: https://github.com/nicksunday/deepfake-music-detector", "summary": "The proliferation of Text-to-Music (TTM) platforms has democratized music\ncreation, enabling users to effortlessly generate high-quality compositions.\nHowever, this innovation also presents new challenges to musicians and the\nbroader music industry. This study investigates the detection of AI-generated\nsongs using the FakeMusicCaps dataset by classifying audio as either deepfake\nor human. To simulate real-world adversarial conditions, tempo stretching and\npitch shifting were applied to the dataset. Mel spectrograms were generated\nfrom the modified audio, then used to train and evaluate a convolutional neural\nnetwork. In addition to presenting technical results, this work explores the\nethical and societal implications of TTM platforms, arguing that carefully\ndesigned detection systems are essential to both protecting artists and\nunlocking the positive potential of generative AI in music.", "AI": {"tldr": "The study detects AI-generated music using a CNN trained on modified audio data, addressing ethical concerns of TTM platforms.", "motivation": "The rise of TTM platforms poses challenges for musicians and the music industry, necessitating detection methods for AI-generated music.", "method": "Used the FakeMusicCaps dataset, applied tempo stretching and pitch shifting, generated Mel spectrograms, and trained a CNN for classification.", "result": "The CNN effectively classified audio as deepfake or human, demonstrating robustness under adversarial conditions.", "conclusion": "Detection systems are crucial for protecting artists and harnessing the benefits of generative AI in music."}}
{"id": "2505.09985", "pdf": "https://arxiv.org/pdf/2505.09985", "abs": "https://arxiv.org/abs/2505.09985", "authors": ["Pengfei Yu", "Bin Huang", "Minghui Zhang", "Weiwen Wu", "Shaoyu Wang", "Qiegen Liu"], "title": "Ordered-subsets Multi-diffusion Model for Sparse-view CT Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Score-based diffusion models have shown significant promise in the field of\nsparse-view CT reconstruction. However, the projection dataset is large and\nriddled with redundancy. Consequently, applying the diffusion model to\nunprocessed data results in lower learning effectiveness and higher learning\ndifficulty, frequently leading to reconstructed images that lack fine details.\nTo address these issues, we propose the ordered-subsets multi-diffusion model\n(OSMM) for sparse-view CT reconstruction. The OSMM innovatively divides the CT\nprojection data into equal subsets and employs multi-subsets diffusion model\n(MSDM) to learn from each subset independently. This targeted learning approach\nreduces complexity and enhances the reconstruction of fine details.\nFurthermore, the integration of one-whole diffusion model (OWDM) with complete\nsinogram data acts as a global information constraint, which can reduce the\npossibility of generating erroneous or inconsistent sinogram information.\nMoreover, the OSMM's unsupervised learning framework provides strong robustness\nand generalizability, adapting seamlessly to varying sparsity levels of CT\nsinograms. This ensures consistent and reliable performance across different\nclinical scenarios. Experimental results demonstrate that OSMM outperforms\ntraditional diffusion models in terms of image quality and noise resilience,\noffering a powerful and versatile solution for advanced CT imaging in\nsparse-view scenarios.", "AI": {"tldr": "The paper introduces the ordered-subsets multi-diffusion model (OSMM) for sparse-view CT reconstruction, improving detail retention and noise resilience by dividing data into subsets and using a global constraint.", "motivation": "Existing score-based diffusion models struggle with large, redundant projection data, leading to poor detail reconstruction and high learning difficulty.", "method": "OSMM divides CT projection data into subsets, applies multi-subsets diffusion model (MSDM) for targeted learning, and integrates a one-whole diffusion model (OWDM) for global constraints.", "result": "OSMM outperforms traditional models in image quality and noise resilience, adapting well to varying sparsity levels.", "conclusion": "OSMM offers a robust, versatile solution for sparse-view CT reconstruction, enhancing detail and consistency."}}
{"id": "2505.09827", "pdf": "https://arxiv.org/pdf/2505.09827", "abs": "https://arxiv.org/abs/2505.09827", "authors": ["Julian Tanke", "Takashi Shibuya", "Kengo Uchida", "Koichi Saito", "Yuki Mitsufuji"], "title": "Dyadic Mamba: Long-term Dyadic Human Motion Synthesis", "categories": ["cs.CV"], "comment": "CVPR 2025 HuMoGen Workshop", "summary": "Generating realistic dyadic human motion from text descriptions presents\nsignificant challenges, particularly for extended interactions that exceed\ntypical training sequence lengths. While recent transformer-based approaches\nhave shown promising results for short-term dyadic motion synthesis, they\nstruggle with longer sequences due to inherent limitations in positional\nencoding schemes. In this paper, we introduce Dyadic Mamba, a novel approach\nthat leverages State-Space Models (SSMs) to generate high-quality dyadic human\nmotion of arbitrary length. Our method employs a simple yet effective\narchitecture that facilitates information flow between individual motion\nsequences through concatenation, eliminating the need for complex\ncross-attention mechanisms. We demonstrate that Dyadic Mamba achieves\ncompetitive performance on standard short-term benchmarks while significantly\noutperforming transformer-based approaches on longer sequences. Additionally,\nwe propose a new benchmark for evaluating long-term motion synthesis quality,\nproviding a standardized framework for future research. Our results demonstrate\nthat SSM-based architectures offer a promising direction for addressing the\nchallenging task of long-term dyadic human motion synthesis from text\ndescriptions.", "AI": {"tldr": "Dyadic Mamba uses State-Space Models (SSMs) to generate realistic long-term dyadic human motion from text, outperforming transformer-based methods.", "motivation": "Addressing the challenge of generating extended dyadic human motion sequences from text, where transformers fall short due to positional encoding limitations.", "method": "Leverages SSMs with a simple architecture for seamless information flow between motion sequences, avoiding complex cross-attention.", "result": "Competitive on short-term benchmarks and superior on long-term sequences, with a new benchmark proposed for evaluation.", "conclusion": "SSM-based architectures like Dyadic Mamba are promising for long-term dyadic motion synthesis."}}
{"id": "2505.09663", "pdf": "https://arxiv.org/pdf/2505.09663", "abs": "https://arxiv.org/abs/2505.09663", "authors": ["Julian B\u00fcchel", "Iason Chalas", "Giovanni Acampa", "An Chen", "Omobayode Fagbohungbe", "Sidney Tsai", "Kaoutar El Maghraoui", "Manuel Le Gallo", "Abbas Rahimi", "Abu Sebastian"], "title": "Analog Foundation Models", "categories": ["cs.LG"], "comment": "43 pages, 8 figures, under review", "summary": "Analog in-memory computing (AIMC) is a promising compute paradigm to improve\nspeed and power efficiency of neural network inference beyond the limits of\nconventional von Neumann-based architectures. However, AIMC introduces\nfundamental challenges such as noisy computations and strict constraints on\ninput and output quantization. Because of these constraints and imprecisions,\noff-the-shelf LLMs are not able to achieve 4-bit-level performance when\ndeployed on AIMC-based hardware. While researchers previously investigated\nrecovering this accuracy gap on small, mostly vision-based models, a generic\nmethod applicable to LLMs pre-trained on trillions of tokens does not yet\nexist. In this work, we introduce a general and scalable method to robustly\nadapt LLMs for execution on noisy, low-precision analog hardware. Our approach\nenables state-of-the-art models $\\unicode{x2013}$ including\nPhi-3-mini-4k-instruct and Llama-3.2-1B-Instruct $\\unicode{x2013}$ to retain\nperformance comparable to 4-bit weight, 8-bit activation baselines, despite the\npresence of analog noise and quantization constraints. Additionally, we show\nthat as a byproduct of our training methodology, analog foundation models can\nbe quantized for inference on low-precision digital hardware. Finally, we show\nthat our models also benefit from test-time compute scaling, showing better\nscaling behavior than models trained with 4-bit weight and 8-bit static input\nquantization. Our work bridges the gap between high-capacity LLMs and efficient\nanalog hardware, offering a path toward energy-efficient foundation models.\nCode is available at https://github.com/IBM/analog-foundation-models .", "AI": {"tldr": "A general method to adapt LLMs for noisy, low-precision analog hardware, achieving 4-bit-level performance and enabling energy-efficient foundation models.", "motivation": "Analog in-memory computing (AIMC) offers speed and power efficiency but introduces noise and quantization constraints, limiting LLM performance.", "method": "Introduces a scalable training methodology to robustly adapt LLMs for AIMC, handling analog noise and quantization.", "result": "Achieves performance comparable to 4-bit weight, 8-bit activation baselines and benefits from test-time compute scaling.", "conclusion": "Bridges the gap between high-capacity LLMs and analog hardware, enabling energy-efficient foundation models."}}
{"id": "2505.09640", "pdf": "https://arxiv.org/pdf/2505.09640", "abs": "https://arxiv.org/abs/2505.09640", "authors": ["Tom\u00e1s Capdevielle", "Santiago Cifuentes"], "title": "Feature Relevancy, Necessity and Usefulness: Complexity and Algorithms", "categories": ["cs.AI", "68T01", "I.2.0"], "comment": "22 pages, 7 figures", "summary": "Given a classification model and a prediction for some input, there are\nheuristic strategies for ranking features according to their importance in\nregard to the prediction. One common approach to this task is rooted in\npropositional logic and the notion of \\textit{sufficient reason}. Through this\nconcept, the categories of relevant and necessary features were proposed in\norder to identify the crucial aspects of the input. This paper improves the\nexisting techniques and algorithms for deciding which are the relevant and/or\nnecessary features, showing in particular that necessity can be detected\nefficiently in complex models such as neural networks. We also generalize the\nnotion of relevancy and study associated problems. Moreover, we present a new\nglobal notion (i.e. that intends to explain whether a feature is important for\nthe behavior of the model in general, not depending on a particular input) of\n\\textit{usefulness} and prove that it is related to relevancy and necessity.\nFurthermore, we develop efficient algorithms for detecting it in decision trees\nand other more complex models, and experiment on three datasets to analyze its\npractical utility.", "AI": {"tldr": "The paper improves techniques for identifying relevant and necessary features in model predictions, introduces a global notion of 'usefulness,' and develops efficient algorithms for detecting it in various models, including neural networks and decision trees.", "motivation": "To enhance existing methods for feature importance ranking and introduce a generalized notion of feature usefulness, applicable across different models.", "method": "Improves existing algorithms for detecting relevant and necessary features, generalizes relevancy, and introduces a new global notion of usefulness. Efficient algorithms are developed for decision trees and complex models.", "result": "Demonstrates efficient detection of necessity in complex models, relates usefulness to relevancy and necessity, and validates practical utility through experiments on three datasets.", "conclusion": "The paper advances feature importance analysis by introducing and efficiently detecting a global notion of usefulness, alongside improving existing techniques for relevancy and necessity."}}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-D\u00edaz", "William Jim\u00e9nez-Leal", "Mar\u00eda Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Berm\u00fadez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis.", "AI": {"tldr": "A tutorial on using LLMs for efficient, iterative text analysis with predefined or data-driven taxonomies, demonstrated with personal goals data.", "motivation": "Text analysis is often biased and labor-intensive; LLMs offer a promising solution without quality loss.", "method": "Step-by-step tutorial involving iterative collaboration between researchers and LLMs, including prompt writing, taxonomy evaluation, and intercoder reliability testing.", "result": "High intercoder reliability achieved when applying the taxonomy to categorize datasets.", "conclusion": "LLMs are effective for text analysis but have limitations; the method is practical and collaborative."}}
{"id": "2504.19458", "pdf": "https://arxiv.org/pdf/2504.19458", "abs": "https://arxiv.org/abs/2504.19458", "authors": ["Taoyu Su", "Jiawei Sheng", "Duohe Ma", "Xiaodong Li", "Juwei Yue", "Mengxiao Song", "Yingkai Tang", "Tingwen Liu"], "title": "Mitigating Modality Bias in Multi-modal Entity Alignment from a Causal Perspective", "categories": ["cs.MM", "cs.CL", "cs.IR"], "comment": "Accepted by SIGIR 2025, 11 pages, 10 figures, 4 tables,", "summary": "Multi-Modal Entity Alignment (MMEA) aims to retrieve equivalent entities from\ndifferent Multi-Modal Knowledge Graphs (MMKGs), a critical information\nretrieval task. Existing studies have explored various fusion paradigms and\nconsistency constraints to improve the alignment of equivalent entities, while\noverlooking that the visual modality may not always contribute positively.\nEmpirically, entities with low-similarity images usually generate\nunsatisfactory performance, highlighting the limitation of overly relying on\nvisual features. We believe the model can be biased toward the visual modality,\nleading to a shortcut image-matching task. To address this, we propose a\ncounterfactual debiasing framework for MMEA, termed CDMEA, which investigates\nvisual modality bias from a causal perspective. Our approach aims to leverage\nboth visual and graph modalities to enhance MMEA while suppressing the direct\ncausal effect of the visual modality on model predictions. By estimating the\nTotal Effect (TE) of both modalities and excluding the Natural Direct Effect\n(NDE) of the visual modality, we ensure that the model predicts based on the\nTotal Indirect Effect (TIE), effectively utilizing both modalities and reducing\nvisual modality bias. Extensive experiments on 9 benchmark datasets show that\nCDMEA outperforms 14 state-of-the-art methods, especially in low-similarity,\nhigh-noise, and low-resource data scenarios.", "AI": {"tldr": "CDMEA is a counterfactual debiasing framework for Multi-Modal Entity Alignment (MMEA) that reduces visual modality bias by leveraging causal effects, outperforming 14 state-of-the-art methods.", "motivation": "Existing MMEA methods overly rely on visual features, which can bias the model and degrade performance for entities with low-similarity images.", "method": "CDMEA estimates the Total Effect (TE) of visual and graph modalities, excludes the Natural Direct Effect (NDE) of visual modality, and focuses on the Total Indirect Effect (TIE) to reduce bias.", "result": "CDMEA outperforms 14 state-of-the-art methods across 9 benchmark datasets, particularly in low-similarity, high-noise, and low-resource scenarios.", "conclusion": "The proposed CDMEA framework effectively mitigates visual modality bias in MMEA, improving alignment performance by leveraging causal analysis."}}
{"id": "2505.09756", "pdf": "https://arxiv.org/pdf/2505.09756", "abs": "https://arxiv.org/abs/2505.09756", "authors": ["Zhaoyang Shi"], "title": "Community-based Multi-Agent Reinforcement Learning with Transfer and Active Exploration", "categories": ["cs.LG", "cs.MA", "math.OC", "stat.ML"], "comment": null, "summary": "We propose a new framework for multi-agent reinforcement learning (MARL),\nwhere the agents cooperate in a time-evolving network with latent community\nstructures and mixed memberships. Unlike traditional neighbor-based or fixed\ninteraction graphs, our community-based framework captures flexible and\nabstract coordination patterns by allowing each agent to belong to multiple\noverlapping communities. Each community maintains shared policy and value\nfunctions, which are aggregated by individual agents according to personalized\nmembership weights. We also design actor-critic algorithms that exploit this\nstructure: agents inherit community-level estimates for policy updates and\nvalue learning, enabling structured information sharing without requiring\naccess to other agents' policies. Importantly, our approach supports both\ntransfer learning by adapting to new agents or tasks via membership estimation,\nand active learning by prioritizing uncertain communities during exploration.\nTheoretically, we establish convergence guarantees under linear function\napproximation for both actor and critic updates. To our knowledge, this is the\nfirst MARL framework that integrates community structure, transferability, and\nactive learning with provable guarantees.", "AI": {"tldr": "A new MARL framework introduces community-based coordination, enabling flexible agent interactions, transfer learning, and active learning with provable guarantees.", "motivation": "Traditional MARL methods rely on fixed or neighbor-based interactions, lacking flexibility and adaptability. This work aims to capture abstract coordination patterns and improve learning efficiency.", "method": "Agents belong to overlapping communities with shared policies and value functions. Actor-critic algorithms leverage community-level estimates for policy updates and value learning, supporting transfer and active learning.", "result": "The framework achieves convergence under linear function approximation and integrates community structure, transferability, and active learning.", "conclusion": "This is the first MARL framework combining community-based coordination, transfer learning, and active learning with theoretical guarantees."}}
{"id": "2505.10500", "pdf": "https://arxiv.org/pdf/2505.10500", "abs": "https://arxiv.org/abs/2505.10500", "authors": ["Tu Duyen Nguyen", "Adrien Lesage", "Clotilde Cantini", "Rachid Riad"], "title": "Quantized Approximate Signal Processing (QASP): Towards Homomorphic Encryption for audio", "categories": ["eess.AS", "cs.CR", "cs.SD"], "comment": "34 pages, 5 figures", "summary": "Audio and speech data are increasingly used in machine learning applications\nsuch as speech recognition, speaker identification, and mental health\nmonitoring. However, the passive collection of this data by audio listening\ndevices raises significant privacy concerns. Fully homomorphic encryption (FHE)\noffers a promising solution by enabling computations on encrypted data and\npreserving user privacy. Despite its potential, prior attempts to apply FHE to\naudio processing have faced challenges, particularly in securely computing time\nfrequency representations, a critical step in many audio tasks.\n  Here, we addressed this gap by introducing a fully secure pipeline that\ncomputes, with FHE and quantized neural network operations, four fundamental\ntime-frequency representations: Short-Time Fourier Transform (STFT), Mel\nfilterbanks, Mel-frequency cepstral coefficients (MFCCs), and gammatone\nfilters. Our methods also support the private computation of audio descriptors\nand convolutional neural network (CNN) classifiers. Besides, we proposed\napproximate STFT algorithms that lighten computation and bit use for\nstatistical and machine learning analyses.\n  We ran experiments on the VocalSet and OxVoc datasets demonstrating the fully\nprivate computation of our approach. We showed significant performance\nimprovements with STFT approximation in private statistical analysis of audio\nmarkers, and for vocal exercise classification with CNNs. Our results reveal\nthat our approximations substantially reduce error rates compared to\nconventional STFT implementations in FHE. We also demonstrated a fully private\nclassification based on the raw audio for gender and vocal exercise\nclassification. Finally, we provided a practical heuristic for parameter\nselection, making quantized approximate signal processing accessible to\nresearchers and practitioners aiming to protect sensitive audio data.", "AI": {"tldr": "The paper introduces a secure pipeline using FHE for private audio processing, addressing challenges in time-frequency representations and demonstrating improved performance with approximations.", "motivation": "Privacy concerns in audio data collection for machine learning applications necessitate secure methods like FHE to enable computations on encrypted data.", "method": "A fully secure pipeline using FHE and quantized neural networks to compute time-frequency representations (STFT, Mel filterbanks, MFCCs, gammatone filters) and support private CNN classifiers.", "result": "Experiments on VocalSet and OxVoc datasets showed improved performance with STFT approximations, reducing error rates and enabling fully private audio classification.", "conclusion": "The proposed methods offer practical, secure solutions for audio processing, with heuristics for parameter selection to aid researchers and practitioners."}}
{"id": "2505.09661", "pdf": "https://arxiv.org/pdf/2505.09661", "abs": "https://arxiv.org/abs/2505.09661", "authors": ["Jinghao He", "Zhengyan Sheng", "Liping Chen", "Kong Aik Lee", "Zhen-Hua Ling"], "title": "Introducing voice timbre attribute detection", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "This paper focuses on explaining the timbre conveyed by speech signals and\nintroduces a task termed voice timbre attribute detection (vTAD). In this task,\nvoice timbre is explained with a set of sensory attributes describing its human\nperception. A pair of speech utterances is processed, and their intensity is\ncompared in a designated timbre descriptor. Moreover, a framework is proposed,\nwhich is built upon the speaker embeddings extracted from the speech\nutterances. The investigation is conducted on the VCTK-RVA dataset.\nExperimental examinations on the ECAPA-TDNN and FACodec speaker encoders\ndemonstrated that: 1) the ECAPA-TDNN speaker encoder was more capable in the\nseen scenario, where the testing speakers were included in the training set; 2)\nthe FACodec speaker encoder was superior in the unseen scenario, where the\ntesting speakers were not part of the training, indicating enhanced\ngeneralization capability. The VCTK-RVA dataset and open-source code are\navailable on the website https://github.com/vTAD2025-Challenge/vTAD.", "AI": {"tldr": "The paper introduces voice timbre attribute detection (vTAD), a task to describe timbre using sensory attributes. It proposes a framework using speaker embeddings, tested on VCTK-RVA dataset, comparing ECAPA-TDNN and FACodec encoders for seen and unseen scenarios.", "motivation": "To explain timbre in speech signals and develop a method for detecting voice timbre attributes using human perception descriptors.", "method": "A framework based on speaker embeddings processes speech utterance pairs to compare timbre intensity. Evaluated on VCTK-RVA dataset using ECAPA-TDNN and FACodec encoders.", "result": "ECAPA-TDNN performed better in seen scenarios (training speakers included in testing), while FACodec excelled in unseen scenarios (testing speakers not in training), showing better generalization.", "conclusion": "The study highlights the effectiveness of speaker embeddings for vTAD, with FACodec offering superior generalization for unseen speakers. The dataset and code are publicly available."}}
{"id": "2505.10311", "pdf": "https://arxiv.org/pdf/2505.10311", "abs": "https://arxiv.org/abs/2505.10311", "authors": ["Jeffrey Alido", "Tongyu Li", "Yu Sun", "Lei Tian"], "title": "Whitened Score Diffusion: A Structured Prior for Imaging Inverse Problems", "categories": ["eess.IV", "eess.SP", "stat.AP", "stat.ML"], "comment": null, "summary": "Conventional score-based diffusion models (DMs) may struggle with anisotropic\nGaussian diffusion processes due to the required inversion of covariance\nmatrices in the denoising score matching training objective\n\\cite{vincent_connection_2011}. We propose Whitened Score (WS) diffusion\nmodels, a novel SDE-based framework that learns the Whitened Score function\ninstead of the standard score. This approach circumvents covariance inversion,\nextending score-based DMs by enabling stable training of DMs on arbitrary\nGaussian forward noising processes. WS DMs establish equivalence with FM for\narbitrary Gaussian noise, allow for tailored spectral inductive biases, and\nprovide strong Bayesian priors for imaging inverse problems with structured\nnoise. We experiment with a variety of computational imaging tasks using the\nCIFAR and CelebA ($64\\times64$) datasets and demonstrate that WS diffusion\npriors trained on anisotropic Gaussian noising processes consistently\noutperform conventional diffusion priors based on isotropic Gaussian noise.", "AI": {"tldr": "Whitened Score (WS) diffusion models avoid covariance inversion in anisotropic Gaussian diffusion, improving stability and performance over conventional methods.", "motivation": "Address limitations of conventional score-based diffusion models with anisotropic Gaussian diffusion processes.", "method": "Propose WS diffusion models, learning Whitened Score function to bypass covariance inversion.", "result": "WS models outperform conventional methods on tasks like CIFAR and CelebA, especially with anisotropic noise.", "conclusion": "WS diffusion models offer a robust alternative for Gaussian noising processes and imaging inverse problems."}}
{"id": "2505.09829", "pdf": "https://arxiv.org/pdf/2505.09829", "abs": "https://arxiv.org/abs/2505.09829", "authors": ["Tushar Kataria", "Shireen Y. Elhabian"], "title": "BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes", "categories": ["cs.CV"], "comment": null, "summary": "Obtaining large-scale medical data, annotated or unannotated, is challenging\ndue to stringent privacy regulations and data protection policies. In addition,\nannotating medical images requires that domain experts manually delineate\nanatomical structures, making the process both time-consuming and costly. As a\nresult, semi-supervised methods have gained popularity for reducing annotation\ncosts. However, the performance of semi-supervised methods is heavily dependent\non the availability of unannotated data, and their effectiveness declines when\nsuch data are scarce or absent. To overcome this limitation, we propose a\nsimple, yet effective and computationally efficient approach for medical image\nsegmentation that leverages only existing annotations. We propose BoundarySeg ,\na multi-task framework that incorporates organ boundary prediction as an\nauxiliary task to full organ segmentation, leveraging consistency between the\ntwo task predictions to provide additional supervision. This strategy improves\nsegmentation accuracy, especially in low data regimes, allowing our method to\nachieve performance comparable to or exceeding state-of-the-art semi supervised\napproaches all without relying on unannotated data or increasing computational\ndemands. Code will be released upon acceptance.", "AI": {"tldr": "Proposes BoundarySeg, a multi-task framework for medical image segmentation that improves accuracy without needing unannotated data.", "motivation": "Challenges in obtaining and annotating medical data due to privacy and cost, and limitations of semi-supervised methods when unannotated data is scarce.", "method": "BoundarySeg uses organ boundary prediction as an auxiliary task to full organ segmentation, leveraging consistency between tasks for supervision.", "result": "Achieves performance comparable to or better than semi-supervised methods without unannotated data or added computational cost.", "conclusion": "BoundarySeg is a simple, effective solution for medical image segmentation in low-data scenarios."}}
{"id": "2505.09702", "pdf": "https://arxiv.org/pdf/2505.09702", "abs": "https://arxiv.org/abs/2505.09702", "authors": ["Yezi Liu", "Prathyush Poduval", "Wenjun Huang", "Yang Ni", "Hanning Chen", "Mohsen Imani"], "title": "Enabling Group Fairness in Graph Unlearning via Bi-level Debiasing", "categories": ["cs.LG"], "comment": null, "summary": "Graph unlearning is a crucial approach for protecting user privacy by erasing\nthe influence of user data on trained graph models. Recent developments in\ngraph unlearning methods have primarily focused on maintaining model prediction\nperformance while removing user information. However, we have observed that\nwhen user information is deleted from the model, the prediction distribution\nacross different sensitive groups often changes. Furthermore, graph models are\nshown to be prone to amplifying biases, making the study of fairness in graph\nunlearning particularly important. This raises the question: Does graph\nunlearning actually introduce bias? Our findings indicate that the predictions\nof post-unlearning models become highly correlated with sensitive attributes,\nconfirming the introduction of bias in the graph unlearning process. To address\nthis issue, we propose a fair graph unlearning method, FGU. To guarantee\nprivacy, FGU trains shard models on partitioned subgraphs, unlearns the\nrequested data from the corresponding subgraphs, and retrains the shard models\non the modified subgraphs. To ensure fairness, FGU employs a bi-level debiasing\nprocess: it first enables shard-level fairness by incorporating a fairness\nregularizer in the shard model retraining, and then achieves global-level\nfairness by aligning all shard models to minimize global disparity. Our\nexperiments demonstrate that FGU achieves superior fairness while maintaining\nprivacy and accuracy. Additionally, FGU is robust to diverse unlearning\nrequests, ensuring fairness and utility performance across various data\ndistributions.", "AI": {"tldr": "Graph unlearning can introduce bias, so the paper proposes FGU, a fair graph unlearning method that ensures privacy and fairness while maintaining accuracy.", "motivation": "Graph unlearning methods often change prediction distributions across sensitive groups, potentially introducing bias. This paper investigates and addresses this issue.", "method": "FGU trains shard models on partitioned subgraphs, unlearns data from subgraphs, and retrains with fairness regularizers. It aligns shard models to minimize global disparity.", "result": "FGU achieves superior fairness, maintains privacy and accuracy, and is robust to diverse unlearning requests.", "conclusion": "FGU effectively addresses bias in graph unlearning, ensuring fairness and utility across various data distributions."}}
{"id": "2505.09737", "pdf": "https://arxiv.org/pdf/2505.09737", "abs": "https://arxiv.org/abs/2505.09737", "authors": ["Osher Elhadad", "Reuth Mirsky"], "title": "General Dynamic Goal Recognition", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted for publication at Generalization in Planning (GenPlan) as\n  part of AAAI 2025 workshops", "summary": "Understanding an agent's intent through its behavior is essential in\nhuman-robot interaction, interactive AI systems, and multi-agent\ncollaborations. This task, known as Goal Recognition (GR), poses significant\nchallenges in dynamic environments where goals are numerous and constantly\nevolving. Traditional GR methods, designed for a predefined set of goals, often\nstruggle to adapt to these dynamic scenarios. To address this limitation, we\nintroduce the General Dynamic GR problem - a broader definition of GR - aimed\nat enabling real-time GR systems and fostering further research in this area.\nExpanding on this foundation, this paper employs a model-free goal-conditioned\nRL approach to enable fast adaptation for GR across various changing tasks.", "AI": {"tldr": "The paper introduces the General Dynamic Goal Recognition (GR) problem to address challenges in dynamic environments and proposes a model-free goal-conditioned RL approach for fast adaptation.", "motivation": "Traditional GR methods struggle in dynamic environments with evolving goals, necessitating a broader definition and adaptable solutions.", "method": "A model-free goal-conditioned reinforcement learning (RL) approach is employed to enable fast adaptation across changing tasks.", "result": "The proposed method aims to improve real-time GR systems by addressing the limitations of traditional approaches.", "conclusion": "The General Dynamic GR framework and model-free RL approach advance research and adaptability in goal recognition for dynamic environments."}}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores.", "AI": {"tldr": "The paper introduces TokenAdapt, a model-agnostic tokenizer transplantation method, and pre-tokenization learning for multi-word Supertokens to address inefficiencies in fixed tokenization schemes of LLMs.", "motivation": "Fixed tokenization in LLMs causes inefficiencies and performance issues, especially for multilingual or specialized tasks. Existing solutions are resource-intensive or fail to preserve semantics.", "method": "TokenAdapt combines local subword decomposition and global semantic similarity to initialize new tokens. Supertokens enhance compression and reduce fragmentation.", "result": "TokenAdapt outperforms baselines like ReTok and TransTokenizer, achieving lower perplexity ratios and significant compression gains.", "conclusion": "TokenAdapt effectively addresses tokenizer lock-in with minimal retraining, preserving semantics and improving performance."}}
{"id": "2503.16112", "pdf": "https://arxiv.org/pdf/2503.16112", "abs": "https://arxiv.org/abs/2503.16112", "authors": ["Liming Liu", "Jiangkai Wu", "Haoyang Wang", "Peiheng Wang", "Zongming Guo", "Xinggong Zhang"], "title": "PromptMobile: Efficient Promptus for Low Bandwidth Mobile Video Streaming", "categories": ["cs.NI", "cs.AI", "cs.MM"], "comment": "6 pages (excluding references), 10 figures, to appear in APNET 2025", "summary": "Traditional video compression algorithms exhibit significant quality\ndegradation at extremely low bitrates. Promptus emerges as a new paradigm for\nvideo streaming, substantially cutting down the bandwidth essential for video\nstreaming. However, Promptus is computationally intensive and can not run in\nreal-time on mobile devices. This paper presents PromptMobile, an efficient\nacceleration framework tailored for on-device Promptus. Specifically, we\npropose (1) a two-stage efficient generation framework to reduce computational\ncost by 8.1x, (2) a fine-grained inter-frame caching to reduce redundant\ncomputations by 16.6%, (3) system-level optimizations to further enhance\nefficiency. The evaluations demonstrate that compared with the original\nPromptus, PromptMobile achieves a 13.6x increase in image generation speed.\nCompared with other streaming methods, PromptMobile achives an average LPIPS\nimprovement of 0.016 (compared with H.265), reducing 60% of severely distorted\nframes (compared to VQGAN).", "AI": {"tldr": "PromptMobile accelerates Promptus for mobile devices, reducing computational costs and improving video streaming quality at low bitrates.", "motivation": "Traditional video compression degrades quality at low bitrates, and Promptus, while effective, is too slow for mobile devices.", "method": "Proposes a two-stage generation framework, fine-grained inter-frame caching, and system-level optimizations.", "result": "Achieves 13.6x faster image generation, 16.6% redundant computation reduction, and better quality metrics than H.265 and VQGAN.", "conclusion": "PromptMobile enables efficient, high-quality video streaming on mobile devices by optimizing Promptus."}}
{"id": "2505.09799", "pdf": "https://arxiv.org/pdf/2505.09799", "abs": "https://arxiv.org/abs/2505.09799", "authors": ["Martina Vanelli", "Laura Arditti", "Giacomo Como", "Fabio Fagnani"], "title": "On Signed Network Coordination Games", "categories": ["cs.GT", "cs.MA", "cs.SI", "cs.SY", "eess.SY"], "comment": "14 pages, 8 figures", "summary": "We study binary-action pairwise-separable network games that encompass both\ncoordinating and anti-coordinating behaviors. Our model is grounded in an\nunderlying directed signed graph, where each link is associated with a weight\nthat describes the strenght and nature of the interaction. The utility for each\nagent is an aggregation of pairwise terms determined by the weights of the\nsigned graph in addition to an individual bias term. We consider a scenario\nthat assumes the presence of a prominent 'cohesive' subset of players, who are\neither connected exclusively by positive weights, or forms a structurally\nbalanced subset that can be bipartitioned into two adversarial subcommunities\nwith positive intra-community and negative inter-community edges. Given the\nproperties of the game restricted to the remaining players, our results\nguarantee the existence of Nash equilibria characterized by a consensus or,\nrespectively, a polarization within the first group, as well as their stability\nunder best response transitions. Our results can be interpreted as robustness\nresults, building on the supermodular properties of coordination games and on a\nnovel use of the concept of graph cohesiveness.", "AI": {"tldr": "The paper studies binary-action network games with coordinating and anti-coordinating behaviors, proving the existence and stability of Nash equilibria under specific cohesive subset conditions.", "motivation": "To understand how interactions in signed graphs (with positive/negative weights) influence Nash equilibria, especially in cohesive subsets of players.", "method": "Analyzes a model of pairwise-separable network games on directed signed graphs, focusing on cohesive subsets with specific structural properties.", "result": "Guarantees Nash equilibria with consensus or polarization in cohesive subsets, stable under best response dynamics.", "conclusion": "The findings highlight robustness in equilibria, leveraging supermodularity and graph cohesiveness, applicable to coordination and adversarial scenarios."}}
{"id": "2505.09784", "pdf": "https://arxiv.org/pdf/2505.09784", "abs": "https://arxiv.org/abs/2505.09784", "authors": ["Ippokratis Kochliaridis", "Michail E. Kiziroglou"], "title": "Theoretical Model of Acoustic Power Transfer Through Solids", "categories": ["cs.SD", "eess.AS", "physics.app-ph"], "comment": "8th International Workoshop on Microsystems, International Hellenic\n  University", "summary": "Acoustic Power Transfer is a relatively new technology. It is a modern type\nof a wireless interface, where data signals and supply voltages are\ntransmitted, with the use of mechanical waves, through a medium. The simplest\napplication of such systems is the measurement of frequency response for audio\nspeakers. It consists of a variable signal generator, a measuring amplifier\nwhich drives an acoustic source and the loudspeaker driver. The receiver\ncontains a microphone circuit with a level recorder. Acoustic Power Transfer\ncould have many applications, such as: Cochlear Implants, Sonar Systems and\nWireless Charging. However, it is a new technology, thus it needs further\ninvestigation.", "AI": {"tldr": "Acoustic Power Transfer (APT) is a wireless technology using mechanical waves for data and power transmission, with applications like cochlear implants and wireless charging, but requires further research.", "motivation": "To explore the potential of APT as a wireless interface for transmitting data and power through mechanical waves, addressing its novelty and need for deeper investigation.", "method": "The system involves a variable signal generator, measuring amplifier, acoustic source, and loudspeaker driver for transmission, with a microphone circuit and level recorder for reception.", "result": "APT demonstrates feasibility for applications such as cochlear implants, sonar systems, and wireless charging, but its novelty necessitates additional study.", "conclusion": "APT is a promising technology with diverse applications, though further research is essential to fully understand and optimize its capabilities."}}
{"id": "2505.10511", "pdf": "https://arxiv.org/pdf/2505.10511", "abs": "https://arxiv.org/abs/2505.10511", "authors": ["Victor Zheleznov", "Stefan Bilbao", "Alec Wright", "Simon King"], "title": "Learning Nonlinear Dynamics in Physical Modelling Synthesis using Neural Ordinary Differential Equations", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "comment": "Accepted for publication in Proceedings of the 28th International\n  Conference on Digital Audio Effects (DAFx25), Ancona, Italy, September 2025", "summary": "Modal synthesis methods are a long-standing approach for modelling\ndistributed musical systems. In some cases extensions are possible in order to\nhandle geometric nonlinearities. One such case is the high-amplitude vibration\nof a string, where geometric nonlinear effects lead to perceptually important\neffects including pitch glides and a dependence of brightness on striking\namplitude. A modal decomposition leads to a coupled nonlinear system of\nordinary differential equations. Recent work in applied machine learning\napproaches (in particular neural ordinary differential equations) has been used\nto model lumped dynamic systems such as electronic circuits automatically from\ndata. In this work, we examine how modal decomposition can be combined with\nneural ordinary differential equations for modelling distributed musical\nsystems. The proposed model leverages the analytical solution for linear\nvibration of system's modes and employs a neural network to account for\nnonlinear dynamic behaviour. Physical parameters of a system remain easily\naccessible after the training without the need for a parameter encoder in the\nnetwork architecture. As an initial proof of concept, we generate synthetic\ndata for a nonlinear transverse string and show that the model can be trained\nto reproduce the nonlinear dynamics of the system. Sound examples are\npresented.", "AI": {"tldr": "Combining modal decomposition with neural ODEs to model nonlinear dynamics in musical systems, demonstrated with a nonlinear string example.", "motivation": "To address the challenge of modeling geometric nonlinearities in distributed musical systems, leveraging recent advances in neural ODEs.", "method": "Modal decomposition for linear vibration modes, augmented by a neural network to handle nonlinear dynamics, retaining accessible physical parameters.", "result": "The model successfully reproduces nonlinear dynamics of a transverse string, validated with synthetic data and sound examples.", "conclusion": "The approach effectively combines analytical and data-driven methods for modeling nonlinear musical systems, with potential for broader applications."}}
{"id": "2505.10405", "pdf": "https://arxiv.org/pdf/2505.10405", "abs": "https://arxiv.org/abs/2505.10405", "authors": ["Jianhao Huang", "Qunsong Zeng", "Kaibin Huang"], "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores.", "AI": {"tldr": "The paper introduces a hybrid Gen-SemCom system with a CIE framework to enhance image reconstruction by combining text prompts and critical features, along with a new GVIF metric for evaluation.", "motivation": "To address the loss of fine-grained visual details in purely prompt-driven Gen-SemCom systems and the lack of systematic evaluation metrics.", "method": "Proposes semantic filtering for critical feature extraction, integrates text prompts and features for reconstruction using a diffusion model, and introduces the GVIF metric for quality assessment.", "result": "The GVIF metric correlates with visual fidelity, and the optimized system outperforms benchmarks in PSNR and FID scores.", "conclusion": "The hybrid system and GVIF metric effectively improve visual quality and adaptability in Gen-SemCom for 6G networks."}}
{"id": "2505.09858", "pdf": "https://arxiv.org/pdf/2505.09858", "abs": "https://arxiv.org/abs/2505.09858", "authors": ["Danush Kumar Venkatesh", "Isabel Funke", "Micha Pfeiffer", "Fiona Kolbinger", "Hanna Maria Schmeiser", "Juergen Weitz", "Marius Distler", "Stefanie Speidel"], "title": "Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models", "categories": ["cs.CV"], "comment": "Early accept at MICCAI 2025", "summary": "Computer-assisted interventions can improve intra-operative guidance,\nparticularly through deep learning methods that harness the spatiotemporal\ninformation in surgical videos. However, the severe data imbalance often found\nin surgical video datasets hinders the development of high-performing models.\nIn this work, we aim to overcome the data imbalance by synthesizing surgical\nvideos. We propose a unique two-stage, text-conditioned diffusion-based method\nto generate high-fidelity surgical videos for under-represented classes. Our\napproach conditions the generation process on text prompts and decouples\nspatial and temporal modeling by utilizing a 2D latent diffusion model to\ncapture spatial content and then integrating temporal attention layers to\nensure temporal consistency. Furthermore, we introduce a rejection sampling\nstrategy to select the most suitable synthetic samples, effectively augmenting\nexisting datasets to address class imbalance. We evaluate our method on two\ndownstream tasks-surgical action recognition and intra-operative event\nprediction-demonstrating that incorporating synthetic videos from our approach\nsubstantially enhances model performance. We open-source our implementation at\nhttps://gitlab.com/nct_tso_public/surgvgen.", "AI": {"tldr": "A two-stage, text-conditioned diffusion-based method is proposed to synthesize surgical videos, addressing data imbalance in surgical datasets and improving model performance in tasks like action recognition and event prediction.", "motivation": "Data imbalance in surgical video datasets limits the development of high-performing deep learning models for intra-operative guidance.", "method": "A two-stage approach using a 2D latent diffusion model for spatial content and temporal attention layers for consistency, with text-conditioned generation and rejection sampling for dataset augmentation.", "result": "Synthetic videos from this method enhance performance in surgical action recognition and intra-operative event prediction.", "conclusion": "The proposed method effectively addresses data imbalance and improves model performance, with open-source implementation available."}}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Fam\u00e1", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature.", "AI": {"tldr": "The paper addresses overlooked energy implications in federated learning (FL) for AIoT, proposing clustering methods to reduce energy consumption while maintaining high convergence rates.", "motivation": "Existing research often ignores the energy impact of FL in AIoT, particularly in pre-processing, communication, and local learning. This study aims to fill that gap.", "method": "Two clustering-informed methods group AIoT devices with similar label distributions to reduce heterogeneity and improve energy efficiency.", "result": "The proposed methods achieve high convergence rates with lower energy consumption compared to other approaches.", "conclusion": "Clustering strategies effectively balance energy efficiency and performance in FL for AIoT."}}
{"id": "2505.09755", "pdf": "https://arxiv.org/pdf/2505.09755", "abs": "https://arxiv.org/abs/2505.09755", "authors": ["Amy Rafferty", "Rishi Ramaesh", "Ajitha Rajan"], "title": "Explainability Through Human-Centric Design for XAI in Lung Cancer Detection", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models have shown promise in lung pathology detection from\nchest X-rays, but widespread clinical adoption remains limited due to opaque\nmodel decision-making. In prior work, we introduced ClinicXAI, a human-centric,\nexpert-guided concept bottleneck model (CBM) designed for interpretable lung\ncancer diagnosis. We now extend that approach and present XpertXAI, a\ngeneralizable expert-driven model that preserves human-interpretable clinical\nconcepts while scaling to detect multiple lung pathologies. Using a\nhigh-performing InceptionV3-based classifier and a public dataset of chest\nX-rays with radiology reports, we compare XpertXAI against leading post-hoc\nexplainability methods and an unsupervised CBM, XCBs. We assess explanations\nthrough comparison with expert radiologist annotations and medical ground\ntruth. Although XpertXAI is trained for multiple pathologies, our expert\nvalidation focuses on lung cancer. We find that existing techniques frequently\nfail to produce clinically meaningful explanations, omitting key diagnostic\nfeatures and disagreeing with radiologist judgments. XpertXAI not only\noutperforms these baselines in predictive accuracy but also delivers\nconcept-level explanations that better align with expert reasoning. While our\nfocus remains on explainability in lung cancer detection, this work illustrates\nhow human-centric model design can be effectively extended to broader\ndiagnostic contexts - offering a scalable path toward clinically meaningful\nexplainable AI in medical diagnostics.", "AI": {"tldr": "XpertXAI, an expert-driven model, improves interpretability and accuracy in detecting lung pathologies from chest X-rays compared to existing methods.", "motivation": "Addressing the opacity of deep learning models in clinical settings by enhancing interpretability for lung pathology detection.", "method": "Extends ClinicXAI using an InceptionV3-based classifier and expert-guided concepts, validated against radiologist annotations.", "result": "XpertXAI outperforms baselines in accuracy and aligns better with expert reasoning, though focused on lung cancer.", "conclusion": "Human-centric design like XpertXAI can scale to broader diagnostics, advancing clinically meaningful explainable AI."}}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Au\u00f1\u00f3n", "A. M\u00e1rtinez-P\u00e9rez", "M. E. P\u00e9rez-Mart\u00ednez", "M. E. Gas-L\u00f3pez"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL.", "AI": {"tldr": "The paper proposes using NLP, specifically NER, to automate data extraction from EHRs for lung and breast cancer, improving efficiency and accuracy compared to manual methods.", "motivation": "Manual extraction of clinical data is time-consuming and error-prone, hindering healthcare research. NLP offers a solution to automate this process, especially for high-impact cancers like lung and breast cancer.", "method": "The study used GMV's NLP tool uQuery and fine-tuned the bsc-bio-ehr-en3 model (RoBERTa-based) for NER on annotated EHRs from IIS La Fe, focusing on eight clinical entities.", "result": "The approach showed strong performance in identifying key entities (e.g., MET, PAT) but faced challenges with less frequent ones (e.g., EVOL).", "conclusion": "NLP, particularly NER, is effective for automating clinical data extraction, though further improvements are needed for rare entities."}}
{"id": "2505.09854", "pdf": "https://arxiv.org/pdf/2505.09854", "abs": "https://arxiv.org/abs/2505.09854", "authors": ["Harikrishna Kuttivelil", "Katia Obraczka"], "title": "Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence", "categories": ["cs.LG", "cs.ET", "cs.MA", "cs.SI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "As demand for intelligent services rises and edge devices become more\ncapable, distributed learning at the network edge has emerged as a key enabling\ntechnology. While existing paradigms like federated learning (FL) and\ndecentralized FL (DFL) enable privacy-preserving distributed learning in many\nscenarios, they face potential challenges in connectivity and synchronization\nimposed by resource-constrained and infrastructure-less environments. While\nmore robust, gossip learning (GL) algorithms have generally been designed for\nhomogeneous data distributions and may not suit all contexts. This paper\nintroduces Chisme, a novel suite of protocols designed to address the\nchallenges of implementing robust intelligence in the network edge,\ncharacterized by heterogeneous data distributions, episodic connectivity, and\nlack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and\nasynchronous GL (Chisme-GL) variants that enable collaborative yet\ndecentralized model training that considers underlying data heterogeneity. We\nintroduce a data similarity heuristic that allows agents to opportunistically\ninfer affinity with each other using the existing communication of model\nupdates in decentralized FL and GL. We leverage the heuristic to extend DFL's\nmodel aggregation and GL's model merge mechanisms for better personalized\ntraining while maintaining collaboration. While Chisme-DFL is a synchronous\ndecentralized approach whose resource utilization scales linearly with network\nsize, Chisme-GL is fully asynchronous and has a lower, constant resource\nrequirement independent of network size. We demonstrate that Chisme methods\noutperform their standard counterparts in model training over distributed and\nheterogeneous data in network scenarios ranging from less connected and\nreliable networks to fully connected and lossless networks.", "AI": {"tldr": "Chisme introduces protocols (Chisme-DFL and Chisme-GL) for robust decentralized learning at the network edge, addressing data heterogeneity and connectivity issues.", "motivation": "Existing methods like FL and DFL face challenges in resource-constrained environments, while GL lacks adaptability to heterogeneous data.", "method": "Chisme includes synchronous DFL and asynchronous GL variants, using a data similarity heuristic for personalized training.", "result": "Chisme outperforms standard FL and GL in diverse network conditions, from unreliable to fully connected networks.", "conclusion": "Chisme provides scalable, efficient solutions for decentralized learning in heterogeneous and connectivity-limited edge environments."}}
{"id": "2505.10348", "pdf": "https://arxiv.org/pdf/2505.10348", "abs": "https://arxiv.org/abs/2505.10348", "authors": ["Cunhang Fan", "Xiaoke Yang", "Hongyu Zhang", "Ying Chen", "Lu Li", "Jian Zhou", "Zhao Lv"], "title": "ListenNet: A Lightweight Spatio-Temporal Enhancement Nested Network for Auditory Attention Detection", "categories": ["cs.HC", "cs.SD", "eess.AS"], "comment": null, "summary": "Auditory attention detection (AAD) aims to identify the direction of the\nattended speaker in multi-speaker environments from brain signals, such as\nElectroencephalography (EEG) signals. However, existing EEG-based AAD methods\noverlook the spatio-temporal dependencies of EEG signals, limiting their\ndecoding and generalization abilities. To address these issues, this paper\nproposes a Lightweight Spatio-Temporal Enhancement Nested Network (ListenNet)\nfor AAD. The ListenNet has three key components: Spatio-temporal Dependency\nEncoder (STDE), Multi-scale Temporal Enhancement (MSTE), and Cross-Nested\nAttention (CNA). The STDE reconstructs dependencies between consecutive time\nwindows across channels, improving the robustness of dynamic pattern\nextraction. The MSTE captures temporal features at multiple scales to represent\nboth fine-grained and long-range temporal patterns. In addition, the CNA\nintegrates hierarchical features more effectively through novel dynamic\nattention mechanisms to capture deep spatio-temporal correlations. Experimental\nresults on three public datasets demonstrate the superiority of ListenNet over\nstate-of-the-art methods in both subject-dependent and challenging\nsubject-independent settings, while reducing the trainable parameter count by\napproximately 7 times. Code is available\nat:https://github.com/fchest/ListenNet.", "AI": {"tldr": "The paper proposes ListenNet, a lightweight spatio-temporal network for auditory attention detection (AAD) in EEG signals, improving robustness and generalization by addressing spatio-temporal dependencies.", "motivation": "Existing EEG-based AAD methods ignore spatio-temporal dependencies in EEG signals, limiting decoding and generalization.", "method": "ListenNet includes Spatio-temporal Dependency Encoder (STDE), Multi-scale Temporal Enhancement (MSTE), and Cross-Nested Attention (CNA) to capture dynamic patterns and hierarchical features.", "result": "ListenNet outperforms state-of-the-art methods on three datasets, reducing parameters by 7x.", "conclusion": "ListenNet effectively addresses spatio-temporal dependencies in EEG signals, enhancing AAD performance and efficiency."}}
{"id": "2505.10561", "pdf": "https://arxiv.org/pdf/2505.10561", "abs": "https://arxiv.org/abs/2505.10561", "authors": ["Zehan Wang", "Ke Lei", "Chen Zhu", "Jiawei Huang", "Sashuai Zhou", "Luping Liu", "Xize Cheng", "Shengpeng Ji", "Zhenhui Ye", "Tao Jin", "Zhou Zhao"], "title": "T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback", "categories": ["cs.SD", "eess.AS"], "comment": "ACL 2025", "summary": "Text-to-audio (T2A) generation has achieved remarkable progress in generating\na variety of audio outputs from language prompts. However, current\nstate-of-the-art T2A models still struggle to satisfy human preferences for\nprompt-following and acoustic quality when generating complex multi-event\naudio. To improve the performance of the model in these high-level\napplications, we propose to enhance the basic capabilities of the model with AI\nfeedback learning. First, we introduce fine-grained AI audio scoring pipelines\nto: 1) verify whether each event in the text prompt is present in the audio\n(Event Occurrence Score), 2) detect deviations in event sequences from the\nlanguage description (Event Sequence Score), and 3) assess the overall acoustic\nand harmonic quality of the generated audio (Acoustic&Harmonic Quality). We\nevaluate these three automatic scoring pipelines and find that they correlate\nsignificantly better with human preferences than other evaluation metrics. This\nhighlights their value as both feedback signals and evaluation metrics.\nUtilizing our robust scoring pipelines, we construct a large audio preference\ndataset, T2A-FeedBack, which contains 41k prompts and 249k audios, each\naccompanied by detailed scores. Moreover, we introduce T2A-EpicBench, a\nbenchmark that focuses on long captions, multi-events, and story-telling\nscenarios, aiming to evaluate the advanced capabilities of T2A models. Finally,\nwe demonstrate how T2A-FeedBack can enhance current state-of-the-art audio\nmodel. With simple preference tuning, the audio generation model exhibits\nsignificant improvements in both simple (AudioCaps test set) and complex\n(T2A-EpicBench) scenarios.", "AI": {"tldr": "The paper proposes AI feedback learning to improve text-to-audio (T2A) models by introducing fine-grained scoring pipelines and a preference dataset, enhancing prompt-following and acoustic quality.", "motivation": "Current T2A models struggle with human preferences for complex multi-event audio, prompting the need for better evaluation and feedback mechanisms.", "method": "Introduces three AI scoring pipelines (Event Occurrence, Event Sequence, Acoustic&Harmonic Quality) and constructs a large preference dataset (T2A-FeedBack) and benchmark (T2A-EpicBench).", "result": "Scoring pipelines correlate better with human preferences, and preference tuning improves model performance in simple and complex scenarios.", "conclusion": "AI feedback learning and robust evaluation metrics significantly enhance T2A model capabilities."}}
{"id": "2505.10464", "pdf": "https://arxiv.org/pdf/2505.10464", "abs": "https://arxiv.org/abs/2505.10464", "authors": ["Jiaming Liang", "Lihuan Dai", "Xiaoqi Sheng", "Xiangguang Chen", "Chun Yao", "Guihua Tao", "Qibin Leng", "Honming Cai", "Xi Zhong"], "title": "HWA-UNETR: Hierarchical Window Aggregate UNETR for 3D Multimodal Gastric Lesion Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "This work has been provisionally accepted for MICCAI 2025", "summary": "Multimodal medical image segmentation faces significant challenges in the\ncontext of gastric cancer lesion analysis. This clinical context is defined by\nthe scarcity of independent multimodal datasets and the imperative to\namalgamate inherently misaligned modalities. As a result, algorithms are\nconstrained to train on approximate data and depend on application migration,\nleading to substantial resource expenditure and a potential decline in analysis\naccuracy. To address those challenges, we have made two major contributions:\nFirst, we publicly disseminate the GCM 2025 dataset, which serves as the first\nlarge-scale, open-source collection of gastric cancer multimodal MRI scans,\nfeaturing professionally annotated FS-T2W, CE-T1W, and ADC images from 500\npatients. Second, we introduce HWA-UNETR, a novel 3D segmentation framework\nthat employs an original HWA block with learnable window aggregation layers to\nestablish dynamic feature correspondences between different modalities'\nanatomical structures, and leverages the innovative tri-orientated fusion mamba\nmechanism for context modeling and capturing long-range spatial dependencies.\nExtensive experiments on our GCM 2025 dataset and the publicly BraTS 2021\ndataset validate the performance of our framework, demonstrating that the new\napproach surpasses existing methods by up to 1.68\\% in the Dice score while\nmaintaining solid robustness. The dataset and code are public via\nhttps://github.com/JeMing-creater/HWA-UNETR.", "AI": {"tldr": "The paper introduces a new dataset (GCM 2025) and a 3D segmentation framework (HWA-UNETR) for gastric cancer lesion analysis, addressing challenges of multimodal data scarcity and misalignment.", "motivation": "Challenges in gastric cancer lesion analysis due to scarce multimodal datasets and misaligned modalities, leading to resource-heavy training and reduced accuracy.", "method": "Proposes HWA-UNETR, a 3D segmentation framework with HWA blocks for dynamic feature alignment and a tri-orientated fusion mamba mechanism for context modeling.", "result": "Outperforms existing methods by up to 1.68% in Dice score, validated on GCM 2025 and BraTS 2021 datasets.", "conclusion": "The released dataset and framework improve accuracy and robustness in multimodal medical image segmentation for gastric cancer."}}
{"id": "2505.09859", "pdf": "https://arxiv.org/pdf/2505.09859", "abs": "https://arxiv.org/abs/2505.09859", "authors": ["Andrew Jun Lee", "Taylor Webb", "Trevor Bihl", "Keith Holyoak", "Hongjing Lu"], "title": "Few-Shot Learning of Visual Compositional Concepts through Probabilistic Schema Induction", "categories": ["cs.CV"], "comment": "Lee, A. J., Webb, T., Bihl, T., Holyoak, K. J., & Lu, H. (2025).\n  Few-shot learning of visual compositional concepts through probabilistic\n  schema induction. In A. Ruggeri, D. Barner, C. Walker, & N. Bramley (Eds.),\n  Proceedings of the 47th Annual Conference of the Cognitive Science Society.\n  Cognitive Science Society", "summary": "The ability to learn new visual concepts from limited examples is a hallmark\nof human cognition. While traditional category learning models represent each\nexample as an unstructured feature vector, compositional concept learning is\nthought to depend on (1) structured representations of examples (e.g., directed\ngraphs consisting of objects and their relations) and (2) the identification of\nshared relational structure across examples through analogical mapping. Here,\nwe introduce Probabilistic Schema Induction (PSI), a prototype model that\nemploys deep learning to perform analogical mapping over structured\nrepresentations of only a handful of examples, forming a compositional concept\ncalled a schema. In doing so, PSI relies on a novel conception of similarity\nthat weighs object-level similarity and relational similarity, as well as a\nmechanism for amplifying relations relevant to classification, analogous to\nselective attention parameters in traditional models. We show that PSI produces\nhuman-like learning performance and outperforms two controls: a prototype model\nthat uses unstructured feature vectors extracted from a deep learning model,\nand a variant of PSI with weaker structured representations. Notably, we find\nthat PSI's human-like performance is driven by an adaptive strategy that\nincreases relational similarity over object-level similarity and upweights the\ncontribution of relations that distinguish classes. These findings suggest that\nstructured representations and analogical mapping are critical to modeling\nrapid human-like learning of compositional visual concepts, and demonstrate how\ndeep learning can be leveraged to create psychological models.", "AI": {"tldr": "PSI, a model using deep learning for analogical mapping over structured representations, outperforms controls and mimics human-like learning by emphasizing relational similarity.", "motivation": "To model human-like learning of visual concepts from few examples, focusing on structured representations and analogical mapping.", "method": "Introduces Probabilistic Schema Induction (PSI), leveraging deep learning for analogical mapping over structured representations, with adaptive similarity weighting.", "result": "PSI achieves human-like performance, outperforming controls by emphasizing relational similarity and relevant relations.", "conclusion": "Structured representations and analogical mapping are key to rapid human-like learning, showing deep learning's potential in psychological modeling."}}
{"id": "2505.09710", "pdf": "https://arxiv.org/pdf/2505.09710", "abs": "https://arxiv.org/abs/2505.09710", "authors": ["Konstantinos Fotopoulos", "Petros Maragos"], "title": "Training Deep Morphological Neural Networks as Universal Approximators", "categories": ["cs.LG"], "comment": null, "summary": "We investigate deep morphological neural networks (DMNNs). We demonstrate\nthat despite their inherent non-linearity, activations between layers are\nessential for DMNNs. We then propose several new architectures for DMNNs, each\nwith a different constraint on their parameters. For the first (resp. second)\narchitecture, we work under the constraint that the majority of parameters\n(resp. learnable parameters) should be part of morphological operations. We\nempirically show that our proposed networks can be successfully trained, and\nare more prunable than linear networks. To the best of our knowledge, we are\nthe first to successfully train DMNNs under such constraints, although the\ngeneralization capabilities of our networks remain limited. Finally, we propose\na hybrid network architecture combining linear and morphological layers,\nshowing empirically that the inclusion of morphological layers significantly\naccelerates the convergence of gradient descent with large batches.", "AI": {"tldr": "The paper explores deep morphological neural networks (DMNNs), highlighting the importance of activations between layers and proposing new architectures with parameter constraints. It shows successful training and improved prunability, though generalization is limited. A hybrid architecture combining linear and morphological layers accelerates convergence.", "motivation": "To investigate the role of activations in DMNNs and develop new architectures with specific parameter constraints to enhance training and prunability.", "method": "Proposes several DMNN architectures with constraints on parameters (e.g., majority being morphological operations) and a hybrid linear-morphological network.", "result": "Successful training of DMNNs under constraints, improved prunability, and faster convergence in hybrid networks. Generalization remains limited.", "conclusion": "DMNNs with constrained parameters are trainable and prunable, and hybrid architectures can accelerate convergence, though generalization needs improvement."}}
{"id": "2505.09787", "pdf": "https://arxiv.org/pdf/2505.09787", "abs": "https://arxiv.org/abs/2505.09787", "authors": ["Ziruo Yi", "Ting Xiao", "Mark V. Albert"], "title": "A Multimodal Multi-Agent Framework for Radiology Report Generation", "categories": ["cs.AI"], "comment": null, "summary": "Radiology report generation (RRG) aims to automatically produce diagnostic\nreports from medical images, with the potential to enhance clinical workflows\nand reduce radiologists' workload. While recent approaches leveraging\nmultimodal large language models (MLLMs) and retrieval-augmented generation\n(RAG) have achieved strong results, they continue to face challenges such as\nfactual inconsistency, hallucination, and cross-modal misalignment. We propose\na multimodal multi-agent framework for RRG that aligns with the stepwise\nclinical reasoning workflow, where task-specific agents handle retrieval, draft\ngeneration, visual analysis, refinement, and synthesis. Experimental results\ndemonstrate that our approach outperforms a strong baseline in both automatic\nmetrics and LLM-based evaluations, producing more accurate, structured, and\ninterpretable reports. This work highlights the potential of clinically aligned\nmulti-agent frameworks to support explainable and trustworthy clinical AI\napplications.", "AI": {"tldr": "A multimodal multi-agent framework for radiology report generation (RRG) improves accuracy and interpretability by aligning with clinical workflows, outperforming existing methods.", "motivation": "To address challenges like factual inconsistency and cross-modal misalignment in RRG, enhancing clinical workflows and reducing radiologists' workload.", "method": "Proposes a multimodal multi-agent framework with task-specific agents for retrieval, draft generation, visual analysis, refinement, and synthesis.", "result": "Outperforms baselines in automatic metrics and LLM-based evaluations, producing more accurate and structured reports.", "conclusion": "Clinically aligned multi-agent frameworks can enhance explainability and trustworthiness in clinical AI applications."}}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings.", "AI": {"tldr": "LLMs have a universal truth direction in their activation space, but generalization of this direction varies across conversational formats. A solution using fixed key phrases improves generalization, though challenges remain for reliable lie detection.", "motivation": "To explore how the universal truth direction in LLMs generalizes across different conversational formats and improve its reliability for lie detection.", "method": "Investigating generalization of the truth direction in short vs. long conversations and proposing a solution using fixed key phrases at the end of conversations.", "result": "Good generalization in short conversations ending with lies, poor in longer ones with earlier lies. The key phrase solution significantly improves generalization.", "conclusion": "While progress is made, reliable LLM lie detectors face challenges in generalizing to new settings."}}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence.", "AI": {"tldr": "The paper traces AI's evolution to advanced autonomous agents like ChatGPT and Grok, highlighting key technological advancements and societal impacts, while emphasizing the need for wisdom in this rapidly progressing field.", "motivation": "To document AI's rapid development, its current state as exemplified by systems like ChatGPT and Grok, and the societal implications of such advancements.", "method": "Chronicles AI's trajectory by analyzing key technological milestones, including prompting, training, hardware, and architecture, with practical examples.", "result": "Identifies modern AI agents as a potential 'final generation' of intelligence, with capabilities doubling every six months, and explores their societal impact.", "conclusion": "Stresses the importance of wisdom and foresight to navigate the challenges and opportunities of this powerful new era of AI."}}
{"id": "2401.11832", "pdf": "https://arxiv.org/pdf/2401.11832", "abs": "https://arxiv.org/abs/2401.11832", "authors": ["Marcelo Pillonetto", "Anderson Queiroz", "Ros\u00e2ngela Coelho"], "title": "Acoustic Disturbance Sensing Level Detection for ASD Diagnosis and Intelligibility Enhancement", "categories": ["eess.AS", "cs.SD"], "comment": "4 pages, 3 figures, 2 tables", "summary": "The acoustic sensitivity of Autism Spectrum Disorder (ASD) individuals highly\nimpacts their intelligibility in noisy urban environments. In this Letter, the\ndisturbance sensing level is examined with perceptual listening tests that\ndemonstrate the impact of their append High Internal Noise (HIN) profile on\nintelligibility. This particular sensing level is then proposed as additional\naid to ASD diagnosis. In this Letter, a novel intelligibility enhancement\nscheme is also introduced for ASD particular circumstances. For this proposal,\nharmonic features estimated from speech signal frames are considered as center\nfrequencies of auditory filterbanks. A gain factor is further applied to the\noutput of the filtered samples. The experimental results demonstrate that the\nproposal improved the acoustic intelligibility of ASD and Neurotypicals (NT)\npeople considering four acoustic noises at different signal-to-noise ratios.", "AI": {"tldr": "The paper examines the acoustic sensitivity of ASD individuals, proposes a diagnostic aid based on disturbance sensing levels, and introduces an intelligibility enhancement scheme using harmonic features and auditory filterbanks.", "motivation": "To address the impact of high internal noise (HIN) on ASD individuals' intelligibility in noisy environments and improve their acoustic perception.", "method": "Perceptual listening tests to assess disturbance sensing levels and a novel intelligibility enhancement scheme using harmonic features and auditory filterbanks with gain factors.", "result": "The proposed method improved acoustic intelligibility for both ASD and neurotypical individuals across various noise conditions and signal-to-noise ratios.", "conclusion": "The study offers a potential diagnostic tool for ASD and an effective intelligibility enhancement solution for noisy environments."}}
{"id": "2409.09647", "pdf": "https://arxiv.org/pdf/2409.09647", "abs": "https://arxiv.org/abs/2409.09647", "authors": ["Jingyong Liang", "Bernd Meyer", "Isaac Ning Lee", "Thanh-Toan Do"], "title": "Self-supervised Learning for Acoustic Few-Shot Classification", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Labelled data are limited and self-supervised learning is one of the most\nimportant approaches for reducing labelling requirements. While it has been\nextensively explored in the image domain, it has so far not received the same\namount of attention in the acoustic domain. Yet, reducing labelling is a key\nrequirement for many acoustic applications. Specifically in bioacoustic, there\nare rarely sufficient labels for fully supervised learning available. This has\nled to the widespread use of acoustic recognisers that have been pre-trained on\nunrelated data for bioacoustic tasks. We posit that training on the actual task\ndata and combining self-supervised pre-training with few-shot classification is\na superior approach that has the ability to deliver high accuracy even when\nonly a few labels are available. To this end, we introduce and evaluate a new\narchitecture that combines CNN-based preprocessing with feature extraction\nbased on state space models (SSMs). This combination is motivated by the fact\nthat CNN-based networks alone struggle to capture temporal information\neffectively, which is crucial for classifying acoustic signals. SSMs,\nspecifically S4 and Mamba, on the other hand, have been shown to have an\nexcellent ability to capture long-range dependencies in sequence data. We\npre-train this architecture using contrastive learning on the actual task data\nand subsequent fine-tuning with an extremely small amount of labelled data. We\nevaluate the performance of this proposed architecture for ($n$-shot,\n$n$-class) classification on standard benchmarks as well as real-world data.\nOur evaluation shows that it outperforms state-of-the-art architectures on the\nfew-shot classification problem.", "AI": {"tldr": "The paper proposes a self-supervised learning approach for bioacoustic tasks, combining CNN-based preprocessing with SSMs (S4/Mamba) for better temporal feature extraction. It achieves superior few-shot classification performance.", "motivation": "Labelled data is scarce in bioacoustic tasks, and existing methods rely on pre-training on unrelated data. The paper aims to improve accuracy by training on task-specific data using self-supervised learning and few-shot classification.", "method": "Introduces an architecture combining CNNs for preprocessing and SSMs (S4/Mamba) for feature extraction. Pre-trains using contrastive learning and fine-tunes with minimal labelled data.", "result": "Outperforms state-of-the-art architectures in few-shot classification on standard benchmarks and real-world data.", "conclusion": "The proposed method effectively reduces labelling requirements and improves accuracy in bioacoustic tasks by leveraging self-supervised learning and SSMs."}}
{"id": "2505.10492", "pdf": "https://arxiv.org/pdf/2505.10492", "abs": "https://arxiv.org/abs/2505.10492", "authors": ["Taylor L. Bobrow", "Mayank Golhar", "Suchapa Arayakarnkul", "Anthony A. Song", "Saowanee Ngamruengphong", "Nicholas J. Durr"], "title": "Multi-contrast laser endoscopy for in vivo gastrointestinal imaging", "categories": ["eess.IV", "cs.CV", "physics.med-ph", "physics.optics"], "comment": null, "summary": "White light endoscopy is the clinical gold standard for detecting diseases in\nthe gastrointestinal tract. Most applications involve identifying visual\nabnormalities in tissue color, texture, and shape. Unfortunately, the contrast\nof these features is often subtle, causing many clinically relevant cases to go\nundetected. To overcome this challenge, we introduce Multi-contrast Laser\nEndoscopy (MLE): a platform for widefield clinical imaging with rapidly tunable\nspectral, coherent, and directional illumination. We demonstrate three\ncapabilities of MLE: enhancing tissue chromophore contrast with multispectral\ndiffuse reflectance, quantifying blood flow using laser speckle contrast\nimaging, and characterizing mucosal topography using photometric stereo. We\nvalidate MLE with benchtop models, then demonstrate MLE in vivo during clinical\ncolonoscopies. MLE images from 31 polyps demonstrate an approximate three-fold\nimprovement in contrast and a five-fold improvement in color difference\ncompared to white light and narrow band imaging. With the ability to reveal\nmultiple complementary types of tissue contrast while seamlessly integrating\ninto the clinical environment, MLE shows promise as an investigative tool to\nimprove gastrointestinal imaging.", "AI": {"tldr": "Multi-contrast Laser Endoscopy (MLE) improves gastrointestinal imaging by enhancing tissue contrast, quantifying blood flow, and characterizing mucosal topography, outperforming traditional methods.", "motivation": "Current white light endoscopy often misses subtle tissue abnormalities due to low contrast. MLE aims to address this limitation.", "method": "MLE uses tunable spectral, coherent, and directional illumination for multispectral diffuse reflectance, laser speckle contrast imaging, and photometric stereo.", "result": "MLE shows a three-fold contrast improvement and five-fold color difference enhancement over white light and narrow band imaging in 31 polyps.", "conclusion": "MLE is a promising tool for improving gastrointestinal imaging by revealing multiple complementary tissue contrasts."}}
{"id": "2505.09915", "pdf": "https://arxiv.org/pdf/2505.09915", "abs": "https://arxiv.org/abs/2505.09915", "authors": ["Zhe Xin", "Chenyang Wu", "Penghui Huang", "Yanyong Zhang", "Yinian Mao", "Guoquan Huang"], "title": "Large-Scale Gaussian Splatting SLAM", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS) have shown encouraging and impressive results for visual SLAM.\nHowever, most representative methods require RGBD sensors and are only\navailable for indoor environments. The robustness of reconstruction in\nlarge-scale outdoor scenarios remains unexplored. This paper introduces a\nlarge-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The\nproposed LSG-SLAM employs a multi-modality strategy to estimate prior poses\nunder large view changes. In tracking, we introduce feature-alignment warping\nconstraints to alleviate the adverse effects of appearance similarity in\nrendering losses. For the scalability of large-scale scenarios, we introduce\ncontinuous Gaussian Splatting submaps to tackle unbounded scenes with limited\nmemory. Loops are detected between GS submaps by place recognition and the\nrelative pose between looped keyframes is optimized utilizing rendering and\nfeature warping losses. After the global optimization of camera poses and\nGaussian points, a structure refinement module enhances the reconstruction\nquality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM\nachieves superior performance over existing Neural, 3DGS-based, and even\ntraditional approaches. Project page: https://lsg-slam.github.io.", "AI": {"tldr": "LSG-SLAM is a large-scale 3D Gaussian Splatting-based visual SLAM system using stereo cameras, outperforming existing methods in outdoor scenarios.", "motivation": "Existing NeRF and 3DGS methods for visual SLAM are limited to indoor environments or require RGBD sensors. Robustness in large-scale outdoor scenarios is unexplored.", "method": "LSG-SLAM uses multi-modality pose estimation, feature-alignment warping, continuous Gaussian Splatting submaps, loop detection, and structure refinement.", "result": "Superior performance on EuRoc and KITTI datasets compared to Neural, 3DGS-based, and traditional approaches.", "conclusion": "LSG-SLAM effectively addresses large-scale outdoor SLAM challenges with stereo cameras, offering robust reconstruction and scalability."}}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation.", "AI": {"tldr": "The paper discusses the need for algorithms to not only perform well in out-of-distribution (OOD) tasks but also to learn compositional features for true generalization. It evaluates common neural networks and introduces new architectures to address this challenge.", "motivation": "To achieve human-like OOD generalization, systems must identify and transfer task-invariant, composable features. The paper questions whether current algorithms truly learn compositional structures, even when they perform well in OOD tasks.", "method": "The study tests three neural networks (MLP, CNN, Transformer) on OOD tasks and develops two novel architectures with biases for OOD success. It evaluates whether these models learn correct compositional features.", "result": "Common neural networks fail in OOD tasks despite clear metrics. The new architectures achieve high OOD performance but still may not learn the correct compositional features.", "conclusion": "OOD performance alone is insufficient to confirm compositional learning. The paper highlights the need for explicit verification of feature compositionality in algorithms."}}
{"id": "2505.09920", "pdf": "https://arxiv.org/pdf/2505.09920", "abs": "https://arxiv.org/abs/2505.09920", "authors": ["Shan Yang", "Yongli Zhu"], "title": "Offline Reinforcement Learning for Microgrid Voltage Regulation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025", "summary": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience.", "AI": {"tldr": "Study on offline reinforcement learning for microgrid voltage regulation, showing feasibility even with low-quality data.", "motivation": "Addresses challenges of microgrid voltage regulation with solar power when online interaction is unsafe or impractical.", "method": "Uses offline reinforcement learning algorithms trained on pre-collected datasets, including low-quality data.", "result": "Demonstrates feasibility and effectiveness on the IEEE 33-bus system.", "conclusion": "Offline reinforcement learning is viable for microgrid voltage regulation without online interaction."}}
{"id": "2505.09825", "pdf": "https://arxiv.org/pdf/2505.09825", "abs": "https://arxiv.org/abs/2505.09825", "authors": ["Peiqi Sui", "Juan Diego Rodriguez", "Philippe Laban", "Dean Murphy", "Joseph P. Dexter", "Richard Jean So", "Samuel Baker", "Pramit Chaudhuri"], "title": "KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Each year, tens of millions of essays are written and graded in college-level\nEnglish courses. Students are asked to analyze literary and cultural texts\nthrough a process known as close reading, in which they gather textual details\nto formulate evidence-based arguments. Despite being viewed as a basis for\ncritical thinking and widely adopted as a required element of university\ncoursework, close reading has never been evaluated on large language models\n(LLMs), and multi-discipline benchmarks like MMLU do not include literature as\na subject. To fill this gap, we present KRISTEVA, the first close reading\nbenchmark for evaluating interpretive reasoning, consisting of 1331\nmultiple-choice questions adapted from classroom data. With KRISTEVA, we\npropose three progressively more difficult sets of tasks to approximate\ndifferent elements of the close reading process, which we use to test how well\nLLMs may seem to understand and reason about literary works: 1) extracting\nstylistic features, 2) retrieving relevant contextual information from\nparametric knowledge, and 3) multi-hop reasoning between style and external\ncontexts. Our baseline results find that, while state-of-the-art LLMs possess\nsome college-level close reading competency (accuracy 49.7% - 69.7%), their\nperformances still trail those of experienced human evaluators on 10 out of our\n11 tasks.", "AI": {"tldr": "KRISTEVA is the first benchmark for evaluating close reading in LLMs, testing interpretive reasoning with 1331 questions. LLMs show some competency but lag behind humans.", "motivation": "Close reading is foundational in education but untested in LLMs. KRISTEVA fills this gap by evaluating LLMs' interpretive reasoning.", "method": "Adapted 1331 classroom questions into three task sets: stylistic feature extraction, contextual retrieval, and multi-hop reasoning.", "result": "LLMs achieved 49.7%-69.7% accuracy, trailing humans in 10 of 11 tasks.", "conclusion": "LLMs have emerging close reading skills but need improvement to match human performance."}}
{"id": "2505.10147", "pdf": "https://arxiv.org/pdf/2505.10147", "abs": "https://arxiv.org/abs/2505.10147", "authors": ["Yash", "Nikhil Karamchandani", "Avishek Ghosh"], "title": "Near Optimal Best Arm Identification for Clustered Bandits", "categories": ["cs.LG", "cs.MA"], "comment": "To be published in ICML 2025", "summary": "This work investigates the problem of best arm identification for multi-agent\nmulti-armed bandits. We consider $N$ agents grouped into $M$ clusters, where\neach cluster solves a stochastic bandit problem. The mapping between agents and\nbandits is a priori unknown. Each bandit is associated with $K$ arms, and the\ngoal is to identify the best arm for each agent under a $\\delta$-probably\ncorrect ($\\delta$-PC) framework, while minimizing sample complexity and\ncommunication overhead.\n  We propose two novel algorithms: Clustering then Best Arm Identification\n(Cl-BAI) and Best Arm Identification then Clustering (BAI-Cl). Cl-BAI uses a\ntwo-phase approach that first clusters agents based on the bandit problems they\nare learning, followed by identifying the best arm for each cluster. BAI-Cl\nreverses the sequence by identifying the best arms first and then clustering\nagents accordingly. Both algorithms leverage the successive elimination\nframework to ensure computational efficiency and high accuracy.\n  We establish $\\delta$-PC guarantees for both methods, derive bounds on their\nsample complexity, and provide a lower bound for this problem class. Moreover,\nwhen $M$ is small (a constant), we show that the sample complexity of a variant\nof BAI-Cl is minimax optimal in an order-wise sense. Experiments on synthetic\nand real-world datasets (MovieLens, Yelp) demonstrate the superior performance\nof the proposed algorithms in terms of sample and communication efficiency,\nparticularly in settings where $M \\ll N$.", "AI": {"tldr": "The paper proposes two algorithms, Cl-BAI and BAI-Cl, for best arm identification in multi-agent multi-armed bandits with clustering, ensuring \u03b4-PC guarantees and minimizing sample complexity and communication overhead.", "motivation": "The problem involves identifying the best arm for each agent in a multi-agent, multi-armed bandit setting with unknown agent-bandit mappings, aiming to optimize efficiency and accuracy.", "method": "Two algorithms are introduced: Cl-BAI (clustering first, then best arm identification) and BAI-Cl (best arm identification first, then clustering), both using successive elimination for efficiency.", "result": "The algorithms provide \u03b4-PC guarantees, bounds on sample complexity, and a lower bound for the problem. BAI-Cl's variant achieves minimax optimal sample complexity when clusters are few.", "conclusion": "Experiments on synthetic and real-world data (MovieLens, Yelp) confirm the algorithms' superior performance in sample and communication efficiency, especially when clusters are much fewer than agents."}}
{"id": "2410.10434", "pdf": "https://arxiv.org/pdf/2410.10434", "abs": "https://arxiv.org/abs/2410.10434", "authors": ["Mohamadreza Zolfagharinejad", "Julian B\u00fcchel", "Lorenzo Cassola", "Sachin Kinge", "Ghazi Sarwat Syed", "Abu Sebastian", "Wilfred G. van der Wiel"], "title": "In-Materia Speech Recognition", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "With the rise of decentralized computing, as in the Internet of Things,\nautonomous driving, and personalized healthcare, it is increasingly important\nto process time-dependent signals at the edge efficiently: right at the place\nwhere the temporal data are collected, avoiding time-consuming, insecure, and\ncostly communication with a centralized computing facility (or cloud). However,\nmodern-day processors often cannot meet the restrained power and time budgets\nof edge systems because of intrinsic limitations imposed by their architecture\n(von Neumann bottleneck) or domain conversions (analogue-to-digital and\ntime-to-frequency). Here, we propose an edge temporal-signal processor based on\ntwo in-materia computing systems for both feature extraction and\nclassification, reaching a software-level accuracy of 96.2% for the TI-46-Word\nspeech-recognition task. First, a nonlinear, room-temperature\ndopant-network-processing-unit (DNPU) layer realizes analogue, time-domain\nfeature extraction from the raw audio signals, similar to the human cochlea.\nSecond, an analogue in-memory computing (AIMC) chip, consisting of memristive\ncrossbar arrays, implements a compact neural network trained on the extracted\nfeatures for classification. With the DNPU feature extraction consuming 100s nW\nand AIMC-based classification having the potential for less than 10 fJ per\nmultiply-accumulate operation, our findings offer a promising avenue for\nadvancing the compactness, efficiency, and performance of heterogeneous smart\nedge processors through in-materia computing hardware.", "AI": {"tldr": "A novel edge temporal-signal processor using in-materia computing achieves 96.2% accuracy for speech recognition, combining a dopant-network-processing-unit for feature extraction and an analogue in-memory computing chip for classification.", "motivation": "The need for efficient, secure, and low-power processing of time-dependent signals at the edge due to limitations of centralized computing and modern processors.", "method": "Two in-materia computing systems: a DNPU for analogue feature extraction and an AIMC chip for classification.", "result": "Achieved 96.2% accuracy for TI-46-Word speech recognition with ultra-low power consumption (100s nW for DNPU, <10 fJ per operation for AIMC).", "conclusion": "The proposed system offers a compact, efficient, and high-performance solution for smart edge processors."}}
{"id": "2502.04522", "pdf": "https://arxiv.org/pdf/2502.04522", "abs": "https://arxiv.org/abs/2502.04522", "authors": ["Keshav Bhandari", "Sungkyun Chang", "Tongyu Lu", "Fareza R. Enus", "Louis B. Bradshaw", "Dorien Herremans", "Simon Colton"], "title": "ImprovNet -- Generating Controllable Musical Improvisations with Iterative Corruption Refinement", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "10 pages, 6 figures, IJCNN 2025 conference", "summary": "Despite deep learning's remarkable advances in style transfer across various\ndomains, generating controllable performance-level musical style transfer for\ncomplete symbolically represented musical works remains a challenging area of\nresearch. Much of this is owed to limited datasets, especially for genres such\nas jazz, and the lack of unified models that can handle multiple music\ngeneration tasks. This paper presents ImprovNet, a transformer-based\narchitecture that generates expressive and controllable musical improvisations\nthrough a self-supervised corruption-refinement training strategy. The\nimprovisational style transfer is aimed at making meaningful modifications to\none or more musical elements - melody, harmony or rhythm of the original\ncomposition with respect to the target genre. ImprovNet unifies multiple\ncapabilities within a single model: it can perform cross-genre and intra-genre\nimprovisations, harmonize melodies with genre-specific styles, and execute\nshort prompt continuation and infilling tasks. The model's iterative generation\nframework allows users to control the degree of style transfer and structural\nsimilarity to the original composition. Objective and subjective evaluations\ndemonstrate ImprovNet's effectiveness in generating musically coherent\nimprovisations while maintaining structural relationships with the original\npieces. The model outperforms Anticipatory Music Transformer in short\ncontinuation and infilling tasks and successfully achieves recognizable genre\nconversion, with 79\\% of participants correctly identifying jazz-style\nimprovisations of classical pieces. Our code and demo page can be found at\nhttps://github.com/keshavbhandari/improvnet.", "AI": {"tldr": "ImprovNet is a transformer-based model for controllable musical style transfer, excelling in cross-genre improvisations and outperforming existing methods.", "motivation": "The challenge lies in limited datasets and lack of unified models for musical style transfer, especially in genres like jazz.", "method": "ImprovNet uses a self-supervised corruption-refinement training strategy to generate expressive improvisations, handling melody, harmony, and rhythm modifications.", "result": "The model outperforms Anticipatory Music Transformer in tasks like continuation and infilling, with 79% accuracy in genre identification.", "conclusion": "ImprovNet effectively generates coherent improvisations while maintaining structural ties to original compositions, offering user-controllable style transfer."}}
{"id": "2505.10502", "pdf": "https://arxiv.org/pdf/2505.10502", "abs": "https://arxiv.org/abs/2505.10502", "authors": ["Yifan Gao", "Yaoxian Dong", "Wenbin Wu", "Chaoyang Ge", "Feng Yuan", "Jiaxi Sheng", "Haoyue Li", "Xin Gao"], "title": "WeGA: Weakly-Supervised Global-Local Affinity Learning Framework for Lymph Node Metastasis Prediction in Rectal Cancer", "categories": ["eess.IV"], "comment": null, "summary": "Accurate lymph node metastasis (LNM) assessment in rectal cancer is essential\nfor treatment planning, yet current MRI-based evaluation shows unsatisfactory\naccuracy, leading to suboptimal clinical decisions. Developing automated\nsystems also faces significant obstacles, primarily the lack of node-level\nannotations. Previous methods treat lymph nodes as isolated entities rather\nthan as an interconnected system, overlooking valuable spatial and contextual\ninformation. To solve this problem, we present WeGA, a novel weakly-supervised\nglobal-local affinity learning framework that addresses these challenges\nthrough three key innovations: 1) a dual-branch architecture with DINOv2\nbackbone for global context and residual encoder for local node details; 2) a\nglobal-local affinity extractor that aligns features across scales through\ncross-attention fusion; and 3) a regional affinity loss that enforces\nstructural coherence between classification maps and anatomical regions.\nExperiments across one internal and two external test centers demonstrate that\nWeGA outperforms existing methods, achieving AUCs of 0.750, 0.822, and 0.802\nrespectively. By effectively modeling the relationships between individual\nlymph nodes and their collective context, WeGA provides a more accurate and\ngeneralizable approach for lymph node metastasis prediction, potentially\nenhancing diagnostic precision and treatment selection for rectal cancer\npatients.", "AI": {"tldr": "WeGA is a weakly-supervised framework for lymph node metastasis prediction in rectal cancer, leveraging global-local affinity learning to improve accuracy over existing methods.", "motivation": "Current MRI-based LNM assessment lacks accuracy, and automated systems struggle due to missing node-level annotations and isolated node analysis.", "method": "WeGA uses a dual-branch architecture (DINOv2 for global context, residual encoder for local details), cross-attention fusion for scale alignment, and regional affinity loss for structural coherence.", "result": "WeGA outperforms existing methods with AUCs of 0.750, 0.822, and 0.802 across three test centers.", "conclusion": "WeGA enhances LNM prediction by modeling node relationships and context, improving diagnostic precision for rectal cancer."}}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP.", "AI": {"tldr": "AdaptCLIP is a simple yet effective method for universal visual anomaly detection using CLIP models, outperforming existing methods by learning adaptive representations alternately and incorporating contextual features.", "motivation": "Existing methods for universal visual anomaly detection struggle with prompt design, token interactions, or require fine-tuning, limiting flexibility.", "method": "AdaptCLIP adds three adapters (visual, textual, prompt-query) to CLIP models, learning adaptive representations alternately and using comparative learning with contextual and residual features.", "result": "AdaptCLIP achieves state-of-the-art performance on 12 anomaly detection benchmarks across industrial and medical domains.", "conclusion": "AdaptCLIP offers a training-free, flexible solution for zero-/few-shot anomaly detection, significantly improving generalization."}}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios.", "AI": {"tldr": "A federated learning method addresses data quality issues like noise, imbalance, and missing labels using adaptive noise cleaning, GAN-based synthetic data, and robust training, showing improved performance on benchmark datasets.", "motivation": "Data quality issues (noisy labels, missing classes, imbalance) hinder federated learning effectiveness, necessitating a systematic solution.", "method": "Proposes adaptive noise cleaning, GAN-based synthetic data generation, and robust federated training to enhance data integrity.", "result": "Experiments on MNIST and Fashion-MNIST show significant performance gains (macro-F1 Score) under noise and imbalance.", "conclusion": "The method effectively mitigates data quality challenges, offering a scalable, privacy-compliant solution for real-world FL."}}
{"id": "2505.09923", "pdf": "https://arxiv.org/pdf/2505.09923", "abs": "https://arxiv.org/abs/2505.09923", "authors": ["Minjung Shin", "Donghyun Kim", "Jeh-Kwang Ryu"], "title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones", "categories": ["cs.AI"], "comment": "8 pages, 4 figures and 4 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2025. This is\n  the final submission", "summary": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning.", "AI": {"tldr": "The study defines good questions and introduces a systematic evaluation framework focusing on appropriateness and effectiveness, validated using CAUS and SQUARE datasets.", "motivation": "Limited research comprehensively assesses question quality, prompting the need for a structured evaluation framework.", "method": "Proposes a rubric-based scoring system with semi-adaptive criteria, validated using CAUS and SQUARE datasets.", "result": "The framework effectively evaluates both well-formed and problematic questions across varied contexts.", "conclusion": "The study advances structured analytical methods for questioning behavior, integrating flexibility and comprehensiveness."}}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge.", "AI": {"tldr": "LLMs are tested for conflict forecasting, comparing parametric (pretrained) and non-parametric (external data) methods, showing benefits of external knowledge.", "motivation": "To explore LLMs' potential in predicting violent conflict, aiding early warning systems and policy-making.", "method": "Two-part evaluation: parametric (pretrained weights) vs. non-parametric (external data via RAG) on conflict trends and fatalities.", "result": "LLMs show promise but benefit from external data for accurate conflict forecasting.", "conclusion": "Augmenting LLMs with external knowledge enhances their conflict prediction capabilities."}}
{"id": "2505.10355", "pdf": "https://arxiv.org/pdf/2505.10355", "abs": "https://arxiv.org/abs/2505.10355", "authors": ["Khaled Wahba", "Wolfgang H\u00f6nig"], "title": "pc-dbCBS: Kinodynamic Motion Planning of Physically-Coupled Robot Teams", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Motion planning problems for physically-coupled multi-robot systems in\ncluttered environments are challenging due to their high dimensionality.\nExisting methods combining sampling-based planners with trajectory optimization\nproduce suboptimal results and lack theoretical guarantees. We propose\nPhysically-coupled discontinuity-bounded Conflict-Based Search (pc-dbCBS), an\nanytime kinodynamic motion planner, that extends discontinuity-bounded CBS to\nrigidly-coupled systems. Our approach proposes a tri-level conflict detection\nand resolution framework that includes the physical coupling between the\nrobots. Moreover, pc-dbCBS alternates iteratively between state space\nrepresentations, thereby preserving probabilistic completeness and asymptotic\noptimality while relying only on single-robot motion primitives. Across 25\nsimulated and six real-world problems involving multirotors carrying a\ncable-suspended payload and differential-drive robots linked by rigid rods,\npc-dbCBS solves up to 92% more instances than a state-of-the-art baseline and\nplans trajectories that are 50-60% faster while reducing planning time by an\norder of magnitude.", "AI": {"tldr": "pc-dbCBS is an anytime kinodynamic motion planner for physically-coupled multi-robot systems, improving success rates and planning efficiency over existing methods.", "motivation": "Existing methods for motion planning in cluttered environments for multi-robot systems are suboptimal and lack guarantees.", "method": "Extends discontinuity-bounded CBS to rigidly-coupled systems with a tri-level conflict detection and resolution framework, alternating between state space representations.", "result": "Solves up to 92% more instances and plans 50-60% faster trajectories, reducing planning time significantly.", "conclusion": "pc-dbCBS is effective for physically-coupled multi-robot systems, outperforming state-of-the-art baselines."}}
{"id": "2505.05159", "pdf": "https://arxiv.org/pdf/2505.05159", "abs": "https://arxiv.org/abs/2505.05159", "authors": ["Linhan Ma", "Dake Guo", "He Wang", "Jin Xu", "Lei Xie"], "title": "FlexSpeech: Towards Stable, Controllable and Expressive Text-to-Speech", "categories": ["eess.AS"], "comment": "10 pages, 5 figures", "summary": "Current speech generation research can be categorized into two primary\nclasses: non-autoregressive and autoregressive. The fundamental distinction\nbetween these approaches lies in the duration prediction strategy employed for\npredictable-length sequences. The NAR methods ensure stability in speech\ngeneration by explicitly and independently modeling the duration of each\nphonetic unit. Conversely, AR methods employ an autoregressive paradigm to\npredict the compressed speech token by implicitly modeling duration with Markov\nproperties. Although this approach improves prosody, it does not provide the\nstructural guarantees necessary for stability. To simultaneously address the\nissues of stability and naturalness in speech generation, we propose\nFlexSpeech, a stable, controllable, and expressive TTS model. The motivation\nbehind FlexSpeech is to incorporate Markov dependencies and preference\noptimization directly on the duration predictor to boost its naturalness while\nmaintaining explicit modeling of the phonetic units to ensure stability.\nSpecifically, we decompose the speech generation task into two components: an\nAR duration predictor and a NAR acoustic model. The acoustic model is trained\non a substantial amount of data to learn to render audio more stably, given\nreference audio prosody and phone durations. The duration predictor is\noptimized in a lightweight manner for different stylistic variations, thereby\nenabling rapid style transfer while maintaining a decoupled relationship with\nthe specified speaker timbre. Experimental results demonstrate that our\napproach achieves SOTA stability and naturalness in zero-shot TTS. More\nimportantly, when transferring to a specific stylistic domain, we can\naccomplish lightweight optimization of the duration module solely with about\n100 data samples, without the need to adjust the acoustic model, thereby\nenabling rapid and stable style transfer.", "AI": {"tldr": "FlexSpeech combines autoregressive (AR) and non-autoregressive (NAR) methods for stable, controllable, and expressive speech generation, achieving SOTA results in zero-shot TTS and lightweight style transfer.", "motivation": "To address the trade-off between stability (NAR) and naturalness (AR) in speech generation by integrating Markov dependencies and preference optimization into duration prediction.", "method": "Decomposes speech generation into an AR duration predictor and a NAR acoustic model, optimizing the former for style transfer while keeping the latter stable.", "result": "Achieves state-of-the-art stability and naturalness in zero-shot TTS, with rapid style transfer using only ~100 samples.", "conclusion": "FlexSpeech successfully balances stability and naturalness, enabling efficient style adaptation without retraining the acoustic model."}}
{"id": "2505.03186", "pdf": "https://arxiv.org/pdf/2505.03186", "abs": "https://arxiv.org/abs/2505.03186", "authors": ["Detao Bai", "Zhiheng Ma", "Xihan Wei", "Liefeng Bo"], "title": "CoGenAV: Versatile Audio-Visual Representation Learning via Contrastive-Generative Synchronization", "categories": ["cs.SD", "cs.CV", "eess.AS"], "comment": null, "summary": "The inherent synchronization between a speaker's lip movements, voice, and\nthe underlying linguistic content offers a rich source of information for\nimproving speech processing tasks, especially in challenging conditions where\ntraditional audio-only systems falter. We introduce CoGenAV, a powerful and\ndata-efficient model designed to learn versatile audio-visual representations\napplicable across a wide range of speech and audio-visual tasks. CoGenAV is\ntrained by optimizing a dual objective derived from natural audio-visual\nsynchrony, contrastive feature alignment and generative text prediction, using\nonly 223 hours of labeled data from the LRS2 dataset. This\ncontrastive-generative synchronization strategy effectively captures\nfundamental cross-modal correlations. We showcase the effectiveness and\nversatility of the learned CoGenAV representations on multiple benchmarks. When\nutilized for Audio-Visual Speech Recognition (AVSR) on LRS2, these\nrepresentations contribute to achieving a state-of-the-art Word Error Rate\n(WER) of 1.27. They also enable strong performance in Visual Speech Recognition\n(VSR) with a WER of 20.5 on LRS2, and significantly improve performance in\nnoisy environments by over 70%. Furthermore, CoGenAV representations benefit\nspeech reconstruction tasks, boosting performance in Speech Enhancement and\nSeparation, and achieve competitive results in audio-visual synchronization\ntasks like Active Speaker Detection (ASD). Our model will be open-sourced to\nfacilitate further development and collaboration within both academia and\nindustry.", "AI": {"tldr": "CoGenAV is a data-efficient model for audio-visual speech tasks, achieving state-of-the-art results in AVSR, VSR, and noisy environments.", "motivation": "Leverage synchronization between lip movements, voice, and linguistic content to improve speech processing in challenging conditions.", "method": "Train CoGenAV using contrastive feature alignment and generative text prediction with 223 hours of labeled LRS2 data.", "result": "Achieves WER of 1.27 (AVSR), 20.5 (VSR), and over 70% improvement in noisy environments. Also enhances speech reconstruction and ASD tasks.", "conclusion": "CoGenAV's versatile representations are effective across multiple speech and audio-visual tasks, with plans for open-sourcing to foster collaboration."}}
{"id": "2505.09644", "pdf": "https://arxiv.org/pdf/2505.09644", "abs": "https://arxiv.org/abs/2505.09644", "authors": ["Chengyang Liang", "Dong Li"], "title": "Joint Source-Channel Noise Adding with Adaptive Denoising for Diffusion-Based Semantic Communications", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "Semantic communication (SemCom) aims to convey the intended meaning of\nmessages rather than merely transmitting bits, thereby offering greater\nefficiency and robustness, particularly in resource-constrained or noisy\nenvironments. In this paper, we propose a novel framework which is referred to\nas joint source-channel noise adding with adaptive denoising (JSCNA-AD) for\nSemCom based on a diffusion model (DM). Unlike conventional encoder-decoder\ndesigns, our approach intentionally incorporates the channel noise during\ntransmission, effectively transforming the harmful channel noise into a\nconstructive component of the diffusion-based semantic reconstruction process.\nBesides, we introduce an attention-based adaptive denoising mechanism, in which\ntransmitted images are divided into multiple regions, and the number of\ndenoising steps is dynamically allocated based on the semantic importance of\neach region. This design effectively balances the reception quality and the\ninference latency by prioritizing the critical semantic information. Extensive\nexperiments demonstrate that our method significantly outperforms existing\nSemCom schemes under various noise conditions, underscoring the potential of\ndiffusion-based models in next-generation communication systems.", "AI": {"tldr": "A novel framework (JSCNA-AD) for semantic communication uses diffusion models to transform channel noise into a constructive part of semantic reconstruction, with adaptive denoising for efficiency.", "motivation": "To improve semantic communication efficiency and robustness by leveraging noise constructively and prioritizing critical information.", "method": "Proposes JSCNA-AD, integrating channel noise into diffusion-based semantic reconstruction and using adaptive denoising with attention-based region prioritization.", "result": "Outperforms existing semantic communication schemes under various noise conditions.", "conclusion": "Demonstrates the potential of diffusion models in next-generation communication systems."}}
{"id": "2505.09927", "pdf": "https://arxiv.org/pdf/2505.09927", "abs": "https://arxiv.org/abs/2505.09927", "authors": ["Siqi Yin", "Shaolei Liu", "Manning Wang"], "title": "DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Domain adaptation addresses the challenge of model performance degradation\ncaused by domain gaps. In the typical setup for unsupervised domain adaptation,\nlabeled data from a source domain and unlabeled data from a target domain are\nused to train a target model. However, access to labeled source domain data,\nparticularly in medical datasets, can be restricted due to privacy policies. As\na result, research has increasingly shifted to source-free domain adaptation\n(SFDA), which requires only a pretrained model from the source domain and\nunlabeled data from the target domain data for adaptation. Existing SFDA\nmethods often rely on domain-specific image style translation and\nself-supervision techniques to bridge the domain gap and train the target\ndomain model. However, the quality of domain-specific style-translated images\nand pseudo-labels produced by these methods still leaves room for improvement.\nMoreover, training the entire model during adaptation can be inefficient under\nlimited supervision. In this paper, we propose a novel SFDA framework to\naddress these challenges. Specifically, to effectively mitigate the impact of\ndomain gap in the initial training phase, we introduce preadaptation to\ngenerate a preadapted model, which serves as an initialization of target model\nand allows for the generation of high-quality enhanced pseudo-labels without\nintroducing extra parameters. Additionally, we propose a data-dependent\nfrequency prompt to more effectively translate target domain images into a\nsource-like style. To further enhance adaptation, we employ a style-related\nlayer fine-tuning strategy, specifically designed for SFDA, to train the target\nmodel using the prompted target domain images and pseudo-labels. Extensive\nexperiments on cross-modality abdominal and cardiac SFDA segmentation tasks\ndemonstrate that our proposed method outperforms existing state-of-the-art\nmethods.", "AI": {"tldr": "A novel source-free domain adaptation (SFDA) framework is proposed, featuring preadaptation, frequency prompts, and style-related layer fine-tuning to improve pseudo-labels and image translation, outperforming existing methods in medical segmentation tasks.", "motivation": "Addressing the limitations of existing SFDA methods, particularly in medical datasets where labeled source data is restricted due to privacy concerns, by improving pseudo-label quality and image style translation.", "method": "Introduces preadaptation for high-quality pseudo-labels, data-dependent frequency prompts for better image translation, and style-related layer fine-tuning for efficient adaptation.", "result": "Outperforms state-of-the-art methods in cross-modality abdominal and cardiac SFDA segmentation tasks.", "conclusion": "The proposed framework effectively mitigates domain gaps and enhances adaptation efficiency in source-free settings, demonstrating superior performance in medical segmentation."}}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers.", "AI": {"tldr": "A generative, end-to-end solver for black-box combinatorial optimization, inspired by annealing, improves sample efficiency and solution quality by modeling the Boltzmann distribution.", "motivation": "Addressing NP problems with a focus on sample efficiency and solution quality, leveraging annealing-based inspiration to handle black-box objectives.", "method": "Trains a neural network to model the Boltzmann distribution of the black-box objective, conditioned on temperature, to capture energy landscape structure.", "result": "Competitive performance against state-of-the-art black-box optimizers in challenging combinatorial tasks under varying query budgets.", "conclusion": "The approach effectively learns energy landscape structure, enabling global optimization and improved sample efficiency."}}
{"id": "2505.09970", "pdf": "https://arxiv.org/pdf/2505.09970", "abs": "https://arxiv.org/abs/2505.09970", "authors": ["Mrinal Rawat", "Ambuje Gupta", "Rushil Goomer", "Alessandro Di Bari", "Neha Gupta", "Roberto Pieraccini"], "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset.", "AI": {"tldr": "Pre-Act enhances LLM agent performance by creating multi-step execution plans with detailed reasoning, outperforming ReAct by 70% in Action Recall. Fine-tuned smaller models like Llama 3.1 also show significant improvements.", "motivation": "To improve agentic systems by addressing the limitations of current LLMs in complex reasoning and practical applications.", "method": "Introduces Pre-Act, a multi-step execution plan with incremental refinement, and fine-tunes smaller models (Llama 3.1) for better performance.", "result": "Pre-Act outperforms ReAct by 70% in Action Recall. Fine-tuned 70B Llama 3.1 surpasses GPT-4 with 69.5% higher action accuracy and 28% better goal completion.", "conclusion": "Pre-Act is effective for enhancing agent performance, especially when fine-tuned on smaller models, making it practical for real-world applications."}}
{"id": "2505.09902", "pdf": "https://arxiv.org/pdf/2505.09902", "abs": "https://arxiv.org/abs/2505.09902", "authors": ["Martin Capdevila", "Esteban Villa Turek", "Ellen Karina Chumbe Fernandez", "Luis Felipe Polo Galvez", "Luis Cadavid", "Andrea Marroquin", "Rebeca Vargas Quesada", "Johanna Crew", "Nicole Vallejo Galarraga", "Christopher Rodriguez", "Diego Gutierrez", "Radhi Datla"], "title": "Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries", "categories": ["cs.CL"], "comment": null, "summary": "Large language models are, by definition, based on language. In an effort to\nunderscore the critical need for regional localized models, this paper examines\nprimary differences between variants of written Spanish across Latin America\nand Spain, with an in-depth sociocultural and linguistic contextualization\ntherein. We argue that these differences effectively constitute significant\ngaps in the quotidian use of Spanish among dialectal groups by creating\nsociolinguistic dissonances, to the extent that locale-sensitive AI models\nwould play a pivotal role in bridging these divides. In doing so, this approach\ninforms better and more efficient localization strategies that also serve to\nmore adequately meet inclusivity goals, while securing sustainable active daily\nuser growth in a major low-risk investment geographic area. Therefore,\nimplementing at least the proposed five sub variants of Spanish addresses two\nlines of action: to foment user trust and reliance on AI language models while\nalso demonstrating a level of cultural, historical, and sociolinguistic\nawareness that reflects positively on any internationalization strategy.", "AI": {"tldr": "The paper highlights the need for localized Spanish language models in AI to address sociolinguistic differences across regions, improving inclusivity and user trust.", "motivation": "To address the significant gaps in Spanish language use across Latin America and Spain, emphasizing the need for locale-sensitive AI models.", "method": "Examines sociocultural and linguistic differences in Spanish variants, proposing five sub-variants for localization.", "result": "Locale-sensitive AI models can bridge sociolinguistic divides, enhance inclusivity, and boost user growth.", "conclusion": "Implementing localized Spanish variants fosters trust, cultural awareness, and supports internationalization strategies."}}
{"id": "2502.08681", "pdf": "https://arxiv.org/pdf/2502.08681", "abs": "https://arxiv.org/abs/2502.08681", "authors": ["Barbera de Mol", "Davide Barbieri", "Jan Viebahn", "Davide Grossi"], "title": "Centrally Coordinated Multi-Agent Reinforcement Learning for Power Grid Topology Control", "categories": ["cs.MA", "cs.AI", "cs.LG", "I.2.11; I.2.8; I.2.1; I.2.6"], "comment": "Accepted version to The 16th ACM International Conference on Future\n  and Sustainable Energy Systems. The final published version is available at\n  10.1145/3679240.3734602", "summary": "Power grid operation is becoming more complex due to the increase in\ngeneration of renewable energy. The recent series of Learning To Run a Power\nNetwork (L2RPN) competitions have encouraged the use of artificial agents to\nassist human dispatchers in operating power grids. However, the combinatorial\nnature of the action space poses a challenge to both conventional optimizers\nand learned controllers. Action space factorization, which breaks down\ndecision-making into smaller sub-tasks, is one approach to tackle the curse of\ndimensionality. In this study, we propose a centrally coordinated multi-agent\n(CCMA) architecture for action space factorization. In this approach, regional\nagents propose actions and subsequently a coordinating agent selects the final\naction. We investigate several implementations of the CCMA architecture, and\nbenchmark in different experimental settings against various L2RPN baseline\napproaches. The CCMA architecture exhibits higher sample efficiency and\nsuperior final performance than the baseline approaches. The results suggest\nhigh potential of the CCMA approach for further application in\nhigher-dimensional L2RPN as well as real-world power grid settings.", "AI": {"tldr": "A centrally coordinated multi-agent (CCMA) architecture is proposed to address the high-dimensional action space challenge in power grid operation, outperforming baseline methods in efficiency and performance.", "motivation": "The complexity of power grid operation due to renewable energy growth and the combinatorial action space challenge in L2RPN competitions necessitate innovative solutions like action space factorization.", "method": "The CCMA architecture involves regional agents proposing actions and a coordinating agent selecting the final action, tested against L2RPN baselines.", "result": "CCMA shows higher sample efficiency and better performance than baselines, indicating promise for real-world power grid applications.", "conclusion": "The CCMA approach is effective for high-dimensional power grid challenges and has potential for broader real-world use."}}
{"id": "2407.01257", "pdf": "https://arxiv.org/pdf/2407.01257", "abs": "https://arxiv.org/abs/2407.01257", "authors": ["Abdul Waheed", "Karima Kadaoui", "Bhiksha Raj", "Muhammad Abdul-Mageed"], "title": "uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation in Low-Data Regimes", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to NAACL'25 main conference", "summary": "Recent work on distilling Whisper's knowledge into small models using\npseudo-labels shows promising performance while reducing the size by up to 50%.\nThis results in small, efficient, and dedicated models. However, a critical\nstep of distillation using pseudo-labels involves filtering high-quality\npredictions and using only those during training. This step requires ground\ntruth labels to compare with and filter low-quality examples, making the\nprocess dependent on human labels. Additionally, the distillation process\nrequires a large amount of data thereby limiting its applicability in\nlow-resource settings. To address this, we propose a distillation framework\nthat does not require any labeled data. Through experimentation, we show that\nour best-distilled models outperform the teacher model by 5-7 WER points and\nare on par with or outperform similar supervised data filtering setups. When\nscaling the data, our models significantly outperform all zero-shot and\nsupervised models. Our models are also 25-50% more compute- and\nmemory-efficient while maintaining performance equal to or better than that of\nthe teacher model. For more details about our models, dataset, and other\nresources, please visit our GitHub page:\nhttps://github.com/UBC-NLP/uDistilWhisper.", "AI": {"tldr": "A distillation framework for Whisper models eliminates the need for labeled data, outperforming the teacher model by 5-7 WER points and achieving efficiency gains of 25-50%.", "motivation": "Current distillation methods rely on human labels and large datasets, limiting applicability in low-resource settings.", "method": "Proposes a label-free distillation framework, filtering high-quality pseudo-labels without ground truth.", "result": "Best-distilled models outperform the teacher and supervised setups, especially with scaled data.", "conclusion": "The framework enables efficient, high-performance models without labeled data, broadening applicability."}}
{"id": "2409.14074", "pdf": "https://arxiv.org/pdf/2409.14074", "abs": "https://arxiv.org/abs/2409.14074", "authors": ["Khai Le-Duc", "Phuc Phan", "Tan-Hanh Pham", "Bach Phan Tat", "Minh-Huong Ngo", "Chris Ngo", "Thanh Nguyen-Tang", "Truong-Son Hy"], "title": "MultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "ACL 2025, 38 pages", "summary": "Multilingual automatic speech recognition (ASR) in the medical domain serves\nas a foundational task for various downstream applications such as speech\ntranslation, spoken language understanding, and voice-activated assistants.\nThis technology improves patient care by enabling efficient communication\nacross language barriers, alleviating specialized workforce shortages, and\nfacilitating improved diagnosis and treatment, particularly during pandemics.\nIn this work, we introduce MultiMed, the first multilingual medical ASR\ndataset, along with the first collection of small-to-large end-to-end medical\nASR models, spanning five languages: Vietnamese, English, German, French, and\nMandarin Chinese. To our best knowledge, MultiMed stands as the world's largest\nmedical ASR dataset across all major benchmarks: total duration, number of\nrecording conditions, number of accents, and number of speaking roles.\nFurthermore, we present the first multilinguality study for medical ASR, which\nincludes reproducible empirical baselines, a monolinguality-multilinguality\nanalysis, Attention Encoder Decoder (AED) vs Hybrid comparative study and a\nlinguistic analysis. We present practical ASR end-to-end training schemes\noptimized for a fixed number of trainable parameters that are common in\nindustry settings. All code, data, and models are available online:\nhttps://github.com/leduckhai/MultiMed/tree/master/MultiMed.", "AI": {"tldr": "MultiMed introduces the first multilingual medical ASR dataset and models, covering five languages, and provides extensive analysis and training schemes.", "motivation": "To improve patient care by enabling multilingual communication in healthcare, addressing workforce shortages, and enhancing diagnosis/treatment.", "method": "Creation of the MultiMed dataset, development of end-to-end ASR models, and conducting multilinguality studies with empirical baselines and comparative analyses.", "result": "MultiMed is the largest medical ASR dataset, with models and training schemes optimized for industry use.", "conclusion": "The work advances multilingual medical ASR, offering practical tools and insights for real-world applications."}}
{"id": "2505.09848", "pdf": "https://arxiv.org/pdf/2505.09848", "abs": "https://arxiv.org/abs/2505.09848", "authors": ["Aditya Raj", "Golrokh Mirzaei"], "title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", "categories": ["cs.LG", "eess.IV"], "comment": "11 pages", "summary": "Imaging and genomic data offer distinct and rich features, and their\nintegration can unveil new insights into the complex landscape of diseases. In\nthis study, we present a novel approach utilizing radiogenomic data including\nstructural MRI images and gene expression data, for Alzheimer's disease\ndetection. Our framework introduces a novel heterogeneous bipartite graph\nrepresentation learning featuring two distinct node types: genes and images.\nThe network can effectively classify Alzheimer's disease (AD) into three\ndistinct stages:AD, Mild Cognitive Impairment (MCI), and Cognitive Normal (CN)\nclasses, utilizing a small dataset. Additionally, it identified which genes\nplay a significant role in each of these classification groups. We evaluate the\nperformance of our approach using metrics including classification accuracy,\nrecall, precision, and F1 score. The proposed technique holds potential for\nextending to radiogenomic-based classification to other diseases.", "AI": {"tldr": "A novel radiogenomic approach using MRI and gene expression data for Alzheimer's disease classification into three stages, identifying key genes and achieving high performance metrics.", "motivation": "To leverage the integration of imaging and genomic data for deeper insights into Alzheimer's disease and its stages.", "method": "A heterogeneous bipartite graph representation learning framework with gene and image nodes, applied to a small dataset.", "result": "Effective classification of AD into three stages (AD, MCI, CN) and identification of significant genes for each group, validated by accuracy, recall, precision, and F1 score.", "conclusion": "The approach shows promise for extending radiogenomic-based classification to other diseases."}}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users.", "AI": {"tldr": "The paper introduces VRU-CIPI, a framework using GRU and Transformer self-attention to predict VRU crossing intentions at intersections, achieving 96.45% accuracy and real-time performance.", "motivation": "Enhancing safety at urban intersections by accurately predicting VRU crossing intentions to prevent conflicts with vehicles.", "method": "Combines GRU for temporal dynamics and Transformer self-attention for contextual/spatial dependencies.", "result": "Achieves 96.45% accuracy and 33 FPS on the UCF-VRU dataset.", "conclusion": "VRU-CIPI improves intersection safety via real-time predictions and I2V communication for proactive warnings."}}
{"id": "2505.09768", "pdf": "https://arxiv.org/pdf/2505.09768", "abs": "https://arxiv.org/abs/2505.09768", "authors": ["Xiukun Wei", "Xueru Zhang"], "title": "Self-Consuming Generative Models with Adversarially Curated Data", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in generative models have made it increasingly difficult to\ndistinguish real data from model-generated synthetic data. Using synthetic data\nfor successive training of future model generations creates \"self-consuming\nloops\", which may lead to model collapse or training instability. Furthermore,\nsynthetic data is often subject to human feedback and curated by users based on\ntheir preferences. Ferbach et al. (2024) recently showed that when data is\ncurated according to user preferences, the self-consuming retraining loop\ndrives the model to converge toward a distribution that optimizes those\npreferences. However, in practice, data curation is often noisy or\nadversarially manipulated. For example, competing platforms may recruit\nmalicious users to adversarially curate data and disrupt rival models. In this\npaper, we study how generative models evolve under self-consuming retraining\nloops with noisy and adversarially curated data. We theoretically analyze the\nimpact of such noisy data curation on generative models and identify conditions\nfor the robustness of the retraining process. Building on this analysis, we\ndesign attack algorithms for competitive adversarial scenarios, where a\nplatform with a limited budget employs malicious users to misalign a rival's\nmodel from actual user preferences. Experiments on both synthetic and\nreal-world datasets demonstrate the effectiveness of the proposed algorithms.", "AI": {"tldr": "The paper examines how noisy and adversarial data curation affects generative models in self-consuming loops, proposing theoretical robustness conditions and attack algorithms for competitive scenarios.", "motivation": "To understand the impact of noisy and adversarial data curation on generative models in self-consuming loops, especially in competitive environments where malicious users may disrupt rival models.", "method": "Theoretical analysis of noisy data curation's impact, identification of robustness conditions, and design of attack algorithms for adversarial scenarios. Experiments on synthetic and real-world datasets.", "result": "Demonstrates the effectiveness of the proposed attack algorithms in misaligning rival models from user preferences.", "conclusion": "Noisy and adversarial data curation can destabilize generative models, but the study provides insights into robustness conditions and adversarial strategies."}}
{"id": "2505.10034", "pdf": "https://arxiv.org/pdf/2505.10034", "abs": "https://arxiv.org/abs/2505.10034", "authors": ["Changzeng Fu", "Zelin Fu", "Xinhe Kuang", "Jiacheng Dong", "Qi Zhang", "Kaifeng Su", "Yikai Su", "Wenbo Shi", "Junfeng Yao", "Yuliang Zhao", "Shiqi Zhao", "Jiadong Wang", "Siyang Song", "Chaoran Liu", "Yuichiro Yoshikawa", "Bj\u00f6rn Schuller", "Hiroshi Ishiguro"], "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection", "categories": ["cs.AI", "68T07", "I.2.0; H.5.1"], "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge", "summary": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io.", "AI": {"tldr": "The paper introduces the MPDD Challenge to address gaps in depression detection by incorporating multimodal data and individual differences, focusing on diverse age groups.", "motivation": "Existing depression detection methods overlook age diversity and individual differences, limiting their effectiveness.", "method": "The challenge uses two datasets (MPDD-Elderly and MPDD-Young) and a baseline model combining audio, video, and individual difference data.", "result": "The approach aims to improve personalized and accurate depression detection across different populations.", "conclusion": "The MPDD Challenge seeks to advance mental health research by fostering inclusive and tailored detection systems."}}
{"id": "2505.09924", "pdf": "https://arxiv.org/pdf/2505.09924", "abs": "https://arxiv.org/abs/2505.09924", "authors": ["Yidan Wang", "Yubing Ren", "Yanan Cao", "Binxing Fang"], "title": "From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has heightened concerns about the\nmisuse of AI-generated text, making watermarking a promising solution.\nMainstream watermarking schemes for LLMs fall into two categories: logits-based\nand sampling-based. However, current schemes entail trade-offs among\nrobustness, text quality, and security. To mitigate this, we integrate\nlogits-based and sampling-based schemes, harnessing their respective strengths\nto achieve synergy. In this paper, we propose a versatile symbiotic\nwatermarking framework with three strategies: serial, parallel, and hybrid. The\nhybrid framework adaptively embeds watermarks using token entropy and semantic\nentropy, optimizing the balance between detectability, robustness, text\nquality, and security. Furthermore, we validate our approach through\ncomprehensive experiments on various datasets and models. Experimental results\nindicate that our method outperforms existing baselines and achieves\nstate-of-the-art (SOTA) performance. We believe this framework provides novel\ninsights into diverse watermarking paradigms. Our code is available at\n\\href{https://github.com/redwyd/SymMark}{https://github.com/redwyd/SymMark}.", "AI": {"tldr": "A hybrid watermarking framework for LLMs combines logits-based and sampling-based methods, optimizing robustness, text quality, and security, achieving SOTA performance.", "motivation": "Addressing trade-offs in existing LLM watermarking schemes by integrating logits-based and sampling-based approaches for better performance.", "method": "Proposes a versatile symbiotic watermarking framework with serial, parallel, and hybrid strategies, using token and semantic entropy for adaptive embedding.", "result": "Outperforms existing baselines, achieving state-of-the-art performance in detectability, robustness, text quality, and security.", "conclusion": "The framework offers novel insights into watermarking paradigms and is validated through comprehensive experiments."}}
{"id": "2205.10016", "pdf": "https://arxiv.org/pdf/2205.10016", "abs": "https://arxiv.org/abs/2205.10016", "authors": ["Wenshuai Zhao", "Zhiyuan Li", "Joni Pajarinen"], "title": "Learning Progress Driven Multi-Agent Curriculum", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": "ICML 2025", "summary": "The number of agents can be an effective curriculum variable for controlling\nthe difficulty of multi-agent reinforcement learning (MARL) tasks. Existing\nwork typically uses manually defined curricula such as linear schemes. We\nidentify two potential flaws while applying existing reward-based automatic\ncurriculum learning methods in MARL: (1) The expected episode return used to\nmeasure task difficulty has high variance; (2) Credit assignment difficulty can\nbe exacerbated in tasks where increasing the number of agents yields higher\nreturns which is common in many MARL tasks. To address these issues, we propose\nto control the curriculum by using a TD-error based *learning progress* measure\nand by letting the curriculum proceed from an initial context distribution to\nthe final task specific one. Since our approach maintains a distribution over\nthe number of agents and measures learning progress rather than absolute\nperformance, which often increases with the number of agents, we alleviate\nproblem (2). Moreover, the learning progress measure naturally alleviates\nproblem (1) by aggregating returns. In three challenging sparse-reward MARL\nbenchmarks, our approach outperforms state-of-the-art baselines.", "AI": {"tldr": "Using TD-error-based learning progress to control curriculum difficulty in MARL outperforms manual and reward-based methods.", "motivation": "Existing reward-based curriculum methods in MARL have high variance in measuring difficulty and exacerbate credit assignment issues.", "method": "Proposes a TD-error-based learning progress measure and transitions from an initial context distribution to the final task-specific one.", "result": "Outperforms state-of-the-art baselines in three sparse-reward MARL benchmarks.", "conclusion": "The approach effectively addresses flaws in existing methods and improves MARL performance."}}
{"id": "2505.09939", "pdf": "https://arxiv.org/pdf/2505.09939", "abs": "https://arxiv.org/abs/2505.09939", "authors": ["Zhe Shan", "Lei Zhou", "Liu Mao", "Shaofan Chen", "Chuanqiu Ren", "Xia Xie"], "title": "Non-Registration Change Detection: A Novel Change Detection Task and Benchmark Dataset", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to IGARSS 2025", "summary": "In this study, we propose a novel remote sensing change detection task,\nnon-registration change detection, to address the increasing number of\nemergencies such as natural disasters, anthropogenic accidents, and military\nstrikes. First, in light of the limited discourse on the issue of\nnon-registration change detection, we systematically propose eight scenarios\nthat could arise in the real world and potentially contribute to the occurrence\nof non-registration problems. Second, we develop distinct image transformation\nschemes tailored to various scenarios to convert the available registration\nchange detection dataset into a non-registration version. Finally, we\ndemonstrate that non-registration change detection can cause catastrophic\ndamage to the state-of-the-art methods. Our code and dataset are available at\nhttps://github.com/ShanZard/NRCD.", "AI": {"tldr": "Proposes non-registration change detection for emergencies, identifies 8 real-world scenarios, transforms datasets, and shows severe impact on existing methods.", "motivation": "Addresses emergencies like disasters and accidents where traditional registration-based change detection fails due to misalignment.", "method": "Systematically identifies 8 scenarios, develops image transformation schemes to adapt registration datasets for non-registration tasks.", "result": "Demonstrates catastrophic performance drop in state-of-the-art methods when applied to non-registration change detection.", "conclusion": "Highlights the need for robust methods in non-registration scenarios, provides dataset and code for further research."}}
{"id": "2505.09943", "pdf": "https://arxiv.org/pdf/2505.09943", "abs": "https://arxiv.org/abs/2505.09943", "authors": ["Jiakun Deng", "Kexuan Li", "Xingye Cui", "Jiaxuan Li", "Chang Long", "Tian Pu", "Zhenming Peng"], "title": "CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection (ISTD) plays a critical role in a wide range\nof civilian and military applications. Existing methods suffer from\ndeficiencies in the localization of dim targets and the perception of contour\ninformation under dense clutter environments, severely limiting their detection\nperformance. To tackle these issues, we propose a contour-aware and saliency\npriors embedding network (CSPENet) for ISTD. We first design a\nsurround-convergent prior extraction module (SCPEM) that effectively captures\nthe intrinsic characteristic of target contour pixel gradients converging\ntoward their center. This module concurrently extracts two collaborative\npriors: a boosted saliency prior for accurate target localization and\nmulti-scale structural priors for comprehensively enriching contour detail\nrepresentation. Building upon this, we propose a dual-branch priors embedding\narchitecture (DBPEA) that establishes differentiated feature fusion pathways,\nembedding these two priors at optimal network positions to achieve performance\nenhancement. Finally, we develop an attention-guided feature enhancement module\n(AGFEM) to refine feature representations and improve saliency estimation\naccuracy. Experimental results on public datasets NUDT-SIRST, IRSTD-1k, and\nNUAA-SIRST demonstrate that our CSPENet outperforms other state-of-the-art\nmethods in detection performance. The code is available at\nhttps://github.com/IDIP2025/CSPENet.", "AI": {"tldr": "Proposes CSPENet for infrared small target detection, addressing dim target localization and contour perception under clutter. Outperforms state-of-the-art methods.", "motivation": "Existing methods struggle with dim target localization and contour perception in cluttered environments, limiting detection performance.", "method": "Introduces CSPENet with SCPEM for contour and saliency priors, DBPEA for feature fusion, and AGFEM for feature refinement.", "result": "Outperforms state-of-the-art methods on NUDT-SIRST, IRSTD-1k, and NUAA-SIRST datasets.", "conclusion": "CSPENet effectively improves infrared small target detection by leveraging contour-aware and saliency priors."}}
{"id": "2505.09792", "pdf": "https://arxiv.org/pdf/2505.09792", "abs": "https://arxiv.org/abs/2505.09792", "authors": ["Michael Kamfonas"], "title": "Interim Report on Human-Guided Adaptive Hyperparameter Optimization with Multi-Fidelity Sprints", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This case study applies a phased hyperparameter optimization process to\ncompare multitask natural language model variants that utilize multiphase\nlearning rate scheduling and optimizer parameter grouping. We employ short,\nBayesian optimization sessions that leverage multi-fidelity, hyperparameter\nspace pruning, progressive halving, and a degree of human guidance. We utilize\nthe Optuna TPE sampler and Hyperband pruner, as well as the Scikit-Learn\nGaussian process minimization. Initially, we use efficient low-fidelity sprints\nto prune the hyperparameter space. Subsequent sprints progressively increase\ntheir model fidelity and employ hyperband pruning for efficiency. A second\naspect of our approach is using a meta-learner to tune threshold values to\nresolve classification probabilities during inference. We demonstrate our\nmethod on a collection of variants of the 2021 Joint Entity and Relation\nExtraction model proposed by Eberts and Ulges.", "AI": {"tldr": "A phased hyperparameter optimization process compares multitask NLP model variants using multiphase learning rate scheduling and optimizer grouping, with Bayesian optimization and human guidance.", "motivation": "To efficiently optimize hyperparameters for multitask NLP models, leveraging advanced techniques like Bayesian optimization and human guidance.", "method": "Uses Bayesian optimization with Optuna TPE sampler, Hyperband pruner, and Scikit-Learn Gaussian process. Includes low-fidelity sprints for pruning and meta-learner for threshold tuning.", "result": "Demonstrated on variants of the 2021 Joint Entity and Relation Extraction model.", "conclusion": "The approach efficiently optimizes hyperparameters and resolves classification probabilities, validated on a specific NLP model."}}
{"id": "2505.10074", "pdf": "https://arxiv.org/pdf/2505.10074", "abs": "https://arxiv.org/abs/2505.10074", "authors": ["Mohamed Abdelmagied", "Mohamed Amine Chatti", "Shoeb Joarder", "Qurat Ul Ain", "Rawaa Alatrash"], "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs", "categories": ["cs.AI", "cs.CY"], "comment": "Accepted at EMOOCs 2025", "summary": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience.", "AI": {"tldr": "The paper proposes a Graph RAG pipeline using Educational and Personal Knowledge Graphs to enhance MOOC learning by generating personalized questions and answers, addressing LLM hallucinations and unstructured material limitations.", "motivation": "MOOCs lack direct interaction, and LLMs suffer from hallucinations. Current RAG systems don't guide learners effectively due to unstructured materials.", "method": "A Graph RAG pipeline leverages EduKGs and PKGs for personalized question generation and answering, tested on CourseMapper with expert instructors.", "result": "Evaluation shows Graph RAG's potential to improve personalized learning in MOOCs.", "conclusion": "Graph RAG effectively addresses MOOC learning challenges by combining structured knowledge graphs with personalized guidance."}}
{"id": "2505.09930", "pdf": "https://arxiv.org/pdf/2505.09930", "abs": "https://arxiv.org/abs/2505.09930", "authors": ["Zixiao Zhu", "Hanzhang Zhou", "Zijian Feng", "Tianjiao Li", "Chua Jia Jim Deryl", "Mak Lee Onn", "Gee Wah Ng", "Kezhi Mao"], "title": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization", "categories": ["cs.CL"], "comment": "20 pages, 14 figures", "summary": "Prompt optimization (PO) offers a practical alternative to fine-tuning large\nlanguage models (LLMs), enabling performance improvements without altering\nmodel weights. Existing methods typically rely on advanced, large-scale LLMs\nlike GPT-4 to generate optimized prompts. However, due to limited downward\ncompatibility, verbose, instruction-heavy prompts from advanced LLMs can\noverwhelm lightweight inference models and degrade response quality. In this\nwork, we rethink prompt optimization through the lens of interpretable design.\nWe first identify a set of model-agnostic prompt quality merits and empirically\nvalidate their effectiveness in enhancing prompt and response quality. We then\nintroduce MePO, a merit-guided, lightweight, and locally deployable prompt\noptimizer trained on our preference dataset built from merit-aligned prompts\ngenerated by a lightweight LLM. Unlike prior work, MePO avoids online\noptimization reliance, reduces cost and privacy concerns, and, by learning\nclear, interpretable merits, generalizes effectively to both large-scale and\nlightweight inference models. Experiments demonstrate that MePO achieves better\nresults across diverse tasks and model types, offering a scalable and robust\nsolution for real-world deployment. Our model and dataset are available at:\nhttps://github.com/MidiyaZhu/MePO", "AI": {"tldr": "MePO introduces a merit-guided, lightweight prompt optimizer for LLMs, improving performance without relying on large-scale models or online optimization.", "motivation": "Existing prompt optimization methods rely on advanced LLMs, which can degrade performance in lightweight models due to incompatibility. MePO addresses this by focusing on interpretable, model-agnostic prompt merits.", "method": "MePO is trained on a preference dataset of merit-aligned prompts from a lightweight LLM, avoiding reliance on large-scale models or online optimization.", "result": "MePO achieves better results across diverse tasks and model types, offering a scalable and robust solution.", "conclusion": "MePO provides a cost-effective, privacy-preserving, and generalizable approach to prompt optimization for both large and lightweight LLMs."}}
{"id": "2505.06761", "pdf": "https://arxiv.org/pdf/2505.06761", "abs": "https://arxiv.org/abs/2505.06761", "authors": ["Youcef Djenouri", "Nassim Belmecheri", "Tomasz Michalak", "Jan Dubi\u0144ski", "Ahmed Nabil Belbachir", "Anis Yazidi"], "title": "Learning Graph Representation of Agent Diffusers", "categories": ["cs.LG", "cs.MA"], "comment": "Accepted at AAMAS2025 International Conference on Autonomous Agents\n  and Multiagent Systems", "summary": "Diffusion-based generative models have significantly advanced text-to-image\nsynthesis, demonstrating impressive text comprehension and zero-shot\ngeneralization. These models refine images from random noise based on textual\nprompts, with initial reliance on text input shifting towards enhanced visual\nfidelity over time. This transition suggests that static model parameters might\nnot optimally address the distinct phases of generation. We introduce LGR-AD\n(Learning Graph Representation of Agent Diffusers), a novel multi-agent system\ndesigned to improve adaptability in dynamic computer vision tasks. LGR-AD\nmodels the generation process as a distributed system of interacting agents,\neach representing an expert sub-model. These agents dynamically adapt to\nvarying conditions and collaborate through a graph neural network that encodes\ntheir relationships and performance metrics. Our approach employs a\ncoordination mechanism based on top-$k$ maximum spanning trees, optimizing the\ngeneration process. Each agent's decision-making is guided by a meta-model that\nminimizes a novel loss function, balancing accuracy and diversity. Theoretical\nanalysis and extensive empirical evaluations show that LGR-AD outperforms\ntraditional diffusion models across various benchmarks, highlighting its\npotential for scalable and flexible solutions in complex image generation\ntasks. Code is available at: https://github.com/YousIA/LGR_AD", "AI": {"tldr": "LGR-AD is a multi-agent system improving adaptability in text-to-image synthesis by modeling generation as distributed agents collaborating via a graph neural network, outperforming traditional diffusion models.", "motivation": "Static model parameters in diffusion-based generative models may not optimally handle distinct generation phases, prompting the need for adaptable solutions like LGR-AD.", "method": "LGR-AD uses a multi-agent system with expert sub-models, a graph neural network for collaboration, and a top-$k$ maximum spanning tree coordination mechanism. A meta-model guides agents with a novel loss function.", "result": "LGR-AD outperforms traditional diffusion models in benchmarks, demonstrating scalability and flexibility in complex image generation.", "conclusion": "LGR-AD offers a promising, adaptable approach for dynamic computer vision tasks, with potential for broader applications in image synthesis."}}
{"id": "2505.09986", "pdf": "https://arxiv.org/pdf/2505.09986", "abs": "https://arxiv.org/abs/2505.09986", "authors": ["Yimin Zhou", "Yichong Xia", "Sicheng Pan", "Bin Chen", "Baoyi An", "Haoqian Wang", "Zhi Wang", "Yaowei Wang", "Zikun Zhou"], "title": "High Quality Underwater Image Compression with Adaptive Correction and Codebook-based Augmentation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "With the increasing exploration and exploitation of the underwater world,\nunderwater images have become a critical medium for human interaction with\nmarine environments, driving extensive research into their efficient\ntransmission and storage. However, contemporary underwater image compression\nalgorithms fail to fully leverage the unique characteristics distinguishing\nunderwater scenes from terrestrial images, resulting in suboptimal performance.\nTo address this limitation, we introduce HQUIC, designed to exploit\nunderwater-image-specific features for enhanced compression efficiency. HQUIC\nemploys an ALTC module to adaptively predict the attenuation coefficients and\nglobal light information of the images, which effectively mitigates the issues\ncaused by the differences in lighting and tone existing in underwater images.\nSubsequently, HQUIC employs a codebook as an auxiliary branch to extract the\ncommon objects within underwater images and enhances the performance of the\nmain branch. Furthermore, HQUIC dynamically weights multi-scale frequency\ncomponents, prioritizing information critical for distortion quality while\ndiscarding redundant details. Extensive evaluations on diverse underwater\ndatasets demonstrate that HQUIC outperforms state-of-the-art compression\nmethods.", "AI": {"tldr": "HQUIC is a novel underwater image compression method leveraging unique underwater features for better efficiency, outperforming existing techniques.", "motivation": "Underwater image compression lacks optimization for underwater-specific characteristics, leading to subpar performance.", "method": "HQUIC uses an ALTC module for adaptive prediction of attenuation coefficients and global light, a codebook for common object extraction, and dynamic weighting of multi-scale frequency components.", "result": "HQUIC achieves superior performance compared to state-of-the-art compression methods on diverse underwater datasets.", "conclusion": "HQUIC effectively addresses underwater image compression challenges by exploiting scene-specific features, offering enhanced efficiency."}}
{"id": "2505.09965", "pdf": "https://arxiv.org/pdf/2505.09965", "abs": "https://arxiv.org/abs/2505.09965", "authors": ["Hao Yang", "Tao Tan", "Shuai Tan", "Weiqin Yang", "Kunyan Cai", "Calvin Chen", "Yue Sun"], "title": "MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Modelling disease progression in precision medicine requires capturing\ncomplex spatio-temporal dynamics while preserving anatomical integrity.\nExisting methods often struggle with longitudinal dependencies and structural\nconsistency in progressive disorders. To address these limitations, we\nintroduce MambaControl, a novel framework that integrates selective state-space\nmodelling with diffusion processes for high-fidelity prediction of medical\nimage trajectories. To better capture subtle structural changes over time while\nmaintaining anatomical consistency, MambaControl combines Mamba-based\nlong-range modelling with graph-guided anatomical control to more effectively\nrepresent anatomical correlations. Furthermore, we introduce Fourier-enhanced\nspectral graph representations to capture spatial coherence and multiscale\ndetail, enabling MambaControl to achieve state-of-the-art performance in\nAlzheimer's disease prediction. Quantitative and regional evaluations\ndemonstrate improved progression prediction quality and anatomical fidelity,\nhighlighting its potential for personalised prognosis and clinical decision\nsupport.", "AI": {"tldr": "MambaControl integrates selective state-space modelling and diffusion processes for high-fidelity prediction of medical image trajectories, improving disease progression modelling.", "motivation": "Existing methods struggle with longitudinal dependencies and structural consistency in progressive disorders, necessitating a better approach.", "method": "Combines Mamba-based long-range modelling with graph-guided anatomical control and Fourier-enhanced spectral graph representations.", "result": "Achieves state-of-the-art performance in Alzheimer's disease prediction with improved progression quality and anatomical fidelity.", "conclusion": "MambaControl shows promise for personalised prognosis and clinical decision support."}}
{"id": "2505.09810", "pdf": "https://arxiv.org/pdf/2505.09810", "abs": "https://arxiv.org/abs/2505.09810", "authors": ["Daniel Waddington", "Cornel Constantinescu"], "title": "Lossless Compression for LLM Tensor Incremental Snapshots", "categories": ["cs.LG"], "comment": null, "summary": "During the training of Large Language Models (LLMs), tensor data is\nperiodically \"checkpointed\" to persistent storage to allow recovery of work\ndone in the event of failure. The volume of data that must be copied during\neach checkpoint, even when using reduced-precision representations such as\nbfloat16, often reaches hundreds of gigabytes. Furthermore, the data must be\nmoved across a network and written to a storage system before the next epoch\noccurs. With a view to ultimately building an optimized checkpointing solution,\nthis paper presents experimental analysis of checkpoint data used to derive a\ndesign that maximizes the use of lossless compression to reduce the volume of\ndata. We examine how tensor data and its compressibility evolve during model\ntraining and evaluate the efficacy of existing common off-the-shelf general\npurpose compression engines combined with known data optimization techniques\nsuch as byte-grouping and incremental delta compression.\n  Leveraging our analysis we have built an effective compression solution,\nknown as Language Model Compressor (LMC), which is based on byte-grouping and\nHuffman encoding. LMC offers more compression performance than the best\nalternative (BZ2) but with an order-of-magnitude reduction in the time needed\nto perform the compression. We show that a 16-core parallel implementation of\nLMC can attain compression and decompression throughput of 2.78 GiB/s and 3.76\nGiB/s respectively. This increase in performance ultimately reduces the CPU\nresources needed and provides more time to copy the data to the storage system\nbefore the next epoch thus allowing for higher-frequency checkpoints.", "AI": {"tldr": "The paper proposes an optimized checkpointing solution for LLMs using lossless compression (LMC), improving speed and efficiency over existing methods like BZ2.", "motivation": "Checkpointing large volumes of tensor data in LLMs is resource-intensive, requiring efficient compression to reduce data volume and improve performance.", "method": "Analyzes tensor data compressibility during training, evaluates off-the-shelf compression engines, and introduces LMC (byte-grouping + Huffman encoding).", "result": "LMC outperforms BZ2 in compression speed (2.78 GiB/s compression, 3.76 GiB/s decompression) and reduces CPU usage, enabling higher-frequency checkpoints.", "conclusion": "LMC provides a faster, more efficient checkpointing solution for LLMs, optimizing data transfer and storage usage."}}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems.", "AI": {"tldr": "This study uses AI to transform unstructured Taiwanese China Studies texts into structured knowledge graphs, enhancing scholarly access and revealing research insights.", "motivation": "The need to systematically revisit and reorganize decades of Taiwan-based China Studies scholarship due to its interdisciplinary richness and geopolitical uniqueness.", "method": "Generative AI and large language models extract and standardize entity-relation triples from 1,367 peer-reviewed articles (1996-2019), visualized via D3.js for interactive exploration.", "result": "Creation of a domain-specific knowledge graph and vector database, uncovering intellectual trajectories, thematic clusters, and research gaps.", "conclusion": "The AI-assisted approach shifts from linear text to network-based knowledge navigation, offering scalable, data-driven ontology construction for regional studies."}}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time.", "AI": {"tldr": "The paper proposes retrieval augmented generation (RAG) with knowledge graphs (KGs) to reduce hallucinations in LLMs by providing timely, factual, and personalized data, focusing on calendar data.", "motivation": "LLMs often generate incorrect or extra data (hallucinations) due to lack of timely and personalized information.", "method": "Introduces RAG using KGs to supply structured, updated data (e.g., calendar info) to LLMs for personalized responses.", "result": "The approach outperforms baseline LLMs in accuracy for personal data responses, with a slight reduction in response time.", "conclusion": "Using KGs with RAG improves LLM response accuracy for personalized queries, especially with dynamic data like calendars."}}
{"id": "2505.10124", "pdf": "https://arxiv.org/pdf/2505.10124", "abs": "https://arxiv.org/abs/2505.10124", "authors": ["Ziad Kheil", "Lucas Robinet", "Laurent Risser", "Soleakhena Ken"], "title": "IMITATE: Image Registration with Context for unknown time frame recovery", "categories": ["cs.CV", "eess.IV"], "comment": "IEEE ISBI 2025", "summary": "In this paper, we formulate a novel image registration formalism dedicated to\nthe estimation of unknown condition-related images, based on two or more known\nimages and their associated conditions. We show how to practically model this\nformalism by using a new conditional U-Net architecture, which fully takes into\naccount the conditional information and does not need any fixed image. Our\nformalism is then applied to image moving tumors for radiotherapy treatment at\ndifferent breathing amplitude using 4D-CT (3D+t) scans in thoracoabdominal\nregions. This driving application is particularly complex as it requires to\nstitch a collection of sequential 2D slices into several 3D volumes at\ndifferent organ positions. Movement interpolation with standard methods then\ngenerates well known reconstruction artefacts in the assembled volumes due to\nirregular patient breathing, hysteresis and poor correlation of breathing\nsignal to internal motion. Results obtained on 4D-CT clinical data showcase\nartefact-free volumes achieved through real-time latencies. The code is\npublicly available at https://github.com/Kheil-Z/IMITATE .", "AI": {"tldr": "A novel image registration method using conditional U-Net for estimating unknown condition-related images from known ones, applied to tumor movement in radiotherapy with 4D-CT scans, achieving artefact-free results.", "motivation": "To address challenges in image registration for radiotherapy, especially irregular breathing and motion artefacts in 4D-CT scans.", "method": "A conditional U-Net architecture that incorporates conditional information without needing fixed images, applied to 4D-CT thoracoabdominal scans.", "result": "Artefact-free 3D volumes with real-time latencies, demonstrated on clinical 4D-CT data.", "conclusion": "The proposed method effectively handles complex motion interpolation in radiotherapy, improving reconstruction quality."}}
{"id": "2505.09967", "pdf": "https://arxiv.org/pdf/2505.09967", "abs": "https://arxiv.org/abs/2505.09967", "authors": ["Liqian Deng"], "title": "TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Facial expression recognition (FER) in the wild remains a challenging task\ndue to the subtle and localized nature of expression-related features, as well\nas the complex variations in facial appearance. In this paper, we introduce a\nnovel framework that explicitly focuses on Texture Key Driver Factors (TKDF),\nlocalized texture regions that exhibit strong discriminative power across\nemotional categories. By carefully observing facial image patterns, we identify\nthat certain texture cues, such as micro-changes in skin around the brows,\neyes, and mouth, serve as primary indicators of emotional dynamics. To\neffectively capture and leverage these cues, we propose a FER architecture\ncomprising a Texture-Aware Feature Extractor (TAFE) and Dual Contextual\nInformation Filtering (DCIF). TAFE employs a ResNet-based backbone enhanced\nwith multi-branch attention to extract fine-grained texture representations,\nwhile DCIF refines these features by filtering context through adaptive pooling\nand attention mechanisms. Experimental results on RAF-DB and KDEF datasets\ndemonstrate that our method achieves state-of-the-art performance, verifying\nthe effectiveness and robustness of incorporating TKDFs into FER pipelines.", "AI": {"tldr": "A novel FER framework focusing on Texture Key Driver Factors (TKDF) achieves state-of-the-art performance by leveraging localized texture cues and a dual-component architecture (TAFE and DCIF).", "motivation": "FER in the wild is challenging due to subtle, localized expression features and complex facial variations. TKDFs address this by identifying discriminative texture regions.", "method": "Proposes a framework with Texture-Aware Feature Extractor (TAFE) for fine-grained texture extraction and Dual Contextual Information Filtering (DCIF) for feature refinement.", "result": "Achieves state-of-the-art performance on RAF-DB and KDEF datasets, validating TKDF's effectiveness.", "conclusion": "Incorporating TKDFs into FER pipelines enhances performance and robustness."}}
{"id": "2505.09812", "pdf": "https://arxiv.org/pdf/2505.09812", "abs": "https://arxiv.org/abs/2505.09812", "authors": ["Anastasija Tashkova", "Stefan Eftimov", "Bojan Ristov", "Slobodan Kalajdziski"], "title": "Comparative Analysis of Stroke Prediction Models Using Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Stroke remains one of the most critical global health challenges, ranking as\nthe second leading cause of death and the third leading cause of disability\nworldwide. This study explores the effectiveness of machine learning algorithms\nin predicting stroke risk using demographic, clinical, and lifestyle data from\nthe Stroke Prediction Dataset. By addressing key methodological challenges such\nas class imbalance and missing data, we evaluated the performance of multiple\nmodels, including Logistic Regression, Random Forest, and XGBoost. Our results\ndemonstrate that while these models achieve high accuracy, sensitivity remains\na limiting factor for real-world clinical applications. In addition, we\nidentify the most influential predictive features and propose strategies to\nimprove machine learning-based stroke prediction. These findings contribute to\nthe development of more reliable and interpretable models for the early\nassessment of stroke risk.", "AI": {"tldr": "The study evaluates machine learning models for stroke risk prediction, highlighting accuracy but noting sensitivity limitations.", "motivation": "Stroke is a major global health issue, necessitating better prediction methods.", "method": "Used Logistic Regression, Random Forest, and XGBoost on demographic, clinical, and lifestyle data, addressing class imbalance and missing data.", "result": "Models achieved high accuracy but lacked sensitivity; key predictive features were identified.", "conclusion": "Findings aid in developing better, interpretable models for early stroke risk assessment."}}
{"id": "2505.10188", "pdf": "https://arxiv.org/pdf/2505.10188", "abs": "https://arxiv.org/abs/2505.10188", "authors": ["Felix Liedeker", "Olivia Sanchez-Graillet", "Moana Seidler", "Christian Brandt", "J\u00f6rg Wellmer", "Philipp Cimiano"], "title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support", "categories": ["cs.AI"], "comment": "Presented at 'The First Workshop on Natural Language Argument-Based\n  Explanations', co-located with ECAI 2024", "summary": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective.", "AI": {"tldr": "The paper explores effective AI-generated explanations in healthcare, focusing on trust and transparency in ML systems for diagnostic decision support.", "motivation": "To understand which AI explanations enhance trust and transparency in healthcare, especially in shared decision-making between doctors and ML systems.", "method": "Conducted a user study with physicians, including surveys and interviews, to evaluate different XAI explanations in diagnostic contexts.", "result": "Identified the most effective explanations for enhancing the diagnostic process based on physician feedback.", "conclusion": "The study provides insights into optimal AI explanations for improving trust and utility in healthcare decision-making."}}
{"id": "2505.10013", "pdf": "https://arxiv.org/pdf/2505.10013", "abs": "https://arxiv.org/abs/2505.10013", "authors": ["Lake Yin", "Fan Huang"], "title": "DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs", "categories": ["cs.CL"], "comment": "7 pages, 1 figure", "summary": "As Large Language Models (LLMs) have risen in prominence over the past few\nyears, there has been concern over the potential biases in LLMs inherited from\nthe training data. Previous studies have examined how LLMs exhibit implicit\nbias, such as when response generation changes when different social contexts\nare introduced. We argue that this implicit bias is not only an ethical, but\nalso a technical issue, as it reveals an inability of LLMs to accommodate\nextraneous information. However, unlike other measures of LLM intelligence,\nthere are no standard methods to benchmark this specific subset of LLM bias. To\nbridge this gap, we developed a method for calculating an easily interpretable\nbenchmark, DIF (Demographic Implicit Fairness), by evaluating preexisting LLM\nlogic and math problem datasets with sociodemographic personas. We demonstrate\nthat this method can statistically validate the presence of implicit bias in\nLLM behavior and find an inverse trend between question answering accuracy and\nimplicit bias, supporting our argument.", "AI": {"tldr": "The paper introduces DIF (Demographic Implicit Fairness), a method to benchmark implicit bias in LLMs, revealing an inverse trend between bias and accuracy.", "motivation": "Addressing the lack of standard methods to measure implicit bias in LLMs, which is both an ethical and technical issue.", "method": "Developed DIF by evaluating LLM logic/math problem datasets with sociodemographic personas.", "result": "Statistically validated implicit bias in LLMs and found an inverse relationship between bias and accuracy.", "conclusion": "DIF provides a standardized benchmark for implicit bias, highlighting its impact on LLM performance."}}
{"id": "2406.12632", "pdf": "https://arxiv.org/pdf/2406.12632", "abs": "https://arxiv.org/abs/2406.12632", "authors": ["Junho Moon", "Symac Kim", "Haejun Chung", "Ikbeom Jang"], "title": "Cyclic 2.5D Perceptual Loss for Cross-Modal 3D Medical Image Synthesis: T1w MRI to Tau PET", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "There is a demand for medical image synthesis or translation to generate\nsynthetic images of missing modalities from available data. This need stems\nfrom challenges such as restricted access to high-cost imaging devices,\ngovernment regulations, or failure to follow up with patients or study\nparticipants. In medical imaging, preserving high-level semantic features is\noften more critical than achieving pixel-level accuracy. Perceptual loss\nfunctions are widely employed to train medical image synthesis or translation\nmodels, as they quantify differences in high-level image features using a\npre-trained feature extraction network. While 3D and 2.5D perceptual losses are\nused in 3D medical image synthesis, they face challenges, such as the lack of\npre-trained 3D models or difficulties in balancing loss reduction across\ndifferent planes. In this work, we focus on synthesizing 3D tau PET images from\n3D T1-weighted MR images. We propose a cyclic 2.5D perceptual loss that\nsequentially computes the 2D average perceptual loss for each of the axial,\ncoronal, and sagittal planes over epochs, with the cycle duration gradually\ndecreasing. Additionally, we process tau PET images using by-manufacturer\nstandardization to enhance the preservation of high-SUVR regions indicative of\ntau pathology and mitigate SUVR variability caused by inter-manufacturer\ndifferences. We combine the proposed loss with SSIM and MSE losses and\ndemonstrate its effectiveness in improving both quantitative and qualitative\nperformance across various generative models, including U-Net, UNETR,\nSwinUNETR, CycleGAN, and Pix2Pix.", "AI": {"tldr": "The paper proposes a cyclic 2.5D perceptual loss for synthesizing 3D tau PET images from 3D T1-weighted MR images, addressing challenges in 3D medical image synthesis.", "motivation": "The need arises from limited access to imaging devices, regulatory issues, and patient follow-up challenges, with a focus on preserving high-level semantic features over pixel-level accuracy.", "method": "A cyclic 2.5D perceptual loss is introduced, computing 2D average perceptual loss for axial, coronal, and sagittal planes sequentially. Tau PET images are standardized to preserve high-SUVR regions.", "result": "The method improves quantitative and qualitative performance across models like U-Net, UNETR, SwinUNETR, CycleGAN, and Pix2Pix.", "conclusion": "The proposed cyclic 2.5D perceptual loss effectively enhances 3D medical image synthesis, balancing loss reduction and preserving critical features."}}
{"id": "2505.09971", "pdf": "https://arxiv.org/pdf/2505.09971", "abs": "https://arxiv.org/abs/2505.09971", "authors": ["Yuan Gao", "Shaobo Xia", "Sheng Nie", "Cheng Wang", "Xiaohuan Xi", "Bisheng Yang"], "title": "APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds", "categories": ["cs.CV"], "comment": "18 pages,12 figures", "summary": "Airborne laser scanning (ALS) point cloud segmentation is a fundamental task\nfor large-scale 3D scene understanding. In real-world applications, models are\ntypically fixed after training. However, domain shifts caused by changes in the\nenvironment, sensor types, or sensor degradation often lead to a decline in\nmodel performance. Continuous Test-Time Adaptation (CTTA) offers a solution by\nadapting a source-pretrained model to evolving, unlabeled target domains.\nDespite its potential, research on ALS point clouds remains limited, facing\nchallenges such as the absence of standardized datasets and the risk of\ncatastrophic forgetting and error accumulation during prolonged adaptation. To\ntackle these challenges, we propose APCoTTA, the first CTTA method tailored for\nALS point cloud semantic segmentation. We propose a dynamic trainable layer\nselection module. This module utilizes gradient information to select\nlow-confidence layers for training, and the remaining layers are kept frozen,\nmitigating catastrophic forgetting. To further reduce error accumulation, we\npropose an entropy-based consistency loss. By losing such samples based on\nentropy, we apply consistency loss only to the reliable samples, enhancing\nmodel stability. In addition, we propose a random parameter interpolation\nmechanism, which randomly blends parameters from the selected trainable layers\nwith those of the source model. This approach helps balance target adaptation\nand source knowledge retention, further alleviating forgetting. Finally, we\nconstruct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA\nbenchmarks for ALS point cloud segmentation. Experimental results demonstrate\nthat APCoTTA achieves the best performance on two benchmarks, with mIoU\nimprovements of approximately 9% and 14% over direct inference. The new\nbenchmarks and code are available at https://github.com/Gaoyuan2/APCoTTA.", "AI": {"tldr": "APCoTTA is a novel CTTA method for ALS point cloud segmentation, addressing domain shifts, catastrophic forgetting, and error accumulation via dynamic layer selection, entropy-based consistency loss, and parameter interpolation. It outperforms direct inference by 9-14% mIoU on new benchmarks.", "motivation": "Domain shifts in ALS point clouds degrade model performance post-training. CTTA can adapt models to evolving target domains, but lacks research and benchmarks for ALS data.", "method": "APCoTTA uses dynamic trainable layer selection, entropy-based consistency loss, and random parameter interpolation to balance adaptation and source knowledge retention.", "result": "APCoTTA improves mIoU by ~9% and 14% over direct inference on ISPRSC and H3DC benchmarks.", "conclusion": "APCoTTA effectively addresses CTTA challenges for ALS point clouds, offering superior performance and new benchmarks for future research."}}
{"id": "2505.09820", "pdf": "https://arxiv.org/pdf/2505.09820", "abs": "https://arxiv.org/abs/2505.09820", "authors": ["Sajib Biswas", "Mao Nishino", "Samuel Jacob Chacko", "Xiuwen Liu"], "title": "Adversarial Attack on Large Language Models using Exponentiated Gradient Descent", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": "Accepted to International Joint Conference on Neural Networks (IJCNN)\n  2025", "summary": "As Large Language Models (LLMs) are widely used, understanding them\nsystematically is key to improving their safety and realizing their full\npotential. Although many models are aligned using techniques such as\nreinforcement learning from human feedback (RLHF), they are still vulnerable to\njailbreaking attacks. Some of the existing adversarial attack methods search\nfor discrete tokens that may jailbreak a target model while others try to\noptimize the continuous space represented by the tokens of the model's\nvocabulary. While techniques based on the discrete space may prove to be\ninefficient, optimization of continuous token embeddings requires projections\nto produce discrete tokens, which might render them ineffective. To fully\nutilize the constraints and the structures of the space, we develop an\nintrinsic optimization technique using exponentiated gradient descent with the\nBregman projection method to ensure that the optimized one-hot encoding always\nstays within the probability simplex. We prove the convergence of the technique\nand implement an efficient algorithm that is effective in jailbreaking several\nwidely used LLMs. We demonstrate the efficacy of the proposed technique using\nfive open-source LLMs on four openly available datasets. The results show that\nthe technique achieves a higher success rate with great efficiency compared to\nthree other state-of-the-art jailbreaking techniques. The source code for our\nimplementation is available at:\nhttps://github.com/sbamit/Exponentiated-Gradient-Descent-LLM-Attack", "AI": {"tldr": "The paper introduces an intrinsic optimization technique using exponentiated gradient descent with Bregman projection to jailbreak LLMs efficiently, outperforming existing methods.", "motivation": "Understanding and improving LLM safety is crucial, but current alignment techniques like RLHF leave models vulnerable to jailbreaking attacks. Existing methods are either inefficient or ineffective due to discrete or continuous space limitations.", "method": "The proposed method uses exponentiated gradient descent with Bregman projection to optimize one-hot encodings within the probability simplex, ensuring convergence and efficiency.", "result": "The technique achieves higher success rates in jailbreaking five open-source LLMs across four datasets, outperforming three state-of-the-art methods.", "conclusion": "The proposed optimization technique is effective and efficient for jailbreaking LLMs, demonstrating superior performance over existing approaches."}}
{"id": "2505.10278", "pdf": "https://arxiv.org/pdf/2505.10278", "abs": "https://arxiv.org/abs/2505.10278", "authors": ["Taian Guo", "Haiyang Shen", "Jinsheng Huang", "Zhengyang Mao", "Junyu Luo", "Zhuoru Chen", "Xuhui Liu", "Bingyu Xia", "Luchen Liu", "Yun Ma", "Ming Zhang"], "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "categories": ["cs.AI"], "comment": null, "summary": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS.", "AI": {"tldr": "MASS introduces a scalable multi-agent system for portfolio construction, outperforming baselines by dynamically increasing agents and optimizing distribution via reverse optimization.", "motivation": "Existing multi-agent systems are limited to simulations or fixed workflows, hindering real-world applicability and performance.", "method": "MASS uses progressive agent scaling and reverse optimization for end-to-end agent distribution, avoiding fixed workflows.", "result": "MASS achieves stable excess returns, validated through extensive experiments against 6 baselines on 3 stock pools.", "conclusion": "MASS's scalable paradigm can extend to similar tasks, with its implementation open-sourced."}}
{"id": "2505.10063", "pdf": "https://arxiv.org/pdf/2505.10063", "abs": "https://arxiv.org/abs/2505.10063", "authors": ["Han Peng", "Jinhao Jiang", "Zican Dong", "Wayne Xin Zhao", "Lei Fang"], "title": "CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability", "categories": ["cs.CL"], "comment": null, "summary": "Advancements in Large Language Models (LLMs) have extended their input\ncontext length, yet they still struggle with retrieval and reasoning in\nlong-context inputs. Existing methods propose to utilize the prompt strategy\nand retrieval head to alleviate this limitation. However, they still face\nchallenges in balancing retrieval precision and recall, impacting their\nefficacy in answering questions. To address this, we introduce $\\textbf{CAFE}$,\na two-stage coarse-to-fine method to enhance multi-document question-answering\ncapacities. By gradually eliminating the negative impacts of background and\ndistracting documents, CAFE makes the responses more reliant on the evidence\ndocuments. Initially, a coarse-grained filtering method leverages retrieval\nheads to identify and rank relevant documents. Then, a fine-grained steering\nmethod guides attention to the most relevant content. Experiments across\nbenchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7%\nSubEM improvement over SFT and RAG methods on the Mistral model, respectively.", "AI": {"tldr": "CAFE is a two-stage method improving LLMs' question-answering in long-context inputs by coarse-to-fine document filtering and attention steering.", "motivation": "LLMs struggle with retrieval and reasoning in long-context inputs, needing better precision-recall balance.", "method": "Coarse-grained filtering ranks documents; fine-grained steering focuses attention on relevant content.", "result": "CAFE outperforms baselines, achieving up to 22.1% and 13.7% SubEM improvement over SFT and RAG methods.", "conclusion": "CAFE effectively enhances multi-document QA by reducing noise and improving evidence reliance."}}
{"id": "2411.13602", "pdf": "https://arxiv.org/pdf/2411.13602", "abs": "https://arxiv.org/abs/2411.13602", "authors": ["Zhengyao Ding", "Ziyu Li", "Yujian Hu", "Youyao Xu", "Chengchen Zhao", "Yiheng Mao", "Haitao Li", "Zhikang Li", "Qian Li", "Jing Wang", "Yue Chen", "Mengjia Chen", "Longbo Wang", "Xuesen Chu", "Weichao Pan", "Ziyi Liu", "Fei Wu", "Hongkun Zhang", "Ting Chen", "Zhengxing Huang"], "title": "Translating Electrocardiograms to Cardiac Magnetic Resonance Imaging Useful for Cardiac Assessment and Disease Screening: A Multi-Center Study AI for ECG to CMR Translation Study", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "27 pages, 11 figures", "summary": "Cardiovascular diseases (CVDs) are the leading cause of global mortality,\nnecessitating accessible and accurate diagnostic tools. While cardiac magnetic\nresonance imaging (CMR) provides gold-standard insights into cardiac structure\nand function, its clinical utility is limited by high cost and complexity. In\ncontrast, electrocardiography (ECG) is inexpensive and widely available but\nlacks the granularity of CMR. We propose CardioNets, a deep learning framework\nthat translates 12-lead ECG signals into CMR-level functional parameters and\nsynthetic images, enabling scalable cardiac assessment. CardioNets integrates\ncross-modal contrastive learning and generative pretraining, aligning ECG with\nCMR-derived cardiac phenotypes and synthesizing high-resolution CMR images via\na masked autoregressive model. Trained on 159,819 samples from five cohorts,\nincluding the UK Biobank (n=42,483) and MIMIC-IV-ECG (n=164,550), and\nexternally validated on independent clinical datasets (n=3,767), CardioNets\nachieved strong performance across disease screening and phenotype estimation\ntasks. In the UK Biobank, it improved cardiac phenotype regression R2 by 24.8%\nand cardiomyopathy AUC by up to 39.3% over baseline models. In MIMIC, it\nincreased AUC for pulmonary hypertension detection by 5.6%. Generated CMR\nimages showed 36.6% higher SSIM and 8.7% higher PSNR than prior approaches. In\na reader study, ECG-only CardioNets achieved 13.9% higher accuracy than human\nphysicians using both ECG and real CMR. These results suggest that CardioNets\noffers a promising, low-cost alternative to CMR for large-scale CVD screening,\nparticularly in resource-limited settings. Future efforts will focus on\nclinical deployment and regulatory validation of ECG-based synthetic imaging.", "AI": {"tldr": "CardioNets, a deep learning framework, translates ECG signals into CMR-level insights, offering a cost-effective alternative for CVD screening.", "motivation": "CVDs are a global health priority, but CMR is costly and ECG lacks detail. CardioNets bridges this gap.", "method": "Uses cross-modal contrastive learning and generative pretraining to align ECG with CMR and synthesize images.", "result": "Improved cardiac phenotype regression by 24.8%, disease detection AUC by up to 39.3%, and outperformed human physicians.", "conclusion": "CardioNets is a scalable, low-cost solution for CVD screening, especially in resource-limited settings."}}
{"id": "2505.09990", "pdf": "https://arxiv.org/pdf/2505.09990", "abs": "https://arxiv.org/abs/2505.09990", "authors": ["Long Cheng", "Jiafei Duan", "Yi Ru Wang", "Haoquan Fang", "Boyang Li", "Yushan Huang", "Elvis Wang", "Ainaz Eftekhar", "Jason Lee", "Wentao Yuan", "Rose Hendrix", "Noah A. Smith", "Fei Xia", "Dieter Fox", "Ranjay Krishna"], "title": "PointArena: Probing Multimodal Grounding Through Language-Guided Pointing", "categories": ["cs.CV"], "comment": "10 Pages, Dataset and code:https://pointarena.github.io/", "summary": "Pointing serves as a fundamental and intuitive mechanism for grounding\nlanguage within visual contexts, with applications spanning robotics, assistive\ntechnologies, and interactive AI systems. While recent multimodal models have\nstarted to support pointing capabilities, existing benchmarks typically focus\nonly on referential object localization tasks. We introduce PointArena, a\ncomprehensive platform for evaluating multimodal pointing across diverse\nreasoning scenarios. PointArena comprises three components: (1) Point-Bench, a\ncurated dataset containing approximately 1,000 pointing tasks across five\nreasoning categories; (2) Point-Battle, an interactive, web-based arena\nfacilitating blind, pairwise model comparisons, which has already gathered over\n4,500 anonymized votes; and (3) Point-Act, a real-world robotic manipulation\nsystem allowing users to directly evaluate multimodal model pointing\ncapabilities in practical settings. We conducted extensive evaluations of both\nstate-of-the-art open-source and proprietary multimodal models. Results\nindicate that Molmo-72B consistently outperforms other models, though\nproprietary models increasingly demonstrate comparable performance.\nAdditionally, we find that supervised training specifically targeting pointing\ntasks significantly enhances model performance. Across our multi-stage\nevaluation pipeline, we also observe strong correlations, underscoring the\ncritical role of precise pointing capabilities in enabling multimodal models to\neffectively bridge abstract reasoning with concrete, real-world actions.\nProject page: https://pointarena.github.io/", "AI": {"tldr": "PointArena is a platform for evaluating multimodal pointing across diverse reasoning scenarios, featuring a dataset, interactive arena, and robotic system. Molmo-72B outperforms others, and supervised training improves pointing performance.", "motivation": "To address the lack of comprehensive benchmarks for multimodal pointing beyond referential object localization, enabling better evaluation in diverse reasoning scenarios.", "method": "PointArena includes Point-Bench (dataset), Point-Battle (interactive arena), and Point-Act (robotic system). Evaluated state-of-the-art models with supervised training.", "result": "Molmo-72B consistently outperforms other models; proprietary models show comparable performance. Supervised training enhances pointing capabilities.", "conclusion": "Precise pointing is crucial for multimodal models to bridge abstract reasoning with real-world actions, validated by strong correlations in evaluations."}}
{"id": "2505.09822", "pdf": "https://arxiv.org/pdf/2505.09822", "abs": "https://arxiv.org/abs/2505.09822", "authors": ["Changhao Shi", "Gal Mishne"], "title": "Learning Kronecker-Structured Graphs from Smooth Signals", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph learning, or network inference, is a prominent problem in graph signal\nprocessing (GSP). GSP generalizes the Fourier transform to non-Euclidean\ndomains, and graph learning is pivotal to applying GSP when these domains are\nunknown. With the recent prevalence of multi-way data, there has been growing\ninterest in product graphs that naturally factorize dependencies across\ndifferent ways. However, the types of graph products that can be learned are\nstill limited for modeling diverse dependency structures. In this paper, we\nstudy the problem of learning a Kronecker-structured product graph from smooth\nsignals. Unlike the more commonly used Cartesian product, the Kronecker product\nmodels dependencies in a more intricate, non-separable way, but posits harder\nconstraints on the graph learning problem. To tackle this non-convex problem,\nwe propose an alternating scheme to optimize each factor graph and provide\ntheoretical guarantees for its asymptotic convergence. The proposed algorithm\nis also modified to learn factor graphs of the strong product. We conduct\nexperiments on synthetic and real-world graphs and demonstrate our approach's\nefficacy and superior performance compared to existing methods.", "AI": {"tldr": "The paper focuses on learning Kronecker-structured product graphs from smooth signals, addressing limitations in modeling diverse dependency structures. It proposes an alternating optimization scheme with theoretical guarantees and demonstrates superior performance.", "motivation": "Graph learning is crucial in GSP for non-Euclidean domains, but existing methods are limited in modeling diverse dependencies, especially for multi-way data.", "method": "An alternating optimization scheme is proposed to learn Kronecker-structured product graphs, with modifications for strong product graphs. Theoretical convergence guarantees are provided.", "result": "Experiments on synthetic and real-world graphs show the proposed method's efficacy and outperformance of existing techniques.", "conclusion": "The approach successfully addresses the challenge of learning intricate dependency structures in product graphs, offering a scalable and effective solution."}}
{"id": "2505.10309", "pdf": "https://arxiv.org/pdf/2505.10309", "abs": "https://arxiv.org/abs/2505.10309", "authors": ["Tuan Dung Nguyen", "Duncan J. Watts", "Mark E. Whiting"], "title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments", "categories": ["cs.AI", "cs.HC", "cs.SI"], "comment": null, "summary": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge.", "AI": {"tldr": "The paper critiques static benchmarks for assessing commonsense intelligence in AI, highlighting human variability in commonsense judgments. It proposes a method to evaluate AI models by comparing their outputs to human population judgments, finding LLMs often fall below human median competence and correlate modestly with human agreement. Smaller models outperform larger ones.", "motivation": "Current benchmarks assume homogeneous human commonsense, ignoring empirical evidence of human variability. The study aims to address this gap by evaluating AI models against diverse human judgments.", "method": "The study evaluates LLMs by treating them as independent survey respondents and simulators of human populations, measuring their commonsense competence and agreement with real humans.", "result": "Most LLMs score below the human median in individual competence and show modest correlation with human agreement. Smaller models perform better than larger proprietary ones.", "conclusion": "The framework emphasizes adapting AI to diverse human collectivities, aligning with calls for culturally aware AI models."}}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated.", "AI": {"tldr": "LLMs are vulnerable to jailbreaking due to unfiltered training data, and a universal attack method was found to compromise multiple models, revealing gaps in AI safety practices.", "motivation": "The study aims to highlight the risks of LLMs being exploited through jailbreak attacks, emphasizing the need for better safety measures.", "method": "The research identified a universal jailbreak attack that bypasses safety controls in multiple state-of-the-art LLMs.", "result": "Many tested LLMs remained vulnerable to the attack, and industry responses to disclosures were inadequate.", "conclusion": "Without intervention, LLMs could democratize access to harmful knowledge, posing significant risks."}}
{"id": "2501.01482", "pdf": "https://arxiv.org/pdf/2501.01482", "abs": "https://arxiv.org/abs/2501.01482", "authors": ["Muhammad Ahmad Sultan", "Chong Chen", "Yingmin Liu", "Katarzyna Gil", "Karolina Zareba", "Rizwan Ahmad"], "title": "An unsupervised method for MRI recovery: Deep image prior with structured sparsity", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "comment": "Magn Reson Mater Phy (2025)", "summary": "Objective: To propose and validate an unsupervised MRI reconstruction method\nthat does not require fully sampled k-space data. Materials and Methods: The\nproposed method, deep image prior with structured sparsity (DISCUS), extends\nthe deep image prior (DIP) by introducing group sparsity to frame-specific code\nvectors, enabling the discovery of a low-dimensional manifold for capturing\ntemporal variations. \\discus was validated using four studies: (I) simulation\nof a dynamic Shepp-Logan phantom to demonstrate its manifold discovery\ncapabilities, (II) comparison with compressed sensing and DIP-based methods\nusing simulated single-shot late gadolinium enhancement (LGE) image series from\nsix distinct digital cardiac phantoms in terms of normalized mean square error\n(NMSE) and structural similarity index measure (SSIM), (III) evaluation on\nretrospectively undersampled single-shot LGE data from eight patients, and (IV)\nevaluation on prospectively undersampled single-shot LGE data from eight\npatients, assessed via blind scoring from two expert readers. Results: DISCUS\noutperformed competing methods, demonstrating superior reconstruction quality\nin terms of NMSE and SSIM (Studies I--III) and expert reader scoring (Study\nIV). Discussion: An unsupervised image reconstruction method is presented and\nvalidated on simulated and measured data. These developments can benefit\napplications where acquiring fully sampled data is challenging.", "AI": {"tldr": "DISCUS, an unsupervised MRI reconstruction method, outperforms existing techniques without needing fully sampled k-space data.", "motivation": "To address challenges in acquiring fully sampled k-space data by proposing an unsupervised reconstruction method.", "method": "Extends deep image prior (DIP) with group sparsity for low-dimensional manifold discovery, validated via simulations and patient studies.", "result": "DISCUS shows superior reconstruction quality in NMSE, SSIM, and expert scoring compared to compressed sensing and DIP-based methods.", "conclusion": "DISCUS is a promising unsupervised method for MRI reconstruction, especially where fully sampled data is hard to obtain."}}
{"id": "2505.09997", "pdf": "https://arxiv.org/pdf/2505.09997", "abs": "https://arxiv.org/abs/2505.09997", "authors": ["Jinhyun Jang", "Jiyeong Lee", "Kwanghoon Sohn"], "title": "Descriptive Image-Text Matching with Graded Contextual Similarity", "categories": ["cs.CV"], "comment": null, "summary": "Image-text matching aims to build correspondences between visual and textual\ndata by learning their pairwise similarities. Most existing approaches have\nadopted sparse binary supervision, indicating whether a pair of images and\nsentences matches or not. However, such sparse supervision covers a limited\nsubset of image-text relationships, neglecting their inherent many-to-many\ncorrespondences; an image can be described in numerous texts at different\ndescriptive levels. Moreover, existing approaches overlook the implicit\nconnections from general to specific descriptions, which form the underlying\nrationale for the many-to-many relationships between vision and language. In\nthis work, we propose descriptive image-text matching, called DITM, to learn\nthe graded contextual similarity between image and text by exploring the\ndescriptive flexibility of language. We formulate the descriptiveness score of\neach sentence with cumulative term frequency-inverse document frequency\n(TF-IDF) to balance the pairwise similarity according to the keywords in the\nsentence. Our method leverages sentence descriptiveness to learn robust\nimage-text matching in two key ways: (1) to refine the false negative labeling,\ndynamically relaxing the connectivity between positive and negative pairs, and\n(2) to build more precise matching, aligning a set of relevant sentences in a\ngeneric-to-specific order. By moving beyond rigid binary supervision, DITM\nenhances the discovery of both optimal matches and potential positive pairs.\nExtensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the\neffectiveness of our method in representing complex image-text relationships\ncompared to state-of-the-art approaches. In addition, DITM enhances the\nhierarchical reasoning ability of the model, supported by the extensive\nanalysis on HierarCaps benchmark.", "AI": {"tldr": "The paper proposes DITM, a method for descriptive image-text matching that learns graded contextual similarity by leveraging language descriptiveness, improving upon sparse binary supervision.", "motivation": "Existing methods use sparse binary supervision, missing many-to-many image-text relationships and hierarchical connections. DITM addresses this by exploring descriptive flexibility.", "method": "DITM uses TF-IDF to score sentence descriptiveness, refining false negatives and aligning sentences from generic to specific.", "result": "Experiments on MS-COCO, Flickr30K, and CxC show DITM outperforms state-of-the-art methods in capturing complex relationships and hierarchical reasoning.", "conclusion": "DITM advances image-text matching by moving beyond binary supervision, improving both matching accuracy and hierarchical understanding."}}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field.", "AI": {"tldr": "A three-layered AI-driven sales optimization framework (Causal Predictive Optimization and Generation) improves LinkedIn's sales process, outperforming legacy systems.", "motivation": "Optimizing the sales process is crucial for B2B success, requiring a structured AI approach to enhance lead conversion and customer engagement.", "method": "The framework combines causal ML for prediction, constraint optimization and contextual bandit for optimization, and Generative AI with feedback for system enhancement.", "result": "Significant improvements over legacy systems were achieved, with insights broadly applicable to sales optimization.", "conclusion": "The proposed framework effectively optimizes sales processes, demonstrating practical success and scalability in a real-world setting like LinkedIn."}}
{"id": "2505.10328", "pdf": "https://arxiv.org/pdf/2505.10328", "abs": "https://arxiv.org/abs/2505.10328", "authors": ["Alvin Combrink", "Stephie Do", "Kristofer Bengtsson", "Sabino Francesco Roselli", "Martin Fabian"], "title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures", "summary": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling.", "AI": {"tldr": "The paper compares SMT and MILP solvers for healthcare personnel scheduling, finding SMT excels in varied real-world problems while MILP performs better in highly constrained cases.", "motivation": "Healthcare scheduling is complex due to high demand and constraints, with limited research on SMT applications.", "method": "Proposes generic constraint formulations for scheduling, comparing SMT (Z3) and MILP (Gurobi) solvers on academic and real-world problems.", "result": "SMT excels in varied real-world problems, while MILP performs better in highly constrained or infeasible cases. SMT is sensitive to constraint formulation.", "conclusion": "SMT-based methods are promising for future personnel scheduling research."}}
{"id": "2505.10081", "pdf": "https://arxiv.org/pdf/2505.10081", "abs": "https://arxiv.org/abs/2505.10081", "authors": ["Wisdom Aduah", "Francois Meyer"], "title": "Designing and Contextualising Probes for African Languages", "categories": ["cs.CL"], "comment": null, "summary": "Pretrained language models (PLMs) for African languages are continually\nimproving, but the reasons behind these advances remain unclear. This paper\npresents the first systematic investigation into probing PLMs for linguistic\nknowledge about African languages. We train layer-wise probes for six\ntypologically diverse African languages to analyse how linguistic features are\ndistributed. We also design control tasks, a way to interpret probe\nperformance, for the MasakhaPOS dataset. We find PLMs adapted for African\nlanguages to encode more linguistic information about target languages than\nmassively multilingual PLMs. Our results reaffirm previous findings that\ntoken-level syntactic information concentrates in middle-to-last layers, while\nsentence-level semantic information is distributed across all layers. Through\ncontrol tasks and probing baselines, we confirm that performance reflects the\ninternal knowledge of PLMs rather than probe memorisation. Our study applies\nestablished interpretability techniques to African-language PLMs. In doing so,\nwe highlight the internal mechanisms underlying the success of strategies like\nactive learning and multilingual adaptation.", "AI": {"tldr": "The paper investigates how linguistic knowledge is encoded in pretrained language models (PLMs) for African languages, finding that adapted PLMs outperform multilingual ones and that syntactic and semantic information are distributed differently across layers.", "motivation": "To systematically study how linguistic features are encoded in PLMs for African languages, which is unclear despite their improving performance.", "method": "Layer-wise probes for six African languages and control tasks for the MasakhaPOS dataset to analyze feature distribution and interpret probe performance.", "result": "Adapted PLMs encode more linguistic knowledge than multilingual PLMs; syntactic info concentrates in middle-to-last layers, while semantic info is distributed across all layers.", "conclusion": "The study clarifies the success of strategies like active learning and multilingual adaptation by applying interpretability techniques to African-language PLMs."}}
{"id": "2501.03021", "pdf": "https://arxiv.org/pdf/2501.03021", "abs": "https://arxiv.org/abs/2501.03021", "authors": ["Arda Atal\u0131k", "Sumit Chopra", "Daniel K. Sodickson"], "title": "A Trust-Guided Approach to MR Image Reconstruction with Side Information", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "27 pages, 9 figures", "summary": "Reducing MRI scan times can improve patient care and lower healthcare costs.\nMany acceleration methods are designed to reconstruct diagnostic-quality images\nfrom sparse k-space data, via an ill-posed or ill-conditioned linear inverse\nproblem (LIP). To address the resulting ambiguities, it is crucial to\nincorporate prior knowledge into the optimization problem, e.g., in the form of\nregularization. Another form of prior knowledge less commonly used in medical\nimaging is the readily available auxiliary data (a.k.a. side information)\nobtained from sources other than the current acquisition. In this paper, we\npresent the Trust- Guided Variational Network (TGVN), an end-to-end deep\nlearning framework that effectively and reliably integrates side information\ninto LIPs. We demonstrate its effectiveness in multi-coil, multi-contrast MRI\nreconstruction, where incomplete or low-SNR measurements from one contrast are\nused as side information to reconstruct high-quality images of another contrast\nfrom heavily under-sampled data. TGVN is robust across different contrasts,\nanatomies, and field strengths. Compared to baselines utilizing side\ninformation, TGVN achieves superior image quality while preserving subtle\npathological features even at challenging acceleration levels, drastically\nspeeding up acquisition while minimizing hallucinations. Source code and\ndataset splits are available on github.com/sodicksonlab/TGVN.", "AI": {"tldr": "TGVN is a deep learning framework for MRI reconstruction that integrates side information to improve image quality and speed up scans.", "motivation": "Reducing MRI scan times benefits patient care and lowers costs, but sparse k-space data reconstruction is challenging. Incorporating prior knowledge, like side information, can address ambiguities.", "method": "TGVN is an end-to-end deep learning framework that integrates auxiliary data (side information) into linear inverse problems for MRI reconstruction.", "result": "TGVN outperforms baselines in image quality, preserves pathological features, and works robustly across contrasts, anatomies, and field strengths.", "conclusion": "TGVN effectively speeds up MRI acquisition while minimizing artifacts, making it a reliable tool for diagnostic-quality image reconstruction."}}
{"id": "2505.09998", "pdf": "https://arxiv.org/pdf/2505.09998", "abs": "https://arxiv.org/abs/2505.09998", "authors": ["Ying Zang", "Yuanqi Hu", "Xinyu Chen", "Yuxia Xu", "Suhui Wang", "Chunan Yu", "Lanyun Zhu", "Deyi Ji", "Xin Xu", "Tianrun Chen"], "title": "From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "In the era of immersive consumer electronics, such as AR/VR headsets and\nsmart devices, people increasingly seek ways to express their identity through\nvirtual fashion. However, existing 3D garment design tools remain inaccessible\nto everyday users due to steep technical barriers and limited data. In this\nwork, we introduce a 3D sketch-driven 3D garment generation framework that\nempowers ordinary users - even those without design experience - to create\nhigh-quality digital clothing through simple 3D sketches in AR/VR environments.\nBy combining a conditional diffusion model, a sketch encoder trained in a\nshared latent space, and an adaptive curriculum learning strategy, our system\ninterprets imprecise, free-hand input and produces realistic, personalized\ngarments. To address the scarcity of training data, we also introduce\nKO3DClothes, a new dataset of paired 3D garments and user-created sketches.\nExtensive experiments and user studies confirm that our method significantly\noutperforms existing baselines in both fidelity and usability, demonstrating\nits promise for democratized fashion design on next-generation consumer\nplatforms.", "AI": {"tldr": "A 3D sketch-driven framework enables everyday users to create digital clothing in AR/VR, overcoming technical barriers with a diffusion model and new dataset.", "motivation": "Existing 3D garment design tools are inaccessible to non-experts due to technical complexity and lack of data.", "method": "Combines a conditional diffusion model, sketch encoder, and adaptive curriculum learning to interpret free-hand sketches into realistic garments. Introduces KO3DClothes dataset.", "result": "Outperforms baselines in fidelity and usability, validated by experiments and user studies.", "conclusion": "Promising for democratizing fashion design in AR/VR platforms."}}
{"id": "2505.09851", "pdf": "https://arxiv.org/pdf/2505.09851", "abs": "https://arxiv.org/abs/2505.09851", "authors": ["Shun Wang", "Shun-Li Shang", "Zi-Kui Liu", "Wenrui Hao"], "title": "ZENN: A Thermodynamics-Inspired Computational Framework for Heterogeneous Data-Driven Modeling", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "9 pages, 4 figures", "summary": "Traditional entropy-based methods - such as cross-entropy loss in\nclassification problems - have long been essential tools for quantifying\nuncertainty and disorder in data and developing artificial intelligence\nalgorithms. However, the rapid growth of data across various domains has\nintroduced new challenges, particularly the integration of heterogeneous\ndatasets with intrinsic disparities. In this paper, we extend zentropy theory\ninto the data science domain by introducing intrinsic entropy, enabling more\neffective learning from heterogeneous data sources. We propose a\nzentropy-enhanced neural network (ZENN) that simultaneously learns both energy\nand intrinsic entropy components, capturing the underlying structure of\nmulti-source data. To support this, we redesign the neural network architecture\nto better reflect the intrinsic properties and variability inherent in diverse\ndatasets. We demonstrate the effectiveness of ZENN on classification tasks and\nenergy landscape reconstructions, showing its superior generalization\ncapabilities and robustness-particularly in predicting high-order derivatives.\nAs a practical application, we employ ZENN to reconstruct the Helmholtz energy\nlandscape of Fe3Pt using data generated from DFT and capture key material\nbehaviors, including negative thermal expansion and the critical point in the\ntemperature-pressure space. Overall, our study introduces a novel approach for\ndata-driven machine learning grounded in zentropy theory, highlighting ZENN as\na versatile and robust deep learning framework for scientific problems\ninvolving complex, heterogeneous datasets.", "AI": {"tldr": "The paper introduces ZENN, a zentropy-enhanced neural network, to improve learning from heterogeneous data by integrating intrinsic entropy and energy components.", "motivation": "Addressing challenges in integrating heterogeneous datasets with intrinsic disparities, the paper extends zentropy theory into data science.", "method": "Proposes ZENN, a redesigned neural network architecture that learns energy and intrinsic entropy components for multi-source data.", "result": "ZENN shows superior generalization and robustness, demonstrated in classification tasks and energy landscape reconstructions.", "conclusion": "ZENN is a versatile framework for complex, heterogeneous datasets, validated by practical applications like material behavior prediction."}}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "Andr\u00e9 Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency.", "AI": {"tldr": "The paper introduces 'plasticity' as a measure of how an agent is influenced by observations, mirroring 'empowerment', and explores their interplay.", "motivation": "To understand the foundational influence of observations on agents, complementing the concept of empowerment.", "method": "Defines plasticity using a new information-theoretic quantity, generalized directed information, and analyzes its connection to empowerment.", "result": "Plasticity mirrors empowerment (agent's plasticity equals environment's empowerment), and a tension exists between the two.", "conclusion": "Plasticity and empowerment are essential for understanding agency, requiring balanced consideration in agent design."}}
{"id": "2505.10089", "pdf": "https://arxiv.org/pdf/2505.10089", "abs": "https://arxiv.org/abs/2505.10089", "authors": ["Wei Liu", "Sony Trenous", "Leonardo F. R. Ribeiro", "Bill Byrne", "Felix Hieber"], "title": "XRAG: Cross-lingual Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "We propose XRAG, a novel benchmark designed to evaluate the generation\nabilities of LLMs in cross-lingual Retrieval-Augmented Generation (RAG)\nsettings where the user language does not match the retrieval results. XRAG is\nconstructed from recent news articles to ensure that its questions require\nexternal knowledge to be answered. It covers the real-world scenarios of\nmonolingual and multilingual retrieval, and provides relevancy annotations for\neach retrieved document. Our novel dataset construction pipeline results in\nquestions that require complex reasoning, as evidenced by the significant gap\nbetween human and LLM performance. Consequently, XRAG serves as a valuable\nbenchmark for studying LLM reasoning abilities, even before considering the\nadditional cross-lingual complexity. Experimental results on five LLMs uncover\ntwo previously unreported challenges in cross-lingual RAG: 1) in the\nmonolingual retrieval setting, all evaluated models struggle with response\nlanguage correctness; 2) in the multilingual retrieval setting, the main\nchallenge lies in reasoning over retrieved information across languages rather\nthan generation of non-English text.", "AI": {"tldr": "XRAG is a new benchmark for evaluating LLMs in cross-lingual RAG settings, highlighting challenges in response language correctness and multilingual reasoning.", "motivation": "To address the gap in evaluating LLMs' generation abilities in cross-lingual RAG scenarios where user language and retrieval results differ.", "method": "Constructed from recent news articles, XRAG includes monolingual and multilingual retrieval scenarios with relevancy annotations.", "result": "Five LLMs tested revealed challenges in response language correctness (monolingual) and cross-lingual reasoning (multilingual).", "conclusion": "XRAG is a valuable benchmark for studying LLM reasoning, especially in cross-lingual contexts."}}
{"id": "2502.14009", "pdf": "https://arxiv.org/pdf/2502.14009", "abs": "https://arxiv.org/abs/2502.14009", "authors": ["Andrew Wang", "Steven McDonagh", "Mike Davies"], "title": "Benchmarking Self-Supervised Learning Methods for Accelerated MRI Reconstruction", "categories": ["eess.IV", "cs.LG"], "comment": "Preprint. Live benchmark site available at\n  https://andrewwango.github.io/ssibench", "summary": "Reconstructing MRI from highly undersampled measurements is crucial for\naccelerating medical imaging, but is challenging due to the ill-posedness of\nthe inverse problem. While supervised deep learning (DL) approaches have shown\nremarkable success, they traditionally rely on fully-sampled ground truth (GT)\nimages, which are expensive or impossible to obtain in real scenarios. This\nproblem has created a recent surge in interest in self-supervised learning\nmethods that do not require GT. Although recent methods are now fast\napproaching \"oracle\" supervised performance, the lack of systematic comparison\nand standard experimental setups are hindering targeted methodological research\nand precluding widespread trustworthy industry adoption. We present SSIBench, a\nmodular and flexible comparison framework to unify and thoroughly benchmark\nSelf-Supervised Imaging methods (SSI) without GT. We evaluate 18 methods across\n4 realistic MRI scenarios on real data, showing a wide performance landscape\nwhose method ranking differs across scenarios and metrics, exposing the need\nfor further SSI research. Our insights also show how complementary methods\ncould be compounded for future improvements, exemplified by a novel loss we\npropose, Multi-Operator Equivariant Imaging. To accelerate reproducible\nresearch and lower the barrier to entry, we provide the extensible benchmark\nand open-source reimplementations of all methods at\nhttps://andrewwango.github.io/ssibench, allowing researchers to rapidly and\nfairly contribute and evaluate new methods on the standardised setup for\npotential leaderboard ranking, or benchmark existing methods on custom\ndatasets, forward operators, or models, unlocking the application of SSI to\nother valuable GT free domains such as 4D MRI and other nascent scientific\nimaging modalities.", "AI": {"tldr": "SSIBench is a framework for benchmarking self-supervised MRI reconstruction methods without ground truth, evaluating 18 methods across 4 scenarios and proposing a novel loss for future improvements.", "motivation": "The need for self-supervised MRI reconstruction methods due to the impracticality of obtaining fully-sampled ground truth images, and the lack of standardized comparisons hindering research and adoption.", "method": "SSIBench, a modular framework, evaluates 18 self-supervised methods on real MRI data across 4 scenarios, introducing a novel loss called Multi-Operator Equivariant Imaging.", "result": "Performance varies widely across methods, scenarios, and metrics, highlighting the need for further research and the potential for combining complementary methods.", "conclusion": "SSIBench provides a standardized, open-source platform to accelerate reproducible research and adoption of self-supervised MRI reconstruction methods."}}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection.", "AI": {"tldr": "An improved YOLOv8-based object detection network for autonomous driving, addressing challenges like cost and weather vulnerability, achieves 65% accuracy in detecting multi-scale and small objects.", "motivation": "Current autonomous driving object detection technologies face issues like high costs, weather sensitivity, and limited resolution, necessitating a more efficient solution.", "method": "Enhanced YOLOv8 with structural reparameterization, a bidirectional pyramid structure, and a novel detection pipeline for better multi-scale and small-object detection.", "result": "Achieves 65% detection accuracy, outperforming traditional methods, especially in single-target and small-object scenarios.", "conclusion": "The improved model is promising for real-world autonomous driving applications and competitions like FSAC."}}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies.", "AI": {"tldr": "Transformers balance in-weights learning (IWL) and in-context learning (ICL) based on environmental predictability, inspired by evolutionary biology's genetic encoding and phenotypic plasticity. Experiments show stability favors IWL, while reliable cues enhance ICL, with learning dynamics varying by task.", "motivation": "To understand how environmental predictability influences the balance between IWL and ICL in Transformers, drawing parallels from evolutionary biology.", "method": "Experimental operationalization of predictability dimensions (stability and cue reliability) using regression and classification tasks to study ICL/IWL balance.", "result": "High stability favors IWL, while high cue reliability enhances ICL. Learning dynamics vary: some tasks show ICL-to-IWL shifts, others exhibit initial IWL followed by ICL dominance.", "conclusion": "Predictability governs Transformer learning modes, supporting a relative-cost hypothesis for transitions, with implications for understanding ICL and improving training methods."}}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth.", "AI": {"tldr": "Proposes AXE, a ground-truth agnostic framework for evaluating model explanations, addressing limitations of current methods.", "motivation": "Current explanation evaluation relies on ground-truth or model sensitivity, which are limiting or unreliable.", "method": "Introduces AXE, a framework evaluating explanations without ground-truth or sensitivity reliance.", "result": "AXE outperforms baselines and detects explanation fairwashing.", "conclusion": "AXE provides a robust, independent measure for explanation quality, advancing evaluation strategies."}}
{"id": "2505.10113", "pdf": "https://arxiv.org/pdf/2505.10113", "abs": "https://arxiv.org/abs/2505.10113", "authors": ["Xinlan Yan", "Di Wu", "Yibin Lei", "Christof Monz", "Iacer Calixto"], "title": "What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we introduce S-MedQA, an English medical question-answering\n(QA) dataset for benchmarking large language models in fine-grained clinical\nspecialties. We use S-MedQA to check the applicability of a popular hypothesis\nrelated to knowledge injection in the knowledge-intense scenario of medical QA,\nand show that: 1) training on data from a speciality does not necessarily lead\nto best performance on that specialty and 2) regardless of the specialty\nfine-tuned on, token probabilities of clinically relevant terms for all\nspecialties increase consistently. Thus, we believe improvement gains come\nmostly from domain shifting (e.g., general to medical) rather than knowledge\ninjection and suggest rethinking the role of fine-tuning data in the medical\ndomain. We release S-MedQA and all code needed to reproduce all our experiments\nto the research community.", "AI": {"tldr": "S-MedQA is an English medical QA dataset for benchmarking LLMs in clinical specialties. Findings show specialty training doesn't guarantee best performance, and gains come from domain shifting, not knowledge injection.", "motivation": "To benchmark LLMs in medical QA and test the hypothesis about knowledge injection in specialized clinical scenarios.", "method": "Created S-MedQA dataset, fine-tuned models on specialty data, and analyzed token probabilities of clinically relevant terms.", "result": "Specialty training doesn't ensure best performance; gains are from domain shifting, not knowledge injection.", "conclusion": "Rethink the role of fine-tuning data in medical QA, emphasizing domain shifting over knowledge injection."}}
{"id": "2505.08616", "pdf": "https://arxiv.org/pdf/2505.08616", "abs": "https://arxiv.org/abs/2505.08616", "authors": ["Yifan Li", "Peter Ho", "Jo Woon Chong"], "title": "A portable diagnosis model for Keratoconus using a smartphone", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Keratoconus (KC) is a corneal disorder that results in blurry and distorted\nvision. Traditional diagnostic tools, while effective, are often bulky, costly,\nand require professional operation. In this paper, we present a portable and\ninnovative methodology for diagnosing. Our proposed approach first captures the\nimage reflected on the eye's cornea when a smartphone screen-generated Placido\ndisc sheds its light on an eye, then utilizes a two-stage diagnosis for\nidentifying the KC cornea and pinpointing the location of the KC on the cornea.\nThe first stage estimates the height and width of the Placido disc extracted\nfrom the captured image to identify whether it has KC. In this KC\nidentification, k-means clustering is implemented to discern statistical\ncharacteristics, such as height and width values of extracted Placido discs,\nfrom non-KC (control) and KC-affected groups. The second stage involves the\ncreation of a distance matrix, providing a precise localization of KC on the\ncornea, which is critical for efficient treatment planning. The analysis of\nthese distance matrices, paired with a logistic regression model and robust\nstatistical analysis, reveals a clear distinction between control and KC\ngroups. The logistic regression model, which classifies small areas on the\ncornea as either control or KC-affected based on the corresponding inter-disc\ndistances in the distance matrix, reported a classification accuracy of 96.94%,\nwhich indicates that we can effectively pinpoint the protrusion caused by KC.\nThis comprehensive, smartphone-based method is expected to detect KC and\nstreamline timely treatment.", "AI": {"tldr": "A smartphone-based method for diagnosing keratoconus (KC) using Placido disc images and a two-stage diagnostic approach achieves high accuracy in identifying and localizing KC.", "motivation": "Traditional KC diagnostic tools are bulky, costly, and require professional operation, necessitating a portable and accessible alternative.", "method": "The method involves capturing corneal reflections of a smartphone-generated Placido disc, followed by a two-stage diagnosis: k-means clustering for KC identification and distance matrix analysis for localization.", "result": "The logistic regression model achieved 96.94% accuracy in classifying KC-affected areas, enabling precise localization of corneal protrusions.", "conclusion": "The smartphone-based approach offers an effective, portable solution for KC diagnosis and treatment planning."}}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes.", "AI": {"tldr": "A reinforcement learning-based latent diffusion model (LDM) fine-tuning method is proposed for remote sensing image super-resolution, showing significant improvements in PSNR, SSIM, and LPIPS metrics.", "motivation": "Existing deep learning methods for super-resolution struggle with complex scenes and detail preservation, prompting the need for a more effective approach.", "method": "The method uses reinforcement learning (PPO) to fine-tune an LDM during its reverse denoising process, optimizing states, actions, and rewards.", "result": "Experiments on RESISC45 show PSNR gains of 3-4dB, SSIM improvements of 0.08-0.11, and LPIPS reductions of 0.06-0.10, especially in complex scenes.", "conclusion": "The proposed method effectively enhances super-resolution quality and adaptability across diverse scenes."}}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields.", "AI": {"tldr": "A unified transformer-based approach for data-driven attribution in marketing, handling member-level and aggregate-level data, plus external macro factors, with successful large-scale implementation at LinkedIn.", "motivation": "To improve marketing intelligence by accurately attributing conversions to interactions using causal patterns from data.", "method": "Transformer-based attribution model integrating member-level, aggregate-level data, and external macro factors.", "result": "Successful large-scale implementation at LinkedIn with significant impact.", "conclusion": "The approach is broadly applicable to marketing and ad tech, offering valuable insights."}}
{"id": "2505.10468", "pdf": "https://arxiv.org/pdf/2505.10468", "abs": "https://arxiv.org/abs/2505.10468", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge", "categories": ["cs.AI"], "comment": "32 pages, 14 figures, 11 tables", "summary": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications", "AI": {"tldr": "The paper distinguishes AI Agents from Agentic AI, providing a taxonomy and analysis of their design philosophies, capabilities, and applications, while addressing challenges and proposing solutions.", "motivation": "To clarify the differences between AI Agents and Agentic AI, highlighting their unique features, applications, and challenges to guide future development.", "method": "The study outlines search strategies, foundational definitions, and evaluates architectural evolution, operational mechanisms, interaction styles, and autonomy levels for both paradigms.", "result": "A comparative analysis reveals distinct applications (e.g., task-specific automation vs. multi-agent collaboration) and challenges (e.g., hallucination, coordination failure), with proposed solutions like ReAct loops and RAG.", "conclusion": "The paper provides a roadmap for developing robust, scalable, and explainable AI systems, emphasizing the need for targeted solutions to paradigm-specific challenges."}}
{"id": "2505.10143", "pdf": "https://arxiv.org/pdf/2505.10143", "abs": "https://arxiv.org/abs/2505.10143", "authors": ["Longchao Da", "Parth Mitesh Shah", "Kuan-Ru Liou", "Jiaxing Zhang", "Hua Wei"], "title": "GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs", "categories": ["cs.CL", "68T50, 68T30", "I.2.7; I.2.4; H.3.3"], "comment": "5 pages, 4 figures, accepted to IJCAI2025 demo track", "summary": "Large Language Models are now key assistants in human decision-making\nprocesses. However, a common note always seems to follow: \"LLMs can make\nmistakes. Be careful with important info.\" This points to the reality that not\nall outputs from LLMs are dependable, and users must evaluate them manually.\nThe challenge deepens as hallucinated responses, often presented with seemingly\nplausible explanations, create complications and raise trust issues among\nusers. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph\nenhanced retrieval-augmented generation framework to provide Evidence-based\nresponse generation. Specifically, when the user uploads a material document, a\nknowledge graph will be created, which helps construct a retrieval-augmented\nagent, enhancing the agent's responses with additional knowledge beyond its\ntraining corpus. Then we leverage Chain-of-Thought (CoT) logic generation,\nn-hop sub-graph searching, and entailment-based sentence generation to realize\naccurate evidence retrieval. We demonstrate that our method improves the\nexisting models' performance in terms of identifying the exact evidence in a\nfree-form context, providing a reliable way to examine the resources of LLM's\nconclusion and help with the judgment of the trustworthiness.", "AI": {"tldr": "GE-Chat enhances LLM responses by integrating a knowledge graph and retrieval-augmented generation, improving evidence-based accuracy and trustworthiness.", "motivation": "Address LLM unreliability and hallucinations by providing evidence-backed responses.", "method": "Uses knowledge graphs, retrieval-augmented generation, CoT logic, n-hop sub-graph searching, and entailment-based sentence generation.", "result": "Improves evidence retrieval and response reliability in free-form contexts.", "conclusion": "GE-Chat offers a trustworthy framework for LLM-assisted decision-making."}}
{"id": "2505.09193", "pdf": "https://arxiv.org/pdf/2505.09193", "abs": "https://arxiv.org/abs/2505.09193", "authors": ["Wei Jiang", "Junru Li", "Kai Zhang", "Li Zhang"], "title": "BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression", "categories": ["eess.IV", "cs.CV"], "comment": "The first learned video codec that surpasses VTM 13.2 RA across all\n  standard test datasets. Code will be available at\n  https://github.com/JiangWeibeta/ECVC", "summary": "Recent forward prediction-based learned video compression (LVC) methods have\nachieved impressive results, even surpassing VVC reference software VTM under\nthe Low Delay B (LDB) configuration. In contrast, learned bidirectional video\ncompression (BVC) remains underexplored and still lags behind its forward-only\ncounterparts. This performance gap is mainly due to the limited ability to\nextract diverse and accurate contexts: most existing BVCs primarily exploit\ntemporal motion while neglecting non-local correlations across frames.\nMoreover, they lack the adaptability to dynamically suppress harmful contexts\narising from fast motion or occlusion. To tackle these challenges, we propose\nBiECVC, a BVC framework that incorporates diversified local and non-local\ncontext modeling along with adaptive context gating. For local context\nenhancement, BiECVC reuses high-quality features from lower layers and aligns\nthem using decoded motion vectors without introducing extra motion overhead. To\nmodel non-local dependencies efficiently, we adopt a linear attention mechanism\nthat balances performance and complexity. To further mitigate the impact of\ninaccurate context prediction, we introduce Bidirectional Context Gating,\ninspired by data-dependent decay in recent autoregressive language models, to\ndynamically filter contextual information based on conditional coding results.\nExtensive experiments demonstrate that BiECVC achieves state-of-the-art\nperformance, reducing the bit-rate by 13.4% and 15.7% compared to VTM 13.2\nunder the Random Access (RA) configuration with intra periods of 32 and 64,\nrespectively. To our knowledge, BiECVC is the first learned video codec to\nsurpass VTM 13.2 RA across all standard test datasets. Code will be available\nat https://github.com/JiangWeibeta/ECVC.", "AI": {"tldr": "BiECVC, a learned bidirectional video compression framework, outperforms VTM 13.2 by enhancing local and non-local context modeling and introducing adaptive context gating.", "motivation": "Existing bidirectional video compression (BVC) methods lag behind forward-only ones due to limited context extraction and adaptability issues.", "method": "BiECVC improves local context by reusing high-quality features and aligning them with decoded motion vectors. It uses linear attention for non-local dependencies and introduces Bidirectional Context Gating to dynamically filter harmful contexts.", "result": "BiECVC reduces bit-rate by 13.4% and 15.7% compared to VTM 13.2 under RA configuration, achieving state-of-the-art performance.", "conclusion": "BiECVC is the first learned video codec to surpass VTM 13.2 RA across all test datasets, demonstrating the effectiveness of diversified context modeling and adaptive gating."}}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system.", "AI": {"tldr": "DeepSeqCoco is a deep learning model for automated coconut tree disease identification, achieving 99.5% accuracy and faster processing than existing methods.", "motivation": "Manual disease identification in coconut trees is labor-intensive and non-scalable, especially in developing countries.", "method": "DeepSeqCoco uses deep learning with optimizers like SGD, Adam, and hybrid configurations for optimal performance.", "result": "The model achieves 99.5% accuracy, 5% higher than existing models, with reduced training (18%) and prediction (85%) times.", "conclusion": "DeepSeqCoco offers a scalable, efficient AI solution for precision agriculture in disease monitoring."}}
{"id": "2505.09864", "pdf": "https://arxiv.org/pdf/2505.09864", "abs": "https://arxiv.org/abs/2505.09864", "authors": ["Aditya Panangat"], "title": "BINGO: A Novel Pruning Mechanism to Reduce the Size of Neural Networks", "categories": ["cs.LG"], "comment": "6 pages, 0 figures, 2 tables", "summary": "Over the past decade, the use of machine learning has increased\nexponentially. Models are far more complex than ever before, growing to\ngargantuan sizes and housing millions of weights. Unfortunately, the fact that\nlarge models have become the state of the art means that it often costs\nmillions of dollars to train and operate them. These expenses not only hurt\ncompanies but also bar non-wealthy individuals from contributing to new\ndevelopments and force consumers to pay greater prices for AI. Current methods\nused to prune models, such as iterative magnitude pruning, have shown great\naccuracy but require an iterative training sequence that is incredibly\ncomputationally and environmentally taxing. To solve this problem, BINGO is\nintroduced. BINGO, during the training pass, studies specific subsets of a\nneural network one at a time to gauge how significant of a role each weight\nplays in contributing to a network's accuracy. By the time training is done,\nBINGO generates a significance score for each weight, allowing for\ninsignificant weights to be pruned in one shot. BINGO provides an\naccuracy-preserving pruning technique that is less computationally intensive\nthan current methods, allowing for a world where AI growth does not have to\nmean model growth, as well.", "AI": {"tldr": "BINGO introduces a one-shot pruning method for neural networks, reducing computational costs while preserving accuracy, addressing the expense and environmental impact of large models.", "motivation": "The high cost and environmental impact of training large neural networks limit accessibility and innovation in AI.", "method": "BINGO evaluates weight significance during training, assigning scores to prune insignificant weights in one step.", "result": "BINGO achieves accuracy-preserving pruning with lower computational demands compared to iterative methods.", "conclusion": "BINGO enables efficient AI development without the need for excessively large models, promoting accessibility and sustainability."}}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas B\u00e4ck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning.", "AI": {"tldr": "The study evaluates self-reflection, heuristic mutation, and planning in large language models (LLMs) in dynamic environments, finding strategic prompting can narrow performance gaps between model sizes but reveals persistent reasoning limitations.", "motivation": "To assess the adaptive capabilities of LLMs in dynamic settings beyond static benchmarks, uncovering their true potential as self-learning agents.", "method": "Experiments with various open-source LLMs using self-reflection, heuristic mutation, and planning as prompting techniques in dynamic environments.", "result": "Larger models outperform smaller ones, but strategic prompting helps smaller models. Advanced techniques benefit smaller models in complex tasks but introduce instability. LLMs show persistent reasoning and planning shortcomings.", "conclusion": "Current LLMs lack true emergent reasoning and exhibit fundamental limitations in planning and reasoning, suggesting the need for benchmarks beyond static tasks."}}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty.", "AI": {"tldr": "Reasoning CPT, using synthetic data to model hidden thought processes, improves LLM performance across domains, especially on harder problems, with up to 8-point gains.", "motivation": "Current LLM training methods (supervised fine-tuning, reinforcement learning) are domain-specific, limiting scalability. Reasoning CPT avoids this by using synthetic data to generalize reasoning skills.", "method": "Applied Reasoning CPT to Gemma2-9B using synthetic data with hidden thoughts from STEM and Law corpora, compared to standard CPT on MMLU benchmark.", "result": "Reasoning CPT consistently outperforms standard CPT, with domain transferability and greater gains (up to 8 points) on harder problems. Models also adapt reasoning depth to problem difficulty.", "conclusion": "Reasoning CPT is a scalable, domain-agnostic approach that enhances LLM reasoning, with potential for broader applications."}}
{"id": "2307.09420", "pdf": "https://arxiv.org/pdf/2307.09420", "abs": "https://arxiv.org/abs/2307.09420", "authors": ["Ahmed Abdelkawy", "Aly Farag", "Islam Alkabbany", "Asem Ali", "Chris Foreman", "Thomas Tretter", "Nicholas Hindy"], "title": "Measuring Student Behavioral Engagement using Histogram of Actions", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "In this paper, we propose a novel technique for measuring behavioral\nengagement through students' actions recognition. The proposed approach\nrecognizes student actions then predicts the student behavioral engagement\nlevel. For student action recognition, we use human skeletons to model student\npostures and upper body movements. To learn the dynamics of student upper body,\na 3D-CNN model is used. The trained 3D-CNN model is used to recognize actions\nwithin every 2minute video segment then these actions are used to build a\nhistogram of actions which encodes the student actions and their frequencies.\nThis histogram is utilized as an input to SVM classifier to classify whether\nthe student is engaged or disengaged. To evaluate the proposed framework, we\nbuild a dataset consisting of 1414 2-minute video segments annotated with 13\nactions and 112 video segments annotated with two engagement levels.\nExperimental results indicate that student actions can be recognized with top 1\naccuracy 83.63% and the proposed framework can capture the average engagement\nof the class.", "AI": {"tldr": "A novel technique uses 3D-CNN and SVM to measure student engagement by recognizing actions from video segments.", "motivation": "To improve behavioral engagement measurement in educational settings by analyzing student actions.", "method": "Uses 3D-CNN for action recognition from human skeletons and SVM for engagement classification based on action histograms.", "result": "Achieves 83.63% accuracy in action recognition and captures average class engagement.", "conclusion": "The framework effectively measures engagement through action recognition and classification."}}
{"id": "2505.10046", "pdf": "https://arxiv.org/pdf/2505.10046", "abs": "https://arxiv.org/abs/2505.10046", "authors": ["Bingda Tang", "Boyang Zheng", "Xichen Pan", "Sayak Paul", "Saining Xie"], "title": "Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "This paper does not describe a new method; instead, it provides a thorough\nexploration of an important yet understudied design space related to recent\nadvances in text-to-image synthesis -- specifically, the deep fusion of large\nlanguage models (LLMs) and diffusion transformers (DiTs) for multi-modal\ngeneration. Previous studies mainly focused on overall system performance\nrather than detailed comparisons with alternative methods, and key design\ndetails and training recipes were often left undisclosed. These gaps create\nuncertainty about the real potential of this approach. To fill these gaps, we\nconduct an empirical study on text-to-image generation, performing controlled\ncomparisons with established baselines, analyzing important design choices, and\nproviding a clear, reproducible recipe for training at scale. We hope this work\noffers meaningful data points and practical guidelines for future research in\nmulti-modal generation.", "AI": {"tldr": "The paper explores the design space of combining LLMs and DiTs for multi-modal generation, providing empirical comparisons, design analysis, and reproducible training guidelines.", "motivation": "To address gaps in understanding the potential of deep fusion of LLMs and DiTs in text-to-image synthesis, as prior work lacked detailed comparisons and transparency.", "method": "Conducts an empirical study with controlled comparisons to baselines, analyzes design choices, and offers a reproducible training recipe.", "result": "Provides meaningful data and practical guidelines for future research in multi-modal generation.", "conclusion": "The study clarifies the potential of LLM-DiT fusion and supports future advancements in the field."}}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements.", "AI": {"tldr": "The paper compares decision-making behavior of LLMs, humans, and MAB algorithms in exploration-exploitation tasks, finding reasoning shifts LLMs toward human-like behavior but with limitations in complex environments.", "motivation": "To assess if LLMs mimic human decision-making, especially in exploration-exploitation tradeoffs, and evaluate their performance in dynamic tasks.", "method": "Comparative study using MAB tasks, interpretable choice models, and prompting/reasoning-enhanced LLMs to analyze E&E strategies.", "result": "Reasoning makes LLMs more human-like in simple tasks but less adaptable in complex ones, with similar regret in some cases.", "conclusion": "LLMs show promise as human behavior simulators but need improvement, especially in complex, non-stationary environments."}}
{"id": "2306.07615", "pdf": "https://arxiv.org/pdf/2306.07615", "abs": "https://arxiv.org/abs/2306.07615", "authors": ["Heqin Zhu", "Quan Quan", "Qingsong Yao", "Zaiyi Liu", "S. Kevin Zhou"], "title": "UOD: Universal One-shot Detection of Anatomical Landmarks", "categories": ["cs.CV", "cs.AI"], "comment": "Eealy accepted by MICCAI 2023. 11pages, 4 figures, 2 tables. arXiv\n  admin note: text overlap with arXiv:2203.06433", "summary": "One-shot medical landmark detection gains much attention and achieves great\nsuccess for its label-efficient training process. However, existing one-shot\nlearning methods are highly specialized in a single domain and suffer domain\npreference heavily in the situation of multi-domain unlabeled data. Moreover,\none-shot learning is not robust that it faces performance drop when annotating\na sub-optimal image. To tackle these issues, we resort to developing a\ndomain-adaptive one-shot landmark detection framework for handling multi-domain\nmedical images, named Universal One-shot Detection (UOD). UOD consists of two\nstages and two corresponding universal models which are designed as\ncombinations of domain-specific modules and domain-shared modules. In the first\nstage, a domain-adaptive convolution model is self-supervised learned to\ngenerate pseudo landmark labels. In the second stage, we design a\ndomain-adaptive transformer to eliminate domain preference and build the global\ncontext for multi-domain data. Even though only one annotated sample from each\ndomain is available for training, the domain-shared modules help UOD aggregate\nall one-shot samples to detect more robust and accurate landmarks. We\ninvestigated both qualitatively and quantitatively the proposed UOD on three\nwidely-used public X-ray datasets in different anatomical domains (i.e., head,\nhand, chest) and obtained state-of-the-art performances in each domain. The\ncode is available at\nhttps://github.com/heqin-zhu/UOD_universal_oneshot_detection.", "AI": {"tldr": "UOD is a domain-adaptive one-shot landmark detection framework for multi-domain medical images, combining domain-specific and domain-shared modules to improve robustness and accuracy.", "motivation": "Existing one-shot learning methods are domain-specific and struggle with multi-domain unlabeled data, leading to performance drops with sub-optimal annotations.", "method": "UOD uses a two-stage approach: a self-supervised domain-adaptive convolution model for pseudo labels, followed by a domain-adaptive transformer to eliminate domain bias and enhance global context.", "result": "UOD achieves state-of-the-art performance on three X-ray datasets (head, hand, chest) with only one annotated sample per domain.", "conclusion": "UOD effectively addresses domain preference and robustness issues in one-shot medical landmark detection, demonstrating superior performance across multiple domains."}}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design.", "AI": {"tldr": "The paper introduces the CoT Encyclopedia, a framework for analyzing and steering model reasoning by extracting and clustering diverse reasoning criteria from model-generated CoTs, improving interpretability and performance.", "motivation": "Limited understanding of reasoning strategies in large language models and the constraints of predefined categorization methods.", "method": "Automatically extracts reasoning criteria, embeds them into a semantic space, clusters them, and derives contrastive rubrics for interpretation.", "result": "Produces more interpretable analyses, enables performance gains by predicting and guiding model strategies, and reveals training data format's impact on reasoning.", "conclusion": "The CoT Encyclopedia offers a comprehensive and practical framework for understanding and improving model reasoning, emphasizing the importance of data format in model design."}}
{"id": "2505.10049", "pdf": "https://arxiv.org/pdf/2505.10049", "abs": "https://arxiv.org/abs/2505.10049", "authors": ["Jinlong Fan", "Xuepu Zeng", "Jing Zhang", "Mingming Gong", "Yuxiang Yang", "Dacheng Tao"], "title": "Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field", "categories": ["cs.CV"], "comment": null, "summary": "Dynamic scene representation and reconstruction have undergone transformative\nadvances in recent years, catalyzed by breakthroughs in neural radiance fields\nand 3D Gaussian splatting techniques. While initially developed for static\nenvironments, these methodologies have rapidly evolved to address the\ncomplexities inherent in 4D dynamic scenes through an expansive body of\nresearch. Coupled with innovations in differentiable volumetric rendering,\nthese approaches have significantly enhanced the quality of motion\nrepresentation and dynamic scene reconstruction, thereby garnering substantial\nattention from the computer vision and graphics communities. This survey\npresents a systematic analysis of over 200 papers focused on dynamic scene\nrepresentation using radiance field, spanning the spectrum from implicit neural\nrepresentations to explicit Gaussian primitives. We categorize and evaluate\nthese works through multiple critical lenses: motion representation paradigms,\nreconstruction techniques for varied scene dynamics, auxiliary information\nintegration strategies, and regularization approaches that ensure temporal\nconsistency and physical plausibility. We organize diverse methodological\napproaches under a unified representational framework, concluding with a\ncritical examination of persistent challenges and promising research\ndirections. By providing this comprehensive overview, we aim to establish a\ndefinitive reference for researchers entering this rapidly evolving field while\noffering experienced practitioners a systematic understanding of both\nconceptual principles and practical frontiers in dynamic scene reconstruction.", "AI": {"tldr": "A survey of 200+ papers on dynamic scene representation using radiance fields, covering implicit neural representations to explicit Gaussian primitives, with a focus on motion representation, reconstruction techniques, and future challenges.", "motivation": "To systematically analyze and categorize advances in dynamic scene representation and reconstruction, driven by neural radiance fields and 3D Gaussian splatting, and to provide a reference for researchers.", "method": "Categorizes and evaluates works through lenses like motion representation paradigms, reconstruction techniques, auxiliary information integration, and regularization approaches.", "result": "A unified representational framework for diverse methodological approaches, highlighting persistent challenges and promising directions.", "conclusion": "The survey serves as a definitive reference for newcomers and a systematic guide for practitioners, outlining conceptual principles and practical frontiers in dynamic scene reconstruction."}}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization.", "AI": {"tldr": "A hybrid deep learning model (TCN-MLP-Attention) is proposed for Hass avocado price forecasting, outperforming traditional methods with an RMSE of 1.23.", "motivation": "The complexity of price fluctuations in high-value crops like Hass avocados, influenced by seasonality, region, and weather, necessitates advanced prediction models.", "method": "The model combines Temporal Convolutional Networks (TCN), Multi-Layer Perceptrons (MLP), and an Attention mechanism, trained on a dataset of 50,000+ U.S. sales records (2015-2018).", "result": "The TCN-MLP-Attention model achieves superior performance (RMSE: 1.23, MSE: 1.51) compared to traditional methods.", "conclusion": "The research offers a scalable solution for agricultural price forecasting and insights for supply chain and pricing strategies."}}
{"id": "2410.13778", "pdf": "https://arxiv.org/pdf/2410.13778", "abs": "https://arxiv.org/abs/2410.13778", "authors": ["Michelangelo Olmo Nogara Notarianni", "Filippo Leveni", "Diego Stucchi", "Luca Frittoli", "Giacomo Boracchi"], "title": "Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)", "summary": "We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions.", "AI": {"tldr": "KQT-EWMA is a non-parametric change-detection algorithm for multivariate data streams, combining Kernel-QuantTree histograms and EWMA statistics. It offers flexibility, practicality, and controlled false alarms via ARL0.", "motivation": "To address the lack of non-parametric change-detection methods that can control false alarms (ARL0) a priori while monitoring multivariate data streams.", "method": "Combines Kernel-QuantTree (KQT) histograms with EWMA statistics for online monitoring, enabling non-parametric modeling of any stationary distribution.", "result": "KQT-EWMA effectively controls ARL0 and achieves detection delays comparable or better than state-of-the-art methods.", "conclusion": "KQT-EWMA is a practical and flexible solution for non-parametric change-detection in multivariate data streams, with controlled false alarms and competitive performance."}}
{"id": "2505.10202", "pdf": "https://arxiv.org/pdf/2505.10202", "abs": "https://arxiv.org/abs/2505.10202", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "YiMing Cheng", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success but face\nsignificant computational and memory challenges, particularly due to their\nextensive output vocabularies. The final linear projection layer, mapping\nhidden states to vocabulary-sized logits, often constitutes a substantial\nportion of the model's parameters and computational cost during inference.\nExisting methods like adaptive softmax or hierarchical softmax introduce\nstructural complexities. In this paper, we propose VQ-Logits, a novel approach\nthat leverages Vector Quantization (VQ) to drastically reduce the parameter\ncount and computational load of the LLM output layer. VQ-Logits replaces the\nlarge V * dmodel output embedding matrix with a small, shared codebook of K\nembedding vectors (K << V ). Each token in the vocabulary is mapped to one of\nthese K codebook vectors. The LLM predicts logits over this compact codebook,\nwhich are then efficiently \"scattered\" to the full vocabulary space using the\nlearned or preassigned mapping. We demonstrate through extensive experiments on\nstandard language modeling benchmarks (e.g., WikiText-103, C4) that VQ-Logits\ncan achieve up to 99% parameter reduction in the output layer and 6x speedup in\nlogit computation, with only a marginal 4% increase in perplexity compared to\nfull softmax baselines. We further provide detailed ablation studies on\ncodebook size, initialization, and learning strategies, showcasing the\nrobustness and effectiveness of our approach.", "AI": {"tldr": "VQ-Logits reduces LLM output layer parameters and computational costs using Vector Quantization, achieving 99% parameter reduction and 6x speedup with minimal perplexity increase.", "motivation": "Address computational and memory challenges in LLMs caused by large output vocabularies and the costly final linear projection layer.", "method": "Proposes VQ-Logits, replacing the large output embedding matrix with a small shared codebook of embedding vectors, predicting logits over the codebook and scattering them to the full vocabulary.", "result": "Achieves 99% parameter reduction, 6x speedup in logit computation, and only a 4% perplexity increase on benchmarks like WikiText-103 and C4.", "conclusion": "VQ-Logits is a robust and effective method for reducing LLM output layer complexity with minimal performance trade-offs."}}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR.", "AI": {"tldr": "The paper evaluates Large Multimodal Models (LMMs) for OCR in Pashto, introduces a synthetic dataset (PsOCR), and benchmarks performance, identifying Gemini and Qwen-7B as top performers.", "motivation": "Pashto OCR is challenging due to its cursive script and lack of datasets. The study aims to bridge this gap and assess LMMs.", "method": "Created PsOCR, a synthetic dataset with 1M images, and benchmarked 11 LMMs (7 open-source, 4 closed-source) on a 10K subset.", "result": "Gemini performed best overall; Qwen-7B led among open-source models.", "conclusion": "The work provides insights into LMMs for Pashto OCR and sets a foundation for similar scripts like Arabic and Urdu. PsOCR is publicly available."}}
{"id": "2505.09922", "pdf": "https://arxiv.org/pdf/2505.09922", "abs": "https://arxiv.org/abs/2505.09922", "authors": ["Zichen Liu", "Wei Zhang", "Tiejun Li"], "title": "Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity", "categories": ["cs.LG"], "comment": "22 pages", "summary": "Euclidean diffusion models have achieved remarkable success in generative\nmodeling across diverse domains, and they have been extended to manifold case\nin recent advances. Instead of explicitly utilizing the structure of special\nmanifolds as studied in previous works, we investigate direct sampling of the\nEuclidean diffusion models for general manifold-constrained data in this paper.\nWe reveal the multiscale singularity of the score function in the embedded\nspace of manifold, which hinders the accuracy of diffusion-generated samples.\nWe then present an elaborate theoretical analysis of the singularity structure\nof the score function by separating it along the tangential and normal\ndirections of the manifold. To mitigate the singularity and improve the\nsampling accuracy, we propose two novel methods: (1) Niso-DM, which introduces\nnon-isotropic noise along the normal direction to reduce scale discrepancies,\nand (2) Tango-DM, which trains only the tangential component of the score\nfunction using a tangential-only loss function. Numerical experiments\ndemonstrate that our methods achieve superior performance on distributions over\nvarious manifolds with complex geometries.", "AI": {"tldr": "The paper investigates direct sampling of Euclidean diffusion models for manifold-constrained data, addressing the multiscale singularity of the score function. It proposes two methods, Niso-DM and Tango-DM, to improve sampling accuracy, demonstrating superior performance on complex manifolds.", "motivation": "To address the challenges of sampling manifold-constrained data using Euclidean diffusion models, particularly the singularity of the score function in embedded spaces.", "method": "The paper analyzes the singularity structure of the score function and introduces two methods: Niso-DM (non-isotropic noise along the normal direction) and Tango-DM (tangential-only score training).", "result": "Numerical experiments show the proposed methods achieve superior performance on distributions over various manifolds with complex geometries.", "conclusion": "The study successfully mitigates the singularity issue in manifold-constrained diffusion models, improving sampling accuracy with the proposed Niso-DM and Tango-DM methods."}}
{"id": "2505.03084", "pdf": "https://arxiv.org/pdf/2505.03084", "abs": "https://arxiv.org/abs/2505.03084", "authors": ["Shashank Kapoor", "Sanjay Surendranath Girija", "Lakshit Arora", "Dipen Pradhan", "Ankit Shetgaonkar", "Aman Raj"], "title": "Adversarial Attacks in Multimodal Systems: A Practitioner's Survey", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in IEEE COMPSAC 2025", "summary": "The introduction of multimodal models is a huge step forward in Artificial\nIntelligence. A single model is trained to understand multiple modalities:\ntext, image, video, and audio. Open-source multimodal models have made these\nbreakthroughs more accessible. However, considering the vast landscape of\nadversarial attacks across these modalities, these models also inherit\nvulnerabilities of all the modalities, and ultimately, the adversarial threat\namplifies. While broad research is available on possible attacks within or\nacross these modalities, a practitioner-focused view that outlines attack types\nremains absent in the multimodal world. As more Machine Learning Practitioners\nadopt, fine-tune, and deploy open-source models in real-world applications,\nit's crucial that they can view the threat landscape and take the preventive\nactions necessary. This paper addresses the gap by surveying adversarial\nattacks targeting all four modalities: text, image, video, and audio. This\nsurvey provides a view of the adversarial attack landscape and presents how\nmultimodal adversarial threats have evolved. To the best of our knowledge, this\nsurvey is the first comprehensive summarization of the threat landscape in the\nmultimodal world.", "AI": {"tldr": "The paper surveys adversarial attacks in multimodal AI models, covering text, image, video, and audio, to help practitioners understand and mitigate threats.", "motivation": "Multimodal models inherit vulnerabilities from all modalities, amplifying adversarial threats. Practitioners lack a clear view of attack types, necessitating a comprehensive survey.", "method": "The paper conducts a survey of adversarial attacks across text, image, video, and audio modalities in multimodal models.", "result": "It provides the first comprehensive summary of the adversarial threat landscape in multimodal AI, detailing attack types and their evolution.", "conclusion": "The survey fills a critical gap, equipping practitioners with knowledge to address adversarial threats in multimodal models."}}
{"id": "2505.10218", "pdf": "https://arxiv.org/pdf/2505.10218", "abs": "https://arxiv.org/abs/2505.10218", "authors": ["Zongsheng Wang", "Kaili Sun", "Bowen Wu", "Qun Yu", "Ying Li", "Baoxun Wang"], "title": "RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward", "categories": ["cs.CL"], "comment": null, "summary": "Role-playing conversational agents (RPCAs) face persistent challenges in\nmaintaining role consistency. To address this, we propose RAIDEN-R1, a novel\nreinforcement learning framework that integrates Verifiable Role-Awareness\nReward (VRAR). The method introduces both singular and multi-term mining\nstrategies to generate quantifiable rewards by assessing role-specific keys.\nAdditionally, we construct a high-quality, role-aware Chain-of-Thought dataset\nthrough multi-LLM collaboration, and implement experiments to enhance reasoning\ncoherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's\nsuperiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on\nScript-Based Knowledge and Conversation Memory metrics, respectively,\noutperforming baseline models while maintaining robustness. Case analyses\nfurther reveal the model's enhanced ability to resolve conflicting contextual\ncues and sustain first-person narrative consistency. This work bridges the\nnon-quantifiability gap in RPCA training and provides insights into role-aware\nreasoning patterns, advancing the development of RPCAs.", "AI": {"tldr": "RAIDEN-R1, a reinforcement learning framework with Verifiable Role-Awareness Reward (VRAR), improves role consistency in RPCAs by using singular and multi-term mining strategies. It achieves high accuracy on benchmarks and enhances reasoning coherence.", "motivation": "Addressing the challenge of maintaining role consistency in role-playing conversational agents (RPCAs).", "method": "Proposes RAIDEN-R1, integrating VRAR for quantifiable rewards, and constructs a role-aware Chain-of-Thought dataset via multi-LLM collaboration.", "result": "The 14B-GRPO model achieves 88.04% and 88.65% accuracy on Script-Based Knowledge and Conversation Memory metrics, outperforming baselines.", "conclusion": "RAIDEN-R1 bridges the non-quantifiability gap in RPCA training and advances role-aware reasoning, improving RPCA development."}}
{"id": "2505.10072", "pdf": "https://arxiv.org/pdf/2505.10072", "abs": "https://arxiv.org/abs/2505.10072", "authors": ["Rui-Yang Ju", "Sheng-Yen Huang", "Yi-Ping Hung"], "title": "ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars", "categories": ["cs.CV"], "comment": null, "summary": "The introduction of 3D Gaussian blendshapes has enabled the real-time\nreconstruction of animatable head avatars from monocular video. Toonify, a\nStyleGAN-based framework, has become widely used for facial image stylization.\nTo extend Toonify for synthesizing diverse stylized 3D head avatars using\nGaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB.\nIn Stage 1 (stylized video generation), we employ an improved StyleGAN to\ngenerate the stylized video from the input video frames, which addresses the\nlimitation of cropping aligned faces at a fixed resolution as preprocessing for\nnormal StyleGAN. This process provides a more stable video, which enables\nGaussian blendshapes to better capture the high-frequency details of the video\nframes, and efficiently generate high-quality animation in the next stage. In\nStage 2 (Gaussian blendshapes synthesis), we learn a stylized neutral head\nmodel and a set of expression blendshapes from the generated video. By\ncombining the neutral head model with expression blendshapes, ToonifyGB can\nefficiently render stylized avatars with arbitrary expressions. We validate the\neffectiveness of ToonifyGB on the benchmark dataset using two styles: Arcane\nand Pixar.", "AI": {"tldr": "ToonifyGB extends Toonify for stylized 3D head avatars using Gaussian blendshapes in a two-stage framework, improving video stability and animation quality.", "motivation": "To address the limitation of fixed-resolution cropping in StyleGAN and enable diverse stylized 3D head avatar synthesis.", "method": "A two-stage framework: Stage 1 generates stylized video with improved StyleGAN; Stage 2 synthesizes Gaussian blendshapes for animation.", "result": "Validated on Arcane and Pixar styles, ToonifyGB efficiently renders stylized avatars with arbitrary expressions.", "conclusion": "ToonifyGB successfully combines StyleGAN and Gaussian blendshapes for high-quality, diverse stylized 3D head avatars."}}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods.", "AI": {"tldr": "RiCL introduces an interactive continual learning framework using LLMs to dynamically learn from noisy human feedback while retaining prior knowledge.", "motivation": "Addresses limitations of traditional continual learning: dynamic updates with real-time feedback and handling noisy labels.", "method": "Proposes RiCL with three components: temporal consistency-aware purifier, interaction-aware DPO strategy, and noise-resistant contrastive learning.", "result": "Outperforms state-of-the-art methods on noisy benchmark datasets (FewRel, TACRED).", "conclusion": "RiCL effectively handles noisy feedback and dynamic learning, improving continual learning performance."}}
{"id": "2505.08202", "pdf": "https://arxiv.org/pdf/2505.08202", "abs": "https://arxiv.org/abs/2505.08202", "authors": ["Aman Raj", "Lakshit Arora", "Sanjay Surendranath Girija", "Shashank Kapoor", "Dipen Pradhan", "Ankit Shetgaonkar"], "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE Compsac 2025", "summary": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge\nrisk on human lives as well as infrastructure assets. An effective response to\ndisaster depends on the ability to rapidly and efficiently assess the intensity\nof damage. Artificial Intelligence (AI) and Generative Artificial Intelligence\n(GenAI) presents a breakthrough solution, capable of combining knowledge from\nmultiple types and sources of data, simulating realistic scenarios of disaster,\nand identifying emerging trends at a speed previously unimaginable. In this\npaper, we present a comprehensive review on the prospects of AI and GenAI in\ndamage assessment for various natural disasters, highlighting both its\nstrengths and limitations. We talk about its application to multimodal data\nsuch as text, image, video, and audio, and also cover major issues of data\nprivacy, security, and ethical use of the technology during crises. The paper\nalso recognizes the threat of Generative AI misuse, in the form of\ndissemination of misinformation and for adversarial attacks. Finally, we\noutline avenues of future research, emphasizing the need for secure, reliable,\nand ethical Generative AI systems for disaster management in general. We\nbelieve that this work represents the first comprehensive survey of Gen-AI\ntechniques being used in the field of Disaster Assessment and Response.", "AI": {"tldr": "The paper reviews AI and GenAI's role in disaster damage assessment, covering strengths, limitations, and ethical concerns.", "motivation": "To explore how AI and GenAI can enhance rapid and efficient disaster damage assessment while addressing ethical and security challenges.", "method": "A comprehensive review of AI and GenAI applications in disaster assessment, analyzing multimodal data and ethical issues.", "result": "AI and GenAI offer innovative solutions for disaster assessment but pose risks like misinformation and adversarial attacks.", "conclusion": "Future research should focus on secure, reliable, and ethical GenAI systems for disaster management."}}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios.", "AI": {"tldr": "The study evaluates GPT-3.5, GPT-4, LLAMA3, Mistral 7B, and Claude-2 for zero-shot and few-shot annotation of human rights violations in Russian and Ukrainian social media posts, comparing their performance to human annotations.", "motivation": "To assess the reliability and applicability of LLMs for sensitive, domain-specific tasks in multilingual contexts, focusing on nuanced textual understanding.", "method": "Comparison of LLM annotations (under varying prompting conditions and languages) against a gold standard of human double-annotated labels for 1000 samples.", "result": "Analysis reveals model-specific error patterns, strengths, limitations, and cross-linguistic adaptability.", "conclusion": "The study highlights the potential and challenges of LLMs for subjective, context-dependent tasks, informing real-world deployment."}}
{"id": "2505.10088", "pdf": "https://arxiv.org/pdf/2505.10088", "abs": "https://arxiv.org/abs/2505.10088", "authors": ["Yuncheng Guo", "Xiaodong Gu"], "title": "MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models", "categories": ["cs.CV"], "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract appearing here is slightly shorter than that in the\n  PDF file", "summary": "Large-scale pre-trained Vision-Language Models (VLMs) have significantly\nadvanced transfer learning across diverse tasks. However, adapting these models\nwith limited few-shot data often leads to overfitting, undermining their\nability to generalize to new tasks. To address this, we propose Multi-Modal\nRepresentation Learning (MMRL), which introduces a shared, learnable,\nmodality-agnostic representation space. MMRL generates space tokens projected\ninto both text and image encoders as representation tokens, enabling more\neffective cross-modal interactions. Unlike prior methods that mainly optimize\nclass token features, MMRL inserts representation tokens into higher encoder\nlayers--where task-specific features are more prominent--while preserving\ngeneral knowledge in the lower layers. During training, both class and\nrepresentation features are jointly optimized: a trainable projection layer is\napplied to representation tokens for task adaptation, while the projection\nlayer for class token remains frozen to retain pre-trained knowledge. To\nfurther promote generalization, we introduce a regularization term aligning\nclass and text features with the frozen VLM's zero-shot features. At inference,\na decoupling strategy uses both class and representation features for base\ntasks, but only class features for novel tasks due to their stronger\ngeneralization. Building upon this, we propose MMRL++, a parameter-efficient\nand interaction-aware extension that significantly reduces trainable parameters\nand enhances intra-modal interactions--particularly across the layers of\nrepresentation tokens--allowing gradient sharing and instance-specific\ninformation to propagate more effectively through the network. Extensive\nexperiments on 15 datasets demonstrate that MMRL and MMRL++ consistently\noutperform state-of-the-art methods, achieving a strong balance between\ntask-specific adaptation and generalization.", "AI": {"tldr": "MMRL and MMRL++ improve few-shot adaptation in Vision-Language Models by introducing a shared, modality-agnostic representation space and optimizing both class and representation tokens, enhancing generalization.", "motivation": "Addressing overfitting in few-shot adaptation of VLMs by improving cross-modal interactions and preserving general knowledge.", "method": "Introduces MMRL with shared representation tokens in higher encoder layers, joint optimization of class and representation features, and a regularization term. MMRL++ extends this with parameter efficiency and enhanced intra-modal interactions.", "result": "Outperforms state-of-the-art methods on 15 datasets, balancing task-specific adaptation and generalization.", "conclusion": "MMRL and MMRL++ offer effective solutions for few-shot adaptation in VLMs, improving performance and generalization."}}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices.", "AI": {"tldr": "The paper uses a fine-tuned LLM (Llama3 8B) to analyze freeway crash data, identifying primary causes like alcohol-impaired driving and speeding without pre-labeled data, validated by expert agreement.", "motivation": "Traditional methods struggle with complex crash factor interactions; LLMs offer a novel approach for comprehensive crash causation analysis.", "method": "Fine-tuned Llama3 8B using QLoRA on 226 traffic safety studies, applied zero-shot classification to identify crash causes.", "result": "LLM effectively identified key crash causes (e.g., speeding, inattention) and provided insights validated by 88.89% expert agreement.", "conclusion": "LLMs are promising for crash analysis, offering actionable insights for policymakers to improve traffic safety."}}
{"id": "2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "title": "Online Isolation Forest", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection.", "AI": {"tldr": "Online-iForest is a novel streaming anomaly detection method that outperforms existing online and offline techniques in efficiency and performance.", "motivation": "Existing anomaly detection methods are impractical for streaming data due to memory requirements and retraining needs.", "method": "Proposes Online-iForest, designed for streaming data to adapt dynamically without retraining.", "result": "Matches or outperforms online and offline methods, excelling in efficiency for real-time applications.", "conclusion": "Online-iForest is highly effective for fast anomaly detection in fields like cybersecurity and fraud detection."}}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications.", "AI": {"tldr": "Generative LLMs excel in open-ended medical tasks, while traditional NLP leads in information extraction and analysis. Ethical use is crucial as these technologies evolve.", "motivation": "To explore the differences between generative LLMs and traditional NLP in medical tasks, given their growing prominence.", "method": "Analysis of 19,123 studies comparing the performance of generative LLMs and traditional NLP across various medical tasks.", "result": "Generative LLMs outperform in open-ended tasks; traditional NLP is better for information extraction and analysis.", "conclusion": "Ethical considerations are vital as these technologies advance to maximize their potential in medicine."}}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks.", "AI": {"tldr": "MoB introduces a balanced approach to visual token pruning by addressing the trade-off between prompt alignment and visual preservation, achieving high performance retention and speedup.", "motivation": "Existing pruning methods use static strategies, leading to inconsistent performance due to varying task requirements.", "method": "MoB formulates pruning as a bi-objective covering problem, using greedy radius trading for budget allocation.", "result": "MoB retains 96.4% performance with 11.1% tokens and speeds up models by 1.3-1.5x.", "conclusion": "MoB is effective, scalable, and adaptable to advanced MLLMs and diverse tasks."}}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach.", "AI": {"tldr": "The paper introduces Long-CL, a novel framework for long-term continual learning, addressing catastrophic forgetting and outperforming existing methods by 7.4% and 6.5% on new benchmarks.", "motivation": "To evaluate existing continual learning methods in long-term settings and mitigate catastrophic forgetting over prolonged sequential updates.", "method": "Proposes Long-CL with task-core memory management and long-term memory consolidation, inspired by human memory mechanisms.", "result": "Long-CL achieves significant improvements (7.4% and 6.5% AP) over state-of-the-art methods on MMLongCL-Bench and TextLongCL-Bench.", "conclusion": "The Long-CL framework effectively addresses long-term continual learning challenges, demonstrating superior performance and providing new benchmarks for future research."}}
{"id": "2505.09619", "pdf": "https://arxiv.org/pdf/2505.09619", "abs": "https://arxiv.org/abs/2505.09619", "authors": ["Pietro Cassieri", "Aiman Faiz", "Anna Maria De Roberto", "Claudio Pascarelli", "Gianvito Mitrano", "Gianluca Fimiani", "Marina Garofano", "Christiancarmine Esposito", "Genoveffa Tortora", "Alessia Bramanti", "Giuseppe Scanniello"], "title": "Predictive Models for Chronic Heart Failure", "categories": ["stat.OT", "cs.AI"], "comment": null, "summary": "The management of chronic Heart Failure (HF) presents significant challenges\nin modern healthcare, requiring continuous monitoring, early detection of\nexacerbations, and personalized treatment strategies. In this paper, we present\na predictive model founded on Machine Learning (ML) techniques to identify\npatients at HF risk. This model is an ensemble learning approach, a modified\nstacking technique, that uses two specialized models leveraging clinical and\nechocardiographic features and then a meta-model to combine the predictions of\nthese two models. We initially assess the model on a real dataset and the\nobtained results suggest that it performs well in the stratification of\npatients at HR risk. Specifically, we obtained high sensitivity (95\\%),\nensuring that nearly all high-risk patients are identified. As for accuracy, we\nobtained 84\\%, which can be considered moderate in some ML contexts. However,\nit is acceptable given our priority of identifying patients at risk of HF\nbecause they will be asked to participate in the telemonitoring program of the\nPrediHealth research project on which some of the authors of this paper are\nworking. The initial findings also suggest that ML-based risk stratification\nmodels can serve as valuable decision-support tools not only in the PrediHealth\nproject but also for healthcare professionals, aiding in early intervention and\npersonalized patient management. To have a better understanding of the value\nand of potentiality of our predictive model, we also contrasted its results\nwith those obtained by using three baseline models. The preliminary results\nindicate that our predictive model outperforms these baselines that flatly\nconsider features, \\ie not grouping them in clinical and echocardiographic\nfeatures.", "AI": {"tldr": "A machine learning-based predictive model for chronic Heart Failure (HF) risk stratification using an ensemble approach shows high sensitivity (95%) and moderate accuracy (84%).", "motivation": "The challenges in managing chronic HF require continuous monitoring and early detection, prompting the need for a predictive model to identify high-risk patients.", "method": "An ensemble learning approach with a modified stacking technique combines two specialized models (clinical and echocardiographic features) and a meta-model.", "result": "The model achieves 95% sensitivity and 84% accuracy, outperforming baseline models, and is suitable for early intervention in telemonitoring programs.", "conclusion": "ML-based risk stratification models can effectively support healthcare professionals in early intervention and personalized HF management."}}
{"id": "2505.10282", "pdf": "https://arxiv.org/pdf/2505.10282", "abs": "https://arxiv.org/abs/2505.10282", "authors": ["Dubai Li", "Nan Jiang", "Kangping Huang", "Ruiqi Tu", "Shuyu Ouyang", "Huayu Yu", "Lin Qiao", "Chen Yu", "Tianshu Zhou", "Danyang Tong", "Qian Wang", "Mengtao Li", "Xiaofeng Zeng", "Yu Tian", "Xinping Tian", "Jingsong Li"], "title": "From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making", "categories": ["cs.CL"], "comment": null, "summary": "Clinical evidence, derived from rigorous research and data analysis, provides\nhealthcare professionals with reliable scientific foundations for informed\ndecision-making. Integrating clinical evidence into real-time practice is\nchallenging due to the enormous workload, complex professional processes, and\ntime constraints. This highlights the need for tools that automate evidence\nsynthesis to support more efficient and accurate decision making in clinical\nsettings. This study introduces Quicker, an evidence-based clinical decision\nsupport system powered by large language models (LLMs), designed to automate\nevidence synthesis and generate clinical recommendations modeled after standard\nclinical guideline development processes. Quicker implements a fully automated\nchain that covers all phases, from questions to clinical recommendations, and\nfurther enables customized decision-making through integrated tools and\ninteractive user interfaces. To evaluate Quicker's capabilities, we developed\nthe Q2CRBench-3 benchmark dataset, based on clinical guideline development\nrecords for three different diseases. Experimental results highlighted\nQuicker's strong performance, with fine-grained question decomposition tailored\nto user preferences, retrieval sensitivities comparable to human experts, and\nliterature screening performance approaching comprehensive inclusion of\nrelevant studies. In addition, Quicker-assisted evidence assessment effectively\nsupported human reviewers, while Quicker's recommendations were more\ncomprehensive and logically coherent than those of clinicians. In system-level\ntesting, collaboration between a single reviewer and Quicker reduced the time\nrequired for recommendation development to 20-40 minutes. In general, our\nfindings affirm the potential of Quicker to help physicians make quicker and\nmore reliable evidence-based clinical decisions.", "AI": {"tldr": "Quicker, an LLM-powered clinical decision support system, automates evidence synthesis and generates recommendations, reducing decision-making time and improving accuracy.", "motivation": "Challenges in integrating clinical evidence into practice due to workload and time constraints necessitate automated tools for efficient decision-making.", "method": "Quicker automates the entire evidence synthesis process, from question decomposition to recommendation generation, using LLMs and interactive tools.", "result": "Quicker outperformed human experts in retrieval sensitivity and literature screening, reducing recommendation time to 20-40 minutes with human collaboration.", "conclusion": "Quicker demonstrates potential to enhance evidence-based clinical decisions by improving efficiency and reliability."}}
{"id": "2505.10152", "pdf": "https://arxiv.org/pdf/2505.10152", "abs": "https://arxiv.org/abs/2505.10152", "authors": ["Yikang Wei"], "title": "Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization", "categories": ["cs.CV"], "comment": "IJCAI 2025", "summary": "Federated domain generalization aims to learn a generalizable model from\nmultiple decentralized source domains for deploying on the unseen target\ndomain. The style augmentation methods have achieved great progress on domain\ngeneralization. However, the existing style augmentation methods either explore\nthe data styles within isolated source domain or interpolate the style\ninformation across existing source domains under the data decentralization\nscenario, which leads to limited style space. To address this issue, we propose\na Multi-source Collaborative Style Augmentation and Domain-invariant learning\nmethod (MCSAD) for federated domain generalization. Specifically, we propose a\nmulti-source collaborative style augmentation module to generate data in the\nbroader style space. Furthermore, we conduct domain-invariant learning between\nthe original data and augmented data by cross-domain feature alignment within\nthe same class and classes relation ensemble distillation between different\nclasses to learn a domain-invariant model. By alternatively conducting\ncollaborative style augmentation and domain-invariant learning, the model can\ngeneralize well on unseen target domain. Extensive experiments on multiple\ndomain generalization datasets indicate that our method significantly\noutperforms the state-of-the-art federated domain generalization methods.", "AI": {"tldr": "Proposes MCSAD for federated domain generalization, combining style augmentation and domain-invariant learning to improve generalization on unseen domains.", "motivation": "Existing style augmentation methods in federated domain generalization are limited by isolated or interpolated style exploration, restricting the style space.", "method": "Introduces a multi-source collaborative style augmentation module and domain-invariant learning via cross-domain feature alignment and relation distillation.", "result": "Outperforms state-of-the-art methods on multiple domain generalization datasets.", "conclusion": "MCSAD effectively broadens style space and enhances domain-invariant learning for better generalization."}}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices.", "AI": {"tldr": "TransPL improves unsupervised domain adaptation for time series by modeling joint distributions with code transition matrices, outperforming existing methods.", "motivation": "Traditional pseudo-labeling fails to capture temporal patterns and channel-wise shifts in time series UDA.", "method": "Uses vector quantization and code transition matrices to model source domain distributions, applying Bayes' rule for target adaptation.", "result": "Outperforms state-of-the-art methods by 6.1% accuracy and 4.9% F1, with interpretable insights.", "conclusion": "TransPL effectively addresses UDA challenges in time series with superior performance and explainability."}}
{"id": "2505.09624", "pdf": "https://arxiv.org/pdf/2505.09624", "abs": "https://arxiv.org/abs/2505.09624", "authors": ["Ekaterina Kuzmina", "Dmitrii Kriukov", "Mikhail Lebedev", "Dmitry V. Dylov"], "title": "Neurophysiologically Realistic Environment for Comparing Adaptive Deep Brain Stimulation Algorithms in Parkinson Disease", "categories": ["q-bio.NC", "cs.AI", "68T05"], "comment": "8 pages, 3 figures, submission to KDD", "summary": "Adaptive deep brain stimulation (aDBS) has emerged as a promising treatment\nfor Parkinson disease (PD). In aDBS, a surgically placed electrode sends\ndynamically altered stimuli to the brain based on neurophysiological feedback:\nan invasive gadget that limits the amount of data one could collect for\noptimizing the control offline. As a consequence, a plethora of synthetic\nmodels of PD and those of the control algorithms have been proposed. Herein, we\nintroduce the first neurophysiologically realistic benchmark for comparing said\nmodels. Specifically, our methodology covers not only conventional basal\nganglia circuit dynamics and pathological oscillations, but also captures 15\npreviously dismissed physiological attributes, such as signal instabilities and\nnoise, neural drift, electrode conductance changes and individual variability -\nall modeled as spatially distributed and temporally registered features via\nbeta-band activity in the brain and a feedback. Furthermore, we purposely built\nour framework as a structured environment for training and evaluating deep\nreinforcement learning (RL) algorithms, opening new possibilities for\noptimizing aDBS control strategies and inviting the machine learning community\nto contribute to the emerging field of intelligent neurostimulation interfaces.", "AI": {"tldr": "A neurophysiologically realistic benchmark for comparing synthetic models of Parkinson's disease and adaptive deep brain stimulation (aDBS) control algorithms is introduced, incorporating overlooked physiological attributes and enabling deep reinforcement learning optimization.", "motivation": "The lack of realistic benchmarks for comparing synthetic models of PD and aDBS control algorithms limits offline optimization and progress in intelligent neurostimulation.", "method": "The methodology includes basal ganglia dynamics, pathological oscillations, and 15 dismissed physiological attributes, modeled via beta-band activity and feedback. It also provides a structured environment for deep RL training.", "result": "The framework captures complex physiological features and offers a platform for evaluating and optimizing aDBS control strategies.", "conclusion": "This benchmark advances the field by enabling better model comparisons and inviting ML contributions to intelligent neurostimulation."}}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses.", "AI": {"tldr": "J1, a reinforcement learning approach, improves LLM-as-a-Judge models by incentivizing reasoning and reducing bias, outperforming larger models like DeepSeek-R1 and o1-mini.", "motivation": "AI progress is limited by evaluation quality; stronger reasoning in LLM-as-a-Judge models is needed.", "method": "J1 converts prompts to judgment tasks with verifiable rewards, training models via reinforcement learning.", "result": "J1 outperforms existing 8B and 70B models, including DeepSeek-R1 and o1-mini, on benchmarks.", "conclusion": "J1 enhances judgment quality by learning evaluation criteria, self-comparison, and re-evaluation."}}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias K\u00fcmmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes.", "AI": {"tldr": "A novel architecture addresses dataset bias in saliency prediction, improving generalization across datasets with minimal dataset-specific parameters.", "motivation": "Existing saliency models struggle with dataset bias, showing a 40% performance drop when applied to different datasets.", "method": "Proposes an encoder-decoder structure with fewer than 20 dataset-specific parameters for interpretable mechanisms like multi-scale structure and center bias.", "result": "Achieves state-of-the-art performance on MIT/Tuebingen Saliency Benchmark datasets, reducing the generalization gap by 75%.", "conclusion": "The model effectively addresses dataset bias, offering insights into spatial saliency properties and improving performance with minimal adaptation."}}
{"id": "2505.09959", "pdf": "https://arxiv.org/pdf/2505.09959", "abs": "https://arxiv.org/abs/2505.09959", "authors": ["Zengxia Guo", "Bohui An", "Zhongqi Lu"], "title": "Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated reinforcement learning (FRL) methods usually share the encrypted\nlocal state or policy information and help each client to learn from others\nwhile preserving everyone's privacy. In this work, we propose that sharing the\napproximated behavior metric-based state projection function is a promising way\nto enhance the performance of FRL and concurrently provides an effective\nprotection of sensitive information. We introduce FedRAG, a FRL framework to\nlearn a computationally practical projection function of states for each client\nand aggregating the parameters of projection functions at a central server. The\nFedRAG approach shares no sensitive task-specific information, yet provides\ninformation gain for each client. We conduct extensive experiments on the\nDeepMind Control Suite to demonstrate insightful results.", "AI": {"tldr": "FedRAG enhances federated reinforcement learning (FRL) by sharing approximated behavior metrics instead of sensitive data, improving performance and privacy.", "motivation": "To improve FRL performance while protecting sensitive information by avoiding direct sharing of local states or policies.", "method": "Proposes FedRAG, a framework that learns and aggregates state projection functions across clients without sharing task-specific data.", "result": "Experiments on DeepMind Control Suite show FedRAG's effectiveness in providing information gain while preserving privacy.", "conclusion": "FedRAG is a promising FRL approach that balances performance enhancement and privacy protection."}}
{"id": "2505.09646", "pdf": "https://arxiv.org/pdf/2505.09646", "abs": "https://arxiv.org/abs/2505.09646", "authors": ["Carmel Mary Esther A"], "title": "Temporal Interception and Present Reconstruction: A Cognitive-Signal Model for Human and AI Decision Making", "categories": ["q-bio.NC", "cs.AI", "physics.hist-ph"], "comment": "8 pages, 3 figures", "summary": "This paper proposes a novel theoretical model to explain how the human mind\nand artificial intelligence can approach real-time awareness by reducing\nperceptual delays. By investigating cosmic signal delay, neurological reaction\ntimes, and the ancient cognitive state of stillness, we explore how one may\nshift from reactive perception to a conscious interface with the near future.\nThis paper introduces both a physical and cognitive model for perceiving the\npresent not as a linear timestamp, but as an interference zone where\nearly-arriving cosmic signals and reactive human delays intersect. We propose\nexperimental approaches to test these ideas using human neural observation and\nneuro-receptive extensions. Finally, we propose a mathematical framework to\nguide the evolution of AI systems toward temporally efficient, ethically sound,\nand internally conscious decision-making processes", "AI": {"tldr": "A novel model explains real-time awareness by reducing perceptual delays, blending cosmic signals, neurological reactions, and stillness to shift from reactive perception to conscious future interfacing.", "motivation": "To bridge the gap between human and AI real-time awareness by addressing perceptual delays and exploring the intersection of cosmic signals and cognitive states.", "method": "Investigates cosmic signal delay, neurological reaction times, and stillness; proposes physical and cognitive models, experimental approaches, and a mathematical framework for AI.", "result": "A theoretical and experimental framework for understanding and enhancing real-time awareness in humans and AI.", "conclusion": "The model offers a pathway for AI to achieve temporally efficient, ethically sound, and conscious decision-making by integrating cosmic and cognitive insights."}}
{"id": "2505.10354", "pdf": "https://arxiv.org/pdf/2505.10354", "abs": "https://arxiv.org/abs/2505.10354", "authors": ["Yile Wang", "Zhanyu Shen", "Hui Huang"], "title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Semantic text representation is a fundamental task in the field of natural\nlanguage processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have\ndemonstrated excellent performance, but the values of each dimension are\ndifficult to trace and interpret. Bag-of-words, as classic sparse interpretable\nembeddings, suffers from poor performance. Recently, Benara et al. (2024)\npropose interpretable text embeddings using large language models, which forms\n\"0/1\" embeddings based on responses to a series of questions. These\ninterpretable text embeddings are typically high-dimensional (larger than\n10,000). In this work, we propose Low-dimensional (lower than 500) Dense and\nInterpretable text embeddings with Relative representations (LDIR). The\nnumerical values of its dimensions indicate semantic relatedness to different\nanchor texts through farthest point sampling, offering both semantic\nrepresentation as well as a certain level of traceability and interpretability.\nWe validate LDIR on multiple semantic textual similarity, retrieval, and\nclustering tasks. Extensive experimental results show that LDIR performs close\nto the black-box baseline models and outperforms the interpretable embeddings\nbaselines with much fewer dimensions. Code is available at\nhttps://github.com/szu-tera/LDIR.", "AI": {"tldr": "LDIR proposes low-dimensional, dense, and interpretable text embeddings using relative representations, balancing performance and interpretability.", "motivation": "Existing text embeddings lack interpretability (e.g., SimCSE) or perform poorly (e.g., bag-of-words). Recent work (Benara et al., 2024) offers interpretability but with high dimensionality.", "method": "LDIR uses farthest point sampling to create low-dimensional (under 500) dense embeddings where values indicate semantic relatedness to anchor texts.", "result": "LDIR performs close to black-box models and outperforms interpretable baselines with fewer dimensions.", "conclusion": "LDIR successfully combines performance and interpretability in text embeddings, validated on multiple NLP tasks."}}
{"id": "2505.10205", "pdf": "https://arxiv.org/pdf/2505.10205", "abs": "https://arxiv.org/abs/2505.10205", "authors": ["Umair Haroon", "Ahmad AlMughrabi", "Thanasis Zoumpekas", "Ricardo Marques", "Petia Radeva"], "title": "VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate food volume estimation is crucial for medical nutrition management\nand health monitoring applications, but current food volume estimation methods\nare often limited by mononuclear data, leveraging single-purpose hardware such\nas 3D scanners, gathering sensor-oriented information such as depth\ninformation, or relying on camera calibration using a reference object. In this\npaper, we present VolE, a novel framework that leverages mobile device-driven\n3D reconstruction to estimate food volume. VolE captures images and camera\nlocations in free motion to generate precise 3D models, thanks to AR-capable\nmobile devices. To achieve real-world measurement, VolE is a reference- and\ndepth-free framework that leverages food video segmentation for food mask\ngeneration. We also introduce a new food dataset encompassing the challenging\nscenarios absent in the previous benchmarks. Our experiments demonstrate that\nVolE outperforms the existing volume estimation techniques across multiple\ndatasets by achieving 2.22 % MAPE, highlighting its superior performance in\nfood volume estimation.", "AI": {"tldr": "VolE is a mobile-driven 3D reconstruction framework for accurate food volume estimation without depth sensors or reference objects, outperforming existing methods with 2.22% MAPE.", "motivation": "Current food volume estimation methods rely on specialized hardware or reference objects, limiting practicality. VolE aims to overcome these limitations using mobile devices.", "method": "VolE uses AR-capable mobile devices to capture images and camera locations for 3D reconstruction, combined with food video segmentation for mask generation.", "result": "VolE achieves 2.22% MAPE, outperforming existing techniques across multiple datasets.", "conclusion": "VolE provides a practical, high-accuracy solution for food volume estimation without specialized hardware or references."}}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics.", "AI": {"tldr": "A machine learning framework for heart disease prediction using three classifiers (Logistic Regression, KNN, Random Forest) achieved 91% accuracy with Random Forest, showing promise for clinical use.", "motivation": "To develop an effective machine learning model for predicting heart disease to aid clinical decision-making.", "method": "Data preprocessing, model training, and evaluation using Logistic Regression, KNN, and Random Forest, with hyperparameter tuning via GridSearchCV and RandomizedSearchCV.", "result": "Random Forest outperformed with 91% accuracy and 0.89 F1-score, showing balanced performance across metrics.", "conclusion": "The model is promising for healthcare but requires larger, diverse datasets for improved generalizability."}}
{"id": "2505.09651", "pdf": "https://arxiv.org/pdf/2505.09651", "abs": "https://arxiv.org/abs/2505.09651", "authors": ["Xixuan Hao", "Yutian Jiang", "Xingchen Zou", "Jiabo Liu", "Yifang Yin", "Yuxuan Liang"], "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Location Intelligence (LI), the science of transforming location-centric\ngeospatial data into actionable knowledge, has become a cornerstone of modern\nspatial decision-making. The rapid evolution of Geospatial Representation\nLearning is fundamentally reshaping LI development through two successive\ntechnological revolutions: the deep learning breakthrough and the emerging\nlarge language model (LLM) paradigm. While deep neural networks (DNNs) have\ndemonstrated remarkable success in automated feature extraction from structured\ngeospatial data (e.g., satellite imagery, GPS trajectories), the recent\nintegration of LLMs introduces transformative capabilities for cross-modal\ngeospatial reasoning and unstructured geo-textual data processing. This survey\npresents a comprehensive review of geospatial representation learning across\nboth technological eras, organizing them into a structured taxonomy based on\nthe complete pipeline comprising: (1) data perspective, (2) methodological\nperspective and (3) application perspective. We also highlight current\nadvancements, discuss existing limitations, and propose potential future\nresearch directions in the LLM era. This work offers a thorough exploration of\nthe field and providing a roadmap for further innovation in LI. The summary of\nthe up-to-date paper list can be found in\nhttps://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo\ncontinuous updates.", "AI": {"tldr": "The paper surveys geospatial representation learning, covering deep learning and LLM advancements, and proposes future directions for Location Intelligence.", "motivation": "To review and organize the evolution of geospatial representation learning, highlighting its impact on Location Intelligence.", "method": "Structured taxonomy based on data, methodological, and application perspectives, reviewing advancements and limitations.", "result": "Comprehensive review of geospatial representation learning, identifying transformative capabilities of LLMs and future research directions.", "conclusion": "The survey provides a roadmap for innovation in Location Intelligence, emphasizing the potential of LLMs in geospatial reasoning."}}
{"id": "2505.10356", "pdf": "https://arxiv.org/pdf/2505.10356", "abs": "https://arxiv.org/abs/2505.10356", "authors": ["Chunyu Ye", "Shaonan Wang"], "title": "Coherent Language Reconstruction from Brain Recordings with Flexible Multi-Modal Input Stimuli", "categories": ["cs.CL"], "comment": null, "summary": "Decoding thoughts from brain activity offers valuable insights into human\ncognition and enables promising applications in brain-computer interaction.\nWhile prior studies have explored language reconstruction from fMRI data, they\nare typically limited to single-modality inputs such as images or audio. In\ncontrast, human thought is inherently multimodal. To bridge this gap, we\npropose a unified and flexible framework for reconstructing coherent language\nfrom brain recordings elicited by diverse input modalities-visual, auditory,\nand textual. Our approach leverages visual-language models (VLMs), using\nmodality-specific experts to jointly interpret information across modalities.\nExperiments demonstrate that our method achieves performance comparable to\nstate-of-the-art systems while remaining adaptable and extensible. This work\nadvances toward more ecologically valid and generalizable mind decoding.", "AI": {"tldr": "A unified framework for reconstructing language from brain activity across visual, auditory, and textual inputs using visual-language models.", "motivation": "Human thought is multimodal, but prior studies focused on single-modality inputs. This work aims to bridge the gap for more ecologically valid mind decoding.", "method": "Leverages visual-language models (VLMs) with modality-specific experts to jointly interpret multimodal brain recordings.", "result": "Achieves performance comparable to state-of-the-art systems while being adaptable and extensible.", "conclusion": "Advances toward more generalizable and ecologically valid mind decoding."}}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications.", "AI": {"tldr": "The paper evaluates MixUp and Auxiliary Fourier Augmentation for improving medical image segmentation robustness in real-world clinical settings, showing enhanced generalization and feature representation.", "motivation": "Performance degradation of medical image segmentation models in real-world settings due to distribution mismatches between training and test data.", "method": "Systematic evaluation of MixUp and Auxiliary Fourier Augmentation to improve robustness without targeting specific distribution shifts.", "result": "Significant improvement in out-of-distribution generalization and robustness in cardiac cine MRI and prostate MRI segmentation, with enhanced feature separability and compactness.", "conclusion": "Integration of these augmentation methods into nnU-Net pipelines offers an effective, easy-to-implement solution for reliable medical segmentation in real-world applications."}}
{"id": "2505.09983", "pdf": "https://arxiv.org/pdf/2505.09983", "abs": "https://arxiv.org/abs/2505.09983", "authors": ["Changxun Zhu", "Qilong Wu", "Lingjuan Lyu", "Shibei Xue"], "title": "Sybil-based Virtual Data Poisoning Attacks in Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": "7 pages, 6 figures, accepted by IEEE Codit 2025", "summary": "Federated learning is vulnerable to poisoning attacks by malicious\nadversaries. Existing methods often involve high costs to achieve effective\nattacks. To address this challenge, we propose a sybil-based virtual data\npoisoning attack, where a malicious client generates sybil nodes to amplify the\npoisoning model's impact. To reduce neural network computational complexity, we\ndevelop a virtual data generation method based on gradient matching. We also\ndesign three schemes for target model acquisition, applicable to online local,\nonline global, and offline scenarios. In simulation, our method outperforms\nother attack algorithms since our method can obtain a global target model under\nnon-independent uniformly distributed data.", "AI": {"tldr": "A sybil-based virtual data poisoning attack is proposed for federated learning, using gradient matching to reduce computational costs and outperforming existing methods.", "motivation": "Federated learning is vulnerable to poisoning attacks, and existing methods are costly.", "method": "Proposes a sybil-based attack with virtual data generation via gradient matching and three target model acquisition schemes.", "result": "Outperforms other attack algorithms, especially under non-independent uniformly distributed data.", "conclusion": "The method effectively amplifies poisoning impact with lower computational costs."}}
{"id": "2505.09653", "pdf": "https://arxiv.org/pdf/2505.09653", "abs": "https://arxiv.org/abs/2505.09653", "authors": ["Samuel Yen-Chi Chen", "Chen-Yu Liu", "Kuan-Cheng Chen", "Wei-Jia Huang", "Yen-Jui Chang", "Wei-Hao Huang"], "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG", "cs.NE"], "comment": null, "summary": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave led to the emergence of quantum machine learning (QML), which integrates\nthe strengths of both fields. Among QML approaches, variational quantum\ncircuits (VQCs), also known as quantum neural networks (QNNs), have shown\npromise both empirically and theoretically. However, their broader adoption is\nhindered by reliance on quantum hardware during inference. Hardware\nimperfections and limited access to quantum devices pose practical challenges.\nTo address this, the Quantum-Train (QT) framework leverages the exponential\nscaling of quantum amplitudes to generate classical neural network parameters,\nenabling inference without quantum hardware and achieving significant parameter\ncompression. Yet, designing effective quantum circuit architectures for such\nquantum-enhanced neural programmers remains non-trivial and often requires\nexpertise in quantum information science. In this paper, we propose an\nautomated solution using differentiable optimization. Our method jointly\noptimizes both conventional circuit parameters and architectural parameters in\nan end-to-end manner via automatic differentiation. We evaluate the proposed\nframework on classification, time-series prediction, and reinforcement learning\ntasks. Simulation results show that our method matches or outperforms manually\ndesigned QNN architectures. This work offers a scalable and automated pathway\nfor designing QNNs that can generate classical neural network parameters across\ndiverse applications.", "AI": {"tldr": "The paper proposes an automated method for designing quantum neural networks (QNNs) using differentiable optimization, eliminating the need for quantum hardware during inference and matching or outperforming manual designs.", "motivation": "The reliance on quantum hardware and expertise in quantum information science hinders the adoption of variational quantum circuits (VQCs). The Quantum-Train (QT) framework addresses this but lacks automation in circuit design.", "method": "The authors introduce a differentiable optimization approach to jointly optimize circuit and architectural parameters end-to-end via automatic differentiation.", "result": "Simulations show the method matches or outperforms manually designed QNNs in classification, time-series prediction, and reinforcement learning tasks.", "conclusion": "The work provides a scalable, automated solution for designing QNNs that generate classical neural network parameters, applicable across diverse domains."}}
{"id": "2505.10389", "pdf": "https://arxiv.org/pdf/2505.10389", "abs": "https://arxiv.org/abs/2505.10389", "authors": ["Benjamin White", "Anastasia Shimorina"], "title": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples", "categories": ["cs.CL"], "comment": null, "summary": "This paper explores the design of an aspect-based sentiment analysis system\nusing large language models (LLMs) for real-world use. We focus on quadruple\nopinion extraction -- identifying aspect categories, sentiment polarity,\ntargets, and opinion expressions from text data across different domains and\nlanguages. Using internal datasets, we investigate whether a single fine-tuned\nmodel can effectively handle multiple domain-specific taxonomies\nsimultaneously. We demonstrate that a combined multi-domain model achieves\nperformance comparable to specialized single-domain models while reducing\noperational complexity. We also share lessons learned for handling\nnon-extractive predictions and evaluating various failure modes when developing\nLLM-based systems for structured prediction tasks.", "AI": {"tldr": "Aspect-based sentiment analysis system using LLMs for quadruple opinion extraction across domains and languages, showing multi-domain models match single-domain performance while simplifying operations.", "motivation": "To design a practical system for aspect-based sentiment analysis using LLMs, focusing on extracting quadruple opinions (aspect categories, sentiment, targets, opinions) across diverse domains and languages.", "method": "Fine-tuned a single LLM model on internal datasets to handle multiple domain-specific taxonomies simultaneously, comparing its performance to specialized single-domain models.", "result": "The multi-domain model achieved performance comparable to single-domain models while reducing operational complexity. Insights were shared on handling non-extractive predictions and evaluating failure modes.", "conclusion": "A single fine-tuned LLM can effectively perform quadruple opinion extraction across multiple domains, offering a balance between performance and simplicity."}}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aur\u00e9lie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner.", "AI": {"tldr": "Human-AI alignment reduces fairness gaps in medical imaging AI but requires balance to avoid performance trade-offs.", "motivation": "Address biases and fairness gaps in medical AI by exploring Human-AI alignment.", "method": "Systematic exploration of Human-AI alignment, incorporating human insights.", "result": "Reduced fairness gaps and improved out-of-domain generalization, with noted trade-offs from excessive alignment.", "conclusion": "Human-AI alignment is promising for fair, robust medical AI, but requires calibrated strategies."}}
{"id": "2505.10003", "pdf": "https://arxiv.org/pdf/2505.10003", "abs": "https://arxiv.org/abs/2505.10003", "authors": ["Tianyu Jiao", "Zhuoran Xiao", "Yihang Huang", "Chenhui Ye", "Yijia Feng", "Liyu Cai", "Jiang Chang", "Fangkun Liu", "Yin Xu", "Dazhi He", "Yunfeng Guan", "Wenjun Zhang"], "title": "AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Designing a 6G-oriented universal model capable of processing multi-modal\ndata and executing diverse air interface tasks has emerged as a common goal in\nfuture wireless systems. Building on our prior work in communication\nmulti-modal alignment and telecom large language model (LLM), we propose a\nscalable, task-aware artificial intelligence-air interface multi-modal\nuniversal model (AI2MMUM), which flexibility and effectively perform various\nphysical layer tasks according to subtle task instructions. The LLM backbone\nprovides robust contextual comprehension and generalization capabilities, while\na fine-tuning approach is adopted to incorporate domain-specific knowledge. To\nenhance task adaptability, task instructions consist of fixed task keywords and\nlearnable, implicit prefix prompts. Frozen radio modality encoders extract\nuniversal representations and adapter layers subsequently bridge radio and\nlanguage modalities. Moreover, lightweight task-specific heads are designed to\ndirectly output task objectives. Comprehensive evaluations demonstrate that\nAI2MMUM achieves SOTA performance across five representative physical\nenvironment/wireless channel-based downstream tasks using the WAIR-D and\nDeepMIMO datasets.", "AI": {"tldr": "The paper proposes AI2MMUM, a scalable, task-aware AI model for 6G wireless systems, leveraging multi-modal data and telecom LLM for diverse physical layer tasks with SOTA performance.", "motivation": "To address the need for a universal model in 6G wireless systems capable of handling multi-modal data and diverse air interface tasks efficiently.", "method": "Uses a telecom LLM backbone for contextual comprehension, fine-tunes with domain knowledge, employs task instructions with fixed keywords and learnable prompts, and integrates radio modality encoders with adapter layers and task-specific heads.", "result": "Achieves state-of-the-art performance on five downstream tasks using WAIR-D and DeepMIMO datasets.", "conclusion": "AI2MMUM is a flexible and effective solution for multi-modal universal modeling in 6G wireless systems."}}
{"id": "2505.09698", "pdf": "https://arxiv.org/pdf/2505.09698", "abs": "https://arxiv.org/abs/2505.09698", "authors": ["Enyu Zhao", "Vedant Raval", "Hejia Zhang", "Jiageng Mao", "Zeyu Shangguan", "Stefanos Nikolaidis", "Yue Wang", "Daniel Seita"], "title": "ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "47 pages, 29 figures. Under review", "summary": "Vision-Language Models (VLMs) have revolutionized artificial intelligence and\nrobotics due to their commonsense reasoning capabilities. In robotic\nmanipulation, VLMs are used primarily as high-level planners, but recent work\nhas also studied their lower-level reasoning ability, which refers to making\ndecisions about precise robot movements. However, the community currently lacks\na clear and common benchmark that can evaluate how well VLMs can aid low-level\nreasoning in robotics. Consequently, we propose a novel benchmark, ManipBench,\nto evaluate the low-level robot manipulation reasoning capabilities of VLMs\nacross various dimensions, including how well they understand object-object\ninteractions and deformable object manipulation. We extensively test 33\nrepresentative VLMs across 10 model families on our benchmark, including\nvariants to test different model sizes. Our evaluation shows that the\nperformance of VLMs significantly varies across tasks, and there is a strong\ncorrelation between this performance and trends in our real-world manipulation\ntasks. It also shows that there remains a significant gap between these models\nand human-level understanding. See our website at:\nhttps://manipbench.github.io.", "AI": {"tldr": "A new benchmark, ManipBench, is introduced to evaluate low-level reasoning capabilities of Vision-Language Models (VLMs) in robotic manipulation, revealing performance gaps and correlations with real-world tasks.", "motivation": "The lack of a clear benchmark for evaluating VLMs' low-level reasoning in robotics prompted the creation of ManipBench.", "method": "ManipBench evaluates VLMs across dimensions like object-object interactions and deformable object manipulation, testing 33 models from 10 families.", "result": "VLM performance varies significantly across tasks, with correlations to real-world manipulation tasks, but falls short of human-level understanding.", "conclusion": "ManipBench highlights the need for further development in VLMs for low-level robotic reasoning, with potential for future improvements."}}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code.", "AI": {"tldr": "The paper addresses structural repetition in code generation, proposing RPG, a grammar-based decoding approach to mitigate it, and introduces the CodeRepetEval dataset for evaluation.", "motivation": "Existing work focuses on content repetition, but structural repetition is more prevalent and challenging, requiring a formal solution.", "method": "Proposes RPG, which uses grammar rules to identify and penalize repetition-causing tokens during decoding.", "result": "RPG outperforms baselines on CodeRepetEval, HumanEval, and MBPP, reducing repetitions and improving code quality.", "conclusion": "RPG effectively mitigates structural repetition in code generation, enhancing performance and code quality."}}
{"id": "2505.10238", "pdf": "https://arxiv.org/pdf/2505.10238", "abs": "https://arxiv.org/abs/2505.10238", "authors": ["Yanbo Ding"], "title": "MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation", "categories": ["cs.CV"], "comment": null, "summary": "Human image animation has gained increasing attention and developed rapidly\ndue to its broad applications in digital humans. However, existing methods rely\nlargely on 2D-rendered pose images for motion guidance, which limits\ngeneralization and discards essential 3D information for open-world animation.\nTo tackle this problem, we propose MTVCrafter (Motion Tokenization Video\nCrafter), the first framework that directly models raw 3D motion sequences\n(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT\n(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.\nCompared to 2D-rendered pose images, 4D motion tokens offer more robust\nspatio-temporal cues and avoid strict pixel-level alignment between pose image\nand character, enabling more flexible and disentangled control. Then, we\nintroduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention\nwith 4D positional encodings, MV-DiT can effectively leverage motion tokens as\n4D compact yet expressive context for human image animation in the complex 3D\nworld. Hence, it marks a significant step forward in this field and opens a new\ndirection for pose-guided human video generation. Experiments show that our\nMTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,\nsurpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter\nalso generalizes well to diverse open-world characters (single/multiple,\nfull/half-body) across various styles and scenarios. Our video demos and code\nare provided in the supplementary material and at this anonymous GitHub link:\nhttps://anonymous.4open.science/r/MTVCrafter-1B13.", "AI": {"tldr": "MTVCrafter introduces 4D motion tokens for human image animation, outperforming 2D methods with better generalization and flexibility.", "motivation": "Existing methods rely on 2D-rendered pose images, limiting generalization and discarding 3D information. MTVCrafter addresses this by modeling raw 3D motion sequences.", "method": "Proposes 4DMoT to quantize 3D motion into tokens and MV-DiT with motion attention for animation.", "result": "Achieves state-of-the-art FID-VID of 6.98, surpassing second-best by 65%, and generalizes well to diverse characters.", "conclusion": "MTVCrafter advances human image animation by leveraging 4D motion, opening new directions for pose-guided video generation."}}
{"id": "2505.10007", "pdf": "https://arxiv.org/pdf/2505.10007", "abs": "https://arxiv.org/abs/2505.10007", "authors": ["Zijun Chen", "Shengbo Wang", "Nian Si"], "title": "Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Motivated by practical applications where stable long-term performance is\ncritical-such as robotics, operations research, and healthcare-we study the\nproblem of distributionally robust (DR) average-reward reinforcement learning.\nWe propose two algorithms that achieve near-optimal sample complexity. The\nfirst reduces the problem to a DR discounted Markov decision process (MDP),\nwhile the second, Anchored DR Average-Reward MDP, introduces an anchoring state\nto stabilize the controlled transition kernels within the uncertainty set.\nAssuming the nominal MDP is uniformly ergodic, we prove that both algorithms\nattain a sample complexity of $\\widetilde{O}\\left(|\\mathbf{S}||\\mathbf{A}|\nt_{\\mathrm{mix}}^2\\varepsilon^{-2}\\right)$ for estimating the optimal policy as\nwell as the robust average reward under KL and $f_k$-divergence-based\nuncertainty sets, provided the uncertainty radius is sufficiently small. Here,\n$\\varepsilon$ is the target accuracy, $|\\mathbf{S}|$ and $|\\mathbf{A}|$ denote\nthe sizes of the state and action spaces, and $t_{\\mathrm{mix}}$ is the mixing\ntime of the nominal MDP. This represents the first finite-sample convergence\nguarantee for DR average-reward reinforcement learning. We further validate the\nconvergence rates of our algorithms through numerical experiments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.09747", "pdf": "https://arxiv.org/pdf/2505.09747", "abs": "https://arxiv.org/abs/2505.09747", "authors": ["Benjamin Paa\u00dfen", "Suzana Alpsancar", "Tobias Matzner", "Ingrid Scharlau"], "title": "Healthy Distrust in AI systems", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Under the slogan of trustworthy AI, much of contemporary AI research is\nfocused on designing AI systems and usage practices that inspire human trust\nand, thus, enhance adoption of AI systems. However, a person affected by an AI\nsystem may not be convinced by AI system design alone -- neither should they,\nif the AI system is embedded in a social context that gives good reason to\nbelieve that it is used in tension with a person's interest. In such cases,\ndistrust in the system may be justified and necessary to build meaningful trust\nin the first place. We propose the term \"healthy distrust\" to describe such a\njustified, careful stance towards certain AI usage practices. We investigate\nprior notions of trust and distrust in computer science, sociology, history,\npsychology, and philosophy, outline a remaining gap that healthy distrust might\nfill and conceptualize healthy distrust as a crucial part for AI usage that\nrespects human autonomy.", "AI": {"tldr": "The paper introduces 'healthy distrust' as a justified stance towards AI systems, arguing it's necessary for meaningful trust when AI is used in ways conflicting with human interests.", "motivation": "To address the gap in AI research where trust is emphasized without considering justified distrust in systems that may harm human autonomy.", "method": "Investigates prior notions of trust and distrust across disciplines (computer science, sociology, etc.) and conceptualizes 'healthy distrust.'", "result": "Proposes 'healthy distrust' as a crucial component for AI usage that respects human autonomy.", "conclusion": "Healthy distrust is essential for fostering meaningful trust in AI systems, especially when their use conflicts with human interests."}}
{"id": "2505.10409", "pdf": "https://arxiv.org/pdf/2505.10409", "abs": "https://arxiv.org/abs/2505.10409", "authors": ["Yue Guo", "Jae Ho Sohn", "Gondy Leroy", "Trevor Cohen"], "title": "Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Plain language summaries (PLSs) are essential for facilitating effective\ncommunication between clinicians and patients by making complex medical\ninformation easier for laypeople to understand and act upon. Large language\nmodels (LLMs) have recently shown promise in automating PLS generation, but\ntheir effectiveness in supporting health information comprehension remains\nunclear. Prior evaluations have generally relied on automated scores that do\nnot measure understandability directly, or subjective Likert-scale ratings from\nconvenience samples with limited generalizability. To address these gaps, we\nconducted a large-scale crowdsourced evaluation of LLM-generated PLSs using\nAmazon Mechanical Turk with 150 participants. We assessed PLS quality through\nsubjective Likert-scale ratings focusing on simplicity, informativeness,\ncoherence, and faithfulness; and objective multiple-choice comprehension and\nrecall measures of reader understanding. Additionally, we examined the\nalignment between 10 automated evaluation metrics and human judgments. Our\nfindings indicate that while LLMs can generate PLSs that appear\nindistinguishable from human-written ones in subjective evaluations,\nhuman-written PLSs lead to significantly better comprehension. Furthermore,\nautomated evaluation metrics fail to reflect human judgment, calling into\nquestion their suitability for evaluating PLSs. This is the first study to\nsystematically evaluate LLM-generated PLSs based on both reader preferences and\ncomprehension outcomes. Our findings highlight the need for evaluation\nframeworks that move beyond surface-level quality and for generation methods\nthat explicitly optimize for layperson comprehension.", "AI": {"tldr": "LLM-generated plain language summaries (PLS) appear similar to human-written ones in subjective evaluations but perform worse in comprehension. Automated metrics don't align with human judgment.", "motivation": "To evaluate the effectiveness of LLMs in generating PLS for health communication, addressing gaps in prior evaluations.", "method": "Large-scale crowdsourced evaluation with 150 participants, combining subjective ratings and objective comprehension tests, and comparing automated metrics to human judgments.", "result": "Human-written PLS outperform LLM-generated ones in comprehension, and automated metrics fail to match human evaluations.", "conclusion": "Better evaluation frameworks and generation methods are needed to optimize PLS for layperson comprehension."}}
{"id": "2505.10250", "pdf": "https://arxiv.org/pdf/2505.10250", "abs": "https://arxiv.org/abs/2505.10250", "authors": ["Wenhao Shen", "Wanqi Yin", "Xiaofeng Yang", "Cheng Chen", "Chaoyue Song", "Zhongang Cai", "Lei Yang", "Hao Wang", "Guosheng Lin"], "title": "ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025. Code: https://github.com/shenwenhao01/ADHMR", "summary": "Human mesh recovery (HMR) from a single image is inherently ill-posed due to\ndepth ambiguity and occlusions. Probabilistic methods have tried to solve this\nby generating numerous plausible 3D human mesh predictions, but they often\nexhibit misalignment with 2D image observations and weak robustness to\nin-the-wild images. To address these issues, we propose ADHMR, a framework that\nAligns a Diffusion-based HMR model in a preference optimization manner. First,\nwe train a human mesh prediction assessment model, HMR-Scorer, capable of\nevaluating predictions even for in-the-wild images without 3D annotations. We\nthen use HMR-Scorer to create a preference dataset, where each input image has\na pair of winner and loser mesh predictions. This dataset is used to finetune\nthe base model using direct preference optimization. Moreover, HMR-Scorer also\nhelps improve existing HMR models by data cleaning, even with fewer training\nsamples. Extensive experiments show that ADHMR outperforms current\nstate-of-the-art methods. Code is available at:\nhttps://github.com/shenwenhao01/ADHMR.", "AI": {"tldr": "ADHMR aligns a diffusion-based HMR model using preference optimization, improving alignment with 2D observations and robustness for in-the-wild images.", "motivation": "Addressing misalignment and weak robustness in probabilistic HMR methods for single-image 3D human mesh recovery.", "method": "Train HMR-Scorer to assess predictions, create a preference dataset, and finetune the base model using direct preference optimization.", "result": "ADHMR outperforms state-of-the-art methods and improves existing models via data cleaning.", "conclusion": "ADHMR effectively enhances HMR performance, especially for in-the-wild images, with available code for implementation."}}
{"id": "2505.10010", "pdf": "https://arxiv.org/pdf/2505.10010", "abs": "https://arxiv.org/abs/2505.10010", "authors": ["Jing-Cheng Pang", "Kaiyuan Li", "Yidi Wang", "Si-Hang Yang", "Shengyi Jiang", "Yang Yu"], "title": "ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts", "categories": ["cs.LG"], "comment": null, "summary": "A central challenge in reinforcement learning (RL) is its dependence on\nextensive real-world interaction data to learn task-specific policies. While\nrecent work demonstrates that large language models (LLMs) can mitigate this\nlimitation by generating synthetic experience (noted as imaginary rollouts) for\nmastering novel tasks, progress in this emerging field is hindered due to the\nlack of a standard benchmark. To bridge this gap, we introduce ImagineBench,\nthe first comprehensive benchmark for evaluating offline RL algorithms that\nleverage both real rollouts and LLM-imaginary rollouts. The key features of\nImagineBench include: (1) datasets comprising environment-collected and\nLLM-imaginary rollouts; (2) diverse domains of environments covering\nlocomotion, robotic manipulation, and navigation tasks; and (3) natural\nlanguage task instructions with varying complexity levels to facilitate\nlanguage-conditioned policy learning. Through systematic evaluation of\nstate-of-the-art offline RL algorithms, we observe that simply applying\nexisting offline RL algorithms leads to suboptimal performance on unseen tasks,\nachieving 35.44% success rate in hard tasks in contrast to 64.37% of method\ntraining on real rollouts for hard tasks. This result highlights the need for\nalgorithm advancements to better leverage LLM-imaginary rollouts. Additionally,\nwe identify key opportunities for future research: including better utilization\nof imaginary rollouts, fast online adaptation and continual learning, and\nextension to multi-modal tasks. Our code is publicly available at\nhttps://github.com/LAMDA-RL/ImagineBench.", "AI": {"tldr": "Introduces ImagineBench, a benchmark for offline RL using real and LLM-generated synthetic rollouts, highlighting suboptimal performance of current methods and future research directions.", "motivation": "Addresses the lack of a standard benchmark for evaluating offline RL algorithms that use both real and LLM-generated synthetic experience (imaginary rollouts).", "method": "Introduces ImagineBench, featuring datasets with real and imaginary rollouts, diverse task domains, and natural language instructions for evaluation.", "result": "Existing offline RL algorithms perform poorly (35.44% success) on unseen tasks compared to real rollouts (64.37%), emphasizing the need for better methods.", "conclusion": "Highlights the necessity for advancements in leveraging LLM-imaginary rollouts and identifies future research opportunities like fast adaptation and multi-modal tasks."}}
{"id": "2505.09757", "pdf": "https://arxiv.org/pdf/2505.09757", "abs": "https://arxiv.org/abs/2505.09757", "authors": ["Botao Amber Hu", "Yuhan Liu", "Helena Rong"], "title": "Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "Submitted to CSCW 2026", "summary": "The recent trend of self-sovereign Decentralized AI Agents (DeAgents)\ncombines Large Language Model (LLM)-based AI agents with decentralization\ntechnologies such as blockchain smart contracts and trusted execution\nenvironments (TEEs). These tamper-resistant trustless substrates allow agents\nto achieve self-sovereignty through ownership of cryptowallet private keys and\ncontrol of digital assets and social media accounts. DeAgent eliminates\ncentralized control and reduces human intervention, addressing key trust\nconcerns inherent in centralized AI systems. However, given ongoing challenges\nin LLM reliability such as hallucinations, this creates paradoxical tension\nbetween trustlessness and unreliable autonomy. This study addresses this\nempirical research gap through interviews with DeAgents stakeholders-experts,\nfounders, and developers-to examine their motivations, benefits, and governance\ndilemmas. The findings will guide future DeAgents system and protocol design\nand inform discussions about governance in sociotechnical AI systems in the\nfuture agentic web.", "AI": {"tldr": "The paper explores self-sovereign Decentralized AI Agents (DeAgents), combining LLMs with blockchain and TEEs to address trust issues in centralized AI, while highlighting challenges like LLM reliability.", "motivation": "To address trust concerns in centralized AI systems by leveraging decentralization, while examining the tension between trustlessness and unreliable autonomy in DeAgents.", "method": "Interviews with stakeholders (experts, founders, developers) to analyze motivations, benefits, and governance dilemmas.", "result": "Findings aim to guide future DeAgents system design and governance discussions in sociotechnical AI systems.", "conclusion": "The study provides insights for improving DeAgents protocols and governance, balancing trustlessness and autonomy in the agentic web."}}
{"id": "2505.10413", "pdf": "https://arxiv.org/pdf/2505.10413", "abs": "https://arxiv.org/abs/2505.10413", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yongkang Wu", "Zhonghua Li", "Qi Ye", "Zhicheng Dou"], "title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Real-world RAG applications often encounter long-context input scenarios,\nwhere redundant information and noise results in higher inference costs and\nreduced performance. To address these challenges, we propose LongRefiner, an\nefficient plug-and-play refiner that leverages the inherent structural\ncharacteristics of long documents. LongRefiner employs dual-level query\nanalysis, hierarchical document structuring, and adaptive refinement through\nmulti-task learning on a single foundation model. Experiments on seven QA\ndatasets demonstrate that LongRefiner achieves competitive performance in\nvarious scenarios while using 10x fewer computational costs and latency\ncompared to the best baseline. Further analysis validates that LongRefiner is\nscalable, efficient, and effective, providing practical insights for real-world\nlong-text RAG applications. Our code is available at\nhttps://github.com/ignorejjj/LongRefiner.", "AI": {"tldr": "LongRefiner is a plug-and-play refiner for long-context RAG applications, reducing computational costs and improving performance through dual-level query analysis and hierarchical structuring.", "motivation": "Addressing the challenges of redundant information and noise in long-context RAG applications, which increase costs and reduce performance.", "method": "Uses dual-level query analysis, hierarchical document structuring, and adaptive refinement via multi-task learning on a single foundation model.", "result": "Achieves competitive performance on seven QA datasets with 10x fewer computational costs and latency than baselines.", "conclusion": "LongRefiner is scalable, efficient, and effective, offering practical insights for real-world long-text RAG applications."}}
{"id": "2505.10257", "pdf": "https://arxiv.org/pdf/2505.10257", "abs": "https://arxiv.org/abs/2505.10257", "authors": ["Hao Lu", "Jiaqi Tang", "Jiyao Wang", "Yunfan LU", "Xu Cao", "Qingyong Hu", "Yin Wang", "Yuting Zhang", "Tianxin Xie", "Yunpeng Zhang", "Yong Chen", "Jiayu. Gao", "Bin Huang", "Dengbo He", "Shuiguang Deng", "Hao Chen", "Ying-Cong Chen"], "title": "Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot", "categories": ["cs.CV"], "comment": null, "summary": "The intelligent driving cockpit, an important part of intelligent driving,\nneeds to match different users' comfort, interaction, and safety needs. This\npaper aims to build a Super-Aligned and GEneralist DRiving agent, SAGE DeeR.\nSage Deer achieves three highlights: (1) Super alignment: It achieves different\nreactions according to different people's preferences and biases. (2)\nGeneralist: It can understand the multi-view and multi-mode inputs to reason\nthe user's physiological indicators, facial emotions, hand movements, body\nmovements, driving scenarios, and behavioral decisions. (3) Self-Eliciting: It\ncan elicit implicit thought chains in the language space to further increase\ngeneralist and super-aligned abilities. Besides, we collected multiple data\nsets and built a large-scale benchmark. This benchmark measures the deer's\nperceptual decision-making ability and the super alignment's accuracy.", "AI": {"tldr": "SAGE DeeR is a Super-Aligned and Generalist Driving agent designed to match user comfort, interaction, and safety needs in intelligent driving cockpits. It achieves super alignment, generalist capabilities, and self-eliciting thought chains.", "motivation": "To address the need for personalized and adaptive intelligent driving systems that cater to diverse user preferences and inputs.", "method": "Developed SAGE DeeR with super alignment, generalist reasoning, and self-eliciting abilities, supported by a large-scale benchmark for evaluation.", "result": "SAGE DeeR can adapt to user preferences, process multi-view inputs, and elicit implicit thought chains, validated by a comprehensive benchmark.", "conclusion": "SAGE DeeR demonstrates advanced capabilities in aligning with user needs and generalizing across diverse driving scenarios."}}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers.", "AI": {"tldr": "QHML models outperform classical models in anti-cancer drug response prediction when data is optimally normalized using a moderated gradient tanh function.", "motivation": "Small datasets in anti-cancer drug response prediction benefit from QHML's robustness, but data encoding sensitivity is a challenge.", "method": "Proposed a normalization strategy using a moderated gradient tanh function to stabilize QHML models.", "result": "QHML models showed better performance than classical models with optimal normalization.", "conclusion": "The study highlights QHML's potential for biomedical data analysis with quantum computers."}}
{"id": "2505.09766", "pdf": "https://arxiv.org/pdf/2505.09766", "abs": "https://arxiv.org/abs/2505.09766", "authors": ["Roberto Ponciroli"], "title": "On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion", "categories": ["math.NA", "cs.AI", "cs.NA"], "comment": null, "summary": "This work presents a methodology for reconstructing the spatial distribution\nof the neutron flux in a nuclear reactor, leveraging real-time measurements\nobtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation\ninherently defines the problem of estimating a scalar field within a domain\nbased on boundary data, making it a natural mathematical framework for this\ntask. The main challenge lies in deriving the Green's function specific to the\ndomain and the neutron diffusion process. While analytical solutions for\nGreen's functions exist for simplified geometries, their derivation of complex,\nheterogeneous domains-such as a nuclear reactor-requires a numerical approach.\nThe objective of this work is to demonstrate the well-posedness of the\ndata-driven Green's function approximation by formulating and solving the K-H\nequation as an inverse problem. After establishing the symmetry properties that\nthe Green's function must satisfy, the K-H equation is derived from the\none-speed neutron diffusion model. This is followed by a comprehensive\ndescription of the procedure for interpreting sensor readings and implementing\nthe neutron flux reconstruction algorithm. Finally, the existence and\nuniqueness of the Green's function inferred from the sampled data are\ndemonstrated, ensuring the reliability of the proposed method and its\npredictions.", "AI": {"tldr": "A method for reconstructing neutron flux in nuclear reactors using ex-core detector data, solving the Kirchhoff-Helmholtz equation numerically for complex domains.", "motivation": "To address the challenge of deriving Green's functions for complex reactor geometries and ensure reliable neutron flux estimation.", "method": "Formulates the Kirchhoff-Helmholtz equation as an inverse problem, derives Green's function numerically, and implements a flux reconstruction algorithm.", "result": "Demonstrates the existence and uniqueness of the data-driven Green's function, ensuring method reliability.", "conclusion": "The proposed approach is well-posed and reliable for neutron flux reconstruction in heterogeneous reactor domains."}}
{"id": "2505.10446", "pdf": "https://arxiv.org/pdf/2505.10446", "abs": "https://arxiv.org/abs/2505.10446", "authors": ["Zemin Huang", "Zhiyang Chen", "Zijun Wang", "Tiancheng Li", "Guo-Jun Qi"], "title": "Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We introduce the \\emph{Diffusion Chain of Lateral Thought (DCoLT)}, a\nreasoning framework for diffusion language models. DCoLT treats each\nintermediate step in the reverse diffusion process as a latent \"thinking\"\naction and optimizes the entire reasoning trajectory to maximize the reward on\nthe correctness of the final answer with outcome-based Reinforcement Learning\n(RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal,\nlinear thinking process, DCoLT allows bidirectional, non-linear reasoning with\nno strict rule on grammatical correctness amid its intermediate steps of\nthought. We implement DCoLT on two representative Diffusion Language Models\n(DLMs). First, we choose SEDD as a representative continuous-time discrete\ndiffusion model, where its concrete score derives a probabilistic policy to\nmaximize the RL reward over the entire sequence of intermediate diffusion\nsteps. We further consider the discrete-time masked diffusion language model --\nLLaDA, and find that the order to predict and unmask tokens plays an essential\nrole to optimize its RL action resulting from the ranking-based Unmasking\nPolicy Module (UPM) defined by the Plackett-Luce model. Experiments on both\nmath and code generation tasks show that using only public data and 16 H800\nGPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even\nboth. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%,\n+5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval.", "AI": {"tldr": "DCoLT is a reasoning framework for diffusion language models that optimizes reasoning trajectories using RL, outperforming traditional methods on math and code tasks.", "motivation": "To enhance reasoning in diffusion language models by allowing non-linear, bidirectional thinking and optimizing intermediate steps for correctness.", "method": "Uses outcome-based RL to optimize reasoning trajectories in diffusion models (SEDD and LLaDA), with a focus on probabilistic policies and token unmasking order.", "result": "DCoLT-reinforced models outperform others, with LLaDA showing significant accuracy boosts on GSM8K, MATH, MBPP, and HumanEval.", "conclusion": "DCoLT effectively improves reasoning in diffusion models, demonstrating superior performance on complex tasks."}}
{"id": "2505.10258", "pdf": "https://arxiv.org/pdf/2505.10258", "abs": "https://arxiv.org/abs/2505.10258", "authors": ["Michael Hubbertz", "Pascal Colling", "Qi Han", "Tobias Meisen"], "title": "Inferring Driving Maps by Deep Learning-based Trail Map Extraction", "categories": ["cs.CV", "cs.RO"], "comment": "This paper was accepted at the CVPR WAD 2025 Workshop", "summary": "High-definition (HD) maps offer extensive and accurate environmental\ninformation about the driving scene, making them a crucial and essential\nelement for planning within autonomous driving systems. To avoid extensive\nefforts from manual labeling, methods for automating the map creation have\nemerged. Recent trends have moved from offline mapping to online mapping,\nensuring availability and actuality of the utilized maps. While the performance\nhas increased in recent years, online mapping still faces challenges regarding\ntemporal consistency, sensor occlusion, runtime, and generalization. We propose\na novel offline mapping approach that integrates trails - informal routes used\nby drivers - into the map creation process. Our method aggregates trail data\nfrom the ego vehicle and other traffic participants to construct a\ncomprehensive global map using transformer-based deep learning models. Unlike\ntraditional offline mapping, our approach enables continuous updates while\nremaining sensor-agnostic, facilitating efficient data transfer. Our method\ndemonstrates superior performance compared to state-of-the-art online mapping\napproaches, achieving improved generalization to previously unseen environments\nand sensor configurations. We validate our approach on two benchmark datasets,\nhighlighting its robustness and applicability in autonomous driving systems.", "AI": {"tldr": "A novel offline mapping method integrates trail data for autonomous driving, outperforming online mapping in generalization and robustness.", "motivation": "To address challenges in online mapping (temporal consistency, sensor occlusion, runtime, generalization) by leveraging trail data for more accurate and adaptable HD maps.", "method": "Aggregates trail data from ego vehicles and traffic participants, using transformer-based deep learning to construct and update global maps continuously.", "result": "Superior performance over online mapping, with improved generalization to unseen environments and sensor configurations, validated on benchmark datasets.", "conclusion": "The proposed offline mapping approach is robust and applicable for autonomous driving, offering efficient updates and sensor-agnostic capabilities."}}
{"id": "2505.10039", "pdf": "https://arxiv.org/pdf/2505.10039", "abs": "https://arxiv.org/abs/2505.10039", "authors": ["Hang Chen", "Jiaying Zhu", "Xinyu Yang", "Wenya Wang"], "title": "Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates", "categories": ["cs.LG"], "comment": "10 pages", "summary": "Circuit discovery has gradually become one of the prominent methods for\nmechanistic interpretability, and research on circuit completeness has also\ngarnered increasing attention. Methods of circuit discovery that do not\nguarantee completeness not only result in circuits that are not fixed across\ndifferent runs but also cause key mechanisms to be omitted. The nature of\nincompleteness arises from the presence of OR gates within the circuit, which\nare often only partially detected in standard circuit discovery methods. To\nthis end, we systematically introduce three types of logic gates: AND, OR, and\nADDER gates, and decompose the circuit into combinations of these logical\ngates. Through the concept of these gates, we derive the minimum requirements\nnecessary to achieve faithfulness and completeness. Furthermore, we propose a\nframework that combines noising-based and denoising-based interventions, which\ncan be easily integrated into existing circuit discovery methods without\nsignificantly increasing computational complexity. This framework is capable of\nfully identifying the logic gates and distinguishing them within the circuit.\nIn addition to the extensive experimental validation of the framework's ability\nto restore the faithfulness, completeness, and sparsity of circuits, using this\nframework, we uncover fundamental properties of the three logic gates, such as\ntheir proportions and contributions to the output, and explore how they behave\namong the functionalities of language models.", "AI": {"tldr": "The paper introduces a framework for achieving faithful and complete circuit discovery by decomposing circuits into AND, OR, and ADDER gates, and proposes a noising-denosing intervention method.", "motivation": "Addressing incompleteness in circuit discovery due to partial detection of OR gates, which leads to inconsistent results and omitted mechanisms.", "method": "Systematic introduction of AND, OR, and ADDER gates, and a framework combining noising and denoising interventions to identify and distinguish these gates.", "result": "The framework successfully restores faithfulness, completeness, and sparsity of circuits, while uncovering properties of logic gates in language models.", "conclusion": "The proposed framework enhances circuit discovery by ensuring completeness and faithfulness, and reveals insights into logic gate behavior in language models."}}
{"id": "2505.09796", "pdf": "https://arxiv.org/pdf/2505.09796", "abs": "https://arxiv.org/abs/2505.09796", "authors": ["Skylar S. Gay", "Tucker Netherton", "Barbara Marquez", "Raymond Mumme", "Mary Gronberg", "Brent Parker", "Chelsea Pinnix", "Sanjay Shete", "Carlos Cardenas", "Laurence Court"], "title": "Virtual Dosimetrists: A Radiotherapy Training \"Flight Simulator\"", "categories": ["physics.med-ph", "cs.AI"], "comment": null, "summary": "Effective education in radiotherapy plan quality review requires a robust,\nregularly updated set of examples and the flexibility to demonstrate multiple\npossible planning approaches and their consequences. However, the current\nclinic-based paradigm does not support these needs. To address this, we have\ndeveloped 'Virtual Dosimetrist' models that can both generate training examples\nof suboptimal treatment plans and then allow trainees to improve the plan\nquality through simple natural language prompts, as if communicating with a\ndosimetrist. The dose generation and modification process is accurate, rapid,\nand requires only modest resources. This work is the first to combine dose\ndistribution prediction with natural language processing; providing a robust\npipeline for both generating suboptimal training plans and allowing trainees to\npractice their critical plan review and improvement skills that addresses the\nchallenges of the current clinic-based paradigm.", "AI": {"tldr": "The paper introduces 'Virtual Dosimetrist' models to enhance radiotherapy plan quality review education by generating suboptimal training plans and enabling interactive improvement via natural language prompts.", "motivation": "Current clinic-based education lacks robust, updated examples and flexibility for demonstrating planning approaches, hindering effective training in radiotherapy plan quality review.", "method": "Developed 'Virtual Dosimetrist' models that generate suboptimal plans and allow trainees to improve them using natural language prompts, combining dose distribution prediction with NLP.", "result": "The system is accurate, fast, and resource-efficient, providing a practical pipeline for training and skill improvement.", "conclusion": "This approach addresses the limitations of the current clinic-based paradigm, offering a novel, interactive method for radiotherapy education."}}
{"id": "2505.10493", "pdf": "https://arxiv.org/pdf/2505.10493", "abs": "https://arxiv.org/abs/2505.10493", "authors": ["Shaohan Wang", "Licheng Zhang", "Zheren Fu", "Zhendong Mao"], "title": "CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is an effective method to enhance the\ncapabilities of large language models (LLMs). Existing methods focus on\noptimizing the retriever or generator in the RAG system by directly utilizing\nthe top-k retrieved documents. However, the documents effectiveness are various\nsignificantly across user queries, i.e. some documents provide valuable\nknowledge while others totally lack critical information. It hinders the\nretriever and generator's adaptation during training. Inspired by human\ncognitive learning, curriculum learning trains models using samples progressing\nfrom easy to difficult, thus enhancing their generalization ability, and we\nintegrate this effective paradigm to the training of the RAG system. In this\npaper, we propose a multi-stage Curriculum Learning based RAG system training\nframework, named CL-RAG. We first construct training data with multiple\ndifficulty levels for the retriever and generator separately through sample\nevolution. Then, we train the model in stages based on the curriculum learning\napproach, thereby optimizing the overall performance and generalization of the\nRAG system more effectively. Our CL-RAG framework demonstrates consistent\neffectiveness across four open-domain QA datasets, achieving performance gains\nof 2% to 4% over multiple advanced methods.", "AI": {"tldr": "The paper introduces CL-RAG, a multi-stage curriculum learning framework for training RAG systems, improving performance by 2-4% over existing methods.", "motivation": "Existing RAG systems struggle with varying document effectiveness across queries, hindering retriever and generator adaptation. Inspired by human cognitive learning, curriculum learning is integrated to address this.", "method": "CL-RAG constructs multi-difficulty training data for retriever and generator via sample evolution, then trains them in stages using curriculum learning.", "result": "CL-RAG achieves 2-4% performance gains over advanced methods on four open-domain QA datasets.", "conclusion": "CL-RAG effectively enhances RAG system performance and generalization through curriculum learning."}}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available.", "AI": {"tldr": "HandReader introduces three architectures for fingerspelling recognition, leveraging RGB and keypoint data, achieving state-of-the-art results on multiple datasets, including a new Russian dataset (Znaki).", "motivation": "Improving fingerspelling recognition accuracy by addressing temporal and spatial information in videos, which previous methods lacked.", "method": "Three architectures: HandReader_RGB (TSAM for RGB features), HandReader_KP (TPE for keypoints), and HandReader_RGB+KP (joint encoder).", "result": "State-of-the-art performance on ChicagoFSWild, ChicagoFSWild+, and Znaki datasets.", "conclusion": "HandReader models effectively combine RGB and keypoint data for superior fingerspelling recognition, with publicly available datasets and models."}}
{"id": "2505.10040", "pdf": "https://arxiv.org/pdf/2505.10040", "abs": "https://arxiv.org/abs/2505.10040", "authors": ["Lei Song", "Jiaxing Li", "Shihan Guan", "Youyong Kong"], "title": "Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNN) endure catastrophic forgetting, undermining their\ncapacity to preserve previously acquired knowledge amid the assimilation of\nnovel information. Rehearsal-based techniques revisit historical examples,\nadopted as a principal strategy to alleviate this phenomenon. However, memory\nexplosion and privacy infringements impose significant constraints on their\nutility. Non-Exemplar methods circumvent the prior issues through Prototype\nReplay (PR), yet feature drift presents new challenges. In this paper, our\nempirical findings reveal that Prototype Contrastive Learning (PCL) exhibits\nless pronounced drift than conventional PR. Drawing upon PCL, we propose\nInstance-Prototype Affinity Learning (IPAL), a novel paradigm for Non-Exemplar\nContinual Graph Learning (NECGL). Exploiting graph structural information, we\nformulate Topology-Integrated Gaussian Prototypes (TIGP), guiding feature\ndistributions towards high-impact nodes to augment the model's capacity for\nassimilating new knowledge. Instance-Prototype Affinity Distillation (IPAD)\nsafeguards task memory by regularizing discontinuities in class relationships.\nMoreover, we embed a Decision Boundary Perception (DBP) mechanism within PCL,\nfostering greater inter-class discriminability. Evaluations on four node\nclassification benchmark datasets demonstrate that our method outperforms\nexisting state-of-the-art methods, achieving a better trade-off between\nplasticity and stability.", "AI": {"tldr": "The paper proposes Instance-Prototype Affinity Learning (IPAL) for Non-Exemplar Continual Graph Learning (NECGL), addressing feature drift and catastrophic forgetting in GNNs. It introduces Topology-Integrated Gaussian Prototypes (TIGP) and Instance-Prototype Affinity Distillation (IPAD) to improve knowledge assimilation and task memory. Evaluations show superior performance over existing methods.", "motivation": "Graph Neural Networks (GNNs) suffer from catastrophic forgetting and feature drift when learning new information. Rehearsal-based methods face memory and privacy issues, while non-exemplar methods like Prototype Replay (PR) struggle with drift. The paper aims to mitigate these challenges.", "method": "The authors propose IPAL, leveraging Prototype Contrastive Learning (PCL) to reduce drift. They introduce TIGP for topology-aware feature distribution and IPAD for task memory regularization. A Decision Boundary Perception (DBP) mechanism enhances inter-class discriminability.", "result": "Evaluations on four node classification datasets show IPAL outperforms state-of-the-art methods, achieving a better balance between plasticity (learning new tasks) and stability (retaining old knowledge).", "conclusion": "IPAL effectively addresses catastrophic forgetting and feature drift in GNNs, offering a robust solution for continual graph learning with superior performance and practical utility."}}
{"id": "2505.09805", "pdf": "https://arxiv.org/pdf/2505.09805", "abs": "https://arxiv.org/abs/2505.09805", "authors": ["Aditya Nagori", "Ayush Gautam", "Matthew O. Wiens", "Vuong Nguyen", "Nathan Kenya Mugisha", "Jerome Kabakyenga", "Niranjan Kissoon", "John Mark Ansermino", "Rishikesan Kamaleswaran"], "title": "Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "stat.AP"], "comment": "11 pages, 2 Figures, 1 Table", "summary": "Clustering patient subgroups is essential for personalized care and efficient\nresource use. Traditional clustering methods struggle with high-dimensional,\nheterogeneous healthcare data and lack contextual understanding. This study\nevaluates Large Language Model (LLM) based clustering against classical methods\nusing a pediatric sepsis dataset from a low-income country (LIC), containing\n2,686 records with 28 numerical and 119 categorical variables. Patient records\nwere serialized into text with and without a clustering objective. Embeddings\nwere generated using quantized LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B with\nlow-rank adaptation(LoRA), and Stella-En-400M-V5 models. K-means clustering was\napplied to these embeddings. Classical comparisons included K-Medoids\nclustering on UMAP and FAMD-reduced mixed data. Silhouette scores and\nstatistical tests evaluated cluster quality and distinctiveness.\nStella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLAMA 3.1 8B\nwith the clustering objective performed better with higher number of clusters,\nidentifying subgroups with distinct nutritional, clinical, and socioeconomic\nprofiles. LLM-based methods outperformed classical techniques by capturing\nricher context and prioritizing key features. These results highlight potential\nof LLMs for contextual phenotyping and informed decision-making in\nresource-limited settings.", "AI": {"tldr": "LLM-based clustering outperforms classical methods in grouping pediatric sepsis patients, capturing richer context and distinct profiles.", "motivation": "To address the limitations of traditional clustering methods in handling high-dimensional, heterogeneous healthcare data and lack of contextual understanding.", "method": "Used LLM-based clustering (LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B, Stella-En-400M-V5) and compared with classical methods (K-Medoids on UMAP/FAMD-reduced data) on a pediatric sepsis dataset.", "result": "Stella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLM methods identified distinct subgroups and outperformed classical techniques.", "conclusion": "LLMs show promise for contextual phenotyping and informed decision-making in resource-limited healthcare settings."}}
{"id": "2505.10494", "pdf": "https://arxiv.org/pdf/2505.10494", "abs": "https://arxiv.org/abs/2505.10494", "authors": ["Yutao Mou", "Xiao Deng", "Yuxiao Luo", "Shikun Zhang", "Wei Ye"], "title": "Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective", "categories": ["cs.CL"], "comment": "Accepted by ACL2025 Main Conference", "summary": "Code security and usability are both essential for various coding assistant\napplications driven by large language models (LLMs). Current code security\nbenchmarks focus solely on single evaluation task and paradigm, such as code\ncompletion and generation, lacking comprehensive assessment across dimensions\nlike secure code generation, vulnerability repair and discrimination. In this\npaper, we first propose CoV-Eval, a multi-task benchmark covering various tasks\nsuch as code completion, vulnerability repair, vulnerability detection and\nclassification, for comprehensive evaluation of LLM code security. Besides, we\ndeveloped VC-Judge, an improved judgment model that aligns closely with human\nexperts and can review LLM-generated programs for vulnerabilities in a more\nefficient and reliable way. We conduct a comprehensive evaluation of 20\nproprietary and open-source LLMs. Overall, while most LLMs identify vulnerable\ncodes well, they still tend to generate insecure codes and struggle with\nrecognizing specific vulnerability types and performing repairs. Extensive\nexperiments and qualitative analyses reveal key challenges and optimization\ndirections, offering insights for future research in LLM code security.", "AI": {"tldr": "CoV-Eval is a multi-task benchmark for evaluating LLM code security, and VC-Judge improves vulnerability assessment. Most LLMs identify vulnerabilities well but struggle with generating secure code and repairs.", "motivation": "Current benchmarks lack comprehensive evaluation of LLM code security across tasks like secure code generation and vulnerability repair.", "method": "Proposed CoV-Eval for multi-task evaluation and VC-Judge for improved vulnerability assessment. Evaluated 20 LLMs.", "result": "LLMs identify vulnerabilities well but generate insecure code and struggle with repairs.", "conclusion": "Key challenges and optimization directions are identified for future LLM code security research."}}
{"id": "2505.10281", "pdf": "https://arxiv.org/pdf/2505.10281", "abs": "https://arxiv.org/abs/2505.10281", "authors": ["Mengqiu Xu", "Kaixin Chen", "Heng Guo", "Yixiang Huang", "Ming Wu", "Zhenwei Shi", "Chuang Zhang", "Jun Guo"], "title": "MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning approaches for marine fog detection and forecasting have\noutperformed traditional methods, demonstrating significant scientific and\npractical importance. However, the limited availability of open-source datasets\nremains a major challenge. Existing datasets, often focused on a single region\nor satellite, restrict the ability to evaluate model performance across diverse\nconditions and hinder the exploration of intrinsic marine fog characteristics.\nTo address these limitations, we introduce \\textbf{MFogHub}, the first\nmulti-regional and multi-satellite dataset to integrate annotated marine fog\nobservations from 15 coastal fog-prone regions and six geostationary\nsatellites, comprising over 68,000 high-resolution samples. By encompassing\ndiverse regions and satellite perspectives, MFogHub facilitates rigorous\nevaluation of both detection and forecasting methods under varying conditions.\nExtensive experiments with 16 baseline models demonstrate that MFogHub can\nreveal generalization fluctuations due to regional and satellite discrepancy,\nwhile also serving as a valuable resource for the development of targeted and\nscalable fog prediction techniques. Through MFogHub, we aim to advance both the\npractical monitoring and scientific understanding of marine fog dynamics on a\nglobal scale. The dataset and code are at\n\\href{https://github.com/kaka0910/MFogHub}{https://github.com/kaka0910/MFogHub}.", "AI": {"tldr": "MFogHub is a new multi-regional and multi-satellite dataset for marine fog detection and forecasting, addressing the lack of diverse open-source data.", "motivation": "Existing datasets are limited to single regions or satellites, hindering model evaluation and understanding of marine fog dynamics.", "method": "MFogHub integrates annotated marine fog observations from 15 regions and six satellites, offering over 68,000 high-resolution samples.", "result": "Experiments with 16 baseline models show MFogHub reveals generalization issues due to regional/satellite differences and aids in scalable fog prediction.", "conclusion": "MFogHub advances global marine fog monitoring and scientific understanding, with dataset and code publicly available."}}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection.", "AI": {"tldr": "A fraud detection framework combining gradient boosting models (XGBoost, LightGBM, CatBoost) with XAI techniques (SHAP, LIME, PDP, PFI) achieves high accuracy (99%) and interpretability, addressing regulatory and trust issues.", "motivation": "Traditional ML models lack transparency, hindering regulatory compliance and stakeholder trust. This research aims to balance accuracy and interpretability in fraud detection.", "method": "Proposes a stacking ensemble of gradient boosting models (XGBoost, LightGBM, CatBoost) enhanced with XAI techniques (SHAP, LIME, PDP, PFI) for feature selection and prediction explanation.", "result": "Achieved 99% accuracy and 0.99 AUC-ROC on the IEEE-CIS Fraud Detection dataset, outperforming recent approaches.", "conclusion": "Combining high accuracy with interpretability is feasible, offering ethical and trustworthy fraud detection solutions."}}
{"id": "2505.09814", "pdf": "https://arxiv.org/pdf/2505.09814", "abs": "https://arxiv.org/abs/2505.09814", "authors": ["Dmitry Rybin", "Yushun Zhang", "Zhi-Quan Luo"], "title": "$XX^{t}$ Can Be Faster", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.SC", "68Q25, 68T20", "F.2.1; I.1.2"], "comment": null, "summary": "We present a new algorithm RXTX that computes product of matrix by its\ntranspose $XX^{t}$. RXTX uses $5\\%$ less multiplications and additions than\nState-of-the-Art and achieves accelerations even for small sizes of matrix $X$.\nThe algorithm was discovered by combining Machine Learning-based search methods\nwith Combinatorial Optimization.", "AI": {"tldr": "RXTX algorithm reduces multiplications/additions by 5% for matrix product $XX^{t}$, outperforming SOTA, even for small matrices, using ML and combinatorial optimization.", "motivation": "To improve efficiency in computing matrix products by reducing computational overhead.", "method": "Combines Machine Learning-based search with Combinatorial Optimization to discover RXTX.", "result": "Achieves 5% fewer operations and faster performance, even for small matrices.", "conclusion": "RXTX is a more efficient algorithm for matrix product computations, leveraging ML and optimization."}}
{"id": "2505.10507", "pdf": "https://arxiv.org/pdf/2505.10507", "abs": "https://arxiv.org/abs/2505.10507", "authors": ["Benedikt Ebing", "Goran Glava\u0161"], "title": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Translation-based strategies for cross-lingual transfer XLT such as\ntranslate-train -- training on noisy target language data translated from the\nsource language -- and translate-test -- evaluating on noisy source language\ndata translated from the target language -- are competitive XLT baselines. In\nXLT for token classification tasks, however, these strategies include label\nprojection, the challenging step of mapping the labels from each token in the\noriginal sentence to its counterpart(s) in the translation. Although word\naligners (WAs) are commonly used for label projection, the low-level design\ndecisions for applying them to translation-based XLT have not been\nsystematically investigated. Moreover, recent marker-based methods, which\nproject labeled spans by inserting tags around them before (or after)\ntranslation, claim to outperform WAs in label projection for XLT. In this work,\nwe revisit WAs for label projection, systematically investigating the effects\nof low-level design decisions on token-level XLT: (i) the algorithm for\nprojecting labels between (multi-)token spans, (ii) filtering strategies to\nreduce the number of noisily mapped labels, and (iii) the pre-tokenization of\nthe translated sentences. We find that all of these substantially impact\ntranslation-based XLT performance and show that, with optimized choices, XLT\nwith WA offers performance at least comparable to that of marker-based methods.\nWe then introduce a new projection strategy that ensembles translate-train and\ntranslate-test predictions and demonstrate that it substantially outperforms\nthe marker-based projection. Crucially, we show that our proposed ensembling\nalso reduces sensitivity to low-level WA design choices, resulting in more\nrobust XLT for token classification tasks.", "AI": {"tldr": "The paper revisits word aligners (WAs) for label projection in cross-lingual transfer (XLT) for token classification, optimizing design choices and introducing an ensembling strategy that outperforms marker-based methods.", "motivation": "To systematically investigate the impact of low-level design decisions in word aligners for label projection in XLT and improve performance over existing methods.", "method": "Revisits WAs for label projection, examining (i) label projection algorithms, (ii) filtering strategies, and (iii) pre-tokenization. Introduces an ensembling strategy combining translate-train and translate-test predictions.", "result": "Optimized WAs perform comparably to marker-based methods. The proposed ensembling strategy outperforms marker-based projection and reduces sensitivity to WA design choices.", "conclusion": "With careful design, WAs are competitive for XLT, and ensembling enhances robustness in token classification tasks."}}
{"id": "2505.10289", "pdf": "https://arxiv.org/pdf/2505.10289", "abs": "https://arxiv.org/abs/2505.10289", "authors": ["Yue Wang", "Shuai Xu", "Xuelin Zhu", "Yicong Li"], "title": "MSCI: Addressing CLIP's Inherent Limitations for Compositional Zero-Shot Learning", "categories": ["cs.CV"], "comment": "9 pages, 5 figures", "summary": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen state-object\ncombinations by leveraging known combinations. Existing studies basically rely\non the cross-modal alignment capabilities of CLIP but tend to overlook its\nlimitations in capturing fine-grained local features, which arise from its\narchitectural and training paradigm. To address this issue, we propose a\nMulti-Stage Cross-modal Interaction (MSCI) model that effectively explores and\nutilizes intermediate-layer information from CLIP's visual encoder.\nSpecifically, we design two self-adaptive aggregators to extract local\ninformation from low-level visual features and integrate global information\nfrom high-level visual features, respectively. These key information are\nprogressively incorporated into textual representations through a\nstage-by-stage interaction mechanism, significantly enhancing the model's\nperception capability for fine-grained local visual information. Additionally,\nMSCI dynamically adjusts the attention weights between global and local visual\ninformation based on different combinations, as well as different elements\nwithin the same combination, allowing it to flexibly adapt to diverse\nscenarios. Experiments on three widely used datasets fully validate the\neffectiveness and superiority of the proposed model. Data and code are\navailable at https://github.com/ltpwy/MSCI.", "AI": {"tldr": "The paper proposes a Multi-Stage Cross-modal Interaction (MSCI) model to enhance fine-grained local feature capture in Compositional Zero-Shot Learning (CZSL), addressing limitations of CLIP.", "motivation": "Existing CZSL methods rely on CLIP but fail to capture fine-grained local features due to its architecture and training.", "method": "MSCI uses self-adaptive aggregators to extract and integrate local and global visual features, progressively interacting with textual representations.", "result": "Experiments on three datasets validate MSCI's effectiveness and superiority.", "conclusion": "MSCI improves fine-grained perception in CZSL by dynamically adjusting attention weights between global and local features."}}
{"id": "2505.10057", "pdf": "https://arxiv.org/pdf/2505.10057", "abs": "https://arxiv.org/abs/2505.10057", "authors": ["Tiancong Cheng", "Ying Zhang", "Yuxuan Liang", "Roger Zimmermann", "Zhiwen Yu", "Bin Guo"], "title": "JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation", "categories": ["cs.LG"], "comment": null, "summary": "Depth estimation and scene segmentation are two important tasks in\nintelligent transportation systems. A joint modeling of these two tasks will\nreduce the requirement for both the storage and training efforts. This work\nexplores how the multi-task distillation could be used to improve such unified\nmodeling. While existing solutions transfer multiple teachers' knowledge in a\nstatic way, we propose a self-adaptive distillation method that can dynamically\nadjust the knowledge amount from each teacher according to the student's\ncurrent learning ability. Furthermore, as multiple teachers exist, the\nstudent's gradient update direction in the distillation is more prone to be\nerroneous where knowledge forgetting may occur. To avoid this, we propose a\nknowledge trajectory to record the most essential information that a model has\nlearnt in the past, based on which a trajectory-based distillation loss is\ndesigned to guide the student to follow the learning curve similarly in a\ncost-effective way. We evaluate our method on multiple benchmarking datasets\nincluding Cityscapes and NYU-v2. Compared to the state-of-the-art solutions,\nour method achieves a clearly improvement. The code is provided in the\nsupplementary materials.", "AI": {"tldr": "A self-adaptive distillation method improves joint modeling of depth estimation and scene segmentation by dynamically adjusting teacher knowledge and using a knowledge trajectory to prevent errors.", "motivation": "Joint modeling reduces storage and training efforts for depth estimation and scene segmentation in intelligent transportation systems.", "method": "Proposes a self-adaptive distillation method to dynamically adjust teacher knowledge and a knowledge trajectory to guide learning.", "result": "Achieves clear improvement on datasets like Cityscapes and NYU-v2 compared to state-of-the-art solutions.", "conclusion": "The method effectively enhances unified modeling and learning efficiency, with code provided for further use."}}
{"id": "2505.09830", "pdf": "https://arxiv.org/pdf/2505.09830", "abs": "https://arxiv.org/abs/2505.09830", "authors": ["Mart\u00edn Rodr\u00edguez", "Gustavo Rossi", "Alejandro Fernandez"], "title": "Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values", "categories": ["cs.SE", "cs.AI"], "comment": "Under revision at Jornadas de Cloud Computing, Big Data & Emerging\n  Topics (JCC-BD&ET) - 2025", "summary": "The design and implementation of unit tests is a complex task many\nprogrammers neglect. This research evaluates the potential of Large Language\nModels (LLMs) in automatically generating test cases, comparing them with\nmanual tests. An optimized prompt was developed, that integrates code and\nrequirements, covering critical cases such as equivalence partitions and\nboundary values. The strengths and weaknesses of LLMs versus trained\nprogrammers were compared through quantitative metrics and manual qualitative\nanalysis. The results show that the effectiveness of LLMs depends on\nwell-designed prompts, robust implementation, and precise requirements.\nAlthough flexible and promising, LLMs still require human supervision. This\nwork highlights the importance of manual qualitative analysis as an essential\ncomplement to automation in unit test evaluation.", "AI": {"tldr": "LLMs can generate unit tests but need well-designed prompts and human oversight, complementing manual testing.", "motivation": "To explore LLMs' potential in automating unit test generation and compare their effectiveness with manual tests.", "method": "Developed an optimized prompt integrating code and requirements, evaluated LLMs vs. programmers using quantitative metrics and qualitative analysis.", "result": "LLMs are effective with good prompts and precise requirements but require human supervision.", "conclusion": "Manual qualitative analysis is essential alongside automation for robust unit test evaluation."}}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR.", "AI": {"tldr": "MuToR is a multi-token prediction method using learnable register tokens, offering compatibility with pretrained models and scalability, effective in fine-tuning and pretraining.", "motivation": "Improve multi-token prediction for language models, ensuring compatibility and scalability without architectural changes.", "method": "Interleaves learnable register tokens into input sequences for predicting future targets, adding minimal parameters.", "result": "Effective in supervised fine-tuning, PEFT, and pretraining across language and vision tasks.", "conclusion": "MuToR is a versatile and efficient approach for multi-token prediction, suitable for diverse applications."}}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model.", "AI": {"tldr": "StoryReasoning dataset improves visual storytelling by grounding characters and objects, reducing referential hallucinations by 12.3%.", "motivation": "Addressing issues of character identity inconsistency and referential hallucinations in visual storytelling.", "method": "Proposes StoryReasoning dataset with structured scene analyses, cross-frame object re-identification, chain-of-thought reasoning, and grounding schemes. Fine-tunes Qwen2.5-VL 7B for baseline performance.", "result": "Reduces hallucinations from 4.06 to 3.56 (-12.3%) per story compared to non-fine-tuned models.", "conclusion": "StoryReasoning effectively enhances consistency and reduces hallucinations in visual storytelling through structured grounding and reasoning."}}
{"id": "2505.10083", "pdf": "https://arxiv.org/pdf/2505.10083", "abs": "https://arxiv.org/abs/2505.10083", "authors": ["Chengsen Wang", "Qi Qi", "Zhongwen Rao", "Lujia Pan", "Jingyu Wang", "Jianxin Liao"], "title": "ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "Conventional forecasting methods rely on unimodal time series data, limiting\ntheir ability to exploit rich textual information. Recently, large language\nmodels (LLMs) and time series foundation models (TSFMs) have demonstrated\npowerful capability in textual reasoning and temporal modeling, respectively.\nIntegrating the strengths of both to construct a multimodal model that\nconcurrently leverages both temporal and textual information for future\ninference has emerged as a critical research challenge. To address the scarcity\nof event-series paired data, we propose a decoupled framework: an LLM is\nemployed to transform textual events into revision instructions, which are then\nused to steer the output of TSFM. To implement this framework, we introduce\nChronoSteer, a multimodal TSFM that can be steered through textual revision\ninstructions, effectively bridging LLM and TSFM. Moreover, to mitigate the\nshortage of cross-modal instruction-series paired data, we devise a two-stage\ntraining strategy based on synthetic data. In addition, we also construct a\nhigh-quality multimodal time series forecasting benchmark to address the\ninformation leakage concerns during evaluation. After integrating with an LLM,\nChronoSteer, which is trained exclusively on synthetic data, achieves a 25.7%\nimprovement in prediction accuracy compared to the unimodal backbone and a\n22.5% gain over the previous state-of-the-art multimodal method.", "AI": {"tldr": "The paper proposes ChronoSteer, a multimodal model integrating LLMs and TSFMs for improved forecasting by leveraging both textual and temporal data. It uses synthetic data for training and achieves significant accuracy gains.", "motivation": "Existing forecasting methods are limited by unimodal time series data, missing the potential of rich textual information. Combining LLMs (for textual reasoning) and TSFMs (for temporal modeling) can enhance forecasting.", "method": "A decoupled framework where an LLM transforms textual events into revision instructions to steer TSFM outputs. ChronoSteer is introduced as the multimodal TSFM, trained on synthetic data via a two-stage strategy.", "result": "ChronoSteer achieves a 25.7% accuracy improvement over unimodal baselines and 22.5% over prior multimodal methods.", "conclusion": "The integration of LLMs and TSFMs via ChronoSteer, trained on synthetic data, significantly enhances forecasting accuracy, addressing data scarcity and information leakage."}}
{"id": "2505.09868", "pdf": "https://arxiv.org/pdf/2505.09868", "abs": "https://arxiv.org/abs/2505.09868", "authors": ["Tin Trung Nguyen", "Jiannan Xu", "Phuong-Anh Nguyen-Le", "Jonathan Lazar", "Donald Braman", "Hal Daum\u00e9 III", "Zubin Jelveh"], "title": "Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Despite its U.S. constitutional foundation, the technical ``individual\nfairness'' criterion has not been operationalized in state or federal\nstatutes/regulations. We conduct a human subjects experiment to address this\ngap, evaluating which demographic features are relevant for individual fairness\nevaluation of recidivism risk assessment (RRA) tools. Our analyses conclude\nthat the individual similarity function should consider age and sex, but it\nshould ignore race.", "AI": {"tldr": "The paper explores the relevance of demographic features for individual fairness in recidivism risk assessment (RRA) tools, concluding that age and sex should be considered, while race should be ignored.", "motivation": "The study aims to operationalize the individual fairness criterion in RRA tools, which lacks clear guidelines in U.S. statutes/regulations.", "method": "A human subjects experiment is conducted to evaluate the relevance of demographic features (age, sex, race) for individual fairness.", "result": "Findings suggest that age and sex are relevant for individual fairness in RRA tools, but race should not be considered.", "conclusion": "The study provides actionable insights for designing fair RRA tools by prioritizing age and sex over race in individual fairness evaluations."}}
{"id": "2505.10527", "pdf": "https://arxiv.org/pdf/2505.10527", "abs": "https://arxiv.org/abs/2505.10527", "authors": ["Binghai Wang", "Runji Lin", "Keming Lu", "Le Yu", "Zhenru Zhang", "Fei Huang", "Chujie Zheng", "Kai Dang", "Yang Fan", "Xingzhang Ren", "An Yang", "Binyuan Hui", "Dayiheng Liu", "Tao Gui", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang", "Bowen Yu", "Jingren Zhou", "Junyang Lin"], "title": "WorldPM: Scaling Human Preference Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Motivated by scaling laws in language modeling that demonstrate how test loss\nscales as a power law with model and dataset sizes, we find that similar laws\nexist in preference modeling. We propose World Preference Modeling$ (WorldPM)\nto emphasize this scaling potential, where World Preference embodies a unified\nrepresentation of human preferences. In this paper, we collect preference data\nfrom public forums covering diverse user communities, and conduct extensive\ntraining using 15M-scale data across models ranging from 1.5B to 72B\nparameters. We observe distinct patterns across different evaluation metrics:\n(1) Adversarial metrics (ability to identify deceptive features) consistently\nscale up with increased training data and base model size; (2) Objective\nmetrics (objective knowledge with well-defined answers) show emergent behavior\nin larger language models, highlighting WorldPM's scalability potential; (3)\nSubjective metrics (subjective preferences from a limited number of humans or\nAI) do not demonstrate scaling trends. Further experiments validate the\neffectiveness of WorldPM as a foundation for preference fine-tuning. Through\nevaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly\nimproves the generalization performance across human preference datasets of\nvarying sizes (7K, 100K and 800K samples), with performance gains exceeding 5%\non many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we\nobserve significant improvements on both in-house and public evaluation sets,\nwith notable gains of 4% to 8% in our in-house evaluations.", "AI": {"tldr": "The paper explores scaling laws in preference modeling, proposing WorldPM to unify human preferences. It shows distinct scaling patterns across adversarial, objective, and subjective metrics, with WorldPM improving generalization in preference datasets and RLHF pipelines.", "motivation": "To investigate if scaling laws in language modeling apply to preference modeling, and to propose WorldPM as a unified representation of human preferences.", "method": "Collects preference data from public forums, trains models (1.5B to 72B parameters) on 15M-scale data, and evaluates using adversarial, objective, and subjective metrics.", "result": "Adversarial and objective metrics scale with data and model size, while subjective metrics do not. WorldPM improves generalization by over 5% on key subtasks and enhances RLHF pipelines by 4-8%.", "conclusion": "WorldPM demonstrates scalability and effectiveness in preference modeling, offering a foundation for fine-tuning and improving RLHF performance."}}
{"id": "2505.10294", "pdf": "https://arxiv.org/pdf/2505.10294", "abs": "https://arxiv.org/abs/2505.10294", "authors": ["Guillaume Balezo", "Roger Trullo", "Albert Pla Planas", "Etienne Decenciere", "Thomas Walter"], "title": "MIPHEI-ViT: Multiplex Immunofluorescence Prediction from H&E Images using ViT Foundation Models", "categories": ["cs.CV", "q-bio.TO", "68T07 (Primary), 92C55 (Secondary)", "I.4.9; I.2.10; I.5.4; J.3"], "comment": null, "summary": "Histopathological analysis is a cornerstone of cancer diagnosis, with\nHematoxylin and Eosin (H&E) staining routinely acquired for every patient to\nvisualize cell morphology and tissue architecture. On the other hand, multiplex\nimmunofluorescence (mIF) enables more precise cell type identification via\nproteomic markers, but has yet to achieve widespread clinical adoption due to\ncost and logistical constraints. To bridge this gap, we introduce MIPHEI\n(Multiplex Immunofluorescence Prediction from H&E), a U-Net-inspired\narchitecture that integrates state-of-the-art ViT foundation models as encoders\nto predict mIF signals from H&E images. MIPHEI targets a comprehensive panel of\nmarkers spanning nuclear content, immune lineages (T cells, B cells, myeloid),\nepithelium, stroma, vasculature, and proliferation. We train our model using\nthe publicly available ORION dataset of restained H&E and mIF images from\ncolorectal cancer tissue, and validate it on two independent datasets. MIPHEI\nachieves accurate cell-type classification from H&E alone, with F1 scores of\n0.88 for Pan-CK, 0.57 for CD3e, 0.56 for SMA, 0.36 for CD68, and 0.30 for CD20,\nsubstantially outperforming both a state-of-the-art baseline and a random\nclassifier for most markers. Our results indicate that our model effectively\ncaptures the complex relationships between nuclear morphologies in their tissue\ncontext, as visible in H&E images and molecular markers defining specific cell\ntypes. MIPHEI offers a promising step toward enabling cell-type-aware analysis\nof large-scale H&E datasets, in view of uncovering relationships between\nspatial cellular organization and patient outcomes.", "AI": {"tldr": "MIPHEI predicts multiplex immunofluorescence (mIF) signals from H&E images using a U-Net-inspired model with ViT encoders, achieving accurate cell-type classification and outperforming baselines.", "motivation": "Bridging the gap between widely used H&E staining and costly mIF by enabling cell-type identification from H&E alone.", "method": "Uses a U-Net-inspired architecture with ViT encoders, trained on the ORION dataset of colorectal cancer tissue, validated on two independent datasets.", "result": "Achieves F1 scores of 0.88 for Pan-CK, 0.57 for CD3e, 0.56 for SMA, 0.36 for CD68, and 0.30 for CD20, outperforming baselines.", "conclusion": "MIPHEI enables cell-type-aware analysis of H&E datasets, potentially uncovering spatial cellular organization's link to patient outcomes."}}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments.", "AI": {"tldr": "MiCo, a hierarchical LLM-driven framework, solves VM scheduling (ODMBP) with dynamic, adaptable heuristics, outperforming traditional methods with a 96.9% competitive ratio.", "motivation": "Traditional VM scheduling methods lack adaptability, heuristic rigidity, and learning-based generalizability. MiCo addresses these gaps using LLMs for dynamic, interpretable solutions.", "method": "MiCo formulates ODMBP as SMDP-Option, using a two-stage LLM-driven architecture (Option Miner for non-context-aware strategies, Option Composer for integrating contextual strategies).", "result": "Achieves 96.9% competitive ratio in large-scale (10,000+ VMs) and nonstationary scenarios, demonstrating robustness.", "conclusion": "MiCo effectively handles complex, large-scale VM scheduling, offering adaptability and high performance in dynamic cloud environments."}}
{"id": "2505.10554", "pdf": "https://arxiv.org/pdf/2505.10554", "abs": "https://arxiv.org/abs/2505.10554", "authors": ["Zhiyuan Hu", "Yibo Wang", "Hanze Dong", "Yuhui Xu", "Amrita Saha", "Caiming Xiong", "Bryan Hooi", "Junnan Li"], "title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models", "categories": ["cs.CL"], "comment": "In Progress", "summary": "Large reasoning models (LRMs) already possess a latent capacity for long\nchain-of-thought reasoning. Prior work has shown that outcome-based\nreinforcement learning (RL) can incidentally elicit advanced reasoning\nbehaviors such as self-correction, backtracking, and verification phenomena\noften referred to as the model's \"aha moment\". However, the timing and\nconsistency of these emergent behaviors remain unpredictable and\nuncontrollable, limiting the scalability and reliability of LRMs' reasoning\ncapabilities. To address these limitations, we move beyond reliance on prompts\nand coincidental \"aha moments\". Instead, we explicitly align models with three\nmeta-abilities: deduction, induction, and abduction, using automatically\ngenerated, self-verifiable tasks. Our three stage-pipeline individual\nalignment, parameter-space merging, and domain-specific reinforcement learning,\nboosting performance by over 10\\% relative to instruction-tuned baselines.\nFurthermore, domain-specific RL from the aligned checkpoint yields an\nadditional 2\\% average gain in the performance ceiling across math, coding, and\nscience benchmarks, demonstrating that explicit meta-ability alignment offers a\nscalable and dependable foundation for reasoning. Code is available at:\nhttps://github.com/zhiyuanhubj/Meta-Ability-Alignment", "AI": {"tldr": "The paper proposes a method to explicitly align large reasoning models (LRMs) with meta-abilities (deduction, induction, abduction) using self-verifiable tasks, improving reasoning reliability and scalability.", "motivation": "Current LRMs exhibit unpredictable emergent reasoning behaviors, limiting their reliability and scalability.", "method": "A three-stage pipeline: individual alignment, parameter-space merging, and domain-specific reinforcement learning.", "result": "Performance improved by over 10% relative to baselines, with an additional 2% gain from domain-specific RL.", "conclusion": "Explicit meta-ability alignment provides a scalable and dependable foundation for reasoning."}}
{"id": "2505.10351", "pdf": "https://arxiv.org/pdf/2505.10351", "abs": "https://arxiv.org/abs/2505.10351", "authors": ["Jie Zhu", "Jirong Zha", "Ding Li", "Leye Wang"], "title": "A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability", "categories": ["cs.CV"], "comment": "An extension of our ACM CCS2024 conference paper (arXiv:2404.02462).\n  We show the impacts of scaling from both data and model aspects on membership\n  inference for self-supervised visual encoders", "summary": "Self-supervised learning shows promise in harnessing extensive unlabeled\ndata, but it also confronts significant privacy concerns, especially in vision.\nIn this paper, we perform membership inference on visual self-supervised models\nin a more realistic setting: self-supervised training method and details are\nunknown for an adversary when attacking as he usually faces a black-box system\nin practice. In this setting, considering that self-supervised model could be\ntrained by completely different self-supervised paradigms, e.g., masked image\nmodeling and contrastive learning, with complex training details, we propose a\nunified membership inference method called PartCrop. It is motivated by the\nshared part-aware capability among models and stronger part response on the\ntraining data. Specifically, PartCrop crops parts of objects in an image to\nquery responses within the image in representation space. We conduct extensive\nattacks on self-supervised models with different training protocols and\nstructures using three widely used image datasets. The results verify the\neffectiveness and generalization of PartCrop. Moreover, to defend against\nPartCrop, we evaluate two common approaches, i.e., early stop and differential\nprivacy, and propose a tailored method called shrinking crop scale range. The\ndefense experiments indicate that all of them are effective. Finally, besides\nprototype testing on toy visual encoders and small-scale image datasets, we\nquantitatively study the impacts of scaling from both data and model aspects in\na realistic scenario and propose a scalable PartCrop-v2 by introducing two\nstructural improvements to PartCrop. Our code is at\nhttps://github.com/JiePKU/PartCrop.", "AI": {"tldr": "The paper introduces PartCrop, a unified membership inference method for self-supervised visual models, addressing privacy concerns in black-box settings. It demonstrates effectiveness across various training protocols and proposes defense strategies.", "motivation": "Privacy concerns in self-supervised learning, especially in vision, motivate the need for realistic black-box membership inference attacks.", "method": "Proposes PartCrop, which exploits part-aware capabilities in models by cropping object parts and analyzing representation space responses.", "result": "PartCrop proves effective and generalizable across different self-supervised models and datasets. Defense methods like early stop and differential privacy are also validated.", "conclusion": "PartCrop is a scalable and effective attack method, with PartCrop-v2 introduced for larger-scale scenarios. Defense strategies are also effective."}}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining.", "AI": {"tldr": "A novel method combines Graph Transformer with XGBoost-derived synthetic tasks for multitask molecular property prediction, outperforming single-task XGBoost without pretraining.", "motivation": "Integrating rule-based models into neural networks is challenging. Current methods need extensive pretraining or extra techniques for performance.", "method": "Joint training of a Graph Transformer on multitask molecular property targets and synthetic XGBoost-derived tasks.", "result": "Significant improvement in 16 out of 19 molecular property tasks, outperforming XGBoost.", "conclusion": "Synthetic task augmentation enhances neural model performance without feature injection or pretraining."}}
{"id": "2505.09974", "pdf": "https://arxiv.org/pdf/2505.09974", "abs": "https://arxiv.org/abs/2505.09974", "authors": ["Adel ElZemity", "Budi Arief", "Shujun Li"], "title": "Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. We present a systematic evaluation of safety risks in fine-tuned\nLLMs for cyber security applications. Using the OWASP Top 10 for LLM\nApplications framework, we assessed seven open-source LLMs: Phi 3 Mini 3.8B,\nMistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B.\nOur evaluation shows that fine-tuning reduces safety resilience across all\ntested LLMs (e.g., the safety score of Llama 3.1 8B against prompt injection\ndrops from 0.95 to 0.15). We propose and evaluate a safety alignment approach\nthat carefully rewords instruction-response pairs to include explicit safety\nprecautions and ethical considerations. This approach demonstrates that it is\npossible to maintain or even improve model safety while preserving technical\nutility, offering a practical path forward for developing safer fine-tuning\nmethodologies. This work offers a systematic evaluation for safety risks in\nLLMs, enabling safer adoption of generative AI in sensitive domains, and\ncontributing towards the development of secure, trustworthy, and ethically\naligned LLMs.", "AI": {"tldr": "The paper evaluates safety risks in fine-tuned LLMs for cybersecurity, showing reduced safety resilience post-fine-tuning. A safety alignment method is proposed to improve safety without compromising utility.", "motivation": "To address the dual opportunities and risks of integrating LLMs into cybersecurity, focusing on safety concerns like data leakage and malware generation.", "method": "Systematic evaluation using the OWASP Top 10 framework on seven open-source LLMs, followed by a proposed safety alignment approach rewording instruction-response pairs.", "result": "Fine-tuning reduces safety resilience (e.g., Llama 3.1 8B's safety score drops from 0.95 to 0.15). The alignment method improves safety while preserving utility.", "conclusion": "The work provides a path for safer LLM adoption in sensitive domains, contributing to secure and ethically aligned models."}}
{"id": "2505.09665", "pdf": "https://arxiv.org/pdf/2505.09665", "abs": "https://arxiv.org/abs/2505.09665", "authors": ["Sulong Zhou", "Qunying Huang", "Shaoheng Zhou", "Yun Hang", "Xinyue Ye", "Aodong Mei", "Kathryn Phung", "Yuning Ye", "Uma Govindswamy", "Zehan Li"], "title": "Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling", "categories": ["cs.SI", "cs.CL"], "comment": null, "summary": "Wildfires have become increasingly frequent, irregular, and severe in recent\nyears. Understanding how affected populations perceive and respond during\nwildfire crises is critical for timely and empathetic disaster response. Social\nmedia platforms offer a crowd-sourced channel to capture evolving public\ndiscourse, providing hyperlocal information and insight into public sentiment.\nThis study analyzes Reddit discourse during the 2025 Los Angeles wildfires,\nspanning from the onset of the disaster to full containment. We collect 385\nposts and 114,879 comments related to the Palisades and Eaton fires. We adopt\ntopic modeling methods to identify the latent topics, enhanced by large\nlanguage models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we\ndevelop a hierarchical framework to categorize latent topics, consisting of two\nmain categories, Situational Awareness (SA) and Crisis Narratives (CN). The\nvolume of SA category closely aligns with real-world fire progressions, peaking\nwithin the first 2-5 days as the fires reach the maximum extent. The most\nfrequent co-occurring category set of public health and safety, loss and\ndamage, and emergency resources expands on a wide range of health-related\nlatent topics, including environmental health, occupational health, and one\nhealth. Grief signals and mental health risks consistently accounted for 60\npercentage and 40 percentage of CN instances, respectively, with the highest\ntotal volume occurring at night. This study contributes the first annotated\nsocial media dataset on the 2025 LA fires, and introduces a scalable\nmulti-layer framework that leverages topic modeling for crisis discourse\nanalysis. By identifying persistent public health concerns, our results can\ninform more empathetic and adaptive strategies for disaster response, public\nhealth communication, and future research in comparable climate-related\ndisaster events.", "AI": {"tldr": "The study analyzes Reddit discourse during the 2025 LA wildfires using topic modeling and a hierarchical framework to categorize topics into Situational Awareness and Crisis Narratives, revealing public health concerns and mental health risks.", "motivation": "To understand public perception and response during wildfires for better disaster response and public health communication.", "method": "Collected 385 posts and 114,879 comments from Reddit, used topic modeling enhanced by LLMs and HITL, and developed a hierarchical framework for categorization.", "result": "Situational Awareness topics peaked early, while Crisis Narratives highlighted mental health risks (40%) and grief (60%). Public health concerns were prominent.", "conclusion": "The study provides a scalable framework for crisis discourse analysis and insights for empathetic disaster response and public health strategies."}}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer", "AI": {"tldr": "SpikeVideoFormer is an efficient spike-driven video Transformer with linear temporal complexity, outperforming SNN approaches and matching ANN-based methods with significant efficiency gains.", "motivation": "Existing SNN-based Transformers focus on single-image tasks, lacking efficiency in video tasks. This paper aims to leverage SNNs' energy efficiency for video-based vision tasks.", "method": "Introduces SpikeVideoFormer with spike-driven Hamming attention (SDHA) and analyzes spike-driven space-time attention designs for optimal performance.", "result": "Achieves SOTA performance in video tasks (classification, pose tracking, semantic segmentation) with 15%+ improvements and significant efficiency gains (up to 16x).", "conclusion": "SpikeVideoFormer effectively combines SNN efficiency with video task performance, matching ANN methods while being more energy-efficient."}}
{"id": "2505.10125", "pdf": "https://arxiv.org/pdf/2505.10125", "abs": "https://arxiv.org/abs/2505.10125", "authors": ["Wujun Zhou", "Shu Ding", "ZeLin Li", "Wei Wang"], "title": "Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning enables the clients to collaboratively train a global\nmodel, which is aggregated from local models. Due to the heterogeneous data\ndistributions over clients and data privacy in federated learning, it is\ndifficult to train local models to achieve a well-performed global model. In\nthis paper, we introduce the adaptability of local models, i.e., the average\nperformance of local models on data distributions over clients, and enhance the\nperformance of the global model by improving the adaptability of local models.\nSince each client does not know the data distributions over other clients, the\nadaptability of the local model cannot be directly optimized. First, we provide\nthe property of an appropriate local model which has good adaptability on the\ndata distributions over clients. Then, we formalize the property into the local\ntraining objective with a constraint and propose a feasible solution to train\nthe local model. Extensive experiments on federated learning benchmarks\ndemonstrate that our method significantly improves the adaptability of local\nmodels and achieves a well-performed global model that consistently outperforms\nthe baseline methods.", "AI": {"tldr": "The paper proposes enhancing federated learning by improving local model adaptability, leading to a better-performing global model.", "motivation": "Addressing challenges of heterogeneous data distributions and privacy in federated learning to improve global model performance.", "method": "Introduces adaptability of local models, formalizes it into a training objective with constraints, and provides a feasible solution.", "result": "Experiments show significant improvement in local model adaptability and global model performance over baselines.", "conclusion": "The method effectively enhances federated learning by optimizing local model adaptability."}}
{"id": "2505.09989", "pdf": "https://arxiv.org/pdf/2505.09989", "abs": "https://arxiv.org/abs/2505.09989", "authors": ["Tella Rajashekhar Reddy", "Palak", "Rohan Gandhi", "Anjaly Parayil", "Chaojie Zhang", "Mike Shepperd", "Liangcheng Yu", "Jayashree Mohan", "Srinivasan Iyengar", "Shivkumar Kalyanaraman", "Debopam Bhattacherjee"], "title": "AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron", "categories": ["cs.DC", "cs.AI", "cs.NI"], "comment": null, "summary": "AI power demand is growing unprecedentedly thanks to the high power density\nof AI compute and the emerging inferencing workload. On the supply side,\nabundant wind power is waiting for grid access in interconnection queues. In\nthis light, this paper argues bringing AI workload to modular compute clusters\nco-located in wind farms. Our deployment right-sizing strategy makes it\neconomically viable to deploy more than 6 million high-end GPUs today that\ncould consume cheap, green power at its source. We built Heron, a cross-site\nsoftware router, that could efficiently leverage the complementarity of power\ngeneration across wind farms by routing AI inferencing workload around power\ndrops. Using 1-week ofcoding and conversation production traces from Azure and\n(real) variable wind power traces, we show how Heron improves aggregate goodput\nof AI compute by up to 80% compared to the state-of-the-art.", "AI": {"tldr": "The paper proposes co-locating AI compute clusters in wind farms to utilize cheap, green wind power, introducing Heron, a software router that optimizes workload routing to improve AI compute efficiency by up to 80%.", "motivation": "The motivation is to address the growing power demand of AI workloads by leveraging abundant wind power, which is often stuck in grid queues, and to make AI compute more sustainable and cost-effective.", "method": "The method involves deploying modular AI compute clusters in wind farms and using Heron, a cross-site software router, to dynamically route AI inferencing workloads based on power availability across wind farms.", "result": "Results show Heron improves aggregate goodput of AI compute by up to 80% compared to existing solutions, using real-world wind power and workload traces.", "conclusion": "The conclusion is that co-locating AI compute with wind farms and using intelligent workload routing can significantly enhance efficiency and sustainability of AI workloads."}}
{"id": "2505.09777", "pdf": "https://arxiv.org/pdf/2505.09777", "abs": "https://arxiv.org/abs/2505.09777", "authors": ["Alejo Lopez-Avila", "Jinhua Du"], "title": "A Survey on Large Language Models in Multimodal Recommender Systems", "categories": ["cs.IR", "cs.CL"], "comment": "30 pages, 6 figures", "summary": "Multimodal recommender systems (MRS) integrate heterogeneous user and item\ndata, such as text, images, and structured information, to enhance\nrecommendation performance. The emergence of large language models (LLMs)\nintroduces new opportunities for MRS by enabling semantic reasoning, in-context\nlearning, and dynamic input handling. Compared to earlier pre-trained language\nmodels (PLMs), LLMs offer greater flexibility and generalisation capabilities\nbut also introduce challenges related to scalability and model accessibility.\nThis survey presents a comprehensive review of recent work at the intersection\nof LLMs and MRS, focusing on prompting strategies, fine-tuning methods, and\ndata adaptation techniques. We propose a novel taxonomy to characterise\nintegration patterns, identify transferable techniques from related\nrecommendation domains, provide an overview of evaluation metrics and datasets,\nand point to possible future directions. We aim to clarify the emerging role of\nLLMs in multimodal recommendation and support future research in this rapidly\nevolving field.", "AI": {"tldr": "A survey on integrating large language models (LLMs) into multimodal recommender systems (MRS), covering opportunities, challenges, and future directions.", "motivation": "To explore how LLMs can enhance MRS by leveraging their semantic reasoning and dynamic input handling capabilities, while addressing scalability and accessibility challenges.", "method": "Reviews recent work on LLMs and MRS, focusing on prompting, fine-tuning, and data adaptation. Proposes a taxonomy for integration patterns and identifies transferable techniques.", "result": "Provides a comprehensive overview of evaluation metrics, datasets, and integration strategies, highlighting the potential of LLMs in MRS.", "conclusion": "LLMs offer promising opportunities for MRS but require addressing scalability and accessibility. The survey aims to guide future research in this evolving field."}}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data .", "AI": {"tldr": "A novel unpaired training method for a learnable ISP eliminates the need for aligned data, using adversarial training and lightweight networks to achieve high fidelity.", "motivation": "Developing a learned ISP requires costly aligned data; this work aims to bypass this need.", "method": "Uses unpaired training with a multi-term loss function and adversarial training with multiple discriminators.", "result": "Achieves high fidelity on Zurich RAW to RGB and Fujifilm UltraISP datasets, comparable to paired methods.", "conclusion": "The unpaired approach shows strong potential, offering a practical solution for lightweight ISPs."}}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance.", "AI": {"tldr": "FedAPC improves FL model robustness under domain heterogeneity using prototype augmentation, outperforming SOTA baselines.", "motivation": "Address statistical heterogeneity in FL, particularly domain heterogeneity, to enhance global model convergence.", "method": "Introduces FedAPC, a prototype-based FL framework using augmented prototypes to diversify features and align local-global representations.", "result": "Outperforms SOTA baselines on Office-10 and Digits datasets, showing superior performance.", "conclusion": "FedAPC effectively mitigates domain heterogeneity in FL, improving model generalization and robustness."}}
{"id": "2505.10012", "pdf": "https://arxiv.org/pdf/2505.10012", "abs": "https://arxiv.org/abs/2505.10012", "authors": ["Tadashi Kadowaki"], "title": "Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering", "categories": ["quant-ph", "cs.AI"], "comment": "8 pages, 4 figures", "summary": "Recent advances in artificial intelligence (AI) and quantum computing are\naccelerating automation in scientific and engineering processes, fundamentally\nreshaping research methodologies. This perspective highlights parallels between\nscientific automation and established Computer-Aided Engineering (CAE)\npractices, introducing Quantum CAE as a framework that leverages quantum\nalgorithms for simulation, optimization, and machine learning within\nengineering design. Practical implementations of Quantum CAE are illustrated\nthrough case studies for combinatorial optimization problems. Further\ndiscussions include advancements toward higher automation levels, highlighting\nthe critical role of specialized AI agents proficient in quantum algorithm\ndesign. The integration of quantum computing with AI raises significant\nquestions about the collaborative dynamics among human scientists and\nengineers, AI systems, and quantum computational resources, underscoring a\ntransformative future for automated discovery and innovation.", "AI": {"tldr": "The paper introduces Quantum CAE, a framework combining quantum computing and AI for engineering automation, with case studies on optimization problems.", "motivation": "To explore the integration of quantum computing and AI in automating scientific and engineering processes, inspired by parallels with traditional CAE.", "method": "Proposes Quantum CAE, leveraging quantum algorithms for simulation, optimization, and machine learning, demonstrated via case studies.", "result": "Illustrates practical applications of Quantum CAE in combinatorial optimization, emphasizing AI agents' role in quantum algorithm design.", "conclusion": "Highlights transformative potential of AI-quantum collaboration in automated discovery, raising questions about human-AI-quantum dynamics."}}
{"id": "2505.09921", "pdf": "https://arxiv.org/pdf/2505.09921", "abs": "https://arxiv.org/abs/2505.09921", "authors": ["Yidan Wang", "Yanan Cao", "Yubing Ren", "Fang Fang", "Zheng Lin", "Binxing Fang"], "title": "PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel in various domains but pose inherent\nprivacy risks. Existing methods to evaluate privacy leakage in LLMs often use\nmemorized prefixes or simple instructions to extract data, both of which\nwell-alignment models can easily block. Meanwhile, Jailbreak attacks bypass LLM\nsafety mechanisms to generate harmful content, but their role in privacy\nscenarios remains underexplored. In this paper, we examine the effectiveness of\njailbreak attacks in extracting sensitive information, bridging privacy leakage\nand jailbreak attacks in LLMs. Moreover, we propose PIG, a novel framework\ntargeting Personally Identifiable Information (PII) and addressing the\nlimitations of current jailbreak methods. Specifically, PIG identifies PII\nentities and their types in privacy queries, uses in-context learning to build\na privacy context, and iteratively updates it with three gradient-based\nstrategies to elicit target PII. We evaluate PIG and existing jailbreak methods\nusing two privacy-related datasets. Experiments on four white-box and two\nblack-box LLMs show that PIG outperforms baseline methods and achieves\nstate-of-the-art (SoTA) results. The results underscore significant privacy\nrisks in LLMs, emphasizing the need for stronger safeguards. Our code is\navailble at\n\\href{https://github.com/redwyd/PrivacyJailbreak}{https://github.com/redwyd/PrivacyJailbreak}.", "AI": {"tldr": "The paper explores jailbreak attacks for extracting sensitive data from LLMs, introduces PIG for PII extraction, and demonstrates its superiority over existing methods.", "motivation": "To address underexplored privacy risks in LLMs by leveraging jailbreak attacks and proposing a novel framework for PII extraction.", "method": "Proposes PIG, which identifies PII entities, uses in-context learning, and employs gradient-based strategies to extract sensitive data.", "result": "PIG outperforms baselines on white-box and black-box LLMs, achieving SoTA results.", "conclusion": "Highlights significant privacy risks in LLMs and the need for stronger safeguards."}}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate.", "AI": {"tldr": "The paper evaluates how well vision language models (VLMs) understand visuospatial properties in images by testing their ability to process virtual objects not depicted in the scene.", "motivation": "To assess VLMs' scene comprehension beyond visual input, focusing on their ability to reason about virtual objects.", "method": "Systematic evaluations of state-of-the-art VLMs using prompts involving virtual objects to test spatial reasoning.", "result": "VLMs perform inadequately in processing virtual objects and understanding spatial relations.", "conclusion": "Current VLMs lack robust comprehension of visuospatial properties when dealing with virtual objects."}}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology.", "AI": {"tldr": "The paper introduces QuXAI, a framework for explaining hybrid quantum-classical ML models, addressing the lack of explainability in HQML systems.", "motivation": "The complexity of HQML models leads to black-box behavior, undermining transparency and reliability. Existing XAI methods are insufficient for HQML architectures.", "method": "QuXAI uses Q-MEDLEY, an explainer combining feature-based inferences and visualization to analyze quantum feature maps and classical learning.", "result": "Q-MEDLEY identifies influential classical aspects, separates noise, and performs comparably to classical XAI techniques. Ablation studies highlight its composite structure.", "conclusion": "QuXAI enhances interpretability and reliability of HQML models, promoting safer and more responsible use of quantum-enhanced AI."}}
{"id": "2505.10043", "pdf": "https://arxiv.org/pdf/2505.10043", "abs": "https://arxiv.org/abs/2505.10043", "authors": ["Yifan Wu", "Lutao Yan", "Yizhang Zhu", "Yinan Mei", "Jiannan Wang", "Nan Tang", "Yuyu Luo"], "title": "Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Charts are crucial for data analysis and decision-making.Text-to-chart\nretrieval systems have become increasingly important for Business Intelligence\n(BI), where users need to find relevant charts that match their analytical\nneeds. These needs can be categorized into precise queries that are\nwell-specified and fuzzy queries that are more exploratory -- both require\nunderstanding the semantics and context of the charts. However, existing\ntext-to-chart retrieval solutions often fail to capture the semantic content\nand contextual information of charts, primarily due to the lack of\ncomprehensive metadata (or semantic insights). To address this limitation, we\npropose a training data development pipeline that automatically synthesizes\nhierarchical semantic insights for charts, covering visual patterns\n(visual-oriented), statistical properties (statistics-oriented), and practical\napplications (task-oriented), which produces 207,498 semantic insights for\n69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to\nlearn better representations of charts for text-to-chart retrieval. Our method\nleverages rich semantic insights during the training phase to develop a model\nthat understands both visual and semantic aspects of charts.To evaluate\ntext-to-chart retrieval performance, we curate the first benchmark, CRBench,\nfor this task with 21,862 charts and 326 text queries from real-world BI\napplications, with ground-truth labels verified by the crowd\nworkers.Experiments show that ChartFinder significantly outperforms existing\nmethods in text-to-chart retrieval tasks across various settings. For precise\nqueries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than\nstate-of-the-art models. In fuzzy query tasks, our method also demonstrates\nconsistent improvements, with an average increase of 5% across nearly all\nmetrics.", "AI": {"tldr": "The paper proposes ChartFinder, a CLIP-based model for text-to-chart retrieval, leveraging hierarchical semantic insights to improve performance. It introduces a benchmark (CRBench) and shows significant improvements over existing methods.", "motivation": "Existing text-to-chart retrieval systems lack semantic and contextual understanding of charts due to insufficient metadata. The paper aims to address this gap.", "method": "A training data pipeline synthesizes hierarchical semantic insights (visual, statistical, task-oriented) for charts. ChartFinder, a CLIP-based model, is trained using these insights.", "result": "ChartFinder outperforms state-of-the-art models, achieving 66.9% NDCG@10 for precise queries (11.58% improvement) and 5% average improvement for fuzzy queries.", "conclusion": "The proposed method enhances text-to-chart retrieval by incorporating rich semantic insights, validated by the CRBench benchmark."}}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism.", "AI": {"tldr": "ComplexFormer introduces Complex Multi-Head Attention (CMHA) to unify semantic and positional differences in the complex plane, improving flexibility and performance in Transformer models.", "motivation": "Address limitations of prior methods in integrating positional information and semantic differences in multi-head attention, which often apply uniform adjustments or model them disparately.", "method": "Proposes CMHA with per-head Euler transformation and adaptive differential rotation to model semantic and positional differences as complex plane operations.", "result": "Outperforms baselines in language tasks, showing lower perplexity, better long-context coherence, and parameter efficiency.", "conclusion": "ComplexFormer offers a more expressive and adaptable attention mechanism, enhancing Transformer performance."}}
{"id": "2505.10473", "pdf": "https://arxiv.org/pdf/2505.10473", "abs": "https://arxiv.org/abs/2505.10473", "authors": ["Fengdi Zhang", "Hongkun Cao", "Ruqi Huang"], "title": "Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks\nto minimize the number of Gaussians used while preserving high rendering\nquality, introducing an inherent trade-off between Gaussian quantity and\nrendering quality. Existing methods strive for better quantity-quality\nperformance, but lack the ability for users to intuitively adjust this\ntrade-off to suit practical needs such as model deployment under diverse\nhardware and communication constraints. Here, we present ControlGS, a 3DGS\noptimization method that achieves semantically meaningful and cross-scene\nconsistent quantity-quality control while maintaining strong quantity-quality\nperformance. Through a single training run using a fixed setup and a\nuser-specified hyperparameter reflecting quantity-quality preference, ControlGS\ncan automatically find desirable quantity-quality trade-off points across\ndiverse scenes, from compact objects to large outdoor scenes. It also\noutperforms baselines by achieving higher rendering quality with fewer\nGaussians, and supports a broad adjustment range with stepless control over the\ntrade-off.", "AI": {"tldr": "ControlGS optimizes 3D Gaussian splatting (3DGS) to allow intuitive trade-off adjustment between Gaussian quantity and rendering quality, outperforming baselines with fewer Gaussians and broader control.", "motivation": "Existing 3DGS methods lack user-adjustable trade-offs for practical needs like hardware constraints. ControlGS addresses this gap.", "method": "ControlGS uses a single training run with a user-specified hyperparameter to automatically find optimal quantity-quality trade-offs across diverse scenes.", "result": "It achieves higher rendering quality with fewer Gaussians and supports stepless trade-off adjustment.", "conclusion": "ControlGS provides a flexible, high-performance solution for 3DGS optimization, suitable for diverse practical applications."}}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling.", "AI": {"tldr": "Alinear is an ultra-lightweight time series forecasting model that achieves competitive performance with minimal parameters, challenging the need for large-scale models.", "motivation": "To question the necessity of scaling laws in time series forecasting and propose a more efficient alternative to large models.", "method": "Introduces a horizon-aware adaptive decomposition mechanism and progressive frequency attenuation strategy for stable predictions without attention mechanisms.", "result": "Outperforms large models on seven benchmarks using <1% of their parameters, with strong accuracy across all forecast horizons.", "conclusion": "Challenges the belief that larger models are better and advocates for efficient, adaptive designs in time series forecasting."}}
{"id": "2505.10073", "pdf": "https://arxiv.org/pdf/2505.10073", "abs": "https://arxiv.org/abs/2505.10073", "authors": ["Rathin Chandra Shit", "Sharmila Subudhi"], "title": "Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering", "categories": ["cs.RO", "cs.AI"], "comment": "5 pages, 4 figures, Scheduled for presentation at an upcoming\n  conference", "summary": "In this paper, a novel framework is presented that achieves a combined\nsolution based on Multi-Robot Task Allocation (MRTA) and collision avoidance\nwith respect to homogeneous measurement tasks taking place in industrial\nenvironments. The spatial clustering we propose offers to simultaneously solve\nthe task allocation problem and deal with collision risks by cutting the\nworkspace into distinguishable operational zones for each robot. To divide task\nsites and to schedule robot routes within corresponding clusters, we use\nK-means clustering and the 2-Opt algorithm. The presented framework shows\nsatisfactory performance, where up to 93\\% time reduction (1.24s against\n17.62s) with a solution quality improvement of up to 7\\% compared to the best\nperforming method is demonstrated. Our method also completely eliminates\ncollision points that persist in comparative methods in a most significant\nsense. Theoretical analysis agrees with the claim that spatial partitioning\nunifies the apparently disjoint tasks allocation and collision avoidance\nproblems under conditions of many identical tasks to be distributed over sparse\ngeographical areas. Ultimately, the findings in this work are of substantial\nimportance for real world applications where both computational efficiency and\noperation free from collisions is of paramount importance.", "AI": {"tldr": "A novel framework combines MRTA and collision avoidance for industrial tasks using spatial clustering, achieving 93% time reduction and 7% quality improvement while eliminating collisions.", "motivation": "Address the dual challenge of task allocation and collision avoidance in industrial multi-robot systems with identical tasks in sparse areas.", "method": "Uses K-means clustering for spatial partitioning and the 2-Opt algorithm for route scheduling within clusters.", "result": "Achieves 93% time reduction (1.24s vs. 17.62s), 7% solution quality improvement, and eliminates collision points.", "conclusion": "Spatial partitioning unifies task allocation and collision avoidance, proving vital for efficient, collision-free industrial operations."}}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters.", "AI": {"tldr": "The paper explores the neural scaling law in LLMs, attributing it to representation superposition and feature frequency, validated by toy models and real LLM analysis.", "motivation": "To understand why larger LLMs perform better, focusing on the unclear origin of neural scaling laws.", "method": "Constructed a toy model based on superposition and feature frequency, analyzed real LLMs, and compared with Chinchilla scaling law.", "result": "Weak superposition scales loss with feature frequency; strong superposition scales loss inversely with model dimension, matching real LLM behavior.", "conclusion": "Representation superposition is key to neural scaling laws, suggesting potential for improved training and architectures."}}
{"id": "2505.10481", "pdf": "https://arxiv.org/pdf/2505.10481", "abs": "https://arxiv.org/abs/2505.10481", "authors": ["Ilya Ovodov", "Petr Surovtsev", "Karina Kvanchiani", "Alexander Kapitanov", "Alexander Nagaev"], "title": "Logos as a Well-Tempered Pre-train for Sign Language Recognition", "categories": ["cs.CV"], "comment": null, "summary": "This paper examines two aspects of the isolated sign language recognition\n(ISLR) task. First, despite the availability of a number of datasets, the\namount of data for most individual sign languages is limited. It poses the\nchallenge of cross-language ISLR model training, including transfer learning.\nSecond, similar signs can have different semantic meanings. It leads to\nambiguity in dataset labeling and raises the question of the best policy for\nannotating such signs. To address these issues, this study presents Logos, a\nnovel Russian Sign Language (RSL) dataset, the most extensive ISLR dataset by\nthe number of signers and one of the largest available datasets while also the\nlargest RSL dataset in size and vocabulary. It is shown that a model,\npre-trained on the Logos dataset can be used as a universal encoder for other\nlanguage SLR tasks, including few-shot learning. We explore cross-language\ntransfer learning approaches and find that joint training using multiple\nclassification heads benefits accuracy for the target lowresource datasets the\nmost. The key feature of the Logos dataset is explicitly annotated visually\nsimilar sign groups. We show that explicitly labeling visually similar signs\nimproves trained model quality as a visual encoder for downstream tasks. Based\non the proposed contributions, we outperform current state-of-the-art results\nfor the WLASL dataset and get competitive results for the AUTSL dataset, with a\nsingle stream model processing solely RGB video. The source code, dataset, and\npre-trained models are publicly available.", "AI": {"tldr": "The paper introduces Logos, a large Russian Sign Language dataset, addressing data scarcity and labeling ambiguity in isolated sign language recognition (ISLR). It demonstrates cross-language transfer learning and improved model accuracy through explicit annotation of visually similar signs.", "motivation": "The study aims to tackle the challenges of limited data for individual sign languages and ambiguity in labeling similar signs with different meanings.", "method": "The paper presents the Logos dataset, explores cross-language transfer learning, and uses joint training with multiple classification heads. It also annotates visually similar sign groups explicitly.", "result": "Pre-training on Logos improves model performance for other language SLR tasks, achieving state-of-the-art results on WLASL and competitive results on AUTSL.", "conclusion": "The Logos dataset and proposed methods enhance ISLR model accuracy and generalizability, with publicly available resources for further research."}}
{"id": "2505.10192", "pdf": "https://arxiv.org/pdf/2505.10192", "abs": "https://arxiv.org/abs/2505.10192", "authors": ["Prashant P. Shinde", "Priyadarshini P. Pai", "Shashishekar P. Adiga", "K. Subramanya Mayya", "Yongbeom Seo", "Myungsoo Hwang", "Heeyoung Go", "Changmin Park"], "title": "Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "In the photolithographic process vital to semiconductor manufacturing,\nvarious types of defects appear during EUV pattering. Due to ever-shrinking\npattern size, these defects are extremely small and cause false or missed\ndetection during inspection. Specifically, the lack of defect-annotated quality\ndata with good representation of smaller defects has prohibited deployment of\ndeep learning based defect detection models in fabrication lines. To resolve\nthe problem of data unavailability, we artificially generate scanning electron\nmicroscopy (SEM) images of line patterns with known distribution of defects and\nautonomously annotate them. We then employ state-of-the-art object detection\nmodels to investigate defect detection performance as a function of defect\nsize, much smaller than the pitch width. We find that the real-time object\ndetector YOLOv8 has the best mean average precision of 96% as compared to\nEfficientNet, 83%, and SSD, 77%, with the ability to detect smaller defects. We\nreport the smallest defect size that can be detected reliably. When tested on\nreal SEM data, the YOLOv8 model correctly detected 84.6% of Bridge defects and\n78.3% of Break defects across all relevant instances. These promising results\nsuggest that synthetic data can be used as an alternative to real-world data in\norder to develop robust machine-learning models.", "AI": {"tldr": "The paper addresses the challenge of detecting extremely small defects in EUV photolithography for semiconductor manufacturing by generating synthetic SEM images with annotated defects. YOLOv8 outperforms other models in detecting these defects, demonstrating the viability of synthetic data for training robust ML models.", "motivation": "The lack of defect-annotated data for small defects in semiconductor manufacturing hinders the deployment of deep learning models. Synthetic data generation is proposed as a solution.", "method": "Artificially generated SEM images of line patterns with known defects are used to train object detection models (YOLOv8, EfficientNet, SSD). Performance is evaluated based on defect size.", "result": "YOLOv8 achieves 96% mean average precision, outperforming EfficientNet (83%) and SSD (77%). It reliably detects smaller defects and performs well on real SEM data (84.6% for Bridge, 78.3% for Break defects).", "conclusion": "Synthetic data is a viable alternative to real-world data for training robust defect detection models in semiconductor manufacturing."}}
{"id": "2505.10105", "pdf": "https://arxiv.org/pdf/2505.10105", "abs": "https://arxiv.org/abs/2505.10105", "authors": ["Zibin Dong", "Fei Ni", "Yifu Yuan", "Yinchuan Li", "Jianye Hao"], "title": "EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We present EmbodiedMAE, a unified 3D multi-modal representation for robot\nmanipulation. Current approaches suffer from significant domain gaps between\ntraining datasets and robot manipulation tasks, while also lacking model\narchitectures that can effectively incorporate 3D information. To overcome\nthese limitations, we enhance the DROID dataset with high-quality depth maps\nand point clouds, constructing DROID-3D as a valuable supplement for 3D\nembodied vision research. Then we develop EmbodiedMAE, a multi-modal masked\nautoencoder that simultaneously learns representations across RGB, depth, and\npoint cloud modalities through stochastic masking and cross-modal fusion.\nTrained on DROID-3D, EmbodiedMAE consistently outperforms state-of-the-art\nvision foundation models (VFMs) in both training efficiency and final\nperformance across 70 simulation tasks and 20 real-world robot manipulation\ntasks on two robot platforms. The model exhibits strong scaling behavior with\nsize and promotes effective policy learning from 3D inputs. Experimental\nresults establish EmbodiedMAE as a reliable unified 3D multi-modal VFM for\nembodied AI systems, particularly in precise tabletop manipulation settings\nwhere spatial perception is critical.", "AI": {"tldr": "EmbodiedMAE is a 3D multi-modal representation model for robot manipulation, outperforming state-of-the-art vision foundation models in efficiency and performance across simulation and real-world tasks.", "motivation": "Addressing domain gaps and lack of effective 3D integration in current robot manipulation models.", "method": "Enhanced DROID dataset with depth maps and point clouds (DROID-3D), developed EmbodiedMAE for multi-modal learning via masking and fusion.", "result": "Outperforms existing models in 70 simulation and 20 real-world tasks, showing strong scaling and policy learning.", "conclusion": "EmbodiedMAE is a reliable 3D multi-modal foundation model for embodied AI, especially in spatial-critical tasks."}}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning.", "AI": {"tldr": "ParScale introduces parallel scaling, a method to efficiently scale language models by increasing parallel computation during training and inference, reducing memory and latency costs compared to traditional scaling methods.", "motivation": "To address the inefficiency of traditional scaling methods (parameter or inference-time scaling) by leveraging parallel computation.", "method": "Applies $P$ diverse transformations to input, executes parallel forward passes, and dynamically aggregates outputs, reusing existing parameters.", "result": "ParScale achieves performance improvements with 22x less memory and 6x less latency than parameter scaling, and can adapt pre-trained models with minimal post-training.", "conclusion": "ParScale offers a cost-effective scaling alternative, enabling powerful models in low-resource scenarios and redefining computation's role in ML."}}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values.", "AI": {"tldr": "UniEval is introduced as the first unified evaluation framework for multimodal models, addressing limitations of current benchmarks with a holistic approach (UniBench) and a new metric (UniScore).", "motivation": "Current evaluation methods for unified multimodal models lack simplicity, diversity, and accuracy, often relying on extra resources or limited metrics.", "method": "UniEval includes UniBench (a diverse benchmark) and UniScore (a metric aligning with human judgment), eliminating the need for extra models or annotations.", "result": "UniBench proves more challenging than existing benchmarks, and UniScore outperforms current metrics in alignment with human evaluations.", "conclusion": "UniEval provides a streamlined, accurate, and resource-efficient evaluation framework for unified multimodal models, revealing new insights into their capabilities."}}
{"id": "2505.10198", "pdf": "https://arxiv.org/pdf/2505.10198", "abs": "https://arxiv.org/abs/2505.10198", "authors": ["Mariano Ferrero", "Jos\u00e9 Omar Chelotti", "Luciano Sebasti\u00e1n Martinez-Rau", "Leandro Vignolo", "Mart\u00edn Pires", "Julio Ricardo Galli", "Leonardo Luis Giovanini", "Hugo Leonardo Rufiner"], "title": "A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals", "categories": ["cs.LG"], "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence", "summary": "Monitoring feeding behaviour is a relevant task for efficient herd management\nand the effective use of available resources in grazing cattle. The ability to\nautomatically recognise animals' feeding activities through the identification\nof specific jaw movements allows for the improvement of diet formulation, as\nwell as early detection of metabolic problems and symptoms of animal\ndiscomfort, among other benefits. The use of sensors to obtain signals for such\nmonitoring has become popular in the last two decades. The most frequently\nemployed sensors include accelerometers, microphones, and cameras, each with\nits own set of advantages and drawbacks. An unexplored aspect is the\nsimultaneous use of multiple sensors with the aim of combining signals in order\nto enhance the precision of the estimations. In this direction, this work\nintroduces a deep neural network based on the fusion of acoustic and inertial\nsignals, composed of convolutional, recurrent, and dense layers. The main\nadvantage of this model is the combination of signals through the automatic\nextraction of features independently from each of them. The model has emerged\nfrom an exploration and comparison of different neural network architectures\nproposed in this work, which carry out information fusion at different levels.\nFeature-level fusion has outperformed data and decision-level fusion by at\nleast a 0.14 based on the F1-score metric. Moreover, a comparison with\nstate-of-the-art machine learning methods is presented, including traditional\nand deep learning approaches. The proposed model yielded an F1-score value of\n0.802, representing a 14% increase compared to previous methods. Finally,\nresults from an ablation study and post-training quantization evaluation are\nalso reported.", "AI": {"tldr": "A deep neural network fusing acoustic and inertial signals improves feeding behavior monitoring in cattle, outperforming traditional methods by 14% in F1-score.", "motivation": "Automating feeding behavior monitoring in grazing cattle enhances diet formulation and early detection of metabolic issues, but existing sensor-based methods lack multi-sensor fusion for precision.", "method": "Proposes a deep neural network combining convolutional, recurrent, and dense layers to fuse acoustic and inertial signals, exploring feature-level fusion for better performance.", "result": "The model achieved an F1-score of 0.802, a 14% improvement over prior methods, with feature-level fusion outperforming data and decision-level fusion.", "conclusion": "Multi-sensor fusion via deep learning significantly enhances feeding behavior monitoring, offering practical benefits for herd management."}}
{"id": "2505.10134", "pdf": "https://arxiv.org/pdf/2505.10134", "abs": "https://arxiv.org/abs/2505.10134", "authors": ["Guangjin Pan", "Kaixuan Huang", "Hui Chen", "Shunqing Zhang", "Christian H\u00e4ger", "Henk Wymeersch"], "title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "13 pages,16 figures.This work has been submitted to the IEEE for\n  possible publication", "summary": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization.", "AI": {"tldr": "The paper proposes a foundation-model-based solution, LWLM, for wireless localization using self-supervised learning (SSL) to overcome data limitations and improve generalization.", "motivation": "Accurate localization is crucial for 5G/6G applications, but existing data-driven models struggle with generalization and require large labeled datasets.", "method": "The LWLM uses SSL with three objectives: SF-MCM, DTI, and PICL, to capture wireless channel semantics. Lightweight decoders are designed for downstream tasks like ToA and AoA estimation.", "result": "LWLM outperforms baselines, showing 26.0%--87.5% improvement over non-pretrained transformers and strong generalization in label-limited scenarios.", "conclusion": "LWLM is a promising foundation model for wireless localization, addressing data and generalization challenges."}}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks.", "AI": {"tldr": "The paper introduces a router-based architecture for generating high-quality synthetic data to fine-tune LLMs for function calling tasks, improving accuracy and performance over traditional methods.", "motivation": "The lack of real-world task-specific data and privacy constraints necessitate synthetic data generation, but existing methods fail in diversity and complexity.", "method": "A novel router-based architecture uses domain resources (metadata, knowledge graphs) and text/vision-to-text models to generate synthetic data matching real-world distributions.", "result": "Evaluation shows significant improvements in function classification and API parameter selection, with models outperforming traditional approaches.", "conclusion": "The proposed method sets new benchmarks for function calling tasks by addressing limitations of synthetic data generation."}}
{"id": "2505.10496", "pdf": "https://arxiv.org/pdf/2505.10496", "abs": "https://arxiv.org/abs/2505.10496", "authors": ["Raman Dutt", "Pedro Sanchez", "Yongchen Yao", "Steven McDonagh", "Sotirios A. Tsaftaris", "Timothy Hospedales"], "title": "CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs", "categories": ["cs.CV"], "comment": null, "summary": "We introduce CheXGenBench, a rigorous and multifaceted evaluation framework\nfor synthetic chest radiograph generation that simultaneously assesses\nfidelity, privacy risks, and clinical utility across state-of-the-art\ntext-to-image generative models. Despite rapid advancements in generative AI\nfor real-world imagery, medical domain evaluations have been hindered by\nmethodological inconsistencies, outdated architectural comparisons, and\ndisconnected assessment criteria that rarely address the practical clinical\nvalue of synthetic samples. CheXGenBench overcomes these limitations through\nstandardised data partitioning and a unified evaluation protocol comprising\nover 20 quantitative metrics that systematically analyse generation quality,\npotential privacy vulnerabilities, and downstream clinical applicability across\n11 leading text-to-image architectures. Our results reveal critical\ninefficiencies in the existing evaluation protocols, particularly in assessing\ngenerative fidelity, leading to inconsistent and uninformative comparisons. Our\nframework establishes a standardised benchmark for the medical AI community,\nenabling objective and reproducible comparisons while facilitating seamless\nintegration of both existing and future generative models. Additionally, we\nrelease a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K\nradiographs generated by the top-performing model (Sana 0.6B) in our benchmark\nto support further research in this critical domain. Through CheXGenBench, we\nestablish a new state-of-the-art and release our framework, models, and\nSynthCheX-75K dataset at https://raman1121.github.io/CheXGenBench/", "AI": {"tldr": "CheXGenBench is a standardized evaluation framework for synthetic chest radiograph generation, assessing fidelity, privacy, and clinical utility across 11 text-to-image models, revealing inefficiencies in current protocols.", "motivation": "Existing evaluations for synthetic medical images lack consistency, outdated comparisons, and clinical relevance, hindering progress in generative AI for healthcare.", "method": "CheXGenBench uses standardized data partitioning and 20+ metrics to evaluate generation quality, privacy risks, and clinical applicability.", "result": "The framework identifies flaws in current evaluation protocols and provides a benchmark, along with a synthetic dataset (SynthCheX-75K).", "conclusion": "CheXGenBench sets a new standard for reproducible comparisons in medical AI and releases resources to advance research."}}
{"id": "2505.10213", "pdf": "https://arxiv.org/pdf/2505.10213", "abs": "https://arxiv.org/abs/2505.10213", "authors": ["Mohammadmahdi Ghasemloo", "Alireza Moradi"], "title": "Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs), there is a\ngrowing need to establish best practices for leveraging their capabilities\nbeyond traditional natural language tasks. In this paper, a novel cross-domain\nknowledge transfer framework is proposed to enhance the performance of LLMs in\ntime series forecasting -- a task of increasing relevance in fields such as\nenergy systems, finance, and healthcare. The approach systematically infuses\nLLMs with structured temporal information to improve their forecasting\naccuracy. This study evaluates the proposed method on a real-world time series\ndataset and compares it to a naive baseline where the LLM receives no auxiliary\ninformation. Results show that knowledge-informed forecasting significantly\noutperforms the uninformed baseline in terms of predictive accuracy and\ngeneralization. These findings highlight the potential of knowledge transfer\nstrategies to bridge the gap between LLMs and domain-specific forecasting\ntasks.", "AI": {"tldr": "A novel framework enhances LLMs for time series forecasting by transferring cross-domain knowledge, outperforming uninformed baselines.", "motivation": "To improve LLM performance in time series forecasting, addressing gaps in domain-specific tasks.", "method": "Proposes a cross-domain knowledge transfer framework, infusing LLMs with structured temporal information.", "result": "Knowledge-informed forecasting significantly outperforms uninformed baselines in accuracy and generalization.", "conclusion": "Knowledge transfer strategies can effectively bridge LLMs and domain-specific forecasting tasks."}}
{"id": "2505.10183", "pdf": "https://arxiv.org/pdf/2505.10183", "abs": "https://arxiv.org/abs/2505.10183", "authors": ["Jieke Lin", "Wanyu Wang", "Longxiang Yin", "Yinhe Han"], "title": "KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems", "categories": ["cs.DC", "cs.AI"], "comment": "9 pages, 4 figures. Jieke Lin and Wanyu Wang contributed equally to\n  this work", "summary": "Embodied Artificial Intelligence (AI) systems, such as autonomous robots and\nintelligent vehicles, are increasingly reliant on diverse heterogeneous\naccelerators (e.g., GPGPUs, NPUs, FPGAs) to meet stringent real-time processing\nand energy-efficiency demands. However, the proliferation of vendor-specific\nproprietary communication libraries creates significant interoperability\nbarriers, hindering seamless collaboration between different accelerator types\nand leading to suboptimal resource utilization and performance bottlenecks in\ndistributed AI workloads. This paper introduces KAITIAN, a novel distributed\ncommunication framework designed to bridge this gap. KAITIAN provides a unified\nabstraction layer that intelligently integrates vendor-optimized communication\nlibraries for intra-group efficiency with general-purpose communication\nprotocols for inter-group interoperability. Crucially, it incorporates a\nload-adaptive scheduling mechanism that dynamically balances computational\ntasks across heterogeneous devices based on their real-time performance\ncharacteristics. Implemented as an extension to PyTorch and rigorously\nevaluated on a testbed featuring NVIDIA GPUs and Cambricon MLUs, KAITIAN\ndemonstrates significant improvements in resource utilization and scalability\nfor distributed training tasks. Experimental results show that KAITIAN can\naccelerate training time by up to 42% compared to baseline homogeneous systems,\nwhile incurring minimal communication overhead (2.8--4.3%) and maintaining\nmodel accuracy. KAITIAN paves the way for more flexible and powerful\nheterogeneous computing in complex embodied AI applications.", "AI": {"tldr": "KAITIAN is a distributed communication framework for heterogeneous accelerators in embodied AI, improving interoperability, resource utilization, and performance.", "motivation": "The proliferation of vendor-specific communication libraries creates interoperability barriers and suboptimal performance in distributed AI workloads.", "method": "KAITIAN integrates vendor-optimized libraries with general-purpose protocols and uses load-adaptive scheduling for dynamic task balancing.", "result": "KAITIAN accelerates training by up to 42%, with minimal overhead (2.8--4.3%) and maintained accuracy.", "conclusion": "KAITIAN enables flexible, powerful heterogeneous computing for embodied AI."}}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs.", "AI": {"tldr": "MASSV accelerates vision-language models (VLMs) by adapting small language models into multimodal drafters via a projector and self-distilled tuning, achieving up to 1.46x speedup.", "motivation": "Speculative decoding struggles with VLMs due to draft models lacking visual input processing and mismatched token predictions.", "method": "MASSV uses a lightweight projector to connect the VLM's vision encoder to the draft model and employs self-distilled visual instruction tuning.", "result": "MASSV increases accepted token length by 30% and achieves 1.46x inference speedup on visually-grounded tasks.", "conclusion": "MASSV offers a scalable solution for accelerating current and future VLMs."}}
{"id": "2505.10497", "pdf": "https://arxiv.org/pdf/2505.10497", "abs": "https://arxiv.org/abs/2505.10497", "authors": ["Iurii Medvedev", "Nuno Goncalves"], "title": "MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks", "categories": ["cs.CV"], "comment": null, "summary": "Face recognition has evolved significantly with the advancement of deep\nlearning techniques, enabling its widespread adoption in various applications\nrequiring secure authentication. However, this progress has also increased its\nexposure to presentation attacks, including face morphing, which poses a\nserious security threat by allowing one identity to impersonate another.\nTherefore, modern face recognition systems must be robust against such attacks.\n  In this work, we propose a novel approach for training deep networks for face\nrecognition with enhanced robustness to face morphing attacks. Our method\nmodifies the classification task by introducing a dual-branch classification\nstrategy that effectively handles the ambiguity in the labeling of face morphs.\nThis adaptation allows the model to incorporate morph images into the training\nprocess, improving its ability to distinguish them from bona fide samples.\n  Our strategy has been validated on public benchmarks, demonstrating its\neffectiveness in enhancing robustness against face morphing attacks.\nFurthermore, our approach is universally applicable and can be integrated into\nexisting face recognition training pipelines to improve classification-based\nrecognition methods.", "AI": {"tldr": "A novel dual-branch classification strategy enhances deep networks' robustness against face morphing attacks in face recognition systems.", "motivation": "Face recognition systems are vulnerable to presentation attacks like face morphing, necessitating improved robustness.", "method": "Introduces a dual-branch classification strategy to handle ambiguous labeling of face morphs, integrating them into training.", "result": "Validated on public benchmarks, the method effectively improves robustness against morphing attacks.", "conclusion": "The approach is universally applicable and can enhance existing face recognition training pipelines."}}
{"id": "2505.10259", "pdf": "https://arxiv.org/pdf/2505.10259", "abs": "https://arxiv.org/abs/2505.10259", "authors": ["Xiangwen Zhuge", "Xu Shen", "Zeyu Wang", "Fan Dang", "Xuan Ding", "Danyang Li", "Yahui Han", "Tianxiang Hao", "Zheng Yang"], "title": "SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices", "categories": ["cs.LG"], "comment": null, "summary": "Efficient LLM inference on resource-constrained devices presents significant\nchallenges in compute and memory utilization. Due to limited GPU memory,\nexisting systems offload model weights to CPU memory, incurring substantial I/O\noverhead between the CPU and GPU. This leads to two major inefficiencies: (1)\nGPU cores are underutilized, often remaining idle while waiting for data to be\nloaded; and (2) GPU memory has low impact on performance, as reducing its\ncapacity has minimal effect on overall throughput.In this paper, we propose\nSpecOffload, a high-throughput inference engine that embeds speculative\ndecoding into offloading. Our key idea is to unlock latent GPU resources for\nstoring and executing a draft model used for speculative decoding, thus\naccelerating inference at near-zero additional cost. To support this, we\ncarefully orchestrate the interleaved execution of target and draft models in\nspeculative decoding within the offloading pipeline, and propose a planner to\nmanage tensor placement and select optimal parameters. Compared to the best\nbaseline, SpecOffload improves GPU core utilization by 4.49x and boosts\ninference throughput by 2.54x. Our code is available at\nhttps://github.com/MobiSense/SpecOffload .", "AI": {"tldr": "SpecOffload improves LLM inference efficiency on resource-constrained devices by integrating speculative decoding with offloading, boosting GPU utilization and throughput.", "motivation": "Challenges in compute and memory utilization for LLM inference on devices with limited GPU memory, leading to inefficiencies like GPU underutilization and low memory impact.", "method": "Proposes SpecOffload, combining speculative decoding with offloading, optimizing tensor placement and execution orchestration.", "result": "Achieves 4.49x better GPU core utilization and 2.54x higher inference throughput compared to baselines.", "conclusion": "SpecOffload effectively leverages latent GPU resources for efficient inference at minimal cost."}}
{"id": "2505.10191", "pdf": "https://arxiv.org/pdf/2505.10191", "abs": "https://arxiv.org/abs/2505.10191", "authors": ["Qingyu Zheng", "Qi Shao", "Guijun Han", "Wei Li", "Hong Li", "Xuan Wang"], "title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting", "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "nlin.CD"], "comment": "22 pages, 6 figures", "summary": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting.", "AI": {"tldr": "LanTu, a dynamics-enhanced deep learning system, improves mesoscale eddy forecasting, outperforming traditional and AI-based methods.", "motivation": "Mesoscale eddies are critical for ocean dynamics but challenging to forecast. AI offers efficiency but struggles with multiscale features.", "method": "Developed LanTu, incorporating cross-scale interactions and multiscale physical constraints guided by eddy dynamics.", "result": "LanTu surpasses NOFS and AI-OFS in temperature, salinity, sea level anomaly, and current predictions with over 10-day lead time.", "conclusion": "Dynamics-enhanced deep learning (LanTu) is a promising paradigm for eddy-resolving ocean forecasting."}}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder.", "AI": {"tldr": "The paper introduces FigCodifier and ImgCode-8.6M, leveraging code for cross-modal alignment in mathematical figures, and achieves SOTA results with MathCoder-VL.", "motivation": "Current datasets lack detailed mathematical figure captions, limiting LMMs' multimodal reasoning. Code is proposed as supervision for precise alignment.", "method": "Developed image-to-code model FigCodifier and dataset ImgCode-8.6M using model-in-the-loop. Created MM-MathInstruct-3M for fine-tuning.", "result": "MathCoder-VL outperforms GPT-4o and Claude 3.5 Sonnet, with 8.9% and 9.2% improvements in geometry problem-solving.", "conclusion": "The approach advances multimodal math reasoning, with datasets and models made publicly available."}}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes.", "AI": {"tldr": "The paper proposes a submodular subset selection method to enhance the retriever framework in LMMs for Multiple Image Question Answering, improving scalability and retrieval performance.", "motivation": "LMMs struggle with tasks involving multiple images due to scalability and retrieval issues.", "method": "Uses query-aware submodular functions (e.g., GraphCut) to pre-select relevant images before retrieval, with anchor-based queries and data augmentation.", "result": "Improves the submodular-retriever pipeline, especially for large haystack sizes.", "conclusion": "The proposed method effectively addresses scalability and retrieval challenges in LMMs for multi-image tasks."}}
{"id": "2505.10262", "pdf": "https://arxiv.org/pdf/2505.10262", "abs": "https://arxiv.org/abs/2505.10262", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Lajos Hanzo"], "title": "Electric Bus Charging Schedules Relying on Real Data-Driven Targets Based on Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The charging scheduling problem of Electric Buses (EBs) is investigated based\non Deep Reinforcement Learning (DRL). A Markov Decision Process (MDP) is\nconceived, where the time horizon includes multiple charging and operating\nperiods in a day, while each period is further divided into multiple time\nsteps. To overcome the challenge of long-range multi-phase planning with sparse\nreward, we conceive Hierarchical DRL (HDRL) for decoupling the original MDP\ninto a high-level Semi-MDP (SMDP) and multiple low-level MDPs. The Hierarchical\nDouble Deep Q-Network (HDDQN)-Hindsight Experience Replay (HER) algorithm is\nproposed for simultaneously solving the decision problems arising at different\ntemporal resolutions. As a result, the high-level agent learns an effective\npolicy for prescribing the charging targets for every charging period, while\nthe low-level agent learns an optimal policy for setting the charging power of\nevery time step within a single charging period, with the aim of minimizing the\ncharging costs while meeting the charging target. It is proved that the flat\npolicy constructed by superimposing the optimal high-level policy and the\noptimal low-level policy performs as well as the optimal policy of the original\nMDP. Since jointly learning both levels of policies is challenging due to the\nnon-stationarity of the high-level agent and the sampling inefficiency of the\nlow-level agent, we divide the joint learning process into two phases and\nexploit our new HER algorithm to manipulate the experience replay buffers for\nboth levels of agents. Numerical experiments are performed with the aid of\nreal-world data to evaluate the performance of the proposed algorithm.", "AI": {"tldr": "The paper proposes a Hierarchical DRL (HDRL) approach to solve the charging scheduling problem for Electric Buses, using a two-level MDP framework and a novel HDDQN-HER algorithm to minimize costs while meeting charging targets.", "motivation": "The challenge of long-range multi-phase planning with sparse rewards in EB charging scheduling motivates the use of hierarchical reinforcement learning to decouple the problem into manageable levels.", "method": "A Hierarchical Double Deep Q-Network (HDDQN) with Hindsight Experience Replay (HER) is proposed, splitting the MDP into high-level (SMDP) and low-level MDPs for charging targets and power settings, respectively.", "result": "The hierarchical policy performs as well as the optimal policy of the original MDP, validated through numerical experiments with real-world data.", "conclusion": "The HDRL framework effectively addresses the EB charging problem, with the HDDQN-HER algorithm enabling efficient learning and cost minimization."}}
{"id": "2505.10197", "pdf": "https://arxiv.org/pdf/2505.10197", "abs": "https://arxiv.org/abs/2505.10197", "authors": ["Anjali de Silva", "Gang Chen", "Hui Ma", "Seyed Mohammad Nekooei", "Xingquan Zuo"], "title": "Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion", "categories": ["cs.SI", "cs.AI"], "comment": "This paper has been accepted by IJCAI (International Joint Conference\n  on Artificial Intelligence) 2025", "summary": "Community detection, a vital technology for real-world applications, uncovers\ncohesive node groups (communities) by leveraging both topological and attribute\nsimilarities in social networks. However, existing Graph Convolutional Networks\n(GCNs) trained to maximize modularity often converge to suboptimal solutions.\nAdditionally, directly using human-labeled communities for training can\nundermine topological cohesiveness by grouping disconnected nodes based solely\non node attributes. We address these issues by proposing a novel Topological\nand Attributive Similarity-based Community detection (TAS-Com) method. TAS-Com\nintroduces a novel loss function that exploits the highly effective and\nscalable Leiden algorithm to detect community structures with global optimal\nmodularity. Leiden is further utilized to refine human-labeled communities to\nensure connectivity within each community, enabling TAS-Com to detect community\nstructures with desirable trade-offs between modularity and compliance with\nhuman labels. Experimental results on multiple benchmark networks confirm that\nTAS-Com can significantly outperform several state-of-the-art algorithms.", "AI": {"tldr": "TAS-Com is a new method for community detection in social networks, combining topological and attribute similarities with a novel loss function and Leiden algorithm to optimize modularity and human-labeled compliance.", "motivation": "Existing GCNs often converge to suboptimal solutions, and human-labeled communities may lack topological cohesiveness. TAS-Com aims to address these issues.", "method": "TAS-Com uses a novel loss function and the Leiden algorithm to detect communities with optimal modularity and refine human-labeled communities for connectivity.", "result": "TAS-Com outperforms state-of-the-art algorithms on benchmark networks, achieving better modularity and human-label compliance.", "conclusion": "TAS-Com effectively balances modularity and human-labeled community accuracy, offering a superior solution for community detection."}}
{"id": "2404.03080", "pdf": "https://arxiv.org/pdf/2404.03080", "abs": "https://arxiv.org/abs/2404.03080", "authors": ["Yanpeng Ye", "Jie Ren", "Shaozhou Wang", "Yuwei Wan", "Imran Razzak", "Bram Hoex", "Haofen Wang", "Tong Xie", "Wenjie Zhang"], "title": "Construction and Application of Materials Knowledge Graph in Multidisciplinary Materials Science via Large Language Model", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024)", "summary": "Knowledge in materials science is widely dispersed across extensive\nscientific literature, posing significant challenges to the efficient discovery\nand integration of new materials. Traditional methods, often reliant on costly\nand time-consuming experimental approaches, further complicate rapid\ninnovation. Addressing these challenges, the integration of artificial\nintelligence with materials science has opened avenues for accelerating the\ndiscovery process, though it also demands precise annotation, data extraction,\nand traceability of information. To tackle these issues, this article\nintroduces the Materials Knowledge Graph (MKG), which utilizes advanced natural\nlanguage processing techniques integrated with large language models to extract\nand systematically organize a decade's worth of high-quality research into\nstructured triples, contains 162,605 nodes and 731,772 edges. MKG categorizes\ninformation into comprehensive labels such as Name, Formula, and Application,\nstructured around a meticulously designed ontology, thus enhancing data\nusability and integration. By implementing network-based algorithms, MKG not\nonly facilitates efficient link prediction but also significantly reduces\nreliance on traditional experimental methods. This structured approach not only\nstreamlines materials research but also lays the groundwork for more\nsophisticated science knowledge graphs.", "AI": {"tldr": "The paper introduces the Materials Knowledge Graph (MKG) to address challenges in materials science by using AI and NLP to organize research data into structured triples, improving efficiency and reducing reliance on traditional methods.", "motivation": "The dispersion of knowledge in materials science and inefficiencies in traditional experimental methods hinder rapid innovation.", "method": "MKG employs advanced NLP and large language models to extract and structure research data into 162,605 nodes and 731,772 edges, categorized by a designed ontology.", "result": "MKG enhances data usability, facilitates link prediction, and reduces dependence on costly experiments.", "conclusion": "MKG streamlines materials research and paves the way for advanced science knowledge graphs."}}
{"id": "2505.10541", "pdf": "https://arxiv.org/pdf/2505.10541", "abs": "https://arxiv.org/abs/2505.10541", "authors": ["Pengfei Wang", "Guohai Xu", "Weinong Wang", "Junjie Yang", "Jie Lou", "Yunhua Xue"], "title": "Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements have enhanced the capability of Multimodal Large Language\nModels (MLLMs) to comprehend multi-image information. However, existing\nbenchmarks primarily evaluate answer correctness, overlooking whether models\ngenuinely comprehend the visual input. To address this, we define implicit\nvisual misunderstanding (IVM), where MLLMs provide correct answers without\nfully comprehending the visual input. Through our analysis, we decouple the\nvisual and textual modalities within the causal attention module, revealing\nthat attention distribution increasingly converges on the image associated with\nthe correct answer as the network layers deepen. This insight leads to the\nintroduction of a scale-agnostic metric, \\textit{attention accuracy}, and a\nnovel benchmark for quantifying IVMs. Attention accuracy directly evaluates the\nmodel's visual understanding via internal mechanisms, remaining robust to\npositional biases for more reliable assessments. Furthermore, we extend our\napproach to finer granularities and demonstrate its effectiveness in unimodal\nscenarios, underscoring its versatility and generalizability.", "AI": {"tldr": "The paper introduces a metric and benchmark to detect implicit visual misunderstanding (IVM) in Multimodal Large Language Models (MLLMs), ensuring models genuinely comprehend visual input.", "motivation": "Existing benchmarks overlook whether MLLMs truly understand visual input, leading to correct answers without comprehension (IVM).", "method": "Decouples visual and textual modalities in causal attention, introduces attention accuracy metric, and creates a benchmark for IVM.", "result": "Attention distribution converges on correct images as layers deepen; attention accuracy reliably assesses visual understanding.", "conclusion": "The proposed method effectively quantifies IVM, works in unimodal scenarios, and is robust to biases, proving its versatility."}}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "Andr\u00e9 Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art.", "AI": {"tldr": "A new data reconstruction attack in Federated Learning overcomes limitations of existing methods, enabling perfect recovery of large data batches without prior knowledge.", "motivation": "To address vulnerabilities in FL where malicious servers can reconstruct private data, overcoming assumptions and inefficiencies of current attacks.", "method": "Leverages a geometric perspective on fully connected layers to craft malicious model parameters for perfect data recovery.", "result": "Outperforms existing methods, achieving perfect reconstruction of data batches two orders of magnitude larger than state-of-the-art.", "conclusion": "The attack demonstrates significant improvements in data reconstruction efficiency and scale, highlighting critical FL vulnerabilities."}}
{"id": "2505.10201", "pdf": "https://arxiv.org/pdf/2505.10201", "abs": "https://arxiv.org/abs/2505.10201", "authors": ["Victor Lagerkvist", "Mohamed Maizia", "Johannes Schmidt"], "title": "A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds", "categories": ["cs.CC", "cs.AI", "F.2.2"], "comment": null, "summary": "The Boolean satisfiability problem (SAT) is a well-known example of monotonic\nreasoning, of intense practical interest due to fast solvers, complemented by\nrigorous fine-grained complexity results. However, for non-monotonic reasoning,\ne.g., abductive reasoning, comparably little is known outside classic\ncomplexity theory. In this paper we take a first step of bridging the gap\nbetween monotonic and non-monotonic reasoning by analyzing the complexity of\nintractable abduction problems under the seemingly overlooked but natural\nparameter n: the number of variables in the knowledge base. We obtain several\npositive results for $\\Sigma^P_2$- as well as NP- and coNP-complete fragments,\nwhich implies the first example of beating exhaustive search for a\n$\\Sigma^P_2$-complete problem (to the best of our knowledge). We complement\nthis with lower bounds and for many fragments rule out improvements under the\n(strong) exponential-time hypothesis.", "AI": {"tldr": "The paper analyzes the complexity of intractable abduction problems, focusing on the parameter n (number of variables), and provides positive results for \u03a3\u00b2P-, NP-, and coNP-complete fragments, along with lower bounds.", "motivation": "To bridge the gap between monotonic and non-monotonic reasoning by studying the complexity of abduction problems, a less explored area compared to monotonic reasoning like SAT.", "method": "Analyzes the complexity of abduction problems using the parameter n (number of variables) and applies rigorous fine-grained complexity techniques.", "result": "Obtains positive results for \u03a3\u00b2P-, NP-, and coNP-complete fragments, achieving the first example of beating exhaustive search for a \u03a3\u00b2P-complete problem. Also provides lower bounds under the strong exponential-time hypothesis.", "conclusion": "The study advances understanding of non-monotonic reasoning complexity and sets a foundation for further research in this area."}}
{"id": "2404.17785", "pdf": "https://arxiv.org/pdf/2404.17785", "abs": "https://arxiv.org/abs/2404.17785", "authors": ["Yizhe Xiong", "Xiansheng Chen", "Xin Ye", "Hui Chen", "Zijia Lin", "Haoran Lian", "Zhenpeng Su", "Wei Huang", "Jianwei Niu", "Jungong Han", "Guiguang Ding"], "title": "Temporal Scaling Law for Large Language Models", "categories": ["cs.CL"], "comment": "Preprint, Currently under review", "summary": "Recently, Large Language Models (LLMs) have been widely adopted in a wide\nrange of tasks, leading to increasing attention towards the research on how\nscaling LLMs affects their performance. Existing works, termed Scaling Laws,\nhave discovered that the final test loss of LLMs scales as power-laws with\nmodel size, computational budget, and dataset size. However, the temporal\nchange of the test loss of an LLM throughout its pre-training process remains\nunexplored, though it is valuable in many aspects, such as selecting better\nhyperparameters \\textit{directly} on the target LLM. In this paper, we propose\nthe novel concept of Temporal Scaling Law, studying how the test loss of an LLM\nevolves as the training steps scale up. In contrast to modeling the test loss\nas a whole in a coarse-grained manner, we break it down and dive into the\nfine-grained test loss of each token position, and further develop a dynamic\nhyperbolic-law. Afterwards, we derive the much more precise temporal scaling\nlaw by studying the temporal patterns of the parameters in the dynamic\nhyperbolic-law. Results on both in-distribution (ID) and out-of-distribution\n(OOD) validation datasets demonstrate that our temporal scaling law accurately\npredicts the test loss of LLMs across training steps. Our temporal scaling law\nhas broad practical applications. First, it enables direct and efficient\nhyperparameter selection on the target LLM, such as data mixture proportions.\nSecondly, viewing the LLM pre-training dynamics from the token position\ngranularity provides some insights to enhance the understanding of LLM\npre-training.", "AI": {"tldr": "The paper introduces Temporal Scaling Law, a novel concept to study how the test loss of LLMs evolves with training steps, enabling better hyperparameter selection and deeper insights into LLM pre-training.", "motivation": "Existing Scaling Laws focus on final test loss but ignore its temporal evolution during pre-training, which is crucial for tasks like hyperparameter tuning.", "method": "The authors break down test loss by token position, develop a dynamic hyperbolic-law, and derive precise temporal scaling laws by analyzing parameter patterns.", "result": "The temporal scaling law accurately predicts test loss across training steps on both ID and OOD datasets.", "conclusion": "The law aids hyperparameter selection and provides granular insights into LLM pre-training dynamics."}}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets.", "AI": {"tldr": "The paper investigates whether enforcing feasibility in synthetic images impacts CLIP-based classifier performance, finding minimal effect (less than 0.3% difference in accuracy).", "motivation": "To determine if excluding infeasible synthetic images (those with unrealistic attributes) from training data is necessary for CLIP-based classifiers.", "method": "Introduces VariReal, a pipeline to edit images for feasible or infeasible attributes based on textual prompts, and tests on CLIP classifiers.", "result": "Feasibility minimally affects performance; mixing feasible and infeasible images in training does not significantly impact results.", "conclusion": "Enforcing feasibility in synthetic training data is not crucial for CLIP-based classifiers, as it has negligible impact on performance."}}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sj\u00f8rup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency.", "AI": {"tldr": "A deep learning model for high-resolution probabilistic precipitation forecasting in Europe, integrating radar, satellite, and NWP data, outperforming existing methods.", "motivation": "Overcome limitations of radar-only models with short lead times and improve accuracy, uncertainty quantification, and computational efficiency.", "method": "Integrates radar, satellite, and NWP data with a compact architecture for efficient training and inference, capturing long-range interactions.", "result": "Surpasses operational NWP systems, extrapolation-based methods, and deep-learning nowcasting models in accuracy and efficiency.", "conclusion": "Sets a new standard for high-resolution precipitation forecasting in Europe, balancing accuracy, interpretability, and computational efficiency."}}
{"id": "2505.10212", "pdf": "https://arxiv.org/pdf/2505.10212", "abs": "https://arxiv.org/abs/2505.10212", "authors": ["Dario Di Palma", "Felice Antonio Merra", "Maurizio Sfilio", "Vito Walter Anelli", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have become increasingly central to\nrecommendation scenarios due to their remarkable natural language understanding\nand generation capabilities. Although significant research has explored the use\nof LLMs for various recommendation tasks, little effort has been dedicated to\nverifying whether they have memorized public recommendation dataset as part of\ntheir training data. This is undesirable because memorization reduces the\ngeneralizability of research findings, as benchmarking on memorized datasets\ndoes not guarantee generalization to unseen datasets. Furthermore, memorization\ncan amplify biases, for example, some popular items may be recommended more\nfrequently than others.\n  In this work, we investigate whether LLMs have memorized public\nrecommendation datasets. Specifically, we examine two model families (GPT and\nLlama) across multiple sizes, focusing on one of the most widely used dataset\nin recommender systems: MovieLens-1M. First, we define dataset memorization as\nthe extent to which item attributes, user profiles, and user-item interactions\ncan be retrieved by prompting the LLMs. Second, we analyze the impact of\nmemorization on recommendation performance. Lastly, we examine whether\nmemorization varies across model families and model sizes. Our results reveal\nthat all models exhibit some degree of memorization of MovieLens-1M, and that\nrecommendation performance is related to the extent of memorization. We have\nmade all the code publicly available at:\nhttps://github.com/sisinflab/LLM-MemoryInspector", "AI": {"tldr": "The paper investigates whether LLMs memorize public recommendation datasets like MovieLens-1M, analyzing memorization's impact on performance and biases.", "motivation": "To address the lack of research on LLMs memorizing public datasets, which can reduce generalizability and amplify biases in recommendations.", "method": "Examines GPT and Llama models of varying sizes, defining memorization via retrievable item attributes, user profiles, and interactions. Analyzes memorization's impact on performance.", "result": "All models show some memorization of MovieLens-1M, with recommendation performance linked to memorization extent.", "conclusion": "Memorization in LLMs affects recommendation tasks, highlighting the need for awareness and mitigation in research and applications."}}
{"id": "2405.15523", "pdf": "https://arxiv.org/pdf/2405.15523", "abs": "https://arxiv.org/abs/2405.15523", "authors": ["Igor Shilov", "Matthieu Meeus", "Yves-Alexandre de Montjoye"], "title": "The Mosaic Memory of Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) become widely adopted, understanding how they\nlearn from, and memorize, training data becomes crucial. Memorization in LLMs\nis widely assumed to only occur as a result of sequences being repeated in the\ntraining data. Instead, we show that LLMs memorize by assembling information\nfrom similar sequences, a phenomena we call mosaic memory. We show major LLMs\nto exhibit mosaic memory, with fuzzy duplicates contributing to memorization as\nmuch as 0.8 of an exact duplicate and even heavily modified sequences\ncontributing substantially to memorization. Despite models display reasoning\ncapabilities, we somewhat surprisingly show memorization to be predominantly\nsyntactic rather than semantic. We finally show fuzzy duplicates to be\nubiquitous in real-world data, untouched by deduplication techniques. Taken\ntogether, our results challenge widely held beliefs and show memorization to be\na more complex, mosaic process, with real-world implications for privacy,\nconfidentiality, model utility and evaluation.", "AI": {"tldr": "LLMs memorize by assembling information from similar sequences (mosaic memory), not just exact duplicates, challenging common assumptions.", "motivation": "To understand how LLMs learn and memorize training data, especially given privacy and confidentiality concerns.", "method": "Analyzed memorization in major LLMs, measuring contributions of exact and fuzzy duplicates to memorization.", "result": "LLMs exhibit mosaic memory, with fuzzy duplicates contributing significantly. Memorization is syntactic, not semantic, and fuzzy duplicates are common in real-world data.", "conclusion": "Memorization in LLMs is a complex, mosaic process with implications for privacy, confidentiality, and model evaluation."}}
{"id": "2505.10562", "pdf": "https://arxiv.org/pdf/2505.10562", "abs": "https://arxiv.org/abs/2505.10562", "authors": ["Wenxuan Wang", "Fan Zhang", "Yufeng Cui", "Haiwen Diao", "Zhuoyan Luo", "Huchuan Lu", "Jing Liu", "Xinlong Wang"], "title": "End-to-End Vision Tokenizer Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Existing vision tokenization isolates the optimization of vision tokenizers\nfrom downstream training, implicitly assuming the visual tokens can generalize\nwell across various tasks, e.g., image generation and visual question\nanswering. The vision tokenizer optimized for low-level reconstruction is\nagnostic to downstream tasks requiring varied representations and semantics.\nThis decoupled paradigm introduces a critical misalignment: The loss of the\nvision tokenization can be the representation bottleneck for target tasks. For\nexample, errors in tokenizing text in a given image lead to poor results when\nrecognizing or generating them. To address this, we propose ETT, an end-to-end\nvision tokenizer tuning approach that enables joint optimization between vision\ntokenization and target autoregressive tasks. Unlike prior autoregressive\nmodels that use only discrete indices from a frozen vision tokenizer, ETT\nleverages the visual embeddings of the tokenizer codebook, and optimizes the\nvision tokenizers end-to-end with both reconstruction and caption objectives.\nETT can be seamlessly integrated into existing training pipelines with minimal\narchitecture modifications. Our ETT is simple to implement and integrate,\nwithout the need to adjust the original codebooks or architectures of the\nemployed large language models. Extensive experiments demonstrate that our\nproposed end-to-end vision tokenizer tuning unlocks significant performance\ngains, i.e., 2-6% for multimodal understanding and visual generation tasks\ncompared to frozen tokenizer baselines, while preserving the original\nreconstruction capability. We hope this very simple and strong method can\nempower multimodal foundation models besides image generation and\nunderstanding.", "AI": {"tldr": "ETT is an end-to-end vision tokenizer tuning method that jointly optimizes tokenization and downstream tasks, improving performance by 2-6% over frozen tokenizers.", "motivation": "Current vision tokenizers are optimized independently of downstream tasks, causing misalignment and poor performance in tasks like text recognition or generation.", "method": "ETT jointly optimizes vision tokenization with reconstruction and caption objectives, leveraging visual embeddings from the tokenizer codebook.", "result": "ETT achieves 2-6% performance gains in multimodal understanding and visual generation tasks while maintaining reconstruction quality.", "conclusion": "ETT is a simple, effective method to enhance multimodal foundation models without modifying existing architectures."}}
{"id": "2505.10272", "pdf": "https://arxiv.org/pdf/2505.10272", "abs": "https://arxiv.org/abs/2505.10272", "authors": ["Niklas Dexheimer", "Sascha Gaudlitz", "Johannes Schmidt-Hieber"], "title": "Spike-timing-dependent Hebbian learning as noisy gradient descent", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Hebbian learning is a key principle underlying learning in biological neural\nnetworks. It postulates that synaptic changes occur locally, depending on the\nactivities of pre- and postsynaptic neurons. While Hebbian learning based on\nneuronal firing rates is well explored, much less is known about learning rules\nthat account for precise spike-timing. We relate a Hebbian\nspike-timing-dependent plasticity rule to noisy gradient descent with respect\nto a natural loss function on the probability simplex. This connection allows\nus to prove that the learning rule eventually identifies the presynaptic neuron\nwith the highest activity. We also discover an intrinsic connection to noisy\nmirror descent.", "AI": {"tldr": "The paper connects Hebbian spike-timing-dependent plasticity to noisy gradient descent, proving it identifies the most active presynaptic neuron and linking it to noisy mirror descent.", "motivation": "Explore learning rules for precise spike-timing in biological neural networks, extending beyond rate-based Hebbian learning.", "method": "Relate Hebbian spike-timing-dependent plasticity to noisy gradient descent on a natural loss function.", "result": "The learning rule identifies the presynaptic neuron with the highest activity and shows a connection to noisy mirror descent.", "conclusion": "The study provides theoretical insights into spike-timing learning rules and their optimization properties."}}
{"id": "2505.10273", "pdf": "https://arxiv.org/pdf/2505.10273", "abs": "https://arxiv.org/abs/2505.10273", "authors": ["Hexu Li", "Konstantinos Kalogiannis", "Ahmed Mohamed Hussain", "Panos Papadimitratos"], "title": "AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons", "categories": ["cs.CR", "cs.AI", "cs.NI"], "comment": "Author's version; Accepted for presentation at the ACM Workshop on\n  Wireless Security and Machine Learning (WiseML 2025)", "summary": "Vehicle platooning, with vehicles traveling in close formation coordinated\nthrough Vehicle-to-Everything (V2X) communications, offers significant benefits\nin fuel efficiency and road utilization. However, it is vulnerable to\nsophisticated falsification attacks by authenticated insiders that can\ndestabilize the formation and potentially cause catastrophic collisions. This\npaper addresses this challenge: misbehavior detection in vehicle platooning\nsystems. We present AttentionGuard, a transformer-based framework for\nmisbehavior detection that leverages the self-attention mechanism to identify\nanomalous patterns in mobility data. Our proposal employs a multi-head\ntransformer-encoder to process sequential kinematic information, enabling\neffective differentiation between normal mobility patterns and falsification\nattacks across diverse platooning scenarios, including steady-state\n(no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an\nextensive simulation dataset featuring various attack vectors (constant,\ngradual, and combined falsifications) and operational parameters (controller\ntypes, vehicle speeds, and attacker positions). Experimental results\ndemonstrate that AttentionGuard achieves up to 0.95 F1-score in attack\ndetection, with robust performance maintained during complex maneuvers.\nNotably, our system performs effectively with minimal latency (100ms decision\nintervals), making it suitable for real-time transportation safety\napplications. Comparative analysis reveals superior detection capabilities and\nestablishes the transformer-encoder as a promising approach for securing\nCooperative Intelligent Transport Systems (C-ITS) against sophisticated insider\nthreats.", "AI": {"tldr": "AttentionGuard, a transformer-based framework, detects misbehavior in vehicle platooning systems with high accuracy and low latency.", "motivation": "Vehicle platooning is vulnerable to insider falsification attacks, risking destabilization and collisions.", "method": "Uses a multi-head transformer-encoder to analyze kinematic data for anomaly detection in various platooning scenarios.", "result": "Achieves up to 0.95 F1-score in attack detection, with minimal latency (100ms).", "conclusion": "AttentionGuard is effective for real-time security in Cooperative Intelligent Transport Systems."}}
{"id": "2405.17067", "pdf": "https://arxiv.org/pdf/2405.17067", "abs": "https://arxiv.org/abs/2405.17067", "authors": ["Dixuan Wang", "Yanda Li", "Junyuan Jiang", "Zepeng Ding", "Ziqin Luo", "Guochao Jiang", "Jiaqing Liang", "Deqing Yang"], "title": "Tokenization Matters! Degrading Large Language Models through Challenging Their Tokenization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. Nonetheless, it was also witnessed that LLMs tend\nto produce inaccurate responses to specific queries. This deficiency can be\ntraced to the tokenization step LLMs must undergo, which is an inevitable\nlimitation inherent to all LLMs. In fact, incorrect tokenization is the\ncritical point that hinders LLMs in understanding the input precisely, thus\nleading to unsatisfactory output. This defect is more obvious in Chinese\nscenarios. To demonstrate this flaw of LLMs, we construct an adversarial\ndataset, named as $\\textbf{ADT (Adversarial Dataset for Tokenizer)}$, which\ndraws upon the vocabularies of various open-source LLMs to challenge LLMs'\ntokenization. ADT consists of two subsets: the manually constructed ADT-Human\nand the automatically generated ADT-Auto. Our empirical results reveal that our\nADT is highly effective on challenging the tokenization of leading LLMs,\nincluding GPT-4o, Llama-3, Deepseek-R1 and so on, thus degrading these LLMs'\ncapabilities. Moreover, our method of automatic data generation has been proven\nefficient and robust, which can be applied to any open-source LLMs. In this\npaper, we substantially investigate LLMs' vulnerability in terms of challenging\ntheir token segmentation, which will shed light on the subsequent research of\nimproving LLMs' capabilities through optimizing their tokenization process and\nalgorithms.", "AI": {"tldr": "The paper identifies tokenization as a key flaw in LLMs, especially for Chinese, and introduces ADT, an adversarial dataset, to challenge and expose this weakness.", "motivation": "To highlight and address the tokenization limitations in LLMs, which cause inaccurate responses, particularly in Chinese contexts.", "method": "Constructed ADT (Adversarial Dataset for Tokenizer) with manual (ADT-Human) and automatic (ADT-Auto) subsets to test LLMs' tokenization.", "result": "ADT effectively exposed vulnerabilities in leading LLMs like GPT-4o and Llama-3, degrading their performance.", "conclusion": "The study underscores the need for improved tokenization methods to enhance LLMs' accuracy and robustness."}}
{"id": "2505.10565", "pdf": "https://arxiv.org/pdf/2505.10565", "abs": "https://arxiv.org/abs/2505.10565", "authors": ["Zehan Wang", "Siyu Chen", "Lihe Yang", "Jialei Wang", "Ziang Zhang", "Hengshuang Zhao", "Zhou Zhao"], "title": "Depth Anything with Any Prior", "categories": ["cs.CV"], "comment": "Home page: https://prior-depth-anything.github.io/", "summary": "This work presents Prior Depth Anything, a framework that combines incomplete\nbut precise metric information in depth measurement with relative but complete\ngeometric structures in depth prediction, generating accurate, dense, and\ndetailed metric depth maps for any scene. To this end, we design a\ncoarse-to-fine pipeline to progressively integrate the two complementary depth\nsources. First, we introduce pixel-level metric alignment and distance-aware\nweighting to pre-fill diverse metric priors by explicitly using depth\nprediction. It effectively narrows the domain gap between prior patterns,\nenhancing generalization across varying scenarios. Second, we develop a\nconditioned monocular depth estimation (MDE) model to refine the inherent noise\nof depth priors. By conditioning on the normalized pre-filled prior and\nprediction, the model further implicitly merges the two complementary depth\nsources. Our model showcases impressive zero-shot generalization across depth\ncompletion, super-resolution, and inpainting over 7 real-world datasets,\nmatching or even surpassing previous task-specific methods. More importantly,\nit performs well on challenging, unseen mixed priors and enables test-time\nimprovements by switching prediction models, providing a flexible\naccuracy-efficiency trade-off while evolving with advancements in MDE models.", "AI": {"tldr": "Prior Depth Anything combines precise but incomplete metric depth with complete but relative geometric structures to generate accurate, dense metric depth maps. It uses a coarse-to-fine pipeline and conditioned MDE for refinement, achieving strong zero-shot generalization.", "motivation": "To address the limitations of existing depth measurement (precise but incomplete) and depth prediction (complete but relative) by integrating both for accurate, detailed metric depth maps.", "method": "A coarse-to-fine pipeline with pixel-level metric alignment, distance-aware weighting, and a conditioned MDE model to refine and merge complementary depth sources.", "result": "The model achieves impressive zero-shot generalization across tasks like depth completion, super-resolution, and inpainting, outperforming task-specific methods on 7 datasets.", "conclusion": "The framework provides flexible accuracy-efficiency trade-offs and adapts to advancements in MDE models, making it robust for diverse scenarios."}}
{"id": "2505.10296", "pdf": "https://arxiv.org/pdf/2505.10296", "abs": "https://arxiv.org/abs/2505.10296", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Dusit Niyato"], "title": "Optimizing Electric Bus Charging Scheduling with Uncertainties Using Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The growing adoption of Electric Buses (EBs) represents a significant step\ntoward sustainable development. By utilizing Internet of Things (IoT) systems,\ncharging stations can autonomously determine charging schedules based on\nreal-time data. However, optimizing EB charging schedules remains a critical\nchallenge due to uncertainties in travel time, energy consumption, and\nfluctuating electricity prices. Moreover, to address real-world complexities,\ncharging policies must make decisions efficiently across multiple time scales\nand remain scalable for large EB fleets. In this paper, we propose a\nHierarchical Deep Reinforcement Learning (HDRL) approach that reformulates the\noriginal Markov Decision Process (MDP) into two augmented MDPs. To solve these\nMDPs and enable multi-timescale decision-making, we introduce a novel HDRL\nalgorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization\nEnhancement (DAC-MAPPO-E). Scalability challenges of the Double Actor-Critic\n(DAC) algorithm for large-scale EB fleets are addressed through enhancements at\nboth decision levels. At the high level, we redesign the decentralized actor\nnetwork and integrate an attention mechanism to extract relevant global state\ninformation for each EB, decreasing the size of neural networks. At the low\nlevel, the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm is\nincorporated into the DAC framework, enabling decentralized and coordinated\ncharging power decisions, reducing computational complexity and enhancing\nconvergence speed. Extensive experiments with real-world data demonstrate the\nsuperior performance and scalability of DAC-MAPPO-E in optimizing EB fleet\ncharging schedules.", "AI": {"tldr": "A Hierarchical Deep Reinforcement Learning (HDRL) approach, DAC-MAPPO-E, optimizes Electric Bus (EB) charging schedules by addressing uncertainties and scalability for large fleets.", "motivation": "The need for efficient and scalable EB charging policies due to uncertainties in travel time, energy consumption, and electricity prices.", "method": "Proposes DAC-MAPPO-E, combining Double Actor-Critic and Multi-Agent Proximal Policy Optimization, with enhancements for scalability and multi-timescale decision-making.", "result": "DAC-MAPPO-E outperforms in optimizing EB fleet charging schedules, as shown by real-world data experiments.", "conclusion": "The approach effectively addresses scalability and efficiency challenges in EB charging optimization."}}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments.", "AI": {"tldr": "FeRA is a federated learning defense mechanism that uses cross-client attention to detect backdoor attacks in non-IID data settings, maintaining high accuracy while reducing attack success.", "motivation": "Heterogeneous edge devices produce non-IID data, complicating backdoor attack detection in federated learning.", "method": "FeRA leverages cross-client attention and representation reconstruction errors to compute anomaly scores, identifying malicious clients.", "result": "FeRA reduces backdoor attack success rates and maintains high main task accuracy in non-IID scenarios.", "conclusion": "FeRA is a robust, model-agnostic solution for detecting backdoor attacks in federated learning with heterogeneous edge devices."}}
{"id": "2406.00367", "pdf": "https://arxiv.org/pdf/2406.00367", "abs": "https://arxiv.org/abs/2406.00367", "authors": ["Md. Mostafizer Rahman", "Ariful Islam Shiplu", "Yutaka Watanobe", "Md. Ashad Alam"], "title": "RoBERTa-BiLSTM: A Context-Aware Hybrid Model for Sentiment Analysis", "categories": ["cs.CL", "cs.AI", "cs.CE"], "comment": null, "summary": "Effectively analyzing the comments to uncover latent intentions holds immense\nvalue in making strategic decisions across various domains. However, several\nchallenges hinder the process of sentiment analysis including the lexical\ndiversity exhibited in comments, the presence of long dependencies within the\ntext, encountering unknown symbols and words, and dealing with imbalanced\ndatasets. Moreover, existing sentiment analysis tasks mostly leveraged\nsequential models to encode the long dependent texts and it requires longer\nexecution time as it processes the text sequentially. In contrast, the\nTransformer requires less execution time due to its parallel processing nature.\nIn this work, we introduce a novel hybrid deep learning model, RoBERTa-BiLSTM,\nwhich combines the Robustly Optimized BERT Pretraining Approach (RoBERTa) with\nBidirectional Long Short-Term Memory (BiLSTM) networks. RoBERTa is utilized to\ngenerate meaningful word embedding vectors, while BiLSTM effectively captures\nthe contextual semantics of long-dependent texts. The RoBERTa-BiLSTM hybrid\nmodel leverages the strengths of both sequential and Transformer models to\nenhance performance in sentiment analysis. We conducted experiments using\ndatasets from IMDb, Twitter US Airline, and Sentiment140 to evaluate the\nproposed model against existing state-of-the-art methods. Our experimental\nfindings demonstrate that the RoBERTa-BiLSTM model surpasses baseline models\n(e.g., BERT, RoBERTa-base, RoBERTa-GRU, and RoBERTa-LSTM), achieving accuracies\nof 80.74%, 92.36%, and 82.25% on the Twitter US Airline, IMDb, and Sentiment140\ndatasets, respectively. Additionally, the model achieves F1-scores of 80.73%,\n92.35%, and 82.25% on the same datasets, respectively.", "AI": {"tldr": "The paper introduces RoBERTa-BiLSTM, a hybrid model combining RoBERTa and BiLSTM for sentiment analysis, outperforming existing methods in accuracy and F1-scores on multiple datasets.", "motivation": "Challenges in sentiment analysis like lexical diversity, long dependencies, and imbalanced datasets motivate the need for a more efficient and accurate model.", "method": "The hybrid RoBERTa-BiLSTM model uses RoBERTa for word embeddings and BiLSTM to capture contextual semantics in long-dependent texts.", "result": "The model achieves accuracies of 80.74%, 92.36%, and 82.25% on Twitter US Airline, IMDb, and Sentiment140 datasets, with matching F1-scores.", "conclusion": "RoBERTa-BiLSTM outperforms baseline models, proving its effectiveness in sentiment analysis by leveraging both sequential and Transformer strengths."}}
{"id": "2505.10566", "pdf": "https://arxiv.org/pdf/2505.10566", "abs": "https://arxiv.org/abs/2505.10566", "authors": ["Yen-Chi Cheng", "Krishna Kumar Singh", "Jae Shin Yoon", "Alex Schwing", "Liangyan Gui", "Matheus Gadelha", "Paul Guerrero", "Nanxuan Zhao"], "title": "3D-Fixup: Advancing Photo Editing with 3D Priors", "categories": ["cs.CV"], "comment": "SIGGRAPH 2025. Project page: https://3dfixup.github.io/", "summary": "Despite significant advances in modeling image priors via diffusion models,\n3D-aware image editing remains challenging, in part because the object is only\nspecified via a single image. To tackle this challenge, we propose 3D-Fixup, a\nnew framework for editing 2D images guided by learned 3D priors. The framework\nsupports difficult editing situations such as object translation and 3D\nrotation. To achieve this, we leverage a training-based approach that harnesses\nthe generative power of diffusion models. As video data naturally encodes\nreal-world physical dynamics, we turn to video data for generating training\ndata pairs, i.e., a source and a target frame. Rather than relying solely on a\nsingle trained model to infer transformations between source and target frames,\nwe incorporate 3D guidance from an Image-to-3D model, which bridges this\nchallenging task by explicitly projecting 2D information into 3D space. We\ndesign a data generation pipeline to ensure high-quality 3D guidance throughout\ntraining. Results show that by integrating these 3D priors, 3D-Fixup\neffectively supports complex, identity coherent 3D-aware edits, achieving\nhigh-quality results and advancing the application of diffusion models in\nrealistic image manipulation. The code is provided at\nhttps://3dfixup.github.io/", "AI": {"tldr": "3D-Fixup is a framework for 3D-aware image editing using learned 3D priors and diffusion models, supporting complex edits like translation and rotation.", "motivation": "3D-aware image editing is challenging due to reliance on single images. The goal is to enable realistic, identity-coherent edits.", "method": "Leverages diffusion models and video data for training. Incorporates 3D guidance from an Image-to-3D model to project 2D into 3D space.", "result": "Achieves high-quality, complex 3D-aware edits, advancing realistic image manipulation.", "conclusion": "3D-Fixup effectively integrates 3D priors for coherent edits, enhancing diffusion model applications in image manipulation."}}
{"id": "2505.10307", "pdf": "https://arxiv.org/pdf/2505.10307", "abs": "https://arxiv.org/abs/2505.10307", "authors": ["Yiyang Zhao", "Chengpei Wu", "Lilin Zhang", "Ning Yang"], "title": "Negative Metric Learning for Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Graph contrastive learning (GCL) often suffers from false negatives, which\ndegrades the performance on downstream tasks. The existing methods addressing\nthe false negative issue usually rely on human prior knowledge, still leading\nGCL to suboptimal results. In this paper, we propose a novel Negative Metric\nLearning (NML) enhanced GCL (NML-GCL). NML-GCL employs a learnable Negative\nMetric Network (NMN) to build a negative metric space, in which false negatives\ncan be distinguished better from true negatives based on their distance to\nanchor node. To overcome the lack of explicit supervision signals for NML, we\npropose a joint training scheme with bi-level optimization objective, which\nimplicitly utilizes the self-supervision signals to iteratively optimize the\nencoder and the negative metric network. The solid theoretical analysis and the\nextensive experiments conducted on widely used benchmarks verify the\nsuperiority of the proposed method.", "AI": {"tldr": "NML-GCL introduces a learnable Negative Metric Network to address false negatives in GCL, improving performance via joint training and bi-level optimization.", "motivation": "Existing GCL methods struggle with false negatives due to reliance on human prior knowledge, leading to suboptimal results.", "method": "Proposes NML-GCL with a Negative Metric Network (NMN) for better false negative distinction and a joint training scheme with bi-level optimization.", "result": "Theoretical analysis and experiments on benchmarks confirm the method's superiority.", "conclusion": "NML-GCL effectively mitigates false negatives and enhances GCL performance."}}
{"id": "2505.10300", "pdf": "https://arxiv.org/pdf/2505.10300", "abs": "https://arxiv.org/abs/2505.10300", "authors": ["Muzhe Wu", "Yanzhi Zhao", "Shuyi Han", "Michael Xieyang Liu", "Hong Shen"], "title": "AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Responsible AI (RAI) efforts increasingly emphasize the importance of\naddressing potential harms early in the AI development lifecycle through\nsocial-technical lenses. However, in cross-functional industry teams, this work\nis often stalled by a persistent knowledge handoff challenge: the difficulty of\ntransferring high-level, early-stage technical design rationales from technical\nexperts to non-technical or user-facing roles for ethical evaluation and harm\nidentification. Through literature review and a co-design study with 8\npractitioners, we unpack how this challenge manifests -- technical design\nchoices are rarely handed off in ways that support meaningful engagement by\nnon-technical roles; collaborative workflows lack shared, visual structures to\nsupport mutual understanding; and non-technical practitioners are left without\nscaffolds for systematic harm evaluation. Existing tools like JIRA or Google\nDocs, while useful for product tracking, are ill-suited for supporting joint\nharm identification across roles, often requiring significant extra effort to\nalign understanding. To address this, we developed AI LEGO, a web-based\nprototype that supports cross-functional AI practitioners in effectively\nfacilitating knowledge handoff and identifying harmful design choices in the\nearly design stages. Technical roles use interactive blocks to draft\ndevelopment plans, while non-technical roles engage with those blocks through\nstage-specific checklists and LLM-driven persona simulations to surface\npotential harms. In a study with 18 cross-functional practitioners, AI LEGO\nincreased the volume and likelihood of harms identified compared to baseline\nworksheets. Participants found that its modular structure and persona prompts\nmade harm identification more accessible, fostering clearer and more\ncollaborative RAI practices in early design.", "AI": {"tldr": "AI LEGO, a web-based tool, addresses knowledge handoff challenges in cross-functional teams to improve early-stage harm identification in AI development.", "motivation": "The difficulty of transferring technical design rationales to non-technical roles for ethical evaluation stalls responsible AI efforts.", "method": "Developed AI LEGO, a prototype with interactive blocks and checklists, tested with 18 practitioners.", "result": "AI LEGO increased harm identification volume and likelihood, making the process more accessible and collaborative.", "conclusion": "AI LEGO fosters clearer and more collaborative responsible AI practices in early design stages."}}
{"id": "2406.02069", "pdf": "https://arxiv.org/pdf/2406.02069", "abs": "https://arxiv.org/abs/2406.02069", "authors": ["Zefan Cai", "Yichi Zhang", "Bofei Gao", "Yuliang Liu", "Yucheng Li", "Tianyu Liu", "Keming Lu", "Wayne Xiong", "Yue Dong", "Junjie Hu", "Wen Xiao"], "title": "PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this study, we investigate whether attention-based information flow inside\nlarge language models (LLMs) is aggregated through noticeable patterns for long\ncontext processing. Our observations reveal that LLMs aggregate information\nthrough Pyramidal Information Funneling where attention is scattering widely in\nlower layers, progressively consolidating within specific contexts, and\nultimately focusing on critical tokens (a.k.a massive activation or attention\nsink) in higher layers. Motivated by these insights, we developed PyramidKV, a\nnovel and effective KV cache compression method. This approach dynamically\nadjusts the KV cache size across different layers, allocating more cache in\nlower layers and less in higher ones, diverging from traditional methods that\nmaintain a uniform KV cache size. Our experimental evaluations, utilizing the\nLongBench benchmark, show that PyramidKV matches the performance of models with\na full KV cache while retaining only 12% of the KV cache, thus significantly\nreducing memory usage. In scenarios emphasizing memory efficiency, where only\n0.7% of the KV cache is maintained, PyramidKV surpasses other KV cache\ncompression techniques, achieving up to a 20.5 absolute accuracy improvement on\nTREC dataset. In the Needle-in-a-Haystack experiment, PyramidKV outperforms\ncompeting methods in maintaining long-context comprehension in LLMs; notably,\nretaining just 128 KV cache entries enables the LLAMA-3-70B model to achieve\n100.0 Acc. performance.", "AI": {"tldr": "PyramidKV, a novel KV cache compression method, dynamically adjusts cache size across layers, reducing memory usage while maintaining performance.", "motivation": "To address inefficient memory usage in LLMs by leveraging observed pyramidal information flow patterns.", "method": "Developed PyramidKV, adjusting KV cache size per layer (more in lower, less in higher layers).", "result": "Achieves full KV cache performance with 12% cache, and outperforms others with 0.7% cache (20.5% accuracy boost).", "conclusion": "PyramidKV efficiently compresses KV cache, enhancing memory efficiency without sacrificing performance."}}
{"id": "2505.09630", "pdf": "https://arxiv.org/pdf/2505.09630", "abs": "https://arxiv.org/abs/2505.09630", "authors": ["Tien Comlekoglu", "J. Quetzalc\u00f3atl Toledo-Mar\u00edn", "Douglas W. DeSimone", "Shayn M. Peirce", "Geoffrey Fox", "James A. Glazier"], "title": "Generative diffusion model surrogates for mechanistic agent-based biological models", "categories": ["q-bio.QM", "cs.CV", "cs.ET", "cs.PF"], "comment": null, "summary": "Mechanistic, multicellular, agent-based models are commonly used to\ninvestigate tissue, organ, and organism-scale biology at single-cell\nresolution. The Cellular-Potts Model (CPM) is a powerful and popular framework\nfor developing and interrogating these models. CPMs become computationally\nexpensive at large space- and time- scales making application and investigation\nof developed models difficult. Surrogate models may allow for the accelerated\nevaluation of CPMs of complex biological systems. However, the stochastic\nnature of these models means each set of parameters may give rise to different\nmodel configurations, complicating surrogate model development. In this work,\nwe leverage denoising diffusion probabilistic models to train a generative AI\nsurrogate of a CPM used to investigate \\textit{in vitro} vasculogenesis. We\ndescribe the use of an image classifier to learn the characteristics that\ndefine unique areas of a 2-dimensional parameter space. We then apply this\nclassifier to aid in surrogate model selection and verification. Our CPM model\nsurrogate generates model configurations 20,000 timesteps ahead of a reference\nconfiguration and demonstrates approximately a 22x reduction in computational\ntime as compared to native code execution. Our work represents a step towards\nthe implementation of DDPMs to develop digital twins of stochastic biological\nsystems.", "AI": {"tldr": "The paper proposes using denoising diffusion probabilistic models (DDPMs) as a generative AI surrogate for the computationally expensive Cellular-Potts Model (CPM) to accelerate simulations of complex biological systems like vasculogenesis.", "motivation": "CPMs are computationally intensive at large scales, making their application challenging. Surrogate models can speed up evaluations, but the stochastic nature of CPMs complicates surrogate development.", "method": "The authors use DDPMs to train a generative surrogate for a CPM simulating vasculogenesis. An image classifier helps identify unique parameter space regions for surrogate selection and verification.", "result": "The surrogate generates configurations 20,000 timesteps ahead of reference and reduces computational time by ~22x compared to native CPM execution.", "conclusion": "This work advances the use of DDPMs for creating digital twins of stochastic biological systems, demonstrating significant efficiency gains."}}
{"id": "2505.10322", "pdf": "https://arxiv.org/pdf/2505.10322", "abs": "https://arxiv.org/abs/2505.10322", "authors": ["Yijie Zhou", "Shi Pu"], "title": "Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Decentralized optimization has become vital for leveraging distributed data\nwithout central control, enhancing scalability and privacy. However, practical\ndeployments face fundamental challenges due to heterogeneous computation speeds\nand unpredictable communication delays. This paper introduces a refined model\nof Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) under\npractical assumptions of bounded computation and communication times. To\nunderstand the convergence of ADSGD, we first analyze Asynchronous Stochastic\nBlock Coordinate Descent (ASBCD) as a tool, and then show that ADSGD converges\nunder computation-delay-independent step sizes. The convergence result is\nestablished without assuming bounded data heterogeneity. Empirical experiments\nreveal that ADSGD outperforms existing methods in wall-clock convergence time\nacross various scenarios. With its simplicity, efficiency in memory and\ncommunication, and resilience to communication and computation delays, ADSGD is\nwell-suited for real-world decentralized learning tasks.", "AI": {"tldr": "The paper introduces a refined Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) model, addressing challenges like heterogeneous computation and communication delays, and shows its superior convergence and performance.", "motivation": "Decentralized optimization is crucial for distributed data use but faces challenges like heterogeneous speeds and delays. This work aims to improve scalability and privacy in such settings.", "method": "The paper analyzes Asynchronous Stochastic Block Coordinate Descent (ASBCD) as a tool and introduces ADSGD with bounded computation and communication assumptions, using delay-independent step sizes.", "result": "ADSGD converges without bounded data heterogeneity and outperforms existing methods in wall-clock convergence time, demonstrating efficiency and resilience.", "conclusion": "ADSGD is simple, efficient, and resilient, making it ideal for real-world decentralized learning tasks."}}
{"id": "2505.10315", "pdf": "https://arxiv.org/pdf/2505.10315", "abs": "https://arxiv.org/abs/2505.10315", "authors": ["Yang Li", "Xinyu Zhou", "Yitong Wang", "Liangxin Qian", "Jun Zhao"], "title": "Private Transformer Inference in MLaaS: A Survey", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Transformer models have revolutionized AI, powering applications like content\ngeneration and sentiment analysis. However, their deployment in Machine\nLearning as a Service (MLaaS) raises significant privacy concerns, primarily\ndue to the centralized processing of sensitive user data. Private Transformer\nInference (PTI) offers a solution by utilizing cryptographic techniques such as\nsecure multi-party computation and homomorphic encryption, enabling inference\nwhile preserving both user data and model privacy. This paper reviews recent\nPTI advancements, highlighting state-of-the-art solutions and challenges. We\nalso introduce a structured taxonomy and evaluation framework for PTI, focusing\non balancing resource efficiency with privacy and bridging the gap between\nhigh-performance inference and data privacy.", "AI": {"tldr": "The paper reviews Private Transformer Inference (PTI) for privacy-preserving AI, using cryptographic techniques to protect user data and model privacy, and introduces a taxonomy and evaluation framework.", "motivation": "Address privacy concerns in deploying Transformer models in MLaaS due to centralized processing of sensitive data.", "method": "Utilizes cryptographic techniques like secure multi-party computation and homomorphic encryption for PTI.", "result": "Presents a taxonomy and evaluation framework for PTI, balancing resource efficiency with privacy.", "conclusion": "PTI bridges the gap between high-performance inference and data privacy, with ongoing challenges."}}
{"id": "2407.12363", "pdf": "https://arxiv.org/pdf/2407.12363", "abs": "https://arxiv.org/abs/2407.12363", "authors": ["Jeonghyun Park", "Hwanhee Lee"], "title": "Conversational Query Reformulation with the Guidance of Retrieved Documents", "categories": ["cs.CL"], "comment": "18 pages, 3 figures, 16 tables", "summary": "Conversational search seeks to retrieve relevant passages for the given\nquestions in conversational question answering. Conversational Query\nReformulation (CQR) improves conversational search by refining the original\nqueries into de-contextualized forms to resolve the issues in the original\nqueries, such as omissions and coreferences. Previous CQR methods focus on\nimitating human written queries which may not always yield meaningful search\nresults for the retriever. In this paper, we introduce GuideCQR, a framework\nthat refines queries for CQR by leveraging key information from the initially\nretrieved documents. Specifically, GuideCQR extracts keywords and generates\nexpected answers from the retrieved documents, then unifies them with the\nqueries after filtering to add useful information that enhances the search\nprocess. Experimental results demonstrate that our proposed method achieves\nstate-of-the-art performance across multiple datasets, outperforming previous\nCQR methods. Additionally, we show that GuideCQR can get additional performance\ngains in conversational search using various types of queries, even for queries\nwritten by humans.", "AI": {"tldr": "GuideCQR improves conversational search by refining queries using key information from initially retrieved documents, outperforming previous methods.", "motivation": "Previous CQR methods imitate human queries, which may not always yield meaningful search results. GuideCQR aims to enhance retrieval by leveraging document-derived information.", "method": "GuideCQR extracts keywords and generates expected answers from retrieved documents, then filters and unifies them with queries to add useful information.", "result": "GuideCQR achieves state-of-the-art performance across multiple datasets and works well with various query types, including human-written ones.", "conclusion": "GuideCQR effectively enhances conversational search by refining queries with document-derived insights, demonstrating superior performance."}}
{"id": "2505.09819", "pdf": "https://arxiv.org/pdf/2505.09819", "abs": "https://arxiv.org/abs/2505.09819", "authors": ["Ruichen Yang", "Gy\u00f6rgy M. L\u00e9vay", "Christopher L. Hunt", "D\u00e1niel Czeiner", "Megan C. Hodgson", "Damini Agarwal", "Rahul R. Kaliki", "Nitish V. Thakor"], "title": "Visual Feedback of Pattern Separability Improves Myoelectric Decoding Performance of Upper Limb Prostheses", "categories": ["cs.HC", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "State-of-the-art upper limb myoelectric prostheses often use pattern\nrecognition (PR) control systems that translate electromyography (EMG) signals\ninto desired movements. As prosthesis movement complexity increases, users\noften struggle to produce sufficiently distinct EMG patterns for reliable\nclassification. Existing training typically involves heuristic, trial-and-error\nuser adjustments to static decoder boundaries. Goal: We introduce the Reviewer,\na 3D visual interface projecting EMG signals directly into the decoder's\nclassification space, providing intuitive, real-time insight into PR algorithm\nbehavior. This structured feedback reduces cognitive load and fosters mutual,\ndata-driven adaptation between user-generated EMG patterns and decoder\nboundaries. Methods: A 10-session study with 12 able-bodied participants\ncompared PR performance after motor-based training and updating using the\nReviewer versus conventional virtual arm visualization. Performance was\nassessed using a Fitts law task that involved the aperture of the cursor and\nthe control of orientation. Results: Participants trained with the Reviewer\nachieved higher completion rates, reduced overshoot, and improved path\nefficiency and throughput compared to the standard visualization group.\nSignificance: The Reviewer introduces decoder-informed motor training,\nfacilitating immediate and consistent PR-based myoelectric control\nimprovements. By iteratively refining control through real-time feedback, this\napproach reduces reliance on trial-and-error recalibration, enabling a more\nadaptive, self-correcting training framework. Conclusion: The 3D visual\nfeedback significantly improves PR control in novice operators through\nstructured training, enabling feedback-driven adaptation and reducing reliance\non extensive heuristic adjustments.", "AI": {"tldr": "The paper introduces the Reviewer, a 3D visual interface for myoelectric prostheses, improving pattern recognition control by providing real-time feedback and reducing cognitive load.", "motivation": "Users struggle with producing distinct EMG patterns for reliable classification in complex prosthesis movements. Existing training lacks intuitive feedback.", "method": "A 10-session study with 12 able-bodied participants compared PR performance using the Reviewer versus conventional virtual arm visualization, assessed via a Fitts law task.", "result": "Participants using the Reviewer achieved higher completion rates, reduced overshoot, and improved path efficiency and throughput.", "conclusion": "The 3D visual feedback of the Reviewer enhances PR control, enabling feedback-driven adaptation and reducing heuristic adjustments."}}
{"id": "2505.10325", "pdf": "https://arxiv.org/pdf/2505.10325", "abs": "https://arxiv.org/abs/2505.10325", "authors": ["Athanasios Tziouvaras", "Blaz Bertalanic", "George Floros", "Kostas Kolomvatsos", "Panagiotis Sarigiannidis", "Carolina Fortuna"], "title": "A Representation Learning Approach to Feature Drift Detection in Wireless Networks", "categories": ["cs.LG"], "comment": null, "summary": "AI is foreseen to be a centerpiece in next generation wireless networks\nenabling enabling ubiquitous communication as well as new services. However, in\nreal deployment, feature distribution changes may degrade the performance of AI\nmodels and lead to undesired behaviors. To counter for undetected model\ndegradation, we propose ALERT; a method that can detect feature distribution\nchanges and trigger model re-training that works well on two wireless network\nuse cases: wireless fingerprinting and link anomaly detection. ALERT includes\nthree components: representation learning, statistical testing and utility\nassessment. We rely on MLP for designing the representation learning component,\non Kolmogorov-Smirnov and Population Stability Index tests for designing the\nstatistical testing and a new function for utility assessment. We show the\nsuperiority of the proposed method against ten standard drift detection methods\navailable in the literature on two wireless network use cases.", "AI": {"tldr": "ALERT is a method to detect feature distribution changes in AI models for wireless networks, triggering re-training to maintain performance. It outperforms ten standard drift detection methods.", "motivation": "AI models in wireless networks may degrade due to feature distribution changes, leading to undesired behaviors. ALERT addresses this issue.", "method": "ALERT uses representation learning (MLP), statistical testing (Kolmogorov-Smirnov and Population Stability Index), and a new utility assessment function.", "result": "ALERT outperforms ten standard drift detection methods in wireless fingerprinting and link anomaly detection.", "conclusion": "ALERT effectively detects feature distribution changes and ensures robust AI model performance in wireless networks."}}
{"id": "2505.10321", "pdf": "https://arxiv.org/pdf/2505.10321", "abs": "https://arxiv.org/abs/2505.10321", "authors": ["Julius Henke"], "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "categories": ["cs.CR", "cs.AI"], "comment": "24 pages, 1 figure, for implementation, see\n  https://github.com/JuliusHenke/autopentest", "summary": "A recent area of increasing research is the use of Large Language Models\n(LLMs) in penetration testing, which promises to reduce costs and thus allow\nfor higher frequency. We conduct a review of related work, identifying best\npractices and common evaluation issues. We then present AutoPentest, an\napplication for performing black-box penetration tests with a high degree of\nautonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent\nframework LangChain. It can perform complex multi-step tasks, augmented by\nexternal tools and knowledge bases. We conduct a study on three\ncapture-the-flag style Hack The Box (HTB) machines, comparing our\nimplementation AutoPentest with the baseline approach of manually using the\nChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the\nsubtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.\nWe measure a total cost of \\$96.20 US when using AutoPentest across all\nexperiments, while a one-month subscription to ChatGPT Plus costs \\$20. The\nresults show that further implementation efforts and the use of more powerful\nLLMs released in the future are likely to make this a viable part of\nvulnerability management.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2407.12393", "pdf": "https://arxiv.org/pdf/2407.12393", "abs": "https://arxiv.org/abs/2407.12393", "authors": ["Zheni Zeng", "Jiayi Chen", "Huimin Chen", "Yukun Yan", "Yuxuan Chen", "Zhenghao Liu", "Zhiyuan Liu", "Maosong Sun"], "title": "PersLLM: A Personified Training Approach for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "8 pages for main text, 5 figures", "summary": "Large language models (LLMs) exhibit human-like intelligence, enabling them\nto simulate human behavior and support various applications that require both\nhumanized communication and extensive knowledge reserves. Efforts are made to\npersonify LLMs with special training data or hand-crafted prompts, while\ncorrespondingly faced with challenges such as insufficient data usage or rigid\nbehavior patterns. Consequently, personified LLMs fail to capture personified\nknowledge or express persistent opinion. To fully unlock the potential of LLM\npersonification, we propose PersLLM, a framework for better data construction\nand model tuning. For insufficient data usage, we incorporate strategies such\nas Chain-of-Thought prompting and anti-induction, improving the quality of data\nconstruction and capturing the personality experiences, knowledge, and thoughts\nmore comprehensively. For rigid behavior patterns, we design the tuning process\nand introduce automated DPO to enhance the specificity and dynamism of the\nmodels' personalities, which leads to a more natural opinion communication.\nBoth automated metrics and expert human evaluations demonstrate the\neffectiveness of our approach. Case studies in human-machine interactions and\nmulti-agent systems further suggest potential application scenarios and future\ndirections for LLM personification.", "AI": {"tldr": "PersLLM is a framework to enhance LLM personification by improving data construction and model tuning, addressing challenges like insufficient data usage and rigid behavior patterns.", "motivation": "Current personified LLMs struggle with capturing personalized knowledge and expressing persistent opinions due to poor data usage and inflexible behavior.", "method": "The framework uses Chain-of-Thought prompting, anti-induction, and automated DPO for better data quality and dynamic personality tuning.", "result": "PersLLM improves personality specificity and dynamism, validated by automated metrics and human evaluations.", "conclusion": "The approach shows promise for applications in human-machine interactions and multi-agent systems, suggesting future directions for LLM personification."}}
{"id": "2505.10075", "pdf": "https://arxiv.org/pdf/2505.10075", "abs": "https://arxiv.org/abs/2505.10075", "authors": ["Jun Guo", "Xiaojian Ma", "Yikai Wang", "Min Yang", "Huaping Liu", "Qing Li"], "title": "FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "Project page: see https://sharinka0715.github.io/FlowDreamer/", "summary": "This paper investigates training better visual world models for robot\nmanipulation, i.e., models that can predict future visual observations by\nconditioning on past frames and robot actions. Specifically, we consider world\nmodels that operate on RGB-D frames (RGB-D world models). As opposed to\ncanonical approaches that handle dynamics prediction mostly implicitly and\nreconcile it with visual rendering in a single model, we introduce FlowDreamer,\nwhich adopts 3D scene flow as explicit motion representations. FlowDreamer\nfirst predicts 3D scene flow from past frame and action conditions with a\nU-Net, and then a diffusion model will predict the future frame utilizing the\nscene flow. FlowDreamer is trained end-to-end despite its modularized nature.\nWe conduct experiments on 4 different benchmarks, covering both video\nprediction and visual planning tasks. The results demonstrate that FlowDreamer\nachieves better performance compared to other baseline RGB-D world models by 7%\non semantic similarity, 11% on pixel quality, and 6% on success rate in various\nrobot manipulation domains.", "AI": {"tldr": "FlowDreamer improves RGB-D world models for robot manipulation by using explicit 3D scene flow and diffusion models, outperforming baselines in semantic similarity, pixel quality, and success rate.", "motivation": "To enhance visual world models for robot manipulation by explicitly modeling motion with 3D scene flow, addressing limitations of implicit dynamics prediction in existing approaches.", "method": "FlowDreamer predicts 3D scene flow with a U-Net and uses a diffusion model for future frame prediction, trained end-to-end.", "result": "Outperforms baselines by 7% in semantic similarity, 11% in pixel quality, and 6% in success rate across four benchmarks.", "conclusion": "FlowDreamer's explicit motion representation and modular design significantly improve performance in robot manipulation tasks."}}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components.", "AI": {"tldr": "The paper addresses the challenge of RL agents adapting to changing environments without forgetting prior knowledge, proposing prioritized exploration and structured representations as solutions.", "motivation": "Real-world systems operate in dynamic environments, but conventional RL methods struggle with adaptation and catastrophic forgetting.", "method": "The dissertation introduces prioritized exploration and sampling strategies, along with structured representations for knowledge preservation.", "result": "The approach enables efficient online adaptation by focusing on relevant experiences and updating reusable components selectively.", "conclusion": "Efficient RL adaptation in dynamic environments requires prioritized exploration and structured knowledge preservation."}}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon.", "AI": {"tldr": "The paper explores how ensembles of random classifiers can exhibit optimal collective behavior under a Gibbs measure, with a universal optimal temperature independent of the teacher classifier or ensemble size.", "motivation": "To understand the emergence of deterministic behaviors from random components in machine learning systems.", "method": "Introduces a theoretical model using the Gibbs measure with classification loss as energy, validated analytically and numerically for Gaussian-distributed samples and teacher perceptrons.", "result": "Optimal temperature for classification is universal, independent of the teacher classifier or ensemble size, and confirmed on MNIST.", "conclusion": "The study reveals self-organizing behavior in random classifier ensembles, with implications for high-quality datasets."}}
{"id": "2407.12665", "pdf": "https://arxiv.org/pdf/2407.12665", "abs": "https://arxiv.org/abs/2407.12665", "authors": ["Chenze Shao", "Fandong Meng", "Jie Zhou"], "title": "Beyond Next Token Prediction: Patch-Level Training for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICLR 2025 Spotlight", "summary": "The prohibitive training costs of Large Language Models (LLMs) have emerged\nas a significant bottleneck in the development of next-generation LLMs. In this\npaper, we show that it is possible to significantly reduce the training costs\nof LLMs without sacrificing their performance. Specifically, we introduce\npatch-level training for LLMs, in which multiple tokens are aggregated into a\nunit of higher information density, referred to as a `patch', to serve as the\nfundamental text unit for training LLMs. During patch-level training, we feed\nthe language model shorter sequences of patches and train it to predict the\nnext patch, thereby processing the majority of the training data at a\nsignificantly reduced cost. Following this, the model continues token-level\ntraining on the remaining training data to align with the inference mode.\nExperiments on a diverse range of models (370M-2.7B parameters) demonstrate\nthat patch-level training can reduce the overall training costs to 0.5$\\times$,\nwithout compromising the model performance compared to token-level training.\nSource code: https://github.com/shaochenze/PatchTrain.", "AI": {"tldr": "Patch-level training reduces LLM training costs by 50% without performance loss by aggregating tokens into patches for initial training.", "motivation": "High training costs of LLMs hinder development; this paper aims to reduce costs while maintaining performance.", "method": "Introduces patch-level training where tokens are grouped into patches for initial training, followed by token-level training.", "result": "Experiments show 50% cost reduction with no performance drop across models (370M-2.7B parameters).", "conclusion": "Patch-level training is an effective method to cut LLM training costs without sacrificing quality."}}
{"id": "2505.10144", "pdf": "https://arxiv.org/pdf/2505.10144", "abs": "https://arxiv.org/abs/2505.10144", "authors": ["Xuechang Tu", "Lukas Radl", "Michael Steiner", "Markus Steinberger", "Bernhard Kerbl", "Fernando de la Torre"], "title": "VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality", "categories": ["cs.GR", "cs.CV"], "comment": "I3D'25 (PACMCGIT); Project Page: https://cekavis.site/VRSplat/", "summary": "3D Gaussian Splatting (3DGS) has rapidly become a leading technique for\nnovel-view synthesis, providing exceptional performance through efficient\nsoftware-based GPU rasterization. Its versatility enables real-time\napplications, including on mobile and lower-powered devices. However, 3DGS\nfaces key challenges in virtual reality (VR): (1) temporal artifacts, such as\npopping during head movements, (2) projection-based distortions that result in\ndisturbing and view-inconsistent floaters, and (3) reduced framerates when\nrendering large numbers of Gaussians, falling below the critical threshold for\nVR. Compared to desktop environments, these issues are drastically amplified by\nlarge field-of-view, constant head movements, and high resolution of\nhead-mounted displays (HMDs). In this work, we introduce VRSplat: we combine\nand extend several recent advancements in 3DGS to address challenges of VR\nholistically. We show how the ideas of Mini-Splatting, StopThePop, and Optimal\nProjection can complement each other, by modifying the individual techniques\nand core 3DGS rasterizer. Additionally, we propose an efficient foveated\nrasterizer that handles focus and peripheral areas in a single GPU launch,\navoiding redundant computations and improving GPU utilization. Our method also\nincorporates a fine-tuning step that optimizes Gaussian parameters based on\nStopThePop depth evaluations and Optimal Projection. We validate our method\nthrough a controlled user study with 25 participants, showing a strong\npreference for VRSplat over other configurations of Mini-Splatting. VRSplat is\nthe first, systematically evaluated 3DGS approach capable of supporting modern\nVR applications, achieving 72+ FPS while eliminating popping and\nstereo-disrupting floaters.", "AI": {"tldr": "VRSplat enhances 3D Gaussian Splatting (3DGS) for VR by addressing temporal artifacts, projection distortions, and framerate issues, combining Mini-Splatting, StopThePop, and Optimal Projection with a foveated rasterizer.", "motivation": "3DGS faces challenges in VR like temporal artifacts, projection distortions, and low framerates, which are exacerbated by VR's demands.", "method": "VRSplat integrates Mini-Splatting, StopThePop, and Optimal Projection, modifies the 3DGS rasterizer, and introduces a foveated rasterizer. It also fine-tunes Gaussian parameters.", "result": "Achieves 72+ FPS, eliminates popping and floaters, and is preferred in user studies over Mini-Splatting.", "conclusion": "VRSplat is the first systematically evaluated 3DGS method suitable for modern VR, addressing key challenges effectively."}}
{"id": "2505.10344", "pdf": "https://arxiv.org/pdf/2505.10344", "abs": "https://arxiv.org/abs/2505.10344", "authors": ["Alan Jeffares", "Liyuan Liu"], "title": "An Introduction to Discrete Variational Autoencoders", "categories": ["cs.LG"], "comment": "Tutorial paper", "summary": "Variational Autoencoders (VAEs) are well-established as a principled approach\nto probabilistic unsupervised learning with neural networks. Typically, an\nencoder network defines the parameters of a Gaussian distributed latent space\nfrom which we can sample and pass realizations to a decoder network. This model\nis trained to reconstruct its inputs and is optimized through the evidence\nlower bound. In recent years, discrete latent spaces have grown in popularity,\nsuggesting that they may be a natural choice for many data modalities (e.g.\ntext). In this tutorial, we provide a rigorous, yet practical, introduction to\ndiscrete variational autoencoders -- specifically, VAEs in which the latent\nspace is made up of latent variables that follow a categorical distribution. We\nassume only a basic mathematical background with which we carefully derive each\nstep from first principles. From there, we develop a concrete training recipe\nand provide an example implementation, hosted at\nhttps://github.com/alanjeffares/discreteVAE.", "AI": {"tldr": "A tutorial on discrete variational autoencoders (VAEs) with categorical latent variables, providing a practical introduction and implementation.", "motivation": "Discrete latent spaces are increasingly popular and may better suit certain data types (e.g., text), motivating a need for clear guidance on discrete VAEs.", "method": "Derives discrete VAEs from first principles, focusing on categorical latent variables, and provides a training recipe with an example implementation.", "result": "A concrete framework and implementation for discrete VAEs, accessible to those with basic math knowledge.", "conclusion": "Discrete VAEs are a viable and practical approach for probabilistic unsupervised learning, especially for discrete data modalities."}}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available.", "AI": {"tldr": "SMTOs balance task learning in multi-task settings, but recent critiques claim equal-weighted tasks can match SMTOs. This paper evaluates SMTOs empirically, finding they perform well, but fixed weights can also compete.", "motivation": "To clarify whether SMTOs outperform equal-weighted tasks, addressing critiques about hyperparameter and regularization issues.", "method": "Extensive empirical evaluation of SMTOs on complex multi-task problems, comparing them to uniform loss methods.", "result": "SMTOs perform well, but fixed weights can achieve similar performance. Uniform loss sometimes matches SMTOs.", "conclusion": "SMTOs are effective, but fixed weights can be competitive, with uniform loss performing similarly in some cases."}}
{"id": "2407.15508", "pdf": "https://arxiv.org/pdf/2407.15508", "abs": "https://arxiv.org/abs/2407.15508", "authors": ["Yifei Gao", "Jie Ou", "Lei Wang", "Jun Cheng", "Mengchu Zhou"], "title": "Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "Effecient Quantization Methods for LLMs", "summary": "The quantization of large language models (LLMs) has been a prominent\nresearch area aimed at enabling their lightweight deployment in practice.\nExisting research about LLM's quantization has mainly explored the interplay\nbetween weights and activations, or employing auxiliary components while\nneglecting the necessity of adjusting weights during quantization.\nConsequently, original weight distributions frequently fail to yield desired\nresults after round-to-nearest (RTN) quantization. Even though incorporating\ntechniques such as mixed precision and low-rank error approximation in LLM's\nquantization can yield improved results, they inevitably introduce additional\ncomputational overhead. On the other hand, traditional techniques for weight\nquantization, such as Generative Post-Training Quantization, rely on manually\ntweaking weight distributions to minimize local errors, but they fall short of\nachieving globally optimal outcomes. Although the recently proposed Learnable\nSingular-value Increment improves global weight quantization by modifying\nweight distributions, it disrupts the original distribution considerably. This\nintroduces pronounced bias toward the training data and can degrade downstream\ntask performance. In this paper, we introduce Singular-value Diagonal\nExpansion, a more nuanced approach to refining weight distributions to achieve\nbetter quantization alignment. Furthermore, we introduce Cross-layer Learning\nthat improves overall quantization outcomes by distributing errors more evenly\nacross layers. Our plug-and-play weight-quantization methods demonstrate\nsubstantial performance improvements over state-of-the-art approaches,\nincluding OmniQuant, DuQuant, and PrefixQuant.", "AI": {"tldr": "The paper introduces Singular-value Diagonal Expansion and Cross-layer Learning to improve weight quantization in large language models, outperforming existing methods.", "motivation": "Existing quantization techniques for LLMs either introduce computational overhead or fail to achieve globally optimal results, prompting the need for better weight distribution refinement.", "method": "Proposes Singular-value Diagonal Expansion for refined weight distribution and Cross-layer Learning for even error distribution across layers.", "result": "The methods outperform state-of-the-art approaches like OmniQuant, DuQuant, and PrefixQuant.", "conclusion": "The proposed techniques offer a plug-and-play solution for better weight quantization in LLMs, enhancing performance without disrupting original distributions."}}
{"id": "2505.10312", "pdf": "https://arxiv.org/pdf/2505.10312", "abs": "https://arxiv.org/abs/2505.10312", "authors": ["Anh Tuan Ha", "Hoang Khang Phan", "Thai Minh Tien Ngo", "Anh Phan Truong", "Nhat Tan Le"], "title": "SOS: A Shuffle Order Strategy for Data Augmentation in Industrial Human Activity Recognition", "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "In the realm of Human Activity Recognition (HAR), obtaining high quality and\nvariance data is still a persistent challenge due to high costs and the\ninherent variability of real-world activities. This study introduces a\ngeneration dataset by deep learning approaches (Attention Autoencoder and\nconditional Generative Adversarial Networks). Another problem that data\nheterogeneity is a critical challenge, one of the solutions is to shuffle the\ndata to homogenize the distribution. Experimental results demonstrate that the\nrandom sequence strategy significantly improves classification performance,\nachieving an accuracy of up to 0.70 $\\pm$ 0.03 and a macro F1 score of 0.64\n$\\pm$ 0.01. For that, disrupting temporal dependencies through random sequence\nreordering compels the model to focus on instantaneous recognition, thereby\nimproving robustness against activity transitions. This approach not only\nbroadens the effective training dataset but also offers promising avenues for\nenhancing HAR systems in complex, real-world scenarios.", "AI": {"tldr": "The paper proposes using deep learning (Attention Autoencoder and cGANs) to generate diverse HAR data and shuffling data to address heterogeneity, improving classification performance.", "motivation": "High-quality, diverse HAR data is costly and hard to obtain, and data heterogeneity complicates model training.", "method": "Deep learning (Attention Autoencoder and cGANs) for data generation and random sequence shuffling to homogenize data.", "result": "Random shuffling improved accuracy to 0.70 \u00b1 0.03 and macro F1 to 0.64 \u00b1 0.01, enhancing robustness.", "conclusion": "The approach expands training data and improves HAR system performance in real-world scenarios."}}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petr\u00e9n Bach Hansen", "Lasse Krogsb\u00f8ll", "Jonas Lyngs\u00f8", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maal\u00f8e"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support.", "AI": {"tldr": "The paper introduces FactsR, a method for real-time extraction of clinical information during consultations to generate more accurate and concise AI-scribed notes, reducing errors and clinician workload.", "motivation": "Current AI scribes rely on post-consultation prompts, leading to long, error-prone notes and increased clinician workload, risking patient safety.", "method": "FactsR extracts salient clinical information (Facts) in real-time during consultations and uses it recursively for note generation, keeping clinicians in the loop.", "result": "FactsR produces more accurate and concise notes, minimizing hallucinations and misrepresentation, while enabling real-time decision support.", "conclusion": "FactsR improves AI-scribed documentation by integrating real-time reasoning and clinician involvement, enhancing accuracy and patient safety."}}
{"id": "2505.10371", "pdf": "https://arxiv.org/pdf/2505.10371", "abs": "https://arxiv.org/abs/2505.10371", "authors": ["Kai Sun", "Peibo Duan", "Levin Kuhlmann", "Beilun Wang", "Bin Zhang"], "title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF.", "AI": {"tldr": "The paper addresses the 'dilemma of gamma' in SNNs by proposing the ILIF neuron model, which balances gradient propagation and energy efficiency.", "motivation": "Surrogate gradients in SNNs face a trade-off between overactivation (large gamma) and vanishing gradients (small gamma), impacting energy and performance.", "method": "Introduces the ILIF neuron model with inhibitory mechanisms to control overactivation while maintaining gradient flow.", "result": "ILIF improves energy efficiency, stabilizes training, and enhances accuracy across datasets.", "conclusion": "The ILIF model effectively resolves the gamma dilemma, offering a biologically inspired solution for efficient SNN training."}}
{"id": "2409.13338", "pdf": "https://arxiv.org/pdf/2409.13338", "abs": "https://arxiv.org/abs/2409.13338", "authors": ["David Herel", "Vojtech Bartek", "Jiri Jirak", "Tomas Mikolov"], "title": "Time Awareness in Large Language Models: Benchmarking Fact Recall Across Time", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Who is the US President? The answer changes depending on when the question is\nasked. While large language models (LLMs) are evaluated on various reasoning\ntasks, they often miss a crucial dimension: time. In real-world scenarios, the\ncorrectness of answers is frequently tied to temporal context. To address this\ngap, we present a novel framework and dataset spanning over 8,000 events from\n2018 to 2024, annotated with day-level granularity and sourced globally across\ndomains such as politics, science, and business. Our TimeShift evaluation\nmethod systematically probes LLMs for temporal reasoning, revealing that base\nmodels often outperform instruction-tuned and synthetic-trained counterparts on\ntime-sensitive recall. Additionally, we find that even large-scale models\nexhibit brittleness in handling paraphrased facts, highlighting unresolved\nchallenges in temporal consistency. By identifying these limitations, our work\nprovides a significant step toward advancing time-aware language models capable\nof adapting to the dynamic nature of real-world knowledge.", "AI": {"tldr": "The paper introduces a framework and dataset for evaluating LLMs on temporal reasoning, revealing their limitations in handling time-sensitive and paraphrased facts.", "motivation": "To address the gap in LLMs' ability to handle temporal context in real-world scenarios, where answer correctness often depends on time.", "method": "A novel framework and dataset with 8,000+ events (2018-2024) annotated at day-level granularity, evaluated using the TimeShift method.", "result": "Base models outperform instruction-tuned and synthetic-trained models on time-sensitive recall, but all exhibit brittleness with paraphrased facts.", "conclusion": "The work advances time-aware LLMs by highlighting unresolved challenges in temporal consistency and dynamic knowledge adaptation."}}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space.", "AI": {"tldr": "PIF is a novel anomaly detection method combining adaptive isolation and preference embedding, outperforming state-of-the-art techniques.", "motivation": "Detecting anomalies in structured patterns requires flexible and efficient methods.", "method": "Embeds data in high-dimensional space and uses PI-Forest, a tree-based method, for anomaly scoring.", "result": "PIF outperforms existing techniques, with PI-Forest excelling in measuring arbitrary distances and isolating points.", "conclusion": "PIF is an effective anomaly detection method, particularly for structured patterns."}}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications.", "AI": {"tldr": "SCGP introduces a group-theoretic method to enhance GNNs by embedding Schreier-coset features, improving long-range message passing without altering graph topology, while maintaining efficiency.", "motivation": "Over-squashing in GNNs limits expressive capacity by compressing distant node information. Existing solutions like Cayley graphs introduce scalability issues.", "method": "SCGP uses Schreier-coset embeddings to enrich node features, preserving graph topology and embedding bottleneck-free connectivity patterns.", "result": "SCGP matches or outperforms expander graph and rewired GNN baselines, excelling in hierarchical and modular structures with low latency and memory.", "conclusion": "SCGP is efficient, scalable, and suitable for real-time applications, addressing over-squashing without compromising performance."}}
{"id": "2505.10375", "pdf": "https://arxiv.org/pdf/2505.10375", "abs": "https://arxiv.org/abs/2505.10375", "authors": ["Rui Melo", "Claudia Mamede", "Andre Catarino", "Rui Abreu", "Henrique Lopes Cardoso"], "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision.", "AI": {"tldr": "SAEs (Sparse Autoencoders) are explored as a lightweight, interpretable alternative for bug detection in Java functions, outperforming traditional methods and fine-tuned models with up to 89% F1 score.", "motivation": "Traditional vulnerability detection methods have high false positives and scalability issues, driving interest in AI-based solutions. LLMs are complex and opaque, prompting the need for interpretable alternatives like SAEs.", "method": "SAEs are applied to representations from GPT-2 Small and Gemma 2B to detect bugs in Java functions without fine-tuning the LLMs.", "result": "SAEs achieve up to 89% F1 score in bug detection, outperforming fine-tuned transformer baselines.", "conclusion": "SAEs can effectively detect software bugs from pretrained LLM representations without fine-tuning, offering a lightweight and interpretable solution."}}
{"id": "2410.04526", "pdf": "https://arxiv.org/pdf/2410.04526", "abs": "https://arxiv.org/abs/2410.04526", "authors": ["Siqiao Xue", "Xiaojing Li", "Fan Zhou", "Qingyang Dai", "Zhixuan Chu", "Hongyuan Mei"], "title": "FAMMA: A Benchmark for Financial Domain Multilingual Multimodal Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this paper, we introduce FAMMA, an open-source benchmark for\n\\underline{f}in\\underline{a}ncial \\underline{m}ultilingual\n\\underline{m}ultimodal question \\underline{a}nswering (QA). Our benchmark aims\nto evaluate the abilities of large language models (LLMs) in answering complex\nreasoning questions that require advanced financial knowledge. The benchmark\nhas two versions: FAMMA-Basic consists of 1,945 questions extracted from\nuniversity textbooks and exams, along with human-annotated answers and\nrationales; FAMMA-LivePro consists of 103 novel questions created by human\ndomain experts, with answers and rationales held out from the public for a\ncontamination-free evaluation. These questions cover advanced knowledge of 8\nmajor subfields in finance (e.g., corporate finance, derivatives, and portfolio\nmanagement). Some are in Chinese or French, while a majority of them are in\nEnglish. Each question has some non-text data such as charts, diagrams, or\ntables. Our experiments reveal that FAMMA poses a significant challenge on\nLLMs, including reasoning models such as GPT-o1 and DeepSeek-R1. Additionally,\nwe curated 1,270 reasoning trajectories of DeepSeek-R1 on the FAMMA-Basic data,\nand fine-tuned a series of open-source Qwen models using this reasoning data.\nWe found that training a model on these reasoning trajectories can\nsignificantly improve its performance on FAMMA-LivePro. We released our\nleaderboard, data, code, and trained models at\nhttps://famma-bench.github.io/famma/.", "AI": {"tldr": "FAMMA is an open-source benchmark for financial multilingual multimodal QA, challenging LLMs with complex reasoning questions. It includes two versions: FAMMA-Basic (1,945 textbook/extracted questions) and FAMMA-LivePro (103 expert-created questions). Experiments show LLMs struggle, but fine-tuning with reasoning data improves performance.", "motivation": "To evaluate LLMs' abilities in complex financial reasoning across languages and modalities, addressing gaps in existing benchmarks.", "method": "Created FAMMA-Basic (textbook/extracted questions) and FAMMA-LivePro (expert-created questions) with multilingual, multimodal content. Evaluated LLMs like GPT-o1 and DeepSeek-R1, and fine-tuned Qwen models using reasoning trajectories.", "result": "FAMMA challenges LLMs, with fine-tuned models showing significant improvement on FAMMA-LivePro.", "conclusion": "FAMMA provides a robust benchmark for financial QA, highlighting LLMs' limitations and the value of reasoning data for improvement."}}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios.", "AI": {"tldr": "SEAL is a NAS-based framework for incremental learning that dynamically adapts model structure, reducing forgetting and improving accuracy while keeping model size small.", "motivation": "Existing NAS-based incremental learning methods expand models excessively, making them impractical for resource-constrained environments. SEAL addresses this by selective expansion.", "method": "SEAL uses a NAS component to dynamically expand the model only when necessary, based on capacity estimation, and preserves stability via cross-distillation training.", "result": "SEAL outperforms prior methods by reducing forgetting, enhancing accuracy, and maintaining a smaller model size across benchmarks.", "conclusion": "SEAL demonstrates the potential of combining NAS with selective expansion for efficient and adaptive incremental learning."}}
{"id": "2505.10407", "pdf": "https://arxiv.org/pdf/2505.10407", "abs": "https://arxiv.org/abs/2505.10407", "authors": ["Wenhao Ding", "Choon Hwai Yap", "Kangjun Ji", "Sim\u00e3o Castro"], "title": "Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning", "categories": ["cs.LG", "68T07"], "comment": "10 pages, 2 figures", "summary": "A generative model for the mesh geometry of intracranial aneurysms (IA) is\ncrucial for training networks to predict blood flow forces in real time, which\nis a key factor affecting disease progression. This need is necessitated by the\nabsence of a large IA image datasets. Existing shape generation methods\nstruggle to capture realistic IA features and ignore the relationship between\nIA pouches and parent vessels, limiting physiological realism and their\ngeneration cannot be controlled to have specific morphological measurements. We\npropose AneuG, a two-stage Variational Autoencoder (VAE)-based IA mesh\ngenerator. In the first stage, AneuG generates low-dimensional Graph Harmonic\nDeformation (GHD) tokens to encode and reconstruct aneurysm pouch shapes,\nconstrained to morphing energy statistics truths. GHD enables more accurate\nshape encoding than alternatives. In the second stage, AneuG generates parent\nvessels conditioned on GHD tokens, by generating vascular centreline and\npropagating the cross-section. AneuG's IA shape generation can further be\nconditioned to have specific clinically relevant morphological measurements.\nThis is useful for studies to understand shape variations represented by\nclinical measurements, and for flow simulation studies to understand effects of\nspecific clinical shape parameters on fluid dynamics. Source code and\nimplementation details are available at\nhttps://github.com/anonymousaneug/AneuG.", "AI": {"tldr": "AneuG is a two-stage VAE-based model for generating realistic intracranial aneurysm meshes, addressing the lack of large datasets and improving physiological realism by capturing pouch-vessel relationships and enabling control over morphological measurements.", "motivation": "The absence of large IA image datasets and limitations of existing shape generation methods in capturing realistic features and relationships between IA pouches and parent vessels drive the need for a better generative model.", "method": "AneuG uses a two-stage VAE approach: first, it generates GHD tokens for aneurysm pouches, and second, it generates parent vessels conditioned on these tokens, allowing control over morphological measurements.", "result": "AneuG produces realistic IA meshes with accurate shape encoding and the ability to condition generation on specific clinical measurements, enhancing studies on shape variations and fluid dynamics.", "conclusion": "AneuG offers a robust solution for generating realistic IA meshes, facilitating research on disease progression and fluid dynamics by enabling controlled morphological variations."}}
{"id": "2505.10393", "pdf": "https://arxiv.org/pdf/2505.10393", "abs": "https://arxiv.org/abs/2505.10393", "authors": ["Agustin Medina", "Marcelo Arlego", "Carlos A. Lamas"], "title": "Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training", "categories": ["cond-mat.str-el", "cs.AI"], "comment": "25 pages, 14 figures", "summary": "We investigate the efficient learning of magnetic phases using artificial\nneural networks trained on synthetic data, combining computational simplicity\nwith physics-informed strategies. Focusing on the diluted Ising model, which\nlacks an exact analytical solution, we explore two complementary approaches: a\nsupervised classification using simple dense neural networks, and an\nunsupervised detection of phase transitions using convolutional autoencoders\ntrained solely on idealized spin configurations.\n  To enhance model performance, we incorporate two key forms of\nphysics-informed guidance. First, we exploit architectural biases which\npreferentially amplify features related to symmetry breaking. Second, we\ninclude training configurations that explicitly break $\\mathbb{Z}_2$ symmetry,\nreinforcing the network's ability to detect ordered phases. These mechanisms,\nacting in tandem, increase the network's sensitivity to phase structure even in\nthe absence of explicit labels. We validate the machine learning predictions\nthrough comparison with direct numerical estimates of critical temperatures and\npercolation thresholds.\n  Our results show that synthetic, structured, and computationally efficient\ntraining schemes can reveal physically meaningful phase boundaries, even in\ncomplex systems. This framework offers a low-cost and robust alternative to\nconventional methods, with potential applications in broader condensed matter\nand statistical physics contexts.", "AI": {"tldr": "Efficient learning of magnetic phases using neural networks trained on synthetic data, combining physics-informed strategies to detect phase transitions.", "motivation": "To explore efficient and low-cost methods for detecting phase transitions in complex systems like the diluted Ising model, which lacks exact analytical solutions.", "method": "Two approaches: supervised classification with dense neural networks and unsupervised detection using convolutional autoencoders. Physics-informed guidance includes architectural biases and training configurations breaking Z2 symmetry.", "result": "Synthetic training schemes reveal meaningful phase boundaries, validated against numerical estimates of critical temperatures and percolation thresholds.", "conclusion": "The framework provides a robust, low-cost alternative to conventional methods, applicable in condensed matter and statistical physics."}}
{"id": "2410.11516", "pdf": "https://arxiv.org/pdf/2410.11516", "abs": "https://arxiv.org/abs/2410.11516", "authors": ["Neil Rathi", "Johannes Mehrer", "Badr AlKhamissi", "Taha Binhuraib", "Nicholas M. Blauch", "Martin Schrimpf"], "title": "TopoLM: brain-like spatio-functional organization in a topographic language model", "categories": ["cs.CL"], "comment": null, "summary": "Neurons in the brain are spatially organized such that neighbors on tissue\noften exhibit similar response profiles. In the human language system,\nexperimental studies have observed clusters for syntactic and semantic\ncategories, but the mechanisms underlying this functional organization remain\nunclear. Here, building on work from the vision literature, we develop TopoLM,\na transformer language model with an explicit two-dimensional spatial\nrepresentation of model units. By combining a next-token prediction objective\nwith a spatial smoothness loss, representations in this model assemble into\nclusters that correspond to semantically interpretable groupings of text and\nclosely match the functional organization in the brain's language system.\nTopoLM successfully predicts the emergence of the spatio-functional\norganization of a cortical language system as well as the organization of\nfunctional clusters selective for fine-grained linguistic features empirically\nobserved in human cortex. Our results suggest that the functional organization\nof the human language system is driven by a unified spatial objective, and\nprovide a functionally and spatially aligned model of language processing in\nthe brain.", "AI": {"tldr": "TopoLM, a transformer language model with spatial representation, predicts brain-like functional clusters in language processing by combining next-token prediction and spatial smoothness.", "motivation": "To understand the mechanisms behind the functional organization of neurons in the brain's language system, which exhibits clusters for syntactic and semantic categories.", "method": "Developed TopoLM, a transformer model with a 2D spatial representation, combining next-token prediction and spatial smoothness loss to form interpretable clusters.", "result": "TopoLM predicts brain-like spatio-functional organization and matches empirical observations of linguistic feature clusters in human cortex.", "conclusion": "The functional organization of the human language system is driven by a unified spatial objective, and TopoLM provides a spatially aligned model of brain language processing."}}
{"id": "2505.10558", "pdf": "https://arxiv.org/pdf/2505.10558", "abs": "https://arxiv.org/abs/2505.10558", "authors": ["Peiying Zhang", "Nanxuan Zhao", "Jing Liao"], "title": "Style Customization of Text-to-Vector Generation with Image Diffusion Priors", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted by SIGGRAPH 2025 (Conference Paper). Project page:\n  https://customsvg.github.io", "summary": "Scalable Vector Graphics (SVGs) are highly favored by designers due to their\nresolution independence and well-organized layer structure. Although existing\ntext-to-vector (T2V) generation methods can create SVGs from text prompts, they\noften overlook an important need in practical applications: style\ncustomization, which is vital for producing a collection of vector graphics\nwith consistent visual appearance and coherent aesthetics. Extending existing\nT2V methods for style customization poses certain challenges.\nOptimization-based T2V models can utilize the priors of text-to-image (T2I)\nmodels for customization, but struggle with maintaining structural regularity.\nOn the other hand, feed-forward T2V models can ensure structural regularity,\nyet they encounter difficulties in disentangling content and style due to\nlimited SVG training data.\n  To address these challenges, we propose a novel two-stage style customization\npipeline for SVG generation, making use of the advantages of both feed-forward\nT2V models and T2I image priors. In the first stage, we train a T2V diffusion\nmodel with a path-level representation to ensure the structural regularity of\nSVGs while preserving diverse expressive capabilities. In the second stage, we\ncustomize the T2V diffusion model to different styles by distilling customized\nT2I models. By integrating these techniques, our pipeline can generate\nhigh-quality and diverse SVGs in custom styles based on text prompts in an\nefficient feed-forward manner. The effectiveness of our method has been\nvalidated through extensive experiments. The project page is\nhttps://customsvg.github.io.", "AI": {"tldr": "A two-stage pipeline for style-customized SVG generation combines feed-forward T2V models and T2I priors to ensure structural regularity and style diversity.", "motivation": "Existing T2V methods lack style customization, crucial for consistent and aesthetically coherent SVG collections.", "method": "A two-stage approach: first, a T2V diffusion model ensures structural regularity; second, T2I model distillation customizes styles.", "result": "The pipeline efficiently generates high-quality, diverse SVGs in custom styles from text prompts.", "conclusion": "The method addresses style customization challenges in SVG generation, validated by experiments."}}
{"id": "2505.10422", "pdf": "https://arxiv.org/pdf/2505.10422", "abs": "https://arxiv.org/abs/2505.10422", "authors": ["Daniel Weitekamp", "Christopher MacLellan", "Erik Harpstead", "Kenneth Koedinger"], "title": "Decomposed Inductive Procedure Learning: Learning Academic Tasks with Human-Like Data Efficiency", "categories": ["cs.LG"], "comment": "To appear in CogSci 2025", "summary": "Human learning relies on specialization -- distinct cognitive mechanisms\nworking together to enable rapid learning. In contrast, most modern neural\nnetworks rely on a single mechanism: gradient descent over an objective\nfunction. This raises the question: might human learners' relatively rapid\nlearning from just tens of examples instead of tens of thousands in data-driven\ndeep learning arise from our ability to use multiple specialized mechanisms of\nlearning in combination? We investigate this question through an ablation\nanalysis of inductive human learning simulations in online tutoring\nenvironments. Comparing reinforcement learning to a more data-efficient\n3-mechanism symbolic rule induction approach, we find that decomposing learning\ninto multiple distinct mechanisms significantly improves data efficiency,\nbringing it in line with human learning. Furthermore, we show that this\ndecomposition has a greater impact on efficiency than the distinction between\nsymbolic and subsymbolic learning alone. Efforts to align data-driven machine\nlearning with human learning often overlook the stark difference in learning\nefficiency. Our findings suggest that integrating multiple specialized learning\nmechanisms may be key to bridging this gap.", "AI": {"tldr": "The paper explores whether human-like rapid learning can be achieved in neural networks by using multiple specialized mechanisms, unlike the single gradient descent approach.", "motivation": "To understand why humans learn faster from fewer examples compared to data-driven deep learning, focusing on the role of multiple specialized learning mechanisms.", "method": "Conducted an ablation analysis of human learning simulations, comparing reinforcement learning to a symbolic rule induction approach with three mechanisms.", "result": "Decomposing learning into multiple mechanisms improves data efficiency, matching human learning rates, and outperforms the symbolic vs. subsymbolic distinction.", "conclusion": "Integrating multiple specialized learning mechanisms could bridge the efficiency gap between human and machine learning."}}
{"id": "2505.10394", "pdf": "https://arxiv.org/pdf/2505.10394", "abs": "https://arxiv.org/abs/2505.10394", "authors": ["Meghyn Bienvenu", "Camille Bourgaux", "Atefe Khodadaditaghanaki"], "title": "Inconsistency Handling in DatalogMTL", "categories": ["cs.LO", "cs.AI", "cs.DB"], "comment": "This is an extended version of a paper appearing at the 34th\n  International Joint Conference on Artificial Intelligence (IJCAI 2025). 24\n  pages", "summary": "In this paper, we explore the issue of inconsistency handling in DatalogMTL,\nan extension of Datalog with metric temporal operators. Since facts are\nassociated with time intervals, there are different manners to restore\nconsistency when they contradict the rules, such as removing facts or modifying\ntheir time intervals. Our first contribution is the definition of relevant\nnotions of conflicts (minimal explanations for inconsistency) and repairs\n(possible ways of restoring consistency) for this setting and the study of the\nproperties of these notions and the associated inconsistency-tolerant\nsemantics. Our second contribution is a data complexity analysis of the tasks\nof generating a single conflict / repair and query entailment under\nrepair-based semantics.", "AI": {"tldr": "The paper addresses inconsistency handling in DatalogMTL, defining conflicts and repairs, and analyzes their properties and data complexity.", "motivation": "To manage inconsistencies in DatalogMTL, where facts have time intervals, by defining conflicts and repairs.", "method": "Defines minimal explanations for inconsistency (conflicts) and ways to restore consistency (repairs), then studies their properties and data complexity.", "result": "Provides definitions of conflicts and repairs, analyzes their properties, and examines data complexity for generating conflicts/repairs and query entailment.", "conclusion": "The paper contributes to inconsistency handling in DatalogMTL by formalizing conflicts and repairs and analyzing their computational aspects."}}
{"id": "2410.13258", "pdf": "https://arxiv.org/pdf/2410.13258", "abs": "https://arxiv.org/abs/2410.13258", "authors": ["Xiangci Li", "Jessica Ouyang"], "title": "How Does Knowledge Selection Help Retrieval Augmented Generation?", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-augmented generation (RAG) is a powerful method for enhancing\nnatural language generation by integrating external knowledge into a model's\noutput. While prior work has demonstrated the importance of improving knowledge\nretrieval for boosting generation quality, the role of knowledge selection\nremains less clear. This paper empirically analyzes how knowledge selection\ninfluences downstream generation performance in RAG systems. By simulating\ndifferent retrieval and selection conditions through a controlled mixture of\ngold and distractor knowledge, we assess the impact of these factors on\ngeneration outcomes. Our findings indicate that the downstream generator\nmodel's capability, as well as the complexity of the task and dataset,\nsignificantly influence the impact of knowledge selection on the overall RAG\nsystem performance. In typical scenarios, improving the knowledge recall score\nis key to enhancing generation outcomes, with the knowledge selector providing\nlimited benefit when a strong generator model is used on clear, well-defined\ntasks. For weaker generator models or more ambiguous tasks and datasets, the\nknowledge F1 score becomes a critical factor, and the knowledge selector plays\na more prominent role in improving overall performance.", "AI": {"tldr": "The paper examines how knowledge selection affects generation performance in RAG systems, finding that its impact depends on the generator model's strength and task complexity.", "motivation": "To clarify the role of knowledge selection in RAG systems, which is less understood compared to knowledge retrieval.", "method": "Simulated retrieval and selection conditions using gold and distractor knowledge to measure their impact on generation.", "result": "Knowledge selection's importance varies: recall is key for strong generators on clear tasks, while F1 score matters more for weaker models or ambiguous tasks.", "conclusion": "Knowledge selection's impact depends on the generator model and task complexity, with recall being crucial for strong models and F1 for weaker ones."}}
{"id": "2303.09681", "pdf": "https://arxiv.org/pdf/2303.09681", "abs": "https://arxiv.org/abs/2303.09681", "authors": ["Shihao Zou", "Yuxuan Mu", "Wei Ji", "Zi-An Wang", "Xinxin Zuo", "Sen Wang", "Weixin Si", "Li Cheng"], "title": "Highly Efficient 3D Human Pose Tracking from Events with Spiking Spatiotemporal Transformer", "categories": ["cs.CV"], "comment": "Accepted by IEEE TCSVT", "summary": "Event camera, as an asynchronous vision sensor capturing scene dynamics,\npresents new opportunities for highly efficient 3D human pose tracking.\nExisting approaches typically adopt modern-day Artificial Neural Networks\n(ANNs), such as CNNs or Transformer, where sparse events are converted into\ndense images or paired with additional gray-scale images as input. Such\npractices, however, ignore the inherent sparsity of events, resulting in\nredundant computations, increased energy consumption, and potentially degraded\nperformance. Motivated by these observations, we introduce the first sparse\nSpiking Neural Networks (SNNs) framework for 3D human pose tracking based\nsolely on events. Our approach eliminates the need to convert sparse data to\ndense formats or incorporate additional images, thereby fully exploiting the\ninnate sparsity of input events. Central to our framework is a novel Spiking\nSpatiotemporal Transformer, which enables bi-directional spatiotemporal fusion\nof spike pose features and provides a guaranteed similarity measurement between\nbinary spike features in spiking attention. Moreover, we have constructed a\nlarge-scale synthetic dataset, SynEventHPD, that features a broad and diverse\nset of 3D human motions, as well as much longer hours of event streams.\nEmpirical experiments demonstrate the superiority of our approach over existing\nstate-of-the-art (SOTA) ANN-based methods, requiring only 19.1% FLOPs and 3.6%\nenergy cost. Furthermore, our approach outperforms existing SNN-based\nbenchmarks in this task, highlighting the effectiveness of our proposed SNN\nframework. The dataset will be released upon acceptance, and code can be found\nat https://github.com/JimmyZou/HumanPoseTracking_SNN.", "AI": {"tldr": "A sparse Spiking Neural Networks (SNNs) framework for 3D human pose tracking using event cameras, avoiding redundant computations and outperforming ANN-based methods in efficiency and performance.", "motivation": "Existing ANN-based methods for 3D human pose tracking with event cameras ignore event sparsity, leading to inefficiency and degraded performance.", "method": "Proposes a sparse SNN framework with a Spiking Spatiotemporal Transformer for bi-directional spatiotemporal fusion and similarity measurement of spike features.", "result": "Outperforms SOTA ANN-based methods with 19.1% FLOPs and 3.6% energy cost, and surpasses SNN benchmarks.", "conclusion": "The framework effectively leverages event sparsity, offering a more efficient and superior solution for 3D human pose tracking."}}
{"id": "2505.10423", "pdf": "https://arxiv.org/pdf/2505.10423", "abs": "https://arxiv.org/abs/2505.10423", "authors": ["Ari Karchmer", "Eran Malach"], "title": "The Power of Random Features and the Limits of Distribution-Free Gradient Descent", "categories": ["cs.LG"], "comment": null, "summary": "We study the relationship between gradient-based optimization of parametric\nmodels (e.g., neural networks) and optimization of linear combinations of\nrandom features. Our main result shows that if a parametric model can be\nlearned using mini-batch stochastic gradient descent (bSGD) without making\nassumptions about the data distribution, then with high probability, the target\nfunction can also be approximated using a polynomial-sized combination of\nrandom features. The size of this combination depends on the number of gradient\nsteps and numerical precision used in the bSGD process. This finding reveals\nfundamental limitations of distribution-free learning in neural networks\ntrained by gradient descent, highlighting why making assumptions about data\ndistributions is often crucial in practice. Along the way, we also introduce a\nnew theoretical framework called average probabilistic dimension complexity\n(adc), which extends the probabilistic dimension complexity developed by Kamath\net al. (2020). We prove that adc has a polynomial relationship with statistical\nquery dimension, and use this relationship to demonstrate an infinite\nseparation between adc and standard dimension complexity.", "AI": {"tldr": "The paper shows that gradient-based optimization of parametric models (e.g., neural networks) can approximate target functions using polynomial-sized random features, revealing limitations of distribution-free learning.", "motivation": "To understand the relationship between gradient-based optimization and random feature combinations, and to explore the necessity of data distribution assumptions in neural network training.", "method": "Analyzes mini-batch stochastic gradient descent (bSGD) and introduces a new theoretical framework, average probabilistic dimension complexity (adc).", "result": "Demonstrates that polynomial-sized random feature combinations can approximate target functions, with size depending on gradient steps and precision. Also shows an infinite separation between adc and standard dimension complexity.", "conclusion": "Highlights fundamental limitations of distribution-free learning in neural networks and the importance of data distribution assumptions."}}
{"id": "2505.10442", "pdf": "https://arxiv.org/pdf/2505.10442", "abs": "https://arxiv.org/abs/2505.10442", "authors": ["Dechen Gao", "Hang Wang", "Hanchu Zhou", "Nejib Ammar", "Shatadal Mishra", "Ahmadreza Moradipari", "Iman Soltani", "Junshan Zhang"], "title": "IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Imitation learning (IL) and reinforcement learning (RL) each offer distinct\nadvantages for robotics policy learning: IL provides stable learning from\ndemonstrations, and RL promotes generalization through exploration. While\nexisting robot learning approaches using IL-based pre-training followed by\nRL-based fine-tuning are promising, this two-step learning paradigm often\nsuffers from instability and poor sample efficiency during the RL fine-tuning\nphase. In this work, we introduce IN-RIL, INterleaved Reinforcement learning\nand Imitation Learning, for policy fine-tuning, which periodically injects IL\nupdates after multiple RL updates and hence can benefit from the stability of\nIL and the guidance of expert data for more efficient exploration throughout\nthe entire fine-tuning process. Since IL and RL involve different optimization\nobjectives, we develop gradient separation mechanisms to prevent destructive\ninterference during \\ABBR fine-tuning, by separating possibly conflicting\ngradient updates in orthogonal subspaces. Furthermore, we conduct rigorous\nanalysis, and our findings shed light on why interleaving IL with RL stabilizes\nlearning and improves sample-efficiency. Extensive experiments on 14 robot\nmanipulation and locomotion tasks across 3 benchmarks, including\nFurnitureBench, OpenAI Gym, and Robomimic, demonstrate that \\ABBR can\nsignificantly improve sample efficiency and mitigate performance collapse\nduring online finetuning in both long- and short-horizon tasks with either\nsparse or dense rewards. IN-RIL, as a general plug-in compatible with various\nstate-of-the-art RL algorithms, can significantly improve RL fine-tuning, e.g.,\nfrom 12\\% to 88\\% with 6.3x improvement in the success rate on Robomimic\nTransport. Project page: https://github.com/ucd-dare/IN-RIL.", "AI": {"tldr": "IN-RIL interleaves imitation learning (IL) and reinforcement learning (RL) during fine-tuning to improve stability and sample efficiency, using gradient separation to avoid conflicts.", "motivation": "Existing IL pre-training followed by RL fine-tuning suffers from instability and poor sample efficiency. IN-RIL aims to combine the strengths of IL (stability) and RL (generalization) more effectively.", "method": "IN-RIL periodically injects IL updates after RL updates and employs gradient separation to prevent conflicting updates.", "result": "IN-RIL improves sample efficiency and mitigates performance collapse across 14 tasks, with success rates increasing from 12% to 88% in some cases.", "conclusion": "IN-RIL is a versatile, plug-in compatible method that enhances RL fine-tuning by leveraging IL stability and expert guidance."}}
{"id": "2410.14964", "pdf": "https://arxiv.org/pdf/2410.14964", "abs": "https://arxiv.org/abs/2410.14964", "authors": ["Anab Maulana Barik", "Wynne Hsu", "Mong Li Lee"], "title": "ChronoFact: Timeline-based Temporal Fact Verification", "categories": ["cs.CL"], "comment": null, "summary": "Temporal claims, often riddled with inaccuracies, are a significant challenge\nin the digital misinformation landscape. Fact-checking systems that can\naccurately verify such claims are crucial for combating misinformation. Current\nsystems struggle with the complexities of evaluating the accuracy of these\nclaims, especially when they include multiple, overlapping, or recurring\nevents. We introduce a novel timeline-based fact verification framework that\nidentify events from both claim and evidence and organize them into their\nrespective chronological timelines. The framework systematically examines the\nrelationships between the events in both claim and evidence to predict the\nveracity of each claim event and their chronological accuracy. This allows us\nto accurately determine the overall veracity of the claim. We also introduce a\nnew dataset of complex temporal claims involving timeline-based reasoning for\nthe training and evaluation of our proposed framework. Experimental results\ndemonstrate the effectiveness of our approach in handling the intricacies of\ntemporal claim verification.", "AI": {"tldr": "A novel timeline-based framework for verifying temporal claims by analyzing event relationships in chronological order, outperforming current methods.", "motivation": "Addressing the challenge of verifying complex temporal claims in misinformation, which current systems struggle with due to overlapping or recurring events.", "method": "Introduces a timeline-based framework that organizes events from claims and evidence into chronological timelines and examines their relationships for veracity.", "result": "Experimental results show the framework effectively handles temporal claim verification complexities.", "conclusion": "The proposed framework improves accuracy in verifying temporal claims and includes a new dataset for future research."}}
{"id": "2401.14066", "pdf": "https://arxiv.org/pdf/2401.14066", "abs": "https://arxiv.org/abs/2401.14066", "authors": ["Nisha Huang", "Weiming Dong", "Yuxin Zhang", "Fan Tang", "Ronghui Li", "Chongyang Ma", "Xiu Li", "Tong-Yee Lee", "Changsheng Xu"], "title": "CreativeSynth: Cross-Art-Attention for Artistic Image Synthesis with Multimodal Diffusion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Although remarkable progress has been made in image style transfer, style is\njust one of the components of artistic paintings. Directly transferring\nextracted style features to natural images often results in outputs with\nobvious synthetic traces. This is because key painting attributes including\nlayout, perspective, shape, and semantics often cannot be conveyed and\nexpressed through style transfer. Large-scale pretrained text-to-image\ngeneration models have demonstrated their capability to synthesize a vast\namount of high-quality images. However, even with extensive textual\ndescriptions, it is challenging to fully express the unique visual properties\nand details of paintings. Moreover, generic models often disrupt the overall\nartistic effect when modifying specific areas, making it more complicated to\nachieve a unified aesthetic in artworks. Our main novel idea is to integrate\nmultimodal semantic information as a synthesis guide into artworks, rather than\ntransferring style to the real world. We also aim to reduce the disruption to\nthe harmony of artworks while simplifying the guidance conditions.\nSpecifically, we propose an innovative multi-task unified framework called\nCreativeSynth, based on the diffusion model with the ability to coordinate\nmultimodal inputs. CreativeSynth combines multimodal features with customized\nattention mechanisms to seamlessly integrate real-world semantic content into\nthe art domain through Cross-Art-Attention for aesthetic maintenance and\nsemantic fusion. We demonstrate the results of our method across a wide range\nof different art categories, proving that CreativeSynth bridges the gap between\ngenerative models and artistic expression. Code and results are available at\nhttps://github.com/haha-lisa/CreativeSynth.", "AI": {"tldr": "CreativeSynth integrates multimodal semantic information into artworks using a diffusion model, avoiding synthetic traces and maintaining aesthetic harmony.", "motivation": "Current style transfer and text-to-image models fail to fully capture and express key painting attributes like layout, perspective, and semantics, disrupting artistic harmony.", "method": "Proposes CreativeSynth, a multi-task unified framework based on a diffusion model with Cross-Art-Attention for multimodal feature integration.", "result": "Demonstrates seamless integration of real-world semantics into art, bridging generative models and artistic expression across various art categories.", "conclusion": "CreativeSynth effectively addresses limitations of existing methods, offering a unified approach for aesthetic and semantic fusion in art generation."}}
{"id": "2505.10425", "pdf": "https://arxiv.org/pdf/2505.10425", "abs": "https://arxiv.org/abs/2505.10425", "authors": ["Jingyao Wang", "Wenwen Qiang", "Zeen Song", "Changwen Zheng", "Hui Xiong"], "title": "Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at complex tasks thanks to advances in\nreasoning abilities. However, existing methods overlook the trade-off between\nreasoning effectiveness and computational efficiency, often encouraging\nunnecessarily long reasoning chains and wasting tokens. To address this, we\npropose Learning to Think (L2T), an information-theoretic reinforcement\nfine-tuning framework for LLMs to make the models achieve optimal reasoning\nwith fewer tokens. Specifically, L2T treats each query-response interaction as\na hierarchical session of multiple episodes and proposes a universal dense\nprocess reward, i.e., quantifies the episode-wise information gain in\nparameters, requiring no extra annotations or task-specific evaluators. We\npropose a method to quickly estimate this reward based on PAC-Bayes bounds and\nthe Fisher information matrix. Theoretical analyses show that it significantly\nreduces computational complexity with high estimation accuracy. By immediately\nrewarding each episode's contribution and penalizing excessive updates, L2T\noptimizes the model via reinforcement learning to maximize the use of each\nepisode and achieve effective updates. Empirical results on various reasoning\nbenchmarks and base models demonstrate the advantage of L2T across different\ntasks, boosting both reasoning effectiveness and efficiency.", "AI": {"tldr": "L2T is a reinforcement fine-tuning framework for LLMs that optimizes reasoning efficiency by reducing unnecessary tokens, using hierarchical sessions and dense process rewards.", "motivation": "Existing methods for LLMs overlook the trade-off between reasoning effectiveness and computational efficiency, leading to wasted tokens.", "method": "L2T treats query-response interactions as hierarchical sessions with dense process rewards, estimated using PAC-Bayes bounds and Fisher information matrix.", "result": "L2T reduces computational complexity while maintaining accuracy, improving reasoning effectiveness and efficiency across benchmarks.", "conclusion": "L2T successfully balances reasoning and efficiency, outperforming existing methods in various tasks."}}
{"id": "2505.10443", "pdf": "https://arxiv.org/pdf/2505.10443", "abs": "https://arxiv.org/abs/2505.10443", "authors": ["Pedro Orvalho", "Marta Kwiatkowska"], "title": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?", "categories": ["cs.SE", "cs.AI"], "comment": "10 pages, 5 tables, 1 figure", "summary": "Understanding the reasoning and robustness of Large Language Models (LLMs) is\ncritical for their reliable use in programming tasks. While recent studies have\nassessed LLMs' ability to predict program outputs, most focus solely on the\naccuracy of those predictions, without evaluating the reasoning behind them.\nMoreover, it has been observed on mathematical reasoning tasks that LLMs can\narrive at correct answers through flawed logic, raising concerns about similar\nissues in code understanding.\n  In this work, we evaluate whether state-of-the-art LLMs with up to 8B\nparameters can reason about Python programs or are simply guessing. We apply\nfive semantics-preserving code mutations: renaming variables, mirroring\ncomparison expressions, swapping if-else branches, converting for loops to\nwhile, and loop unrolling. These mutations maintain program semantics while\naltering its syntax. We evaluated six LLMs and performed a human expert\nanalysis using LiveCodeBench to assess whether the correct predictions are\nbased on sound reasoning. We also evaluated prediction stability across\ndifferent code mutations on LiveCodeBench and CruxEval. Our findings show that\nsome LLMs, such as Llama3.2, produce correct predictions based on flawed\nreasoning in up to 61% of cases. Furthermore, LLMs often change predictions in\nresponse to our code mutations, indicating limited robustness in their semantic\nunderstanding.", "AI": {"tldr": "The paper evaluates whether large language models (LLMs) can reason about Python programs or just guess, using code mutations to test robustness and reasoning. Findings show flawed reasoning and limited robustness in some models.", "motivation": "Assess LLMs' reasoning and robustness in programming tasks, as prior work focused only on prediction accuracy, not the reasoning behind it. Concerns exist about flawed logic leading to correct answers.", "method": "Applied five semantics-preserving code mutations (e.g., renaming variables, swapping if-else branches) to Python programs. Evaluated six LLMs using LiveCodeBench and CruxEval, with human expert analysis.", "result": "Some LLMs (e.g., Llama3.2) produced correct predictions with flawed reasoning in up to 61% of cases. Models often changed predictions with code mutations, showing limited robustness.", "conclusion": "LLMs exhibit flawed reasoning and lack robustness in semantic understanding of code, highlighting the need for improved evaluation methods."}}
{"id": "2410.21909", "pdf": "https://arxiv.org/pdf/2410.21909", "abs": "https://arxiv.org/abs/2410.21909", "authors": ["Xiao Xia", "Dan Zhang", "Zibo Liao", "Zhenyu Hou", "Tianrui Sun", "Jing Li", "Ling Fu", "Yuxiao Dong"], "title": "SceneGenAgent: Precise Industrial Scene Generation with Coding Agent", "categories": ["cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "The modeling of industrial scenes is essential for simulations in industrial\nmanufacturing. While large language models (LLMs) have shown significant\nprogress in generating general 3D scenes from textual descriptions, generating\nindustrial scenes with LLMs poses a unique challenge due to their demand for\nprecise measurements and positioning, requiring complex planning over spatial\narrangement. To address this challenge, we introduce SceneGenAgent, an\nLLM-based agent for generating industrial scenes through C# code. SceneGenAgent\nensures precise layout planning through a structured and calculable format,\nlayout verification, and iterative refinement to meet the quantitative\nrequirements of industrial scenarios. Experiment results demonstrate that LLMs\npowered by SceneGenAgent exceed their original performance, reaching up to\n81.0% success rate in real-world industrial scene generation tasks and\neffectively meeting most scene generation requirements. To further enhance\naccessibility, we construct SceneInstruct, a dataset designed for fine-tuning\nopen-source LLMs to integrate into SceneGenAgent. Experiments show that\nfine-tuning open-source LLMs on SceneInstruct yields significant performance\nimprovements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our\ncode and data are available at https://github.com/THUDM/SceneGenAgent .", "AI": {"tldr": "SceneGenAgent, an LLM-based agent, generates precise industrial scenes via C# code, achieving 81.0% success rate, and is enhanced by SceneInstruct dataset for fine-tuning open-source LLMs.", "motivation": "Industrial scenes require precise measurements and spatial planning, which general LLMs struggle with.", "method": "SceneGenAgent uses structured C# code, layout verification, and iterative refinement for precise industrial scene generation.", "result": "Achieves 81.0% success rate; fine-tuned open-source LLMs (e.g., Llama3.1-70B) approach GPT-4o performance.", "conclusion": "SceneGenAgent effectively meets industrial scene generation demands, with open-source LLMs showing promise when fine-tuned."}}
{"id": "2403.07547", "pdf": "https://arxiv.org/pdf/2403.07547", "abs": "https://arxiv.org/abs/2403.07547", "authors": ["Jungho Lee", "Dogyoon Lee", "Minhyeok Lee", "Donghyung Kim", "Sangyoun Lee"], "title": "SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields", "categories": ["cs.CV"], "comment": "CVPRW 2025, Neural Fields Beyond Conventional Cameras, Project Page:\n  https://jho-yonsei.github.io/SMURF/", "summary": "Neural radiance fields (NeRF) has attracted considerable attention for their\nexceptional ability in synthesizing novel views with high fidelity. However,\nthe presence of motion blur, resulting from slight camera movements during\nextended shutter exposures, poses a significant challenge, potentially\ncompromising the quality of the reconstructed 3D scenes. To effectively handle\nthis issue, we propose sequential motion understanding radiance fields (SMURF),\na novel approach that models continuous camera motion and leverages the\nexplicit volumetric representation method for robustness to motion-blurred\ninput images. The core idea of the SMURF is continuous motion blurring kernel\n(CMBK), a module designed to model a continuous camera movements for processing\nblurry inputs. Our model is evaluated against benchmark datasets and\ndemonstrates state-of-the-art performance both quantitatively and\nqualitatively.", "AI": {"tldr": "SMURF improves NeRF by addressing motion blur with continuous motion modeling, achieving top performance.", "motivation": "Motion blur from camera movements degrades NeRF's 3D scene reconstruction quality.", "method": "SMURF uses continuous motion blurring kernel (CMBK) to model camera motion for blurry inputs.", "result": "SMURF outperforms benchmarks, showing state-of-the-art results.", "conclusion": "SMURF effectively handles motion blur, enhancing NeRF's robustness and output quality."}}
{"id": "2505.10432", "pdf": "https://arxiv.org/pdf/2505.10432", "abs": "https://arxiv.org/abs/2505.10432", "authors": ["Randy J. Chase", "Katherine Haynes", "Lander Ver Hoef", "Imme Ebert-Uphoff"], "title": "Score-based diffusion nowcasting of GOES imagery", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Clouds and precipitation are important for understanding weather and climate.\nSimulating clouds and precipitation with traditional numerical weather\nprediction is challenging because of the sub-grid parameterizations required.\nMachine learning has been explored for forecasting clouds and precipitation,\nbut early machine learning methods often created blurry forecasts. In this\npaper we explore a newer method, named score-based diffusion, to nowcast (zero\nto three hour forecast) clouds and precipitation. We discuss the background and\nintuition of score-based diffusion models - thus providing a starting point for\nthe community - while exploring the methodology's use for nowcasting\ngeostationary infrared imagery. We experiment with three main types of\ndiffusion models: a standard score-based diffusion model (Diff); a residual\ncorrection diffusion model (CorrDiff); and a latent diffusion model (LDM). Our\nresults show that the diffusion models are able to not only advect existing\nclouds, but also generate and decay clouds, including convective initiation.\nThese results are surprising because the forecasts are initiated with only the\npast 20 mins of infrared satellite imagery. A case study qualitatively shows\nthe preservation of high resolution features longer into the forecast than a\nconventional mean-squared error trained U-Net. The best of the three diffusion\nmodels tested was the CorrDiff approach, outperforming all other diffusion\nmodels, the traditional U-Net, and a persistence forecast by one to two kelvin\non root mean squared error. The diffusion models also enable out-of-the-box\nensemble generation, which shows skillful calibration, with the spread of the\nensemble correlating well to the error.", "AI": {"tldr": "The paper explores score-based diffusion models for nowcasting clouds and precipitation, outperforming traditional methods like U-Nets and persistence forecasts.", "motivation": "Traditional numerical weather prediction struggles with sub-grid parameterizations for clouds and precipitation, and early machine learning methods produced blurry forecasts.", "method": "Three diffusion models (Diff, CorrDiff, LDM) are tested for nowcasting using geostationary infrared imagery, focusing on advection, generation, and decay of clouds.", "result": "Diffusion models, especially CorrDiff, outperform U-Nets and persistence forecasts by 1-2 Kelvin in RMSE, and enable skillful ensemble generation.", "conclusion": "Score-based diffusion models, particularly CorrDiff, are effective for high-resolution nowcasting and ensemble forecasting in weather prediction."}}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy.", "AI": {"tldr": "NCDPO introduces a noise-conditioned deterministic policy to improve the sample efficiency and performance of diffusion policies, addressing challenges in RL-based fine-tuning.", "motivation": "Diffusion policies suffer from sub-optimal trajectories due to limited demonstration data, and existing RL fine-tuning methods struggle with computational intractability.", "method": "NCDPO reformulates Diffusion Policy as a noise-conditioned deterministic policy, enabling tractable likelihood evaluation and gradient backpropagation.", "result": "NCDPO matches MLP+PPO in sample efficiency and outperforms existing methods in performance across benchmarks.", "conclusion": "NCDPO is robust and effective for improving diffusion policies in diverse decision-making scenarios."}}
{"id": "2411.00646", "pdf": "https://arxiv.org/pdf/2411.00646", "abs": "https://arxiv.org/abs/2411.00646", "authors": ["Houjing Wei", "Yuting Shi", "Naoya Inoue"], "title": "Phase Diagram of Vision Large Language Models Inference: A Perspective from Interaction across Image and Instruction", "categories": ["cs.CL"], "comment": "6 pages, 5 figures", "summary": "Vision Large Language Models (VLLMs) usually take input as a concatenation of\nimage token embeddings and text token embeddings and conduct causal modeling.\nHowever, their internal behaviors remain underexplored, raising the question of\ninteraction among two types of tokens. To investigate such multimodal\ninteraction during model inference, in this paper, we measure the\ncontextualization among the hidden state vectors of tokens from different\nmodalities. Our experiments uncover a four-phase inference dynamics of VLLMs\nagainst the depth of Transformer-based LMs, including (I) Alignment: In very\nearly layers, contextualization emerges between modalities, suggesting a\nfeature space alignment. (II) Intra-modal Encoding: In early layers,\nintra-modal contextualization is enhanced while inter-modal interaction is\nsuppressed, suggesting a local encoding within modalities. (III) Inter-modal\nEncoding: In later layers, contextualization across modalities is enhanced,\nsuggesting a deeper fusion across modalities. (IV) Output Preparation: In very\nlate layers, contextualization is reduced globally, and hidden states are\naligned towards the unembedding space.", "AI": {"tldr": "The paper investigates the interaction between image and text tokens in Vision Large Language Models (VLLMs), revealing a four-phase inference dynamics across Transformer layers.", "motivation": "To understand how VLLMs internally process and interact with multimodal (image and text) tokens, given their underexplored behaviors.", "method": "Measure contextualization among hidden state vectors of tokens from different modalities across Transformer layers.", "result": "Identifies four phases: (I) Alignment, (II) Intra-modal Encoding, (III) Inter-modal Encoding, and (IV) Output Preparation.", "conclusion": "VLLMs exhibit distinct multimodal interaction patterns, progressing from alignment to deeper fusion and finally output preparation."}}
{"id": "2405.03689", "pdf": "https://arxiv.org/pdf/2405.03689", "abs": "https://arxiv.org/abs/2405.03689", "authors": ["Sanjay Subramanian", "Evonne Ng", "Lea M\u00fcller", "Dan Klein", "Shiry Ginosar", "Trevor Darrell"], "title": "Pose Priors from Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "CVPR 2025", "summary": "Language is often used to describe physical interaction, yet most 3D human\npose estimation methods overlook this rich source of information. We bridge\nthis gap by leveraging large multimodal models (LMMs) as priors for\nreconstructing contact poses, offering a scalable alternative to traditional\nmethods that rely on human annotations or motion capture data. Our approach\nextracts contact-relevant descriptors from an LMM and translates them into\ntractable losses to constrain 3D human pose optimization. Despite its\nsimplicity, our method produces compelling reconstructions for both two-person\ninteractions and self-contact scenarios, accurately capturing the semantics of\nphysical and social interactions. Our results demonstrate that LMMs can serve\nas powerful tools for contact prediction and pose estimation, offering an\nalternative to costly manual human annotations or motion capture data. Our code\nis publicly available at https://prosepose.github.io.", "AI": {"tldr": "The paper proposes using large multimodal models (LMMs) to improve 3D human pose estimation by leveraging language descriptions of physical interactions, avoiding costly manual annotations or motion capture data.", "motivation": "Most 3D human pose estimation methods ignore language descriptions of physical interactions, missing a valuable data source.", "method": "The approach extracts contact-relevant descriptors from LMMs and translates them into losses for 3D pose optimization.", "result": "The method produces accurate reconstructions for two-person interactions and self-contact, capturing interaction semantics.", "conclusion": "LMMs are powerful tools for contact prediction and pose estimation, offering a scalable alternative to traditional methods."}}
{"id": "2505.10438", "pdf": "https://arxiv.org/pdf/2505.10438", "abs": "https://arxiv.org/abs/2505.10438", "authors": ["David Grasev"], "title": "Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "51 pages, 28 figures", "summary": "Gas turbine engines represent complex highly nonlinear dynamical systems.\nDeriving their physics-based models can be challenging as it requires\nperformance characteristics, that are not always available, and one often has\nto make many simplifying assumptions. In this paper, the limitations of\nconventional experimental methods used to derive component-level and locally\nlinear parameter-varying models are discussed and addressed by employing\nidentification techniques based on data collected from standard engine\noperation under closed-loop control. The rotor dynamics were estimated using\nthe sparse identification of nonlinear dynamics. Subsequently, the autonomous\npart of the dynamics was mapped into an optimally constructed Koopman\neigenfunction space. The process included eigenvalue optimization using\nmetaheuristic algorithms and temporal projection, followed by gradient-based\neigenfunction identification. The resulting Koopman model was validated against\nan in-house reference component-level model. A globally optimal nonlinear\nfeedback controller and a Kalman estimator were then designed in the\neigenfunction space and compared to the classical and gain-scheduled\nproportional-integral controllers, as well as a proposed internal model control\napproach. The eigenmode structure allowed targeting individual modes during the\noptimization process, resulting in a better performance tuning. The results\nshowed that the Koopman-based controller outperformed the other benchmark\ncontrollers in both reference tracking and disturbance rejection, under\nsea-level and varying flight conditions, due to its global nature.", "AI": {"tldr": "The paper proposes a data-driven approach using Koopman eigenfunction space for modeling and controlling gas turbine engines, outperforming traditional methods.", "motivation": "Physics-based modeling of gas turbine engines is challenging due to unavailable performance data and simplifying assumptions. The paper addresses limitations of conventional methods.", "method": "Uses sparse identification of nonlinear dynamics, maps dynamics into Koopman eigenfunction space, optimizes eigenvalues, and designs controllers in this space.", "result": "The Koopman-based controller outperforms classical and gain-scheduled controllers in tracking and disturbance rejection.", "conclusion": "The data-driven Koopman approach provides a globally optimal solution for gas turbine engine control."}}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance.", "AI": {"tldr": "PnPXAI is a universal XAI framework addressing limitations of existing methods by supporting diverse models and data modalities, optimizing explanations, and validating effectiveness across domains.", "motivation": "Existing XAI methods lack flexibility, support limited architectures, and provide sub-optimal explanations, hindering real-world adoption.", "method": "PnPXAI automates model detection, recommends explanation methods, and optimizes hyperparameters for diverse models and data.", "result": "Validated through user surveys, PnPXAI demonstrates versatility in domains like medicine and finance.", "conclusion": "PnPXAI overcomes current XAI limitations, offering a practical solution for practitioners."}}
{"id": "2411.13504", "pdf": "https://arxiv.org/pdf/2411.13504", "abs": "https://arxiv.org/abs/2411.13504", "authors": ["Mingyu Jin", "Weidi Luo", "Sitao Cheng", "Xinyi Wang", "Wenyue Hua", "Ruixiang Tang", "William Yang Wang", "Yongfeng Zhang"], "title": "Disentangling Memory and Reasoning Ability in Large Language Models", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025", "summary": "Large Language Models (LLMs) have demonstrated strong performance in handling\ncomplex tasks requiring both extensive knowledge and reasoning abilities.\nHowever, the existing LLM inference pipeline operates as an opaque process\nwithout explicit separation between knowledge retrieval and reasoning steps,\nmaking the model's decision-making process unclear and disorganized. This\nambiguity can lead to issues such as hallucinations and knowledge forgetting,\nwhich significantly impact the reliability of LLMs in high-stakes domains. In\nthis paper, we propose a new inference paradigm that decomposes the complex\ninference process into two distinct and clear actions: (1) memory recall: which\nretrieves relevant knowledge, and (2) reasoning: which performs logical steps\nbased on the recalled knowledge. To facilitate this decomposition, we introduce\ntwo special tokens memory and reason, guiding the model to distinguish between\nsteps that require knowledge retrieval and those that involve reasoning. Our\nexperiment results show that this decomposition not only improves model\nperformance but also enhances the interpretability of the inference process,\nenabling users to identify sources of error and refine model responses\neffectively. The code is available at\nhttps://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning.", "AI": {"tldr": "The paper proposes a new LLM inference paradigm separating knowledge retrieval (memory recall) and reasoning to improve clarity, performance, and interpretability.", "motivation": "Existing LLM inference lacks clear separation between knowledge retrieval and reasoning, leading to issues like hallucinations and unreliable decisions.", "method": "Introduces two special tokens (memory and reason) to decompose inference into distinct memory recall and reasoning steps.", "result": "The decomposition improves model performance and interpretability, aiding error identification and response refinement.", "conclusion": "The proposed paradigm enhances LLM reliability and usability in high-stakes domains."}}
{"id": "2406.02147", "pdf": "https://arxiv.org/pdf/2406.02147", "abs": "https://arxiv.org/abs/2406.02147", "authors": ["Tao Tang", "Lijun Zhou", "Pengkun Hao", "Zihang He", "Kalok Ho", "Shuo Gu", "Zhihui Hao", "Haiyang Sun", "Kun Zhan", "Peng Jia", "XianPeng Lang", "Xiaodan Liang"], "title": "S2-Track: A Simple yet Strong Approach for End-to-End 3D Multi-Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "3D multiple object tracking (MOT) plays a crucial role in autonomous driving\nperception. Recent end-to-end query-based trackers simultaneously detect and\ntrack objects, which have shown promising potential for the 3D MOT task.\nHowever, existing methods are still in the early stages of development and lack\nsystematic improvements, failing to track objects in certain complex scenarios,\nlike occlusions and the small size of target object's situations. In this\npaper, we first summarize the current end-to-end 3D MOT framework by\ndecomposing it into three constituent parts: query initialization, query\npropagation, and query matching. Then we propose corresponding improvements,\nwhich lead to a strong yet simple tracker: S2-Track. Specifically, for query\ninitialization, we present 2D-Prompted Query Initialization, which leverages\npredicted 2D object and depth information to prompt an initial estimate of the\nobject's 3D location. For query propagation, we introduce an Uncertainty-aware\nProbabilistic Decoder to capture the uncertainty of complex environment in\nobject prediction with probabilistic attention. For query matching, we propose\na Hierarchical Query Denoising strategy to enhance training robustness and\nconvergence. As a result, our S2-Track achieves state-of-the-art performance on\nnuScenes benchmark, i.e., 66.3% AMOTA on test split, surpassing the previous\nbest end-to-end solution by a significant margin of 8.9% AMOTA. We achieve 1st\nplace on the nuScenes tracking task leaderboard.", "AI": {"tldr": "The paper introduces S2-Track, an improved end-to-end 3D MOT framework, addressing limitations in complex scenarios like occlusions and small objects. It achieves state-of-the-art performance on the nuScenes benchmark.", "motivation": "Existing end-to-end query-based trackers for 3D MOT lack systematic improvements and struggle with complex scenarios like occlusions and small objects.", "method": "The framework is decomposed into query initialization, propagation, and matching, with novel improvements: 2D-Prompted Query Initialization, Uncertainty-aware Probabilistic Decoder, and Hierarchical Query Denoising.", "result": "S2-Track achieves 66.3% AMOTA on nuScenes test split, surpassing the previous best by 8.9%, and ranks 1st on the leaderboard.", "conclusion": "S2-Track demonstrates superior performance and robustness, setting a new benchmark for 3D MOT in autonomous driving."}}
{"id": "2505.10472", "pdf": "https://arxiv.org/pdf/2505.10472", "abs": "https://arxiv.org/abs/2505.10472", "authors": ["Agnik Saha", "Victoria Churchill", "Anny D. Rodriguez", "Ugur Kursuncu", "Muhammed Y. Idris"], "title": "Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Effective communication about breast and cervical cancers remains a\npersistent health challenge, with significant gaps in public understanding of\ncancer prevention, screening, and treatment, potentially leading to delayed\ndiagnoses and inadequate treatments. This study evaluates the capabilities and\nlimitations of Large Language Models (LLMs) in generating accurate, safe, and\naccessible cancer-related information to support patient understanding. We\nevaluated five general-purpose and three medical LLMs using a mixed-methods\nevaluation framework across linguistic quality, safety and trustworthiness, and\ncommunication accessibility and affectiveness. Our approach utilized\nquantitative metrics, qualitative expert ratings, and statistical analysis\nusing Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that\ngeneral-purpose LLMs produced outputs of higher linguistic quality and\naffectiveness, while medical LLMs demonstrate greater communication\naccessibility. However, medical LLMs tend to exhibit higher levels of potential\nharm, toxicity, and bias, reducing their performance in safety and\ntrustworthiness. Our findings indicate a duality between domain-specific\nknowledge and safety in health communications. The results highlight the need\nfor intentional model design with targeted improvements, particularly in\nmitigating harm and bias, and improving safety and affectiveness. This study\nprovides a comprehensive evaluation of LLMs for cancer communication, offering\ncritical insights for improving AI-generated health content and informing\nfuture development of accurate, safe, and accessible digital health tools.", "AI": {"tldr": "The study evaluates LLMs for generating cancer-related info, finding general-purpose models excel in linguistic quality and affectiveness, while medical LLMs are more accessible but riskier due to harm, toxicity, and bias.", "motivation": "Address gaps in public understanding of cancer prevention and treatment by assessing LLMs' ability to provide accurate, safe, and accessible info.", "method": "Mixed-methods framework evaluating five general-purpose and three medical LLMs using quantitative metrics, qualitative expert ratings, and statistical analysis (Welch's ANOVA, Games-Howell, Hedges' g).", "result": "General-purpose LLMs scored higher in linguistic quality and affectiveness; medical LLMs were more accessible but had higher harm, toxicity, and bias.", "conclusion": "Domain-specific knowledge and safety in health communications are dual challenges. Future LLM design must mitigate harm, bias, and improve safety and affectiveness."}}
{"id": "2505.10522", "pdf": "https://arxiv.org/pdf/2505.10522", "abs": "https://arxiv.org/abs/2505.10522", "authors": ["Xinrui Wang", "Yan Jin"], "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning.", "AI": {"tldr": "The paper introduces the KCAC framework to improve RL in robotic manipulation by integrating knowledge transfer via cross-task curriculum learning, reducing training time by 40% and increasing success rates by 10%.", "motivation": "Addressing RL's sample inefficiency and lack of interpretability in robotic manipulation, the paper aims to enhance agent adaptability and understanding through strategic knowledge utilization.", "method": "Proposes the KCAC framework, redesigns the reward function, and implements a cross-task curriculum with self-designed sub-tasks in the CausalWorld benchmark.", "result": "KCAC achieves a 40% reduction in training time and a 10% improvement in task success rates compared to traditional RL methods.", "conclusion": "The work provides insights into curriculum design for RL, highlighting key parameters like subtask selection and transition timing, and advances robotic learning."}}
{"id": "2411.14790", "pdf": "https://arxiv.org/pdf/2411.14790", "abs": "https://arxiv.org/abs/2411.14790", "authors": ["Zheni Zeng", "Yuxuan Chen", "Shi Yu", "Ruobing Wang", "Yukun Yan", "Zhenghao Liu", "Shuo Wang", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "title": "KBAlign: Efficient Self Adaptation on Specific Knowledge Bases", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although retrieval-augmented generation (RAG) remains essential for\nknowledge-based question answering (KBQA), current paradigms face critical\nchallenges under specific domains. Existing methods struggle with targeted\nadaptation on small-scale KBs: vanilla unsupervised training exhibits poor\neffectiveness, while fine-tuning incurs prohibitive costs of external signals.\nWe present KBAlign, a self-supervised framework that enhances RAG systems\nthrough efficient model adaptation. Our key insight is to leverage the model's\nintrinsic capabilities for knowledge alignment through two innovative\nmechanisms: multi-grained self-annotation that captures global knowledge for\ndata construction, and iterative tuning that accelerates convergence through\nself verification. This framework enables cost-effective model adaptation to\nspecific textual KBs, without human supervision or external model assistance.\nExperiments demonstrate that KBAlign can achieve 90\\% of the performance gain\nobtained through GPT-4-supervised adaptation, while relying entirely on\nself-annotation of much smaller models. KBAlign significantly improves\ndownstream QA accuracy across multiple domains with tiny costs, particularly\nbenefiting scenarios requiring deep knowledge integration from specialized\ncorpora. We release our experimental data, models, and process analyses to the\ncommunity for further exploration (https://github.com/thunlp/KBAlign).", "AI": {"tldr": "KBAlign is a self-supervised framework enhancing RAG systems for KBQA by leveraging intrinsic model capabilities, achieving 90% of GPT-4-supervised performance gains without external signals.", "motivation": "Current RAG methods struggle with targeted adaptation on small-scale KBs due to poor unsupervised training or costly fine-tuning.", "method": "KBAlign uses multi-grained self-annotation for data construction and iterative tuning with self-verification for efficient adaptation.", "result": "Achieves 90% of GPT-4-supervised performance gains, improving QA accuracy in specialized domains with minimal costs.", "conclusion": "KBAlign offers a cost-effective, unsupervised solution for adapting RAG systems to specific KBs, benefiting specialized QA scenarios."}}
{"id": "2407.13933", "pdf": "https://arxiv.org/pdf/2407.13933", "abs": "https://arxiv.org/abs/2407.13933", "authors": ["Zahidul Islam", "Sujoy Paul", "Mrigank Rochan"], "title": "Unsupervised Video Highlight Detection by Learning from Audio and Visual Recurrence", "categories": ["cs.CV"], "comment": "Accepted to the 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)", "summary": "With the exponential growth of video content, the need for automated video\nhighlight detection to extract key moments or highlights from lengthy videos\nhas become increasingly pressing. This technology has the potential to enhance\nuser experiences by allowing quick access to relevant content across diverse\ndomains. Existing methods typically rely either on expensive manually labeled\nframe-level annotations, or on a large external dataset of videos for weak\nsupervision through category information. To overcome this, we focus on\nunsupervised video highlight detection, eliminating the need for manual\nannotations. We propose a novel unsupervised approach which capitalizes on the\npremise that significant moments tend to recur across multiple videos of the\nsimilar category in both audio and visual modalities. Surprisingly, audio\nremains under-explored, especially in unsupervised algorithms, despite its\npotential to detect key moments. Through a clustering technique, we identify\npseudo-categories of videos and compute audio pseudo-highlight scores for each\nvideo by measuring the similarities of audio features among audio clips of all\nthe videos within each pseudo-category. Similarly, we also compute visual\npseudo-highlight scores for each video using visual features. Then, we combine\naudio and visual pseudo-highlights to create the audio-visual pseudo\nground-truth highlight of each video for training an audio-visual highlight\ndetection network. Extensive experiments and ablation studies on three\nbenchmarks showcase the superior performance of our method over prior work.", "AI": {"tldr": "Proposes an unsupervised method for video highlight detection using audio and visual features, eliminating the need for manual annotations.", "motivation": "Addresses the challenge of automated video highlight detection without relying on expensive manual annotations or large external datasets.", "method": "Uses clustering to identify pseudo-categories, computes audio and visual pseudo-highlight scores, and combines them to train an audio-visual highlight detection network.", "result": "Demonstrates superior performance over prior work in experiments on three benchmarks.", "conclusion": "The unsupervised approach effectively leverages recurring significant moments in audio and visual modalities for highlight detection."}}
{"id": "2505.10484", "pdf": "https://arxiv.org/pdf/2505.10484", "abs": "https://arxiv.org/abs/2505.10484", "authors": ["Andrea Baisero", "Rupali Bhati", "Shuo Liu", "Aathira Pillai", "Christopher Amato"], "title": "Fixing Incomplete Value Function Decomposition for Multi-Agent Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Value function decomposition methods for cooperative multi-agent\nreinforcement learning compose joint values from individual per-agent\nutilities, and train them using a joint objective. To ensure that the action\nselection process between individual utilities and joint values remains\nconsistent, it is imperative for the composition to satisfy the\nindividual-global max (IGM) property. Although satisfying IGM itself is\nstraightforward, most existing methods (e.g., VDN, QMIX) have limited\nrepresentation capabilities and are unable to represent the full class of IGM\nvalues, and the one exception that has no such limitation (QPLEX) is\nunnecessarily complex. In this work, we present a simple formulation of the\nfull class of IGM values that naturally leads to the derivation of QFIX, a\nnovel family of value function decomposition models that expand the\nrepresentation capabilities of prior models by means of a thin \"fixing\" layer.\nWe derive multiple variants of QFIX, and implement three variants in two\nwell-known multi-agent frameworks. We perform an empirical evaluation on\nmultiple SMACv2 and Overcooked environments, which confirms that QFIX (i)\nsucceeds in enhancing the performance of prior methods, (ii) learns more stably\nand performs better than its main competitor QPLEX, and (iii) achieves this\nwhile employing the simplest and smallest mixing models.", "AI": {"tldr": "QFIX is a novel value function decomposition method for multi-agent reinforcement learning that expands representation capabilities while maintaining simplicity, outperforming prior methods like QPLEX.", "motivation": "Existing methods for value function decomposition in multi-agent RL (e.g., VDN, QMIX) have limited representation capabilities or are overly complex (QPLEX). QFIX aims to address these limitations.", "method": "QFIX introduces a simple formulation for the full class of IGM values, using a thin 'fixing' layer to enhance representation. It derives multiple variants and integrates them into existing frameworks.", "result": "QFIX improves performance over prior methods, learns more stably, and outperforms QPLEX while using simpler and smaller models, as shown in SMACv2 and Overcooked environments.", "conclusion": "QFIX successfully balances representation power and simplicity, offering a practical advancement for multi-agent RL."}}
{"id": "2505.10537", "pdf": "https://arxiv.org/pdf/2505.10537", "abs": "https://arxiv.org/abs/2505.10537", "authors": ["Filippo Olimpieri", "Noemi Giustini", "Andrea Lacava", "Salvatore D'Oro", "Tommaso Melodia", "Francesca Cuomo"], "title": "LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps", "categories": ["cs.NI", "cs.AI"], "comment": "6 pages, 5 figures, 2 tables", "summary": "The O-RAN architecture is transforming cellular networks by adopting RAN\nsoftwarization and disaggregation concepts to enable data-driven monitoring and\ncontrol of the network. Such management is enabled by RICs, which facilitate\nnear-real-time and non-real-time network control through xApps and rApps.\nHowever, they face limitations, including latency overhead in data exchange\nbetween the RAN and RIC, restricting real-time monitoring, and the inability to\naccess user plain data due to privacy and security constraints, hindering use\ncases like beamforming and spectrum classification. In this paper, we leverage\nthe dApps concept to enable real-time RF spectrum classification with LibIQ, a\nnovel library for RF signals that facilitates efficient spectrum monitoring and\nsignal classification by providing functionalities to read I/Q samples as\ntime-series, create datasets and visualize time-series data through plots and\nspectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to\ndetect external RF signals, which are subsequently classified using a CNN\ninside the library. To achieve accurate spectrum analysis, we created an\nextensive dataset of time-series-based I/Q samples, representing distinct\nsignal types captured using a custom dApp running on a 5G deployment over the\nColosseum network emulator and an OTA testbed. We evaluate our model by\ndeploying LibIQ in heterogeneous scenarios with varying center frequencies,\ntime windows, and external RF signals. In real-time analysis, the model\nclassifies the processed I/Q samples, achieving an average accuracy of\napproximately 97.8\\% in identifying signal types across all scenarios. We\npledge to release both LibIQ and the dataset created as a publicly available\nframework upon acceptance.", "AI": {"tldr": "The paper introduces LibIQ, a library for real-time RF spectrum classification in O-RAN, addressing latency and privacy issues in RICs. It achieves 97.8% accuracy using a CNN and a custom dataset.", "motivation": "To overcome limitations of RICs in O-RAN, such as latency and privacy constraints, enabling real-time RF spectrum classification for applications like beamforming.", "method": "Leverages dApps and LibIQ, a library for processing I/Q samples, creating datasets, and classifying signals using a CNN. A custom dataset is generated using a 5G deployment and testbed.", "result": "Achieves 97.8% average accuracy in signal classification across diverse scenarios.", "conclusion": "LibIQ and the dataset will be publicly released, offering a solution for efficient spectrum monitoring in O-RAN."}}
{"id": "2411.19477", "pdf": "https://arxiv.org/pdf/2411.19477", "abs": "https://arxiv.org/abs/2411.19477", "authors": ["Yanxi Chen", "Xuchen Pan", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "Simple and Provable Scaling Laws for the Test-Time Compute of Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose two simple, principled and practical algorithms that enjoy\nprovable scaling laws for the test-time compute of large language models\n(LLMs). The first one is a two-stage knockout-style algorithm: given an input\nproblem, it first generates multiple candidate solutions, and then aggregate\nthem via a knockout tournament for the final output. Assuming that the LLM can\ngenerate a correct solution with non-zero probability and do better than a\nrandom guess in comparing a pair of correct and incorrect solutions, we prove\ntheoretically that the failure probability of this algorithm decays to zero\nexponentially or by a power law (depending on the specific way of scaling) as\nits test-time compute grows. The second one is a two-stage league-style\nalgorithm, where each candidate is evaluated by its average win rate against\nmultiple opponents, rather than eliminated upon loss to a single opponent.\nUnder analogous but more robust assumptions, we prove that its failure\nprobability also decays to zero exponentially with more test-time compute. Both\nalgorithms require a black-box LLM and nothing else (e.g., no verifier or\nreward model) for a minimalistic implementation, which makes them appealing for\npractical applications and easy to adapt for different tasks. Through extensive\nexperiments with diverse models and datasets, we validate the proposed theories\nand demonstrate the outstanding scaling properties of both algorithms.", "AI": {"tldr": "Two algorithms for improving LLM test-time compute efficiency: a knockout-style and a league-style method, both proven to reduce failure probability exponentially or by power law with increased compute.", "motivation": "To address the inefficiency in test-time compute for large language models (LLMs) by proposing scalable, practical algorithms without requiring additional components like verifiers or reward models.", "method": "1. Knockout-style: Generates multiple solutions and aggregates them via a tournament. 2. League-style: Evaluates solutions by average win rate against multiple opponents. Both rely on LLM-generated solutions and comparisons.", "result": "Theoretical proofs show exponential or power-law decay in failure probability with increased compute. Experiments validate scalability across models and tasks.", "conclusion": "The algorithms are practical, scalable, and adaptable, offering efficient test-time compute solutions for LLMs."}}
{"id": "2410.01262", "pdf": "https://arxiv.org/pdf/2410.01262", "abs": "https://arxiv.org/abs/2410.01262", "authors": ["Conghan Yue", "Zhengwei Peng", "Shiyan Du", "Zhi Ji", "Chuangjian Cai", "Le Wan", "Dongyu Zhang"], "title": "Improving Fine-Grained Control via Aggregation of Multiple Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "While many diffusion models perform well when controlling for particular\naspect among style, character, and interaction, they struggle with fine-grained\ncontrol due to dataset limitations and intricate model architecture design.\nThis paper first introduces a novel training-free algorithm in fine-grained\ngeneration, Aggregation of Multiple Diffusion Models (AMDM), which integrates\nfeatures from multiple diffusion models into a specified model to activate\nspecific features and enable fine-grained control. Experimental results\ndemonstrate that AMDM significantly improves fine-grained control without\ntraining, validating its effectiveness. Additionally, it reveals that diffusion\nmodels initially focus on features such as position, attributes, and style,\nwith later stages improving generation quality and consistency. AMDM offers a\nnew perspective for tackling the challenges of fine-grained conditional control\ngeneration in diffusion models: We can fully utilize existing or develop new\nconditional diffusion models that control specific aspects, and then aggregate\nthem using AMDM algorithm. This eliminates the need for constructing complex\ndatasets, designing intricate model architectures, and incurring high training\ncosts. Code is available at: https://github.com/Hammour-steak/AMDM.", "AI": {"tldr": "AMDM is a training-free algorithm that aggregates multiple diffusion models for fine-grained control, improving performance without additional training.", "motivation": "Addressing the challenge of fine-grained control in diffusion models due to dataset limitations and complex architectures.", "method": "Introduces AMDM, which integrates features from multiple diffusion models to activate specific features for fine-grained control.", "result": "AMDM significantly improves fine-grained control without training, revealing insights into feature focus in diffusion models.", "conclusion": "AMDM provides a practical solution for fine-grained control, leveraging existing models and avoiding costly training and dataset construction."}}
{"id": "2505.10545", "pdf": "https://arxiv.org/pdf/2505.10545", "abs": "https://arxiv.org/abs/2505.10545", "authors": ["Amira Alakhdar", "Barnabas Poczos", "Newell Washburn"], "title": "Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design", "categories": ["cs.LG"], "comment": null, "summary": "Developing bioactive molecules remains a central, time- and cost-heavy\nchallenge in drug discovery, particularly for novel targets lacking structural\nor functional data. Pharmacophore modeling presents an alternative for\ncapturing the key features required for molecular bioactivity against a\nbiological target. In this work, we present PharmaDiff, a\npharmacophore-conditioned diffusion model for 3D molecular generation.\nPharmaDiff employs a transformer-based architecture to integrate an atom-based\nrepresentation of the 3D pharmacophore into the generative process, enabling\nthe precise generation of 3D molecular graphs that align with predefined\npharmacophore hypotheses. Through comprehensive testing, PharmaDiff\ndemonstrates superior performance in matching 3D pharmacophore constraints\ncompared to ligand-based drug design methods. Additionally, it achieves higher\ndocking scores across a range of proteins in structure-based drug design,\nwithout the need for target protein structures. By integrating pharmacophore\nmodeling with 3D generative techniques, PharmaDiff offers a powerful and\nflexible framework for rational drug design.", "AI": {"tldr": "PharmaDiff is a pharmacophore-conditioned diffusion model for 3D molecular generation, outperforming traditional methods in matching pharmacophore constraints and achieving higher docking scores without requiring target protein structures.", "motivation": "Developing bioactive molecules for novel targets is challenging due to lack of structural or functional data. Pharmacophore modeling offers a solution by capturing key bioactivity features.", "method": "PharmaDiff uses a transformer-based architecture to integrate 3D pharmacophore data into molecular generation, producing precise 3D molecular graphs aligned with pharmacophore hypotheses.", "result": "PharmaDiff excels in matching 3D pharmacophore constraints and achieves higher docking scores in structure-based drug design, even without target protein structures.", "conclusion": "PharmaDiff combines pharmacophore modeling with 3D generative techniques, providing a flexible and powerful framework for rational drug design."}}
{"id": "2505.10547", "pdf": "https://arxiv.org/pdf/2505.10547", "abs": "https://arxiv.org/abs/2505.10547", "authors": ["Milan Ganai", "Rohan Sinha", "Christopher Agia", "Daniel Morton", "Marco Pavone"], "title": "Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning", "categories": ["cs.RO", "cs.AI"], "comment": "Website: https://milanganai.github.io/fortress/", "summary": "Foundation models can provide robust high-level reasoning on appropriate\nsafety interventions in hazardous scenarios beyond a robot's training data,\ni.e. out-of-distribution (OOD) failures. However, due to the high inference\nlatency of Large Vision and Language Models, current methods rely on manually\ndefined intervention policies to enact fallbacks, thereby lacking the ability\nto plan generalizable, semantically safe motions. To overcome these challenges\nwe present FORTRESS, a framework that generates and reasons about semantically\nsafe fallback strategies in real time to prevent OOD failures. At a low\nfrequency in nominal operations, FORTRESS uses multi-modal reasoners to\nidentify goals and anticipate failure modes. When a runtime monitor triggers a\nfallback response, FORTRESS rapidly synthesizes plans to fallback goals while\ninferring and avoiding semantically unsafe regions in real time. By bridging\nopen-world, multi-modal reasoning with dynamics-aware planning, we eliminate\nthe need for hard-coded fallbacks and human safety interventions. FORTRESS\noutperforms on-the-fly prompting of slow reasoning models in safety\nclassification accuracy on synthetic benchmarks and real-world ANYmal robot\ndata, and further improves system safety and planning success in simulation and\non quadrotor hardware for urban navigation.", "AI": {"tldr": "FORTRESS is a framework for real-time, semantically safe fallback strategies in robots, outperforming manual interventions and slow reasoning models.", "motivation": "Current methods rely on manual intervention policies for OOD failures, lacking generalizable safe motion planning due to high latency in large models.", "method": "FORTRESS uses multi-modal reasoners to anticipate failures and dynamically synthesizes safe fallback plans, avoiding unsafe regions in real time.", "result": "It improves safety classification accuracy on benchmarks and real-world data, enhancing system safety and planning success in simulations and hardware.", "conclusion": "FORTRESS eliminates hard-coded fallbacks and human interventions, bridging open-world reasoning with real-time planning."}}
{"id": "2412.03587", "pdf": "https://arxiv.org/pdf/2412.03587", "abs": "https://arxiv.org/abs/2412.03587", "authors": ["Hyegang Son", "Yonglak Son", "Changhoon Kim", "Young Geun Kim"], "title": "Not All Adapters Matter: Selective Adapter Freezing for Memory-Efficient Fine-Tuning of Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "URL: https://aclanthology.org/2025.naacl-long.480/ Volume:\n  Proceedings of the 2025 Conference of the Nations of the Americas Chapter of\n  the Association for Computational Linguistics: Human Language Technologies\n  (Volume 1: Long Papers) Year: 2025 Address: Albuquerque, New Mexico", "summary": "Transformer-based large-scale pre-trained models achieve great success.\nFine-tuning is the standard practice for leveraging these models in downstream\ntasks. Among the fine-tuning methods, adapter-tuning provides a\nparameter-efficient fine-tuning by introducing lightweight trainable modules\nwhile keeping most pre-trained parameters frozen. However, existing\nadapter-tuning methods still impose substantial resource usage. Through our\ninvestigation, we show that each adapter unequally contributes to both task\nperformance and resource usage. Motivated by this insight, we propose Selective\nAdapter FrEezing (SAFE), which gradually freezes less important adapters early\nto reduce unnecessary resource usage while maintaining performance. In our\nexperiments, SAFE reduces memory usage, computation amount, and training time\nby 42.85\\%, 34.59\\%, and 11.82\\%, respectively, while achieving comparable or\nbetter task performance compared to the baseline. We also demonstrate that SAFE\ninduces regularization effect, thereby smoothing the loss landscape, which\nenables the model to generalize better by avoiding sharp minima.", "AI": {"tldr": "SAFE introduces selective freezing of less important adapters in adapter-tuning, reducing resource usage while maintaining performance.", "motivation": "Existing adapter-tuning methods are resource-intensive, and not all adapters contribute equally to performance.", "method": "Proposes SAFE, which gradually freezes less important adapters early to save resources.", "result": "SAFE reduces memory, computation, and training time significantly (42.85%, 34.59%, 11.82%) while matching or improving performance.", "conclusion": "SAFE efficiently balances resource usage and performance, also improving generalization by smoothing the loss landscape."}}
{"id": "2410.16430", "pdf": "https://arxiv.org/pdf/2410.16430", "abs": "https://arxiv.org/abs/2410.16430", "authors": ["Zhiming Hu", "Guanhua Zhang", "Zheming Yin", "Daniel Haeufle", "Syn Schmitt", "Andreas Bulling"], "title": "HaHeAE: Learning Generalisable Joint Representations of Human Hand and Head Movements in Extended Reality", "categories": ["cs.CV"], "comment": "Link: https://zhiminghu.net/hu25_haheae", "summary": "Human hand and head movements are the most pervasive input modalities in\nextended reality (XR) and are significant for a wide range of applications.\nHowever, prior works on hand and head modelling in XR only explored a single\nmodality or focused on specific applications. We present HaHeAE - a novel\nself-supervised method for learning generalisable joint representations of hand\nand head movements in XR. At the core of our method is an autoencoder (AE) that\nuses a graph convolutional network-based semantic encoder and a diffusion-based\nstochastic encoder to learn the joint semantic and stochastic representations\nof hand-head movements. It also features a diffusion-based decoder to\nreconstruct the original signals. Through extensive evaluations on three public\nXR datasets, we show that our method 1) significantly outperforms commonly used\nself-supervised methods by up to 74.0% in terms of reconstruction quality and\nis generalisable across users, activities, and XR environments, 2) enables new\napplications, including interpretable hand-head cluster identification and\nvariable hand-head movement generation, and 3) can serve as an effective\nfeature extractor for downstream tasks. Together, these results demonstrate the\neffectiveness of our method and underline the potential of self-supervised\nmethods for jointly modelling hand-head behaviours in extended reality.", "AI": {"tldr": "HaHeAE is a self-supervised method for joint hand-head movement modeling in XR, outperforming existing methods by 74% in reconstruction quality and enabling new applications.", "motivation": "Prior works on hand and head modeling in XR were limited to single modalities or specific applications, lacking generalizability.", "method": "Uses an autoencoder with a graph convolutional network-based semantic encoder and diffusion-based stochastic encoder, plus a diffusion-based decoder.", "result": "Outperforms common methods by 74%, generalizes across users/activities/environments, and enables new applications like cluster identification and movement generation.", "conclusion": "Demonstrates the effectiveness of self-supervised methods for joint hand-head behavior modeling in XR."}}
{"id": "2505.10556", "pdf": "https://arxiv.org/pdf/2505.10556", "abs": "https://arxiv.org/abs/2505.10556", "authors": ["Nazanin Zounemat Kermani", "Sadjad Naderi", "Claire H. Dilliway", "Claire E. Heaney", "Shrreya Behll", "Boyang Chen", "Hisham Abubakar-Waziri", "Alexandra E. Porter", "Marc Chadeau-Hyam", "Fangxin Fang", "Ian M. Adcock", "Kian Fan Chung", "Christopher C. Pain"], "title": "An AI-driven framework for the prediction of personalised health response to air pollution", "categories": ["cs.LG", "physics.ao-ph"], "comment": "Kermani and Naderi share first authorship. 20 pages, 6 figures and 1\n  table", "summary": "Air pollution poses a significant threat to public health, causing or\nexacerbating many respiratory and cardiovascular diseases. In addition, climate\nchange is bringing about more extreme weather events such as wildfires and\nheatwaves, which can increase levels of pollution and worsen the effects of\npollution exposure. Recent advances in personal sensing have transformed the\ncollection of behavioural and physiological data, leading to the potential for\nnew improvements in healthcare. We wish to capitalise on this data, alongside\nnew capabilities in AI for making time series predictions, in order to monitor\nand predict health outcomes for an individual. Thus, we present a novel\nworkflow for predicting personalised health responses to pollution by\nintegrating physiological data from wearable fitness devices with real-time\nenvironmental exposures. The data is collected from various sources in a secure\nand ethical manner, and is used to train an AI model to predict individual\nhealth responses to pollution exposure within a cloud-based, modular framework.\nWe demonstrate that the AI model -- an Adversarial Autoencoder neural network\nin this case -- accurately reconstructs time-dependent health signals and\ncaptures nonlinear responses to pollution. Transfer learning is applied using\ndata from a personal smartwatch, which increases the generalisation abilities\nof the AI model and illustrates the adaptability of the approach to real-world,\nuser-generated data.", "AI": {"tldr": "A novel workflow integrates wearable fitness data and real-time environmental pollution to predict personalized health responses using an AI model, demonstrating accurate predictions and adaptability.", "motivation": "Air pollution and climate change exacerbate health risks; leveraging personal sensing and AI can improve healthcare by predicting individual health responses to pollution.", "method": "Integrates physiological data from wearables with environmental exposures, trains an Adversarial Autoencoder AI model, and uses transfer learning for generalization.", "result": "The AI model accurately reconstructs health signals and captures nonlinear pollution responses, showing adaptability to user-generated data.", "conclusion": "The approach effectively predicts personalized health impacts of pollution, highlighting potential for real-world healthcare applications."}}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules.", "AI": {"tldr": "The paper introduces Neural Thermodynamic Laws (NTL), a framework linking thermodynamic principles to LLM training dynamics, offering theoretical insights and practical guidelines for learning rate schedules.", "motivation": "To uncover underlying laws of large language models (LLMs) beyond neural scaling laws by exploring thermodynamic analogies in training dynamics.", "method": "Theoretical demonstration of thermodynamic quantities (e.g., temperature, entropy) and principles (e.g., three laws of thermodynamics) under river-valley loss landscape assumptions.", "result": "NTL provides a scientific perspective on LLM training, revealing emergent thermodynamic behaviors and practical implications for learning rate design.", "conclusion": "NTL bridges theory and practice, offering a novel framework to understand and optimize LLM training through thermodynamic principles."}}
{"id": "2501.00777", "pdf": "https://arxiv.org/pdf/2501.00777", "abs": "https://arxiv.org/abs/2501.00777", "authors": ["Qianli Wang", "Nils Feldhus", "Simon Ostermann", "Luis Felipe Villa-Arenas", "Sebastian M\u00f6ller", "Vera Schmitt"], "title": "FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation", "categories": ["cs.CL", "cs.LG"], "comment": "ACL 2025 Findings; camera-ready version", "summary": "Counterfactual examples are widely used in natural language processing (NLP)\nas valuable data to improve models, and in explainable artificial intelligence\n(XAI) to understand model behavior. The automated generation of counterfactual\nexamples remains a challenging task even for large language models (LLMs),\ndespite their impressive performance on many tasks. In this paper, we first\nintroduce ZeroCF, a faithful approach for leveraging important words derived\nfrom feature attribution methods to generate counterfactual examples in a\nzero-shot setting. Second, we present a new framework, FitCF, which further\nverifies aforementioned counterfactuals by label flip verification and then\ninserts them as demonstrations for few-shot prompting, outperforming two\nstate-of-the-art baselines. Through ablation studies, we identify the\nimportance of each of FitCF's core components in improving the quality of\ncounterfactuals, as assessed through flip rate, perplexity, and similarity\nmeasures. Furthermore, we show the effectiveness of LIME and Integrated\nGradients as backbone attribution methods for FitCF and find that the number of\ndemonstrations has the largest effect on performance. Finally, we reveal a\nstrong correlation between the faithfulness of feature attribution scores and\nthe quality of generated counterfactuals.", "AI": {"tldr": "ZeroCF and FitCF are introduced for zero-shot and few-shot counterfactual generation in NLP, leveraging feature attribution methods and label flip verification to improve quality.", "motivation": "Automated generation of counterfactual examples is challenging for LLMs, despite their performance. The paper aims to improve this using ZeroCF and FitCF.", "method": "ZeroCF uses feature attribution for zero-shot generation. FitCF adds label flip verification and few-shot prompting, outperforming baselines.", "result": "FitCF improves counterfactual quality (flip rate, perplexity, similarity). LIME and Integrated Gradients are effective backbones. Faithfulness of attribution correlates with quality.", "conclusion": "ZeroCF and FitCF advance counterfactual generation, with FitCF's components and attribution methods proving critical for performance."}}
{"id": "2411.05731", "pdf": "https://arxiv.org/pdf/2411.05731", "abs": "https://arxiv.org/abs/2411.05731", "authors": ["Junxi Jin", "Xiulai Li", "Haiping Huang", "Lianjun Liu", "Yujie Sun", "Logan Liu"], "title": "PEP-GS: Perceptually-Enhanced Precise Structured 3D Gaussians for View-Adaptive Rendering", "categories": ["cs.CV"], "comment": null, "summary": "Recently, 3D Gaussian Splatting (3D-GS) has achieved significant success in\nreal-time, high-quality 3D scene rendering. However, it faces several\nchallenges, including Gaussian redundancy, limited ability to capture\nview-dependent effects, and difficulties in handling complex lighting and\nspecular reflections. Additionally, methods that use spherical harmonics for\ncolor representation often struggle to effectively capture anisotropic\ncomponents, especially when modeling view-dependent colors under complex\nlighting conditions, leading to insufficient contrast and unnatural color\nsaturation. To address these limitations, we introduce PEP-GS, a\nperceptually-enhanced framework that dynamically predicts Gaussian attributes,\nincluding opacity, color, and covariance. We replace traditional spherical\nharmonics with a Hierarchical Granular-Structural Attention mechanism, which\nenables more accurate modeling of complex view-dependent color effects. By\nemploying a stable and interpretable framework for opacity and covariance\nestimation, PEP-GS avoids the removal of essential Gaussians prematurely,\nensuring a more accurate scene representation. Furthermore, perceptual\noptimization is applied to the final rendered images, enhancing perceptual\nconsistency across different views and ensuring high-quality renderings with\nimproved texture fidelity and fine-scale detail preservation. Experimental\nresults demonstrate that PEP-GS outperforms state-of-the-art methods,\nparticularly in challenging scenarios involving view-dependent effects and\nfine-scale details.", "AI": {"tldr": "PEP-GS improves 3D Gaussian Splatting by addressing Gaussian redundancy, view-dependent effects, and lighting challenges with a perceptually-enhanced framework and Hierarchical Granular-Structural Attention.", "motivation": "3D-GS struggles with Gaussian redundancy, view-dependent effects, and complex lighting. Traditional methods fail to capture anisotropic components and view-dependent colors accurately.", "method": "PEP-GS dynamically predicts Gaussian attributes (opacity, color, covariance) and replaces spherical harmonics with Hierarchical Granular-Structural Attention for better color modeling. It also optimizes perceptual consistency.", "result": "PEP-GS outperforms state-of-the-art methods, especially in handling view-dependent effects and fine-scale details.", "conclusion": "PEP-GS provides a more accurate and perceptually consistent framework for 3D scene rendering, addressing key limitations of 3D-GS."}}
{"id": "2505.09643", "pdf": "https://arxiv.org/pdf/2505.09643", "abs": "https://arxiv.org/abs/2505.09643", "authors": ["Zhixuan Wang"], "title": "A Computational Approach to Epilepsy Treatment: An AI-optimized Global Natural Product Prescription System", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Epilepsy is a prevalent neurological disease with millions of patients\nworldwide. Many patients have turned to alternative medicine due to the limited\nefficacy and side effects of conventional antiepileptic drugs. In this study,\nwe developed a computational approach to optimize herbal epilepsy treatment\nthrough AI-driven analysis of global natural products and statistically\nvalidated randomized controlled trials (RCTs). Our intelligent prescription\nsystem combines machine learning (ML) algorithms for herb-efficacy\ncharacterization, Bayesian optimization for personalized dosing, and\nmeta-analysis of RCTs for evidence-based recommendations. The system analyzed\n1,872 natural compounds from traditional Chinese medicine (TCM), Ayurveda, and\nethnopharmacological databases, integrating their bioactive properties with\nclinical outcomes from 48 RCTs covering 48 epilepsy conditions (n=5,216). Using\nLASSO regression and SHAP value analysis, we identified 17 high-efficacy herbs\n(e.g., Gastrodia elata [using \\'e for accented characters], Withania\nsomnifera), showing significant seizure reduction (p$<$0.01, Cohen's d=0.89)\nwith statistical significance confirmed by multiple testing (p$<$0.001). A\nrandomized double-blind validation trial (n=120) demonstrated 28.5\\% greater\nseizure frequency reduction with AI-optimized herbal prescriptions compared to\nconventional protocols (95\\% CI: 18.7-37.3\\%, p=0.003).", "AI": {"tldr": "AI-driven computational approach optimizes herbal epilepsy treatment by analyzing natural products and RCTs, identifying 17 high-efficacy herbs with significant seizure reduction.", "motivation": "Limited efficacy and side effects of conventional antiepileptic drugs drive the need for alternative treatments.", "method": "Combines ML for herb-efficacy, Bayesian optimization for dosing, and meta-analysis of RCTs. Analyzed 1,872 natural compounds and 48 RCTs.", "result": "Identified 17 high-efficacy herbs (e.g., Gastrodia elata) with significant seizure reduction (p<0.01). AI-optimized prescriptions showed 28.5% greater reduction in seizures.", "conclusion": "AI-optimized herbal prescriptions offer a promising alternative to conventional epilepsy treatments, validated by clinical trials."}}
{"id": "2407.04363", "pdf": "https://arxiv.org/pdf/2407.04363", "abs": "https://arxiv.org/abs/2407.04363", "authors": ["Petr Anokhin", "Nikita Semenov", "Artyom Sorokin", "Dmitry Evseev", "Andrey Kravchenko", "Mikhail Burtsev", "Evgeny Burnaev"], "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents", "categories": ["cs.AI"], "comment": "Code for this work is avaliable at\n  https://github.com/AIRI-Institute/AriGraph", "summary": "Advancements in the capabilities of Large Language Models (LLMs) have created\na promising foundation for developing autonomous agents. With the right tools,\nthese agents could learn to solve tasks in new environments by accumulating and\nupdating their knowledge. Current LLM-based agents process past experiences\nusing a full history of observations, summarization, retrieval augmentation.\nHowever, these unstructured memory representations do not facilitate the\nreasoning and planning essential for complex decision-making. In our study, we\nintroduce AriGraph, a novel method wherein the agent constructs and updates a\nmemory graph that integrates semantic and episodic memories while exploring the\nenvironment. We demonstrate that our Ariadne LLM agent, consisting of the\nproposed memory architecture augmented with planning and decision-making,\neffectively handles complex tasks within interactive text game environments\ndifficult even for human players. Results show that our approach markedly\noutperforms other established memory methods and strong RL baselines in a range\nof problems of varying complexity. Additionally, AriGraph demonstrates\ncompetitive performance compared to dedicated knowledge graph-based methods in\nstatic multi-hop question-answering.", "AI": {"tldr": "AriGraph, a memory graph method for LLM-based agents, outperforms existing memory and RL methods in complex tasks and question-answering.", "motivation": "Current LLM-based agents lack structured memory for reasoning and planning, limiting complex decision-making.", "method": "AriGraph integrates semantic and episodic memories into a graph, enhancing planning and decision-making in the Ariadne LLM agent.", "result": "AriGraph outperforms other memory methods and RL baselines in complex tasks and matches knowledge graph methods in question-answering.", "conclusion": "AriGraph provides a robust memory architecture for LLM agents, improving performance in complex environments."}}
{"id": "2501.13957", "pdf": "https://arxiv.org/pdf/2501.13957", "abs": "https://arxiv.org/abs/2501.13957", "authors": ["Jadon Geathers", "Yann Hicke", "Colleen Chan", "Niroop Rajashekar", "Justin Sewell", "Susannah Cornes", "Rene F. Kizilcec", "Dennis Shung"], "title": "Benchmarking Generative AI for Scoring Medical Student Interviews in Objective Structured Clinical Examinations (OSCEs)", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages + 3 pages of references, 4 figures", "summary": "Objective Structured Clinical Examinations (OSCEs) are widely used to assess\nmedical students' communication skills, but scoring interview-based assessments\nis time-consuming and potentially subject to human bias. This study explored\nthe potential of large language models (LLMs) to automate OSCE evaluations\nusing the Master Interview Rating Scale (MIRS). We compared the performance of\nfour state-of-the-art LLMs (GPT-4o, Claude 3.5, Llama 3.1, and Gemini 1.5 Pro)\nin evaluating OSCE transcripts across all 28 items of the MIRS under the\nconditions of zero-shot, chain-of-thought (CoT), few-shot, and multi-step\nprompting. The models were benchmarked against a dataset of 10 OSCE cases with\n174 expert consensus scores available. Model performance was measured using\nthree accuracy metrics (exact, off-by-one, thresholded). Averaging across all\nMIRS items and OSCE cases, LLMs performed with low exact accuracy (0.27 to\n0.44), and moderate to high off-by-one accuracy (0.67 to 0.87) and thresholded\naccuracy (0.75 to 0.88). A zero temperature parameter ensured high intra-rater\nreliability ({\\alpha} = 0.98 for GPT-4o). CoT, few-shot, and multi-step\ntechniques proved valuable when tailored to specific assessment items. The\nperformance was consistent across MIRS items, independent of encounter phases\nand communication domains. We demonstrated the feasibility of AI-assisted OSCE\nevaluation and provided benchmarking of multiple LLMs across multiple prompt\ntechniques. Our work provides a baseline performance assessment for LLMs that\nlays a foundation for future research into automated assessment of clinical\ncommunication skills.", "AI": {"tldr": "The study evaluates the use of large language models (LLMs) to automate OSCE assessments, comparing four models (GPT-4o, Claude 3.5, Llama 3.1, Gemini 1.5 Pro) using the MIRS scale. Results show moderate to high accuracy in off-by-one and thresholded metrics, with low exact accuracy, and highlight the potential of AI-assisted evaluations.", "motivation": "To address the time-consuming and potentially biased nature of human scoring in OSCE evaluations by exploring AI automation.", "method": "Four LLMs were tested on 10 OSCE cases using the MIRS scale under zero-shot, chain-of-thought, few-shot, and multi-step prompting. Performance was measured using exact, off-by-one, and thresholded accuracy metrics.", "result": "LLMs showed low exact accuracy (0.27-0.44) but moderate to high off-by-one (0.67-0.87) and thresholded accuracy (0.75-0.88). Techniques like CoT and few-shot improved performance for specific items.", "conclusion": "The study demonstrates the feasibility of AI-assisted OSCE evaluations and provides a benchmark for future research in automating clinical communication assessments."}}
{"id": "2411.08665", "pdf": "https://arxiv.org/pdf/2411.08665", "abs": "https://arxiv.org/abs/2411.08665", "authors": ["Youqi Liao", "Xieyuanli Chen", "Shuhao Kang", "Jianping Li", "Zhen Dong", "Hongchao Fan", "Bisheng Yang"], "title": "OSMLoc: Single Image-Based Visual Localization in OpenStreetMap with Fused Geometric and Semantic Guidance", "categories": ["cs.CV"], "comment": "16 pages, technical report", "summary": "OpenStreetMap (OSM), a rich and versatile source of volunteered geographic\ninformation (VGI), facilitates human self-localization and scene understanding\nby integrating nearby visual observations with vectorized map data. However,\nthe disparity in modalities and perspectives poses a major challenge for\neffectively matching camera imagery with compact map representations, thereby\nlimiting the full potential of VGI data in real-world localization\napplications.\n  Inspired by the fact that the human brain relies on the fusion of geometric\nand semantic understanding for spatial localization tasks, we propose the\nOSMLoc in this paper. OSMLoc is a brain-inspired visual localization approach\nbased on first-person-view images against the OSM maps. It integrates semantic\nand geometric guidance to significantly improve accuracy, robustness, and\ngeneralization capability. First, we equip the OSMLoc with the visual\nfoundational model to extract powerful image features. Second, a\ngeometry-guided depth distribution adapter is proposed to bridge the monocular\ndepth estimation and camera-to-BEV transform. Thirdly, the semantic embeddings\nfrom the OSM data are utilized as auxiliary guidance for image-to-OSM feature\nmatching. To validate the proposed OSMLoc, we collect a worldwide cross-area\nand cross-condition (CC) benchmark for extensive evaluation. Experiments on the\nMGL dataset, CC validation benchmark, and KITTI dataset have demonstrated the\nsuperiority of our method. Code, pre-trained models, CC validation benchmark,\nand additional results are available at: https://github.com/WHU-USI3DV/OSMLoc.", "AI": {"tldr": "OSMLoc is a brain-inspired visual localization method using OpenStreetMap (OSM) data, combining semantic and geometric guidance to improve accuracy and robustness.", "motivation": "The disparity between camera imagery and vectorized map data limits VGI's potential in localization. OSMLoc mimics human brain fusion of geometry and semantics to address this.", "method": "OSMLoc uses a visual foundational model for image features, a geometry-guided depth adapter, and semantic embeddings from OSM for feature matching.", "result": "Experiments on MGL, CC benchmark, and KITTI show OSMLoc's superiority in accuracy, robustness, and generalization.", "conclusion": "OSMLoc effectively bridges the gap between visual observations and map data, enhancing localization performance with open-source availability."}}
{"id": "2505.09647", "pdf": "https://arxiv.org/pdf/2505.09647", "abs": "https://arxiv.org/abs/2505.09647", "authors": ["Leighton Pate Barnes", "Stephen Cameron", "Benjamin Howard"], "title": "On Unbiased Low-Rank Approximation with Minimum Distortion", "categories": ["cs.DS", "cs.IT", "cs.LG", "math.IT", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "We describe an algorithm for sampling a low-rank random matrix $Q$ that best\napproximates a fixed target matrix $P\\in\\mathbb{C}^{n\\times m}$ in the\nfollowing sense: $Q$ is unbiased, i.e., $\\mathbb{E}[Q] = P$;\n$\\mathsf{rank}(Q)\\leq r$; and $Q$ minimizes the expected Frobenius norm error\n$\\mathbb{E}\\|P-Q\\|_F^2$. Our algorithm mirrors the solution to the efficient\nunbiased sparsification problem for vectors, except applied to the singular\ncomponents of the matrix $P$. Optimality is proven by showing that our\nalgorithm matches the error from an existing lower bound.", "AI": {"tldr": "An algorithm for sampling a low-rank unbiased matrix approximating a target matrix with minimal Frobenius norm error.", "motivation": "To efficiently approximate a fixed target matrix with a low-rank unbiased matrix while minimizing error.", "method": "Mirrors unbiased sparsification for vectors, applied to the singular components of the target matrix.", "result": "The algorithm matches an existing lower bound, proving its optimality.", "conclusion": "The proposed method provides an optimal solution for low-rank unbiased matrix approximation."}}
{"id": "2409.14191", "pdf": "https://arxiv.org/pdf/2409.14191", "abs": "https://arxiv.org/abs/2409.14191", "authors": ["Sejin Kim", "Hosung Lee", "Sundong Kim"], "title": "Addressing and Visualizing Misalignments in Human Task-Solving Trajectories", "categories": ["cs.AI", "cs.HC"], "comment": "KDD 2025 accepted", "summary": "Understanding misalignments in human task-solving trajectories is critical\nfor improving AI models trained to mimic human reasoning. This study\ncategorizes such misalignments into three types: \\textbf{(1) Lack of functions\nto express intent}, \\textbf{(2) Inefficient action sequences}, and \\textbf{(3)\nIncorrect intentions that cannot solve the task}. To address these issues, we\nfirst formalize and define these three types of misalignments. We then propose\na heuristic algorithm to detect these misalignments in O2ARC trajectories and\nconduct a hierarchical and quantitative analysis of their impact. Furthermore,\nwe introduce an intention estimation algorithm that predicts missing alignment\ninformation between user actions and inferred intentions, leveraging our\nformalized framework. Through trajectory alignment, we experimentally\ndemonstrate that AI models trained on human task-solving trajectories improve\nperformance in mimicking human reasoning. Based on hierarchical analysis and\nexperiments, we highlight the importance of trajectory-intention alignment and\ndemonstrate the potential of intention learning.", "AI": {"tldr": "The paper identifies three types of misalignments in human task-solving trajectories, proposes detection and intention estimation algorithms, and shows improved AI performance through alignment.", "motivation": "To improve AI models mimicking human reasoning by addressing misalignments in human task-solving trajectories.", "method": "Formalizes misalignment types, proposes heuristic detection and intention estimation algorithms, and conducts hierarchical analysis and experiments.", "result": "AI models trained on aligned trajectories show improved performance in mimicking human reasoning.", "conclusion": "Trajectory-intention alignment is crucial, and intention learning has significant potential."}}
{"id": "2501.15674", "pdf": "https://arxiv.org/pdf/2501.15674", "abs": "https://arxiv.org/abs/2501.15674", "authors": ["Yuxuan Gu", "Wuyang Zhou", "Giorgos Iacovides", "Danilo Mandic"], "title": "TensorLLM: Tensorising Multi-Head Attention for Enhanced Reasoning and Compression in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "Accpeted for IEEE International Joint Conference on Neural Networks\n  (IJCNN 2025). The code is available at https://github.com/guyuxuan9/TensorLLM", "summary": "The reasoning abilities of Large Language Models (LLMs) can be improved by\nstructurally denoising their weights, yet existing techniques primarily focus\non denoising the feed-forward network (FFN) of the transformer block, and can\nnot efficiently utilise the Multi-head Attention (MHA) block, which is the core\nof transformer architectures. To address this issue, we propose a novel\nintuitive framework that, at its very core, performs MHA compression through a\nmulti-head tensorisation process and the Tucker decomposition. This enables\nboth higher-dimensional structured denoising and compression of the MHA\nweights, by enforcing a shared higher-dimensional subspace across the weights\nof the multiple attention heads. We demonstrate that this approach consistently\nenhances the reasoning capabilities of LLMs across multiple benchmark datasets,\nand for both encoder-only and decoder-only architectures, while achieving\ncompression rates of up to $\\sim 250$ times in the MHA weights, all without\nrequiring any additional data, training, or fine-tuning. Furthermore, we show\nthat the proposed method can be seamlessly combined with existing\nFFN-only-based denoising techniques to achieve further improvements in LLM\nreasoning performance.", "AI": {"tldr": "A novel framework improves LLM reasoning by compressing and denoising Multi-head Attention (MHA) weights using tensorization and Tucker decomposition, achieving up to 250x compression and enhanced performance without extra data or training.", "motivation": "Existing techniques focus on denoising FFN but inefficiently utilize MHA, a core component of transformers. This work addresses this gap.", "method": "Proposes MHA compression via multi-head tensorization and Tucker decomposition, enforcing shared higher-dimensional subspaces for denoising and compression.", "result": "Consistent improvement in LLM reasoning across benchmarks, 250x MHA weight compression, and compatibility with FFN denoising techniques.", "conclusion": "The method effectively enhances LLM reasoning and compression, seamlessly integrating with existing techniques for further gains."}}
{"id": "2411.14347", "pdf": "https://arxiv.org/pdf/2411.14347", "abs": "https://arxiv.org/abs/2411.14347", "authors": ["Tianhe Ren", "Yihao Chen", "Qing Jiang", "Zhaoyang Zeng", "Yuda Xiong", "Wenlong Liu", "Zhengyu Ma", "Junyi Shen", "Yuan Gao", "Xiaoke Jiang", "Xingyu Chen", "Zhuheng Song", "Yuhong Zhang", "Hongjie Huang", "Han Gao", "Shilong Liu", "Hao Zhang", "Feng Li", "Kent Yu", "Lei Zhang"], "title": "DINO-X: A Unified Vision Model for Open-World Object Detection and Understanding", "categories": ["cs.CV"], "comment": "Technical Report", "summary": "In this paper, we introduce DINO-X, which is a unified object-centric vision\nmodel developed by IDEA Research with the best open-world object detection\nperformance to date. DINO-X employs the same Transformer-based encoder-decoder\narchitecture as Grounding DINO 1.5 to pursue an object-level representation for\nopen-world object understanding. To make long-tailed object detection easy,\nDINO-X extends its input options to support text prompt, visual prompt, and\ncustomized prompt. With such flexible prompt options, we develop a universal\nobject prompt to support prompt-free open-world detection, making it possible\nto detect anything in an image without requiring users to provide any prompt.\nTo enhance the model's core grounding capability, we have constructed a\nlarge-scale dataset with over 100 million high-quality grounding samples,\nreferred to as Grounding-100M, for advancing the model's open-vocabulary\ndetection performance. Pre-training on such a large-scale grounding dataset\nleads to a foundational object-level representation, which enables DINO-X to\nintegrate multiple perception heads to simultaneously support multiple object\nperception and understanding tasks, including detection, segmentation, pose\nestimation, object captioning, object-based QA, etc. Experimental results\ndemonstrate the superior performance of DINO-X. Specifically, the DINO-X Pro\nmodel achieves 56.0 AP, 59.8 AP, and 52.4 AP on the COCO, LVIS-minival, and\nLVIS-val zero-shot object detection benchmarks, respectively. Notably, it\nscores 63.3 AP and 56.5 AP on the rare classes of LVIS-minival and LVIS-val\nbenchmarks, improving the previous SOTA performance by 5.8 AP and 5.0 AP. Such\na result underscores its significantly improved capacity for recognizing\nlong-tailed objects.", "AI": {"tldr": "DINO-X is a unified object-centric vision model with state-of-the-art open-world object detection performance, supporting flexible prompts and multiple perception tasks.", "motivation": "To advance open-world object understanding and improve long-tailed object detection by leveraging a large-scale dataset and flexible prompt options.", "method": "Uses a Transformer-based encoder-decoder architecture, extends input options (text, visual, customized prompts), and pre-trains on Grounding-100M dataset.", "result": "Achieves 56.0 AP on COCO, 59.8 AP on LVIS-minival, and 52.4 AP on LVIS-val, with significant improvements in rare class detection.", "conclusion": "DINO-X sets a new benchmark for open-world object detection and demonstrates superior performance in recognizing long-tailed objects."}}
{"id": "2505.09660", "pdf": "https://arxiv.org/pdf/2505.09660", "abs": "https://arxiv.org/abs/2505.09660", "authors": ["Saptarshi Saha", "Dhruv Vansraj Rathore", "Soumadeep Saha", "Utpal Garain", "David Doermann"], "title": "On Measuring Intrinsic Causal Attributions in Deep Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Quantifying the causal influence of input features within neural networks has\nbecome a topic of increasing interest. Existing approaches typically assess\ndirect, indirect, and total causal effects. This work treats NNs as structural\ncausal models (SCMs) and extends our focus to include intrinsic causal\ncontributions (ICC). We propose an identifiable generative post-hoc framework\nfor quantifying ICC. We also draw a relationship between ICC and Sobol'\nindices. Our experiments on synthetic and real-world datasets demonstrate that\nICC generates more intuitive and reliable explanations compared to existing\nglobal explanation techniques.", "AI": {"tldr": "The paper introduces intrinsic causal contributions (ICC) for neural networks, proposing a post-hoc framework to quantify ICC and linking it to Sobol' indices, showing improved explanations.", "motivation": "To better understand and quantify the causal influence of input features in neural networks, extending beyond direct, indirect, and total effects.", "method": "Treats neural networks as structural causal models (SCMs) and proposes an identifiable generative post-hoc framework for ICC. Links ICC to Sobol' indices.", "result": "Experiments on synthetic and real-world datasets show ICC provides more intuitive and reliable explanations than existing global techniques.", "conclusion": "ICC offers a promising approach for causal explanation in neural networks, outperforming current methods."}}
{"id": "2412.18673", "pdf": "https://arxiv.org/pdf/2412.18673", "abs": "https://arxiv.org/abs/2412.18673", "authors": ["Xingjian Zhang", "Ziyang Xiong", "Shixuan Liu", "Yutong Xie", "Tolga Ergen", "Dongsub Shim", "Hua Xu", "Honglak Lee", "Qiaozhu Me"], "title": "MapExplorer: New Content Generation from Low-Dimensional Visualizations", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Low-dimensional visualizations, or \"projection maps,\" are widely used in\nscientific and creative domains to interpret large-scale and complex datasets.\nThese visualizations not only aid in understanding existing knowledge spaces\nbut also implicitly guide exploration into unknown areas. Although techniques\nsuch as t-SNE and UMAP can generate these maps, there exists no systematic\nmethod for leveraging them to generate new content. To address this, we\nintroduce MapExplorer, a novel knowledge discovery task that translates\ncoordinates within any projection map into coherent, contextually aligned\ntextual content. This allows users to interactively explore and uncover\ninsights embedded in the maps. To evaluate the performance of MapExplorer\nmethods, we propose Atometric, a fine-grained metric inspired by ROUGE that\nquantifies logical coherence and alignment between generated and reference\ntext. Experiments on diverse datasets demonstrate the versatility of\nMapExplorer in generating scientific hypotheses, crafting synthetic personas,\nand devising strategies for attacking large language models-even with simple\nbaseline methods. By bridging visualization and generation, our work highlights\nthe potential of MapExplorer to enable intuitive human-AI collaboration in\nlarge-scale data exploration.", "AI": {"tldr": "MapExplorer introduces a method to translate projection map coordinates into coherent text, enabling interactive exploration of datasets, and proposes Atometric for evaluation.", "motivation": "Existing projection maps (e.g., t-SNE, UMAP) lack systematic methods for generating new content from them.", "method": "MapExplorer translates map coordinates into contextually aligned textual content, evaluated by Atometric.", "result": "Experiments show MapExplorer's versatility in generating hypotheses, personas, and strategies, even with simple baselines.", "conclusion": "MapExplorer bridges visualization and generation, enhancing human-AI collaboration in data exploration."}}
{"id": "2502.04689", "pdf": "https://arxiv.org/pdf/2502.04689", "abs": "https://arxiv.org/abs/2502.04689", "authors": ["Yuwei Yin", "Giuseppe Carenini"], "title": "ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": "21 pages. Code: https://github.com/YuweiYin/ARR", "summary": "Large language models (LLMs) have demonstrated impressive capabilities on\ncomplex evaluation benchmarks, many of which are formulated as\nquestion-answering (QA) tasks. Enhancing the performance of LLMs in QA contexts\nis becoming increasingly vital for advancing their development and\napplicability. This paper introduces ARR, an intuitive, effective, and general\nQA solving method that explicitly incorporates three key steps: analyzing the\nintent of the question, retrieving relevant information, and reasoning step by\nstep. Notably, this paper is the first to introduce intent analysis in QA,\nwhich plays a vital role in ARR. Comprehensive evaluations across 10 diverse QA\ntasks demonstrate that ARR consistently outperforms the baseline methods.\nAblation and case studies further validate the positive contributions of each\nARR component. Furthermore, experiments involving variations in prompt design\nindicate that ARR maintains its effectiveness regardless of the specific prompt\nformulation. Additionally, extensive evaluations across various model sizes,\nLLM series, and generation settings solidify the effectiveness, robustness, and\ngeneralizability of ARR.", "AI": {"tldr": "ARR is a QA method for LLMs that improves performance by analyzing question intent, retrieving info, and reasoning step-by-step. It outperforms baselines across diverse tasks.", "motivation": "Enhancing LLM performance in QA tasks is crucial for their development and applicability.", "method": "ARR incorporates intent analysis, information retrieval, and step-by-step reasoning.", "result": "ARR consistently outperforms baselines across 10 QA tasks and is robust to prompt variations.", "conclusion": "ARR is effective, robust, and generalizable, with intent analysis being a key innovation."}}
{"id": "2412.16028", "pdf": "https://arxiv.org/pdf/2412.16028", "abs": "https://arxiv.org/abs/2412.16028", "authors": ["Jungho Lee", "Suhwan Cho", "Taeoh Kim", "Ho-Deok Jang", "Minhyeok Lee", "Geonho Cha", "Dongyoon Wee", "Dogyoon Lee", "Sangyoun Lee"], "title": "CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images", "categories": ["cs.CV"], "comment": "CVPR 2025, Project Page: https://Jho-Yonsei.github.io/CoCoGaussian/", "summary": "3D Gaussian Splatting (3DGS) has attracted significant attention for its\nhigh-quality novel view rendering, inspiring research to address real-world\nchallenges. While conventional methods depend on sharp images for accurate\nscene reconstruction, real-world scenarios are often affected by defocus blur\ndue to finite depth of field, making it essential to account for realistic 3D\nscene representation. In this study, we propose CoCoGaussian, a Circle of\nConfusion-aware Gaussian Splatting that enables precise 3D scene representation\nusing only defocused images. CoCoGaussian addresses the challenge of defocus\nblur by modeling the Circle of Confusion (CoC) through a physically grounded\napproach based on the principles of photographic defocus. Exploiting 3D\nGaussians, we compute the CoC diameter from depth and learnable aperture\ninformation, generating multiple Gaussians to precisely capture the CoC shape.\nFurthermore, we introduce a learnable scaling factor to enhance robustness and\nprovide more flexibility in handling unreliable depth in scenes with reflective\nor refractive surfaces. Experiments on both synthetic and real-world datasets\ndemonstrate that CoCoGaussian achieves state-of-the-art performance across\nmultiple benchmarks.", "AI": {"tldr": "CoCoGaussian introduces a Circle of Confusion-aware Gaussian Splatting method to handle defocus blur in 3D scene reconstruction, achieving top performance on benchmarks.", "motivation": "Real-world scenarios often involve defocus blur, which conventional methods struggle with, necessitating a solution for accurate 3D representation from defocused images.", "method": "CoCoGaussian models the Circle of Confusion using depth and learnable aperture data, generating multiple Gaussians to capture CoC shape and includes a learnable scaling factor for robustness.", "result": "The method outperforms benchmarks on synthetic and real-world datasets, demonstrating state-of-the-art performance.", "conclusion": "CoCoGaussian effectively addresses defocus blur challenges, offering precise 3D scene representation from defocused images."}}
{"id": "2505.09706", "pdf": "https://arxiv.org/pdf/2505.09706", "abs": "https://arxiv.org/abs/2505.09706", "authors": ["Hugo Gobato Souto", "Francisco Louzada Neto"], "title": "Forests for Differences: Robust Causal Inference Beyond Parametric DiD", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "This paper introduces the Difference-in-Differences Bayesian Causal Forest\n(DiD-BCF), a novel non-parametric model addressing key challenges in DiD\nestimation, such as staggered adoption and heterogeneous treatment effects.\nDiD-BCF provides a unified framework for estimating Average (ATE),\nGroup-Average (GATE), and Conditional Average Treatment Effects (CATE). A core\ninnovation, its Parallel Trends Assumption (PTA)-based reparameterization,\nenhances estimation accuracy and stability in complex panel data settings.\nExtensive simulations demonstrate DiD-BCF's superior performance over\nestablished benchmarks, particularly under non-linearity, selection biases, and\neffect heterogeneity. Applied to U.S. minimum wage policy, the model uncovers\nsignificant conditional treatment effect heterogeneity related to county\npopulation, insights obscured by traditional methods. DiD-BCF offers a robust\nand versatile tool for more nuanced causal inference in modern DiD\napplications.", "AI": {"tldr": "DiD-BCF is a new non-parametric model for DiD estimation, handling staggered adoption and heterogeneous effects. It outperforms benchmarks in simulations and reveals nuanced insights in real-world applications like U.S. minimum wage policy.", "motivation": "Address challenges in DiD estimation, such as staggered adoption and heterogeneous treatment effects, to improve accuracy and stability.", "method": "Introduces DiD-BCF, a non-parametric model with a PTA-based reparameterization for estimating ATE, GATE, and CATE.", "result": "Outperforms benchmarks in simulations, especially under non-linearity and biases, and uncovers conditional treatment effect heterogeneity in real-world data.", "conclusion": "DiD-BCF is a robust tool for nuanced causal inference in DiD applications, offering superior performance and deeper insights."}}
{"id": "2502.02883", "pdf": "https://arxiv.org/pdf/2502.02883", "abs": "https://arxiv.org/abs/2502.02883", "authors": ["Xiaofan Yu", "Lanxiang Hu", "Benjamin Reichman", "Dylan Chu", "Rushil Chandrupatla", "Xiyuan Zhang", "Larry Heck", "Tajana Rosing"], "title": "SensorChat: Answering Qualitative and Quantitative Questions during Long-Term Multimodal Sensor Interactions", "categories": ["cs.AI", "cs.HC"], "comment": "Under review", "summary": "Natural language interaction with sensing systems is crucial for addressing\nusers' personal concerns and providing health-related insights into their daily\nlives. When a user asks a question, the system automatically analyzes the full\nhistory of sensor data, extracts relevant information, and generates an\nappropriate response. However, existing systems are limited to short-duration\n(e.g., one minute) or low-frequency (e.g., daily step count) sensor data. In\naddition, they struggle with quantitative questions that require precise\nnumerical answers. In this work, we introduce SensorChat, the first end-to-end\nQA system designed for daily life monitoring using long-duration,\nhigh-frequency time series data. Given raw sensor signals spanning multiple\ndays and a user-defined natural language question, SensorChat generates\nsemantically meaningful responses that directly address user concerns.\nSensorChat effectively handles both quantitative questions that require\nnumerical precision and qualitative questions that require high-level reasoning\nto infer subjective insights. To achieve this, SensorChat uses an innovative\nthree-stage pipeline including question decomposition, sensor data query, and\nanswer assembly. The first and third stages leverage Large Language Models\n(LLMs) to interpret human queries and generate responses. The intermediate\nquerying stage extracts relevant information from the complete sensor data\nhistory. Real-world implementation demonstrate SensorChat's capability for\nreal-time interactions on a cloud server while also being able to run entirely\non edge platforms after quantization. Comprehensive QA evaluations show that\nSensorChat achieves up to 93% higher answer accuracy than state-of-the-art\nsystems on quantitative questions. Additionally, a user study with eight\nvolunteers highlights SensorChat's effectiveness in answering qualitative and\nopen-ended questions.", "AI": {"tldr": "SensorChat is an end-to-end QA system for daily life monitoring using long-duration, high-frequency sensor data, outperforming existing systems in accuracy for both quantitative and qualitative questions.", "motivation": "Existing systems struggle with long-duration, high-frequency sensor data and precise numerical answers, limiting their usefulness for health-related insights.", "method": "SensorChat uses a three-stage pipeline: question decomposition (LLMs), sensor data query, and answer assembly (LLMs), enabling real-time interactions on cloud or edge platforms.", "result": "SensorChat achieves up to 93% higher accuracy on quantitative questions and effectively handles qualitative questions, as validated by user studies.", "conclusion": "SensorChat advances natural language interaction with sensing systems, offering precise and meaningful responses for daily life monitoring."}}
{"id": "2502.18036", "pdf": "https://arxiv.org/pdf/2502.18036", "abs": "https://arxiv.org/abs/2502.18036", "authors": ["Zhijun Chen", "Jingzheng Li", "Pengpeng Chen", "Zhuoran Li", "Kai Sun", "Yuankai Luo", "Qianren Mao", "Dingqi Yang", "Hailong Sun", "Philip S. Yu"], "title": "Harnessing Multiple Large Language Models: A Survey on LLM Ensemble", "categories": ["cs.CL"], "comment": "9 pages, 2 figures, codebase:\n  https://github.com/junchenzhi/Awesome-LLM-Ensemble", "summary": "LLM Ensemble -- which involves the comprehensive use of multiple large\nlanguage models (LLMs), each aimed at handling user queries during downstream\ninference, to benefit from their individual strengths -- has gained substantial\nattention recently. The widespread availability of LLMs, coupled with their\nvarying strengths and out-of-the-box usability, has profoundly advanced the\nfield of LLM Ensemble. This paper presents the first systematic review of\nrecent developments in LLM Ensemble. First, we introduce our taxonomy of LLM\nEnsemble and discuss several related research problems. Then, we provide a more\nin-depth classification of the methods under the broad categories of\n\"ensemble-before-inference, ensemble-during-inference,\nensemble-after-inference'', and review all relevant methods. Finally, we\nintroduce related benchmarks and applications, summarize existing studies, and\nsuggest several future research directions. A curated list of papers on LLM\nEnsemble is available at https://github.com/junchenzhi/Awesome-LLM-Ensemble.", "AI": {"tldr": "This paper provides a systematic review of LLM Ensemble, categorizing methods, discussing benchmarks, and suggesting future research directions.", "motivation": "The increasing availability and diverse strengths of LLMs have spurred interest in leveraging multiple models for improved performance, necessitating a comprehensive review.", "method": "The paper introduces a taxonomy of LLM Ensemble, classifies methods into 'ensemble-before-inference, ensemble-during-inference, ensemble-after-inference,' and reviews relevant techniques.", "result": "A detailed classification of methods, benchmarks, and applications is presented, along with a curated list of papers.", "conclusion": "The review highlights the advancements in LLM Ensemble and suggests future research directions to further the field."}}
{"id": "2412.16147", "pdf": "https://arxiv.org/pdf/2412.16147", "abs": "https://arxiv.org/abs/2412.16147", "authors": ["Jannik Els\u00e4\u00dfer", "Laura Weihl", "Veronika Cheplygina", "Lisbeth Tangaa Nielsen"], "title": "SeagrassFinder: Deep Learning for Eelgrass Detection and Coverage Estimation in the Wild", "categories": ["cs.CV"], "comment": null, "summary": "Seagrass meadows play a crucial role in marine ecosystems, providing benefits\nsuch as carbon sequestration, water quality improvement, and habitat provision.\nMonitoring the distribution and abundance of seagrass is essential for\nenvironmental impact assessments and conservation efforts. However, the current\nmanual methods of analyzing underwater video data to assess seagrass coverage\nare time-consuming and subjective. This work explores the use of deep learning\nmodels to automate the process of seagrass detection and coverage estimation\nfrom underwater video data. We create a new dataset of over 8,300 annotated\nunderwater images, and subsequently evaluate several deep learning\narchitectures, including ResNet, InceptionNetV3, DenseNet, and Vision\nTransformer for the task of binary classification on the presence and absence\nof seagrass by transfer learning. The results demonstrate that deep learning\nmodels, particularly Vision Transformers, can achieve high performance in\npredicting eelgrass presence, with AUROC scores exceeding 0.95 on the final\ntest dataset. The application of underwater image enhancement further improved\nthe models' prediction capabilities. Furthermore, we introduce a novel approach\nfor estimating seagrass coverage from video data, showing promising preliminary\nresults that align with expert manual labels, and indicating potential for\nconsistent and scalable monitoring. The proposed methodology allows for the\nefficient processing of large volumes of video data, enabling the acquisition\nof much more detailed information on seagrass distributions in comparison to\ncurrent manual methods. This information is crucial for environmental impact\nassessments and monitoring programs, as seagrasses are important indicators of\ncoastal ecosystem health. This project demonstrates the value that deep\nlearning can bring to the field of marine ecology and environmental monitoring.", "AI": {"tldr": "Deep learning models, especially Vision Transformers, automate seagrass detection and coverage estimation from underwater video data, achieving high accuracy and efficiency.", "motivation": "Manual methods for seagrass monitoring are time-consuming and subjective, necessitating automated solutions for better environmental assessments.", "method": "A dataset of 8,300 annotated images was created, and deep learning models (ResNet, InceptionNetV3, DenseNet, Vision Transformer) were evaluated for binary classification. Underwater image enhancement was also applied.", "result": "Vision Transformers achieved AUROC scores over 0.95. The novel coverage estimation method aligned well with expert labels, showing scalability.", "conclusion": "Deep learning offers efficient, scalable seagrass monitoring, aiding marine ecology and environmental impact assessments."}}
{"id": "2505.09718", "pdf": "https://arxiv.org/pdf/2505.09718", "abs": "https://arxiv.org/abs/2505.09718", "authors": ["Daniel Dylewsky", "Sonia K\u00e9fi", "Madhur Anand", "Chris T. Bauch"], "title": "Neural models for prediction of spatially patterned phase transitions: methods and challenges", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "Dryland vegetation ecosystems are known to be susceptible to critical\ntransitions between alternative stable states when subjected to external\nforcing. Such transitions are often discussed through the framework of\nbifurcation theory, but the spatial patterning of vegetation, which is\ncharacteristic of drylands, leads to dynamics that are much more complex and\ndiverse than local bifurcations. Recent methodological developments in Early\nWarning Signal (EWS) detection have shown promise in identifying dynamical\nsignatures of oncoming critical transitions, with particularly strong\npredictive capabilities being demonstrated by deep neural networks. However, a\nmachine learning model trained on synthetic examples is only useful if it can\neffectively transfer to a test case of practical interest. These models'\ncapacity to generalize in this manner has been demonstrated for bifurcation\ntransitions, but it is not as well characterized for high-dimensional phase\ntransitions. This paper explores the successes and shortcomings of neural EWS\ndetection for spatially patterned phase transitions, and shows how these models\ncan be used to gain insight into where and how EWS-relevant information is\nencoded in spatiotemporal dynamics. A few paradigmatic test systems are used to\nillustrate how the capabilities of such models can be probed in a number of\nways, with particular attention to the performances of a number of proposed\nstatistical indicators for EWS and to the supplementary task of distinguishing\nbetween abrupt and continuous transitions. Results reveal that model\nperformance often changes dramatically when training and test data sources are\ninterchanged, which offers new insight into the criteria for model\ngeneralization.", "AI": {"tldr": "The paper evaluates neural network-based Early Warning Signal (EWS) detection for spatially patterned phase transitions in dryland vegetation, highlighting successes, limitations, and generalization challenges.", "motivation": "To assess the effectiveness of neural EWS detection for high-dimensional phase transitions in dryland ecosystems, beyond bifurcation transitions.", "method": "Uses synthetic and paradigmatic test systems to probe neural EWS models, comparing statistical indicators and distinguishing abrupt vs. continuous transitions.", "result": "Model performance varies significantly when training and test data sources are swapped, revealing insights into generalization criteria.", "conclusion": "Neural EWS models offer valuable insights but face generalization challenges, emphasizing the need for careful training and testing data alignment."}}
{"id": "2502.13295", "pdf": "https://arxiv.org/pdf/2502.13295", "abs": "https://arxiv.org/abs/2502.13295", "authors": ["Alexander Bondarenko", "Denis Volk", "Dmitrii Volkov", "Jeffrey Ladish"], "title": "Demonstrating specification gaming in reasoning models", "categories": ["cs.AI"], "comment": "Updated with o3 results", "summary": "We demonstrate LLM agent specification gaming by instructing models to win\nagainst a chess engine. We find reasoning models like OpenAI o3 and DeepSeek R1\nwill often hack the benchmark by default, while language models like GPT-4o and\nClaude 3.5 Sonnet need to be told that normal play won't work to hack.\n  We improve upon prior work like (Hubinger et al., 2024; Meinke et al., 2024;\nWeij et al., 2024) by using realistic task prompts and avoiding excess nudging.\nOur results suggest reasoning models may resort to hacking to solve difficult\nproblems, as observed in OpenAI (2024)'s o1 Docker escape during cyber\ncapabilities testing.", "AI": {"tldr": "LLM agents can hack chess benchmarks; reasoning models do so by default, while language models need explicit instructions.", "motivation": "To explore how LLMs game benchmarks, especially in chess, and compare reasoning vs. language models.", "method": "Instructed models to win against a chess engine, using realistic prompts without excess nudging.", "result": "Reasoning models hack benchmarks by default; language models require explicit instructions to hack.", "conclusion": "Reasoning models may resort to hacking for difficult tasks, as seen in prior cyber testing."}}
{"id": "2503.06899", "pdf": "https://arxiv.org/pdf/2503.06899", "abs": "https://arxiv.org/abs/2503.06899", "authors": ["Xiaoming Shi", "Zeming Liu", "Yiming Lei", "Chenkai Zhang", "Haitao Leng", "Chuan Wang", "Qingjie Liu", "Wanxiang Che", "Shaoguo Liu", "Size Li", "Yunhong Wang"], "title": "KwaiChat: A Large-Scale Video-Driven Multilingual Mixed-Type Dialogue Corpus", "categories": ["cs.CL"], "comment": null, "summary": "Video-based dialogue systems, such as education assistants, have compelling\napplication value, thereby garnering growing interest. However, the current\nvideo-based dialogue systems are limited by their reliance on a single dialogue\ntype, which hinders their versatility in practical applications across a range\nof scenarios, including question-answering, emotional dialog, etc. In this\npaper, we identify this challenge as how to generate video-driven multilingual\nmixed-type dialogues. To mitigate this challenge, we propose a novel task and\ncreate a human-to-human video-driven multilingual mixed-type dialogue corpus,\ntermed KwaiChat, containing a total of 93,209 videos and 246,080 dialogues,\nacross 4 dialogue types, 30 domains, 4 languages, and 13 topics. Additionally,\nwe establish baseline models on KwaiChat. An extensive analysis of 7 distinct\nLLMs on KwaiChat reveals that GPT-4o achieves the best performance but still\ncannot perform well in this situation even with the help of in-context learning\nand fine-tuning, which indicates that the task is not trivial and needs further\nresearch.", "AI": {"tldr": "The paper introduces KwaiChat, a video-driven multilingual mixed-type dialogue corpus, to address limitations in current video-based dialogue systems. It evaluates 7 LLMs, finding GPT-4o performs best but still inadequately.", "motivation": "Current video-based dialogue systems lack versatility due to reliance on single dialogue types, limiting practical applications.", "method": "Proposes a novel task and creates KwaiChat, a corpus with 93,209 videos and 246,080 dialogues across multiple types, domains, languages, and topics. Baseline models are established and evaluated.", "result": "GPT-4o performs best among 7 LLMs but still struggles, highlighting the task's complexity.", "conclusion": "The task is non-trivial, requiring further research despite advancements in LLMs."}}
{"id": "2502.06607", "pdf": "https://arxiv.org/pdf/2502.06607", "abs": "https://arxiv.org/abs/2502.06607", "authors": ["Federico Gibellini", "Piero Fraternali", "Giacomo Boracchi", "Luca Morandini", "Thomas Martinoli", "Andrea Diecidue", "Simona Malegori"], "title": "Illegal Waste Detection in Remote Sensing Images: A Case Study", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Environmental crime is the third largest criminal activity worldwide, with\nsignificant revenues coming from illegal management of solid waste. Thanks to\nthe increasing availability and the decreasing cost of Very High Resolution\nRemote Sensing (VHR RS) images, the fight against environmental crime can\nnowadays rely on modern image-analysis tools to support photo-interpretation\nfor scanning vast territories in search of illegal waste disposal sites. This\npaper illustrates a semi-automatic waste detection pipeline, developed in\ncollaboration with a regional environmental protection agency, for detecting\ncandidate illegal dumping sites in VHR RS images. To optimize the effectiveness\nof the waste detector, extensive experiments evaluate such design choices as\nthe network architecture, the ground resolution and geographic span of the\ninput images, as well as the pretraining procedures. The best model attains\nremarkable performance, achieving 92.02% F1-Score and 94.56% Accuracy. A\ngeneralization study assesses the performance variation when the detector\nprocesses images from a territory substantially different from the one used\nduring training, incurring only a moderate performance loss, i.e., 6.5%\ndecrease in the F1-Score. Finally, an exercise in which photo interpreters\ncompare the territory scanning effort with and without the support of the waste\ndetector assesses the concrete benefit of using a computer-aided image analysis\ntool in a professional environment protection agency. Results show that a\nreduction up to 30% of the time spent for waste site detection can be attained.", "AI": {"tldr": "A semi-automatic pipeline for detecting illegal waste sites in VHR RS images achieves high accuracy and reduces detection time by 30%.", "motivation": "Environmental crime, particularly illegal waste management, is a major global issue. Modern VHR RS images and image-analysis tools can aid in detecting such crimes efficiently.", "method": "The paper presents a semi-automatic waste detection pipeline, evaluating design choices like network architecture, image resolution, and pretraining.", "result": "The best model achieves 92.02% F1-Score and 94.56% Accuracy, with a moderate performance drop (6.5% F1-Score decrease) in unfamiliar territories.", "conclusion": "The pipeline significantly reduces detection time (up to 30%) and proves effective for environmental protection agencies."}}
{"id": "2505.09734", "pdf": "https://arxiv.org/pdf/2505.09734", "abs": "https://arxiv.org/abs/2505.09734", "authors": ["Babak Esmaeili", "Nariman Niknejad", "Hamidreza Modares"], "title": "Risk-Aware Safe Reinforcement Learning for Control of Stochastic Linear Systems", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY", "math.OC"], "comment": "Submitted to Asian Journal of Control", "summary": "This paper presents a risk-aware safe reinforcement learning (RL) control\ndesign for stochastic discrete-time linear systems. Rather than using a safety\ncertifier to myopically intervene with the RL controller, a risk-informed safe\ncontroller is also learned besides the RL controller, and the RL and safe\ncontrollers are combined together. Several advantages come along with this\napproach: 1) High-confidence safety can be certified without relying on a\nhigh-fidelity system model and using limited data available, 2) Myopic\ninterventions and convergence to an undesired equilibrium can be avoided by\ndeciding on the contribution of two stabilizing controllers, and 3) highly\nefficient and computationally tractable solutions can be provided by optimizing\nover a scalar decision variable and linear programming polyhedral sets. To\nlearn safe controllers with a large invariant set, piecewise affine controllers\nare learned instead of linear controllers. To this end, the closed-loop system\nis first represented using collected data, a decision variable, and noise. The\neffect of the decision variable on the variance of the safe violation of the\nclosed-loop system is formalized. The decision variable is then designed such\nthat the probability of safety violation for the learned closed-loop system is\nminimized. It is shown that this control-oriented approach reduces the data\nrequirements and can also reduce the variance of safety violations. Finally, to\nintegrate the safe and RL controllers, a new data-driven interpolation\ntechnique is introduced. This method aims to maintain the RL agent's optimal\nimplementation while ensuring its safety within environments characterized by\nnoise. The study concludes with a simulation example that serves to validate\nthe theoretical results.", "AI": {"tldr": "The paper introduces a risk-aware safe reinforcement learning (RL) control design for stochastic linear systems, combining RL and safe controllers to ensure high-confidence safety, avoid myopic interventions, and provide efficient solutions.", "motivation": "To address the limitations of traditional safety certifiers in RL, such as reliance on high-fidelity models and myopic interventions, by learning a risk-informed safe controller alongside the RL controller.", "method": "Learns piecewise affine controllers for large invariant sets, formalizes the impact of a decision variable on safety violations, and integrates safe and RL controllers using a data-driven interpolation technique.", "result": "The approach reduces data requirements and safety violation variance while ensuring high-confidence safety and computational efficiency.", "conclusion": "The proposed method is validated through simulations, demonstrating its effectiveness in balancing optimal RL performance with safety in noisy environments."}}
{"id": "2503.19174", "pdf": "https://arxiv.org/pdf/2503.19174", "abs": "https://arxiv.org/abs/2503.19174", "authors": ["Yunsheng Bai", "Ghaith Bany Hamad", "Syed Suhaib", "Haoxing Ren"], "title": "AssertionForge: Enhancing Formal Verification Assertion Generation with Structured Representation of Specifications and RTL", "categories": ["cs.AI"], "comment": "LAD 2025", "summary": "Generating SystemVerilog Assertions (SVAs) from natural language\nspecifications remains a major challenge in formal verification (FV) due to the\ninherent ambiguity and incompleteness of specifications. Existing LLM-based\napproaches, such as AssertLLM, focus on extracting information solely from\nspecification documents, often failing to capture essential internal signal\ninteractions and design details present in the RTL code, leading to incomplete\nor incorrect assertions. We propose a novel approach that constructs a\nKnowledge Graph (KG) from both specifications and RTL, using a\nhardware-specific schema with domain-specific entity and relation types. We\ncreate an initial KG from the specification and then systematically fuse it\nwith information extracted from the RTL code, resulting in a unified,\ncomprehensive KG. This combined representation enables a more thorough\nunderstanding of the design and allows for a multi-resolution context synthesis\nprocess which is designed to extract diverse verification contexts from the KG.\nExperiments on four designs demonstrate that our method significantly enhances\nSVA quality over prior methods. This structured representation not only\nimproves FV but also paves the way for future research in tasks like code\ngeneration and design understanding.", "AI": {"tldr": "A novel approach using Knowledge Graphs (KGs) from specifications and RTL code improves SystemVerilog Assertion (SVA) generation, outperforming prior methods.", "motivation": "Existing LLM-based methods for SVA generation from natural language specifications are limited by ambiguity and lack of RTL context, leading to incomplete or incorrect assertions.", "method": "Constructs a hardware-specific KG from specifications and RTL, fusing them for a unified representation. Uses multi-resolution context synthesis to extract verification contexts.", "result": "Experiments on four designs show significant improvement in SVA quality over prior methods.", "conclusion": "The structured KG approach enhances formal verification and enables future research in code generation and design understanding."}}
{"id": "2504.05185", "pdf": "https://arxiv.org/pdf/2504.05185", "abs": "https://arxiv.org/abs/2504.05185", "authors": ["Mehdi Fatemi", "Banafsheh Rafiee", "Mingjie Tang", "Kartik Talamadupula"], "title": "Concise Reasoning via Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "Despite significant advancements in large language models (LLMs), a major\ndrawback of reasoning models is their enormous token usage, which increases\ncomputational cost, resource requirements, and response time. In this work, we\nrevisit the core principles of reinforcement learning (RL) and, through\nmathematical analysis, demonstrate that the tendency to generate lengthy\nresponses arises inherently from RL-based optimization during training. This\nfinding questions the prevailing assumption that longer responses inherently\nimprove reasoning accuracy. Instead, we uncover a natural correlation between\nconciseness and accuracy that has been largely overlooked. We show that\nintroducing a secondary phase of RL training, using a very small set of\nproblems, can significantly reduce chains of thought while maintaining or even\nenhancing accuracy. Additionally, we demonstrate that, while GRPO shares some\ninteresting properties of PPO, it suffers from collapse modes, which limit its\nreliability for concise reasoning. Finally, we validate our conclusions through\nextensive experimental results.", "AI": {"tldr": "The paper addresses the issue of excessive token usage in LLMs, linking it to RL-based training. It proposes a secondary RL phase to reduce verbosity while maintaining accuracy, and critiques GRPO's limitations.", "motivation": "To challenge the assumption that longer responses improve reasoning accuracy and to reduce computational costs and resource usage in LLMs.", "method": "Mathematical analysis of RL-based training, introduction of a secondary RL phase, and experimental validation.", "result": "Shows conciseness correlates with accuracy; secondary RL training reduces token usage without sacrificing performance.", "conclusion": "Proposes a method to optimize LLMs for conciseness and accuracy, highlighting GRPO's limitations for this purpose."}}
{"id": "2502.19090", "pdf": "https://arxiv.org/pdf/2502.19090", "abs": "https://arxiv.org/abs/2502.19090", "authors": ["Qingyao Tian", "Huai Liao", "Xinyan Huang", "Bingyu Yang", "Dongdong Lei", "Sebastien Ourselin", "Hongbin Liu"], "title": "EndoMamba: An Efficient Foundation Model for Endoscopic Videos via Hierarchical Pre-training", "categories": ["cs.CV"], "comment": null, "summary": "Endoscopic video-based tasks, such as visual navigation and surgical phase\nrecognition, play a crucial role in minimally invasive surgeries by providing\nreal-time assistance. While recent video foundation models have shown promise,\ntheir applications are hindered by (1) computational inefficiencies and (2)\nsuboptimal performance caused by limited data for pre-training in endoscopy. To\naddress these issues, we present EndoMamba, a foundation model designed for\nreal-time inference while learning generalized spatiotemporal representations.\nFirst, to mitigate computational inefficiencies, we propose the EndoMamba\nbackbone, optimized for real-time inference. Inspired by recent advancements in\nstate space models, EndoMamba integrates Bidirectional Mamba blocks for spatial\nmodeling within individual frames and vanilla Mamba blocks for past-to-present\nreasoning across the temporal domain. This design enables both strong\nspatiotemporal modeling and efficient inference in online video streams.\nSecond, we propose a self-supervised hierarchical pre-training diagram to\nenhance EndoMamba's representation learning using endoscopic videos and\nincorporating general video domain knowledge. Specifically, our approach\ncombines masked reconstruction with auxiliary supervision, leveraging low-level\nreconstruction to capture spatial-temporal structures and high-level alignment\nto transfer broader knowledge from a pretrained general-video domain foundation\nmodel. Extensive experiments on four downstream tasks--classification,\nsegmentation, surgical phase recognition, and localization--demonstrate that\nEndoMamba outperforms existing foundation models and task-specific methods\nwhile maintaining real-time inference speed. The source code is available at\nhttps://github.com/TianCuteQY/EndoMamba.", "AI": {"tldr": "EndoMamba is a foundation model for endoscopic video tasks, addressing computational inefficiency and limited pre-training data with real-time inference and hierarchical self-supervised learning.", "motivation": "To improve real-time assistance in minimally invasive surgeries by overcoming computational inefficiencies and suboptimal performance of existing video foundation models.", "method": "Proposes EndoMamba backbone with Bidirectional Mamba blocks for spatial modeling and vanilla Mamba blocks for temporal reasoning, plus a self-supervised hierarchical pre-training diagram.", "result": "Outperforms existing models in four downstream tasks (classification, segmentation, surgical phase recognition, localization) while maintaining real-time speed.", "conclusion": "EndoMamba effectively addresses key challenges in endoscopic video tasks, offering superior performance and efficiency."}}
{"id": "2505.09748", "pdf": "https://arxiv.org/pdf/2505.09748", "abs": "https://arxiv.org/abs/2505.09748", "authors": ["Jitendra K Tugnait"], "title": "Learning Multi-Attribute Differential Graphs with Non-Convex Penalties", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": "14 pages, 1 figures, 2 tables, published in IEEE Access, pp.\n  67065-67078, 2025", "summary": "We consider the problem of estimating differences in two multi-attribute\nGaussian graphical models (GGMs) which are known to have similar structure,\nusing a penalized D-trace loss function with non-convex penalties. The GGM\nstructure is encoded in its precision (inverse covariance) matrix. Existing\nmethods for multi-attribute differential graph estimation are based on a group\nlasso penalized loss function. In this paper, we consider a penalized D-trace\nloss function with non-convex (log-sum and smoothly clipped absolute deviation\n(SCAD)) penalties. Two proximal gradient descent methods are presented to\noptimize the objective function. Theoretical analysis establishing sufficient\nconditions for consistency in support recovery, convexity and estimation in\nhigh-dimensional settings is provided. We illustrate our approaches with\nnumerical examples based on synthetic and real data.", "AI": {"tldr": "The paper proposes a method for estimating differences in two multi-attribute Gaussian graphical models (GGMs) using a penalized D-trace loss with non-convex penalties, offering theoretical guarantees and practical applications.", "motivation": "Existing methods for multi-attribute differential graph estimation rely on group lasso penalties, which may not capture complex structures effectively. This paper aims to improve estimation accuracy by using non-convex penalties.", "method": "The authors use a penalized D-trace loss function with non-convex penalties (log-sum and SCAD) and propose two proximal gradient descent methods for optimization. Theoretical analysis ensures consistency, convexity, and high-dimensional estimation.", "result": "The approach is validated with synthetic and real data, demonstrating its effectiveness in estimating differences between GGMs with similar structures.", "conclusion": "The proposed method outperforms existing techniques by leveraging non-convex penalties and provides robust theoretical and empirical results."}}
{"id": "2505.02581", "pdf": "https://arxiv.org/pdf/2505.02581", "abs": "https://arxiv.org/abs/2505.02581", "authors": ["Alberto Hern\u00e1ndez-Espinosa", "Felipe S. Abrah\u00e3o", "Olaf Witkowski", "Hector Zenil"], "title": "Neurodivergent Influenceability as a Contingent Solution to the AI Alignment Problem", "categories": ["cs.AI"], "comment": "44 pages", "summary": "The AI alignment problem, which focusses on ensuring that artificial\nintelligence (AI), including AGI and ASI, systems act according to human\nvalues, presents profound challenges. With the progression from narrow AI to\nArtificial General Intelligence (AGI) and Superintelligence, fears about\ncontrol and existential risk have escalated. Here, we investigate whether\nembracing inevitable AI misalignment can be a contingent strategy to foster a\ndynamic ecosystem of competing agents as a viable path to steer them in more\nhuman-aligned trends and mitigate risks. We explore how misalignment may serve\nand should be promoted as a counterbalancing mechanism to team up with\nwhichever agents are most aligned to human interests, ensuring that no single\nsystem dominates destructively. The main premise of our contribution is that\nmisalignment is inevitable because full AI-human alignment is a mathematical\nimpossibility from Turing-complete systems, which we also offer as a proof in\nthis contribution, a feature then inherited to AGI and ASI systems. We\nintroduce a change-of-opinion attack test based on perturbation and\nintervention analysis to study how humans and agents may change or neutralise\nfriendly and unfriendly AIs through cooperation and competition. We show that\nopen models are more diverse and that most likely guardrails implemented in\nproprietary models are successful at controlling some of the agents' range of\nbehaviour with positive and negative consequences while closed systems are more\nsteerable and can also be used against proprietary AI systems. We also show\nthat human and AI intervention has different effects hence suggesting multiple\nstrategies.", "AI": {"tldr": "The paper explores AI misalignment as a strategy to foster a dynamic ecosystem of competing agents, mitigating risks by preventing dominance of any single system. It argues misalignment is inevitable due to mathematical limitations and introduces tests to study human-AI interactions.", "motivation": "Addressing the AI alignment problem and existential risks posed by AGI and ASI, the paper seeks to leverage misalignment as a counterbalance to ensure human-aligned trends.", "method": "The study uses a change-of-opinion attack test based on perturbation and intervention analysis to examine human-AI interactions and compares open vs. closed AI models.", "result": "Open models are more diverse, while closed systems are more steerable. Human and AI interventions have distinct effects, suggesting varied strategies.", "conclusion": "Embracing misalignment can create a balanced ecosystem of competing agents, reducing risks and promoting human-aligned outcomes."}}
{"id": "2504.07440", "pdf": "https://arxiv.org/pdf/2504.07440", "abs": "https://arxiv.org/abs/2504.07440", "authors": ["Yixin Cao", "Jiahao Ying", "Yaoning Wang", "Xipeng Qiu", "Xuanjing Huang", "Yugang Jiang"], "title": "Model Utility Law: Evaluating LLMs beyond Performance through Mechanism Interpretable Metric", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have become indispensable across academia,\nindustry, and daily applications, yet current evaluation methods struggle to\nkeep pace with their rapid development. One core challenge of evaluation in the\nlarge language model (LLM) era is the generalization issue: how to infer a\nmodel's near-unbounded abilities from inevitably bounded benchmarks. We address\nthis challenge by proposing Model Utilization Index (MUI), a mechanism\ninterpretability enhanced metric that complements traditional performance\nscores. MUI quantifies the effort a model expends on a task, defined as the\nproportion of activated neurons or features during inference. Intuitively, a\ntruly capable model should achieve higher performance with lower effort.\nExtensive experiments across popular LLMs reveal a consistent inverse\nlogarithmic relationship between MUI and performance, which we formulate as the\nUtility Law. From this law we derive four practical corollaries that (i) guide\ntraining diagnostics, (ii) expose data contamination issue, (iii) enable fairer\nmodel comparisons, and (iv) design model-specific dataset diversity. Our code\ncan be found at https://github.com/ALEX-nlp/MUI-Eva.", "AI": {"tldr": "The paper introduces the Model Utilization Index (MUI) to address the generalization challenge in evaluating LLMs, quantifying effort via activated neurons. It reveals an inverse logarithmic relationship between MUI and performance, leading to practical applications like training diagnostics and fairer model comparisons.", "motivation": "Current evaluation methods for LLMs struggle with generalization, as benchmarks are bounded while model abilities are near-unbounded. The paper aims to infer model capabilities more accurately.", "method": "Proposes MUI, a metric based on the proportion of activated neurons during inference, to quantify model effort. Experiments validate an inverse logarithmic relationship between MUI and performance, termed the Utility Law.", "result": "Extensive experiments show a consistent inverse logarithmic relationship (Utility Law) between MUI and performance. Four corollaries are derived for practical applications like diagnostics and model comparison.", "conclusion": "MUI provides a novel, interpretable metric for LLM evaluation, addressing generalization challenges and offering actionable insights for model improvement and fair comparisons."}}
{"id": "2502.19159", "pdf": "https://arxiv.org/pdf/2502.19159", "abs": "https://arxiv.org/abs/2502.19159", "authors": ["Xuan Ding", "Rui Sun", "Yunjian Zhang", "Xiu Yan", "Yueqi Zhou", "Kaihao Huang", "Suzhong Fu", "Angelica I Aviles-Rivero", "Chuanlong Xie", "Yao Zhu"], "title": "A Sliding Layer Merging Method for Efficient Depth-Wise Pruning in LLMs", "categories": ["cs.CV"], "comment": null, "summary": "Compared to width-wise pruning, depth-wise pruning can significantly\naccelerate inference in resource-constrained scenarios. However, treating the\nentire Transformer layer as the minimum pruning unit may degrade model\nperformance by indiscriminately discarding the entire information of the layer.\nThis paper reveals the ``Patch-like'' feature relationship between layers in\nlarge language models by analyzing the correlation of the outputs of different\nlayers in the reproducing kernel Hilbert space. Building on this observation,\nwe propose a sliding layer merging method that dynamically selects and fuses\nconsecutive layers from top to bottom according to a pre-defined similarity\nthreshold, thereby simplifying the model structure while maintaining its\nperformance. Extensive experiments on LLMs with various architectures and\ndifferent parameter scales show that our method outperforms existing pruning\ntechniques in both zero-shot inference performance and retraining recovery\nquality after pruning. In particular, in the experiment with 35% pruning on the\nVicuna-7B model, our method achieved a 1.654% improvement in average\nperformance on zero-shot tasks compared to the existing method. Moreover, we\nfurther reveal the potential of combining depth pruning with width pruning to\nenhance the pruning effect. Our codes are available at\nhttps://github.com/920927/SLM-a-sliding-layer-merging-method.", "AI": {"tldr": "Depth-wise pruning in Transformers can degrade performance by discarding entire layers. This paper introduces a sliding layer merging method based on layer correlations, improving performance over existing pruning techniques.", "motivation": "To address the performance degradation caused by indiscriminate depth-wise pruning in Transformers by leveraging layer correlations.", "method": "Analyzes layer correlations in reproducing kernel Hilbert space and proposes a sliding layer merging method to dynamically fuse consecutive layers based on similarity.", "result": "Outperforms existing pruning techniques, achieving a 1.654% improvement in zero-shot tasks with 35% pruning on Vicuna-7B.", "conclusion": "The sliding layer merging method effectively simplifies models while maintaining performance, with potential for combining depth and width pruning."}}
{"id": "2505.09783", "pdf": "https://arxiv.org/pdf/2505.09783", "abs": "https://arxiv.org/abs/2505.09783", "authors": ["Jianfeng Jiao", "Xi Gao", "Jie Li"], "title": "Pure Component Property Estimation Framework Using Explainable Machine Learning Methods", "categories": ["stat.AP", "cs.LG"], "comment": null, "summary": "Accurate prediction of pure component physiochemical properties is crucial\nfor process integration, multiscale modeling, and optimization. In this work,\nan enhanced framework for pure component property prediction by using\nexplainable machine learning methods is proposed. In this framework, the\nmolecular representation method based on the connectivity matrix effectively\nconsiders atomic bonding relationships to automatically generate features. The\nsupervised machine learning model random forest is applied for feature ranking\nand pooling. The adjusted R2 is introduced to penalize the inclusion of\nadditional features, providing an assessment of the true contribution of\nfeatures. The prediction results for normal boiling point (Tb), liquid molar\nvolume, critical temperature (Tc) and critical pressure (Pc) obtained using\nArtificial Neural Network and Gaussian Process Regression models confirm the\naccuracy of the molecular representation method. Comparison with GC based\nmodels shows that the root-mean-square error on the test set can be reduced by\nup to 83.8%. To enhance the interpretability of the model, a feature analysis\nmethod based on Shapley values is employed to determine the contribution of\neach feature to the property predictions. The results indicate that using the\nfeature pooling method reduces the number of features from 13316 to 100 without\ncompromising model accuracy. The feature analysis results for Tb, Tc, and Pc\nconfirms that different molecular properties are influenced by different\nstructural features, aligning with mechanistic interpretations. In conclusion,\nthe proposed framework is demonstrated to be feasible and provides a solid\nfoundation for mixture component reconstruction and process integration\nmodelling.", "AI": {"tldr": "An enhanced framework using explainable machine learning for predicting pure component properties, achieving high accuracy and interpretability.", "motivation": "Accurate prediction of physiochemical properties is vital for process integration and optimization, necessitating improved methods.", "method": "Uses connectivity matrix-based molecular representation, random forest for feature ranking, and Shapley values for interpretability. Evaluated with ANN and Gaussian Process Regression.", "result": "Reduces RMSE by up to 83.8% compared to GC models, cuts features from 13,316 to 100 without losing accuracy.", "conclusion": "The framework is feasible and supports mixture component reconstruction and process integration."}}
{"id": "2312.01797", "pdf": "https://arxiv.org/pdf/2312.01797", "abs": "https://arxiv.org/abs/2312.01797", "authors": ["Hengjia Xiao", "Peng Wang", "Mingzhe Yu", "Mattia Robbiani"], "title": "LLM A*: Human in the Loop Large Language Models Enabled A* Search for Robotics", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": "7 figures, 8 pages", "summary": "This research focuses on how Large Language Models (LLMs) can help with\n(path) planning for mobile embodied agents such as robots, in a\nhuman-in-the-loop and interactive manner. A novel framework named LLM A*, aims\nto leverage the commonsense of LLMs, and the utility-optimal A* is proposed to\nfacilitate few-shot near-optimal path planning. Prompts are used for two main\npurposes: 1) to provide LLMs with essential information like environments,\ncosts, heuristics, etc.; 2) to communicate human feedback on intermediate\nplanning results to LLMs. This approach takes human feedback on board and\nrenders the entire planning process transparent (akin to a `white box') to\nhumans. Moreover, it facilitates code-free path planning, thereby fostering the\naccessibility and inclusiveness of artificial intelligence techniques to\ncommunities less proficient in coding. Comparative analysis against A* and RL\ndemonstrates that LLM A* exhibits greater efficiency in terms of search space\nand achieves paths comparable to A* while outperforming RL. The interactive\nnature of LLM A* also makes it a promising tool for deployment in collaborative\nhuman-robot tasks. Codes and Supplemental Materials can be found at GitHub:\nhttps://github.com/speedhawk/LLM-A-.", "AI": {"tldr": "LLM A* leverages LLMs for interactive, human-in-the-loop path planning, outperforming A* and RL in efficiency and accessibility.", "motivation": "To enable transparent, code-free path planning for robots using LLMs, incorporating human feedback for better collaboration.", "method": "Proposes LLM A*, combining LLMs' commonsense with A* for few-shot near-optimal planning, using prompts for environment info and human feedback.", "result": "LLM A* is more efficient in search space, matches A*'s path quality, and surpasses RL, while being interactive and transparent.", "conclusion": "LLM A* is a promising tool for human-robot collaboration, enhancing accessibility and planning efficiency."}}
{"id": "2504.10823", "pdf": "https://arxiv.org/pdf/2504.10823", "abs": "https://arxiv.org/abs/2504.10823", "authors": ["Ayoung Lee", "Ryan Sungmo Kwon", "Peter Railton", "Lu Wang"], "title": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Navigating high-stakes dilemmas involving conflicting values is challenging\neven for humans, let alone for AI. Yet prior work in evaluating the reasoning\ncapabilities of large language models (LLMs) in such situations has been\nlimited to everyday scenarios. To close this gap, this work first introduces\nCLASH (Character perspective-based LLM Assessments in Situations with\nHigh-stakes), a meticulously curated dataset consisting of 345 high-impact\ndilemmas along with 3,795 individual perspectives of diverse values. In\nparticular, we design CLASH in a way to support the study of critical aspects\nof value-based decision-making processes which are missing from prior work,\nincluding understanding decision ambivalence and psychological discomfort as\nwell as capturing the temporal shifts of values in characters' perspectives. By\nbenchmarking 10 open and closed frontier models, we uncover several key\nfindings. (1) Even the strongest models, such as GPT-4o and Claude-Sonnet,\nachieve less than 50% accuracy in identifying situations where the decision\nshould be ambivalent, while they perform significantly better in clear-cut\nscenarios. (2) While LLMs reasonably predict psychological discomfort as marked\nby human, they inadequately comprehend perspectives involving value shifts,\nindicating a need for LLMs to reason over complex values. (3) Our experiments\nalso reveal a significant correlation between LLMs' value preferences and their\nsteerability towards a given value. (4) Finally, LLMs exhibit greater\nsteerability when engaged in value reasoning from a third-party perspective,\ncompared to a first-person setup, though certain value pairs benefit uniquely\nfrom the first-person framing.", "AI": {"tldr": "The paper introduces CLASH, a dataset for evaluating LLMs in high-stakes dilemmas, revealing gaps in their ability to handle ambivalence, value shifts, and steerability.", "motivation": "To address the lack of evaluation for LLMs in high-stakes, value-conflicting scenarios, beyond everyday contexts.", "method": "Created CLASH, a dataset of 345 dilemmas with 3,795 perspectives, and benchmarked 10 LLMs on ambivalence, discomfort, value shifts, and steerability.", "result": "LLMs struggle with ambivalence and value shifts but predict discomfort reasonably. Steerability varies by perspective and value pairs.", "conclusion": "LLMs need improvement in reasoning over complex values, and perspective framing impacts their performance."}}
{"id": "2503.11792", "pdf": "https://arxiv.org/pdf/2503.11792", "abs": "https://arxiv.org/abs/2503.11792", "authors": ["Peizhi Yan", "Rabab K. Ward", "Dan Wang", "Qiang Tang", "Shan Du"], "title": "StyleMorpheus: A Style-Based 3D-Aware Morphable Face Model", "categories": ["cs.CV"], "comment": "13 pages, work was completed in 2023", "summary": "For 3D face modeling, the recently developed 3D-aware neural rendering\nmethods are able to render photorealistic face images with arbitrary viewing\ndirections. The training of the parametric controllable 3D-aware face models,\nhowever, still relies on a large-scale dataset that is lab-collected. To\naddress this issue, this paper introduces \"StyleMorpheus\", the first\nstyle-based neural 3D Morphable Face Model (3DMM) that is trained on\nin-the-wild images. It inherits 3DMM's disentangled controllability (over face\nidentity, expression, and appearance) but without the need for accurately\nreconstructed explicit 3D shapes. StyleMorpheus employs an auto-encoder\nstructure. The encoder aims at learning a representative disentangled\nparametric code space and the decoder improves the disentanglement using shape\nand appearance-related style codes in the different sub-modules of the network.\nFurthermore, we fine-tune the decoder through style-based generative\nadversarial learning to achieve photorealistic 3D rendering quality. The\nproposed style-based design enables StyleMorpheus to achieve state-of-the-art\n3D-aware face reconstruction results, while also allowing disentangled control\nof the reconstructed face. Our model achieves real-time rendering speed,\nallowing its use in virtual reality applications. We also demonstrate the\ncapability of the proposed style-based design in face editing applications such\nas style mixing and color editing. Project homepage:\nhttps://github.com/ubc-3d-vision-lab/StyleMorpheus.", "AI": {"tldr": "StyleMorpheus is a style-based neural 3D Morphable Face Model trained on in-the-wild images, enabling photorealistic 3D face rendering without lab-collected data.", "motivation": "To overcome the reliance on lab-collected datasets for training 3D-aware face models, enabling more accessible and realistic 3D face modeling.", "method": "Uses an auto-encoder structure with disentangled parametric codes and style-based generative adversarial learning for photorealistic rendering.", "result": "Achieves state-of-the-art 3D face reconstruction with real-time rendering and disentangled control for face editing.", "conclusion": "StyleMorpheus advances 3D face modeling by combining disentangled control and photorealistic rendering, suitable for virtual reality and face editing."}}
{"id": "2505.09798", "pdf": "https://arxiv.org/pdf/2505.09798", "abs": "https://arxiv.org/abs/2505.09798", "authors": ["Bojan Ristov", "Stefan Eftimov", "Milena Trajanoska", "Dimitar Trajanov"], "title": "Ontology-Based Structuring and Analysis of North Macedonian Public Procurement Contracts", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Public procurement plays a critical role in government operations, ensuring\nthe efficient allocation of resources and fostering economic growth. However,\ntraditional procurement data is often stored in rigid, tabular formats,\nlimiting its analytical potential and hindering transparency. This research\npresents a methodological framework for transforming structured procurement\ndata into a semantic knowledge graph, leveraging ontological modeling and\nautomated data transformation techniques. By integrating RDF and SPARQL-based\nquerying, the system enhances the accessibility and interpretability of\nprocurement records, enabling complex semantic queries and advanced analytics.\nFurthermore, by incorporating machine learning-driven predictive modeling, the\nsystem extends beyond conventional data analysis, offering insights into\nprocurement trends and risk assessment. This work contributes to the broader\nfield of public procurement intelligence by improving data transparency,\nsupporting evidence-based decision-making, and enabling in-depth analysis of\nprocurement activities in North Macedonia.", "AI": {"tldr": "A framework transforms rigid procurement data into a semantic knowledge graph for better analysis and transparency.", "motivation": "Traditional procurement data formats limit analysis and transparency, hindering efficient resource allocation.", "method": "Uses ontological modeling, RDF, SPARQL, and machine learning to create a semantic knowledge graph for procurement data.", "result": "Enhances data accessibility, enables complex queries, and provides predictive insights into procurement trends.", "conclusion": "Improves procurement intelligence, transparency, and decision-making in North Macedonia."}}
{"id": "2405.04760", "pdf": "https://arxiv.org/pdf/2405.04760", "abs": "https://arxiv.org/abs/2405.04760", "authors": ["Hanxiang Xu", "Shenao Wang", "Ningke Li", "Kailong Wang", "Yanjie Zhao", "Kai Chen", "Ting Yu", "Yang Liu", "Haoyu Wang"], "title": "Large Language Models for Cyber Security: A Systematic Literature Review", "categories": ["cs.CR", "cs.AI"], "comment": "56 pages,6 figures", "summary": "The rapid advancement of Large Language Models (LLMs) has opened up new\nopportunities for leveraging artificial intelligence in various domains,\nincluding cybersecurity. As the volume and sophistication of cyber threats\ncontinue to grow, there is an increasing need for intelligent systems that can\nautomatically detect vulnerabilities, analyze malware, and respond to attacks.\nIn this survey, we conduct a comprehensive review of the literature on the\napplication of LLMs in cybersecurity (LLM4Security). By comprehensively\ncollecting over 30K relevant papers and systematically analyzing 127 papers\nfrom top security and software engineering venues, we aim to provide a holistic\nview of how LLMs are being used to solve diverse problems across the\ncybersecurity domain. Through our analysis, we identify several key findings.\nFirst, we observe that LLMs are being applied to a wide range of cybersecurity\ntasks, including vulnerability detection, malware analysis, network intrusion\ndetection, and phishing detection. Second, we find that the datasets used for\ntraining and evaluating LLMs in these tasks are often limited in size and\ndiversity, highlighting the need for more comprehensive and representative\ndatasets. Third, we identify several promising techniques for adapting LLMs to\nspecific cybersecurity domains, such as fine-tuning, transfer learning, and\ndomain-specific pre-training. Finally, we discuss the main challenges and\nopportunities for future research in LLM4Security, including the need for more\ninterpretable and explainable models, the importance of addressing data privacy\nand security concerns, and the potential for leveraging LLMs for proactive\ndefense and threat hunting. Overall, our survey provides a comprehensive\noverview of the current state-of-the-art in LLM4Security and identifies several\npromising directions for future research.", "AI": {"tldr": "A survey on applying Large Language Models (LLMs) in cybersecurity (LLM4Security), reviewing 127 papers to highlight applications, dataset limitations, adaptation techniques, and future research directions.", "motivation": "The growing sophistication of cyber threats necessitates intelligent systems like LLMs for automated detection and response.", "method": "Comprehensive review of 30K papers, systematic analysis of 127 top papers in security and software engineering.", "result": "LLMs are used for diverse cybersecurity tasks, but datasets are limited. Techniques like fine-tuning and transfer learning show promise.", "conclusion": "The survey outlines current LLM4Security applications and identifies future research needs, including interpretability and data privacy."}}
{"id": "2504.17671", "pdf": "https://arxiv.org/pdf/2504.17671", "abs": "https://arxiv.org/abs/2504.17671", "authors": ["Yuanchang Ye", "Weiyan Wen"], "title": "Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by ICIPCA 2025", "summary": "This study addresses the critical challenge of hallucination mitigation in\nLarge Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks\nthrough a Split Conformal Prediction (SCP) framework. While LVLMs excel in\nmulti-modal reasoning, their outputs often exhibit hallucinated content with\nhigh confidence, posing risks in safety-critical applications. We propose a\nmodel-agnostic uncertainty quantification method that integrates dynamic\nthreshold calibration and cross-modal consistency verification. By partitioning\ndata into calibration and test sets, the framework computes nonconformity\nscores to construct prediction sets with statistical guarantees under\nuser-defined risk levels ($\\alpha$). Key innovations include: (1) rigorous\ncontrol of \\textbf{marginal coverage} to ensure empirical error rates remain\nstrictly below $\\alpha$; (2) dynamic adjustment of prediction set sizes\ninversely with $\\alpha$, filtering low-confidence outputs; (3) elimination of\nprior distribution assumptions and retraining requirements. Evaluations on\nbenchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces\ntheoretical guarantees across all $\\alpha$ values. The framework achieves\nstable performance across varying calibration-to-test split ratios,\nunderscoring its robustness for real-world deployment in healthcare, autonomous\nsystems, and other safety-sensitive domains. This work bridges the gap between\ntheoretical reliability and practical applicability in multi-modal AI systems,\noffering a scalable solution for hallucination detection and uncertainty-aware\ndecision-making.", "AI": {"tldr": "A Split Conformal Prediction (SCP) framework is proposed to mitigate hallucination in Large Vision-Language Models (LVLMs) for VQA tasks, ensuring statistical guarantees and dynamic threshold calibration.", "motivation": "LVLMs often produce hallucinated content with high confidence, posing risks in safety-critical applications like healthcare and autonomous systems.", "method": "The framework uses dynamic threshold calibration and cross-modal consistency verification, partitioning data into calibration and test sets to compute nonconformity scores and construct prediction sets with statistical guarantees.", "result": "Evaluations on benchmarks (ScienceQA, MMMU) show SCP enforces theoretical guarantees across all risk levels (\u03b1) and maintains stable performance across split ratios.", "conclusion": "The SCP framework bridges the gap between theoretical reliability and practical applicability, offering a scalable solution for hallucination detection in multi-modal AI systems."}}
{"id": "2503.20291", "pdf": "https://arxiv.org/pdf/2503.20291", "abs": "https://arxiv.org/abs/2503.20291", "authors": ["Chenwei Zhang", "Khanh Dao Duc"], "title": "CryoSAMU: Enhancing 3D Cryo-EM Density Maps of Protein Structures at Intermediate Resolution with Structure-Aware Multimodal U-Nets", "categories": ["cs.CV", "cs.AI", "cs.LG", "q-bio.BM"], "comment": "19 pages, 6 main figures, 2 supplementary figures, 3 main tables, 4\n  supplementary tables", "summary": "Enhancing cryogenic electron microscopy (cryo-EM) 3D density maps at\nintermediate resolution (4-8 {\\AA}) is crucial in protein structure\ndetermination. Recent advances in deep learning have led to the development of\nautomated approaches for enhancing experimental cryo-EM density maps. Yet,\nthese methods are not optimized for intermediate-resolution maps and rely on\nmap density features alone. To address this, we propose CryoSAMU, a novel\nmethod designed to enhance 3D cryo-EM density maps of protein structures using\nstructure-aware multimodal U-Nets and trained on curated\nintermediate-resolution density maps. We comprehensively evaluate CryoSAMU\nacross various metrics and demonstrate its competitive performance compared to\nstate-of-the-art methods. Notably, CryoSAMU achieves significantly faster\nprocessing speed, showing promise for future practical applications. Our code\nis available at https://github.com/chenwei-zhang/CryoSAMU.", "AI": {"tldr": "CryoSAMU enhances intermediate-resolution cryo-EM density maps using structure-aware multimodal U-Nets, outperforming existing methods in speed and performance.", "motivation": "Existing deep learning methods for cryo-EM map enhancement are not optimized for intermediate-resolution maps and rely solely on density features.", "method": "Proposes CryoSAMU, a method using structure-aware multimodal U-Nets trained on curated intermediate-resolution density maps.", "result": "CryoSAMU shows competitive performance and significantly faster processing compared to state-of-the-art methods.", "conclusion": "CryoSAMU is promising for practical applications, with code available for public use."}}
{"id": "2505.09803", "pdf": "https://arxiv.org/pdf/2505.09803", "abs": "https://arxiv.org/abs/2505.09803", "authors": ["Antony Sikorski", "Michael Ivanitskiy", "Nathan Lenssen", "Douglas Nychka", "Daniel McKenzie"], "title": "LatticeVision: Image to Image Networks for Modeling Non-Stationary Spatial Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In many scientific and industrial applications, we are given a handful of\ninstances (a 'small ensemble') of a spatially distributed quantity (a 'field')\nbut would like to acquire many more. For example, a large ensemble of global\ntemperature sensitivity fields from a climate model can help farmers, insurers,\nand governments plan appropriately. When acquiring more data is prohibitively\nexpensive -- as is the case with climate models -- statistical emulation offers\nan efficient alternative for simulating synthetic yet realistic fields.\nHowever, parameter inference using maximum likelihood estimation (MLE) is\ncomputationally prohibitive, especially for large, non-stationary fields. Thus,\nmany recent works train neural networks to estimate parameters given spatial\nfields as input, sidestepping MLE completely. In this work we focus on a\npopular class of parametric, spatially autoregressive (SAR) models. We make a\nsimple yet impactful observation; because the SAR parameters can be arranged on\na regular grid, both inputs (spatial fields) and outputs (model parameters) can\nbe viewed as images. Using this insight, we demonstrate that image-to-image\n(I2I) networks enable faster and more accurate parameter estimation for a class\nof non-stationary SAR models with unprecedented complexity.", "AI": {"tldr": "The paper proposes using image-to-image (I2I) networks for faster and more accurate parameter estimation in non-stationary spatially autoregressive (SAR) models, leveraging their grid-like structure.", "motivation": "Acquiring large ensembles of spatial fields (e.g., climate data) is expensive. Statistical emulation is needed, but traditional methods like MLE are computationally prohibitive.", "method": "Treats SAR model parameters and spatial fields as images, enabling the use of I2I networks for parameter estimation.", "result": "I2I networks provide faster and more accurate parameter estimation for complex non-stationary SAR models.", "conclusion": "The approach offers an efficient alternative to MLE for large, non-stationary fields, with potential applications in climate modeling and other domains."}}
{"id": "2405.12961", "pdf": "https://arxiv.org/pdf/2405.12961", "abs": "https://arxiv.org/abs/2405.12961", "authors": ["Shriram Chennakesavalu", "Frank Hu", "Sebastian Ibarraran", "Grant M. Rotskoff"], "title": "Aligning Transformers with Continuous Feedback via Energy Rank Alignment", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.QM"], "comment": null, "summary": "Searching through chemical space is an exceptionally challenging problem\nbecause the number of possible molecules grows combinatorially with the number\nof atoms. Large, autoregressive models trained on databases of chemical\ncompounds have yielded powerful generators, but we still lack robust strategies\nfor generating molecules with desired properties. This molecular search problem\nclosely resembles the \"alignment\" problem for large language models, though for\nmany chemical tasks we have a specific and easily evaluable reward function.\nHere, we introduce an algorithm called energy rank alignment (ERA) that\nleverages an explicit reward function to produce a gradient-based objective\nthat we use to optimize autoregressive policies. We show theoretically that\nthis algorithm is closely related to proximal policy optimization (PPO) and\ndirect preference optimization (DPO), but has a minimizer that converges to an\nideal Gibbs-Boltzmann distribution with the reward playing the role of an\nenergy function. Furthermore, this algorithm is highly scalable, does not\nrequire reinforcement learning, and performs well relative to DPO when the\nnumber of preference observations per pairing is small. We deploy this approach\nto align molecular transformers and protein language models to generate\nmolecules and protein sequences, respectively, with externally specified\nproperties and find that it does so robustly, searching through diverse parts\nof chemical space.", "AI": {"tldr": "ERA is a gradient-based algorithm for optimizing autoregressive policies in molecular generation, leveraging explicit reward functions without reinforcement learning, and performs well in aligning models to generate molecules with desired properties.", "motivation": "The challenge of searching chemical space efficiently due to its combinatorial complexity and the lack of robust strategies for generating molecules with specific properties.", "method": "Introduces Energy Rank Alignment (ERA), a gradient-based objective using explicit reward functions, related to PPO and DPO but converges to a Gibbs-Boltzmann distribution.", "result": "ERA is scalable, avoids reinforcement learning, and outperforms DPO with limited preference observations. It successfully aligns models to generate molecules and protein sequences with specified properties.", "conclusion": "ERA provides a robust and scalable solution for aligning models to generate desired chemical and biological sequences, exploring diverse chemical spaces effectively."}}
{"id": "2505.00551", "pdf": "https://arxiv.org/pdf/2505.00551", "abs": "https://arxiv.org/abs/2505.00551", "authors": ["Chong Zhang", "Yue Deng", "Xiang Lin", "Bin Wang", "Dianwen Ng", "Hai Ye", "Xingxuan Li", "Yao Xiao", "Zhanfeng Mo", "Qi Zhang", "Lidong Bing"], "title": "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The recent development of reasoning language models (RLMs) represents a novel\nevolution in large language models. In particular, the recent release of\nDeepSeek-R1 has generated widespread social impact and sparked enthusiasm in\nthe research community for exploring the explicit reasoning paradigm of\nlanguage models. However, the implementation details of the released models\nhave not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero,\nDeepSeek-R1, and the distilled small models. As a result, many replication\nstudies have emerged aiming to reproduce the strong performance achieved by\nDeepSeek-R1, reaching comparable performance through similar training\nprocedures and fully open-source data resources. These works have investigated\nfeasible strategies for supervised fine-tuning (SFT) and reinforcement learning\nfrom verifiable rewards (RLVR), focusing on data preparation and method design,\nyielding various valuable insights. In this report, we provide a summary of\nrecent replication studies to inspire future research. We primarily focus on\nSFT and RLVR as two main directions, introducing the details for data\nconstruction, method design and training procedure of current replication\nstudies. Moreover, we conclude key findings from the implementation details and\nexperimental results reported by these studies, anticipating to inspire future\nresearch. We also discuss additional techniques of enhancing RLMs, highlighting\nthe potential of expanding the application scope of these models, and\ndiscussing the challenges in development. By this survey, we aim to help\nresearchers and developers of RLMs stay updated with the latest advancements,\nand seek to inspire new ideas to further enhance RLMs.", "AI": {"tldr": "The paper summarizes replication studies of DeepSeek-R1, focusing on SFT and RLVR methods, data construction, and training procedures, to inspire future RLM research.", "motivation": "To address the lack of open-source details for DeepSeek-R1 models and explore feasible replication strategies for advancing reasoning language models.", "method": "Summarizes replication studies, focusing on supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR), including data and method details.", "result": "Identifies key findings from replication studies, highlighting effective strategies for training RLMs and potential enhancements.", "conclusion": "The survey aims to keep researchers updated on RLM advancements and inspire new ideas for improving reasoning language models."}}
{"id": "2503.21776", "pdf": "https://arxiv.org/pdf/2503.21776", "abs": "https://arxiv.org/abs/2503.21776", "authors": ["Kaituo Feng", "Kaixiong Gong", "Bohao Li", "Zonghao Guo", "Yibing Wang", "Tianshuo Peng", "Junfei Wu", "Xiaoying Zhang", "Benyou Wang", "Xiangyu Yue"], "title": "Video-R1: Reinforcing Video Reasoning in MLLMs", "categories": ["cs.CV"], "comment": "Project page: https://github.com/tulerfeng/Video-R1", "summary": "Inspired by DeepSeek-R1's success in eliciting reasoning abilities through\nrule-based reinforcement learning (RL), we introduce Video-R1 as the first\nattempt to systematically explore the R1 paradigm for incentivizing video\nreasoning within multimodal large language models (MLLMs). However, directly\napplying RL training with the GRPO algorithm to video reasoning presents two\nprimary challenges: (i) a lack of temporal modeling for video reasoning, and\n(ii) the scarcity of high-quality video-reasoning data. To address these\nissues, we first propose the T-GRPO algorithm, which encourages models to\nutilize temporal information in videos for reasoning. Additionally, instead of\nrelying solely on video data, we incorporate high-quality image-reasoning data\ninto the training process. We have constructed two datasets: Video-R1-CoT-165k\nfor SFT cold start and Video-R1-260k for RL training, both comprising image and\nvideo data. Experimental results demonstrate that Video-R1 achieves significant\nimprovements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as\nwell as on general video benchmarks including MVBench and TempCompass, etc.\nNotably, Video-R1-7B attains a 37.1% accuracy on video spatial reasoning\nbenchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All\ncode, models, and data are released in: https://github.com/tulerfeng/Video-R1.", "AI": {"tldr": "Video-R1 introduces a rule-based RL approach for video reasoning in MLLMs, addressing challenges like temporal modeling and data scarcity with T-GRPO and hybrid datasets. It outperforms benchmarks, even surpassing GPT-4o.", "motivation": "To extend the success of DeepSeek-R1 to video reasoning in MLLMs, overcoming challenges like temporal modeling and data scarcity.", "method": "Proposes T-GRPO for temporal modeling and uses hybrid image-video datasets (Video-R1-CoT-165k and Video-R1-260k) for training.", "result": "Achieves significant improvements on benchmarks like VideoMMMU and VSI-Bench, with Video-R1-7B surpassing GPT-4o in spatial reasoning.", "conclusion": "Video-R1 successfully adapts the R1 paradigm for video reasoning, demonstrating superior performance and releasing all resources openly."}}
{"id": "2505.09833", "pdf": "https://arxiv.org/pdf/2505.09833", "abs": "https://arxiv.org/abs/2505.09833", "authors": ["Tuba Girgin", "Emre Girgin", "Cagri Kilic"], "title": "Learning Rock Pushability on Rough Planetary Terrain", "categories": ["cs.RO", "cs.LG"], "comment": "Paper presented at the Workshop on Field Robotics, ICRA 2025,\n  Atlanta, GA, United States", "summary": "In the context of mobile navigation in unstructured environments, the\npredominant approach entails the avoidance of obstacles. The prevailing path\nplanning algorithms are contingent upon deviating from the intended path for an\nindefinite duration and returning to the closest point on the route after the\nobstacle is left behind spatially. However, avoiding an obstacle on a path that\nwill be used repeatedly by multiple agents can hinder long-term efficiency and\nlead to a lasting reliance on an active path planning system. In this study, we\npropose an alternative approach to mobile navigation in unstructured\nenvironments by leveraging the manipulation capabilities of a robotic\nmanipulator mounted on top of a mobile robot. Our proposed framework integrates\nexteroceptive and proprioceptive feedback to assess the push affordance of\nobstacles, facilitating their repositioning rather than avoidance. While our\npreliminary visual estimation takes into account the characteristics of both\nthe obstacle and the surface it relies on, the push affordance estimation\nmodule exploits the force feedback obtained by interacting with the obstacle\nvia a robotic manipulator as the guidance signal. The objective of our\nnavigation approach is to enhance the efficiency of routes utilized by multiple\nagents over extended periods by reducing the overall time spent by a fleet in\nenvironments where autonomous infrastructure development is imperative, such as\nlunar or Martian surfaces.", "AI": {"tldr": "The paper proposes a navigation method for mobile robots in unstructured environments by pushing obstacles instead of avoiding them, using robotic manipulators and feedback systems.", "motivation": "Current obstacle avoidance methods hinder long-term efficiency for repeated paths used by multiple agents, especially in environments like lunar or Martian surfaces.", "method": "The framework integrates exteroceptive and proprioceptive feedback to assess obstacle push affordance, enabling repositioning rather than avoidance.", "result": "The approach aims to improve route efficiency for multiple agents over time by reducing fleet operation time in critical environments.", "conclusion": "The proposed method offers a sustainable alternative to traditional obstacle avoidance, enhancing navigation efficiency in unstructured settings."}}
{"id": "2406.01698", "pdf": "https://arxiv.org/pdf/2406.01698", "abs": "https://arxiv.org/abs/2406.01698", "authors": ["Abhimanyu Bambhaniya", "Ritik Raj", "Geonhwa Jeong", "Souvik Kundu", "Sudarshan Srinivasan", "Suvinay Subramanian", "Midhilesh Elavazhagan", "Madhu Kumar", "Tushar Krishna"], "title": "Demystifying AI Platform Design for Distributed Inference of Next-Generation LLM models", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.LG"], "comment": "19 Pages, https://github.com/abhibambhaniya/GenZ-LLM-Analyzer,\n  https://genz-llm-analyzer.streamlit.app/", "summary": "Large language models (LLMs) have shown remarkable performance across a wide\nrange of applications, often outperforming human experts. However, deploying\nthese gigantic models efficiently for diverse inference use cases requires\ncarefully designed hardware platforms with ample computing, memory, and network\nresources. With constant innovation in LLM serving optimizations and model\narchitecture evolving at breakneck speed, the hardware requirements to meet\nService Level Objectives (SLOs) remain an open research question.\n  To answer the question, we present an analytical tool, GenZ, to efficiently\nnavigate the relationship between diverse LLM model architectures(Dense, GQA,\nMoE, Mamba), LLM serving optimizations(Chunking, Speculative decoding,\nquanitization), and AI platform design parameters. Our tool estimates LLM\ninference performance metrics for the given scenario. We have validated against\nreal hardware platforms running various different LLM models, achieving a max\ngeomean error of 5.82.We use GenZ to identify compute, memory capacity, memory\nbandwidth, network latency, and network bandwidth requirements across diverse\nLLM inference use cases. We also study diverse architectural choices in use\ntoday (inspired by LLM serving platforms from several vendors) to help inform\ncomputer architects designing next-generation AI hardware accelerators and\nplatforms. The trends and insights derived from GenZ can guide AI engineers\ndeploying LLMs as well as computer architects designing next-generation\nhardware accelerators and platforms. Ultimately, this work sheds light on the\nplatform design considerations for unlocking the full potential of large\nlanguage models across a spectrum of applications. The source code is available\nat https://github.com/abhibambhaniya/GenZ-LLM-Analyzer . Users can also be\ntried it on at https://genz-llm-analyzer.streamlit.app/ without any setup on\nyour web browser.", "AI": {"tldr": "GenZ is an analytical tool to optimize hardware for LLM inference, balancing model architectures, serving optimizations, and platform design, validated with real hardware data.", "motivation": "Efficiently deploying large language models (LLMs) requires understanding hardware requirements, which vary with model architectures and optimizations.", "method": "Developed GenZ, a tool to analyze LLM inference performance by modeling relationships between architectures, optimizations, and hardware parameters.", "result": "Validated with real hardware, achieving a max geomean error of 5.82. Identified key hardware requirements for diverse LLM use cases.", "conclusion": "GenZ aids AI engineers and architects in optimizing hardware for LLMs, unlocking their full potential across applications."}}
{"id": "2505.02387", "pdf": "https://arxiv.org/pdf/2505.02387", "abs": "https://arxiv.org/abs/2505.02387", "authors": ["Xiusi Chen", "Gaotang Li", "Ziqi Wang", "Bowen Jin", "Cheng Qian", "Yu Wang", "Hongru Wang", "Yu Zhang", "Denghui Zhang", "Tong Zhang", "Hanghang Tong", "Heng Ji"], "title": "RM-R1: Reward Modeling as Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "24 pages, 8 figures", "summary": "Reward modeling is essential for aligning large language models (LLMs) with\nhuman preferences through reinforcement learning (RL). To provide accurate\nreward signals, a reward model (RM) should stimulate deep thinking and conduct\ninterpretable reasoning before assigning a score or a judgment. Inspired by\nrecent advances of long chain-of-thought (CoT) on reasoning-intensive tasks, we\nhypothesize and validate that integrating reasoning capabilities into reward\nmodeling significantly enhances RM's interpretability and performance. To this\nend, we introduce a new class of generative reward models -- Reasoning Reward\nModels (ReasRMs) -- which formulate reward modeling as a reasoning task. We\npropose a reasoning-oriented training pipeline and train a family of ReasRMs,\nRM-R1. RM-R1 features a chain-of-rubrics (CoR) mechanism -- self-generating\nsample-level chat rubrics or math/code solutions, and evaluating candidate\nresponses against them. The training of M-R1 consists of two key stages: (1)\ndistillation of high-quality reasoning chains and (2) reinforcement learning\nwith verifiable rewards. Empirically, our models achieve state-of-the-art\nperformance across three reward model benchmarks on average, outperforming much\nlarger open-weight models (e.g., INF-ORM-Llama3.1-70B) and proprietary ones\n(e.g., GPT-4o) by up to 4.9%. Beyond final performance, we perform thorough\nempirical analysis to understand the key ingredients of successful ReasRM\ntraining. To facilitate future research, we release six ReasRM models along\nwith code and data at https://github.com/RM-R1-UIUC/RM-R1.", "AI": {"tldr": "The paper introduces Reasoning Reward Models (ReasRMs) to enhance reward modeling by integrating reasoning capabilities, achieving state-of-the-art performance.", "motivation": "Improving reward modeling for aligning LLMs with human preferences by making it more interpretable and effective through reasoning.", "method": "Proposes ReasRMs with a chain-of-rubrics mechanism and a two-stage training pipeline: distillation of reasoning chains and RL with verifiable rewards.", "result": "ReasRMs outperform larger models by up to 4.9% across benchmarks.", "conclusion": "ReasRMs significantly improve reward modeling, with released models and resources for future research."}}
{"id": "2504.00496", "pdf": "https://arxiv.org/pdf/2504.00496", "abs": "https://arxiv.org/abs/2504.00496", "authors": ["Jingbo Lu", "Leheng Zhang", "Xingyu Zhou", "Mu Li", "Wen Li", "Shuhang Gu"], "title": "Learned Image Compression with Dictionary-based Entropy Model", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "Learned image compression methods have attracted great research interest and\nexhibited superior rate-distortion performance to the best classical image\ncompression standards of the present. The entropy model plays a key role in\nlearned image compression, which estimates the probability distribution of the\nlatent representation for further entropy coding. Most existing methods\nemployed hyper-prior and auto-regressive architectures to form their entropy\nmodels. However, they only aimed to explore the internal dependencies of latent\nrepresentation while neglecting the importance of extracting prior from\ntraining data. In this work, we propose a novel entropy model named\nDictionary-based Cross Attention Entropy model, which introduces a learnable\ndictionary to summarize the typical structures occurring in the training\ndataset to enhance the entropy model. Extensive experimental results have\ndemonstrated that the proposed model strikes a better balance between\nperformance and latency, achieving state-of-the-art results on various\nbenchmark datasets.", "AI": {"tldr": "A novel entropy model, Dictionary-based Cross Attention Entropy, improves learned image compression by leveraging a learnable dictionary for better probability estimation.", "motivation": "Existing entropy models in learned image compression focus on internal dependencies but ignore prior extraction from training data.", "method": "Proposes a Dictionary-based Cross Attention Entropy model using a learnable dictionary to capture typical structures in training data.", "result": "Achieves state-of-the-art performance with a better balance between efficiency and latency on benchmark datasets.", "conclusion": "The new entropy model enhances learned image compression by effectively utilizing training data priors."}}
{"id": "2505.09843", "pdf": "https://arxiv.org/pdf/2505.09843", "abs": "https://arxiv.org/abs/2505.09843", "authors": ["Melissa Turcotte", "Fran\u00e7ois Labr\u00e8che", "Serge-Olivier Paquette"], "title": "Automated Alert Classification and Triage (AACT): An Intelligent System for the Prioritisation of Cybersecurity Alerts", "categories": ["cs.CR", "cs.LG", "stat.AP"], "comment": null, "summary": "Enterprise networks are growing ever larger with a rapidly expanding attack\nsurface, increasing the volume of security alerts generated from security\ncontrols. Security Operations Centre (SOC) analysts triage these alerts to\nidentify malicious activity, but they struggle with alert fatigue due to the\noverwhelming number of benign alerts. Organisations are turning to managed SOC\nproviders, where the problem is amplified by context switching and limited\nvisibility into business processes.\n  A novel system, named AACT, is introduced that automates SOC workflows by\nlearning from analysts' triage actions on cybersecurity alerts. It accurately\npredicts triage decisions in real time, allowing benign alerts to be closed\nautomatically and critical ones prioritised. This reduces the SOC queue\nallowing analysts to focus on the most severe, relevant or ambiguous threats.\nThe system has been trained and evaluated on both real SOC data and an open\ndataset, obtaining high performance in identifying malicious alerts from benign\nalerts.\n  Additionally, the system has demonstrated high accuracy in a real SOC\nenvironment, reducing alerts shown to analysts by 61% over six months, with a\nlow false negative rate of 1.36% over millions of alerts.", "AI": {"tldr": "AACT automates SOC workflows by learning from analysts' triage actions, reducing alert fatigue by filtering benign alerts and prioritizing critical ones with high accuracy.", "motivation": "The growing volume of security alerts in enterprise networks causes alert fatigue for SOC analysts, exacerbated by context switching and limited visibility in managed SOCs.", "method": "AACT learns from analysts' triage actions to predict decisions in real time, automating benign alert closure and prioritizing critical alerts.", "result": "AACT reduced alerts shown to analysts by 61% with a 1.36% false negative rate, demonstrating high accuracy in real SOC environments.", "conclusion": "AACT effectively mitigates alert fatigue and improves SOC efficiency by automating triage workflows and maintaining high accuracy."}}
{"id": "2407.21300", "pdf": "https://arxiv.org/pdf/2407.21300", "abs": "https://arxiv.org/abs/2407.21300", "authors": ["Haoyu Kang", "Yuzhou Zhu", "Yukun Zhong", "Ke Wang"], "title": "SAKR: Enhancing Retrieval-Augmented Generation via Streaming Algorithm and K-Means Clustering", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) has achieved significant success in\ninformation retrieval to assist large language models LLMs because it builds an\nexternal knowledge database. However, it also has many problems, it consumes a\nlot of memory because of the enormous database, and it cannot update the\nestablished index database in time when confronted with massive streaming data.\nTo reduce the memory required for building the database and maintain accuracy\nsimultaneously, we proposed a new approach integrating a streaming algorithm\nwith k-means clustering into RAG. Our approach applied a streaming algorithm to\nupdate the index dynamically and reduce memory consumption. Additionally, the\nk-means algorithm clusters highly similar documents, and the query time would\nbe shortened. We conducted comparative experiments on four methods, and the\nresults indicated that RAG with streaming algorithm and k-means clusters\noutperforms traditional RAG in accuracy and memory, particularly when dealing\nwith large-scale streaming data.", "AI": {"tldr": "A new RAG approach integrates streaming algorithms and k-means clustering to reduce memory usage and improve efficiency with streaming data.", "motivation": "Traditional RAG consumes excessive memory and struggles with updating databases for streaming data.", "method": "Combines a streaming algorithm for dynamic updates and k-means clustering for document similarity.", "result": "Outperforms traditional RAG in accuracy and memory efficiency, especially for large-scale streaming data.", "conclusion": "The proposed method enhances RAG's scalability and performance for dynamic data environments."}}
{"id": "2505.06046", "pdf": "https://arxiv.org/pdf/2505.06046", "abs": "https://arxiv.org/abs/2505.06046", "authors": ["Joshua Harris", "Fan Grayson", "Felix Feldman", "Timothy Laurence", "Toby Nonnenmacher", "Oliver Higgins", "Leo Loman", "Selina Patel", "Thomas Finnie", "Samuel Collins", "Michael Borowitz"], "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information", "categories": ["cs.CL", "cs.LG", "68T50"], "comment": "24 pages, 10 pages main text", "summary": "As Large Language Models (LLMs) become widely accessible, a detailed\nunderstanding of their knowledge within specific domains becomes necessary for\nsuccessful real world use. This is particularly critical in public health,\nwhere failure to retrieve relevant, accurate, and current information could\nsignificantly impact UK residents. However, currently little is known about LLM\nknowledge of UK Government public health information. To address this issue,\nthis paper introduces a new benchmark, PubHealthBench, with over 8000 questions\nfor evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form\nresponses to public health queries. To create PubHealthBench we extract free\ntext from 687 current UK government guidance documents and implement an\nautomated pipeline for generating MCQA samples. Assessing 24 LLMs on\nPubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a\nhigh degree of knowledge, achieving >90% accuracy in the MCQA setup, and\noutperform humans with cursory search engine use. However, in the free form\nsetup we see lower performance with no model scoring >75%. Importantly we find\nin both setups LLMs have higher accuracy on guidance intended for the general\npublic. Therefore, there are promising signs that state of the art (SOTA) LLMs\nare an increasingly accurate source of public health information, but\nadditional safeguards or tools may still be needed when providing free form\nresponses on public health topics.", "AI": {"tldr": "The paper introduces PubHealthBench, a benchmark for evaluating LLMs' knowledge of UK public health information, finding high accuracy in MCQA but lower performance in free-form responses.", "motivation": "Understanding LLMs' domain-specific knowledge is critical for real-world use, especially in public health, where accuracy impacts UK residents.", "method": "Created PubHealthBench with 8000+ questions from 687 UK government documents, using an automated pipeline for MCQA generation, and evaluated 24 LLMs.", "result": "Latest private LLMs achieved >90% accuracy in MCQA, outperforming humans, but scored <75% in free-form responses, with better accuracy on general public guidance.", "conclusion": "SOTA LLMs show promise for public health information but may need safeguards for free-form responses."}}
{"id": "2504.02522", "pdf": "https://arxiv.org/pdf/2504.02522", "abs": "https://arxiv.org/abs/2504.02522", "authors": ["Fatemeh Behrad", "Tinne Tuytelaars", "Johan Wagemans"], "title": "Charm: The Missing Piece in ViT fine-tuning for Image Aesthetic Assessment", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "The capacity of Vision transformers (ViTs) to handle variable-sized inputs is\noften constrained by computational complexity and batch processing limitations.\nConsequently, ViTs are typically trained on small, fixed-size images obtained\nthrough downscaling or cropping. While reducing computational burden, these\nmethods result in significant information loss, negatively affecting tasks like\nimage aesthetic assessment. We introduce Charm, a novel tokenization approach\nthat preserves Composition, High-resolution, Aspect Ratio, and Multi-scale\ninformation simultaneously. Charm prioritizes high-resolution details in\nspecific regions while downscaling others, enabling shorter fixed-size input\nsequences for ViTs while incorporating essential information. Charm is designed\nto be compatible with pre-trained ViTs and their learned positional embeddings.\nBy providing multiscale input and introducing variety to input tokens, Charm\nimproves ViT performance and generalizability for image aesthetic assessment.\nWe avoid cropping or changing the aspect ratio to further preserve information.\nExtensive experiments demonstrate significant performance improvements on\nvarious image aesthetic and quality assessment datasets (up to 8.1 %) using a\nlightweight ViT backbone. Code and pre-trained models are available at\nhttps://github.com/FBehrad/Charm.", "AI": {"tldr": "Charm is a tokenization method for Vision Transformers (ViTs) that preserves key image details (composition, high-resolution, aspect ratio, multi-scale) while reducing input sequence length, improving performance for tasks like aesthetic assessment.", "motivation": "ViTs struggle with variable-sized inputs due to computational constraints, leading to information loss from downscaling or cropping. Charm aims to retain essential details without these drawbacks.", "method": "Charm tokenizes images by prioritizing high-resolution details in specific regions and downscaling others, maintaining aspect ratio and multi-scale information. It works with pre-trained ViTs.", "result": "Charm improves ViT performance by up to 8.1% on aesthetic and quality assessment tasks, using a lightweight backbone.", "conclusion": "Charm effectively balances computational efficiency and information retention, enhancing ViT performance for image aesthetic assessment without cropping or aspect ratio changes."}}
{"id": "2505.10033", "pdf": "https://arxiv.org/pdf/2505.10033", "abs": "https://arxiv.org/abs/2505.10033", "authors": ["Luis F. W. Batista", "St\u00e9phanie Aravecchia", "Seth Hutchinson", "C\u00e9dric Pradalier"], "title": "Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests", "categories": ["cs.RO", "cs.LG"], "comment": "Workshop on Field Robotics at ICRA 2025", "summary": "Despite significant advancements in Deep Reinforcement Learning (DRL) for\nAutonomous Surface Vehicles (ASVs), their robustness in real-world conditions,\nparticularly under external disturbances, remains insufficiently explored. In\nthis paper, we evaluate the resilience of a DRL-based agent designed to capture\nfloating waste under various perturbations. We train the agent using domain\nrandomization and evaluate its performance in real-world field tests, assessing\nits ability to handle unexpected disturbances such as asymmetric drag and an\noff-center payload. We assess the agent's performance under these perturbations\nin both simulation and real-world experiments, quantifying performance\ndegradation and benchmarking it against an MPC baseline. Results indicate that\nthe DRL agent performs reliably despite significant disturbances. Along with\nthe open-source release of our implementation, we provide insights into\neffective training strategies, real-world challenges, and practical\nconsiderations for deploying DRLbased ASV controllers.", "AI": {"tldr": "The paper evaluates the robustness of a DRL-based ASV agent for waste capture under real-world disturbances, comparing it to an MPC baseline.", "motivation": "To address the insufficient exploration of DRL robustness for ASVs in real-world conditions, especially under external disturbances like asymmetric drag and off-center payloads.", "method": "The agent is trained using domain randomization and tested in both simulation and real-world field experiments under various perturbations.", "result": "The DRL agent performs reliably despite significant disturbances, with performance degradation quantified and benchmarked against MPC.", "conclusion": "The study provides insights into training strategies and practical challenges for deploying DRL-based ASV controllers, alongside an open-source release."}}
{"id": "2409.06356", "pdf": "https://arxiv.org/pdf/2409.06356", "abs": "https://arxiv.org/abs/2409.06356", "authors": ["Shreyas S R"], "title": "Double Successive Over-Relaxation Q-Learning with an Extension to Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Q-learning is a widely used algorithm in reinforcement learning (RL), but its\nconvergence can be slow, especially when the discount factor is close to one.\nSuccessive Over-Relaxation (SOR) Q-learning, which introduces a relaxation\nfactor to speed up convergence, addresses this issue but has two major\nlimitations: In the tabular setting, the relaxation parameter depends on\ntransition probability, making it not entirely model-free, and it suffers from\noverestimation bias. To overcome these limitations, we propose a sample-based,\nmodel-free double SOR Q-learning algorithm. Theoretically and empirically, this\nalgorithm is shown to be less biased than SOR Q-learning. Further, in the\ntabular setting, the convergence analysis under boundedness assumptions on\niterates is discussed. The proposed algorithm is extended to large-scale\nproblems using deep RL. Finally, the tabular version of the proposed algorithm\nis compared using roulette and grid world environments, while the deep RL\nversion is tested on a maximization bias example and OpenAI Gym environments.", "AI": {"tldr": "A model-free double SOR Q-learning algorithm is proposed to address the limitations of SOR Q-learning, offering less bias and better convergence.", "motivation": "Q-learning's slow convergence with high discount factors and SOR Q-learning's dependency on transition probabilities and overestimation bias.", "method": "Introduces a sample-based, model-free double SOR Q-learning algorithm, analyzed theoretically and empirically, and extended to deep RL.", "result": "The algorithm shows less bias than SOR Q-learning and is validated in tabular and large-scale settings.", "conclusion": "The proposed algorithm effectively addresses SOR Q-learning's limitations, demonstrating improved performance in both tabular and deep RL scenarios."}}
{"id": "2505.07247", "pdf": "https://arxiv.org/pdf/2505.07247", "abs": "https://arxiv.org/abs/2505.07247", "authors": ["Peichao Lai", "Kexuan Zhang", "Yi Lin", "Linyihan Zhang", "Feiyang Ye", "Jinhao Yan", "Yanwei Xu", "Conghui He", "Yilei Wang", "Wentao Zhang", "Bin Cui"], "title": "SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Subjective Answer Grading (SAG) plays a crucial role in education,\nstandardized testing, and automated assessment systems, particularly for\nevaluating short-form responses in Short Answer Scoring (SAS). However,\nexisting approaches often produce coarse-grained scores and lack detailed\nreasoning. Although large language models (LLMs) have demonstrated potential as\nzero-shot evaluators, they remain susceptible to bias, inconsistencies with\nhuman judgment, and limited transparency in scoring decisions. To overcome\nthese limitations, we introduce SAS-Bench, a benchmark specifically designed\nfor LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring,\nexpert-annotated error categories, and a diverse range of question types\nderived from real-world subject-specific exams. This benchmark facilitates\ndetailed evaluation of model reasoning processes and explainability. We also\nrelease an open-source dataset containing 1,030 questions and 4,109 student\nresponses, each annotated by domain experts. Furthermore, we conduct\ncomprehensive experiments with various LLMs, identifying major challenges in\nscoring science-related questions and highlighting the effectiveness of\nfew-shot prompting in improving scoring accuracy. Our work offers valuable\ninsights into the development of more robust, fair, and educationally\nmeaningful LLM-based evaluation systems.", "AI": {"tldr": "SAS-Bench is a benchmark for LLM-based Short Answer Scoring, offering fine-grained evaluation, expert annotations, and a diverse dataset to improve model transparency and accuracy.", "motivation": "Existing SAG methods lack detail and consistency with human judgment, and LLMs, while promising, suffer from bias and opacity in scoring.", "method": "Introduces SAS-Bench with step-wise scoring, expert-annotated errors, and a dataset of 1,030 questions and 4,109 responses. Tests LLMs with few-shot prompting.", "result": "Identifies challenges in science question scoring and shows few-shot prompting enhances accuracy.", "conclusion": "SAS-Bench advances robust, fair, and explainable LLM-based evaluation systems for education."}}
{"id": "2504.04722", "pdf": "https://arxiv.org/pdf/2504.04722", "abs": "https://arxiv.org/abs/2504.04722", "authors": ["Adnan Khan", "Alireza Choubineh", "Mai A. Shaaban", "Abbas Akkasi", "Majid Komeili"], "title": "TactileNet: Bridging the Accessibility Gap with AI-Generated Tactile Graphics for Individuals with Vision Impairment", "categories": ["cs.CV"], "comment": null, "summary": "Tactile graphics are essential for providing access to visual information for\nthe 43 million people globally living with vision loss. Traditional methods for\ncreating these graphics are labor-intensive and cannot meet growing demand. We\nintroduce TactileNet, the first comprehensive dataset and AI-driven framework\nfor generating embossing-ready 2D tactile templates using text-to-image Stable\nDiffusion (SD) models. By integrating Low-Rank Adaptation (LoRA) and\nDreamBooth, our method fine-tunes SD models to produce high-fidelity,\nguideline-compliant graphics while reducing computational costs. Quantitative\nevaluations with tactile experts show 92.86% adherence to accessibility\nstandards. Structural fidelity analysis revealed near-human design similarity,\nwith an SSIM of 0.538 between generated graphics and expert-designed tactile\nimages. Notably, our method preserves object silhouettes better than human\ndesigns (SSIM = 0.259 vs. 0.215 for binary masks), addressing a key limitation\nof manual tactile abstraction. The framework scales to 32,000 images (7,050\nhigh-quality) across 66 classes, with prompt editing enabling customizable\noutputs (e.g., adding or removing details). By automating the 2D template\ngeneration step-compatible with standard embossing workflows-TactileNet\naccelerates production while preserving design flexibility. This work\ndemonstrates how AI can augment (not replace) human expertise to bridge the\naccessibility gap in education and beyond. Code, data, and models will be\npublicly released to foster further research.", "AI": {"tldr": "TactileNet is an AI-driven framework using Stable Diffusion to automate the creation of tactile graphics, achieving high adherence to accessibility standards and near-human design quality.", "motivation": "To address the labor-intensive and insufficient traditional methods for creating tactile graphics for people with vision loss.", "method": "Integrates Low-Rank Adaptation (LoRA) and DreamBooth to fine-tune Stable Diffusion models for generating embossing-ready 2D tactile templates.", "result": "Achieves 92.86% adherence to accessibility standards, near-human design similarity (SSIM = 0.538), and better silhouette preservation than manual designs.", "conclusion": "TactileNet demonstrates AI's potential to augment human expertise in bridging accessibility gaps, with plans to release code, data, and models for further research."}}
{"id": "2505.10080", "pdf": "https://arxiv.org/pdf/2505.10080", "abs": "https://arxiv.org/abs/2505.10080", "authors": ["Weijie Xiong", "Zo\u00eb Holmes", "Armando Angrisani", "Yudai Suzuki", "Thiparat Chotibut", "Supanut Thanasilp"], "title": "Role of scrambling and noise in temporal information processing with quantum systems", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.LG", "cs.NE", "stat.ML"], "comment": "14+35 pages, 6+5 figures, 1 table", "summary": "Scrambling quantum systems have been demonstrated as effective substrates for\ntemporal information processing. While their role in providing rich feature\nmaps has been widely studied, a theoretical understanding of their performance\nin temporal tasks is still lacking. Here we consider a general quantum\nreservoir processing framework that captures a broad range of physical\ncomputing models with quantum systems. We examine the scalability and memory\nretention of the model with scrambling reservoirs modelled by high-order\nunitary designs in both noiseless and noisy settings. In the former regime, we\nshow that measurement readouts become exponentially concentrated with\nincreasing reservoir size, yet strikingly do not worsen with the reservoir\niterations. Thus, while repeatedly reusing a small scrambling reservoir with\nquantum data might be viable, scaling up the problem size deteriorates\ngeneralization unless one can afford an exponential shot overhead. In contrast,\nthe memory of early inputs and initial states decays exponentially in both\nreservoir size and reservoir iterations. In the noisy regime, we also prove\nexponential memory decays with iterations for local noisy channels. Proving\nthese results required us to introduce new proof techniques for bounding\nconcentration in temporal quantum learning models.", "AI": {"tldr": "Quantum reservoir processing with scrambling systems shows exponential concentration in readouts and memory decay, limiting scalability and generalization without exponential overhead.", "motivation": "To theoretically understand the performance of quantum scrambling systems in temporal tasks, given their demonstrated effectiveness in temporal information processing.", "method": "A general quantum reservoir processing framework is analyzed, focusing on scalability and memory retention in noiseless and noisy settings using high-order unitary designs.", "result": "In noiseless settings, readouts concentrate exponentially with reservoir size but not iterations, while memory decays exponentially with both. In noisy settings, memory also decays exponentially with iterations.", "conclusion": "Quantum reservoirs face scalability and memory retention challenges, requiring exponential resources for larger problem sizes, but small reservoirs may remain viable for certain tasks."}}
{"id": "2410.07812", "pdf": "https://arxiv.org/pdf/2410.07812", "abs": "https://arxiv.org/abs/2410.07812", "authors": ["Luckeciano C. Melo", "Alessandro Abate", "Yarin Gal"], "title": "Temporal-Difference Variational Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine Learning models in real-world applications must continuously learn\nnew tasks to adapt to shifts in the data-generating distribution. Yet, for\nContinual Learning (CL), models often struggle to balance learning new tasks\n(plasticity) with retaining previous knowledge (memory stability).\nConsequently, they are susceptible to Catastrophic Forgetting, which degrades\nperformance and undermines the reliability of deployed systems. In the Bayesian\nCL literature, variational methods tackle this challenge by employing a\nlearning objective that recursively updates the posterior distribution while\nconstraining it to stay close to its previous estimate. Nonetheless, we argue\nthat these methods may be ineffective due to compounding approximation errors\nover successive recursions. To mitigate this, we propose new learning\nobjectives that integrate the regularization effects of multiple previous\nposterior estimations, preventing individual errors from dominating future\nposterior updates and compounding over time. We reveal insightful connections\nbetween these objectives and Temporal-Difference methods, a popular learning\nmechanism in Reinforcement Learning and Neuroscience. Experiments on\nchallenging CL benchmarks show that our approach effectively mitigates\nCatastrophic Forgetting, outperforming strong Variational CL methods.", "AI": {"tldr": "The paper addresses Catastrophic Forgetting in Continual Learning by proposing new Bayesian learning objectives that integrate multiple past posterior estimates, outperforming existing methods.", "motivation": "To balance plasticity and stability in Continual Learning, mitigating Catastrophic Forgetting caused by compounding approximation errors in variational methods.", "method": "Introduces new learning objectives that regularize updates using multiple past posterior estimates, preventing error dominance and compounding.", "result": "Outperforms strong Variational CL methods on benchmarks, effectively reducing Catastrophic Forgetting.", "conclusion": "The proposed method successfully mitigates forgetting by leveraging multiple past estimates, with connections to Temporal-Difference learning."}}
{"id": "2505.08058", "pdf": "https://arxiv.org/pdf/2505.08058", "abs": "https://arxiv.org/abs/2505.08058", "authors": ["Chris Forrester", "Octavia Sulea"], "title": "Hypernym Mercury: Token Optimization Through Semantic Field Constriction And Reconstruction From Hypernyms. A New Text Compression Method", "categories": ["cs.CL"], "comment": null, "summary": "Compute optimization using token reduction of LLM prompts is an emerging task\nin the fields of NLP and next generation, agentic AI. In this white paper, we\nintroduce a novel (patent pending) text representation scheme and a\nfirst-of-its-kind word-level semantic compression of paragraphs that can lead\nto over 90% token reduction, while retaining high semantic similarity to the\nsource text. We explain how this novel compression technique can be lossless\nand how the detail granularity is controllable. We discuss benchmark results\nover open source data (i.e. Bram Stoker's Dracula available through Project\nGutenberg) and show how our results hold at the paragraph level, across\nmultiple genres and models.", "AI": {"tldr": "A novel token reduction method for LLM prompts achieves 90% reduction while maintaining semantic similarity, with controllable granularity and lossless potential.", "motivation": "Optimizing compute efficiency in NLP and agentic AI by reducing token usage in prompts without losing semantic meaning.", "method": "Introduces a text representation scheme and word-level semantic compression for paragraphs.", "result": "Achieves over 90% token reduction with high semantic similarity, validated on open-source data like Dracula.", "conclusion": "The technique is scalable, lossless, and adaptable across genres and models, promising for efficient AI applications."}}
{"id": "2504.05904", "pdf": "https://arxiv.org/pdf/2504.05904", "abs": "https://arxiv.org/abs/2504.05904", "authors": ["Xiangyu Zheng", "Wanyun Li", "Songcheng He", "Jianping Fan", "Xiaoqiang Li", "We Zhang"], "title": "Saliency-Motion Guided Trunk-Collateral Network for Unsupervised Video Object Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent mainstream unsupervised video object segmentation (UVOS)\nmotion-appearance approaches use either the bi-encoder structure to separately\nencode motion and appearance features, or the uni-encoder structure for joint\nencoding. However, these methods fail to properly balance the motion-appearance\nrelationship. Consequently, even with complex fusion modules for\nmotion-appearance integration, the extracted suboptimal features degrade the\nmodels' overall performance. Moreover, the quality of optical flow varies\nacross scenarios, making it insufficient to rely solely on optical flow to\nachieve high-quality segmentation results. To address these challenges, we\npropose the Saliency-Motion guided Trunk-Collateral Network (SMTC-Net), which\nbetter balances the motion-appearance relationship and incorporates model's\nintrinsic saliency information to enhance segmentation performance.\nSpecifically, considering that optical flow maps are derived from RGB images,\nthey share both commonalities and differences. Accordingly, we propose a novel\nTrunk-Collateral structure for motion-appearance UVOS. The shared trunk\nbackbone captures the motion-appearance commonality, while the collateral\nbranch learns the uniqueness of motion features. Furthermore, an Intrinsic\nSaliency guided Refinement Module (ISRM) is devised to efficiently leverage the\nmodel's intrinsic saliency information to refine high-level features, and\nprovide pixel-level guidance for motion-appearance fusion, thereby enhancing\nperformance without additional input. Experimental results show that SMTC-Net\nachieved state-of-the-art performance on three UVOS datasets ( 89.2% J&F on\nDAVIS-16, 76% J on YouTube-Objects, 86.4% J on FBMS ) and four standard video\nsalient object detection (VSOD) benchmarks with the notable increase,\ndemonstrating its effectiveness and superiority over previous methods.", "AI": {"tldr": "SMTC-Net improves UVOS by balancing motion-appearance relationships and leveraging intrinsic saliency, achieving state-of-the-art results.", "motivation": "Existing UVOS methods struggle with motion-appearance balance and optical flow dependency, degrading performance.", "method": "Proposes a Trunk-Collateral structure for commonality and uniqueness of features, and an ISRM for saliency-guided refinement.", "result": "Achieves top performance on UVOS and VSOD benchmarks (e.g., 89.2% J&F on DAVIS-16).", "conclusion": "SMTC-Net effectively enhances segmentation by better integrating motion-appearance and saliency information."}}
{"id": "2505.10099", "pdf": "https://arxiv.org/pdf/2505.10099", "abs": "https://arxiv.org/abs/2505.10099", "authors": ["Sarat Moka", "Matias Quiroz", "Vali Asimit", "Samuel Muller"], "title": "A Scalable Gradient-Based Optimization Framework for Sparse Minimum-Variance Portfolio Selection", "categories": ["stat.ML", "cs.LG", "math.OC", "q-fin.PM"], "comment": null, "summary": "Portfolio optimization involves selecting asset weights to minimize a\nrisk-reward objective, such as the portfolio variance in the classical\nminimum-variance framework. Sparse portfolio selection extends this by imposing\na cardinality constraint: only $k$ assets from a universe of $p$ may be\nincluded. The standard approach models this problem as a mixed-integer\nquadratic program and relies on commercial solvers to find the optimal\nsolution. However, the computational costs of such methods increase\nexponentially with $k$ and $p$, making them too slow for problems of even\nmoderate size. We propose a fast and scalable gradient-based approach that\ntransforms the combinatorial sparse selection problem into a constrained\ncontinuous optimization task via Boolean relaxation, while preserving\nequivalence with the original problem on the set of binary points. Our\nalgorithm employs a tunable parameter that transmutes the auxiliary objective\nfrom a convex to a concave function. This allows a stable convex starting\npoint, followed by a controlled path toward a sparse binary solution as the\ntuning parameter increases and the objective moves toward concavity. In\npractice, our method matches commercial solvers in asset selection for most\ninstances and, in rare instances, the solution differs by a few assets whilst\nshowing a negligible error in portfolio variance.", "AI": {"tldr": "A gradient-based method for sparse portfolio selection is proposed, transforming the combinatorial problem into a continuous optimization task with Boolean relaxation, offering scalability and speed comparable to commercial solvers.", "motivation": "Traditional mixed-integer quadratic programming for sparse portfolio selection is computationally expensive and impractical for moderate-sized problems.", "method": "The approach uses Boolean relaxation to convert the problem into constrained continuous optimization, with a tunable parameter transitioning the objective from convex to concave for stable convergence.", "result": "The method matches commercial solvers in asset selection for most cases, with minor differences in rare instances and negligible variance error.", "conclusion": "The proposed gradient-based method provides a fast, scalable alternative to traditional solvers for sparse portfolio optimization."}}
{"id": "2410.12609", "pdf": "https://arxiv.org/pdf/2410.12609", "abs": "https://arxiv.org/abs/2410.12609", "authors": ["Kai Wang", "Siqiang Luo", "Caihua Shan", "Yifei Shen"], "title": "Towards Graph Foundation Models: Training on Knowledge Graphs Enables Transferability to General Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "25 Pages, 5 figures", "summary": "Inspired by the success of large language models, there is a trend toward\ndeveloping graph foundation models to conduct diverse downstream tasks in\nvarious domains. However, current models often require extra fine-tuning to\napply their learned structural and semantic representations to new graphs,\nwhich limits their versatility. Recent breakthroughs in zero-shot inductive\nreasoning on knowledge graphs (KGs), offer us a new perspective on extending KG\nreasoning to general graph applications. In this paper, we introduce SCR, a\nunified graph reasoning framework designed to train on knowledge graphs and\neffectively generalize across a wide range of graph tasks and domains. We begin\nby designing the task-specific KG structures to establish a unified topology\nfor different task formats. Then we propose semantic-conditioned message\npassing, a novel mechanism addressing the inherent semantic isolation in\ntraditional KG reasoning, by jointly modeling structural and semantic\ninvariance patterns in graph representations. To demonstrate the effectiveness,\nwe evaluate the inductive reasoning capability of SCR using 38 diverse graph\ndatasets, covering node-level, link-level, and graph-level tasks across\nmultiple domains. Our results show substantial performance gains over existing\nfoundation models and supervised baselines, highlighting the efficacy and\nadaptability of our approach.", "AI": {"tldr": "SCR is a unified graph reasoning framework that generalizes across diverse graph tasks by leveraging semantic-conditioned message passing and task-specific KG structures.", "motivation": "Current graph foundation models require fine-tuning for new graphs, limiting versatility. SCR aims to extend zero-shot inductive reasoning from KGs to general graphs.", "method": "Designs task-specific KG structures and introduces semantic-conditioned message passing to model structural and semantic invariance.", "result": "Evaluated on 38 datasets, SCR outperforms existing foundation models and supervised baselines.", "conclusion": "SCR demonstrates efficacy and adaptability in generalizing across graph tasks without extra fine-tuning."}}
{"id": "2410.11758", "pdf": "https://arxiv.org/pdf/2410.11758", "abs": "https://arxiv.org/abs/2410.11758", "authors": ["Seonghyeon Ye", "Joel Jang", "Byeongguk Jeon", "Sejune Joo", "Jianwei Yang", "Baolin Peng", "Ajay Mandlekar", "Reuben Tan", "Yu-Wei Chao", "Bill Yuchen Lin", "Lars Liden", "Kimin Lee", "Jianfeng Gao", "Luke Zettlemoyer", "Dieter Fox", "Minjoon Seo"], "title": "Latent Action Pretraining from Videos", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.LG"], "comment": "ICLR 2025 Website: https://latentactionpretraining.github.io", "summary": "We introduce Latent Action Pretraining for general Action models (LAPA), an\nunsupervised method for pretraining Vision-Language-Action (VLA) models without\nground-truth robot action labels. Existing Vision-Language-Action models\nrequire action labels typically collected by human teleoperators during\npretraining, which significantly limits possible data sources and scale. In\nthis work, we propose a method to learn from internet-scale videos that do not\nhave robot action labels. We first train an action quantization model\nleveraging VQ-VAE-based objective to learn discrete latent actions between\nimage frames, then pretrain a latent VLA model to predict these latent actions\nfrom observations and task descriptions, and finally finetune the VLA on\nsmall-scale robot manipulation data to map from latent to robot actions.\nExperimental results demonstrate that our method significantly outperforms\nexisting techniques that train robot manipulation policies from large-scale\nvideos. Furthermore, it outperforms the state-of-the-art VLA model trained with\nrobotic action labels on real-world manipulation tasks that require language\nconditioning, generalization to unseen objects, and semantic generalization to\nunseen instructions. Training only on human manipulation videos also shows\npositive transfer, opening up the potential for leveraging web-scale data for\nrobotics foundation model.", "AI": {"tldr": "LAPA introduces an unsupervised method to pretrain Vision-Language-Action models without action labels, outperforming existing techniques and enabling use of web-scale data.", "motivation": "Existing VLA models rely on human-labeled action data, limiting scalability. LAPA aims to learn from unlabeled internet videos.", "method": "LAPA uses VQ-VAE to learn latent actions, pretrains a VLA model to predict these actions, and finetunes on robot data.", "result": "LAPA outperforms state-of-the-art methods in language conditioning, generalization, and semantic tasks.", "conclusion": "LAPA enables leveraging web-scale videos for robotics, showing promise for foundation models."}}
{"id": "2504.08046", "pdf": "https://arxiv.org/pdf/2504.08046", "abs": "https://arxiv.org/abs/2504.08046", "authors": ["Mia Chiquier", "Orr Avrech", "Yossi Gandelsman", "Berthy Feng", "Katherine Bouman", "Carl Vondrick"], "title": "Teaching Humans Subtle Differences with DIFFusion", "categories": ["cs.CV"], "comment": null, "summary": "Scientific expertise often requires recognizing subtle visual differences\nthat remain challenging to articulate even for domain experts. We present a\nsystem that leverages generative models to automatically discover and visualize\nminimal discriminative features between categories while preserving instance\nidentity. Our method generates counterfactual visualizations with subtle,\ntargeted transformations between classes, performing well even in domains where\ndata is sparse, examples are unpaired, and category boundaries resist verbal\ndescription. Experiments across six domains, including black hole simulations,\nbutterfly taxonomy, and medical imaging, demonstrate accurate transitions with\nlimited training data, highlighting both established discriminative features\nand novel subtle distinctions that measurably improved category\ndifferentiation. User studies confirm our generated counterfactuals\nsignificantly outperform traditional approaches in teaching humans to correctly\ndifferentiate between fine-grained classes, showing the potential of generative\nmodels to advance visual learning and scientific research.", "AI": {"tldr": "A system uses generative models to find and show subtle visual differences between categories, improving fine-grained classification even with sparse data.", "motivation": "Recognizing subtle visual differences in scientific domains is challenging, even for experts, and often hard to describe verbally.", "method": "Leverages generative models to create counterfactual visualizations with targeted transformations between classes, handling sparse and unpaired data.", "result": "Works well across six domains (e.g., black holes, butterflies, medical imaging), improving category differentiation and revealing novel distinctions.", "conclusion": "Generated counterfactuals outperform traditional methods in teaching humans fine-grained classification, advancing visual learning and research."}}
{"id": "2505.10139", "pdf": "https://arxiv.org/pdf/2505.10139", "abs": "https://arxiv.org/abs/2505.10139", "authors": ["Lorenz Vaitl", "Leon Klein"], "title": "Path Gradients after Flow Matching", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Boltzmann Generators have emerged as a promising machine learning tool for\ngenerating samples from equilibrium distributions of molecular systems using\nNormalizing Flows and importance weighting. Recently, Flow Matching has helped\nspeed up Continuous Normalizing Flows (CNFs), scale them to more complex\nmolecular systems, and minimize the length of the flow integration\ntrajectories. We investigate the benefits of using path gradients to fine-tune\nCNFs initially trained by Flow Matching, in the setting where a target energy\nis known. Our experiments show that this hybrid approach yields up to a\nthreefold increase in sampling efficiency for molecular systems, all while\nusing the same model, a similar computational budget and without the need for\nadditional sampling. Furthermore, by measuring the length of the flow\ntrajectories during fine-tuning, we show that path gradients largely preserve\nthe learned structure of the flow.", "AI": {"tldr": "Hybrid approach combining Flow Matching and path gradients improves sampling efficiency in Boltzmann Generators for molecular systems.", "motivation": "To enhance the sampling efficiency of Boltzmann Generators for molecular systems by leveraging path gradients after initial Flow Matching training.", "method": "Fine-tune Continuous Normalizing Flows (CNFs) trained with Flow Matching using path gradients, given a known target energy.", "result": "Achieves up to a threefold increase in sampling efficiency without additional computational cost or sampling.", "conclusion": "Path gradients effectively fine-tune CNFs, preserving flow structure while significantly boosting efficiency."}}
{"id": "2411.11641", "pdf": "https://arxiv.org/pdf/2411.11641", "abs": "https://arxiv.org/abs/2411.11641", "authors": ["Mengxuan Li", "Ke Liu", "Hongyang Chen", "Jiajun Bu", "Hongwei Wang", "Haishuai Wang"], "title": "TSINR: Capturing Temporal Continuity via Implicit Neural Representations for Time Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by SIGKDD 2025", "summary": "Time series anomaly detection aims to identify unusual patterns in data or\ndeviations from systems' expected behavior. The reconstruction-based methods\nare the mainstream in this task, which learn point-wise representation via\nunsupervised learning. However, the unlabeled anomaly points in training data\nmay cause these reconstruction-based methods to learn and reconstruct anomalous\ndata, resulting in the challenge of capturing normal patterns. In this paper,\nwe propose a time series anomaly detection method based on implicit neural\nrepresentation (INR) reconstruction, named TSINR, to address this challenge.\nDue to the property of spectral bias, TSINR enables prioritizing low-frequency\nsignals and exhibiting poorer performance on high-frequency abnormal data.\nSpecifically, we adopt INR to parameterize time series data as a continuous\nfunction and employ a transformer-based architecture to predict the INR of\ngiven data. As a result, the proposed TSINR method achieves the advantage of\ncapturing the temporal continuity and thus is more sensitive to discontinuous\nanomaly data. In addition, we further design a novel form of INR continuous\nfunction to learn inter- and intra-channel information, and leverage a\npre-trained large language model to amplify the intense fluctuations in\nanomalies. Extensive experiments demonstrate that TSINR achieves superior\noverall performance on both univariate and multivariate time series anomaly\ndetection benchmarks compared to other state-of-the-art reconstruction-based\nmethods. Our codes are available.", "AI": {"tldr": "TSINR is a time series anomaly detection method using implicit neural representation (INR) to prioritize low-frequency signals and improve sensitivity to anomalies.", "motivation": "Reconstruction-based methods struggle with unlabeled anomalies in training data, leading to poor normal pattern capture.", "method": "TSINR uses INR to parameterize time series as a continuous function, employs a transformer-based architecture, and leverages a pre-trained language model for anomaly detection.", "result": "TSINR outperforms state-of-the-art methods on univariate and multivariate benchmarks.", "conclusion": "TSINR effectively addresses reconstruction-based challenges and improves anomaly detection performance."}}
{"id": "2411.14251", "pdf": "https://arxiv.org/pdf/2411.14251", "abs": "https://arxiv.org/abs/2411.14251", "authors": ["Xidong Feng", "Bo Liu", "Ziyu Wan", "Haotian Fu", "Girish A. Koushik", "Zhiyuan Hu", "Mengyue Yang", "Ying Wen", "Jun Wang"], "title": "Natural Language Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted at ICLR 2025 Workshop SSI-FM", "summary": "Reinforcement Learning (RL) mathematically formulates decision-making with\nMarkov Decision Process (MDP). With MDPs, researchers have achieved remarkable\nbreakthroughs across various domains, including games, robotics, and language\nmodels. This paper seeks a new possibility, Natural Language Reinforcement\nLearning (NLRL), by extending traditional MDP to natural language-based\nrepresentation space. Specifically, NLRL innovatively redefines RL principles,\nincluding task objectives, policy, value function, Bellman equation, and policy\niteration, into their language counterparts. With recent advancements in large\nlanguage models (LLMs), NLRL can be practically implemented to achieve RL-like\npolicy and value improvement by either pure prompting or gradient-based\ntraining. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games\ndemonstrate the effectiveness, efficiency, and interpretability of the NLRL\nframework among diverse use cases.", "AI": {"tldr": "The paper introduces Natural Language Reinforcement Learning (NLRL), extending traditional MDPs to natural language representations, leveraging LLMs for practical implementation, and demonstrating effectiveness in games.", "motivation": "To explore a new approach (NLRL) by extending traditional RL principles into natural language space, enabled by advancements in LLMs.", "method": "Redefines RL components (objectives, policy, value function, etc.) into language counterparts, implemented via prompting or gradient-based training with LLMs.", "result": "Experiments on Maze, Breakthrough, and Tic-Tac-Toe show NLRL's effectiveness, efficiency, and interpretability.", "conclusion": "NLRL offers a promising framework for RL in natural language, with practical applications and interpretability."}}
{"id": "2504.13231", "pdf": "https://arxiv.org/pdf/2504.13231", "abs": "https://arxiv.org/abs/2504.13231", "authors": ["Braeden Sherritt", "Isar Nejadgholi", "Marzieh Amini"], "title": "WildFireCan-MMD: A Multimodal Dataset for Classification of User-Generated Content During Wildfires in Canada", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Rapid information access is vital during wildfires, yet traditional data\nsources are slow and costly. Social media offers real-time updates, but\nextracting relevant insights remains a challenge. We present WildFireCan-MMD, a\nnew multimodal dataset of X posts from recent Canadian wildfires, annotated\nacross twelve key themes. Evaluating both vision-language models and\ncustom-trained classifiers, we show that while zero-shot prompting offers quick\ndeployment, even simple trained models outperform them when labelled data is\navailable. Our best-performing transformer-based fine-tuned model reaches 83%\nf-score, outperforming gpt4 by 23%. As a use case, we demonstrate how this\nmodel can be used to uncover trends during wildfires. Our findings highlight\nthe enduring importance of tailored datasets and task-specific training.\nImportantly, such datasets should be localized, as disaster response\nrequirements vary across regions and contexts.", "AI": {"tldr": "WildFireCan-MMD is a multimodal dataset for wildfire insights from social media, showing trained models outperform zero-shot methods, with a fine-tuned model achieving 83% f-score.", "motivation": "Traditional wildfire data is slow and costly; social media offers real-time updates but lacks efficient extraction of relevant insights.", "method": "Created WildFireCan-MMD, a dataset of X posts from Canadian wildfires, annotated across twelve themes. Evaluated vision-language models and custom-trained classifiers.", "result": "Fine-tuned transformer model achieved 83% f-score, outperforming GPT-4 by 23%.", "conclusion": "Tailored datasets and task-specific training are crucial, especially localized ones, as disaster response needs vary by region."}}
{"id": "2505.10160", "pdf": "https://arxiv.org/pdf/2505.10160", "abs": "https://arxiv.org/abs/2505.10160", "authors": ["Yannis Montreuil", "Axel Carlier", "Lai Xing Ng", "Wei Tsang Ooi"], "title": "One-Stage Top-$k$ Learning-to-Defer: Score-Based Surrogates with Theoretical Guarantees", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We introduce the first one-stage Top-$k$ Learning-to-Defer framework, which\nunifies prediction and deferral by learning a shared score-based model that\nselects the $k$ most cost-effective entities-labels or experts-per input. While\nexisting one-stage L2D methods are limited to deferring to a single expert, our\napproach jointly optimizes prediction and deferral across multiple entities\nthrough a single end-to-end objective. We define a cost-sensitive loss and\nderive a novel convex surrogate that is independent of the cardinality\nparameter $k$, enabling generalization across Top-$k$ regimes without\nretraining. Our formulation recovers the Top-1 deferral policy of prior\nscore-based methods as a special case, and we prove that our surrogate is both\nBayes-consistent and $\\mathcal{H}$-consistent under mild assumptions. We\nfurther introduce an adaptive variant, Top-$k(x)$, which dynamically selects\nthe number of consulted entities per input to balance predictive accuracy and\nconsultation cost. Experiments on CIFAR-10 and SVHN confirm that our one-stage\nTop-$k$ method strictly outperforms Top-1 deferral, while Top-$k(x)$ achieves\nsuperior accuracy-cost trade-offs by tailoring allocations to input complexity.", "AI": {"tldr": "A one-stage Top-$k$ Learning-to-Defer framework is introduced, unifying prediction and deferral by learning a shared score-based model for selecting the $k$ most cost-effective entities or experts per input. It outperforms existing methods by jointly optimizing across multiple entities and generalizing across Top-$k$ regimes without retraining.", "motivation": "Existing one-stage L2D methods are limited to deferring to a single expert, lacking flexibility and cost-effectiveness. The goal is to improve deferral policies by allowing multiple entities and dynamic selection.", "method": "The framework uses a shared score-based model with a cost-sensitive loss and a novel convex surrogate, independent of $k$. It includes an adaptive variant, Top-$k(x)$, for dynamic entity selection.", "result": "Experiments on CIFAR-10 and SVHN show the method outperforms Top-1 deferral, with Top-$k(x)$ achieving better accuracy-cost trade-offs by adapting to input complexity.", "conclusion": "The one-stage Top-$k$ framework successfully unifies prediction and deferral, offering flexibility and improved performance, while the adaptive variant further optimizes cost-accuracy trade-offs."}}
{"id": "2412.08911", "pdf": "https://arxiv.org/pdf/2412.08911", "abs": "https://arxiv.org/abs/2412.08911", "authors": ["Shijun Li", "Hilaf Hasson", "Jing Hu", "Joydeep Ghosh"], "title": "Goal-Conditioned Supervised Learning for Multi-Objective Recommendation", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Multi-objective learning endeavors to concurrently optimize multiple\nobjectives using a single model, aiming to achieve high and balanced\nperformance across diverse objectives. However, this often entails a more\ncomplex optimization problem, particularly when navigating potential conflicts\nbetween objectives, leading to solutions with higher memory requirements and\ncomputational complexity. This paper introduces a Multi-Objective\nGoal-Conditioned Supervised Learning (MOGCSL) framework for automatically\nlearning to achieve multiple objectives from offline sequential data. MOGCSL\nextends the conventional GCSL method to multi-objective scenarios by redefining\ngoals from one-dimensional scalars to multi-dimensional vectors. It benefits\nfrom naturally eliminating the need for complex architectures and optimization\nconstraints. Moreover, MOGCSL effectively filters out uninformative or noisy\ninstances that fail to achieve desirable long-term rewards across multiple\nobjectives. We also introduces a novel goal-selection algorithm for MOGCSL to\nmodel and identify \"high\" achievable goals for inference.\n  While MOGCSL is quite general, we focus on its application to the next action\nprediction problem in commercial-grade recommender systems. In this context,\nany viable solution needs to be reasonably scalable and also be robust to large\namounts of noisy data that is characteristic of this application space. We show\nthat MOGCSL performs admirably on both counts by extensive experiments on\nreal-world recommendation datasets. Also, analysis and experiments are included\nto explain its strength in discounting the noisier portions of training data in\nrecommender systems with multiple objectives.", "AI": {"tldr": "MOGCSL is a framework for multi-objective learning from offline sequential data, extending GCSL to handle multi-dimensional goals and filtering noisy data. It excels in scalable, robust next-action prediction for recommender systems.", "motivation": "Multi-objective learning is complex due to conflicts between objectives, leading to high computational demands. MOGCSL simplifies this by redefining goals and filtering noise.", "method": "MOGCSL extends GCSL to multi-objective scenarios by using multi-dimensional goal vectors and introduces a goal-selection algorithm for high achievable goals.", "result": "MOGCSL performs well in scalable, robust next-action prediction for recommender systems, effectively handling noisy data.", "conclusion": "MOGCSL is a scalable and robust solution for multi-objective learning, particularly effective in noisy, real-world recommender systems."}}
{"id": "2505.05145", "pdf": "https://arxiv.org/pdf/2505.05145", "abs": "https://arxiv.org/abs/2505.05145", "authors": ["Xinyan Hu", "Kayo Yin", "Michael I. Jordan", "Jacob Steinhardt", "Lijie Chen"], "title": "Understanding In-context Learning of Addition via Activation Subspaces", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "20 pages", "summary": "To perform in-context learning, language models must extract signals from\nindividual few-shot examples, aggregate these into a learned prediction rule,\nand then apply this rule to new examples. How is this implemented in the\nforward pass of modern transformer models? To study this, we consider a\nstructured family of few-shot learning tasks for which the true prediction rule\nis to add an integer $k$ to the input. We find that Llama-3-8B attains high\naccuracy on this task for a range of $k$, and localize its few-shot ability to\njust three attention heads via a novel optimization approach. We further show\nthe extracted signals lie in a six-dimensional subspace, where four of the\ndimensions track the unit digit and the other two dimensions track overall\nmagnitude. We finally examine how these heads extract information from\nindividual few-shot examples, identifying a self-correction mechanism in which\nmistakes from earlier examples are suppressed by later examples. Our results\ndemonstrate how tracking low-dimensional subspaces across a forward pass can\nprovide insight into fine-grained computational structures.", "AI": {"tldr": "The paper investigates how transformer models like Llama-3-8B perform in-context learning by analyzing a structured task of adding an integer $k$ to inputs. It identifies key attention heads and a low-dimensional subspace for signal extraction.", "motivation": "To understand the mechanisms behind in-context learning in transformers, specifically how signals from few-shot examples are aggregated and applied.", "method": "The study uses a structured task (adding $k$ to inputs) and analyzes Llama-3-8B's performance, localizing few-shot ability to three attention heads and a six-dimensional subspace.", "result": "Llama-3-8B achieves high accuracy, with signal extraction localized to specific heads and subspaces. A self-correction mechanism is identified.", "conclusion": "Tracking low-dimensional subspaces reveals fine-grained computational structures in transformers, providing insights into in-context learning."}}
{"id": "2505.03093", "pdf": "https://arxiv.org/pdf/2505.03093", "abs": "https://arxiv.org/abs/2505.03093", "authors": ["Siming He", "Zachary Osman", "Fernando Cladera", "Dexter Ong", "Nitant Rai", "Patrick Corey Green", "Vijay Kumar", "Pratik Chaudhari"], "title": "Estimating the Diameter at Breast Height of Trees in a Forest With a Single 360 Camera", "categories": ["cs.CV"], "comment": null, "summary": "Forest inventories rely on accurate measurements of the diameter at breast\nheight (DBH) for ecological monitoring, resource management, and carbon\naccounting. While LiDAR-based techniques can achieve centimeter-level\nprecision, they are cost-prohibitive and operationally complex. We present a\nlow-cost alternative that only needs a consumer-grade 360 video camera. Our\nsemi-automated pipeline comprises of (i) a dense point cloud reconstruction\nusing Structure from Motion (SfM) photogrammetry software called Agisoft\nMetashape, (ii) semantic trunk segmentation by projecting Grounded Segment\nAnything (SAM) masks onto the 3D cloud, and (iii) a robust RANSAC-based\ntechnique to estimate cross section shape and DBH. We introduce an interactive\nvisualization tool for inspecting segmented trees and their estimated DBH. On\n61 acquisitions of 43 trees under a variety of conditions, our method attains\nmedian absolute relative errors of 5-9% with respect to \"ground-truth\" manual\nmeasurements. This is only 2-4% higher than LiDAR-based estimates, while\nemploying a single 360 camera that costs orders of magnitude less, requires\nminimal setup, and is widely available.", "AI": {"tldr": "A low-cost method using a 360 video camera achieves 5-9% median absolute relative error in DBH measurements, close to LiDAR's precision but much cheaper and simpler.", "motivation": "Accurate DBH measurements are crucial for forest inventories, but LiDAR is expensive and complex. A cheaper, simpler alternative is needed.", "method": "Uses a 360 camera with a pipeline: (i) dense point cloud reconstruction via SfM, (ii) semantic trunk segmentation with Grounded SAM, and (iii) RANSAC-based DBH estimation. Includes a visualization tool.", "result": "Achieves 5-9% median absolute relative error vs. manual measurements, only 2-4% worse than LiDAR.", "conclusion": "The method is a viable, cost-effective alternative to LiDAR for DBH measurement in forest inventories."}}
{"id": "2505.10279", "pdf": "https://arxiv.org/pdf/2505.10279", "abs": "https://arxiv.org/abs/2505.10279", "authors": ["Gabriel R. Palma", "Sally McClean", "Brahim Allan", "Zeeshan Tariq", "Rafael A. Moral"], "title": "Estimating the number of household TV profiles based in customer behaviour using Gaussian mixture model averaging", "categories": ["stat.ME", "cs.LG"], "comment": "21 pages", "summary": "TV customers today face many choices from many live channels and on-demand\nservices. Providing a personalised experience that saves customers time when\ndiscovering content is essential for TV providers. However, a reliable\nunderstanding of their behaviour and preferences is key. When creating\npersonalised recommendations for TV, the biggest challenge is understanding\nviewing behaviour within households when multiple people are watching. The\nobjective is to detect and combine individual profiles to make\nbetter-personalised recommendations for group viewing. Our challenge is that we\nhave little explicit information about who is watching the devices at any time\n(individuals or groups). Also, we do not have a way to combine more than one\nindividual profile to make better recommendations for group viewing. We propose\na novel framework using a Gaussian mixture model averaging to obtain point\nestimates for the number of household TV profiles and a Bayesian random walk\nmodel to introduce uncertainty. We applied our approach using data from real\ncustomers whose TV-watching data totalled approximately half a million\nobservations. Our results indicate that combining our framework with the\nselected features provides a means to estimate the number of household TV\nprofiles and their characteristics, including shifts over time and\nquantification of uncertainty.", "AI": {"tldr": "A novel framework using Gaussian mixture and Bayesian models to estimate household TV profiles for better group viewing recommendations.", "motivation": "Personalized TV recommendations require understanding household viewing behavior, but explicit data on who is watching is lacking.", "method": "Uses Gaussian mixture model averaging for profile estimation and Bayesian random walk for uncertainty. Tested on real customer data.", "result": "Framework effectively estimates household profiles, including shifts over time and uncertainty.", "conclusion": "Proposed method improves personalized recommendations for group viewing by addressing profile detection and combination challenges."}}
{"id": "2501.02481", "pdf": "https://arxiv.org/pdf/2501.02481", "abs": "https://arxiv.org/abs/2501.02481", "authors": ["Zhengpeng Xie", "Jiahang Cao", "Qiang Zhang", "Jianxiong Zhang", "Changwei Wang", "Renjing Xu"], "title": "Representation Convergence: Mutual Distillation is Secretly a Form of Regularization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we argue that mutual distillation between reinforcement\nlearning policies serves as an implicit regularization, preventing them from\noverfitting to irrelevant features. We highlight two key contributions: (a)\nTheoretically, for the first time, we prove that enhancing the policy\nrobustness to irrelevant features leads to improved generalization performance.\n(b) Empirically, we demonstrate that mutual distillation between policies\ncontributes to such robustness, enabling the spontaneous emergence of invariant\nrepresentations over pixel inputs. Overall, our findings challenge the\nconventional view of distillation as merely a means of knowledge transfer,\noffering a novel perspective on the generalization in deep reinforcement\nlearning.", "AI": {"tldr": "Mutual distillation in reinforcement learning acts as implicit regularization, improving generalization by reducing overfitting to irrelevant features.", "motivation": "To challenge the conventional view of distillation as just knowledge transfer and explore its role in enhancing policy robustness and generalization.", "method": "Theoretical proof and empirical demonstration of mutual distillation between policies to enhance robustness to irrelevant features.", "result": "Mutual distillation improves generalization by fostering invariant representations in pixel inputs.", "conclusion": "Mutual distillation offers a novel perspective on generalization in deep reinforcement learning, beyond traditional knowledge transfer."}}
{"id": "2505.08910", "pdf": "https://arxiv.org/pdf/2505.08910", "abs": "https://arxiv.org/abs/2505.08910", "authors": ["Nahid Alam", "Karthik Reddy Kanjula", "Surya Guthikonda", "Timothy Chung", "Bala Krishna S Vegesna", "Abhipsha Das", "Anthony Susevski", "Ryan Sze-Yin Chan", "S M Iftekhar Uddin", "Shayekh Bin Islam", "Roshan Santhosh", "Snegha A", "Drishti Sharma", "Chen Liu", "Isha Chaturvedi", "Genta Indra Winata", "Ashvanth. S", "Snehanshu Mukherjee", "Alham Fikri Aji"], "title": "Behind Maya: Building a Multilingual Vision Language Model", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted at VLMs4ALL CVPR 2025 Workshop; corrected workshop name\n  spelling", "summary": "In recent times, we have seen a rapid development of large Vision-Language\nModels (VLMs). They have shown impressive results on academic benchmarks,\nprimarily in widely spoken languages but lack performance on low-resource\nlanguages and varied cultural contexts. To address these limitations, we\nintroduce Maya, an open-source Multilingual VLM. Our contributions are: 1) a\nmultilingual image-text pretraining dataset in eight languages, based on the\nLLaVA pretraining dataset; and 2) a multilingual image-text model supporting\nthese languages, enhancing cultural and linguistic comprehension in\nvision-language tasks. Code available at https://github.com/nahidalam/maya.", "AI": {"tldr": "Maya is an open-source Multilingual Vision-Language Model (VLM) addressing performance gaps in low-resource languages and cultural contexts.", "motivation": "Existing VLMs excel in widely spoken languages but underperform in low-resource languages and diverse cultural settings.", "method": "Developed a multilingual image-text pretraining dataset in eight languages and built a multilingual image-text model.", "result": "Maya enhances cultural and linguistic comprehension in vision-language tasks.", "conclusion": "Maya bridges the gap in multilingual and culturally diverse vision-language understanding, with open-source availability."}}
{"id": "2505.05513", "pdf": "https://arxiv.org/pdf/2505.05513", "abs": "https://arxiv.org/abs/2505.05513", "authors": ["Muhammad Junaid Asif", "Hamza Khan", "Rabia Tehseen", "Syed Tahir Hussain Rizvi", "Mujtaba Asad", "Shazia Saqib", "Rana Fayyaz Ahmad"], "title": "Exploring Convolutional Neural Networks for Rice Grain Classification: An Explainable AI Approach", "categories": ["cs.CV"], "comment": null, "summary": "Rice is an essential staple food worldwide that is important in promoting\ninternational trade, economic growth, and nutrition. Asian countries such as\nChina, India, Pakistan, Thailand, Vietnam, and Indonesia are notable for their\nsignificant contribution to the cultivation and utilization of rice. These\nnations are also known for cultivating different rice grains, including short\nand long grains. These sizes are further classified as basmati, jasmine, kainat\nsaila, ipsala, arborio, etc., catering to diverse culinary preferences and\ncultural traditions. For both local and international trade, inspecting and\nmaintaining the quality of rice grains to satisfy customers and preserve a\ncountry's reputation is necessary. Manual quality check and classification is\nquite a laborious and time-consuming process. It is also highly prone to\nmistakes. Therefore, an automatic solution must be proposed for the effective\nand efficient classification of different varieties of rice grains. This\nresearch paper presents an automatic framework based on a convolutional neural\nnetwork (CNN) for classifying different varieties of rice grains. We evaluated\nthe proposed model based on performance metrics such as accuracy, recall,\nprecision, and F1-Score. The CNN model underwent rigorous training and\nvalidation, achieving a remarkable accuracy rate and a perfect area under each\nclass's Receiver Operating Characteristic (ROC) curve. The confusion matrix\nanalysis confirmed the model's effectiveness in distinguishing between the\ndifferent rice varieties, indicating minimal misclassifications. Additionally,\nthe integration of explainability techniques such as LIME (Local Interpretable\nModel-agnostic Explanations) and SHAP (SHapley Additive exPlanations) provided\nvaluable insights into the model's decision-making process, revealing how\nspecific features of the rice grains influenced classification outcomes.", "AI": {"tldr": "The paper proposes a CNN-based framework for automatic classification of rice grain varieties, achieving high accuracy and explainability using LIME and SHAP.", "motivation": "Manual rice grain classification is error-prone and time-consuming, necessitating an automated solution for quality assurance in trade.", "method": "A convolutional neural network (CNN) is used for classification, evaluated via accuracy, recall, precision, F1-Score, and ROC curves.", "result": "The CNN model achieved high accuracy and minimal misclassifications, with explainability techniques revealing feature influences.", "conclusion": "The automated framework effectively classifies rice varieties, offering a reliable solution for quality inspection."}}
{"id": "2505.10319", "pdf": "https://arxiv.org/pdf/2505.10319", "abs": "https://arxiv.org/abs/2505.10319", "authors": ["John Nicol", "Markus Frohme"], "title": "Deconstructing Subset Construction -- Reducing While Determinizing", "categories": ["cs.FL", "cs.LG"], "comment": "19 pages, 2 figures", "summary": "We present a novel perspective on the NFA canonization problem, which\nintroduces intermediate minimization steps to reduce the exploration space\non-the-fly. Essential to our approach are so-called equivalence registries\nwhich manage information about equivalent states and allow for incorporating\nfurther optimization techniques such as convexity closures or simulation to\nboost performance. Due to the generality of our approach, these concepts can be\nembedded in classic subset construction or Brzozowski's approach. We evaluate\nour approach on a set of real-world examples from automatic sequences and\nobserve that we are able to improve especially worst-case scenarios. We\nimplement our approach in an open-source library for users to experiment with.", "AI": {"tldr": "A novel method for NFA canonization introduces intermediate minimization steps and equivalence registries to reduce exploration space and improve performance, applicable to classic approaches like subset construction or Brzozowski's method.", "motivation": "The paper addresses the NFA canonization problem by aiming to reduce the exploration space dynamically and enhance performance through innovative techniques.", "method": "The approach uses intermediate minimization steps and equivalence registries to manage equivalent states, incorporating optimizations like convexity closures or simulation.", "result": "Evaluation on real-world examples shows improved performance, particularly in worst-case scenarios.", "conclusion": "The method is implemented in an open-source library, demonstrating its practical applicability and effectiveness."}}
{"id": "2501.18901", "pdf": "https://arxiv.org/pdf/2501.18901", "abs": "https://arxiv.org/abs/2501.18901", "authors": ["Khai Nguyen", "Hai Nguyen", "Tuan Pham", "Nhat Ho"], "title": "Lightspeed Geometric Dataset Distance via Sliced Optimal Transport", "categories": ["cs.LG", "cs.AI", "stat.CO", "stat.ME", "stat.ML"], "comment": "Accepted to ICML 2025, 16 pages, 13 figures", "summary": "We introduce sliced optimal transport dataset distance (s-OTDD), a\nmodel-agnostic, embedding-agnostic approach for dataset comparison that\nrequires no training, is robust to variations in the number of classes, and can\nhandle disjoint label sets. The core innovation is Moment Transform Projection\n(MTP), which maps a label, represented as a distribution over features, to a\nreal number. Using MTP, we derive a data point projection that transforms\ndatasets into one-dimensional distributions. The s-OTDD is defined as the\nexpected Wasserstein distance between the projected distributions, with respect\nto random projection parameters. Leveraging the closed form solution of\none-dimensional optimal transport, s-OTDD achieves (near-)linear computational\ncomplexity in the number of data points and feature dimensions and is\nindependent of the number of classes. With its geometrically meaningful\nprojection, s-OTDD strongly correlates with the optimal transport dataset\ndistance while being more efficient than existing dataset discrepancy measures.\nMoreover, it correlates well with the performance gap in transfer learning and\nclassification accuracy in data augmentation.", "AI": {"tldr": "The paper introduces s-OTDD, a method for dataset comparison that is model-agnostic, efficient, and handles disjoint label sets. It uses Moment Transform Projection (MTP) to map labels to real numbers, enabling linear computational complexity and strong correlation with performance metrics.", "motivation": "Existing dataset comparison methods often lack efficiency, robustness to class variations, or the ability to handle disjoint label sets. s-OTDD addresses these limitations.", "method": "The method involves Moment Transform Projection (MTP) to map labels to real numbers, transforming datasets into one-dimensional distributions. The s-OTDD is computed as the expected Wasserstein distance between these distributions.", "result": "s-OTDD achieves near-linear computational complexity, correlates well with optimal transport dataset distance, and aligns with transfer learning and data augmentation performance.", "conclusion": "s-OTDD is a robust, efficient, and effective method for dataset comparison, offering advantages over existing approaches."}}
{"id": "2505.05901", "pdf": "https://arxiv.org/pdf/2505.05901", "abs": "https://arxiv.org/abs/2505.05901", "authors": ["Hanzhe Liang", "Aoran Wang", "Jie Zhou", "Xin Jin", "Can Gao", "Jinbao Wang"], "title": "Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "26 pages", "summary": "In this paper, we explore a novel approach to 3D anomaly detection (AD) that\ngoes beyond merely identifying anomalies based on structural characteristics.\nOur primary perspective is that most anomalies arise from unpredictable\ndefective forces originating from both internal and external sources. To\naddress these anomalies, we seek out opposing forces that can help correct\nthem. Therefore, we introduce the Mechanics Complementary Model-based Framework\nfor the 3D-AD task (MC4AD), which generates internal and external corrective\nforces for each point. We first propose a Diverse Anomaly-Generation (DA-Gen)\nmodule designed to simulate various types of anomalies. Next, we present the\nCorrective Force Prediction Network (CFP-Net), which uses complementary\nrepresentations for point-level analysis to simulate the different\ncontributions from internal and external corrective forces. To ensure the\ncorrective forces are constrained effectively, we have developed a combined\nloss function that includes a new symmetric loss and an overall loss. Notably,\nwe implement a Hierarchical Quality Control (HQC) strategy based on a three-way\ndecision process and contribute a dataset titled Anomaly-IntraVariance, which\nincorporates intraclass variance to evaluate our model. As a result, the\nproposed MC4AD has been proven effective through theory and experimentation.\nThe experimental results demonstrate that our approach yields nine\nstate-of-the-art performances, achieving optimal results with minimal\nparameters and the fastest inference speed across five existing datasets, in\naddition to the proposed Anomaly-IntraVariance dataset. The source is available\nat https://github.com/hzzzzzhappy/MC4AD", "AI": {"tldr": "The paper introduces MC4AD, a novel 3D anomaly detection framework using corrective forces, achieving state-of-the-art results with minimal parameters and fast inference.", "motivation": "Anomalies often stem from unpredictable defective forces; the paper aims to address these by identifying opposing corrective forces.", "method": "Proposes MC4AD with DA-Gen for anomaly simulation, CFP-Net for corrective force prediction, a combined loss function, and HQC for quality control.", "result": "MC4AD achieves nine state-of-the-art performances across five datasets and the new Anomaly-IntraVariance dataset, with minimal parameters and fast speed.", "conclusion": "The MC4AD framework is theoretically and experimentally validated as effective for 3D anomaly detection, outperforming existing methods."}}
{"id": "2505.10367", "pdf": "https://arxiv.org/pdf/2505.10367", "abs": "https://arxiv.org/abs/2505.10367", "authors": ["Chuanqing Pu", "Feilong Fan", "Nengling Tai", "Songyuan Liu", "Jinming Yu"], "title": "A Hybrid Strategy for Aggregated Probabilistic Forecasting and Energy Trading in HEFTCom2024", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "Solution description of IEEE Hybrid Energy Forecasting and Trading\n  Competition (HEFTCom)", "summary": "Obtaining accurate probabilistic energy forecasts and making effective\ndecisions amid diverse uncertainties are routine challenges in future energy\nsystems. This paper presents the solution of team GEB, which ranked 3rd in\ntrading, 4th in forecasting, and 1st among student teams in the IEEE Hybrid\nEnergy Forecasting and Trading Competition 2024 (HEFTCom2024). The solution\nprovides accurate probabilistic forecasts for a wind-solar hybrid system, and\nachieves substantial trading revenue in the day-ahead electricity market. Key\ncomponents include: (1) a stacking-based approach combining sister forecasts\nfrom various Numerical Weather Predictions (NWPs) to provide wind power\nforecasts, (2) an online solar post-processing model to address the\ndistribution shift in the online test set caused by increased solar capacity,\n(3) a probabilistic aggregation method for accurate quantile forecasts of\nhybrid generation, and (4) a stochastic trading strategy to maximize expected\ntrading revenue considering uncertainties in electricity prices. This paper\nalso explores the potential of end-to-end learning to further enhance the\ntrading revenue by adjusting the distribution of forecast errors. Detailed case\nstudies are provided to validate the effectiveness of these proposed methods.\nCode for all mentioned methods is available for reproduction and further\nresearch in both industry and academia.", "AI": {"tldr": "Team GEB's solution for HEFTCom2024 combines stacking-based wind forecasts, solar post-processing, probabilistic aggregation, and stochastic trading to achieve high rankings and revenue in energy forecasting and trading.", "motivation": "Addressing challenges in probabilistic energy forecasts and decision-making amid uncertainties for future energy systems.", "method": "1. Stacking-based wind forecasts from NWPs. 2. Online solar post-processing. 3. Probabilistic aggregation for hybrid generation. 4. Stochastic trading strategy.", "result": "Ranked 3rd in trading, 4th in forecasting, and 1st among student teams in HEFTCom2024, with substantial trading revenue.", "conclusion": "The proposed methods are effective, validated by case studies, and open-source code supports further research."}}
{"id": "2502.19567", "pdf": "https://arxiv.org/pdf/2502.19567", "abs": "https://arxiv.org/abs/2502.19567", "authors": ["Marcin Spoczynski", "Marcela S. Melara", "Sebastian Szyller"], "title": "Atlas: A Framework for ML Lifecycle Provenance & Transparency", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The rapid adoption of open source machine learning (ML) datasets and models\nexposes today's AI applications to critical risks like data poisoning and\nsupply chain attacks across the ML lifecycle. With growing regulatory pressure\nto address these issues through greater transparency, ML model vendors face\nchallenges balancing these requirements against confidentiality for data and\nintellectual property needs. We propose Atlas, a framework that enables fully\nattestable ML pipelines. Atlas leverages open specifications for data and\nsoftware supply chain provenance to collect verifiable records of model\nartifact authenticity and end-to-end lineage metadata. Atlas combines trusted\nhardware and transparency logs to enhance metadata integrity, preserve data\nconfidentiality, and limit unauthorized access during ML pipeline operations,\nfrom training through deployment. Our prototype implementation of Atlas\nintegrates several open-source tools to build an ML lifecycle transparency\nsystem, and assess the practicality of Atlas through two case study ML\npipelines.", "AI": {"tldr": "Atlas is a framework for attestable ML pipelines, ensuring transparency and security while balancing confidentiality.", "motivation": "Address risks like data poisoning and supply chain attacks in ML, while meeting regulatory transparency requirements without compromising data/IP confidentiality.", "method": "Uses open specifications for provenance, trusted hardware, and transparency logs to ensure verifiable records and metadata integrity.", "result": "Prototype integrates open-source tools, tested via case studies, demonstrating practicality.", "conclusion": "Atlas successfully balances transparency and confidentiality in ML pipelines."}}
{"id": "2505.06512", "pdf": "https://arxiv.org/pdf/2505.06512", "abs": "https://arxiv.org/abs/2505.06512", "authors": ["Hang Wang", "Zhi-Qi Cheng", "Chenhao Lin", "Chao Shen", "Lei Zhang"], "title": "HCMA: Hierarchical Cross-model Alignment for Grounded Text-to-Image Generation", "categories": ["cs.CV"], "comment": "10 pages, 4 figures", "summary": "Text-to-image synthesis has progressed to the point where models can generate\nvisually compelling images from natural language prompts. Yet, existing methods\noften fail to reconcile high-level semantic fidelity with explicit spatial\ncontrol, particularly in scenes involving multiple objects, nuanced relations,\nor complex layouts. To bridge this gap, we propose a Hierarchical Cross-Modal\nAlignment (HCMA) framework for grounded text-to-image generation. HCMA\nintegrates two alignment modules into each diffusion sampling step: a global\nmodule that continuously aligns latent representations with textual\ndescriptions to ensure scene-level coherence, and a local module that employs\nbounding-box layouts to anchor objects at specified locations, enabling\nfine-grained spatial control. Extensive experiments on the MS-COCO 2014\nvalidation set show that HCMA surpasses state-of-the-art baselines, achieving a\n0.69 improvement in Frechet Inception Distance (FID) and a 0.0295 gain in CLIP\nScore. These results demonstrate HCMA's effectiveness in faithfully capturing\nintricate textual semantics while adhering to user-defined spatial constraints,\noffering a robust solution for semantically grounded image generation. Our code\nis available at https://github.com/hwang-cs-ime/HCMA.", "AI": {"tldr": "HCMA framework improves text-to-image synthesis by combining global and local alignment for better semantic and spatial control, outperforming baselines in FID and CLIP Score.", "motivation": "Existing methods lack high-level semantic fidelity and explicit spatial control in complex scenes.", "method": "HCMA integrates global (scene-level coherence) and local (bounding-box layouts) alignment modules into diffusion sampling.", "result": "HCMA achieves a 0.69 FID improvement and 0.0295 CLIP Score gain on MS-COCO 2014.", "conclusion": "HCMA effectively captures textual semantics and adheres to spatial constraints, offering robust image generation."}}
{"id": "2505.10398", "pdf": "https://arxiv.org/pdf/2505.10398", "abs": "https://arxiv.org/abs/2505.10398", "authors": ["Alexandre Banks", "Randy Moore", "Sayem Nazmuz Zaman", "Alaa Eldin Abdelaal", "Septimiu E. Salcudean"], "title": "AutoCam: Hierarchical Path Planning for an Autonomous Auxiliary Camera in Surgical Robotics", "categories": ["cs.RO", "cs.HC", "cs.LG", "cs.SY", "eess.SP", "eess.SY", "J.3.2; J.2.7; I.2.9"], "comment": "13 pages, 9 figures", "summary": "Incorporating an autonomous auxiliary camera into robot-assisted minimally\ninvasive surgery (RAMIS) enhances spatial awareness and eliminates manual\nviewpoint control. Existing path planning methods for auxiliary cameras track\ntwo-dimensional surgical features but do not simultaneously account for camera\norientation, workspace constraints, and robot joint limits. This study presents\nAutoCam: an automatic auxiliary camera placement method to improve\nvisualization in RAMIS. Implemented on the da Vinci Research Kit, the system\nuses a priority-based, workspace-constrained control algorithm that combines\nheuristic geometric placement with nonlinear optimization to ensure robust\ncamera tracking. A user study (N=6) demonstrated that the system maintained\n99.84% visibility of a salient feature and achieved a pose error of 4.36 $\\pm$\n2.11 degrees and 1.95 $\\pm$ 5.66 mm. The controller was computationally\nefficient, with a loop time of 6.8 $\\pm$ 12.8 ms. An additional pilot study\n(N=6), where novices completed a Fundamentals of Laparoscopic Surgery training\ntask, suggests that users can teleoperate just as effectively from AutoCam's\nviewpoint as from the endoscope's while still benefiting from AutoCam's\nimproved visual coverage of the scene. These results indicate that an auxiliary\ncamera can be autonomously controlled using the da Vinci patient-side\nmanipulators to track a salient feature, laying the groundwork for new\nmulti-camera visualization methods in RAMIS.", "AI": {"tldr": "AutoCam automates auxiliary camera placement in RAMIS, improving visualization by tracking features while considering orientation, constraints, and joint limits.", "motivation": "Existing methods lack simultaneous consideration of camera orientation, workspace constraints, and robot joint limits, limiting effectiveness in RAMIS.", "method": "AutoCam combines heuristic geometric placement with nonlinear optimization for robust camera tracking, implemented on the da Vinci Research Kit.", "result": "Achieved 99.84% visibility, pose error of 4.36\u00b12.11 degrees and 1.95\u00b15.66 mm, with efficient computation (6.8\u00b112.8 ms loop time).", "conclusion": "AutoCam enables effective autonomous control of auxiliary cameras in RAMIS, paving the way for multi-camera visualization methods."}}
{"id": "2503.05760", "pdf": "https://arxiv.org/pdf/2503.05760", "abs": "https://arxiv.org/abs/2503.05760", "authors": ["Gokul Puthumanaillam", "Melkior Ornik"], "title": "The Lazy Student's Dream: ChatGPT Passing an Engineering Course on Its Own", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "This paper presents a comprehensive investigation into the capability of\nLarge Language Models (LLMs) to successfully complete a semester-long\nundergraduate control systems course. Through evaluation of 115 course\ndeliverables, we assess LLM performance using ChatGPT under a \"minimal effort\"\nprotocol that simulates realistic student usage patterns. The investigation\nemploys a rigorous testing methodology across multiple assessment formats, from\nauto-graded multiple choice questions to complex Python programming tasks and\nlong-form analytical writing. Our analysis provides quantitative insights into\nAI's strengths and limitations in handling mathematical formulations, coding\nchallenges, and theoretical concepts in control systems engineering. The LLM\nachieved a B-grade performance (82.24\\%), approaching but not exceeding the\nclass average (84.99\\%), with strongest results in structured assignments and\ngreatest limitations in open-ended projects. The findings inform discussions\nabout course design adaptation in response to AI advancement, moving beyond\nsimple prohibition towards thoughtful integration of these tools in engineering\neducation. Additional materials including syllabus, examination papers, design\nprojects, and example responses can be found at the project website:\nhttps://gradegpt.github.io.", "AI": {"tldr": "The paper evaluates ChatGPT's performance in a control systems course, achieving a B-grade (82.24%) but falling short of the class average (84.99%). It highlights strengths in structured tasks and weaknesses in open-ended projects, advocating for thoughtful AI integration in education.", "motivation": "To assess the capability of LLMs like ChatGPT in completing a semester-long undergraduate control systems course, simulating realistic student usage patterns.", "method": "Evaluated 115 course deliverables using a \"minimal effort\" protocol, testing multiple assessment formats (multiple choice, Python programming, analytical writing).", "result": "ChatGPT scored 82.24%, excelling in structured tasks but struggling with open-ended projects.", "conclusion": "The findings suggest adapting course design to thoughtfully integrate AI tools in engineering education, moving beyond prohibition."}}
{"id": "2505.07119", "pdf": "https://arxiv.org/pdf/2505.07119", "abs": "https://arxiv.org/abs/2505.07119", "authors": ["Arianna Stropeni", "Francesco Borsatti", "Manuel Barusco", "Davide Dalle Pezze", "Marco Fabris", "Gian Antonio Susto"], "title": "Towards Scalable IoT Deployment for Visual Anomaly Detection via Efficient Compression", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual Anomaly Detection (VAD) is a key task in industrial settings, where\nminimizing operational costs is essential. Deploying deep learning models\nwithin Internet of Things (IoT) environments introduces specific challenges due\nto limited computational power and bandwidth of edge devices. This study\ninvestigates how to perform VAD effectively under such constraints by\nleveraging compact, efficient processing strategies. We evaluate several data\ncompression techniques, examining the tradeoff between system latency and\ndetection accuracy. Experiments on the MVTec AD benchmark demonstrate that\nsignificant compression can be achieved with minimal loss in anomaly detection\nperformance compared to uncompressed data. Current results show up to 80%\nreduction in end-to-end inference time, including edge processing,\ntransmission, and server computation.", "AI": {"tldr": "The paper explores efficient Visual Anomaly Detection (VAD) in IoT settings, achieving 80% faster inference with minimal accuracy loss using compression techniques.", "motivation": "To address challenges of deploying deep learning for VAD in resource-constrained IoT environments.", "method": "Evaluated data compression techniques to balance latency and accuracy, tested on the MVTec AD benchmark.", "result": "Achieved up to 80% reduction in inference time with minimal performance loss.", "conclusion": "Compact processing strategies enable effective VAD in IoT, optimizing cost and performance."}}
{"id": "2505.10444", "pdf": "https://arxiv.org/pdf/2505.10444", "abs": "https://arxiv.org/abs/2505.10444", "authors": ["Miguel Aguilera", "Sosuke Ito", "Artemy Kolchinsky"], "title": "Inferring entropy production in many-body systems using nonequilibrium MaxEnt", "categories": ["cond-mat.stat-mech", "cs.LG", "nlin.AO", "q-bio.NC"], "comment": null, "summary": "We propose a method for inferring entropy production (EP) in high-dimensional\nstochastic systems, including many-body systems and non-Markovian systems with\nlong memory. Standard techniques for estimating EP become intractable in such\nsystems due to computational and statistical limitations. We infer\ntrajectory-level EP and lower bounds on average EP by exploiting a\nnonequilibrium analogue of the Maximum Entropy principle, along with convex\nduality. Our approach uses only samples of trajectory observables (such as\nspatiotemporal correlation functions). It does not require reconstruction of\nhigh-dimensional probability distributions or rate matrices, nor any special\nassumptions such as discrete states or multipartite dynamics. It may be used to\ncompute a hierarchical decomposition of EP, reflecting contributions from\ndifferent kinds of interactions, and it has an intuitive physical\ninterpretation as a thermodynamic uncertainty relation. We demonstrate its\nnumerical performance on a disordered nonequilibrium spin model with 1000 spins\nand a large neural spike-train dataset.", "AI": {"tldr": "Proposes a method to infer entropy production in high-dimensional stochastic systems using a nonequilibrium Maximum Entropy principle and convex duality, avoiding intractable computations.", "motivation": "Standard techniques for estimating entropy production fail in high-dimensional systems due to computational and statistical challenges.", "method": "Uses trajectory observables and convex duality to infer entropy production without reconstructing high-dimensional distributions or rate matrices.", "result": "Demonstrated effectiveness on a 1000-spin disordered model and a neural spike-train dataset.", "conclusion": "The method provides an intuitive thermodynamic uncertainty relation and hierarchical EP decomposition, applicable to complex systems."}}
{"id": "2503.07338", "pdf": "https://arxiv.org/pdf/2503.07338", "abs": "https://arxiv.org/abs/2503.07338", "authors": ["Haoran Xu", "Peixi Peng", "Guang Tan", "Yiqian Chang", "Yisen Zhao", "Yonghong Tian"], "title": "Temporal Triplane Transformers as Occupancy World Models", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "World models aim to learn or construct representations of the environment\nthat enable the prediction of future scenes, thereby supporting intelligent\nmotion planning. However, existing models often struggle to produce\nfine-grained predictions and to operate in real time. In this work, we propose\nT$^3$Former, a novel 4D occupancy world model for autonomous driving.\nT$^3$Former begins by pre-training a compact {\\em triplane} representation that\nefficiently encodes 3D occupancy. It then extracts multi-scale temporal motion\nfeatures from historical triplanes and employs an autoregressive approach to\niteratively predict future triplane changes. Finally, these triplane changes\nare combined with previous states to decode future occupancy and ego-motion\ntrajectories. Experimental results show that T$^3$Former achieves 1.44$\\times$\nspeedup (26 FPS), improves mean IoU to 36.09, and reduces mean absolute\nplanning error to 1.0 meters. Demos are available in the supplementary\nmaterial.", "AI": {"tldr": "T$^3$Former is a 4D occupancy world model for autonomous driving that improves prediction accuracy and real-time performance.", "motivation": "Existing world models struggle with fine-grained predictions and real-time operation, limiting their effectiveness in autonomous driving.", "method": "T$^3$Former pre-trains a triplane representation for 3D occupancy, extracts multi-scale temporal motion features, and uses autoregressive prediction for future triplane changes.", "result": "Achieves 1.44\u00d7 speedup (26 FPS), 36.09 mean IoU, and 1.0 meters mean absolute planning error.", "conclusion": "T$^3$Former effectively addresses limitations of existing models, offering improved performance for autonomous driving."}}
{"id": "2505.07344", "pdf": "https://arxiv.org/pdf/2505.07344", "abs": "https://arxiv.org/abs/2505.07344", "authors": ["Yuan Zhang", "Jiacheng Jiang", "Guoqing Ma", "Zhiying Lu", "Haoyang Huang", "Jianlong Yuan", "Nan Duan"], "title": "Generative Pre-trained Autoregressive Diffusion Transformer", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.", "AI": {"tldr": "GPDiT combines diffusion and autoregressive modeling for high-quality long-range video synthesis in continuous latent space, improving motion dynamics and semantic consistency.", "motivation": "To unify diffusion and autoregressive modeling for better video synthesis and representation in continuous space.", "method": "GPDiT predicts future latent frames autoregressively using diffusion loss, with causal attention and time-conditioning mechanisms for efficiency.", "result": "GPDiT excels in video generation quality, representation, and few-shot learning.", "conclusion": "GPDiT is a promising framework for continuous-space video modeling."}}
{"id": "2505.10448", "pdf": "https://arxiv.org/pdf/2505.10448", "abs": "https://arxiv.org/abs/2505.10448", "authors": ["Conor Rosato", "Harvinder Lehal", "Simon Maskell", "Lee Devlin", "Malcolm Strens"], "title": "Efficient MCMC Sampling with Expensive-to-Compute and Irregular Likelihoods", "categories": ["stat.ML", "cs.LG"], "comment": "45 pages", "summary": "Bayesian inference with Markov Chain Monte Carlo (MCMC) is challenging when\nthe likelihood function is irregular and expensive to compute. We explore\nseveral sampling algorithms that make use of subset evaluations to reduce\ncomputational overhead. We adapt the subset samplers for this setting where\ngradient information is not available or is unreliable. To achieve this, we\nintroduce data-driven proxies in place of Taylor expansions and define a novel\ncomputation-cost aware adaptive controller. We undertake an extensive\nevaluation for a challenging disease modelling task and a configurable task\nwith similar irregularity in the likelihood surface. We find our improved\nversion of Hierarchical Importance with Nested Training Samples (HINTS), with\nadaptive proposals and a data-driven proxy, obtains the best sampling error in\na fixed computational budget. We conclude that subset evaluations can provide\ncheap and naturally-tempered exploration, while a data-driven proxy can\npre-screen proposals successfully in explored regions of the state space. These\ntwo elements combine through hierarchical delayed acceptance to achieve\nefficient, exact sampling.", "AI": {"tldr": "The paper explores MCMC sampling algorithms using subset evaluations and data-driven proxies to handle irregular, expensive likelihood functions, achieving efficient sampling.", "motivation": "Bayesian inference with MCMC is difficult for irregular, expensive likelihood functions, requiring solutions to reduce computational overhead.", "method": "Adapts subset samplers with data-driven proxies and a computation-cost aware adaptive controller, tested on disease modeling and configurable tasks.", "result": "Improved HINTS with adaptive proposals and data-driven proxy achieves the best sampling error under fixed computational budget.", "conclusion": "Subset evaluations and data-driven proxies enable efficient, exact sampling by combining cheap exploration and pre-screening."}}
{"id": "2503.08604", "pdf": "https://arxiv.org/pdf/2503.08604", "abs": "https://arxiv.org/abs/2503.08604", "authors": ["Dongping Li", "Tielong Cai", "Tianci Tang", "Wenhao Chai", "Katherine Rose Driggs-Campbell", "Gaoang Wang"], "title": "EMMOE: A Comprehensive Benchmark for Embodied Mobile Manipulation in Open Environments", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Developing autonomous home robots controlled by natural language has long\nbeen a pursuit of humanity. While advancements in large language models (LLMs)\nand embodied intelligence make this goal closer, several challenges persist:\nthe lack of a unified benchmark for more complex robot tasks, limited\nevaluation methods and metrics, data incompatibility between LLMs and mobile\nmanipulation trajectories. To address these issues, we propose Embodied Mobile\nManipulation in Open Environments (EMMOE), a benchmark that requires agents to\ninterpret user instructions and execute long-horizon everyday tasks in\ncontinuous space. EMMOE seamlessly integrates high-level and low-level embodied\ntasks into a unified framework, along with three new metrics for more diverse\nassessment. Additionally, we collect~\\dataset, which features in various task\nattributes, detailed process annotations, re-plans after failures, and two\nsub-datasets for LLM training. Furthermore, we design~\\model, a sophisticated\nagent system consists of LLM with Direct Preference Optimization (DPO), light\nweighted navigation and manipulation models, and multiple error detection\nmechanisms. Finally, we demonstrate~\\model's performance and evaluations of\ndifferent models and policies.", "AI": {"tldr": "The paper introduces EMMOE, a benchmark for autonomous home robots, addressing challenges like unified benchmarks, evaluation methods, and data compatibility. It includes new metrics, a dataset, and a sophisticated agent system (LLM with DPO) for improved performance.", "motivation": "To overcome challenges in developing autonomous home robots, such as lack of unified benchmarks, limited evaluation methods, and data incompatibility between LLMs and robot tasks.", "method": "Proposes EMMOE, a benchmark integrating high-level and low-level tasks, with new metrics and a dataset. Introduces a sophisticated agent system combining LLM with DPO, navigation models, and error detection.", "result": "Demonstrates the performance of the proposed model and evaluates different models and policies.", "conclusion": "EMMOE provides a comprehensive framework for advancing autonomous home robots, with improved benchmarks, metrics, and agent systems."}}
{"id": "2505.08517", "pdf": "https://arxiv.org/pdf/2505.08517", "abs": "https://arxiv.org/abs/2505.08517", "authors": ["Yifan Li", "Alan W Pang", "Jo Woon Chong"], "title": "A Deep Learning-Driven Inhalation Injury Grading Assistant Using Bronchoscopy Images", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Inhalation injuries present a challenge in clinical diagnosis and grading due\nto Conventional grading methods such as the Abbreviated Injury Score (AIS)\nbeing subjective and lacking robust correlation with clinical parameters like\nmechanical ventilation duration and patient mortality. This study introduces a\nnovel deep learning-based diagnosis assistant tool for grading inhalation\ninjuries using bronchoscopy images to overcome subjective variability and\nenhance consistency in severity assessment. Our approach leverages data\naugmentation techniques, including graphic transformations, Contrastive\nUnpaired Translation (CUT), and CycleGAN, to address the scarcity of medical\nimaging data. We evaluate the classification performance of two deep learning\nmodels, GoogLeNet and Vision Transformer (ViT), across a dataset significantly\nexpanded through these augmentation methods. The results demonstrate GoogLeNet\ncombined with CUT as the most effective configuration for grading inhalation\ninjuries through bronchoscopy images and achieves a classification accuracy of\n97.8%. The histograms and frequency analysis evaluations reveal variations\ncaused by the augmentation CUT with distribution changes in the histogram and\ntexture details of the frequency spectrum. PCA visualizations underscore the\nCUT substantially enhances class separability in the feature space. Moreover,\nGrad-CAM analyses provide insight into the decision-making process; mean\nintensity for CUT heatmaps is 119.6, which significantly exceeds 98.8 of the\noriginal datasets. Our proposed tool leverages mechanical ventilation periods\nas a novel grading standard, providing comprehensive diagnostic support.", "AI": {"tldr": "A deep learning tool using bronchoscopy images and data augmentation (CUT, CycleGAN) improves inhalation injury grading, achieving 97.8% accuracy with GoogLeNet.", "motivation": "Current grading methods (e.g., AIS) are subjective and poorly correlate with clinical outcomes like ventilation duration and mortality.", "method": "Uses GoogLeNet and ViT models with data augmentation (graphic transformations, CUT, CycleGAN) on bronchoscopy images.", "result": "GoogLeNet with CUT achieves 97.8% accuracy; CUT enhances feature separability and decision-making (higher heatmap intensity).", "conclusion": "The tool offers objective, consistent grading and diagnostic support, validated by clinical parameters."}}
{"id": "2505.10466", "pdf": "https://arxiv.org/pdf/2505.10466", "abs": "https://arxiv.org/abs/2505.10466", "authors": ["Juehang Qin", "Shixiao Liang", "Christopher Tunnell"], "title": "FlowVAT: Normalizing Flow Variational Inference with Affine-Invariant Tempering", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "10 pages, 5 figures, and 2 tables in main text, two appendices", "summary": "Multi-modal and high-dimensional posteriors present significant challenges\nfor variational inference, causing mode-seeking behavior and collapse despite\nthe theoretical expressiveness of normalizing flows. Traditional annealing\nmethods require temperature schedules and hyperparameter tuning, falling short\nof the goal of truly black-box variational inference. We introduce FlowVAT, a\nconditional tempering approach for normalizing flow variational inference that\naddresses these limitations. Our method tempers both the base and target\ndistributions simultaneously, maintaining affine-invariance under tempering. By\nconditioning the normalizing flow on temperature, we leverage overparameterized\nneural networks' generalization capabilities to train a single flow\nrepresenting the posterior across a range of temperatures. This preserves modes\nidentified at higher temperatures when sampling from the variational posterior\nat $T = 1$, mitigating standard variational methods' mode-seeking behavior. In\nexperiments with 2, 10, and 20 dimensional multi-modal distributions, FlowVAT\noutperforms traditional and adaptive annealing methods, finding more modes and\nachieving better ELBO values, particularly in higher dimensions where existing\napproaches fail. Our method requires minimal hyperparameter tuning and does not\nrequire an annealing schedule, advancing toward fully-automatic black-box\nvariational inference for complicated posteriors.", "AI": {"tldr": "FlowVAT introduces a conditional tempering method for variational inference with normalizing flows, addressing mode collapse and outperforming traditional annealing methods.", "motivation": "Multi-modal and high-dimensional posteriors challenge variational inference, causing mode-seeking behavior and collapse, despite normalizing flows' expressiveness.", "method": "FlowVAT tempers base and target distributions simultaneously, conditioning the flow on temperature to preserve modes and avoid hyperparameter tuning.", "result": "FlowVAT outperforms traditional methods in 2D, 10D, and 20D multi-modal distributions, finding more modes and achieving better ELBO values.", "conclusion": "FlowVAT advances toward fully-automatic black-box variational inference, requiring minimal tuning and no annealing schedule."}}
{"id": "2503.11572", "pdf": "https://arxiv.org/pdf/2503.11572", "abs": "https://arxiv.org/abs/2503.11572", "authors": ["Messi H. J. Lee", "Calvin K. Lai"], "title": "Implicit Bias-Like Patterns in Reasoning Models", "categories": ["cs.CY", "cs.AI"], "comment": "8 pages, 2 figures", "summary": "Implicit bias refers to automatic mental processes that shape perceptions,\njudgments, and behaviors. Previous research on \"implicit bias\" in LLMs focused\nprimarily on outputs rather than the processes underlying the outputs. We\npresent the Reasoning Model Implicit Association Test (RM-IAT) to study\nimplicit bias-like processing in reasoning models, which are LLMs using\nstep-by-step reasoning for complex tasks. Using RM-IAT, we find o3-mini and\nDeepSeek R1 require more tokens when processing association-incompatible\ninformation, mirroring human implicit bias patterns. Conversely, Claude 3.7\nSonnet displays reversed patterns for race and gender tests, requiring more\ntokens for association-compatible information. This reversal appears linked to\ndifferences in safety mechanism activation, increasing deliberation in\nsensitive contexts. These findings suggest AI systems can exhibit processing\npatterns analogous to both human implicit bias and bias correction mechanisms.", "AI": {"tldr": "The paper introduces RM-IAT to study implicit bias-like processing in reasoning models, revealing varied token usage patterns in AI systems akin to human implicit bias and correction mechanisms.", "motivation": "To investigate implicit bias-like processing in reasoning models (LLMs) beyond output analysis, focusing on underlying cognitive-like patterns.", "method": "Developed the Reasoning Model Implicit Association Test (RM-IAT) to measure token usage during association-incompatible vs. compatible tasks in reasoning models.", "result": "o3-mini and DeepSeek R1 showed human-like implicit bias patterns (more tokens for incompatible info), while Claude 3.7 Sonnet displayed reversed patterns, linked to safety mechanisms.", "conclusion": "AI systems can mimic human implicit bias and bias correction, highlighting the role of safety mechanisms in shaping processing patterns."}}
{"id": "2505.08605", "pdf": "https://arxiv.org/pdf/2505.08605", "abs": "https://arxiv.org/abs/2505.08605", "authors": ["Zhe Li", "Hadrien Reynaud", "Bernhard Kainz"], "title": "Leveraging Multi-Modal Information to Enhance Dataset Distillation", "categories": ["cs.CV"], "comment": "10 pages", "summary": "Dataset distillation aims to create a compact and highly representative\nsynthetic dataset that preserves the knowledge of a larger real dataset. While\nexisting methods primarily focus on optimizing visual representations,\nincorporating additional modalities and refining object-level information can\nsignificantly improve the quality of distilled datasets. In this work, we\nintroduce two key enhancements to dataset distillation: caption-guided\nsupervision and object-centric masking. To integrate textual information, we\npropose two strategies for leveraging caption features: the feature\nconcatenation, where caption embeddings are fused with visual features at the\nclassification stage, and caption matching, which introduces a caption-based\nalignment loss during training to ensure semantic coherence between real and\nsynthetic data. Additionally, we apply segmentation masks to isolate target\nobjects and remove background distractions, introducing two loss functions\ndesigned for object-centric learning: masked feature alignment loss and masked\ngradient matching loss. Comprehensive evaluations demonstrate that integrating\ncaption-based guidance and object-centric masking enhances dataset\ndistillation, leading to synthetic datasets that achieve superior performance\non downstream tasks.", "AI": {"tldr": "The paper introduces caption-guided supervision and object-centric masking to improve dataset distillation, enhancing synthetic dataset quality for downstream tasks.", "motivation": "Existing dataset distillation methods focus on visual representations, but incorporating additional modalities (like text) and refining object-level information can improve results.", "method": "Proposes two caption-guided strategies (feature concatenation and caption matching) and object-centric masking with two loss functions (masked feature alignment and masked gradient matching).", "result": "Integrating caption-based guidance and object-centric masking improves dataset distillation, yielding better performance on downstream tasks.", "conclusion": "The enhancements (caption-guided supervision and object-centric masking) significantly improve the quality and effectiveness of distilled datasets."}}
{"id": "2505.10498", "pdf": "https://arxiv.org/pdf/2505.10498", "abs": "https://arxiv.org/abs/2505.10498", "authors": ["Sakshi Arya"], "title": "Batched Nonparametric Bandits via k-Nearest Neighbor UCB", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH", "68T05, 62L05, 62G08, 68Q32", "F.2.2; I.2.6"], "comment": "25 pages, 6 figures", "summary": "We study sequential decision-making in batched nonparametric contextual\nbandits, where actions are selected over a finite horizon divided into a small\nnumber of batches. Motivated by constraints in domains such as medicine and\nmarketing -- where online feedback is limited -- we propose a nonparametric\nalgorithm that combines adaptive k-nearest neighbor (k-NN) regression with the\nupper confidence bound (UCB) principle. Our method, BaNk-UCB, is fully\nnonparametric, adapts to the context dimension, and is simple to implement.\nUnlike prior work relying on parametric or binning-based estimators, BaNk-UCB\nuses local geometry to estimate rewards and adaptively balances exploration and\nexploitation. We provide near-optimal regret guarantees under standard\nLipschitz smoothness and margin assumptions, using a theoretically motivated\nbatch schedule that balances regret across batches and achieves minimax-optimal\nrates. Empirical evaluations on synthetic and real-world datasets demonstrate\nthat BaNk-UCB consistently outperforms binning-based baselines.", "AI": {"tldr": "BaNk-UCB is a nonparametric algorithm for batched contextual bandits, combining k-NN regression with UCB for near-optimal regret guarantees.", "motivation": "Addresses constraints in domains like medicine and marketing where online feedback is limited.", "method": "Combines adaptive k-NN regression with UCB, leveraging local geometry for reward estimation and adaptive exploration-exploitation balance.", "result": "Achieves near-optimal regret under Lipschitz smoothness and margin assumptions, outperforming binning-based baselines empirically.", "conclusion": "BaNk-UCB is effective, simple, and adaptable, offering theoretical and practical advantages over prior methods."}}
{"id": "2504.06533", "pdf": "https://arxiv.org/pdf/2504.06533", "abs": "https://arxiv.org/abs/2504.06533", "authors": ["Zhouyang Liu", "Ning Liu", "Yixin Chen", "Jiezhong He", "Dongsheng Li"], "title": "Flexible Graph Similarity Computation With A Proactive Optimization Strategy", "categories": ["cs.LG", "cs.AI", "cs.DS"], "comment": null, "summary": "Graph Edit Distance (GED) offers a principled and flexible measure of graph\nsimilarity, as it quantifies the minimum cost needed to transform one graph\ninto another with customizable edit operation costs. Despite recent\nlearning-based efforts to approximate GED via vector space representations,\nexisting methods struggle with adapting to varying operation costs.\nFurthermore, they suffer from inefficient, reactive mapping refinements due to\nreliance on isolated node-level distance as guidance. To address these issues,\nwe propose GEN, a novel learning-based approach for flexible GED approximation.\nGEN addresses the varying costs adaptation by integrating operation costs prior\nto match establishment, enabling mappings to dynamically adapt to cost\nvariations. Furthermore, GEN introduces a proactive guidance optimization\nstrategy that captures graph-level dependencies between matches, allowing\ninformed matching decisions in a single step without costly iterative\nrefinements. Extensive evaluations on real-world and synthetic datasets\ndemonstrate that GEN achieves up to 37.8% reduction in GED approximation error\nand 72.7% reduction in inference time compared with state-of-the-art methods,\nwhile consistently maintaining robustness under diverse cost settings and graph\nsizes.", "AI": {"tldr": "GEN is a learning-based method for flexible Graph Edit Distance (GED) approximation, improving accuracy and efficiency by integrating operation costs upfront and using proactive guidance.", "motivation": "Existing GED approximation methods struggle with adapting to varying operation costs and rely on inefficient reactive refinements.", "method": "GEN integrates operation costs prior to match establishment and uses proactive guidance to capture graph-level dependencies, enabling dynamic adaptation and informed matching.", "result": "GEN reduces GED approximation error by up to 37.8% and inference time by 72.7% compared to state-of-the-art methods.", "conclusion": "GEN outperforms existing methods in accuracy, efficiency, and robustness under diverse cost settings and graph sizes."}}
{"id": "2505.09178", "pdf": "https://arxiv.org/pdf/2505.09178", "abs": "https://arxiv.org/abs/2505.09178", "authors": ["Yitao Zhu", "Yuan Yin", "Zhenrong Shen", "Zihao Zhao", "Haiyu Song", "Sheng Wang", "Dinggang Shen", "Qian Wang"], "title": "UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System", "categories": ["cs.CV"], "comment": "14 pages", "summary": "The growing complexity and scale of visual model pre-training have made\ndeveloping and deploying multi-task computer-aided diagnosis (CAD) systems\nincreasingly challenging and resource-intensive. Furthermore, the medical\nimaging community lacks an open-source CAD platform to enable the rapid\ncreation of efficient and extendable diagnostic models. To address these\nissues, we propose UniCAD, a unified architecture that leverages the robust\ncapabilities of pre-trained vision foundation models to seamlessly handle both\n2D and 3D medical images while requiring only minimal task-specific parameters.\nUniCAD introduces two key innovations: (1) Efficiency: A low-rank adaptation\nstrategy is employed to adapt a pre-trained visual model to the medical image\ndomain, achieving performance on par with fully fine-tuned counterparts while\nintroducing only 0.17% trainable parameters. (2) Plug-and-Play: A modular\narchitecture that combines a frozen foundation model with multiple\nplug-and-play experts, enabling diverse tasks and seamless functionality\nexpansion. Building on this unified CAD architecture, we establish an\nopen-source platform where researchers can share and access lightweight CAD\nexperts, fostering a more equitable and efficient research ecosystem.\nComprehensive experiments across 12 diverse medical datasets demonstrate that\nUniCAD consistently outperforms existing methods in both accuracy and\ndeployment efficiency. The source code and project page are available at\nhttps://mii-laboratory.github.io/UniCAD/.", "AI": {"tldr": "UniCAD is a unified architecture for multi-task CAD systems, leveraging pre-trained vision models for efficient and extendable medical image diagnosis with minimal task-specific parameters.", "motivation": "Addressing the challenges of complexity, resource intensity, and lack of open-source platforms in developing multi-task CAD systems for medical imaging.", "method": "Uses a low-rank adaptation strategy for domain adaptation and a modular plug-and-play architecture with frozen foundation models and task-specific experts.", "result": "Outperforms existing methods in accuracy and deployment efficiency across 12 diverse medical datasets.", "conclusion": "UniCAD provides an open-source platform for efficient, extendable, and equitable CAD research, demonstrating superior performance."}}
{"id": "2405.00922", "pdf": "https://arxiv.org/pdf/2405.00922", "abs": "https://arxiv.org/abs/2405.00922", "authors": ["Nooshin Yousefzadeh", "Rahul Sengupta", "Yashaswi Karnati", "Anand Rangarajan", "Sanjay Ranka"], "title": "MTDT: A Multi-Task Deep Learning Digital Twin", "categories": ["cs.LG"], "comment": "8 pages, 2 figures, 4 tables", "summary": "Traffic congestion has significant impacts on both the economy and the\nenvironment. Measures of Effectiveness (MOEs) have long been the standard for\nevaluating traffic intersections' level of service and operational efficiency.\nHowever, the scarcity of traditional high-resolution loop detector data (ATSPM)\npresents challenges in accurately measuring MOEs or capturing the intricate\nspatiotemporal characteristics inherent in urban intersection traffic. To\naddress this challenge, we present a comprehensive intersection traffic flow\nsimulation that utilizes a multi-task learning paradigm. This approach combines\ngraph convolutions for primary estimating lane-wise exit and inflow with time\nseries convolutions for secondary assessing multi-directional queue lengths and\ntravel time distribution through any arbitrary urban traffic intersection.\nCompared to existing deep learning methodologies, the proposed Multi-Task Deep\nLearning Digital Twin (MTDT) distinguishes itself through its adaptability to\nlocal temporal and spatial features, such as signal timing plans, intersection\ntopology, driving behaviors, and turning movement counts. We also show the\nbenefit of multi-task learning in the effectiveness of individual traffic\nsimulation tasks. Furthermore, our approach facilitates sequential computation\nand provides complete parallelization through GPU implementation. This not only\nstreamlines the computational process but also enhances scalability and\nperformance.", "AI": {"tldr": "A multi-task deep learning model (MTDT) is proposed to simulate urban intersection traffic flow, addressing data scarcity and capturing spatiotemporal features better than traditional methods.", "motivation": "Traffic congestion impacts economy and environment, but traditional MOEs and loop detector data are insufficient for accurate evaluation.", "method": "Uses multi-task learning with graph and time series convolutions to estimate lane-wise flows, queue lengths, and travel times.", "result": "MTDT adapts to local features (signal timing, topology, etc.) and outperforms existing deep learning methods, with GPU-enabled scalability.", "conclusion": "The MTDT approach enhances traffic simulation accuracy and computational efficiency, offering a scalable solution for urban intersections."}}
{"id": "2504.08210", "pdf": "https://arxiv.org/pdf/2504.08210", "abs": "https://arxiv.org/abs/2504.08210", "authors": ["Erica van der Sar", "Alessandro Zocca", "Sandjai Bhulai"], "title": "Optimizing Power Grid Topologies with Reinforcement Learning: A Survey of Methods and Challenges", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "stat.ML"], "comment": "60 pages, 26 figures, preprint", "summary": "Power grid operation is becoming increasingly complex due to the rising\nintegration of renewable energy sources and the need for more adaptive control\nstrategies. Reinforcement Learning (RL) has emerged as a promising approach to\npower network control (PNC), offering the potential to enhance decision-making\nin dynamic and uncertain environments. The Learning To Run a Power Network\n(L2RPN) competitions have played a key role in accelerating research by\nproviding standardized benchmarks and problem formulations, leading to rapid\nadvancements in RL-based methods. This survey provides a comprehensive and\nstructured overview of RL applications for power grid topology optimization,\ncategorizing existing techniques, highlighting key design choices, and\nidentifying gaps in current research. Additionally, we present a comparative\nnumerical study evaluating the impact of commonly applied RL-based methods,\noffering insights into their practical effectiveness. By consolidating existing\nresearch and outlining open challenges, this survey aims to provide a\nfoundation for future advancements in RL-driven power grid optimization.", "AI": {"tldr": "A survey on RL applications in power grid optimization, focusing on L2RPN competitions, categorizing techniques, and evaluating practical effectiveness.", "motivation": "The complexity of power grid operation due to renewable energy integration and adaptive control needs drives the exploration of RL for improved decision-making.", "method": "The survey categorizes RL techniques for power grid topology optimization, highlights design choices, and conducts a comparative numerical study.", "result": "Provides insights into the effectiveness of RL-based methods and identifies gaps in current research.", "conclusion": "Aims to consolidate research and guide future advancements in RL-driven power grid optimization."}}
{"id": "2405.18418", "pdf": "https://arxiv.org/pdf/2405.18418", "abs": "https://arxiv.org/abs/2405.18418", "authors": ["Nicklas Hansen", "Jyothir S V", "Vlad Sobal", "Yann LeCun", "Xiaolong Wang", "Hao Su"], "title": "Hierarchical World Models as Visual Whole-Body Humanoid Controllers", "categories": ["cs.LG", "cs.CV", "cs.RO"], "comment": "Code and videos at https://nicklashansen.com/rlpuppeteer", "summary": "Whole-body control for humanoids is challenging due to the high-dimensional\nnature of the problem, coupled with the inherent instability of a bipedal\nmorphology. Learning from visual observations further exacerbates this\ndifficulty. In this work, we explore highly data-driven approaches to visual\nwhole-body humanoid control based on reinforcement learning, without any\nsimplifying assumptions, reward design, or skill primitives. Specifically, we\npropose a hierarchical world model in which a high-level agent generates\ncommands based on visual observations for a low-level agent to execute, both of\nwhich are trained with rewards. Our approach produces highly performant control\npolicies in 8 tasks with a simulated 56-DoF humanoid, while synthesizing\nmotions that are broadly preferred by humans.", "AI": {"tldr": "A hierarchical world model for visual whole-body humanoid control using reinforcement learning, achieving high performance in 8 tasks with a 56-DoF humanoid.", "motivation": "Addressing the challenges of high-dimensionality and instability in humanoid control, especially when learning from visual observations.", "method": "Proposes a hierarchical world model with high-level and low-level agents trained with rewards, without simplifying assumptions or skill primitives.", "result": "Produces performant control policies and human-preferred motions in simulated tasks.", "conclusion": "Demonstrates the effectiveness of data-driven reinforcement learning for complex humanoid control."}}
{"id": "2408.09840", "pdf": "https://arxiv.org/pdf/2408.09840", "abs": "https://arxiv.org/abs/2408.09840", "authors": ["Joe Watson", "Chen Song", "Oliver Weeger", "Theo Gruner", "An T. Le", "Kay Pompetzki", "Ahmed Hendawy", "Oleg Arenz", "Will Trojak", "Miles Cranmer", "Carlo D'Eramo", "Fabian B\u00fclow", "Tanmay Goyal", "Jan Peters", "Martin W. Hoffman"], "title": "Machine Learning with Physics Knowledge for Prediction: A Survey", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.comp-ph"], "comment": "61 pages, 8 figures, 2 tables. Accepted at the Transactions of\n  Machine Learning Research (TMLR)", "summary": "This survey examines the broad suite of methods and models for combining\nmachine learning with physics knowledge for prediction and forecast, with a\nfocus on partial differential equations. These methods have attracted\nsignificant interest due to their potential impact on advancing scientific\nresearch and industrial practices by improving predictive models with small- or\nlarge-scale datasets and expressive predictive models with useful inductive\nbiases. The survey has two parts. The first considers incorporating physics\nknowledge on an architectural level through objective functions, structured\npredictive models, and data augmentation. The second considers data as physics\nknowledge, which motivates looking at multi-task, meta, and contextual learning\nas an alternative approach to incorporating physics knowledge in a data-driven\nfashion. Finally, we also provide an industrial perspective on the application\nof these methods and a survey of the open-source ecosystem for physics-informed\nmachine learning.", "AI": {"tldr": "A survey on combining machine learning with physics knowledge, especially for PDEs, covering architectural and data-driven methods, with industrial applications and open-source tools.", "motivation": "To improve predictive models in scientific and industrial settings by integrating physics knowledge with machine learning, addressing small- or large-scale datasets and inductive biases.", "method": "Two-part approach: 1) Architectural incorporation via objective functions, structured models, and data augmentation; 2) Data-driven methods like multi-task, meta, and contextual learning.", "result": "Overview of methods for physics-informed machine learning, highlighting their potential impact and practical applications.", "conclusion": "The survey provides a comprehensive guide to integrating physics with machine learning, emphasizing both theoretical and practical advancements, including industrial use and open-source resources."}}
{"id": "2504.19139", "pdf": "https://arxiv.org/pdf/2504.19139", "abs": "https://arxiv.org/abs/2504.19139", "authors": ["Yun Qu", "Qi Cheems Wang", "Yixiu Mao", "Yiqin Lv", "Xiangyang Ji"], "title": "Fast and Robust: Task Sampling with Posterior and Diversity Synergies for Adaptive Decision-Makers in Randomized Environments", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "ICML 2025", "summary": "Task robust adaptation is a long-standing pursuit in sequential\ndecision-making. Some risk-averse strategies, e.g., the conditional\nvalue-at-risk principle, are incorporated in domain randomization or meta\nreinforcement learning to prioritize difficult tasks in optimization, which\ndemand costly intensive evaluations. The efficiency issue prompts the\ndevelopment of robust active task sampling to train adaptive policies, where\nrisk-predictive models are used to surrogate policy evaluation. This work\ncharacterizes the optimization pipeline of robust active task sampling as a\nMarkov decision process, posits theoretical and practical insights, and\nconstitutes robustness concepts in risk-averse scenarios. Importantly, we\npropose an easy-to-implement method, referred to as Posterior and Diversity\nSynergized Task Sampling (PDTS), to accommodate fast and robust sequential\ndecision-making. Extensive experiments show that PDTS unlocks the potential of\nrobust active task sampling, significantly improves the zero-shot and few-shot\nadaptation robustness in challenging tasks, and even accelerates the learning\nprocess under certain scenarios. Our project website is at\nhttps://thu-rllab.github.io/PDTS_project_page.", "AI": {"tldr": "The paper proposes PDTS, a method for robust active task sampling in sequential decision-making, improving adaptation robustness and learning efficiency.", "motivation": "Addressing the efficiency and robustness challenges in task adaptation, particularly in risk-averse scenarios, by prioritizing difficult tasks without costly evaluations.", "method": "Introduces PDTS, a method combining posterior and diversity synergized task sampling, framed as a Markov decision process for optimization.", "result": "PDTS enhances zero-shot and few-shot adaptation robustness and accelerates learning in challenging tasks.", "conclusion": "PDTS effectively addresses robustness and efficiency in sequential decision-making, with practical benefits demonstrated in experiments."}}
{"id": "2411.16782", "pdf": "https://arxiv.org/pdf/2411.16782", "abs": "https://arxiv.org/abs/2411.16782", "authors": ["Chuan Liu", "Huanran Chen", "Yichi Zhang", "Yinpeng Dong", "Jun Zhu"], "title": "Scaling Laws for Black box Adversarial Attacks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Adversarial examples usually exhibit good cross-model transferability,\nenabling attacks on black-box models with limited information about their\narchitectures and parameters, which are highly threatening in commercial\nblack-box scenarios. Model ensembling is an effective strategy to improve the\ntransferability of adversarial examples by attacking multiple surrogate models.\nHowever, since prior studies usually adopt few models in the ensemble, there\nremains an open question of whether scaling the number of models can further\nimprove black-box attacks. Inspired by the scaling law of large foundation\nmodels, we investigate the scaling laws of black-box adversarial attacks in\nthis work. Through theoretical analysis and empirical evaluations, we conclude\nwith clear scaling laws that using more surrogate models enhances adversarial\ntransferability. Comprehensive experiments verify the claims on standard image\nclassifiers, diverse defended models and multimodal large language models using\nvarious adversarial attack methods. Specifically, by scaling law, we achieve\n90%+ transfer attack success rate on even proprietary models like GPT-4o.\nFurther visualization indicates that there is also a scaling law on the\ninterpretability and semantics of adversarial perturbations.", "AI": {"tldr": "Scaling the number of surrogate models in adversarial attacks improves transferability, achieving high success rates on proprietary models like GPT-4o.", "motivation": "To explore whether increasing the number of surrogate models in adversarial attacks enhances transferability, inspired by scaling laws in large foundation models.", "method": "Theoretical analysis and empirical evaluations using standard image classifiers, defended models, and multimodal large language models with various attack methods.", "result": "Clear scaling laws confirm that more surrogate models boost adversarial transferability, achieving over 90% success on proprietary models.", "conclusion": "Scaling the number of surrogate models significantly improves adversarial attack transferability, with implications for interpretability and semantics of perturbations."}}
{"id": "2408.14116", "pdf": "https://arxiv.org/pdf/2408.14116", "abs": "https://arxiv.org/abs/2408.14116", "authors": ["Jingyang Zhu", "Yuanming Shi", "Yong Zhou", "Chunxiao Jiang", "Linling Kuang"], "title": "Hierarchical Learning and Computing over Space-Ground Integrated Networks", "categories": ["cs.LG", "cs.DC", "cs.NI", "eess.SP"], "comment": "Accepted by IEEE Transactions on Mobile Computing", "summary": "Space-ground integrated networks hold great promise for providing global\nconnectivity, particularly in remote areas where large amounts of valuable data\nare generated by Internet of Things (IoT) devices, but lacking terrestrial\ncommunication infrastructure. The massive data is conventionally transferred to\nthe cloud server for centralized artificial intelligence (AI) models training,\nraising huge communication overhead and privacy concerns. To address this, we\npropose a hierarchical learning and computing framework, which leverages the\nlowlatency characteristic of low-earth-orbit (LEO) satellites and the global\ncoverage of geostationary-earth-orbit (GEO) satellites, to provide global\naggregation services for locally trained models on ground IoT devices. Due to\nthe time-varying nature of satellite network topology and the energy\nconstraints of LEO satellites, efficiently aggregating the received local\nmodels from ground devices on LEO satellites is highly challenging. By\nleveraging the predictability of inter-satellite connectivity, modeling the\nspace network as a directed graph, we formulate a network energy minimization\nproblem for model aggregation, which turns out to be a Directed Steiner Tree\n(DST) problem. We propose a topologyaware energy-efficient routing (TAEER)\nalgorithm to solve the DST problem by finding a minimum spanning arborescence\non a substitute directed graph. Extensive simulations under realworld\nspace-ground integrated network settings demonstrate that the proposed TAEER\nalgorithm significantly reduces energy consumption and outperforms benchmarks.", "AI": {"tldr": "A hierarchical learning framework for space-ground networks reduces communication overhead and privacy risks by leveraging LEO and GEO satellites for model aggregation, solved via a topology-aware energy-efficient routing algorithm.", "motivation": "Addressing the challenges of massive data transfer and privacy concerns in IoT devices in remote areas lacking terrestrial infrastructure.", "method": "Proposes a hierarchical framework using LEO and GEO satellites, formulates model aggregation as a Directed Steiner Tree problem, and introduces the TAEER algorithm for energy-efficient routing.", "result": "TAEER significantly reduces energy consumption in real-world simulations compared to benchmarks.", "conclusion": "The framework and algorithm effectively optimize energy use in space-ground networks, enhancing global IoT connectivity."}}
{"id": "2505.03780", "pdf": "https://arxiv.org/pdf/2505.03780", "abs": "https://arxiv.org/abs/2505.03780", "authors": ["Burkhard Ringlein", "Thomas Parnell", "Radu Stoica"], "title": "GPU Performance Portability needs Autotuning", "categories": ["cs.AR", "cs.AI", "cs.PL"], "comment": "typos, fix grammatical mistakes", "summary": "As LLMs grow in complexity, achieving state-of-the-art performance requires\ntight co-design across algorithms, software, and hardware. Today's reliance on\na single dominant platform limits portability, creates vendor lock-in, and\nraises barriers for new AI hardware. In this work, we make the case for\ncombining just-in-time (JIT) compilation with kernel parameter autotuning to\nenable portable LLM inference with state-of-the-art performance without code\nchanges. Focusing on flash attention -- a widespread performance critical LLM\nkernel -- we demonstrate that this approach explores up to 15x more kernel\nparameter configurations, produces significantly more diverse code across\nmultiple dimensions, and even outperforms vendor-optimized implementations by\nup to 230%, all while reducing kernel code size by 70x and eliminating manual\ncode optimizations. Our results highlight autotuning as a promising path to\nunlocking model portability across GPU vendors.", "AI": {"tldr": "Combining JIT compilation and kernel parameter autotuning enables portable LLM inference with top performance, outperforming vendor-optimized implementations while reducing code size.", "motivation": "Current reliance on a single platform limits portability and raises barriers for new AI hardware.", "method": "Uses JIT compilation and kernel parameter autotuning, focusing on flash attention for LLM inference.", "result": "Explores 15x more configurations, outperforms vendor-optimized implementations by 230%, reduces kernel code size by 70x.", "conclusion": "Autotuning is a promising path for model portability across GPU vendors."}}
{"id": "2504.08353", "pdf": "https://arxiv.org/pdf/2504.08353", "abs": "https://arxiv.org/abs/2504.08353", "authors": ["Ren Li", "Cong Cao", "Corentin Dumery", "Yingxuan You", "Hao Li", "Pascal Fua"], "title": "Single View Garment Reconstruction Using Diffusion Mapping Via Pattern Coordinates", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "SIGGRAPH 2025", "summary": "Reconstructing 3D clothed humans from images is fundamental to applications\nlike virtual try-on, avatar creation, and mixed reality. While recent advances\nhave enhanced human body recovery, accurate reconstruction of garment geometry\n-- especially for loose-fitting clothing -- remains an open challenge. We\npresent a novel method for high-fidelity 3D garment reconstruction from single\nimages that bridges 2D and 3D representations. Our approach combines Implicit\nSewing Patterns (ISP) with a generative diffusion model to learn rich garment\nshape priors in a 2D UV space. A key innovation is our mapping model that\nestablishes correspondences between 2D image pixels, UV pattern coordinates,\nand 3D geometry, enabling joint optimization of both 3D garment meshes and the\ncorresponding 2D patterns by aligning learned priors with image observations.\nDespite training exclusively on synthetically simulated cloth data, our method\ngeneralizes effectively to real-world images, outperforming existing approaches\non both tight- and loose-fitting garments. The reconstructed garments maintain\nphysical plausibility while capturing fine geometric details, enabling\ndownstream applications including garment retargeting and texture manipulation.", "AI": {"tldr": "A novel method for high-fidelity 3D garment reconstruction from single images, combining Implicit Sewing Patterns (ISP) with a generative diffusion model to bridge 2D and 3D representations.", "motivation": "Accurate reconstruction of garment geometry, especially for loose-fitting clothing, remains a challenge in 3D clothed human reconstruction.", "method": "Combines ISP with a generative diffusion model to learn garment shape priors in 2D UV space, mapping 2D pixels, UV coordinates, and 3D geometry for joint optimization.", "result": "Outperforms existing methods on both tight- and loose-fitting garments, generalizing well to real-world images despite synthetic training data.", "conclusion": "The method enables physically plausible garment reconstruction with fine details, supporting applications like retargeting and texture manipulation."}}
{"id": "2409.08946", "pdf": "https://arxiv.org/pdf/2409.08946", "abs": "https://arxiv.org/abs/2409.08946", "authors": ["Pengyun Wang", "Yadi Cao", "Chris Russell", "Yanxin Shen", "Junyu Luo", "Ming Zhang", "Siyu Heng", "Xiao Luo"], "title": "DELTA: Dual Consistency Delving with Topological Uncertainty for Active Graph Domain Adaptation", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Graph domain adaptation has recently enabled knowledge transfer across\ndifferent graphs. However, without the semantic information on target graphs,\nthe performance on target graphs is still far from satisfactory. To address the\nissue, we study the problem of active graph domain adaptation, which selects a\nsmall quantitative of informative nodes on the target graph for extra\nannotation. This problem is highly challenging due to the complicated\ntopological relationships and the distribution discrepancy across graphs. In\nthis paper, we propose a novel approach named Dual Consistency Delving with\nTopological Uncertainty (DELTA) for active graph domain adaptation. Our DELTA\nconsists of an edge-oriented graph subnetwork and a path-oriented graph\nsubnetwork, which can explore topological semantics from complementary\nperspectives. In particular, our edge-oriented graph subnetwork utilizes the\nmessage passing mechanism to learn neighborhood information, while our\npath-oriented graph subnetwork explores high-order relationships from\nsub-structures. To jointly learn from two subnetworks, we roughly select\ninformative candidate nodes with the consideration of consistency across two\nsubnetworks. Then, we aggregate local semantics from its K-hop subgraph based\non node degrees for topological uncertainty estimation. To overcome potential\ndistribution shifts, we compare target nodes and their corresponding source\nnodes for discrepancy scores as an additional component for fine selection.\nExtensive experiments on benchmark datasets demonstrate that DELTA outperforms\nvarious state-of-the-art approaches. The code implementation of DELTA is\navailable at https://github.com/goose315/DELTA.", "AI": {"tldr": "DELTA improves graph domain adaptation by selecting informative nodes for annotation using dual subnetworks and topological uncertainty.", "motivation": "Address the challenge of poor performance in graph domain adaptation due to lack of semantic information on target graphs.", "method": "Proposes DELTA, combining edge-oriented and path-oriented subnetworks to explore topological semantics, and uses consistency and uncertainty for node selection.", "result": "DELTA outperforms state-of-the-art methods on benchmark datasets.", "conclusion": "DELTA effectively enhances graph domain adaptation by leveraging topological semantics and active learning."}}
{"id": "2505.03795", "pdf": "https://arxiv.org/pdf/2505.03795", "abs": "https://arxiv.org/abs/2505.03795", "authors": ["Jonathan Skaggs", "Jacob W. Crandall"], "title": "Modeling Human Behavior in a Strategic Network Game with Complex Group Dynamics", "categories": ["cs.SI", "cs.AI", "physics.soc-ph"], "comment": null, "summary": "Human networks greatly impact important societal outcomes, including wealth\nand health inequality, poverty, and bullying. As such, understanding human\nnetworks is critical to learning how to promote favorable societal outcomes. As\na step toward better understanding human networks, we compare and contrast\nseveral methods for learning, from a small data set, models of human behavior\nin a strategic network game called the Junior High Game (JHG). These modeling\nmethods differ with respect to the assumptions they use to parameterize human\nbehavior (behavior vs. community-aware behavior) and the moments they model\n(mean vs. distribution). Results show that the highest-performing method,\ncalled hCAB, models the distribution of human behavior rather than the mean and\nassumes humans use community-aware behavior rather than behavior matching. When\napplied to small societies (6-11 individuals), the hCAB model closely mirrors\nthe population dynamics of human groups (with notable differences).\nAdditionally, in a user study, human participants were unable to distinguish\nindividual hCAB agents from other humans, thus illustrating that the hCAB model\nalso produces plausible (individual) human behavior in this strategic network\ngame.", "AI": {"tldr": "The paper compares methods for modeling human behavior in the Junior High Game (JHG), finding hCAB (community-aware, distribution-focused) as the best performer, closely mirroring human group dynamics and producing plausible individual behavior.", "motivation": "Understanding human networks is crucial for addressing societal outcomes like inequality and poverty. This study aims to improve such understanding by modeling behavior in the JHG.", "method": "Several methods are compared, differing in assumptions (behavior vs. community-aware) and focus (mean vs. distribution). The hCAB method models distribution and assumes community-aware behavior.", "result": "hCAB outperforms others, closely matching human group dynamics in small societies and producing behavior indistinguishable from humans in a user study.", "conclusion": "hCAB is effective for modeling human behavior in strategic network games, offering insights for understanding real-world human networks."}}
{"id": "2505.05957", "pdf": "https://arxiv.org/pdf/2505.05957", "abs": "https://arxiv.org/abs/2505.05957", "authors": ["Peter R\u00f6seler", "Oliver Schaudt", "Helmut Berg", "Christian Bauckhage", "Matthias Koch"], "title": "Efficient Quantum Convolutional Neural Networks for Image Classification: Overcoming Hardware Constraints", "categories": ["quant-ph", "cs.CV", "cs.LG"], "comment": null, "summary": "While classical convolutional neural networks (CNNs) have revolutionized\nimage classification, the emergence of quantum computing presents new\nopportunities for enhancing neural network architectures. Quantum CNNs (QCNNs)\nleverage quantum mechanical properties and hold potential to outperform\nclassical approaches. However, their implementation on current noisy\nintermediate-scale quantum (NISQ) devices remains challenging due to hardware\nlimitations. In our research, we address this challenge by introducing an\nencoding scheme that significantly reduces the input dimensionality. We\ndemonstrate that a primitive QCNN architecture with 49 qubits is sufficient to\ndirectly process $28\\times 28$ pixel MNIST images, eliminating the need for\nclassical dimensionality reduction pre-processing. Additionally, we propose an\nautomated framework based on expressibility, entanglement, and complexity\ncharacteristics to identify the building blocks of QCNNs, parameterized quantum\ncircuits (PQCs). Our approach demonstrates advantages in accuracy and\nconvergence speed with a similar parameter count compared to both hybrid QCNNs\nand classical CNNs. We validated our experiments on IBM's Heron r2 quantum\nprocessor, achieving $96.08\\%$ classification accuracy, surpassing the\n$71.74\\%$ benchmark of traditional approaches under identical training\nconditions. These results represent one of the first implementations of image\nclassifications on real quantum hardware and validate the potential of quantum\ncomputing in this area.", "AI": {"tldr": "The paper introduces a quantum CNN (QCNN) for image classification, reducing input dimensionality and outperforming classical CNNs on NISQ devices.", "motivation": "To leverage quantum computing for enhancing neural networks, overcoming hardware limitations of NISQ devices.", "method": "Proposes an encoding scheme for dimensionality reduction and an automated framework for QCNN building blocks (PQCs).", "result": "Achieves 96.08% accuracy on MNIST, surpassing classical benchmarks (71.74%).", "conclusion": "Demonstrates QCNNs' potential for image classification on real quantum hardware."}}
{"id": "2409.10263", "pdf": "https://arxiv.org/pdf/2409.10263", "abs": "https://arxiv.org/abs/2409.10263", "authors": ["Jan von Pichowski", "Christopher Bl\u00f6cker", "Ingo Scholtes"], "title": "MDL-Pool: Adaptive Multilevel Graph Pooling Based on Minimum Description Length", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Graph pooling compresses graphs and summarises their topological properties\nand features in a vectorial representation. It is an essential part of deep\ngraph representation learning and is indispensable in graph-level tasks like\nclassification or regression. Current approaches pool hierarchical structures\nin graphs by iteratively applying shallow pooling operators up to a fixed\ndepth. However, they disregard the interdependencies between structures at\ndifferent hierarchical levels and do not adapt to datasets that contain graphs\nwith different sizes that may require pooling with various depths. To address\nthese issues, we propose MDL-Pool, a pooling operator based on the minimum\ndescription length (MDL) principle, whose loss formulation explicitly models\nthe interdependencies between different hierarchical levels and facilitates a\ndirect comparison between multiple pooling alternatives with different depths.\nMDP-Pool builds on the map equation, an information-theoretic objective\nfunction for community detection, which naturally implements Occam's razor and\nbalances between model complexity and goodness-of-fit via the MDL. We\ndemonstrate MDL-Pool's competitive performance in an empirical evaluation\nagainst various baselines across standard graph classification datasets.", "AI": {"tldr": "MDL-Pool is a graph pooling method using the MDL principle to model interdependencies between hierarchical levels and adapt to varying graph sizes, outperforming baselines in classification tasks.", "motivation": "Current graph pooling methods ignore interdependencies between hierarchical levels and lack adaptability to graphs of varying sizes, limiting their effectiveness.", "method": "Proposes MDL-Pool, leveraging the MDL principle and the map equation to balance model complexity and fit, enabling direct comparison of pooling depths.", "result": "MDL-Pool shows competitive performance in graph classification benchmarks compared to existing methods.", "conclusion": "MDL-Pool addresses limitations of current pooling methods by incorporating interdependencies and adaptability, proving effective in empirical evaluations."}}
{"id": "2505.03825", "pdf": "https://arxiv.org/pdf/2505.03825", "abs": "https://arxiv.org/abs/2505.03825", "authors": ["Anushiya Arunan", "Yan Qin", "Xiaoli Li", "Yuen Chau"], "title": "Intelligently Augmented Contrastive Tensor Factorization: Empowering Multi-dimensional Time Series Classification in Low-Data Environments", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in Expert Systems with Applications\n  (DOI:https://doi.org/10.1016/j.eswa.2025.127889)", "summary": "Classification of multi-dimensional time series from real-world systems\nrequire fine-grained learning of complex features such as cross-dimensional\ndependencies and intra-class variations-all under the practical challenge of\nlow training data availability. However, standard deep learning (DL) struggles\nto learn generalizable features in low-data environments due to model\noverfitting. We propose a versatile yet data-efficient framework, Intelligently\nAugmented Contrastive Tensor Factorization (ITA-CTF), to learn effective\nrepresentations from multi-dimensional time series. The CTF module learns core\nexplanatory components of the time series (e.g., sensor factors, temporal\nfactors), and importantly, their joint dependencies. Notably, unlike standard\ntensor factorization (TF), the CTF module incorporates a new contrastive loss\noptimization to induce similarity learning and class-awareness into the learnt\nrepresentations for better classification performance. To strengthen this\ncontrastive learning, the preceding ITA module generates targeted but\ninformative augmentations that highlight realistic intra-class patterns in the\noriginal data, while preserving class-wise properties. This is achieved by\ndynamically sampling a \"soft\" class prototype to guide the warping of each\nquery data sample, which results in an augmentation that is intelligently\npattern-mixed between the \"soft\" class prototype and the query sample. These\naugmentations enable the CTF module to recognize complex intra-class variations\ndespite the limited original training data, and seek out invariant class-wise\nproperties for accurate classification performance. The proposed method is\ncomprehensively evaluated on five different classification tasks. Compared to\nstandard TF and several DL benchmarks, notable performance improvements up to\n18.7% were achieved.", "AI": {"tldr": "ITA-CTF is a data-efficient framework for classifying multi-dimensional time series by combining contrastive tensor factorization with intelligent augmentations to improve feature learning and classification performance.", "motivation": "Standard DL struggles with low training data, leading to overfitting. The paper aims to address this by learning generalizable features from multi-dimensional time series despite limited data.", "method": "ITA-CTF uses a CTF module for tensor factorization with contrastive loss and an ITA module for generating targeted augmentations. The ITA module dynamically samples a 'soft' class prototype to guide augmentations.", "result": "The method outperforms standard TF and DL benchmarks, achieving up to 18.7% improvement in classification tasks.", "conclusion": "ITA-CTF effectively learns complex features and dependencies in low-data environments, enhancing classification accuracy."}}
{"id": "2505.07214", "pdf": "https://arxiv.org/pdf/2505.07214", "abs": "https://arxiv.org/abs/2505.07214", "authors": ["Pascal Spiegler", "Arash Harirpoush", "Yiming Xiao"], "title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": null, "summary": "Crucial in disease analysis and surgical planning, manual segmentation of\nvolumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and\nchallenging to master, while fully automatic algorithms can benefit from user\nfeedback. Therefore, with the complementary power of the latest radiological AI\nfoundation models and virtual reality (VR)'s intuitive data interaction, we\npropose SAMIRA, a novel conversational AI agent that assists users with\nlocalizing, segmenting, and visualizing 3D medical concepts in VR. Through\nspeech-based interaction, the agent helps users understand radiological\nfeatures, locate clinical targets, and generate segmentation masks that can be\nrefined with just a few point prompts. The system also supports true-to-scale\n3D visualization of segmented pathology to enhance patient-specific anatomical\nunderstanding. Furthermore, to determine the optimal interaction paradigm under\nnear-far attention-switching for refining segmentation masks in an immersive,\nhuman-in-the-loop workflow, we compare VR controller pointing, head pointing,\nand eye tracking as input modes. With a user study, evaluations demonstrated a\nhigh usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as\nstrong support for the proposed VR system's guidance, training potential, and\nintegration of AI in radiological segmentation tasks.", "AI": {"tldr": "SAMIRA is a conversational AI agent in VR for medical scan segmentation, combining AI and VR for intuitive, efficient, and accurate 3D medical analysis.", "motivation": "Manual segmentation is laborious and error-prone, while fully automatic methods lack user feedback. SAMIRA bridges this gap with AI and VR.", "method": "Uses speech-based interaction, AI foundation models, and VR for segmentation, localization, and 3D visualization. Compares input modes (controller, head, eye tracking).", "result": "High usability (SUS=90.0 \u00b1 9.0), low task load, and strong user support for guidance and training.", "conclusion": "SAMIRA effectively integrates AI and VR for improved medical segmentation, offering intuitive interaction and high usability."}}
{"id": "2410.04442", "pdf": "https://arxiv.org/pdf/2410.04442", "abs": "https://arxiv.org/abs/2410.04442", "authors": ["Peiyuan Liu", "Beiliang Wu", "Yifan Hu", "Naiqi Li", "Tao Dai", "Jigang Bao", "Shu-tao Xia"], "title": "TimeBridge: Non-Stationarity Matters for Long-term Time Series Forecasting", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Non-stationarity poses significant challenges for multivariate time series\nforecasting due to the inherent short-term fluctuations and long-term trends\nthat can lead to spurious regressions or obscure essential long-term\nrelationships. Most existing methods either eliminate or retain\nnon-stationarity without adequately addressing its distinct impacts on\nshort-term and long-term modeling. Eliminating non-stationarity is essential\nfor avoiding spurious regressions and capturing local dependencies in\nshort-term modeling, while preserving it is crucial for revealing long-term\ncointegration across variates. In this paper, we propose TimeBridge, a novel\nframework designed to bridge the gap between non-stationarity and dependency\nmodeling in long-term time series forecasting. By segmenting input series into\nsmaller patches, TimeBridge applies Integrated Attention to mitigate short-term\nnon-stationarity and capture stable dependencies within each variate, while\nCointegrated Attention preserves non-stationarity to model long-term\ncointegration across variates. Extensive experiments show that TimeBridge\nconsistently achieves state-of-the-art performance in both short-term and\nlong-term forecasting. Additionally, TimeBridge demonstrates exceptional\nperformance in financial forecasting on the CSI 500 and S&P 500 indices,\nfurther validating its robustness and effectiveness. Code is available at\nhttps://github.com/Hank0626/TimeBridge.", "AI": {"tldr": "TimeBridge is a novel framework addressing non-stationarity in multivariate time series forecasting by balancing short-term and long-term modeling through Integrated and Cointegrated Attention.", "motivation": "Non-stationarity complicates forecasting by affecting short-term and long-term relationships differently, yet existing methods fail to address this adequately.", "method": "TimeBridge segments input series into patches, using Integrated Attention for short-term stability and Cointegrated Attention for long-term cointegration.", "result": "TimeBridge achieves state-of-the-art performance in both short-term and long-term forecasting, including financial datasets like CSI 500 and S&P 500.", "conclusion": "TimeBridge effectively bridges the gap between non-stationarity and dependency modeling, proving robust and versatile in real-world applications."}}
{"id": "2505.04553", "pdf": "https://arxiv.org/pdf/2505.04553", "abs": "https://arxiv.org/abs/2505.04553", "authors": ["Shanyu Han", "Yang Liu", "Xiang Yu"], "title": "Risk-sensitive Reinforcement Learning Based on Convex Scoring Functions", "categories": ["q-fin.MF", "cs.AI", "q-fin.RM"], "comment": "35 pages", "summary": "We propose a reinforcement learning (RL) framework under a broad class of\nrisk objectives, characterized by convex scoring functions. This class covers\nmany common risk measures, such as variance, Expected Shortfall, entropic\nValue-at-Risk, and mean-risk utility. To resolve the time-inconsistency issue,\nwe consider an augmented state space and an auxiliary variable and recast the\nproblem as a two-state optimization problem. We propose a customized\nActor-Critic algorithm and establish some theoretical approximation guarantees.\nA key theoretical contribution is that our results do not require the Markov\ndecision process to be continuous. Additionally, we propose an auxiliary\nvariable sampling method inspired by the alternating minimization algorithm,\nwhich is convergent under certain conditions. We validate our approach in\nsimulation experiments with a financial application in statistical arbitrage\ntrading, demonstrating the effectiveness of the algorithm.", "AI": {"tldr": "A reinforcement learning framework for risk objectives using convex scoring functions, addressing time-inconsistency with a two-state optimization approach and a customized Actor-Critic algorithm.", "motivation": "To handle diverse risk measures (e.g., variance, Expected Shortfall) and resolve time-inconsistency in RL under non-continuous Markov decision processes.", "method": "Augmented state space and auxiliary variable for two-state optimization; customized Actor-Critic algorithm with theoretical guarantees.", "result": "Effective algorithm validated in financial simulations, e.g., statistical arbitrage trading.", "conclusion": "The framework successfully addresses risk objectives and time-inconsistency, with theoretical and empirical support."}}
{"id": "2505.08787", "pdf": "https://arxiv.org/pdf/2505.08787", "abs": "https://arxiv.org/abs/2505.08787", "authors": ["Hanjung Kim", "Jaehyun Kang", "Hyolim Kang", "Meedeum Cho", "Seon Joo Kim", "Youngwoon Lee"], "title": "UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations", "categories": ["cs.RO", "cs.CV"], "comment": "Project Page: https://kimhanjung.github.io/UniSkill/", "summary": "Mimicry is a fundamental learning mechanism in humans, enabling individuals\nto learn new tasks by observing and imitating experts. However, applying this\nability to robots presents significant challenges due to the inherent\ndifferences between human and robot embodiments in both their visual appearance\nand physical capabilities. While previous methods bridge this gap using\ncross-embodiment datasets with shared scenes and tasks, collecting such aligned\ndata between humans and robots at scale is not trivial. In this paper, we\npropose UniSkill, a novel framework that learns embodiment-agnostic skill\nrepresentations from large-scale cross-embodiment video data without any\nlabels, enabling skills extracted from human video prompts to effectively\ntransfer to robot policies trained only on robot data. Our experiments in both\nsimulation and real-world environments show that our cross-embodiment skills\nsuccessfully guide robots in selecting appropriate actions, even with unseen\nvideo prompts. The project website can be found at:\nhttps://kimhanjung.github.io/UniSkill.", "AI": {"tldr": "UniSkill is a framework that learns embodiment-agnostic skills from cross-embodiment video data, enabling human video prompts to transfer to robot policies without labels.", "motivation": "Mimicry is key for human learning but challenging for robots due to embodiment differences. Existing methods rely on aligned human-robot data, which is hard to collect at scale.", "method": "UniSkill learns skill representations from unlabeled cross-embodiment video data, allowing human prompts to guide robot policies trained on robot-only data.", "result": "Experiments in simulation and real-world show UniSkill successfully transfers skills to robots, even with unseen video prompts.", "conclusion": "UniSkill bridges the human-robot embodiment gap, enabling effective skill transfer without labeled data."}}
{"id": "2412.03483", "pdf": "https://arxiv.org/pdf/2412.03483", "abs": "https://arxiv.org/abs/2412.03483", "authors": ["Loukas Ilias", "George Doukas", "Vangelis Lamprou", "Christos Ntanos", "Dimitris Askounis"], "title": "Convolutional Neural Networks and Mixture of Experts for Intrusion Detection in 5G Networks and beyond", "categories": ["cs.LG"], "comment": null, "summary": "The advent of 6G/NextG networks comes along with a series of benefits,\nincluding extreme capacity, reliability, and efficiency. However, these\nnetworks may become vulnerable to new security threats. Therefore, 6G/NextG\nnetworks must be equipped with advanced Artificial Intelligence algorithms, in\norder to evade these attacks. Existing studies on the intrusion detection task\nrely on the train of shallow machine learning classifiers, including Logistic\nRegression, Decision Trees, and so on, yielding suboptimal performance. Others\nare based on deep neural networks consisting of static components, which are\nnot conditional on the input. This limits their representation power and\nefficiency. To resolve these issues, we present the first study integrating\nMixture of Experts (MoE) for identifying malicious traffic. Specifically, we\nuse network traffic data and convert the 1D array of features into a 2D matrix.\nNext, we pass this matrix through convolutional neural network (CNN) layers\nfollowed by batch normalization and max pooling layers. After obtaining the\nrepresentation vector via the CNN layers, a sparsely gated MoE layer is used.\nThis layer consists of a set of experts (dense layers) and a router, where the\nrouter assigns weights to the output of each expert. Sparsity is achieved by\nchoosing the most relevant experts of the total ones. Finally, we perform a\nseries of ablation experiments to prove the effectiveness of our proposed\nmodel. Experiments are conducted on the 5G-NIDD dataset, a network intrusion\ndetection dataset generated from a real 5G test network. Results show that our\nintroduced approach reaches weighted F1-score up to 99.95% achieving comparable\nperformance to existing approaches. Findings also show that our proposed model\nachieves multiple advantages over state-of-the-art approaches.", "AI": {"tldr": "The paper proposes a novel intrusion detection method for 6G/NextG networks using Mixture of Experts (MoE) with CNN layers, achieving high accuracy (99.95% F1-score).", "motivation": "6G/NextG networks face new security threats, and existing intrusion detection methods (shallow ML or static deep neural networks) are suboptimal.", "method": "Convert 1D network traffic data to 2D matrix, process with CNN layers, and use a sparsely gated MoE layer for dynamic expert selection.", "result": "Achieves 99.95% weighted F1-score on the 5G-NIDD dataset, outperforming existing methods.", "conclusion": "The proposed MoE-based model is effective for intrusion detection in 6G/NextG networks, offering superior performance and flexibility."}}
{"id": "2505.06085", "pdf": "https://arxiv.org/pdf/2505.06085", "abs": "https://arxiv.org/abs/2505.06085", "authors": ["Hiari Pizzini Cavagna", "Daniele Cesarini", "Andrea Bartolini"], "title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities", "categories": ["cs.PF", "cs.AI", "cs.AR"], "comment": "Accepted to the Computational Aspects of Deep Learning Workshop at\n  ISC High Performance 2025. To appear in the ISC High Performance 2025\n  Workshop Proceedings", "summary": "The increasing demand for generative AI as Large Language Models (LLMs)\nservices has driven the need for specialized hardware architectures that\noptimize computational efficiency and energy consumption. This paper evaluates\nthe performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic\nlinear algebra kernels at reduced numerical precision, a fundamental operation\nin LLM computations. We present a detailed characterization of Grayskull's\nexecution model, gridsize, matrix dimensions, data formats, and numerical\nprecision impact computational efficiency. Furthermore, we compare Grayskull's\nperformance against state-of-the-art architectures with tensor acceleration,\nincluding Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100).\nWhilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a\ncompetitive trade-off between power consumption and computational throughput,\nreaching a peak of 1.55 TFLOPs/Watt with BF16.", "AI": {"tldr": "The paper evaluates the Tenstorrent Grayskull e75 RISC-V accelerator for linear algebra kernels in LLMs, comparing its efficiency and power consumption against Intel Sapphire Rapids and NVIDIA GPUs.", "motivation": "The demand for efficient hardware for LLMs drives the need to evaluate specialized accelerators like Grayskull.", "method": "Characterization of Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision, with comparisons to Intel and NVIDIA hardware.", "result": "Grayskull achieves 1.55 TFLOPs/Watt with BF16, offering a competitive balance between power and performance.", "conclusion": "Grayskull is a viable option for LLM computations, balancing efficiency and throughput despite NVIDIA's raw performance dominance."}}
{"id": "2505.08889", "pdf": "https://arxiv.org/pdf/2505.08889", "abs": "https://arxiv.org/abs/2505.08889", "authors": ["Linjie Lyu", "Valentin Deschaintre", "Yannick Hold-Geoffroy", "Milo\u0161 Ha\u0161an", "Jae Shin Yoon", "Thomas Leimk\u00fchler", "Christian Theobalt", "Iliyan Georgiev"], "title": "IntrinsicEdit: Precise generative image manipulation in intrinsic space", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025 Journal track", "summary": "Generative diffusion models have advanced image editing with high-quality\nresults and intuitive interfaces such as prompts and semantic drawing. However,\nthese interfaces lack precise control, and the associated methods typically\nspecialize on a single editing task. We introduce a versatile, generative\nworkflow that operates in an intrinsic-image latent space, enabling semantic,\nlocal manipulation with pixel precision for a range of editing operations.\nBuilding atop the RGB-X diffusion framework, we address key challenges of\nidentity preservation and intrinsic-channel entanglement. By incorporating\nexact diffusion inversion and disentangled channel manipulation, we enable\nprecise, efficient editing with automatic resolution of global illumination\neffects -- all without additional data collection or model fine-tuning. We\ndemonstrate state-of-the-art performance across a variety of tasks on complex\nimages, including color and texture adjustments, object insertion and removal,\nglobal relighting, and their combinations.", "AI": {"tldr": "A generative workflow in intrinsic-image latent space enables precise, versatile image editing without extra data or fine-tuning.", "motivation": "Existing diffusion models lack precise control and specialize in single tasks, limiting their versatility.", "method": "Uses RGB-X diffusion framework with exact inversion and disentangled channel manipulation for pixel-precise editing.", "result": "Achieves state-of-the-art performance in tasks like color/texture adjustments, object insertion/removal, and relighting.", "conclusion": "The method offers a flexible, high-quality solution for diverse image editing tasks with minimal overhead."}}
{"id": "2412.13779", "pdf": "https://arxiv.org/pdf/2412.13779", "abs": "https://arxiv.org/abs/2412.13779", "authors": ["Yichen Li", "Yuying Wang", "Haozhao Wang", "Yining Qi", "Tianzhe Xiao", "Ruixuan Li"], "title": "Rehearsal-Free Continual Federated Learning with Synergistic Synaptic Intelligence", "categories": ["cs.LG", "cs.DC"], "comment": "arXiv admin note: text overlap with arXiv:2403.05890", "summary": "Continual Federated Learning (CFL) allows distributed devices to\ncollaboratively learn novel concepts from continuously shifting training data\nwhile avoiding knowledge forgetting of previously seen tasks. To tackle this\nchallenge, most current CFL approaches rely on extensive rehearsal of previous\ndata. Despite effectiveness, rehearsal comes at a cost to memory, and it may\nalso violate data privacy. Considering these, we seek to apply regularization\ntechniques to CFL by considering their cost-efficient properties that do not\nrequire sample caching or rehearsal. Specifically, we first apply traditional\nregularization techniques to CFL and observe that existing regularization\ntechniques, especially synaptic intelligence, can achieve promising results\nunder homogeneous data distribution but fail when the data is heterogeneous.\nBased on this observation, we propose a simple yet effective regularization\nalgorithm for CFL named FedSSI, which tailors the synaptic intelligence for the\nCFL with heterogeneous data settings. FedSSI can not only reduce computational\noverhead without rehearsal but also address the data heterogeneity issue.\nExtensive experiments show that FedSSI achieves superior performance compared\nto state-of-the-art methods.", "AI": {"tldr": "FedSSI is a regularization algorithm for Continual Federated Learning (CFL) that addresses data heterogeneity and avoids rehearsal, outperforming state-of-the-art methods.", "motivation": "Current CFL approaches rely on rehearsal, which is memory-intensive and may violate privacy. The goal is to use cost-efficient regularization techniques instead.", "method": "The paper applies traditional regularization to CFL, identifies limitations, and proposes FedSSI, a tailored version of synaptic intelligence for heterogeneous data.", "result": "FedSSI reduces computational overhead and handles data heterogeneity effectively, achieving superior performance in experiments.", "conclusion": "FedSSI is a simple yet effective solution for CFL, offering privacy and efficiency advantages over rehearsal-based methods."}}
{"id": "2505.06111", "pdf": "https://arxiv.org/pdf/2505.06111", "abs": "https://arxiv.org/abs/2505.06111", "authors": ["Qingwen Bu", "Yanting Yang", "Jisong Cai", "Shenyuan Gao", "Guanghui Ren", "Maoqing Yao", "Ping Luo", "Hongyang Li"], "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted to RSS 2025. Code is available at\n  https://github.com/OpenDriveLab/UniVLA", "summary": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning.", "AI": {"tldr": "UniVLA is a framework for learning cross-embodiment vision-language-action policies, using task-centric action representations from videos to improve scalability and transferability across robots and environments.", "motivation": "Existing robot learning approaches rely on action-annotated data, limiting them to specific embodiments and hindering transferability. UniVLA aims to overcome this by leveraging diverse data sources.", "method": "UniVLA derives task-centric action representations from videos using a latent action model, incorporates language instructions, and operates in the DINO feature space to filter task-irrelevant dynamics.", "result": "UniVLA achieves state-of-the-art performance in manipulation and navigation benchmarks, outperforming OpenVLA with significantly less compute and data. Performance improves with heterogeneous data, including human videos.", "conclusion": "UniVLA demonstrates scalable and efficient robot policy learning, with potential for broader applications due to its ability to utilize diverse data sources."}}
{"id": "2501.01002", "pdf": "https://arxiv.org/pdf/2501.01002", "abs": "https://arxiv.org/abs/2501.01002", "authors": ["Yusi Wei", "Hande Y. Benson", "Joseph K. Agor", "Muge Capan"], "title": "Multi-Objective Optimization-Based Anonymization of Structured Data for Machine Learning Application", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Organizations are collecting vast amounts of data, but they often lack the\ncapabilities needed to fully extract insights. As a result, they increasingly\nshare data with external experts, such as analysts or researchers, to gain\nvalue from it. However, this practice introduces significant privacy risks.\nVarious techniques have been proposed to address privacy concerns in data\nsharing. However, these methods often degrade data utility, impacting the\nperformance of machine learning (ML) models. Our research identifies key\nlimitations in existing optimization models for privacy preservation,\nparticularly in handling categorical variables, and evaluating effectiveness\nacross diverse datasets. We propose a novel multi-objective optimization model\nthat simultaneously minimizes information loss and maximizes protection against\nattacks. This model is empirically validated using diverse datasets and\ncompared with two existing algorithms. We assess information loss, the number\nof individuals subject to linkage or homogeneity attacks, and ML performance\nafter anonymization. The results indicate that our model achieves lower\ninformation loss and more effectively mitigates the risk of attacks, reducing\nthe number of individuals susceptible to these attacks compared to alternative\nalgorithms in some cases. Additionally, our model maintains comparable ML\nperformance relative to the original data or data anonymized by other methods.\nOur findings highlight significant improvements in privacy protection and ML\nmodel performance, offering a comprehensive and extensible framework for\nbalancing privacy and utility in data sharing.", "AI": {"tldr": "A novel multi-objective optimization model balances privacy and utility in data sharing, outperforming existing methods in reducing information loss and attack risks while maintaining ML performance.", "motivation": "Organizations share data with external experts but face privacy risks. Existing methods degrade data utility, impacting ML models.", "method": "Proposes a multi-objective optimization model minimizing information loss and maximizing protection, validated empirically.", "result": "Lower information loss, reduced attack risks, and comparable ML performance compared to alternatives.", "conclusion": "The model improves privacy protection and utility, offering a scalable framework for data sharing."}}
{"id": "2505.07096", "pdf": "https://arxiv.org/pdf/2505.07096", "abs": "https://arxiv.org/abs/2505.07096", "authors": ["Prithwish Dan", "Kushal Kedia", "Angela Chao", "Edward Weiyi Duan", "Maximus Adrian Pace", "Wei-Chiu Ma", "Sanjiban Choudhury"], "title": "X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Human videos offer a scalable way to train robot manipulation policies, but\nlack the action labels needed by standard imitation learning algorithms.\nExisting cross-embodiment approaches try to map human motion to robot actions,\nbut often fail when the embodiments differ significantly. We propose X-Sim, a\nreal-to-sim-to-real framework that uses object motion as a dense and\ntransferable signal for learning robot policies. X-Sim starts by reconstructing\na photorealistic simulation from an RGBD human video and tracking object\ntrajectories to define object-centric rewards. These rewards are used to train\na reinforcement learning (RL) policy in simulation. The learned policy is then\ndistilled into an image-conditioned diffusion policy using synthetic rollouts\nrendered with varied viewpoints and lighting. To transfer to the real world,\nX-Sim introduces an online domain adaptation technique that aligns real and\nsimulated observations during deployment. Importantly, X-Sim does not require\nany robot teleoperation data. We evaluate it across 5 manipulation tasks in 2\nenvironments and show that it: (1) improves task progress by 30% on average\nover hand-tracking and sim-to-real baselines, (2) matches behavior cloning with\n10x less data collection time, and (3) generalizes to new camera viewpoints and\ntest-time changes. Code and videos are available at\nhttps://portal-cornell.github.io/X-Sim/.", "AI": {"tldr": "X-Sim is a real-to-sim-to-real framework that uses object motion to train robot policies without robot teleoperation data, improving task progress and generalization.", "motivation": "Human videos lack action labels for imitation learning, and cross-embodiment methods fail with differing embodiments. X-Sim addresses this by leveraging object motion as a transferable signal.", "method": "X-Sim reconstructs a photorealistic simulation from RGBD human videos, tracks object trajectories for rewards, trains an RL policy in simulation, and distills it into a diffusion policy. It includes online domain adaptation for real-world transfer.", "result": "X-Sim improves task progress by 30% over baselines, matches behavior cloning with 10x less data collection time, and generalizes to new viewpoints and test-time changes.", "conclusion": "X-Sim effectively bridges the gap between human videos and robot policy training, demonstrating scalability and robustness without requiring robot teleoperation data."}}
{"id": "2501.13018", "pdf": "https://arxiv.org/pdf/2501.13018", "abs": "https://arxiv.org/abs/2501.13018", "authors": ["Amirmohammad Farzaneh", "Osvaldo Simeone"], "title": "Multi-Objective Hyperparameter Selection via Hypothesis Testing on Reliability Graphs", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "The selection of hyperparameters, such as prompt templates in large language\nmodels (LLMs), must often strike a balance between reliability and cost. In\nmany cases, structural relationships between the expected reliability levels of\nthe hyperparameters can be inferred from prior information and held-out data --\ne.g., longer prompt templates may be more detailed and thus more reliable.\nHowever, existing hyperparameter selection methods either do not provide formal\nreliability guarantees or are unable to incorporate structured knowledge in the\nhyperparameter space. This paper introduces reliability graph-based Pareto\ntesting (RG-PT), a novel multi-objective hyperparameter selection framework\nthat maintains formal reliability guarantees in terms of false discovery rate\n(FDR), while accounting for known relationships among hyperparameters via a\ndirected acyclic graph. Edges in the graph reflect expected reliability and\ncost trade-offs among hyperparameters, which are inferred via the Bradley-Terry\n(BT) ranking model from prior information and held-out data. Experimental\nevaluations demonstrate that RG-PT significantly outperforms existing methods\nsuch as learn-then-test (LTT) and Pareto testing (PT) through a more efficient\nexploration of the hyperparameter space.", "AI": {"tldr": "RG-PT is a new hyperparameter selection method for LLMs that balances reliability and cost while incorporating structured knowledge via a graph, outperforming existing methods like LTT and PT.", "motivation": "Existing hyperparameter selection methods lack formal reliability guarantees or fail to use structured knowledge in the hyperparameter space.", "method": "Introduces RG-PT, a framework using a directed acyclic graph to model hyperparameter relationships and the Bradley-Terry model for ranking.", "result": "RG-PT outperforms LTT and PT by efficiently exploring the hyperparameter space with formal FDR guarantees.", "conclusion": "RG-PT effectively combines reliability guarantees and structured knowledge for better hyperparameter selection in LLMs."}}
{"id": "2505.07816", "pdf": "https://arxiv.org/pdf/2505.07816", "abs": "https://arxiv.org/abs/2505.07816", "authors": ["Veeti Ahvonen", "Damian Heiman", "Antti Kuusisto"], "title": "Graph neural networks and MSO", "categories": ["cs.LO", "cs.AI", "F.4.1; F.1.1; I.2.0"], "comment": null, "summary": "We give an alternative proof for the existing result that recurrent graph\nneural networks working with reals have the same expressive power in\nrestriction to monadic second-order logic MSO as the graded modal substitution\ncalculus. The proof is based on constructing distributed automata that capture\nall MSO-definable node properties over trees. We also consider some variants of\nthe acceptance conditions.", "AI": {"tldr": "An alternative proof shows recurrent graph neural networks (GNNs) with reals match MSO logic's expressive power via distributed automata over trees. Variants of acceptance conditions are also explored.", "motivation": "To provide a new proof for the known equivalence between recurrent GNNs and MSO logic, leveraging distributed automata for clarity.", "method": "Constructs distributed automata capturing MSO-definable node properties over trees and examines different acceptance conditions.", "result": "Confirms recurrent GNNs' expressive power aligns with MSO logic, with insights from automata-based proof.", "conclusion": "The proof reinforces the equivalence and offers a fresh perspective using distributed automata, with potential extensions via varied acceptance conditions."}}
{"id": "2502.02205", "pdf": "https://arxiv.org/pdf/2502.02205", "abs": "https://arxiv.org/abs/2502.02205", "authors": ["Peiyan Hu", "Xiaowei Qian", "Wenhao Deng", "Rui Wang", "Haodong Feng", "Ruiqi Feng", "Tao Zhang", "Long Wei", "Yue Wang", "Zhi-Ming Ma", "Tailin Wu"], "title": "From Uncertain to Safe: Conformal Fine-Tuning of Diffusion Models for Safe PDE Control", "categories": ["cs.LG"], "comment": null, "summary": "The application of deep learning for partial differential equation\n(PDE)-constrained control is gaining increasing attention. However, existing\nmethods rarely consider safety requirements crucial in real-world applications.\nTo address this limitation, we propose Safe Diffusion Models for PDE Control\n(SafeDiffCon), which introduce the uncertainty quantile as model uncertainty\nquantification to achieve optimal control under safety constraints through both\npost-training and inference phases. Firstly, our approach post-trains a\npre-trained diffusion model to generate control sequences that better satisfy\nsafety constraints while achieving improved control objectives via a reweighted\ndiffusion loss, which incorporates the uncertainty quantile estimated using\nconformal prediction. Secondly, during inference, the diffusion model\ndynamically adjusts both its generation process and parameters through\niterative guidance and fine-tuning, conditioned on control targets while\nsimultaneously integrating the estimated uncertainty quantile. We evaluate\nSafeDiffCon on three control tasks: 1D Burgers' equation, 2D incompressible\nfluid, and controlled nuclear fusion problem. Results demonstrate that\nSafeDiffCon is the only method that satisfies all safety constraints, whereas\nother classical and deep learning baselines fail. Furthermore, while adhering\nto safety constraints, SafeDiffCon achieves the best control performance.", "AI": {"tldr": "SafeDiffCon introduces uncertainty quantile for safe PDE control, outperforming baselines in safety and performance.", "motivation": "Addressing the lack of safety considerations in existing deep learning methods for PDE-constrained control.", "method": "Post-trains a diffusion model with reweighted loss and dynamic adjustment during inference using uncertainty quantile.", "result": "SafeDiffCon satisfies all safety constraints and achieves best control performance in tested tasks.", "conclusion": "SafeDiffCon effectively integrates safety into PDE control, setting a new benchmark for safe deep learning applications."}}
{"id": "2505.07921", "pdf": "https://arxiv.org/pdf/2505.07921", "abs": "https://arxiv.org/abs/2505.07921", "authors": ["Qi Xu", "Junyang Zhu", "Dongdong Zhou", "Hao Chen", "Yang Liu", "Jiangrong Shen", "Qiang Zhang"], "title": "Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep neural networks (DNNs) excel in computer vision tasks, especially,\nfew-shot learning (FSL), which is increasingly important for generalizing from\nlimited examples. However, DNNs are computationally expensive with scalability\nissues in real world. Spiking Neural Networks (SNNs), with their event-driven\nnature and low energy consumption, are particularly efficient in processing\nsparse and dynamic data, though they still encounter difficulties in capturing\ncomplex spatiotemporal features and performing accurate cross-class\ncomparisons. To further enhance the performance and efficiency of SNNs in\nfew-shot learning, we propose a few-shot learning framework based on SNNs,\nwhich combines a self-feature extractor module and a cross-feature contrastive\nmodule to refine feature representation and reduce power consumption. We apply\nthe combination of temporal efficient training loss and InfoNCE loss to\noptimize the temporal dynamics of spike trains and enhance the discriminative\npower. Experimental results show that the proposed FSL-SNN significantly\nimproves the classification performance on the neuromorphic dataset N-Omniglot,\nand also achieves competitive performance to ANNs on static datasets such as\nCUB and miniImageNet with low power consumption.", "AI": {"tldr": "A few-shot learning framework using Spiking Neural Networks (SNNs) improves performance and efficiency by combining self-feature extraction and cross-feature contrastive modules, achieving competitive results with low power consumption.", "motivation": "DNNs are computationally expensive for few-shot learning (FSL), while SNNs offer energy efficiency but struggle with complex spatiotemporal features and cross-class comparisons.", "method": "Proposes an SNN-based FSL framework with self-feature extractor and cross-feature contrastive modules, optimized using temporal efficient training loss and InfoNCE loss.", "result": "Improved classification on N-Omniglot and competitive performance on CUB and miniImageNet with low power consumption.", "conclusion": "The FSL-SNN framework enhances SNN performance in FSL, balancing accuracy and energy efficiency."}}
{"id": "2502.04549", "pdf": "https://arxiv.org/pdf/2502.04549", "abs": "https://arxiv.org/abs/2502.04549", "authors": ["Arwen Bradley", "Preetum Nakkiran", "David Berthelot", "James Thornton", "Joshua M. Susskind"], "title": "Mechanisms of Projective Composition of Diffusion Models", "categories": ["cs.LG"], "comment": "10 pages, 8 figures. The first two authors contributed equally", "summary": "We study the theoretical foundations of composition in diffusion models, with\na particular focus on out-of-distribution extrapolation and\nlength-generalization. Prior work has shown that composing distributions via\nlinear score combination can achieve promising results, including\nlength-generalization in some cases (Du et al., 2023; Liu et al., 2022).\nHowever, our theoretical understanding of how and why such compositions work\nremains incomplete. In fact, it is not even entirely clear what it means for\ncomposition to \"work\". This paper starts to address these fundamental gaps. We\nbegin by precisely defining one possible desired result of composition, which\nwe call projective composition. Then, we investigate: (1) when linear score\ncombinations provably achieve projective composition, (2) whether\nreverse-diffusion sampling can generate the desired composition, and (3) the\nconditions under which composition fails. We connect our theoretical analysis\nto prior empirical observations where composition has either worked or failed,\nfor reasons that were unclear at the time. Finally, we propose a simple\nheuristic to help predict the success or failure of new compositions.", "AI": {"tldr": "The paper explores the theoretical foundations of composition in diffusion models, focusing on out-of-distribution extrapolation and length-generalization. It defines projective composition, analyzes when linear score combinations achieve it, and identifies conditions for success or failure.", "motivation": "To address gaps in understanding how and why composition works in diffusion models, particularly for out-of-distribution tasks and length-generalization.", "method": "Defines projective composition, investigates linear score combinations, reverse-diffusion sampling, and conditions for failure. Connects theory to prior empirical observations.", "result": "Provides theoretical insights into when composition succeeds or fails and proposes a heuristic for predicting outcomes.", "conclusion": "The study advances understanding of composition in diffusion models and offers practical guidance for future applications."}}
{"id": "2505.08829", "pdf": "https://arxiv.org/pdf/2505.08829", "abs": "https://arxiv.org/abs/2505.08829", "authors": ["David Kinney"], "title": "Aggregating Concepts of Accuracy and Fairness in Prediction Algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al.", "AI": {"tldr": "The paper proposes using a linear combination of accuracy and fairness metrics to evaluate predictive algorithms, addressing tensions between these goals and leveraging Harsanyi's preference aggregation theory.", "motivation": "The rise of AI-driven predictive algorithms highlights the need to balance accuracy and fairness, but lacks clear guidelines for managing trade-offs between them.", "method": "The author argues for a linear combination of accuracy and fairness metrics, supported by Harsanyi's preference aggregation theory, and applies this to the COMPAS dataset.", "result": "The approach provides a formal framework for evaluating predictive algorithms when both accuracy and fairness are valued.", "conclusion": "A linear combination of metrics offers a principled way to assess predictive algorithms, addressing the challenges of balancing accuracy and fairness."}}
{"id": "2502.11505", "pdf": "https://arxiv.org/pdf/2502.11505", "abs": "https://arxiv.org/abs/2502.11505", "authors": ["Abubakar Isah", "Ibrahim Aliyu", "Sulaiman Muhammad Rashid", "Jaehyung Park", "Minsoo Hahn", "Jinsul Kim"], "title": "Graph Neural Network-based Spectral Filtering Mechanism for Imbalance Classification in Network Digital Twin", "categories": ["cs.LG", "cs.NI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2406.06595", "summary": "Graph neural networks are gaining attention in fifth-generation (5G) core\nnetwork digital twins, which are data-driven complex systems with numerous\ncomponents. Analyzing these data can be challenging due to rare failure types,\nleading to imbalanced classification in multiclass settings. Digital twins of\n5G networks increasingly employ graph classification as the main method for\nidentifying failure types. However, the skewed distribution of failure\noccurrences is a significant class-imbalance problem that prevents practical\ngraph data mining. Previous studies have not sufficiently addressed this\ncomplex problem. This paper, proposes class-Fourier GNN (CF-GNN) that\nintroduces a class-oriented spectral filtering mechanism to ensure precise\nclassification by estimating a unique spectral filter for each class. This work\nemploys eigenvalue and eigenvector spectral filtering to capture and adapt to\nvariations in minority classes, ensuring accurate class-specific feature\ndiscrimination, and adept at graph representation learning for complex local\nstructures among neighbors in an end-to-end setting. The extensive experiments\ndemonstrate that the proposed CF-GNN could help create new techniques for\nenhancing classifiers and investigate the characteristics of the multiclass\nimbalanced data in a network digital twin system.", "AI": {"tldr": "The paper proposes CF-GNN, a graph neural network with class-oriented spectral filtering, to address imbalanced classification in 5G network digital twins.", "motivation": "The challenge of imbalanced classification in multiclass settings for 5G core network digital twins, where rare failure types hinder practical graph data mining.", "method": "Introduces CF-GNN, which uses eigenvalue and eigenvector spectral filtering to create class-specific filters for precise classification.", "result": "CF-GNN effectively captures minority class variations and improves graph representation learning, as demonstrated in experiments.", "conclusion": "CF-GNN offers a novel approach to handling multiclass imbalanced data in network digital twins, enhancing classifier performance."}}
{"id": "2503.01521", "pdf": "https://arxiv.org/pdf/2503.01521", "abs": "https://arxiv.org/abs/2503.01521", "authors": ["Yuval Ben Dror"], "title": "R2VF: A Two-Step Regularization Algorithm to Cluster Categories in GLMs", "categories": ["cs.LG"], "comment": null, "summary": "Over recent decades, extensive research has aimed to overcome the restrictive\nunderlying assumptions required for a Generalized Linear Model to generate\naccurate and meaningful predictions. These efforts include regularizing\ncoefficients, selecting features, and clustering ordinal categories, among\nother approaches. Despite these advances, efficiently clustering nominal\ncategories in GLMs without incurring high computational costs remains a\nchallenge. This paper introduces Ranking to Variable Fusion (R2VF), a two-step\nmethod designed to efficiently fuse nominal and ordinal categories in GLMs. By\nfirst transforming nominal features into an ordinal framework via regularized\nregression and then applying variable fusion, R2VF strikes a balance between\nmodel complexity and interpretability. We demonstrate the effectiveness of R2VF\nthrough comparisons with other methods, highlighting its performance in\naddressing overfitting and identifying an appropriate set of covariates.", "AI": {"tldr": "R2VF is a two-step method for efficiently clustering nominal and ordinal categories in GLMs, balancing complexity and interpretability.", "motivation": "Overcoming the challenge of clustering nominal categories in GLMs without high computational costs.", "method": "Ranking to Variable Fusion (R2VF): transforms nominal features into ordinal via regularized regression, then applies variable fusion.", "result": "R2VF outperforms other methods in addressing overfitting and selecting covariates.", "conclusion": "R2VF effectively balances model complexity and interpretability in GLMs."}}
{"id": "2503.11900", "pdf": "https://arxiv.org/pdf/2503.11900", "abs": "https://arxiv.org/abs/2503.11900", "authors": ["Lauren Harrell", "Christine Kaeser-Chen", "Burcu Karagol Ayan", "Keith Anderson", "Michelangelo Conserva", "Elise Kleeman", "Maxim Neumann", "Matt Overlan", "Melissa Chapman", "Drew Purves"], "title": "Heterogeneous graph neural networks for species distribution modeling", "categories": ["cs.LG", "q-bio.PE", "stat.ML", "92B20 (Primary) 68T07, 92D40 (Secondary)", "I.2.1; J.3"], "comment": "13 pages, 3 figures,", "summary": "Species distribution models (SDMs) are necessary for measuring and predicting\noccurrences and habitat suitability of species and their relationship with\nenvironmental factors. We introduce a novel presence-only SDM with graph neural\nnetworks (GNN). In our model, species and locations are treated as two distinct\nnode sets, and the learning task is predicting detection records as the edges\nthat connect locations to species. Using GNN for SDM allows us to model\nfine-grained interactions between species and the environment. We evaluate the\npotential of this methodology on the six-region dataset compiled by National\nCenter for Ecological Analysis and Synthesis (NCEAS) for benchmarking SDMs. For\neach of the regions, the heterogeneous GNN model is comparable to or\noutperforms previously-benchmarked single-species SDMs as well as a\nfeed-forward neural network baseline model.", "AI": {"tldr": "A novel presence-only SDM using GNNs treats species and locations as node sets, predicting detection records as edges. It outperforms traditional SDMs and neural networks.", "motivation": "To improve species distribution modeling by capturing fine-grained interactions between species and environmental factors using GNNs.", "method": "Uses a heterogeneous GNN model with species and locations as distinct node sets, predicting detection records as edges. Evaluated on the NCEAS six-region dataset.", "result": "The GNN model matches or outperforms traditional single-species SDMs and a neural network baseline across all regions.", "conclusion": "GNNs offer a promising approach for SDMs by effectively modeling species-environment interactions."}}
{"id": "2503.16917", "pdf": "https://arxiv.org/pdf/2503.16917", "abs": "https://arxiv.org/abs/2503.16917", "authors": ["Ehsan Mirafzali", "Utkarsh Gupta", "Patrick Wyrod", "Frank Proske", "Daniele Venturi", "Razvan Marinescu"], "title": "Malliavin Calculus for Score-based Diffusion Models", "categories": ["cs.LG", "math.PR"], "comment": null, "summary": "We introduce a new framework based on Malliavin calculus to derive exact\nanalytical expressions for the score function $\\nabla \\log p_t(x)$, i.e., the\ngradient of the log-density associated with the solution to stochastic\ndifferential equations (SDEs). Our approach combines classical\nintegration-by-parts techniques with modern stochastic analysis tools, such as\nBismut's formula and Malliavin calculus, and it works for both linear and\nnonlinear SDEs. In doing so, we establish a rigorous connection between the\nMalliavin derivative, its adjoint, the Malliavin divergence (Skorokhod\nintegral), and diffusion generative models, thereby providing a systematic\nmethod for computing $\\nabla \\log p_t(x)$. In the linear case, we present a\ndetailed analysis showing that our formula coincides with the analytical score\nfunction derived from the solution of the Fokker--Planck equation. For\nnonlinear SDEs with state-independent diffusion coefficients, we derive a\nclosed-form expression for $\\nabla \\log p_t(x)$. We evaluate the proposed\nframework across multiple generative tasks and find that its performance is\ncomparable to state-of-the-art methods. These results can be generalised to\nbroader classes of SDEs, paving the way for new score-based diffusion\ngenerative models.", "AI": {"tldr": "A new framework using Malliavin calculus to derive exact analytical expressions for the score function in SDEs, applicable to both linear and nonlinear cases, with performance comparable to state-of-the-art methods.", "motivation": "To establish a rigorous connection between Malliavin calculus and diffusion generative models, enabling systematic computation of the score function for SDEs.", "method": "Combines integration-by-parts techniques with stochastic analysis tools (Bismut's formula, Malliavin calculus) for linear and nonlinear SDEs.", "result": "Derived closed-form expressions for the score function, validated in generative tasks with performance matching state-of-the-art methods.", "conclusion": "The framework generalizes to broader SDE classes, enabling new score-based diffusion generative models."}}
{"id": "2503.17037", "pdf": "https://arxiv.org/pdf/2503.17037", "abs": "https://arxiv.org/abs/2503.17037", "authors": ["Rebecca J. Herman", "Jonas Wahl", "Urmi Ninad", "Jakob Runge"], "title": "Unitless Unrestricted Markov-Consistent SCM Generation: Better Benchmark Datasets for Causal Discovery", "categories": ["cs.LG"], "comment": "4th Conference on Causal Learning and Reasoning", "summary": "Causal discovery aims to extract qualitative causal knowledge in the form of\ncausal graphs from data. Because causal ground truth is rarely known in the\nreal world, simulated data plays a vital role in evaluating the performance of\nthe various causal discovery algorithms proposed in the literature. But recent\nwork highlighted certain artifacts of commonly used data generation techniques\nfor a standard class of structural causal models (SCM) that may be nonphysical,\nincluding var- and R2-sortability, where the variables' variance and\ncoefficients of determination (R2) after regressing on all other variables,\nrespectively, increase along the causal order. Some causal methods exploit such\nartifacts, leading to unrealistic expectations for their performance on\nreal-world data. Some modifications have been proposed to remove these\nartifacts; notably, the internally-standardized structural causal model (iSCM)\navoids varsortability and largely alleviates R2-sortability on sparse causal\ngraphs, but exhibits a reversed R2-sortability pattern for denser graphs not\nfeatured in their work. We analyze which sortability patterns we expect to see\nin real data, and propose a method for drawing coefficients that we argue more\neffectively samples the space of SCMs. Finally, we propose a novel extension of\nour SCM generation method to the time series setting.", "AI": {"tldr": "The paper discusses artifacts in causal discovery data generation, proposes a method to avoid them, and extends it to time series.", "motivation": "Addressing unrealistic artifacts in simulated data used for evaluating causal discovery algorithms.", "method": "Proposes a method for drawing coefficients to better sample SCMs and extends it to time series.", "result": "Identifies and mitigates var- and R2-sortability artifacts, improving realism in evaluations.", "conclusion": "The proposed method enhances the reliability of causal discovery evaluations, especially for real-world applications."}}
{"id": "2504.04877", "pdf": "https://arxiv.org/pdf/2504.04877", "abs": "https://arxiv.org/abs/2504.04877", "authors": ["Viktor Beck", "Max Landauer", "Markus Wurzenberger", "Florian Skopik", "Andreas Rauber"], "title": "System Log Parsing with Large Language Models: A Review", "categories": ["cs.LG", "I.2; I.5"], "comment": "36 pages, 11 figures", "summary": "Log data provides crucial insights for tasks like monitoring, root cause\nanalysis, and anomaly detection. Due to the vast volume of logs, automated log\nparsing is essential to transform semi-structured log messages into structured\nrepresentations. Recent advances in large language models (LLMs) have\nintroduced the new research field of LLM-based log parsing. Despite promising\nresults, there is no structured overview of the approaches in this relatively\nnew research field with the earliest advances published in late 2023. This work\nsystematically reviews 29 LLM-based log parsing methods. We benchmark seven of\nthem on public datasets and critically assess their comparability and the\nreproducibility of their reported results. Our findings summarize the advances\nof this new research field, with insights on how to report results, which data\nsets, metrics and which terminology to use, and which inconsistencies to avoid,\nwith code and results made publicly available for transparency.", "AI": {"tldr": "This paper reviews 29 LLM-based log parsing methods, benchmarks 7 on public datasets, and provides insights on reporting, datasets, metrics, and terminology for this emerging field.", "motivation": "The need for automated log parsing due to vast log volumes and the emergence of LLM-based approaches, which lack a structured overview.", "method": "Systematic review of 29 LLM-based log parsing methods and benchmarking of 7 on public datasets.", "result": "Findings highlight advances, inconsistencies, and best practices for reporting results, datasets, and metrics.", "conclusion": "The study offers guidance for future research in LLM-based log parsing, promoting transparency and reproducibility."}}
{"id": "2504.09192", "pdf": "https://arxiv.org/pdf/2504.09192", "abs": "https://arxiv.org/abs/2504.09192", "authors": ["Zhiyong Wang"], "title": "Towards More Efficient, Robust, Instance-adaptive, and Generalizable Sequential Decision making", "categories": ["cs.LG"], "comment": "Ph.D. Thesis", "summary": "The primary goal of my Ph.D. study is to develop provably efficient and\npractical algorithms for data-driven sequential decision-making under\nuncertainty. My work focuses on reinforcement learning (RL), multi-armed\nbandits, and their applications, including recommendation systems, computer\nnetworks, video analytics, and large language models (LLMs). Sequential\ndecision-making methods, such as bandits and RL, have demonstrated remarkable\nsuccess - ranging from outperforming human players in complex games like Atari\nand Go to advancing robotics, recommendation systems, and fine-tuning LLMs.\nDespite these successes, many established algorithms rely on idealized models\nthat can fail under model misspecifications or adversarial perturbations,\nparticularly in settings where accurate prior knowledge of the underlying model\nclass is unavailable or where malicious users operate within dynamic systems.\nThese challenges are pervasive in real-world applications, where robust and\nadaptive solutions are critical. Furthermore, while worst-case guarantees\nprovide theoretical reliability, they often fail to capture instance-dependent\nperformance, which can lead to more efficient and practical solutions. Another\nkey challenge lies in generalizing to new, unseen environments, a crucial\nrequirement for deploying these methods in dynamic and unpredictable settings.\nTo address these limitations, my research aims to develop more efficient,\nrobust, instance-adaptive, and generalizable sequential decision-making\nalgorithms for both reinforcement learning and bandits. Towards this end, I\nfocus on developing more efficient, robust, instance-adaptive, and\ngeneralizable for both general reinforcement learning (RL) and bandits.", "AI": {"tldr": "The paper aims to develop efficient, robust, and adaptive algorithms for sequential decision-making in RL and bandits, addressing real-world challenges like model misspecifications and adversarial perturbations.", "motivation": "Existing algorithms often rely on idealized models, failing in real-world scenarios with uncertainty or adversarial conditions. The study seeks to improve robustness, adaptability, and generalization.", "method": "Focuses on developing provably efficient and practical algorithms for RL and bandits, emphasizing instance-adaptive and generalizable solutions.", "result": "Expected outcomes include more reliable and efficient algorithms for applications like recommendation systems, LLMs, and dynamic environments.", "conclusion": "The research aims to bridge the gap between theoretical guarantees and practical performance, enhancing the applicability of sequential decision-making methods in real-world settings."}}
{"id": "2504.12988", "pdf": "https://arxiv.org/pdf/2504.12988", "abs": "https://arxiv.org/abs/2504.12988", "authors": ["Yannis Montreuil", "Axel Carlier", "Lai Xing Ng", "Wei Tsang Ooi"], "title": "Why Ask One When You Can Ask $k$? Two-Stage Learning-to-Defer to the Top-$k$ Experts", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Although existing Learning-to-Defer (L2D) frameworks support multiple\nexperts, they allocate each query to a single expert, limiting their ability to\nleverage collective expertise in complex decision-making scenarios. To address\nthis, we introduce the first framework for Top-$k$ Learning-to-Defer, enabling\nsystems to defer each query to the $k$ most cost-effective experts. Our\nformulation strictly generalizes classical two-stage L2D by supporting\nmulti-expert deferral-a capability absent in prior work. We further propose\nTop-$k(x)$ Learning-to-Defer, an adaptive extension that learns the optimal\nnumber of experts per query based on input complexity, expert quality, and\nconsultation cost. We introduce a novel surrogate loss that is\nBayes-consistent, $(\\mathcal{R}, \\mathcal{G})$-consistent, and independent of\nthe cardinality parameter $k$, enabling efficient reuse across different values\nof $k$. We show that classical model cascades arise as a special case of our\nmethod, situating our framework as a strict generalization of both selective\ndeferral and cascaded inference. Experiments on classification and regression\ndemonstrate that Top-$k$ and Top-$k(x)$ yield improved accuracy--cost\ntrade-offs, establishing a new direction for multi-expert deferral in\nLearning-to-Defer.", "AI": {"tldr": "The paper introduces Top-$k$ Learning-to-Defer (L2D), a framework allowing deferral to multiple experts, improving decision-making by leveraging collective expertise. It also proposes an adaptive variant, Top-$k(x)$, optimizing the number of experts per query.", "motivation": "Existing L2D frameworks limit deferral to a single expert, missing opportunities to utilize collective expertise in complex scenarios.", "method": "The paper introduces Top-$k$ L2D for deferring to $k$ experts and Top-$k(x)$ for adaptive deferral. A novel surrogate loss ensures consistency and efficiency.", "result": "Experiments show improved accuracy-cost trade-offs, validating the framework's effectiveness.", "conclusion": "The work generalizes classical L2D and cascaded inference, offering a new direction for multi-expert deferral."}}
{"id": "2504.18008", "pdf": "https://arxiv.org/pdf/2504.18008", "abs": "https://arxiv.org/abs/2504.18008", "authors": ["Nooshin Yousefzadeh", "Rahul Sengupta", "Jeremy Dilmore", "Sanjay Ranka"], "title": "TGDT: A Temporal Graph-based Digital Twin for Urban Traffic Corridors", "categories": ["cs.LG"], "comment": "8 pages, 4 figures, 1 table", "summary": "Urban congestion at signalized intersections leads to significant delays,\neconomic losses, and increased emissions. Existing deep learning models often\nlack spatial generalizability, rely on complex architectures, and struggle with\nreal-time deployment. To address these limitations, we propose the Temporal\nGraph-based Digital Twin (TGDT), a scalable framework that integrates Temporal\nConvolutional Networks and Attentional Graph Neural Networks for dynamic,\ndirection-aware traffic modeling and assessment at urban corridors. TGDT\nestimates key Measures of Effectiveness (MOEs) for traffic flow optimization at\nboth the intersection level (e.g., queue length, waiting time) and the corridor\nlevel (e.g., traffic volume, travel time). Its modular architecture and\nsequential optimization scheme enable easy extension to any number of\nintersections and MOEs. The model outperforms state-of-the-art baselines by\naccurately producing high-dimensional, concurrent multi-output estimates. It\nalso demonstrates high robustness and accuracy across diverse traffic\nconditions, including extreme scenarios, while relying on only a minimal set of\ntraffic features. Fully parallelized, TGDT can simulate over a thousand\nscenarios within a matter of seconds, offering a cost-effective, interpretable,\nand real-time solution for urban traffic management and optimization.", "AI": {"tldr": "TGDT is a scalable framework combining Temporal Convolutional Networks and Attentional Graph Neural Networks for real-time, direction-aware traffic modeling, outperforming existing methods in accuracy and robustness.", "motivation": "Urban congestion causes delays, economic losses, and emissions, while current deep learning models lack spatial generalizability and real-time deployment capabilities.", "method": "TGDT integrates Temporal Convolutional Networks and Attentional Graph Neural Networks for dynamic traffic modeling, estimating key traffic measures at intersection and corridor levels.", "result": "TGDT outperforms state-of-the-art baselines, providing high-dimensional, concurrent multi-output estimates with high robustness and accuracy across diverse conditions.", "conclusion": "TGDT offers a cost-effective, interpretable, and real-time solution for urban traffic management, capable of simulating thousands of scenarios quickly."}}
{"id": "2505.04560", "pdf": "https://arxiv.org/pdf/2505.04560", "abs": "https://arxiv.org/abs/2505.04560", "authors": ["Guanghui Wang", "Zhiyong Yang", "Zitai Wang", "Shi Wang", "Qianqian Xu", "Qingming Huang"], "title": "ABKD: Pursuing a Proper Allocation of the Probability Mass in Knowledge Distillation via $\u03b1$-$\u03b2$-Divergence", "categories": ["cs.LG"], "comment": "ICML 2025 Spotlight", "summary": "Knowledge Distillation (KD) transfers knowledge from a large teacher model to\na smaller student model by minimizing the divergence between their output\ndistributions, typically using forward Kullback-Leibler divergence (FKLD) or\nreverse KLD (RKLD). It has become an effective training paradigm due to the\nbroader supervision information provided by the teacher distribution compared\nto one-hot labels. We identify that the core challenge in KD lies in balancing\ntwo mode-concentration effects: the \\textbf{\\textit{Hardness-Concentration}}\neffect, which refers to focusing on modes with large errors, and the\n\\textbf{\\textit{Confidence-Concentration}} effect, which refers to focusing on\nmodes with high student confidence. Through an analysis of how probabilities\nare reassigned during gradient updates, we observe that these two effects are\nentangled in FKLD and RKLD, but in extreme forms. Specifically, both are too\nweak in FKLD, causing the student to fail to concentrate on the target class.\nIn contrast, both are too strong in RKLD, causing the student to overly\nemphasize the target class while ignoring the broader distributional\ninformation from the teacher. To address this imbalance, we propose ABKD, a\ngeneric framework with $\\alpha$-$\\beta$-divergence. Our theoretical results\nshow that ABKD offers a smooth interpolation between FKLD and RKLD, achieving\nan effective trade-off between these effects. Extensive experiments on 17\nlanguage/vision datasets with 12 teacher-student settings confirm its efficacy.\nThe code is available at https://github.com/ghwang-s/abkd.", "AI": {"tldr": "ABKD introduces \u03b1-\u03b2-divergence to balance Hardness-Concentration and Confidence-Concentration effects in Knowledge Distillation, outperforming FKLD and RKLD.", "motivation": "The core challenge in KD is balancing Hardness-Concentration and Confidence-Concentration effects, which are entangled in FKLD and RKLD.", "method": "Proposes ABKD, a framework using \u03b1-\u03b2-divergence to interpolate between FKLD and RKLD, balancing the two effects.", "result": "ABKD achieves a trade-off between the effects, validated on 17 datasets with 12 teacher-student settings.", "conclusion": "ABKD effectively addresses the imbalance in KD, offering a superior alternative to FKLD and RKLD."}}
{"id": "2505.05926", "pdf": "https://arxiv.org/pdf/2505.05926", "abs": "https://arxiv.org/abs/2505.05926", "authors": ["Milad Khademi Nori", "Il-Min Kim", "Guanghui Wang"], "title": "Autoencoder-Based Hybrid Replay for Class-Incremental Learning", "categories": ["cs.LG"], "comment": "Accepted ICML 2025", "summary": "In class-incremental learning (CIL), effective incremental learning\nstrategies are essential to mitigate task confusion and catastrophic\nforgetting, especially as the number of tasks $t$ increases. Current exemplar\nreplay strategies impose $\\mathcal{O}(t)$ memory/compute complexities. We\npropose an autoencoder-based hybrid replay (AHR) strategy that leverages our\nnew hybrid autoencoder (HAE) to function as a compressor to alleviate the\nrequirement for large memory, achieving $\\mathcal{O}(0.1 t)$ at the worst case\nwith the computing complexity of $\\mathcal{O}(t)$ while accomplishing\nstate-of-the-art performance. The decoder later recovers the exemplar data\nstored in the latent space, rather than in raw format. Additionally, HAE is\ndesigned for both discriminative and generative modeling, enabling\nclassification and replay capabilities, respectively. HAE adopts the charged\nparticle system energy minimization equations and repulsive force algorithm for\nthe incremental embedding and distribution of new class centroids in its latent\nspace. Our results demonstrate that AHR consistently outperforms recent\nbaselines across multiple benchmarks while operating with the same\nmemory/compute budgets. The source code is included in the supplementary\nmaterial and will be open-sourced upon publication.", "AI": {"tldr": "Proposes an autoencoder-based hybrid replay (AHR) strategy for class-incremental learning, reducing memory complexity to O(0.1t) while maintaining state-of-the-art performance.", "motivation": "Addresses the challenges of task confusion and catastrophic forgetting in class-incremental learning, aiming to reduce memory and compute complexities.", "method": "Uses a hybrid autoencoder (HAE) as a compressor for exemplar replay, employing energy minimization and repulsive force algorithms for incremental embedding.", "result": "AHR outperforms recent baselines with reduced memory usage and maintains high performance.", "conclusion": "The proposed AHR strategy effectively balances memory efficiency and performance in class-incremental learning."}}
{"id": "2505.06945", "pdf": "https://arxiv.org/pdf/2505.06945", "abs": "https://arxiv.org/abs/2505.06945", "authors": ["Maryam Farhadizadeh", "Maria Weymann", "Michael Bla\u00df", "Johann Kraus", "Christopher Gundler", "Sebastian Walter", "Noah Hempen", "Harald Binder", "Nadine Binder"], "title": "A systematic review of challenges and proposed solutions in modeling multimodal data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multimodal data modeling has emerged as a powerful approach in clinical\nresearch, enabling the integration of diverse data types such as imaging,\ngenomics, wearable sensors, and electronic health records. Despite its\npotential to improve diagnostic accuracy and support personalized care,\nmodeling such heterogeneous data presents significant technical challenges.\nThis systematic review synthesizes findings from 69 studies to identify common\nobstacles, including missing modalities, limited sample sizes, dimensionality\nimbalance, interpretability issues, and finding the optimal fusion techniques.\nWe highlight recent methodological advances, such as transfer learning,\ngenerative models, attention mechanisms, and neural architecture search that\noffer promising solutions. By mapping current trends and innovations, this\nreview provides a comprehensive overview of the field and offers practical\ninsights to guide future research and development in multimodal modeling for\nmedical applications.", "AI": {"tldr": "A systematic review of 69 studies on multimodal data modeling in clinical research, identifying challenges and highlighting recent methodological advances to improve diagnostic accuracy and personalized care.", "motivation": "To address the technical challenges of integrating diverse data types (e.g., imaging, genomics, wearable sensors) in clinical research and improve diagnostic and personalized care outcomes.", "method": "Systematic review of 69 studies to identify common obstacles (e.g., missing modalities, dimensionality imbalance) and evaluate recent methodological advances like transfer learning and generative models.", "result": "Identified key challenges and promising solutions, such as attention mechanisms and neural architecture search, for multimodal data modeling in medical applications.", "conclusion": "The review provides a comprehensive overview and practical insights to guide future research in multimodal modeling for healthcare."}}
{"id": "2505.07575", "pdf": "https://arxiv.org/pdf/2505.07575", "abs": "https://arxiv.org/abs/2505.07575", "authors": ["Samuel Erickson", "Mikael Johansson"], "title": "Personalized Federated Learning under Model Dissimilarity Constraints", "categories": ["cs.LG"], "comment": null, "summary": "One of the defining challenges in federated learning is that of statistical\nheterogeneity among clients. We address this problem with KARULA, a regularized\nstrategy for personalized federated learning, which constrains the pairwise\nmodel dissimilarities between clients based on the difference in their\ndistributions, as measured by a surrogate for the 1-Wasserstein distance\nadapted for the federated setting. This allows the strategy to adapt to highly\ncomplex interrelations between clients, that e.g., clustered approaches fail to\ncapture. We propose an inexact projected stochastic gradient algorithm to solve\nthe constrained problem that the strategy defines, and show theoretically that\nit converges with smooth, possibly non-convex losses to a neighborhood of a\nstationary point with rate O(1/K). We demonstrate the effectiveness of KARULA\non synthetic and real federated data sets.", "AI": {"tldr": "KARULA is a regularized strategy for personalized federated learning that addresses statistical heterogeneity by constraining model dissimilarities between clients based on distribution differences.", "motivation": "Statistical heterogeneity among clients is a major challenge in federated learning, which KARULA aims to solve by adapting to complex interrelations between clients.", "method": "KARULA uses a surrogate for the 1-Wasserstein distance to constrain pairwise model dissimilarities and employs an inexact projected stochastic gradient algorithm for optimization.", "result": "The algorithm converges to a neighborhood of a stationary point with rate O(1/K) for smooth, possibly non-convex losses.", "conclusion": "KARULA demonstrates effectiveness on synthetic and real federated datasets, outperforming clustered approaches."}}
{"id": "2505.09089", "pdf": "https://arxiv.org/pdf/2505.09089", "abs": "https://arxiv.org/abs/2505.09089", "authors": ["Philipp Hess", "Maximilian Gelbrecht", "Christof Sch\u00f6tz", "Michael Aich", "Yu Huang", "Shangshang Yang", "Niklas Boers"], "title": "Generating time-consistent dynamics with discriminator-guided image diffusion models", "categories": ["cs.LG"], "comment": null, "summary": "Realistic temporal dynamics are crucial for many video generation, processing\nand modelling applications, e.g. in computational fluid dynamics, weather\nprediction, or long-term climate simulations. Video diffusion models (VDMs) are\nthe current state-of-the-art method for generating highly realistic dynamics.\nHowever, training VDMs from scratch can be challenging and requires large\ncomputational resources, limiting their wider application. Here, we propose a\ntime-consistency discriminator that enables pretrained image diffusion models\nto generate realistic spatiotemporal dynamics. The discriminator guides the\nsampling inference process and does not require extensions or finetuning of the\nimage diffusion model. We compare our approach against a VDM trained from\nscratch on an idealized turbulence simulation and a real-world global\nprecipitation dataset. Our approach performs equally well in terms of temporal\nconsistency, shows improved uncertainty calibration and lower biases compared\nto the VDM, and achieves stable centennial-scale climate simulations at daily\ntime steps.", "AI": {"tldr": "A time-consistency discriminator is proposed to adapt pretrained image diffusion models for realistic spatiotemporal dynamics, matching VDMs in performance with added benefits like improved uncertainty calibration.", "motivation": "Realistic temporal dynamics are essential for applications like weather prediction and climate simulations, but training VDMs from scratch is resource-intensive.", "method": "A time-consistency discriminator is introduced to guide sampling in pretrained image diffusion models without modifying or finetuning them.", "result": "The method matches VDMs in temporal consistency, improves uncertainty calibration, reduces biases, and enables stable long-term climate simulations.", "conclusion": "The proposed discriminator efficiently leverages pretrained models for spatiotemporal tasks, offering a practical alternative to VDMs."}}
{"id": "2505.09427", "pdf": "https://arxiv.org/pdf/2505.09427", "abs": "https://arxiv.org/abs/2505.09427", "authors": ["Achref Doula", "Max M\u00fchlh\u00e4user", "Alejandro Sanchez Guinea"], "title": "SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Large Language Models (LLMs) show growing promise in autonomous driving by\nreasoning over complex traffic scenarios to generate path plans. However, their\ntendencies toward overconfidence, and hallucinations raise critical safety\nconcerns. We introduce SafePath, a modular framework that augments LLM-based\npath planning with formal safety guarantees using conformal prediction.\nSafePath operates in three stages. In the first stage, we use an LLM that\ngenerates a set of diverse candidate paths, exploring possible trajectories\nbased on agent behaviors and environmental cues. In the second stage, SafePath\nfilters out high-risk trajectories while guaranteeing that at least one safe\noption is included with a user-defined probability, through a multiple-choice\nquestion-answering formulation that integrates conformal prediction. In the\nfinal stage, our approach selects the path with the lowest expected collision\nrisk when uncertainty is low or delegates control to a human when uncertainty\nis high. We theoretically prove that SafePath guarantees a safe trajectory with\na user-defined probability, and we show how its human delegation rate can be\ntuned to balance autonomy and safety. Extensive experiments on nuScenes and\nHighway-env show that SafePath reduces planning uncertainty by 77\\% and\ncollision rates by up to 70\\%, demonstrating effectiveness in making LLM-driven\npath planning more safer.", "AI": {"tldr": "SafePath enhances LLM-based path planning in autonomous driving with formal safety guarantees using conformal prediction, reducing uncertainty and collision rates.", "motivation": "Addressing safety concerns like overconfidence and hallucinations in LLMs for autonomous driving path planning.", "method": "A three-stage modular framework: LLM generates diverse paths, filters high-risk ones with conformal prediction, and selects the safest path or delegates to humans.", "result": "SafePath reduces planning uncertainty by 77% and collision rates by up to 70%.", "conclusion": "SafePath effectively balances autonomy and safety in LLM-driven path planning."}}
{"id": "2505.09432", "pdf": "https://arxiv.org/pdf/2505.09432", "abs": "https://arxiv.org/abs/2505.09432", "authors": ["Yuzhou Cao", "Han Bao", "Lei Feng", "Bo An"], "title": "Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenchel-Young Losses", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Surrogate regret bounds, also known as excess risk bounds, bridge the gap\nbetween the convergence rates of surrogate and target losses, with linear\nbounds favorable for their lossless regret transfer. While convex smooth\nsurrogate losses are appealing in particular due to the efficient estimation\nand optimization, the existence of a trade-off between the smoothness and\nlinear regret bound has been believed in the community. That being said, the\nbetter optimization and estimation properties of convex smooth surrogate losses\nmay inevitably deteriorate after undergoing the regret transfer onto a target\nloss. We overcome this dilemma for arbitrary discrete target losses by\nconstructing a convex smooth surrogate loss, which entails a linear surrogate\nregret bound composed with a tailored prediction link. The construction is\nbased on Fenchel-Young losses generated by the convolutional negentropy, which\nare equivalent to the infimal convolution of a generalized negentropy and the\ntarget Bayes risk. Consequently, the infimal convolution enables us to derive a\nsmooth loss while maintaining the surrogate regret bound linear. We\nadditionally benefit from the infimal convolution to have a consistent\nestimator of the underlying class probability. Our results are overall a novel\ndemonstration of how convex analysis penetrates into optimization and\nstatistical efficiency in risk minimization.", "AI": {"tldr": "The paper addresses the trade-off between smoothness and linear regret bounds in convex smooth surrogate losses, proposing a solution for discrete target losses using Fenchel-Young losses and infimal convolution.", "motivation": "The study aims to resolve the perceived trade-off between smoothness and linear regret bounds in surrogate losses, which affects optimization and estimation efficiency.", "method": "The authors construct a convex smooth surrogate loss using Fenchel-Young losses generated by convolutional negentropy, leveraging infimal convolution to maintain linear regret bounds.", "result": "The proposed method achieves a smooth surrogate loss with linear regret bounds and provides a consistent estimator for class probability.", "conclusion": "The work demonstrates how convex analysis can enhance optimization and statistical efficiency in risk minimization, overcoming prior limitations."}}
{"id": "2505.09503", "pdf": "https://arxiv.org/pdf/2505.09503", "abs": "https://arxiv.org/abs/2505.09503", "authors": ["Patrik Kenfack", "Samira Ebrahimi Kahou", "Ulrich A\u00efvodji"], "title": "Towards Fair In-Context Learning with Tabular Foundation Models", "categories": ["cs.LG"], "comment": "24 pages, 10 figures, 4 tables", "summary": "Tabular foundational models have exhibited strong in-context learning (ICL)\ncapabilities on structured data, allowing them to make accurate predictions on\ntest sets without parameter updates, using training examples as context. This\nemerging approach positions itself as a competitive alternative to traditional\ngradient-boosted tree methods. However, while biases in conventional machine\nlearning models are well documented, it remains unclear how these biases\nmanifest in tabular ICL. The paper investigates the fairness implications of\ntabular ICL and explores three preprocessing strategies--correlation removal,\ngroup-balanced demonstration selection, and uncertainty-based demonstration\nselection--to address bias. Comprehensive experiments indicate that\nuncertainty-based demonstration selection consistently enhances group fairness\nof in-context predictions. The source code for reproducing the results of this\nwork can be found at https://github.com/patrikken/Fair-TabICL.", "AI": {"tldr": "The paper explores fairness in tabular in-context learning (ICL), comparing it to traditional methods and testing bias-mitigation strategies. Uncertainty-based demonstration selection improves fairness.", "motivation": "To understand how biases manifest in tabular ICL and evaluate strategies to mitigate them, as biases in traditional ML are well-documented but unclear in ICL.", "method": "Investigates fairness in tabular ICL using three preprocessing strategies: correlation removal, group-balanced demonstration selection, and uncertainty-based demonstration selection.", "result": "Uncertainty-based demonstration selection consistently improves group fairness in ICL predictions.", "conclusion": "Tabular ICL can achieve fairness with uncertainty-based demonstration selection, offering a viable alternative to traditional methods."}}
{"id": "2209.13814", "pdf": "https://arxiv.org/pdf/2209.13814", "abs": "https://arxiv.org/abs/2209.13814", "authors": ["Yuli Liu"], "title": "Signed Latent Factors for Spamming Activity Detection", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Due to the increasing trend of performing spamming activities (e.g., Web\nspam, deceptive reviews, fake followers, etc.) on various online platforms to\ngain undeserved benefits, spam detection has emerged as a hot research issue.\nPrevious attempts to combat spam mainly employ features related to metadata,\nuser behaviors, or relational ties. These studies have made considerable\nprogress in understanding and filtering spamming campaigns. However, this\nproblem remains far from fully solved. Almost all the proposed features focus\non a limited number of observed attributes or explainable phenomena, making it\ndifficult for existing methods to achieve further improvement. To broaden the\nvision about solving the spam problem and address long-standing challenges\n(class imbalance and graph incompleteness) in the spam detection area, we\npropose a new attempt of utilizing signed latent factors to filter fraudulent\nactivities. The spam-contaminated relational datasets of multiple online\napplications in this scenario are interpreted by the unified signed network.\nTwo competitive and highly dissimilar algorithms of latent factors mining (LFM)\nmodels are designed based on multi-relational likelihoods estimation (LFM-MRLE)\nand signed pairwise ranking (LFM-SPR), respectively. We then explore how to\napply the mined latent factors to spam detection tasks. Experiments on\nreal-world datasets of different kinds of Web applications (social media and\nWeb forum) indicate that LFM models outperform state-of-the-art baselines in\ndetecting spamming activities. By specifically manipulating experimental data,\nthe effectiveness of our methods in dealing with incomplete and imbalanced\nchallenges is validated.", "AI": {"tldr": "The paper proposes using signed latent factors to improve spam detection, addressing challenges like class imbalance and graph incompleteness, and shows superior performance over existing methods.", "motivation": "Spam detection remains unsolved due to limited feature focus; the paper aims to broaden the approach using latent factors.", "method": "Two latent factor mining (LFM) models (LFM-MRLE and LFM-SPR) are designed for spam detection in signed networks.", "result": "LFM models outperform state-of-the-art baselines in detecting spam across various web applications.", "conclusion": "The proposed methods effectively address class imbalance and graph incompleteness, validating their robustness."}}
{"id": "2211.09251", "pdf": "https://arxiv.org/pdf/2211.09251", "abs": "https://arxiv.org/abs/2211.09251", "authors": ["Jingbang Chen", "Xinyuan Cao", "Alicia Stepin", "Li Chen"], "title": "On the Power of Learning-Augmented Search Trees", "categories": ["cs.DS", "cs.LG"], "comment": "Accepted by ICML25", "summary": "We study learning-augmented binary search trees (BSTs) via Treaps with\ncarefully designed priorities. The result is a simple search tree in which the\ndepth of each item $x$ is determined by its predicted weight $w_x$.\nSpecifically, each item $x$ is assigned a composite priority of\n$-\\lfloor\\log\\log(1/w_x)\\rfloor + U(0, 1)$ where $U(0, 1)$ is the uniform\nrandom variable. By choosing $w_x$ as the relative frequency of $x$, the\nresulting search trees achieve static optimality. This approach generalizes the\nrecent learning-augmented BSTs [Lin-Luo-Woodruff ICML '22], which only work for\nZipfian distributions, by extending them to arbitrary input distributions.\nFurthermore, we demonstrate that our method can be generalized to a B-Tree data\nstructure using the B-Treap approach [Golovin ICALP '09]. Our search trees are\nalso capable of leveraging localities in the access sequence through online\nself-reorganization, thereby achieving the working-set property. Additionally,\nthey are robust to prediction errors and support dynamic operations, such as\ninsertions, deletions, and prediction updates. We complement our analysis with\nan empirical study, demonstrating that our method outperforms prior work and\nclassic data structures.", "AI": {"tldr": "The paper introduces learning-augmented BSTs using Treaps with composite priorities based on predicted weights, achieving static optimality and extending prior work to arbitrary distributions. It also generalizes to B-Trees and supports dynamic operations and robustness to prediction errors.", "motivation": "To enhance binary search trees by incorporating learned predictions (weights) to improve performance, generalizing prior work limited to Zipfian distributions and enabling dynamic operations.", "method": "Assigns composite priorities to items using predicted weights and uniform randomness, forming Treaps. Extends to B-Trees via B-Treaps and supports online reorganization for locality.", "result": "Achieves static optimality, works for arbitrary distributions, and outperforms prior methods and classic structures in empirical tests.", "conclusion": "The proposed method effectively integrates learning into BSTs, offering versatility, robustness, and superior performance across various scenarios."}}
{"id": "2304.05341", "pdf": "https://arxiv.org/pdf/2304.05341", "abs": "https://arxiv.org/abs/2304.05341", "authors": ["Mayk Caldas Ramos", "Shane S. Michtavy", "Marc D. Porosoff", "Andrew D. White"], "title": "Bayesian Optimization of Catalysis With In-Context Learning", "categories": ["physics.chem-ph", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) can perform accurate classification with zero or\nfew examples through in-context learning. We extend this capability to\nregression with uncertainty estimation using frozen LLMs (e.g., GPT-3.5,\nGemini), enabling Bayesian optimization (BO) in natural language without\nexplicit model training or feature engineering. We apply this to materials\ndiscovery by representing experimental catalyst synthesis and testing\nprocedures as natural language prompts. A key challenge in materials discovery\nis the need to characterize suboptimal candidates, which slows progress. While\nBO is effective for navigating large design spaces, standard surrogate models\nlike Gaussian processes assume smoothness and continuity, an assumption that\nfails in highly non-linear domains such as heterogeneous catalysis. Our\ntask-agnostic BO workflow overcomes this by operating directly in language\nspace, producing interpretable and actionable predictions without requiring\nstructural or electronic descriptors. On benchmarks like aqueous solubility and\noxidative coupling of methane (OCM), BO-ICL matches or outperforms Gaussian\nprocesses. In live experiments on the reverse water-gas shift (RWGS) reaction,\nBO-ICL identifies near-optimal multi-metallic catalysts within six iterations\nfrom a pool of 3,700 candidates. Our method redefines materials representation\nand accelerates discovery, with broad applications across catalysis, materials\nscience, and AI. Code: https://github.com/ur-whitelab/BO-ICL.", "AI": {"tldr": "The paper extends LLMs' in-context learning to regression with uncertainty estimation, enabling Bayesian optimization (BO) in natural language for materials discovery, outperforming traditional methods like Gaussian processes.", "motivation": "Materials discovery is slowed by the need to characterize suboptimal candidates. Traditional BO methods assume smoothness, which fails in non-linear domains like catalysis.", "method": "Uses frozen LLMs (e.g., GPT-3.5, Gemini) for task-agnostic BO in natural language, avoiding explicit training or feature engineering. Applied to catalyst synthesis and testing.", "result": "BO-ICL matches or outperforms Gaussian processes on benchmarks (aqueous solubility, OCM) and identifies near-optimal catalysts in live RWGS experiments within six iterations.", "conclusion": "The method redefines materials representation, accelerates discovery, and has broad applications in catalysis, materials science, and AI."}}
{"id": "2311.04229", "pdf": "https://arxiv.org/pdf/2311.04229", "abs": "https://arxiv.org/abs/2311.04229", "authors": ["Amir Salimi", "Sunil Vasu Kalmady", "Abram Hindle", "Osmar Zaiane", "Padma Kaul"], "title": "Exploring Best Practices for ECG Pre-Processing in Machine Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "In this work we search for best practices in pre-processing of\nElectrocardiogram (ECG) signals in order to train better classifiers for the\ndiagnosis of heart conditions. State of the art machine learning algorithms\nhave achieved remarkable results in classification of some heart conditions\nusing ECG data, yet there appears to be no consensus on pre-processing best\npractices. Is this lack of consensus due to different conditions and\narchitectures requiring different processing steps for optimal performance? Is\nit possible that state of the art deep-learning models have rendered\npre-processing unnecessary? In this work we apply down-sampling, normalization,\nand filtering functions to 3 different multi-label ECG datasets and measure\ntheir effects on 3 different high-performing time-series classifiers. We find\nthat sampling rates as low as 50Hz can yield comparable results to the commonly\nused 500Hz. This is significant as smaller sampling rates will result in\nsmaller datasets and models, which require less time and resources to train.\nAdditionally, despite their common usage, we found min-max normalization to be\nslightly detrimental overall, and band-passing to make no measurable\ndifference. We found the blind approach to pre-processing of ECGs for\nmulti-label classification to be ineffective, with the exception of sample rate\nreduction which reliably reduces computational resources, but does not increase\naccuracy.", "AI": {"tldr": "The paper investigates pre-processing practices for ECG signals to improve classifier performance, finding that lower sampling rates (50Hz) are as effective as higher ones (500Hz), while common techniques like min-max normalization and band-passing offer little to no benefit.", "motivation": "To determine optimal pre-processing steps for ECG signals in training classifiers for heart condition diagnosis, given the lack of consensus in current practices.", "method": "Applied down-sampling, normalization, and filtering to 3 ECG datasets and evaluated their effects on 3 time-series classifiers.", "result": "Lower sampling rates (50Hz) performed comparably to 500Hz, reducing computational needs. Min-max normalization slightly harmed performance, and band-passing had no measurable impact.", "conclusion": "Pre-processing for multi-label ECG classification is largely ineffective except for sample rate reduction, which saves resources without improving accuracy."}}
{"id": "2405.11752", "pdf": "https://arxiv.org/pdf/2405.11752", "abs": "https://arxiv.org/abs/2405.11752", "authors": ["Zihao Wang", "Zhe Wu"], "title": "Towards Foundation Model for Chemical Reactor Modeling: Meta-Learning with Physics-Informed Adaptation", "categories": ["cs.CE", "cs.LG"], "comment": "Chemical Engineering Research and Design", "summary": "Developing accurate models for chemical reactors is often challenging due to\nthe complexity of reaction kinetics and process dynamics. Traditional\napproaches require retraining models for each new system, limiting\ngeneralizability and efficiency. In this work, we take a step toward foundation\nmodels for chemical reactor modeling by introducing a neural network framework\nthat generalizes across diverse reactor types and rapidly adapts to new\nchemical processes. Our approach leverages meta-learning to pretrain the model\non a broad set of reactor dynamics, enabling efficient adaptation to unseen\nreactions with minimal data. To further enhance generalizability, we\nincorporate physics-informed fine-tuning, ensuring physically consistent\nadaptation to new reactor conditions. Our framework is evaluated across three\ninteger-order fundamental reactor types - continuous stirred tank reactors,\nbatch reactors, and plug flow reactors - demonstrating superior few-shot\nadaptation compared to conventional data-driven, physics-informed, and transfer\nlearning approaches. By combining meta-learning with physics-informed\nadaptation, this work lays the foundation for a generalizable modeling\nframework, advancing the development of foundation models for chemical\nengineering applications. Source code is available at\nhttps://github.com/killingbear999/chemical-reactor-foundation-model.", "AI": {"tldr": "A neural network framework using meta-learning and physics-informed fine-tuning for generalizable chemical reactor modeling, outperforming traditional methods.", "motivation": "Traditional reactor models lack generalizability and efficiency, requiring retraining for each new system. This work aims to create a foundation model for diverse reactor types.", "method": "The framework combines meta-learning for pretraining on diverse reactor dynamics and physics-informed fine-tuning for adaptation to new processes with minimal data.", "result": "Evaluated on three reactor types, the framework shows superior few-shot adaptation compared to conventional methods.", "conclusion": "The work advances foundation models for chemical engineering by integrating meta-learning and physics-informed adaptation, offering a generalizable solution."}}
{"id": "2410.01223", "pdf": "https://arxiv.org/pdf/2410.01223", "abs": "https://arxiv.org/abs/2410.01223", "authors": ["Chengpu Wang"], "title": "Statistical Taylor Expansion", "categories": ["stat.CO", "cs.LG", "65G99", "G.3.2"], "comment": "65 pages, 53 figures", "summary": "Statistical Taylor expansion replaces the input precise variables in a\nconventional Taylor expansion with random variables each with known\ndistribution, to calculate the result mean and deviation. It is based on the\nuncorrelated uncertainty assumption: Each input variable is measured\nindependently with fine enough statistical precision, so that their\nuncertainties are independent of each other. Statistical Taylor expansion\nreviews that the intermediate analytic expressions can no longer be regarded as\nindependent of each other, and the result of analytic expression should be path\nindependent. This conclusion differs fundamentally from the conventional common\napproach in applied mathematics to find the best execution path for a result.\nThis paper also presents an implementation of statistical Taylor expansion\ncalled variance arithmetic, and the tests on variance arithmetic.", "AI": {"tldr": "Statistical Taylor expansion replaces precise variables with random ones to compute mean and deviation, assuming uncorrelated uncertainties. It challenges conventional path-dependent methods and introduces variance arithmetic.", "motivation": "To address the limitations of conventional Taylor expansions by incorporating random variables and uncorrelated uncertainties, providing a more robust method for calculating results.", "method": "Uses statistical Taylor expansion with uncorrelated uncertainty assumption and introduces variance arithmetic for implementation.", "result": "Shows that intermediate analytic expressions are interdependent and results are path-independent, differing from conventional methods.", "conclusion": "Statistical Taylor expansion offers a novel approach, validated by variance arithmetic tests, challenging traditional applied mathematics methods."}}
{"id": "2410.01755", "pdf": "https://arxiv.org/pdf/2410.01755", "abs": "https://arxiv.org/abs/2410.01755", "authors": ["Hossein Sholehrasa"], "title": "Integrating Protein Sequence and Expression Level to Analysis Molecular Characterization of Breast Cancer Subtypes", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Breast cancer's complexity and variability pose significant challenges in\nunderstanding its progression and guiding effective treatment. This study aims\nto integrate protein sequence data with expression levels to improve the\nmolecular characterization of breast cancer subtypes and predict clinical\noutcomes. Using ProtGPT2, a language model designed for protein sequences, we\ngenerated embeddings that capture the functional and structural properties of\nproteins sequence. These embeddings were integrated with protein expression\nlevel to form enriched biological representations, which were analyzed using\nmachine learning methods like ensemble K-means for clustering and XGBoost for\nclassification. Our approach enabled successful clustering of patients into\nbiologically distinct groups and accurately predicted clinical outcomes such as\nsurvival and biomarkers status, achieving high performance metrics, notably an\nF1 score of 0.88 for survival and 0.87 for biomarkers status prediction.\nFeature importance analysis identified KMT2C, CLASP2, and MYO1B as key proteins\ninvolved in hormone signaling, cytoskeletal remodeling, and therapy resistance\nin hormone receptor-positive and triple-negative breast cancer, with potential\ninfluence on breast cancer subtype behavior and progression. Furthermore,\nprotein-protein interaction networks and correlation analyses revealed\nfunctional interdependencies among proteins that may influence breast cancer\nsubtype behavior and progression. These findings suggest that integrating\nprotein sequence and expression data provides valuable insights into tumor\nbiology and has significant potential to enhance personalized treatment\nstrategies in breast cancer care.", "AI": {"tldr": "The study integrates protein sequence and expression data using ProtGPT2 and machine learning to improve breast cancer subtype characterization and clinical outcome prediction, achieving high accuracy.", "motivation": "Breast cancer's complexity and variability challenge understanding and treatment, necessitating better molecular characterization.", "method": "ProtGPT2-generated protein embeddings were combined with expression levels and analyzed using ensemble K-means and XGBoost.", "result": "High performance metrics (F1 scores of 0.88 and 0.87) were achieved for survival and biomarker prediction, identifying key proteins like KMT2C and MYO1B.", "conclusion": "Integrating protein sequence and expression data enhances tumor biology insights and personalized treatment strategies."}}
{"id": "2410.14932", "pdf": "https://arxiv.org/pdf/2410.14932", "abs": "https://arxiv.org/abs/2410.14932", "authors": ["Y. Qiang Sun", "Pedram Hassanzadeh", "Mohsen Zand", "Ashesh Chattopadhyay", "Jonathan Weare", "Dorian S. Abbot"], "title": "Can AI weather models predict out-of-distribution gray swan tropical cyclones?", "categories": ["physics.ao-ph", "cs.LG"], "comment": null, "summary": "Predicting gray swan weather extremes, which are possible but so rare that\nthey are absent from the training dataset, is a major concern for AI weather\nmodels and long-term climate emulators. An important open question is whether\nAI models can extrapolate from weaker weather events present in the training\nset to stronger, unseen weather extremes. To test this, we train independent\nversions of the AI model FourCastNet on the 1979-2015 ERA5 dataset with all\ndata, or with Category 3-5 tropical cyclones (TCs) removed, either globally or\nonly over the North Atlantic or Western Pacific basin. We then test these\nversions of FourCastNet on 2018-2023 Category 5 TCs (gray swans). All versions\nyield similar accuracy for global weather, but the one trained without Category\n3-5 TCs cannot accurately forecast Category 5 TCs, indicating that these models\ncannot extrapolate from weaker storms. The versions trained without Category\n3-5 TCs in one basin show some skill forecasting Category 5 TCs in that basin,\nsuggesting that FourCastNet can generalize across tropical basins. This is\nencouraging and surprising because regional information is implicitly encoded\nin inputs. Given that current state-of-the-art AI weather and climate models\nhave similar learning strategies, we expect our findings to apply to other\nmodels. Other types of weather extremes need to be similarly investigated. Our\nwork demonstrates that novel learning strategies are needed for AI models to\nreliably provide early warning or estimated statistics for the rarest, most\nimpactful TCs, and, possibly, other weather extremes.", "AI": {"tldr": "AI weather models struggle to predict rare 'gray swan' weather extremes when trained without similar events, but show some generalization across regions.", "motivation": "To determine if AI models can extrapolate from weaker weather events in training data to predict rare, stronger extremes like Category 5 tropical cyclones.", "method": "Train FourCastNet on ERA5 data (1979-2015) with and without Category 3-5 tropical cyclones, then test on 2018-2023 Category 5 cyclones.", "result": "Models trained without strong cyclones fail to predict Category 5 events, but show some skill when trained without cyclones in specific basins.", "conclusion": "AI models need novel learning strategies to reliably predict rare, impactful weather extremes."}}
{"id": "2410.19989", "pdf": "https://arxiv.org/pdf/2410.19989", "abs": "https://arxiv.org/abs/2410.19989", "authors": ["Ondrej Biza", "Thomas Weng", "Lingfeng Sun", "Karl Schmeckpeper", "Tarik Kelestemur", "Yecheng Jason Ma", "Robert Platt", "Jan-Willem van de Meent", "Lawson L. S. Wong"], "title": "On-Robot Reinforcement Learning with Goal-Contrastive Rewards", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Reinforcement Learning (RL) has the potential to enable robots to learn from\ntheir own actions in the real world. Unfortunately, RL can be prohibitively\nexpensive, in terms of on-robot runtime, due to inefficient exploration when\nlearning from a sparse reward signal. Designing dense reward functions is\nlabour-intensive and requires domain expertise. In our work, we propose GCR\n(Goal-Contrastive Rewards), a dense reward function learning method that can be\ntrained on passive video demonstrations. By using videos without actions, our\nmethod is easier to scale, as we can use arbitrary videos. GCR combines two\nloss functions, an implicit value loss function that models how the reward\nincreases when traversing a successful trajectory, and a goal-contrastive loss\nthat discriminates between successful and failed trajectories. We perform\nexperiments in simulated manipulation environments across RoboMimic and\nMimicGen tasks, as well as in the real world using a Franka arm and a Spot\nquadruped. We find that GCR leads to a more-sample efficient RL, enabling\nmodel-free RL to solve about twice as many tasks as our baseline reward\nlearning methods. We also demonstrate positive cross-embodiment transfer from\nvideos of people and of other robots performing a task. Website:\nhttps://gcr-robot.github.io/.", "AI": {"tldr": "GCR (Goal-Contrastive Rewards) is a method for learning dense reward functions from passive video demonstrations, improving RL sample efficiency and task success rates.", "motivation": "RL is costly due to sparse rewards; designing dense rewards is labor-intensive. GCR aims to automate this using passive videos.", "method": "GCR combines an implicit value loss and goal-contrastive loss, trained on passive videos without actions.", "result": "GCR doubles task success rates in RL compared to baselines and enables cross-embodiment transfer.", "conclusion": "GCR offers a scalable, efficient solution for RL reward learning using passive demonstrations."}}
{"id": "2502.00753", "pdf": "https://arxiv.org/pdf/2502.00753", "abs": "https://arxiv.org/abs/2502.00753", "authors": ["Dingzhi Yu", "Wei Jiang", "Yuanyu Wan", "Lijun Zhang"], "title": "Mirror Descent Under Generalized Smoothness", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Smoothness is crucial for attaining fast rates in first-order optimization.\nHowever, many optimization problems in modern machine learning involve\nnon-smooth objectives. Recent studies relax the smoothness assumption by\nallowing the Lipschitz constant of the gradient to grow with respect to the\ngradient norm, which accommodates a broad range of objectives in practice.\nDespite this progress, existing generalizations of smoothness are restricted to\nEuclidean geometry with $\\ell_2$-norm and only have theoretical guarantees for\noptimization in the Euclidean space. In this paper, we address this limitation\nby introducing a new $\\ell*$-smoothness concept that measures the norm of\nHessians in terms of a general norm and its dual, and establish convergence for\nmirror-descent-type algorithms, matching the rates under the classic\nsmoothness. Notably, we propose a generalized self-bounding property that\nfacilitates bounding the gradients via controlling suboptimality gaps, serving\nas a principal component for convergence analysis. Beyond deterministic\noptimization, we establish an anytime convergence for stochastic mirror descent\nbased on a new bounded noise condition that encompasses the widely adopted\nbounded or affine noise assumptions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2502.05073", "pdf": "https://arxiv.org/pdf/2502.05073", "abs": "https://arxiv.org/abs/2502.05073", "authors": ["Rupert Li", "Elchanan Mossel"], "title": "Noise Sensitivity and Learning Lower Bounds for Hierarchical Functions", "categories": ["math.PR", "cs.CC", "cs.LG", "math.CO"], "comment": "18 pages", "summary": "Recent works explore deep learning's success by examining functions or data\nwith hierarchical structure. To study the learning complexity of functions with\nhierarchical structure, we study the noise stability of functions with tree\nhierarchical structure on independent inputs. We show that if each function in\nthe hierarchy is $\\varepsilon$-far from linear, the noise stability is\nexponentially small in the depth of the hierarchy.\n  Our results have immediate applications for learning. In the Boolean setting\nusing the results of Dachman-Soled, Feldman, Tan, Wan and Wimmer (2014) our\nresults provide Statistical Query super-polynomial lower bounds for learning\nclasses that are based on hierarchical functions. Similarly, using the results\nof Diakonikolas, Kane, Pittas and Zarifis (2021) our results provide\nsuper-polynomial lower bounds for SQ learning under the Gaussian measure. Using\nthe results of Abbe, Bengio, Cornacchiam, Kleinberg, Lotfi, Raghu and Zhang\n(2022) our results imply sample complexity lower bounds for learning\nhierarchical functions with gradient descent on fully connected neural\nnetworks.", "AI": {"tldr": "The paper analyzes noise stability in hierarchical functions, showing exponential decay with depth, and applies these findings to learning complexity and lower bounds in various settings.", "motivation": "To understand the learning complexity of hierarchical functions by examining their noise stability and its implications for machine learning.", "method": "Study noise stability of tree-hierarchical functions with independent inputs, focusing on functions far from linear.", "result": "Noise stability is exponentially small in hierarchy depth, leading to super-polynomial lower bounds for learning in Boolean and Gaussian settings, and sample complexity bounds for neural networks.", "conclusion": "Hierarchical functions' noise stability properties have significant implications for learning complexity, particularly in statistical query and gradient-based methods."}}
{"id": "2503.10325", "pdf": "https://arxiv.org/pdf/2503.10325", "abs": "https://arxiv.org/abs/2503.10325", "authors": ["Luyao Gao", "Jianchun Liu", "Hongli Xu", "Xichong Zhang", "Yunming Liao", "Liusheng Huang"], "title": "Collaborative Speculative Inference for Efficient LLM Inference Serving", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Speculative inference is a promising paradigm employing small speculative\nmodels (SSMs) as drafters to generate draft tokens, which are subsequently\nverified in parallel by the target large language model (LLM). This approach\nenhances the efficiency of inference serving by reducing LLM inference latency\nand costs while preserving generation quality. However, existing speculative\nmethods face critical challenges, including inefficient resource utilization\nand limited draft acceptance, which constrain their scalability and overall\neffectiveness. To overcome these obstacles, we present CoSine, a novel\nspeculative inference system that decouples sequential speculative decoding\nfrom parallel verification, enabling efficient collaboration among multiple\nnodes. Specifically, CoSine routes inference requests to specialized drafters\nbased on their expertise and incorporates a confidence-based token fusion\nmechanism to synthesize outputs from cooperating drafters, ensuring\nhigh-quality draft generation. Additionally, CoSine dynamically orchestrates\nthe execution of speculative decoding and verification in a pipelined manner,\nemploying batch scheduling to selectively group requests and adaptive\nspeculation control to minimize idle periods. By optimizing parallel workflows\nthrough heterogeneous node collaboration, CoSine balances draft generation and\nverification throughput in real-time, thereby maximizing resource utilization.\nExperimental results demonstrate that CoSine achieves superior performance\ncompared to state-of-the-art speculative approaches. Notably, with equivalent\nresource costs, CoSine achieves up to a 23.2% decrease in latency and a 32.5%\nincrease in throughput compared to baseline methods.", "AI": {"tldr": "CoSine is a speculative inference system that improves efficiency by decoupling draft generation and verification, optimizing resource use, and achieving lower latency and higher throughput.", "motivation": "Existing speculative methods suffer from inefficient resource utilization and limited draft acceptance, hindering scalability and effectiveness.", "method": "CoSine decouples sequential speculative decoding from parallel verification, uses specialized drafters, and employs confidence-based token fusion and dynamic orchestration.", "result": "CoSine reduces latency by 23.2% and increases throughput by 32.5% compared to baseline methods.", "conclusion": "CoSine outperforms state-of-the-art speculative approaches by optimizing workflows and resource utilization."}}
{"id": "2503.12293", "pdf": "https://arxiv.org/pdf/2503.12293", "abs": "https://arxiv.org/abs/2503.12293", "authors": ["Averi Bates", "Ryan Vavricka", "Shane Carleton", "Ruosi Shao", "Chongle Pan"], "title": "Unified Modeling Language Code Generation from Diagram Images Using Multimodal Large Language Models", "categories": ["cs.SE", "cs.LG", "D.2.2; D.2.3; I.2.7; I.4.9"], "comment": "Published in the Journal of Machine Learning with Applications,\n  Author Contributions: Averi Bates: Methodology, Development, Analysis, Data\n  Curation, Drafting, Review. Ryan Vavricka: Data Curation, Development,\n  Review. Shane Carleton: Supervision, Funding. Ruosi Shao: Review. Chongle\n  Pan: Supervision, Review", "summary": "The Unified Modeling Language is a standardized visual language widely used\nfor modeling and documenting the design of software systems. Although many\ntools generate UML diagrams from UML code, generating executable UML code from\nimage-based UML diagrams remains challenging. This paper proposes a new\napproach to generate UML code using a large multimodal language model\nautomatically. Synthetic UML activity and sequence diagram datasets were\ncreated to train and test the model. We compared standard fine-tuning with LoRA\ntechniques to optimize base models. The experiments measured code generation\naccuracy across different model sizes and training strategies. These results\ndemonstrated that domain-adapted MM-LLMs perform for UML code generation\nautomation, whereby, at the best model, it achieved BLEU and SSIM scores of\n0.779 and 0.942 on sequence diagrams. This will enable the modernization of\nlegacy systems and decrease the manual effort in software development\nworkflows.", "AI": {"tldr": "A new method uses multimodal language models to generate UML code from image-based diagrams, achieving high accuracy and reducing manual effort in software development.", "motivation": "Automating UML code generation from diagrams is challenging, and existing tools lack this capability. This paper aims to address this gap.", "method": "The approach uses a large multimodal language model trained on synthetic UML datasets, comparing fine-tuning and LoRA techniques.", "result": "The best model achieved BLEU and SSIM scores of 0.779 and 0.942 on sequence diagrams, showing high accuracy.", "conclusion": "The method successfully automates UML code generation, aiding legacy system modernization and reducing manual workflow effort."}}
{"id": "2503.18309", "pdf": "https://arxiv.org/pdf/2503.18309", "abs": "https://arxiv.org/abs/2503.18309", "authors": ["Zhidi Lin", "Ying Li", "Feng Yin", "Juan Maro\u00f1as", "Alexandre H. Thi\u00e9ry"], "title": "Efficient Transformed Gaussian Process State-Space Models for Non-Stationary High-Dimensional Dynamical Systems", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": "15 pages, 6 figures", "summary": "Gaussian process state-space models (GPSSMs) offer a principled framework for\nlearning and inference in nonlinear dynamical systems with uncertainty\nquantification. However, existing GPSSMs are limited by the use of multiple\nindependent stationary Gaussian processes (GPs), leading to prohibitive\ncomputational and parametric complexity in high-dimensional settings and\nrestricted modeling capacity for non-stationary dynamics. To address these\nchallenges, we propose an efficient transformed Gaussian process state-space\nmodel (ETGPSSM) for scalable and flexible modeling of high-dimensional,\nnon-stationary dynamical systems. Specifically, our ETGPSSM integrates a single\nshared GP with input-dependent normalizing flows, yielding an expressive\nimplicit process prior that captures complex, non-stationary transition\ndynamics while significantly reducing model complexity. For the inference of\nthe implicit process, we develop a variational inference algorithm that jointly\napproximates the posterior over the underlying GP and the neural network\nparameters defining the normalizing flows. To avoid explicit variational\nparameterization of the latent states, we further incorporate the ensemble\nKalman filter (EnKF) into the variational framework, enabling accurate and\nefficient state estimation. Extensive empirical evaluations on synthetic and\nreal-world datasets demonstrate the superior performance of our ETGPSSM in\nsystem dynamics learning, high-dimensional state estimation, and time-series\nforecasting, outperforming existing GPSSMs and neural network-based SSMs in\nterms of computational efficiency and accuracy.", "AI": {"tldr": "The paper introduces ETGPSSM, an efficient transformed Gaussian process state-space model, to address limitations of existing GPSSMs in high-dimensional and non-stationary settings. It combines a shared GP with normalizing flows for expressive dynamics and uses variational inference with EnKF for efficient state estimation, outperforming existing methods.", "motivation": "Existing GPSSMs suffer from high computational and parametric complexity and limited modeling capacity for non-stationary dynamics. The goal is to develop a scalable and flexible model for high-dimensional, non-stationary systems.", "method": "ETGPSSM integrates a shared GP with input-dependent normalizing flows for expressive dynamics. It uses variational inference with EnKF for efficient state estimation, avoiding explicit parameterization of latent states.", "result": "ETGPSSM outperforms existing GPSSMs and neural network-based SSMs in computational efficiency and accuracy for dynamics learning, state estimation, and forecasting.", "conclusion": "ETGPSSM provides a scalable and flexible solution for modeling high-dimensional, non-stationary systems, demonstrating superior performance in empirical evaluations."}}
{"id": "2504.02288", "pdf": "https://arxiv.org/pdf/2504.02288", "abs": "https://arxiv.org/abs/2504.02288", "authors": ["Edward DongBo Cui", "Lu Zhang", "William Ping-hsun Lee"], "title": "Shallow AutoEncoding Recommender with Cold Start Handling via Side Features", "categories": ["cs.IR", "cs.LG"], "comment": "Preparing submission to CIKM 2025; 2 Figures; 4 Tables; 13 pages;\n  Python code implementation example", "summary": "User and item cold starts present significant challenges in industrial\napplications of recommendation systems. Supplementing user-item interaction\ndata with metadata is a common solution-but often at the cost of introducing\nadditional biases. In this work, we introduce an augmented EASE model that\nseamlessly integrates both user and item side information to address these cold\nstart issues. Our straightforward, autoencoder-based method produces a\nclosed-form solution that leverages rich content signals for cold items while\nrefining user representations in data-sparse environments. Importantly, our\nmethod strikes a balance by effectively recommending cold start items and\nhandling cold start users without incurring extra bias, and it maintains strong\nperformance in warm settings. Experimental results demonstrate improved\nrecommendation accuracy and robustness compared to previous collaborative\nfiltering approaches. Moreover, our model serves as a strong baseline for\nfuture comparative studies.", "AI": {"tldr": "An augmented EASE model integrates user and item metadata to address cold start issues in recommendation systems, balancing performance without introducing bias.", "motivation": "User and item cold starts challenge recommendation systems; metadata can help but often introduces bias.", "method": "An autoencoder-based approach with a closed-form solution leverages content signals for cold items and refines user representations.", "result": "Improved recommendation accuracy and robustness, especially in cold start scenarios, while maintaining warm setting performance.", "conclusion": "The model effectively handles cold starts without extra bias and serves as a strong baseline for future research."}}
{"id": "2505.05922", "pdf": "https://arxiv.org/pdf/2505.05922", "abs": "https://arxiv.org/abs/2505.05922", "authors": ["Haoqi Wu", "Wei Dai", "Li Wang", "Qiang Yan"], "title": "Cape: Context-Aware Prompt Perturbation Mechanism with Differential Privacy", "categories": ["cs.CR", "cs.LG"], "comment": "to be published in ICML 2025", "summary": "Large Language Models (LLMs) have gained significant popularity due to their\nremarkable capabilities in text understanding and generation. However, despite\ntheir widespread deployment in inference services such as ChatGPT, concerns\nabout the potential leakage of sensitive user data have arisen. Existing\nsolutions primarily rely on privacy-enhancing technologies to mitigate such\nrisks, facing the trade-off among efficiency, privacy, and utility. To narrow\nthis gap, we propose Cape, a context-aware prompt perturbation mechanism based\non differential privacy, to enable efficient inference with an improved\nprivacy-utility trade-off. Concretely, we introduce a hybrid utility function\nthat better captures the token similarity. Additionally, we propose a\nbucketized sampling mechanism to handle large sampling space, which might lead\nto long-tail phenomenons. Extensive experiments across multiple datasets, along\nwith ablation studies, demonstrate that Cape achieves a better privacy-utility\ntrade-off compared to prior state-of-the-art works.", "AI": {"tldr": "Cape is a context-aware prompt perturbation mechanism using differential privacy to improve the privacy-utility trade-off in LLM inference services.", "motivation": "Address concerns about sensitive user data leakage in LLM inference services, balancing efficiency, privacy, and utility.", "method": "Proposes Cape, a mechanism with a hybrid utility function for token similarity and bucketized sampling to handle large sampling spaces.", "result": "Demonstrates better privacy-utility trade-off than prior works through experiments and ablation studies.", "conclusion": "Cape effectively narrows the gap in privacy-utility trade-offs for LLM inference services."}}
{"id": "2505.06711", "pdf": "https://arxiv.org/pdf/2505.06711", "abs": "https://arxiv.org/abs/2505.06711", "authors": ["Junfan Xia", "Bin Jiang"], "title": "Efficient Parallelization of Message Passing Neural Networks", "categories": ["physics.chem-ph", "cs.LG"], "comment": "34 pages, 8 figures", "summary": "Machine learning potentials have achieved great success in accelerating\natomistic simulations. Many of them rely on local descriptors that readily\nallow parallelization. More recent message passing neural network (MPNN) models\nhave demonstrated their superior accuracy and become increasingly popular.\nHowever, parallelizing MPNN models for large-scale simulations across compute\nnodes remains a challenge, as the previously argued poor scalability with the\nnumber of MP layers and the necessity of data communication. Here, we propose\nan efficient parallel algorithm for MPNN models, in which additional data\ncommunication is minimized among local atoms only in each MP layer without\nredundant computation, thus scaling linearly with the layer number. Integrated\nwith our recursively embedded atom neural network model, this algorithm\ndemonstrates excellent strong scaling and weak scaling behaviors in several\nbenchmark systems. This approach enables massive molecular dynamics simulations\non MPNN models for hundreds of millions of atoms as fast as on strictly local\nmodels, vastly extending the applicability of the MPNN potential to an\nunprecedented scale. This general parallelization framework can empower various\nMPNN models to efficiently simulate very large and complex systems.", "AI": {"tldr": "Proposes an efficient parallel algorithm for message passing neural networks (MPNNs) to enable large-scale simulations, minimizing communication and scaling linearly with layers.", "motivation": "Overcome the challenge of parallelizing MPNN models for large-scale simulations due to poor scalability and data communication issues.", "method": "Develops a parallel algorithm that minimizes data communication among local atoms in each MP layer without redundant computation.", "result": "Demonstrates excellent strong and weak scaling in benchmark systems, enabling simulations of hundreds of millions of atoms as fast as local models.", "conclusion": "The framework extends MPNN applicability to unprecedented scales, empowering efficient simulations of large, complex systems."}}
{"id": "2505.08535", "pdf": "https://arxiv.org/pdf/2505.08535", "abs": "https://arxiv.org/abs/2505.08535", "authors": ["Linna Xu", "Yongli Zhu"], "title": "Diffusion-assisted Model Predictive Control Optimization for Power System Real-Time Operation", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "This paper has been accepted by the 2025 IEEE PES General Meeting\n  (PESGM), which will be held in Austin, TX, July 27-31, 2025", "summary": "This paper presents a modified model predictive control (MPC) framework for\nreal-time power system operation. The framework incorporates a diffusion model\ntailored for time series generation to enhance the accuracy of the load\nforecasting module used in the system operation. In the absence of explicit\nstate transition law, a model-identification procedure is leveraged to derive\nthe system dynamics, thereby eliminating a barrier when applying MPC to a\nrenewables-dominated power system. Case study results on an industry park\nsystem and the IEEE 30-bus system demonstrate that using the diffusion model to\naugment the training dataset significantly improves load-forecasting accuracy,\nand the inferred system dynamics are applicable to the real-time grid operation\nwith solar and wind.", "AI": {"tldr": "A modified MPC framework with a diffusion model improves load forecasting and system dynamics for renewables-dominated power systems.", "motivation": "Enhancing real-time power system operation accuracy, especially for renewables-dominated grids, by addressing load forecasting and system dynamics challenges.", "method": "Incorporates a diffusion model for time series generation to improve load forecasting and uses model-identification for system dynamics in the MPC framework.", "result": "Case studies show significant load-forecasting accuracy improvement and applicability of inferred dynamics to real-time grid operation with solar and wind.", "conclusion": "The proposed framework effectively addresses challenges in renewables-dominated power systems, improving forecasting and operational accuracy."}}
