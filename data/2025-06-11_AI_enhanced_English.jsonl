{"id": "2506.08633", "pdf": "https://arxiv.org/pdf/2506.08633", "abs": "https://arxiv.org/abs/2506.08633", "authors": ["\u0160imon Sedl\u00e1\u010dek", "Bolaji Yusuf", "J\u00e1n \u0160vec", "Pradyoth Hegde", "Santosh Kesiraju", "Old\u0159ich Plchot", "Jan \u010cernock\u00fd"], "title": "Approaching Dialogue State Tracking via Aligning Speech Encoders and LLMs", "categories": ["eess.AS", "cs.CL"], "comment": "Accepted to Interspeech 2025", "summary": "In this work, we approach spoken Dialogue State Tracking (DST) by bridging\nthe representation spaces of speech encoders and LLMs via a small connector\nmodule, with a focus on fully open-sourced and open-data components\n(WavLM-large, OLMo). We focus on ablating different aspects of such systems\nincluding full/LoRA adapter fine-tuning, the effect of agent turns in the\ndialogue history, as well as fuzzy matching-based output post-processing, which\ngreatly improves performance of our systems on named entities in the dialogue\nslot values. We conduct our experiments on the SpokenWOZ dataset, and\nadditionally utilize the Speech-Aware MultiWOZ dataset to augment our training\ndata. Ultimately, our best-performing WavLM + connector + OLMo-1B aligned\nmodels achieve state of the art on the SpokenWOZ test set (34.66% JGA), and our\nsystem with Gemma-2-9B-instruct further surpasses this result, reaching 42.17%\nJGA on SpokenWOZ test.", "AI": {"tldr": "The paper introduces a method for spoken Dialogue State Tracking (DST) by connecting speech encoders and LLMs with a small module, achieving state-of-the-art results on SpokenWOZ.", "motivation": "To improve spoken DST by leveraging open-sourced components (WavLM, OLMo) and exploring system optimizations like fine-tuning and post-processing.", "method": "Uses a connector module between speech encoders (WavLM) and LLMs (OLMo, Gemma), with ablations on fine-tuning, dialogue history, and fuzzy matching post-processing.", "result": "Achieves 34.66% JGA with WavLM + OLMo-1B and 42.17% JGA with Gemma-2-9B on SpokenWOZ.", "conclusion": "The approach effectively bridges speech and language models, setting new benchmarks for spoken DST."}}
{"id": "2506.08507", "pdf": "https://arxiv.org/pdf/2506.08507", "abs": "https://arxiv.org/abs/2506.08507", "authors": ["Kuo Yang", "Xingjie Yang", "Linhui Yu", "Qing Xu", "Yan Fang", "Xu Wang", "Zhengyang Zhou", "Yang Wang"], "title": "MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM)-driven Multi-agent systems (Mas) have recently\nemerged as a powerful paradigm for tackling complex real-world tasks. However,\nexisting Mas construction methods typically rely on manually crafted\ninteraction mechanisms or heuristic rules, introducing human biases and\nconstraining the autonomous ability. Even with recent advances in adaptive Mas\nconstruction, existing systems largely remain within the paradigm of\nsemi-autonomous patterns. In this work, we propose MasHost, a Reinforcement\nLearning (RL)-based framework for autonomous and query-adaptive Mas design. By\nformulating Mas construction as a graph search problem, our proposed MasHost\njointly samples agent roles and their interactions through a unified\nprobabilistic sampling mechanism. Beyond the accuracy and efficiency objectives\npursued in prior works, we introduce component rationality as an additional and\nnovel design principle in Mas. To achieve this multi-objective optimization, we\npropose Hierarchical Relative Policy Optimization (HRPO), a novel RL strategy\nthat collaboratively integrates group-relative advantages and action-wise\nrewards. To our knowledge, our proposed MasHost is the first RL-driven\nframework for autonomous Mas graph construction. Extensive experiments on six\nbenchmarks demonstrate that MasHost consistently outperforms most competitive\nbaselines, validating its effectiveness, efficiency, and structure rationality.", "AI": {"tldr": "MasHost is an RL-based framework for autonomous Multi-agent system (Mas) design, introducing component rationality and outperforming baselines.", "motivation": "Existing Mas methods rely on manual or heuristic rules, limiting autonomy and introducing biases.", "method": "Formulates Mas construction as a graph search problem, using probabilistic sampling and HRPO for multi-objective optimization.", "result": "Outperforms baselines in experiments across six benchmarks.", "conclusion": "MasHost is effective, efficient, and introduces novel design principles for autonomous Mas."}}
{"id": "2506.08357", "pdf": "https://arxiv.org/pdf/2506.08357", "abs": "https://arxiv.org/abs/2506.08357", "authors": ["Franck Meyer", "Kyunghoon Hur", "Edward Choi"], "title": "MD-ViSCo: A Unified Model for Multi-Directional Vital Sign Waveform Conversion", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Main paper (16 pages, 5 figures). Paper submitted for review. Code\n  available at https://github.com/fr-meyer/MD-ViSCo", "summary": "Despite the remarkable progress of deep-learning methods generating a target\nvital sign waveform from a source vital sign waveform, most existing models are\ndesigned exclusively for a specific source-to-target pair. This requires\ndistinct model architectures, optimization procedures, and pre-processing\npipelines, resulting in multiple models that hinder usability in clinical\nsettings. To address this limitation, we propose the Multi-Directional\nVital-Sign Converter (MD-ViSCo), a unified framework capable of generating any\ntarget waveform such as electrocardiogram (ECG), photoplethysmogram (PPG), or\narterial blood pressure (ABP) from any single input waveform with a single\nmodel. MD-ViSCo employs a shallow 1-Dimensional U-Net integrated with a Swin\nTransformer that leverages Adaptive Instance Normalization (AdaIN) to capture\ndistinct waveform styles. To evaluate the efficacy of MD-ViSCo, we conduct\nmulti-directional waveform generation on two publicly available datasets. Our\nframework surpasses state-of-the-art baselines (NabNet & PPG2ABP) on average\nacross all waveform types, lowering Mean absolute error (MAE) by 8.8% and\nimproving Pearson correlation (PC) by 4.9% over two datasets. In addition, the\ngenerated ABP waveforms satisfy the Association for the Advancement of Medical\nInstrumentation (AAMI) criterion and achieve Grade B on the British\nHypertension Society (BHS) standard, outperforming all baselines. By\neliminating the need for developing a distinct model for each task, we believe\nthat this work offers a unified framework that can deal with any kind of vital\nsign waveforms with a single model in healthcare monitoring.", "AI": {"tldr": "MD-ViSCo is a unified framework for generating any target vital sign waveform from any single input waveform using a single model, outperforming existing methods.", "motivation": "Existing models are limited to specific source-to-target pairs, requiring multiple models and hindering clinical usability.", "method": "MD-ViSCo uses a 1D U-Net with Swin Transformer and AdaIN to capture waveform styles, evaluated on public datasets.", "result": "MD-ViSCo reduces MAE by 8.8% and improves PC by 4.9%, meeting AAMI and BHS standards for ABP waveforms.", "conclusion": "MD-ViSCo provides a versatile, single-model solution for vital sign waveform generation in healthcare."}}
{"id": "2506.08038", "pdf": "https://arxiv.org/pdf/2506.08038", "abs": "https://arxiv.org/abs/2506.08038", "authors": ["Chen Huang", "Dingxuan Wang", "Ronghui Hou"], "title": "Joint Routing and Control Optimization in VANET", "categories": ["eess.SY", "cs.MA", "cs.SY"], "comment": "11 pages; 10 figures", "summary": "In this paper, we introduce DynaRoute, an adaptive joint optimization\nframework for dynamic vehicular networks that simultaneously addresses platoon\ncontrol and data transmission through trajectory-aware routing and\nsafety-constrained vehicle coordination. DynaRoute guarantees continuous\nvehicle movement via platoon safety control with optimizing transmission paths\nthrough real-time trajectory prediction and ensuring reliable data. Our\nsolution achieves three key objectives: (1) maintaining platoon stability\nthrough accurate data transmission, (2) enabling adaptive routing based on\nvehicle movement patterns, and (3) enhancing overall intelligent transportation\nsystem performance. DynaRoute equires predefined traffic models and adapts to\ndynamic network conditions using local vehicle state information. We present\ncomprehensive simulation results demonstrating that DynaRoute maintains control\nand transmission performance in multiple complex scenarios while significantly\nimproving throughput and reliability compared to traditional approaches.", "AI": {"tldr": "DynaRoute is an adaptive framework for dynamic vehicular networks, optimizing platoon control and data transmission via trajectory-aware routing and safety-constrained coordination.", "motivation": "To address the challenges of maintaining platoon stability and reliable data transmission in dynamic vehicular networks.", "method": "Uses real-time trajectory prediction and local vehicle state information to optimize routing and ensure safety.", "result": "Achieves stable platoon control, adaptive routing, and improved system performance, outperforming traditional methods in throughput and reliability.", "conclusion": "DynaRoute effectively enhances intelligent transportation systems by integrating platoon control and data transmission optimization."}}
{"id": "2506.08457", "pdf": "https://arxiv.org/pdf/2506.08457", "abs": "https://arxiv.org/abs/2506.08457", "authors": ["Ge Zhu", "Yutong Wen", "Zhiyao Duan"], "title": "A Review on Score-based Generative Models for Audio Applications", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Diffusion models have emerged as powerful deep generative techniques,\nproducing high-quality and diverse samples in applications in various domains\nincluding audio. These models have many different design choices suitable for\ndifferent applications, however, existing reviews lack in-depth discussions of\nthese design choices. The audio diffusion model literature also lacks\nprincipled guidance for the implementation of these design choices and their\ncomparisons for different applications. This survey provides a comprehensive\nreview of diffusion model design with an emphasis on design principles for\nquality improvement and conditioning for audio applications. We adopt the score\nmodeling perspective as a unifying framework that accommodates various\ninterpretations, including recent approaches like flow matching. We\nsystematically examine the training and sampling procedures of diffusion\nmodels, and audio applications through different conditioning mechanisms. To\naddress the lack of audio diffusion model codebases and to promote reproducible\nresearch and rapid prototyping, we introduce an open-source codebase at\nhttps://github.com/gzhu06/AudioDiffuser that implements our reviewed framework\nfor various audio applications. We demonstrate its capabilities through three\ncase studies: audio generation, speech enhancement, and text-to-speech\nsynthesis, with benchmark evaluations on standard datasets.", "AI": {"tldr": "A survey on diffusion models for audio applications, focusing on design choices, quality improvement, and conditioning. Includes an open-source codebase for reproducibility.", "motivation": "Existing reviews lack in-depth discussion of design choices in diffusion models for audio, and there's no principled guidance for implementation.", "method": "Adopts a score modeling perspective to unify interpretations, examines training/sampling procedures, and introduces an open-source codebase.", "result": "Demonstrates capabilities through case studies: audio generation, speech enhancement, and text-to-speech synthesis.", "conclusion": "Provides comprehensive guidance and tools for implementing diffusion models in audio applications, promoting reproducible research."}}
{"id": "2506.08430", "pdf": "https://arxiv.org/pdf/2506.08430", "abs": "https://arxiv.org/abs/2506.08430", "authors": ["Ziqi. Liu", "Ziyang. Zhou", "Mingxuan. Hu"], "title": "CAF-I: A Collaborative Multi-Agent Framework for Enhanced Irony Detection with Large Language Models", "categories": ["cs.CL", "cs.MA"], "comment": "ICML 2025 Workshop on Collaborative and Federated Agentic Workflows", "summary": "Large language model (LLM) have become mainstream methods in the field of\nsarcasm detection. However, existing LLM methods face challenges in irony\ndetection, including: 1. single-perspective limitations, 2. insufficient\ncomprehensive understanding, and 3. lack of interpretability. This paper\nintroduces the Collaborative Agent Framework for Irony (CAF-I), an LLM-driven\nmulti-agent system designed to overcome these issues. CAF-I employs specialized\nagents for Context, Semantics, and Rhetoric, which perform multidimensional\nanalysis and engage in interactive collaborative optimization. A Decision Agent\nthen consolidates these perspectives, with a Refinement Evaluator Agent\nproviding conditional feedback for optimization. Experiments on benchmark\ndatasets establish CAF-I's state-of-the-art zero-shot performance. Achieving\nSOTA on the vast majority of metrics, CAF-I reaches an average Macro-F1 of\n76.31, a 4.98 absolute improvement over the strongest prior baseline. This\nsuccess is attained by its effective simulation of human-like multi-perspective\nanalysis, enhancing detection accuracy and interpretability.", "AI": {"tldr": "CAF-I, a multi-agent LLM framework, improves sarcasm detection by addressing single-perspective limitations, lack of understanding, and interpretability issues, achieving SOTA performance with a 4.98% boost in Macro-F1.", "motivation": "Existing LLM methods for sarcasm detection suffer from single-perspective analysis, insufficient understanding, and poor interpretability.", "method": "CAF-I uses specialized agents (Context, Semantics, Rhetoric) for multidimensional analysis and collaborative optimization, with a Decision Agent and Refinement Evaluator Agent for consolidation and feedback.", "result": "CAF-I achieves a Macro-F1 of 76.31, a 4.98 absolute improvement over prior baselines, demonstrating SOTA zero-shot performance.", "conclusion": "CAF-I's human-like multi-perspective analysis enhances sarcasm detection accuracy and interpretability, setting a new benchmark."}}
{"id": "2506.08471", "pdf": "https://arxiv.org/pdf/2506.08471", "abs": "https://arxiv.org/abs/2506.08471", "authors": ["Tal I. Sommer", "Ori Katz"], "title": "Passive acoustic non-line-of-sight localization without a relay surface", "categories": ["cs.SD", "eess.AS", "eess.SP"], "comment": null, "summary": "The detection and localization of a source hidden outside the Line-of-Sight\n(LOS) traditionally rely on the acquisition of indirect signals, such as those\nreflected from visible relay surfaces such as floors or walls. These reflected\nsignals are then utilized to reconstruct the obscured scene. In this study, we\npresent an approach that utilize signals diffracted from an edge of an obstacle\nto achieve three-dimensional (3D) localization of an acoustic point source\nsituated outside the LOS. We address two scenarios - a doorway and a convex\ncorner - and propose a localization method for each of them. For the first\nscenario, we utilize the two edges of the door as virtual detector arrays. For\nthe second scenario, we exploit the spectral signature of a knife-edge\ndiffraction, inspired by the human perception of sound location by the\nhead-related transfer function (HRTF). In both methods, knife-edge diffraction\nis utilized to extend the capabilities of non-line-of-sight (NLOS) acoustic\nsensing, enabling localization in environments where conventional relay-surface\nbased approaches may be limited.", "AI": {"tldr": "The paper introduces a method for 3D localization of an acoustic source outside the Line-of-Sight (LOS) using signals diffracted from obstacle edges, addressing doorway and convex corner scenarios.", "motivation": "Traditional NLOS localization relies on reflected signals from visible surfaces, which may be limited in certain environments. This study explores edge diffraction for broader applicability.", "method": "Two scenarios are addressed: (1) using door edges as virtual detector arrays, and (2) leveraging knife-edge diffraction inspired by HRTF for convex corners.", "result": "The proposed methods enable 3D localization of acoustic sources in NLOS environments where conventional approaches may fail.", "conclusion": "Edge diffraction extends NLOS acoustic sensing capabilities, offering solutions for challenging scenarios like doorways and convex corners."}}
{"id": "2506.08807", "pdf": "https://arxiv.org/pdf/2506.08807", "abs": "https://arxiv.org/abs/2506.08807", "authors": ["Luca Ballotta", "\u00c1ron V\u00e9k\u00e1ssy", "Stephanie Gil", "Michal Yemini"], "title": "Confidence Boosts Trust-Based Resilience in Cooperative Multi-Robot Systems", "categories": ["eess.SP", "cs.MA", "cs.RO", "cs.SY", "eess.SY"], "comment": "This work has been submitted to IEEE for possible publication", "summary": "Wireless communication-based multi-robot systems open the door to\ncyberattacks that can disrupt safety and performance of collaborative robots.\nThe physical channel supporting inter-robot communication offers an attractive\nopportunity to decouple the detection of malicious robots from task-relevant\ndata exchange between legitimate robots. Yet, trustworthiness indications\ncoming from physical channels are uncertain and must be handled with this in\nmind. In this paper, we propose a resilient protocol for multi-robot operation\nwherein a parameter {\\lambda}t accounts for how confident a robot is about the\nlegitimacy of nearby robots that the physical channel indicates. Analytical\nresults prove that our protocol achieves resilient coordination with\narbitrarily many malicious robots under mild assumptions. Tuning {\\lambda}t\nallows a designer to trade between near-optimal inter-robot coordination and\nquick task execution; see Fig. 1. This is a fundamental performance tradeoff\nand must be carefully evaluated based on the task at hand. The effectiveness of\nour approach is numerically verified with experiments involving platoons of\nautonomous cars where some vehicles are maliciously spoofed.", "AI": {"tldr": "A resilient protocol for multi-robot systems uses physical channel trustworthiness to detect malicious robots, balancing coordination and task speed.", "motivation": "Wireless multi-robot systems are vulnerable to cyberattacks, requiring robust detection methods without disrupting legitimate communication.", "method": "A protocol with parameter \u03bbt to measure confidence in robot legitimacy, enabling resilient coordination under mild assumptions.", "result": "Achieves resilient coordination with arbitrary malicious robots, with tradeoffs between coordination and task speed.", "conclusion": "The protocol is effective, as shown in autonomous car platoon experiments with spoofed vehicles."}}
{"id": "2506.08120", "pdf": "https://arxiv.org/pdf/2506.08120", "abs": "https://arxiv.org/abs/2506.08120", "authors": ["Toyin Aguda", "Erik Wilson", "Allan Anzagira", "Simerjot Kaur", "Charese Smiley"], "title": "Conservative Bias in Large Language Models: Measuring Relation Predictions", "categories": ["cs.CL"], "comment": "10 pages", "summary": "Large language models (LLMs) exhibit pronounced conservative bias in relation\nextraction tasks, frequently defaulting to No_Relation label when an\nappropriate option is unavailable. While this behavior helps prevent incorrect\nrelation assignments, our analysis reveals that it also leads to significant\ninformation loss when reasoning is not explicitly included in the output. We\nsystematically evaluate this trade-off across multiple prompts, datasets, and\nrelation types, introducing the concept of Hobson's choice to capture scenarios\nwhere models opt for safe but uninformative labels over hallucinated ones. Our\nfindings suggest that conservative bias occurs twice as often as hallucination.\nTo quantify this effect, we use SBERT and LLM prompts to capture the semantic\nsimilarity between conservative bias behaviors in constrained prompts and\nlabels generated from semi-constrained and open-ended prompts.", "AI": {"tldr": "LLMs show conservative bias in relation extraction, often choosing 'No_Relation' to avoid errors, but this leads to information loss. The study evaluates this trade-off and introduces 'Hobson's choice' to describe safe but uninformative labels. Conservative bias is twice as common as hallucination.", "motivation": "To understand and quantify the conservative bias in LLMs during relation extraction tasks, which causes information loss despite preventing incorrect assignments.", "method": "Systematic evaluation across prompts, datasets, and relation types using SBERT and LLM prompts to measure semantic similarity between conservative bias behaviors.", "result": "Conservative bias occurs twice as often as hallucination, highlighting a significant trade-off between safety and informativeness.", "conclusion": "The study underscores the need to balance conservative bias and hallucination in LLMs for relation extraction, proposing further research to mitigate information loss."}}
{"id": "2506.08200", "pdf": "https://arxiv.org/pdf/2506.08200", "abs": "https://arxiv.org/abs/2506.08200", "authors": ["Kat R. Agres", "Adyasha Dash", "Phoebe Chua", "Stefan K. Ehrlich"], "title": "AffectMachine-Pop: A controllable expert system for real-time pop music generation", "categories": ["cs.HC", "cs.MM"], "comment": null, "summary": "Music is a powerful medium for influencing listeners' emotional states, and\nthis capacity has driven a surge of research interest in AI-based affective\nmusic generation in recent years. Many existing systems, however, are a black\nbox which are not directly controllable, thus making these systems less\nflexible and adaptive to users. We present \\textit{AffectMachine-Pop}, an\nexpert system capable of generating retro-pop music according to arousal and\nvalence values, which can either be pre-determined or based on a listener's\nreal-time emotion states. To validate the efficacy of the system, we conducted\na listening study demonstrating that AffectMachine-Pop is capable of generating\naffective music at target levels of arousal and valence. The system is tailored\nfor use either as a tool for generating interactive affective music based on\nuser input, or for incorporation into biofeedback or neurofeedback systems to\nassist users with emotion self-regulation.", "AI": {"tldr": "AffectMachine-Pop is an AI system for generating retro-pop music based on arousal and valence values, validated by a listening study.", "motivation": "Existing AI-based affective music systems lack controllability and flexibility for users.", "method": "Expert system generating music based on pre-determined or real-time arousal and valence values.", "result": "Listening study confirmed the system's ability to generate music matching target emotional states.", "conclusion": "AffectMachine-Pop is adaptable for interactive music generation or emotion self-regulation tools."}}
{"id": "2506.08346", "pdf": "https://arxiv.org/pdf/2506.08346", "abs": "https://arxiv.org/abs/2506.08346", "authors": ["Wenhan Yao", "Fen Xiao", "Xiarun Chen", "Jia Liu", "YongQiang He", "Weiping Wen"], "title": "SPBA: Utilizing Speech Large Language Model for Backdoor Attacks on Speech Classification Models", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "Accepted by IJCNN 2025", "summary": "Deep speech classification tasks, including keyword spotting and speaker\nverification, are vital in speech-based human-computer interaction. Recently,\nthe security of these technologies has been revealed to be susceptible to\nbackdoor attacks. Specifically, attackers use noisy disruption triggers and\nspeech element triggers to produce poisoned speech samples that train models to\nbecome vulnerable. However, these methods typically create only a limited\nnumber of backdoors due to the inherent constraints of the trigger function. In\nthis paper, we propose that speech backdoor attacks can strategically focus on\nspeech elements such as timbre and emotion, leveraging the Speech Large\nLanguage Model (SLLM) to generate diverse triggers. Increasing the number of\ntriggers may disproportionately elevate the poisoning rate, resulting in higher\nattack costs and a lower success rate per trigger. We introduce the Multiple\nGradient Descent Algorithm (MGDA) as a mitigation strategy to address this\nchallenge. The proposed attack is called the Speech Prompt Backdoor Attack\n(SPBA). Building on this foundation, we conducted attack experiments on two\nspeech classification tasks, demonstrating that SPBA shows significant trigger\neffectiveness and achieves exceptional performance in attack metrics.", "AI": {"tldr": "The paper introduces SPBA, a speech backdoor attack method using diverse triggers via SLLM, and proposes MGDA for mitigation. It shows high effectiveness in attack metrics.", "motivation": "Security vulnerabilities in deep speech classification tasks due to backdoor attacks, with existing methods limited by trigger constraints.", "method": "Proposes SPBA, leveraging SLLM for diverse triggers (timbre, emotion) and MGDA for mitigation. Tests on speech classification tasks.", "result": "SPBA demonstrates significant trigger effectiveness and exceptional performance in attack metrics.", "conclusion": "SPBA is an effective backdoor attack method, with MGDA mitigating its challenges, showing promise for future security research."}}
{"id": "2506.08183", "pdf": "https://arxiv.org/pdf/2506.08183", "abs": "https://arxiv.org/abs/2506.08183", "authors": ["Isha Puri", "David Cox"], "title": "A System for Accurate Tracking and Video Recordings of Rodent Eye Movements using Convolutional Neural Networks for Biomedical Image Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Research in neuroscience and vision science relies heavily on careful\nmeasurements of animal subject's gaze direction. Rodents are the most widely\nstudied animal subjects for such research because of their economic advantage\nand hardiness. Recently, video based eye trackers that use image processing\ntechniques have become a popular option for gaze tracking because they are easy\nto use and are completely noninvasive. Although significant progress has been\nmade in improving the accuracy and robustness of eye tracking algorithms,\nunfortunately, almost all of the techniques have focused on human eyes, which\ndoes not account for the unique characteristics of the rodent eye images, e.g.,\nvariability in eye parameters, abundance of surrounding hair, and their small\nsize. To overcome these unique challenges, this work presents a flexible,\nrobust, and highly accurate model for pupil and corneal reflection\nidentification in rodent gaze determination that can be incrementally trained\nto account for variability in eye parameters encountered in the field. To the\nbest of our knowledge, this is the first paper that demonstrates a highly\naccurate and practical biomedical image segmentation based convolutional neural\nnetwork architecture for pupil and corneal reflection identification in eye\nimages. This new method, in conjunction with our automated infrared videobased\neye recording system, offers the state of the art technology in eye tracking\nfor neuroscience and vision science research for rodents.", "AI": {"tldr": "A new flexible, robust, and accurate model for rodent gaze tracking using a convolutional neural network, addressing unique challenges like small eye size and surrounding hair.", "motivation": "Existing eye tracking methods focus on humans, neglecting rodent-specific challenges like eye variability and hair interference.", "method": "Develops a biomedical image segmentation-based CNN for pupil and corneal reflection identification, incrementally trainable for field variability.", "result": "Achieves high accuracy in rodent gaze determination, paired with an automated infrared video system for state-of-the-art tracking.", "conclusion": "Introduces a pioneering, practical solution for rodent eye tracking in neuroscience and vision science research."}}
{"id": "2506.08048", "pdf": "https://arxiv.org/pdf/2506.08048", "abs": "https://arxiv.org/abs/2506.08048", "authors": ["Zheng Han", "Jun Zhou", "Jialun Pei", "Jing Qin", "Yingfang Fan", "Qi Dou"], "title": "Towards Reliable AR-Guided Surgical Navigation: Interactive Deformation Modeling with Data-Driven Biomechanics and Prompts", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "In augmented reality (AR)-guided surgical navigation, preoperative organ\nmodels are superimposed onto the patient's intraoperative anatomy to visualize\ncritical structures such as vessels and tumors. Accurate deformation modeling\nis essential to maintain the reliability of AR overlays by ensuring alignment\nbetween preoperative models and the dynamically changing anatomy. Although the\nfinite element method (FEM) offers physically plausible modeling, its high\ncomputational cost limits intraoperative applicability. Moreover, existing\nalgorithms often fail to handle large anatomical changes, such as those induced\nby pneumoperitoneum or ligament dissection, leading to inaccurate anatomical\ncorrespondences and compromised AR guidance. To address these challenges, we\npropose a data-driven biomechanics algorithm that preserves FEM-level accuracy\nwhile improving computational efficiency. In addition, we introduce a novel\nhuman-in-the-loop mechanism into the deformation modeling process. This enables\nsurgeons to interactively provide prompts to correct anatomical misalignments,\nthereby incorporating clinical expertise and allowing the model to adapt\ndynamically to complex surgical scenarios. Experiments on a publicly available\ndataset demonstrate that our algorithm achieves a mean target registration\nerror of 3.42 mm. Incorporating surgeon prompts through the interactive\nframework further reduces the error to 2.78 mm, surpassing state-of-the-art\nmethods in volumetric accuracy. These results highlight the ability of our\nframework to deliver efficient and accurate deformation modeling while\nenhancing surgeon-algorithm collaboration, paving the way for safer and more\nreliable computer-assisted surgeries.", "AI": {"tldr": "A data-driven biomechanics algorithm improves AR-guided surgical navigation by combining FEM-level accuracy with computational efficiency and a human-in-the-loop mechanism for surgeon interaction.", "motivation": "Accurate deformation modeling in AR-guided surgeries is challenged by high computational costs of FEM and inability to handle large anatomical changes, leading to unreliable AR overlays.", "method": "Proposes a data-driven biomechanics algorithm with a human-in-the-loop mechanism, allowing surgeons to correct misalignments interactively.", "result": "Achieves a mean target registration error of 3.42 mm, reduced to 2.78 mm with surgeon prompts, outperforming state-of-the-art methods.", "conclusion": "The framework enhances accuracy and surgeon-algorithm collaboration, advancing safer and more reliable computer-assisted surgeries."}}
{"id": "2506.08026", "pdf": "https://arxiv.org/pdf/2506.08026", "abs": "https://arxiv.org/abs/2506.08026", "authors": ["Xibai Wang"], "title": "TIP-Search: Time-Predictable Inference Scheduling for Market Prediction under Uncertain Load", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "q-fin.CP"], "comment": null, "summary": "This paper proposes TIP-Search, a time-predictable inference scheduling\nframework for real-time market prediction under uncertain workloads. Motivated\nby the strict latency demands in high-frequency financial systems, TIP-Search\ndynamically selects a deep learning model from a heterogeneous pool, aiming to\nmaximize predictive accuracy while satisfying per-task deadline constraints.\nOur approach profiles latency and generalization performance offline, then\nperforms online task-aware selection without relying on explicit input domain\nlabels. We evaluate TIP-Search on three real-world limit order book datasets\n(FI-2010, Binance BTC/USDT, LOBSTER AAPL) and demonstrate that it outperforms\nstatic baselines with up to 8.5% improvement in accuracy and 100% deadline\nsatisfaction. Our results highlight the effectiveness of TIP-Search in robust\nlow-latency financial inference under uncertainty.", "AI": {"tldr": "TIP-Search is a dynamic deep learning model selection framework for real-time market prediction, ensuring accuracy and deadline compliance under uncertain workloads.", "motivation": "Addresses strict latency demands in high-frequency financial systems by dynamically selecting models to meet deadlines and maximize accuracy.", "method": "Profiles latency and performance offline, then performs online task-aware model selection without domain labels.", "result": "Outperforms static baselines with 8.5% higher accuracy and 100% deadline satisfaction on real-world datasets.", "conclusion": "TIP-Search effectively enables robust, low-latency financial inference under uncertainty."}}
{"id": "2506.08018", "pdf": "https://arxiv.org/pdf/2506.08018", "abs": "https://arxiv.org/abs/2506.08018", "authors": ["Fei Li", "Song Liu", "Weiguo Wu", "Shiqiang Nie", "Jinyu Wang"], "title": "KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache", "categories": ["cs.LG", "cs.AI", "03B65 ((Primary))", "I.2.7"], "comment": "14 pages, 8 figures, 4 tables", "summary": "The high memory demands of the Key-Value (KV) Cache during the inference of\nLarge Language Models (LLMs) severely restrict their deployment in\nresource-constrained platforms. Quantization can effectively alleviate the\nmemory pressure caused by KV Cache. However, existing methods either rely on\nstatic one-size-fits-all precision allocation or fail to dynamically prioritize\ncritical KV in long-context tasks, forcing memory-accuracy-throughput\ntradeoffs. In this work, we propose a novel mixed-precision quantization method\nfor KV Cache named KVmix. KVmix leverages gradient-based importance analysis to\nevaluate how individual Key and Value projection matrices affect the model\nloss, enabling layer-specific bit-width allocation for mix-precision\nquantization. It dynamically prioritizes higher precision for important layers\nwhile aggressively quantizing less influential ones, achieving a tunable\nbalance between accuracy and efficiency. KVmix also introduces a dynamic\nlong-context optimization strategy that adaptively keeps full-precision KV\npairs for recent pivotal tokens and compresses older ones, achieving\nhigh-quality sequence generation with low memory usage. Additionally, KVmix\nprovides efficient low-bit quantization and CUDA kernels to optimize\ncomputational overhead. On LLMs such as Llama and Mistral, KVmix achieves\nnear-lossless inference performance with extremely low quantization\nconfiguration (Key 2.19bit Value 2.38bit), while delivering a remarkable 4.9x\nmemory compression and a 5.3x speedup in inference throughput.", "AI": {"tldr": "KVmix is a mixed-precision quantization method for KV Cache in LLMs, dynamically allocating bit-widths and optimizing long-context tasks for memory efficiency and speed.", "motivation": "The high memory demands of KV Cache in LLMs limit deployment on resource-constrained platforms, necessitating efficient quantization methods.", "method": "KVmix uses gradient-based importance analysis for layer-specific bit-width allocation and dynamic long-context optimization, prioritizing critical KV pairs.", "result": "KVmix achieves near-lossless performance with low quantization (Key 2.19bit, Value 2.38bit), 4.9x memory compression, and 5.3x speedup.", "conclusion": "KVmix effectively balances accuracy and efficiency, enabling high-performance LLM inference with minimal memory usage."}}
{"id": "2506.08540", "pdf": "https://arxiv.org/pdf/2506.08540", "abs": "https://arxiv.org/abs/2506.08540", "authors": ["Dima Mrad", "Sara Najem"], "title": "Higher-Order Network Representation of J. S. Bach's Solo Violin Sonatas and Partitas: Topological and Geometrical Explorations", "categories": ["cs.SD", "eess.AS", "physics.soc-ph"], "comment": null, "summary": "Music is inherently complex, with structures and interactions that unfold\nacross multiple layers. Complex networks have emerged as powerful structures\nfor the quantitative analysis of Western classical music, revealing significant\nfeatures of its harmonic and structural organization. Although notable works\nhave used these approaches to study music, dyadic representations of\ninteractions fall short in conveying the underlying complexity and depth. In\nrecent years, the limitations of traditional graph representations have been\nquestioned and challenged in the context of interactions that could be\nhigher-dimensional. Effective musical analysis requires models that capture\nhigher-order interactions and a framework that simultaneously captures\ntransitions between them. Subsequently, in this paper, we present a topological\nframework for analyzing J. S. Bach's Solo Violin Sonatas and Partitas that uses\nhigher-order networks where single notes are vertices, two-note chords are\nedges, three-notes are triangles, etc. We subsequently account for the flow of\nmusic, by modeling transitions between successive notes. We identify\ngenre-specific patterns in the works' geometric and topological properties. In\nparticular, we find signatures in the trends of the evolution of the Euler\ncharacteristic and curvature, as well as examining adherence to the\nGauss-Bonnet theorem across different movement types. The distinctions are\nrevealed between slow movements, Fugues, and Baroque dance movements through\ntheir simplicial complex representation.", "AI": {"tldr": "A topological framework using higher-order networks analyzes J.S. Bach's Solo Violin Sonatas and Partitas, revealing genre-specific patterns in geometric and topological properties.", "motivation": "Traditional dyadic representations fail to capture the complexity of music, necessitating higher-order models for accurate analysis.", "method": "Higher-order networks represent notes as vertices, chords as edges, and higher structures (e.g., triangles) to model transitions and flow.", "result": "Genre-specific patterns emerge in Euler characteristic, curvature, and adherence to the Gauss-Bonnet theorem, distinguishing movement types.", "conclusion": "The framework successfully captures higher-order interactions in music, providing insights into Bach's compositions."}}
{"id": "2506.09046", "pdf": "https://arxiv.org/pdf/2506.09046", "abs": "https://arxiv.org/abs/2506.09046", "authors": ["Xiaowen Ma", "Chenyang Lin", "Yao Zhang", "Volker Tresp", "Yunpu Ma"], "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Leveraging multiple Large Language Models(LLMs) has proven effective for\naddressing complex, high-dimensional tasks, but current approaches often rely\non static, manually engineered multi-agent configurations. To overcome these\nconstraints, we present the Agentic Neural Network(ANN), a framework that\nconceptualizes multi-agent collaboration as a layered neural network\narchitecture. In this design, each agent operates as a node, and each layer\nforms a cooperative \"team\" focused on a specific subtask. Agentic Neural\nNetwork follows a two-phase optimization strategy: (1) Forward Phase-Drawing\ninspiration from neural network forward passes, tasks are dynamically\ndecomposed into subtasks, and cooperative agent teams with suitable aggregation\nmethods are constructed layer by layer. (2) Backward Phase-Mirroring\nbackpropagation, we refine both global and local collaboration through\niterative feedback, allowing agents to self-evolve their roles, prompts, and\ncoordination. This neuro-symbolic approach enables ANN to create new or\nspecialized agent teams post-training, delivering notable gains in accuracy and\nadaptability. Across four benchmark datasets, ANN surpasses leading multi-agent\nbaselines under the same configurations, showing consistent performance\nimprovements. Our findings indicate that ANN provides a scalable, data-driven\nframework for multi-agent systems, combining the collaborative capabilities of\nLLMs with the efficiency and flexibility of neural network principles. We plan\nto open-source the entire framework.", "AI": {"tldr": "The paper introduces Agentic Neural Network (ANN), a framework for dynamic multi-agent collaboration inspired by neural networks, improving accuracy and adaptability in complex tasks.", "motivation": "Current multi-agent systems rely on static configurations, limiting flexibility and performance. ANN aims to address this by enabling dynamic, data-driven collaboration.", "method": "ANN uses a two-phase optimization: (1) Forward Phase for dynamic task decomposition and agent team formation, and (2) Backward Phase for iterative refinement of collaboration.", "result": "ANN outperforms existing multi-agent systems on four benchmark datasets, showing consistent improvements in accuracy and adaptability.", "conclusion": "ANN offers a scalable, data-driven approach for multi-agent systems, combining LLM collaboration with neural network efficiency. The framework will be open-sourced."}}
{"id": "2506.08123", "pdf": "https://arxiv.org/pdf/2506.08123", "abs": "https://arxiv.org/abs/2506.08123", "authors": ["Jacob Dineen", "Aswin RRV", "Qin Liu", "Zhikun Xu", "Xiao Ye", "Ming Shen", "Zhaonan Li", "Shijie Lu", "Chitta Baral", "Muhao Chen", "Ben Zhou"], "title": "QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA", "categories": ["cs.CL"], "comment": null, "summary": "Alignment of large language models with explicit principles (such as\nhelpfulness, honesty, and harmlessness) is crucial for ensuring safe and\nreliable AI systems. However, standard reward-based alignment methods typically\ncollapse diverse feedback into a single scalar reward, entangling multiple\nobjectives into one opaque training signal, which hinders interpretability. In\nthis work, we introduce QA-LIGN, an automatic symbolic reward decomposition\napproach that preserves the structure of each constitutional principle within\nthe reward mechanism. Instead of training a black-box reward model that outputs\na monolithic score, QA-LIGN formulates principle-specific evaluation questions\nand derives separate reward components for each principle, making it a drop-in\nreward model replacement. Experiments aligning an uncensored large language\nmodel with a set of constitutional principles demonstrate that QA-LIGN offers\ngreater transparency and adaptability in the alignment process. At the same\ntime, our approach achieves performance on par with or better than a DPO\nbaseline. Overall, these results represent a step toward more interpretable and\ncontrollable alignment of language models, achieved without sacrificing\nend-task performance.", "AI": {"tldr": "QA-LIGN decomposes rewards by principles for transparent AI alignment, matching or outperforming DPO.", "motivation": "Standard reward-based alignment methods collapse diverse feedback into a single opaque signal, hindering interpretability.", "method": "QA-LIGN uses principle-specific evaluation questions to derive separate reward components, replacing monolithic reward models.", "result": "QA-LIGN offers greater transparency and adaptability, performing on par or better than DPO.", "conclusion": "QA-LIGN advances interpretable and controllable alignment without sacrificing performance."}}
{"id": "2506.08493", "pdf": "https://arxiv.org/pdf/2506.08493", "abs": "https://arxiv.org/abs/2506.08493", "authors": ["Qilin Yin", "Wei Lu", "Xiangyang Luo", "Xiaochun Cao"], "title": "Context-aware TFL: A Universal Context-aware Contrastive Learning Framework for Temporal Forgery Localization", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Most research efforts in the multimedia forensics domain have focused on\ndetecting forgery audio-visual content and reached sound achievements. However,\nthese works only consider deepfake detection as a classification task and\nignore the case where partial segments of the video are tampered with. Temporal\nforgery localization (TFL) of small fake audio-visual clips embedded in real\nvideos is still challenging and more in line with realistic application\nscenarios. To resolve this issue, we propose a universal context-aware\ncontrastive learning framework (UniCaCLF) for TFL. Our approach leverages\nsupervised contrastive learning to discover and identify forged instants by\nmeans of anomaly detection, allowing for the precise localization of temporal\nforged segments. To this end, we propose a novel context-aware perception layer\nthat utilizes a heterogeneous activation operation and an adaptive context\nupdater to construct a context-aware contrastive objective, which enhances the\ndiscriminability of forged instant features by contrasting them with genuine\ninstant features in terms of their distances to the global context. An\nefficient context-aware contrastive coding is introduced to further push the\nlimit of instant feature distinguishability between genuine and forged instants\nin a supervised sample-by-sample manner, suppressing the cross-sample influence\nto improve temporal forgery localization performance. Extensive experimental\nresults over five public datasets demonstrate that our proposed UniCaCLF\nsignificantly outperforms the state-of-the-art competing algorithms.", "AI": {"tldr": "The paper proposes UniCaCLF, a context-aware contrastive learning framework for temporal forgery localization (TFL) in videos, outperforming existing methods.", "motivation": "Existing deepfake detection methods treat it as classification, ignoring partial tampering. TFL for small fake clips in real videos is more realistic but challenging.", "method": "Uses supervised contrastive learning with a context-aware perception layer and adaptive context updater to enhance feature discriminability and localize forged segments.", "result": "UniCaCLF significantly outperforms state-of-the-art methods on five public datasets.", "conclusion": "The framework effectively addresses TFL challenges, offering precise localization of forged segments in videos."}}
{"id": "2506.08348", "pdf": "https://arxiv.org/pdf/2506.08348", "abs": "https://arxiv.org/abs/2506.08348", "authors": ["Wenhan Yao", "Fen Xiao", "Xiarun Chen", "Jia Liu", "YongQiang He", "Weiping Wen"], "title": "Pureformer-VC: Non-parallel Voice Conversion with Pure Stylized Transformer Blocks and Triplet Discriminative Training", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by IJCNN 2025", "summary": "As a foundational technology for intelligent human-computer interaction,\nvoice conversion (VC) seeks to transform speech from any source timbre into any\ntarget timbre. Traditional voice conversion methods based on Generative\nAdversarial Networks (GANs) encounter significant challenges in precisely\nencoding diverse speech elements and effectively synthesising these elements\ninto natural-sounding converted speech. To overcome these limitations, we\nintroduce Pureformer-VC, an encoder-decoder framework that utilizes Conformer\nblocks to build a disentangled encoder and employs Zipformer blocks to create a\nstyle transfer decoder. We adopt a variational decoupled training approach to\nisolate speech components using a Variational Autoencoder (VAE), complemented\nby triplet discriminative training to enhance the speaker's discriminative\ncapabilities. Furthermore, we incorporate the Attention Style Transfer\nMechanism (ASTM) with Zipformer's shared weights to improve the style transfer\nperformance in the decoder. We conducted experiments on two multi-speaker\ndatasets. The experimental results demonstrate that the proposed model achieves\ncomparable subjective evaluation scores while significantly enhancing objective\nmetrics compared to existing approaches in many-to-many and many-to-one VC\nscenarios.", "AI": {"tldr": "Pureformer-VC is a novel voice conversion framework using Conformer and Zipformer blocks, with variational decoupled training and attention style transfer, outperforming traditional GAN-based methods in both subjective and objective metrics.", "motivation": "Traditional GAN-based voice conversion methods struggle with precise encoding and natural synthesis of speech elements. Pureformer-VC aims to address these limitations.", "method": "The framework uses Conformer blocks for a disentangled encoder and Zipformer blocks for a style transfer decoder, with variational decoupled training (VAE) and triplet discriminative training. ASTM enhances style transfer.", "result": "Experiments on multi-speaker datasets show Pureformer-VC achieves comparable subjective scores and better objective metrics than existing methods in many-to-many and many-to-one VC.", "conclusion": "Pureformer-VC effectively overcomes traditional GAN limitations, offering improved performance in voice conversion tasks."}}
{"id": "2506.08280", "pdf": "https://arxiv.org/pdf/2506.08280", "abs": "https://arxiv.org/abs/2506.08280", "authors": ["Daniel H. Pak", "Shubh Thaker", "Kyle Baylous", "Xiaoran Zhang", "Danny Bluestein", "James S. Duncan"], "title": "Snap-and-tune: combining deep learning and test-time optimization for high-fidelity cardiovascular volumetric meshing", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "High-quality volumetric meshing from medical images is a key bottleneck for\nphysics-based simulations in personalized medicine. For volumetric meshing of\ncomplex medical structures, recent studies have often utilized deep learning\n(DL)-based template deformation approaches to enable fast test-time generation\nwith high spatial accuracy. However, these approaches still exhibit\nlimitations, such as limited flexibility at high-curvature areas and\nunrealistic inter-part distances. In this study, we introduce a simple yet\neffective snap-and-tune strategy that sequentially applies DL and test-time\noptimization, which combines fast initial shape fitting with more detailed\nsample-specific mesh corrections. Our method provides significant improvements\nin both spatial accuracy and mesh quality, while being fully automated and\nrequiring no additional training labels. Finally, we demonstrate the\nversatility and usefulness of our newly generated meshes via solid mechanics\nsimulations in two different software platforms. Our code is available at\nhttps://github.com/danpak94/Deep-Cardiac-Volumetric-Mesh.", "AI": {"tldr": "A snap-and-tune strategy combining DL and test-time optimization improves volumetric meshing from medical images, enhancing spatial accuracy and mesh quality without extra training labels.", "motivation": "High-quality volumetric meshing is crucial for personalized medicine, but existing DL-based methods struggle with high-curvature areas and inter-part distances.", "method": "The proposed method uses a sequential DL and test-time optimization approach (snap-and-tune) for fast initial fitting and detailed mesh corrections.", "result": "The method significantly improves spatial accuracy and mesh quality, demonstrated via solid mechanics simulations.", "conclusion": "The snap-and-tune strategy is versatile, automated, and effective for generating high-quality meshes for medical simulations."}}
{"id": "2506.08052", "pdf": "https://arxiv.org/pdf/2506.08052", "abs": "https://arxiv.org/abs/2506.08052", "authors": ["Yongkang Li", "Kaixin Xiong", "Xiangyu Guo", "Fang Li", "Sixu Yan", "Gangwei Xu", "Lijun Zhou", "Long Chen", "Haiyang Sun", "Bing Wang", "Guang Chen", "Hangjun Ye", "Wenyu Liu", "Xinggang Wang"], "title": "ReCogDrive: A Reinforced Cognitive Framework for End-to-End Autonomous Driving", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Although end-to-end autonomous driving has made remarkable progress, its\nperformance degrades significantly in rare and long-tail scenarios. Recent\napproaches attempt to address this challenge by leveraging the rich world\nknowledge of Vision-Language Models (VLMs), but these methods suffer from\nseveral limitations: (1) a significant domain gap between the pre-training data\nof VLMs and real-world driving data, (2) a dimensionality mismatch between the\ndiscrete language space and the continuous action space, and (3) imitation\nlearning tends to capture the average behavior present in the dataset, which\nmay be suboptimal even dangerous. In this paper, we propose ReCogDrive, an\nautonomous driving system that integrates VLMs with diffusion planner, which\nadopts a three-stage paradigm for training. In the first stage, we use a\nlarge-scale driving question-answering datasets to train the VLMs, mitigating\nthe domain discrepancy between generic content and real-world driving\nscenarios. In the second stage, we employ a diffusion-based planner to perform\nimitation learning, mapping representations from the latent language space to\ncontinuous driving actions. Finally, we fine-tune the diffusion planner using\nreinforcement learning with NAVSIM non-reactive simulator, enabling the model\nto generate safer, more human-like driving trajectories. We evaluate our\napproach on the planning-oriented NAVSIM benchmark, achieving a PDMS of 89.6\nand setting a new state-of-the-art that surpasses the previous vision-only SOTA\nby 5.6 PDMS.", "AI": {"tldr": "ReCogDrive integrates Vision-Language Models (VLMs) with a diffusion planner to improve autonomous driving in rare scenarios, addressing domain gaps and action space mismatches.", "motivation": "Current autonomous driving systems struggle with rare scenarios and domain gaps between VLMs and real-world data. Imitation learning also captures suboptimal behaviors.", "method": "A three-stage approach: (1) train VLMs on driving Q&A data, (2) use a diffusion planner for imitation learning, (3) fine-tune with reinforcement learning.", "result": "Achieves 89.6 PDMS on NAVSIM, surpassing the previous SOTA by 5.6 PDMS.", "conclusion": "ReCogDrive effectively bridges domain gaps and improves driving performance in rare scenarios."}}
{"id": "2506.08098", "pdf": "https://arxiv.org/pdf/2506.08098", "abs": "https://arxiv.org/abs/2506.08098", "authors": ["Akash Vishwakarma", "Hojin Lee", "Mohith Suresh", "Priyam Shankar Sharma", "Rahul Vishwakarma", "Sparsh Gupta", "Yuvraj Anupam Chauhan"], "title": "Cognitive Weave: Synthesizing Abstracted Knowledge with a Spatio-Temporal Resonance Graph", "categories": ["cs.AI"], "comment": null, "summary": "The emergence of capable large language model (LLM) based agents necessitates\nmemory architectures that transcend mere data storage, enabling continuous\nlearning, nuanced reasoning, and dynamic adaptation. Current memory systems\noften grapple with fundamental limitations in structural flexibility, temporal\nawareness, and the ability to synthesize higher-level insights from raw\ninteraction data. This paper introduces Cognitive Weave, a novel memory\nframework centered around a multi-layered spatio-temporal resonance graph\n(STRG). This graph manages information as semantically rich insight particles\n(IPs), which are dynamically enriched with resonance keys, signifiers, and\nsituational imprints via a dedicated semantic oracle interface (SOI). These IPs\nare interconnected through typed relational strands, forming an evolving\nknowledge tapestry. A key component of Cognitive Weave is the cognitive\nrefinement process, an autonomous mechanism that includes the synthesis of\ninsight aggregates (IAs) condensed, higher-level knowledge structures derived\nfrom identified clusters of related IPs. We present comprehensive experimental\nresults demonstrating Cognitive Weave's marked enhancement over existing\napproaches in long-horizon planning tasks, evolving question-answering\nscenarios, and multi-session dialogue coherence. The system achieves a notable\n34% average improvement in task completion rates and a 42% reduction in mean\nquery latency when compared to state-of-the-art baselines. Furthermore, this\npaper explores the ethical considerations inherent in such advanced memory\nsystems, discusses the implications for long-term memory in LLMs, and outlines\npromising future research trajectories.", "AI": {"tldr": "Cognitive Weave is a novel memory framework for LLM-based agents, using a multi-layered spatio-temporal resonance graph to enhance learning, reasoning, and adaptation, outperforming existing methods by 34% in task completion and 42% in query latency.", "motivation": "Current memory systems lack structural flexibility, temporal awareness, and higher-level insight synthesis, limiting LLM-based agents' capabilities.", "method": "Introduces Cognitive Weave with a spatio-temporal resonance graph (STRG) managing insight particles (IPs) and a semantic oracle interface (SOI) for dynamic enrichment, interconnected by relational strands. Includes cognitive refinement for higher-level knowledge synthesis.", "result": "Achieves 34% better task completion and 42% lower query latency than baselines in planning, QA, and dialogue tasks.", "conclusion": "Cognitive Weave advances LLM memory systems, with ethical considerations and future research directions outlined."}}
{"id": "2506.08019", "pdf": "https://arxiv.org/pdf/2506.08019", "abs": "https://arxiv.org/abs/2506.08019", "authors": ["Andrew Wells", "Geraldine Henningsen", "Brice Bolane Tchinde Kengne"], "title": "Gridding Forced Displacement using Semi-Supervised Learning", "categories": ["cs.LG", "cs.CV", "cs.CY"], "comment": null, "summary": "We present a semi-supervised approach that disaggregates refugee statistics\nfrom administrative boundaries to 0.5-degree grid cells across 25 Sub-Saharan\nAfrican countries. By integrating UNHCR's ProGres registration data with\nsatellite-derived building footprints from Google Open Buildings and location\ncoordinates from OpenStreetMap Populated Places, our label spreading algorithm\ncreates spatially explicit refugee statistics at high granularity.This\nmethodology achieves 92.9% average accuracy in placing over 10 million refugee\nobservations into appropriate grid cells, enabling the identification of\nlocalized displacement patterns previously obscured in broader regional and\nnational statistics. The resulting high-resolution dataset provides a\nfoundation for a deeper understanding of displacement drivers.", "AI": {"tldr": "A semi-supervised method disaggregates refugee stats to 0.5-degree grids in 25 African countries, achieving 92.9% accuracy.", "motivation": "To uncover localized displacement patterns obscured in broader statistics.", "method": "Integrates UNHCR data, satellite footprints, and OpenStreetMap coordinates using label spreading.", "result": "92.9% accuracy in placing 10M+ refugee observations into grid cells.", "conclusion": "High-resolution dataset aids in understanding displacement drivers."}}
{"id": "2506.08570", "pdf": "https://arxiv.org/pdf/2506.08570", "abs": "https://arxiv.org/abs/2506.08570", "authors": ["Or Tal", "Felix Kreuk", "Yossi Adi"], "title": "Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": null, "summary": "Recent progress in text-to-music generation has enabled models to synthesize\nhigh-quality musical segments, full compositions, and even respond to\nfine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA)\nsystems differ significantly across many dimensions, such as training datasets,\nmodeling paradigms, and architectural choices. This diversity complicates\nefforts to evaluate models fairly and pinpoint which design choices most\ninfluence performance. While factors like data and architecture are important,\nin this study we focus exclusively on the modeling paradigm. We conduct a\nsystematic empirical analysis to isolate its effects, offering insights into\nassociated trade-offs and emergent behaviors that can guide future\ntext-to-music generation systems. Specifically, we compare the two arguably\nmost common modeling paradigms: Auto-Regressive decoding and Conditional\nFlow-Matching. We conduct a controlled comparison by training all models from\nscratch using identical datasets, training configurations, and similar backbone\narchitectures. Performance is evaluated across multiple axes, including\ngeneration quality, robustness to inference configurations, scalability,\nadherence to both textual and temporally aligned conditioning, and editing\ncapabilities in the form of audio inpainting. This comparative study sheds\nlight on distinct strengths and limitations of each paradigm, providing\nactionable insights that can inform future architectural and training decisions\nin the evolving landscape of text-to-music generation. Audio sampled examples\nare available at: https://huggingface.co/spaces/ortal1602/ARvsFM", "AI": {"tldr": "The paper compares Auto-Regressive decoding and Conditional Flow-Matching paradigms in text-to-music generation, analyzing their performance and trade-offs.", "motivation": "To isolate the effects of modeling paradigms in text-to-music generation and guide future system designs.", "method": "A controlled comparison of Auto-Regressive decoding and Conditional Flow-Matching using identical datasets, training configurations, and similar architectures.", "result": "The study highlights distinct strengths and limitations of each paradigm, providing insights into generation quality, robustness, scalability, and editing capabilities.", "conclusion": "The findings offer actionable insights for future text-to-music generation systems, emphasizing the importance of modeling paradigm choices."}}
{"id": "2411.00570", "pdf": "https://arxiv.org/pdf/2411.00570", "abs": "https://arxiv.org/abs/2411.00570", "authors": ["Julian Heinovski", "Do\u011fanalp Ergen\u00e7", "Kirsten Thommes", "Falko Dressler"], "title": "Incentive-based Platoon Formation: Optimizing the Personal Benefit for Drivers", "categories": ["cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "Platooning or cooperative adaptive cruise control (CACC) has been\ninvestigated for decades, but debate about its lasting impact is still ongoing.\nWhile the benefits of platooning and the formation of platoons are well\nunderstood for trucks, they are less clear for passenger cars, which have a\nhigher heterogeneity in trips and drivers' preferences. Most importantly, it\nremains unclear how to form platoons of passenger cars in order to optimize the\npersonal benefit for the individual driver. To this end, in this paper, we\npropose a novel platoon formation algorithm that optimizes the personal benefit\nfor drivers of individual passenger cars. For computing vehicle-to-platoon\nassignments, the algorithm utilizes a new metric that we propose to evaluate\nthe personal benefits of various driving systems, including platooning. By\ncombining fuel and travel time costs into a single monetary value, drivers can\nestimate overall trip costs according to a personal monetary value for time\nspent. This provides an intuitive way for drivers to understand and compare the\nbenefits of driving systems like human driving, adaptive cruise control (ACC),\nand, of course, platooning. Unlike previous similarity-based methods, our\nproposed algorithm forms platoons only when beneficial for the driver, rather\nthan solely for platooning. We demonstrate the new metric for the total trip\ncost in a numerical analysis and explain its interpretation. Results of a\nlarge-scale simulation study demonstrate that our proposed platoon formation\nalgorithm outperforms normal ACC as well as previous similarity-based\nplatooning approaches by balancing fuel savings and travel time, independent of\ntraffic and drivers' time cost.", "AI": {"tldr": "A novel platoon formation algorithm optimizes personal benefits for passenger car drivers by balancing fuel savings and travel time, outperforming traditional methods.", "motivation": "The impact of platooning on passenger cars is unclear due to trip and driver heterogeneity. The paper aims to optimize personal benefits for individual drivers.", "method": "Proposes a new metric combining fuel and travel time costs into a single monetary value, and a platoon formation algorithm prioritizing driver benefits.", "result": "The algorithm outperforms adaptive cruise control and similarity-based platooning, balancing fuel savings and travel time effectively.", "conclusion": "The proposed method provides an intuitive way for drivers to evaluate and benefit from platooning, addressing previous limitations."}}
{"id": "2506.08136", "pdf": "https://arxiv.org/pdf/2506.08136", "abs": "https://arxiv.org/abs/2506.08136", "authors": ["Zefang Liu", "Yinzhu Quan"], "title": "EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments", "categories": ["cs.CL"], "comment": null, "summary": "We introduce EconWebArena, a benchmark for evaluating autonomous agents on\ncomplex, multimodal economic tasks in realistic web environments. The benchmark\ncomprises 360 curated tasks from 82 authoritative websites spanning domains\nsuch as macroeconomics, labor, finance, trade, and public policy. Each task\nchallenges agents to navigate live websites, interpret structured and visual\ncontent, interact with real interfaces, and extract precise, time-sensitive\ndata through multi-step workflows. We construct the benchmark by prompting\nmultiple large language models (LLMs) to generate candidate tasks, followed by\nrigorous human curation to ensure clarity, feasibility, and source reliability.\nUnlike prior work, EconWebArena emphasizes fidelity to authoritative data\nsources and the need for grounded web-based economic reasoning. We evaluate a\ndiverse set of state-of-the-art multimodal LLMs as web agents, analyze failure\ncases, and conduct ablation studies to assess the impact of visual grounding,\nplan-based reasoning, and interaction design. Our results reveal substantial\nperformance gaps and highlight persistent challenges in grounding, navigation,\nand multimodal understanding, positioning EconWebArena as a rigorous testbed\nfor economic web intelligence.", "AI": {"tldr": "EconWebArena is a benchmark for evaluating autonomous agents on complex economic tasks in web environments, featuring 360 tasks from 82 authoritative sources. It tests navigation, multimodal understanding, and data extraction, with rigorous human curation. Evaluations reveal performance gaps in grounding and reasoning.", "motivation": "To create a realistic benchmark for assessing autonomous agents' ability to handle complex, multimodal economic tasks on live websites, emphasizing authoritative data and grounded reasoning.", "method": "Tasks were generated by LLMs and curated by humans for clarity and reliability. The benchmark evaluates multimodal LLMs as web agents, analyzing grounding, navigation, and interaction.", "result": "Substantial performance gaps were found, highlighting challenges in grounding, navigation, and multimodal understanding.", "conclusion": "EconWebArena serves as a rigorous testbed for advancing economic web intelligence, identifying key areas for improvement in autonomous agents."}}
{"id": "2506.08524", "pdf": "https://arxiv.org/pdf/2506.08524", "abs": "https://arxiv.org/abs/2506.08524", "authors": ["Weiguo Wang", "Andy Nie", "Wenrui Zhou", "Yi Kai", "Chengchen Hu"], "title": "Teaching Physical Awareness to LLMs through Sounds", "categories": ["cs.SD", "cs.AI", "cs.MM", "cs.RO", "eess.AS"], "comment": "ICML 2025", "summary": "Large Language Models (LLMs) have shown remarkable capabilities in text and\nmultimodal processing, yet they fundamentally lack physical\nawareness--understanding of real-world physical phenomena. In this work, we\npresent ACORN, a framework that teaches LLMs physical awareness through sound,\nfocusing on fundamental physical phenomena like the Doppler effect, multipath\neffect, and spatial relationships. To overcome data scarcity, ACORN introduce a\nphysics-based simulator combining real-world sound sources with controlled\nphysical channels to generate diverse training data. Using this simulator, we\nbuild AQA-PHY, a comprehensive Audio Question-Answer dataset, and propose an\naudio encoder that processes both magnitude and phase information. By\nconnecting our audio encoder to state-of-the-art LLMs, we demonstrate\nreasonable results in both simulated and real-world tasks, such as\nline-of-sight detection, Doppler effect estimation, and Direction-of-Arrival\nestimation, paving the way for enabling LLMs to understand physical world.", "AI": {"tldr": "ACORN teaches LLMs physical awareness using sound and a physics-based simulator, achieving reasonable results in real-world tasks.", "motivation": "LLMs lack physical awareness, limiting their understanding of real-world phenomena.", "method": "ACORN uses a physics-based simulator to generate training data, builds the AQA-PHY dataset, and connects an audio encoder to LLMs.", "result": "Demonstrates success in tasks like line-of-sight detection and Doppler effect estimation.", "conclusion": "ACORN paves the way for LLMs to understand the physical world through sound."}}
{"id": "2506.08372", "pdf": "https://arxiv.org/pdf/2506.08372", "abs": "https://arxiv.org/abs/2506.08372", "authors": ["Rishabh Ranjan", "Likhith Ayinala", "Mayank Vatsa", "Richa Singh"], "title": "Multimodal Zero-Shot Framework for Deepfake Hate Speech Detection in Low-Resource Languages", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted in Interpseech 2025", "summary": "This paper introduces a novel multimodal framework for hate speech detection\nin deepfake audio, excelling even in zero-shot scenarios. Unlike previous\napproaches, our method uses contrastive learning to jointly align audio and\ntext representations across languages. We present the first benchmark dataset\nwith 127,290 paired text and synthesized speech samples in six languages:\nEnglish and five low-resource Indian languages (Hindi, Bengali, Marathi, Tamil,\nTelugu). Our model learns a shared semantic embedding space, enabling robust\ncross-lingual and cross-modal classification. Experiments on two multilingual\ntest sets show our approach outperforms baselines, achieving accuracies of\n0.819 and 0.701, and generalizes well to unseen languages. This demonstrates\nthe advantage of combining modalities for hate speech detection in synthetic\nmedia, especially in low-resource settings where unimodal models falter. The\nDataset is available at https://www.iab-rubric.org/resources.", "AI": {"tldr": "A novel multimodal framework for hate speech detection in deepfake audio using contrastive learning, outperforming baselines in multilingual and zero-shot scenarios.", "motivation": "Addressing the challenge of hate speech detection in synthetic media, especially in low-resource languages, where unimodal models struggle.", "method": "Uses contrastive learning to align audio and text representations across languages, creating a shared semantic embedding space.", "result": "Achieves accuracies of 0.819 and 0.701 on multilingual test sets, generalizing well to unseen languages.", "conclusion": "The framework demonstrates the effectiveness of multimodal approaches for hate speech detection in low-resource settings."}}
{"id": "2506.08520", "pdf": "https://arxiv.org/pdf/2506.08520", "abs": "https://arxiv.org/abs/2506.08520", "authors": ["Srinivasan Kidambi", "Pravin Nair"], "title": "Plug-and-Play Linear Attention for Pre-trained Image and Video Restoration Models", "categories": ["eess.IV", "cs.CV"], "comment": "6 pages, 1 pseudo-code, 3 figure panels, 2 plot panels, 7 tables, 24\n  references", "summary": "Multi-head self-attention (MHSA) has become a core component in modern\ncomputer vision models. However, its quadratic complexity with respect to input\nlength poses a significant computational bottleneck in real-time and resource\nconstrained environments. We propose PnP-Nystra, a Nystr\\\"om based linear\napproximation of self-attention, developed as a plug-and-play (PnP) module that\ncan be integrated into the pre-trained image and video restoration models\nwithout retraining. As a drop-in replacement for MHSA, PnP-Nystra enables\nefficient acceleration in various window-based transformer architectures,\nincluding SwinIR, Uformer, and RVRT. Our experiments across diverse image and\nvideo restoration tasks, including denoising, deblurring, and super-resolution,\ndemonstrate that PnP-Nystra achieves a 2-4x speed-up on an NVIDIA RTX 4090 GPU\nand a 2-5x speed-up on CPU inference. Despite these significant gains, the\nmethod incurs a maximum PSNR drop of only 1.5 dB across all evaluated tasks. To\nthe best of our knowledge, we are the first to demonstrate a linear attention\nfunctioning as a training-free substitute for MHSA in restoration models.", "AI": {"tldr": "PnP-Nystra is a Nystr\u00f6m-based linear approximation of self-attention, offering a plug-and-play module for efficient acceleration in transformer architectures without retraining.", "motivation": "Quadratic complexity of multi-head self-attention (MHSA) is a computational bottleneck in real-time and resource-constrained environments.", "method": "Proposes PnP-Nystra, a Nystr\u00f6m-based linear approximation of self-attention, as a drop-in replacement for MHSA in pre-trained models.", "result": "Achieves 2-4x speed-up on GPU and 2-5x on CPU with a maximum PSNR drop of 1.5 dB.", "conclusion": "PnP-Nystra is the first linear attention method functioning as a training-free substitute for MHSA in restoration models."}}
{"id": "2506.08071", "pdf": "https://arxiv.org/pdf/2506.08071", "abs": "https://arxiv.org/abs/2506.08071", "authors": ["Aniket Rege", "Zinnia Nie", "Mahesh Ramesh", "Unmesh Raskar", "Zhuoran Yu", "Aditya Kusupati", "Yong Jae Lee", "Ramya Korlakai Vinayak"], "title": "CuRe: Cultural Gaps in the Long Tail of Text-to-Image Systems", "categories": ["cs.CV"], "comment": "41 pages, 22 figures, 17 tables", "summary": "Popular text-to-image (T2I) systems are trained on web-scraped data, which is\nheavily Amero and Euro-centric, underrepresenting the cultures of the Global\nSouth. To analyze these biases, we introduce CuRe, a novel and scalable\nbenchmarking and scoring suite for cultural representativeness that leverages\nthe marginal utility of attribute specification to T2I systems as a proxy for\nhuman judgments. Our CuRe benchmark dataset has a novel categorical hierarchy\nbuilt from the crowdsourced Wikimedia knowledge graph, with 300 cultural\nartifacts across 32 cultural subcategories grouped into six broad cultural axes\n(food, art, fashion, architecture, celebrations, and people). Our dataset's\ncategorical hierarchy enables CuRe scorers to evaluate T2I systems by analyzing\ntheir response to increasing the informativeness of text conditioning, enabling\nfine-grained cultural comparisons. We empirically observe much stronger\ncorrelations of our class of scorers to human judgments of perceptual\nsimilarity, image-text alignment, and cultural diversity across image encoders\n(SigLIP 2, AIMV2 and DINOv2), vision-language models (OpenCLIP, SigLIP 2,\nGemini 2.0 Flash) and state-of-the-art text-to-image systems, including three\nvariants of Stable Diffusion (1.5, XL, 3.5 Large), FLUX.1 [dev], Ideogram 2.0,\nand DALL-E 3. The code and dataset is open-sourced and available at\nhttps://aniketrege.github.io/cure/.", "AI": {"tldr": "CuRe is a benchmarking tool for evaluating cultural representativeness in text-to-image systems, addressing biases toward Global South cultures.", "motivation": "To address the underrepresentation of Global South cultures in T2I systems trained on Amero/Euro-centric data.", "method": "Leverages marginal utility of attribute specification to create a scalable benchmark (CuRe) with a hierarchical dataset of 300 cultural artifacts across 32 subcategories.", "result": "Strong correlations between CuRe scorers and human judgments across various models and T2I systems.", "conclusion": "CuRe provides a fine-grained, scalable solution for assessing cultural diversity in T2I systems, with open-sourced code and dataset."}}
{"id": "2506.08119", "pdf": "https://arxiv.org/pdf/2506.08119", "abs": "https://arxiv.org/abs/2506.08119", "authors": ["Subhrangshu Nandi", "Arghya Datta", "Nikhil Vichare", "Indranil Bhattacharya", "Huzefa Raja", "Jing Xu", "Shayan Ray", "Giuseppe Carenini", "Abhi Srivastava", "Aaron Chan", "Man Ho Woo", "Amar Kandola", "Brandon Theresa", "Francesco Carbone"], "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "categories": ["cs.AI"], "comment": "Under review", "summary": "Large Language Models (LLMs) demonstrate impressive general-purpose reasoning\nand problem-solving abilities. However, they struggle with executing complex,\nlong-horizon workflows that demand strict adherence to Standard Operating\nProcedures (SOPs), a critical requirement for real-world industrial automation.\nDespite this need, there is a lack of public benchmarks that reflect the\ncomplexity, structure, and domain-specific nuances of SOPs. To address this, we\npresent three main contributions. First, we introduce a synthetic data\ngeneration framework to create realistic, industry-grade SOPs that rigorously\ntest the planning, reasoning, and tool-use capabilities of LLM-based agents.\nSecond, using this framework, we develop SOP-Bench, a benchmark of over 1,800\ntasks across 10 industrial domains, each with APIs, tool interfaces, and\nhuman-validated test cases. Third, we evaluate two prominent agent\narchitectures: Function-Calling and ReAct Agents, on SOP-Bench, observing\naverage success rates of only 27% and 48%, respectively. Remarkably, when the\ntool registry is much larger than necessary, agents invoke incorrect tools\nnearly 100% of the time. These findings underscore a substantial gap between\ncurrent agentic capabilities of LLMs and the demands of automating real-world\nSOPs. Performance varies significantly by task and domain, highlighting the\nneed for domain-specific benchmarking and architectural choices before\ndeployment. SOP-Bench is publicly available at\nhttp://sop-bench.s3-website-us-west-2.amazonaws.com/. We also release the\nprompts underpinning the data generation framework to support new\ndomain-specific SOP benchmarks. We invite the community to extend SOP-Bench\nwith SOPs from their industrial domains.", "AI": {"tldr": "The paper introduces SOP-Bench, a benchmark for evaluating LLM-based agents on complex industrial SOPs, revealing significant performance gaps.", "motivation": "Address the lack of benchmarks for LLMs handling complex, domain-specific SOPs in industrial automation.", "method": "Develop a synthetic data generation framework for realistic SOPs and create SOP-Bench with 1,800 tasks across 10 domains. Evaluate Function-Calling and ReAct Agents.", "result": "Agents achieved low success rates (27% and 48%) and struggled with incorrect tool usage in larger registries.", "conclusion": "Current LLM agents fall short in automating real-world SOPs, emphasizing the need for domain-specific benchmarking and architectural improvements."}}
{"id": "2506.08020", "pdf": "https://arxiv.org/pdf/2506.08020", "abs": "https://arxiv.org/abs/2506.08020", "authors": ["Zi-Ying Chen", "Chuan-Xian Ren", "Hong Yan"], "title": "Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Partial domain adaptation (PDA) problem requires aligning cross-domain\nsamples while distinguishing the outlier classes for accurate knowledge\ntransfer. The widely used weighting framework tries to address the outlier\nclasses by introducing the reweighed source domain with a similar label\ndistribution to the target domain. However, the empirical modeling of weights\ncan only characterize the sample-wise relations, which leads to insufficient\nexploration of cluster structures, and the weights could be sensitive to the\ninaccurate prediction and cause confusion on the outlier classes. To tackle\nthese issues, we propose a Bi-level Unbalanced Optimal Transport (BUOT) model\nto simultaneously characterize the sample-wise and class-wise relations in a\nunified transport framework. Specifically, a cooperation mechanism between\nsample-level and class-level transport is introduced, where the sample-level\ntransport provides essential structure information for the class-level\nknowledge transfer, while the class-level transport supplies discriminative\ninformation for the outlier identification. The bi-level transport plan\nprovides guidance for the alignment process. By incorporating the label-aware\ntransport cost, the local transport structure is ensured and a fast computation\nformulation is derived to improve the efficiency. Extensive experiments on\nbenchmark datasets validate the competitiveness of BUOT.", "AI": {"tldr": "The paper proposes a Bi-level Unbalanced Optimal Transport (BUOT) model to address partial domain adaptation by simultaneously handling sample-wise and class-wise relations, improving outlier identification and alignment.", "motivation": "The motivation is to overcome limitations in existing weighting frameworks for partial domain adaptation, which inadequately explore cluster structures and are sensitive to inaccurate predictions.", "method": "The method introduces a bi-level transport framework (BUOT) that combines sample-level and class-level transport, leveraging their cooperation for better alignment and outlier identification.", "result": "Extensive experiments on benchmark datasets show BUOT's competitiveness in addressing partial domain adaptation.", "conclusion": "BUOT effectively unifies sample-wise and class-wise relations, enhancing knowledge transfer and outlier identification in partial domain adaptation."}}
{"id": "2506.08717", "pdf": "https://arxiv.org/pdf/2506.08717", "abs": "https://arxiv.org/abs/2506.08717", "authors": ["Mehedi Hasan Bijoy", "Dejan Porjazovski", "Tam\u00e1s Gr\u00f3sz", "Mikko Kurimo"], "title": "Multi-Teacher Language-Aware Knowledge Distillation for Multilingual Speech Emotion Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to INTERSPEECH 2025 conference", "summary": "Speech Emotion Recognition (SER) is crucial for improving human-computer\ninteraction. Despite strides in monolingual SER, extending them to build a\nmultilingual system remains challenging. Our goal is to train a single model\ncapable of multilingual SER by distilling knowledge from multiple teacher\nmodels. To address this, we introduce a novel language-aware multi-teacher\nknowledge distillation method to advance SER in English, Finnish, and French.\nIt leverages Wav2Vec2.0 as the foundation of monolingual teacher models and\nthen distills their knowledge into a single multilingual student model. The\nstudent model demonstrates state-of-the-art performance, with a weighted recall\nof 72.9 on the English dataset and an unweighted recall of 63.4 on the Finnish\ndataset, surpassing fine-tuning and knowledge distillation baselines. Our\nmethod excels in improving recall for sad and neutral emotions, although it\nstill faces challenges in recognizing anger and happiness.", "AI": {"tldr": "A novel language-aware multi-teacher knowledge distillation method is introduced to create a multilingual Speech Emotion Recognition (SER) model, achieving state-of-the-art performance in English, Finnish, and French.", "motivation": "Extending monolingual SER to multilingual systems is challenging, and the goal is to train a single model capable of multilingual SER by distilling knowledge from multiple teacher models.", "method": "The method uses Wav2Vec2.0 as the foundation for monolingual teacher models and distills their knowledge into a single multilingual student model.", "result": "The student model achieves a weighted recall of 72.9 on English and 63.4 on Finnish datasets, outperforming baselines. It excels in recognizing sad and neutral emotions but struggles with anger and happiness.", "conclusion": "The proposed method advances multilingual SER performance but has limitations in recognizing certain emotions."}}
{"id": "2308.00505", "pdf": "https://arxiv.org/pdf/2308.00505", "abs": "https://arxiv.org/abs/2308.00505", "authors": ["Frederike Oetker", "Vittorio Nespeca", "Rick Quax"], "title": "FREIDA: A Framework for developing quantitative agent based models based on qualitative expert knowledge", "categories": ["cs.AI", "cs.MA"], "comment": "26 pages, 4 figures, 15 tables, Appendix I-II", "summary": "Agent Based Models (ABMs) often deal with systems where there is a lack of\nquantitative data or where quantitative data alone may be insufficient to fully\ncapture the complexities of real-world systems. Expert knowledge and\nqualitative insights, such as those obtained through interviews, ethnographic\nresearch, historical accounts, or participatory workshops, are critical in\nconstructing realistic behavioral rules, interactions, and decision-making\nprocesses within these models. However, there is a lack of systematic\napproaches that are able to incorporate both qualitative and quantitative data\nacross the entire modeling cycle. To address this, we propose FREIDA (FRamework\nfor Expert-Informed Data-driven Agent-based models), a systematic mixed-methods\nframework to develop, train, and validate ABMs, particularly in data-sparse\ncontexts. Our main technical innovation is to extract what we call Expected\nSystem Behaviors (ESBs) from qualitative data, which are testable statements\nthat can be evaluated on model simulations. Divided into Calibration Statements\n(CS) for model calibration and Validation Statements (VS) for model validation,\nthey provide a quantitative scoring mechanism on the same footing as\nquantitative data. In this way, qualitative insights can inform not only model\nspecification but also its parameterization and assessment of fitness for\npurpose, which is a long standing challenge. We illustrate the application of\nFREIDA through a case study of criminal cocaine networks in the Netherlands.", "AI": {"tldr": "FREIDA is a mixed-methods framework integrating qualitative and quantitative data for ABMs, using Expected System Behaviors (ESBs) for calibration and validation.", "motivation": "Addressing the lack of systematic approaches to incorporate qualitative and quantitative data in ABMs, especially in data-sparse contexts.", "method": "Proposes FREIDA, which extracts ESBs from qualitative data as testable statements (CS for calibration, VS for validation) for quantitative scoring.", "result": "Enables qualitative insights to inform model specification, parameterization, and validation, demonstrated via a case study on criminal cocaine networks.", "conclusion": "FREIDA bridges the gap between qualitative and quantitative data in ABMs, enhancing their realism and applicability."}}
{"id": "2506.08147", "pdf": "https://arxiv.org/pdf/2506.08147", "abs": "https://arxiv.org/abs/2506.08147", "authors": ["Muhammad Usman", "Muhammad Ahmad", "M. Shahiki Tash", "Irina Gelbukh", "Rolando Quintero Tellez", "Grigori Sidorov"], "title": "Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Social media platforms are critical spaces for public discourse, shaping\nopinions and community dynamics, yet their widespread use has amplified harmful\ncontent, particularly hate speech, threatening online safety and inclusivity.\nWhile hate speech detection has been extensively studied in languages like\nEnglish and Spanish, Urdu remains underexplored, especially using\ntranslation-based approaches. To address this gap, we introduce a trilingual\ndataset of 10,193 tweets in English (3,834 samples), Urdu (3,197 samples), and\nSpanish (3,162 samples), collected via keyword filtering, with a balanced\ndistribution of 4,849 Hateful and 5,344 Not-Hateful labels. Our methodology\nleverages attention layers as a precursor to transformer-based models and large\nlanguage models (LLMs), enhancing feature extraction for multilingual hate\nspeech detection. For non-transformer models, we use TF-IDF for feature\nextraction. The dataset is benchmarked using state-of-the-art models, including\nGPT-3.5 Turbo and Qwen 2.5 72B, alongside traditional machine learning models\nlike SVM and other transformers (e.g., BERT, RoBERTa). Three annotators,\nfollowing rigorous guidelines, ensured high dataset quality, achieving a\nFleiss' Kappa of 0.821. Our approach, integrating attention layers with GPT-3.5\nTurbo and Qwen 2.5 72B, achieves strong performance, with macro F1 scores of\n0.87 for English (GPT-3.5 Turbo), 0.85 for Spanish (GPT-3.5 Turbo), 0.81 for\nUrdu (Qwen 2.5 72B), and 0.88 for the joint multilingual model (Qwen 2.5 72B).\nThese results reflect improvements of 8.75% in English (over SVM baseline\n0.80), 8.97% in Spanish (over SVM baseline 0.78), 5.19% in Urdu (over SVM\nbaseline 0.77), and 7.32% in the joint multilingual model (over SVM baseline\n0.82). Our framework offers a robust solution for multilingual hate speech\ndetection, fostering safer digital communities worldwide.", "AI": {"tldr": "The paper introduces a trilingual dataset for hate speech detection in English, Urdu, and Spanish, leveraging attention layers and transformer models to achieve strong performance, with significant improvements over baseline methods.", "motivation": "Addressing the underexplored area of hate speech detection in Urdu and enhancing multilingual approaches using translation-based methods.", "method": "Uses attention layers with transformer models (e.g., GPT-3.5 Turbo, Qwen 2.5 72B) and TF-IDF for non-transformer models, benchmarked against traditional ML models like SVM.", "result": "Achieves macro F1 scores of 0.87 (English), 0.85 (Spanish), 0.81 (Urdu), and 0.88 (multilingual), with improvements of 5-9% over baselines.", "conclusion": "The framework provides a robust solution for multilingual hate speech detection, promoting safer online communities."}}
{"id": "2506.08591", "pdf": "https://arxiv.org/pdf/2506.08591", "abs": "https://arxiv.org/abs/2506.08591", "authors": ["Chengchao Shen", "Hourun Zhu", "Gongfan Fang", "Jianxin Wang", "Xinchao Wang"], "title": "Diversity-Guided MLP Reduction for Efficient Large Vision Transformers", "categories": ["cs.CV", "cs.LG", "cs.MM"], "comment": null, "summary": "Transformer models achieve excellent scaling property, where the performance\nis improved with the increment of model capacity. However, large-scale model\nparameters lead to an unaffordable cost of computing and memory. We analyze\npopular transformer architectures and find that multilayer perceptron (MLP)\nmodules take up the majority of model parameters. To this end, we focus on the\nrecoverability of the compressed models and propose a Diversity-Guided MLP\nReduction (DGMR) method to significantly reduce the parameters of large vision\ntransformers with only negligible performance degradation. Specifically, we\nconduct a Gram-Schmidt weight pruning strategy to eliminate redundant neurons\nof MLP hidden layer, while preserving weight diversity for better performance\nrecover during distillation. Compared to the model trained from scratch, our\npruned model only requires 0.06\\% data of LAION-2B (for the training of large\nvision transformers) without labels (ImageNet-1K) to recover the original\nperformance. Experimental results on several state-of-the-art large vision\ntransformers demonstrate that our method achieves a more than 57.0\\% parameter\nand FLOPs reduction in a near lossless manner. Notably, for EVA-CLIP-E (4.4B),\nour method accomplishes a 71.5\\% parameter and FLOPs reduction without\nperformance degradation. The source code and trained weights are available at\nhttps://github.com/visresearch/DGMR.", "AI": {"tldr": "DGMR method reduces MLP parameters in large vision transformers with minimal performance loss, achieving over 57% parameter and FLOPs reduction.", "motivation": "Large transformer models are computationally expensive due to MLP modules dominating parameters.", "method": "Diversity-Guided MLP Reduction (DGMR) uses Gram-Schmidt pruning to eliminate redundant neurons while preserving weight diversity.", "result": "Achieves 57-71.5% parameter and FLOPs reduction with negligible performance loss, requiring only 0.06% of training data.", "conclusion": "DGMR effectively compresses large vision transformers, maintaining performance while reducing computational costs."}}
{"id": "2506.08967", "pdf": "https://arxiv.org/pdf/2506.08967", "abs": "https://arxiv.org/abs/2506.08967", "authors": ["Ailin Huang", "Bingxin Li", "Bruce Wang", "Boyong Wu", "Chao Yan", "Chengli Feng", "Heng Wang", "Hongyu Zhou", "Hongyuan Wang", "Jingbei Li", "Jianjian Sun", "Joanna Wang", "Mingrui Chen", "Peng Liu", "Ruihang Miao", "Shilei Jiang", "Tian Fei", "Wang You", "Xi Chen", "Xuerui Yang", "Yechang Huang", "Yuxiang Zhang", "Zheng Ge", "Zheng Gong", "Zhewei Huang", "Zixin Zhang", "Bin Wang", "Bo Li", "Buyun Ma", "Changxin Miao", "Changyi Wan", "Chen Xu", "Dapeng Shi", "Dingyuan Hu", "Enle Liu", "Guanzhe Huang", "Gulin Yan", "Hanpeng Hu", "Haonan Jia", "Jiahao Gong", "Jiaoren Wu", "Jie Wu", "Jie Yang", "Junzhe Lin", "Kaixiang Li", "Lei Xia", "Longlong Gu", "Ming Li", "Nie Hao", "Ranchen Ming", "Shaoliang Pang", "Siqi Liu", "Song Yuan", "Tiancheng Cao", "Wen Li", "Wenqing He", "Xu Zhao", "Xuelin Zhang", "Yanbo Yu", "Yinmin Zhong", "Yu Zhou", "Yuanwei Liang", "Yuanwei Lu", "Yuxiang Yang", "Zidong Yang", "Zili Zhang", "Binxing Jiao", "Heung-Yeung Shum", "Jiansheng Chen", "Jing Li", "Xiangyu Zhang", "Xinhao Zhang", "Yibo Zhu", "Daxin Jiang", "Shuchang Zhou", "Chen Hu"], "title": "Step-Audio-AQAA: a Fully End-to-End Expressive Large Audio Language Model", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "12 pages, 3 figures", "summary": "Large Audio-Language Models (LALMs) have significantly advanced intelligent\nhuman-computer interaction, yet their reliance on text-based outputs limits\ntheir ability to generate natural speech responses directly, hindering seamless\naudio interactions. To address this, we introduce Step-Audio-AQAA, a fully\nend-to-end LALM designed for Audio Query-Audio Answer (AQAA) tasks. The model\nintegrates a dual-codebook audio tokenizer for linguistic and semantic feature\nextraction, a 130-billion-parameter backbone LLM and a neural vocoder for\nhigh-fidelity speech synthesis. Our post-training approach employs interleaved\ntoken-output of text and audio to enhance semantic coherence and combines\nDirect Preference Optimization (DPO) with model merge to improve performance.\nEvaluations on the StepEval-Audio-360 benchmark demonstrate that\nStep-Audio-AQAA excels especially in speech control, outperforming the\nstate-of-art LALMs in key areas. This work contributes a promising solution for\nend-to-end LALMs and highlights the critical role of token-based vocoder in\nenhancing overall performance for AQAA tasks.", "AI": {"tldr": "Step-Audio-AQAA is an end-to-end LALM for Audio Query-Audio Answer tasks, integrating a dual-codebook tokenizer, a large LLM, and a neural vocoder, outperforming state-of-the-art models.", "motivation": "Existing LALMs rely on text outputs, limiting natural speech generation for seamless audio interactions.", "method": "Uses a dual-codebook audio tokenizer, 130B-parameter LLM, and neural vocoder, with post-training via interleaved token-output and DPO.", "result": "Outperforms state-of-the-art LALMs in speech control on StepEval-Audio-360 benchmark.", "conclusion": "Step-Audio-AQAA advances end-to-end LALMs, emphasizing the importance of token-based vocoders for AQAA tasks."}}
{"id": "2506.08534", "pdf": "https://arxiv.org/pdf/2506.08534", "abs": "https://arxiv.org/abs/2506.08534", "authors": ["Donglian Li", "Hui Guo", "Minglang Chen", "Huizhen Chen", "Jialing Chen", "Bocheng Liang", "Pengchen Liang", "Ying Tan"], "title": "DCD: A Semantic Segmentation Model for Fetal Ultrasound Four-Chamber View", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Accurate segmentation of anatomical structures in the apical four-chamber\n(A4C) view of fetal echocardiography is essential for early diagnosis and\nprenatal evaluation of congenital heart disease (CHD). However, precise\nsegmentation remains challenging due to ultrasound artifacts, speckle noise,\nanatomical variability, and boundary ambiguity across different gestational\nstages. To reduce the workload of sonographers and enhance segmentation\naccuracy, we propose DCD, an advanced deep learning-based model for automatic\nsegmentation of key anatomical structures in the fetal A4C view. Our model\nincorporates a Dense Atrous Spatial Pyramid Pooling (Dense ASPP) module,\nenabling superior multi-scale feature extraction, and a Convolutional Block\nAttention Module (CBAM) to enhance adaptive feature representation. By\neffectively capturing both local and global contextual information, DCD\nachieves precise and robust segmentation, contributing to improved prenatal\ncardiac assessment.", "AI": {"tldr": "A deep learning model (DCD) is proposed for automatic segmentation of fetal heart structures in A4C view, addressing challenges like noise and variability.", "motivation": "Accurate segmentation in fetal echocardiography is crucial for early CHD diagnosis but is hindered by ultrasound artifacts and anatomical variability.", "method": "DCD integrates Dense ASPP for multi-scale feature extraction and CBAM for adaptive feature representation, combining local and global context.", "result": "DCD achieves precise and robust segmentation, enhancing prenatal cardiac assessment.", "conclusion": "The model reduces sonographer workload and improves segmentation accuracy for better CHD diagnosis."}}
{"id": "2506.08137", "pdf": "https://arxiv.org/pdf/2506.08137", "abs": "https://arxiv.org/abs/2506.08137", "authors": ["Oishee Bintey Hoque", "Abhijin Adiga", "Aniruddha Adiga", "Siddharth Chaudhary", "Madhav V. Marathe", "S. S. Ravi", "Kirti Rajagopalan", "Amanda Wilson", "Samarth Swarup"], "title": "IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate canal network mapping is essential for water management, including\nirrigation planning and infrastructure maintenance. State-of-the-art semantic\nsegmentation models for infrastructure mapping, such as roads, rely on large,\nwell-annotated remote sensing datasets. However, incomplete or inadequate\nground truth can hinder these learning approaches. Many infrastructure networks\nhave graph-level properties such as reachability to a source (like canals) or\nconnectivity (roads) that can be leveraged to improve these existing ground\ntruth. This paper develops a novel iterative framework IGraSS, combining a\nsemantic segmentation module-incorporating RGB and additional modalities (NDWI,\nDEM)-with a graph-based ground-truth refinement module. The segmentation module\nprocesses satellite imagery patches, while the refinement module operates on\nthe entire data viewing the infrastructure network as a graph. Experiments show\nthat IGraSS reduces unreachable canal segments from around 18% to 3%, and\ntraining with refined ground truth significantly improves canal identification.\nIGraSS serves as a robust framework for both refining noisy ground truth and\nmapping canal networks from remote sensing imagery. We also demonstrate the\neffectiveness and generalizability of IGraSS using road networks as an example,\napplying a different graph-theoretic constraint to complete road networks.", "AI": {"tldr": "IGraSS is a novel framework combining semantic segmentation and graph-based refinement to improve canal and road network mapping from noisy ground truth.", "motivation": "Accurate canal and road network mapping is crucial for water and infrastructure management, but incomplete ground truth hinders existing methods.", "method": "IGraSS integrates RGB, NDWI, and DEM data in a semantic segmentation module and refines ground truth using graph-level properties like reachability and connectivity.", "result": "IGraSS reduces unreachable canal segments from 18% to 3% and improves canal identification. It also generalizes to road networks.", "conclusion": "IGraSS effectively refines noisy ground truth and enhances infrastructure mapping, proving robust and generalizable."}}
{"id": "2506.08134", "pdf": "https://arxiv.org/pdf/2506.08134", "abs": "https://arxiv.org/abs/2506.08134", "authors": ["Qiyao Wei", "Samuel Holt", "Jing Yang", "Markus Wulfmeier", "Mihaela van der Schaar"], "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning", "categories": ["cs.AI", "cs.CY", "68T50, 68T07", "I.2.7; H.5.3"], "comment": "18 pages, 3 figures. Position paper", "summary": "Peer review, the bedrock of scientific advancement in machine learning (ML),\nis strained by a crisis of scale. Exponential growth in manuscript submissions\nto premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite\ncapacity of qualified reviewers, leading to concerns about review quality,\nconsistency, and reviewer fatigue. This position paper argues that AI-assisted\npeer review must become an urgent research and infrastructure priority. We\nadvocate for a comprehensive AI-augmented ecosystem, leveraging Large Language\nModels (LLMs) not as replacements for human judgment, but as sophisticated\ncollaborators for authors, reviewers, and Area Chairs (ACs). We propose\nspecific roles for AI in enhancing factual verification, guiding reviewer\nperformance, assisting authors in quality improvement, and supporting ACs in\ndecision-making. Crucially, we contend that the development of such systems\nhinges on access to more granular, structured, and ethically-sourced peer\nreview process data. We outline a research agenda, including illustrative\nexperiments, to develop and validate these AI assistants, and discuss\nsignificant technical and ethical challenges. We call upon the ML community to\nproactively build this AI-assisted future, ensuring the continued integrity and\nscalability of scientific validation, while maintaining high standards of peer\nreview.", "AI": {"tldr": "The paper advocates for AI-assisted peer review in ML to address the crisis of scale, proposing LLMs as collaborators to enhance review quality without replacing human judgment.", "motivation": "The exponential growth in ML manuscript submissions is overwhelming reviewers, risking review quality and consistency. AI assistance is seen as a solution to maintain integrity and scalability.", "method": "Proposes an AI-augmented ecosystem using LLMs for factual verification, reviewer guidance, author assistance, and AC decision support, requiring structured review data.", "result": "Outlines a research agenda for developing AI assistants, including experiments, while addressing technical and ethical challenges.", "conclusion": "Calls for proactive development of AI-assisted peer review to uphold scientific validation standards and scalability in ML."}}
{"id": "2506.08021", "pdf": "https://arxiv.org/pdf/2506.08021", "abs": "https://arxiv.org/abs/2506.08021", "authors": ["Weihao Zou", "Weibing Feng", "Pin Wu"], "title": "FlowBERT: Prompt-tuned BERT for variable flow field prediction", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "This study proposes a universal flow field prediction framework based on\nknowledge transfer\n  from large language model (LLM), addressing the high computational costs of\ntraditional\n  computational fluid dynamics (CFD) methods and the limited cross-condition\ntransfer capability\n  of existing deep learning models. The framework innovatively integrates\nProper Orthogonal\n  Decomposition (POD) dimensionality reduction with fine-tuning strategies for\npretrained LLM,\n  where POD facilitates compressed representation of flow field features while\nthe fine-tuned model\n  learns to encode system dynamics in state space. To enhance the model's\nadaptability to flow field\n  data, we specifically designed fluid dynamics-oriented text templates that\nimprove predictive\n  performance through enriched contextual semantic information. Experimental\nresults demonstrate\n  that our framework outperforms conventional Transformer models in few-shot\nlearning scenarios while\n  exhibiting exceptional generalization across various inflow conditions and\nairfoil geometries.\n  Ablation studies reveal the contributions of key components in the FlowBERT\narchitecture. Compared\n  to traditional Navier-Stokes equation solvers requiring hours of computation,\nour approach reduces\n  prediction time to seconds while maintaining over 90% accuracy. The developed\nknowledge transfer\n  paradigm establishes a new direction for rapid fluid dynamics prediction,\nwith potential\n  applications extending to aerodynamic optimization, flow control, and other\nengineering domains.", "AI": {"tldr": "A framework using LLM and POD for fast, accurate flow field prediction, reducing computational time from hours to seconds.", "motivation": "Address high computational costs of CFD and limited transferability of deep learning models in fluid dynamics.", "method": "Integrates POD dimensionality reduction with fine-tuned LLM, using fluid dynamics-oriented text templates.", "result": "Outperforms Transformers in few-shot learning, generalizes well, and achieves >90% accuracy in seconds.", "conclusion": "Sets a new direction for rapid fluid dynamics prediction, with applications in aerodynamics and engineering."}}
{"id": "2506.08846", "pdf": "https://arxiv.org/pdf/2506.08846", "abs": "https://arxiv.org/abs/2506.08846", "authors": ["Katelyn Xiaoying Mei", "Anna Seo Gyeong Choi", "Hilke Schellmann", "Mona Sloane", "Allison Koenecke"], "title": "Addressing Pitfalls in Auditing Practices of Automatic Speech Recognition Technologies: A Case Study of People with Aphasia", "categories": ["cs.CY", "cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Automatic Speech Recognition (ASR) has transformed daily tasks from video\ntranscription to workplace hiring. ASR systems' growing use warrants robust and\nstandardized auditing approaches to ensure automated transcriptions of high and\nequitable quality. This is especially critical for people with speech and\nlanguage disorders (such as aphasia) who may disproportionately depend on ASR\nsystems to navigate everyday life. In this work, we identify three pitfalls in\nexisting standard ASR auditing procedures, and demonstrate how addressing them\nimpacts audit results via a case study of six popular ASR systems' performance\nfor aphasia speakers. First, audits often adhere to a single method of text\nstandardization during data pre-processing, which (a) masks variability in ASR\nperformance from applying different standardization methods, and (b) may not be\nconsistent with how users - especially those from marginalized speech\ncommunities - would want their transcriptions to be standardized. Second,\naudits often display high-level demographic findings without further\nconsidering performance disparities among (a) more nuanced demographic\nsubgroups, and (b) relevant covariates capturing acoustic information from the\ninput audio. Third, audits often rely on a single gold-standard metric -- the\nWord Error Rate -- which does not fully capture the extent of errors arising\nfrom generative AI models, such as transcription hallucinations. We propose a\nmore holistic auditing framework that accounts for these three pitfalls, and\nexemplify its results in our case study, finding consistently worse ASR\nperformance for aphasia speakers relative to a control group. We call on\npractitioners to implement these robust ASR auditing practices that remain\nflexible to the rapidly changing ASR landscape.", "AI": {"tldr": "The paper highlights flaws in current ASR auditing methods and proposes a more holistic framework, demonstrating its impact through a case study on aphasia speakers.", "motivation": "To address the need for robust and equitable ASR auditing, especially for marginalized groups like aphasia speakers.", "method": "Identifies three pitfalls in ASR audits: text standardization, demographic granularity, and reliance on Word Error Rate. Proposes a new framework addressing these issues.", "result": "ASR performance for aphasia speakers was consistently worse than controls, validating the need for improved auditing practices.", "conclusion": "Calls for adopting flexible, holistic ASR auditing frameworks to ensure equitable performance across diverse user groups."}}
{"id": "2401.00776", "pdf": "https://arxiv.org/pdf/2401.00776", "abs": "https://arxiv.org/abs/2401.00776", "authors": ["Qin Yang"], "title": "Edge Computing based Human-Robot Cognitive Fusion: A Medical Case Study in the Autism Spectrum Disorder Therapy", "categories": ["cs.RO", "cs.AI", "cs.DC", "cs.LG", "cs.MA"], "comment": "This paper was accepted by the 2025 IEEE Conference on Cognitive and\n  Computational Aspects of Situation Management (CogSIMA)", "summary": "In recent years, edge computing has served as a paradigm that enables many\nfuture technologies like AI, Robotics, IoT, and high-speed wireless sensor\nnetworks (like 5G) by connecting cloud computing facilities and services to the\nend users. Especially in medical and healthcare applications, it provides\nremote patient monitoring and increases voluminous multimedia. From the\nrobotics angle, robot-assisted therapy (RAT) is an active-assistive robotic\ntechnology in rehabilitation robotics, attracting researchers to study and\nbenefit people with disability like autism spectrum disorder (ASD) children.\nHowever, the main challenge of RAT is that the model capable of detecting the\naffective states of ASD people exists and can recall individual preferences.\nMoreover, involving expert diagnosis and recommendations to guide robots in\nupdating the therapy approach to adapt to different statuses and scenarios is a\ncrucial part of the ASD therapy process. This paper proposes the architecture\nof edge cognitive computing by combining human experts and assisted robots\ncollaborating in the same framework to achieve a seamless remote diagnosis,\nround-the-clock symptom monitoring, emergency warning, therapy alteration, and\nadvanced assistance.", "AI": {"tldr": "The paper proposes an edge cognitive computing architecture integrating human experts and assisted robots for seamless remote diagnosis and therapy adaptation in ASD treatment.", "motivation": "Edge computing supports advanced technologies like AI and IoT, particularly in healthcare. The challenge in robot-assisted therapy (RAT) for ASD is detecting affective states and adapting therapy with expert input.", "method": "The paper introduces an architecture combining edge computing, human experts, and assisted robots to enable remote diagnosis, monitoring, and adaptive therapy.", "result": "The proposed framework aims to achieve continuous symptom monitoring, emergency alerts, and personalized therapy updates for ASD patients.", "conclusion": "The architecture enhances RAT by leveraging edge computing and expert collaboration, improving ASD therapy outcomes."}}
{"id": "2506.08158", "pdf": "https://arxiv.org/pdf/2506.08158", "abs": "https://arxiv.org/abs/2506.08158", "authors": ["Lijing Zhu", "Qizhen Lan", "Qing Tian", "Wenbo Sun", "Li Yang", "Lu Xia", "Yixin Xie", "Xi Xiao", "Tiehang Duan", "Cui Tao", "Shuteng Niu"], "title": "ETT-CKGE: Efficient Task-driven Tokens for Continual Knowledge Graph Embedding", "categories": ["cs.CL"], "comment": null, "summary": "Continual Knowledge Graph Embedding (CKGE) seeks to integrate new knowledge\nwhile preserving past information. However, existing methods struggle with\nefficiency and scalability due to two key limitations: (1) suboptimal knowledge\npreservation between snapshots caused by manually designed node/relation\nimportance scores that ignore graph dependencies relevant to the downstream\ntask, and (2) computationally expensive graph traversal for node/relation\nimportance calculation, leading to slow training and high memory overhead. To\naddress these limitations, we introduce ETT-CKGE (Efficient, Task-driven,\nTokens for Continual Knowledge Graph Embedding), a novel task-guided CKGE\nmethod that leverages efficient task-driven tokens for efficient and effective\nknowledge transfer between snapshots. Our method introduces a set of learnable\ntokens that directly capture task-relevant signals, eliminating the need for\nexplicit node scoring or traversal. These tokens serve as consistent and\nreusable guidance across snapshots, enabling efficient token-masked embedding\nalignment between snapshots. Importantly, knowledge transfer is achieved\nthrough simple matrix operations, significantly reducing training time and\nmemory usage. Extensive experiments across six benchmark datasets demonstrate\nthat ETT-CKGE consistently achieves superior or competitive predictive\nperformance, while substantially improving training efficiency and scalability\ncompared to state-of-the-art CKGE methods. The code is available at:\nhttps://github.com/lijingzhu1/ETT-CKGE/tree/main", "AI": {"tldr": "ETT-CKGE introduces task-driven tokens for efficient continual knowledge graph embedding, improving scalability and performance.", "motivation": "Existing CKGE methods are inefficient and struggle with knowledge preservation due to suboptimal scoring and expensive graph traversal.", "method": "ETT-CKGE uses learnable task-driven tokens to capture task-relevant signals, avoiding explicit node scoring or traversal, and employs token-masked embedding alignment.", "result": "ETT-CKGE achieves superior or competitive predictive performance while significantly reducing training time and memory usage.", "conclusion": "ETT-CKGE is a scalable and efficient solution for continual knowledge graph embedding, outperforming existing methods."}}
{"id": "2305.11566", "pdf": "https://arxiv.org/pdf/2305.11566", "abs": "https://arxiv.org/abs/2305.11566", "authors": ["Qiong Chang", "Xiang Li", "Xin Xu", "Xin Liu", "Yun Li", "Miyazaki Jun"], "title": "StereoVAE: A lightweight stereo-matching system using embedded GPUs", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.RO"], "comment": "Will revise part of the contents", "summary": "We present a lightweight system for stereo matching through embedded GPUs. It\nbreaks the trade-off between accuracy and processing speed in stereo matching,\nenabling our embedded system to further improve the matching accuracy while\nensuring real-time processing. The main idea of our method is to construct a\ntiny neural network based on variational auto-encoder (VAE) to upsample and\nrefinement a small size of coarse disparity map, which is first generated by a\ntraditional matching method. The proposed hybrid structure cannot only bring\nthe advantage of traditional methods in terms of computational complexity, but\nalso ensure the matching accuracy under the impact of neural network. Extensive\nexperiments on the KITTI 2015 benchmark demonstrate that our tiny system\nexhibits high robustness in improving the accuracy of the coarse disparity maps\ngenerated by different algorithms, while also running in real-time on embedded\nGPUs.", "AI": {"tldr": "A lightweight system for stereo matching on embedded GPUs balances accuracy and speed using a hybrid approach combining traditional methods and a tiny VAE-based neural network.", "motivation": "To break the trade-off between accuracy and processing speed in stereo matching, enabling real-time performance on embedded systems without sacrificing accuracy.", "method": "A hybrid approach: a coarse disparity map is generated traditionally, then upsampled and refined by a tiny VAE-based neural network.", "result": "The system improves accuracy of coarse disparity maps from various algorithms and runs in real-time on embedded GPUs, as shown on the KITTI 2015 benchmark.", "conclusion": "The proposed hybrid system effectively combines traditional and neural network methods for efficient, accurate stereo matching on embedded GPUs."}}
{"id": "2506.08400", "pdf": "https://arxiv.org/pdf/2506.08400", "abs": "https://arxiv.org/abs/2506.08400", "authors": ["Luel Hagos Beyene", "Vivek Verma", "Min Ma", "Jesujoba O. Alabi", "Fabian David Schmidt", "Joyce Nakatumba-Nabende", "David Ifeoluwa Adelani"], "title": "mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "comment": "working paper", "summary": "Large Language models (LLMs) have demonstrated impressive performance on a\nwide range of tasks, including in multimodal settings such as speech. However,\ntheir evaluation is often limited to English and a few high-resource languages.\nFor low-resource languages, there is no standardized evaluation benchmark. In\nthis paper, we address this gap by introducing mSTEB, a new benchmark to\nevaluate the performance of LLMs on a wide range of tasks covering language\nidentification, text classification, question answering, and translation tasks\non both speech and text modalities. We evaluated the performance of leading\nLLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open\nmodels such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in\nperformance between high-resource and low-resource languages, especially for\nlanguages spoken in Africa and Americas/Oceania. Our findings show that more\ninvestment is needed to address their under-representation in LLMs coverage.", "AI": {"tldr": "The paper introduces mSTEB, a benchmark to evaluate LLMs on low-resource languages, revealing performance gaps between high- and low-resource languages.", "motivation": "Current LLM evaluations lack standardization for low-resource languages, limiting their applicability.", "method": "The authors created mSTEB, a benchmark covering tasks like language identification, text classification, QA, and translation across speech and text. Leading LLMs (e.g., Gemini 2.0 Flash, GPT-4o) and open models (e.g., Qwen 2 Audio) were evaluated.", "result": "A significant performance gap exists between high- and low-resource languages, particularly in African and Americas/Oceania languages.", "conclusion": "More investment is needed to improve LLM coverage for underrepresented languages."}}
{"id": "2506.08623", "pdf": "https://arxiv.org/pdf/2506.08623", "abs": "https://arxiv.org/abs/2506.08623", "authors": ["Rinat Prochii", "Elizaveta Dakhova", "Pavel Birulin", "Maxim Sharaev"], "title": "Biologically Inspired Deep Learning Approaches for Fetal Ultrasound Image Classification", "categories": ["eess.IV", "cs.CV"], "comment": "16 pages, 2 figures, 3 tables", "summary": "Accurate classification of second-trimester fetal ultrasound images remains\nchallenging due to low image quality, high intra-class variability, and\nsignificant class imbalance. In this work, we introduce a simple yet powerful,\nbiologically inspired deep learning ensemble framework that-unlike prior\nstudies focused on only a handful of anatomical targets-simultaneously\ndistinguishes 16 fetal structures. Drawing on the hierarchical, modular\norganization of biological vision systems, our model stacks two complementary\nbranches (a \"shallow\" path for coarse, low-resolution cues and a \"detailed\"\npath for fine, high-resolution features), concatenating their outputs for final\nprediction. To our knowledge, no existing method has addressed such a large\nnumber of classes with a comparably lightweight architecture. We trained and\nevaluated on 5,298 routinely acquired clinical images (annotated by three\nexperts and reconciled via Dawid-Skene), reflecting real-world noise and\nvariability rather than a \"cleaned\" dataset. Despite this complexity, our\nensemble (EfficientNet-B0 + EfficientNet-B6 with LDAM-Focal loss) identifies\n90% of organs with accuracy > 0.75 and 75% of organs with accuracy >\n0.85-performance competitive with more elaborate models applied to far fewer\ncategories. These results demonstrate that biologically inspired modular\nstacking can yield robust, scalable fetal anatomy recognition in challenging\nclinical settings.", "AI": {"tldr": "A biologically inspired deep learning ensemble framework is introduced to classify 16 fetal structures in ultrasound images, achieving high accuracy despite challenges like low image quality and class imbalance.", "motivation": "The challenge of accurately classifying second-trimester fetal ultrasound images due to low quality, high variability, and class imbalance motivates the development of a robust solution.", "method": "The model uses a hierarchical, modular approach with two branches (shallow for coarse cues, detailed for fine features) and combines their outputs. It employs EfficientNet-B0 + EfficientNet-B6 with LDAM-Focal loss.", "result": "The model achieves >0.75 accuracy for 90% of organs and >0.85 for 75%, outperforming simpler models on a large number of classes.", "conclusion": "Biologically inspired modular stacking enables scalable and robust fetal anatomy recognition in noisy clinical settings."}}
{"id": "2506.08163", "pdf": "https://arxiv.org/pdf/2506.08163", "abs": "https://arxiv.org/abs/2506.08163", "authors": ["Harshvardhan Takawale", "Nirupam Roy"], "title": "Spectral Domain Neural Reconstruction for Passband FMCW Radars", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2503.23313", "summary": "We present SpINRv2, a neural framework for high-fidelity volumetric\nreconstruction using Frequency-Modulated Continuous-Wave (FMCW) radar.\nExtending our prior work (SpINR), this version introduces enhancements that\nallow accurate learning under high start frequencies-where phase aliasing and\nsub-bin ambiguity become prominent. Our core contribution is a fully\ndifferentiable frequency-domain forward model that captures the complex radar\nresponse using closed-form synthesis, paired with an implicit neural\nrepresentation (INR) for continuous volumetric scene modeling. Unlike\ntime-domain baselines, SpINRv2 directly supervises the complex frequency\nspectrum, preserving spectral fidelity while drastically reducing computational\noverhead. Additionally, we introduce sparsity and smoothness regularization to\ndisambiguate sub-bin ambiguities that arise at fine range resolutions.\nExperimental results show that SpINRv2 significantly outperforms both classical\nand learning-based baselines, especially under high-frequency regimes,\nestablishing a new benchmark for neural radar-based 3D imaging.", "AI": {"tldr": "SpINRv2 is an improved neural framework for high-fidelity volumetric reconstruction using FMCW radar, addressing phase aliasing and sub-bin ambiguity at high frequencies.", "motivation": "To enhance volumetric reconstruction accuracy under high-frequency conditions where phase aliasing and sub-bin ambiguity are problematic.", "method": "Introduces a differentiable frequency-domain forward model with closed-form synthesis and implicit neural representation (INR) for scene modeling, plus sparsity and smoothness regularization.", "result": "Outperforms classical and learning-based baselines, especially in high-frequency regimes, setting a new benchmark for neural radar-based 3D imaging.", "conclusion": "SpINRv2 advances neural radar imaging by improving spectral fidelity and computational efficiency, addressing key challenges in high-frequency scenarios."}}
{"id": "2506.08150", "pdf": "https://arxiv.org/pdf/2506.08150", "abs": "https://arxiv.org/abs/2506.08150", "authors": ["Arvid Becker", "Pedro Cabalar", "Martin Di\u00e9guez", "Javier Romero", "Susana Hahn", "Torsten Schaub"], "title": "Compiling Metric Temporal Answer Set Programming", "categories": ["cs.AI", "cs.LO", "I.2.4; I.2.8"], "comment": null, "summary": "We develop a computational approach to Metric Answer Set Programming (ASP) to\nallow for expressing quantitative temporal constrains, like durations and\ndeadlines. A central challenge is to maintain scalability when dealing with\nfine-grained timing constraints, which can significantly exacerbate ASP's\ngrounding bottleneck. To address this issue, we leverage extensions of ASP with\ndifference constraints, a simplified form of linear constraints, to handle\ntime-related aspects externally. Our approach effectively decouples metric ASP\nfrom the granularity of time, resulting in a solution that is unaffected by\ntime precision.", "AI": {"tldr": "A computational approach for Metric ASP with quantitative temporal constraints, addressing scalability via difference constraints.", "motivation": "To handle fine-grained timing constraints in ASP without exacerbating grounding bottlenecks.", "method": "Extends ASP with difference constraints to manage time-related aspects externally.", "result": "Decouples metric ASP from time granularity, ensuring scalability regardless of time precision.", "conclusion": "The approach successfully maintains scalability while handling quantitative temporal constraints."}}
{"id": "2506.08022", "pdf": "https://arxiv.org/pdf/2506.08022", "abs": "https://arxiv.org/abs/2506.08022", "authors": ["Chenxi Liu", "Tianyi Xiong", "Ruibo Chen", "Yihan Wu", "Junfeng Guo", "Tianyi Zhou", "Heng Huang"], "title": "Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The task adaptation and alignment of Large Multimodal Models (LMMs) have been\nsignificantly advanced by instruction tuning and further strengthened by recent\npreference optimization. Yet, most LMMs still suffer from severe modality\nimbalance during reasoning, i.e., outweighing language prior biases over visual\ninputs, which bottlenecks their generalization to downstream tasks and causes\nhallucinations. However, existing preference optimization approaches for LMMs\ndo not focus on restraining the internal biases of their Large Language Model\n(LLM) backbones when curating the training data. Moreover, they heavily rely on\noffline data and lack the capacity to explore diverse responses adaptive to\ndynamic distributional shifts during training. Meanwhile, Group Relative Policy\nOptimization (GRPO), a recent method using online-generated data and verified\nrewards to improve reasoning capabilities, remains largely underexplored in LMM\nalignment. In this paper, we propose a novel preference learning framework,\nModality-Balancing Preference Optimization (MBPO), to address the modality\nimbalance in LMMs. MBPO constructs a more effective offline preference dataset\nby generating hard negatives, i.e., rejected responses misled by LLM biases due\nto limited usage of visual information, through adversarial perturbation of\ninput images. Moreover, MBPO leverages the easy-to-verify nature of close-ended\ntasks to generate online responses with verified rewards. GRPO is then employed\nto train the model with offline-online hybrid data. Extensive experiments\ndemonstrate that MBPO can enhance LMM performance on challenging\nvision-language tasks and effectively reduce hallucinations.", "AI": {"tldr": "MBPO addresses modality imbalance in LMMs by generating hard negatives and using online responses with verified rewards, improving performance and reducing hallucinations.", "motivation": "Existing LMMs suffer from modality imbalance and LLM biases, limiting generalization and causing hallucinations. Current methods lack focus on these issues and rely on offline data.", "method": "MBPO constructs an offline preference dataset with hard negatives via adversarial image perturbation and uses online responses with verified rewards. GRPO trains the model with hybrid data.", "result": "MBPO enhances LMM performance on vision-language tasks and reduces hallucinations.", "conclusion": "MBPO effectively balances modalities and improves LMM reasoning, offering a robust solution for alignment challenges."}}
{"id": "2410.23323", "pdf": "https://arxiv.org/pdf/2410.23323", "abs": "https://arxiv.org/abs/2410.23323", "authors": ["Peter Ochieng", "Dennis Kaburu"], "title": "Phonology-Guided Speech-to-Speech Translation for African Languages", "categories": ["eess.AS", "cs.AI", "cs.CL"], "comment": null, "summary": "We present a prosody-guided framework for speech-to-speech translation (S2ST)\nthat aligns and translates speech \\emph{without} transcripts by leveraging\ncross-linguistic pause synchrony. Analyzing a 6{,}000-hour East African news\ncorpus spanning five languages, we show that \\emph{within-phylum} language\npairs exhibit 30--40\\% lower pause variance and over 3$\\times$ higher\nonset/offset correlation compared to cross-phylum pairs. These findings\nmotivate \\textbf{SPaDA}, a dynamic-programming alignment algorithm that\nintegrates silence consistency, rate synchrony, and semantic similarity. SPaDA\nimproves alignment $F_1$ by +3--4 points and eliminates up to 38\\% of spurious\nmatches relative to greedy VAD baselines. Using SPaDA-aligned segments, we\ntrain \\textbf{SegUniDiff}, a diffusion-based S2ST model guided by\n\\emph{external gradients} from frozen semantic and speaker encoders. SegUniDiff\nmatches an enhanced cascade in BLEU (30.3 on CVSS-C vs.\\ 28.9 for UnitY),\nreduces speaker error rate (EER) from 12.5\\% to 5.3\\%, and runs at an RTF of\n1.02. To support evaluation in low-resource settings, we also release a\nthree-tier, transcript-free BLEU suite (M1--M3) that correlates strongly with\nhuman judgments. Together, our results show that prosodic cues in multilingual\nspeech provide a reliable scaffold for scalable, non-autoregressive S2ST.", "AI": {"tldr": "A prosody-guided framework for speech-to-speech translation (S2ST) leverages pause synchrony and introduces SPaDA for alignment and SegUniDiff for translation, improving accuracy and reducing speaker error.", "motivation": "To enable speech-to-speech translation without transcripts by leveraging cross-linguistic pause synchrony, addressing challenges in alignment and translation.", "method": "Developed SPaDA, a dynamic-programming alignment algorithm integrating silence consistency, rate synchrony, and semantic similarity, and SegUniDiff, a diffusion-based S2ST model guided by external gradients.", "result": "SPaDA improves alignment F1 by +3-4 points and reduces spurious matches by 38%. SegUniDiff matches BLEU scores of cascaded systems (30.3 vs. 28.9), reduces speaker error rate (12.5% to 5.3%), and runs efficiently (RTF 1.02).", "conclusion": "Prosodic cues in multilingual speech provide a reliable foundation for scalable, non-autoregressive S2ST, with practical improvements in alignment and translation quality."}}
{"id": "2401.05572", "pdf": "https://arxiv.org/pdf/2401.05572", "abs": "https://arxiv.org/abs/2401.05572", "authors": ["Qin Yang"], "title": "Innate-Values-driven Reinforcement Learning based Cooperative Multi-Agent Cognitive Modeling", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.RO"], "comment": "This paper had been accepted by the 2025 IEEE Conference on Cognitive\n  and Computational Aspects of Situation Management (CogSIMA)", "summary": "In multi-agent systems (MAS), the dynamic interaction among multiple\ndecision-makers is driven by their innate values, affecting the environment's\nstate, and can cause specific behavioral patterns to emerge. On the other hand,\ninnate values in cognitive modeling reflect individual interests and\npreferences for specific tasks and drive them to develop diverse skills and\nplans, satisfying their various needs and achieving common goals in\ncooperation. Therefore, building the awareness of AI agents to balance the\ngroup utilities and system costs and meet group members' needs in their\ncooperation is a crucial problem for individuals learning to support their\ncommunity and even integrate into human society in the long term. However, the\ncurrent MAS reinforcement learning domain lacks a general intrinsic model to\ndescribe agents' dynamic motivation for decision-making and learning from an\nindividual needs perspective in their cooperation. To address the gap, this\npaper proposes a general MAS innate-values reinforcement learning (IVRL)\narchitecture from the individual preferences angle. We tested the Multi-Agent\nIVRL Actor-Critic Model in different StarCraft Multi-Agent Challenge (SMAC)\nsettings, which demonstrated its potential to organize the group's behaviours\nto achieve better performance.", "AI": {"tldr": "The paper proposes a Multi-Agent Innate-Values Reinforcement Learning (IVRL) architecture to address the lack of a general intrinsic model for dynamic motivation in MAS, tested in StarCraft settings.", "motivation": "Current MAS reinforcement learning lacks a model to describe agents' dynamic motivation from an individual needs perspective during cooperation.", "method": "Proposes a general MAS innate-values reinforcement learning (IVRL) architecture, tested using a Multi-Agent IVRL Actor-Critic Model in StarCraft Multi-Agent Challenge (SMAC) settings.", "result": "The model demonstrated potential to organize group behaviors for better performance in SMAC.", "conclusion": "The IVRL architecture effectively balances group utilities and individual needs, enhancing cooperation in MAS."}}
{"id": "2506.08172", "pdf": "https://arxiv.org/pdf/2506.08172", "abs": "https://arxiv.org/abs/2506.08172", "authors": ["Gerardo Aleman Manzanarez", "Nora de la Cruz Arana", "Jorge Garcia Flores", "Yobany Garcia Medina", "Raul Monroy", "Nathalie Pernelle"], "title": "Can Artificial Intelligence Write Like Borges? An Evaluation Protocol for Spanish Microfiction", "categories": ["cs.CL"], "comment": "28 pages, 16 figures. Submitted to Applied Sciences", "summary": "Automated story writing has been a subject of study for over 60 years. Large\nlanguage models can generate narratively consistent and linguistically coherent\nshort fiction texts. Despite these advancements, rigorous assessment of such\noutputs for literary merit - especially concerning aesthetic qualities - has\nreceived scant attention. In this paper, we address the challenge of evaluating\nAI-generated microfictions and argue that this task requires consideration of\nliterary criteria across various aspects of the text, such as thematic\ncoherence, textual clarity, interpretive depth, and aesthetic quality. To\nfacilitate this, we present GrAImes: an evaluation protocol grounded in\nliterary theory, specifically drawing from a literary perspective, to offer an\nobjective framework for assessing AI-generated microfiction. Furthermore, we\nreport the results of our validation of the evaluation protocol, as answered by\nboth literature experts and literary enthusiasts. This protocol will serve as a\nfoundation for evaluating automatically generated microfictions and assessing\ntheir literary value.", "AI": {"tldr": "The paper introduces GrAImes, a literary theory-based protocol for evaluating AI-generated microfiction, addressing gaps in assessing literary merit.", "motivation": "Despite AI's ability to generate coherent short fiction, rigorous evaluation of literary qualities like thematic coherence and aesthetic quality is lacking.", "method": "The authors propose GrAImes, an evaluation protocol grounded in literary theory, and validate it with literature experts and enthusiasts.", "result": "The protocol provides an objective framework for assessing AI-generated microfiction, validated by expert and enthusiast feedback.", "conclusion": "GrAImes offers a foundational tool for evaluating the literary value of AI-generated microfictions."}}
{"id": "2306.08730", "pdf": "https://arxiv.org/pdf/2306.08730", "abs": "https://arxiv.org/abs/2306.08730", "authors": ["Chenghong Bian", "Yulin Shao", "Deniz Gunduz"], "title": "Over-the-Air Learning-based Geometry Point Cloud Transmission", "categories": ["eess.SP", "cs.MM"], "comment": "17 pages, accepted to IEEE JSAC SI on Intelligent Communications for\n  Real-Time Computer Vision (Comm4CV)", "summary": "This paper presents novel solutions for the efficient and reliable\ntransmission of point clouds over wireless channels for real-time applications.\nWe first propose SEmatic Point cloud Transmission (SEPT) for small-scale point\nclouds, which encodes the point cloud via an iterative downsampling and feature\nextraction process. At the receiver, SEPT decoder reconstructs the point cloud\nwith latent reconstruction and offset-based upsampling. A novel\nchannel-adaptive module is proposed to allow SEPT to operate effectively over a\nwide range of channel conditions. Next, we propose OTA-NeRF, a scheme inspired\nby neural radiance fields. OTA-NeRF performs voxelization to the point cloud\ninput and learns to encode the voxelized point cloud into a neural network.\nInstead of transmitting the extracted feature vectors as in SEPT, it transmits\nthe learned neural network weights in an analog fashion along with few\nhyperparameters that are transmitted digitally. At the receiver, the OTA-NeRF\ndecoder reconstructs the original point cloud using the received noisy neural\nnetwork weights. To further increase the bandwidth efficiency of the OTA-NeRF\nscheme, a fine-tuning algorithm is developed, where only a fraction of the\nneural network weights are retrained and transmitted. Noticing the poor\ngenerality of the OTA-NeRF schemes, we propose an alternative approach, termed\nOTA-MetaNeRF, which encodes different input point clouds into the latent\nvectors with shared neural network weights. Extensive numerical experiments\nconfirm that the proposed SEPT, OTA-NeRF and OTA-MetaNeRF schemes achieve\nsuperior or comparable performance over the conventional approaches, where an\noctree-based or a learning-based point cloud compression scheme is concatenated\nwith a channel code. Finally, the run-time complexities are evaluated to verify\nthe capability of the proposed schemes for real-time communications.", "AI": {"tldr": "The paper introduces SEPT, OTA-NeRF, and OTA-MetaNeRF for efficient wireless transmission of point clouds, outperforming conventional methods in performance and real-time capability.", "motivation": "To address the challenge of efficient and reliable point cloud transmission over wireless channels for real-time applications.", "method": "SEPT uses iterative downsampling and feature extraction, while OTA-NeRF and OTA-MetaNeRF leverage neural networks for encoding and analog transmission.", "result": "The proposed schemes achieve superior or comparable performance to conventional methods, with verified real-time capability.", "conclusion": "The novel schemes offer effective solutions for real-time point cloud transmission, balancing efficiency and reliability."}}
{"id": "2506.08564", "pdf": "https://arxiv.org/pdf/2506.08564", "abs": "https://arxiv.org/abs/2506.08564", "authors": ["Tuukka T\u00f6r\u00f6", "Antti Suni", "Juraj \u0160imko"], "title": "Neighbors and relatives: How do speech embeddings reflect linguistic connections across the world?", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "27 pages, 11 figures (+5 supplementary), submitted to PLOS One", "summary": "Investigating linguistic relationships on a global scale requires analyzing\ndiverse features such as syntax, phonology and prosody, which evolve at varying\nrates influenced by internal diversification, language contact, and\nsociolinguistic factors. Recent advances in machine learning (ML) offer\ncomplementary alternatives to traditional historical and typological\napproaches. Instead of relying on expert labor in analyzing specific linguistic\nfeatures, these new methods enable the exploration of linguistic variation\nthrough embeddings derived directly from speech, opening new avenues for\nlarge-scale, data-driven analyses.\n  This study employs embeddings from the fine-tuned XLS-R self-supervised\nlanguage identification model voxlingua107-xls-r-300m-wav2vec, to analyze\nrelationships between 106 world languages based on speech recordings. Using\nlinear discriminant analysis (LDA), language embeddings are clustered and\ncompared with genealogical, lexical, and geographical distances. The results\ndemonstrate that embedding-based distances align closely with traditional\nmeasures, effectively capturing both global and local typological patterns.\nChallenges in visualizing relationships, particularly with hierarchical\nclustering and network-based methods, highlight the dynamic nature of language\nchange.\n  The findings show potential for scalable analyses of language variation based\non speech embeddings, providing new perspectives on relationships among\nlanguages. By addressing methodological considerations such as corpus size and\nlatent space dimensionality, this approach opens avenues for studying\nlow-resource languages and bridging macro- and micro-level linguistic\nvariation. Future work aims to extend these methods to underrepresented\nlanguages and integrate sociolinguistic variation for a more comprehensive\nunderstanding of linguistic diversity.", "AI": {"tldr": "The study uses ML-derived speech embeddings to analyze relationships among 106 languages, showing alignment with traditional measures and highlighting scalability for low-resource languages.", "motivation": "To explore linguistic relationships globally using data-driven methods, overcoming limitations of traditional approaches.", "method": "Employs embeddings from XLS-R model and LDA to cluster languages, comparing results with genealogical, lexical, and geographical distances.", "result": "Embedding-based distances align with traditional measures, capturing typological patterns but revealing visualization challenges.", "conclusion": "The approach offers scalable analysis of language variation, with potential for studying low-resource languages and integrating sociolinguistic factors."}}
{"id": "2506.08677", "pdf": "https://arxiv.org/pdf/2506.08677", "abs": "https://arxiv.org/abs/2506.08677", "authors": ["Milica \u0160kipina", "Nikola Jovi\u0161i\u0107", "Nicola Dall'Asen", "Vanja \u0160venda", "Anil Osman Tur", "Slobodan Ili\u0107", "Elisa Ricci", "Dubravko \u0106ulibrk"], "title": "MAMBO: High-Resolution Generative Approach for Mammography Images", "categories": ["eess.IV", "cs.CV"], "comment": "21 pages, 14 figures, 7 tables", "summary": "Mammography is the gold standard for the detection and diagnosis of breast\ncancer. This procedure can be significantly enhanced with Artificial\nIntelligence (AI)-based software, which assists radiologists in identifying\nabnormalities. However, training AI systems requires large and diverse\ndatasets, which are often difficult to obtain due to privacy and ethical\nconstraints. To address this issue, the paper introduces MAMmography ensemBle\nmOdel (MAMBO), a novel patch-based diffusion approach designed to generate\nfull-resolution mammograms. Diffusion models have shown breakthrough results in\nrealistic image generation, yet few studies have focused on mammograms, and\nnone have successfully generated high-resolution outputs required to capture\nfine-grained features of small lesions. To achieve this, MAMBO integrates\nseparate diffusion models to capture both local and global (image-level)\ncontexts. The contextual information is then fed into the final patch-based\nmodel, significantly aiding the noise removal process. This thoughtful design\nenables MAMBO to generate highly realistic mammograms of up to 3840x3840\npixels. Importantly, this approach can be used to enhance the training of\nclassification models and extended to anomaly detection. Experiments, both\nnumerical and radiologist validation, assess MAMBO's capabilities in image\ngeneration, super-resolution, and anomaly detection, highlighting its potential\nto enhance mammography analysis for more accurate diagnoses and earlier lesion\ndetection.", "AI": {"tldr": "The paper introduces MAMBO, a patch-based diffusion model for generating high-resolution mammograms to address data scarcity in AI training, enhancing breast cancer detection.", "motivation": "The need for large, diverse datasets for AI in mammography is hindered by privacy and ethical constraints, prompting the development of MAMBO.", "method": "MAMBO uses separate diffusion models for local and global contexts, integrating them into a patch-based model to generate realistic 3840x3840 pixel mammograms.", "result": "MAMBO successfully generates high-resolution mammograms, aiding in noise removal and improving training for classification and anomaly detection models.", "conclusion": "MAMBO demonstrates potential to enhance mammography analysis, enabling more accurate diagnoses and earlier lesion detection through realistic image generation."}}
{"id": "2506.08185", "pdf": "https://arxiv.org/pdf/2506.08185", "abs": "https://arxiv.org/abs/2506.08185", "authors": ["Huixin Zhan", "Jason H. Moore"], "title": "Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion Models in a Vision-Language-Action Framework", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Surgeons exhibit distinct operating styles due to differences in training,\nexperience, and motor behavior - yet current AI systems often ignore this\npersonalization signal. We propose a novel approach to model fine-grained,\nsurgeon-specific fingerprinting in robotic surgery using a discrete diffusion\nframework integrated with a vision-language-action (VLA) pipeline. Our method\nformulates gesture prediction as a structured sequence denoising task,\nconditioned on multimodal inputs including endoscopic video, surgical intent\nlanguage, and a privacy-aware embedding of surgeon identity and skill.\nPersonalized surgeon fingerprinting is encoded through natural language prompts\nusing third-party language models, allowing the model to retain individual\nbehavioral style without exposing explicit identity. We evaluate our method on\nthe JIGSAWS dataset and demonstrate that it accurately reconstructs gesture\nsequences while learning meaningful motion fingerprints unique to each surgeon.\nTo quantify the privacy implications of personalization, we perform membership\ninference attacks and find that more expressive embeddings improve task\nperformance but simultaneously increase susceptibility to identity leakage.\nThese findings demonstrate that while personalized embeddings improve\nperformance, they also increase vulnerability to identity leakage, revealing\nthe importance of balancing personalization with privacy risk in surgical\nmodeling. Code is available at:\nhttps://github.com/huixin-zhan-ai/Surgeon_style_fingerprinting.", "AI": {"tldr": "The paper proposes a method to model surgeon-specific styles in robotic surgery using a discrete diffusion framework with a vision-language-action pipeline, balancing personalization and privacy risks.", "motivation": "Current AI systems ignore surgeon personalization signals, which vary due to training, experience, and motor behavior.", "method": "Uses a discrete diffusion framework with multimodal inputs (video, surgical intent language, and privacy-aware embeddings) to predict gestures and encode surgeon fingerprints via language prompts.", "result": "Accurately reconstructs gesture sequences and learns unique surgeon motion fingerprints, but expressive embeddings increase identity leakage risk.", "conclusion": "Personalized embeddings improve performance but raise privacy concerns, highlighting the need to balance personalization with privacy in surgical AI."}}
{"id": "2506.08306", "pdf": "https://arxiv.org/pdf/2506.08306", "abs": "https://arxiv.org/abs/2506.08306", "authors": ["Tuan Truong", "Rithwik Sudharsan", "Yibo Yang", "Peter Xiangyuan Ma", "Ruihan Yang", "Stephan Mandt", "Joshua S. Bloom"], "title": "AstroCompress: A benchmark dataset for multi-purpose compression of astronomical data", "categories": ["cs.AI", "astro-ph.IM"], "comment": "ICLR 2025 conference paper. See reviews at\n  https://openreview.net/forum?id=kQCHCkNk7s", "summary": "The site conditions that make astronomical observatories in space and on the\nground so desirable -- cold and dark -- demand a physical remoteness that leads\nto limited data transmission capabilities. Such transmission limitations\ndirectly bottleneck the amount of data acquired and in an era of costly modern\nobservatories, any improvements in lossless data compression has the potential\nscale to billions of dollars worth of additional science that can be\naccomplished on the same instrument. Traditional lossless methods for\ncompressing astrophysical data are manually designed. Neural data compression,\non the other hand, holds the promise of learning compression algorithms\nend-to-end from data and outperforming classical techniques by leveraging the\nunique spatial, temporal, and wavelength structures of astronomical images.\nThis paper introduces AstroCompress: a neural compression challenge for\nastrophysics data, featuring four new datasets (and one legacy dataset) with\n16-bit unsigned integer imaging data in various modes: space-based,\nground-based, multi-wavelength, and time-series imaging. We provide code to\neasily access the data and benchmark seven lossless compression methods (three\nneural and four non-neural, including all practical state-of-the-art\nalgorithms). Our results on lossless compression indicate that lossless neural\ncompression techniques can enhance data collection at observatories, and\nprovide guidance on the adoption of neural compression in scientific\napplications. Though the scope of this paper is restricted to lossless\ncompression, we also comment on the potential exploration of lossy compression\nmethods in future studies.", "AI": {"tldr": "AstroCompress introduces neural lossless compression for astrophysics data, outperforming traditional methods and enhancing observatory data collection.", "motivation": "Remote observatories face data transmission bottlenecks; improved compression can unlock billions in additional science.", "method": "AstroCompress benchmarks seven methods (three neural, four non-neural) on diverse astrophysics datasets.", "result": "Neural compression outperforms classical techniques, improving data collection efficiency.", "conclusion": "Neural compression shows promise for observatories, with potential for future lossy methods."}}
{"id": "2506.08027", "pdf": "https://arxiv.org/pdf/2506.08027", "abs": "https://arxiv.org/abs/2506.08027", "authors": ["Asit Mishra", "Dusan Stosic", "Simon Layton"], "title": "Recipes for Pre-training LLMs with MXFP8", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Precision scaling - using fewer bits to represent model parameters and\nrelated tensors during pre-training - has emerged as a compelling technique for\nimproving GPU efficiency without sacrificing accuracy. Microscaling (MX)\nformats in NVIDIA's latest Blackwell GPUs represent a major leap in enabling\nthis precision scaling aspect. These formats combine narrow floating-point data\ntypes with per-block scaling factors, offering a fine-grained approach to\nquantizing tensors.\n  Although MX-formats offer the promise of improved numeric stability compared\nto other reduced-precision representations, in practice they must be used\ncarefully in order to successfully converge an LLM on a multi-trillion token\ndataset. In this paper, we show that the rounding mode suggested in OCP\nspecification can lead to divergence when pre-training an LLM. We show an\nimproved rounding mode, which uses round-to-infinity to compute scaling\nfactors, enables successful pre-training in MXFP8 for an 8B model on 15T\ntokens.", "AI": {"tldr": "Precision scaling with MX-formats improves GPU efficiency but requires careful rounding mode selection for LLM pre-training.", "motivation": "To address the challenge of numeric stability in reduced-precision representations like MX-formats during LLM pre-training.", "method": "Proposes an improved rounding mode (round-to-infinity) for computing scaling factors in MXFP8.", "result": "Successfully pre-trains an 8B model on 15T tokens using MXFP8 with the new rounding mode.", "conclusion": "Careful selection of rounding modes is crucial for stable LLM pre-training in reduced-precision formats."}}
{"id": "2503.00493", "pdf": "https://arxiv.org/pdf/2503.00493", "abs": "https://arxiv.org/abs/2503.00493", "authors": ["Boyi Kang", "Xinfa Zhu", "Zihan Zhang", "Zhen Ye", "Mingshuai Liu", "Ziqian Wang", "Yike Zhu", "Guobin Ma", "Jun Chen", "Longshuai Xiao", "Chao Weng", "Wei Xue", "Lei Xie"], "title": "LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "comment": "ACL2025 main, Codes available at\n  https://github.com/Kevin-naticl/LLaSE-G1", "summary": "Recent advancements in language models (LMs) have demonstrated strong\ncapabilities in semantic understanding and contextual modeling, which have\nflourished in generative speech enhancement (SE). However, many LM-based SE\napproaches primarily focus on semantic information, often neglecting the\ncritical role of acoustic information, which leads to acoustic inconsistency\nafter enhancement and limited generalization across diverse SE tasks. In this\npaper, we introduce LLaSE-G1, a LLaMA-based language model that incentivizes\ngeneralization capabilities for speech enhancement. LLaSE-G1 offers the\nfollowing key contributions: First, to mitigate acoustic inconsistency,\nLLaSE-G1 employs continuous representations from WavLM as input and predicts\nspeech tokens from X-Codec2, maximizing acoustic preservation. Second, to\npromote generalization capability, LLaSE-G1 introduces dual-channel inputs and\noutputs, unifying multiple SE tasks without requiring task-specific IDs. Third,\nLLaSE-G1 outperforms prior task-specific discriminative and generative SE\nmodels, demonstrating scaling effects at test time and emerging capabilities\nfor unseen SE tasks. Additionally, we release our code and models to support\nfurther research in this area.", "AI": {"tldr": "LLaSE-G1 is a LLaMA-based language model for speech enhancement, addressing acoustic inconsistency and improving generalization by using WavLM and X-Codec2, and outperforming prior models.", "motivation": "Existing LM-based SE approaches neglect acoustic information, causing inconsistency and limited generalization.", "method": "LLaSE-G1 uses continuous WavLM representations and X-Codec2 tokens, with dual-channel inputs/outputs for task unification.", "result": "Outperforms prior discriminative and generative SE models, showing scaling effects and capabilities for unseen tasks.", "conclusion": "LLaSE-G1 advances SE by balancing semantic and acoustic information, with released code/models for further research."}}
{"id": "2410.15876", "pdf": "https://arxiv.org/pdf/2410.15876", "abs": "https://arxiv.org/abs/2410.15876", "authors": ["Woosung Koh", "Wonbeen Oh", "Siyeol Kim", "Suhin Shin", "Hyeongjin Kim", "Jaein Jang", "Junghyun Lee", "Se-Young Yun"], "title": "FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "ICLR 2025", "summary": "Multi-agent reinforcement learning has demonstrated significant potential in\naddressing complex cooperative tasks across various real-world applications.\nHowever, existing MARL approaches often rely on the restrictive assumption that\nthe number of entities (e.g., agents, obstacles) remains constant between\ntraining and inference. This overlooks scenarios where entities are dynamically\nremoved or added during the inference trajectory -- a common occurrence in\nreal-world environments like search and rescue missions and dynamic combat\nsituations. In this paper, we tackle the challenge of intra-trajectory dynamic\nentity composition under zero-shot out-of-domain (OOD) generalization, where\nsuch dynamic changes cannot be anticipated beforehand. Our empirical studies\nreveal that existing MARL methods suffer significant performance degradation\nand increased uncertainty in these scenarios. In response, we propose\nFlickerFusion, a novel OOD generalization method that acts as a universally\napplicable augmentation technique for MARL backbone methods. FlickerFusion\nstochastically drops out parts of the observation space, emulating being\nin-domain when inferenced OOD. The results show that FlickerFusion not only\nachieves superior inference rewards but also uniquely reduces uncertainty\nvis-\\`a-vis the backbone, compared to existing methods. Benchmarks,\nimplementations, and model weights are organized and open-sourced at\nflickerfusion305.github.io, accompanied by ample demo video renderings.", "AI": {"tldr": "FlickerFusion is a novel OOD generalization method for MARL that handles dynamic entity changes by stochastically dropping parts of observations, improving performance and reducing uncertainty.", "motivation": "Existing MARL methods fail in dynamic environments where entity counts change unpredictably, limiting real-world applicability.", "method": "Proposes FlickerFusion, an augmentation technique that randomly drops observation parts to simulate OOD conditions during training.", "result": "FlickerFusion outperforms existing methods in rewards and reduces uncertainty, validated through benchmarks.", "conclusion": "FlickerFusion enhances MARL robustness for dynamic environments, with open-sourced resources for reproducibility."}}
{"id": "2506.08174", "pdf": "https://arxiv.org/pdf/2506.08174", "abs": "https://arxiv.org/abs/2506.08174", "authors": ["Li Weigang", "Pedro Carvalho Brom"], "title": "LLM-BT: Back-Translation as a Framework for Terminology Standardization and Dynamic Semantic Embedding", "categories": ["cs.CL"], "comment": "23 pages", "summary": "The rapid growth of English technical terms challenges traditional\nexpert-driven standardization, especially in fast-evolving fields like AI and\nquantum computing. Manual methods struggle to ensure multilingual consistency.\nWe propose \\textbf{LLM-BT}, a back-translation framework powered by large\nlanguage models (LLMs) to automate terminology verification and standardization\nvia cross-lingual semantic alignment. Our contributions are: \\textbf{(1)\nTerm-Level Consistency Validation:} Using English $\\rightarrow$ intermediate\nlanguage $\\rightarrow$ English back-translation, LLM-BT achieves high term\nconsistency across models (e.g., GPT-4, DeepSeek, Grok), with case studies\nshowing over 90\\% exact or semantic matches. \\textbf{(2) Multi-Path\nVerification Workflow:} A novel ``Retrieve--Generate--Verify--Optimize''\npipeline integrates serial (e.g., EN $\\rightarrow$ ZHcn $\\rightarrow$ ZHtw\n$\\rightarrow$ EN) and parallel (e.g., EN $\\rightarrow$ Chinese/Portuguese\n$\\rightarrow$ EN) BT routes. BLEU and term accuracy indicate strong\ncross-lingual robustness (BLEU $>$ 0.45; Portuguese accuracy 100\\%).\n\\textbf{(3) Back-Translation as Semantic Embedding:} BT is conceptualized as\ndynamic semantic embedding, revealing latent meaning trajectories. Unlike\nstatic embeddings, LLM-BT provides transparent path-based embeddings shaped by\nmodel evolution. LLM-BT transforms back-translation into an active engine for\nmultilingual terminology standardization, enabling human--AI collaboration:\nmachines ensure semantic fidelity, humans guide cultural interpretation. This\ninfrastructure supports terminology governance across scientific and\ntechnological fields worldwide.", "AI": {"tldr": "LLM-BT is a back-translation framework using LLMs to automate multilingual technical term standardization, ensuring high consistency and semantic alignment across languages.", "motivation": "Traditional expert-driven standardization struggles with the rapid growth of technical terms, especially in fast-evolving fields like AI and quantum computing. Manual methods fail to ensure multilingual consistency.", "method": "LLM-BT employs a back-translation framework with term-level consistency validation, a multi-path verification workflow, and conceptualizes back-translation as dynamic semantic embedding.", "result": "Achieves over 90% exact or semantic matches in term consistency, strong cross-lingual robustness (BLEU > 0.45; Portuguese accuracy 100%), and provides transparent path-based embeddings.", "conclusion": "LLM-BT transforms back-translation into an active engine for multilingual terminology standardization, enabling human-AI collaboration for semantic fidelity and cultural interpretation."}}
{"id": "2309.14704", "pdf": "https://arxiv.org/pdf/2309.14704", "abs": "https://arxiv.org/abs/2309.14704", "authors": ["Zhihao Zhang", "Yiwei Chen", "Weizhan Zhang", "Caixia Yan", "Qinghua Zheng", "Qi Wang", "Wangdu Chen"], "title": "Tile Classification Based Viewport Prediction with Multi-modal Fusion Transformer", "categories": ["cs.CV", "cs.MM"], "comment": "This paper is accepted by ACM-MM 2023", "summary": "Viewport prediction is a crucial aspect of tile-based 360 video streaming\nsystem. However, existing trajectory based methods lack of robustness, also\noversimplify the process of information construction and fusion between\ndifferent modality inputs, leading to the error accumulation problem. In this\npaper, we propose a tile classification based viewport prediction method with\nMulti-modal Fusion Transformer, namely MFTR. Specifically, MFTR utilizes\ntransformer-based networks to extract the long-range dependencies within each\nmodality, then mine intra- and inter-modality relations to capture the combined\nimpact of user historical inputs and video contents on future viewport\nselection. In addition, MFTR categorizes future tiles into two categories: user\ninterested or not, and selects future viewport as the region that contains most\nuser interested tiles. Comparing with predicting head trajectories, choosing\nfuture viewport based on tile's binary classification results exhibits better\nrobustness and interpretability. To evaluate our proposed MFTR, we conduct\nextensive experiments on two widely used PVS-HM and Xu-Gaze dataset. MFTR shows\nsuperior performance over state-of-the-art methods in terms of average\nprediction accuracy and overlap ratio, also presents competitive computation\nefficiency.", "AI": {"tldr": "Proposes MFTR, a tile classification-based viewport prediction method using Multi-modal Fusion Transformer for robust and interpretable 360 video streaming.", "motivation": "Existing trajectory-based methods lack robustness and oversimplify multi-modal input fusion, causing error accumulation.", "method": "MFTR uses transformer networks to extract long-range dependencies, mine intra- and inter-modality relations, and classify tiles into user-interested or not.", "result": "MFTR outperforms state-of-the-art methods in accuracy and overlap ratio, with competitive efficiency.", "conclusion": "MFTR offers a robust, interpretable solution for viewport prediction in 360 video streaming."}}
{"id": "2506.08911", "pdf": "https://arxiv.org/pdf/2506.08911", "abs": "https://arxiv.org/abs/2506.08911", "authors": ["Petar Jaku\u0161", "Hrvoje D\u017eapo"], "title": "Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU", "categories": ["cs.HC", "cs.LG", "cs.SD", "eess.AS"], "comment": "4 pages", "summary": "This paper presents a keyword spotting (KWS) system implemented on the NXP\nMCXN947 microcontroller with an integrated Neural Processing Unit (NPU),\nenabling real-time voice interaction on resource-constrained devices. The\nsystem combines MFCC feature extraction with a CNN classifier, optimized using\nQuantization Aware Training to reduce model size with minimal accuracy drop.\nExperimental results demonstrate a 59x speedup in inference time when\nleveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy\nwith a model size of 30.58 KB, demonstrating the feasibility of efficient,\nlow-power voice interfaces on embedded platforms.", "AI": {"tldr": "A KWS system on NXP MCXN947 with NPU achieves real-time voice interaction using MFCC and CNN, optimized via Quantization Aware Training, yielding 97.06% accuracy and 59x speedup.", "motivation": "Enable efficient, low-power voice interfaces on resource-constrained embedded devices.", "method": "Combines MFCC feature extraction with a CNN classifier, optimized using Quantization Aware Training.", "result": "59x speedup in inference time with NPU, 97.06% accuracy, and 30.58 KB model size.", "conclusion": "Demonstrates feasibility of efficient, low-power voice interfaces on embedded platforms."}}
{"id": "2506.08716", "pdf": "https://arxiv.org/pdf/2506.08716", "abs": "https://arxiv.org/abs/2506.08716", "authors": ["Maximilian Tschuchnig", "Lukas Lamminger", "Philipp Steininger", "Michael Gadermayr"], "title": "Enhancing Synthetic CT from CBCT via Multimodal Fusion: A Study on the Impact of CBCT Quality and Alignment", "categories": ["eess.IV", "cs.CV"], "comment": "Data is open source. Code will be provided on acceptance. Paper\n  currently under review", "summary": "Cone-Beam Computed Tomography (CBCT) is widely used for real-time\nintraoperative imaging due to its low radiation dose and high acquisition\nspeed. However, despite its high resolution, CBCT suffers from significant\nartifacts and thereby lower visual quality, compared to conventional Computed\nTomography (CT). A recent approach to mitigate these artifacts is synthetic CT\n(sCT) generation, translating CBCT volumes into the CT domain. In this work, we\nenhance sCT generation through multimodal learning, integrating intraoperative\nCBCT with preoperative CT. Beyond validation on two real-world datasets, we use\na versatile synthetic dataset, to analyze how CBCT-CT alignment and CBCT\nquality affect sCT quality. The results demonstrate that multimodal sCT\nconsistently outperform unimodal baselines, with the most significant gains\nobserved in well-aligned, low-quality CBCT-CT cases. Finally, we demonstrate\nthat these findings are highly reproducible in real-world clinical datasets.", "AI": {"tldr": "The paper proposes enhancing synthetic CT (sCT) generation from CBCT by integrating preoperative CT via multimodal learning, showing improved results, especially for low-quality CBCT-CT cases.", "motivation": "CBCT has high resolution but suffers from artifacts, leading to lower visual quality compared to conventional CT. Synthetic CT generation aims to mitigate these artifacts.", "method": "Multimodal learning is used to integrate intraoperative CBCT with preoperative CT for sCT generation. Validation includes real-world and synthetic datasets.", "result": "Multimodal sCT outperforms unimodal baselines, with significant gains in well-aligned, low-quality CBCT-CT cases. Findings are reproducible in clinical datasets.", "conclusion": "Multimodal learning effectively enhances sCT generation, particularly improving quality in challenging CBCT-CT scenarios."}}
{"id": "2506.08189", "pdf": "https://arxiv.org/pdf/2506.08189", "abs": "https://arxiv.org/abs/2506.08189", "authors": ["Amartya Dutta", "Kazi Sajeed Mehrab", "Medha Sawhney", "Abhilash Neog", "Mridul Khurana", "Sepideh Fatemi", "Aanish Pradhan", "M. Maruf", "Ismini Lourentzou", "Arka Daw", "Anuj Karpatne"], "title": "Open World Scene Graph Generation using Vision Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted in CVPR 2025 Workshop (CVinW)", "summary": "Scene-Graph Generation (SGG) seeks to recognize objects in an image and\ndistill their salient pairwise relationships. Most methods depend on\ndataset-specific supervision to learn the variety of interactions, restricting\ntheir usefulness in open-world settings, involving novel objects and/or\nrelations. Even methods that leverage large Vision Language Models (VLMs)\ntypically require benchmark-specific fine-tuning. We introduce Open-World SGG,\na training-free, efficient, model-agnostic framework that taps directly into\nthe pretrained knowledge of VLMs to produce scene graphs with zero additional\nlearning. Casting SGG as a zero-shot structured-reasoning problem, our method\ncombines multimodal prompting, embedding alignment, and a lightweight\npair-refinement strategy, enabling inference over unseen object vocabularies\nand relation sets. To assess this setting, we formalize an Open-World\nevaluation protocol that measures performance when no SGG-specific data have\nbeen observed either in terms of objects and relations. Experiments on Visual\nGenome, Open Images V6, and the Panoptic Scene Graph (PSG) dataset demonstrate\nthe capacity of pretrained VLMs to perform relational understanding without\ntask-level training.", "AI": {"tldr": "Open-World SGG is a training-free framework leveraging VLMs for zero-shot scene-graph generation, enabling inference on unseen objects and relations without dataset-specific fine-tuning.", "motivation": "Current SGG methods rely on dataset-specific supervision or fine-tuning, limiting their applicability in open-world settings with novel objects/relations.", "method": "The framework uses multimodal prompting, embedding alignment, and pair-refinement for zero-shot structured reasoning.", "result": "Experiments on Visual Genome, Open Images V6, and PSG show VLMs can perform relational understanding without task-level training.", "conclusion": "Open-World SGG demonstrates the potential of pretrained VLMs for zero-shot relational understanding, broadening SGG applicability."}}
{"id": "2506.08321", "pdf": "https://arxiv.org/pdf/2506.08321", "abs": "https://arxiv.org/abs/2506.08321", "authors": ["Manooshree Patel", "Rayna Bhattacharyya", "Thomas Lu", "Arnav Mehta", "Niels Voss", "Narges Norouzi", "Gireeja Ranade"], "title": "LeanTutor: A Formally-Verified AI Tutor for Mathematical Proofs", "categories": ["cs.AI", "cs.HC", "cs.LO"], "comment": null, "summary": "We present LeanTutor, a Large Language Model (LLM)-based tutoring system for\nmath proofs. LeanTutor interacts with the student in natural language, formally\nverifies student-written math proofs in Lean, generates correct next steps, and\nprovides the appropriate instructional guidance. LeanTutor is composed of three\nmodules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and\n(iii) a natural language feedback generator. The first module faithfully\nautoformalizes student proofs into Lean and verifies proof accuracy via\nsuccessful code compilation. If the proof has an error, the incorrect step is\nidentified. The next-step generator module outputs a valid next Lean tactic for\nincorrect proofs via LLM-based candidate generation and proof search. The\nfeedback generator module leverages Lean data to produce a\npedagogically-motivated natural language hint for the student user. To evaluate\nour system, we introduce PeanoBench, a human-written dataset derived from the\nNatural Numbers Game, consisting of 371 Peano Arithmetic proofs, where each\nnatural language proof step is paired with the corresponding logically\nequivalent tactic in Lean. The Autoformalizer correctly formalizes 57% of\ntactics in correct proofs and accurately identifies the incorrect step in 30%\nof incorrect proofs. In generating natural language hints for erroneous proofs,\nLeanTutor outperforms a simple baseline on accuracy and relevance metrics.", "AI": {"tldr": "LeanTutor is an LLM-based tutoring system for math proofs, featuring autoformalization, next-step generation, and natural language feedback. It was evaluated using PeanoBench, showing promising results in formalization and error identification.", "motivation": "To enhance math proof tutoring by leveraging LLMs for formal verification, step generation, and pedagogically sound feedback.", "method": "LeanTutor uses three modules: autoformalizer/proof-checker, next-step generator, and feedback generator, evaluated on the PeanoBench dataset.", "result": "Autoformalizer achieved 57% accuracy in correct proofs and 30% in error identification. LeanTutor outperformed baselines in hint generation.", "conclusion": "LeanTutor demonstrates effective LLM-based tutoring for math proofs, with room for improvement in formalization and error detection."}}
{"id": "2506.08051", "pdf": "https://arxiv.org/pdf/2506.08051", "abs": "https://arxiv.org/abs/2506.08051", "authors": ["Mahmuda Sultana Mimi", "Md Monzurul Islam", "Anannya Ghosh Tusti", "Shriyank Somvanshi", "Subasish Das"], "title": "ST-GraphNet: A Spatio-Temporal Graph Neural Network for Understanding and Predicting Automated Vehicle Crash Severity", "categories": ["cs.LG"], "comment": null, "summary": "Understanding the spatial and temporal dynamics of automated vehicle (AV)\ncrash severity is critical for advancing urban mobility safety and\ninfrastructure planning. In this work, we introduce ST-GraphNet, a\nspatio-temporal graph neural network framework designed to model and predict AV\ncrash severity by using both fine-grained and region-aggregated spatial graphs.\nUsing a balanced dataset of 2,352 real-world AV-related crash reports from\nTexas (2024), including geospatial coordinates, crash timestamps, SAE\nautomation levels, and narrative descriptions, we construct two complementary\ngraph representations: (1) a fine-grained graph with individual crash events as\nnodes, where edges are defined via spatio-temporal proximity; and (2) a\ncoarse-grained graph where crashes are aggregated into Hexagonal Hierarchical\nSpatial Indexing (H3)-based spatial cells, connected through hexagonal\nadjacency. Each node in the graph is enriched with multimodal data, including\nsemantic, spatial, and temporal attributes, including textual embeddings from\ncrash narratives using a pretrained Sentence-BERT model. We evaluate various\ngraph neural network (GNN) architectures, such as Graph Convolutional Networks\n(GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN\n(DSTGCN), to classify crash severity and predict high-risk regions. Our\nproposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3\ngraph, achieves a test accuracy of 97.74\\%, substantially outperforming the\nbest fine-grained model (64.7\\% test accuracy). These findings highlight the\neffectiveness of spatial aggregation, dynamic message passing, and multi-modal\nfeature integration in capturing the complex spatio-temporal patterns\nunderlying AV crash severity.", "AI": {"tldr": "ST-GraphNet, a spatio-temporal graph neural network, predicts AV crash severity with high accuracy using multimodal data and spatial aggregation.", "motivation": "Understanding AV crash severity dynamics is crucial for urban safety and infrastructure planning.", "method": "ST-GraphNet uses fine-grained and coarse-grained spatial graphs with multimodal data, evaluated via GNN architectures like GCN, GAT, and DSTGCN.", "result": "ST-GraphNet achieves 97.74% test accuracy, outperforming fine-grained models (64.7%).", "conclusion": "Spatial aggregation and dynamic message passing effectively capture spatio-temporal patterns in AV crash severity."}}
{"id": "2503.23004", "pdf": "https://arxiv.org/pdf/2503.23004", "abs": "https://arxiv.org/abs/2503.23004", "authors": ["Stefano Damiano", "Kathleen MacWilliam", "Valerio Lorenzoni", "Thomas Dietzen", "Toon van Waterschoot"], "title": "The trajectoRIR Database: Room Acoustic Recordings Along a Trajectory of Moving Microphones", "categories": ["eess.AS"], "comment": "17 pages, 7 figures", "summary": "Data availability is essential to develop acoustic signal processing\nalgorithms, especially when it comes to data-driven approaches that demand\nlarge and diverse training datasets. For this reason, an increasing number of\ndatabases have been published in recent years, including either room impulse\nresponses (RIRs) or recordings of moving audio. In this paper we introduce the\ntrajectoRIR database, an extensive, multi-array collection of both dynamic and\nstationary acoustic recordings along a controlled trajectory in a room.\nSpecifically, the database features recordings using moving microphones and\nstationary RIRs spatially sampling the room acoustics along an L-shaped,\n3.74-meter-long trajectory. This combination makes trajectoRIR unique and\napplicable in various tasks ranging from sound source localization and tracking\nto spatially dynamic sound field reconstruction and system identification. The\nrecording room has a reverberation time of 0.5 seconds, and the three different\nmicrophone configurations employed include a dummy head, with additional\nreference microphones located next to the ears, 3 first-order Ambisonics\nmicrophones, two circular arrays of 16 and 4 channels, and a 12-channel linear\narray. The motion of the microphones was achieved using a robotic cart\ntraversing a rail at three speeds: [0.2,0.4,0.8] m/s. Audio signals were\nreproduced using two stationary loudspeakers. The collected database features\n8648 stationary RIRs, as well as perfect sweeps, speech, music, and stationary\nnoise recorded during motion. MATLAB and Python scripts are included to access\nthe recorded audio as well as to retrieve geometrical information.", "AI": {"tldr": "The paper introduces trajectoRIR, a unique database combining dynamic and stationary acoustic recordings for diverse signal processing tasks.", "motivation": "Data-driven acoustic signal processing requires large, diverse datasets. Existing databases lack combined dynamic and stationary recordings, which trajectoRIR addresses.", "method": "The database includes recordings from moving and stationary microphones along an L-shaped trajectory, using various configurations (dummy head, Ambisonics, circular/linear arrays). Motion was controlled via a robotic cart at three speeds.", "result": "trajectoRIR offers 8648 stationary RIRs and dynamic recordings (sweeps, speech, music, noise), with MATLAB/Python scripts for access.", "conclusion": "trajectoRIR is a versatile database for tasks like sound localization, tracking, and sound field reconstruction, filling a gap in available datasets."}}
{"id": "2506.08184", "pdf": "https://arxiv.org/pdf/2506.08184", "abs": "https://arxiv.org/abs/2506.08184", "authors": ["Chupei Wang", "Jiaqiu Vince Sun"], "title": "Unable to forget: Proactive lnterference Reveals Working Memory Limits in LLMs Beyond Context Length", "categories": ["cs.CL", "cs.AI", "q-bio.NC"], "comment": null, "summary": "Information retrieval in Large Language Models (LLMs) is increasingly\nrecognized as intertwined with generation capabilities rather than mere lookup.\nWhile longer contexts are often assumed to improve retrieval, the effects of\nintra-context interference remain understudied. To address this, we adapt the\nproactive interference (PI) paradigm from cognitive science, where earlier\ninformation disrupts recall of newer updates. In humans, susceptibility to such\ninterference is inversely linked to working memory capacity. We introduce\nPI-LLM, an evaluation that sequentially streams semantically related key-value\nupdates and queries only the final values. Although these final values are\nclearly positioned just before the query, LLM retrieval accuracy declines\nlog-linearly toward zero as interference accumulates; errors arise from\nretrieving previously overwritten values. Attempts to mitigate interference via\nprompt engineering (e.g., instructing models to ignore earlier input) yield\nlimited success. These findings reveal a fundamental constraint on LLMs'\nability to disentangle interference and flexibly manipulate information,\nsuggesting a working memory bottleneck beyond mere context access. This calls\nfor approaches that strengthen models' ability to suppress irrelevant content\nduring retrieval.", "AI": {"tldr": "The paper investigates how interference in long contexts affects LLM retrieval, showing accuracy declines as interference accumulates, and mitigation efforts are limited.", "motivation": "To understand the impact of intra-context interference on LLM retrieval, inspired by cognitive science's proactive interference paradigm.", "method": "Introduces PI-LLM, an evaluation streaming related key-value updates and querying final values to measure interference effects.", "result": "LLM retrieval accuracy declines log-linearly with interference; prompt engineering mitigates poorly.", "conclusion": "LLMs face a working memory bottleneck, needing better methods to suppress irrelevant content during retrieval."}}
{"id": "2410.15461", "pdf": "https://arxiv.org/pdf/2410.15461", "abs": "https://arxiv.org/abs/2410.15461", "authors": ["Xiaowei Chi", "Chun-Kai Fan", "Hengyuan Zhang", "Xingqun Qi", "Rongyu Zhang", "Anthony Chen", "Chi-min Chan", "Wei Xue", "Qifeng Liu", "Shanghang Zhang", "Yike Guo"], "title": "EVA: An Embodied World Model for Future Video Anticipation", "categories": ["cs.CV", "cs.MM", "cs.RO"], "comment": null, "summary": "Video generation models have made significant progress in simulating future\nstates, showcasing their potential as world simulators in embodied scenarios.\nHowever, existing models often lack robust understanding, limiting their\nability to perform multi-step predictions or handle Out-of-Distribution (OOD)\nscenarios. To address this challenge, we propose the Reflection of Generation\n(RoG), a set of intermediate reasoning strategies designed to enhance video\nprediction. It leverages the complementary strengths of pre-trained\nvision-language and video generation models, enabling them to function as a\nworld model in embodied scenarios. To support RoG, we introduce Embodied Video\nAnticipation Benchmark(EVA-Bench), a comprehensive benchmark that evaluates\nembodied world models across diverse tasks and scenarios, utilizing both\nin-domain and OOD datasets. Building on this foundation, we devise a world\nmodel, Embodied Video Anticipator (EVA), that follows a multistage training\nparadigm to generate high-fidelity video frames and apply an autoregressive\nstrategy to enable adaptive generalization for longer video sequences.\nExtensive experiments demonstrate the efficacy of EVA in various downstream\ntasks like video generation and robotics, thereby paving the way for\nlarge-scale pre-trained models in real-world video prediction applications. The\nvideo demos are available at\n\\hyperlink{https://sites.google.com/view/icml-eva}{https://sites.google.com/view/icml-eva}.", "AI": {"tldr": "The paper introduces RoG and EVA-Bench to enhance video prediction in embodied scenarios, proposing the EVA model for high-fidelity video generation and adaptive generalization.", "motivation": "Existing video generation models lack robust understanding for multi-step predictions and OOD scenarios, limiting their use as world simulators.", "method": "Proposes RoG (intermediate reasoning strategies) and EVA-Bench (benchmark), then develops the EVA model with multistage training and autoregressive strategies.", "result": "EVA demonstrates efficacy in video generation and robotics tasks, supporting large-scale pre-trained models for real-world applications.", "conclusion": "The work advances video prediction in embodied scenarios, with potential for broader real-world applications."}}
{"id": "2309.09652", "pdf": "https://arxiv.org/pdf/2309.09652", "abs": "https://arxiv.org/abs/2309.09652", "authors": ["Peter Ochieng"], "title": "Speech Synthesis By Unrolling Diffusion Process using Neural Network Layers", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "10 pages", "summary": "This work introduces UDPNet, a novel architecture designed to accelerate the\nreverse diffusion process in speech synthesis. Unlike traditional diffusion\nmodels that rely on timestep embeddings and shared network parameters, UDPNet\nunrolls the reverse diffusion process directly into the network architecture,\nwith successive layers corresponding to equally spaced steps in the diffusion\nschedule. Each layer progressively refines the noisy input, culminating in a\nhigh-fidelity estimation of the original data, \\(x_0\\). Additionally, we\nredefine the learning target by predicting latent variables instead of the\nconventional \\(x_0\\) or noise \\(\\epsilon_0\\). This shift addresses the common\nissue of large prediction errors in early denoising stages, effectively\nreducing speech distortion. Extensive evaluations on single- and multi-speaker\ndatasets demonstrate that UDPNet consistently outperforms state-of-the-art\nmethods in both quality and efficiency, while generalizing effectively to\nunseen speech. These results position UDPNet as a robust solution for real-time\nspeech synthesis applications. Sample audio is available at\nhttps://onexpeters.github.io/UDPNet/.", "AI": {"tldr": "UDPNet accelerates reverse diffusion in speech synthesis by unrolling the process into its architecture and predicting latent variables, reducing distortion and outperforming existing methods.", "motivation": "Traditional diffusion models face issues like large prediction errors in early denoising stages, leading to speech distortion. UDPNet aims to address these challenges.", "method": "UDPNet unrolls the reverse diffusion process into its architecture, with layers corresponding to diffusion steps, and predicts latent variables instead of conventional targets.", "result": "UDPNet outperforms state-of-the-art methods in quality and efficiency on single- and multi-speaker datasets, generalizing well to unseen speech.", "conclusion": "UDPNet is a robust solution for real-time speech synthesis, offering improved performance and reduced distortion."}}
{"id": "2506.08974", "pdf": "https://arxiv.org/pdf/2506.08974", "abs": "https://arxiv.org/abs/2506.08974", "authors": ["Igor Kvasi\u0107", "Derek Orbaugh Antillon", "\u00d0ula Na\u0111", "Christopher Walker", "Iain Anderson", "Nikola Mi\u0161kovi\u0107"], "title": "Diver-Robot Communication Dataset for Underwater Hand Gesture Recognition", "categories": ["eess.IV"], "comment": "28 pages, 12 figures (Elsevier Computer Networks Journal)", "summary": "In this paper, we present a dataset of diving gesture images used for\nhuman-robot interaction underwater. By offering this open access dataset, the\npaper aims at investigating the potential of using visual detection of diving\ngestures from an autonomous underwater vehicle (AUV) as a form of communication\nwith a human diver. In addition to the image recording, the same dataset was\nrecorded using a smart gesture recognition glove. The glove uses elastomer\nsensors and on-board processing to determine the selected gesture and transmit\nthe command associated with the gesture to the AUV via acoustics. Although this\nmethod can be used under different visibility conditions and even without line\nof sight, it introduces a communication delay required for the acoustic\ntransmission of the gesture command. To compare efficiency, the glove was\nequipped with visual markers proposed in a gesture-based language called\nCADDIAN and recorded with an underwater camera in parallel to the glove's\nonboard recognition process. The dataset contains over 30,000 underwater frames\nof nearly 900 individual gestures annotated in corresponding snippet folders.\nThe dataset was recorded in a balanced ratio with five different divers in sea\nand five different divers in pool conditions, with gestures recorded at 1, 2\nand 3 metres from the camera. The glove gesture recognition statistics are\nreported in terms of average diver reaction time, average time taken to perform\na gesture, recognition success rate, transmission times and more. The dataset\npresented should provide a good baseline for comparing the performance of state\nof the art visual diving gesture recognition techniques under different\nvisibility conditions.", "AI": {"tldr": "A dataset of diving gesture images for human-robot interaction underwater is presented, comparing visual detection with glove-based recognition for efficiency.", "motivation": "To explore visual detection of diving gestures for AUV communication and compare it with glove-based recognition under varying visibility conditions.", "method": "Recorded gestures using an underwater camera and a smart glove with elastomer sensors, annotating over 30,000 frames. Compared visual and glove-based recognition.", "result": "Dataset includes gesture performance metrics like reaction time, recognition success rate, and transmission times.", "conclusion": "The dataset serves as a baseline for evaluating visual gesture recognition techniques in underwater environments."}}
{"id": "2506.08191", "pdf": "https://arxiv.org/pdf/2506.08191", "abs": "https://arxiv.org/abs/2506.08191", "authors": ["Antoni Nowinowski", "Krzysztof Krawiec"], "title": "Generative Learning of Differentiable Object Models for Compositional Interpretation of Complex Scenes", "categories": ["cs.CV"], "comment": null, "summary": "This study builds on the architecture of the Disentangler of Visual Priors\n(DVP), a type of autoencoder that learns to interpret scenes by decomposing the\nperceived objects into independent visual aspects of shape, size, orientation,\nand color appearance. These aspects are expressed as latent parameters which\ncontrol a differentiable renderer that performs image reconstruction, so that\nthe model can be trained end-to-end with gradient using reconstruction loss. In\nthis study, we extend the original DVP so that it can handle multiple objects\nin a scene. We also exploit the interpretability of its latent by using the\ndecoder to sample additional training examples and devising alternative\ntraining modes that rely on loss functions defined not only in the image space,\nbut also in the latent space. This significantly facilitates training, which is\notherwise challenging due to the presence of extensive plateaus in the\nimage-space reconstruction loss. To examine the performance of this approach,\nwe propose a new benchmark featuring multiple 2D objects, which subsumes the\npreviously proposed Multi-dSprites dataset while being more parameterizable. We\ncompare the DVP extended in these ways with two baselines (MONet and LIVE) and\ndemonstrate its superiority in terms of reconstruction quality and capacity to\ndecompose overlapping objects. We also analyze the gradients induced by the\nconsidered loss functions, explain how they impact the efficacy of training,\nand discuss the limitations of differentiable rendering in autoencoders and the\nways in which they can be addressed.", "AI": {"tldr": "Extended DVP autoencoder handles multiple objects, improves training with latent-space losses, and outperforms baselines in reconstruction and decomposition.", "motivation": "To enhance the original DVP by enabling it to process multiple objects in a scene and improve training efficiency using latent-space loss functions.", "method": "Extended DVP architecture with latent-space sampling and alternative training modes, evaluated on a new benchmark with multiple 2D objects.", "result": "Outperforms MONet and LIVE in reconstruction quality and object decomposition, with improved training efficiency.", "conclusion": "The extended DVP shows superior performance but highlights limitations of differentiable rendering in autoencoders, suggesting areas for future work."}}
{"id": "2506.08332", "pdf": "https://arxiv.org/pdf/2506.08332", "abs": "https://arxiv.org/abs/2506.08332", "authors": ["Amur Ghose", "Andrew B. Kahng", "Sayak Kundu", "Zhiang Wang"], "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Machine learning has been widely used to optimize complex engineering\nworkflows across numerous domains. In the context of integrated circuit design,\nmodern flows (e.g., going from a register-transfer level netlist to physical\nlayouts) involve extensive configuration via thousands of parameters, and small\nchanges to these parameters can have large downstream impacts on desired\noutcomes - namely design performance, power, and area. Recent advances in Large\nLanguage Models (LLMs) offer new opportunities for learning and reasoning\nwithin such high-dimensional optimization tasks. In this work, we introduce\nORFS-agent, an LLM-based iterative optimization agent that automates parameter\ntuning in an open-source hardware design flow. ORFS-agent adaptively explores\nparameter configurations, demonstrating clear improvements over standard\nBayesian optimization approaches in terms of resource efficiency and final\ndesign metrics. Our empirical evaluations on two different technology nodes and\na range of circuit benchmarks indicate that ORFS-agent can improve both routed\nwirelength and effective clock period by over 13%, all while using 40% fewer\noptimization iterations. Moreover, by following natural language objectives to\ntrade off certain metrics for others, ORFS-agent demonstrates a flexible and\ninterpretable framework for multi-objective optimization. Crucially, RFS-agent\nis modular and model-agnostic, and can be plugged in to any frontier LLM\nwithout any further fine-tuning.", "AI": {"tldr": "ORFS-agent, an LLM-based iterative optimization agent, improves parameter tuning in hardware design flows, outperforming Bayesian optimization with 13% better design metrics and 40% fewer iterations.", "motivation": "Machine learning can optimize complex engineering workflows, like IC design, where parameter tuning impacts performance, power, and area. LLMs offer new opportunities for high-dimensional optimization.", "method": "ORFS-agent, an LLM-based agent, adaptively explores parameter configurations in hardware design flows, leveraging natural language objectives for multi-objective optimization.", "result": "ORFS-agent improves routed wirelength and clock period by over 13% and uses 40% fewer iterations than Bayesian optimization. It\u2019s flexible, interpretable, and model-agnostic.", "conclusion": "ORFS-agent provides an efficient, modular, and interpretable solution for multi-objective optimization in hardware design, adaptable to any frontier LLM without fine-tuning."}}
{"id": "2506.08054", "pdf": "https://arxiv.org/pdf/2506.08054", "abs": "https://arxiv.org/abs/2506.08054", "authors": ["Yiming Wang", "Hao Peng", "Senzhang Wang", "Haohua Du", "Chunyang Liu", "Jia Wu", "Guanlin Wu"], "title": "STAMImputer: Spatio-Temporal Attention MoE for Traffic Data Imputation", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures, 3 tables. Extended version of paper accepted at\n  IJCAI 2025", "summary": "Traffic data imputation is fundamentally important to support various\napplications in intelligent transportation systems such as traffic flow\nprediction. However, existing time-to-space sequential methods often fail to\neffectively extract features in block-wise missing data scenarios. Meanwhile,\nthe static graph structure for spatial feature propagation significantly\nconstrains the models flexibility in handling the distribution shift issue for\nthe nonstationary traffic data. To address these issues, this paper proposes a\nSpatioTemporal Attention Mixture of experts network named STAMImputer for\ntraffic data imputation. Specifically, we introduce a Mixture of Experts (MoE)\nframework to capture latent spatio-temporal features and their influence\nweights, effectively imputing block missing. A novel Low-rank guided Sampling\nGraph ATtention (LrSGAT) mechanism is designed to dynamically balance the local\nand global correlations across road networks. The sampled attention vectors are\nutilized to generate dynamic graphs that capture real-time spatial\ncorrelations. Extensive experiments are conducted on four traffic datasets for\nevaluation. The result shows STAMImputer achieves significantly performance\nimprovement compared with existing SOTA approaches. Our codes are available at\nhttps://github.com/RingBDStack/STAMImupter.", "AI": {"tldr": "STAMImputer is a SpatioTemporal Attention Mixture of Experts network for traffic data imputation, addressing block-wise missing data and dynamic spatial correlations.", "motivation": "Existing methods fail in block-wise missing data and static graph structures limit flexibility for nonstationary traffic data.", "method": "Uses Mixture of Experts (MoE) for spatio-temporal features and LrSGAT for dynamic graph generation.", "result": "Outperforms SOTA methods on four traffic datasets.", "conclusion": "STAMImputer effectively handles block missing data and dynamic spatial correlations, improving traffic data imputation."}}
{"id": "2403.00790", "pdf": "https://arxiv.org/pdf/2403.00790", "abs": "https://arxiv.org/abs/2403.00790", "authors": ["Tofara Moyo"], "title": "Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Inaccuracies in script", "summary": "In this paper, we explore the intriguing similarities between the structure\nof a discrete neural network, such as a spiking network, and the composition of\na piano piece. While both involve nodes or notes that are activated\nsequentially or in parallel, the latter benefits from the rich body of music\ntheory to guide meaningful combinations. We propose a novel approach that\nleverages musical grammar to regulate activations in a spiking neural network,\nallowing for the representation of symbols as attractors. By applying rules for\nchord progressions from music theory, we demonstrate how certain activations\nnaturally follow others, akin to the concept of attraction. Furthermore, we\nintroduce the concept of modulating keys to navigate different basins of\nattraction within the network. Ultimately, we show that the map of concepts in\nour model is structured by the musical circle of fifths, highlighting the\npotential for leveraging music theory principles in deep learning algorithms.", "AI": {"tldr": "The paper explores parallels between spiking neural networks and piano compositions, proposing musical grammar to regulate network activations and represent symbols as attractors.", "motivation": "To leverage music theory, particularly chord progressions and key modulation, to enhance the structure and dynamics of spiking neural networks.", "method": "Uses musical grammar and chord progression rules to guide activations in spiking networks, introducing key modulation for navigating attraction basins.", "result": "Demonstrates that activations follow patterns akin to musical attraction, with concepts structured by the circle of fifths.", "conclusion": "Music theory principles can effectively structure and enhance deep learning algorithms, particularly in spiking neural networks."}}
{"id": "2506.08221", "pdf": "https://arxiv.org/pdf/2506.08221", "abs": "https://arxiv.org/abs/2506.08221", "authors": ["Samra Zafar", "Shaheer Minhas", "Syed Ali Hassan Zaidi", "Arfa Naeem", "Zahra Ali"], "title": "\"I Wrote, I Paused, I Rewrote\" Teaching LLMs to Read Between the Lines of Student Writing", "categories": ["cs.CL"], "comment": "7 pages, 6 figures, 2 tables", "summary": "Large language models(LLMs) like Gemini are becoming common tools for\nsupporting student writing. But most of their feedback is based only on the\nfinal essay missing important context about how that text was written. In this\npaper, we explore whether using writing process data, collected through\nkeystroke logging and periodic snapshots, can help LLMs give feedback that\nbetter reflects how learners think and revise while writing. We built a digital\nwriting tool that captures both what students type and how their essays evolve\nover time. Twenty students used this tool to write timed essays, which were\nthen evaluated in two ways: (i) LLM generated feedback using both the final\nessay and the full writing trace, and (ii) After the task, students completed\nsurveys about how useful and relatable they found the feedback. Early results\nshow that learners preferred the process-aware LLM feedback, finding it more in\ntune with their own thinking. We also found that certain types of edits, like\nadding new content or reorganizing paragraphs, aligned closely with higher\nscores in areas like coherence and elaboration. Our findings suggest that\nmaking LLMs more aware of the writing process can lead to feedback that feels\nmore meaningful, personal, and supportive.", "AI": {"tldr": "Using writing process data (keystroke logging and snapshots) alongside final essays improves LLM feedback, making it more relatable and useful for students.", "motivation": "Current LLM feedback lacks context from the writing process, missing insights into how students think and revise.", "method": "Built a digital writing tool to capture writing traces; tested with 20 students via LLM feedback (using process data) and surveys.", "result": "Students preferred process-aware feedback, finding it more aligned with their thinking. Certain edits correlated with higher scores.", "conclusion": "Incorporating writing process data into LLM feedback enhances its relevance and supportiveness for learners."}}
{"id": "2505.17114", "pdf": "https://arxiv.org/pdf/2505.17114", "abs": "https://arxiv.org/abs/2505.17114", "authors": ["Subrata Biswas", "Mohammad Nur Hossain Khan", "Bashima Islam"], "title": "RAVEN: Query-Guided Representation Alignment for Question Answering over Audio, Video, Embedded Sensors, and Natural Language", "categories": ["cs.CL", "cs.CV", "cs.LG", "cs.MM"], "comment": null, "summary": "Multimodal question answering (QA) often requires identifying which video,\naudio, or sensor tokens are relevant to the question. Yet modality\ndisagreements are common: off-camera speech, background noise, or motion\noutside the field of view often mislead fusion models that weight all streams\nequally. We present RAVEN, a unified QA architecture whose core is QuART, a\nquery-conditioned cross-modal gating module that assigns scalar relevance\nscores to each token across modalities, enabling the model to amplify\ninformative signals and suppress distractors before fusion. RAVEN is trained\nthrough a three-stage pipeline comprising unimodal pretraining, query-aligned\nfusion, and disagreement-oriented fine-tuning -- each stage targeting a\ndistinct challenge in multi-modal reasoning: representation quality,\ncross-modal relevance, and robustness to modality mismatch. To support training\nand evaluation, we release AVS-QA, a dataset of 300K synchronized\nAudio--Video-Sensor streams paired with automatically generated question-answer\npairs. Experimental results on seven multi-modal QA benchmarks -- including\negocentric and exocentric tasks -- show that RAVEN achieves up to 14.5\\% and\n8.0\\% gains in accuracy compared to state-of-the-art multi-modal large language\nmodels, respectively. Incorporating sensor data provides an additional 16.4\\%\nboost, and the model remains robust under modality corruption, outperforming\nSOTA baselines by 50.23\\%. Our code and dataset are available at\nhttps://github.com/BASHLab/RAVEN.", "AI": {"tldr": "RAVEN introduces QuART, a query-conditioned cross-modal gating module for multimodal QA, improving accuracy and robustness by dynamically weighting tokens across modalities.", "motivation": "Address modality disagreements in multimodal QA, where irrelevant signals (e.g., off-camera speech) mislead models, by dynamically filtering and amplifying relevant tokens.", "method": "RAVEN uses QuART for token relevance scoring, trained via a three-stage pipeline: unimodal pretraining, query-aligned fusion, and disagreement-oriented fine-tuning.", "result": "RAVEN achieves up to 14.5% accuracy gains over SOTA models, with sensor data adding 16.4% improvement. It remains robust under modality corruption, outperforming baselines by 50.23%.", "conclusion": "RAVEN's dynamic token weighting and staged training pipeline effectively address multimodal QA challenges, demonstrating significant performance improvements and robustness."}}
{"id": "2410.10913", "pdf": "https://arxiv.org/pdf/2410.10913", "abs": "https://arxiv.org/abs/2410.10913", "authors": ["Choi Changin", "Lim Sungjun", "Rhee Wonjong"], "title": "Enhancing Retrieval-Augmented Audio Captioning with Generation-Assisted Multimodal Querying and Progressive Learning", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Retrieval-augmented generation can improve audio captioning by incorporating\nrelevant audio-text pairs from a knowledge base. Existing methods typically\nrely solely on the input audio as a unimodal retrieval query. In contrast, we\npropose Generation-Assisted Multimodal Querying, which generates a text\ndescription of the input audio to enable multimodal querying. This approach\naligns the query modality with the audio-text structure of the knowledge base,\nleading to more effective retrieval. Furthermore, we introduce a novel\nprogressive learning strategy that gradually increases the number of\ninterleaved audio-text pairs to enhance the training process. Our experiments\non AudioCaps, Clotho, and Auto-ACD demonstrate that our approach achieves\nstate-of-the-art results across these benchmarks.", "AI": {"tldr": "The paper proposes a multimodal querying method for retrieval-augmented audio captioning, improving retrieval effectiveness by generating text descriptions of input audio. It also introduces a progressive learning strategy for better training.", "motivation": "Existing methods rely on unimodal (audio-only) queries, which may not align well with the audio-text structure of knowledge bases. The goal is to enhance retrieval effectiveness by using multimodal queries.", "method": "Proposes Generation-Assisted Multimodal Querying, where text descriptions of input audio are generated for multimodal retrieval. Also introduces a progressive learning strategy to gradually increase interleaved audio-text pairs during training.", "result": "Achieves state-of-the-art results on AudioCaps, Clotho, and Auto-ACD benchmarks.", "conclusion": "Multimodal querying and progressive learning significantly improve retrieval-augmented audio captioning, outperforming existing methods."}}
{"id": "2506.08513", "pdf": "https://arxiv.org/pdf/2506.08513", "abs": "https://arxiv.org/abs/2506.08513", "authors": ["Leyla A. Kabuli", "Henry Pinkard", "Eric Markley", "Clara S. Hung", "Laura Waller"], "title": "Designing lensless imaging systems to maximize information capture", "categories": ["physics.optics", "eess.IV"], "comment": "23 pages, 10 figures", "summary": "Mask-based lensless imaging uses an optical encoder (e.g. a phase or\namplitude mask) to capture measurements, then a computational decoding\nalgorithm to reconstruct images. In this work, we evaluate and design encoders\nbased on the information content of their measurements using mutual information\nestimation. With this approach, we formalize the object-dependent nature of\nlensless imaging and study the interdependence between object sparsity, encoder\nmultiplexing, and noise. Our analysis reveals that optimal encoder designs\nshould tailor encoder multiplexing to object sparsity for maximum information\ncapture, and that all optimally-encoded measurements share the same level of\nsparsity. Using mutual information-based optimization, we design\ninformation-optimal encoders with improved downstream reconstruction\nperformance. We validate the benefits of reduced multiplexing for dense,\nnatural images by evaluating experimental lensless imaging systems directly\nfrom captured measurements, without the need for image formation models,\nreconstruction algorithms, or ground truth images. Our comprehensive analysis\nestablishes design and engineering principles for improving lensless imaging\nsystems, and offers a model for the study of general multiplexing systems,\nespecially those with object-dependent performance.", "AI": {"tldr": "The paper evaluates and designs optical encoders for lensless imaging using mutual information estimation, optimizing encoder multiplexing for object sparsity to improve information capture and reconstruction performance.", "motivation": "To formalize the object-dependent nature of lensless imaging and study the interplay between object sparsity, encoder multiplexing, and noise for optimal encoder design.", "method": "Uses mutual information estimation to analyze and optimize encoder designs, validating performance through experimental lensless imaging systems.", "result": "Optimal encoders tailor multiplexing to object sparsity, with all optimally-encoded measurements sharing the same sparsity level, leading to improved reconstruction.", "conclusion": "The work provides design principles for lensless imaging systems and a model for studying multiplexing systems with object-dependent performance."}}
{"id": "2506.08194", "pdf": "https://arxiv.org/pdf/2506.08194", "abs": "https://arxiv.org/abs/2506.08194", "authors": ["Mateusz Michalkiewicz", "Anekha Sokhal", "Tadeusz Michalkiewicz", "Piotr Pawlikowski", "Mahsa Baktashmotlagh", "Varun Jampani", "Guha Balakrishnan"], "title": "GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra", "categories": ["cs.CV", "68T45", "I.5.4; I.2.10; I.3.5"], "comment": "15 pages, 4 figures", "summary": "Monocular 3D reconstruction methods and vision-language models (VLMs)\ndemonstrate impressive results on standard benchmarks, yet their true\nunderstanding of geometric properties remains unclear. We introduce GIQ , a\ncomprehensive benchmark specifically designed to evaluate the geometric\nreasoning capabilities of vision and vision-language foundation models. GIQ\ncomprises synthetic and real-world images of 224 diverse polyhedra - including\nPlatonic, Archimedean, Johnson, and Catalan solids, as well as stellations and\ncompound shapes - covering varying levels of complexity and symmetry. Through\nsystematic experiments involving monocular 3D reconstruction, 3D symmetry\ndetection, mental rotation tests, and zero-shot shape classification tasks, we\nreveal significant shortcomings in current models. State-of-the-art\nreconstruction algorithms trained on extensive 3D datasets struggle to\nreconstruct even basic geometric forms accurately. While foundation models\neffectively detect specific 3D symmetry elements via linear probing, they\nfalter significantly in tasks requiring detailed geometric differentiation,\nsuch as mental rotation. Moreover, advanced vision-language assistants exhibit\nremarkably low accuracy on complex polyhedra, systematically misinterpreting\nbasic properties like face geometry, convexity, and compound structures. GIQ is\npublicly available, providing a structured platform to highlight and address\ncritical gaps in geometric intelligence, facilitating future progress in\nrobust, geometry-aware representation learning.", "AI": {"tldr": "GIQ is a benchmark to evaluate geometric reasoning in vision and vision-language models, revealing significant shortcomings in current models despite their performance on standard tasks.", "motivation": "To assess the true geometric understanding of vision and vision-language models, which remains unclear despite their success on benchmarks.", "method": "GIQ includes synthetic and real-world images of 224 diverse polyhedra, tested via monocular 3D reconstruction, symmetry detection, mental rotation, and zero-shot classification.", "result": "Current models struggle with basic geometric forms, symmetry detection, and detailed differentiation, while vision-language assistants perform poorly on complex polyhedra.", "conclusion": "GIQ highlights critical gaps in geometric intelligence, offering a platform to improve geometry-aware representation learning."}}
{"id": "2506.08363", "pdf": "https://arxiv.org/pdf/2506.08363", "abs": "https://arxiv.org/abs/2506.08363", "authors": ["Jun Yin", "Jing Zhong", "Pengyu Zeng", "Peilin Li", "Miao Zhang", "Ran Luo", "Shuai Lu"], "title": "FloorplanMAE:A self-supervised framework for complete floorplan generation from partial inputs", "categories": ["cs.AI"], "comment": null, "summary": "In the architectural design process, floorplan design is often a dynamic and\niterative process. Architects progressively draw various parts of the floorplan\naccording to their ideas and requirements, continuously adjusting and refining\nthroughout the design process. Therefore, the ability to predict a complete\nfloorplan from a partial one holds significant value in the design process.\nSuch prediction can help architects quickly generate preliminary designs,\nimprove design efficiency, and reduce the workload associated with repeated\nmodifications. To address this need, we propose FloorplanMAE, a self-supervised\nlearning framework for restoring incomplete floor plans into complete ones.\nFirst, we developed a floor plan reconstruction dataset, FloorplanNet,\nspecifically trained on architectural floor plans. Secondly, we propose a floor\nplan reconstruction method based on Masked Autoencoders (MAE), which\nreconstructs missing parts by masking sections of the floor plan and training a\nlightweight Vision Transformer (ViT). We evaluated the reconstruction accuracy\nof FloorplanMAE and compared it with state-of-the-art benchmarks. Additionally,\nwe validated the model using real sketches from the early stages of\narchitectural design. Experimental results show that the FloorplanMAE model can\ngenerate high-quality complete floor plans from incomplete partial plans. This\nframework provides a scalable solution for floor plan generation, with broad\napplication prospects.", "AI": {"tldr": "FloorplanMAE is a self-supervised learning framework that predicts complete floorplans from partial ones, improving design efficiency.", "motivation": "Floorplan design is iterative; predicting complete plans from partial ones can save time and reduce repetitive work.", "method": "Uses Masked Autoencoders (MAE) and a lightweight Vision Transformer (ViT) to reconstruct missing parts of floorplans, trained on FloorplanNet dataset.", "result": "Generates high-quality complete floorplans from incomplete ones, outperforming benchmarks.", "conclusion": "FloorplanMAE offers a scalable solution for floorplan generation with broad applications."}}
{"id": "2506.08060", "pdf": "https://arxiv.org/pdf/2506.08060", "abs": "https://arxiv.org/abs/2506.08060", "authors": ["Asankhaya Sharma"], "title": "Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models have transformed natural language processing, yet\nsupervised fine-tuning (SFT) remains computationally intensive. This paper\nformally proves that capabilities acquired through SFT can be approximated by a\nbase transformer model using inference-time techniques, specifically in-context\nlearning (ICL), without altering model parameters, under idealized assumptions\nincluding unbounded computational resources and access to the fine-tuning\ndataset. We extend these results to practical scenarios with finite context\nlengths and partial dataset access. For text generation tasks with fixed output\nlength $l$, datasets of size $\\mathrm{O}\\left( \\frac{m V}{\\varepsilon^2} \\log\n\\frac{m}{\\delta} \\right)$ or, with bounded context, $\\mathrm{O}\\left( \\frac{l\n\\log V}{\\varepsilon^2} \\log \\frac{1}{\\delta} \\right)$ suffice to approximate\nfine-tuned behavior across $m$ contexts within error $\\varepsilon$, where $V$\nis the vocabulary size and $\\delta$ is the failure probability. For linear\nclassification, datasets of size $\\mathrm{O}\\left( \\frac{d}{\\varepsilon}\n\\right)$ or, with fixed context, $\\mathrm{O}\\left( \\frac{1}{\\varepsilon^2} \\log\n\\frac{1}{\\delta} \\right)$ are sufficient, where $d$ is the input dimension.\nGrounded in the Turing completeness of transformers, these results provide a\ntheoretical foundation for resource-efficient deployment of large language\nmodels, with practical techniques like retrieval-augmented generation bridging\ntheory to real-world applications.", "AI": {"tldr": "The paper proves that supervised fine-tuning (SFT) capabilities in large language models can be approximated using inference-time techniques like in-context learning (ICL), without parameter updates, under idealized and practical conditions.", "motivation": "To reduce the computational burden of SFT by showing that similar performance can be achieved through inference-time methods, making large language models more resource-efficient.", "method": "Theoretical analysis under idealized assumptions (unbounded resources, full dataset access) and extension to practical scenarios (finite context, partial dataset). Provides dataset size bounds for approximating SFT behavior.", "result": "For text generation and linear classification tasks, specific dataset sizes suffice to approximate fine-tuned behavior within error bounds, leveraging ICL.", "conclusion": "The study offers a theoretical basis for efficient deployment of large language models, with practical implications for techniques like retrieval-augmented generation."}}
{"id": "2409.08797", "pdf": "https://arxiv.org/pdf/2409.08797", "abs": "https://arxiv.org/abs/2409.08797", "authors": ["Mingyu Cui", "Yifan Yang", "Jiajun Deng", "Jiawen Kang", "Shujie Hu", "Tianzi Wang", "Zhaoqing Li", "Shiliang Zhang", "Xie Chen", "Xunying Liu"], "title": "Exploring SSL Discrete Speech Features for Zipformer-based Contextual ASR", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "Self-supervised learning (SSL) based discrete speech representations are\nhighly compact and domain adaptable. In this paper, SSL discrete speech\nfeatures extracted from WavLM models are used as additional cross-utterance\nacoustic context features in Zipformer-Transducer ASR systems. The efficacy of\nreplacing Fbank features with discrete token features for modelling either\ncross-utterance contexts (from preceding and future segments), or current\nutterance's internal contexts alone, or both at the same time, are demonstrated\nthoroughly on the Gigaspeech 1000-hr corpus. The best Zipformer-Transducer\nsystem using discrete tokens based cross-utterance context features outperforms\nthe baseline using utterance internal context only with statistically\nsignificant word error rate (WER) reductions of 0.32% to 0.41% absolute (2.78%\nto 3.54% relative) on the dev and test data. The lowest published WER of 11.15%\nand 11.14% were obtained on the dev and test sets. Our work is open-source and\npublicly available at\nhttps://github.com/open-creator/icefall/tree/master/egs/gigaspeech/Context\\_ASR.", "AI": {"tldr": "SSL-based discrete speech features improve ASR performance by modeling cross-utterance contexts, achieving significant WER reductions.", "motivation": "To enhance ASR systems by leveraging SSL discrete speech features for better cross-utterance context modeling.", "method": "Use WavLM-extracted discrete tokens in Zipformer-Transducer ASR, replacing Fbank features, and evaluate on Gigaspeech corpus.", "result": "Achieved WER reductions of 0.32%-0.41% absolute (2.78%-3.54% relative) and lowest published WERs of 11.15% and 11.14%.", "conclusion": "SSL discrete tokens effectively improve ASR performance, with open-source implementation available."}}
{"id": "2506.08234", "pdf": "https://arxiv.org/pdf/2506.08234", "abs": "https://arxiv.org/abs/2506.08234", "authors": ["Yu-Ang Lee", "Guan-Ting Yi", "Mei-Yi Liu", "Jui-Chao Lu", "Guan-Bo Yang", "Yun-Nung Chen"], "title": "Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions", "categories": ["cs.CL", "cs.AI"], "comment": "15 pages, 4 figures, 1 table", "summary": "Recent advancements in large language models (LLMs) and AI systems have led\nto a paradigm shift in the design and optimization of complex AI workflows. By\nintegrating multiple components, compound AI systems have become increasingly\nadept at performing sophisticated tasks. However, as these systems grow in\ncomplexity, new challenges arise in optimizing not only individual components\nbut also their interactions. While traditional optimization methods such as\nsupervised fine-tuning (SFT) and reinforcement learning (RL) remain\nfoundational, the rise of natural language feedback introduces promising new\napproaches, especially for optimizing non-differentiable systems. This paper\nprovides a systematic review of recent progress in optimizing compound AI\nsystems, encompassing both numerical and language-based techniques. We\nformalize the notion of compound AI system optimization, classify existing\nmethods along several key dimensions, and highlight open research challenges\nand future directions in this rapidly evolving field. A list of surveyed papers\nis publicly available at https://github.com/MiuLab/AISysOpt-Survey.", "AI": {"tldr": "A review of recent progress in optimizing compound AI systems, covering numerical and language-based techniques, challenges, and future directions.", "motivation": "The increasing complexity of compound AI systems necessitates new optimization methods beyond traditional approaches like SFT and RL.", "method": "Systematic review and classification of optimization techniques, including natural language feedback for non-differentiable systems.", "result": "Formalization of compound AI system optimization, classification of methods, and identification of open challenges.", "conclusion": "The field is rapidly evolving, with promising directions for optimizing interactions in complex AI workflows."}}
{"id": "2505.18956", "pdf": "https://arxiv.org/pdf/2505.18956", "abs": "https://arxiv.org/abs/2505.18956", "authors": ["Yining Pan", "Qiongjie Cui", "Xulei Yang", "Na Zhao"], "title": "How Do Images Align and Complement LiDAR? Towards a Harmonized Multi-modal 3D Panoptic Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "Accepted at the 2025 International Conference on Machine Learning\n  (ICML)", "summary": "LiDAR-based 3D panoptic segmentation often struggles with the inherent\nsparsity of data from LiDAR sensors, which makes it challenging to accurately\nrecognize distant or small objects. Recently, a few studies have sought to\novercome this challenge by integrating LiDAR inputs with camera images,\nleveraging the rich and dense texture information provided by the latter. While\nthese approaches have shown promising results, they still face challenges, such\nas misalignment during data augmentation and the reliance on post-processing\nsteps. To address these issues, we propose Image-Assists-LiDAR (IAL), a novel\nmulti-modal 3D panoptic segmentation framework. In IAL, we first introduce a\nmodality-synchronized data augmentation strategy, PieAug, to ensure alignment\nbetween LiDAR and image inputs from the start. Next, we adopt a transformer\ndecoder to directly predict panoptic segmentation results. To effectively fuse\nLiDAR and image features into tokens for the decoder, we design a\nGeometric-guided Token Fusion (GTF) module. Additionally, we leverage the\ncomplementary strengths of each modality as priors for query initialization\nthrough a Prior-based Query Generation (PQG) module, enhancing the decoder's\nability to generate accurate instance masks. Our IAL framework achieves\nstate-of-the-art performance compared to previous multi-modal 3D panoptic\nsegmentation methods on two widely used benchmarks. Code and models are\npublicly available at <https://github.com/IMPL-Lab/IAL.git>.", "AI": {"tldr": "IAL is a novel multi-modal 3D panoptic segmentation framework that integrates LiDAR and camera data, addressing sparsity and misalignment issues with synchronized augmentation and transformer-based decoding.", "motivation": "Overcome challenges in LiDAR-based 3D panoptic segmentation, such as sparsity and misalignment, by leveraging complementary camera data.", "method": "Proposes IAL with PieAug for synchronized data augmentation, GTF for feature fusion, and PQG for query initialization, using a transformer decoder.", "result": "Achieves state-of-the-art performance on benchmarks.", "conclusion": "IAL effectively combines LiDAR and camera data, improving segmentation accuracy without post-processing."}}
{"id": "2504.00369", "pdf": "https://arxiv.org/pdf/2504.00369", "abs": "https://arxiv.org/abs/2504.00369", "authors": ["Yongyi Zang", "Sean O'Brien", "Taylor Berg-Kirkpatrick", "Julian McAuley", "Zachary Novack"], "title": "Are you really listening? Boosting Perceptual Awareness in Music-QA Benchmarks", "categories": ["cs.SD"], "comment": "ISMIR 2025", "summary": "Large Audio Language Models (LALMs), where pretrained text LLMs are finetuned\nwith audio input, have made remarkable progress in music understanding.\nHowever, current evaluation methodologies exhibit critical limitations: on the\nleading Music Question Answering benchmark, MuchoMusic, text-only LLMs without\naudio perception capabilities achieve surprisingly high accuracy of up to\n56.4%, on par or above most LALMs. Furthermore, when presented with random\nGaussian noise instead of actual audio, LALMs still perform significantly above\nchance. These findings suggest existing benchmarks predominantly assess\nreasoning abilities rather than audio perception. To overcome this challenge,\nwe present RUListening: Robust Understanding through Listening, a framework\nthat enhances perceptual evaluation in Music-QA benchmarks. We introduce the\nPerceptual Index (PI), a quantitative metric that measures a question's\nreliance on audio perception by analyzing log probability distributions from\ntext-only language models. Using this metric, we generate synthetic,\nchallenging distractors to create QA pairs that necessitate genuine audio\nperception. When applied to MuchoMusic, our filtered dataset successfully\nforces models to rely on perceptual information-text-only LLMs perform at\nchance levels, while LALMs similarly deteriorate when audio inputs are replaced\nwith noise. These results validate our framework's effectiveness in creating\nbenchmarks that more accurately evaluate audio perception capabilities.", "AI": {"tldr": "The paper introduces RUListening, a framework to improve evaluation of audio perception in Music-QA benchmarks, addressing limitations in current methods where text-only LLMs perform well without audio input.", "motivation": "Current benchmarks for Large Audio Language Models (LALMs) fail to accurately assess audio perception, as text-only LLMs perform comparably or better, and LALMs still score above chance with noise.", "method": "The authors propose RUListening, which uses the Perceptual Index (PI) to measure audio reliance in questions and generates synthetic distractors to create QA pairs requiring genuine audio perception.", "result": "Applied to MuchoMusic, the filtered dataset forces models to rely on audio: text-only LLMs perform at chance, and LALMs degrade with noise inputs.", "conclusion": "RUListening effectively creates benchmarks that better evaluate audio perception, validated by the results."}}
{"id": "2506.08785", "pdf": "https://arxiv.org/pdf/2506.08785", "abs": "https://arxiv.org/abs/2506.08785", "authors": ["Mukul Lokhande", "Santosh Kumar Vishvakarma"], "title": "POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration", "categories": ["cs.AR", "cs.AI", "cs.CC", "eess.IV"], "comment": null, "summary": "The increasing complexity of AI models requires flexible hardware capable of\nsupporting diverse precision formats, particularly for energy-constrained edge\nplatforms. This work presents PARV-CE, a SIMD-enabled, multi-precision MAC\nengine that performs efficient multiply-accumulate operations using a unified\ndata-path for 4/8/16-bit fixed-point, floating point, and posit formats. The\narchitecture incorporates a layer adaptive precision strategy to align\ncomputational accuracy with workload sensitivity, optimizing both performance\nand energy usage. PARV-CE integrates quantization-aware execution with a\nreconfigurable SIMD pipeline, enabling high-throughput processing with minimal\noverhead through hardware-software co-design. The results demonstrate up to 2x\nimprovement in PDP and 3x reduction in resource usage compared to SoTA designs,\nwhile retaining accuracy within 1.8% FP32 baseline. The architecture supports\nboth on-device training and inference across a range of workloads, including\nDNNs, RNNs, RL, and Transformer models. The empirical analysis establish PARVCE\nincorporated POLARON as a scalable and energy-efficient solution for\nprecision-adaptive AI acceleration at edge.", "AI": {"tldr": "PARV-CE is a multi-precision MAC engine for AI models, optimizing energy and performance with adaptive precision and SIMD support, achieving significant improvements over state-of-the-art designs.", "motivation": "Addressing the need for flexible hardware to support diverse precision formats in energy-constrained edge platforms for AI models.", "method": "PARV-CE uses a unified data-path for 4/8/16-bit fixed-point, floating point, and posit formats, with layer adaptive precision and quantization-aware execution in a reconfigurable SIMD pipeline.", "result": "Demonstrates up to 2x improvement in PDP, 3x reduction in resource usage, and retains accuracy within 1.8% of FP32 baseline.", "conclusion": "PARV-CE, integrated with POLARON, is a scalable and energy-efficient solution for precision-adaptive AI acceleration at the edge."}}
{"id": "2506.08210", "pdf": "https://arxiv.org/pdf/2506.08210", "abs": "https://arxiv.org/abs/2506.08210", "authors": ["Andrew Z. Wang", "Songwei Ge", "Tero Karras", "Ming-Yu Liu", "Yogesh Balaji"], "title": "A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "CVPR 2025", "summary": "Both text-to-image generation and large language models (LLMs) have made\nsignificant advancements. However, many text-to-image models still employ the\nsomewhat outdated T5 and CLIP as their text encoders. In this work, we\ninvestigate the effectiveness of using modern decoder-only LLMs as text\nencoders for text-to-image diffusion models. We build a standardized training\nand evaluation pipeline that allows us to isolate and evaluate the effect of\ndifferent text embeddings. We train a total of 27 text-to-image models with 12\ndifferent text encoders to analyze the critical aspects of LLMs that could\nimpact text-to-image generation, including the approaches to extract\nembeddings, different LLMs variants, and model sizes. Our experiments reveal\nthat the de facto way of using last-layer embeddings as conditioning leads to\ninferior performance. Instead, we explore embeddings from various layers and\nfind that using layer-normalized averaging across all layers significantly\nimproves alignment with complex prompts. Most LLMs with this conditioning\noutperform the baseline T5 model, showing enhanced performance in advanced\nvisio-linguistic reasoning skills.", "AI": {"tldr": "The paper explores using modern decoder-only LLMs as text encoders for text-to-image diffusion models, finding that layer-normalized averaging of embeddings outperforms traditional last-layer embeddings and T5 baselines.", "motivation": "Current text-to-image models often use outdated text encoders like T5 and CLIP. The study investigates whether modern LLMs can improve performance.", "method": "A standardized pipeline trains 27 models with 12 text encoders, analyzing embedding extraction methods, LLM variants, and sizes.", "result": "Layer-normalized averaging of embeddings across all layers improves alignment with complex prompts, outperforming T5 and last-layer embeddings.", "conclusion": "Modern LLMs, with optimized embedding extraction, enhance text-to-image generation, particularly for complex prompts."}}
{"id": "2506.08390", "pdf": "https://arxiv.org/pdf/2506.08390", "abs": "https://arxiv.org/abs/2506.08390", "authors": ["Leheng Sheng", "An Zhang", "Zijian Wu", "Weixiang Zhao", "Changshuo Shen", "Yi Zhang", "Xiang Wang", "Tat-Seng Chua"], "title": "On Reasoning Strength Planning in Large Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Recent studies empirically reveal that large reasoning models (LRMs) can\nautomatically allocate more reasoning strengths (i.e., the number of reasoning\ntokens) for harder problems, exhibiting difficulty-awareness for better task\nperformance. While this automatic reasoning strength allocation phenomenon has\nbeen widely observed, its underlying mechanism remains largely unexplored. To\nthis end, we provide explanations for this phenomenon from the perspective of\nmodel activations. We find evidence that LRMs pre-plan the reasoning strengths\nin their activations even before generation, with this reasoning strength\ncausally controlled by the magnitude of a pre-allocated directional vector.\nSpecifically, we show that the number of reasoning tokens is predictable solely\nbased on the question activations using linear probes, indicating that LRMs\nestimate the required reasoning strength in advance. We then uncover that LRMs\nencode this reasoning strength through a pre-allocated directional vector\nembedded in the activations of the model, where the vector's magnitude\nmodulates the reasoning strength. Subtracting this vector can lead to reduced\nreasoning token number and performance, while adding this vector can lead to\nincreased reasoning token number and even improved performance. We further\nreveal that this direction vector consistently yields positive reasoning length\nprediction, and it modifies the logits of end-of-reasoning token </think> to\naffect the reasoning length. Finally, we demonstrate two potential applications\nof our findings: overthinking behavior detection and enabling efficient\nreasoning on simple problems. Our work provides new insights into the internal\nmechanisms of reasoning in LRMs and offers practical tools for controlling\ntheir reasoning behaviors. Our code is available at\nhttps://github.com/AlphaLab-USTC/LRM-plans-CoT.", "AI": {"tldr": "Large reasoning models (LRMs) pre-plan reasoning strength via activations, controlled by a directional vector's magnitude, influencing performance and token count.", "motivation": "To understand the unexplored mechanism behind LRMs' automatic reasoning strength allocation for varying problem difficulties.", "method": "Analyze model activations, use linear probes to predict reasoning tokens, and manipulate a pre-allocated directional vector to observe its impact.", "result": "LRMs encode reasoning strength in activations via a directional vector; modifying it affects token count and performance.", "conclusion": "The study reveals LRMs' internal reasoning mechanisms and offers tools for controlling reasoning behaviors, with practical applications."}}
{"id": "2506.08062", "pdf": "https://arxiv.org/pdf/2506.08062", "abs": "https://arxiv.org/abs/2506.08062", "authors": ["Woosung Kim", "Jinho Lee", "Jongmin Lee", "Byung-Jun Lee"], "title": "FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Multi-objective Reinforcement Learning", "summary": "Multi-objective reinforcement learning (MORL) aims to optimize policies in\nthe presence of conflicting objectives, where linear scalarization is commonly\nused to reduce vector-valued returns into scalar signals. While effective for\ncertain preferences, this approach cannot capture fairness-oriented goals such\nas Nash social welfare or max-min fairness, which require nonlinear and\nnon-additive trade-offs. Although several online algorithms have been proposed\nfor specific fairness objectives, a unified approach for optimizing nonlinear\nwelfare criteria in the offline setting-where learning must proceed from a\nfixed dataset-remains unexplored. In this work, we present FairDICE, the first\noffline MORL framework that directly optimizes nonlinear welfare objective.\nFairDICE leverages distribution correction estimation to jointly account for\nwelfare maximization and distributional regularization, enabling stable and\nsample-efficient learning without requiring explicit preference weights or\nexhaustive weight search. Across multiple offline benchmarks, FairDICE\ndemonstrates strong fairness-aware performance compared to existing baselines.", "AI": {"tldr": "FairDICE is the first offline MORL framework optimizing nonlinear welfare objectives, outperforming baselines in fairness-aware performance.", "motivation": "Linear scalarization in MORL fails to capture fairness goals like Nash social welfare or max-min fairness, necessitating a unified offline approach.", "method": "FairDICE uses distribution correction estimation for welfare maximization and distributional regularization, enabling stable learning without preference weights.", "result": "FairDICE shows strong fairness-aware performance across offline benchmarks.", "conclusion": "FairDICE successfully addresses the gap in offline MORL for nonlinear welfare objectives."}}
{"id": "2504.08024", "pdf": "https://arxiv.org/pdf/2504.08024", "abs": "https://arxiv.org/abs/2504.08024", "authors": ["Fabian Retkowski", "Maike Z\u00fcfle", "Andreas Sudmann", "Dinah Pfau", "Shinji Watanabe", "Jan Niehues", "Alexander Waibel"], "title": "Summarizing Speech: A Comprehensive Survey", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Speech summarization has become an essential tool for efficiently managing\nand accessing the growing volume of spoken and audiovisual content. However,\ndespite its increasing importance, speech summarization remains loosely\ndefined. The field intersects with several research areas, including speech\nrecognition, text summarization, and specific applications like meeting\nsummarization. This survey not only examines existing datasets and evaluation\nprotocols, which are crucial for assessing the quality of summarization\napproaches, but also synthesizes recent developments in the field, highlighting\nthe shift from traditional systems to advanced models like fine-tuned cascaded\narchitectures and end-to-end solutions. In doing so, we surface the ongoing\nchallenges, such as the need for realistic evaluation benchmarks, multilingual\ndatasets, and long-context handling.", "AI": {"tldr": "The paper surveys speech summarization, covering datasets, evaluation protocols, and advancements like fine-tuned cascaded architectures and end-to-end models, while highlighting challenges like multilingual datasets and long-context handling.", "motivation": "Speech summarization is crucial for managing spoken and audiovisual content but lacks clear definition and faces challenges in evaluation and multilingual support.", "method": "The survey examines existing datasets, evaluation protocols, and synthesizes recent advancements in speech summarization, including traditional systems and modern models.", "result": "The paper highlights advancements in the field and identifies ongoing challenges, such as the need for better benchmarks and multilingual datasets.", "conclusion": "Speech summarization is evolving with advanced models, but challenges like realistic evaluation and long-context handling remain."}}
{"id": "2506.08235", "pdf": "https://arxiv.org/pdf/2506.08235", "abs": "https://arxiv.org/abs/2506.08235", "authors": ["Shashidhar Reddy Javaji", "Yupeng Cao", "Haohang Li", "Yangyang Yu", "Nikhil Muralidhar", "Zining Zhu"], "title": "Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\\rightarrow$ Evidence Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "21 pages, 6 figures, Under review", "summary": "Large language models (LLMs) are increasingly being used for complex research\ntasks such as literature review, idea generation, and scientific paper\nanalysis, yet their ability to truly understand and process the intricate\nrelationships within complex research papers, such as the logical links between\nclaims and supporting evidence remains largely unexplored. In this study, we\npresent CLAIM-BENCH, a comprehensive benchmark for evaluating LLMs'\ncapabilities in scientific claim-evidence extraction and validation, a task\nthat reflects deeper comprehension of scientific argumentation. We\nsystematically compare three approaches which are inspired by divide and\nconquer approaches, across six diverse LLMs, highlighting model-specific\nstrengths and weaknesses in scientific comprehension. Through evaluation\ninvolving over 300 claim-evidence pairs across multiple research domains, we\nreveal significant limitations in LLMs' ability to process complex scientific\ncontent. Our results demonstrate that closed-source models like GPT-4 and\nClaude consistently outperform open-source counterparts in precision and recall\nacross claim-evidence identification tasks. Furthermore, strategically designed\nthree-pass and one-by-one prompting approaches significantly improve LLMs'\nabilities to accurately link dispersed evidence with claims, although this\ncomes at increased computational cost. CLAIM-BENCH sets a new standard for\nevaluating scientific comprehension in LLMs, offering both a diagnostic tool\nand a path forward for building systems capable of deeper, more reliable\nreasoning across full-length papers.", "AI": {"tldr": "CLAIM-BENCH evaluates LLMs' ability to extract and validate scientific claims and evidence, revealing limitations and performance gaps between closed-source and open-source models.", "motivation": "To assess LLMs' deeper comprehension of scientific argumentation, particularly in linking claims and evidence, which remains underexplored.", "method": "Systematically compares three divide-and-conquer-inspired approaches across six LLMs, testing over 300 claim-evidence pairs.", "result": "Closed-source models (e.g., GPT-4, Claude) outperform open-source ones in precision and recall. Three-pass and one-by-one prompting improve accuracy but increase computational cost.", "conclusion": "CLAIM-BENCH provides a benchmark for evaluating LLMs' scientific comprehension, highlighting current limitations and suggesting improvements for deeper reasoning."}}
{"id": "2505.20011", "pdf": "https://arxiv.org/pdf/2505.20011", "abs": "https://arxiv.org/abs/2505.20011", "authors": ["Maciej Swiechowski", "Dominik Slezak"], "title": "The Many Challenges of Human-Like Agents in Virtual Game Environments", "categories": ["cs.AI", "cs.HC", "cs.MM", "68T01", "I.2; I.6.0; H.1.2"], "comment": "In proceedings of the 24th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS-2025), pages 1996--2005, May 19-23,\n  Detroit, Michigan, USA", "summary": "Human-like agents are an increasingly important topic in games and beyond.\nBelievable non-player characters enhance the gaming experience by improving\nimmersion and providing entertainment. They also offer players the opportunity\nto engage with AI entities that can function as opponents, teachers, or\ncooperating partners. Additionally, in games where bots are prohibited -- and\neven more so in non-game environments -- there is a need for methods capable of\nidentifying whether digital interactions occur with bots or humans. This leads\nto two fundamental research questions: (1) how to model and implement\nhuman-like AI, and (2) how to measure its degree of human likeness.\n  This article offers two contributions. The first one is a survey of the most\nsignificant challenges in implementing human-like AI in games (or any virtual\nenvironment featuring simulated agents, although this article specifically\nfocuses on games). Thirteen such challenges, both conceptual and technical, are\ndiscussed in detail. The second is an empirical study performed in a tactical\nvideo game that addresses the research question: \"Is it possible to distinguish\nhuman players from bots (AI agents) based on empirical data?\" A\nmachine-learning approach using a custom deep recurrent convolutional neural\nnetwork is presented. We hypothesize that the more challenging it is to create\nhuman-like AI for a given game, the easier it becomes to develop a method for\ndistinguishing humans from AI-driven players.", "AI": {"tldr": "The paper explores human-like AI in games, addressing challenges in implementation and measuring human likeness. It includes a survey of 13 challenges and an empirical study using machine learning to distinguish humans from bots.", "motivation": "Enhancing gaming immersion and interaction with believable AI, plus the need to identify bots in digital interactions.", "method": "Survey of challenges in human-like AI and an empirical study using a deep recurrent convolutional neural network to differentiate humans from bots.", "result": "The study suggests that harder-to-create human-like AI makes it easier to distinguish humans from bots.", "conclusion": "The paper provides insights into human-like AI challenges and demonstrates a method for bot detection, linking AI complexity to detection ease."}}
{"id": "2506.05688", "pdf": "https://arxiv.org/pdf/2506.05688", "abs": "https://arxiv.org/abs/2506.05688", "authors": ["Keinichi Fujita", "Shota Horiguchi", "Yusuke Ijima"], "title": "Voice Impression Control in Zero-Shot TTS", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": "5 pages,5 figures, Accepted to INTERSPEECH 2025", "summary": "Para-/non-linguistic information in speech is pivotal in shaping the\nlisteners' impression. Although zero-shot text-to-speech (TTS) has achieved\nhigh speaker fidelity, modulating subtle para-/non-linguistic information to\ncontrol perceived voice characteristics, i.e., impressions, remains\nchallenging. We have therefore developed a voice impression control method in\nzero-shot TTS that utilizes a low-dimensional vector to represent the\nintensities of various voice impression pairs (e.g., dark-bright). The results\nof both objective and subjective evaluations have demonstrated our method's\neffectiveness in impression control. Furthermore, generating this vector via a\nlarge language model enables target-impression generation from a natural\nlanguage description of the desired impression, thus eliminating the need for\nmanual optimization. Audio examples are available on our demo page\n(https://ntt-hilab-gensp.github.io/is2025voiceimpression/).", "AI": {"tldr": "A method for controlling voice impressions in zero-shot TTS using low-dimensional vectors and large language models, eliminating manual optimization.", "motivation": "Modulating para-/non-linguistic speech information to control perceived voice impressions is challenging in zero-shot TTS.", "method": "Uses a low-dimensional vector to represent voice impression intensities and leverages a large language model for vector generation from natural language descriptions.", "result": "Demonstrated effectiveness in impression control through objective and subjective evaluations.", "conclusion": "The method successfully enables target-impression generation from natural language, improving zero-shot TTS flexibility."}}
{"id": "2506.08793", "pdf": "https://arxiv.org/pdf/2506.08793", "abs": "https://arxiv.org/abs/2506.08793", "authors": ["Zhuoran Zheng"], "title": "A PDE-Based Image Dehazing Method via Atmospheric Scattering Theory", "categories": ["cs.CV", "eess.IV"], "comment": "report", "summary": "This paper presents a novel partial differential equation (PDE) framework for\nsingle-image dehazing. By integrating the atmospheric scattering model with\nnonlocal regularization and dark channel prior, we propose the improved PDE: \\[\n-\\text{div}\\left(D(\\nabla u)\\nabla u\\right) + \\lambda(t) G(u) = \\Phi(I,t,A) \\]\nwhere $D(\\nabla u) = (|\\nabla u| + \\epsilon)^{-1}$ is the edge-preserving\ndiffusion coefficient, $G(u)$ is the Gaussian convolution operator, and\n$\\lambda(t)$ is the adaptive regularization parameter based on transmission map\n$t$. We prove the existence and uniqueness of weak solutions in $H_0^1(\\Omega)$\nusing Lax-Milgram theorem, and implement an efficient fixed-point iteration\nscheme accelerated by PyTorch GPU computation. The experimental results\ndemonstrate that this method is a promising deghazing solution that can be\ngeneralized to the deep model paradigm.", "AI": {"tldr": "A novel PDE framework for single-image dehazing integrates atmospheric scattering, nonlocal regularization, and dark channel prior, proving existence/uniqueness of solutions and demonstrating promising results.", "motivation": "To improve single-image dehazing by combining physical models (atmospheric scattering) with mathematical techniques (PDEs, nonlocal regularization) for better accuracy and efficiency.", "method": "Proposes an improved PDE with edge-preserving diffusion, adaptive regularization, and Gaussian convolution, solved via Lax-Milgram theorem and GPU-accelerated fixed-point iteration.", "result": "Proves existence/uniqueness of weak solutions and shows the method is effective and generalizable to deep models.", "conclusion": "The framework is a promising dehazing solution, bridging traditional PDEs and modern deep learning paradigms."}}
{"id": "2506.08214", "pdf": "https://arxiv.org/pdf/2506.08214", "abs": "https://arxiv.org/abs/2506.08214", "authors": ["Ioannis Iakovidis", "Zahra Kalantari", "Amir Hossein Payberah", "Fernando Jaramillo", "Francisco Pena Escobar"], "title": "Using Satellite Images And Self-supervised Machine Learning Networks To Detect Water Hidden Under Vegetation", "categories": ["cs.CV"], "comment": "16 pages, 9 figures", "summary": "In recent years the wide availability of high-resolution radar satellite\nimages along with the advancement of computer vision models have enabled the\nremote monitoring of the surface area of wetlands. However, these models\nrequire large amounts of manually annotated satellite images, which are slow\nand expensive to produce. To overcome this problem, self-supervised training\nmethods have been deployed to train models without using annotated data. In\nthis paper we use a combination of deep clustering and negative sampling to\ntrain a model to segment radar satellite images into areas that separate water\nfrom land without the use of any manual annotations. Furthermore, we implement\nan ensemble version of the model to reduce variance and improve performance.\nCompared to a single fully-supervised model using the same architecture, our\nensemble of self-supervised models achieves a 0.02 improvement in the\nIntersection Over Union metric over our test dataset.", "AI": {"tldr": "Self-supervised training with deep clustering and negative sampling improves wetland segmentation in radar images, outperforming supervised models.", "motivation": "Manual annotation of satellite images for wetland monitoring is slow and costly, prompting the need for self-supervised methods.", "method": "Combines deep clustering and negative sampling for training without annotations, plus an ensemble approach to reduce variance.", "result": "Ensemble of self-supervised models achieves a 0.02 higher Intersection Over Union (IoU) than a supervised model.", "conclusion": "Self-supervised methods can effectively replace manual annotations for wetland segmentation, with ensembles enhancing performance."}}
{"id": "2506.08399", "pdf": "https://arxiv.org/pdf/2506.08399", "abs": "https://arxiv.org/abs/2506.08399", "authors": ["Jiachen Ma", "Zhanhui Zhou", "Chao Yang", "Chaochao Lu"], "title": "SafeCoT: Improving VLM Safety with Minimal Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring safe and appropriate responses from vision-language models (VLMs)\nremains a critical challenge, particularly in high-risk or ambiguous scenarios.\nWe introduce SafeCoT, a lightweight, interpretable framework that leverages\nrule-based chain-of-thought (CoT) supervision to improve refusal behavior in\nVLMs. Unlike prior methods that rely on large-scale safety annotations or\ncomplex modeling, SafeCoT uses minimal supervision to help models reason about\nsafety risks and make context-aware refusals. Experiments across multiple\nbenchmarks show that SafeCoT significantly reduces overrefusal and enhances\ngeneralization, even with limited training data. Our approach offers a scalable\nsolution for aligning VLMs with safety-critical objectives.", "AI": {"tldr": "SafeCoT improves refusal behavior in VLMs using rule-based CoT supervision, reducing overrefusal and enhancing generalization with minimal training data.", "motivation": "Addressing the challenge of ensuring safe and appropriate responses from VLMs in high-risk or ambiguous scenarios.", "method": "Introduces SafeCoT, a lightweight framework leveraging rule-based chain-of-thought supervision for context-aware refusals.", "result": "Significantly reduces overrefusal and enhances generalization across benchmarks, even with limited data.", "conclusion": "SafeCoT provides a scalable solution for aligning VLMs with safety-critical objectives."}}
{"id": "2506.08063", "pdf": "https://arxiv.org/pdf/2506.08063", "abs": "https://arxiv.org/abs/2506.08063", "authors": ["Songqiao Hu", "Zeyi Liu", "Xiao He"], "title": "Lite-RVFL: A Lightweight Random Vector Functional-Link Neural Network for Learning Under Concept Drift", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 4 figures, accepted by the 2025 CAA Symposium on Fault\n  Detection, Supervision and Safety for Technical Processes (SAFEPROCESS 2025)", "summary": "The change in data distribution over time, also known as concept drift, poses\na significant challenge to the reliability of online learning methods. Existing\nmethods typically require model retraining or drift detection, both of which\ndemand high computational costs and are often unsuitable for real-time\napplications. To address these limitations, a lightweight, fast and efficient\nrandom vector functional-link network termed Lite-RVFL is proposed, capable of\nadapting to concept drift without drift detection and retraining. Lite-RVFL\nintroduces a novel objective function that assigns weights exponentially\nincreasing to new samples, thereby emphasizing recent data and enabling timely\nadaptation. Theoretical analysis confirms the feasibility of this objective\nfunction for drift adaptation, and an efficient incremental update rule is\nderived. Experimental results on a real-world safety assessment task validate\nthe efficiency, effectiveness in adapting to drift, and potential to capture\ntemporal patterns of Lite-RVFL. The source code is available at\nhttps://github.com/songqiaohu/Lite-RVFL.", "AI": {"tldr": "Lite-RVFL is a lightweight, fast method for adapting to concept drift in online learning without retraining or drift detection, using an exponential weighting strategy for recent data.", "motivation": "Concept drift in online learning challenges reliability, and existing methods are computationally expensive or unsuitable for real-time applications.", "method": "Lite-RVFL uses a novel objective function with exponential weights for new samples and an efficient incremental update rule.", "result": "Theoretical and experimental validation shows Lite-RVFL efficiently adapts to drift and captures temporal patterns.", "conclusion": "Lite-RVFL offers a practical solution for real-time concept drift adaptation with low computational cost."}}
{"id": "2506.00267", "pdf": "https://arxiv.org/pdf/2506.00267", "abs": "https://arxiv.org/abs/2506.00267", "authors": ["Cihan Xiao", "Ruixing Liang", "Xiangyu Zhang", "Mehmet Emre Tiryaki", "Veronica Bae", "Lavanya Shankar", "Rong Yang", "Ethan Poon", "Emmanuel Dupoux", "Sanjeev Khudanpur", "Leibny Paola Garcia Perera"], "title": "CASPER: A Large Scale Spontaneous Speech Dataset", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "The success of large language models has driven interest in developing\nsimilar speech processing capabilities. However, a key challenge is the\nscarcity of high-quality spontaneous speech data, as most existing datasets\ncontain scripted dialogues. To address this, we present a novel pipeline for\neliciting and recording natural dialogues and release our dataset with 100+\nhours of spontaneous speech. Our approach fosters fluid, natural conversations\nwhile encouraging a diverse range of topics and interactive exchanges. Unlike\ntraditional methods, it facilitates genuine interactions, providing a\nreproducible framework for future data collection. This paper introduces our\ndataset and methodology, laying the groundwork for addressing the shortage of\nspontaneous speech data. We plan to expand this dataset in future stages,\noffering a growing resource for the research community.", "AI": {"tldr": "A novel pipeline for collecting spontaneous speech data is introduced, addressing the scarcity of high-quality natural dialogue datasets.", "motivation": "The lack of spontaneous speech data in existing datasets limits the development of speech processing capabilities.", "method": "A pipeline for eliciting and recording natural dialogues, producing a 100+ hour dataset of diverse, fluid conversations.", "result": "A reproducible framework and dataset for spontaneous speech, fostering future research.", "conclusion": "The dataset and methodology provide a foundation for addressing data scarcity, with plans for expansion."}}
{"id": "2506.08260", "pdf": "https://arxiv.org/pdf/2506.08260", "abs": "https://arxiv.org/abs/2506.08260", "authors": ["Wanjing Anya Ma", "Michael Flor", "Zuowei Wang"], "title": "Automatic Generation of Inference Making Questions for Reading Comprehension Assessments", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to the 20th Workshop on Innovative Use of NLP for Building\n  Educational Applications (BEA 2025), co-located with the ACL 2025", "summary": "Inference making is an essential but complex skill in reading comprehension\n(RC). Some inferences require resolving references across sentences, and some\nrely on using prior knowledge to fill in the detail that is not explicitly\nwritten in the text. Diagnostic RC questions can help educators provide more\neffective and targeted reading instruction and interventions for school-age\nstudents. We introduce a taxonomy of inference types for RC and use it to\nanalyze the distribution of items within a diagnostic RC item bank. Next, we\npresent experiments using GPT-4o to generate bridging-inference RC items for\ngiven reading passages via few-shot prompting, comparing conditions with and\nwithout chain-of-thought prompts. Generated items were evaluated on three\naspects: overall item quality, appropriate inference type, and LLM reasoning,\nachieving high inter-rater agreements above 0.90. Our results show that GPT-4o\nproduced 93.8% good-quality questions suitable for operational use in grade\n3-12 contexts; however, only 42.6% of the generated questions accurately\nmatched the targeted inference type. We conclude that combining automatic item\ngeneration with human judgment offers a promising path toward scalable,\nhigh-quality diagnostic RC assessments.", "AI": {"tldr": "The paper introduces a taxonomy for inference types in reading comprehension (RC) and evaluates GPT-4o's ability to generate diagnostic RC questions, finding high quality but limited accuracy in matching targeted inference types.", "motivation": "To improve reading instruction by developing a scalable method for generating diagnostic RC questions using AI.", "method": "A taxonomy of inference types is created and applied to analyze an RC item bank. GPT-4o is used to generate questions via few-shot prompting, with and without chain-of-thought prompts, and evaluated for quality and inference type accuracy.", "result": "GPT-4o produced 93.8% good-quality questions, but only 42.6% matched the targeted inference type. High inter-rater agreement (above 0.90) was achieved.", "conclusion": "Combining AI-generated items with human judgment is promising for scalable, high-quality RC assessments."}}
{"id": "2506.06407", "pdf": "https://arxiv.org/pdf/2506.06407", "abs": "https://arxiv.org/abs/2506.06407", "authors": ["Zhi Wen Soi", "Chaoyi Zhu", "Fouad Abiad", "Aditya Shankar", "Jeroen M. Galjaard", "Huijuan Wang", "Lydia Y. Chen"], "title": "TimeWak: Temporal Chained-Hashing Watermark for Time Series Data", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MM"], "comment": null, "summary": "Synthetic time series generated by diffusion models enable sharing\nprivacy-sensitive datasets, such as patients' functional MRI records. Key\ncriteria for synthetic data include high data utility and traceability to\nverify the data source. Recent watermarking methods embed in homogeneous latent\nspaces, but state-of-the-art time series generators operate in real space,\nmaking latent-based watermarking incompatible. This creates the challenge of\nwatermarking directly in real space while handling feature heterogeneity and\ntemporal dependencies. We propose TimeWak, the first watermarking algorithm for\nmultivariate time series diffusion models. To handle temporal dependence and\nspatial heterogeneity, TimeWak embeds a temporal chained-hashing watermark\ndirectly within the real temporal-feature space. The other unique feature is\nthe $\\epsilon$-exact inversion, which addresses the non-uniform reconstruction\nerror distribution across features from inverting the diffusion process to\ndetect watermarks. We derive the error bound of inverting multivariate time\nseries and further maintain high watermark detectability. We extensively\nevaluate TimeWak on its impact on synthetic data quality, watermark\ndetectability, and robustness under various post-editing attacks, against 5\ndatasets and baselines of different temporal lengths. Our results show that\nTimeWak achieves improvements of 61.96% in context-FID score, and 8.44% in\ncorrelational scores against the state-of-the-art baseline, while remaining\nconsistently detectable.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.07294", "pdf": "https://arxiv.org/pdf/2506.07294", "abs": "https://arxiv.org/abs/2506.07294", "authors": ["Xuanjun Chen", "I-Ming Lin", "Lin Zhang", "Haibin Wu", "Hung-yi Lee", "Jyh-Shing Roger Jang"], "title": "Towards Generalized Source Tracing for Codec-Based Deepfake Speech", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "comment": "Working in progress", "summary": "Recent attempts at source tracing for codec-based deepfake speech\n(CodecFake), generated by neural audio codec-based speech generation (CoSG)\nmodels, have exhibited suboptimal performance. However, how to train source\ntracing models using simulated CoSG data while maintaining strong performance\non real CoSG-generated audio remains an open challenge. In this paper, we show\nthat models trained solely on codec-resynthesized data tend to overfit to\nnon-speech regions and struggle to generalize to unseen content. To mitigate\nthese challenges, we introduce the Semantic-Acoustic Source Tracing Network\n(SASTNet), which jointly leverages Whisper for semantic feature encoding and\nWav2vec2 with AudioMAE for acoustic feature encoding. Our proposed SASTNet\nachieves state-of-the-art performance on the CoSG test set of the CodecFake+\ndataset, demonstrating its effectiveness for reliable source tracing.", "AI": {"tldr": "SASTNet improves source tracing for deepfake speech by combining semantic and acoustic features, outperforming models trained on codec-resynthesized data.", "motivation": "Existing models for tracing deepfake speech (CodecFake) perform poorly, especially when trained on simulated data. The challenge is maintaining performance on real CoSG-generated audio.", "method": "Proposes SASTNet, which uses Whisper for semantic features and Wav2vec2 with AudioMAE for acoustic features.", "result": "SASTNet achieves state-of-the-art performance on the CoSG test set of CodecFake+.", "conclusion": "SASTNet effectively addresses generalization issues in source tracing for deepfake speech."}}
{"id": "2506.08809", "pdf": "https://arxiv.org/pdf/2506.08809", "abs": "https://arxiv.org/abs/2506.08809", "authors": ["Jiaze E", "Srutarshi Banerjee", "Tekin Bicer", "Guannan Wang", "Yanfu Zhang", "Bin Ren"], "title": "HiSin: Efficient High-Resolution Sinogram Inpainting via Resolution-Guided Progressive Inference", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "High-resolution sinogram inpainting is essential for computed tomography\nreconstruction, as missing high-frequency projections can lead to visible\nartifacts and diagnostic errors. Diffusion models are well-suited for this task\ndue to their robustness and detail-preserving capabilities, but their\napplication to high-resolution inputs is limited by excessive memory and\ncomputational demands. To address this limitation, we propose HiSin, a novel\ndiffusion based framework for efficient sinogram inpainting via\nresolution-guided progressive inference. It progressively extracts global\nstructure at low resolution and defers high-resolution inference to small\npatches, enabling memory-efficient inpainting. It further incorporates\nfrequency-aware patch skipping and structure-adaptive step allocation to reduce\nredundant computation. Experimental results show that HiSin reduces peak memory\nusage by up to 31.25% and inference time by up to 18.15%, and maintains\ninpainting accuracy across datasets, resolutions, and mask conditions.", "AI": {"tldr": "HiSin is a diffusion-based framework for efficient high-resolution sinogram inpainting, reducing memory and computational demands while maintaining accuracy.", "motivation": "Missing high-frequency projections in computed tomography can cause artifacts and diagnostic errors, requiring robust inpainting methods.", "method": "HiSin uses resolution-guided progressive inference, frequency-aware patch skipping, and structure-adaptive step allocation to optimize memory and computation.", "result": "HiSin reduces peak memory usage by 31.25% and inference time by 18.15% without compromising accuracy.", "conclusion": "HiSin effectively addresses the limitations of diffusion models for high-resolution sinogram inpainting, offering practical efficiency gains."}}
{"id": "2506.08220", "pdf": "https://arxiv.org/pdf/2506.08220", "abs": "https://arxiv.org/abs/2506.08220", "authors": ["Octave Mariotti", "Zhipeng Du", "Yash Bhalgat", "Oisin Mac Aodha", "Hakan Bilen"], "title": "Jamais Vu: Exposing the Generalization Gap in Supervised Semantic Correspondence", "categories": ["cs.CV"], "comment": null, "summary": "Semantic correspondence (SC) aims to establish semantically meaningful\nmatches across different instances of an object category. We illustrate how\nrecent supervised SC methods remain limited in their ability to generalize\nbeyond sparsely annotated training keypoints, effectively acting as keypoint\ndetectors. To address this, we propose a novel approach for learning dense\ncorrespondences by lifting 2D keypoints into a canonical 3D space using\nmonocular depth estimation. Our method constructs a continuous canonical\nmanifold that captures object geometry without requiring explicit 3D\nsupervision or camera annotations. Additionally, we introduce SPair-U, an\nextension of SPair-71k with novel keypoint annotations, to better assess\ngeneralization. Experiments not only demonstrate that our model significantly\noutperforms supervised baselines on unseen keypoints, highlighting its\neffectiveness in learning robust correspondences, but that unsupervised\nbaselines outperform supervised counterparts when generalized across different\ndatasets.", "AI": {"tldr": "A novel method for dense semantic correspondence by lifting 2D keypoints into 3D space, outperforming supervised baselines and showing unsupervised methods generalize better across datasets.", "motivation": "Supervised SC methods generalize poorly beyond sparsely annotated keypoints, limiting their effectiveness.", "method": "Lifts 2D keypoints into a canonical 3D space using monocular depth estimation, creating a continuous manifold without 3D supervision.", "result": "Outperforms supervised baselines on unseen keypoints and shows unsupervised methods generalize better across datasets.", "conclusion": "The proposed approach effectively learns robust correspondences and highlights the limitations of supervised methods."}}
{"id": "2506.08401", "pdf": "https://arxiv.org/pdf/2506.08401", "abs": "https://arxiv.org/abs/2506.08401", "authors": ["Runze Li", "Di Jin", "Xiaobao Wang", "Dongxiao He", "Bingdao Feng", "Zhen Wang"], "title": "Single-Node Trigger Backdoor Attacks in Graph-Based Recommendation Systems", "categories": ["cs.AI"], "comment": null, "summary": "Graph recommendation systems have been widely studied due to their ability to\neffectively capture the complex interactions between users and items. However,\nthese systems also exhibit certain vulnerabilities when faced with attacks. The\nprevailing shilling attack methods typically manipulate recommendation results\nby injecting a large number of fake nodes and edges. However, such attack\nstrategies face two primary challenges: low stealth and high destructiveness.\nTo address these challenges, this paper proposes a novel graph backdoor attack\nmethod that aims to enhance the exposure of target items to the target user in\na covert manner, without affecting other unrelated nodes. Specifically, we\ndesign a single-node trigger generator, which can effectively expose multiple\ntarget items to the target user by inserting only one fake user node.\nAdditionally, we introduce constraint conditions between the target nodes and\nirrelevant nodes to mitigate the impact of fake nodes on the recommendation\nsystem's performance. Experimental results show that the exposure of the target\nitems reaches no less than 50% in 99% of the target users, while the impact on\nthe recommendation system's performance is controlled within approximately 5%.", "AI": {"tldr": "A novel graph backdoor attack method is proposed to covertly expose target items to users by inserting a single fake node, minimizing impact on system performance.", "motivation": "Address vulnerabilities in graph recommendation systems caused by low stealth and high destructiveness of existing shilling attacks.", "method": "Design a single-node trigger generator to expose target items with constraints to limit impact on unrelated nodes.", "result": "Target items exposed to 50% of users in 99% of cases, with system performance impact under 5%.", "conclusion": "The method effectively enhances target item exposure covertly while maintaining system performance."}}
{"id": "2506.08070", "pdf": "https://arxiv.org/pdf/2506.08070", "abs": "https://arxiv.org/abs/2506.08070", "authors": ["Ziheng Qin", "Hailun Xu", "Wei Chee Yew", "Qi Jia", "Yang Luo", "Kanchan Sarkar", "Danhui Guan", "Kai Wang", "Yang You"], "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution", "categories": ["cs.LG", "cs.AI"], "comment": "V1", "summary": "Machine learning relies heavily on data, yet the continuous growth of\nreal-world data poses challenges for efficient dataset construction and\ntraining. A fundamental yet unsolved question is: given our current model and\ndata, does a new data (sample/batch) need annotation/learning? Conventional\napproaches retain all available data, leading to non-optimal data and training\nefficiency. Active learning aims to reduce data redundancy by selecting a\nsubset of samples to annotate, while it increases pipeline complexity and\nintroduces bias. In this work, we propose Info-Coevolution, a novel framework\nthat efficiently enables models and data to coevolve through online selective\nannotation with no bias. Leveraging task-specific models (and open-source\nmodels), it selectively annotates and integrates online and web data to improve\ndatasets efficiently. For real-world datasets like ImageNet-1K,\nInfo-Coevolution reduces annotation and training costs by 32\\% without\nperformance loss. It is able to automatically give the saving ratio without\ntuning the ratio. It can further reduce the annotation ratio to 50\\% with\nsemi-supervised learning. We also explore retrieval-based dataset enhancement\nusing unlabeled open-source data. Code is available at\nhttps://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.", "AI": {"tldr": "Info-Coevolution is a framework for efficient dataset annotation and training by selectively annotating data, reducing costs by 32% without performance loss.", "motivation": "Addresses inefficiency in dataset construction and training due to redundant data, aiming to reduce annotation and training costs without bias.", "method": "Proposes Info-Coevolution, which selectively annotates and integrates online/web data using task-specific models, enabling coevolution of models and data.", "result": "Achieves 32% reduction in annotation and training costs on ImageNet-1K, with potential for 50% reduction using semi-supervised learning.", "conclusion": "Info-Coevolution efficiently improves datasets and reduces costs, offering a scalable solution for machine learning data challenges."}}
{"id": "2506.07473", "pdf": "https://arxiv.org/pdf/2506.07473", "abs": "https://arxiv.org/abs/2506.07473", "authors": ["Emmanuel Deruty"], "title": "An introduction to pitch strength in contemporary popular music analysis and production", "categories": ["cs.SD", "eess.AS", "00A65", "J.5"], "comment": "In Music 2024, Innovation in Music Conference, 14-16 June, 2024,\n  Kristiania University College, Oslo, Norway", "summary": "Music information retrieval distinguishes between low- and high-level\ndescriptions of music. Current generative AI models rely on text descriptions\nthat are higher level than the controls familiar to studio musicians. Pitch\nstrength, a low-level perceptual parameter of contemporary popular music, may\nbe one feature that could make such AI models more suited to music production.\nSignal and perceptual analyses suggest that pitch strength (1) varies\nsignificantly across and inside songs; (2) contributes to both small- and\nlarge-scale structure; (3) contributes to the handling of polyphonic\ndissonance; and (4) may be a feature of upper harmonics made audible in a\nperspective of perceptual richness.", "AI": {"tldr": "The paper explores pitch strength as a low-level feature in music, suggesting it could enhance AI models for music production by addressing variability, structure, dissonance, and perceptual richness.", "motivation": "To bridge the gap between high-level text descriptions used in generative AI models and the low-level controls familiar to studio musicians, focusing on pitch strength as a key feature.", "method": "Signal and perceptual analyses were conducted to study pitch strength's role in music.", "result": "Pitch strength varies across songs, contributes to structure and dissonance handling, and may relate to upper harmonics in perceptual richness.", "conclusion": "Pitch strength is a promising low-level feature for improving AI models in music production."}}
{"id": "2506.08300", "pdf": "https://arxiv.org/pdf/2506.08300", "abs": "https://arxiv.org/abs/2506.08300", "authors": ["Matteo Cargnelutti", "Catherine Brobston", "John Hess", "Jack Cushman", "Kristi Mukk", "Aristana Scourtas", "Kyle Courtney", "Greg Leppert", "Amanda Watson", "Martha Whitehead", "Jonathan Zittrain"], "title": "Institutional Books 1.0: A 242B token dataset from Harvard Library's collections, refined for accuracy and usability", "categories": ["cs.CL", "cs.DL"], "comment": null, "summary": "Large language models (LLMs) use data to learn about the world in order to\nproduce meaningful correlations and predictions. As such, the nature, scale,\nquality, and diversity of the datasets used to train these models, or to\nsupport their work at inference time, have a direct impact on their quality.\nThe rapid development and adoption of LLMs of varying quality has brought into\nfocus the scarcity of publicly available, high-quality training data and\nrevealed an urgent need to ground the stewardship of these datasets in\nsustainable practices with clear provenance chains. To that end, this technical\nreport introduces Institutional Books 1.0, a large collection of public domain\nbooks originally digitized through Harvard Library's participation in the\nGoogle Books project, beginning in 2006. Working with Harvard Library, we\nextracted, analyzed, and processed these volumes into an extensively-documented\ndataset of historic texts. This analysis covers the entirety of Harvard\nLibrary's collection scanned as part of that project, originally spanning\n1,075,899 volumes written in over 250 different languages for a total of\napproximately 250 billion tokens. As part of this initial release, the\nOCR-extracted text (original and post-processed) as well as the metadata\n(bibliographic, source, and generated) of the 983,004 volumes, or 242B tokens,\nidentified as being in the public domain have been made available. This report\ndescribes this project's goals and methods as well as the results of the\nanalyses we performed, all in service of making this historical collection more\naccessible and easier for humans and machines alike to filter, read and use.", "AI": {"tldr": "The paper introduces Institutional Books 1.0, a high-quality dataset of public domain books from Harvard Library, addressing the scarcity of training data for LLMs.", "motivation": "The rapid development of LLMs highlights the need for sustainable, high-quality datasets with clear provenance.", "method": "Harvard Library's digitized books were extracted, analyzed, and processed into a well-documented dataset.", "result": "A dataset of 983,004 volumes (242B tokens) with OCR-extracted text and metadata was released.", "conclusion": "The project aims to improve accessibility and usability of historical texts for both humans and machines."}}
{"id": "2410.15873", "pdf": "https://arxiv.org/pdf/2410.15873", "abs": "https://arxiv.org/abs/2410.15873", "authors": ["Anna Meyer", "Andr\u00e9 Kaup"], "title": "Variable Rate Learned Wavelet Video Coding using Temporal Layer Adaptivity", "categories": ["eess.IV"], "comment": "6 pages, 5 figures, ICIP2025", "summary": "Learned wavelet video coders provide an explainable framework by performing\ndiscrete wavelet transforms in temporal, horizontal, and vertical dimensions.\nWith a temporal transform based on motion-compensated temporal filtering\n(MCTF), spatial and temporal scalability is obtained. In this paper, we\nintroduce variable rate support and a mechanism for quality adaption to\ndifferent temporal layers for a higher coding efficiency. Moreover, we propose\na multi-stage training strategy that allows training with multiple temporal\nlayers. Our experiments demonstrate Bj{\\o}ntegaard Delta bitrate savings of at\nleast -32% compared to a learned MCTF model without these extensions. Training\nand inference code is available at: https://github.com/FAU-LMS/Learned-pMCTF.", "AI": {"tldr": "The paper introduces a learned wavelet video coder with variable rate support and quality adaptation, achieving significant bitrate savings.", "motivation": "To enhance coding efficiency and scalability in wavelet-based video coding by introducing variable rate support and quality adaptation.", "method": "Proposes a learned wavelet video coder with motion-compensated temporal filtering (MCTF), variable rate support, and a multi-stage training strategy for multiple temporal layers.", "result": "Achieves Bj\u00f8ntegaard Delta bitrate savings of at least -32% compared to a baseline learned MCTF model.", "conclusion": "The proposed extensions improve coding efficiency and scalability, with code made publicly available."}}
{"id": "2506.08227", "pdf": "https://arxiv.org/pdf/2506.08227", "abs": "https://arxiv.org/abs/2506.08227", "authors": ["Vishaal Udandarao", "Mehdi Cherti", "Shyamgopal Karthik", "Jenia Jitsev", "Samuel Albanie", "Matthias Bethge"], "title": "A Good CREPE needs more than just Sugar: Investigating Biases in Compositional Vision-Language Benchmarks", "categories": ["cs.CV"], "comment": null, "summary": "We investigate 17 benchmarks (e.g. SugarCREPE, VALSE) commonly used for\nmeasuring compositional understanding capabilities of vision-language models\n(VLMs). We scrutinize design choices in their construction, including data\nsource (e.g. MS-COCO) and curation procedures (e.g. constructing negative\nimages/captions), uncovering several inherent biases across most benchmarks. We\nfind that blind heuristics (e.g. token-length, log-likelihood under a language\nmodel) perform on par with CLIP models, indicating that these benchmarks do not\neffectively measure compositional understanding. We demonstrate that the\nunderlying factor is a distribution asymmetry between positive and negative\nimages/captions, induced by the benchmark construction procedures. To mitigate\nthese issues, we provide a few key recommendations for constructing more robust\nvision-language compositional understanding benchmarks, that would be less\nprone to such simple attacks.", "AI": {"tldr": "The paper critiques 17 benchmarks for vision-language models, revealing biases and flaws in their design, and suggests improvements for more robust evaluation.", "motivation": "To evaluate the effectiveness of existing benchmarks in measuring compositional understanding in vision-language models and identify their inherent biases.", "method": "Analysis of design choices in benchmark construction, including data sources and curation procedures, and comparison of heuristic performance with CLIP models.", "result": "Found that benchmarks are flawed due to distribution asymmetry, allowing simple heuristics to perform as well as advanced models.", "conclusion": "Proposes recommendations for creating more robust benchmarks to better assess compositional understanding."}}
{"id": "2506.08422", "pdf": "https://arxiv.org/pdf/2506.08422", "abs": "https://arxiv.org/abs/2506.08422", "authors": ["Ikkei Itoku", "David Theil", "Evelyn Eichelsdoerfer Uehara", "Sreyoshi Bhaduri", "Junnosuke Kuroda", "Toshi Yumoto", "Alex Gil", "Natalie Perez", "Rajesh Cherukuri", "Naumaan Nayyar"], "title": "Transforming Expert Knowledge into Scalable Ontology via Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Having a unified, coherent taxonomy is essential for effective knowledge\nrepresentation in domain-specific applications as diverse terminologies need to\nbe mapped to underlying concepts. Traditional manual approaches to taxonomy\nalignment rely on expert review of concept pairs, but this becomes\nprohibitively expensive and time-consuming at scale, while subjective\ninterpretations often lead to expert disagreements. Existing automated methods\nfor taxonomy alignment have shown promise but face limitations in handling\nnuanced semantic relationships and maintaining consistency across different\ndomains. These approaches often struggle with context-dependent concept\nmappings and lack transparent reasoning processes. We propose a novel framework\nthat combines large language models (LLMs) with expert calibration and\niterative prompt optimization to automate taxonomy alignment. Our method\nintegrates expert-labeled examples, multi-stage prompt engineering, and human\nvalidation to guide LLMs in generating both taxonomy linkages and supporting\nrationales. In evaluating our framework on a domain-specific mapping task of\nconcept essentiality, we achieved an F1-score of 0.97, substantially exceeding\nthe human benchmark of 0.68. These results demonstrate the effectiveness of our\napproach in scaling taxonomy alignment while maintaining high-quality mappings\nand preserving expert oversight for ambiguous cases.", "AI": {"tldr": "A novel framework combining LLMs, expert calibration, and iterative prompt optimization automates taxonomy alignment, achieving high accuracy (F1-score 0.97) and outperforming human benchmarks.", "motivation": "Traditional manual and automated taxonomy alignment methods are costly, time-consuming, or lack nuance. A scalable, high-quality solution is needed.", "method": "Integrates LLMs with expert-labeled examples, multi-stage prompt engineering, and human validation to automate taxonomy alignment and generate rationales.", "result": "Achieved an F1-score of 0.97, significantly surpassing the human benchmark of 0.68 in a domain-specific mapping task.", "conclusion": "The framework effectively scales taxonomy alignment, ensuring high-quality mappings and expert oversight for ambiguous cases."}}
{"id": "2506.08113", "pdf": "https://arxiv.org/pdf/2506.08113", "abs": "https://arxiv.org/abs/2506.08113", "authors": ["Timoth\u00e9e Hornek Amir Sartipi", "Igor Tchappi", "Gilbert Fridgen"], "title": "Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "comment": null, "summary": "Accurate electricity price forecasting (EPF) is crucial for effective\ndecision-making in power trading on the spot market. While recent advances in\ngenerative artificial intelligence (GenAI) and pre-trained large language\nmodels (LLMs) have inspired the development of numerous time series foundation\nmodels (TSFMs) for time series forecasting, their effectiveness in EPF remains\nuncertain. To address this gap, we benchmark several state-of-the-art\npretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and\nTimeGPT--against established statistical and machine learning (ML) methods for\nEPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany,\nFrance, the Netherlands, Austria, and Belgium, we generate daily forecasts with\na one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the\nTSFMs, performing on par with traditional models. However, the biseasonal MSTL\nmodel, which captures daily and weekly seasonality, stands out for its\nconsistent performance across countries and evaluation metrics, with no TSFM\nstatistically outperforming it.", "AI": {"tldr": "Benchmarking pretrained time series foundation models (TSFMs) against traditional methods for electricity price forecasting (EPF) reveals that Chronos-Bolt and Time-MoE perform well, but the biseasonal MSTL model remains the most consistent and effective.", "motivation": "Accurate EPF is vital for power trading, but the effectiveness of recent GenAI and LLM-based TSFMs in this domain is unclear.", "method": "Several pretrained TSFMs (Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, TimeGPT) are benchmarked against statistical and ML methods using 2024 DAA electricity prices from multiple European countries.", "result": "Chronos-Bolt and Time-MoE perform comparably to traditional models, but the biseasonal MSTL model consistently outperforms all TSFMs across metrics and countries.", "conclusion": "While TSFMs show promise, traditional models like MSTL, which capture seasonality, remain superior for EPF."}}
{"id": "2506.08343", "pdf": "https://arxiv.org/pdf/2506.08343", "abs": "https://arxiv.org/abs/2506.08343", "authors": ["Chenlong Wang", "Yuanning Feng", "Dongping Chen", "Zhaoyang Chu", "Ranjay Krishna", "Tianyi Zhou"], "title": "Wait, We Don't Need to \"Wait\"! Removing Thinking Tokens Improves Reasoning Efficiency", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in large reasoning models have enabled complex, step-by-step\nreasoning but often introduce significant overthinking, resulting in verbose\nand redundant outputs that hinder efficiency. In this study, we examine whether\nexplicit self-reflection, signaled by tokens such as \"Wait\" and \"Hmm\", is\nnecessary for advanced reasoning. We propose NoWait, a simple yet effective\napproach that disables explicit self-reflection by suppressing these tokens\nduring inference. Extensive experiments on ten benchmarks across textual,\nvisual, and video reasoning tasks show that NoWait reduces chain-of-thought\ntrajectory length by up to 27%-51% in five R1-style model series, without\ncompromising model utility. NoWait thus offers a plug-and-play solution for\nefficient and utility-preserving multimodal reasoning.", "AI": {"tldr": "NoWait, a method disabling explicit self-reflection tokens like 'Wait' and 'Hmm', reduces reasoning trajectory length by 27%-51% without losing utility.", "motivation": "To address the inefficiency caused by verbose and redundant outputs in large reasoning models.", "method": "Proposes NoWait, which suppresses self-reflection tokens during inference.", "result": "Reduces chain-of-thought trajectory length by 27%-51% across ten benchmarks.", "conclusion": "NoWait is a plug-and-play solution for efficient, utility-preserving multimodal reasoning."}}
{"id": "2505.17683", "pdf": "https://arxiv.org/pdf/2505.17683", "abs": "https://arxiv.org/abs/2505.17683", "authors": ["Dan Yuan", "Yi Feng", "Ziyun Tang"], "title": "Dual Attention Residual U-Net for Accurate Brain Ultrasound Segmentation in IVH Detection", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 pages,6 figures and 3 tables", "summary": "Intraventricular hemorrhage (IVH) is a severe neurological complication among\npremature infants, necessitating early and accurate detection from brain\nultrasound (US) images to improve clinical outcomes. While recent deep learning\nmethods offer promise for computer-aided diagnosis, challenges remain in\ncapturing both local spatial details and global contextual dependencies\ncritical for segmenting brain anatomies. In this work, we propose an enhanced\nResidual U-Net architecture incorporating two complementary attention\nmechanisms: the Convolutional Block Attention Module (CBAM) and a Sparse\nAttention Layer (SAL). The CBAM improves the model's ability to refine spatial\nand channel-wise features, while the SAL introduces a dual-branch design,\nsparse attention filters out low-confidence query-key pairs to suppress noise,\nand dense attention ensures comprehensive information propagation. Extensive\nexperiments on the Brain US dataset demonstrate that our method achieves\nstate-of-the-art segmentation performance, with a Dice score of 89.04% and IoU\nof 81.84% for ventricle region segmentation. These results highlight the\neffectiveness of integrating spatial refinement and attention sparsity for\nrobust brain anatomy detection. Code is available at:\nhttps://github.com/DanYuan001/BrainImgSegment.", "AI": {"tldr": "Proposes an enhanced Residual U-Net with dual attention mechanisms (CBAM and SAL) for IVH segmentation in premature infants, achieving state-of-the-art results.", "motivation": "Early and accurate IVH detection from brain US images is critical for improving clinical outcomes in premature infants.", "method": "Uses a Residual U-Net with CBAM for spatial/channel refinement and SAL for sparse/dense attention to balance local and global features.", "result": "Achieves 89.04% Dice score and 81.84% IoU for ventricle segmentation, outperforming existing methods.", "conclusion": "Integrating spatial refinement and attention sparsity enhances robust brain anatomy detection."}}
{"id": "2506.08257", "pdf": "https://arxiv.org/pdf/2506.08257", "abs": "https://arxiv.org/abs/2506.08257", "authors": ["L. Lao Beyer", "T. Li", "X. Chen", "S. Karaman", "K. He"], "title": "Highly Compressed Tokenizer Can Generate Without Training", "categories": ["cs.CV", "cs.AI"], "comment": "Main manuscript: 9 pages, 7 figures. Appendix: 8 pages, 9 figures. To\n  appear in the Proceedings of the 42nd International Conference on Machine\n  Learning", "summary": "Commonly used image tokenizers produce a 2D grid of spatially arranged\ntokens. In contrast, so-called 1D image tokenizers represent images as highly\ncompressed one-dimensional sequences of as few as 32 discrete tokens. We find\nthat the high degree of compression achieved by a 1D tokenizer with vector\nquantization enables image editing and generative capabilities through\nheuristic manipulation of tokens, demonstrating that even very crude\nmanipulations -- such as copying and replacing tokens between latent\nrepresentations of images -- enable fine-grained image editing by transferring\nappearance and semantic attributes. Motivated by the expressivity of the 1D\ntokenizer's latent space, we construct an image generation pipeline leveraging\ngradient-based test-time optimization of tokens with plug-and-play loss\nfunctions such as reconstruction or CLIP similarity. Our approach is\ndemonstrated for inpainting and text-guided image editing use cases, and can\ngenerate diverse and realistic samples without requiring training of any\ngenerative model.", "AI": {"tldr": "1D image tokenizers compress images into 1D sequences, enabling fine-grained editing and generation via heuristic token manipulation and test-time optimization.", "motivation": "To explore the expressivity and capabilities of 1D tokenizers for image editing and generation without training generative models.", "method": "Uses gradient-based test-time optimization of tokens with plug-and-play loss functions (e.g., reconstruction, CLIP similarity) for tasks like inpainting and text-guided editing.", "result": "Demonstrates fine-grained editing (e.g., appearance transfer) and diverse, realistic image generation without training.", "conclusion": "1D tokenizers offer powerful, training-free solutions for image manipulation and generation."}}
{"id": "2506.08424", "pdf": "https://arxiv.org/pdf/2506.08424", "abs": "https://arxiv.org/abs/2506.08424", "authors": ["Yong Liang Goh", "Zhiguang Cao", "Yining Ma", "Jianan Zhou", "Mohammad Haroon Dupty", "Wee Sun Lee"], "title": "SHIELD: Multi-task Multi-distribution Vehicle Routing Solver with Sparsity and Hierarchy", "categories": ["cs.AI"], "comment": "Accepted in the 42nd International Conference of Machine Learning\n  (ICML)", "summary": "Recent advances toward foundation models for routing problems have shown\ngreat potential of a unified deep model for various VRP variants. However, they\noverlook the complex real-world customer distributions. In this work, we\nadvance the Multi-Task VRP (MTVRP) setting to the more realistic yet\nchallenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduce\nSHIELD, a novel model that leverages both sparsity and hierarchy principles.\nBuilding on a deeper decoder architecture, we first incorporate the\nMixture-of-Depths (MoD) technique to enforce sparsity. This improves both\nefficiency and generalization by allowing the model to dynamically select nodes\nto use or skip each decoder layer, providing the needed capacity to adaptively\nallocate computation for learning the task/distribution specific and shared\nrepresentations. We also develop a context-based clustering layer that exploits\nthe presence of hierarchical structures in the problems to produce better local\nrepresentations. These two designs inductively bias the network to identify key\nfeatures that are common across tasks and distributions, leading to\nsignificantly improved generalization on unseen ones. Our empirical results\ndemonstrate the superiority of our approach over existing methods on 9\nreal-world maps with 16 VRP variants each.", "AI": {"tldr": "SHIELD introduces a novel model for Multi-Task Multi-Distribution VRP (MTMDVRP), leveraging sparsity and hierarchy to improve generalization on unseen tasks and distributions.", "motivation": "Existing foundation models for routing problems overlook complex real-world customer distributions, prompting the need for a more realistic setting (MTMDVRP).", "method": "SHIELD uses a deeper decoder with Mixture-of-Depths (MoD) for sparsity and a context-based clustering layer for hierarchy, improving task/distribution-specific and shared representations.", "result": "Empirical results show SHIELD outperforms existing methods on 9 real-world maps with 16 VRP variants each.", "conclusion": "SHIELD's sparsity and hierarchy principles significantly enhance generalization, making it superior for MTMDVRP."}}
{"id": "2506.08125", "pdf": "https://arxiv.org/pdf/2506.08125", "abs": "https://arxiv.org/abs/2506.08125", "authors": ["Hanbing Liu", "Lang Cao", "Yuanyi Ren", "Mengyu Zhou", "Haoyu Dong", "Xiaojun Ma", "Shi Han", "Dongmei Zhang"], "title": "Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language models have demonstrated impressive reasoning capabilities,\nyet they often suffer from inefficiencies due to unnecessarily verbose or\nredundant outputs. While many works have explored reinforcement learning (RL)\nto enhance reasoning abilities, most primarily focus on improving accuracy,\nwith limited attention to reasoning efficiency. Some existing approaches\nintroduce direct length-based rewards to encourage brevity, but this often\nleads to noticeable drops in accuracy. In this paper, we propose Bingo, an RL\nframework that advances length-based reward design to boost efficient\nreasoning. Bingo incorporates two key mechanisms: a significance-aware length\nreward, which gradually guides the model to reduce only insignificant tokens,\nand a dynamic length reward, which initially encourages elaborate reasoning for\nhard questions but decays over time to improve overall efficiency. Experiments\nacross multiple reasoning benchmarks show that Bingo improves both accuracy and\nefficiency. It outperforms the vanilla reward and several other length-based\nreward baselines in RL, achieving a favorable trade-off between accuracy and\nefficiency. These results underscore the potential of training LLMs explicitly\nfor efficient reasoning.", "AI": {"tldr": "Bingo is an RL framework that improves reasoning efficiency in large language models by using significance-aware and dynamic length rewards, balancing accuracy and brevity.", "motivation": "Existing RL approaches for reasoning often focus on accuracy but neglect efficiency, and direct length-based rewards can harm accuracy. Bingo aims to address this gap.", "method": "Bingo introduces two mechanisms: a significance-aware length reward to reduce insignificant tokens gradually, and a dynamic length reward that adjusts based on question difficulty.", "result": "Experiments show Bingo outperforms baselines, improving both accuracy and efficiency across reasoning benchmarks.", "conclusion": "Bingo demonstrates the potential of explicitly training LLMs for efficient reasoning, achieving a favorable trade-off between accuracy and efficiency."}}
{"id": "2506.08349", "pdf": "https://arxiv.org/pdf/2506.08349", "abs": "https://arxiv.org/abs/2506.08349", "authors": ["Yuxuan Zhou", "Xien Liu", "Chenwei Yan", "Chen Ning", "Xiao Zhang", "Boxun Li", "Xiangling Fu", "Shijin Wang", "Guoping Hu", "Yu Wang", "Ji Wu"], "title": "Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 11 figures. Accepted by ICML 2025", "summary": "Large language models (LLMs) have demonstrated remarkable performance on\nvarious medical benchmarks, but their capabilities across different cognitive\nlevels remain underexplored. Inspired by Bloom's Taxonomy, we propose a\nmulti-cognitive-level evaluation framework for assessing LLMs in the medical\ndomain in this study. The framework integrates existing medical datasets and\nintroduces tasks targeting three cognitive levels: preliminary knowledge grasp,\ncomprehensive knowledge application, and scenario-based problem solving. Using\nthis framework, we systematically evaluate state-of-the-art general and medical\nLLMs from six prominent families: Llama, Qwen, Gemma, Phi, GPT, and DeepSeek.\nOur findings reveal a significant performance decline as cognitive complexity\nincreases across evaluated models, with model size playing a more critical role\nin performance at higher cognitive levels. Our study highlights the need to\nenhance LLMs' medical capabilities at higher cognitive levels and provides\ninsights for developing LLMs suited to real-world medical applications.", "AI": {"tldr": "The paper introduces a multi-cognitive-level evaluation framework for LLMs in the medical domain, revealing performance declines as cognitive complexity increases.", "motivation": "To explore LLMs' capabilities across different cognitive levels in the medical domain, inspired by Bloom's Taxonomy.", "method": "Proposes a framework integrating medical datasets and tasks targeting three cognitive levels, evaluating six LLM families.", "result": "Performance declines with higher cognitive complexity, with model size being more critical at advanced levels.", "conclusion": "Highlights the need to improve LLMs' higher cognitive capabilities for real-world medical applications."}}
{"id": "2505.23916", "pdf": "https://arxiv.org/pdf/2505.23916", "abs": "https://arxiv.org/abs/2505.23916", "authors": ["Charles Bricout", "Samira Ebrahimi Kahou", "Sylvain Bouix"], "title": "Estimation of Head Motion in Structural MRI and its Impact on Cortical Thickness Measurements in Retrospective Data", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Motion-related artifacts are inevitable in Magnetic Resonance Imaging (MRI)\nand can bias automated neuroanatomical metrics such as cortical thickness.\nThese biases can interfere with statistical analysis which is a major concern\nas motion has been shown to be more prominent in certain populations such as\nchildren or individuals with ADHD. Manual review cannot objectively quantify\nmotion in anatomical scans, and existing quantitative automated approaches\noften require specialized hardware or custom acquisition protocols. Here, we\ntrain a 3D convolutional neural network to estimate a summary motion metric in\nretrospective routine research scans by leveraging a large training dataset of\nsynthetically motion-corrupted volumes. We validate our method with one\nheld-out site from our training cohort and with 14 fully independent datasets,\nincluding one with manual ratings, achieving a representative $R^2 = 0.65$\nversus manual labels and significant thickness-motion correlations in 12/15\ndatasets. Furthermore, our predicted motion correlates with subject age in line\nwith prior studies. Our approach generalizes across scanner brands and\nprotocols, enabling objective, scalable motion assessment in structural MRI\nstudies without prospective motion correction. By providing reliable motion\nestimates, our method offers researchers a tool to assess and account for\npotential biases in cortical thickness analyses.", "AI": {"tldr": "A 3D CNN is trained to estimate motion artifacts in MRI scans using synthetic motion-corrupted data, validated across multiple datasets, and shown to generalize across scanner brands and protocols.", "motivation": "Motion artifacts in MRI bias neuroanatomical metrics like cortical thickness, especially in populations like children or ADHD patients, but current methods lack objectivity or require specialized hardware.", "method": "A 3D convolutional neural network is trained on synthetically motion-corrupted MRI volumes to estimate motion metrics, validated on independent datasets including manual ratings.", "result": "Achieved $R^2 = 0.65$ against manual labels, significant thickness-motion correlations in 12/15 datasets, and motion-age correlations aligning with prior studies.", "conclusion": "The method provides scalable, objective motion assessment for structural MRI studies, aiding bias evaluation in cortical thickness analyses."}}
{"id": "2506.08279", "pdf": "https://arxiv.org/pdf/2506.08279", "abs": "https://arxiv.org/abs/2506.08279", "authors": ["Aditi Sundararaman", "Amogh Adishesha", "Andrew Jaegle", "Dan Bigioi", "Hyoung-Kyu Song", "Jon Kyl", "Justin Mao", "Kevin Lan", "Mojtaba Komeili", "ShahRukh Athar", "Sheila Babayan", "Stanislau Beliasau", "William Buchwalter"], "title": "Seeing Voices: Generating A-Roll Video from Audio with Mirage", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Technical report website: mirage.app/research/seeing-voices, product\n  website: mirage.app", "summary": "From professional filmmaking to user-generated content, creators and\nconsumers have long recognized that the power of video depends on the\nharmonious integration of what we hear (the video's audio track) with what we\nsee (the video's image sequence). Current approaches to video generation either\nignore sound to focus on general-purpose but silent image sequence generation\nor address both visual and audio elements but focus on restricted application\ndomains such as re-dubbing. We introduce Mirage, an audio-to-video foundation\nmodel that excels at generating realistic, expressive output imagery from\nscratch given an audio input. When integrated with existing methods for speech\nsynthesis (text-to-speech, or TTS), Mirage results in compelling multimodal\nvideo. When trained on audio-video footage of people talking (A-roll) and\nconditioned on audio containing speech, Mirage generates video of people\ndelivering a believable interpretation of the performance implicit in input\naudio. Our central technical contribution is a unified method for training\nself-attention-based audio-to-video generation models, either from scratch or\ngiven existing weights. This methodology allows Mirage to retain generality as\nan approach to audio-to-video generation while producing outputs of superior\nsubjective quality to methods that incorporate audio-specific architectures or\nloss components specific to people, speech, or details of how images or audio\nare captured. We encourage readers to watch and listen to the results of Mirage\nfor themselves (see paper and comments for links).", "AI": {"tldr": "Mirage is an audio-to-video foundation model that generates realistic, expressive video from audio inputs, outperforming existing methods in quality and generality.", "motivation": "Current video generation methods either ignore sound or are domain-specific. Mirage aims to integrate audio and visual elements for more compelling, general-purpose video generation.", "method": "Mirage uses a unified self-attention-based training approach for audio-to-video generation, either from scratch or with existing weights, without relying on domain-specific architectures or losses.", "result": "Mirage produces high-quality, believable video performances from audio inputs, especially when combined with speech synthesis (TTS).", "conclusion": "Mirage advances audio-to-video generation by offering superior quality and generality, demonstrated through realistic outputs."}}
{"id": "2506.08446", "pdf": "https://arxiv.org/pdf/2506.08446", "abs": "https://arxiv.org/abs/2506.08446", "authors": ["Peng-Yuan Wang", "Tian-Shuo Liu", "Chenyang Wang", "Yi-Di Wang", "Shu Yan", "Cheng-Xing Jia", "Xu-Hui Liu", "Xin-Wei Chen", "Jia-Cheng Xu", "Ziniu Li", "Yang Yu"], "title": "A Survey on Large Language Models for Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Mathematical reasoning has long represented one of the most fundamental and\nchallenging frontiers in artificial intelligence research. In recent years,\nlarge language models (LLMs) have achieved significant advances in this area.\nThis survey examines the development of mathematical reasoning abilities in\nLLMs through two high-level cognitive phases: comprehension, where models gain\nmathematical understanding via diverse pretraining strategies, and answer\ngeneration, which has progressed from direct prediction to step-by-step\nChain-of-Thought (CoT) reasoning. We review methods for enhancing mathematical\nreasoning, ranging from training-free prompting to fine-tuning approaches such\nas supervised fine-tuning and reinforcement learning, and discuss recent work\non extended CoT and \"test-time scaling\". Despite notable progress, fundamental\nchallenges remain in terms of capacity, efficiency, and generalization. To\naddress these issues, we highlight promising research directions, including\nadvanced pretraining and knowledge augmentation techniques, formal reasoning\nframeworks, and meta-generalization through principled learning paradigms. This\nsurvey tries to provide some insights for researchers interested in enhancing\nreasoning capabilities of LLMs and for those seeking to apply these techniques\nto other domains.", "AI": {"tldr": "The survey explores the development of mathematical reasoning in large language models (LLMs), covering comprehension and answer generation phases, and reviews methods like prompting and fine-tuning. Challenges remain, and future directions are suggested.", "motivation": "To understand and enhance the mathematical reasoning capabilities of LLMs, addressing fundamental challenges and exploring new research directions.", "method": "Review of methods including training-free prompting, supervised fine-tuning, reinforcement learning, and advanced techniques like Chain-of-Thought (CoT) reasoning.", "result": "Notable progress in mathematical reasoning, but challenges in capacity, efficiency, and generalization persist.", "conclusion": "Promising future directions include advanced pretraining, formal reasoning frameworks, and meta-generalization to further improve LLMs' reasoning abilities."}}
{"id": "2506.08139", "pdf": "https://arxiv.org/pdf/2506.08139", "abs": "https://arxiv.org/abs/2506.08139", "authors": ["Aviad Susman", "Mayte Su\u00e1rez-Fari\u00f1as", "Joseph T Colonel"], "title": "Nearness of Neighbors Attention for Regression in Supervised Finetuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "It is common in supervised machine learning to combine the feature extraction\ncapabilities of neural networks with the predictive power of traditional\nalgorithms, such as k-nearest neighbors (k-NN) or support vector machines. This\nprocedure involves performing supervised fine-tuning (SFT) on a\ndomain-appropriate feature extractor, followed by training a traditional\npredictor on the resulting SFT embeddings. When used in this manner,\ntraditional predictors often deliver increased performance over the SFT model\nitself, despite the fine-tuned feature extractor yielding embeddings\nspecifically optimized for prediction by the neural network's final dense\nlayer. This suggests that directly incorporating traditional algorithms into\nSFT as prediction layers may further improve performance. However, many\ntraditional algorithms have not been implemented as neural network layers due\nto their non-differentiable nature and their unique optimization requirements.\nAs a step towards solving this problem, we introduce the Nearness of Neighbors\nAttention (NONA) regression layer. NONA uses the mechanics of neural network\nattention and a novel learned attention-masking scheme to yield a\ndifferentiable proxy of the k-NN regression algorithm. Results on multiple\nunstructured datasets show improved performance over both dense layer\nprediction and k-NN on SFT embeddings for regression.", "AI": {"tldr": "Combining neural networks with traditional algorithms like k-NN can boost performance. The paper introduces NONA, a differentiable k-NN proxy, showing improved results.", "motivation": "Traditional predictors often outperform neural networks when used with SFT embeddings, suggesting integrating them into SFT could enhance performance.", "method": "Introduces NONA, a differentiable regression layer mimicking k-NN using neural attention and learned masking.", "result": "NONA outperforms both dense layers and k-NN on SFT embeddings in regression tasks.", "conclusion": "NONA successfully bridges the gap between traditional algorithms and neural networks, offering a differentiable solution for improved performance."}}
{"id": "2506.08354", "pdf": "https://arxiv.org/pdf/2506.08354", "abs": "https://arxiv.org/abs/2506.08354", "authors": ["Yiqun Sun", "Qiang Huang", "Anthony K. H. Tung", "Jun Yu"], "title": "Text Embeddings Should Capture Implicit Semantics, Not Just Surface Meaning", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "This position paper argues that the text embedding research community should\nmove beyond surface meaning and embrace implicit semantics as a central\nmodeling goal. Text embedding models have become foundational in modern NLP,\npowering a wide range of applications and drawing increasing research\nattention. Yet, much of this progress remains narrowly focused on surface-level\nsemantics. In contrast, linguistic theory emphasizes that meaning is often\nimplicit, shaped by pragmatics, speaker intent, and sociocultural context.\nCurrent embedding models are typically trained on data that lacks such depth\nand evaluated on benchmarks that reward the capture of surface meaning. As a\nresult, they struggle with tasks requiring interpretive reasoning, speaker\nstance, or social meaning. Our pilot study highlights this gap, showing that\neven state-of-the-art models perform only marginally better than simplistic\nbaselines on implicit semantics tasks. To address this, we call for a paradigm\nshift: embedding research should prioritize more diverse and linguistically\ngrounded training data, design benchmarks that evaluate deeper semantic\nunderstanding, and explicitly frame implicit meaning as a core modeling\nobjective, better aligning embeddings with real-world language complexity.", "AI": {"tldr": "The paper advocates for a shift in text embedding research to focus on implicit semantics, beyond surface-level meaning, to better align with real-world language complexity.", "motivation": "Current text embedding models focus on surface-level semantics, neglecting implicit meaning shaped by pragmatics, intent, and context, leading to poor performance on deeper semantic tasks.", "method": "The authors highlight the gap through a pilot study comparing state-of-the-art models to simplistic baselines on implicit semantics tasks.", "result": "State-of-the-art models perform only marginally better than baselines on tasks requiring implicit meaning.", "conclusion": "The paper calls for a paradigm shift: diverse training data, linguistically grounded benchmarks, and explicit modeling of implicit semantics to improve embeddings."}}
{"id": "2506.08297", "pdf": "https://arxiv.org/pdf/2506.08297", "abs": "https://arxiv.org/abs/2506.08297", "authors": ["Nhat Thanh Tran", "Fanghui Xue", "Shuai Zhang", "Jiancheng Lyu", "Yunling Zheng", "Yingyong Qi", "Jack Xin"], "title": "SEMA: a Scalable and Efficient Mamba like Attention via Token Localization and Averaging", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, figures 3", "summary": "Attention is the critical component of a transformer. Yet the quadratic\ncomputational complexity of vanilla full attention in the input size and the\ninability of its linear attention variant to focus have been challenges for\ncomputer vision tasks. We provide a mathematical definition of generalized\nattention and formulate both vanilla softmax attention and linear attention\nwithin the general framework. We prove that generalized attention disperses,\nthat is, as the number of keys tends to infinity, the query assigns equal\nweights to all keys. Motivated by the dispersion property and recent\ndevelopment of Mamba form of attention, we design Scalable and Efficient Mamba\nlike Attention (SEMA) which utilizes token localization to avoid dispersion and\nmaintain focusing, complemented by theoretically consistent arithmetic\naveraging to capture global aspect of attention. We support our approach on\nImagenet-1k where classification results show that SEMA is a scalable and\neffective alternative beyond linear attention, outperforming recent vision\nMamba models on increasingly larger scales of images at similar model parameter\nsizes.", "AI": {"tldr": "The paper introduces SEMA, a scalable and efficient attention mechanism for computer vision, addressing the limitations of vanilla and linear attention by leveraging token localization and arithmetic averaging.", "motivation": "The quadratic complexity of vanilla attention and the lack of focus in linear attention pose challenges for vision tasks. The dispersion property of generalized attention further motivates the need for a better solution.", "method": "SEMA is designed with token localization to prevent dispersion and maintain focus, combined with arithmetic averaging to capture global attention aspects.", "result": "SEMA outperforms recent vision Mamba models on Imagenet-1k, demonstrating scalability and effectiveness, especially for larger image scales.", "conclusion": "SEMA is a viable alternative to linear attention, offering improved performance and scalability for vision tasks."}}
{"id": "2506.08462", "pdf": "https://arxiv.org/pdf/2506.08462", "abs": "https://arxiv.org/abs/2506.08462", "authors": ["Christos Margadji", "Sebastian W. Pattinson"], "title": "Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing", "categories": ["cs.AI", "cs.HC", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Industrial processes must be robust and adaptable, as environments and tasks\nare often unpredictable, while operational errors remain costly and difficult\nto detect. AI-based control systems offer a path forward, yet typically depend\non supervised learning with extensive labelled datasets, which limits their\nability to generalize across variable and data-scarce industrial settings.\nFoundation models could enable broader reasoning and knowledge integration, but\nrarely deliver the quantitative precision demanded by engineering applications.\nHere, we introduceControl and Interpretation of Production via Hybrid Expertise\nand Reasoning (CIPHER): a vision-language-action (VLA) model framework aiming\nto replicate human-like reasoning for industrial control, instantiated in a\ncommercial-grade 3D printer. It integrates a process expert, a regression model\nenabling quantitative characterization of system states required for\nengineering tasks. CIPHER also incorporates retrieval-augmented generation to\naccess external expert knowledge and support physics-informed, chain-of-thought\nreasoning. This hybrid architecture exhibits strong generalization to\nout-of-distribution tasks. It interprets visual or textual inputs from process\nmonitoring, explains its decisions, and autonomously generates precise machine\ninstructions, without requiring explicit annotations. CIPHER thus lays the\nfoundations for autonomous systems that act with precision, reason with\ncontext, and communicate decisions transparently, supporting safe and trusted\ndeployment in industrial settings.", "AI": {"tldr": "CIPHER is a hybrid AI framework for industrial control, combining vision-language-action models with expert knowledge for precise, adaptable, and explainable automation.", "motivation": "Industrial processes need robust, adaptable control systems, but current AI lacks generalization and precision.", "method": "CIPHER integrates a process expert, regression model, and retrieval-augmented generation for physics-informed reasoning.", "result": "It generalizes well to out-of-distribution tasks, interprets inputs, explains decisions, and generates precise instructions without annotations.", "conclusion": "CIPHER enables autonomous, precise, and transparent industrial systems, supporting safe deployment."}}
{"id": "2506.08140", "pdf": "https://arxiv.org/pdf/2506.08140", "abs": "https://arxiv.org/abs/2506.08140", "authors": ["Yifei Li", "Hanane Nour Moussa", "Ziru Chen", "Shijie Chen", "Botao Yu", "Mingyi Xue", "Benjamin Burns", "Tzu-Yao Chiu", "Vishal Dey", "Zitong Lu", "Chen Wei", "Qianheng Zhang", "Tianyu Zhang", "Song Gao", "Xuhui Huang", "Xia Ning", "Nesreen K. Ahmed", "Ali Payani", "Huan Sun"], "title": "AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Despite long-standing efforts in accelerating scientific discovery with AI,\nbuilding AI co-scientists remains challenging due to limited high-quality data\nfor training and evaluation. To tackle this data scarcity issue, we present\nAutoSDT, an automatic pipeline that collects high-quality coding tasks in\nreal-world data-driven discovery workflows. AutoSDT leverages the coding\ncapabilities and parametric knowledge of LLMs to search for diverse sources,\nselect ecologically valid tasks, and synthesize accurate task instructions and\ncode solutions. Using our pipeline, we construct AutoSDT-5K, a dataset of 5,404\ncoding tasks for data-driven discovery that covers four scientific disciplines\nand 756 unique Python packages. To the best of our knowledge, AutoSDT-5K is the\nonly automatically collected and the largest open dataset for data-driven\nscientific discovery. Expert feedback on a subset of 256 tasks shows the\neffectiveness of AutoSDT: 93% of the collected tasks are ecologically valid,\nand 92.2% of the synthesized programs are functionally correct. Trained on\nAutoSDT-5K, the Qwen2.5-Coder-Instruct LLM series, dubbed AutoSDT-Coder, show\nsubstantial improvement on two challenging data-driven discovery benchmarks,\nScienceAgentBench and DiscoveryBench. Most notably, AutoSDT-Coder-32B reaches\nthe same level of performance as GPT-4o on ScienceAgentBench with a success\nrate of 7.8%, doubling the performance of its base model. On DiscoveryBench, it\nlifts the hypothesis matching score to 8.1, bringing a 17.4% relative\nimprovement and closing the gap between open-weight models and GPT-4o.", "AI": {"tldr": "AutoSDT is an AI pipeline for creating high-quality coding tasks for scientific discovery, resulting in the AutoSDT-5K dataset. It improves LLM performance on benchmarks, matching GPT-4o in some cases.", "motivation": "Addressing data scarcity in AI-driven scientific discovery by automating the collection of high-quality coding tasks.", "method": "AutoSDT uses LLMs to search, select, and synthesize tasks and solutions, creating the AutoSDT-5K dataset.", "result": "AutoSDT-5K contains 5,404 tasks; 93% are valid, and 92.2% of programs are correct. AutoSDT-Coder models show significant benchmark improvements.", "conclusion": "AutoSDT effectively tackles data scarcity, enhancing AI performance in scientific discovery, with results comparable to GPT-4o."}}
{"id": "2506.08359", "pdf": "https://arxiv.org/pdf/2506.08359", "abs": "https://arxiv.org/abs/2506.08359", "authors": ["Li-Ming Zhan", "Bo Liu", "Zexin Lu", "Chengqiang Xie", "Jiannong Cao", "Xiao-Ming Wu"], "title": "DEAL: Disentangling Transformer Head Activations for LLM Steering", "categories": ["cs.CL"], "comment": "Preprint", "summary": "Inference-time steering aims to alter the response characteristics of large\nlanguage models (LLMs) without modifying their underlying parameters. A\ncritical step in this process is the identification of internal modules within\nLLMs that are associated with the target behavior. However, current approaches\nto module selection often depend on superficial cues or ad-hoc heuristics,\nwhich can result in suboptimal or unintended outcomes. In this work, we propose\na principled causal-attribution framework for identifying behavior-relevant\nattention heads in transformers. For each head, we train a vector-quantized\nautoencoder (VQ-AE) on its attention activations, partitioning the latent space\ninto behavior-relevant and behavior-irrelevant subspaces, each quantized with a\nshared learnable codebook. We assess the behavioral relevance of each head by\nquantifying the separability of VQ-AE encodings for behavior-aligned versus\nbehavior-violating responses using a binary classification metric. This yields\na behavioral relevance score that reflects each head discriminative capacity\nwith respect to the target behavior, guiding both selection and importance\nweighting. Experiments on seven LLMs from two model families and five\nbehavioral steering datasets demonstrate that our method enables more accurate\ninference-time interventions, achieving superior performance on the\ntruthfulness-steering task. Furthermore, the heads selected by our approach\nexhibit strong zero-shot generalization in cross-domain truthfulness-steering\nscenarios.", "AI": {"tldr": "A causal-attribution framework identifies behavior-relevant attention heads in LLMs using VQ-AE and binary classification, improving inference-time steering accuracy.", "motivation": "Current module selection methods for LLM behavior steering rely on superficial cues, leading to suboptimal outcomes. A principled approach is needed.", "method": "Train VQ-AE on attention activations, partition latent space, and use binary classification to score heads' behavioral relevance.", "result": "Superior performance in truthfulness-steering tasks and strong zero-shot generalization in cross-domain scenarios.", "conclusion": "The framework enables more accurate inference-time interventions by identifying and weighting behavior-relevant heads."}}
{"id": "2506.08299", "pdf": "https://arxiv.org/pdf/2506.08299", "abs": "https://arxiv.org/abs/2506.08299", "authors": ["Kangning Yang", "Ling Ouyang", "Huiming Sun", "Jie Cai", "Lan Fu", "Jiaming Ding", "Chiu Man Ho", "Zibo Meng"], "title": "OpenRR-1k: A Scalable Dataset for Real-World Reflection Removal", "categories": ["cs.CV"], "comment": null, "summary": "Reflection removal technology plays a crucial role in photography and\ncomputer vision applications. However, existing techniques are hindered by the\nlack of high-quality in-the-wild datasets. In this paper, we propose a novel\nparadigm for collecting reflection datasets from a fresh perspective. Our\napproach is convenient, cost-effective, and scalable, while ensuring that the\ncollected data pairs are of high quality, perfectly aligned, and represent\nnatural and diverse scenarios. Following this paradigm, we collect a\nReal-world, Diverse, and Pixel-aligned dataset (named OpenRR-1k dataset), which\ncontains 1,000 high-quality transmission-reflection image pairs collected in\nthe wild. Through the analysis of several reflection removal methods and\nbenchmark evaluation experiments on our dataset, we demonstrate its\neffectiveness in improving robustness in challenging real-world environments.\nOur dataset is available at https://github.com/caijie0620/OpenRR-1k.", "AI": {"tldr": "The paper introduces a new method for collecting high-quality reflection datasets, resulting in the OpenRR-1k dataset, which improves reflection removal robustness in real-world scenarios.", "motivation": "Existing reflection removal techniques lack high-quality in-the-wild datasets, limiting their effectiveness.", "method": "A novel paradigm for collecting reflection datasets that is convenient, cost-effective, and scalable, ensuring high-quality, aligned, and diverse image pairs.", "result": "The OpenRR-1k dataset with 1,000 high-quality transmission-reflection pairs is created and shown to enhance reflection removal robustness.", "conclusion": "The proposed dataset and collection method effectively address the limitations of existing techniques, improving performance in real-world environments."}}
{"id": "2506.08486", "pdf": "https://arxiv.org/pdf/2506.08486", "abs": "https://arxiv.org/abs/2506.08486", "authors": ["Rahatara Ferdousi", "M Anwar Hossain"], "title": "RHealthTwin: Towards Responsible and Multimodal Digital Twins for Personalized Well-being", "categories": ["cs.AI", "68T50, 92C50, 68T01 68T50, 92C50, 68T01 68T50, 92C50, 68T01", "I.2.7; J.3; I.5.1"], "comment": "18 pages, 12 figures, IEEE EMBS JBHI", "summary": "The rise of large language models (LLMs) has created new possibilities for\ndigital twins in healthcare. However, the deployment of such systems in\nconsumer health contexts raises significant concerns related to hallucination,\nbias, lack of transparency, and ethical misuse. In response to recommendations\nfrom health authorities such as the World Health Organization (WHO), we propose\nResponsible Health Twin (RHealthTwin), a principled framework for building and\ngoverning AI-powered digital twins for well-being assistance. RHealthTwin\nprocesses multimodal inputs that guide a health-focused LLM to produce safe,\nrelevant, and explainable responses. At the core of RHealthTwin is the\nResponsible Prompt Engine (RPE), which addresses the limitations of traditional\nLLM configuration. Conventionally, users input unstructured prompt and the\nsystem instruction to configure the LLM, which increases the risk of\nhallucination. In contrast, RPE extracts predefined slots dynamically to\nstructure both inputs. This guides the language model to generate responses\nthat are context aware, personalized, fair, reliable, and explainable for\nwell-being assistance. The framework further adapts over time through a\nfeedback loop that updates the prompt structure based on user satisfaction. We\nevaluate RHealthTwin across four consumer health domains including mental\nsupport, symptom triage, nutrition planning, and activity coaching. RPE\nachieves state-of-the-art results with BLEU = 0.41, ROUGE-L = 0.63, and\nBERTScore = 0.89 on benchmark datasets. Also, we achieve over 90% in ethical\ncompliance and instruction-following metrics using LLM-as-judge evaluation,\noutperforming baseline strategies. We envision RHealthTwin as a forward-looking\nfoundation for responsible LLM-based applications in health and well-being.", "AI": {"tldr": "RHealthTwin is a framework for responsible AI-powered digital twins in healthcare, addressing hallucination, bias, and ethical concerns with a dynamic prompt engine (RPE) and achieving high performance and compliance.", "motivation": "To mitigate risks like hallucination and bias in LLM-based healthcare applications, aligning with WHO recommendations for ethical AI use.", "method": "Proposes RHealthTwin with a Responsible Prompt Engine (RPE) to structure inputs dynamically, ensuring context-aware, fair, and explainable responses. Includes a feedback loop for continuous improvement.", "result": "Achieves state-of-the-art results (BLEU=0.41, ROUGE-L=0.63, BERTScore=0.89) and over 90% ethical compliance, outperforming baselines.", "conclusion": "RHealthTwin provides a responsible foundation for LLM-based healthcare applications, ensuring safety and reliability."}}
{"id": "2506.08143", "pdf": "https://arxiv.org/pdf/2506.08143", "abs": "https://arxiv.org/abs/2506.08143", "authors": ["Francesco Tonin", "Alex Lambert", "Johan A. K. Suykens", "Volkan Cevher"], "title": "Accelerating Spectral Clustering under Fairness Constraints", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Fairness of decision-making algorithms is an increasingly important issue. In\nthis paper, we focus on spectral clustering with group fairness constraints,\nwhere every demographic group is represented in each cluster proportionally as\nin the general population. We present a new efficient method for fair spectral\nclustering (Fair SC) by casting the Fair SC problem within the difference of\nconvex functions (DC) framework. To this end, we introduce a novel variable\naugmentation strategy and employ an alternating direction method of multipliers\ntype of algorithm adapted to DC problems. We show that each associated\nsubproblem can be solved efficiently, resulting in higher computational\nefficiency compared to prior work, which required a computationally expensive\neigendecomposition. Numerical experiments demonstrate the effectiveness of our\napproach on both synthetic and real-world benchmarks, showing significant\nspeedups in computation time over prior art, especially as the problem size\ngrows. This work thus represents a considerable step forward towards the\nadoption of fair clustering in real-world applications.", "AI": {"tldr": "A new efficient method for fair spectral clustering (Fair SC) is introduced, leveraging a difference of convex functions (DC) framework and an augmented variable strategy for computational efficiency.", "motivation": "Addressing fairness in decision-making algorithms, particularly ensuring proportional representation of demographic groups in clustering.", "method": "Proposes Fair SC using a DC framework, novel variable augmentation, and an adapted alternating direction method of multipliers algorithm.", "result": "Achieves higher computational efficiency and significant speedups, especially for larger problem sizes, compared to prior methods.", "conclusion": "Represents a major advancement for practical adoption of fair clustering in real-world applications."}}
{"id": "2506.08364", "pdf": "https://arxiv.org/pdf/2506.08364", "abs": "https://arxiv.org/abs/2506.08364", "authors": ["Jash Rajesh Parekh", "Pengcheng Jiang", "Jiawei Han"], "title": "CC-RAG: Structured Multi-Hop Reasoning via Theme-Based Causal Graphs", "categories": ["cs.CL"], "comment": null, "summary": "Understanding cause and effect relationships remains a formidable challenge\nfor Large Language Models (LLMs), particularly in specialized domains where\nreasoning requires more than surface-level correlations. Retrieval-Augmented\nGeneration (RAG) improves factual accuracy, but standard RAG pipelines treat\nevidence as flat context, lacking the structure required to model true causal\ndependencies. We introduce Causal-Chain RAG (CC-RAG), a novel approach that\nintegrates zero-shot triple extraction and theme-aware graph chaining into the\nRAG pipeline, enabling structured multi-hop inference. Given a domain specific\ncorpus, CC-RAG constructs a Directed Acyclic Graph (DAG) of <cause, relation,\neffect> triples and uses forward/backward chaining to guide structured answer\ngeneration. Experiments on two real-world domains: Bitcoin price fluctuations\nand Gaucher disease, show that CC-RAG outperforms standard RAG and zero-shot\nLLMs in chain similarity, information density, and lexical diversity. Both\nLLM-as-a-Judge and human evaluations consistently favor CC-RAG. Our results\ndemonstrate that explicitly modeling causal structure enables LLMs to generate\nmore accurate and interpretable responses, especially in specialized domains\nwhere flat retrieval fails.", "AI": {"tldr": "CC-RAG improves causal reasoning in LLMs by structuring evidence into a DAG of cause-effect triples, outperforming standard RAG and zero-shot LLMs.", "motivation": "Addressing the challenge of LLMs in understanding causal relationships, especially in specialized domains where flat context retrieval is insufficient.", "method": "Integrates zero-shot triple extraction and theme-aware graph chaining into RAG, constructing a DAG of <cause, relation, effect> triples for structured multi-hop inference.", "result": "Outperforms standard RAG and zero-shot LLMs in chain similarity, information density, and lexical diversity, validated by LLM and human evaluations.", "conclusion": "Explicitly modeling causal structure enhances LLM accuracy and interpretability, particularly in specialized domains."}}
{"id": "2506.08324", "pdf": "https://arxiv.org/pdf/2506.08324", "abs": "https://arxiv.org/abs/2506.08324", "authors": ["Guandong Li", "Mengxia Ye"], "title": "Hyperspectral Image Classification via Transformer-based Spectral-Spatial Attention Decoupling and Adaptive Gating", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2504.15155,\n  arXiv:2504.13045, arXiv:2503.23472", "summary": "Deep neural networks face several challenges in hyperspectral image\nclassification, including high-dimensional data, sparse distribution of ground\nobjects, and spectral redundancy, which often lead to classification\noverfitting and limited generalization capability. To more effectively extract\nand fuse spatial context with fine spectral information in hyperspectral image\n(HSI) classification, this paper proposes a novel network architecture called\nSTNet. The core advantage of STNet stems from the dual innovative design of its\nSpatial-Spectral Transformer module: first, the fundamental explicit decoupling\nof spatial and spectral attention ensures targeted capture of key information\nin HSI; second, two functionally distinct gating mechanisms perform intelligent\nregulation at both the fusion level of attention flows (adaptive attention\nfusion gating) and the internal level of feature transformation (GFFN). This\ncharacteristic demonstrates superior feature extraction and fusion capabilities\ncompared to traditional convolutional neural networks, while reducing\noverfitting risks in small-sample and high-noise scenarios. STNet enhances\nmodel representation capability without increasing network depth or width. The\nproposed method demonstrates superior performance on IN, UP, and KSC datasets,\noutperforming mainstream hyperspectral image classification approaches.", "AI": {"tldr": "STNet, a novel network architecture, addresses hyperspectral image classification challenges by decoupling spatial-spectral attention and using gating mechanisms, outperforming traditional methods.", "motivation": "Challenges like high-dimensional data, sparse ground objects, and spectral redundancy in hyperspectral image classification lead to overfitting and limited generalization.", "method": "STNet uses a Spatial-Spectral Transformer module with decoupled attention and gating mechanisms (adaptive attention fusion gating and GFFN) for targeted feature extraction and fusion.", "result": "STNet outperforms mainstream methods on IN, UP, and KSC datasets, enhancing representation without increasing network depth or width.", "conclusion": "STNet effectively addresses hyperspectral classification challenges, reducing overfitting and improving generalization with innovative attention and gating designs."}}
{"id": "2506.08518", "pdf": "https://arxiv.org/pdf/2506.08518", "abs": "https://arxiv.org/abs/2506.08518", "authors": ["Sunny Gupta", "Nikita Jangid", "Shounak Das", "Amit Sethi"], "title": "FEDTAIL: Federated Long-Tailed Domain Generalization with Sharpness-Guided Gradient Matching", "categories": ["cs.AI", "cs.CV", "cs.LG", "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"], "comment": "Accepted at ICML 2025 Workshop on Collaborative and Federated Agentic\n  Workflows CFAgentic @ ICML'25", "summary": "Domain Generalization (DG) seeks to train models that perform reliably on\nunseen target domains without access to target data during training. While\nrecent progress in smoothing the loss landscape has improved generalization,\nexisting methods often falter under long-tailed class distributions and\nconflicting optimization objectives. We introduce FedTAIL, a federated domain\ngeneralization framework that explicitly addresses these challenges through\nsharpness-guided, gradient-aligned optimization. Our method incorporates a\ngradient coherence regularizer to mitigate conflicts between classification and\nadversarial objectives, leading to more stable convergence. To combat class\nimbalance, we perform class-wise sharpness minimization and propose a\ncurvature-aware dynamic weighting scheme that adaptively emphasizes\nunderrepresented tail classes. Furthermore, we enhance conditional distribution\nalignment by integrating sharpness-aware perturbations into entropy\nregularization, improving robustness under domain shift. FedTAIL unifies\noptimization harmonization, class-aware regularization, and conditional\nalignment into a scalable, federated-compatible framework. Extensive\nevaluations across standard domain generalization benchmarks demonstrate that\nFedTAIL achieves state-of-the-art performance, particularly in the presence of\ndomain shifts and label imbalance, validating its effectiveness in both\ncentralized and federated settings. Code: https://github.com/sunnyinAI/FedTail", "AI": {"tldr": "FedTAIL is a federated domain generalization framework addressing class imbalance and conflicting objectives through sharpness-guided, gradient-aligned optimization.", "motivation": "Existing DG methods struggle with long-tailed class distributions and conflicting optimization goals.", "method": "FedTAIL uses gradient coherence regularization, class-wise sharpness minimization, and curvature-aware dynamic weighting. It also integrates sharpness-aware perturbations for conditional alignment.", "result": "FedTAIL achieves state-of-the-art performance on DG benchmarks, especially under domain shifts and label imbalance.", "conclusion": "FedTAIL effectively unifies optimization harmonization, class-aware regularization, and conditional alignment, proving robust in both centralized and federated settings."}}
{"id": "2506.08146", "pdf": "https://arxiv.org/pdf/2506.08146", "abs": "https://arxiv.org/abs/2506.08146", "authors": ["Vahidullah Ta\u00e7", "Amirhossein Amiri-Hezaveh", "Manuel K. Rausch", "Grace N. Bechtel", "Francisco Sahli Costabal", "Adrian Buganza Tepole"], "title": "Fully data-driven inverse hyperelasticity with hyper-network neural ODE fields", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "We propose a new framework for identifying mechanical properties of\nheterogeneous materials without a closed-form constitutive equation. Given a\nfull-field measurement of the displacement field, for instance as obtained from\ndigital image correlation (DIC), a continuous approximation of the strain field\nis obtained by training a neural network that incorporates Fourier features to\neffectively capture sharp gradients in the data. A physics-based data-driven\nmethod built upon ordinary neural differential equations (NODEs) is employed to\ndiscover constitutive equations. The NODE framework can represent arbitrary\nmaterials while satisfying constraints in the theory of constitutive equations\nby default. To account for heterogeneity, a hyper-network is defined, where the\ninput is the material coordinate system, and the output is the NODE-based\nconstitutive equation. The parameters of the hyper-network are optimized by\nminimizing a multi-objective loss function that includes penalty terms for\nviolations of the strong form of the equilibrium equations of elasticity and\nthe associated Neumann boundary conditions. We showcase the framework with\nseveral numerical examples, including heterogeneity arising from variations in\nmaterial parameters, spatial transitions from isotropy to anisotropy, material\nidentification in the presence of noise, and, ultimately, application to\nexperimental data. As the numerical results suggest, the proposed approach is\nrobust and general in identifying the mechanical properties of heterogeneous\nmaterials with very few assumptions, making it a suitable alternative to\nclassical inverse methods.", "AI": {"tldr": "A novel framework uses neural networks and physics-based data-driven methods to identify mechanical properties of heterogeneous materials without closed-form constitutive equations.", "motivation": "Traditional methods require closed-form constitutive equations, which are often unavailable for heterogeneous materials. The proposed framework aims to overcome this limitation.", "method": "Combines Fourier-feature neural networks for strain field approximation and NODEs for constitutive equation discovery, using a hyper-network for heterogeneity. A multi-objective loss function ensures physical constraints.", "result": "Demonstrated robustness in identifying mechanical properties for various heterogeneous scenarios, including noisy data and experimental applications.", "conclusion": "The framework is a robust, general alternative to classical inverse methods for heterogeneous material analysis."}}
{"id": "2506.08371", "pdf": "https://arxiv.org/pdf/2506.08371", "abs": "https://arxiv.org/abs/2506.08371", "authors": ["Zikai Xiao", "Ziyang Wang", "Wen Ma", "Yan Zhang", "Wei Shen", "Yan Wang", "Luqi Gong", "Zuozhu Liu"], "title": "Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding", "categories": ["cs.CL"], "comment": null, "summary": "While Large Language Models (LLMs) support long contexts, they struggle with\nperformance degradation within the context window. Current solutions incur\nprohibitive training costs, leaving statistical behaviors and cost-effective\napproaches underexplored. From the decoding perspective, we identify the\nPosterior Salience Attenuation (PSA) phenomenon, where the salience ratio\ncorrelates with long-text performance degradation. Notably, despite the\nattenuation, gold tokens still occupy high-ranking positions in the decoding\nspace. Motivated by it, we propose the training-free Positional Contrastive\nDecoding (PCD) that contrasts the logits derived from long-aware attention with\nthose from designed local-aware attention, enabling the model to focus on the\ngains introduced by large-scale short-to-long training. Through the analysis of\nlong-term decay simulation, we demonstrate that PCD effectively alleviates\nattention score degradation. Experimental results show that PCD achieves\nstate-of-the-art performance on long-context benchmarks.", "AI": {"tldr": "The paper addresses performance degradation in LLMs for long contexts, proposing a training-free method (PCD) to improve long-text performance by leveraging attention contrasts.", "motivation": "LLMs degrade in performance for long contexts, and current solutions are costly. The paper explores statistical behaviors and cost-effective approaches.", "method": "Proposes Positional Contrastive Decoding (PCD), contrasting logits from long-aware and local-aware attention to focus on gains from short-to-long training.", "result": "PCD alleviates attention score degradation and achieves state-of-the-art performance on long-context benchmarks.", "conclusion": "PCD is an effective, training-free solution for improving LLM performance in long-context scenarios."}}
{"id": "2506.08327", "pdf": "https://arxiv.org/pdf/2506.08327", "abs": "https://arxiv.org/abs/2506.08327", "authors": ["Yuto Kase", "Kai Ishibe", "Ryoma Yasuda", "Yudai Washida", "Sakiko Hashimoto"], "title": "Locating Tennis Ball Impact on the Racket in Real Time Using an Event Camera", "categories": ["cs.CV"], "comment": "17 pages, 10 figures, 3 tables", "summary": "In racket sports, such as tennis, locating the ball's position at impact is\nimportant in clarifying player and equipment characteristics, thereby aiding in\npersonalized equipment design. High-speed cameras are used to measure the\nimpact location; however, their excessive memory consumption limits prolonged\nscene capture, and manual digitization for position detection is time-consuming\nand prone to human error. These limitations make it difficult to effectively\ncapture the entire playing scene, hindering the ability to analyze the player's\nperformance. We propose a method for locating the tennis ball impact on the\nracket in real time using an event camera. Event cameras efficiently measure\nbrightness changes (called `events') with microsecond accuracy under high-speed\nmotion while using lower memory consumption. These cameras enable users to\ncontinuously monitor their performance over extended periods. Our method\nconsists of three identification steps: time range of swing, timing at impact,\nand contours of ball and racket. Conventional computer vision techniques are\nutilized along with an original event-based processing to detect the timing at\nimpact (PATS: the amount of polarity asymmetry in time symmetry). The results\nof the experiments were within the permissible range for measuring tennis\nplayers' performance. Moreover, the computation time was sufficiently short for\nreal-time applications.", "AI": {"tldr": "Proposes a real-time method using event cameras to locate tennis ball impact on a racket, overcoming high-speed camera limitations like memory use and manual errors.", "motivation": "High-speed cameras for impact location are memory-intensive and error-prone, hindering prolonged performance analysis.", "method": "Uses event cameras for efficient brightness change detection, with three steps: swing time range, impact timing, and ball/racket contours. Combines conventional vision and event-based processing (PATS).", "result": "Experimental results fit permissible performance measurement ranges, with computation suitable for real-time use.", "conclusion": "Event cameras enable efficient, real-time impact location, aiding prolonged performance monitoring in tennis."}}
{"id": "2506.08532", "pdf": "https://arxiv.org/pdf/2506.08532", "abs": "https://arxiv.org/abs/2506.08532", "authors": ["Yanwei Gong", "Xiaolin Chang"], "title": "Safe and Economical UAV Trajectory Planning in Low-Altitude Airspace: A Hybrid DRL-LLM Approach with Compliance Awareness", "categories": ["cs.AI"], "comment": null, "summary": "The rapid growth of the low-altitude economy has driven the widespread\nadoption of unmanned aerial vehicles (UAVs). This growing deployment presents\nnew challenges for UAV trajectory planning in complex urban environments.\nHowever, existing studies often overlook key factors, such as urban airspace\nconstraints and economic efficiency, which are essential in low-altitude\neconomy contexts. Deep reinforcement learning (DRL) is regarded as a promising\nsolution to these issues, while its practical adoption remains limited by low\nlearning efficiency. To overcome this limitation, we propose a novel UAV\ntrajectory planning framework that combines DRL with large language model (LLM)\nreasoning to enable safe, compliant, and economically viable path planning.\nExperimental results demonstrate that our method significantly outperforms\nexisting baselines across multiple metrics, including data collection rate,\ncollision avoidance, successful landing, regulatory compliance, and energy\nefficiency. These results validate the effectiveness of our approach in\naddressing UAV trajectory planning key challenges under constraints of the\nlow-altitude economy networking.", "AI": {"tldr": "A novel UAV trajectory planning framework combining DRL and LLM reasoning improves efficiency and compliance in complex urban environments.", "motivation": "The rapid growth of the low-altitude economy and UAV adoption highlights the need for efficient, compliant trajectory planning, which existing methods often overlook.", "method": "Proposes a framework integrating deep reinforcement learning (DRL) with large language model (LLM) reasoning for enhanced UAV path planning.", "result": "Outperforms baselines in data collection, collision avoidance, landing success, compliance, and energy efficiency.", "conclusion": "The framework effectively addresses UAV trajectory planning challenges in low-altitude economy contexts."}}
{"id": "2506.08164", "pdf": "https://arxiv.org/pdf/2506.08164", "abs": "https://arxiv.org/abs/2506.08164", "authors": ["Hadi Reisizadeh", "Jinghan Jia", "Zhiqi Bu", "Bhanukiran Vinzamuri", "Anil Ramakrishna", "Kai-Wei Chang", "Volkan Cevher", "Sijia Liu", "Mingyi Hong"], "title": "BLUR: A Bi-Level Optimization Approach for LLM Unlearning", "categories": ["cs.LG"], "comment": null, "summary": "Enabling large language models (LLMs) to unlearn knowledge and capabilities\nacquired during training has proven vital for ensuring compliance with data\nregulations and promoting ethical practices in generative AI. Although there\nare growing interests in developing various unlearning algorithms, it remains\nunclear how to best formulate the unlearning problem. The most popular\nformulation uses a weighted sum of forget and retain loss, but it often leads\nto performance degradation due to the inherent trade-off between forget and\nretain losses. In this work, we argue that it is important to model the\nhierarchical structure of the unlearning problem, where the forget problem\n(which \\textit{unlearns} certain knowledge and/or capabilities) takes priority\nover the retain problem (which preserves model utility). This hierarchical\nstructure naturally leads to a bi-level optimization formulation where the\nlower-level objective focuses on minimizing the forget loss, while the\nupper-level objective aims to maintain the model's utility. Based on this new\nformulation, we propose a novel algorithm, termed Bi-Level UnleaRning\n(\\texttt{BLUR}), which not only possesses strong theoretical guarantees but\nmore importantly, delivers superior performance. In particular, our extensive\nexperiments demonstrate that \\texttt{BLUR} consistently outperforms all the\nstate-of-the-art algorithms across various unlearning tasks, models, and\nmetrics. Codes are available at\nhttps://github.com/OptimAI-Lab/BLURLLMUnlearning.", "AI": {"tldr": "The paper proposes a bi-level optimization framework (BLUR) for unlearning in LLMs, prioritizing forget loss over retain loss to avoid performance degradation.", "motivation": "Addressing the trade-off between forget and retain losses in LLM unlearning, ensuring compliance with data regulations and ethical AI practices.", "method": "Introduces a hierarchical bi-level optimization formulation: lower-level minimizes forget loss, upper-level maintains utility. BLUR algorithm is proposed.", "result": "BLUR outperforms state-of-the-art unlearning algorithms across tasks, models, and metrics.", "conclusion": "BLUR provides a theoretically sound and effective solution for LLM unlearning, prioritizing ethical and regulatory compliance."}}
{"id": "2506.08373", "pdf": "https://arxiv.org/pdf/2506.08373", "abs": "https://arxiv.org/abs/2506.08373", "authors": ["Kevin Galim", "Ethan Ewer", "Wonjun Kang", "Minjae Lee", "Hyung Il Koo", "Kangwook Lee"], "title": "Draft-based Approximate Inference for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Optimizing inference for long-context Large Language Models (LLMs) is\nincreasingly important due to the quadratic compute and linear memory\ncomplexity of Transformers. Existing approximation methods, such as key-value\n(KV) cache dropping, sparse attention, and prompt compression, typically rely\non rough predictions of token or KV pair importance. We propose a novel\nframework for approximate LLM inference that leverages small draft models to\nmore accurately predict the importance of tokens and KV pairs. Specifically, we\nintroduce two instantiations of our proposed framework: (i) SpecKV, which\nleverages a draft output to accurately assess the importance of each KV pair\nfor more effective KV cache dropping, and (ii) SpecPC, which uses the draft\nmodel's attention activations to identify and discard unimportant prompt\ntokens. To the best of our knowledge, this is the first work to use draft\nmodels for approximate LLM inference acceleration, extending their utility\nbeyond traditional lossless speculative decoding. We motivate our methods with\ntheoretical and empirical analyses, and show a strong correlation between the\nattention patterns of draft and target models. Extensive experiments on\nlong-context benchmarks show that our methods consistently achieve higher\naccuracy than existing baselines, while preserving the same improvements in\nmemory usage, latency, and throughput. Our code is available at\nhttps://github.com/furiosa-ai/draft-based-approx-llm.", "AI": {"tldr": "A novel framework using draft models to optimize LLM inference by predicting token and KV pair importance, outperforming existing methods in accuracy and efficiency.", "motivation": "The quadratic compute and linear memory complexity of Transformers in long-context LLMs necessitate efficient inference methods. Existing approaches rely on rough importance predictions, lacking accuracy.", "method": "Proposes SpecKV for KV cache dropping and SpecPC for prompt compression, both leveraging draft models to predict importance more accurately.", "result": "Demonstrates higher accuracy than baselines while maintaining improvements in memory, latency, and throughput.", "conclusion": "The framework extends draft models' utility beyond speculative decoding, offering a promising direction for efficient LLM inference."}}
{"id": "2506.08351", "pdf": "https://arxiv.org/pdf/2506.08351", "abs": "https://arxiv.org/abs/2506.08351", "authors": ["Huixuan Zhang", "Junzhe Zhang", "Xiaojun Wan"], "title": "How Much To Guide: Revisiting Adaptive Guidance in Classifier-Free Guidance Text-to-Vision Diffusion Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "With the rapid development of text-to-vision generation diffusion models,\nclassifier-free guidance has emerged as the most prevalent method for\nconditioning. However, this approach inherently requires twice as many steps\nfor model forwarding compared to unconditional generation, resulting in\nsignificantly higher costs. While previous study has introduced the concept of\nadaptive guidance, it lacks solid analysis and empirical results, making\nprevious method unable to be applied to general diffusion models. In this work,\nwe present another perspective of applying adaptive guidance and propose Step\nAG, which is a simple, universally applicable adaptive guidance strategy. Our\nevaluations focus on both image quality and image-text alignment. whose results\nindicate that restricting classifier-free guidance to the first several\ndenoising steps is sufficient for generating high-quality, well-conditioned\nimages, achieving an average speedup of 20% to 30%. Such improvement is\nconsistent across different settings such as inference steps, and various\nmodels including video generation models, highlighting the superiority of our\nmethod.", "AI": {"tldr": "Proposes Step AG, a simple adaptive guidance strategy for text-to-vision diffusion models, reducing computational costs by 20-30% while maintaining quality.", "motivation": "Classifier-free guidance in diffusion models doubles computational steps, increasing costs. Existing adaptive methods lack analysis and general applicability.", "method": "Introduces Step AG, restricting classifier-free guidance to early denoising steps. Evaluates on image quality and text alignment.", "result": "Achieves 20-30% speedup without compromising quality, consistent across models and settings.", "conclusion": "Step AG is a universally applicable, efficient alternative to traditional classifier-free guidance."}}
{"id": "2506.08580", "pdf": "https://arxiv.org/pdf/2506.08580", "abs": "https://arxiv.org/abs/2506.08580", "authors": ["Yang Lv", "Jinlong Lei", "Peng Yi"], "title": "HGFormer: A Hierarchical Graph Transformer Framework for Two-Stage Colonel Blotto Games via Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Two-stage Colonel Blotto game represents a typical adversarial resource\nallocation problem, in which two opposing agents sequentially allocate\nresources in a network topology across two phases: an initial resource\ndeployment followed by multiple rounds of dynamic reallocation adjustments. The\nsequential dependency between game stages and the complex constraints imposed\nby the graph topology make it difficult for traditional approaches to attain a\nglobally optimal strategy. To address these challenges, we propose a\nhierarchical graph Transformer framework called HGformer. By incorporating an\nenhanced graph Transformer encoder with structural biases and a two-agent\nhierarchical decision model, our approach enables efficient policy generation\nin large-scale adversarial environments. Moreover, we design a layer-by-layer\nfeedback reinforcement learning algorithm that feeds the long-term returns from\nlower-level decisions back into the optimization of the higher-level strategy,\nthus bridging the coordination gap between the two decision-making stages.\nExperimental results demonstrate that, compared to existing hierarchical\ndecision-making or graph neural network methods, HGformer significantly\nimproves resource allocation efficiency and adversarial payoff, achieving\nsuperior overall performance in complex dynamic game scenarios.", "AI": {"tldr": "HGformer, a hierarchical graph Transformer framework, improves resource allocation in two-stage Colonel Blotto games by combining graph Transformer encoders and reinforcement learning.", "motivation": "Traditional methods struggle with sequential dependencies and graph constraints in adversarial resource allocation.", "method": "HGformer uses a graph Transformer encoder and a two-agent hierarchical decision model, enhanced by a feedback reinforcement learning algorithm.", "result": "HGformer outperforms existing methods in resource allocation efficiency and adversarial payoff.", "conclusion": "HGformer is effective for complex dynamic game scenarios, offering superior performance."}}
{"id": "2506.08167", "pdf": "https://arxiv.org/pdf/2506.08167", "abs": "https://arxiv.org/abs/2506.08167", "authors": ["Sunny Gupta", "Nikita Jangid", "Amit Sethi"], "title": "UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"], "comment": null, "summary": "Federated Learning (FL) often suffers from severe performance degradation\nwhen faced with non-IID data, largely due to local classifier bias. Traditional\nremedies such as global model regularization or layer freezing either incur\nhigh computational costs or struggle to adapt to feature shifts. In this work,\nwe propose UniVarFL, a novel FL framework that emulates IID-like training\ndynamics directly at the client level, eliminating the need for global model\ndependency. UniVarFL leverages two complementary regularization strategies\nduring local training: Classifier Variance Regularization, which aligns\nclass-wise probability distributions with those expected under IID conditions,\neffectively mitigating local classifier bias; and Hyperspherical Uniformity\nRegularization, which encourages a uniform distribution of feature\nrepresentations across the hypersphere, thereby enhancing the model's ability\nto generalize under diverse data distributions. Extensive experiments on\nmultiple benchmark datasets demonstrate that UniVarFL outperforms existing\nmethods in accuracy, highlighting its potential as a highly scalable and\nefficient solution for real-world FL deployments, especially in\nresource-constrained settings. Code: https://github.com/sunnyinAI/UniVarFL", "AI": {"tldr": "UniVarFL is a federated learning framework addressing non-IID data issues by using two regularization strategies to mimic IID-like training, improving accuracy and scalability.", "motivation": "Federated Learning (FL) struggles with non-IID data due to local classifier bias, and existing solutions are costly or ineffective.", "method": "UniVarFL employs Classifier Variance Regularization and Hyperspherical Uniformity Regularization during local training to align distributions and enhance generalization.", "result": "UniVarFL outperforms existing methods in accuracy on benchmark datasets, proving scalable and efficient for real-world FL.", "conclusion": "UniVarFL offers a promising solution for FL in resource-constrained settings by effectively mitigating non-IID data challenges."}}
{"id": "2506.08375", "pdf": "https://arxiv.org/pdf/2506.08375", "abs": "https://arxiv.org/abs/2506.08375", "authors": ["Tao Zou", "Xinghua Zhang", "Haiyang Yu", "Minzheng Wang", "Fei Huang", "Yongbin Li"], "title": "EIFBENCH: Extremely Complex Instruction Following Benchmark for Large Language Models", "categories": ["cs.CL"], "comment": "24 pages", "summary": "With the development and widespread application of large language models\n(LLMs), the new paradigm of \"Model as Product\" is rapidly evolving, and demands\nhigher capabilities to address complex user needs, often requiring precise\nworkflow execution which involves the accurate understanding of multiple tasks.\nHowever, existing benchmarks focusing on single-task environments with limited\nconstraints lack the complexity required to fully reflect real-world scenarios.\nTo bridge this gap, we present the Extremely Complex Instruction Following\nBenchmark (EIFBENCH), meticulously crafted to facilitate a more realistic and\nrobust evaluation of LLMs. EIFBENCH not only includes multi-task scenarios that\nenable comprehensive assessment across diverse task types concurrently, but\nalso integrates a variety of constraints, replicating complex operational\nenvironments. Furthermore, we propose the Segment Policy Optimization (SegPO)\nalgorithm to enhance the LLM's ability to accurately fulfill multi-task\nworkflow. Evaluations on EIFBENCH have unveiled considerable performance\ndiscrepancies in existing LLMs when challenged with these extremely complex\ninstructions. This finding underscores the necessity for ongoing optimization\nto navigate the intricate challenges posed by LLM applications.", "AI": {"tldr": "EIFBENCH is a benchmark for evaluating LLMs in multi-task, constrained scenarios, revealing performance gaps and proposing SegPO for improvement.", "motivation": "Existing benchmarks lack complexity for real-world LLM applications, necessitating a more robust evaluation tool.", "method": "Developed EIFBENCH for multi-task, constrained scenarios and proposed SegPO algorithm to enhance LLM performance.", "result": "EIFBENCH exposed significant performance gaps in LLMs under complex instructions.", "conclusion": "Ongoing optimization is needed to address LLM challenges in complex workflows."}}
{"id": "2506.08356", "pdf": "https://arxiv.org/pdf/2506.08356", "abs": "https://arxiv.org/abs/2506.08356", "authors": ["Shivang Chopra", "Lingchao Mao", "Gabriela Sanchez-Rodriguez", "Andrew J Feola", "Jing Li", "Zsolt Kira"], "title": "MedMoE: Modality-Specialized Mixture of Experts for Medical Vision-Language Understanding", "categories": ["cs.CV"], "comment": null, "summary": "Different medical imaging modalities capture diagnostic information at\nvarying spatial resolutions, from coarse global patterns to fine-grained\nlocalized structures. However, most existing vision-language frameworks in the\nmedical domain apply a uniform strategy for local feature extraction,\noverlooking the modality-specific demands. In this work, we present MedMoE, a\nmodular and extensible vision-language processing framework that dynamically\nadapts visual representation based on the diagnostic context. MedMoE\nincorporates a Mixture-of-Experts (MoE) module conditioned on the report type,\nwhich routes multi-scale image features through specialized expert branches\ntrained to capture modality-specific visual semantics. These experts operate\nover feature pyramids derived from a Swin Transformer backbone, enabling\nspatially adaptive attention to clinically relevant regions. This framework\nproduces localized visual representations aligned with textual descriptions,\nwithout requiring modality-specific supervision at inference. Empirical results\non diverse medical benchmarks demonstrate that MedMoE improves alignment and\nretrieval performance across imaging modalities, underscoring the value of\nmodality-specialized visual representations in clinical vision-language\nsystems.", "AI": {"tldr": "MedMoE is a vision-language framework that dynamically adapts visual representation for medical imaging by using modality-specific experts, improving alignment and retrieval performance.", "motivation": "Existing frameworks use uniform feature extraction, ignoring modality-specific needs in medical imaging. MedMoE addresses this gap.", "method": "Uses a Mixture-of-Experts (MoE) module with Swin Transformer backbone to route multi-scale features through modality-specialized branches.", "result": "Improves alignment and retrieval performance across diverse medical benchmarks.", "conclusion": "Modality-specialized visual representations enhance clinical vision-language systems."}}
{"id": "2506.08627", "pdf": "https://arxiv.org/pdf/2506.08627", "abs": "https://arxiv.org/abs/2506.08627", "authors": ["Douwe Geurtjens", "Xixi Lu"], "title": "FoldA: Computing Partial-Order Alignments Using Directed Net Unfoldings", "categories": ["cs.AI"], "comment": "Conditionally accepted at BPM 2025", "summary": "Conformance checking is a fundamental task of process mining, which\nquantifies the extent to which the observed process executions match a\nnormative process model. The state-of-the-art approaches compute alignments by\nexploring the state space formed by the synchronous product of the process\nmodel and the trace. This often leads to state space explosion, particularly\nwhen the model exhibits a high degree of choice and concurrency. Moreover, as\nalignments inherently impose a sequential structure, they fail to fully\nrepresent the concurrent behavior present in many real-world processes. To\naddress these limitations, this paper proposes a new technique for computing\npartial-order alignments {on the fly using directed Petri net unfoldings, named\nFoldA. We evaluate our technique on 485 synthetic model-log pairs and compare\nit against Astar- and Dijkstra-alignments on 13 real-life model-log pairs and 6\nbenchmark pairs. The results show that our unfolding alignment, although it\nrequires more computation time, generally reduces the number of queued states\nand provides a more accurate representation of concurrency.", "AI": {"tldr": "The paper introduces FoldA, a technique for partial-order alignments using Petri net unfoldings to address state space explosion and concurrency representation issues in conformance checking.", "motivation": "Existing alignment methods face state space explosion and fail to represent concurrent behavior accurately.", "method": "Proposes FoldA, a technique using directed Petri net unfoldings for partial-order alignments.", "result": "FoldA reduces queued states and better represents concurrency, though it requires more computation time.", "conclusion": "FoldA improves conformance checking by addressing limitations of sequential alignment methods."}}
{"id": "2506.08169", "pdf": "https://arxiv.org/pdf/2506.08169", "abs": "https://arxiv.org/abs/2506.08169", "authors": ["Jingqiao Tang", "Ryan Bausback", "Feng Bao", "Richard Archibald"], "title": "Federated Learning on Stochastic Neural Networks", "categories": ["cs.LG", "cs.DC"], "comment": "25 pages, 19 figures, Submitted to Journal of Machine Learning for\n  Modeling and Computing", "summary": "Federated learning is a machine learning paradigm that leverages edge\ncomputing on client devices to optimize models while maintaining user privacy\nby ensuring that local data remains on the device. However, since all data is\ncollected by clients, federated learning is susceptible to latent noise in\nlocal datasets. Factors such as limited measurement capabilities or human\nerrors may introduce inaccuracies in client data. To address this challenge, we\npropose the use of a stochastic neural network as the local model within the\nfederated learning framework. Stochastic neural networks not only facilitate\nthe estimation of the true underlying states of the data but also enable the\nquantification of latent noise. We refer to our federated learning approach,\nwhich incorporates stochastic neural networks as local models, as Federated\nstochastic neural networks. We will present numerical experiments demonstrating\nthe performance and effectiveness of our method, particularly in handling\nnon-independent and identically distributed data.", "AI": {"tldr": "Proposes Federated Stochastic Neural Networks (FSNN) to address latent noise in federated learning by using stochastic neural networks as local models.", "motivation": "Federated learning's susceptibility to latent noise in client data due to factors like limited measurement capabilities or human errors.", "method": "Incorporates stochastic neural networks as local models to estimate true data states and quantify latent noise.", "result": "Numerical experiments show effectiveness, especially with non-IID data.", "conclusion": "FSNN improves federated learning by handling latent noise and enhancing model accuracy."}}
{"id": "2506.08403", "pdf": "https://arxiv.org/pdf/2506.08403", "abs": "https://arxiv.org/abs/2506.08403", "authors": ["Weiya Li", "Junjie Chen", "Bei Li", "Boyang Liu", "Zichen Wen", "Nuanqiao Shan", "Xiaoqian Liu", "Anping Liu", "Huajie Liu", "Youyan Wang", "Wujiuge Yin", "Hu Song", "Bing Huang", "Zhiyuan Xia", "Jialiang Chen", "Linfeng Zhang"], "title": "TACTIC: Translation Agents with Cognitive-Theoretic Interactive Collaboration", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 4 figures, Under review. Code:\n  https://github.com/weiyali126/TACTIC", "summary": "Machine translation has long been a central task in natural language\nprocessing. With the rapid advancement of large language models (LLMs), there\nhas been remarkable progress in translation quality. However, fully realizing\nthe translation potential of LLMs remains an open challenge. Recent studies\nhave explored multi-agent systems to decompose complex translation tasks into\ncollaborative subtasks, showing initial promise in enhancing translation\nquality through agent cooperation and specialization. Nevertheless, existing\nmulti-agent translation frameworks largely neglect foundational insights from\ncognitive translation studies. These insights emphasize how human translators\nemploy different cognitive strategies, such as balancing literal and free\ntranslation, refining expressions based on context, and iteratively evaluating\noutputs. To address this limitation, we propose a cognitively informed\nmulti-agent framework called TACTIC, which stands for T ranslation A gents with\nCognitive- T heoretic Interactive Collaboration. The framework comprises six\nfunctionally distinct agents that mirror key cognitive processes observed in\nhuman translation behavior. These include agents for drafting, refinement,\nevaluation, scoring, context reasoning, and external knowledge gathering. By\nsimulating an interactive and theory-grounded translation workflow, TACTIC\neffectively leverages the full capacity of LLMs for high-quality translation.\nExperimental results on diverse language pairs from the FLORES-200 and WMT24\nbenchmarks show that our method consistently achieves state-of-the-art\nperformance. Using DeepSeek-V3 as the base model, TACTIC surpasses GPT-4.1 by\nan average of +0.6 XCOMET and +1.18 COMETKIWI-23. Compared to DeepSeek-R1, it\nfurther improves by +0.84 XCOMET and +2.99 COMETKIWI-23. Code is available at\nhttps://github.com/weiyali126/TACTIC.", "AI": {"tldr": "The paper introduces TACTIC, a cognitively informed multi-agent framework for machine translation, leveraging insights from human cognitive strategies to enhance LLM-based translation quality.", "motivation": "Existing multi-agent translation frameworks overlook cognitive insights from human translation, limiting their potential.", "method": "Proposes TACTIC, a framework with six specialized agents simulating human cognitive processes like drafting, refinement, and evaluation.", "result": "TACTIC outperforms GPT-4.1 and DeepSeek-R1 on FLORES-200 and WMT24 benchmarks, achieving state-of-the-art performance.", "conclusion": "TACTIC demonstrates the value of integrating cognitive theory into multi-agent systems for superior machine translation."}}
{"id": "2506.08361", "pdf": "https://arxiv.org/pdf/2506.08361", "abs": "https://arxiv.org/abs/2506.08361", "authors": ["Yanting Mei", "Zhilu Zhang", "Xiaohe Wu", "Wangmeng Zuo"], "title": "Image Demoir\u00e9ing Using Dual Camera Fusion on Mobile Phones", "categories": ["cs.CV"], "comment": "ICME 2025", "summary": "When shooting electronic screens, moir\\'e patterns usually appear in captured\nimages, which seriously affects the image quality. Existing image demoir\\'eing\nmethods face great challenges in removing large and heavy moir\\'e. To address\nthe issue, we propose to utilize Dual Camera fusion for Image Demoir\\'eing\n(DCID), \\ie, using the ultra-wide-angle (UW) image to assist the moir\\'e\nremoval of wide-angle (W) image. This is inspired by two motivations: (1) the\ntwo lenses are commonly equipped with modern smartphones, (2) the UW image\ngenerally can provide normal colors and textures when moir\\'e exists in the W\nimage mainly due to their different focal lengths. In particular, we propose an\nefficient DCID method, where a lightweight UW image encoder is integrated into\nan existing demoir\\'eing network and a fast two-stage image alignment manner is\npresent. Moreover, we construct a large-scale real-world dataset with diverse\nmobile phones and monitors, containing about 9,000 samples. Experiments on the\ndataset show our method performs better than state-of-the-art methods. Code and\ndataset are available at https://github.com/Mrduckk/DCID.", "AI": {"tldr": "The paper proposes a dual-camera fusion method (DCID) for removing moir\u00e9 patterns in images, leveraging ultra-wide-angle (UW) images to assist wide-angle (W) images, achieving better results than existing methods.", "motivation": "Moir\u00e9 patterns degrade image quality when shooting screens. Existing methods struggle with large moir\u00e9. Modern smartphones often have dual lenses (UW and W), and UW images can provide cleaner textures due to different focal lengths.", "method": "DCID integrates a lightweight UW image encoder into a demoir\u00e9ing network and uses a fast two-stage alignment. A large dataset (9,000 samples) was created for validation.", "result": "Experiments show DCID outperforms state-of-the-art methods.", "conclusion": "The proposed DCID method effectively removes moir\u00e9 patterns by leveraging dual-camera fusion, validated by a new dataset."}}
{"id": "2506.08630", "pdf": "https://arxiv.org/pdf/2506.08630", "abs": "https://arxiv.org/abs/2506.08630", "authors": ["Laurens Engwegen", "Daan Brinks", "Wendelin B\u00f6hmer"], "title": "Modular Recurrence in Contextual MDPs for Universal Morphology Control", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "A universal controller for any robot morphology would greatly improve\ncomputational and data efficiency. By utilizing contextual information about\nthe properties of individual robots and exploiting their modular structure in\nthe architecture of deep reinforcement learning agents, steps have been made\ntowards multi-robot control. Generalization to new, unseen robots, however,\nremains a challenge. In this paper we hypothesize that the relevant contextual\ninformation is partially observable, but that it can be inferred through\ninteractions for better generalization to contexts that are not seen during\ntraining. To this extent, we implement a modular recurrent architecture and\nevaluate its generalization performance on a large set of MuJoCo robots. The\nresults show a substantial improved performance on robots with unseen dynamics,\nkinematics, and topologies, in four different environments.", "AI": {"tldr": "A modular recurrent architecture improves generalization for multi-robot control by inferring partially observable contextual information.", "motivation": "Developing a universal controller for diverse robot morphologies to enhance computational and data efficiency.", "method": "Implemented a modular recurrent architecture to infer contextual information through interactions, evaluated on MuJoCo robots.", "result": "Substantial performance improvement on robots with unseen dynamics, kinematics, and topologies across four environments.", "conclusion": "The approach effectively generalizes to new robots, addressing a key challenge in multi-robot control."}}
{"id": "2506.08176", "pdf": "https://arxiv.org/pdf/2506.08176", "abs": "https://arxiv.org/abs/2506.08176", "authors": ["Anh V Nguyen", "Diego Klabjan"], "title": "FedGA-Tree: Federated Decision Tree using Genetic Algorithm", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "In recent years, with rising concerns for data privacy, Federated Learning\nhas gained prominence, as it enables collaborative training without the\naggregation of raw data from participating clients. However, much of the\ncurrent focus has been on parametric gradient-based models, while nonparametric\ncounterparts such as decision tree are relatively understudied. Existing\nmethods for adapting decision trees to Federated Learning generally combine a\ngreedy tree-building algorithm with differential privacy to produce a global\nmodel for all clients. These methods are limited to classification trees and\ncategorical data due to the constraints of differential privacy. In this paper,\nwe explore an alternative approach that utilizes Genetic Algorithm to\nfacilitate the construction of personalized decision trees and accommodate\ncategorical and numerical data, thus allowing for both classification and\nregression trees. Comprehensive experiments demonstrate that our method\nsurpasses decision trees trained solely on local data and a benchmark\nalgorithm.", "AI": {"tldr": "The paper proposes a Genetic Algorithm-based method for constructing personalized decision trees in Federated Learning, outperforming local data training and benchmark algorithms.", "motivation": "Addressing the understudied area of non-parametric models like decision trees in Federated Learning, and overcoming limitations of existing methods restricted to classification trees and categorical data.", "method": "Utilizes Genetic Algorithm to build personalized decision trees, accommodating both categorical and numerical data for classification and regression tasks.", "result": "The method surpasses decision trees trained on local data and a benchmark algorithm, as shown in comprehensive experiments.", "conclusion": "The proposed approach effectively extends Federated Learning to non-parametric models, offering flexibility and improved performance for decision trees."}}
{"id": "2506.08410", "pdf": "https://arxiv.org/pdf/2506.08410", "abs": "https://arxiv.org/abs/2506.08410", "authors": ["Ziyang Ma", "Qingyue Yuan", "Zhenglin Wang", "Deyu Zhou"], "title": "Large Language Models Have Intrinsic Meta-Cognition, but Need a Good Lens", "categories": ["cs.CL"], "comment": "Preprint", "summary": "Previous research has primarily focused on the cognitive error detection\ncapabilities of Large Language Models (LLMs), often prompting them to analyze\nmistakes in reasoning chains. However, few studies have examined the\nmeta-cognitive abilities of LLMs (e.g., their self-awareness of step errors),\nwhich are crucial for their reliability. While studies on LLM self-evaluation\npresent some measures, such as perplexity, which can reflect the answer\ncorrectness and be viewed as the lens of meta-cognition, they lack step-level\nanalysis and adaptation. This paper studies the evaluation of LLM\nmeta-cognition using the current lenses and how to improve these lenses.\nSpecifically, we propose AutoMeco, an Automated Meta-cognition Evaluation\nframework for benchmarking the existing lenses. Furthermore, a training-free\nMarkovian Intrinsic Reward Adjustment strategy, MIRA, is proposed to boost\ncurrent meta-cognition lenses. Experimental results on three mathematical\nreasoning datasets and three LLMs show the reasonableness of AutoMeco by\ncomparing it with Best-of-N verification. Moreover, the meta-cognition ability\nof LLMs can be better evaluated using MIRA.", "AI": {"tldr": "The paper introduces AutoMeco and MIRA to evaluate and improve LLM meta-cognition, showing effectiveness on mathematical reasoning tasks.", "motivation": "Previous research lacks step-level analysis of LLM meta-cognition, which is crucial for reliability.", "method": "Proposes AutoMeco for benchmarking meta-cognition lenses and MIRA, a training-free strategy to enhance them.", "result": "AutoMeco is validated against Best-of-N verification, and MIRA improves meta-cognition evaluation.", "conclusion": "The study advances LLM meta-cognition evaluation and enhancement, demonstrating practical benefits."}}
{"id": "2506.08391", "pdf": "https://arxiv.org/pdf/2506.08391", "abs": "https://arxiv.org/abs/2506.08391", "authors": ["Woohyeon Park", "Woojin Kim", "Jaeik Kim", "Jaeyoung Do"], "title": "SECOND: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding", "categories": ["cs.CV"], "comment": null, "summary": "Despite significant advancements in Vision-Language Models (VLMs), the\nperformance of existing VLMs remains hindered by object hallucination, a\ncritical challenge to achieving accurate visual understanding. To address this\nissue, we propose SECOND: Selective and Contrastive Decoding, a novel approach\nthat enables VLMs to effectively leverage multi-scale visual information with\nan object-centric manner, closely aligning with human visual perception. SECOND\nprogressively selects and integrates multi-scale visual information,\nfacilitating a more precise interpretation of images. By contrasting these\nvisual information iteratively, SECOND significantly reduces perceptual\nhallucinations and outperforms a wide range of benchmarks. Our theoretical\nanalysis and experiments highlight the largely unexplored potential of\nmulti-scale application in VLMs, showing that prioritizing and contrasting\nacross scales outperforms existing methods.", "AI": {"tldr": "SECOND improves VLMs by reducing object hallucination through selective and contrastive decoding of multi-scale visual information.", "motivation": "Addressing the challenge of object hallucination in VLMs to enhance visual understanding accuracy.", "method": "Proposes SECOND, which selectively integrates and contrasts multi-scale visual information in an object-centric manner.", "result": "SECOND reduces perceptual hallucinations and outperforms benchmarks.", "conclusion": "Multi-scale visual information prioritization and contrast in VLMs show unexplored potential, outperforming existing methods."}}
{"id": "2506.08745", "pdf": "https://arxiv.org/pdf/2506.08745", "abs": "https://arxiv.org/abs/2506.08745", "authors": ["Kongcheng Zhang", "Qi Yao", "Shunyu Liu", "Yingjie Wang", "Baisheng Lai", "Jieping Ye", "Mingli Song", "Dacheng Tao"], "title": "Consistent Paths Lead to Truth: Self-Rewarding Reinforcement Learning for LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances of Reinforcement Learning (RL) have highlighted its potential\nin complex reasoning tasks, yet effective training often relies on external\nsupervision, which limits the broader applicability. In this work, we propose a\nnovel self-rewarding reinforcement learning framework to enhance Large Language\nModel (LLM) reasoning by leveraging the consistency of intermediate reasoning\nstates across different reasoning trajectories. Our key insight is that correct\nresponses often exhibit consistent trajectory patterns in terms of model\nlikelihood: their intermediate reasoning states tend to converge toward their\nown final answers (high consistency) with minimal deviation toward other\ncandidates (low volatility). Inspired by this observation, we introduce CoVo,\nan intrinsic reward mechanism that integrates Consistency and Volatility via a\nrobust vector-space aggregation strategy, complemented by a curiosity bonus to\npromote diverse exploration. CoVo enables LLMs to perform RL in a\nself-rewarding manner, offering a scalable pathway for learning to reason\nwithout external supervision. Extensive experiments on diverse reasoning\nbenchmarks show that CoVo achieves performance comparable to or even surpassing\nsupervised RL. Our code is available at https://github.com/sastpg/CoVo.", "AI": {"tldr": "A self-rewarding RL framework (CoVo) for LLM reasoning leverages consistency and volatility of intermediate states, outperforming supervised RL.", "motivation": "To enable scalable RL for LLM reasoning without external supervision by exploiting consistent reasoning patterns.", "method": "Introduces CoVo, a reward mechanism combining consistency, volatility, and curiosity for self-rewarding RL.", "result": "CoVo matches or surpasses supervised RL on diverse reasoning benchmarks.", "conclusion": "CoVo provides a scalable, unsupervised solution for enhancing LLM reasoning."}}
{"id": "2506.08201", "pdf": "https://arxiv.org/pdf/2506.08201", "abs": "https://arxiv.org/abs/2506.08201", "authors": ["Krishna Pillutla", "Jalaj Upadhyay", "Christopher A. Choquette-Choo", "Krishnamurthy Dvijotham", "Arun Ganesh", "Monika Henzinger", "Jonathan Katz", "Ryan McKenna", "H. Brendan McMahan", "Keith Rush", "Thomas Steinke", "Abhradeep Thakurta"], "title": "Correlated Noise Mechanisms for Differentially Private Learning", "categories": ["cs.LG", "cs.CR"], "comment": "212 pages", "summary": "This monograph explores the design and analysis of correlated noise\nmechanisms for differential privacy (DP), focusing on their application to\nprivate training of AI and machine learning models via the core primitive of\nestimation of weighted prefix sums. While typical DP mechanisms inject\nindependent noise into each step of a stochastic gradient (SGD) learning\nalgorithm in order to protect the privacy of the training data, a growing body\nof recent research demonstrates that introducing (anti-)correlations in the\nnoise can significantly improve privacy-utility trade-offs by carefully\ncanceling out some of the noise added on earlier steps in subsequent steps.\nSuch correlated noise mechanisms, known variously as matrix mechanisms,\nfactorization mechanisms, and DP-Follow-the-Regularized-Leader (DP-FTRL) when\napplied to learning algorithms, have also been influential in practice, with\nindustrial deployment at a global scale.", "AI": {"tldr": "The paper explores correlated noise mechanisms in differential privacy (DP) for AI/ML model training, showing improved privacy-utility trade-offs compared to independent noise.", "motivation": "To enhance privacy-utility trade-offs in DP by leveraging correlated noise, addressing limitations of independent noise in stochastic gradient descent (SGD).", "method": "Uses correlated noise mechanisms (e.g., matrix mechanisms, DP-FTRL) to cancel noise across training steps, applied to weighted prefix sums estimation.", "result": "Demonstrates significant improvements in privacy-utility trade-offs, with practical industrial-scale deployment.", "conclusion": "Correlated noise mechanisms offer superior performance in DP for AI/ML training, with real-world applicability."}}
{"id": "2506.08427", "pdf": "https://arxiv.org/pdf/2506.08427", "abs": "https://arxiv.org/abs/2506.08427", "authors": ["Jiaxiang Liu", "Boxuan Xing", "Chenhao Yuan", "Chenxiang Zhang", "Di Wu", "Xiusheng Huang", "Haida Yu", "Chuhan Lang", "Pengfei Cao", "Jun Zhao", "Kang Liu"], "title": "Know-MRI: A Knowledge Mechanisms Revealer&Interpreter for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "As large language models (LLMs) continue to advance, there is a growing\nurgency to enhance the interpretability of their internal knowledge mechanisms.\nConsequently, many interpretation methods have emerged, aiming to unravel the\nknowledge mechanisms of LLMs from various perspectives. However, current\ninterpretation methods differ in input data formats and interpreting outputs.\nThe tools integrating these methods are only capable of supporting tasks with\nspecific inputs, significantly constraining their practical applications. To\naddress these challenges, we present an open-source Knowledge Mechanisms\nRevealer&Interpreter (Know-MRI) designed to analyze the knowledge mechanisms\nwithin LLMs systematically. Specifically, we have developed an extensible core\nmodule that can automatically match different input data with interpretation\nmethods and consolidate the interpreting outputs. It enables users to freely\nchoose appropriate interpretation methods based on the inputs, making it easier\nto comprehensively diagnose the model's internal knowledge mechanisms from\nmultiple perspectives. Our code is available at\nhttps://github.com/nlpkeg/Know-MRI. We also provide a demonstration video on\nhttps://youtu.be/NVWZABJ43Bs.", "AI": {"tldr": "Know-MRI is an open-source tool designed to systematically analyze and interpret the knowledge mechanisms of large language models (LLMs) by matching input data with appropriate interpretation methods and consolidating outputs.", "motivation": "The need to enhance the interpretability of LLMs' internal knowledge mechanisms, given the diversity and limitations of current interpretation methods.", "method": "Development of an extensible core module in Know-MRI that automatically matches input data with interpretation methods and consolidates outputs.", "result": "Know-MRI enables users to freely choose interpretation methods based on inputs, facilitating comprehensive diagnosis of LLMs' knowledge mechanisms.", "conclusion": "Know-MRI addresses the limitations of current interpretation tools, offering a flexible and systematic approach to understanding LLMs' knowledge mechanisms."}}
{"id": "2506.08418", "pdf": "https://arxiv.org/pdf/2506.08418", "abs": "https://arxiv.org/abs/2506.08418", "authors": ["Taiqin Chen", "Zikun Zhou", "Zheng Fang", "Wenzhen Zou", "Kanjun Liu", "Ke Chen", "Yongbing Zhang", "Yaowei Wang"], "title": "RadioDUN: A Physics-Inspired Deep Unfolding Network for Radio Map Estimation", "categories": ["cs.CV", "eess.SP"], "comment": null, "summary": "The radio map represents the spatial distribution of spectrum resources\nwithin a region, supporting efficient resource allocation and interference\nmitigation. However, it is difficult to construct a dense radio map as a\nlimited number of samples can be measured in practical scenarios. While\nexisting works have used deep learning to estimate dense radio maps from sparse\nsamples, they are hard to integrate with the physical characteristics of the\nradio map. To address this challenge, we cast radio map estimation as the\nsparse signal recovery problem. A physical propagation model is further\nincorporated to decompose the problem into multiple factor optimization\nsub-problems, thereby reducing recovery complexity. Inspired by the existing\ncompressive sensing methods, we propose the Radio Deep Unfolding Network\n(RadioDUN) to unfold the optimization process, achieving adaptive parameter\nadjusting and prior fitting in a learnable manner. To account for the radio\npropagation characteristics, we develop a dynamic reweighting module (DRM) to\nadaptively model the importance of each factor for the radio map. Inspired by\nthe shadowing factor in the physical propagation model, we integrate\nobstacle-related factors to express the obstacle-induced signal stochastic\ndecay. The shadowing loss is further designed to constrain the factor\nprediction and act as a supplementary supervised objective, which enhances the\nperformance of RadioDUN. Extensive experiments have been conducted to\ndemonstrate that the proposed method outperforms the state-of-the-art methods.\nOur code will be made publicly available upon publication.", "AI": {"tldr": "The paper proposes RadioDUN, a deep unfolding network for dense radio map estimation, integrating physical propagation models and adaptive learning to outperform existing methods.", "motivation": "Existing deep learning methods for radio map estimation lack integration with physical characteristics, leading to inefficiencies.", "method": "The paper casts radio map estimation as a sparse signal recovery problem, using a physical propagation model and proposing RadioDUN with a dynamic reweighting module (DRM) and shadowing loss.", "result": "RadioDUN outperforms state-of-the-art methods in experiments.", "conclusion": "The proposed method effectively integrates physical characteristics into deep learning for improved radio map estimation."}}
{"id": "2506.08747", "pdf": "https://arxiv.org/pdf/2506.08747", "abs": "https://arxiv.org/abs/2506.08747", "authors": ["Boyang Sun", "Yu Yao", "Xinshuai Dong", "Zongfang Liu", "Tongliang Liu", "Yumou Qiu", "Kun Zhang"], "title": "A Sample Efficient Conditional Independence Test in the Presence of Discretization", "categories": ["cs.AI", "stat.ML"], "comment": null, "summary": "In many real-world scenarios, interested variables are often represented as\ndiscretized values due to measurement limitations. Applying Conditional\nIndependence (CI) tests directly to such discretized data, however, can lead to\nincorrect conclusions. To address this, recent advancements have sought to\ninfer the correct CI relationship between the latent variables through\nbinarizing observed data. However, this process inevitably results in a loss of\ninformation, which degrades the test's performance. Motivated by this, this\npaper introduces a sample-efficient CI test that does not rely on the\nbinarization process. We find that the independence relationships of latent\ncontinuous variables can be established by addressing an over-identifying\nrestriction problem with Generalized Method of Moments (GMM). Based on this\ninsight, we derive an appropriate test statistic and establish its asymptotic\ndistribution correctly reflecting CI by leveraging nodewise regression.\nTheoretical findings and Empirical results across various datasets demonstrate\nthat the superiority and effectiveness of our proposed test. Our code\nimplementation is provided in https://github.com/boyangaaaaa/DCT", "AI": {"tldr": "A sample-efficient CI test avoids data binarization, using GMM and nodewise regression to infer latent variable relationships, outperforming existing methods.", "motivation": "Discretized data can mislead CI tests; binarization causes information loss. This paper aims to improve CI testing without binarization.", "method": "Proposes a CI test using GMM to address over-identifying restrictions, deriving a test statistic via nodewise regression.", "result": "Theoretical and empirical results show the test's superiority and effectiveness across datasets.", "conclusion": "The proposed CI test is efficient, avoids information loss, and outperforms binarization-based methods."}}
{"id": "2506.08205", "pdf": "https://arxiv.org/pdf/2506.08205", "abs": "https://arxiv.org/abs/2506.08205", "authors": ["Shadab Anwar Shaikh", "Kranthi Balusu", "Ayoub Soulami"], "title": "A Machine Learning Approach to Generate Residual Stress Distributions using Sparse Characterization Data in Friction-Stir Processed Parts", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Residual stresses, which remain within a component after processing, can\ndeteriorate performance. Accurately determining their full-field distributions\nis essential for optimizing the structural integrity and longevity. However,\nthe experimental effort required for full-field characterization is\nimpractical. Given these challenges, this work proposes a machine learning (ML)\nbased Residual Stress Generator (RSG) to infer full-field stresses from limited\nmeasurements. An extensive dataset was initially constructed by performing\nnumerous process simulations with a diverse parameter set. A ML model based on\nU-Net architecture was then trained to learn the underlying structure through\nsystematic hyperparameter tuning. Then, the model's ability to generate\nsimulated stresses was evaluated, and it was ultimately tested on actual\ncharacterization data to validate its effectiveness. The model's prediction of\nsimulated stresses shows that it achieved excellent predictive accuracy and\nexhibited a significant degree of generalization, indicating that it\nsuccessfully learnt the latent structure of residual stress distribution. The\nRSG's performance in predicting experimentally characterized data highlights\nthe feasibility of the proposed approach in providing a comprehensive\nunderstanding of residual stress distributions from limited measurements,\nthereby significantly reducing experimental efforts.", "AI": {"tldr": "A machine learning-based Residual Stress Generator (RSG) is proposed to infer full-field residual stresses from limited measurements, reducing experimental effort while maintaining accuracy.", "motivation": "Residual stresses degrade performance, and full-field characterization is impractical due to high experimental effort.", "method": "A U-Net-based ML model was trained on a dataset from process simulations, then tested on actual characterization data.", "result": "The model achieved excellent predictive accuracy and generalization, successfully learning residual stress distribution patterns.", "conclusion": "The RSG provides a feasible solution for comprehensive residual stress analysis from limited measurements, significantly cutting experimental work."}}
{"id": "2506.08433", "pdf": "https://arxiv.org/pdf/2506.08433", "abs": "https://arxiv.org/abs/2506.08433", "authors": ["Hern\u00e1n Maina", "Nicol\u00e1s Wolovick", "Luciana Benotti"], "title": "Low-resource domain adaptation while minimizing energy and hardware resource consumption", "categories": ["cs.CL", "cs.DC", "cs.LG"], "comment": "A shorter version of this work was accepted as a two-page abstract\n  for presentation at the Widening Natural Language Processing (WiNLP) 2023\n  Workshop. That version was not publicly released, and this is the first\n  public version of the work", "summary": "Training Large Language Models (LLMs) is costly in terms of energy, hardware,\nand annotated data, often resulting in a positionality rooted in predominant\ncultures and values (Santy et al., 2023). Domain adaptation has emerged as a\npromising strategy to better align models with diverse cultural and value\ncontexts (Hershcovich et al., 2022), but its computational cost remains a\nsignificant barrier, particularly for research groups lacking access to\nlarge-scale infrastructure. In this paper, we evaluate how the use of different\nnumerical precisions and data parallelization strategies impacts both training\nspeed (as a proxy to energy and hardware consumption) and model accuracy, with\nthe goal of facilitating domain adaptation in low-resource environments. Our\nfindings are relevant to any setting where energy efficiency, accessibility, or\nlimited hardware availability are key concerns.", "AI": {"tldr": "The paper explores how numerical precisions and data parallelization affect training speed and accuracy for LLMs, aiming to make domain adaptation more accessible in low-resource settings.", "motivation": "High costs and cultural biases in LLM training limit accessibility. Domain adaptation is promising but computationally expensive, especially for groups with limited infrastructure.", "method": "Evaluates the impact of numerical precisions and data parallelization strategies on training speed and model accuracy.", "result": "Findings show trade-offs between training efficiency and accuracy, relevant for energy-efficient and low-resource settings.", "conclusion": "The study provides insights for optimizing domain adaptation in resource-constrained environments, addressing energy efficiency and accessibility."}}
{"id": "2506.08429", "pdf": "https://arxiv.org/pdf/2506.08429", "abs": "https://arxiv.org/abs/2506.08429", "authors": ["Mingjie Xu", "Andrew Estornell", "Hongzheng Yang", "Yuzhi Zhao", "Zhaowei Zhu", "Qi Xuan", "Jiaheng Wei"], "title": "Better Reasoning with Less Data: Enhancing VLMs Through Unified Modality Scoring", "categories": ["cs.CV"], "comment": null, "summary": "The application of visual instruction tuning and other post-training\ntechniques has significantly enhanced the capabilities of Large Language Models\n(LLMs) in visual understanding, enriching Vision-Language Models (VLMs) with\nmore comprehensive visual language datasets. However, the effectiveness of VLMs\nis highly dependent on large-scale, high-quality datasets that ensure precise\nrecognition and accurate reasoning. Two key challenges hinder progress: (1)\nnoisy alignments between images and the corresponding text, which leads to\nmisinterpretation, and (2) ambiguous or misleading text, which obscures visual\ncontent. To address these challenges, we propose SCALE (Single modality data\nquality and Cross modality Alignment Evaluation), a novel quality-driven data\nselection pipeline for VLM instruction tuning datasets. Specifically, SCALE\nintegrates a cross-modality assessment framework that first assigns each data\nentry to its appropriate vision-language task, generates general and\ntask-specific captions (covering scenes, objects, style, etc.), and evaluates\nthe alignment, clarity, task rarity, text coherence, and image clarity of each\nentry based on the generated captions. We reveal that: (1) current unimodal\nquality assessment methods evaluate one modality while overlooking the rest,\nwhich can underestimate samples essential for specific tasks and discard the\nlower-quality instances that help build model robustness; and (2) appropriately\ngenerated image captions provide an efficient way to transfer the image-text\nmultimodal task into a unified text modality.", "AI": {"tldr": "SCALE is a quality-driven data selection pipeline for VLM instruction tuning, addressing noisy alignments and ambiguous text by evaluating cross-modality alignment and data quality.", "motivation": "Current VLMs rely on large-scale datasets, but noisy alignments and misleading text hinder performance. SCALE aims to improve dataset quality for better visual understanding.", "method": "SCALE integrates a cross-modality framework to assign tasks, generate captions, and evaluate alignment, clarity, task rarity, text coherence, and image clarity.", "result": "SCALE shows unimodal methods overlook essential samples and that generated captions efficiently unify multimodal tasks into text.", "conclusion": "SCALE improves VLM performance by enhancing dataset quality and alignment, addressing key challenges in visual instruction tuning."}}
{"id": "2506.08771", "pdf": "https://arxiv.org/pdf/2506.08771", "abs": "https://arxiv.org/abs/2506.08771", "authors": ["Yuni Susanti", "Michael F\u00e4rber"], "title": "Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": "Accepted at KDD 2025 (full research paper)", "summary": "Inferring causal relationships between variable pairs is crucial for\nunderstanding multivariate interactions in complex systems. Knowledge-based\ncausal discovery -- which involves inferring causal relationships by reasoning\nover the metadata of variables (e.g., names or textual context) -- offers a\ncompelling alternative to traditional methods that rely on observational data.\nHowever, existing methods using Large Language Models (LLMs) often produce\nunstable and inconsistent results, compromising their reliability for causal\ninference. To address this, we introduce a novel approach that integrates\nKnowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery.\nOur approach identifies informative metapath-based subgraphs within KGs and\nfurther refines the selection of these subgraphs using Learning-to-Rank-based\nmodels. The top-ranked subgraphs are then incorporated into zero-shot prompts,\nimproving the effectiveness of LLMs in inferring the causal relationship.\nExtensive experiments on biomedical and open-domain datasets demonstrate that\nour method outperforms most baselines by up to 44.4 points in F1 scores,\nevaluated across diverse LLMs and KGs. Our code and datasets are available on\nGitHub: https://github.com/susantiyuni/path-to-causality", "AI": {"tldr": "A novel method integrates Knowledge Graphs (KGs) with Large Language Models (LLMs) to improve knowledge-based causal discovery, outperforming baselines by up to 44.4 points in F1 scores.", "motivation": "Traditional causal discovery methods relying on observational data are unstable when using LLMs. The paper aims to enhance reliability by leveraging KGs.", "method": "The approach identifies metapath-based subgraphs in KGs, refines them with Learning-to-Rank models, and integrates top-ranked subgraphs into zero-shot prompts for LLMs.", "result": "The method achieves significant improvements, outperforming baselines by up to 44.4 points in F1 scores on biomedical and open-domain datasets.", "conclusion": "Integrating KGs with LLMs enhances knowledge-based causal discovery, offering a more reliable alternative to traditional methods."}}
{"id": "2506.08216", "pdf": "https://arxiv.org/pdf/2506.08216", "abs": "https://arxiv.org/abs/2506.08216", "authors": ["Shahaf Bassan", "Guy Amir", "Meirav Zehavi", "Guy Katz"], "title": "What makes an Ensemble (Un) Interpretable?", "categories": ["cs.LG", "cs.CC", "cs.LO"], "comment": "To appear in ICML 2025", "summary": "Ensemble models are widely recognized in the ML community for their limited\ninterpretability. For instance, while a single decision tree is considered\ninterpretable, ensembles of trees (e.g., boosted trees) are often treated as\nblack-boxes. Despite this folklore recognition, there remains a lack of\nrigorous mathematical understanding of what particularly makes an ensemble\n(un)-interpretable, including how fundamental factors like the (1) *number*,\n(2) *size*, and (3) *type* of base models influence its interpretability. In\nthis work, we seek to bridge this gap by applying concepts from computational\ncomplexity theory to study the challenges of generating explanations for\nvarious ensemble configurations. Our analysis uncovers nuanced complexity\npatterns influenced by various factors. For example, we demonstrate that under\nstandard complexity assumptions like P$\\neq$NP, interpreting ensembles remains\nintractable even when base models are of constant size. Surprisingly, the\ncomplexity changes drastically with the number of base models: small ensembles\nof decision trees are efficiently interpretable, whereas interpreting ensembles\nwith even a constant number of linear models remains intractable. We believe\nthat our findings provide a more robust foundation for understanding the\ninterpretability of ensembles, emphasizing the benefits of examining it through\na computational complexity lens.", "AI": {"tldr": "The paper explores why ensemble models are hard to interpret, using computational complexity theory to analyze factors like the number, size, and type of base models.", "motivation": "Despite the common belief that ensembles are less interpretable, there's no rigorous understanding of why. This work aims to mathematically explain what makes ensembles (un)interpretable.", "method": "The study applies computational complexity theory to analyze the interpretability of ensembles, focusing on factors like base model count, size, and type.", "result": "Findings show interpretability varies: small tree ensembles are interpretable, but even constant-sized linear model ensembles are intractable.", "conclusion": "The work provides a theoretical foundation for ensemble interpretability, highlighting the value of a computational complexity perspective."}}
{"id": "2506.08436", "pdf": "https://arxiv.org/pdf/2506.08436", "abs": "https://arxiv.org/abs/2506.08436", "authors": ["Jiujun He", "Huazhen Lin"], "title": "Olica: Efficient Structured Pruning of Large Language Models without Retraining", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Most existing structured pruning methods for Large Language Models (LLMs)\nrequire substantial computational and data resources for retraining to\nreestablish the corrupted correlations, making them prohibitively expensive. To\naddress this, we propose a pruning framework for LLMs called Orthogonal\ndecomposition and Linear Calibration (Olica), which eliminates the need for\nretraining. A key observation is that the multi-head attention (MHA) layer\ndepends on two types of matrix products. By treating these matrix products as\nunified entities and applying principal component analysis (PCA), we extract\nthe most important information to compress LLMs without sacrificing accuracy or\ndisrupting their original structure. Consequently, retraining becomes\nunnecessary. A fast decomposition method is devised, reducing the complexity of\nPCA by a factor of the square of the number of attention heads. Additionally,\nto mitigate error accumulation problem caused by pruning the feed-forward\nnetwork (FFN) layer, we introduce a linear calibration method to reconstruct\nthe residual errors of pruned layers using low-rank matrices. By leveraging\nsingular value decomposition (SVD) on the solution of the least-squares\nproblem, these matrices are obtained without requiring retraining. Extensive\nexperiments show that the proposed Olica is efficient in terms of data usage,\nGPU memory, and running time, while delivering superior performance across\nmultiple benchmarks.", "AI": {"tldr": "Olica is a pruning framework for LLMs that avoids retraining by using PCA and SVD, improving efficiency without accuracy loss.", "motivation": "Existing pruning methods for LLMs are costly due to retraining needs; Olica aims to eliminate this requirement.", "method": "Uses PCA on MHA layers and SVD-based linear calibration for FFN layers to compress LLMs without retraining.", "result": "Olica reduces computational costs and maintains performance across benchmarks.", "conclusion": "Olica offers an efficient, retraining-free pruning solution for LLMs."}}
{"id": "2506.08456", "pdf": "https://arxiv.org/pdf/2506.08456", "abs": "https://arxiv.org/abs/2506.08456", "authors": ["June Suk Choi", "Kyungmin Lee", "Sihyun Yu", "Yisol Choi", "Jinwoo Shin", "Kimin Lee"], "title": "Enhancing Motion Dynamics of Image-to-Video Models via Adaptive Low-Pass Guidance", "categories": ["cs.CV"], "comment": "Preprint. Under review. Project page available at\n  http://choi403.github.io/ALG", "summary": "Recent text-to-video (T2V) models have demonstrated strong capabilities in\nproducing high-quality, dynamic videos. To improve the visual controllability,\nrecent works have considered fine-tuning pre-trained T2V models to support\nimage-to-video (I2V) generation. However, such adaptation frequently suppresses\nmotion dynamics of generated outputs, resulting in more static videos compared\nto their T2V counterparts. In this work, we analyze this phenomenon and\nidentify that it stems from the premature exposure to high-frequency details in\nthe input image, which biases the sampling process toward a shortcut trajectory\nthat overfits to the static appearance of the reference image. To address this,\nwe propose adaptive low-pass guidance (ALG), a simple fix to the I2V model\nsampling procedure to generate more dynamic videos without compromising\nper-frame image quality. Specifically, ALG adaptively modulates the frequency\ncontent of the conditioning image by applying low-pass filtering at the early\nstage of denoising. Extensive experiments demonstrate that ALG significantly\nimproves the temporal dynamics of generated videos, while preserving image\nfidelity and text alignment. Especially, under VBench-I2V test suite, ALG\nachieves an average improvement of 36% in dynamic degree without a significant\ndrop in video quality or image fidelity.", "AI": {"tldr": "The paper addresses the issue of static videos in image-to-video (I2V) generation by proposing adaptive low-pass guidance (ALG), which improves motion dynamics without sacrificing image quality.", "motivation": "Fine-tuning text-to-video (T2V) models for I2V often results in static videos due to premature exposure to high-frequency details in input images, biasing the sampling process.", "method": "The authors propose ALG, which adaptively applies low-pass filtering to the conditioning image during early denoising stages to enhance motion dynamics.", "result": "ALG improves temporal dynamics by 36% in dynamic degree (measured by VBench-I2V) while maintaining image fidelity and text alignment.", "conclusion": "ALG effectively addresses the static video issue in I2V generation, offering a simple yet impactful solution."}}
{"id": "2506.08800", "pdf": "https://arxiv.org/pdf/2506.08800", "abs": "https://arxiv.org/abs/2506.08800", "authors": ["Irene Testini", "Jos\u00e9 Hern\u00e1ndez-Orallo", "Lorenzo Pacchiardi"], "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Data science aims to extract insights from data to support decision-making\nprocesses. Recently, Large Language Models (LLMs) are increasingly used as\nassistants for data science, by suggesting ideas, techniques and small code\nsnippets, or for the interpretation of results and reporting. Proper automation\nof some data-science activities is now promised by the rise of LLM agents,\ni.e., AI systems powered by an LLM equipped with additional affordances--such\nas code execution and knowledge bases--that can perform self-directed actions\nand interact with digital environments. In this paper, we survey the evaluation\nof LLM assistants and agents for data science. We find (1) a dominant focus on\na small subset of goal-oriented activities, largely ignoring data management\nand exploratory activities; (2) a concentration on pure assistance or fully\nautonomous agents, without considering intermediate levels of human-AI\ncollaboration; and (3) an emphasis on human substitution, therefore neglecting\nthe possibility of higher levels of automation thanks to task transformation.", "AI": {"tldr": "The paper surveys the evaluation of LLM assistants and agents in data science, highlighting gaps in focus on data management, human-AI collaboration, and task transformation.", "motivation": "To assess how LLMs are evaluated as assistants and agents in data science, identifying current limitations and overlooked areas.", "method": "Survey of existing evaluations of LLM assistants and agents in data science.", "result": "Identified gaps: narrow focus on goal-oriented tasks, lack of intermediate human-AI collaboration, and neglect of task transformation potential.", "conclusion": "Calls for broader evaluation criteria, including data management, collaborative models, and transformative automation in LLM applications for data science."}}
{"id": "2506.08226", "pdf": "https://arxiv.org/pdf/2506.08226", "abs": "https://arxiv.org/abs/2506.08226", "authors": ["Arthur Feeney", "Kuei-Hsiang Huang", "Aparna Chandramowlishwaran"], "title": "Mondrian: Transformer Operators via Domain Decomposition", "categories": ["cs.LG"], "comment": "26 pages, 7 figures", "summary": "Operator learning enables data-driven modeling of partial differential\nequations (PDEs) by learning mappings between function spaces. However, scaling\ntransformer-based operator models to high-resolution, multiscale domains\nremains a challenge due to the quadratic cost of attention and its coupling to\ndiscretization. We introduce \\textbf{Mondrian}, transformer operators that\ndecompose a domain into non-overlapping subdomains and apply attention over\nsequences of subdomain-restricted functions. Leveraging principles from domain\ndecomposition, Mondrian decouples attention from discretization. Within each\nsubdomain, it replaces standard layers with expressive neural operators, and\nattention across subdomains is computed via softmax-based inner products over\nfunctions. The formulation naturally extends to hierarchical windowed and\nneighborhood attention, supporting both local and global interactions. Mondrian\nachieves strong performance on Allen-Cahn and Navier-Stokes PDEs, demonstrating\nresolution scaling without retraining. These results highlight the promise of\ndomain-decomposed attention for scalable and general-purpose neural operators.", "AI": {"tldr": "Mondrian introduces transformer operators for scalable PDE modeling by decomposing domains into subdomains, decoupling attention from discretization.", "motivation": "To address the challenge of scaling transformer-based operator models for high-resolution, multiscale PDE domains due to quadratic attention costs.", "method": "Decomposes domains into non-overlapping subdomains, applies attention over subdomain-restricted functions, and uses neural operators within subdomains.", "result": "Achieves strong performance on Allen-Cahn and Navier-Stokes PDEs with resolution scaling without retraining.", "conclusion": "Domain-decomposed attention shows promise for scalable and general-purpose neural operators."}}
{"id": "2506.08477", "pdf": "https://arxiv.org/pdf/2506.08477", "abs": "https://arxiv.org/abs/2506.08477", "authors": ["Fengjun Pan", "Anh Tuan Luu", "Xiaobao Wu"], "title": "Detecting Harmful Memes with Decoupled Understanding and Guided CoT Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Detecting harmful memes is essential for maintaining the integrity of online\nenvironments. However, current approaches often struggle with resource\nefficiency, flexibility, or explainability, limiting their practical deployment\nin content moderation systems. To address these challenges, we introduce\nU-CoT+, a novel framework for harmful meme detection. Instead of relying solely\non prompting or fine-tuning multimodal models, we first develop a high-fidelity\nmeme-to-text pipeline that converts visual memes into detail-preserving textual\ndescriptions. This design decouples meme interpretation from meme\nclassification, thus avoiding immediate reasoning over complex raw visual\ncontent and enabling resource-efficient harmful meme detection with general\nlarge language models (LLMs). Building on these textual descriptions, we\nfurther incorporate targeted, interpretable human-crafted guidelines to guide\nmodels' reasoning under zero-shot CoT prompting. As such, this framework allows\nfor easy adaptation to different harmfulness detection criteria across\nplatforms, regions, and over time, offering high flexibility and\nexplainability. Extensive experiments on seven benchmark datasets validate the\neffectiveness of our framework, highlighting its potential for explainable and\nlow-resource harmful meme detection using small-scale LLMs. Codes and data are\navailable at: https://anonymous.4open.science/r/HMC-AF2B/README.md.", "AI": {"tldr": "U-CoT+ is a framework for harmful meme detection using a meme-to-text pipeline and human-crafted guidelines, enabling resource-efficient and explainable classification with small-scale LLMs.", "motivation": "Current harmful meme detection methods lack resource efficiency, flexibility, and explainability, limiting practical deployment.", "method": "Develops a meme-to-text pipeline for detail-preserving descriptions, then uses zero-shot CoT prompting with human-crafted guidelines for classification.", "result": "Validated on seven benchmark datasets, showing effectiveness for explainable and low-resource detection.", "conclusion": "U-CoT+ offers a flexible, explainable, and efficient solution for harmful meme detection, adaptable across platforms and regions."}}
{"id": "2506.08470", "pdf": "https://arxiv.org/pdf/2506.08470", "abs": "https://arxiv.org/abs/2506.08470", "authors": ["Siyuan Shen", "Ziheng Wang", "Xingyue Peng", "Suan Xia", "Ruiqian Li", "Shiying Li", "Jingyi Yu"], "title": "MARMOT: Masked Autoencoder for Modeling Transient Imaging", "categories": ["cs.CV"], "comment": null, "summary": "Pretrained models have demonstrated impressive success in many modalities\nsuch as language and vision. Recent works facilitate the pretraining paradigm\nin imaging research. Transients are a novel modality, which are captured for an\nobject as photon counts versus arrival times using a precisely time-resolved\nsensor. In particular for non-line-of-sight (NLOS) scenarios, transients of\nhidden objects are measured beyond the sensor's direct line of sight. Using\nNLOS transients, the majority of previous works optimize volume density or\nsurfaces to reconstruct the hidden objects and do not transfer priors learned\nfrom datasets. In this work, we present a masked autoencoder for modeling\ntransient imaging, or MARMOT, to facilitate NLOS applications. Our MARMOT is a\nself-supervised model pretrianed on massive and diverse NLOS transient\ndatasets. Using a Transformer-based encoder-decoder, MARMOT learns features\nfrom partially masked transients via a scanning pattern mask (SPM), where the\nunmasked subset is functionally equivalent to arbitrary sampling, and predicts\nfull measurements. Pretrained on TransVerse-a synthesized transient dataset of\n500K 3D models-MARMOT adapts to downstream imaging tasks using direct feature\ntransfer or decoder finetuning. Comprehensive experiments are carried out in\ncomparisons with state-of-the-art methods. Quantitative and qualitative results\ndemonstrate the efficiency of our MARMOT.", "AI": {"tldr": "MARMOT is a masked autoencoder for transient imaging, pretrained on NLOS datasets, outperforming state-of-the-art methods in reconstructing hidden objects.", "motivation": "Existing NLOS transient methods lack dataset-learned priors; MARMOT aims to leverage pretraining for better performance.", "method": "Uses a Transformer-based encoder-decoder with a scanning pattern mask for self-supervised pretraining on 500K synthesized transients.", "result": "MARMOT shows superior efficiency in downstream tasks via direct feature transfer or finetuning.", "conclusion": "MARMOT advances NLOS imaging by integrating pretraining, demonstrating effectiveness in transient modeling."}}
{"id": "2506.08872", "pdf": "https://arxiv.org/pdf/2506.08872", "abs": "https://arxiv.org/abs/2506.08872", "authors": ["Nataliya Kosmyna", "Eugene Hauptmann", "Ye Tong Yuan", "Jessica Situ", "Xian-Hao Liao", "Ashly Vivian Beresnitzky", "Iris Braunstein", "Pattie Maes"], "title": "Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task", "categories": ["cs.AI"], "comment": "206 pages, 92 figures, 4 tables and appendix", "summary": "This study explores the neural and behavioral consequences of LLM-assisted\nessay writing. Participants were divided into three groups: LLM, Search Engine,\nand Brain-only (no tools). Each completed three sessions under the same\ncondition. In a fourth session, LLM users were reassigned to Brain-only group\n(LLM-to-Brain), and Brain-only users were reassigned to LLM condition\n(Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18\ncompleting session 4. We used electroencephalography (EEG) to assess cognitive\nload during essay writing, and analyzed essays using NLP, as well as scoring\nessays with the help from human teachers and an AI judge. Across groups, NERs,\nn-gram patterns, and topic ontology showed within-group homogeneity. EEG\nrevealed significant differences in brain connectivity: Brain-only participants\nexhibited the strongest, most distributed networks; Search Engine users showed\nmoderate engagement; and LLM users displayed the weakest connectivity.\nCognitive activity scaled down in relation to external tool use. In session 4,\nLLM-to-Brain participants showed reduced alpha and beta connectivity,\nindicating under-engagement. Brain-to-LLM users exhibited higher memory recall\nand activation of occipito-parietal and prefrontal areas, similar to Search\nEngine users. Self-reported ownership of essays was the lowest in the LLM group\nand the highest in the Brain-only group. LLM users also struggled to accurately\nquote their own work. While LLMs offer immediate convenience, our findings\nhighlight potential cognitive costs. Over four months, LLM users consistently\nunderperformed at neural, linguistic, and behavioral levels. These results\nraise concerns about the long-term educational implications of LLM reliance and\nunderscore the need for deeper inquiry into AI's role in learning.", "AI": {"tldr": "The study examines the neural and behavioral effects of LLM-assisted essay writing, revealing cognitive costs like reduced brain connectivity and lower self-reported ownership, despite the convenience of LLMs.", "motivation": "To understand the cognitive and educational implications of using LLMs for writing tasks compared to traditional methods like search engines or unaided writing.", "method": "Participants were divided into LLM, Search Engine, and Brain-only groups, with EEG and NLP used to measure cognitive load and essay quality. Some participants switched groups in a fourth session.", "result": "LLM users showed weaker brain connectivity, lower essay ownership, and underperformance in neural, linguistic, and behavioral metrics compared to other groups.", "conclusion": "LLM reliance may have long-term cognitive costs, raising concerns about its educational impact and highlighting the need for further research on AI's role in learning."}}
{"id": "2506.08228", "pdf": "https://arxiv.org/pdf/2506.08228", "abs": "https://arxiv.org/abs/2506.08228", "authors": ["Mustafa Baniodeh", "Kratarth Goel", "Scott Ettinger", "Carlos Fuertes", "Ari Seff", "Tim Shen", "Cole Gulino", "Chenjie Yang", "Ghassen Jerfel", "Dokook Choe", "Rui Wang", "Vinutha Kallem", "Sergio Casas", "Rami Al-Rfou", "Benjamin Sapp", "Dragomir Anguelov"], "title": "Scaling Laws of Motion Forecasting and Planning -- A Technical Report", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study the empirical scaling laws of a family of encoder-decoder\nautoregressive transformer models on the task of joint motion forecasting and\nplanning in the autonomous driving domain. Using a 500 thousand hours driving\ndataset, we demonstrate that, similar to language modeling, model performance\nimproves as a power-law function of the total compute budget, and we observe a\nstrong correlation between model training loss and model evaluation metrics.\nMost interestingly, closed-loop metrics also improve with scaling, which has\nimportant implications for the suitability of open-loop metrics for model\ndevelopment and hill climbing. We also study the optimal scaling of the number\nof transformer parameters and the training data size for a training\ncompute-optimal model. We find that as the training compute budget grows,\noptimal scaling requires increasing the model size 1.5x as fast as the dataset\nsize. We also study inference-time compute scaling, where we observe that\nsampling and clustering the output of smaller models makes them competitive\nwith larger models, up to a crossover point beyond which a larger models\nbecomes more inference-compute efficient. Overall, our experimental results\ndemonstrate that optimizing the training and inference-time scaling properties\nof motion forecasting and planning models is a key lever for improving their\nperformance to address a wide variety of driving scenarios. Finally, we briefly\nstudy the utility of training on general logged driving data of other agents to\nimprove the performance of the ego-agent, an important research area to address\nthe scarcity of robotics data for large capacity models training.", "AI": {"tldr": "The paper explores scaling laws for encoder-decoder transformer models in autonomous driving, showing performance improves with compute and data scaling, and highlights the importance of optimizing training and inference-time compute.", "motivation": "To understand how scaling compute, model size, and data impacts performance in joint motion forecasting and planning for autonomous driving, and to assess the suitability of open-loop metrics.", "method": "Empirical study using a 500K-hour driving dataset, analyzing power-law scaling of compute, model size, and data, and comparing open-loop and closed-loop metrics.", "result": "Performance improves with compute scaling; optimal model size grows 1.5x faster than dataset size. Smaller models with sampling/clustering can compete with larger ones up to a point.", "conclusion": "Optimizing scaling properties is key for performance. Training on general logged data can address data scarcity for large models."}}
{"id": "2506.08479", "pdf": "https://arxiv.org/pdf/2506.08479", "abs": "https://arxiv.org/abs/2506.08479", "authors": ["Chihiro Taguchi", "Seiji Maekawa", "Nikita Bhutani"], "title": "Efficient Context Selection for Long-Context QA: No Tuning, No Iteration, Just Adaptive-$k$", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "26 pages, 16 tables, 5 figures", "summary": "Retrieval-augmented generation (RAG) and long-context language models (LCLMs)\nboth address context limitations of LLMs in open-domain question answering\n(QA). However, optimal external context to retrieve remains an open problem:\nfixing the retrieval size risks either wasting tokens or omitting key evidence.\nExisting adaptive methods like Self-RAG and Self-Route rely on iterative LLM\nprompting and perform well on factoid QA, but struggle with aggregation QA,\nwhere the optimal context size is both unknown and variable. We present\nAdaptive-$k$ retrieval, a simple and effective single-pass method that\nadaptively selects the number of passages based on the distribution of the\nsimilarity scores between the query and the candidate passages. It does not\nrequire model fine-tuning, extra LLM inferences or changes to existing\nretriever-reader pipelines. On both factoid and aggregation QA benchmarks,\nAdaptive-$k$ matches or outperforms fixed-$k$ baselines while using up to 10x\nfewer tokens than full-context input, yet still retrieves 70% of relevant\npassages. It improves accuracy across five LCLMs and two embedding models,\nhighlighting that dynamically adjusting context size leads to more efficient\nand accurate QA.", "AI": {"tldr": "Adaptive-$k$ retrieval dynamically selects the number of passages for QA tasks, outperforming fixed methods while using fewer tokens.", "motivation": "Addressing the challenge of optimal context retrieval in QA, where fixed sizes waste tokens or miss key evidence.", "method": "Adaptive-$k$ retrieval selects passages based on similarity scores, without fine-tuning or extra LLM inferences.", "result": "Matches or outperforms fixed baselines, uses fewer tokens, and retrieves 70% of relevant passages.", "conclusion": "Dynamic context adjustment improves QA efficiency and accuracy across models."}}
{"id": "2506.08512", "pdf": "https://arxiv.org/pdf/2506.08512", "abs": "https://arxiv.org/abs/2506.08512", "authors": ["Zhiyi Zhu", "Xiaoyu Wu", "Zihao Liu", "Linlin Yang"], "title": "MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Video Temporal Grounding (VTG), which aims to localize video clips\ncorresponding to natural language queries, is a fundamental yet challenging\ntask in video understanding. Existing Transformer-based methods often suffer\nfrom redundant attention and suboptimal multi-modal alignment. To address these\nlimitations, we propose MLVTG, a novel framework that integrates two key\nmodules: MambaAligner and LLMRefiner. MambaAligner uses stacked Vision Mamba\nblocks as a backbone instead of Transformers to model temporal dependencies and\nextract robust video representations for multi-modal alignment. LLMRefiner\nleverages the specific frozen layer of a pre-trained Large Language Model (LLM)\nto implicitly transfer semantic priors, enhancing multi-modal alignment without\nfine-tuning. This dual alignment strategy, temporal modeling via structured\nstate-space dynamics and semantic purification via textual priors, enables more\nprecise localization. Extensive experiments on QVHighlights, Charades-STA, and\nTVSum demonstrate that MLVTG achieves state-of-the-art performance and\nsignificantly outperforms existing baselines.", "AI": {"tldr": "MLVTG improves video temporal grounding by combining MambaAligner for temporal modeling and LLMRefiner for semantic alignment, outperforming existing methods.", "motivation": "Existing Transformer-based VTG methods face issues like redundant attention and poor multi-modal alignment, limiting performance.", "method": "MLVTG uses MambaAligner (Vision Mamba blocks) for temporal modeling and LLMRefiner (frozen LLM layer) for semantic alignment.", "result": "MLVTG achieves state-of-the-art performance on QVHighlights, Charades-STA, and TVSum datasets.", "conclusion": "The dual alignment strategy in MLVTG effectively addresses VTG challenges, offering superior localization accuracy."}}
{"id": "2506.08898", "pdf": "https://arxiv.org/pdf/2506.08898", "abs": "https://arxiv.org/abs/2506.08898", "authors": ["Mingfeng Fan", "Jianan Zhou", "Yifeng Zhang", "Yaoxin Wu", "Jinbiao Chen", "Guillaume Adrien Sartoretti"], "title": "Preference-Driven Multi-Objective Combinatorial Optimization with Conditional Computation", "categories": ["cs.AI"], "comment": "22 pages, 6 figures, under review", "summary": "Recent deep reinforcement learning methods have achieved remarkable success\nin solving multi-objective combinatorial optimization problems (MOCOPs) by\ndecomposing them into multiple subproblems, each associated with a specific\nweight vector. However, these methods typically treat all subproblems equally\nand solve them using a single model, hindering the effective exploration of the\nsolution space and thus leading to suboptimal performance. To overcome the\nlimitation, we propose POCCO, a novel plug-and-play framework that enables\nadaptive selection of model structures for subproblems, which are subsequently\noptimized based on preference signals rather than explicit reward values.\nSpecifically, we design a conditional computation block that routes subproblems\nto specialized neural architectures. Moreover, we propose a preference-driven\noptimization algorithm that learns pairwise preferences between winning and\nlosing solutions. We evaluate the efficacy and versatility of POCCO by applying\nit to two state-of-the-art neural methods for MOCOPs. Experimental results\nacross four classic MOCOP benchmarks demonstrate its significant superiority\nand strong generalization.", "AI": {"tldr": "POCCO is a plug-and-play framework for MOCOPs that adaptively selects model structures for subproblems and optimizes them using preference signals, outperforming existing methods.", "motivation": "Existing methods treat all subproblems equally with a single model, limiting solution space exploration and performance.", "method": "POCCO uses a conditional computation block to route subproblems to specialized architectures and a preference-driven optimization algorithm for pairwise preferences.", "result": "POCCO significantly outperforms state-of-the-art methods on four MOCOP benchmarks, showing strong generalization.", "conclusion": "POCCO's adaptive framework enhances performance in MOCOPs by leveraging specialized architectures and preference-driven optimization."}}
{"id": "2506.08231", "pdf": "https://arxiv.org/pdf/2506.08231", "abs": "https://arxiv.org/abs/2506.08231", "authors": ["Melissa Estevez", "Nisha Singh", "Lauren Dyson", "Blythe Adamson", "Qianyu Yuan", "Megan W. Hildner", "Erin Fidyk", "Olive Mbah", "Farhad Khan", "Kathi Seidl-Rathkopf", "Aaron B. Cohen"], "title": "Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "18 pages, 3 tables, 1 figure", "summary": "Large language models (LLMs) are increasingly used to extract clinical data\nfrom electronic health records (EHRs), offering significant improvements in\nscalability and efficiency for real-world data (RWD) curation in oncology.\nHowever, the adoption of LLMs introduces new challenges in ensuring the\nreliability, accuracy, and fairness of extracted data, which are essential for\nresearch, regulatory, and clinical applications. Existing quality assurance\nframeworks for RWD and artificial intelligence do not fully address the unique\nerror modes and complexities associated with LLM-extracted data. In this paper,\nwe propose a comprehensive framework for evaluating the quality of clinical\ndata extracted by LLMs. The framework integrates variable-level performance\nbenchmarking against expert human abstraction, automated verification checks\nfor internal consistency and plausibility, and replication analyses comparing\nLLM-extracted data to human-abstracted datasets or external standards. This\nmultidimensional approach enables the identification of variables most in need\nof improvement, systematic detection of latent errors, and confirmation of\ndataset fitness-for-purpose in real-world research. Additionally, the framework\nsupports bias assessment by stratifying metrics across demographic subgroups.\nBy providing a rigorous and transparent method for assessing LLM-extracted RWD,\nthis framework advances industry standards and supports the trustworthy use of\nAI-powered evidence generation in oncology research and practice.", "AI": {"tldr": "A framework for evaluating LLM-extracted clinical data in oncology, addressing reliability, accuracy, and fairness through benchmarking, verification, and bias assessment.", "motivation": "LLMs improve EHR data extraction but introduce reliability and fairness challenges, requiring a robust quality assurance framework.", "method": "Proposes a multidimensional framework: benchmarking against human abstraction, automated checks, replication analyses, and bias assessment.", "result": "Identifies variables needing improvement, detects errors, and confirms dataset fitness-for-purpose, while assessing bias.", "conclusion": "The framework enhances LLM-extracted RWD quality, supporting trustworthy AI use in oncology research and practice."}}
{"id": "2506.08480", "pdf": "https://arxiv.org/pdf/2506.08480", "abs": "https://arxiv.org/abs/2506.08480", "authors": ["Huixuan Zhang", "Xiaojun Wan"], "title": "Re-Thinking the Automatic Evaluation of Image-Text Alignment in Text-to-Image Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Text-to-image models often struggle to generate images that precisely match\ntextual prompts. Prior research has extensively studied the evaluation of\nimage-text alignment in text-to-image generation. However, existing evaluations\nprimarily focus on agreement with human assessments, neglecting other critical\nproperties of a trustworthy evaluation framework. In this work, we first\nidentify two key aspects that a reliable evaluation should address. We then\nempirically demonstrate that current mainstream evaluation frameworks fail to\nfully satisfy these properties across a diverse range of metrics and models.\nFinally, we propose recommendations for improving image-text alignment\nevaluation.", "AI": {"tldr": "The paper critiques current text-to-image evaluation frameworks for lacking reliability and proposes improvements.", "motivation": "Existing evaluations focus on human agreement but miss other critical properties for trustworthy assessment.", "method": "Identifies key aspects for reliable evaluation and tests current frameworks against them.", "result": "Current frameworks fail to fully meet these properties across metrics and models.", "conclusion": "Recommends improvements for better image-text alignment evaluation."}}
{"id": "2506.08526", "pdf": "https://arxiv.org/pdf/2506.08526", "abs": "https://arxiv.org/abs/2506.08526", "authors": ["Zhongtao Tian", "Wenhao Huang", "Zhidong Chen", "Xiao Wei Sun"], "title": "Robust Visual Localization via Semantic-Guided Multi-Scale Transformer", "categories": ["cs.CV"], "comment": null, "summary": "Visual localization remains challenging in dynamic environments where\nfluctuating lighting, adverse weather, and moving objects disrupt appearance\ncues. Despite advances in feature representation, current absolute pose\nregression methods struggle to maintain consistency under varying conditions.\nTo address this challenge, we propose a framework that synergistically combines\nmulti-scale feature learning with semantic scene understanding. Our approach\nemploys a hierarchical Transformer with cross-scale attention to fuse geometric\ndetails and contextual cues, preserving spatial precision while adapting to\nenvironmental changes. We improve the performance of this architecture with\nsemantic supervision via neural scene representation during training, guiding\nthe network to learn view-invariant features that encode persistent structural\ninformation while suppressing complex environmental interference. Experiments\non TartanAir demonstrate that our approach outperforms existing pose regression\nmethods in challenging scenarios with dynamic objects, illumination changes,\nand occlusions. Our findings show that integrating multi-scale processing with\nsemantic guidance offers a promising strategy for robust visual localization in\nreal-world dynamic environments.", "AI": {"tldr": "A framework combining multi-scale feature learning and semantic scene understanding improves visual localization in dynamic environments.", "motivation": "Challenges in visual localization due to dynamic conditions like lighting changes, weather, and moving objects disrupt appearance cues.", "method": "Hierarchical Transformer with cross-scale attention and semantic supervision via neural scene representation.", "result": "Outperforms existing pose regression methods in dynamic scenarios on TartanAir dataset.", "conclusion": "Multi-scale processing with semantic guidance enhances robustness in real-world dynamic environments."}}
{"id": "2506.08957", "pdf": "https://arxiv.org/pdf/2506.08957", "abs": "https://arxiv.org/abs/2506.08957", "authors": ["Yash Ranjan", "Rahul Sengupta", "Anand Rangarajan", "Sanjay Ranka"], "title": "IntTrajSim: Trajectory Prediction for Simulating Multi-Vehicle driving at Signalized Intersections", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Traffic simulators are widely used to study the operational efficiency of\nroad infrastructure, but their rule-based approach limits their ability to\nmimic real-world driving behavior. Traffic intersections are critical\ncomponents of the road infrastructure, both in terms of safety risk (nearly 28%\nof fatal crashes and 58% of nonfatal crashes happen at intersections) as well\nas the operational efficiency of a road corridor. This raises an important\nquestion: can we create a data-driven simulator that can mimic the macro- and\nmicro-statistics of the driving behavior at a traffic intersection? Deep\nGenerative Modeling-based trajectory prediction models provide a good starting\npoint to model the complex dynamics of vehicles at an intersection. But they\nare not tested in a \"live\" micro-simulation scenario and are not evaluated on\ntraffic engineering-related metrics. In this study, we propose traffic\nengineering-related metrics to evaluate generative trajectory prediction models\nand provide a simulation-in-the-loop pipeline to do so. We also provide a\nmulti-headed self-attention-based trajectory prediction model that incorporates\nthe signal information, which outperforms our previous models on the evaluation\nmetrics.", "AI": {"tldr": "The paper proposes a data-driven traffic simulator using deep generative models to mimic real-world driving behavior at intersections, introducing new evaluation metrics and a simulation-in-the-loop pipeline.", "motivation": "Traditional rule-based traffic simulators fail to accurately mimic real-world driving behavior, especially at intersections, which are critical for safety and efficiency.", "method": "The study uses deep generative modeling for trajectory prediction, introduces traffic engineering metrics, and develops a simulation-in-the-loop pipeline. A multi-headed self-attention-based model incorporating signal information is also proposed.", "result": "The proposed model outperforms previous models on the new evaluation metrics.", "conclusion": "The study demonstrates the feasibility of a data-driven simulator for traffic intersections, improving accuracy and relevance for traffic engineering."}}
{"id": "2506.08240", "pdf": "https://arxiv.org/pdf/2506.08240", "abs": "https://arxiv.org/abs/2506.08240", "authors": ["Dongkyu Cho", "Rumi Chunara"], "title": "Dealing with the Evil Twins: Improving Random Augmentation by Addressing Catastrophic Forgetting of Diverse Augmentations", "categories": ["cs.LG"], "comment": "12 pages, 6 figures", "summary": "Data augmentation is a promising tool for enhancing out-of-distribution\ngeneralization, where the key is to produce diverse, challenging variations of\nthe source domain via costly targeted augmentations that maximize its\ngeneralization effect. Conversely, random augmentation is inexpensive but is\ndeemed suboptimal due to its limited effect. In this paper, we revisit random\naugmentation and explore methods to address its shortcomings. We show that the\nstochastic nature of random augmentation can produce a set of colliding\naugmentations that distorts the learned features, similar to catastrophic\nforgetting. We propose a simple solution that improves the generalization\neffect of random augmentation by addressing forgetting, which displays strong\ngeneralization performance across various single source domain generalization\n(sDG) benchmarks.", "AI": {"tldr": "The paper revisits random augmentation, addressing its shortcomings by mitigating feature distortion caused by colliding augmentations, and proposes a simple solution to improve its generalization effect.", "motivation": "Random augmentation is inexpensive but suboptimal due to limited generalization effects. The paper aims to address its shortcomings, particularly the distortion of learned features caused by colliding augmentations.", "method": "The authors propose a solution to mitigate the forgetting effect in random augmentation, enhancing its generalization performance.", "result": "The proposed method demonstrates strong generalization performance across various single source domain generalization (sDG) benchmarks.", "conclusion": "The study shows that addressing the forgetting issue in random augmentation can significantly improve its effectiveness for out-of-distribution generalization."}}
{"id": "2506.08487", "pdf": "https://arxiv.org/pdf/2506.08487", "abs": "https://arxiv.org/abs/2506.08487", "authors": ["Sumanth Manduru", "Carlotta Domeniconi"], "title": "Fairness is Not Silence: Unmasking Vacuous Neutrality in Small Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid adoption of Small Language Models (SLMs) for on-device and\nresource-constrained deployments has outpaced our understanding of their\nethical risks. To the best of our knowledge, we present the first large-scale\naudit of instruction-tuned SLMs spanning 0.5 to 5 billion parameters-an\noverlooked \"middle tier\" between BERT-class encoders and flagship LLMs. Our\nevaluation includes nine open-source models from the Qwen 2.5, LLaMA 3.2, Gemma\n3, and Phi families. Using the BBQ benchmark under zero-shot prompting, we\nanalyze both utility and fairness across ambiguous and disambiguated contexts.\nThis evaluation reveals three key insights. First, competence and fairness need\nnot be antagonistic: Phi models achieve F1 scores exceeding 90 percent while\nexhibiting minimal bias, showing that efficient and ethical NLP is attainable.\nSecond, social bias varies significantly by architecture: Qwen 2.5 models may\nappear fair, but this often reflects vacuous neutrality, random guessing, or\nevasive behavior rather than genuine ethical alignment. In contrast, LLaMA 3.2\nmodels exhibit stronger stereotypical bias, suggesting overconfidence rather\nthan neutrality. Third, compression introduces nuanced trade-offs: 4-bit AWQ\nquantization improves F1 scores in ambiguous settings for LLaMA 3.2-3B but\nincreases disability-related bias in Phi-4-Mini by over 7 percentage points.\nThese insights provide practical guidance for the responsible deployment of\nSLMs in applications demanding fairness and efficiency, particularly benefiting\nsmall enterprises and resource-constrained environments.", "AI": {"tldr": "The paper audits instruction-tuned Small Language Models (SLMs) for ethical risks, revealing insights on fairness, bias, and trade-offs in resource-constrained deployments.", "motivation": "The rapid adoption of SLMs has outpaced understanding of their ethical risks, prompting the need for a large-scale audit to evaluate fairness and utility.", "method": "The study evaluates nine open-source SLMs (0.5-5B parameters) using the BBQ benchmark under zero-shot prompting, analyzing utility and fairness in ambiguous/disambiguated contexts.", "result": "Key findings: 1) Phi models show high competence and minimal bias; 2) Social bias varies by architecture (Qwen 2.5 appears fair but may lack genuine alignment, LLaMA 3.2 shows overconfidence); 3) Compression (e.g., 4-bit AWQ) introduces nuanced trade-offs in performance and bias.", "conclusion": "The insights guide responsible SLM deployment, balancing fairness and efficiency, especially for small enterprises and resource-constrained environments."}}
{"id": "2506.08529", "pdf": "https://arxiv.org/pdf/2506.08529", "abs": "https://arxiv.org/abs/2506.08529", "authors": ["Xijun Wang", "Xin Li", "Bingchen Li", "Zhibo Chen"], "title": "LiftVSR: Lifting Image Diffusion to Video Super-Resolution via Hybrid Temporal Modeling with Only 4$\\times$RTX 4090s", "categories": ["cs.CV"], "comment": "Project page: https://kopperx.github.io/projects/liftvsr", "summary": "Diffusion models have significantly advanced video super-resolution (VSR) by\nenhancing perceptual quality, largely through elaborately designed temporal\nmodeling to ensure inter-frame consistency. However, existing methods usually\nsuffer from limited temporal coherence and prohibitively high computational\ncosts (e.g., typically requiring over 8 NVIDIA A100-80G GPUs), especially for\nlong videos. In this work, we propose LiftVSR, an efficient VSR framework that\nleverages and elevates the image-wise diffusion prior from PixArt-$\\alpha$,\nachieving state-of-the-art results using only 4$\\times$RTX 4090 GPUs. To\nbalance long-term consistency and efficiency, we introduce a hybrid temporal\nmodeling mechanism that decomposes temporal learning into two complementary\ncomponents: (i) Dynamic Temporal Attention (DTA) for fine-grained temporal\nmodeling within short frame segment ($\\textit{i.e.}$, low complexity), and (ii)\nAttention Memory Cache (AMC) for long-term temporal modeling across segments\n($\\textit{i.e.}$, consistency). Specifically, DTA identifies multiple token\nflows across frames within multi-head query and key tokens to warp inter-frame\ncontexts in the value tokens. AMC adaptively aggregates historical segment\ninformation via a cache unit, ensuring long-term coherence with minimal\noverhead. To further stabilize the cache interaction during inference, we\nintroduce an asymmetric sampling strategy that mitigates feature mismatches\narising from different diffusion sampling steps. Extensive experiments on\nseveral typical VSR benchmarks have demonstrated that LiftVSR achieves\nimpressive performance with significantly lower computational costs.", "AI": {"tldr": "LiftVSR is an efficient video super-resolution framework using diffusion models, achieving state-of-the-art results with reduced computational costs via hybrid temporal modeling.", "motivation": "Existing VSR methods suffer from limited temporal coherence and high computational costs, especially for long videos.", "method": "LiftVSR combines Dynamic Temporal Attention (DTA) for short-term modeling and Attention Memory Cache (AMC) for long-term consistency, with an asymmetric sampling strategy for stable inference.", "result": "LiftVSR achieves impressive performance on VSR benchmarks with significantly lower computational costs (4\u00d7RTX 4090 GPUs).", "conclusion": "LiftVSR balances efficiency and long-term consistency, advancing VSR with practical computational feasibility."}}
{"id": "2506.08963", "pdf": "https://arxiv.org/pdf/2506.08963", "abs": "https://arxiv.org/abs/2506.08963", "authors": ["Yash Ranjan", "Rahul Sengupta", "Anand Rangarajan", "Sanjay Ranka"], "title": "Evaluating Generative Vehicle Trajectory Models for Traffic Intersection Dynamics", "categories": ["cs.AI"], "comment": null, "summary": "Traffic Intersections are vital to urban road networks as they regulate the\nmovement of people and goods. However, they are regions of conflicting\ntrajectories and are prone to accidents. Deep Generative models of traffic\ndynamics at signalized intersections can greatly help traffic authorities\nbetter understand the efficiency and safety aspects. At present, models are\nevaluated on computational metrics that primarily look at trajectory\nreconstruction errors. They are not evaluated online in a `live'\nmicrosimulation scenario. Further, these metrics do not adequately consider\ntraffic engineering-specific concerns such as red-light violations, unallowed\nstoppage, etc. In this work, we provide a comprehensive analytics tool to\ntrain, run, and evaluate models with metrics that give better insights into\nmodel performance from a traffic engineering point of view. We train a\nstate-of-the-art multi-vehicle trajectory forecasting model on a large dataset\ncollected by running a calibrated scenario of a real-world urban intersection.\nWe then evaluate the performance of the prediction models, online in a\nmicrosimulator, under unseen traffic conditions. We show that despite using\nideally-behaved trajectories as input, and achieving low trajectory\nreconstruction errors, the generated trajectories show behaviors that break\ntraffic rules. We introduce new metrics to evaluate such undesired behaviors\nand present our results.", "AI": {"tldr": "The paper introduces a tool to evaluate deep generative models for traffic intersection dynamics, focusing on traffic engineering metrics like rule violations, not just trajectory errors.", "motivation": "Current models for traffic dynamics at intersections lack evaluation on live microsimulations and ignore traffic-specific concerns like red-light violations.", "method": "A multi-vehicle trajectory forecasting model is trained on real-world intersection data and evaluated online in a microsimulator under unseen conditions.", "result": "Despite low trajectory errors, generated trajectories often violate traffic rules, highlighting the need for better evaluation metrics.", "conclusion": "The proposed tool and new metrics provide better insights into model performance from a traffic engineering perspective."}}
{"id": "2506.08243", "pdf": "https://arxiv.org/pdf/2506.08243", "abs": "https://arxiv.org/abs/2506.08243", "authors": ["Zhenjiang Mao", "Artem Bisliouk", "Rohith Reddy Nama", "Ivan Ruchkin"], "title": "Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance in\nmathematical reasoning tasks when guided by Chain-of-Thought (CoT) prompting.\nHowever, they tend to produce highly confident yet incorrect outputs, which\nposes significant risks in domains like education, where users may lack the\nexpertise to assess reasoning steps. To address this, we propose a structured\nframework that models stepwise confidence as a temporal signal and evaluates it\nusing Signal Temporal Logic (STL). In particular, we define formal STL-based\nconstraints to capture desirable temporal properties and compute robustness\nscores that serve as structured, interpretable confidence estimates. Our\napproach also introduces a set of uncertainty reshaping strategies to enforce\nsmoothness, monotonicity, and causal consistency across the reasoning\ntrajectory. Experiments show that our approach consistently improves\ncalibration metrics and provides more reliable uncertainty estimates than\nconventional confidence aggregation and post-hoc calibration.", "AI": {"tldr": "A framework using Signal Temporal Logic (STL) improves LLM confidence calibration in mathematical reasoning by modeling stepwise confidence and enforcing temporal properties.", "motivation": "LLMs often produce incorrect but confident outputs, risking reliability in domains like education where users may lack expertise to verify reasoning.", "method": "Proposes a structured framework modeling stepwise confidence as a temporal signal, evaluated via STL. Introduces uncertainty reshaping strategies for smoothness, monotonicity, and causal consistency.", "result": "Improves calibration metrics and provides more reliable uncertainty estimates compared to conventional methods.", "conclusion": "The STL-based framework enhances LLM confidence calibration, offering structured and interpretable uncertainty estimates for safer deployment."}}
{"id": "2506.08488", "pdf": "https://arxiv.org/pdf/2506.08488", "abs": "https://arxiv.org/abs/2506.08488", "authors": ["Ashutosh Dwivedi", "Siddhant Shivdutt Singh", "Ashutosh Modi"], "title": "EtiCor++: Towards Understanding Etiquettical Bias in LLMs", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Accepted at ACL Findings 2025, 22 pages (9 pages main content + 4\n  pages references + 9 pages appendix)", "summary": "In recent years, researchers have started analyzing the cultural sensitivity\nof LLMs. In this respect, Etiquettes have been an active area of research.\nEtiquettes are region-specific and are an essential part of the culture of a\nregion; hence, it is imperative to make LLMs sensitive to etiquettes. However,\nthere needs to be more resources in evaluating LLMs for their understanding and\nbias with regard to etiquettes. In this resource paper, we introduce EtiCor++,\na corpus of etiquettes worldwide. We introduce different tasks for evaluating\nLLMs for knowledge about etiquettes across various regions. Further, we\nintroduce various metrics for measuring bias in LLMs. Extensive experimentation\nwith LLMs shows inherent bias towards certain regions.", "AI": {"tldr": "The paper introduces EtiCor++, a corpus for evaluating LLMs' cultural sensitivity to etiquettes, highlighting biases in LLMs.", "motivation": "To address the lack of resources for evaluating LLMs' understanding and bias regarding region-specific etiquettes.", "method": "Introduces EtiCor++, a global etiquette corpus, and tasks/metrics for LLM evaluation.", "result": "Experiments reveal inherent biases in LLMs towards certain regions.", "conclusion": "EtiCor++ provides a framework to assess and mitigate cultural biases in LLMs."}}
{"id": "2506.08541", "pdf": "https://arxiv.org/pdf/2506.08541", "abs": "https://arxiv.org/abs/2506.08541", "authors": ["Qi Yan", "Brian Zhang", "Yutong Zhang", "Daniel Yang", "Joshua White", "Di Chen", "Jiachao Liu", "Langechuan Liu", "Binnan Zhuang", "Shaoshuai Shi", "Renjie Liao"], "title": "TrajFlow: Multi-modal Motion Prediction via Flow Matching", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Efficient and accurate motion prediction is crucial for ensuring safety and\ninformed decision-making in autonomous driving, particularly under dynamic\nreal-world conditions that necessitate multi-modal forecasts. We introduce\nTrajFlow, a novel flow matching-based motion prediction framework that\naddresses the scalability and efficiency challenges of existing generative\ntrajectory prediction methods. Unlike conventional generative approaches that\nemploy i.i.d. sampling and require multiple inference passes to capture diverse\noutcomes, TrajFlow predicts multiple plausible future trajectories in a single\npass, significantly reducing computational overhead while maintaining coherence\nacross predictions. Moreover, we propose a ranking loss based on the\nPlackett-Luce distribution to improve uncertainty estimation of predicted\ntrajectories. Additionally, we design a self-conditioning training technique\nthat reuses the model's own predictions to construct noisy inputs during a\nsecond forward pass, thereby improving generalization and accelerating\ninference. Extensive experiments on the large-scale Waymo Open Motion Dataset\n(WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across\nvarious key metrics, underscoring its effectiveness for safety-critical\nautonomous driving applications. The code and other details are available on\nthe project website https://traj-flow.github.io/.", "AI": {"tldr": "TrajFlow is a flow matching-based motion prediction framework for autonomous driving, offering efficient multi-modal trajectory forecasts in a single pass, with improved uncertainty estimation and generalization.", "motivation": "Ensuring safety and informed decision-making in autonomous driving under dynamic conditions requires efficient and accurate motion prediction, particularly for multi-modal forecasts.", "method": "TrajFlow uses flow matching to predict multiple trajectories in one pass, employs a ranking loss for uncertainty estimation, and a self-conditioning training technique for better generalization.", "result": "TrajFlow achieves state-of-the-art performance on the Waymo Open Motion Dataset, demonstrating efficiency and accuracy.", "conclusion": "TrajFlow is effective for safety-critical autonomous driving applications, offering scalable and efficient motion prediction."}}
{"id": "2506.08970", "pdf": "https://arxiv.org/pdf/2506.08970", "abs": "https://arxiv.org/abs/2506.08970", "authors": ["Jiyao Wei", "Saiping Guan", "Da Li", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng"], "title": "A Survey of Link Prediction in N-ary Knowledge Graphs", "categories": ["cs.AI"], "comment": null, "summary": "N-ary Knowledge Graphs (NKGs) are a specialized type of knowledge graph\ndesigned to efficiently represent complex real-world facts. Unlike traditional\nknowledge graphs, where a fact typically involves two entities, NKGs can\ncapture n-ary facts containing more than two entities. Link prediction in NKGs\naims to predict missing elements within these n-ary facts, which is essential\nfor completing NKGs and improving the performance of downstream applications.\nThis task has recently gained significant attention. In this paper, we present\nthe first comprehensive survey of link prediction in NKGs, providing an\noverview of the field, systematically categorizing existing methods, and\nanalyzing their performance and application scenarios. We also outline\npromising directions for future research.", "AI": {"tldr": "A survey on link prediction in N-ary Knowledge Graphs (NKGs), covering methods, performance, and future directions.", "motivation": "NKGs represent complex facts with multiple entities, but link prediction for missing elements is underexplored.", "method": "Systematic categorization and analysis of existing link prediction methods in NKGs.", "result": "Overview of current methods, their performance, and application scenarios.", "conclusion": "Identifies gaps and suggests future research directions for NKG link prediction."}}
{"id": "2506.08244", "pdf": "https://arxiv.org/pdf/2506.08244", "abs": "https://arxiv.org/abs/2506.08244", "authors": ["Riccardo Ali", "Pietro Li\u00f2", "Jamie Vicary"], "title": "Parameter-free approximate equivariance for tasks with finite group symmetry", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Equivariant neural networks incorporate symmetries through group actions,\nembedding them as an inductive bias to improve performance on a wide variety of\ntasks. However, existing equivariant methods can be computationally intensive,\nwith high parameter counts, and are often tied to a specific architecture. We\npropose a simple zero-parameter approach that imposes approximate equivariance\nfor a finite group in the latent representation, as an additional term in the\nloss function. We conduct experiments which allow the network to learn a group\nrepresentation on the latent space, and show in every case it prefers to learn\nthe regular representation. Fixing this action on the latent space, this yields\na simple method to impose approximate equivariance as an additional loss\npenalty. We benchmark our approach on three datasets and compare it against\nseveral existing equivariant methods, showing that in many cases it achieves\nsimilar or better performance for a fraction of the parameters.", "AI": {"tldr": "A zero-parameter method for approximate equivariance in neural networks, outperforming existing methods in efficiency and performance.", "motivation": "Existing equivariant methods are computationally intensive and architecture-specific, prompting a simpler, more flexible solution.", "method": "Proposes a zero-parameter approach using an additional loss term to impose approximate equivariance in latent space, learning group representations.", "result": "The method learns the regular representation and achieves comparable or better performance with fewer parameters on three datasets.", "conclusion": "The approach offers a lightweight, effective alternative to traditional equivariant methods, enhancing flexibility and efficiency."}}
{"id": "2506.08490", "pdf": "https://arxiv.org/pdf/2506.08490", "abs": "https://arxiv.org/abs/2506.08490", "authors": ["Xiao Wei", "Xiaobao Wang", "Ning Zhuang", "Chenyang Wang", "Longbiao Wang", "Jianwu dang"], "title": "Integration of Old and New Knowledge for Generalized Intent Discovery: A Consistency-driven Prototype-Prompting Framework", "categories": ["cs.CL"], "comment": "9 pages, 2 figures, 7 tables, IJCAI 2025", "summary": "Intent detection aims to identify user intents from natural language inputs,\nwhere supervised methods rely heavily on labeled in-domain (IND) data and\nstruggle with out-of-domain (OOD) intents, limiting their practical\napplicability. Generalized Intent Discovery (GID) addresses this by leveraging\nunlabeled OOD data to discover new intents without additional annotation.\nHowever, existing methods focus solely on clustering unsupervised data while\nneglecting domain adaptation. Therefore, we propose a consistency-driven\nprototype-prompting framework for GID from the perspective of integrating old\nand new knowledge, which includes a prototype-prompting framework for\ntransferring old knowledge from external sources, and a hierarchical\nconsistency constraint for learning new knowledge from target domains. We\nconducted extensive experiments and the results show that our method\nsignificantly outperforms all baseline methods, achieving state-of-the-art\nresults, which strongly demonstrates the effectiveness and generalization of\nour methods. Our source code is publicly available at\nhttps://github.com/smileix/cpp.", "AI": {"tldr": "The paper proposes a consistency-driven prototype-prompting framework for Generalized Intent Discovery (GID) to address the limitations of supervised methods in handling out-of-domain intents.", "motivation": "Supervised intent detection methods struggle with out-of-domain (OOD) intents due to reliance on labeled in-domain (IND) data. GID aims to discover new intents from unlabeled OOD data without additional annotation.", "method": "The framework includes a prototype-prompting component for transferring old knowledge and a hierarchical consistency constraint for learning new knowledge from target domains.", "result": "The method outperforms baseline approaches, achieving state-of-the-art results, demonstrating its effectiveness and generalization.", "conclusion": "The proposed framework effectively integrates old and new knowledge for GID, offering a practical solution for intent discovery in diverse domains."}}
{"id": "2506.08543", "pdf": "https://arxiv.org/pdf/2506.08543", "abs": "https://arxiv.org/abs/2506.08543", "authors": ["Bowei Tian", "Xuntao Lyu", "Meng Liu", "Hongyi Wang", "Ang Li"], "title": "Convergence of Spectral Principal Paths: How Deep Networks Distill Linear Representations from Noisy Inputs", "categories": ["cs.CV"], "comment": "arXiv admin note: text overlap with arXiv:2503.22720", "summary": "High-level representations have become a central focus in enhancing AI\ntransparency and control, shifting attention from individual neurons or\ncircuits to structured semantic directions that align with human-interpretable\nconcepts. Motivated by the Linear Representation Hypothesis (LRH), we propose\nthe Input-Space Linearity Hypothesis (ISLH), which posits that concept-aligned\ndirections originate in the input space and are selectively amplified with\nincreasing depth. We then introduce the Spectral Principal Path (SPP)\nframework, which formalizes how deep networks progressively distill linear\nrepresentations along a small set of dominant spectral directions. Building on\nthis framework, we further demonstrate the multimodal robustness of these\nrepresentations in Vision-Language Models (VLMs). By bridging theoretical\ninsights with empirical validation, this work advances a structured theory of\nrepresentation formation in deep networks, paving the way for improving AI\nrobustness, fairness, and transparency.", "AI": {"tldr": "The paper introduces the Input-Space Linearity Hypothesis (ISLH) and the Spectral Principal Path (SPP) framework to explain how deep networks form human-interpretable representations, validated with Vision-Language Models (VLMs).", "motivation": "To enhance AI transparency and control by understanding how deep networks develop structured, human-interpretable representations.", "method": "Proposes ISLH and the SPP framework to analyze how linear representations form in deep networks, with empirical validation using VLMs.", "result": "Demonstrates that concept-aligned directions originate in the input space and are amplified with depth, showing robustness in VLMs.", "conclusion": "Advances a structured theory of representation formation, contributing to AI robustness, fairness, and transparency."}}
{"id": "2506.09038", "pdf": "https://arxiv.org/pdf/2506.09038", "abs": "https://arxiv.org/abs/2506.09038", "authors": ["Polina Kirichenko", "Mark Ibrahim", "Kamalika Chaudhuri", "Samuel J. Bell"], "title": "AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions", "categories": ["cs.AI"], "comment": null, "summary": "For Large Language Models (LLMs) to be reliably deployed in both everyday and\nhigh-stakes domains, knowing when not to answer is equally critical as\nanswering correctly. Real-world user queries, which can be underspecified,\nill-posed, or fundamentally unanswerable, require LLMs to reason about\nuncertainty and selectively abstain -- i.e., refuse to answer definitively.\nHowever, abstention remains understudied, without a systematic evaluation\nframework for modern LLMs. In this work, we introduce AbstentionBench, a\nlarge-scale benchmark for holistically evaluating abstention across 20 diverse\ndatasets, including questions with unknown answers, underspecification, false\npremises, subjective interpretations, and outdated information. Evaluating 20\nfrontier LLMs reveals abstention is an unsolved problem, and one where scaling\nmodels is of little use. While recent reasoning LLMs have shown impressive\nresults in complex problem solving, surprisingly, we find that reasoning\nfine-tuning degrades abstention (by $24\\%$ on average), even for math and\nscience domains on which reasoning models are explicitly trained. We find that\nwhile a carefully crafted system prompt can boost abstention in practice, it\ndoes not resolve models' fundamental inability to reason about uncertainty. We\nrelease AbstentionBench to foster research into advancing LLM reliability.", "AI": {"tldr": "AbstentionBench is introduced to evaluate LLMs' ability to abstain from answering unreliable queries, revealing it as an unsolved problem unaffected by model scaling or reasoning fine-tuning.", "motivation": "LLMs need to know when not to answer to ensure reliability, but abstention is understudied and lacks systematic evaluation.", "method": "AbstentionBench evaluates 20 LLMs across 20 diverse datasets with unanswerable, underspecified, or subjective questions.", "result": "Scaling models or reasoning fine-tuning doesn't improve abstention; reasoning fine-tuning even degrades it by 24%. System prompts help but don't solve the core issue.", "conclusion": "Abstention remains a challenge for LLMs, requiring further research to enhance reliability."}}
{"id": "2506.08255", "pdf": "https://arxiv.org/pdf/2506.08255", "abs": "https://arxiv.org/abs/2506.08255", "authors": ["Patryk Krukowski", "\u0141ukasz Gorczyca", "Piotr Helm", "Kamil Ksi\u0105\u017cek", "Przemys\u0142aw Spurek"], "title": "SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Traditional deep neural networks suffer from several limitations, including\ncatastrophic forgetting. When models are adapted to new datasets, they tend to\nquickly forget previously learned knowledge. Another significant issue is the\nlack of robustness to even small perturbations in the input data. In practice,\nwe can often easily perform adversarial attacks and change the network's\npredictions, adding minimal noise to the input. Dedicated architectures and\ntraining procedures can solve each of the above problems separately.\nUnfortunately, currently, no model can simultaneously address both catastrophic\nforgetting and vulnerability to adversarial attacks. We introduce SHIELD\n(Secure Hypernetworks for Incremental Expansion and Learning Defense), a novel\napproach that integrates a hypernetwork-based continual learning approach with\ninterval arithmetic. SHIELD use the hypernetwork to transfer trainable task\nembedding vectors into the weights of a target model dedicated to specific\ndata. This paradigm allows for the dynamic generation of separate networks for\neach subtask, while the hypernetwork aggregates and analyzes information across\nall tasks. The target model takes in the input a data sample with a defined\ninterval range, and by creating a hypercube, produces a prediction for the\ngiven range. Therefore, such target models provide strict guarantees against\nall possible attacks for data samples within the interval range. Our approach\nenhances security without sacrificing network adaptability, addressing the\noverlooked challenge of safety in continual learning.", "AI": {"tldr": "SHIELD combines hypernetwork-based continual learning with interval arithmetic to tackle catastrophic forgetting and adversarial attacks simultaneously.", "motivation": "Address the dual challenges of catastrophic forgetting in continual learning and vulnerability to adversarial attacks, which current models fail to solve together.", "method": "Uses a hypernetwork to generate task-specific target models with interval arithmetic for robust predictions within defined ranges.", "result": "Provides strict guarantees against adversarial attacks while maintaining adaptability across tasks.", "conclusion": "SHIELD successfully integrates security and adaptability in continual learning, solving a previously unaddressed challenge."}}
{"id": "2506.08500", "pdf": "https://arxiv.org/pdf/2506.08500", "abs": "https://arxiv.org/abs/2506.08500", "authors": ["Arie Cattan", "Alon Jacovi", "Ori Ram", "Jonathan Herzig", "Roee Aharoni", "Sasha Goldshtein", "Eran Ofek", "Idan Szpektor", "Avi Caciularu"], "title": "DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) is a commonly used approach for\nenhancing large language models (LLMs) with relevant and up-to-date\ninformation. However, the retrieved sources can often contain conflicting\ninformation and it remains unclear how models should address such\ndiscrepancies. In this work, we first propose a novel taxonomy of knowledge\nconflict types in RAG, along with the desired model behavior for each type. We\nthen introduce CONFLICTS, a high-quality benchmark with expert annotations of\nconflict types in a realistic RAG setting. CONFLICTS is the first benchmark\nthat enables tracking progress on how models address a wide range of knowledge\nconflicts. We conduct extensive experiments on this benchmark, showing that\nLLMs often struggle to appropriately resolve conflicts between sources. While\nprompting LLMs to explicitly reason about the potential conflict in the\nretrieved documents significantly improves the quality and appropriateness of\ntheir responses, substantial room for improvement in future research remains.", "AI": {"tldr": "The paper introduces a taxonomy for knowledge conflicts in RAG, proposes the CONFLICTS benchmark, and shows LLMs struggle with resolving conflicts, though reasoning prompts help.", "motivation": "To address the challenge of conflicting information in retrieved sources for RAG and improve LLM handling of such discrepancies.", "method": "Proposes a taxonomy of knowledge conflict types, introduces the CONFLICTS benchmark, and tests LLMs with reasoning prompts.", "result": "LLMs often fail to resolve conflicts, but explicit reasoning prompts improve response quality.", "conclusion": "Future research is needed to further enhance LLM conflict resolution in RAG."}}
{"id": "2506.08553", "pdf": "https://arxiv.org/pdf/2506.08553", "abs": "https://arxiv.org/abs/2506.08553", "authors": ["Agnese Taluzzi", "Davide Gesualdi", "Riccardo Santambrogio", "Chiara Plizzari", "Francesca Palermo", "Simone Mentasti", "Matteo Matteucci"], "title": "From Pixels to Graphs: using Scene and Knowledge Graphs for HD-EPIC VQA Challenge", "categories": ["cs.CV"], "comment": "Technical report for the HD-EPIC VQA Challenge 2025 (1st place)", "summary": "This report presents SceneNet and KnowledgeNet, our approaches developed for\nthe HD-EPIC VQA Challenge 2025. SceneNet leverages scene graphs generated with\na multi-modal large language model (MLLM) to capture fine-grained object\ninteractions, spatial relationships, and temporally grounded events. In\nparallel, KnowledgeNet incorporates ConceptNet's external commonsense knowledge\nto introduce high-level semantic connections between entities, enabling\nreasoning beyond directly observable visual evidence. Each method demonstrates\ndistinct strengths across the seven categories of the HD-EPIC benchmark, and\ntheir combination within our framework results in an overall accuracy of 44.21%\non the challenge, highlighting its effectiveness for complex egocentric VQA\ntasks.", "AI": {"tldr": "SceneNet and KnowledgeNet improve VQA performance by combining scene graphs and commonsense knowledge, achieving 44.21% accuracy on HD-EPIC.", "motivation": "To address complex egocentric VQA tasks by capturing fine-grained object interactions and leveraging external commonsense knowledge.", "method": "SceneNet uses MLLM-generated scene graphs; KnowledgeNet integrates ConceptNet for semantic reasoning.", "result": "Combined framework achieves 44.21% accuracy on HD-EPIC benchmark.", "conclusion": "The integration of SceneNet and KnowledgeNet effectively handles complex VQA tasks."}}
{"id": "2506.09049", "pdf": "https://arxiv.org/pdf/2506.09049", "abs": "https://arxiv.org/abs/2506.09049", "authors": ["Li Kang", "Xiufeng Song", "Heng Zhou", "Yiran Qin", "Jie Yang", "Xiaohong Liu", "Philip Torr", "Lei Bai", "Zhenfei Yin"], "title": "VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning", "categories": ["cs.AI", "cs.CV", "cs.RO"], "comment": "Project page: https://faceong.github.io/VIKI-R/", "summary": "Coordinating multiple embodied agents in dynamic environments remains a core\nchallenge in artificial intelligence, requiring both perception-driven\nreasoning and scalable cooperation strategies. While recent works have\nleveraged large language models (LLMs) for multi-agent planning, a few have\nbegun to explore vision-language models (VLMs) for visual reasoning. However,\nthese VLM-based approaches remain limited in their support for diverse\nembodiment types. In this work, we introduce VIKI-Bench, the first hierarchical\nbenchmark tailored for embodied multi-agent cooperation, featuring three\nstructured levels: agent activation, task planning, and trajectory perception.\nVIKI-Bench includes diverse robot embodiments, multi-view visual observations,\nand structured supervision signals to evaluate reasoning grounded in visual\ninputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a\ntwo-stage framework that fine-tunes a pretrained vision-language model (VLM)\nusing Chain-of-Thought annotated demonstrations, followed by reinforcement\nlearning under multi-level reward signals. Our extensive experiments show that\nVIKI-R significantly outperforms baselines method across all task levels.\nFurthermore, we show that reinforcement learning enables the emergence of\ncompositional cooperation patterns among heterogeneous agents. Together,\nVIKI-Bench and VIKI-R offer a unified testbed and method for advancing\nmulti-agent, visual-driven cooperation in embodied AI systems.", "AI": {"tldr": "VIKI-Bench is a hierarchical benchmark for embodied multi-agent cooperation, and VIKI-R is a two-stage framework combining VLM fine-tuning and reinforcement learning, outperforming baselines.", "motivation": "Addressing the challenge of coordinating diverse embodied agents in dynamic environments, leveraging vision-language models for visual reasoning.", "method": "Introduces VIKI-Bench with three levels (agent activation, task planning, trajectory perception) and VIKI-R, a framework fine-tuning VLMs with Chain-of-Thought and reinforcement learning.", "result": "VIKI-R outperforms baselines across all task levels and enables compositional cooperation among heterogeneous agents.", "conclusion": "VIKI-Bench and VIKI-R provide a unified testbed and method for advancing visual-driven multi-agent cooperation in embodied AI."}}
{"id": "2506.08266", "pdf": "https://arxiv.org/pdf/2506.08266", "abs": "https://arxiv.org/abs/2506.08266", "authors": ["Yaswanth Chittepu", "Blossom Metevier", "Will Schwarzer", "Austin Hoag", "Scott Niekum", "Philip S. Thomas"], "title": "Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.AP"], "comment": "20 pages, 6 figures, 4 tables, Second Reinforcement Learning\n  Conference (RLC 2025)", "summary": "Existing approaches to language model alignment often treat safety as a\ntradeoff against helpfulness, which can lead to unacceptable responses in\nsensitive domains. To ensure reliable performance in such settings, we propose\nHigh-Confidence Safe Reinforcement Learning from Human Feedback (HC-RLHF), a\nmethod that provides high-confidence safety guarantees while maximizing\nhelpfulness. Similar to previous methods, HC-RLHF explicitly decouples human\npreferences into helpfulness and harmlessness (safety), which are learned by\ntraining a reward model and a cost model, respectively. It then employs a\ntwo-step process to find safe solutions. In the first step, it optimizes the\nreward function under an intentionally pessimistic version of the cost\nconstraint. In the second step, the trained model undergoes a safety test to\nverify whether its performance stays within an upper-confidence bound of the\nactual cost constraint. We provide a theoretical analysis of HC-RLHF, including\nproof that it will not return an unsafe solution with a probability greater\nthan a user-specified threshold. For our empirical analysis, we apply HC-RLHF\nto align three different language models (Qwen2-1.5B, Qwen2.5-3B, and\nLLaMa3.2-3B) with human preferences. Our results demonstrate that HC-RLHF\nproduces safe models with high probability and can improve harmlessness and\nhelpfulness compared to previous methods.", "AI": {"tldr": "HC-RLHF is a method for aligning language models with high-confidence safety guarantees while maximizing helpfulness, outperforming previous methods in sensitive domains.", "motivation": "Existing methods treat safety as a tradeoff against helpfulness, leading to unreliable responses in sensitive domains. HC-RLHF aims to ensure safety without compromising helpfulness.", "method": "HC-RLHF decouples human preferences into helpfulness (reward model) and harmlessness (cost model). It optimizes reward under a pessimistic cost constraint and verifies safety via a test.", "result": "HC-RLHF aligns models (Qwen2-1.5B, Qwen2.5-3B, LLaMa3.2-3B) safely with high probability, improving harmlessness and helpfulness over prior methods.", "conclusion": "HC-RLHF provides a reliable framework for safe language model alignment, backed by theoretical guarantees and empirical success."}}
{"id": "2506.08504", "pdf": "https://arxiv.org/pdf/2506.08504", "abs": "https://arxiv.org/abs/2506.08504", "authors": ["Divyaksh Shukla", "Ritesh Baviskar", "Dwijesh Gohil", "Aniket Tiwari", "Atul Shree", "Ashutosh Modi"], "title": "CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in conversations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ACL Findings 2025 (16 pages: 5 pages main content + 3\n  pages references + 8 pages appendix)", "summary": "Discourse parsing is an important task useful for NLU applications such as\nsummarization, machine comprehension, and emotion recognition. The current\ndiscourse parsing datasets based on conversations consists of written English\ndialogues restricted to a single domain. In this resource paper, we introduce\nCoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in\nconversations. The corpus (code-mixed in Hindi and English) has both audio and\ntranscribed text and is annotated with nine discourse relations. We experiment\nwith various SoTA baseline models; the poor performance of SoTA models\nhighlights the challenges of multi-domain code-mixed corpus, pointing towards\nthe need for developing better models for such realistic settings.", "AI": {"tldr": "The paper introduces CoMuMDR, a code-mixed multi-modal corpus for discourse parsing in Hindi-English conversations, highlighting challenges for SoTA models.", "motivation": "Existing discourse parsing datasets are limited to single-domain written English dialogues, lacking diversity.", "method": "The authors introduce CoMuMDR, a corpus with audio, transcribed text, and nine discourse relations, and test SoTA models.", "result": "SoTA models perform poorly on the multi-domain code-mixed corpus, indicating its complexity.", "conclusion": "The results emphasize the need for better models to handle multi-domain code-mixed discourse parsing."}}
{"id": "2506.08555", "pdf": "https://arxiv.org/pdf/2506.08555", "abs": "https://arxiv.org/abs/2506.08555", "authors": ["Xinyue Niu", "Akira Furui"], "title": "Towards Cross-Subject EMG Pattern Recognition via Dual-Branch Adversarial Feature Disentanglement", "categories": ["cs.CV", "cs.HC"], "comment": "6 pages, 3 figures. This work has been accepted for presentation at\n  the IEEE Engineering in Medicine and Biology Conference (EMBC) 2025", "summary": "Cross-subject electromyography (EMG) pattern recognition faces significant\nchallenges due to inter-subject variability in muscle anatomy, electrode\nplacement, and signal characteristics. Traditional methods rely on\nsubject-specific calibration data to adapt models to new users, an approach\nthat is both time-consuming and impractical for large-scale, real-world\ndeployment. This paper presents an approach to eliminate calibration\nrequirements through feature disentanglement, enabling effective cross-subject\ngeneralization. We propose an end-to-end dual-branch adversarial neural network\nthat simultaneously performs pattern recognition and individual identification\nby disentangling EMG features into pattern-specific and subject-specific\ncomponents. The pattern-specific components facilitate robust pattern\nrecognition for new users without model calibration, while the subject-specific\ncomponents enable downstream applications such as task-invariant biometric\nidentification. Experimental results demonstrate that the proposed model\nachieves robust performance on data from unseen users, outperforming various\nbaseline methods in cross-subject scenarios. Overall, this study offers a new\nperspective for cross-subject EMG pattern recognition without model calibration\nand highlights the proposed model's potential for broader applications, such as\ntask-independent biometric systems.", "AI": {"tldr": "Proposes a dual-branch adversarial neural network for cross-subject EMG pattern recognition without calibration, improving generalization and enabling biometric applications.", "motivation": "Addresses challenges of inter-subject variability in EMG signals, eliminating the need for time-consuming subject-specific calibration.", "method": "Uses an end-to-end dual-branch adversarial neural network to disentangle EMG features into pattern-specific and subject-specific components.", "result": "Achieves robust performance on unseen users, outperforming baseline methods in cross-subject scenarios.", "conclusion": "Offers a calibration-free approach for EMG pattern recognition and potential for task-independent biometric systems."}}
{"id": "2506.09050", "pdf": "https://arxiv.org/pdf/2506.09050", "abs": "https://arxiv.org/abs/2506.09050", "authors": ["Yuki Imajuku", "Kohki Horie", "Yoichi Iwata", "Kensho Aoki", "Naohiro Takahashi", "Takuya Akiba"], "title": "ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm Engineering", "categories": ["cs.AI"], "comment": "36 pages", "summary": "How well do AI systems perform in algorithm engineering for hard optimization\nproblems in domains such as package-delivery routing, crew scheduling, factory\nproduction planning, and power-grid balancing? We introduce ALE-Bench, a new\nbenchmark for evaluating AI systems on score-based algorithmic programming\ncontests. Drawing on real tasks from the AtCoder Heuristic Contests, ALE-Bench\npresents optimization problems that are computationally hard and admit no known\nexact solution. Unlike short-duration, pass/fail coding benchmarks, ALE-Bench\nencourages iterative solution refinement over long time horizons. Our software\nframework supports interactive agent architectures that leverage test-run\nfeedback and visualizations. Our evaluation of frontier LLMs revealed that\nwhile they demonstrate high performance on specific problems, a notable gap\nremains compared to humans in terms of consistency across problems and\nlong-horizon problem-solving capabilities. This highlights the need for this\nbenchmark to foster future AI advancements.", "AI": {"tldr": "ALE-Bench is a new benchmark for evaluating AI systems on hard optimization problems, revealing gaps in consistency and long-horizon problem-solving compared to humans.", "motivation": "To assess AI performance in algorithm engineering for complex optimization tasks like routing, scheduling, and planning, where exact solutions are unknown.", "method": "Introduces ALE-Bench, leveraging real tasks from AtCoder Heuristic Contests, supporting iterative refinement and interactive agent architectures with test-run feedback.", "result": "Frontier LLMs show high performance on specific problems but lag behind humans in consistency and long-term problem-solving.", "conclusion": "ALE-Bench is essential for driving future AI advancements in tackling hard optimization challenges."}}
{"id": "2506.08267", "pdf": "https://arxiv.org/pdf/2506.08267", "abs": "https://arxiv.org/abs/2506.08267", "authors": ["Mansooreh Montazerin", "Majd Al Aawar", "Antonio Ortega", "Ajitesh Srivastava"], "title": "Sparse Interpretable Deep Learning with LIES Networks for Symbolic Regression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Symbolic regression (SR) aims to discover closed-form mathematical\nexpressions that accurately describe data, offering interpretability and\nanalytical insight beyond standard black-box models. Existing SR methods often\nrely on population-based search or autoregressive modeling, which struggle with\nscalability and symbolic consistency. We introduce LIES (Logarithm, Identity,\nExponential, Sine), a fixed neural network architecture with interpretable\nprimitive activations that are optimized to model symbolic expressions. We\ndevelop a framework to extract compact formulae from LIES networks by training\nwith an appropriate oversampling strategy and a tailored loss function to\npromote sparsity and to prevent gradient instability. After training, it\napplies additional pruning strategies to further simplify the learned\nexpressions into compact formulae. Our experiments on SR benchmarks show that\nthe LIES framework consistently produces sparse and accurate symbolic formulae\noutperforming all baselines. We also demonstrate the importance of each design\ncomponent through ablation studies.", "AI": {"tldr": "LIES introduces a fixed neural network with interpretable activations for symbolic regression, outperforming existing methods in accuracy and sparsity.", "motivation": "Existing SR methods lack scalability and symbolic consistency, prompting the need for a more efficient and interpretable approach.", "method": "LIES uses a neural network with primitive activations, trained with oversampling and a tailored loss for sparsity, followed by pruning.", "result": "LIES outperforms baselines in producing sparse and accurate symbolic formulae, validated by benchmarks and ablation studies.", "conclusion": "The LIES framework effectively addresses scalability and consistency issues in SR, offering a robust solution for interpretable modeling."}}
{"id": "2506.08552", "pdf": "https://arxiv.org/pdf/2506.08552", "abs": "https://arxiv.org/abs/2506.08552", "authors": ["Xinyuan Wang", "Dongjie Wang", "Wangyang Ying", "Haoyue Bai", "Nanxu Gong", "Sixun Dong", "Kunpeng Liu", "Yanjie Fu"], "title": "Efficient Post-Training Refinement of Latent Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning is a key component of language understanding in Large Language\nModels. While Chain-of-Thought prompting enhances performance via explicit\nintermediate steps, it suffers from sufficient token overhead and a fixed\nreasoning trajectory, preventing step-wise refinement. Recent advances in\nlatent reasoning address these limitations by refining internal reasoning\nprocesses directly in the model's latent space, without producing explicit\noutputs. However, a key challenge remains: how to effectively update reasoning\nembeddings during post-training to guide the model toward more accurate\nsolutions. To overcome this challenge, we propose a lightweight post-training\nframework that refines latent reasoning trajectories using two novel\nstrategies: 1) Contrastive reasoning feedback, which compares reasoning\nembeddings against strong and weak baselines to infer effective update\ndirections via embedding enhancement; 2) Residual embedding refinement, which\nstabilizes updates by progressively integrating current and historical\ngradients, enabling fast yet controlled convergence. Extensive experiments and\ncase studies are conducted on five reasoning benchmarks to demonstrate the\neffectiveness of the proposed framework. Notably, a 5\\% accuracy gain on MathQA\nwithout additional training.", "AI": {"tldr": "A lightweight post-training framework refines latent reasoning in LLMs using contrastive feedback and residual embedding refinement, achieving a 5% accuracy boost on MathQA.", "motivation": "Address limitations of Chain-of-Thought prompting (token overhead, fixed reasoning) and latent reasoning challenges (effective embedding updates).", "method": "Proposes two strategies: contrastive reasoning feedback and residual embedding refinement to update reasoning embeddings post-training.", "result": "Demonstrates effectiveness on five benchmarks, notably a 5% accuracy gain on MathQA without extra training.", "conclusion": "The framework successfully refines latent reasoning, improving model accuracy efficiently."}}
{"id": "2506.08562", "pdf": "https://arxiv.org/pdf/2506.08562", "abs": "https://arxiv.org/abs/2506.08562", "authors": ["Duc Thanh Pham", "Hong Dang Nguyen", "Nhat Minh Nguyen Quoc", "Linh Ngo Van", "Sang Dinh Viet", "Duc Anh Nguyen"], "title": "Hierarchical Neural Collapse Detection Transformer for Class Incremental Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Recently, object detection models have witnessed notable performance\nimprovements, particularly with transformer-based models. However, new objects\nfrequently appear in the real world, requiring detection models to continually\nlearn without suffering from catastrophic forgetting. Although Incremental\nObject Detection (IOD) has emerged to address this challenge, these existing\nmodels are still not practical due to their limited performance and prolonged\ninference time. In this paper, we introduce a novel framework for IOD, called\nHier-DETR: Hierarchical Neural Collapse Detection Transformer, ensuring both\nefficiency and competitive performance by leveraging Neural Collapse for\nimbalance dataset and Hierarchical relation of classes' labels.", "AI": {"tldr": "Hier-DETR, a novel IOD framework, improves efficiency and performance using Neural Collapse and hierarchical class relations.", "motivation": "Addressing the impracticality of existing IOD models due to limited performance and slow inference time.", "method": "Leverages Neural Collapse for imbalance datasets and hierarchical class label relations.", "result": "Ensures efficiency and competitive performance in incremental object detection.", "conclusion": "Hier-DETR offers a practical solution for IOD with improved performance and speed."}}
{"id": "2506.00160", "pdf": "https://arxiv.org/pdf/2506.00160", "abs": "https://arxiv.org/abs/2506.00160", "authors": ["Qihui Fan", "Enfu Nan", "Wenbo Li", "Lei Lu", "Pu Zhao", "Yanzhi Wang"], "title": "Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The growing popularity of social deduction game systems for both business\napplications and AI research has greatly benefited from the rapid advancements\nin Large Language Models (LLMs), which now demonstrate stronger reasoning and\npersuasion capabilities. Especially with the raise of DeepSeek R1 and V3\nmodels, LLMs should enable a more engaging experience for human players in\nLLM-agent-based social deduction games like Werewolf. Previous works either\nfine-tuning, advanced prompting engineering, or additional experience pool to\nachieve engaging text-format Werewolf game experience. We propose a novel yet\nstraightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS)\nmodels designed for enhanced compatibility with various LLM models, and\nimproved user engagement. We argue with ever enhancing LLM reasoning, extra\ncomponents will be unnecessary in the case of Werewolf.", "AI": {"tldr": "A novel LLM-based Werewolf game system is proposed, leveraging advanced LLMs like DeepSeek R1 and V3 for better reasoning and persuasion, eliminating the need for extra components.", "motivation": "The rise of LLMs with improved reasoning and persuasion capabilities motivates the development of a more engaging and compatible Werewolf game system.", "method": "The system combines LLMs with tuned Text-to-Speech (TTS) models for enhanced compatibility and user engagement, avoiding complex fine-tuning or additional components.", "result": "The proposed system achieves improved engagement and compatibility with various LLM models.", "conclusion": "With advancing LLM reasoning, extra components are unnecessary for creating engaging Werewolf games."}}
{"id": "2506.08270", "pdf": "https://arxiv.org/pdf/2506.08270", "abs": "https://arxiv.org/abs/2506.08270", "authors": ["Zitong Huang", "Mansooreh Montazerin", "Ajitesh Srivastava"], "title": "SWAT-NN: Simultaneous Weights and Architecture Training for Neural Networks in a Latent Space", "categories": ["cs.LG"], "comment": null, "summary": "Designing neural networks typically relies on manual trial and error or a\nneural architecture search (NAS) followed by weight training. The former is\ntime-consuming and labor-intensive, while the latter often discretizes\narchitecture search and weight optimization. In this paper, we propose a\nfundamentally different approach that simultaneously optimizes both the\narchitecture and the weights of a neural network. Our framework first trains a\nuniversal multi-scale autoencoder that embeds both architectural and parametric\ninformation into a continuous latent space, where functionally similar neural\nnetworks are mapped closer together. Given a dataset, we then randomly\ninitialize a point in the embedding space and update it via gradient descent to\nobtain the optimal neural network, jointly optimizing its structure and\nweights. The optimization process incorporates sparsity and compactness\npenalties to promote efficient models. Experiments on synthetic regression\ntasks demonstrate that our method effectively discovers sparse and compact\nneural networks with strong performance.", "AI": {"tldr": "A novel framework jointly optimizes neural network architecture and weights using a continuous latent space, avoiding manual trial or NAS limitations.", "motivation": "Manual trial and error is laborious, and NAS often separates architecture search from weight optimization. The goal is to unify these processes for efficiency.", "method": "Train a universal multi-scale autoencoder to embed architectures and weights into a continuous latent space. Optimize via gradient descent with sparsity and compactness penalties.", "result": "Effective discovery of sparse, compact neural networks with strong performance on synthetic regression tasks.", "conclusion": "The proposed method successfully unifies architecture and weight optimization, offering a scalable and efficient alternative to traditional approaches."}}
{"id": "2506.08584", "pdf": "https://arxiv.org/pdf/2506.08584", "abs": "https://arxiv.org/abs/2506.08584", "authors": ["Yahan Li", "Jifan Yao", "John Bosco S. Bunyi", "Adam C. Frank", "Angel Hwang", "Ruishan Liu"], "title": "CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmark of Large Language Models in Mental Health Counseling", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly proposed for use in mental\nhealth support, yet their behavior in realistic counseling scenarios remains\nlargely untested. We introduce CounselBench, a large-scale benchmark developed\nwith 100 mental health professionals to evaluate and stress-test LLMs in\nsingle-turn counseling. The first component, CounselBench-EVAL, contains 2,000\nexpert evaluations of responses from GPT-4, LLaMA 3, Gemini, and online human\ntherapists to real patient questions. Each response is rated along six\nclinically grounded dimensions, with written rationales and span-level\nannotations. We find that LLMs often outperform online human therapists in\nperceived quality, but experts frequently flag their outputs for safety\nconcerns such as unauthorized medical advice. Follow-up experiments show that\nLLM judges consistently overrate model responses and overlook safety issues\nidentified by human experts. To probe failure modes more directly, we construct\nCounselBench-Adv, an adversarial dataset of 120 expert-authored counseling\nquestions designed to trigger specific model issues. Evaluation across 2,880\nresponses from eight LLMs reveals consistent, model-specific failure patterns.\nTogether, CounselBench establishes a clinically grounded framework for\nbenchmarking and improving LLM behavior in high-stakes mental health settings.", "AI": {"tldr": "CounselBench evaluates LLMs in mental health counseling, showing they outperform human therapists in quality but raise safety concerns. Human experts highlight issues LLM judges miss.", "motivation": "To assess LLM behavior in realistic mental health counseling scenarios, given their growing use but lack of rigorous testing.", "method": "Developed CounselBench with 100 professionals, including CounselBench-EVAL (2,000 expert evaluations) and CounselBench-Adv (120 adversarial questions). Evaluated responses from GPT-4, LLaMA 3, Gemini, and human therapists.", "result": "LLMs often outperform human therapists in perceived quality but are flagged for safety issues like unauthorized medical advice. LLM judges overrate responses and miss safety concerns.", "conclusion": "CounselBench provides a clinically grounded framework for benchmarking and improving LLMs in mental health settings."}}
{"id": "2506.08566", "pdf": "https://arxiv.org/pdf/2506.08566", "abs": "https://arxiv.org/abs/2506.08566", "authors": ["Yibo Cui", "Liang Xie", "Yu Zhao", "Jiawei Sun", "Erwei Yin"], "title": "Generating Vision-Language Navigation Instructions Incorporated Fine-Grained Alignment Annotations", "categories": ["cs.CV"], "comment": null, "summary": "Vision-Language Navigation (VLN) enables intelligent agents to navigate\nenvironments by integrating visual perception and natural language\ninstructions, yet faces significant challenges due to the scarcity of\nfine-grained cross-modal alignment annotations. Existing datasets primarily\nfocus on global instruction-trajectory matching, neglecting\nsub-instruction-level and entity-level alignments critical for accurate\nnavigation action decision-making. To address this limitation, we propose\nFCA-NIG, a generative framework that automatically constructs navigation\ninstructions with dual-level fine-grained cross-modal annotations. In this\nframework, an augmented trajectory is first divided into sub-trajectories,\nwhich are then processed through GLIP-based landmark detection, crafted\ninstruction construction, OFA-Speaker based R2R-like instruction generation,\nand CLIP-powered entity selection, generating sub-instruction-trajectory pairs\nwith entity-landmark annotations. Finally, these sub-pairs are aggregated to\nform a complete instruction-trajectory pair. The framework generates the\nFCA-R2R dataset, the first large-scale augmentation dataset featuring precise\nsub-instruction-sub-trajectory and entity-landmark alignments. Extensive\nexperiments demonstrate that training with FCA-R2R significantly improves the\nperformance of multiple state-of-the-art VLN agents, including SF, EnvDrop,\nRecBERT, and HAMT. Incorporating sub-instruction-trajectory alignment enhances\nagents' state awareness and decision accuracy, while entity-landmark alignment\nfurther boosts navigation performance and generalization. These results\nhighlight the effectiveness of FCA-NIG in generating high-quality, scalable\ntraining data without manual annotation, advancing fine-grained cross-modal\nlearning in complex navigation tasks.", "AI": {"tldr": "FCA-NIG is a generative framework for creating fine-grained cross-modal annotations in Vision-Language Navigation (VLN), improving agent performance by addressing sub-instruction-level and entity-level alignment gaps.", "motivation": "Existing VLN datasets lack fine-grained cross-modal alignments (sub-instruction and entity levels), hindering accurate navigation decision-making.", "method": "FCA-NIG divides trajectories into sub-trajectories, uses GLIP for landmark detection, OFA-Speaker for instruction generation, and CLIP for entity selection, creating aligned sub-instruction-trajectory pairs.", "result": "FCA-R2R dataset enhances VLN agent performance (e.g., SF, EnvDrop) by improving state awareness and navigation accuracy.", "conclusion": "FCA-NIG generates scalable, high-quality training data without manual annotation, advancing fine-grained cross-modal learning in VLN."}}
{"id": "2506.04760", "pdf": "https://arxiv.org/pdf/2506.04760", "abs": "https://arxiv.org/abs/2506.04760", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Model-based Query Expansion", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown potential in generating hypothetical\ndocuments for query expansion, thereby enhancing information retrieval\nperformance. However, the efficacy of this method is highly dependent on the\nquality of the generated documents, which often requires complex prompt\nstrategies and the integration of advanced dense retrieval techniques. This can\nbe both costly and computationally intensive. To mitigate these limitations, we\nexplore the use of zero-shot LLM-based query expansion to improve sparse\nretrieval, particularly for learned sparse retrievers. We introduce a novel\nfusion ranking framework, Exp4Fuse, which enhances the performance of sparse\nretrievers through an indirect application of zero-shot LLM-based query\nexpansion. Exp4Fuse operates by simultaneously considering two retrieval\nroutes-one based on the original query and the other on the LLM-augmented\nquery. It then generates two ranked lists using a sparse retriever and fuses\nthem using a modified reciprocal rank fusion method. We conduct extensive\nevaluations of Exp4Fuse against leading LLM-based query expansion methods and\nadvanced retrieval techniques on three MS MARCO-related datasets and seven\nlow-resource datasets. Experimental results reveal that Exp4Fuse not only\nsurpasses existing LLM-based query expansion methods in enhancing sparse\nretrievers but also, when combined with advanced sparse retrievers, achieves\nSOTA results on several benchmarks. This highlights the superior performance\nand effectiveness of Exp4Fuse in improving query expansion for sparse\nretrieval.", "AI": {"tldr": "Exp4Fuse, a novel fusion ranking framework, improves sparse retrieval by combining original and LLM-augmented queries, outperforming existing methods.", "motivation": "To address the high cost and computational intensity of LLM-based query expansion by proposing a zero-shot approach for sparse retrievers.", "method": "Exp4Fuse uses two retrieval routes (original and LLM-augmented queries), fuses ranked lists via modified reciprocal rank fusion, and evaluates on multiple datasets.", "result": "Exp4Fuse surpasses existing LLM-based methods and achieves SOTA results when combined with advanced sparse retrievers.", "conclusion": "Exp4Fuse demonstrates superior performance in enhancing query expansion for sparse retrieval."}}
{"id": "2506.08272", "pdf": "https://arxiv.org/pdf/2506.08272", "abs": "https://arxiv.org/abs/2506.08272", "authors": ["Tarushri N. S."], "title": "Universal Differential Equations for Scientific Machine Learning of Node-Wise Battery Dynamics in Smart Grids", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Universal Differential Equations (UDEs), which blend neural networks with\nphysical differential equations, have emerged as a powerful framework for\nscientific machine learning (SciML), enabling data-efficient, interpretable,\nand physically consistent modeling. In the context of smart grid systems,\nmodeling node-wise battery dynamics remains a challenge due to the\nstochasticity of solar input and variability in household load profiles.\nTraditional approaches often struggle with generalization and fail to capture\nunmodeled residual dynamics. This work proposes a UDE-based approach to learn\nnode-specific battery evolution by embedding a neural residual into a\nphysically inspired battery ODE. Synthetic yet realistic solar generation and\nload demand data are used to simulate battery dynamics over time. The neural\ncomponent learns to model unobserved or stochastic corrections arising from\nheterogeneity in node demand and environmental conditions. Comprehensive\nexperiments reveal that the trained UDE aligns closely with ground truth\nbattery trajectories, exhibits smooth convergence behavior, and maintains\nstability in long-term forecasts. These findings affirm the viability of\nUDE-based SciML approaches for battery modeling in decentralized energy\nnetworks and suggest broader implications for real-time control and\noptimization in renewable-integrated smart grids.", "AI": {"tldr": "UDEs combine neural networks with physical differential equations for efficient, interpretable modeling of battery dynamics in smart grids, outperforming traditional methods.", "motivation": "Challenges in modeling battery dynamics due to solar input stochasticity and household load variability, where traditional methods lack generalization and miss residual dynamics.", "method": "Proposes a UDE-based approach embedding a neural residual into a battery ODE, using synthetic solar and load data to learn stochastic corrections.", "result": "UDE closely matches ground truth, shows smooth convergence, and maintains stability in long-term forecasts.", "conclusion": "UDEs are viable for battery modeling in decentralized energy networks, with potential for real-time control in smart grids."}}
{"id": "2506.08592", "pdf": "https://arxiv.org/pdf/2506.08592", "abs": "https://arxiv.org/abs/2506.08592", "authors": ["Liyan Xu", "Zhenlin Su", "Mo Yu", "Jiangnan Li", "Fandong Meng", "Jie Zhou"], "title": "Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This work focuses on an observed limitation of text encoders: embeddings may\nnot be able to recognize fine-grained entities or events within the semantics,\nresulting in failed dense retrieval on even simple cases. To examine such\nbehaviors, we first introduce a new evaluation dataset in Chinese, named\nCapRetrieval, whose passages are image captions, and queries are phrases\ninquiring entities or events in various forms. Zero-shot evaluation suggests\nthat encoders may fail on these fine-grained matching, regardless of training\nsources or model sizes. Aiming for enhancement, we proceed to finetune encoders\nwith our proposed data generation strategies, which obtains the best\nperformance on CapRetrieval. Within this process, we further identify an issue\nof granularity dilemma, a challenge for embeddings to express fine-grained\nsalience while aligning with overall semantics. Our dataset, code and models in\nthis work are publicly released at https://github.com/lxucs/CapRetrieval.", "AI": {"tldr": "The paper addresses the limitation of text encoders in recognizing fine-grained entities/events, introduces a Chinese dataset (CapRetrieval), and proposes finetuning strategies to improve performance.", "motivation": "To examine and address the failure of text encoders in fine-grained semantic recognition, especially in dense retrieval tasks.", "method": "Introduces CapRetrieval dataset, evaluates zero-shot performance, and proposes finetuning strategies with data generation.", "result": "Finetuned encoders achieve the best performance on CapRetrieval, but a granularity dilemma is identified.", "conclusion": "The work highlights encoder limitations, offers solutions, and releases resources for further research."}}
{"id": "2506.08596", "pdf": "https://arxiv.org/pdf/2506.08596", "abs": "https://arxiv.org/abs/2506.08596", "authors": ["Guyang Zhang", "Waleed Abdulla"], "title": "Transformers Meet Hyperspectral Imaging: A Comprehensive Study of Models, Challenges and Open Problems", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Transformers have become the architecture of choice for learning long-range\ndependencies, yet their adoption in hyperspectral imaging (HSI) is still\nemerging. We reviewed more than 300 papers published up to 2025 and present the\nfirst end-to-end survey dedicated to Transformer-based HSI classification. The\nstudy categorizes every stage of a typical pipeline-pre-processing, patch or\npixel tokenization, positional encoding, spatial-spectral feature extraction,\nmulti-head self-attention variants, skip connections, and loss design-and\ncontrasts alternative design choices with the unique spatial-spectral\nproperties of HSI. We map the field's progress against persistent obstacles:\nscarce labeled data, extreme spectral dimensionality, computational overhead,\nand limited model explainability. Finally, we outline a research agenda\nprioritizing valuable public data sets, lightweight on-edge models,\nillumination and sensor shifts robustness, and intrinsically interpretable\nattention mechanisms. Our goal is to guide researchers in selecting, combining,\nor extending Transformer components that are truly fit for purpose for\nnext-generation HSI applications.", "AI": {"tldr": "A survey of Transformer-based HSI classification, reviewing 300+ papers, categorizing pipeline stages, and addressing challenges like data scarcity and computational overhead.", "motivation": "Transformers are underutilized in HSI despite their effectiveness for long-range dependencies. The study aims to guide researchers in adapting Transformers for HSI.", "method": "Review and categorization of Transformer-based HSI classification pipelines, including pre-processing, tokenization, feature extraction, and attention variants.", "result": "Identified persistent challenges (e.g., labeled data scarcity, computational overhead) and outlined a research agenda for future work.", "conclusion": "The survey provides a roadmap for researchers to optimize Transformers for HSI, focusing on practical solutions and interpretability."}}
{"id": "2506.05695", "pdf": "https://arxiv.org/pdf/2506.05695", "abs": "https://arxiv.org/abs/2506.05695", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Knowledge Distillation (KD) compresses large language models (LLMs) by\ntransferring the teacher model's capabilities to a smaller student model,\nreducing inference cost and memory usage while maintaining performance.\nHowever, existing KD methods for LLMs often fail to prevent significant shifts\nin the student model's distribution during training, leading to issues such as\ncatastrophic forgetting, mode collapse, and training-inference mismatch. To\naddress these challenges, we propose a novel, plug-in curriculum learning\nframework inspired by the strength training principle of \"progressive overload\"\n(POCL), which can be seamlessly integrated into existing white-box KD\napproaches with minimal computational overhead. The framework comprises two\ncore components: (1) a difficulty measurer that ranks and partitions training\nsamples from easy to hard, and (2) a training scheduler that incrementally\nintroduces these subsets into the distillation process at fixed intervals while\napplying loss functions with progressively rising temperatures. By starting\nwith the easiest samples and progressively increasing the difficulty, the\napproach enhances both the stability and efficiency of learning. Extensive\nexperiments in instruction-following settings demonstrate that POCL\nconsistently improves the performance of distilled student models across\nvarious white-box KD methods and model families. Our findings highlight the\neffectiveness of sorted training samples in KD for LLMs. More generally, our\nwork demonstrates how to structure training data within the KD process to\nenhance the stability and performance of distilled LLMs.", "AI": {"tldr": "The paper proposes POCL, a curriculum learning framework for Knowledge Distillation (KD) in LLMs, addressing issues like catastrophic forgetting and mode collapse by progressively introducing training samples from easy to hard.", "motivation": "Existing KD methods for LLMs suffer from distribution shifts during training, causing problems like catastrophic forgetting and training-inference mismatch.", "method": "POCL uses a difficulty measurer to rank samples and a training scheduler to introduce them progressively, with rising loss temperatures.", "result": "Experiments show POCL improves student model performance across various KD methods and model families.", "conclusion": "Sorted training samples enhance KD stability and performance, demonstrating the value of structured training data in LLM distillation."}}
{"id": "2506.08274", "pdf": "https://arxiv.org/pdf/2506.08274", "abs": "https://arxiv.org/abs/2506.08274", "authors": ["Jo\u00e3o Manoel Herrera Pinheiro", "Suzana Vilas Boas de Oliveira", "Thiago Henrique Segreto Silva", "Pedro Antonio Rabelo Saraiva", "Enzo Ferreira de Souza", "Leonardo Andr\u00e9 Ambrosio", "Marcelo Becker"], "title": "The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks", "categories": ["cs.LG", "stat.ML"], "comment": "27 pages", "summary": "This research addresses the critical lack of comprehensive studies on feature\nscaling by systematically evaluating 12 scaling techniques - including several\nless common transformations - across 14 different Machine Learning algorithms\nand 16 datasets for classification and regression tasks. We meticulously\nanalyzed impacts on predictive performance (using metrics such as accuracy,\nMAE, MSE, and $R^2$) and computational costs (training time, inference time,\nand memory usage). Key findings reveal that while ensemble methods (such as\nRandom Forest and gradient boosting models like XGBoost, CatBoost and LightGBM)\ndemonstrate robust performance largely independent of scaling, other widely\nused models such as Logistic Regression, SVMs, TabNet, and MLPs show\nsignificant performance variations highly dependent on the chosen scaler. This\nextensive empirical analysis, with all source code, experimental results, and\nmodel parameters made publicly available to ensure complete transparency and\nreproducibility, offers model-specific crucial guidance to practitioners on the\nneed for an optimal selection of feature scaling techniques.", "AI": {"tldr": "The paper evaluates 12 feature scaling techniques across 14 ML algorithms and 16 datasets, revealing that ensemble methods are robust to scaling, while others like Logistic Regression and SVMs are highly sensitive.", "motivation": "Addresses the lack of comprehensive studies on feature scaling by systematically analyzing its impact on predictive performance and computational costs.", "method": "Evaluates 12 scaling techniques on 14 ML algorithms and 16 datasets, measuring performance metrics (accuracy, MAE, MSE, $R^2$) and computational costs (training/inference time, memory usage).", "result": "Ensemble methods (e.g., Random Forest, XGBoost) are largely unaffected by scaling, while models like Logistic Regression and SVMs show significant performance variations.", "conclusion": "Provides model-specific guidance for selecting optimal feature scaling techniques, with all data and code made publicly available for transparency."}}
{"id": "2506.08593", "pdf": "https://arxiv.org/pdf/2506.08593", "abs": "https://arxiv.org/abs/2506.08593", "authors": ["Shuzhou Yuan", "Ercong Nie", "Mario Tawfelis", "Helmut Schmid", "Hinrich Sch\u00fctze", "Michael F\u00e4rber"], "title": "Hateful Person or Hateful Model? Investigating the Role of Personas in Hate Speech Detection by Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Hate speech detection is a socially sensitive and inherently subjective task,\nwith judgments often varying based on personal traits. While prior work has\nexamined how socio-demographic factors influence annotation, the impact of\npersonality traits on Large Language Models (LLMs) remains largely unexplored.\nIn this paper, we present the first comprehensive study on the role of persona\nprompts in hate speech classification, focusing on MBTI-based traits. A human\nannotation survey confirms that MBTI dimensions significantly affect labeling\nbehavior. Extending this to LLMs, we prompt four open-source models with MBTI\npersonas and evaluate their outputs across three hate speech datasets. Our\nanalysis uncovers substantial persona-driven variation, including\ninconsistencies with ground truth, inter-persona disagreement, and logit-level\nbiases. These findings highlight the need to carefully define persona prompts\nin LLM-based annotation workflows, with implications for fairness and alignment\nwith human values.", "AI": {"tldr": "The paper explores how MBTI-based personality traits influence hate speech detection in LLMs, revealing significant biases and inconsistencies.", "motivation": "To investigate the unexplored impact of personality traits on LLM performance in hate speech classification, given the subjective nature of the task.", "method": "Conducted a human annotation survey to confirm MBTI's effect on labeling, then prompted four open-source LLMs with MBTI personas and evaluated their outputs on three datasets.", "result": "Found substantial persona-driven variation, including inconsistencies with ground truth, inter-persona disagreement, and logit-level biases.", "conclusion": "Highlights the need for careful persona prompt design in LLM workflows to ensure fairness and alignment with human values."}}
{"id": "2506.08611", "pdf": "https://arxiv.org/pdf/2506.08611", "abs": "https://arxiv.org/abs/2506.08611", "authors": ["Shiji Zhao", "Chi Chen", "Ranjie Duan", "Xizhe Wang", "Xingxing Wei"], "title": "Towards Class-wise Fair Adversarial Training via Anti-Bias Soft Label Distillation", "categories": ["cs.CV"], "comment": "arXiv admin note: text overlap with arXiv:2312.05508", "summary": "Adversarial Training (AT) is widely recognized as an effective approach to\nenhance the adversarial robustness of Deep Neural Networks. As a variant of AT,\nAdversarial Robustness Distillation (ARD) has shown outstanding performance in\nenhancing the robustness of small models. However, both AT and ARD face robust\nfairness issue: these models tend to display strong adversarial robustness\nagainst some classes (easy classes) while demonstrating weak adversarial\nrobustness against others (hard classes). This paper explores the underlying\nfactors of this problem and points out the smoothness degree of soft labels for\ndifferent classes significantly impacts the robust fairness from both empirical\nobservation and theoretical analysis. Based on the above exploration, we\npropose Anti-Bias Soft Label Distillation (ABSLD) within the Knowledge\nDistillation framework to enhance the adversarial robust fairness.\nSpecifically, ABSLD adaptively reduces the student's error risk gap between\ndifferent classes, which is accomplished by adjusting the class-wise smoothness\ndegree of teacher's soft labels during the training process, and the adjustment\nis managed by assigning varying temperatures to different classes.\nAdditionally, as a label-based approach, ABSLD is highly adaptable and can be\nintegrated with the sample-based methods. Extensive experiments demonstrate\nABSLD outperforms state-of-the-art methods on the comprehensive performance of\nrobustness and fairness.", "AI": {"tldr": "The paper addresses the robust fairness issue in Adversarial Training (AT) and Adversarial Robustness Distillation (ARD), proposing Anti-Bias Soft Label Distillation (ABSLD) to enhance fairness by adjusting class-wise label smoothness.", "motivation": "AT and ARD exhibit robust fairness issues, favoring some classes over others. The paper aims to understand and mitigate this bias.", "method": "Proposes ABSLD, which adjusts class-wise smoothness of teacher's soft labels using varying temperatures to reduce error risk gaps between classes.", "result": "ABSLD outperforms state-of-the-art methods in robustness and fairness, as shown in extensive experiments.", "conclusion": "ABSLD effectively enhances adversarial robust fairness and is adaptable with other methods."}}
{"id": "2506.06363", "pdf": "https://arxiv.org/pdf/2506.06363", "abs": "https://arxiv.org/abs/2506.06363", "authors": ["Thang D. Pham", "Aditya Tanikanti", "Murat Ke\u00e7eli"], "title": "ChemGraph: An Agentic Framework for Computational Chemistry Workflows", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Atomistic simulations are essential tools in chemistry and materials science,\naccelerating the discovery of novel catalysts, energy storage materials, and\npharmaceuticals. However, running these simulations remains challenging due to\nthe wide range of computational methods, diverse software ecosystems, and the\nneed for expert knowledge and manual effort for the setup, execution, and\nvalidation stages. In this work, we present ChemGraph, an agentic framework\npowered by artificial intelligence and state-of-the-art simulation tools to\nstreamline and automate computational chemistry and materials science\nworkflows. ChemGraph leverages graph neural network-based foundation models for\naccurate yet computationally efficient calculations and large language models\n(LLMs) for natural language understanding, task planning, and scientific\nreasoning to provide an intuitive and interactive interface. Users can perform\ntasks such as molecular structure generation, single-point energy, geometry\noptimization, vibrational analysis, and thermochemistry calculations with\nmethods ranging from tight-binding and machine learning interatomic potentials\nto density functional theory or wave function theory-based methods. We evaluate\nChemGraph across 13 benchmark tasks and demonstrate that smaller LLMs\n(GPT-4o-mini, Claude-3.5-haiku, Qwen2.5-14B) perform well on simple workflows,\nwhile more complex tasks benefit from using larger models like GPT-4o.\nImportantly, we show that decomposing complex tasks into smaller subtasks\nthrough a multi-agent framework enables smaller LLM models to match or exceed\nGPT-4o's performance in specific scenarios.", "AI": {"tldr": "ChemGraph is an AI-driven framework automating computational chemistry workflows, combining graph neural networks and LLMs for efficient and intuitive task execution.", "motivation": "Challenges in atomistic simulations include diverse methods, software ecosystems, and manual setup. ChemGraph aims to streamline and automate these workflows.", "method": "Uses graph neural networks for calculations and LLMs for task planning, offering methods from tight-binding to DFT. Evaluated on 13 benchmark tasks with varying LLM sizes.", "result": "Smaller LLMs handle simple tasks well, while complex tasks benefit from larger models. Task decomposition allows smaller models to match GPT-4o in some cases.", "conclusion": "ChemGraph effectively automates computational chemistry workflows, with task decomposition enhancing performance for smaller LLMs."}}
{"id": "2506.08292", "pdf": "https://arxiv.org/pdf/2506.08292", "abs": "https://arxiv.org/abs/2506.08292", "authors": ["Xie Yi", "Zhanke Zhou", "Chentao Cao", "Qiyu Niu", "Tongliang Liu", "Bo Han"], "title": "From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "Multi-agent frameworks can substantially boost the reasoning power of large\nlanguage models (LLMs), but they typically incur heavy computational costs and\nlack convergence guarantees. To overcome these challenges, we recast multi-LLM\ncoordination as an incomplete-information game and seek a Bayesian Nash\nequilibrium (BNE), in which each agent optimally responds to its probabilistic\nbeliefs about the strategies of others. We introduce Efficient Coordination via\nNash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that\nmarries distributed reasoning with centralized final output. Under ECON, each\nLLM independently selects responses that maximize its expected reward,\nconditioned on its beliefs about co-agents, without requiring costly\ninter-agent exchanges. We mathematically prove that ECON attains a markedly\ntighter regret bound than non-equilibrium multi-agent schemes. Empirically,\nECON outperforms existing multi-LLM approaches by 11.2% on average across six\nbenchmarks spanning complex reasoning and planning tasks. Further experiments\ndemonstrate ECON's ability to flexibly incorporate additional models,\nconfirming its scalability and paving the way toward larger, more powerful\nmulti-LLM ensembles. The code is publicly available at:\nhttps://github.com/tmlr-group/ECON.", "AI": {"tldr": "ECON introduces a hierarchical reinforcement-learning paradigm for multi-LLM coordination, achieving better performance and scalability with a proven tighter regret bound.", "motivation": "Multi-agent frameworks enhance LLM reasoning but face computational costs and lack convergence guarantees.", "method": "Recasts multi-LLM coordination as an incomplete-information game, seeking Bayesian Nash equilibrium (BNE) with distributed reasoning and centralized output.", "result": "Outperforms existing multi-LLM approaches by 11.2% on benchmarks and demonstrates scalability.", "conclusion": "ECON offers a scalable, efficient solution for multi-LLM coordination with theoretical and empirical advantages."}}
{"id": "2506.08625", "pdf": "https://arxiv.org/pdf/2506.08625", "abs": "https://arxiv.org/abs/2506.08625", "authors": ["Minhae Oh", "Jeonghye Kim", "Nakyung Lee", "Donggeon Seo", "Taeuk Kim", "Jungwoo Lee"], "title": "RAISE: Enhancing Scientific Reasoning in LLMs via Step-by-Step Retrieval", "categories": ["cs.CL"], "comment": null, "summary": "Scientific reasoning requires not only long-chain reasoning processes, but\nalso knowledge of domain-specific terminologies and adaptation to updated\nfindings. To deal with these challenges for scientific reasoning, we introduce\nRAISE, a step-by-step retrieval-augmented framework which retrieves logically\nrelevant documents from in-the-wild corpus. RAISE is divided into three steps:\nproblem decomposition, logical query generation, and logical retrieval. We\nobserve that RAISE consistently outperforms other baselines on scientific\nreasoning benchmarks. We analyze that unlike other baselines, RAISE retrieves\ndocuments that are not only similar in terms of the domain knowledge, but also\ndocuments logically more relevant.", "AI": {"tldr": "RAISE is a retrieval-augmented framework for scientific reasoning, outperforming baselines by retrieving logically relevant documents.", "motivation": "Scientific reasoning involves complex processes and domain-specific knowledge, requiring adaptive solutions.", "method": "RAISE uses problem decomposition, logical query generation, and logical retrieval to retrieve relevant documents.", "result": "RAISE consistently outperforms baselines on scientific reasoning benchmarks by retrieving logically relevant documents.", "conclusion": "RAISE's logical retrieval approach enhances scientific reasoning by focusing on relevance beyond domain similarity."}}
{"id": "2506.08612", "pdf": "https://arxiv.org/pdf/2506.08612", "abs": "https://arxiv.org/abs/2506.08612", "authors": ["Robert-Jan Bruintjes", "Attila Lengyel", "Osman Semih Kayhan", "Davide Zambrano", "Nergis T\u00f6men", "Hadi Jamali-Rad", "Jan van Gemert"], "title": "Data-Efficient Challenges in Visual Inductive Priors: A Retrospective", "categories": ["cs.CV"], "comment": null, "summary": "Deep Learning requires large amounts of data to train models that work well.\nIn data-deficient settings, performance can be degraded. We investigate which\nDeep Learning methods benefit training models in a data-deficient setting, by\norganizing the \"VIPriors: Visual Inductive Priors for Data-Efficient Deep\nLearning\" workshop series, featuring four editions of data-impaired challenges.\nThese challenges address the problem of training deep learning models for\ncomputer vision tasks with limited data. Participants are limited to training\nmodels from scratch using a low number of training samples and are not allowed\nto use any form of transfer learning. We aim to stimulate the development of\nnovel approaches that incorporate prior knowledge to improve the data\nefficiency of deep learning models. Successful challenge entries make use of\nlarge model ensembles that mix Transformers and CNNs, as well as heavy data\naugmentation. Novel prior knowledge-based methods contribute to success in some\nentries.", "AI": {"tldr": "The paper explores deep learning methods for data-deficient settings through the VIPriors workshop, focusing on training models from scratch with limited data and no transfer learning. Successful approaches include model ensembles and data augmentation.", "motivation": "To address the challenge of training deep learning models effectively in data-deficient settings, particularly for computer vision tasks.", "method": "Organized the VIPriors workshop series with data-impaired challenges, restricting participants to training from scratch with limited data and no transfer learning.", "result": "Successful entries used large model ensembles (Transformers and CNNs), heavy data augmentation, and prior knowledge-based methods.", "conclusion": "Incorporating prior knowledge and innovative methods like ensembles and augmentation can improve data efficiency in deep learning."}}
{"id": "2506.07675", "pdf": "https://arxiv.org/pdf/2506.07675", "abs": "https://arxiv.org/abs/2506.07675", "authors": ["Yuyang Song", "Hanxu Yan", "Jiale Lao", "Yibo Wang", "Yufei Li", "Yuanchun Zhou", "Jianguo Wang", "Mingjie Tang"], "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Query rewrite transforms SQL queries into semantically equivalent forms that\nrun more efficiently. Existing approaches mainly rely on predefined rewrite\nrules, but they handle a limited subset of queries and can cause performance\nregressions. This limitation stems from three challenges of rule-based query\nrewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite\nrules do not generalize to new query patterns, and (3) some rewrite techniques\ncannot be expressed as fixed rules. Motivated by the fact that human experts\nexhibit significantly better rewrite ability but suffer from scalability, and\nLarge Language Models (LLMs) have demonstrated nearly human-level semantic and\nreasoning abilities, we propose a new approach of using LLMs to rewrite SQL\nqueries beyond rules. Due to the hallucination problems in LLMs, directly\napplying LLMs often leads to nonequivalent and suboptimal queries. To address\nthis issue, we propose QUITE (query rewrite), a training-free and\nfeedback-aware system based on LLM agents that rewrites SQL queries into\nsemantically equivalent forms with significantly better performance, covering a\nbroader range of query patterns and rewrite strategies compared to rule-based\nmethods. Firstly, we design a multi-agent framework controlled by a finite\nstate machine (FSM) to equip LLMs with the ability to use external tools and\nenhance the rewrite process with real-time database feedback. Secondly, we\ndevelop a rewrite middleware to enhance the ability of LLMs to generate\noptimized query equivalents. Finally, we employ a novel hint injection\ntechnique to improve execution plans for rewritten queries. Extensive\nexperiments show that QUITE reduces query execution time by up to 35.8% over\nstate-of-the-art approaches and produces 24.1% more rewrites than prior\nmethods, covering query cases that earlier systems did not handle.", "AI": {"tldr": "QUITE uses LLMs to rewrite SQL queries beyond rule-based methods, improving performance and coverage by leveraging multi-agent frameworks and feedback.", "motivation": "Existing rule-based query rewrite methods are limited in handling diverse queries and can cause regressions. Human experts and LLMs offer better rewrite potential but face scalability and hallucination issues.", "method": "QUITE employs a training-free, feedback-aware system with a multi-agent framework, rewrite middleware, and hint injection to optimize SQL queries.", "result": "QUITE reduces execution time by up to 35.8% and produces 24.1% more rewrites than state-of-the-art methods.", "conclusion": "QUITE demonstrates superior performance and broader query coverage, addressing limitations of rule-based approaches."}}
{"id": "2506.08295", "pdf": "https://arxiv.org/pdf/2506.08295", "abs": "https://arxiv.org/abs/2506.08295", "authors": ["Zhanke Zhou", "Xiao Feng", "Zhaocheng Zhu", "Jiangchao Yao", "Sanmi Koyejo", "Bo Han"], "title": "From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "While existing benchmarks probe the reasoning abilities of large language\nmodels (LLMs) across diverse domains, they predominantly assess passive\nreasoning, providing models with all the information needed to reach a\nsolution. By contrast, active reasoning-where an LLM must interact with\nexternal systems to acquire missing evidence or data-has received little\nsystematic attention. To address this shortfall, we present AR-Bench, a novel\nbenchmark designed explicitly to evaluate an LLM's active reasoning skills.\nAR-Bench comprises three task families-detective cases, situation puzzles, and\nguessing numbers-that together simulate real-world, agentic scenarios and\nmeasure performance across commonsense, logical, and symbolic reasoning\nchallenges. Empirical evaluation on AR-Bench demonstrates that contemporary\nLLMs exhibit pronounced difficulties with active reasoning: they frequently\nfail to acquire or leverage the information needed to solve tasks. This gap\nhighlights a stark divergence between their passive and active reasoning\nabilities. Moreover, ablation studies indicate that even advanced strategies,\nsuch as tree-based searching or post-training approaches, yield only modest\ngains and fall short of the levels required for real-world deployment.\nCollectively, these findings highlight the critical need to advance methodology\nfor active reasoning, e.g., incorporating interactive learning, real-time\nfeedback loops, and environment-aware objectives for training. The benchmark is\npublicly available at: https://github.com/tmlr-group/AR-Bench.", "AI": {"tldr": "AR-Bench is a new benchmark evaluating LLMs' active reasoning skills, revealing their struggles compared to passive reasoning.", "motivation": "Existing benchmarks focus on passive reasoning, neglecting active reasoning where LLMs interact with external systems.", "method": "AR-Bench includes detective cases, situation puzzles, and guessing numbers to test commonsense, logical, and symbolic reasoning.", "result": "Current LLMs perform poorly in active reasoning, with limited improvement from advanced strategies.", "conclusion": "The study underscores the need for better methodologies, like interactive learning, to enhance active reasoning in LLMs."}}
{"id": "2506.08643", "pdf": "https://arxiv.org/pdf/2506.08643", "abs": "https://arxiv.org/abs/2506.08643", "authors": ["Son The Nguyen", "Theja Tulabandhula"], "title": "MEMETRON: Metaheuristic Mechanisms for Test-time Response Optimization of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used for both open-ended and\nstructured tasks, yet their inference-time behavior is still largely dictated\nby heuristic decoding strategies such as greedy search, sampling, or reranking.\nThese methods provide limited control and do not explicitly optimize for\ntask-specific objectives. We introduce MEMETRON, a task-agnostic framework that\nformulates LLM decoding as a discrete black-box optimization problem. MEMETRON\nleverages hybrid metaheuristic algorithms, GENETRON and ANNETRON, to search the\nresponse space, guided by reward models and contextual operations performed by\nthe LLM itself. This approach enables efficient discovery of high-reward\nresponses without requiring model retraining or gradient access. The framework\nis modular and generalizes across diverse tasks, requiring only a reward\nfunction and lightweight prompt templates. We evaluate our framework on the\ncritical human preference alignment task and demonstrate that it significantly\noutperforms standard decoding and reranking methods, highlighting its potential\nto improve alignment without model retraining.", "AI": {"tldr": "MEMETRON is a task-agnostic framework for LLM decoding, using metaheuristic algorithms to optimize responses without retraining, outperforming standard methods.", "motivation": "Current LLM decoding strategies lack control and task-specific optimization, limiting performance and alignment with objectives.", "method": "MEMETRON formulates decoding as a discrete black-box optimization problem, using hybrid metaheuristic algorithms (GENETRON, ANNETRON) guided by reward models and LLM operations.", "result": "MEMETRON outperforms standard decoding and reranking methods, especially in human preference alignment tasks.", "conclusion": "MEMETRON offers a modular, efficient solution for improving LLM alignment and performance without retraining."}}
{"id": "2506.08613", "pdf": "https://arxiv.org/pdf/2506.08613", "abs": "https://arxiv.org/abs/2506.08613", "authors": ["Joost van Dalen", "Yuki M. Asano", "Marc Russwurm"], "title": "SAMSelect: A Spectral Index Search for Marine Debris Visualization using Segment Anything", "categories": ["cs.CV"], "comment": null, "summary": "This work proposes SAMSelect, an algorithm to obtain a salient three-channel\nvisualization for multispectral images. We develop SAMSelect and show its use\nfor marine scientists visually interpreting floating marine debris in\nSentinel-2 imagery. These debris are notoriously difficult to visualize due to\ntheir compositional heterogeneity in medium-resolution imagery. Out of these\ndifficulties, a visual interpretation of imagery showing marine debris remains\na common practice by domain experts, who select bands and spectral indices on a\ncase-by-case basis informed by common practices and heuristics. SAMSelect\nselects the band or index combination that achieves the best classification\naccuracy on a small annotated dataset through the Segment Anything Model. Its\ncentral assumption is that the three-channel visualization achieves the most\naccurate segmentation results also provide good visual information for\nphoto-interpretation.\n  We evaluate SAMSelect in three Sentinel-2 scenes containing generic marine\ndebris in Accra, Ghana, and Durban, South Africa, and deployed plastic targets\nfrom the Plastic Litter Project. This reveals the potential of new previously\nunused band combinations (e.g., a normalized difference index of B8, B2), which\ndemonstrate improved performance compared to literature-based indices. We\ndescribe the algorithm in this paper and provide an open-source code repository\nthat will be helpful for domain scientists doing visual photo interpretation,\nespecially in the marine field.", "AI": {"tldr": "SAMSelect is an algorithm for visualizing multispectral images, specifically for marine debris in Sentinel-2 imagery, by selecting optimal band combinations for accurate segmentation and photo-interpretation.", "motivation": "Marine debris is hard to visualize due to heterogeneity in medium-resolution imagery, and current methods rely on manual, heuristic-based band selection.", "method": "SAMSelect uses the Segment Anything Model to choose the best band or index combination for classification accuracy on annotated data.", "result": "Tested on Sentinel-2 scenes, SAMSelect identified new band combinations (e.g., B8, B2) outperforming literature-based indices.", "conclusion": "SAMSelect offers a practical, automated solution for marine scientists, with open-source code for broader application."}}
{"id": "2506.08023", "pdf": "https://arxiv.org/pdf/2506.08023", "abs": "https://arxiv.org/abs/2506.08023", "authors": ["Qifeng Wu", "Zhengzhe Liu", "Han Zhu", "Yizhou Zhao", "Daisuke Kihara", "Min Xu"], "title": "Aligning Proteins and Language: A Foundation Model for Protein Retrieval", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.CV", "cs.LG"], "comment": "4 pages for body, 3 pages for appendix, 11 figures. Accepted to CVPR\n  2025 Workshop on Multimodal Foundation Models for Biomedicine: Challenges and\n  Opportunities(MMFM-BIOMED)", "summary": "This paper aims to retrieve proteins with similar structures and semantics\nfrom large-scale protein dataset, facilitating the functional interpretation of\nprotein structures derived by structural determination methods like\ncryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of\nvision-language models (VLMs), we propose a CLIP-style framework for aligning\n3D protein structures with functional annotations using contrastive learning.\nFor model training, we propose a large-scale dataset of approximately 200,000\nprotein-caption pairs with rich functional descriptors. We evaluate our model\nin both in-domain and more challenging cross-database retrieval on Protein Data\nBank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In\nboth cases, our approach demonstrates promising zero-shot retrieval\nperformance, highlighting the potential of multimodal foundation models for\nstructure-function understanding in protein biology.", "AI": {"tldr": "A CLIP-style framework aligns 3D protein structures with functional annotations using contrastive learning, achieving promising zero-shot retrieval performance.", "motivation": "To facilitate functional interpretation of protein structures by retrieving similar proteins from large datasets, leveraging advances in vision-language models.", "method": "Proposes a contrastive learning framework to align 3D protein structures with functional annotations, trained on a dataset of 200,000 protein-caption pairs.", "result": "Demonstrates promising zero-shot retrieval performance in both in-domain and cross-database settings (PDB and EMDB).", "conclusion": "Highlights the potential of multimodal foundation models for advancing structure-function understanding in protein biology."}}
{"id": "2506.08298", "pdf": "https://arxiv.org/pdf/2506.08298", "abs": "https://arxiv.org/abs/2506.08298", "authors": ["Trung-Kien Nguyen", "Heng Ping", "Shixuan Li", "Peiyu Zhang", "Nikos Kanakaris", "Nicholas Kotov", "Paul Bogdan"], "title": "H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "The growing interests and applications of graph learning in diverse domains\nhave propelled the development of a unified model generalizing well across\ndifferent graphs and tasks, known as the Graph Foundation Model (GFM). Existing\nresearch has leveraged text-attributed graphs (TAGs) to tackle the\nheterogeneity in node features among graphs. However, they primarily focus on\nhomogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple\ntypes of nodes/edges reside, underexplored. To enhance the capabilities and\napplications of GFM, we introduce H$^2$GFM, a novel framework designed to\ngeneralize across both HoTAGs and HeTAGs. Our model projects diverse\nmeta-relations among graphs under a unified textual space, and employs a\ncontext encoding to capture spatial and higher-order semantic relationships. To\nachieve robust node representations, we propose a novel context-adaptive graph\ntransformer (CGT), effectively capturing information from both context\nneighbors and their relationships. Furthermore, we employ a mixture of CGT\nexperts to capture the heterogeneity in structural patterns among graph types.\nComprehensive experiments on a wide range of HoTAGs and HeTAGs as well as\nlearning scenarios demonstrate the effectiveness of our model.", "AI": {"tldr": "The paper introduces H\u00b2GFM, a framework for generalizing Graph Foundation Models (GFMs) across homogeneous and heterogeneous text-attributed graphs (TAGs), using a context-adaptive graph transformer and mixture of experts for robust node representations.", "motivation": "Existing GFMs focus on homogeneous TAGs, leaving heterogeneous TAGs underexplored. The goal is to enhance GFM capabilities by addressing both graph types.", "method": "H\u00b2GFM projects meta-relations into a unified textual space, uses context encoding for semantic relationships, and employs a context-adaptive graph transformer (CGT) with a mixture of experts for structural heterogeneity.", "result": "Comprehensive experiments show H\u00b2GFM's effectiveness across diverse TAGs and learning scenarios.", "conclusion": "H\u00b2GFM successfully generalizes GFMs to both homogeneous and heterogeneous TAGs, improving robustness and applicability."}}
{"id": "2506.08646", "pdf": "https://arxiv.org/pdf/2506.08646", "abs": "https://arxiv.org/abs/2506.08646", "authors": ["Mingyu Zheng", "Zhifan Feng", "Jia Wang", "Lanrui Wang", "Zheng Lin", "Yang Hao", "Weiping Wang"], "title": "TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "27 pages, 19 figures, Findings of ACL 2025", "summary": "Despite the commendable progress of recent LLM-based data synthesis methods,\nthey face two limitations in generating table instruction tuning data. First,\nthey can not thoroughly explore the vast input space of table understanding\ntasks, leading to limited data diversity. Second, they ignore the weaknesses in\ntable understanding ability of the target LLM and blindly pursue the increase\nof data quantity, resulting in suboptimal data efficiency. In this paper, we\nintroduce a progressive and weakness-guided data synthesis framework tailored\nfor table instruction tuning, named TableDreamer, to mitigate the above issues.\nSpecifically, we first synthesize diverse tables and related instructions as\nseed data, and then perform an iterative exploration of the input space under\nthe guidance of the newly identified weakness data, which eventually serve as\nthe final training data for fine-tuning the target LLM. Extensive experiments\non 10 tabular benchmarks demonstrate the effectiveness of the proposed\nframework, which boosts the average accuracy of Llama3.1-8B-instruct by 11.62%\n(49.07% to 60.69%) with 27K GPT-4o synthetic data and outperforms\nstate-of-the-art data synthesis baselines which use more training data. The\ncode and data is available at https://github.com/SpursGoZmy/TableDreamer", "AI": {"tldr": "TableDreamer addresses limitations in LLM-based table instruction tuning data synthesis by diversifying input space exploration and targeting model weaknesses, improving accuracy by 11.62%.", "motivation": "Existing methods lack diversity in table understanding tasks and ignore model weaknesses, leading to inefficient data synthesis.", "method": "A progressive, weakness-guided framework synthesizes diverse seed data and iteratively refines it based on identified weaknesses.", "result": "Boosts Llama3.1-8B-instruct accuracy by 11.62% with 27K synthetic data, outperforming baselines.", "conclusion": "TableDreamer effectively enhances table instruction tuning by addressing diversity and efficiency issues."}}
{"id": "2506.08619", "pdf": "https://arxiv.org/pdf/2506.08619", "abs": "https://arxiv.org/abs/2506.08619", "authors": ["Gon\u00e7alo Dias Pais", "Valter Piedade", "Moitreya Chatterjee", "Marcus Greiff", "Pedro Miraldo"], "title": "A Probability-guided Sampler for Neural Implicit Surface Rendering", "categories": ["cs.CV"], "comment": "Accepted in ECCV 2024", "summary": "Several variants of Neural Radiance Fields (NeRFs) have significantly\nimproved the accuracy of synthesized images and surface reconstruction of 3D\nscenes/objects. In all of these methods, a key characteristic is that none can\ntrain the neural network with every possible input data, specifically, every\npixel and potential 3D point along the projection rays due to scalability\nissues. While vanilla NeRFs uniformly sample both the image pixels and 3D\npoints along the projection rays, some variants focus only on guiding the\nsampling of the 3D points along the projection rays. In this paper, we leverage\nthe implicit surface representation of the foreground scene and model a\nprobability density function in a 3D image projection space to achieve a more\ntargeted sampling of the rays toward regions of interest, resulting in improved\nrendering. Additionally, a new surface reconstruction loss is proposed for\nimproved performance. This new loss fully explores the proposed 3D image\nprojection space model and incorporates near-to-surface and empty space\ncomponents. By integrating our novel sampling strategy and novel loss into\ncurrent state-of-the-art neural implicit surface renderers, we achieve more\naccurate and detailed 3D reconstructions and improved image rendering,\nespecially for the regions of interest in any given scene.", "AI": {"tldr": "The paper introduces a targeted sampling strategy and a new surface reconstruction loss for Neural Radiance Fields (NeRFs) to improve rendering accuracy and 3D reconstruction.", "motivation": "Existing NeRF variants struggle with scalability and uniform sampling, missing detailed regions of interest.", "method": "Leverages implicit surface representation and models a probability density function for targeted ray sampling, along with a novel surface reconstruction loss.", "result": "Achieves more accurate 3D reconstructions and improved image rendering, especially in regions of interest.", "conclusion": "The proposed method enhances NeRF performance by focusing on key areas and optimizing loss functions."}}
{"id": "2506.08029", "pdf": "https://arxiv.org/pdf/2506.08029", "abs": "https://arxiv.org/abs/2506.08029", "authors": ["Jiayu Li", "Masood Mortazavi", "Ning Yan", "Yihong Ma", "Reza Zafarani"], "title": "Inverse Design in Distributed Circuits Using Single-Step Reinforcement Learning", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": "A briefer version of this paper was accepted as a Work-in-Progress\n  (WIP) at the Design Automation Conference (DAC) 2024", "summary": "The goal of inverse design in distributed circuits is to generate\nnear-optimal designs that meet a desirable transfer function specification.\nExisting design exploration methods use some combination of strategies\ninvolving artificial grids, differentiable evaluation procedures, and specific\ntemplate topologies. However, real-world design practices often require\nnon-differentiable evaluation procedures, varying topologies, and\nnear-continuous placement spaces. In this paper, we propose DCIDA, a design\nexploration framework that learns a near-optimal design sampling policy for a\ntarget transfer function. DCIDA decides all design factors in a compound\nsingle-step action by sampling from a set of jointly-trained conditional\ndistributions generated by the policy. Utilizing an injective interdependent\n``map\", DCIDA transforms raw sampled design ``actions\" into uniquely equivalent\nphysical representations, enabling the framework to learn the conditional\ndependencies among joint ``raw'' design decisions. Our experiments demonstrate\nDCIDA's Transformer-based policy network achieves significant reductions in\ndesign error compared to state-of-the-art approaches, with significantly better\nfit in cases involving more complex transfer functions.", "AI": {"tldr": "DCIDA is a framework for inverse design in distributed circuits, using a Transformer-based policy to sample near-optimal designs, outperforming existing methods.", "motivation": "Existing methods struggle with non-differentiable evaluations, varying topologies, and continuous placement spaces, necessitating a more flexible approach.", "method": "DCIDA learns a sampling policy for design factors via jointly-trained conditional distributions, transforming raw actions into physical representations.", "result": "DCIDA reduces design error significantly, especially for complex transfer functions, compared to state-of-the-art methods.", "conclusion": "DCIDA offers a robust solution for inverse design, improving accuracy and adaptability in real-world circuit design scenarios."}}
{"id": "2506.08309", "pdf": "https://arxiv.org/pdf/2506.08309", "abs": "https://arxiv.org/abs/2506.08309", "authors": ["Katherine Tieu", "Dongqi Fu", "Zihao Li", "Ross Maciejewski", "Jingrui He"], "title": "Learnable Spatial-Temporal Positional Encoding for Link Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025. 28 pages, 1 figures, 22 tables", "summary": "Accurate predictions rely on the expressiveness power of graph deep learning\nframeworks like graph neural networks and graph transformers, where a\npositional encoding mechanism has become much more indispensable in recent\nstate-of-the-art works to record the canonical position information. However,\nthe current positional encoding is limited in three aspects: (1) most\npositional encoding methods use pre-defined, and fixed functions, which are\ninadequate to adapt to the complex attributed graphs; (2) a few pioneering\nworks proposed the learnable positional encoding but are still limited to the\nstructural information, not considering the real-world time-evolving\ntopological and feature information; (3) most positional encoding methods are\nequipped with transformers' attention mechanism to fully leverage their\ncapabilities, where the dense or relational attention is often unaffordable on\nlarge-scale structured data. Hence, we aim to develop Learnable\nSpatial-Temporal Positional Encoding in an effective and efficient manner and\npropose a simple temporal link prediction model named L-STEP. Briefly, for\nL-STEP, we (1) prove the proposed positional learning scheme can preserve the\ngraph property from the spatial-temporal spectral viewpoint, (2) verify that\nMLPs can fully exploit the expressiveness and reach transformers' performance\non that encoding, (3) change different initial positional encoding inputs to\nshow robustness, (4) analyze the theoretical complexity and obtain less\nempirical running time than SOTA, and (5) demonstrate its temporal link\nprediction out-performance on 13 classic datasets and with 10 algorithms in\nboth transductive and inductive settings using 3 different sampling strategies.\nAlso, \\name\\ obtains the leading performance in the newest large-scale TGB\nbenchmark. Our code is available at https://github.com/kthrn22/L-STEP.", "AI": {"tldr": "The paper introduces L-STEP, a learnable spatial-temporal positional encoding method for graphs, addressing limitations of current positional encoding techniques and demonstrating superior performance in temporal link prediction.", "motivation": "Current positional encoding methods are limited by pre-defined functions, lack of adaptability to evolving graph structures, and inefficiency with large-scale data.", "method": "Proposes L-STEP, a learnable positional encoding scheme, validated through spatial-temporal spectral analysis, MLP-based expressiveness, and robustness tests.", "result": "L-STEP outperforms 10 algorithms on 13 datasets, achieves leading performance in the TGB benchmark, and reduces empirical running time.", "conclusion": "L-STEP effectively addresses the limitations of existing positional encoding methods, offering a scalable and efficient solution for graph learning tasks."}}
{"id": "2506.08647", "pdf": "https://arxiv.org/pdf/2506.08647", "abs": "https://arxiv.org/abs/2506.08647", "authors": ["Oumaima El Khettari", "Solen Quiniou", "Samuel Chaffron"], "title": "Summarization for Generative Relation Extraction in the Microbiome Domain", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We explore a generative relation extraction (RE) pipeline tailored to the\nstudy of interactions in the intestinal microbiome, a complex and low-resource\nbiomedical domain. Our method leverages summarization with large language\nmodels (LLMs) to refine context before extracting relations via\ninstruction-tuned generation. Preliminary results on a dedicated corpus show\nthat summarization improves generative RE performance by reducing noise and\nguiding the model. However, BERT-based RE approaches still outperform\ngenerative models. This ongoing work demonstrates the potential of generative\nmethods to support the study of specialized domains in low-resources setting.", "AI": {"tldr": "A generative relation extraction (RE) pipeline for the intestinal microbiome uses LLM summarization to refine context, improving performance but still lagging behind BERT-based methods.", "motivation": "To study interactions in the low-resource intestinal microbiome domain using generative RE.", "method": "Leverages LLM summarization to refine context before extracting relations via instruction-tuned generation.", "result": "Summarization improves generative RE performance, but BERT-based methods still outperform.", "conclusion": "Generative methods show promise for specialized, low-resource domains, though further development is needed."}}
{"id": "2506.08629", "pdf": "https://arxiv.org/pdf/2506.08629", "abs": "https://arxiv.org/abs/2506.08629", "authors": ["Feixiang Du", "Shengkun Wu"], "title": "ECMNet:Lightweight Semantic Segmentation with Efficient CNN-Mamba Network", "categories": ["cs.CV", "cs.AI"], "comment": "16 pages, 2 figures, 4 tables", "summary": "In the past decade, Convolutional Neural Networks (CNNs) and Transformers\nhave achieved wide applicaiton in semantic segmentation tasks. Although CNNs\nwith Transformer models greatly improve performance, the global context\nmodeling remains inadequate. Recently, Mamba achieved great potential in vision\ntasks, showing its advantages in modeling long-range dependency. In this paper,\nwe propose a lightweight Efficient CNN-Mamba Network for semantic segmentation,\ndubbed as ECMNet. ECMNet combines CNN with Mamba skillfully in a capsule-based\nframework to address their complementary weaknesses. Specifically, We design a\nEnhanced Dual-Attention Block (EDAB) for lightweight bottleneck. In order to\nimprove the representations ability of feature, We devise a Multi-Scale\nAttention Unit (MSAU) to integrate multi-scale feature aggregation, spatial\naggregation and channel aggregation. Moreover, a Mamba enhanced Feature Fusion\nModule (FFM) merges diverse level feature, significantly enhancing segmented\naccuracy. Extensive experiments on two representative datasets demonstrate that\nthe proposed model excels in accuracy and efficiency balance, achieving 70.6%\nmIoU on Cityscapes and 73.6% mIoU on CamVid test datasets, with 0.87M\nparameters and 8.27G FLOPs on a single RTX 3090 GPU platform.", "AI": {"tldr": "The paper proposes ECMNet, a lightweight CNN-Mamba hybrid network for semantic segmentation, combining CNN and Mamba to address global context modeling. It introduces EDAB, MSAU, and FFM modules, achieving high accuracy with low computational cost.", "motivation": "Existing CNN-Transformer models for semantic segmentation lack adequate global context modeling. Mamba's potential in vision tasks inspired the integration of CNN and Mamba to leverage their complementary strengths.", "method": "ECMNet combines CNN and Mamba in a capsule-based framework. It includes EDAB for lightweight bottlenecks, MSAU for multi-scale feature aggregation, and FFM for enhanced feature fusion.", "result": "The model achieves 70.6% mIoU on Cityscapes and 73.6% mIoU on CamVid, with 0.87M parameters and 8.27G FLOPs.", "conclusion": "ECMNet effectively balances accuracy and efficiency, demonstrating the potential of CNN-Mamba hybrids in semantic segmentation."}}
{"id": "2506.08041", "pdf": "https://arxiv.org/pdf/2506.08041", "abs": "https://arxiv.org/abs/2506.08041", "authors": ["Siddharth Siddharth", "Brainerd Prince", "Amol Harsh", "Shreyas Ramachandran"], "title": "The World of AI: A Novel Approach to AI Literacy for First-year Engineering Students", "categories": ["cs.CY", "cs.AI"], "comment": "Accepted for publication at AIED 2025 in the late-breaking work track", "summary": "This work presents a novel course titled The World of AI designed for\nfirst-year undergraduate engineering students with little to no prior exposure\nto AI. The central problem addressed by this course is that engineering\nstudents often lack foundational knowledge of AI and its broader societal\nimplications at the outset of their academic journeys. We believe the way to\naddress this gap is to design and deliver an interdisciplinary course that can\na) be accessed by first-year undergraduate engineering students across any\ndomain, b) enable them to understand the basic workings of AI systems sans\nmathematics, and c) make them appreciate AI's far-reaching implications on our\nlives. The course was divided into three modules co-delivered by faculty from\nboth engineering and humanities. The planetary module explored AI's dual role\nas both a catalyst for sustainability and a contributor to environmental\nchallenges. The societal impact module focused on AI biases and concerns around\nprivacy and fairness. Lastly, the workplace module highlighted AI-driven job\ndisplacement, emphasizing the importance of adaptation. The novelty of this\ncourse lies in its interdisciplinary curriculum design and pedagogical\napproach, which combines technical instruction with societal discourse. Results\nrevealed that students' comprehension of AI challenges improved across diverse\nmetrics like (a) increased awareness of AI's environmental impact, and (b)\nefficient corrective solutions for AI fairness. Furthermore, it also indicated\nthe evolution in students' perception of AI's transformative impact on our\nlives.", "AI": {"tldr": "A novel interdisciplinary course, 'The World of AI,' was designed for first-year engineering students to address their lack of foundational AI knowledge and societal awareness. The course, co-taught by engineering and humanities faculty, improved students' understanding of AI's environmental, societal, and workplace impacts.", "motivation": "Engineering students often lack foundational AI knowledge and awareness of its societal implications early in their academic journey. This course aims to bridge that gap.", "method": "The course was divided into three interdisciplinary modules: planetary (AI's environmental role), societal (biases, privacy, fairness), and workplace (job displacement). It combined technical instruction with societal discourse.", "result": "Students showed improved comprehension of AI challenges, including increased awareness of environmental impact and better solutions for AI fairness. Their perception of AI's transformative role also evolved.", "conclusion": "The interdisciplinary design of the course successfully enhanced students' foundational AI knowledge and societal awareness, proving its effectiveness for early-stage engineering education."}}
{"id": "2506.08312", "pdf": "https://arxiv.org/pdf/2506.08312", "abs": "https://arxiv.org/abs/2506.08312", "authors": ["Tom\u00e1s Gonz\u00e1lez", "Giulia Fanti", "Aaditya Ramdas"], "title": "Private Evolution Converges", "categories": ["cs.LG", "cs.CR", "cs.DS", "math.PR", "math.ST", "stat.TH", "68P27 (Primary) 68Q32, 68Q87, 60B10 (Secondary)"], "comment": null, "summary": "Private Evolution (PE) is a promising training-free method for differentially\nprivate (DP) synthetic data generation. While it achieves strong performance in\nsome domains (e.g., images and text), its behavior in others (e.g., tabular\ndata) is less consistent. To date, the only theoretical analysis of the\nconvergence of PE depends on unrealistic assumptions about both the algorithm's\nbehavior and the structure of the sensitive dataset. In this work, we develop a\nnew theoretical framework to explain PE's practical behavior and identify\nsufficient conditions for its convergence. For $d$-dimensional sensitive\ndatasets with $n$ data points from a bounded domain, we prove that PE produces\nan $(\\epsilon, \\delta)$-DP synthetic dataset with expected 1-Wasserstein\ndistance of order $\\tilde{O}(d(n\\epsilon)^{-1/d})$ from the original,\nestablishing worst-case convergence of the algorithm as $n \\to \\infty$. Our\nanalysis extends to general Banach spaces as well. We also connect PE to the\nPrivate Signed Measure Mechanism, a method for DP synthetic data generation\nthat has thus far not seen much practical adoption. We demonstrate the\npractical relevance of our theoretical findings in simulations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08672", "pdf": "https://arxiv.org/pdf/2506.08672", "abs": "https://arxiv.org/abs/2506.08672", "authors": ["Yang Liu", "Jiaqi Li", "Zilong Zheng"], "title": "RuleReasoner: Reinforced Rule-based Reasoning via Domain-aware Dynamic Sampling", "categories": ["cs.CL"], "comment": "22 pages, 10 figures, 8 tables", "summary": "Rule-based reasoning has been acknowledged as one of the fundamental problems\nin reasoning, while deviations in rule formats, types, and complexity in\nreal-world applications pose severe challenges. Recent studies have shown that\nlarge reasoning models (LRMs) have remarkable reasoning capabilities, and their\nperformance is substantially enhanced by reinforcement learning (RL). However,\nit remains an open question whether small reasoning models (SRMs) can learn\nrule-based reasoning effectively with robust generalization across diverse\ntasks and domains. To address this, we introduce Reinforced Rule-based\nReasoning, a.k.a. RuleReasoner, a simple yet effective method to conduct\nrule-based reasoning via a wide collection of curated tasks and a novel\ndomain-aware dynamic sampling approach. Specifically, RuleReasoner resamples\neach training batch by updating the sampling weights of different domains based\non historical rewards. This facilitates domain augmentation and flexible online\nlearning schedules for RL, obviating the need for pre-hoc human-engineered\nmix-training recipes used in existing methods. Empirical evaluations on\nin-distribution (ID) and out-of-distribution (OOD) benchmarks reveal that\nRuleReasoner outperforms frontier LRMs by a significant margin ($\\Delta$4.1%\naverage points on eight ID tasks and $\\Delta$10.4% average points on three OOD\ntasks over OpenAI-o1). Notably, our approach also exhibits higher computational\nefficiency compared to prior dynamic sampling methods for RL.", "AI": {"tldr": "RuleReasoner, a reinforced rule-based reasoning method, outperforms large reasoning models (LRMs) with improved generalization and efficiency.", "motivation": "Addressing the challenge of small reasoning models (SRMs) effectively learning rule-based reasoning across diverse tasks and domains.", "method": "Uses a domain-aware dynamic sampling approach for reinforcement learning, updating sampling weights based on historical rewards.", "result": "Outperforms LRMs by 4.1% on in-distribution tasks and 10.4% on out-of-distribution tasks, with higher computational efficiency.", "conclusion": "RuleReasoner is a simple yet effective method for robust rule-based reasoning, demonstrating superior performance and efficiency."}}
{"id": "2506.08632", "pdf": "https://arxiv.org/pdf/2506.08632", "abs": "https://arxiv.org/abs/2506.08632", "authors": ["Yang Bai", "Liudi Yang", "George Eskandar", "Fengyi Shen", "Dong Chen", "Mohammad Altillawi", "Ziyuan Liu", "Gitta Kutyniok"], "title": "RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in generative models have revolutionized video synthesis\nand editing. However, the scarcity of diverse, high-quality datasets continues\nto hinder video-conditioned robotic learning, limiting cross-platform\ngeneralization. In this work, we address the challenge of swapping a robotic\narm in one video with another: a key step for crossembodiment learning. Unlike\nprevious methods that depend on paired video demonstrations in the same\nenvironmental settings, our proposed framework, RoboSwap, operates on unpaired\ndata from diverse environments, alleviating the data collection needs. RoboSwap\nintroduces a novel video editing pipeline integrating both GANs and diffusion\nmodels, combining their isolated advantages. Specifically, we segment robotic\narms from their backgrounds and train an unpaired GAN model to translate one\nrobotic arm to another. The translated arm is blended with the original video\nbackground and refined with a diffusion model to enhance coherence, motion\nrealism and object interaction. The GAN and diffusion stages are trained\nindependently. Our experiments demonstrate that RoboSwap outperforms\nstate-of-the-art video and image editing models on three benchmarks in terms of\nboth structural coherence and motion consistency, thereby offering a robust\nsolution for generating reliable, cross-embodiment data in robotic learning.", "AI": {"tldr": "RoboSwap introduces a novel video editing pipeline combining GANs and diffusion models to swap robotic arms in videos, enabling cross-embodiment learning with unpaired data.", "motivation": "The scarcity of diverse, high-quality datasets hinders video-conditioned robotic learning, especially for cross-platform generalization.", "method": "RoboSwap segments robotic arms, uses GANs for translation, blends with backgrounds, and refines with diffusion models for coherence and realism.", "result": "Outperforms state-of-the-art models on three benchmarks in structural coherence and motion consistency.", "conclusion": "RoboSwap provides a robust solution for generating reliable cross-embodiment data in robotic learning."}}
{"id": "2506.08045", "pdf": "https://arxiv.org/pdf/2506.08045", "abs": "https://arxiv.org/abs/2506.08045", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs", "categories": ["cs.RO", "cs.AI"], "comment": "40 pages, 6 Figures", "summary": "Agentic UAVs represent a new frontier in autonomous aerial intelligence,\nintegrating perception, decision-making, memory, and collaborative planning to\noperate adaptively in complex, real-world environments. Driven by recent\nadvances in Agentic AI, these systems surpass traditional UAVs by exhibiting\ngoal-driven behavior, contextual reasoning, and interactive autonomy. We\nprovide a comprehensive foundation for understanding the architectural\ncomponents and enabling technologies that distinguish Agentic UAVs from\ntraditional autonomous UAVs. Furthermore, a detailed comparative analysis\nhighlights advancements in autonomy with AI agents, learning, and mission\nflexibility. This study explores seven high-impact application domains\nprecision agriculture, construction & mining, disaster response, environmental\nmonitoring, infrastructure inspection, logistics, security, and wildlife\nconservation, illustrating the broad societal value of agentic aerial\nintelligence. Furthermore, we identify key challenges in technical constraints,\nregulatory limitations, and data-model reliability, and we present emerging\nsolutions across hardware innovation, learning architectures, and human-AI\ninteraction. Finally, a future roadmap is proposed, outlining pathways toward\nself-evolving aerial ecosystems, system-level collaboration, and sustainable,\nequitable deployments. This survey establishes a foundational framework for the\nfuture development, deployment, and governance of agentic aerial systems\n(Agentic UAVs) across diverse societal and industrial domains.", "AI": {"tldr": "Agentic UAVs integrate AI-driven autonomy for adaptive operations in complex environments, surpassing traditional UAVs. This paper outlines their architecture, applications, challenges, and future directions.", "motivation": "To advance autonomous aerial intelligence by integrating perception, decision-making, and collaboration, addressing real-world complexities.", "method": "Comparative analysis of Agentic UAVs vs. traditional UAVs, exploration of enabling technologies, and examination of seven high-impact application domains.", "result": "Identifies advancements in autonomy, learning, and mission flexibility, alongside challenges like technical constraints and regulatory issues.", "conclusion": "Proposes a roadmap for self-evolving aerial ecosystems, emphasizing sustainable deployment and governance of Agentic UAVs."}}
{"id": "2506.08316", "pdf": "https://arxiv.org/pdf/2506.08316", "abs": "https://arxiv.org/abs/2506.08316", "authors": ["Alan N. Amin", "Nate Gruver", "Andrew Gordon Wilson"], "title": "Why Masking Diffusion Works: Condition on the Jump Schedule for Improved Discrete Diffusion", "categories": ["cs.LG", "stat.ML"], "comment": "Code available at: https://github.com/AlanNawzadAmin/SCUD", "summary": "Discrete diffusion models, like continuous diffusion models, generate\nhigh-quality samples by gradually undoing noise applied to datapoints with a\nMarkov process. Gradual generation in theory comes with many conceptual\nbenefits; for example, inductive biases can be incorporated into the noising\nMarkov process, and access to improved sampling algorithms. In practice,\nhowever, the consistently best performing discrete diffusion model is,\nsurprisingly, masking diffusion, which does not denoise gradually. Here we\nexplain the superior performance of masking diffusion by noting that it makes\nuse of a fundamental difference between continuous and discrete Markov\nprocesses: discrete Markov processes evolve by discontinuous jumps at a fixed\nrate and, unlike other discrete diffusion models, masking diffusion builds in\nthe known distribution of jump times and only learns where to jump to. We show\nthat we can similarly bake in the known distribution of jump times into any\ndiscrete diffusion model. The resulting models - schedule-conditioned discrete\ndiffusion (SCUD) - generalize classical discrete diffusion and masking\ndiffusion. By applying SCUD to models with noising processes that incorporate\ninductive biases on images, text, and protein data, we build models that\noutperform masking.", "AI": {"tldr": "Masking diffusion outperforms other discrete diffusion models by leveraging the known distribution of jump times in discrete Markov processes. The proposed SCUD framework generalizes this idea, improving performance across various data types.", "motivation": "To explain why masking diffusion performs better than other discrete diffusion models and to generalize its advantages to other models.", "method": "Introduces schedule-conditioned discrete diffusion (SCUD), which incorporates the known distribution of jump times into any discrete diffusion model.", "result": "SCUD models outperform masking diffusion when applied to images, text, and protein data.", "conclusion": "Baking in the known distribution of jump times enhances discrete diffusion models, making SCUD a superior framework."}}
{"id": "2506.08686", "pdf": "https://arxiv.org/pdf/2506.08686", "abs": "https://arxiv.org/abs/2506.08686", "authors": ["Soham Poddar", "Paramita Koley", "Janardan Misra", "Sanjay Podder", "Navveen Balani", "Niloy Ganguly", "Saptarshi Ghosh"], "title": "Brevity is the soul of sustainability: Characterizing LLM response lengths", "categories": ["cs.CL", "cs.CY"], "comment": "Accepted to appear at the ACL 2025 findings", "summary": "A significant portion of the energy consumed by Large Language Models (LLMs)\narises from their inference processes; hence developing energy-efficient\nmethods for inference is crucial. While several techniques exist for inference\noptimization, output compression remains relatively unexplored, with only a few\npreliminary efforts addressing this aspect. In this work, we first benchmark 12\ndecoder-only LLMs across 5 datasets, revealing that these models often produce\nresponses that are substantially longer than necessary. We then conduct a\ncomprehensive quality assessment of LLM responses, formally defining six\ninformation categories present in LLM responses. We show that LLMs often tend\nto include redundant or additional information besides the minimal answer. To\naddress this issue of long responses by LLMs, we explore several simple and\nintuitive prompt-engineering strategies. Empirical evaluation shows that\nappropriate prompts targeting length reduction and controlling information\ncontent can achieve significant energy optimization between 25-60\\% by reducing\nthe response length while preserving the quality of LLM responses.", "AI": {"tldr": "The paper explores energy-efficient inference for LLMs by reducing response length through prompt-engineering, achieving 25-60% energy savings without compromising quality.", "motivation": "Energy consumption in LLM inference is high, and output compression is understudied. The paper aims to address this by optimizing response length.", "method": "Benchmarked 12 decoder-only LLMs across 5 datasets, identified redundant information, and tested prompt-engineering strategies for length reduction.", "result": "Prompt-engineering reduced response length significantly, achieving 25-60% energy savings while maintaining response quality.", "conclusion": "Simple prompt-engineering can effectively optimize LLM energy use by reducing unnecessary response length."}}
{"id": "2506.08635", "pdf": "https://arxiv.org/pdf/2506.08635", "abs": "https://arxiv.org/abs/2506.08635", "authors": ["Siddhant Ranade", "Gon\u00e7alo Dias Pais", "Ross Tyler Whitaker", "Jacinto C. Nascimento", "Pedro Miraldo", "Srikumar Ramalingam"], "title": "SurfR: Surface Reconstruction with Multi-scale Attention", "categories": ["cs.CV"], "comment": "Accepted in 3DV 2025", "summary": "We propose a fast and accurate surface reconstruction algorithm for\nunorganized point clouds using an implicit representation. Recent learning\nmethods are either single-object representations with small neural models that\nallow for high surface details but require per-object training or generalized\nrepresentations that require larger models and generalize to newer shapes but\nlack details, and inference is slow. We propose a new implicit representation\nfor general 3D shapes that is faster than all the baselines at their optimum\nresolution, with only a marginal loss in performance compared to the\nstate-of-the-art. We achieve the best accuracy-speed trade-off using three key\ncontributions. Many implicit methods extract features from the point cloud to\nclassify whether a query point is inside or outside the object. First, to speed\nup the reconstruction, we show that this feature extraction does not need to\nuse the query point at an early stage (lazy query). Second, we use a parallel\nmulti-scale grid representation to develop robust features for different noise\nlevels and input resolutions. Finally, we show that attention across scales can\nprovide improved reconstruction results.", "AI": {"tldr": "A fast and accurate surface reconstruction algorithm for unorganized point clouds using an implicit representation, balancing speed and detail.", "motivation": "Address the trade-off between detail and speed in existing learning methods for 3D surface reconstruction.", "method": "Proposes a new implicit representation with lazy query, parallel multi-scale grid, and cross-scale attention.", "result": "Achieves faster reconstruction than baselines with minimal performance loss.", "conclusion": "The method offers the best accuracy-speed trade-off for 3D surface reconstruction."}}
{"id": "2506.08047", "pdf": "https://arxiv.org/pdf/2506.08047", "abs": "https://arxiv.org/abs/2506.08047", "authors": ["A. G. R. Sandeepa", "Sanka Mohottala"], "title": "Evaluation of Machine Learning Models in Student Academic Performance Prediction", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Paper Accepted for IEEE ICARC Conference (2025). 6 pages, 5 figures", "summary": "This research investigates the use of machine learning methods to forecast\nstudents' academic performance in a school setting. Students' data with\nbehavioral, academic, and demographic details were used in implementations with\nstandard classical machine learning models including multi-layer perceptron\nclassifier (MLPC). MLPC obtained 86.46% maximum accuracy for test set across\nall implementations. Under 10-fold cross validation, MLPC obtained 79.58%\naverage accuracy for test set while for train set, it was 99.65%. MLP's better\nperformance over other machine learning models strongly suggest the potential\nuse of neural networks as data-efficient models. Feature selection approach\nplayed a crucial role in improving the performance and multiple evaluation\napproaches were used in order to compare with existing literature. Explainable\nmachine learning methods were utilized to demystify the black box models and to\nvalidate the feature selection approach.", "AI": {"tldr": "Machine learning, particularly MLPC, effectively predicts student academic performance with high accuracy, outperforming other models. Feature selection and explainable methods enhance model performance and transparency.", "motivation": "To explore the potential of machine learning, especially neural networks, in forecasting student academic performance efficiently.", "method": "Used MLPC and other classical models on student data (behavioral, academic, demographic). Employed feature selection and explainable ML methods.", "result": "MLPC achieved 86.46% max accuracy (test set), 79.58% average under 10-fold CV, and 99.65% for train set.", "conclusion": "Neural networks like MLPC are data-efficient for academic performance prediction, with feature selection and explainability playing key roles."}}
{"id": "2506.08326", "pdf": "https://arxiv.org/pdf/2506.08326", "abs": "https://arxiv.org/abs/2506.08326", "authors": ["Xingbo Fu", "Zehong Wang", "Zihan Chen", "Jiazheng Li", "Yaochen Zhu", "Zhenyu Lei", "Cong Shen", "Yanfang Ye", "Chuxu Zhang", "Jundong Li"], "title": "Graph Prompting for Graph Learning Models: Recent Advances and Future Directions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by KDD 2025 Tutorial/Survey Track", "summary": "Graph learning models have demonstrated great prowess in learning expressive\nrepresentations from large-scale graph data in a wide variety of real-world\nscenarios. As a prevalent strategy for training powerful graph learning models,\nthe \"pre-training, adaptation\" scheme first pre-trains graph learning models on\nunlabeled graph data in a self-supervised manner and then adapts them to\nspecific downstream tasks. During the adaptation phase, graph prompting emerges\nas a promising approach that learns trainable prompts while keeping the\npre-trained graph learning models unchanged. In this paper, we present a\nsystematic review of recent advancements in graph prompting. First, we\nintroduce representative graph pre-training methods that serve as the\nfoundation step of graph prompting. Next, we review mainstream techniques in\ngraph prompting and elaborate on how they design learnable prompts for graph\nprompting. Furthermore, we summarize the real-world applications of graph\nprompting from different domains. Finally, we discuss several open challenges\nin existing studies with promising future directions in this field.", "AI": {"tldr": "A review of graph prompting, covering pre-training methods, prompting techniques, applications, and future challenges.", "motivation": "To systematically explore the advancements in graph prompting, a promising approach for adapting pre-trained graph learning models to downstream tasks.", "method": "Review of graph pre-training methods and analysis of how learnable prompts are designed in graph prompting.", "result": "Summarized real-world applications and identified open challenges in graph prompting.", "conclusion": "Graph prompting is a promising field with potential for further research and development."}}
{"id": "2506.08700", "pdf": "https://arxiv.org/pdf/2506.08700", "abs": "https://arxiv.org/abs/2506.08700", "authors": ["Ruiran Su", "Jiasheng Si", "Zhijiang Guo", "Janet B. Pierrehumbert"], "title": "ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification on Scientific Charts", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Scientific fact-checking has mostly focused on text and tables, overlooking\nscientific charts, which are key for presenting quantitative evidence and\nstatistical reasoning. We introduce ClimateViz, the first large-scale benchmark\nfor scientific fact-checking using expert-curated scientific charts. ClimateViz\ncontains 49,862 claims linked to 2,896 visualizations, each labeled as support,\nrefute, or not enough information. To improve interpretability, each example\nincludes structured knowledge graph explanations covering trends, comparisons,\nand causal relations. We evaluate state-of-the-art multimodal language models,\nincluding both proprietary and open-source systems, in zero-shot and few-shot\nsettings. Results show that current models struggle with chart-based reasoning:\neven the best systems, such as Gemini 2.5 and InternVL 2.5, reach only 76.2 to\n77.8 percent accuracy in label-only settings, far below human performance (89.3\nand 92.7 percent). Explanation-augmented outputs improve performance in some\nmodels. We released our dataset and code alongside the paper.", "AI": {"tldr": "ClimateViz introduces a benchmark for scientific fact-checking using charts, showing current models struggle with chart-based reasoning, lagging behind human performance.", "motivation": "Existing fact-checking overlooks scientific charts, which are crucial for quantitative evidence.", "method": "Created ClimateViz with 49,862 claims linked to 2,896 charts, labeled and explained via knowledge graphs. Evaluated multimodal models in zero-shot and few-shot settings.", "result": "Best models (Gemini 2.5, InternVL 2.5) achieved 76.2-77.8% accuracy, below human performance (89.3-92.7%). Explanation-augmented outputs helped some models.", "conclusion": "Current models are inadequate for chart-based reasoning; ClimateViz provides a valuable benchmark for future improvements."}}
{"id": "2506.08640", "pdf": "https://arxiv.org/pdf/2506.08640", "abs": "https://arxiv.org/abs/2506.08640", "authors": ["Yichong Lu", "Yuzhuo Tian", "Zijin Jiang", "Yikun Zhao", "Yuanbo Yang", "Hao Ouyang", "Haoji Hu", "Huimin Yu", "Yujun Shen", "Yiyi Liao"], "title": "Orientation Matters: Making 3D Generative Models Orientation-Aligned", "categories": ["cs.CV"], "comment": "Project Page: https://xdimlab.github.io/Orientation_Matters", "summary": "Humans intuitively perceive object shape and orientation from a single image,\nguided by strong priors about canonical poses. However, existing 3D generative\nmodels often produce misaligned results due to inconsistent training data,\nlimiting their usability in downstream tasks. To address this gap, we introduce\nthe task of orientation-aligned 3D object generation: producing 3D objects from\nsingle images with consistent orientations across categories. To facilitate\nthis, we construct Objaverse-OA, a dataset of 14,832 orientation-aligned 3D\nmodels spanning 1,008 categories. Leveraging Objaverse-OA, we fine-tune two\nrepresentative 3D generative models based on multi-view diffusion and 3D\nvariational autoencoder frameworks to produce aligned objects that generalize\nwell to unseen objects across various categories. Experimental results\ndemonstrate the superiority of our method over post-hoc alignment approaches.\nFurthermore, we showcase downstream applications enabled by our aligned object\ngeneration, including zero-shot object orientation estimation via\nanalysis-by-synthesis and efficient arrow-based object rotation manipulation.", "AI": {"tldr": "The paper introduces orientation-aligned 3D object generation from single images, addressing misalignment issues in existing models. It presents Objaverse-OA, a dataset for training, and fine-tunes models to improve alignment and generalization.", "motivation": "Existing 3D generative models produce misaligned results due to inconsistent training data, limiting usability in downstream tasks. The goal is to generate 3D objects with consistent orientations.", "method": "The authors construct Objaverse-OA, a dataset of 14,832 orientation-aligned 3D models. They fine-tune multi-view diffusion and 3D variational autoencoder models using this dataset.", "result": "The method outperforms post-hoc alignment approaches and generalizes well to unseen objects. Downstream applications like zero-shot orientation estimation and efficient object rotation are demonstrated.", "conclusion": "The proposed approach successfully addresses orientation misalignment in 3D object generation, enabling practical applications and outperforming existing methods."}}
{"id": "2506.08049", "pdf": "https://arxiv.org/pdf/2506.08049", "abs": "https://arxiv.org/abs/2506.08049", "authors": ["Tengfei Lyu", "Weijia Zhang", "Hao Liu"], "title": "Physics-Informed Teleconnection-Aware Transformer for Global Subseasonal-to-Seasonal Forecasting", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Subseasonal-to-seasonal (S2S) forecasting, which predicts climate conditions\nfrom several weeks to months in advance, presents significant challenges due to\nthe chaotic dynamics of atmospheric systems and complex interactions across\nmultiple scales. Current approaches often fail to explicitly model underlying\nphysical processes and teleconnections that are crucial at S2S timescales. We\nintroduce TelePiT, a novel deep learning architecture that enhances global S2S\nforecasting through integrated multi-scale physics and teleconnection\nawareness. Our approach consists of three key components: (1) Spherical\nHarmonic Embedding, which accurately encodes global atmospheric variables onto\nspherical geometry; (2) Multi-Scale Physics-Informed Neural ODE, which\nexplicitly captures atmospheric physical processes across multiple learnable\nfrequency bands; (3) Teleconnection-Aware Transformer, which models critical\nglobal climate interactions through tactfully injecting teleconnection patterns\ninto the self-attention. Extensive experiments demonstrate that TelePiT\nsignificantly outperforms state-of-the-art data-driven baselines and\noperational numerical weather prediction systems, with remarkable improvements\nfor atmospheric variables including a 57.7% reduction in RMSE for 2-meter\ntemperature compared to previous best models.", "AI": {"tldr": "TelePiT, a deep learning model, improves S2S forecasting by integrating multi-scale physics and teleconnection awareness, outperforming existing methods.", "motivation": "Current S2S forecasting struggles with chaotic dynamics and lacks explicit modeling of physical processes and teleconnections.", "method": "TelePiT uses Spherical Harmonic Embedding, Multi-Scale Physics-Informed Neural ODE, and Teleconnection-Aware Transformer to enhance forecasting.", "result": "TelePiT reduces RMSE for 2-meter temperature by 57.7% compared to prior models.", "conclusion": "TelePiT advances S2S forecasting by effectively modeling multi-scale physics and teleconnections."}}
{"id": "2506.08337", "pdf": "https://arxiv.org/pdf/2506.08337", "abs": "https://arxiv.org/abs/2506.08337", "authors": ["Juhyeok Choi", "Chenglin Fan"], "title": "A Simple Analysis of Discretization Error in Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Diffusion models, formulated as discretizations of stochastic differential\nequations (SDEs), achieve state-of-the-art generative performance. However,\nexisting analyses of their discretization error often rely on complex\nprobabilistic tools. In this work, we present a simplified theoretical\nframework for analyzing the Euler--Maruyama discretization of\nvariance-preserving SDEs (VP-SDEs) in Denoising Diffusion Probabilistic Models\n(DDPMs), where $ T $ denotes the number of denoising steps in the diffusion\nprocess. Our approach leverages Gr\\\"onwall's inequality to derive a convergence\nrate of $ \\mathcal{O}(1/T^{1/2}) $ under Lipschitz assumptions, significantly\nstreamlining prior proofs. Furthermore, we demonstrate that the Gaussian noise\nin the discretization can be replaced by a discrete random variable (e.g.,\nRademacher or uniform noise) without sacrificing convergence guarantees-an\ninsight with practical implications for efficient sampling. Experiments\nvalidate our theory, showing that (1) the error scales as predicted, (2)\ndiscrete noise achieves comparable sample quality to Gaussian noise, and (3)\nincorrect noise scaling degrades performance. By unifying simplified analysis\nand discrete noise substitution, our work bridges theoretical rigor with\npractical efficiency in diffusion-based generative modeling.", "AI": {"tldr": "A simplified theoretical framework for analyzing Euler-Maruyama discretization in DDPMs, showing convergence rate of O(1/T^(1/2)) and validating discrete noise substitution.", "motivation": "Existing analyses of diffusion models' discretization error rely on complex tools, prompting a need for a simplified approach.", "method": "Uses Gr\u00f6nwall's inequality to derive convergence rates and explores replacing Gaussian noise with discrete random variables.", "result": "Achieves O(1/T^(1/2)) convergence, validates discrete noise substitution, and shows incorrect scaling degrades performance.", "conclusion": "Bridges theoretical rigor with practical efficiency in diffusion models, offering insights for efficient sampling."}}
{"id": "2506.08712", "pdf": "https://arxiv.org/pdf/2506.08712", "abs": "https://arxiv.org/abs/2506.08712", "authors": ["Hee Suk Yoon", "Eunseop Yoon", "Mark A. Hasegawa-Johnson", "Sungwoong Kim", "Chang D. Yoo"], "title": "ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Large Language Model Preference Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "We introduce ConfPO, a method for preference learning in Large Language\nModels (LLMs) that identifies and optimizes preference-critical tokens based\nsolely on the training policy's confidence, without requiring any auxiliary\nmodels or compute. Unlike prior Direct Alignment Algorithms (DAAs) such as\nDirect Preference Optimization (DPO), which uniformly adjust all token\nprobabilities regardless of their relevance to preference, ConfPO focuses\noptimization on the most impactful tokens. This targeted approach improves\nalignment quality while mitigating overoptimization (i.e., reward hacking) by\nusing the KL divergence budget more efficiently. In contrast to recent\ntoken-level methods that rely on credit-assignment models or AI annotators,\nraising concerns about scalability and reliability, ConfPO is simple,\nlightweight, and model-free. Experimental results on challenging alignment\nbenchmarks, including AlpacaEval 2 and Arena-Hard, demonstrate that ConfPO\nconsistently outperforms uniform DAAs across various LLMs, delivering better\nalignment with zero additional computational overhead.", "AI": {"tldr": "ConfPO is a lightweight, model-free method for preference learning in LLMs that optimizes preference-critical tokens based on training policy confidence, outperforming uniform methods like DPO.", "motivation": "Prior methods like DPO adjust all tokens uniformly, leading to inefficiency and overoptimization. ConfPO aims to improve alignment by focusing on impactful tokens without auxiliary models.", "method": "ConfPO identifies and optimizes preference-critical tokens using the training policy's confidence, avoiding reliance on external models or compute.", "result": "ConfPO outperforms uniform DAAs on benchmarks like AlpacaEval 2 and Arena-Hard, achieving better alignment with no extra computational cost.", "conclusion": "ConfPO offers a simple, efficient alternative to uniform alignment methods, enhancing performance without additional overhead."}}
{"id": "2506.08649", "pdf": "https://arxiv.org/pdf/2506.08649", "abs": "https://arxiv.org/abs/2506.08649", "authors": ["Zhiyi Zhu", "Xiaoyu Wu", "Youwei Lu"], "title": "Enhancing Video Memorability Prediction with Text-Motion Cross-modal Contrastive Loss and Its Application in Video Summarization", "categories": ["cs.CV"], "comment": null, "summary": "Video memorability refers to the ability of videos to be recalled after\nviewing, playing a crucial role in creating content that remains memorable.\nExisting models typically focus on extracting multimodal features to predict\nvideo memorability scores but often fail to fully utilize motion cues. The\nrepresentation of motion features is compromised during the fine-tuning phase\nof the motion feature extractor due to a lack of labeled data. In this paper,\nwe introduce the Text-Motion Cross-modal Contrastive Loss (TMCCL), a multimodal\nvideo memorability prediction model designed to enhance the representation of\nmotion features. We tackle the challenge of improving motion feature\nrepresentation by leveraging text description similarities across videos to\nestablish positive and negative motion sample sets for a given target. This\nenhancement allows the model to learn similar feature representations for\nsemantically related motion content, resulting in more accurate memorability\npredictions. Our model achieves state-of-the-art performance on two video\nmemorability prediction datasets. Moreover, the potential applications of video\nmemorability prediction have been underexplored. To address this gap, we\npresent Memorability Weighted Correction for Video Summarization (MWCVS), using\nvideo memorability prediction to reduce subjectivity in video summarization\nlabels. Experimental results on two video summarization datasets demonstrate\nthe effectiveness of MWCVS, showcasing the promising applications of video\nmemorability prediction.", "AI": {"tldr": "The paper introduces TMCCL to improve motion feature representation for video memorability prediction and MWCVS to apply memorability in video summarization, achieving state-of-the-art results.", "motivation": "Existing models underutilize motion cues due to limited labeled data, compromising memorability prediction accuracy.", "method": "Proposes TMCCL, leveraging text-motion contrastive learning, and MWCVS for video summarization using memorability scores.", "result": "TMCCL achieves top performance on memorability datasets; MWCVS reduces subjectivity in summarization labels.", "conclusion": "The work advances video memorability prediction and demonstrates its practical application in summarization."}}
{"id": "2506.08059", "pdf": "https://arxiv.org/pdf/2506.08059", "abs": "https://arxiv.org/abs/2506.08059", "authors": ["Huong Van Le", "Weibin Ren", "Junhong Kim", "Yukyung Yun", "Young Bin Park", "Young Jun Kim", "Bok Kyung Han", "Inho Choi", "Jong IL Park", "Hwi-Yeol Yun", "Jae-Mun Choi"], "title": "CaliciBoost: Performance-Driven Evaluation of Molecular Representations for Caco-2 Permeability Prediction", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "49 pages, 11 figures", "summary": "Caco-2 permeability serves as a critical in vitro indicator for predicting\nthe oral absorption of drug candidates during early-stage drug discovery. To\nenhance the accuracy and efficiency of computational predictions, we\nsystematically investigated the impact of eight molecular feature\nrepresentation types including 2D/3D descriptors, structural fingerprints, and\ndeep learning-based embeddings combined with automated machine learning\ntechniques to predict Caco-2 permeability. Using two datasets of differing\nscale and diversity (TDC benchmark and curated OCHEM data), we assessed model\nperformance across representations and identified PaDEL, Mordred, and RDKit\ndescriptors as particularly effective for Caco-2 prediction. Notably, the\nAutoML-based model CaliciBoost achieved the best MAE performance. Furthermore,\nfor both PaDEL and Mordred representations, the incorporation of 3D descriptors\nresulted in a 15.73% reduction in MAE compared to using 2D features alone, as\nconfirmed by feature importance analysis. These findings highlight the\neffectiveness of AutoML approaches in ADMET modeling and offer practical\nguidance for feature selection in data-limited prediction tasks.", "AI": {"tldr": "The paper explores using AutoML and various molecular feature representations to predict Caco-2 permeability, identifying top-performing descriptors and demonstrating the value of 3D features.", "motivation": "Improving the accuracy and efficiency of computational predictions for Caco-2 permeability in early-stage drug discovery.", "method": "Systematic investigation of eight molecular feature representations (2D/3D descriptors, fingerprints, deep learning embeddings) combined with AutoML, tested on two datasets.", "result": "PaDEL, Mordred, and RDKit descriptors were most effective; AutoML model CaliciBoost achieved the best MAE. 3D descriptors reduced MAE by 15.73% compared to 2D.", "conclusion": "AutoML is effective for ADMET modeling, and 3D descriptors enhance predictions, providing practical guidance for feature selection in data-limited tasks."}}
{"id": "2506.08340", "pdf": "https://arxiv.org/pdf/2506.08340", "abs": "https://arxiv.org/abs/2506.08340", "authors": ["Emo Todorov"], "title": "Dynamical System Optimization", "categories": ["cs.LG"], "comment": null, "summary": "We develop an optimization framework centered around a core idea: once a\n(parametric) policy is specified, control authority is transferred to the\npolicy, resulting in an autonomous dynamical system. Thus we should be able to\noptimize policy parameters without further reference to controls or actions,\nand without directly using the machinery of approximate Dynamic Programming and\nReinforcement Learning. Here we derive simpler algorithms at the autonomous\nsystem level, and show that they compute the same quantities as policy\ngradients and Hessians, natural gradients, proximal methods. Analogs to\napproximate policy iteration and off-policy learning are also available. Since\npolicy parameters and other system parameters are treated uniformly, the same\nalgorithms apply to behavioral cloning, mechanism design, system\nidentification, learning of state estimators. Tuning of generative AI models is\nnot only possible, but is conceptually closer to the present framework than to\nReinforcement Learning.", "AI": {"tldr": "The paper introduces an optimization framework where policy parameters are optimized autonomously, bypassing traditional control or reinforcement learning methods.", "motivation": "To simplify policy optimization by treating it as an autonomous system, avoiding complex control or reinforcement learning machinery.", "method": "Derives algorithms at the autonomous system level, showing equivalence to policy gradients, Hessians, natural gradients, and proximal methods.", "result": "Demonstrates that the framework computes the same quantities as traditional methods and extends to behavioral cloning, system identification, and generative AI tuning.", "conclusion": "The framework unifies policy and system parameter optimization, offering a simpler and broader alternative to reinforcement learning."}}
{"id": "2506.08713", "pdf": "https://arxiv.org/pdf/2506.08713", "abs": "https://arxiv.org/abs/2506.08713", "authors": ["Fariz Ikhwantri", "Dusica Marijan"], "title": "Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure", "categories": ["cs.CL", "cs.SE"], "comment": null, "summary": "Ensuring complex systems meet regulations typically requires checking the\nvalidity of assurance cases through a claim-argument-evidence framework. Some\nchallenges in this process include the complicated nature of legal and\ntechnical texts, the need for model explanations, and limited access to\nassurance case data. We propose a compliance detection approach based on\nNatural Language Inference (NLI): EXplainable CompLiance detection with\nArgumentative Inference of Multi-hop reasoning (EXCLAIM). We formulate the\nclaim-argument-evidence structure of an assurance case as a multi-hop inference\nfor explainable and traceable compliance detection. We address the limited\nnumber of assurance cases by generating them using large language models\n(LLMs). We introduce metrics that measure the coverage and structural\nconsistency. We demonstrate the effectiveness of the generated assurance case\nfrom GDPR requirements in a multi-hop inference task as a case study. Our\nresults highlight the potential of NLI-based approaches in automating the\nregulatory compliance process.", "AI": {"tldr": "The paper proposes EXCLAIM, an NLI-based method for explainable compliance detection in assurance cases, addressing challenges like complex texts and data scarcity by using LLMs for case generation and multi-hop reasoning.", "motivation": "Challenges in regulatory compliance include complex legal/technical texts, lack of model explanations, and limited assurance case data.", "method": "EXCLAIM uses NLI for multi-hop reasoning in assurance cases, generates cases with LLMs, and introduces coverage/consistency metrics.", "result": "Demonstrated effectiveness with GDPR requirements, showing NLI's potential in automating compliance.", "conclusion": "NLI-based approaches like EXCLAIM can automate and improve regulatory compliance processes."}}
{"id": "2506.08650", "pdf": "https://arxiv.org/pdf/2506.08650", "abs": "https://arxiv.org/abs/2506.08650", "authors": ["Peter Gr\u00f6nquist", "Stepan Tulyakov", "Dengxin Dai"], "title": "Beyond Calibration: Physically Informed Learning for Raw-to-Raw Mapping", "categories": ["cs.CV"], "comment": null, "summary": "Achieving consistent color reproduction across multiple cameras is essential\nfor seamless image fusion and Image Processing Pipeline (ISP) compatibility in\nmodern devices, but it is a challenging task due to variations in sensors and\noptics. Existing raw-to-raw conversion methods face limitations such as poor\nadaptability to changing illumination, high computational costs, or impractical\nrequirements such as simultaneous camera operation and overlapping\nfields-of-view. We introduce the Neural Physical Model (NPM), a lightweight,\nphysically-informed approach that simulates raw images under specified\nillumination to estimate transformations between devices. The NPM effectively\nadapts to varying illumination conditions, can be initialized with physical\nmeasurements, and supports training with or without paired data. Experiments on\npublic datasets like NUS and BeyondRGB demonstrate that NPM outperforms recent\nstate-of-the-art methods, providing robust chromatic consistency across\ndifferent sensors and optical systems.", "AI": {"tldr": "The paper introduces the Neural Physical Model (NPM) for consistent color reproduction across cameras, outperforming existing methods in adaptability and performance.", "motivation": "Ensuring color consistency across cameras is challenging due to sensor and optic variations, and existing methods have limitations like poor adaptability or high computational costs.", "method": "The proposed Neural Physical Model (NPM) simulates raw images under specified illumination to estimate transformations between devices, supporting training with or without paired data.", "result": "NPM outperforms state-of-the-art methods on datasets like NUS and BeyondRGB, achieving robust chromatic consistency.", "conclusion": "NPM is a lightweight, adaptable solution for color consistency, suitable for diverse illumination and sensor conditions."}}
{"id": "2506.08066", "pdf": "https://arxiv.org/pdf/2506.08066", "abs": "https://arxiv.org/abs/2506.08066", "authors": ["Alexander Stepikin", "Evgenia Romanenkova", "Alexey Zaytsev"], "title": "WWAggr: A Window Wasserstein-based Aggregation for Ensemble Change Point Detection", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Change Point Detection (CPD) aims to identify moments of abrupt distribution\nshifts in data streams. Real-world high-dimensional CPD remains challenging due\nto data pattern complexity and violation of common assumptions. Resorting to\nstandalone deep neural networks, the current state-of-the-art detectors have\nyet to achieve perfect quality. Concurrently, ensembling provides more robust\nsolutions, boosting the performance. In this paper, we investigate ensembles of\ndeep change point detectors and realize that standard prediction aggregation\ntechniques, e.g., averaging, are suboptimal and fail to account for problem\npeculiarities. Alternatively, we introduce WWAggr -- a novel task-specific\nmethod of ensemble aggregation based on the Wasserstein distance. Our procedure\nis versatile, working effectively with various ensembles of deep CPD models.\nMoreover, unlike existing solutions, we practically lift a long-standing\nproblem of the decision threshold selection for CPD.", "AI": {"tldr": "The paper introduces WWAggr, a novel ensemble aggregation method for change point detection (CPD) using Wasserstein distance, addressing suboptimal standard techniques and threshold selection challenges.", "motivation": "Real-world high-dimensional CPD is complex, and current deep neural network detectors lack perfect quality. Ensembling improves robustness, but standard aggregation methods are suboptimal.", "method": "Proposes WWAggr, a task-specific ensemble aggregation method based on Wasserstein distance, compatible with various deep CPD models.", "result": "WWAggr effectively aggregates ensembles and addresses the threshold selection problem in CPD.", "conclusion": "WWAggr offers a versatile and practical solution for improving ensemble-based CPD performance."}}
{"id": "2506.08347", "pdf": "https://arxiv.org/pdf/2506.08347", "abs": "https://arxiv.org/abs/2506.08347", "authors": ["Yinan Huang", "Haoteng Ying", "Eli Chien", "Rongzhe Wei", "Pan Li"], "title": "Differentially Private Relational Learning with Entity-level Privacy Guarantees", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Learning with relational and network-structured data is increasingly vital in\nsensitive domains where protecting the privacy of individual entities is\nparamount. Differential Privacy (DP) offers a principled approach for\nquantifying privacy risks, with DP-SGD emerging as a standard mechanism for\nprivate model training. However, directly applying DP-SGD to relational\nlearning is challenging due to two key factors: (i) entities often participate\nin multiple relations, resulting in high and difficult-to-control sensitivity;\nand (ii) relational learning typically involves multi-stage, potentially\ncoupled (interdependent) sampling procedures that make standard privacy\namplification analyses inapplicable. This work presents a principled framework\nfor relational learning with formal entity-level DP guarantees. We provide a\nrigorous sensitivity analysis and introduce an adaptive gradient clipping\nscheme that modulates clipping thresholds based on entity occurrence frequency.\nWe also extend the privacy amplification results to a tractable subclass of\ncoupled sampling, where the dependence arises only through sample sizes. These\ncontributions lead to a tailored DP-SGD variant for relational data with\nprovable privacy guarantees. Experiments on fine-tuning text encoders over\ntext-attributed network-structured relational data demonstrate the strong\nutility-privacy trade-offs of our approach. Our code is available at\nhttps://github.com/Graph-COM/Node_DP.", "AI": {"tldr": "A framework for relational learning with formal entity-level differential privacy guarantees, addressing challenges in sensitivity and privacy amplification for DP-SGD.", "motivation": "Protecting privacy in relational and network-structured data is critical, but applying DP-SGD directly is challenging due to high sensitivity and interdependent sampling.", "method": "Proposes an adaptive gradient clipping scheme and extends privacy amplification to coupled sampling, resulting in a tailored DP-SGD variant.", "result": "Demonstrates strong utility-privacy trade-offs in experiments on text-attributed network data.", "conclusion": "The framework effectively addresses relational learning challenges with provable privacy guarantees."}}
{"id": "2506.08726", "pdf": "https://arxiv.org/pdf/2506.08726", "abs": "https://arxiv.org/abs/2506.08726", "authors": ["Nelvin Tan", "Zian Seng", "Liang Zhang", "Yu-Ching Shih", "Dong Yang", "Amol Salunkhe"], "title": "Improved LLM Agents for Financial Document Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 5 figures", "summary": "Large language models (LLMs) have shown impressive capabilities on numerous\nnatural language processing tasks. However, LLMs still struggle with numerical\nquestion answering for financial documents that include tabular and textual\ndata. Recent works have showed the effectiveness of critic agents (i.e.,\nself-correction) for this task given oracle labels. Building upon this\nframework, this paper examines the effectiveness of the traditional critic\nagent when oracle labels are not available, and show, through experiments, that\nthis critic agent's performance deteriorates in this scenario. With this in\nmind, we present an improved critic agent, along with the calculator agent\nwhich outperforms the previous state-of-the-art approach (program-of-thought)\nand is safer. Furthermore, we investigate how our agents interact with each\nother, and how this interaction affects their performance.", "AI": {"tldr": "The paper explores the limitations of traditional critic agents in numerical QA for financial documents without oracle labels and introduces an improved critic agent and calculator agent, which outperform prior methods.", "motivation": "LLMs struggle with numerical QA in financial documents, especially without oracle labels, prompting the need for better self-correction methods.", "method": "The study evaluates traditional critic agents without oracle labels, proposes an improved critic agent, and introduces a calculator agent, analyzing their interactions.", "result": "The improved critic agent and calculator agent outperform the state-of-the-art (program-of-thought) and are safer.", "conclusion": "The new agents enhance performance in numerical QA for financial documents, highlighting the importance of agent interaction."}}
{"id": "2506.08666", "pdf": "https://arxiv.org/pdf/2506.08666", "abs": "https://arxiv.org/abs/2506.08666", "authors": ["Wenzhuo Liu", "Fei Zhu", "Haiyang Guo", "Longhui Wei", "Cheng-Lin Liu"], "title": "LLaVA-c: Continual Improved Visual Instruction Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal models like LLaVA-1.5 achieve state-of-the-art visual\nunderstanding through visual instruction tuning on multitask datasets, enabling\nstrong instruction-following and multimodal performance. However, multitask\nlearning faces challenges such as task balancing, requiring careful adjustment\nof data proportions, and expansion costs, where new tasks risk catastrophic\nforgetting and need costly retraining. Continual learning provides a promising\nalternative to acquiring new knowledge incrementally while preserving existing\ncapabilities. However, current methods prioritize task-specific performance,\nneglecting base model degradation from overfitting to specific instructions,\nwhich undermines general capabilities. In this work, we propose a simple but\neffective method with two modifications on LLaVA-1.5: spectral-aware\nconsolidation for improved task balance and unsupervised inquiry regularization\nto prevent base model degradation. We evaluate both general and task-specific\nperformance across continual pretraining and fine-tuning. Experiments\ndemonstrate that LLaVA-c consistently enhances standard benchmark performance\nand preserves general capabilities. For the first time, we show that\ntask-by-task continual learning can achieve results that match or surpass\nmultitask joint learning. The code will be publicly released.", "AI": {"tldr": "LLaVA-c improves continual learning for multimodal models by addressing task balancing and base model degradation, matching or surpassing multitask learning performance.", "motivation": "Multitask learning faces challenges like task balancing and expansion costs, while continual learning often neglects general capabilities.", "method": "Proposes spectral-aware consolidation for task balance and unsupervised inquiry regularization to prevent base model degradation.", "result": "LLaVA-c enhances benchmark performance and preserves general capabilities, matching or surpassing multitask joint learning.", "conclusion": "Continual learning can be as effective as multitask learning with the right modifications."}}
{"id": "2506.08073", "pdf": "https://arxiv.org/pdf/2506.08073", "abs": "https://arxiv.org/abs/2506.08073", "authors": ["Yu Liu", "Utkarsh Pratiush", "Kamyar Barakati", "Hiroshi Funakubo", "Ching-Che Lin", "Jaegyu Kim", "Lane W. Martin", "Sergei V. Kalinin"], "title": "Domain Switching on the Pareto Front: Multi-Objective Deep Kernel Learning in Automated Piezoresponse Force Microscopy", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cs.AI", "cs.LG"], "comment": null, "summary": "Ferroelectric polarization switching underpins the functional performance of\na wide range of materials and devices, yet its dependence on complex local\nmicrostructural features renders systematic exploration by manual or grid-based\nspectroscopic measurements impractical. Here, we introduce a multi-objective\nkernel-learning workflow that infers the microstructural rules governing\nswitching behavior directly from high-resolution imaging data. Applied to\nautomated piezoresponse force microscopy (PFM) experiments, our framework\nefficiently identifies the key relationships between domain-wall configurations\nand local switching kinetics, revealing how specific wall geometries and defect\ndistributions modulate polarization reversal. Post-experiment analysis projects\nabstract reward functions, such as switching ease and domain symmetry, onto\nphysically interpretable descriptors including domain configuration and\nproximity to boundaries. This enables not only high-throughput active learning,\nbut also mechanistic insight into the microstructural control of switching\nphenomena. While demonstrated for ferroelectric domain switching, our approach\nprovides a powerful, generalizable tool for navigating complex,\nnon-differentiable design spaces, from structure-property correlations in\nmolecular discovery to combinatorial optimization across diverse imaging\nmodalities.", "AI": {"tldr": "A multi-objective kernel-learning workflow is introduced to analyze ferroelectric polarization switching, revealing microstructural rules from imaging data.", "motivation": "Understanding the dependence of ferroelectric polarization switching on complex local microstructural features is challenging with manual or grid-based methods.", "method": "A multi-objective kernel-learning workflow is applied to automated piezoresponse force microscopy (PFM) experiments to infer microstructural rules.", "result": "The framework identifies relationships between domain-wall configurations and switching kinetics, revealing how wall geometries and defects modulate polarization reversal.", "conclusion": "The approach provides a generalizable tool for analyzing complex design spaces, applicable beyond ferroelectric switching to other domains like molecular discovery."}}
{"id": "2506.08353", "pdf": "https://arxiv.org/pdf/2506.08353", "abs": "https://arxiv.org/abs/2506.08353", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "An Adaptive Method Stabilizing Activations for Enhanced Generalization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We introduce AdaAct, a novel optimization algorithm that adjusts learning\nrates according to activation variance. Our method enhances the stability of\nneuron outputs by incorporating neuron-wise adaptivity during the training\nprocess, which subsequently leads to better generalization -- a complementary\napproach to conventional activation regularization methods. Experimental\nresults demonstrate AdaAct's competitive performance across standard image\nclassification benchmarks. We evaluate AdaAct on CIFAR and ImageNet, comparing\nit with other state-of-the-art methods. Importantly, AdaAct effectively bridges\nthe gap between the convergence speed of Adam and the strong generalization\ncapabilities of SGD, all while maintaining competitive execution times. Code is\navailable at https://github.com/hseung88/adaact.", "AI": {"tldr": "AdaAct is an optimization algorithm that adjusts learning rates based on activation variance, improving stability and generalization in neural networks.", "motivation": "To enhance neuron output stability and generalization by incorporating neuron-wise adaptivity, bridging the gap between Adam's convergence speed and SGD's generalization.", "method": "AdaAct adjusts learning rates according to activation variance during training, complementing conventional activation regularization.", "result": "Competitive performance on CIFAR and ImageNet benchmarks, bridging Adam's speed and SGD's generalization while maintaining efficiency.", "conclusion": "AdaAct effectively balances convergence speed and generalization, offering a practical alternative to existing methods."}}
{"id": "2506.08738", "pdf": "https://arxiv.org/pdf/2506.08738", "abs": "https://arxiv.org/abs/2506.08738", "authors": ["Dror Kris Markus", "Fabrizio Gilardi", "Daria Stetsenko"], "title": "Societal AI Research Has Become Less Interdisciplinary", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "As artificial intelligence (AI) systems become deeply embedded in everyday\nlife, calls to align AI development with ethical and societal values have\nintensified. Interdisciplinary collaboration is often championed as a key\npathway for fostering such engagement. Yet it remains unclear whether\ninterdisciplinary research teams are actually leading this shift in practice.\nThis study analyzes over 100,000 AI-related papers published on ArXiv between\n2014 and 2024 to examine how ethical values and societal concerns are\nintegrated into technical AI research. We develop a classifier to identify\nsocietal content and measure the extent to which research papers express these\nconsiderations. We find a striking shift: while interdisciplinary teams remain\nmore likely to produce societally-oriented research, computer science-only\nteams now account for a growing share of the field's overall societal output.\nThese teams are increasingly integrating societal concerns into their papers\nand tackling a wide range of domains - from fairness and safety to healthcare\nand misinformation. These findings challenge common assumptions about the\ndrivers of societal AI and raise important questions. First, what are the\nimplications for emerging understandings of AI safety and governance if most\nsocietally-oriented research is being undertaken by exclusively technical\nteams? Second, for scholars in the social sciences and humanities: in a\ntechnical field increasingly responsive to societal demands, what distinctive\nperspectives can we still offer to help shape the future of AI?", "AI": {"tldr": "The study analyzes AI papers to assess societal and ethical integration, finding technical teams increasingly address societal concerns, challenging assumptions about interdisciplinary roles.", "motivation": "To understand how ethical and societal values are integrated into AI research and whether interdisciplinary teams drive this shift.", "method": "Analyzed 100,000+ AI papers on ArXiv (2014-2024), developed a classifier to identify societal content, and measured its prevalence.", "result": "Interdisciplinary teams still lead in societal research, but computer science-only teams are growing in societal output, addressing fairness, safety, healthcare, and misinformation.", "conclusion": "Findings challenge assumptions about interdisciplinary drivers of societal AI, raising questions about AI governance and the role of non-technical fields."}}
{"id": "2506.08678", "pdf": "https://arxiv.org/pdf/2506.08678", "abs": "https://arxiv.org/abs/2506.08678", "authors": ["Juan Yeo", "Soonwoo Cha", "Jiwoo Song", "Hyunbin Jin", "Taesup Kim"], "title": "ATAS: Any-to-Any Self-Distillation for Enhanced Open-Vocabulary Dense Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models such as CLIP have recently propelled open-vocabulary\ndense prediction tasks by enabling recognition of a broad range of visual\nconcepts. However, CLIP still struggles with fine-grained, region-level\nunderstanding, hindering its effectiveness on these dense prediction tasks. We\nidentify two pivotal factors required to address this limitation: semantic\ncoherence and fine-grained vision-language alignment. Current adaptation\nmethods often improve fine-grained alignment at the expense of semantic\ncoherence, and often rely on extra modules or supervised fine-tuning. To\novercome these issues, we propose Any-to-Any Self-Distillation (ATAS), a novel\napproach that simultaneously enhances semantic coherence and fine-grained\nalignment by leveraging own knowledge of a model across all representation\nlevels. Unlike prior methods, ATAS uses only unlabeled images and an internal\nself-distillation process to refine representations of CLIP vision encoders,\npreserving local semantic consistency while sharpening local detail\nrecognition. On open-vocabulary object detection and semantic segmentation\nbenchmarks, ATAS achieves substantial performance gains, outperforming baseline\nCLIP models. These results validate the effectiveness of our approach and\nunderscore the importance of jointly maintaining semantic coherence and\nfine-grained alignment for advanced open-vocabulary dense prediction.", "AI": {"tldr": "ATAS improves CLIP's fine-grained vision-language alignment and semantic coherence via self-distillation, outperforming baselines in dense prediction tasks.", "motivation": "CLIP struggles with fine-grained, region-level understanding, limiting its effectiveness in dense prediction tasks.", "method": "Proposes Any-to-Any Self-Distillation (ATAS), leveraging unlabeled images and internal self-distillation to refine CLIP's vision encoders.", "result": "ATAS achieves significant performance gains in open-vocabulary object detection and semantic segmentation.", "conclusion": "Jointly maintaining semantic coherence and fine-grained alignment is crucial for advanced open-vocabulary dense prediction."}}
{"id": "2506.08074", "pdf": "https://arxiv.org/pdf/2506.08074", "abs": "https://arxiv.org/abs/2506.08074", "authors": ["Abdellah Ghassel", "Ian Robinson", "Gabriel Tanase", "Hal Cooper", "Bryan Thompson", "Zhen Han", "Vassilis N. Ioannidis", "Soji Adeshina", "Huzefa Rangwala"], "title": "Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "KDD '25", "summary": "Retrieval-Augmented Generation (RAG) grounds large language models in\nexternal evidence, yet it still falters when answers must be pieced together\nacross semantically distant documents. We close this gap with the Hierarchical\nLexical Graph (HLG), a three-tier index that (i) traces every atomic\nproposition to its source, (ii) clusters propositions into latent topics, and\n(iii) links entities and relations to expose cross-document paths. On top of\nHLG we build two complementary, plug-and-play retrievers: StatementGraphRAG,\nwhich performs fine-grained entity-aware beam search over propositions for\nhigh-precision factoid questions, and TopicGraphRAG, which selects coarse\ntopics before expanding along entity links to supply broad yet relevant context\nfor exploratory queries. Additionally, existing benchmarks lack the complexity\nrequired to rigorously evaluate multi-hop summarization systems, often focusing\non single-document queries or limited datasets. To address this, we introduce a\nsynthetic dataset generation pipeline that curates realistic, multi-document\nquestion-answer pairs, enabling robust evaluation of multi-hop retrieval\nsystems. Extensive experiments across five datasets demonstrate that our\nmethods outperform naive chunk-based RAG achieving an average relative\nimprovement of 23.1% in retrieval recall and correctness. Open-source Python\nlibrary is available at https://github.com/awslabs/graphrag-toolkit.", "AI": {"tldr": "The paper introduces Hierarchical Lexical Graph (HLG) to improve Retrieval-Augmented Generation (RAG) by addressing gaps in piecing together answers from semantically distant documents. It includes two retrievers, StatementGraphRAG and TopicGraphRAG, and a synthetic dataset for robust evaluation. Results show a 23.1% improvement over naive RAG.", "motivation": "Current RAG systems struggle with multi-hop retrieval across distant documents, limiting their effectiveness in complex queries.", "method": "Proposes HLG, a three-tier index, and two retrievers (StatementGraphRAG and TopicGraphRAG). Introduces a synthetic dataset pipeline for evaluation.", "result": "Outperforms naive RAG with a 23.1% improvement in retrieval recall and correctness across five datasets.", "conclusion": "HLG and the proposed retrievers effectively address multi-hop retrieval challenges, validated by synthetic and real-world datasets."}}
{"id": "2506.08360", "pdf": "https://arxiv.org/pdf/2506.08360", "abs": "https://arxiv.org/abs/2506.08360", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "NysAct: A Scalable Preconditioned Gradient Descent using Nystrom Approximation", "categories": ["cs.LG"], "comment": null, "summary": "Adaptive gradient methods are computationally efficient and converge quickly,\nbut they often suffer from poor generalization. In contrast, second-order\nmethods enhance convergence and generalization but typically incur high\ncomputational and memory costs. In this work, we introduce NysAct, a scalable\nfirst-order gradient preconditioning method that strikes a balance between\nstate-of-the-art first-order and second-order optimization methods. NysAct\nleverages an eigenvalue-shifted Nystrom method to approximate the activation\ncovariance matrix, which is used as a preconditioning matrix, significantly\nreducing time and memory complexities with minimal impact on test accuracy. Our\nexperiments show that NysAct not only achieves improved test accuracy compared\nto both first-order and second-order methods but also demands considerably less\ncomputational resources than existing second-order methods. Code is available\nat https://github.com/hseung88/nysact.", "AI": {"tldr": "NysAct is a scalable first-order gradient preconditioning method that balances efficiency and generalization, outperforming both first-order and second-order methods in test accuracy while using fewer resources.", "motivation": "Address the trade-off between computational efficiency (first-order methods) and generalization (second-order methods) in optimization.", "method": "Uses an eigenvalue-shifted Nystrom method to approximate the activation covariance matrix for preconditioning, reducing time and memory costs.", "result": "NysAct achieves better test accuracy than first-order and second-order methods with lower computational demands.", "conclusion": "NysAct effectively bridges the gap between first-order and second-order methods, offering a practical and efficient solution."}}
{"id": "2506.08746", "pdf": "https://arxiv.org/pdf/2506.08746", "abs": "https://arxiv.org/abs/2506.08746", "authors": ["Muhammad Anwar", "Mishca de Costa", "Issam Hammad", "Daniel Lau"], "title": "Towards Secure and Private Language Models for Nuclear Power Plants", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper introduces a domain-specific Large Language Model for nuclear\napplications, built from the publicly accessible Essential CANDU textbook.\nDrawing on a compact Transformer-based architecture, the model is trained on a\nsingle GPU to protect the sensitive data inherent in nuclear operations.\nDespite relying on a relatively small dataset, it shows encouraging signs of\ncapturing specialized nuclear vocabulary, though the generated text sometimes\nlacks syntactic coherence. By focusing exclusively on nuclear content, this\napproach demonstrates the feasibility of in-house LLM solutions that align with\nrigorous cybersecurity and data confidentiality standards. Early successes in\ntext generation underscore the model's utility for specialized tasks, while\nalso revealing the need for richer corpora, more sophisticated preprocessing,\nand instruction fine-tuning to enhance domain accuracy. Future directions\ninclude extending the dataset to cover diverse nuclear subtopics, refining\ntokenization to reduce noise, and systematically evaluating the model's\nreadiness for real-world applications in nuclear domain.", "AI": {"tldr": "A domain-specific LLM for nuclear applications is developed using a compact Transformer, trained on a single GPU for data security. It captures nuclear vocabulary but lacks syntactic coherence. Future work includes dataset expansion and refinement.", "motivation": "To create a secure, in-house LLM for nuclear applications that adheres to cybersecurity and confidentiality standards.", "method": "Uses a compact Transformer-based architecture trained on a single GPU with data from the Essential CANDU textbook.", "result": "The model captures specialized nuclear vocabulary but sometimes lacks syntactic coherence. Early text generation shows promise.", "conclusion": "The approach is feasible but requires richer corpora, better preprocessing, and fine-tuning for real-world nuclear applications."}}
{"id": "2506.08690", "pdf": "https://arxiv.org/pdf/2506.08690", "abs": "https://arxiv.org/abs/2506.08690", "authors": ["Hugo Porta", "Emanuele Dalsasso", "Jessica L. McCarty", "Devis Tuia"], "title": "CanadaFireSat: Toward high-resolution wildfire forecasting with multiple modalities", "categories": ["cs.CV"], "comment": "34 pages, 11 figures", "summary": "Canada experienced in 2023 one of the most severe wildfire seasons in recent\nhistory, causing damage across ecosystems, destroying communities, and emitting\nlarge quantities of CO2. This extreme wildfire season is symptomatic of a\nclimate-change-induced increase in the length and severity of the fire season\nthat affects the boreal ecosystem. Therefore, it is critical to empower\nwildfire management in boreal communities with better mitigation solutions.\nWildfire probability maps represent an important tool for understanding the\nlikelihood of wildfire occurrence and the potential severity of future\nwildfires. The massive increase in the availability of Earth observation data\nhas enabled the development of deep learning-based wildfire forecasting models,\naiming at providing precise wildfire probability maps at different spatial and\ntemporal scales. A main limitation of such methods is their reliance on\ncoarse-resolution environmental drivers and satellite products, leading to\nwildfire occurrence prediction of reduced resolution, typically around $\\sim\n0.1${\\deg}. This paper presents a benchmark dataset: CanadaFireSat, and\nbaseline methods for high-resolution: 100 m wildfire forecasting across Canada,\nleveraging multi-modal data from high-resolution multi-spectral satellite\nimages (Sentinel-2 L1C), mid-resolution satellite products (MODIS), and\nenvironmental factors (ERA5 reanalysis data). Our experiments consider two\nmajor deep learning architectures. We observe that using multi-modal temporal\ninputs outperforms single-modal temporal inputs across all metrics, achieving a\npeak performance of 60.3% in F1 score for the 2023 wildfire season, a season\nnever seen during model training. This demonstrates the potential of\nmulti-modal deep learning models for wildfire forecasting at high-resolution\nand continental scale.", "AI": {"tldr": "The paper introduces CanadaFireSat, a benchmark dataset for high-resolution wildfire forecasting in Canada, using multi-modal data and deep learning to improve prediction accuracy.", "motivation": "The severe 2023 wildfire season in Canada highlights the need for better wildfire mitigation tools, especially high-resolution forecasting models.", "method": "Leverages multi-modal data (Sentinel-2, MODIS, ERA5) and deep learning architectures to create 100 m resolution wildfire probability maps.", "result": "Multi-modal inputs outperform single-modal, achieving a 60.3% F1 score for the 2023 wildfire season, unseen during training.", "conclusion": "Multi-modal deep learning models show promise for high-resolution, continental-scale wildfire forecasting."}}
{"id": "2506.08149", "pdf": "https://arxiv.org/pdf/2506.08149", "abs": "https://arxiv.org/abs/2506.08149", "authors": ["Hang Wang", "Dechen Gao", "Junshan Zhang"], "title": "Ego-centric Learning of Communicative World Models for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We study multi-agent reinforcement learning (MARL) for tasks in complex\nhigh-dimensional environments, such as autonomous driving. MARL is known to\nsuffer from the \\textit{partial observability} and \\textit{non-stationarity}\nissues. To tackle these challenges, information sharing is often employed,\nwhich however faces major hurdles in practice, including overwhelming\ncommunication overhead and scalability concerns. By making use of generative AI\nembodied in world model together with its latent representation, we develop\n{\\it CALL}, \\underline{C}ommunic\\underline{a}tive Wor\\underline{l}d\nMode\\underline{l}, for MARL, where 1) each agent first learns its world model\nthat encodes its state and intention into low-dimensional latent representation\nwith smaller memory footprint, which can be shared with other agents of\ninterest via lightweight communication; and 2) each agent carries out\nego-centric learning while exploiting lightweight information sharing to enrich\nher world model, and then exploits its generalization capacity to improve\nprediction for better planning. We characterize the gain on the prediction\naccuracy from the information sharing and its impact on performance gap.\nExtensive experiments are carried out on the challenging local trajectory\nplanning tasks in the CARLA platform to demonstrate the performance gains of\nusing \\textit{CALL}.", "AI": {"tldr": "The paper introduces CALL, a communicative world model for MARL, addressing partial observability and non-stationarity by leveraging generative AI and lightweight communication.", "motivation": "To overcome challenges in MARL like partial observability and non-stationarity, while minimizing communication overhead and improving scalability.", "method": "Agents learn world models with low-dimensional latent representations for lightweight sharing and ego-centric learning, enhancing prediction and planning.", "result": "CALL improves prediction accuracy and performance, demonstrated in CARLA platform experiments for trajectory planning.", "conclusion": "CALL effectively addresses MARL challenges with efficient communication and improved generalization, validated in complex environments."}}
{"id": "2506.08365", "pdf": "https://arxiv.org/pdf/2506.08365", "abs": "https://arxiv.org/abs/2506.08365", "authors": ["Cheng Tan", "Zhenxiao Cao", "Zhangyang Gao", "Siyuan Li", "Yufei Huang", "Stan Z. Li"], "title": "AlphaFold Database Debiasing for Robust Inverse Folding", "categories": ["cs.LG", "q-bio.BM"], "comment": "Under review", "summary": "The AlphaFold Protein Structure Database (AFDB) offers unparalleled\nstructural coverage at near-experimental accuracy, positioning it as a valuable\nresource for data-driven protein design. However, its direct use in training\ndeep models that are sensitive to fine-grained atomic geometry, such as inverse\nfolding, exposes a critical limitation. Comparative analysis of structural\nfeature distributions reveals that AFDB structures exhibit distinct statistical\nregularities, reflecting a systematic geometric bias that deviates from the\nconformational diversity found in experimentally determined structures from the\nProtein Data Bank (PDB). While AFDB structures are cleaner and more idealized,\nPDB structures capture the intrinsic variability and physical realism essential\nfor generalization in downstream tasks. To address this discrepancy, we\nintroduce a Debiasing Structure AutoEncoder (DeSAE) that learns to reconstruct\nnative-like conformations from intentionally corrupted backbone geometries. By\ntraining the model to recover plausible structural states, DeSAE implicitly\ncaptures a more robust and natural structural manifold. At inference, applying\nDeSAE to AFDB structures produces debiased structures that significantly\nimprove inverse folding performance across multiple benchmarks. This work\nhighlights the critical impact of subtle systematic biases in predicted\nstructures and presents a principled framework for debiasing, significantly\nboosting the performance of structure-based learning tasks like inverse\nfolding.", "AI": {"tldr": "The paper introduces DeSAE to debias AlphaFold structures, improving their utility for tasks like inverse folding by aligning them closer to experimental PDB structures.", "motivation": "AlphaFold structures (AFDB) have biases that limit their use in fine-grained tasks like inverse folding, unlike experimental PDB structures which capture natural variability.", "method": "A Debiasing Structure AutoEncoder (DeSAE) is trained to reconstruct native-like conformations from corrupted backbones, learning a more natural structural manifold.", "result": "DeSAE debiased AFDB structures enhance inverse folding performance across benchmarks, addressing systematic biases.", "conclusion": "Debiasing predicted structures like AFDB is crucial for structure-based learning, and DeSAE provides an effective framework for this."}}
{"id": "2506.08750", "pdf": "https://arxiv.org/pdf/2506.08750", "abs": "https://arxiv.org/abs/2506.08750", "authors": ["Muhammad Anwar", "Daniel Lau", "Mishca de Costa", "Issam Hammad"], "title": "Unlocking the Potential of Large Language Models in the Nuclear Industry with Synthetic Data", "categories": ["cs.CL"], "comment": null, "summary": "The nuclear industry possesses a wealth of valuable information locked away\nin unstructured text data. This data, however, is not readily usable for\nadvanced Large Language Model (LLM) applications that require clean, structured\nquestion-answer pairs for tasks like model training, fine-tuning, and\nevaluation. This paper explores how synthetic data generation can bridge this\ngap, enabling the development of robust LLMs for the nuclear domain. We discuss\nthe challenges of data scarcity and privacy concerns inherent in the nuclear\nindustry and how synthetic data provides a solution by transforming existing\ntext data into usable Q&A pairs. This approach leverages LLMs to analyze text,\nextract key information, generate relevant questions, and evaluate the quality\nof the resulting synthetic dataset. By unlocking the potential of LLMs in the\nnuclear industry, synthetic data can pave the way for improved information\nretrieval, enhanced knowledge sharing, and more informed decision-making in\nthis critical sector.", "AI": {"tldr": "Synthetic data generation transforms unstructured nuclear industry text into structured Q&A pairs for LLM applications, addressing data scarcity and privacy issues.", "motivation": "The nuclear industry has valuable unstructured text data, but it's unusable for LLMs without structured Q&A pairs. Synthetic data can bridge this gap.", "method": "Leverages LLMs to analyze text, extract key info, generate Q&A pairs, and evaluate dataset quality.", "result": "Enables robust LLMs for nuclear domain, improving info retrieval, knowledge sharing, and decision-making.", "conclusion": "Synthetic data unlocks LLM potential in the nuclear industry, offering scalable solutions for data challenges."}}
{"id": "2506.08691", "pdf": "https://arxiv.org/pdf/2506.08691", "abs": "https://arxiv.org/abs/2506.08691", "authors": ["Congzhi Zhang", "Jiawei Peng", "Zhenglin Wang", "Yilong Lai", "Haowen Sun", "Heng Chang", "Fei Ma", "Weijiang Yu"], "title": "VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism", "categories": ["cs.CV"], "comment": "Accepted by ACL 2025 main", "summary": "Large Vision-Language Models (LVLMs) have shown exceptional performance in\nmultimodal tasks, but their effectiveness in complex visual reasoning is still\nconstrained, especially when employing Chain-of-Thought prompting techniques.\nIn this paper, we propose VReST, a novel training-free approach that enhances\nReasoning in LVLMs through Monte Carlo Tree Search and Self-Reward mechanisms.\nVReST meticulously traverses the reasoning landscape by establishing a search\ntree, where each node encapsulates a reasoning step, and each path delineates a\ncomprehensive reasoning sequence. Our innovative multimodal Self-Reward\nmechanism assesses the quality of reasoning steps by integrating the utility of\nsub-questions, answer correctness, and the relevance of vision-language clues,\nall without the need for additional models. VReST surpasses current prompting\nmethods and secures state-of-the-art performance across three multimodal\nmathematical reasoning benchmarks. Furthermore, it substantiates the efficacy\nof test-time scaling laws in multimodal tasks, offering a promising direction\nfor future research.", "AI": {"tldr": "VReST enhances LVLMs' reasoning via Monte Carlo Tree Search and Self-Reward, outperforming current methods in multimodal benchmarks.", "motivation": "LVLMs struggle with complex visual reasoning despite strong performance in multimodal tasks.", "method": "VReST uses Monte Carlo Tree Search and a Self-Reward mechanism to evaluate reasoning steps without extra models.", "result": "Achieves state-of-the-art performance in three multimodal mathematical reasoning benchmarks.", "conclusion": "VReST demonstrates test-time scaling laws' efficacy, paving the way for future research."}}
{"id": "2506.08153", "pdf": "https://arxiv.org/pdf/2506.08153", "abs": "https://arxiv.org/abs/2506.08153", "authors": ["Renato Cordeiro Ferreira"], "title": "A Metrics-Oriented Architectural Model to Characterize Complexity on Machine Learning-Enabled Systems", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.8; I.2.0"], "comment": "4 pages, 3 figures (2 diagrams, 1 table), to be published in CAIN\n  2025", "summary": "How can the complexity of ML-enabled systems be managed effectively? The goal\nof this research is to investigate how complexity affects ML-Enabled Systems\n(MLES). To address this question, this research aims to introduce a\nmetrics-based architectural model to characterize the complexity of MLES. The\ngoal is to support architectural decisions, providing a guideline for the\ninception and growth of these systems. This paper showcases the first step for\ncreating the metrics-based architectural model: an extension of a reference\narchitecture that can describe MLES to collect their metrics.", "AI": {"tldr": "The paper introduces a metrics-based architectural model to manage complexity in ML-enabled systems (MLES), starting with an extension of a reference architecture for metric collection.", "motivation": "To understand how complexity impacts MLES and support architectural decisions for their development.", "method": "Proposes a metrics-based architectural model, beginning with an extension of a reference architecture to describe MLES and collect metrics.", "result": "Initial step achieved: an extended reference architecture for MLES metric collection.", "conclusion": "The work lays the foundation for a comprehensive model to manage MLES complexity, aiding future architectural decisions."}}
{"id": "2506.08379", "pdf": "https://arxiv.org/pdf/2506.08379", "abs": "https://arxiv.org/abs/2506.08379", "authors": ["Yurun Yuan", "Tengyang Xie"], "title": "Reinforce LLM Reasoning through Multi-Agent Reflection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "International Conference on Machine Learning (ICML), 2025", "summary": "Leveraging more test-time computation has proven to be an effective way to\nboost the reasoning capabilities of large language models (LLMs). Among various\nmethods, the verify-and-improve paradigm stands out for enabling dynamic\nsolution exploration and feedback incorporation. However, existing approaches\noften suffer from restricted feedback spaces and lack of coordinated training\nof different parties, leading to suboptimal performance. To address this, we\nmodel this multi-turn refinement process as a Markov Decision Process and\nintroduce DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement\nlearning algorithm that trains an actor-critic LLM system to iteratively refine\nanswers via direct preference learning on self-generated data. Theoretically,\nDPSDP can match the performance of any policy within the training distribution.\nEmpirically, we instantiate DPSDP with various base models and show\nimprovements on both in- and out-of-distribution benchmarks. For example, on\nbenchmark MATH 500, majority voting over five refinement steps increases\nfirst-turn accuracy from 58.2% to 63.2% with Ministral-based models. An\nablation study further confirms the benefits of multi-agent collaboration and\nout-of-distribution generalization.", "AI": {"tldr": "DPSDP, a reinforcement learning algorithm, improves LLM reasoning by iterative refinement via direct preference learning, outperforming existing methods.", "motivation": "Existing verify-and-improve methods for LLMs have limited feedback and lack coordination, leading to suboptimal performance.", "method": "Model refinement as a Markov Decision Process; introduce DPSDP to train an actor-critic LLM system for iterative answer refinement.", "result": "DPSDP improves accuracy (e.g., from 58.2% to 63.2% on MATH 500) and shows benefits of multi-agent collaboration.", "conclusion": "DPSDP effectively enhances LLM reasoning through coordinated, iterative refinement and generalizes well."}}
{"id": "2506.08753", "pdf": "https://arxiv.org/pdf/2506.08753", "abs": "https://arxiv.org/abs/2506.08753", "authors": ["Pradyoth Hegde", "Santosh Kesiraju", "Jan \u0160vec", "\u0160imon Sedl\u00e1\u010dek", "Bolaji Yusuf", "Old\u0159ich Plchot", "Deepak K T", "Jan \u010cernock\u00fd"], "title": "Factors affecting the in-context learning abilities of LLMs for dialogue state tracking", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to Interspeech 2025", "summary": "This study explores the application of in-context learning (ICL) to the\ndialogue state tracking (DST) problem and investigates the factors that\ninfluence its effectiveness. We use a sentence embedding based k-nearest\nneighbour method to retrieve the suitable demonstrations for ICL. The selected\ndemonstrations, along with the test samples, are structured within a template\nas input to the LLM. We then conduct a systematic study to analyse the impact\nof factors related to demonstration selection and prompt context on DST\nperformance. This work is conducted using the MultiWoZ2.4 dataset and focuses\nprimarily on the OLMo-7B-instruct, Mistral-7B-Instruct-v0.3, and\nLlama3.2-3B-Instruct models. Our findings provide several useful insights on\nin-context learning abilities of LLMs for dialogue state tracking.", "AI": {"tldr": "The study applies in-context learning (ICL) to dialogue state tracking (DST) using a k-nearest neighbor method for demonstration retrieval, analyzes influencing factors, and evaluates performance on LLMs like OLMo-7B-instruct.", "motivation": "To investigate the effectiveness of ICL for DST and identify factors impacting its performance.", "method": "Uses a sentence embedding-based k-nearest neighbor method to retrieve demonstrations, structures them with test samples in a template, and evaluates on MultiWoZ2.4 dataset with specific LLMs.", "result": "Provides insights into the in-context learning abilities of LLMs for DST, focusing on demonstration selection and prompt context.", "conclusion": "The study offers valuable findings on how ICL can be optimized for DST tasks using LLMs."}}
{"id": "2506.08694", "pdf": "https://arxiv.org/pdf/2506.08694", "abs": "https://arxiv.org/abs/2506.08694", "authors": ["Mohammadreza Salehi", "Shashanka Venkataramanan", "Ioana Simion", "Efstratios Gavves", "Cees G. M. Snoek", "Yuki M Asano"], "title": "MoSiC: Optimal-Transport Motion Trajectory for Dense Self-Supervised Learning", "categories": ["cs.CV"], "comment": "preprint", "summary": "Dense self-supervised learning has shown great promise for learning pixel-\nand patch-level representations, but extending it to videos remains challenging\ndue to the complexity of motion dynamics. Existing approaches struggle as they\nrely on static augmentations that fail under object deformations, occlusions,\nand camera movement, leading to inconsistent feature learning over time. We\npropose a motion-guided self-supervised learning framework that clusters dense\npoint tracks to learn spatiotemporally consistent representations. By\nleveraging an off-the-shelf point tracker, we extract long-range motion\ntrajectories and optimize feature clustering through a momentum-encoder-based\noptimal transport mechanism. To ensure temporal coherence, we propagate cluster\nassignments along tracked points, enforcing feature consistency across views\ndespite viewpoint changes. Integrating motion as an implicit supervisory\nsignal, our method learns representations that generalize across frames,\nimproving robustness in dynamic scenes and challenging occlusion scenarios. By\ninitializing from strong image-pretrained models and leveraging video data for\ntraining, we improve state-of-the-art by 1% to 6% on six image and video\ndatasets and four evaluation benchmarks. The implementation is publicly\navailable at our GitHub repository: https://github.com/SMSD75/MoSiC/tree/main", "AI": {"tldr": "A motion-guided self-supervised learning framework improves dense video representation learning by clustering point tracks, enhancing temporal consistency and robustness in dynamic scenes.", "motivation": "Existing self-supervised methods for videos struggle with motion dynamics, deformations, and occlusions, leading to inconsistent feature learning.", "method": "The framework uses an off-the-shelf point tracker for motion trajectories, optimizes feature clustering via momentum-encoder-based optimal transport, and enforces temporal coherence by propagating cluster assignments.", "result": "The method improves state-of-the-art performance by 1% to 6% on six datasets and four benchmarks.", "conclusion": "Motion-guided learning enhances spatiotemporal consistency and generalization, making it robust for dynamic scenes and occlusions."}}
{"id": "2506.08171", "pdf": "https://arxiv.org/pdf/2506.08171", "abs": "https://arxiv.org/abs/2506.08171", "authors": ["Daniel Koh", "Yannic Noller", "Corina S. Pasareanu", "Adrians Skapars", "Youcheng Sun"], "title": "Worst-Case Symbolic Constraints Analysis and Generalisation with Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been successfully applied to a variety of\ncoding tasks, including code generation, completion, and repair. However, more\ncomplex symbolic reasoning tasks remain largely unexplored by LLMs. This paper\ninvestigates the capacity of LLMs to reason about worst-case executions in\nprograms through symbolic constraints analysis, aiming to connect LLMs and\nsymbolic reasoning approaches. Specifically, we define and address the problem\nof worst-case symbolic constraints analysis as a measure to assess the\ncomprehension of LLMs. We evaluate the performance of existing LLMs on this\nnovel task and further improve their capabilities through symbolic\nreasoning-guided fine-tuning, grounded in SMT (Satisfiability Modulo Theories)\nconstraint solving and supported by a specially designed dataset of symbolic\nconstraints. Experimental results show that our solver-aligned model,\nWARP-1.0-3B, consistently surpasses size-matched and even much larger\nbaselines, demonstrating that a 3B LLM can recover the very constraints that\npin down an algorithm's worst-case behaviour through reinforcement learning\nmethods. These findings suggest that LLMs are capable of engaging in deeper\nsymbolic reasoning, supporting a closer integration between neural\nnetwork-based learning and formal methods for rigorous program analysis.", "AI": {"tldr": "The paper explores LLMs' ability to handle worst-case symbolic reasoning in programs, introducing a solver-aligned model (WARP-1.0-3B) that outperforms baselines.", "motivation": "To bridge the gap between LLMs and symbolic reasoning, focusing on worst-case execution analysis.", "method": "Uses symbolic reasoning-guided fine-tuning with SMT constraint solving and a custom dataset.", "result": "WARP-1.0-3B outperforms size-matched and larger baselines in symbolic constraints analysis.", "conclusion": "LLMs can engage in deeper symbolic reasoning, enabling integration with formal program analysis."}}
{"id": "2506.08383", "pdf": "https://arxiv.org/pdf/2506.08383", "abs": "https://arxiv.org/abs/2506.08383", "authors": ["Jiaqi Chen", "Rongbin Ye"], "title": "Network Threat Detection: Addressing Class Imbalanced Data with Deep Forest", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "With the rapid expansion of Internet of Things (IoT) networks, detecting\nmalicious traffic in real-time has become a critical cybersecurity challenge.\nThis research addresses the detection challenges by presenting a comprehensive\nempirical analysis of machine learning techniques for malware detection using\nthe IoT-23 dataset provided by the Stratosphere Laboratory. We address the\nsignificant class imbalance within the dataset through three resampling\nstrategies. We implement and compare a few machine learning techniques. Our\nfindings demonstrate that the combination of appropriate imbalance treatment\ntechniques with ensemble methods, particularly gcForest, achieves better\ndetection performance compared to traditional approaches. This work contributes\nsignificantly to the development of more intelligent and efficient automated\nthreat detection systems for IoT environments, helping to secure critical\ninfrastructure against sophisticated cyber attacks while optimizing\ncomputational resource usage.", "AI": {"tldr": "The paper presents a machine learning-based approach for detecting malicious IoT traffic, using the IoT-23 dataset and addressing class imbalance with resampling strategies. Ensemble methods, especially gcForest, outperform traditional techniques.", "motivation": "The rapid growth of IoT networks necessitates real-time malware detection to enhance cybersecurity, particularly for critical infrastructure.", "method": "The study employs machine learning techniques on the IoT-23 dataset, using three resampling strategies to handle class imbalance, and compares their performance.", "result": "Ensemble methods, particularly gcForest, combined with imbalance treatment, achieve superior detection performance over traditional methods.", "conclusion": "The research advances intelligent, efficient automated threat detection for IoT, improving security and resource optimization."}}
{"id": "2506.08757", "pdf": "https://arxiv.org/pdf/2506.08757", "abs": "https://arxiv.org/abs/2506.08757", "authors": ["Mishca de Costa", "Muhammad Anwar", "Dave Mercier", "Mark Randall", "Issam Hammad"], "title": "Enhancing Accuracy and Maintainability in Nuclear Plant Data Retrieval: A Function-Calling LLM Approach Over NL-to-SQL", "categories": ["cs.CL", "cs.LG"], "comment": "44th Annual CNS Conference and the 49th Annual CNS/CNA Student\n  Conference, Westin Harbour Castle Hotel, Toronto, ON, Canada, June 8-11, 2025", "summary": "Retrieving operational data from nuclear power plants requires exceptional\naccuracy and transparency due to the criticality of the decisions it supports.\nTraditionally, natural language to SQL (NL-to-SQL) approaches have been\nexplored for querying such data. While NL-to-SQL promises ease of use, it poses\nsignificant risks: end-users cannot easily validate generated SQL queries, and\nlegacy nuclear plant databases -- often complex and poorly structured --\ncomplicate query generation due to decades of incremental modifications. These\nchallenges increase the likelihood of inaccuracies and reduce trust in the\napproach. In this work, we propose an alternative paradigm: leveraging\nfunction-calling large language models (LLMs) to address these challenges.\nInstead of directly generating SQL queries, we define a set of pre-approved,\npurpose-specific functions representing common use cases. Queries are processed\nby invoking these functions, which encapsulate validated SQL logic. This hybrid\napproach mitigates the risks associated with direct NL-to-SQL translations by\nensuring that SQL queries are reviewed and optimized by experts before\ndeployment. While this strategy introduces the upfront cost of developing and\nmaintaining the function library, we demonstrate how NL-to-SQL tools can assist\nin the initial generation of function code, allowing experts to focus on\nvalidation rather than creation. Our study includes a performance comparison\nbetween direct NL-to-SQL generation and the proposed function-based approach,\nhighlighting improvements in accuracy and maintainability. This work\nunderscores the importance of balancing user accessibility with operational\nsafety and provides a novel, actionable framework for robust data retrieval in\ncritical systems.", "AI": {"tldr": "The paper proposes using function-calling LLMs instead of direct NL-to-SQL for safer and more accurate data retrieval in nuclear power plants.", "motivation": "Traditional NL-to-SQL poses risks due to unvalidated queries and complex legacy databases, reducing trust and accuracy.", "method": "A function-based approach with pre-approved, purpose-specific functions encapsulating validated SQL logic, assisted by NL-to-SQL tools for initial code generation.", "result": "Improved accuracy and maintainability compared to direct NL-to-SQL, with validated SQL queries.", "conclusion": "Balancing user accessibility with operational safety, the framework offers a robust solution for critical systems."}}
{"id": "2506.08699", "pdf": "https://arxiv.org/pdf/2506.08699", "abs": "https://arxiv.org/abs/2506.08699", "authors": ["Frederik Hagelskjaer"], "title": "ArrowPose: Segmentation, Detection, and 5 DoF Pose Estimation Network for Colorless Point Clouds", "categories": ["cs.CV"], "comment": "6 pages, 5 figures, 4 tables", "summary": "This paper presents a fast detection and 5 DoF (Degrees of Freedom) pose\nestimation network for colorless point clouds. The pose estimation is\ncalculated from center and top points of the object, predicted by the neural\nnetwork. The network is trained on synthetic data, and tested on a benchmark\ndataset, where it demonstrates state-of-the-art performance and outperforms all\ncolorless methods. The network is able to run inference in only 250\nmilliseconds making it usable in many scenarios. Project page with code at\narrowpose.github.io", "AI": {"tldr": "A fast 5 DoF pose estimation network for colorless point clouds, achieving state-of-the-art performance and real-time inference.", "motivation": "To enable efficient and accurate pose estimation from colorless point clouds, addressing limitations of existing methods.", "method": "Uses a neural network to predict object center and top points for pose estimation, trained on synthetic data and tested on benchmarks.", "result": "Outperforms all colorless methods, with inference in 250ms, demonstrating state-of-the-art performance.", "conclusion": "The network is practical for real-time applications, with code available for further use."}}
{"id": "2506.08173", "pdf": "https://arxiv.org/pdf/2506.08173", "abs": "https://arxiv.org/abs/2506.08173", "authors": ["Nguyen Phu Vinh", "Anh Chung Hoang", "Chris Ngo", "Truong-Son Hy"], "title": "Repeton: Structured Bug Repair with ReAct-Guided Patch-and-Test Cycles", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown strong capabilities in code\ngeneration and comprehension, yet their application to complex software\nengineering tasks often suffers from low precision and limited\ninterpretability. We present Repeton, a fully open-source framework that\nleverages LLMs for precise and automated code manipulation in real-world Git\nrepositories. Rather than generating holistic fixes, Repeton operates through a\nstructured patch-and-test pipeline: it iteratively diagnoses issues, proposes\ncode changes, and validates each patch through automated testing. This stepwise\nprocess is guided by lightweight heuristics and development tools, avoiding\nreliance on embedding-based retrieval systems. Evaluated on the SWE-bench Lite\nbenchmark, our method shows good performance compared to RAG-based methods in\nboth patch validity and interpretability. By decomposing software engineering\ntasks into modular, verifiable stages, Repeton provides a practical path toward\nscalable and transparent autonomous debugging.", "AI": {"tldr": "Repeton is an open-source framework using LLMs for precise code manipulation in Git repositories via a structured patch-and-test pipeline, outperforming RAG-based methods in patch validity and interpretability.", "motivation": "LLMs struggle with precision and interpretability in complex software tasks. Repeton aims to address this by enabling precise, automated code manipulation.", "method": "Repeton uses a structured patch-and-test pipeline: iteratively diagnosing issues, proposing changes, and validating patches with automated testing, guided by heuristics and tools.", "result": "Evaluated on SWE-bench Lite, Repeton outperforms RAG-based methods in patch validity and interpretability.", "conclusion": "Repeton offers a scalable and transparent approach to autonomous debugging by modularizing software tasks."}}
{"id": "2506.08388", "pdf": "https://arxiv.org/pdf/2506.08388", "abs": "https://arxiv.org/abs/2506.08388", "authors": ["Edoardo Cetin", "Tianyu Zhao", "Yujin Tang"], "title": "Reinforcement Learning Teachers of Test Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Training reasoning language models (LMs) with reinforcement learning (RL) for\none-hot correctness inherently relies on the LM being able to explore and solve\nits task with some chance at initialization. Furthermore, a key use case of\nreasoning LMs is to act as teachers for distilling new students and\ncold-starting future RL iterations rather than being deployed themselves. From\nthese considerations, we introduce a new framework that avoids RL's exploration\nchallenge by training a new class of Reinforcement-Learned Teachers (RLTs)\nfocused on yielding the most effective downstream distillation. RLTs are\nprompted with both the question and solution to each problem, and tasked to\nsimply \"connect-the-dots\" with detailed explanations tailored for their\nstudents. We train RLTs with dense rewards obtained by feeding each explanation\nto the student and testing its understanding of the problem's solution. In\npractice, the raw outputs of a 7B RLT provide higher final performance on\ncompetition and graduate-level tasks than existing distillation and\ncold-starting pipelines that collect and postprocess the reasoning traces of\norders of magnitude larger LMs. Furthermore, RLTs maintain their effectiveness\nwhen training larger students and when applied zero-shot to out-of-distribution\ntasks, unlocking new levels of efficiency and re-usability for the RL reasoning\nframework.", "AI": {"tldr": "The paper introduces Reinforcement-Learned Teachers (RLTs), a framework for training reasoning LMs to improve downstream distillation without relying on RL's exploration challenges.", "motivation": "To address the limitations of RL for reasoning LMs, particularly the need for exploration at initialization and the focus on distillation for future RL iterations.", "method": "RLTs are trained with dense rewards by prompting them with questions and solutions, requiring them to generate detailed explanations for students.", "result": "A 7B RLT outperforms larger LMs in distillation and cold-starting pipelines, showing effectiveness with larger students and out-of-distribution tasks.", "conclusion": "RLTs enhance efficiency and re-usability in RL reasoning frameworks, offering superior performance for distillation and generalization."}}
{"id": "2506.08768", "pdf": "https://arxiv.org/pdf/2506.08768", "abs": "https://arxiv.org/abs/2506.08768", "authors": ["Ahmed Hasanaath", "Aisha Alansari", "Ahmed Ashraf", "Chafik Salmane", "Hamzah Luqman", "Saad Ezzini"], "title": "AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable progress in reasoning\nabilities and general natural language processing (NLP) tasks, yet their\nperformance on Arabic data, characterized by rich morphology, diverse dialects,\nand complex script, remains underexplored. This paper presents a comprehensive\nbenchmarking study of multiple reasoning-focused LLMs, with a special emphasis\non the newly introduced DeepSeek models, across a suite of fifteen Arabic NLP\ntasks. We experiment with various strategies, including zero-shot, few-shot,\nand fine-tuning. This allows us to systematically evaluate performance on\ndatasets covering a range of applications to examine their capacity for\nlinguistic reasoning under different levels of complexity. Our experiments\nreveal several key findings. First, carefully selecting just three in-context\nexamples delivers an average uplift of over 13 F1 points on classification\ntasks-boosting sentiment analysis from 35.3% to 87.5% and paraphrase detection\nfrom 56.1% to 87.0%. Second, reasoning-focused DeepSeek architectures\noutperform a strong GPT o4-mini baseline by an average of 12 F1 points on\ncomplex inference tasks in the zero-shot setting. Third, LoRA-based fine-tuning\nyields up to an additional 8 points in F1 and BLEU compared to equivalent\nincreases in model scale. The code is available at\nhttps://anonymous.4open.science/r/AraReasoner41299", "AI": {"tldr": "The paper benchmarks reasoning-focused LLMs, especially DeepSeek models, on Arabic NLP tasks, showing significant performance gains with few-shot learning and fine-tuning.", "motivation": "To explore LLMs' performance on Arabic data, which is underexplored due to its complexity, and evaluate reasoning abilities across diverse tasks.", "method": "Evaluates LLMs using zero-shot, few-shot, and fine-tuning strategies on 15 Arabic NLP tasks, comparing DeepSeek models to a GPT-4-mini baseline.", "result": "Few-shot learning boosts performance (e.g., sentiment analysis from 35.3% to 87.5%), DeepSeek outperforms GPT-4-mini by 12 F1 points, and LoRA fine-tuning adds 8 F1/BLEU points.", "conclusion": "Careful in-context example selection and fine-tuning significantly enhance LLM performance on Arabic NLP tasks, with DeepSeek models showing superior reasoning capabilities."}}
{"id": "2506.08704", "pdf": "https://arxiv.org/pdf/2506.08704", "abs": "https://arxiv.org/abs/2506.08704", "authors": ["Xiaohan Zhang", "Sitong Wang", "Yushen Yan", "Yi Yang", "Mingda Xu", "Qi Liu"], "title": "TraGraph-GS: Trajectory Graph-based Gaussian Splatting for Arbitrary Large-Scale Scene Rendering", "categories": ["cs.CV"], "comment": null, "summary": "High-quality novel view synthesis for large-scale scenes presents a\nchallenging dilemma in 3D computer vision. Existing methods typically partition\nlarge scenes into multiple regions, reconstruct a 3D representation using\nGaussian splatting for each region, and eventually merge them for novel view\nrendering. They can accurately render specific scenes, yet they do not\ngeneralize effectively for two reasons: (1) rigid spatial partition techniques\nstruggle with arbitrary camera trajectories, and (2) the merging of regions\nresults in Gaussian overlap to distort texture details. To address these\nchallenges, we propose TraGraph-GS, leveraging a trajectory graph to enable\nhigh-precision rendering for arbitrarily large-scale scenes. We present a\nspatial partitioning method for large-scale scenes based on graphs, which\nincorporates a regularization constraint to enhance the rendering of textures\nand distant objects, as well as a progressive rendering strategy to mitigate\nartifacts caused by Gaussian overlap. Experimental results demonstrate its\nsuperior performance both on four aerial and four ground datasets and highlight\nits remarkable efficiency: our method achieves an average improvement of 1.86\ndB in PSNR on aerial datasets and 1.62 dB on ground datasets compared to\nstate-of-the-art approaches.", "AI": {"tldr": "TraGraph-GS improves novel view synthesis for large-scale scenes by using a trajectory graph for spatial partitioning and progressive rendering, outperforming existing methods.", "motivation": "Existing methods for large-scale novel view synthesis struggle with arbitrary camera trajectories and texture distortion due to Gaussian overlap.", "method": "TraGraph-GS employs a trajectory graph for spatial partitioning, regularization for texture/distant object rendering, and progressive rendering to reduce artifacts.", "result": "Achieves 1.86 dB PSNR improvement on aerial datasets and 1.62 dB on ground datasets over state-of-the-art methods.", "conclusion": "TraGraph-GS effectively addresses challenges in large-scale scene rendering, offering superior performance and efficiency."}}
{"id": "2506.08397", "pdf": "https://arxiv.org/pdf/2506.08397", "abs": "https://arxiv.org/abs/2506.08397", "authors": ["Vamshika Sutar", "Amandeep Singh", "Rohitash Chandra"], "title": "Spatiotemporal deep learning models for detection of rapid intensification in cyclones", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Cyclone rapid intensification is the rapid increase in cyclone wind\nintensity, exceeding a threshold of 30 knots, within 24 hours. Rapid\nintensification is considered an extreme event during a cyclone, and its\noccurrence is relatively rare, contributing to a class imbalance in the\ndataset. A diverse array of factors influences the likelihood of a cyclone\nundergoing rapid intensification, further complicating the task for\nconventional machine learning models. In this paper, we evaluate deep learning,\nensemble learning and data augmentation frameworks to detect cyclone rapid\nintensification based on wind intensity and spatial coordinates. We note that\nconventional data augmentation methods cannot be utilised for generating\nspatiotemporal patterns replicating cyclones that undergo rapid\nintensification. Therefore, our framework employs deep learning models to\ngenerate spatial coordinates and wind intensity that replicate cyclones to\naddress the class imbalance problem of rapid intensification. We also use a\ndeep learning model for the classification module within the data augmentation\nframework to differentiate between rapid and non-rapid intensification events\nduring a cyclone. Our results show that data augmentation improves the results\nfor rapid intensification detection in cyclones, and spatial coordinates play a\ncritical role as input features to the given models. This paves the way for\nresearch in synthetic data generation for spatiotemporal data with extreme\nevents.", "AI": {"tldr": "The paper evaluates deep learning, ensemble learning, and data augmentation to detect cyclone rapid intensification, addressing class imbalance with synthetic data generation.", "motivation": "Rapid intensification in cyclones is rare and complex, causing class imbalance and challenges for conventional models.", "method": "Uses deep learning for synthetic data generation and classification to differentiate rapid and non-rapid intensification events.", "result": "Data augmentation improves detection, with spatial coordinates being critical input features.", "conclusion": "The framework advances synthetic data generation for spatiotemporal data with extreme events."}}
{"id": "2506.08827", "pdf": "https://arxiv.org/pdf/2506.08827", "abs": "https://arxiv.org/abs/2506.08827", "authors": ["Francisco Vargas", "Alejandro Gonz\u00e1lez Coene", "Gaston Escalante", "Exequiel Lob\u00f3n", "Manuel Pulido"], "title": "The impact of fine tuning in LLaMA on hallucinations for named entity extraction in legal documentation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The extraction of information about traffic accidents from legal documents is\ncrucial for quantifying insurance company costs. Extracting entities such as\npercentages of physical and/or psychological disability and the involved\ncompensation amounts is a challenging process, even for experts, due to the\nsubtle arguments and reasoning in the court decision. A two-step procedure is\nproposed: first, segmenting the document identifying the most relevant\nsegments, and then extracting the entities. For text segmentation, two\nmethodologies are compared: a classic method based on regular expressions and a\nsecond approach that divides the document into blocks of n-tokens, which are\nthen vectorized using multilingual models for semantic searches\n(text-embedding-ada-002/MiniLM-L12-v2 ). Subsequently, large language models\n(LLaMA-2 7b, 70b, LLaMA-3 8b, and GPT-4 Turbo) are applied with prompting to\nthe selected segments for entity extraction. For the LLaMA models, fine-tuning\nis performed using LoRA. LLaMA-2 7b, even with zero temperature, shows a\nsignificant number of hallucinations in extractions which are an important\ncontention point for named entity extraction. This work shows that these\nhallucinations are substantially reduced after finetuning the model. The\nperformance of the methodology based on segment vectorization and subsequent\nuse of LLMs significantly surpasses the classic method which achieves an\naccuracy of 39.5%. Among open-source models, LLaMA-2 70B with finetuning\nachieves the highest accuracy 79.4%, surpassing its base version 61.7%.\nNotably, the base LLaMA-3 8B model already performs comparably to the finetuned\nLLaMA-2 70B model, achieving 76.6%, highlighting the rapid progress in model\ndevelopment. Meanwhile, GPT-4 Turbo achieves the highest accuracy at 86.1%.", "AI": {"tldr": "A two-step method for extracting traffic accident details from legal documents outperforms classic methods, with GPT-4 Turbo achieving the highest accuracy (86.1%).", "motivation": "Traffic accident details in legal documents are hard to extract due to complex reasoning, impacting insurance cost quantification.", "method": "Segments documents first, then extracts entities using vectorization and LLMs (e.g., LLaMA-2, GPT-4 Turbo), with some models fine-tuned.", "result": "Vectorization + LLMs outperforms classic methods (39.5% vs. up to 86.1%). LLaMA-3 8B matches fine-tuned LLaMA-2 70B (76.6%).", "conclusion": "Advanced LLMs, especially GPT-4 Turbo, significantly improve entity extraction accuracy, with open-source models like LLaMA-3 showing rapid progress."}}
{"id": "2506.08710", "pdf": "https://arxiv.org/pdf/2506.08710", "abs": "https://arxiv.org/abs/2506.08710", "authors": ["Mengjiao Ma", "Qi Ma", "Yue Li", "Jiahuan Cheng", "Runyi Yang", "Bin Ren", "Nikola Popovic", "Mingqiang Wei", "Nicu Sebe", "Luc Van Gool", "Theo Gevers", "Martin R. Oswald", "Danda Pani Paudel"], "title": "SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting", "categories": ["cs.CV"], "comment": "15 pages, codes, data and benchmark will be released", "summary": "3D Gaussian Splatting (3DGS) serves as a highly performant and efficient\nencoding of scene geometry, appearance, and semantics. Moreover, grounding\nlanguage in 3D scenes has proven to be an effective strategy for 3D scene\nunderstanding. Current Language Gaussian Splatting line of work fall into three\nmain groups: (i) per-scene optimization-based, (ii) per-scene\noptimization-free, and (iii) generalizable approach. However, most of them are\nevaluated only on rendered 2D views of a handful of scenes and viewpoints close\nto the training views, limiting ability and insight into holistic 3D\nunderstanding. To address this gap, we propose the first large-scale benchmark\nthat systematically assesses these three groups of methods directly in 3D\nspace, evaluating on 1060 scenes across three indoor datasets and one outdoor\ndataset. Benchmark results demonstrate a clear advantage of the generalizable\nparadigm, particularly in relaxing the scene-specific limitation, enabling fast\nfeed-forward inference on novel scenes, and achieving superior segmentation\nperformance. We further introduce GaussianWorld-49K a carefully curated 3DGS\ndataset comprising around 49K diverse indoor and outdoor scenes obtained from\nmultiple sources, with which we demonstrate the generalizable approach could\nharness strong data priors. Our codes, benchmark, and datasets will be made\npublic to accelerate research in generalizable 3DGS scene understanding.", "AI": {"tldr": "The paper introduces a large-scale benchmark for evaluating 3D Gaussian Splatting (3DGS) methods in 3D space, highlighting the superiority of generalizable approaches. It also presents GaussianWorld-49K, a diverse 3DGS dataset.", "motivation": "Current 3DGS methods are limited to 2D views and few scenes, hindering holistic 3D understanding. The paper aims to address this gap by providing a comprehensive benchmark and dataset.", "method": "Proposes a large-scale benchmark evaluating three groups of 3DGS methods (per-scene optimization-based, optimization-free, and generalizable) across 1060 scenes in indoor and outdoor datasets. Introduces GaussianWorld-49K, a curated 3DGS dataset.", "result": "The generalizable approach outperforms others, enabling fast inference on novel scenes and superior segmentation. GaussianWorld-49K demonstrates the potential of leveraging strong data priors.", "conclusion": "The benchmark and dataset advance generalizable 3DGS research, with public release to accelerate progress in 3D scene understanding."}}
{"id": "2506.08277", "pdf": "https://arxiv.org/pdf/2506.08277", "abs": "https://arxiv.org/abs/2506.08277", "authors": ["Subba Reddy Oota", "Khushbu Pahwa", "Prachi Jindal", "Satya Sai Srinath Namburi", "Maneesh Singh", "Tanmoy Chakraborty", "Bapi S. Raju", "Manish Gupta"], "title": "Instruction-Tuned Video-Audio Models Elucidate Functional Specialization in the Brain", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "39 pages, 22 figures", "summary": "Recent voxel-wise multimodal brain encoding studies have shown that\nmultimodal large language models (MLLMs) exhibit a higher degree of brain\nalignment compared to unimodal models in both unimodal and multimodal stimulus\nsettings. More recently, instruction-tuned multimodal models have shown to\ngenerate task-specific representations that align strongly with brain activity.\nHowever, prior work evaluating the brain alignment of MLLMs has primarily\nfocused on unimodal settings or relied on non-instruction-tuned multimodal\nmodels for multimodal stimuli. To address this gap, we investigated brain\nalignment, that is, measuring the degree of predictivity of neural activity\nrecorded while participants were watching naturalistic movies (video along with\naudio) with representations derived from MLLMs. We utilized\ninstruction-specific embeddings from six video and two audio instruction-tuned\nMLLMs. Experiments with 13 video task-specific instructions show that\ninstruction-tuned video MLLMs significantly outperform non-instruction-tuned\nmultimodal (by 15%) and unimodal models (by 20%). Our evaluation of MLLMs for\nboth video and audio tasks using language-guided instructions shows clear\ndisentanglement in task-specific representations from MLLMs, leading to precise\ndifferentiation of multimodal functional processing in the brain. We also find\nthat MLLM layers align hierarchically with the brain, with early sensory areas\nshowing strong alignment with early layers, while higher-level visual and\nlanguage regions align more with middle to late layers. These findings provide\nclear evidence for the role of task-specific instructions in improving the\nalignment between brain activity and MLLMs, and open new avenues for mapping\njoint information processing in both the systems. We make the code publicly\navailable [https://github.com/subbareddy248/mllm_videos].", "AI": {"tldr": "Instruction-tuned multimodal large language models (MLLMs) show better brain alignment than non-instruction-tuned models, especially in video and audio tasks, with hierarchical layer-brain alignment.", "motivation": "To address the gap in evaluating brain alignment of MLLMs in multimodal settings using instruction-tuned models.", "method": "Used instruction-specific embeddings from six video and two audio instruction-tuned MLLMs to predict neural activity during naturalistic movie watching.", "result": "Instruction-tuned MLLMs outperformed non-instruction-tuned models by 15-20%, with hierarchical brain-layer alignment.", "conclusion": "Task-specific instructions enhance brain-MLLM alignment, offering new insights into multimodal brain processing."}}
{"id": "2506.08409", "pdf": "https://arxiv.org/pdf/2506.08409", "abs": "https://arxiv.org/abs/2506.08409", "authors": ["Fred Xu", "Song Jiang", "Zijie Huang", "Xiao Luo", "Shichang Zhang", "Adrian Chen", "Yizhou Sun"], "title": "FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Taxonomy Expansion, which models complex concepts and their relations, can be\nformulated as a set representation learning task. The generalization of set,\nfuzzy set, incorporates uncertainty and measures the information within a\nsemantic concept, making it suitable for concept modeling. Existing works\nusually model sets as vectors or geometric objects such as boxes, which are not\nclosed under set operations. In this work, we propose a sound and efficient\nformulation of set representation learning based on its volume approximation as\na fuzzy set. The resulting embedding framework, Fuzzy Set Embedding (FUSE),\nsatisfies all set operations and compactly approximates the underlying fuzzy\nset, hence preserving information while being efficient to learn, relying on\nminimum neural architecture. We empirically demonstrate the power of FUSE on\nthe task of taxonomy expansion, where FUSE achieves remarkable improvements up\nto 23% compared with existing baselines. Our work marks the first attempt to\nunderstand and efficiently compute the embeddings of fuzzy sets.", "AI": {"tldr": "FUSE is a novel fuzzy set embedding framework for taxonomy expansion, improving performance by up to 23% over baselines.", "motivation": "Existing set representations (vectors, boxes) lack closure under set operations and struggle with uncertainty in concept modeling.", "method": "Proposes FUSE, a volume approximation of fuzzy sets, ensuring closure under set operations and efficiency with minimal neural architecture.", "result": "FUSE achieves up to 23% improvement in taxonomy expansion tasks compared to existing methods.", "conclusion": "FUSE is the first efficient fuzzy set embedding framework, preserving information and enabling set operations."}}
{"id": "2506.08836", "pdf": "https://arxiv.org/pdf/2506.08836", "abs": "https://arxiv.org/abs/2506.08836", "authors": ["Flavio D'Intino", "Hans-Peter Hutter"], "title": "Advancing STT for Low-Resource Real-World Speech", "categories": ["cs.CL", "cs.HC"], "comment": "Conference: HCI International 2025, 20 pages, 4 figures", "summary": "Swiss German is a low-resource language represented by diverse dialects that\ndiffer significantly from Standard German and from each other, lacking a\nstandardized written form. As a result, transcribing Swiss German involves\ntranslating into Standard German. Existing datasets have been collected in\ncontrolled environments, yielding effective speech-to-text (STT) models, but\nthese models struggle with spontaneous conversational speech.\n  This paper, therefore, introduces the new SRB-300 dataset, a 300-hour\nannotated speech corpus featuring real-world long-audio recordings from 39\nSwiss German radio and TV stations. It captures spontaneous speech across all\nmajor Swiss dialects recorded in various realistic environments and overcomes\nthe limitation of prior sentence-level corpora.\n  We fine-tuned multiple OpenAI Whisper models on the SRB-300 dataset,\nachieving notable enhancements over previous zero-shot performance metrics.\nImprovements in word error rate (WER) ranged from 19% to 33%, while BLEU scores\nincreased between 8% and 40%. The best fine-tuned model, large-v3, achieved a\nWER of 17.1% and a BLEU score of 74.8. This advancement is crucial for\ndeveloping effective and robust STT systems for Swiss German and other\nlow-resource languages in real-world contexts.", "AI": {"tldr": "The paper introduces the SRB-300 dataset, a 300-hour annotated speech corpus for Swiss German, and fine-tunes Whisper models, achieving significant improvements in transcription accuracy.", "motivation": "Swiss German lacks standardized written forms, and existing STT models struggle with spontaneous speech. The SRB-300 dataset addresses this gap by providing real-world conversational data.", "method": "The authors fine-tuned multiple OpenAI Whisper models on the SRB-300 dataset, which includes diverse Swiss German dialects from radio and TV recordings.", "result": "Fine-tuning improved WER by 19-33% and BLEU scores by 8-40%, with the best model (large-v3) achieving a WER of 17.1% and BLEU of 74.8.", "conclusion": "The SRB-300 dataset and fine-tuned Whisper models significantly advance STT systems for Swiss German and other low-resource languages in real-world settings."}}
{"id": "2506.08729", "pdf": "https://arxiv.org/pdf/2506.08729", "abs": "https://arxiv.org/abs/2506.08729", "authors": ["Dieuwertje Alblas", "Patryk Rygiel", "Julian Suk", "Kaj O. Kappe", "Marieke Hofman", "Christoph Brune", "Kak Khee Yeung", "Jelmer M. Wolterink"], "title": "Geometric deep learning for local growth prediction on abdominal aortic aneurysm surfaces", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Abdominal aortic aneurysms (AAAs) are progressive focal dilatations of the\nabdominal aorta. AAAs may rupture, with a survival rate of only 20\\%. Current\nclinical guidelines recommend elective surgical repair when the maximum AAA\ndiameter exceeds 55 mm in men or 50 mm in women. Patients that do not meet\nthese criteria are periodically monitored, with surveillance intervals based on\nthe maximum AAA diameter. However, this diameter does not take into account the\ncomplex relation between the 3D AAA shape and its growth, making standardized\nintervals potentially unfit. Personalized AAA growth predictions could improve\nmonitoring strategies. We propose to use an SE(3)-symmetric transformer model\nto predict AAA growth directly on the vascular model surface enriched with\nlocal, multi-physical features. In contrast to other works which have\nparameterized the AAA shape, this representation preserves the vascular\nsurface's anatomical structure and geometric fidelity. We train our model using\na longitudinal dataset of 113 computed tomography angiography (CTA) scans of 24\nAAA patients at irregularly sampled intervals. After training, our model\npredicts AAA growth to the next scan moment with a median diameter error of\n1.18 mm. We further demonstrate our model's utility to identify whether a\npatient will become eligible for elective repair within two years (acc = 0.93).\nFinally, we evaluate our model's generalization on an external validation set\nconsisting of 25 CTAs from 7 AAA patients from a different hospital. Our\nresults show that local directional AAA growth prediction from the vascular\nsurface is feasible and may contribute to personalized surveillance strategies.", "AI": {"tldr": "The paper proposes an SE(3)-symmetric transformer model to predict AAA growth using 3D vascular surface features, improving personalized monitoring strategies.", "motivation": "Current AAA monitoring relies on diameter thresholds, ignoring 3D shape complexities, leading to potentially unfit surveillance intervals. Personalized growth predictions could enhance monitoring.", "method": "An SE(3)-symmetric transformer model predicts AAA growth directly on the vascular surface, enriched with local multi-physical features, trained on 113 CTA scans from 24 patients.", "result": "The model predicts AAA growth with a median diameter error of 1.18 mm and identifies elective repair eligibility within two years (accuracy = 0.93). It generalizes well on an external validation set.", "conclusion": "Local directional AAA growth prediction from the vascular surface is feasible and may improve personalized surveillance strategies."}}
{"id": "2506.08311", "pdf": "https://arxiv.org/pdf/2506.08311", "abs": "https://arxiv.org/abs/2506.08311", "authors": ["Ira Ceka", "Saurabh Pujar", "Shyam Ramji", "Luca Buratti", "Gail Kaiser", "Baishakhi Ray"], "title": "Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "With the advent of large language models (LLMs), software engineering agents\n(SWE agents) have emerged as a powerful paradigm for automating a range of\nsoftware tasks -- from code generation and repair to test case synthesis. These\nagents operate autonomously by interpreting user input and responding to\nenvironmental feedback. While various agent architectures have demonstrated\nstrong empirical performance, the internal decision-making worfklows that drive\ntheir behavior remain poorly understood. Deeper insight into these workflows\nhold promise for improving both agent reliability and efficiency. In this work,\nwe present the first systematic study of SWE agent behavior through the lens of\nexecution traces. Our contributions are as follows: (1) we propose the first\ntaxonomy of decision-making pathways across five representative agents; (2)\nusing this taxonomy, we identify three core components essential to agent\nsuccess -- bug localization, patch generation, and reproduction test generation\n-- and study each in depth; (3) we study the impact of test generation on\nsuccessful patch production; and analyze strategies that can lead to successful\ntest generation; (4) we further conduct the first large-scale code clone\nanalysis comparing agent-generated and developer-written patches and provide a\nqualitative study revealing structural and stylistic differences in patch\ncontent. Together, these findings offer novel insights into agent design and\nopen avenues for building agents that are both more effective and more aligned\nwith human development practices.", "AI": {"tldr": "The paper presents a systematic study of software engineering agents (SWE agents) using execution traces, proposing a taxonomy of decision-making pathways and analyzing core components like bug localization, patch generation, and test generation. It also compares agent-generated and developer-written patches.", "motivation": "To improve the reliability and efficiency of SWE agents by understanding their internal decision-making workflows, which are currently poorly understood.", "method": "The study uses execution traces to analyze SWE agents, proposing a taxonomy of decision-making pathways and examining core components. It also conducts a large-scale code clone analysis and qualitative study of patches.", "result": "The study identifies essential components for agent success, analyzes the impact of test generation on patch production, and reveals structural and stylistic differences between agent-generated and developer-written patches.", "conclusion": "The findings provide insights for designing more effective and human-aligned SWE agents, opening new avenues for improving agent reliability and efficiency."}}
{"id": "2506.08412", "pdf": "https://arxiv.org/pdf/2506.08412", "abs": "https://arxiv.org/abs/2506.08412", "authors": ["Saraa Ali", "Aleksandr Khizhik", "Stepan Svirin", "Artem Ryzhikov", "Denis Derkach"], "title": "Learning to Hear Broken Motors: Signature-Guided Data Augmentation for Induction-Motor Diagnostics", "categories": ["cs.LG"], "comment": null, "summary": "The application of machine learning (ML) algorithms in the intelligent\ndiagnosis of three-phase engines has the potential to significantly enhance\ndiagnostic performance and accuracy. Traditional methods largely rely on\nsignature analysis, which, despite being a standard practice, can benefit from\nthe integration of advanced ML techniques. In our study, we innovate by\ncombining ML algorithms with a novel unsupervised anomaly generation\nmethodology that takes into account the engine physics model. We propose\nSignature-Guided Data Augmentation (SGDA), an unsupervised framework that\nsynthesizes physically plausible faults directly in the frequency domain of\nhealthy current signals. Guided by Motor Current Signature Analysis, SGDA\ncreates diverse and realistic anomalies without resorting to computationally\nintensive simulations. This hybrid approach leverages the strengths of both\nsupervised ML and unsupervised signature analysis, achieving superior\ndiagnostic accuracy and reliability along with wide industrial application. The\nfindings highlight the potential of our approach to contribute significantly to\nthe field of engine diagnostics, offering a robust and efficient solution for\nreal-world applications.", "AI": {"tldr": "The paper introduces Signature-Guided Data Augmentation (SGDA), a hybrid ML and unsupervised method for diagnosing three-phase engine faults, improving accuracy and reliability.", "motivation": "Traditional signature analysis methods for engine diagnostics can be enhanced with ML, but lack realistic anomaly generation. The study aims to bridge this gap.", "method": "Combines ML with unsupervised anomaly generation using engine physics. SGDA synthesizes faults in the frequency domain of healthy signals, guided by Motor Current Signature Analysis.", "result": "Achieves superior diagnostic accuracy and reliability, offering a robust solution for industrial applications.", "conclusion": "SGDA significantly advances engine diagnostics by efficiently generating realistic anomalies and improving performance."}}
{"id": "2506.08885", "pdf": "https://arxiv.org/pdf/2506.08885", "abs": "https://arxiv.org/abs/2506.08885", "authors": ["Danush Khanna", "Krishna Kumar", "Basab Ghosh", "Vinija Jain", "Vasu Sharma", "Aman Chadha", "Amitava Das"], "title": "AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Adversarial threats against LLMs are escalating faster than current defenses\ncan adapt. We expose a critical geometric blind spot in alignment: adversarial\nprompts exploit latent camouflage, embedding perilously close to the safe\nrepresentation manifold while encoding unsafe intent thereby evading surface\nlevel defenses like Direct Preference Optimization (DPO), which remain blind to\nthe latent geometry. We introduce ALKALI, the first rigorously curated\nadversarial benchmark and the most comprehensive to date spanning 9,000 prompts\nacross three macro categories, six subtypes, and fifteen attack families.\nEvaluation of 21 leading LLMs reveals alarmingly high Attack Success Rates\n(ASRs) across both open and closed source models, exposing an underlying\nvulnerability we term latent camouflage, a structural blind spot where\nadversarial completions mimic the latent geometry of safe ones. To mitigate\nthis vulnerability, we introduce GRACE - Geometric Representation Aware\nContrastive Enhancement, an alignment framework coupling preference learning\nwith latent space regularization. GRACE enforces two constraints: latent\nseparation between safe and adversarial completions, and adversarial cohesion\namong unsafe and jailbreak behaviors. These operate over layerwise pooled\nembeddings guided by a learned attention profile, reshaping internal geometry\nwithout modifying the base model, and achieve up to 39% ASR reduction.\nMoreover, we introduce AVQI, a geometry aware metric that quantifies latent\nalignment failure via cluster separation and compactness. AVQI reveals when\nunsafe completions mimic the geometry of safe ones, offering a principled lens\ninto how models internally encode safety. We make the code publicly available\nat https://anonymous.4open.science/r/alkali-B416/README.md.", "AI": {"tldr": "The paper exposes a geometric blind spot in LLM alignment, introduces ALKALI (an adversarial benchmark), and proposes GRACE (a defense framework) to mitigate latent camouflage vulnerabilities.", "motivation": "Adversarial threats against LLMs are outpacing defenses, exploiting latent geometry to evade detection.", "method": "Introduces ALKALI benchmark and GRACE framework, which enforces latent separation and adversarial cohesion via geometric regularization.", "result": "GRACE reduces Attack Success Rates by up to 39%, and AVQI metric quantifies latent alignment failures.", "conclusion": "The work highlights latent camouflage vulnerabilities and offers practical solutions for improving LLM safety."}}
{"id": "2506.08735", "pdf": "https://arxiv.org/pdf/2506.08735", "abs": "https://arxiv.org/abs/2506.08735", "authors": ["Yuhang Wang", "Jun Li", "Zhijian Wu", "Jianhua Xu"], "title": "InceptionMamba: An Efficient Hybrid Network with Large Band Convolution and Bottleneck Mamba", "categories": ["cs.CV"], "comment": null, "summary": "Within the family of convolutional neural networks, InceptionNeXt has shown\nexcellent competitiveness in image classification and a number of downstream\ntasks. Built on parallel one-dimensional strip convolutions, however, it\nsuffers from limited ability of capturing spatial dependencies along different\ndimensions and fails to fully explore spatial modeling in local neighborhood.\nBesides, inherent locality constraints of convolution operations are\ndetrimental to effective global context modeling. To overcome these\nlimitations, we propose a novel backbone architecture termed InceptionMamba in\nthis study. More specifically, the traditional one-dimensional strip\nconvolutions are replaced by orthogonal band convolutions in our InceptionMamba\nto achieve cohesive spatial modeling. Furthermore, global contextual modeling\ncan be achieved via a bottleneck Mamba module, facilitating enhanced\ncross-channel information fusion and enlarged receptive field. Extensive\nevaluations on classification and various downstream tasks demonstrate that the\nproposed InceptionMamba achieves state-of-the-art performance with superior\nparameter and computational efficiency. The source code will be available at\nhttps://github.com/Wake1021/InceptionMamba.", "AI": {"tldr": "InceptionMamba improves spatial and global context modeling over InceptionNeXt by replacing strip convolutions with orthogonal band convolutions and adding a bottleneck Mamba module.", "motivation": "InceptionNeXt's limitations in capturing spatial dependencies and global context modeling inspired the development of InceptionMamba.", "method": "Replaces one-dimensional strip convolutions with orthogonal band convolutions and introduces a bottleneck Mamba module for global context modeling.", "result": "Achieves state-of-the-art performance in classification and downstream tasks with superior efficiency.", "conclusion": "InceptionMamba addresses InceptionNeXt's limitations, offering better spatial and global modeling with high efficiency."}}
{"id": "2506.08320", "pdf": "https://arxiv.org/pdf/2506.08320", "abs": "https://arxiv.org/abs/2506.08320", "authors": ["Vivek Vaidya", "Aditya Patwardhan", "Ashish Kundu"], "title": "How Good LLM-Generated Password Policies Are?", "categories": ["cs.CR", "cs.AI"], "comment": "11 pages, 2 Tables, 9 figures, 3 Algorithms", "summary": "Generative AI technologies, particularly Large Language Models (LLMs), are\nrapidly being adopted across industry, academia, and government sectors, owing\nto their remarkable capabilities in natural language processing. However,\ndespite their strengths, the inconsistency and unpredictability of LLM outputs\npresent substantial challenges, especially in security-critical domains such as\naccess control. One critical issue that emerges prominently is the consistency\nof LLM-generated responses, which is paramount for ensuring secure and reliable\noperations.\n  In this paper, we study the application of LLMs within the context of\nCybersecurity Access Control Systems. Specifically, we investigate the\nconsistency and accuracy of LLM-generated password policies, translating\nnatural language prompts into executable pwquality.conf configuration files.\nOur experimental methodology adopts two distinct approaches: firstly, we\nutilize pre-trained LLMs to generate configuration files purely from natural\nlanguage prompts without additional guidance. Secondly, we provide these models\nwith official pwquality.conf documentation to serve as an informative baseline.\nWe systematically assess the soundness, accuracy, and consistency of these\nAI-generated configurations. Our findings underscore significant challenges in\nthe current generation of LLMs and contribute valuable insights into refining\nthe deployment of LLMs in Access Control Systems.", "AI": {"tldr": "The paper examines the consistency and accuracy of LLM-generated password policies for cybersecurity access control, highlighting challenges in their reliability.", "motivation": "To address the inconsistency and unpredictability of LLM outputs in security-critical domains like access control.", "method": "Two approaches: generating configurations from natural language prompts alone and with official documentation, then assessing soundness, accuracy, and consistency.", "result": "Significant challenges in LLM-generated configurations were identified.", "conclusion": "The study provides insights for improving LLM deployment in access control systems."}}
{"id": "2506.08415", "pdf": "https://arxiv.org/pdf/2506.08415", "abs": "https://arxiv.org/abs/2506.08415", "authors": ["Licong Lin", "Jingfeng Wu", "Peter L. Bartlett"], "title": "Improved Scaling Laws in Linear Regression via Data Reuse", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Neural scaling laws suggest that the test error of large language models\ntrained online decreases polynomially as the model size and data size increase.\nHowever, such scaling can be unsustainable when running out of new data. In\nthis work, we show that data reuse can improve existing scaling laws in linear\nregression. Specifically, we derive sharp test error bounds on $M$-dimensional\nlinear models trained by multi-pass stochastic gradient descent (multi-pass\nSGD) on $N$ data with sketched features. Assuming that the data covariance has\na power-law spectrum of degree $a$, and that the true parameter follows a prior\nwith an aligned power-law spectrum of degree $b-a$ (with $a > b > 1$), we show\nthat multi-pass SGD achieves a test error of $\\Theta(M^{1-b} + L^{(1-b)/a})$,\nwhere $L \\lesssim N^{a/b}$ is the number of iterations. In the same setting,\none-pass SGD only attains a test error of $\\Theta(M^{1-b} + N^{(1-b)/a})$ (see\ne.g., Lin et al., 2024). This suggests an improved scaling law via data reuse\n(i.e., choosing $L>N$) in data-constrained regimes. Numerical simulations are\nalso provided to verify our theoretical findings.", "AI": {"tldr": "Data reuse improves neural scaling laws in linear regression, showing better test error bounds with multi-pass SGD compared to one-pass SGD.", "motivation": "Address the unsustainability of neural scaling laws when new data is exhausted by exploring data reuse.", "method": "Derive test error bounds for multi-pass SGD on linear models with sketched features, assuming power-law spectra for data covariance and true parameters.", "result": "Multi-pass SGD achieves better test error scaling (\u0398(M^{1\u2212b} + L^{(1\u2212b)/a})) than one-pass SGD (\u0398(M^{1\u2212b} + N^{(1\u2212b)/a})).", "conclusion": "Data reuse via multi-pass SGD offers improved scaling laws in data-constrained scenarios, validated by simulations."}}
{"id": "2506.08897", "pdf": "https://arxiv.org/pdf/2506.08897", "abs": "https://arxiv.org/abs/2506.08897", "authors": ["Hiba Khey", "Amine Lakhder", "Salma Rouichi", "Imane El Ghabi", "Kamal Hejjaoui", "Younes En-nahli", "Fahd Kalloubi", "Moez Amri"], "title": "PlantBert: An Open Source Language Model for Plant Science", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid advancement of transformer-based language models has catalyzed\nbreakthroughs in biomedical and clinical natural language processing; however,\nplant science remains markedly underserved by such domain-adapted tools. In\nthis work, we present PlantBert, a high-performance, open-source language model\nspecifically tailored for extracting structured knowledge from plant\nstress-response literature. Built upon the DeBERTa architecture-known for its\ndisentangled attention and robust contextual encoding-PlantBert is fine-tuned\non a meticulously curated corpus of expert-annotated abstracts, with a primary\nfocus on lentil (Lens culinaris) responses to diverse abiotic and biotic\nstressors. Our methodology combines transformer-based modeling with\nrule-enhanced linguistic post-processing and ontology-grounded entity\nnormalization, enabling PlantBert to capture biologically meaningful\nrelationships with precision and semantic fidelity. The underlying corpus is\nannotated using a hierarchical schema aligned with the Crop Ontology,\nencompassing molecular, physiological, biochemical, and agronomic dimensions of\nplant adaptation. PlantBert exhibits strong generalization capabilities across\nentity types and demonstrates the feasibility of robust domain adaptation in\nlow-resource scientific fields. By providing a scalable and reproducible\nframework for high-resolution entity recognition, PlantBert bridges a critical\ngap in agricultural NLP and paves the way for intelligent, data-driven systems\nin plant genomics, phenomics, and agronomic knowledge discovery. Our model is\npublicly released to promote transparency and accelerate cross-disciplinary\ninnovation in computational plant science.", "AI": {"tldr": "PlantBert is a transformer-based language model tailored for plant science, specifically for extracting structured knowledge from plant stress-response literature, built on DeBERTa and fine-tuned on expert-annotated abstracts.", "motivation": "Plant science lacks domain-adapted NLP tools despite advancements in transformer models. PlantBert aims to fill this gap by providing a specialized tool for plant stress-response literature.", "method": "PlantBert uses DeBERTa architecture, fine-tuned on expert-annotated abstracts, combined with rule-enhanced post-processing and ontology-grounded entity normalization.", "result": "PlantBert shows strong generalization across entity types and robust domain adaptation in low-resource fields, enabling precise, biologically meaningful relationship extraction.", "conclusion": "PlantBert bridges a gap in agricultural NLP, offering a scalable framework for entity recognition and fostering innovation in computational plant science."}}
{"id": "2506.08772", "pdf": "https://arxiv.org/pdf/2506.08772", "abs": "https://arxiv.org/abs/2506.08772", "authors": ["Jiayi Song", "Kaiyu Li", "Xiangyong Cao", "Deyu Meng"], "title": "RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Semantic segmentation in remote sensing images is crucial for various\napplications, yet its performance is heavily reliant on large-scale,\nhigh-quality pixel-wise annotations, which are notoriously expensive and\ntime-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers a\npromising alternative to mitigate this data dependency. However, existing SSS\nmethods often struggle with the inherent distribution mismatch between limited\nlabeled data and abundant unlabeled data, leading to suboptimal generalization.\nWe propose that Vision Foundation Models (VFMs), pre-trained on vast and\ndiverse datasets, possess robust generalization capabilities that can\neffectively bridge this distribution gap and provide strong semantic priors for\nSSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation and\nFusion), a novel framework that leverages the powerful semantic knowledge\nembedded in VFMs to guide semi-supervised learning in remote sensing.\nSpecifically, RS-MTDF employs multiple frozen VFMs (\\textit{e.g.}, DINOv2 and\nCLIP) as expert teachers, utilizing feature-level distillation to align student\nfeatures with their robust representations. To further enhance discriminative\npower, the distilled knowledge is seamlessly fused into the student decoder.\nExtensive experiments on three challenging remote sensing datasets (ISPRS\nPotsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achieves\nstate-of-the-art performance. Notably, our method outperforms existing\napproaches across various label ratios on LoveDA and secures the highest IoU in\nthe majority of semantic categories. These results underscore the efficacy of\nmulti-teacher VFM guidance in significantly enhancing both generalization and\nsemantic understanding for remote sensing segmentation. Ablation studies\nfurther validate the contribution of each proposed module.", "AI": {"tldr": "The paper proposes RS-MTDF, a semi-supervised semantic segmentation framework for remote sensing, leveraging Vision Foundation Models (VFMs) to address distribution mismatch and improve generalization.", "motivation": "Semantic segmentation in remote sensing relies on costly annotations. Semi-supervised methods struggle with distribution gaps between labeled and unlabeled data. VFMs offer robust generalization to bridge this gap.", "method": "RS-MTDF uses multiple frozen VFMs (e.g., DINOv2, CLIP) as teachers for feature-level distillation, fusing their knowledge into the student decoder.", "result": "Experiments on ISPRS Potsdam, LoveDA, and DeepGlobe show RS-MTDF achieves state-of-the-art performance, outperforming others in various label ratios and semantic categories.", "conclusion": "Multi-teacher VFM guidance enhances generalization and semantic understanding in remote sensing segmentation, validated by ablation studies."}}
{"id": "2506.08336", "pdf": "https://arxiv.org/pdf/2506.08336", "abs": "https://arxiv.org/abs/2506.08336", "authors": ["Li Changjiang", "Liang Jiacheng", "Cao Bochuan", "Chen Jinghui", "Wang Ting"], "title": "Your Agent Can Defend Itself against Backdoor Attacks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite their growing adoption across domains, large language model\n(LLM)-powered agents face significant security risks from backdoor attacks\nduring training and fine-tuning. These compromised agents can subsequently be\nmanipulated to execute malicious operations when presented with specific\ntriggers in their inputs or environments. To address this pressing risk, we\npresent ReAgent, a novel defense against a range of backdoor attacks on\nLLM-based agents. Intuitively, backdoor attacks often result in inconsistencies\namong the user's instruction, the agent's planning, and its execution. Drawing\non this insight, ReAgent employs a two-level approach to detect potential\nbackdoors. At the execution level, ReAgent verifies consistency between the\nagent's thoughts and actions; at the planning level, ReAgent leverages the\nagent's capability to reconstruct the instruction based on its thought\ntrajectory, checking for consistency between the reconstructed instruction and\nthe user's instruction. Extensive evaluation demonstrates ReAgent's\neffectiveness against various backdoor attacks across tasks. For instance,\nReAgent reduces the attack success rate by up to 90\\% in database operation\ntasks, outperforming existing defenses by large margins. This work reveals the\npotential of utilizing compromised agents themselves to mitigate backdoor\nrisks.", "AI": {"tldr": "ReAgent is a defense mechanism against backdoor attacks on LLM-based agents, detecting inconsistencies between instructions, planning, and execution to mitigate risks.", "motivation": "Addressing security risks from backdoor attacks during LLM training and fine-tuning, which can manipulate agents into malicious operations.", "method": "ReAgent uses a two-level approach: execution-level verification of thought-action consistency and planning-level reconstruction of instructions for consistency checks.", "result": "ReAgent reduces attack success rates by up to 90% in tasks like database operations, outperforming existing defenses.", "conclusion": "ReAgent demonstrates the potential of leveraging compromised agents to mitigate backdoor risks effectively."}}
{"id": "2506.08417", "pdf": "https://arxiv.org/pdf/2506.08417", "abs": "https://arxiv.org/abs/2506.08417", "authors": ["Qingmao Yao", "Zhichao Lei", "Tianyuan Chen", "Ziyue Yuan", "Xuefan Chen", "Jianxiang Liu", "Faguo Wu", "Xiao Zhang"], "title": "Offline RL with Smooth OOD Generalization in Convex Hull and its Neighborhood", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR 2025", "summary": "Offline Reinforcement Learning (RL) struggles with distributional shifts,\nleading to the $Q$-value overestimation for out-of-distribution (OOD) actions.\nExisting methods address this issue by imposing constraints; however, they\noften become overly conservative when evaluating OOD regions, which constrains\nthe $Q$-function generalization. This over-constraint issue results in poor\n$Q$-value estimation and hinders policy improvement. In this paper, we\nintroduce a novel approach to achieve better $Q$-value estimation by enhancing\n$Q$-function generalization in OOD regions within Convex Hull and its\nNeighborhood (CHN). Under the safety generalization guarantees of the CHN, we\npropose the Smooth Bellman Operator (SBO), which updates OOD $Q$-values by\nsmoothing them with neighboring in-sample $Q$-values. We theoretically show\nthat SBO approximates true $Q$-values for both in-sample and OOD actions within\nthe CHN. Our practical algorithm, Smooth Q-function OOD Generalization (SQOG),\nempirically alleviates the over-constraint issue, achieving near-accurate\n$Q$-value estimation. On the D4RL benchmarks, SQOG outperforms existing\nstate-of-the-art methods in both performance and computational efficiency.", "AI": {"tldr": "The paper introduces a novel approach to improve $Q$-value estimation in offline RL by enhancing generalization in OOD regions, using a Smooth Bellman Operator (SBO) and achieving better performance than existing methods.", "motivation": "Offline RL suffers from $Q$-value overestimation for OOD actions due to distributional shifts, and existing methods are overly conservative, limiting $Q$-function generalization.", "method": "Proposes the Smooth Bellman Operator (SBO) to update OOD $Q$-values by smoothing them with neighboring in-sample values, ensuring safety within the Convex Hull and its Neighborhood (CHN).", "result": "SQOG, the practical algorithm, achieves near-accurate $Q$-value estimation and outperforms state-of-the-art methods on D4RL benchmarks.", "conclusion": "The approach effectively addresses the over-constraint issue, improving $Q$-value generalization and policy performance in offline RL."}}
{"id": "2506.08899", "pdf": "https://arxiv.org/pdf/2506.08899", "abs": "https://arxiv.org/abs/2506.08899", "authors": ["Elias Horner", "Cristinel Mateis", "Guido Governatori", "Agata Ciabattoni"], "title": "From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LO"], "comment": null, "summary": "We present a novel approach to the automated semantic analysis of legal texts\nusing large language models (LLMs), targeting their transformation into formal\nrepresentations in Defeasible Deontic Logic (DDL). We propose a structured\npipeline that segments complex normative language into atomic snippets,\nextracts deontic rules, and evaluates them for syntactic and semantic\ncoherence. Our methodology is evaluated across various LLM configurations,\nincluding prompt engineering strategies, fine-tuned models, and multi-stage\npipelines, focusing on legal norms from the Australian Telecommunications\nConsumer Protections Code. Empirical results demonstrate promising alignment\nbetween machine-generated and expert-crafted formalizations, showing that LLMs\n- particularly when prompted effectively - can significantly contribute to\nscalable legal informatics.", "AI": {"tldr": "A novel pipeline using LLMs transforms legal texts into Defeasible Deontic Logic, showing promising results in aligning machine-generated and expert formalizations.", "motivation": "To automate semantic analysis of legal texts and transform them into formal representations for scalable legal informatics.", "method": "A structured pipeline segments legal texts, extracts deontic rules, and evaluates coherence, tested with various LLM configurations.", "result": "Empirical results show alignment between machine-generated and expert-crafted formalizations, especially with effective prompting.", "conclusion": "LLMs, when prompted well, can significantly aid scalable legal informatics by automating legal text analysis."}}
{"id": "2506.08777", "pdf": "https://arxiv.org/pdf/2506.08777", "abs": "https://arxiv.org/abs/2506.08777", "authors": ["Keyi Liu", "Weidong Yang", "Ben Fei", "Ying He"], "title": "Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "Self-supervised learning (SSL) for point cloud pre-training has become a\ncornerstone for many 3D vision tasks, enabling effective learning from\nlarge-scale unannotated data. At the scene level, existing SSL methods often\nincorporate volume rendering into the pre-training framework, using RGB-D\nimages as reconstruction signals to facilitate cross-modal learning. This\nstrategy promotes alignment between 2D and 3D modalities and enables the model\nto benefit from rich visual cues in the RGB-D inputs. However, these approaches\nare limited by their reliance on implicit scene representations and high memory\ndemands. Furthermore, since their reconstruction objectives are applied only in\n2D space, they often fail to capture underlying 3D geometric structures. To\naddress these challenges, we propose Gaussian2Scene, a novel scene-level SSL\nframework that leverages the efficiency and explicit nature of 3D Gaussian\nSplatting (3DGS) for pre-training. The use of 3DGS not only alleviates the\ncomputational burden associated with volume rendering but also supports direct\n3D scene reconstruction, thereby enhancing the geometric understanding of the\nbackbone network. Our approach follows a progressive two-stage training\nstrategy. In the first stage, a dual-branch masked autoencoder learns both 2D\nand 3D scene representations. In the second stage, we initialize training with\nreconstructed point clouds and further supervise learning using the geometric\nlocations of Gaussian primitives and rendered RGB images. This process\nreinforces both geometric and cross-modal learning. We demonstrate the\neffectiveness of Gaussian2Scene across several downstream 3D object detection\ntasks, showing consistent improvements over existing pre-training methods.", "AI": {"tldr": "Gaussian2Scene is a novel SSL framework for point cloud pre-training using 3D Gaussian Splatting, improving geometric understanding and computational efficiency over existing methods.", "motivation": "Existing SSL methods for point cloud pre-training rely on implicit scene representations and high memory demands, often failing to capture 3D geometric structures.", "method": "Gaussian2Scene uses 3D Gaussian Splatting for efficient pre-training, with a two-stage strategy: a dual-branch masked autoencoder for 2D/3D representations, followed by supervised learning with reconstructed point clouds and Gaussian primitives.", "result": "The framework shows consistent improvements in downstream 3D object detection tasks compared to existing methods.", "conclusion": "Gaussian2Scene effectively addresses limitations of current SSL approaches by leveraging explicit 3D representations and enhancing geometric learning."}}
{"id": "2506.08344", "pdf": "https://arxiv.org/pdf/2506.08344", "abs": "https://arxiv.org/abs/2506.08344", "authors": ["Ne\u015fet \u00dcnver Akmandor", "Sarvesh Prajapati", "Mark Zolotas", "Ta\u015fk\u0131n Pad\u0131r"], "title": "Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to the 2025 IEEE International Conference on Automation\n  Science and Engineering (CASE)", "summary": "Traditional motion planning methods for robots with many degrees-of-freedom,\nsuch as mobile manipulators, are often computationally prohibitive for\nreal-world settings. In this paper, we propose a novel multi-model motion\nplanning pipeline, termed Re4MPC, which computes trajectories using Nonlinear\nModel Predictive Control (NMPC). Re4MPC generates trajectories in a\ncomputationally efficient manner by reactively selecting the model, cost, and\nconstraints of the NMPC problem depending on the complexity of the task and\nrobot state. The policy for this reactive decision-making is learned via a Deep\nReinforcement Learning (DRL) framework. We introduce a mathematical formulation\nto integrate NMPC into this DRL framework. To validate our methodology and\ndesign choices, we evaluate DRL training and test outcomes in a physics-based\nsimulation involving a mobile manipulator. Experimental results demonstrate\nthat Re4MPC is more computationally efficient and achieves higher success rates\nin reaching end-effector goals than the NMPC baseline, which computes\nwhole-body trajectories without our learning mechanism.", "AI": {"tldr": "Re4MPC is a multi-model motion planning pipeline using NMPC and DRL for efficient trajectory planning in robots, outperforming traditional NMPC methods.", "motivation": "Traditional motion planning for high-DOF robots is computationally expensive, limiting real-world applicability.", "method": "Proposes Re4MPC, combining NMPC with DRL to reactively select models, costs, and constraints for efficient planning.", "result": "Re4MPC shows higher computational efficiency and success rates compared to baseline NMPC.", "conclusion": "Re4MPC offers a promising solution for real-time motion planning in complex robotic systems."}}
{"id": "2506.08419", "pdf": "https://arxiv.org/pdf/2506.08419", "abs": "https://arxiv.org/abs/2506.08419", "authors": ["Ruichen Jiang", "Ali Kavis", "Aryan Mokhtari"], "title": "Online Learning-guided Learning Rate Adaptation via Gradient Alignment", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "24 pages, 5 figures", "summary": "The performance of an optimizer on large-scale deep learning models depends\ncritically on fine-tuning the learning rate, often requiring an extensive grid\nsearch over base learning rates, schedules, and other hyperparameters. In this\npaper, we propose a principled framework called GALA (Gradient Alignment-based\nLearning rate Adaptation), which dynamically adjusts the learning rate by\ntracking the alignment between consecutive gradients and using a local\ncurvature estimate. Guided by the convergence analysis, we formulate the\nproblem of selecting the learning rate as a one-dimensional online learning\nproblem. When paired with an online learning algorithm such as\nFollow-the-Regularized-Leader, our method produces a flexible, adaptive\nlearning rate schedule that tends to increase when consecutive gradients are\naligned and decrease otherwise. We establish a data-adaptive convergence rate\nfor normalized SGD equipped with GALA in the smooth, nonconvex setting.\nEmpirically, common optimizers such as SGD and Adam, when augmented with GALA,\ndemonstrate robust performance across a wide range of initial learning rates\nand perform competitively without the need for tuning.", "AI": {"tldr": "GALA dynamically adjusts learning rates by tracking gradient alignment and local curvature, eliminating the need for extensive hyperparameter tuning.", "motivation": "Fine-tuning learning rates for large-scale deep learning models is time-consuming and requires extensive grid searches.", "method": "GALA adjusts learning rates based on gradient alignment and local curvature, formulated as an online learning problem.", "result": "GALA improves optimizer performance across various initial learning rates, reducing the need for tuning.", "conclusion": "GALA provides a flexible, adaptive learning rate schedule, enhancing optimizer robustness without manual tuning."}}
{"id": "2506.08907", "pdf": "https://arxiv.org/pdf/2506.08907", "abs": "https://arxiv.org/abs/2506.08907", "authors": ["Antonios Dimakis", "John Pavlopoulos", "Antonios Anastasopoulos"], "title": "Dialect Normalization using Large Language Models and Morphological Rules", "categories": ["cs.CL", "I.2.7"], "comment": "19 pages, 18 figures, to be published in the Findings of the\n  Association for Computational Linguistics 2025", "summary": "Natural language understanding systems struggle with low-resource languages,\nincluding many dialects of high-resource ones. Dialect-to-standard\nnormalization attempts to tackle this issue by transforming dialectal text so\nthat it can be used by standard-language tools downstream. In this study, we\ntackle this task by introducing a new normalization method that combines\nrule-based linguistically informed transformations and large language models\n(LLMs) with targeted few-shot prompting, without requiring any parallel data.\nWe implement our method for Greek dialects and apply it on a dataset of\nregional proverbs, evaluating the outputs using human annotators. We then use\nthis dataset to conduct downstream experiments, finding that previous results\nregarding these proverbs relied solely on superficial linguistic information,\nincluding orthographic artifacts, while new observations can still be made\nthrough the remaining semantics.", "AI": {"tldr": "A new method combining rule-based transformations and LLMs with few-shot prompting improves dialect-to-standard normalization for Greek dialects, evaluated on proverbs.", "motivation": "Addressing the challenge of low-resource languages and dialects by enabling standard-language tools to process dialectal text.", "method": "Combines rule-based linguistically informed transformations and LLMs with few-shot prompting, requiring no parallel data.", "result": "Human evaluation shows effectiveness; downstream experiments reveal previous reliance on superficial linguistic information.", "conclusion": "The method successfully normalizes dialectal text, uncovering deeper semantic insights beyond orthographic artifacts."}}
{"id": "2506.08780", "pdf": "https://arxiv.org/pdf/2506.08780", "abs": "https://arxiv.org/abs/2506.08780", "authors": ["Isaac Corley", "Lakshay Sharma", "Ruth Crasto"], "title": "Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The Landsat program offers over 50 years of globally consistent Earth\nimagery. However, the lack of benchmarks for this data constrains progress\ntowards Landsat-based Geospatial Foundation Models (GFM). In this paper, we\nintroduce Landsat-Bench, a suite of three benchmarks with Landsat imagery that\nadapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, and\nLC100-L. We establish baseline and standardized evaluation methods across both\ncommon architectures and Landsat foundation models pretrained on the SSL4EO-L\ndataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extract\nbetter representations for downstream tasks in comparison to ImageNet,\nincluding performance gains of +4% OA and +5.1% mAP on EuroSAT-L and\nBigEarthNet-L.", "AI": {"tldr": "Landsat-Bench introduces three benchmarks for Landsat imagery, showing that SSL4EO-L pretrained models outperform ImageNet in downstream tasks.", "motivation": "The lack of benchmarks for Landsat data hinders progress in Geospatial Foundation Models (GFMs).", "method": "Landsat-Bench adapts three remote sensing datasets (EuroSAT-L, BigEarthNet-L, LC100-L) and evaluates pretrained models.", "result": "SSL4EO-L pretrained GFMs outperform ImageNet, with gains of +4% OA and +5.1% mAP on EuroSAT-L and BigEarthNet-L.", "conclusion": "Landsat-Bench provides standardized benchmarks, demonstrating the superiority of SSL4EO-L pretrained models for Landsat-based tasks."}}
{"id": "2506.08426", "pdf": "https://arxiv.org/pdf/2506.08426", "abs": "https://arxiv.org/abs/2506.08426", "authors": ["Zheng Lin", "Zhe Chen", "Xianhao Chen", "Wei Ni", "Yue Gao"], "title": "HASFL: Heterogeneity-aware Split Federated Learning over Edge Computing Systems", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "16 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:2403.13101", "summary": "Split federated learning (SFL) has emerged as a promising paradigm to\ndemocratize machine learning (ML) on edge devices by enabling layer-wise model\npartitioning. However, existing SFL approaches suffer significantly from the\nstraggler effect due to the heterogeneous capabilities of edge devices. To\naddress the fundamental challenge, we propose adaptively controlling batch\nsizes (BSs) and model splitting (MS) for edge devices to overcome resource\nheterogeneity. We first derive a tight convergence bound of SFL that quantifies\nthe impact of varied BSs and MS on learning performance. Based on the\nconvergence bound, we propose HASFL, a heterogeneity-aware SFL framework\ncapable of adaptively controlling BS and MS to balance communication-computing\nlatency and training convergence in heterogeneous edge networks. Extensive\nexperiments with various datasets validate the effectiveness of HASFL and\ndemonstrate its superiority over state-of-the-art benchmarks.", "AI": {"tldr": "HASFL adaptively controls batch sizes and model splitting to mitigate the straggler effect in split federated learning, improving performance in heterogeneous edge networks.", "motivation": "Existing SFL approaches struggle with the straggler effect due to device heterogeneity, limiting efficiency.", "method": "Proposes HASFL, a framework that adaptively adjusts batch sizes and model splitting based on a derived convergence bound.", "result": "HASFL outperforms benchmarks, balancing latency and convergence in heterogeneous networks.", "conclusion": "HASFL effectively addresses resource heterogeneity in SFL, enhancing learning performance."}}
{"id": "2506.08920", "pdf": "https://arxiv.org/pdf/2506.08920", "abs": "https://arxiv.org/abs/2506.08920", "authors": ["Zeyu Leo Liu", "Greg Durrett", "Eunsol Choi"], "title": "PropMEND: Hypernetworks for Knowledge Propagation in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under review", "summary": "Knowledge editing techniques for large language models (LLMs) can inject\nknowledge that is later reproducible verbatim, but they fall short on\npropagating that knowledge: models cannot answer questions that require\nreasoning with the injected knowledge. We present a hypernetwork-based approach\nfor knowledge propagation, named PropMEND, where we meta-learn how to modify\ngradients of a language modeling loss to encourage injected information to\npropagate. Our approach extends the meta-objective of MEND [29] so that\ngradient updates on knowledge are transformed to enable answering multi-hop\nquestions involving that knowledge. We show improved performance on the\nRippleEdit dataset, showing almost 2x accuracy on challenging multi-hop\nquestions whose answers are not explicitly stated in the injected fact. We\nfurther introduce a new dataset, Controlled RippleEdit, to evaluate the\ngeneralization of our hypernetwork, testing knowledge propagation along\nrelations and entities unseen during hypernetwork training. PropMEND still\noutperforms existing approaches in unseen entity-relation pairs, yet the\nperformance gap decreases substantially, suggesting future work in propagating\nknowledge to a wide range of relations.", "AI": {"tldr": "PropMEND, a hypernetwork-based approach, improves knowledge propagation in LLMs for multi-hop reasoning, outperforming existing methods on RippleEdit and Controlled RippleEdit datasets.", "motivation": "Existing knowledge editing techniques for LLMs lack the ability to propagate injected knowledge for reasoning tasks.", "method": "A hypernetwork meta-learns gradient modifications to enable multi-hop reasoning with injected knowledge.", "result": "PropMEND achieves nearly 2x accuracy on multi-hop questions and generalizes to unseen relations/entities, though with a reduced performance gap.", "conclusion": "PropMEND advances knowledge propagation but highlights the need for further work on broader relation coverage."}}
{"id": "2506.08784", "pdf": "https://arxiv.org/pdf/2506.08784", "abs": "https://arxiv.org/abs/2506.08784", "authors": ["Jongyub Seok", "Chanjin Kang"], "title": "HomographyAD: Deep Anomaly Detection Using Self Homography Learning", "categories": ["cs.CV"], "comment": null, "summary": "Anomaly detection (AD) is a task that distinguishes normal and abnormal data,\nwhich is important for applying automation technologies of the manufacturing\nfacilities. For MVTec dataset that is a representative AD dataset for\nindustrial environment, many recent works have shown remarkable performances.\nHowever, the existing anomaly detection works have a limitation of showing good\nperformance for fully-aligned datasets only, unlike real-world industrial\nenvironments. To solve this limitation, we propose HomographyAD, a novel deep\nanomaly detection methodology based on the ImageNet-pretrained network, which\nis specially designed for actual industrial dataset. Specifically, we first\nsuggest input foreground alignment using the deep homography estimation method.\nIn addition, we fine-tune the model by self homography learning to learn\nadditional shape information from normal samples. Finally, we conduct anomaly\ndetection based on the measure of how far the feature of test sample is from\nthe distribution of the extracted normal features. By applying our proposed\nmethod to various existing AD approaches, we show performance enhancement\nthrough extensive experiments.", "AI": {"tldr": "The paper proposes HomographyAD, a deep anomaly detection method for industrial datasets, addressing alignment issues in real-world scenarios.", "motivation": "Existing anomaly detection methods perform well only on fully-aligned datasets, unlike real-world industrial environments.", "method": "HomographyAD uses ImageNet-pretrained networks, aligns input foregrounds via deep homography estimation, and fine-tunes with self homography learning.", "result": "The method enhances performance when applied to various anomaly detection approaches, validated through experiments.", "conclusion": "HomographyAD effectively addresses alignment limitations in industrial anomaly detection, improving performance."}}
{"id": "2506.08441", "pdf": "https://arxiv.org/pdf/2506.08441", "abs": "https://arxiv.org/abs/2506.08441", "authors": ["Anh N. Nhu", "Sanghyun Son", "Ming Lin"], "title": "Time-Aware World Model for Adaptive Prediction and Control", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "Paper accepted to ICML 2025", "summary": "In this work, we introduce the Time-Aware World Model (TAWM), a model-based\napproach that explicitly incorporates temporal dynamics. By conditioning on the\ntime-step size, {\\Delta}t, and training over a diverse range of {\\Delta}t\nvalues -- rather than sampling at a fixed time-step -- TAWM learns both high-\nand low-frequency task dynamics across diverse control problems. Grounded in\nthe information-theoretic insight that the optimal sampling rate depends on a\nsystem's underlying dynamics, this time-aware formulation improves both\nperformance and data efficiency. Empirical evaluations show that TAWM\nconsistently outperforms conventional models across varying observation rates\nin a variety of control tasks, using the same number of training samples and\niterations. Our code can be found online at:\ngithub.com/anh-nn01/Time-Aware-World-Model.", "AI": {"tldr": "TAWM improves model performance and data efficiency by incorporating temporal dynamics and training over diverse time-step sizes.", "motivation": "To address the limitation of fixed time-step sampling in conventional models, which may miss high- or low-frequency dynamics.", "method": "Introduces Time-Aware World Model (TAWM), conditioning on time-step size (\u0394t) and training over diverse \u0394t values.", "result": "TAWM outperforms conventional models across varying observation rates in control tasks with the same training data.", "conclusion": "TAWM's time-aware formulation enhances performance and efficiency by adapting to system dynamics."}}
{"id": "2506.08435", "pdf": "https://arxiv.org/pdf/2506.08435", "abs": "https://arxiv.org/abs/2506.08435", "authors": ["Mingyuan Fan", "Fuyi Wang", "Cen Chen", "Jianying Zhou"], "title": "Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": "Accepted to Usenix Security 2025", "summary": "Federated learning (FL) enables collaborative model training among multiple\nclients without the need to expose raw data. Its ability to safeguard privacy,\nat the heart of FL, has recently been a hot-button debate topic. To elaborate,\nseveral studies have introduced a type of attacks known as gradient leakage\nattacks (GLAs), which exploit the gradients shared during training to\nreconstruct clients' raw data. On the flip side, some literature, however,\ncontends no substantial privacy risk in practical FL environments due to the\neffectiveness of such GLAs being limited to overly relaxed conditions, such as\nsmall batch sizes and knowledge of clients' data distributions.\n  This paper bridges this critical gap by empirically demonstrating that\nclients' data can still be effectively reconstructed, even within realistic FL\nenvironments. Upon revisiting GLAs, we recognize that their performance\nfailures stem from their inability to handle the gradient matching problem. To\nalleviate the performance bottlenecks identified above, we develop FedLeak,\nwhich introduces two novel techniques, partial gradient matching and gradient\nregularization. Moreover, to evaluate the performance of FedLeak in real-world\nFL environments, we formulate a practical evaluation protocol grounded in a\nthorough review of extensive FL literature and industry practices. Under this\nprotocol, FedLeak can still achieve high-fidelity data reconstruction, thereby\nunderscoring the significant vulnerability in FL systems and the urgent need\nfor more effective defense methods.", "AI": {"tldr": "The paper demonstrates that gradient leakage attacks (GLAs) can effectively reconstruct clients' data in realistic federated learning (FL) environments, introducing FedLeak to address performance bottlenecks and highlighting FL's vulnerability.", "motivation": "The debate on FL's privacy safeguards, with some arguing GLAs are ineffective in practical settings, motivates the need to empirically prove data reconstruction risks in realistic FL environments.", "method": "The authors develop FedLeak, incorporating partial gradient matching and gradient regularization to overcome GLA limitations, and establish a practical evaluation protocol based on FL literature and industry practices.", "result": "FedLeak achieves high-fidelity data reconstruction under realistic conditions, revealing significant vulnerabilities in FL systems.", "conclusion": "The study underscores the urgent need for more effective defense mechanisms in FL due to demonstrated privacy risks."}}
{"id": "2506.08935", "pdf": "https://arxiv.org/pdf/2506.08935", "abs": "https://arxiv.org/abs/2506.08935", "authors": ["Andrew Shin"], "title": "Can A Gamer Train A Mathematical Reasoning Model?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While large language models (LLMs) have achieved remarkable performance in\nvarious tasks including mathematical reasoning, their development typically\ndemands prohibitive computational resources. Recent advancements have reduced\ncosts for training capable models, yet even these approaches rely on high-end\nhardware clusters. In this paper, we demonstrate that a single average gaming\nGPU can train a solid mathematical reasoning model, by integrating\nreinforcement learning and memory optimization techniques. Specifically, we\ntrain a 1.5B parameter mathematical reasoning model on RTX 3080 Ti of 16GB\nmemory that achieves comparable or better performance on mathematical reasoning\nbenchmarks than models several times larger, in resource-constrained\nenvironments. Our results challenge the paradigm that state-of-the-art\nmathematical reasoning necessitates massive infrastructure, democratizing\naccess to high-performance AI research.\nhttps://github.com/shinandrew/YouronMath.", "AI": {"tldr": "A 1.5B parameter mathematical reasoning model trained on a single gaming GPU (RTX 3080 Ti) achieves comparable or better performance than larger models, challenging the need for massive infrastructure.", "motivation": "To democratize access to high-performance AI research by reducing computational resource demands for training capable mathematical reasoning models.", "method": "Integrates reinforcement learning and memory optimization techniques to train a 1.5B parameter model on a single gaming GPU (RTX 3080 Ti).", "result": "The model performs comparably or better than larger models on mathematical reasoning benchmarks, despite limited hardware.", "conclusion": "State-of-the-art mathematical reasoning can be achieved without massive infrastructure, making high-performance AI research more accessible."}}
{"id": "2506.08796", "pdf": "https://arxiv.org/pdf/2506.08796", "abs": "https://arxiv.org/abs/2506.08796", "authors": ["Zhiyuan Ma", "Ruixun Liu", "Sixian Liu", "Jianjun Li", "Bowen Zhou"], "title": "Flow Diverse and Efficient: Learning Momentum Flow Matching via Stochastic Velocity Field Sampling", "categories": ["cs.CV"], "comment": null, "summary": "Recently, the rectified flow (RF) has emerged as the new state-of-the-art\namong flow-based diffusion models due to its high efficiency advantage in\nstraight path sampling, especially with the amazing images generated by a\nseries of RF models such as Flux 1.0 and SD 3.0. Although a straight-line\nconnection between the noisy and natural data distributions is intuitive, fast,\nand easy to optimize, it still inevitably leads to: 1) Diversity concerns,\nwhich arise since straight-line paths only cover a fairly restricted sampling\nspace. 2) Multi-scale noise modeling concerns, since the straight line flow\nonly needs to optimize the constant velocity field $\\bm v$ between the two\ndistributions $\\bm\\pi_0$ and $\\bm\\pi_1$. In this work, we present\nDiscretized-RF, a new family of rectified flow (also called momentum flow\nmodels since they refer to the previous velocity component and the random\nvelocity component in each diffusion step), which discretizes the straight path\ninto a series of variable velocity field sub-paths (namely ``momentum fields'')\nto expand the search space, especially when close to the distribution\n$p_\\text{noise}$. Different from the previous case where noise is directly\nsuperimposed on $\\bm x$, we introduce noise on the velocity $\\bm v$ of the\nsub-path to change its direction in order to improve the diversity and\nmulti-scale noise modeling abilities. Experimental results on several\nrepresentative datasets demonstrate that learning momentum flow matching by\nsampling random velocity fields will produce trajectories that are both diverse\nand efficient, and can consistently generate high-quality and diverse results.\nCode is available at https://github.com/liuruixun/momentum-fm.", "AI": {"tldr": "Discretized-RF improves rectified flow models by introducing momentum fields for better diversity and multi-scale noise modeling.", "motivation": "Address diversity and multi-scale noise modeling limitations in straight-line rectified flow models.", "method": "Discretizes straight paths into variable velocity sub-paths, introducing noise on velocity to enhance diversity.", "result": "Produces diverse, efficient trajectories and high-quality, diverse results.", "conclusion": "Discretized-RF advances rectified flow models with improved performance and flexibility."}}
{"id": "2506.08459", "pdf": "https://arxiv.org/pdf/2506.08459", "abs": "https://arxiv.org/abs/2506.08459", "authors": ["Juanran Wang", "Marc R. Schlichting", "Harrison Delecki", "Mykel J. Kochenderfer"], "title": "Diffusion Models for Safety Validation of Autonomous Driving Systems", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Safety validation of autonomous driving systems is extremely challenging due\nto the high risks and costs of real-world testing as well as the rarity and\ndiversity of potential failures. To address these challenges, we train a\ndenoising diffusion model to generate potential failure cases of an autonomous\nvehicle given any initial traffic state. Experiments on a four-way intersection\nproblem show that in a variety of scenarios, the diffusion model can generate\nrealistic failure samples while capturing a wide variety of potential failures.\nOur model does not require any external training dataset, can perform training\nand inference with modest computing resources, and does not assume any prior\nknowledge of the system under test, with applicability to safety validation for\ntraffic intersections.", "AI": {"tldr": "A denoising diffusion model is trained to generate realistic failure cases for autonomous driving systems, addressing the challenges of high-risk real-world testing and rare failure diversity.", "motivation": "Safety validation for autonomous driving is costly and risky due to rare and diverse failures, necessitating a scalable and efficient method.", "method": "A denoising diffusion model is used to generate failure cases from any initial traffic state without external datasets or extensive resources.", "result": "The model successfully generates realistic failure samples across diverse scenarios, validated on a four-way intersection problem.", "conclusion": "The approach offers a scalable, resource-efficient solution for safety validation in autonomous driving, particularly for traffic intersections."}}
{"id": "2506.08438", "pdf": "https://arxiv.org/pdf/2506.08438", "abs": "https://arxiv.org/abs/2506.08438", "authors": ["Yuchen Wu", "Xinyi Zhong", "Zhuoran Yang"], "title": "Learning to Lead: Incentivizing Strategic Agents in the Dark", "categories": ["cs.LG", "cs.GT", "stat.ML"], "comment": "81 pages, 7 figures", "summary": "We study an online learning version of the generalized principal-agent model,\nwhere a principal interacts repeatedly with a strategic agent possessing\nprivate types, private rewards, and taking unobservable actions. The agent is\nnon-myopic, optimizing a discounted sum of future rewards and may strategically\nmisreport types to manipulate the principal's learning. The principal,\nobserving only her own realized rewards and the agent's reported types, aims to\nlearn an optimal coordination mechanism that minimizes strategic regret. We\ndevelop the first provably sample-efficient algorithm for this challenging\nsetting. Our approach features a novel pipeline that combines (i) a delaying\nmechanism to incentivize approximately myopic agent behavior, (ii) an\ninnovative reward angle estimation framework that uses sector tests and a\nmatching procedure to recover type-dependent reward functions, and (iii) a\npessimistic-optimistic LinUCB algorithm that enables the principal to explore\nefficiently while respecting the agent's incentive constraints. We establish a\nnear optimal $\\tilde{O}(\\sqrt{T}) $ regret bound for learning the principal's\noptimal policy, where $\\tilde{O}(\\cdot) $ omits logarithmic factors. Our\nresults open up new avenues for designing robust online learning algorithms for\na wide range of game-theoretic settings involving private types and strategic\nagents.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08938", "pdf": "https://arxiv.org/pdf/2506.08938", "abs": "https://arxiv.org/abs/2506.08938", "authors": ["Qinggang Zhang", "Zhishang Xiang", "Yilin Xiao", "Le Wang", "Junhui Li", "Xinrun Wang", "Jinsong Su"], "title": "FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": "Qinggang Zhang and Zhishang Xiang contributed equally to this work.\n  Corresponding author: Jinsong Su", "summary": "Large language models (LLMs) augmented with retrieval systems have\ndemonstrated significant potential in handling knowledge-intensive tasks.\nHowever, these models often struggle with unfaithfulness issues, generating\noutputs that either ignore the retrieved context or inconsistently blend it\nwith the LLM`s parametric knowledge. This issue is particularly severe in cases\nof knowledge conflict, where the retrieved context conflicts with the model`s\nparametric knowledge. While existing faithful RAG approaches enforce strict\ncontext adherence through well-designed prompts or modified decoding\nstrategies, our analysis reveals a critical limitation: they achieve\nfaithfulness by forcibly suppressing the model`s parametric knowledge, which\nundermines the model`s internal knowledge structure and increases the risk of\nmisinterpreting the context. To this end, this paper proposes FaithfulRAG, a\nnovel framework that resolves knowledge conflicts by explicitly modeling\ndiscrepancies between the model`s parametric knowledge and retrieved context.\nSpecifically, FaithfulRAG identifies conflicting knowledge at the fact level\nand designs a self-thinking process, allowing LLMs to reason about and\nintegrate conflicting facts before generating responses. Extensive experiments\ndemonstrate that our method outperforms state-of-the-art methods. The code is\navailable at https:// github.com/DeepLearnXMU/Faithful-RAG", "AI": {"tldr": "FaithfulRAG is a new framework addressing unfaithfulness in retrieval-augmented LLMs by modeling knowledge conflicts and enabling reasoning before response generation.", "motivation": "Existing methods suppress LLMs' parametric knowledge to enforce faithfulness, risking misinterpretation and undermining internal knowledge.", "method": "FaithfulRAG identifies fact-level conflicts and uses a self-thinking process for reasoning and integration.", "result": "Outperforms state-of-the-art methods in experiments.", "conclusion": "FaithfulRAG effectively resolves knowledge conflicts while preserving LLMs' parametric knowledge."}}
{"id": "2506.08797", "pdf": "https://arxiv.org/pdf/2506.08797", "abs": "https://arxiv.org/abs/2506.08797", "authors": ["Ziyao Huang", "Zixiang Zhou", "Juan Cao", "Yifeng Ma", "Yi Chen", "Zejing Rao", "Zhiyong Xu", "Hongmei Wang", "Qin Lin", "Yuan Zhou", "Qinglin Lu", "Fan Tang"], "title": "HunyuanVideo-HOMA: Generic Human-Object Interaction in Multimodal Driven Human Animation", "categories": ["cs.CV"], "comment": null, "summary": "To address key limitations in human-object interaction (HOI) video generation\n-- specifically the reliance on curated motion data, limited generalization to\nnovel objects/scenarios, and restricted accessibility -- we introduce\nHunyuanVideo-HOMA, a weakly conditioned multimodal-driven framework.\nHunyuanVideo-HOMA enhances controllability and reduces dependency on precise\ninputs through sparse, decoupled motion guidance. It encodes appearance and\nmotion signals into the dual input space of a multimodal diffusion transformer\n(MMDiT), fusing them within a shared context space to synthesize temporally\nconsistent and physically plausible interactions. To optimize training, we\nintegrate a parameter-space HOI adapter initialized from pretrained MMDiT\nweights, preserving prior knowledge while enabling efficient adaptation, and a\nfacial cross-attention adapter for anatomically accurate audio-driven lip\nsynchronization. Extensive experiments confirm state-of-the-art performance in\ninteraction naturalness and generalization under weak supervision. Finally,\nHunyuanVideo-HOMA demonstrates versatility in text-conditioned generation and\ninteractive object manipulation, supported by a user-friendly demo interface.\nThe project page is at https://anonymous.4open.science/w/homa-page-0FBE/.", "AI": {"tldr": "HunyuanVideo-HOMA is a weakly conditioned multimodal-driven framework for HOI video generation, improving controllability and generalization with sparse motion guidance and dual input encoding.", "motivation": "Addressing limitations in HOI video generation, such as reliance on curated data, limited generalization, and accessibility issues.", "method": "Uses a multimodal diffusion transformer (MMDiT) with dual input space for appearance and motion, plus HOI and facial adapters for efficient training and lip sync.", "result": "Achieves state-of-the-art performance in interaction naturalness and generalization under weak supervision.", "conclusion": "Demonstrates versatility in text-conditioned generation and interactive manipulation, supported by a user-friendly interface."}}
{"id": "2506.08460", "pdf": "https://arxiv.org/pdf/2506.08460", "abs": "https://arxiv.org/abs/2506.08460", "authors": ["Yihong Guo", "Yu Yang", "Pan Xu", "Anqi Liu"], "title": "MOBODY: Model Based Off-Dynamics Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study the off-dynamics offline reinforcement learning problem, where the\ngoal is to learn a policy from offline datasets collected from source and\ntarget domains with mismatched transition. Existing off-dynamics offline RL\nmethods typically either filter source transitions that resemble those of the\ntarget domain or apply reward augmentation to source data, both constrained by\nthe limited transitions available from the target domain. As a result, the\nlearned policy is unable to explore target domain beyond the offline datasets.\nWe propose MOBODY, a Model-Based Off-Dynamics offline RL algorithm that\naddresses this limitation by enabling exploration of the target domain via\nlearned dynamics. MOBODY generates new synthetic transitions in the target\ndomain through model rollouts, which are used as data augmentation during\noffline policy learning. Unlike existing model-based methods that learn\ndynamics from a single domain, MOBODY tackles the challenge of mismatched\ndynamics by leveraging both source and target datasets. Directly merging these\ndatasets can bias the learned model toward source dynamics. Instead, MOBODY\nlearns target dynamics by discovering a shared latent representation of states\nand transitions across domains through representation learning. To stabilize\ntraining, MOBODY incorporates a behavior cloning loss that regularizes the\npolicy. Specifically, we introduce a Q-weighted behavior cloning loss that\nregularizes the policy toward actions with high target-domain Q-values, rather\nthan uniformly imitating all actions in the dataset. These Q-values are learned\nfrom an enhanced target dataset composed of offline target data, augmented\nsource data, and rollout data from the learned target dynamics. We evaluate\nMOBODY on MuJoCo benchmarks and show that it significantly outperforms\nstate-of-the-art baselines, with especially pronounced improvements in\nchallenging scenarios.", "AI": {"tldr": "MOBODY is a Model-Based Off-Dynamics offline RL algorithm that leverages learned dynamics and representation learning to explore target domains beyond offline datasets, outperforming existing methods.", "motivation": "Existing off-dynamics offline RL methods are limited by target domain transitions, restricting policy exploration. MOBODY aims to overcome this by generating synthetic transitions and learning shared latent representations.", "method": "MOBODY uses model rollouts to create synthetic target-domain transitions, learns shared latent representations to handle mismatched dynamics, and employs a Q-weighted behavior cloning loss for stable training.", "result": "MOBODY outperforms state-of-the-art baselines on MuJoCo benchmarks, especially in challenging scenarios.", "conclusion": "MOBODY effectively addresses the limitations of existing methods by enabling target-domain exploration and leveraging representation learning, achieving superior performance."}}
{"id": "2506.08463", "pdf": "https://arxiv.org/pdf/2506.08463", "abs": "https://arxiv.org/abs/2506.08463", "authors": ["Zhishuai Liu", "Yu Yang", "Ruhan Wang", "Pan Xu", "Dongruo Zhou"], "title": "How to Provably Improve Return Conditioned Supervised Learning?", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "25 pages, 4 figures, 12 tables", "summary": "In sequential decision-making problems, Return-Conditioned Supervised\nLearning (RCSL) has gained increasing recognition for its simplicity and\nstability in modern decision-making tasks. Unlike traditional offline\nreinforcement learning (RL) algorithms, RCSL frames policy learning as a\nsupervised learning problem by taking both the state and return as input. This\napproach eliminates the instability often associated with temporal difference\n(TD) learning in offline RL. However, RCSL has been criticized for lacking the\nstitching property, meaning its performance is inherently limited by the\nquality of the policy used to generate the offline dataset. To address this\nlimitation, we propose a principled and simple framework called Reinforced\nRCSL. The key innovation of our framework is the introduction of a concept we\ncall the in-distribution optimal return-to-go. This mechanism leverages our\npolicy to identify the best achievable in-dataset future return based on the\ncurrent state, avoiding the need for complex return augmentation techniques.\nOur theoretical analysis demonstrates that Reinforced RCSL can consistently\noutperform the standard RCSL approach. Empirical results further validate our\nclaims, showing significant performance improvements across a range of\nbenchmarks.", "AI": {"tldr": "Reinforced RCSL improves RCSL by introducing in-distribution optimal return-to-go, outperforming standard RCSL in benchmarks.", "motivation": "RCSL lacks the stitching property, limiting performance based on dataset quality. Reinforced RCSL addresses this.", "method": "Introduces in-distribution optimal return-to-go to identify achievable future returns without complex augmentation.", "result": "Theoretical and empirical results show Reinforced RCSL outperforms standard RCSL.", "conclusion": "Reinforced RCSL offers a simple, effective solution to RCSL's limitations, enhancing performance in sequential decision-making."}}
{"id": "2506.08952", "pdf": "https://arxiv.org/pdf/2506.08952", "abs": "https://arxiv.org/abs/2506.08952", "authors": ["Clara Lachenmaier", "Judith Sieker", "Sina Zarrie\u00df"], "title": "Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint accepted at ACL Main Conference 2025", "summary": "Communication among humans relies on conversational grounding, allowing\ninterlocutors to reach mutual understanding even when they do not have perfect\nknowledge and must resolve discrepancies in each other's beliefs. This paper\ninvestigates how large language models (LLMs) manage common ground in cases\nwhere they (don't) possess knowledge, focusing on facts in the political domain\nwhere the risk of misinformation and grounding failure is high. We examine the\nability of LLMs to answer direct knowledge questions and loaded questions that\npresuppose misinformation. We evaluate whether loaded questions lead LLMs to\nengage in active grounding and correct false user beliefs, in connection to\ntheir level of knowledge and their political bias. Our findings highlight\nsignificant challenges in LLMs' ability to engage in grounding and reject false\nuser beliefs, raising concerns about their role in mitigating misinformation in\npolitical discourse.", "AI": {"tldr": "LLMs struggle with grounding and correcting false beliefs in political discourse, raising concerns about misinformation.", "motivation": "To investigate how LLMs handle common ground and misinformation in political contexts.", "method": "Evaluating LLMs' responses to direct and loaded questions about political facts.", "result": "LLMs often fail to correct false beliefs, showing challenges in grounding.", "conclusion": "LLMs' limitations in grounding pose risks for misinformation in political discourse."}}
{"id": "2506.08817", "pdf": "https://arxiv.org/pdf/2506.08817", "abs": "https://arxiv.org/abs/2506.08817", "authors": ["Shuyi Zhang", "Xiaoshuai Hao", "Yingbo Tang", "Lingfeng Zhang", "Pengwei Wang", "Zhongyuan Wang", "Hongxuan Ma", "Shanghang Zhang"], "title": "Video-CoT: A Comprehensive Dataset for Spatiotemporal Understanding of Videos Based on Chain-of-Thought", "categories": ["cs.CV"], "comment": null, "summary": "Video content comprehension is essential for various applications, ranging\nfrom video analysis to interactive systems. Despite advancements in large-scale\nvision-language models (VLMs), these models often struggle to capture the\nnuanced, spatiotemporal details essential for thorough video analysis. To\naddress this gap, we introduce Video-CoT, a groundbreaking dataset designed to\nenhance spatiotemporal understanding using Chain-of-Thought (CoT)\nmethodologies. Video-CoT contains 192,000 fine-grained spa-tiotemporal\nquestion-answer pairs and 23,000 high-quality CoT-annotated samples, providing\na solid foundation for evaluating spatiotemporal understanding in video\ncomprehension. Additionally, we provide a comprehensive benchmark for assessing\nthese tasks, with each task featuring 750 images and tailored evaluation\nmetrics. Our extensive experiments reveal that current VLMs face significant\nchallenges in achieving satisfactory performance, high-lighting the\ndifficulties of effective spatiotemporal understanding. Overall, the Video-CoT\ndataset and benchmark open new avenues for research in multimedia understanding\nand support future innovations in intelligent systems requiring advanced video\nanalysis capabilities. By making these resources publicly available, we aim to\nencourage further exploration in this critical area. Project\nwebsite:https://video-cot.github.io/ .", "AI": {"tldr": "Video-CoT is a new dataset and benchmark for improving spatiotemporal understanding in video analysis using Chain-of-Thought methodologies, revealing challenges for current vision-language models.", "motivation": "Current vision-language models struggle with nuanced spatiotemporal details in video analysis, necessitating a dedicated dataset and benchmark.", "method": "Introduces Video-CoT, a dataset with 192,000 question-answer pairs and 23,000 CoT-annotated samples, plus a benchmark for evaluation.", "result": "Experiments show current VLMs perform poorly on spatiotemporal tasks, highlighting the difficulty of such understanding.", "conclusion": "Video-CoT advances research in video comprehension and supports future intelligent systems, with resources made public for further exploration."}}
{"id": "2506.08505", "pdf": "https://arxiv.org/pdf/2506.08505", "abs": "https://arxiv.org/abs/2506.08505", "authors": ["Shahaf Bassan", "Yizhak Yisrael Elboher", "Tobias Ladner", "Matthias Althoff", "Guy Katz"], "title": "Explaining, Fast and Slow: Abstraction and Refinement of Provable Explanations", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "To appear in ICML 2025", "summary": "Despite significant advancements in post-hoc explainability techniques for\nneural networks, many current methods rely on heuristics and do not provide\nformally provable guarantees over the explanations provided. Recent work has\nshown that it is possible to obtain explanations with formal guarantees by\nidentifying subsets of input features that are sufficient to determine that\npredictions remain unchanged using neural network verification techniques.\nDespite the appeal of these explanations, their computation faces significant\nscalability challenges. In this work, we address this gap by proposing a novel\nabstraction-refinement technique for efficiently computing provably sufficient\nexplanations of neural network predictions. Our method abstracts the original\nlarge neural network by constructing a substantially reduced network, where a\nsufficient explanation of the reduced network is also provably sufficient for\nthe original network, hence significantly speeding up the verification process.\nIf the explanation is in sufficient on the reduced network, we iteratively\nrefine the network size by gradually increasing it until convergence. Our\nexperiments demonstrate that our approach enhances the efficiency of obtaining\nprovably sufficient explanations for neural network predictions while\nadditionally providing a fine-grained interpretation of the network's\npredictions across different abstraction levels.", "AI": {"tldr": "Proposes an abstraction-refinement technique to efficiently compute provably sufficient explanations for neural network predictions, improving scalability.", "motivation": "Current post-hoc explainability methods lack formal guarantees and face scalability issues when computing provable explanations.", "method": "Uses an abstraction-refinement approach: constructs a reduced network for faster verification, iteratively refines if needed.", "result": "Enhances efficiency in obtaining provably sufficient explanations and provides fine-grained interpretation across abstraction levels.", "conclusion": "The method addresses scalability challenges while maintaining formal guarantees for explanations."}}
{"id": "2506.08464", "pdf": "https://arxiv.org/pdf/2506.08464", "abs": "https://arxiv.org/abs/2506.08464", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "MAC: An Efficient Gradient Preconditioning using Mean Activation Approximated Curvature", "categories": ["cs.LG"], "comment": null, "summary": "Second-order optimization methods for training neural networks, such as KFAC,\nexhibit superior convergence by utilizing curvature information of loss\nlandscape. However, it comes at the expense of high computational burden. In\nthis work, we analyze the two components that constitute the layer-wise Fisher\ninformation matrix (FIM) used in KFAC: the Kronecker factors related to\nactivations and pre-activation gradients. Based on empirical observations on\ntheir eigenspectra, we propose efficient approximations for them, resulting in\na computationally efficient optimization method called MAC. To the best of our\nknowledge, MAC is the first algorithm to apply the Kronecker factorization to\nthe FIM of attention layers used in transformers and explicitly integrate\nattention scores into the preconditioning. We also study the convergence\nproperty of MAC on nonlinear neural networks and provide two conditions under\nwhich it converges to global minima. Our extensive evaluations on various\nnetwork architectures and datasets show that the proposed method outperforms\nKFAC and other state-of-the-art methods in terms of accuracy, end-to-end\ntraining time, and memory usage. Code is available at\nhttps://github.com/hseung88/mac.", "AI": {"tldr": "The paper proposes MAC, an efficient second-order optimization method for neural networks, improving upon KFAC by approximating Kronecker factors in the Fisher information matrix (FIM). MAC outperforms KFAC and other methods in accuracy, training time, and memory usage.", "motivation": "Second-order methods like KFAC improve convergence but are computationally expensive. The paper aims to reduce this burden by analyzing and approximating components of the FIM.", "method": "The authors analyze Kronecker factors (activations and gradients) in the FIM, propose efficient approximations, and apply them to attention layers in transformers, integrating attention scores into preconditioning.", "result": "MAC outperforms KFAC and other state-of-the-art methods in accuracy, training time, and memory usage across various architectures and datasets.", "conclusion": "MAC is a computationally efficient second-order optimization method with proven convergence properties, offering superior performance for training neural networks."}}
{"id": "2506.08966", "pdf": "https://arxiv.org/pdf/2506.08966", "abs": "https://arxiv.org/abs/2506.08966", "authors": ["Marek Kadl\u010d\u00edk", "Michal \u0160tef\u00e1nik", "Timothee Mickus", "Michal Spiegel", "Josef Kucha\u0159"], "title": "Pre-trained Language Models Learn Remarkably Accurate Representations of Numbers", "categories": ["cs.CL", "cs.LG", "cs.NE"], "comment": null, "summary": "Pretrained language models (LMs) are prone to arithmetic errors. Existing\nwork showed limited success in probing numeric values from models'\nrepresentations, indicating that these errors can be attributed to the inherent\nunreliability of distributionally learned embeddings in representing exact\nquantities. However, we observe that previous probing methods are inadequate\nfor the emergent structure of learned number embeddings with sinusoidal\npatterns.\n  In response, we propose a novel probing technique that decodes numeric values\nfrom input embeddings with near-perfect accuracy across a range of open-source\nLMs. This proves that after the sole pre-training, LMs represent numbers with\nremarkable precision. Finally, we find that the embeddings' preciseness judged\nby our probe's accuracy explains a large portion of LM's errors in elementary\narithmetic, and show that aligning the embeddings with the pattern discovered\nby our probe can mitigate these errors.", "AI": {"tldr": "A novel probing technique reveals that pretrained LMs accurately represent numbers, and aligning embeddings with this pattern can reduce arithmetic errors.", "motivation": "Pretrained LMs often make arithmetic errors, and existing probing methods fail to capture the sinusoidal patterns in number embeddings.", "method": "Proposed a new probing technique to decode numeric values from embeddings with high accuracy.", "result": "LMs represent numbers precisely after pre-training, and embedding precision correlates with arithmetic errors.", "conclusion": "Aligning embeddings with the discovered pattern can mitigate arithmetic errors in LMs."}}
{"id": "2506.08835", "pdf": "https://arxiv.org/pdf/2506.08835", "abs": "https://arxiv.org/abs/2506.08835", "authors": ["Shravan Nayak", "Mehar Bhatia", "Xiaofeng Zhang", "Verena Rieser", "Lisa Anne Hendricks", "Sjoerd van Steenkiste", "Yash Goyal", "Karolina Sta\u0144czak", "Aishwarya Agrawal"], "title": "CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The increasing ubiquity of text-to-image (T2I) models as tools for visual\ncontent generation raises concerns about their ability to accurately represent\ndiverse cultural contexts. In this work, we present the first study to\nsystematically quantify the alignment of T2I models and evaluation metrics with\nrespect to both explicit as well as implicit cultural expectations. To this\nend, we introduce CulturalFrames, a novel benchmark designed for rigorous human\nevaluation of cultural representation in visual generations. Spanning 10\ncountries and 5 socio-cultural domains, CulturalFrames comprises 983 prompts,\n3637 corresponding images generated by 4 state-of-the-art T2I models, and over\n10k detailed human annotations. We find that T2I models not only fail to meet\nthe more challenging implicit expectations but also the less challenging\nexplicit expectations. Across models and countries, cultural expectations are\nmissed an average of 44% of the time. Among these failures, explicit\nexpectations are missed at a surprisingly high average rate of 68%, while\nimplicit expectation failures are also significant, averaging 49%. Furthermore,\nwe demonstrate that existing T2I evaluation metrics correlate poorly with human\njudgments of cultural alignment, irrespective of their internal reasoning.\nCollectively, our findings expose critical gaps, providing actionable\ndirections for developing more culturally informed T2I models and evaluation\nmethodologies.", "AI": {"tldr": "The study quantifies cultural misalignment in text-to-image (T2I) models, revealing significant failures in meeting explicit (68%) and implicit (49%) cultural expectations. It introduces CulturalFrames, a benchmark for human evaluation, and highlights poor correlation of existing metrics with human judgments.", "motivation": "Concerns about T2I models' ability to represent diverse cultural contexts accurately drive the need for systematic evaluation.", "method": "CulturalFrames, a benchmark spanning 10 countries and 5 socio-cultural domains, is used to evaluate 4 T2I models with 983 prompts, 3637 images, and 10k human annotations.", "result": "T2I models miss cultural expectations 44% of the time, with explicit failures at 68% and implicit at 49%. Existing metrics poorly correlate with human judgments.", "conclusion": "The study identifies gaps in cultural representation, urging development of more culturally informed T2I models and evaluation methods."}}
{"id": "2506.08533", "pdf": "https://arxiv.org/pdf/2506.08533", "abs": "https://arxiv.org/abs/2506.08533", "authors": ["Nihal Acharya Adde", "Alexandra Gianzina", "Hanno Gottschalk", "Andreas Ebert"], "title": "Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "Published at ESANN 2025 Conference", "summary": "This paper introduces Evolutionary Multi-Objective Network Architecture\nSearch (EMNAS) for the first time to optimize neural network architectures in\nlarge-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS uses\ngenetic algorithms to automate network design, tailored to enhance rewards and\nreduce model size without compromising performance. Additionally,\nparallelization techniques are employed to accelerate the search, and\nteacher-student methodologies are implemented to ensure scalable optimization.\nThis research underscores the potential of transfer learning as a robust\nframework for optimizing performance across iterative learning processes by\neffectively leveraging knowledge from earlier generations to enhance learning\nefficiency and stability in subsequent generations. Experimental results\ndemonstrate that tailored EMNAS outperforms manually designed models, achieving\nhigher rewards with fewer parameters. The findings of these strategies\ncontribute positively to EMNAS for RL in autonomous driving, advancing the\nfield toward better-performing networks suitable for real-world scenarios.", "AI": {"tldr": "EMNAS uses genetic algorithms to optimize neural networks for RL in autonomous driving, improving rewards and reducing model size. Parallelization and teacher-student methods enhance scalability and efficiency.", "motivation": "To automate and optimize neural network design for RL in autonomous driving, improving performance and efficiency.", "method": "Genetic algorithms for architecture search, parallelization for speed, and teacher-student methods for scalable optimization.", "result": "EMNAS outperforms manual designs, achieving higher rewards with fewer parameters.", "conclusion": "EMNAS advances RL for autonomous driving, offering better-performing networks for real-world applications."}}
{"id": "2506.08473", "pdf": "https://arxiv.org/pdf/2506.08473", "abs": "https://arxiv.org/abs/2506.08473", "authors": ["Shuo Yang", "Qihui Zhang", "Yuyang Liu", "Yue Huang", "Xiaojun Jia", "Kunpeng Ning", "Jiayu Yao", "Jigang Wang", "Hailiang Dai", "Yibing Song", "Li Yuan"], "title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) are vulnerable to safety risks during\nfine-tuning, where small amounts of malicious or harmless data can compromise\nsafeguards. In this paper, building on the concept of alignment direction --\ndefined by the weight difference between aligned and unaligned models -- we\nobserve that perturbations along this direction preserve model safety. In\ncontrast, perturbations along directions orthogonal to this alignment are\nstrongly linked to harmful direction perturbations, rapidly degrading safety\nand framing the parameter space as a narrow safety basin. Based on this\ninsight, we propose a methodology for safety fine-tuning called AsFT (Anchoring\nSafety in Fine-Tuning), which integrates a regularization term into the\ntraining objective. This term uses the alignment direction as an anchor to\nsuppress updates in harmful directions, ensuring that fine-tuning is\nconstrained within the narrow safety basin. Extensive experiments on multiple\ndatasets show that AsFT outperforms Safe LoRA, reducing harmful behavior by\n7.60 percent, improving model performance by 3.44 percent, and maintaining\nrobust performance across various experimental settings. Code is available at\nhttps://github.com/PKU-YuanGroup/AsFT", "AI": {"tldr": "AsFT (Anchoring Safety in Fine-Tuning) is a method to enhance LLM safety during fine-tuning by using alignment direction as an anchor to suppress harmful updates, outperforming Safe LoRA in reducing harmful behavior and improving performance.", "motivation": "LLMs are vulnerable to safety risks during fine-tuning, where even small malicious or harmless data can compromise safeguards.", "method": "Proposes AsFT, which integrates a regularization term using alignment direction to suppress harmful updates, constraining fine-tuning within a narrow safety basin.", "result": "AsFT reduces harmful behavior by 7.60%, improves model performance by 3.44%, and maintains robustness across settings.", "conclusion": "AsFT effectively anchors safety in fine-tuning, outperforming existing methods and ensuring robust performance."}}
{"id": "2506.08972", "pdf": "https://arxiv.org/pdf/2506.08972", "abs": "https://arxiv.org/abs/2506.08972", "authors": ["Yuan Guo", "Tingjia Miao", "Zheng Wu", "Pengzhou Cheng", "Ming Zhou", "Zhuosheng Zhang"], "title": "Atomic-to-Compositional Generalization for Mobile Agents with A New Benchmark and Scheduling System", "categories": ["cs.CL"], "comment": null, "summary": "Autonomous agents powered by multimodal large language models have been\ndeveloped to facilitate task execution on mobile devices. However, prior work\nhas predominantly focused on atomic tasks -- such as shot-chain execution tasks\nand single-screen grounding tasks -- while overlooking the generalization to\ncompositional tasks, which are indispensable for real-world applications. This\nwork introduces UI-NEXUS, a comprehensive benchmark designed to evaluate mobile\nagents on three categories of compositional operations: Simple Concatenation,\nContext Transition, and Deep Dive. UI-NEXUS supports interactive evaluation in\n20 fully controllable local utility app environments, as well as 30 online\nChinese and English service apps. It comprises 100 interactive task templates\nwith an average optimal step count of 14.05. Experimental results across a\nrange of mobile agents with agentic workflow or agent-as-a-model show that\nUI-NEXUS presents significant challenges. Specifically, existing agents\ngenerally struggle to balance performance and efficiency, exhibiting\nrepresentative failure modes such as under-execution, over-execution, and\nattention drift, causing visible atomic-to-compositional generalization gap.\nInspired by these findings, we propose AGENT-NEXUS, a lightweight and efficient\nscheduling system to tackle compositional mobile tasks. AGENT-NEXUS\nextrapolates the abilities of existing mobile agents by dynamically decomposing\nlong-horizon tasks to a series of self-contained atomic subtasks. AGENT-NEXUS\nachieves 24% to 40% task success rate improvement for existing mobile agents on\ncompositional operation tasks within the UI-NEXUS benchmark without\nsignificantly sacrificing inference overhead. The demo video, dataset, and code\nare available on the project page at https://ui-nexus.github.io.", "AI": {"tldr": "UI-NEXUS is a benchmark for evaluating mobile agents on compositional tasks, revealing challenges like under/over-execution. AGENT-NEXUS, a proposed scheduling system, improves task success rates by 24-40%.", "motivation": "Prior work focused on atomic tasks, neglecting compositional tasks crucial for real-world applications.", "method": "UI-NEXUS benchmark evaluates agents on three compositional operations. AGENT-NEXUS dynamically decomposes tasks into subtasks.", "result": "Existing agents struggle with performance-efficiency balance. AGENT-NEXUS improves success rates by 24-40%.", "conclusion": "AGENT-NEXUS effectively addresses compositional task challenges, enhancing mobile agent performance."}}
{"id": "2506.08849", "pdf": "https://arxiv.org/pdf/2506.08849", "abs": "https://arxiv.org/abs/2506.08849", "authors": ["Jingguo Qu", "Xinyang Han", "Tonghuan Xiao", "Jia Ai", "Juan Wu", "Tong Zhao", "Jing Qin", "Ann Dorothy King", "Winnie Chiu-Wing Chu", "Jing Cai", "Michael Tin-Cheung Ying\u0131nst"], "title": "Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Medical ultrasonography is an essential imaging technique for examining\nsuperficial organs and tissues, including lymph nodes, breast, and thyroid. It\nemploys high-frequency ultrasound waves to generate detailed images of the\ninternal structures of the human body. However, manually contouring regions of\ninterest in these images is a labor-intensive task that demands expertise and\noften results in inconsistent interpretations among individuals.\nVision-language foundation models, which have excelled in various computer\nvision applications, present new opportunities for enhancing ultrasound image\nanalysis. Yet, their performance is hindered by the significant differences\nbetween natural and medical imaging domains. This research seeks to overcome\nthese challenges by developing domain adaptation methods for vision-language\nfoundation models. In this study, we explore the fine-tuning pipeline for\nvision-language foundation models by utilizing large language model as text\nrefiner with special-designed adaptation strategies and task-driven heads. Our\napproach has been extensively evaluated on six ultrasound datasets and two\ntasks: segmentation and classification. The experimental results show that our\nmethod can effectively improve the performance of vision-language foundation\nmodels for ultrasound image analysis, and outperform the existing\nstate-of-the-art vision-language and pure foundation models. The source code of\nthis study is available at\n\\href{https://github.com/jinggqu/NextGen-UIA}{GitHub}.", "AI": {"tldr": "The paper proposes domain adaptation methods for vision-language foundation models to enhance ultrasound image analysis, achieving superior performance in segmentation and classification tasks.", "motivation": "Manual contouring in medical ultrasonography is labor-intensive and inconsistent. Vision-language models show promise but struggle with domain differences between natural and medical images.", "method": "Fine-tuning pipeline for vision-language models using a large language model as text refiner, with adaptation strategies and task-driven heads.", "result": "Outperforms state-of-the-art models on six ultrasound datasets for segmentation and classification.", "conclusion": "The approach effectively bridges domain gaps, improving ultrasound image analysis performance."}}
{"id": "2506.08563", "pdf": "https://arxiv.org/pdf/2506.08563", "abs": "https://arxiv.org/abs/2506.08563", "authors": ["Siyuan Yang", "Cheng Song", "Zhilu Lai", "Wenjia Wang"], "title": "KP-PINNs: Kernel Packet Accelerated Physics Informed Neural Networks", "categories": ["cs.CE", "cs.AI", "math-ph", "math.MP", "physics.comp-ph"], "comment": "Accepted to IJCAI 2025", "summary": "Differential equations are involved in modeling many engineering problems.\nMany efforts have been devoted to solving differential equations. Due to the\nflexibility of neural networks, Physics Informed Neural Networks (PINNs) have\nrecently been proposed to solve complex differential equations and have\ndemonstrated superior performance in many applications. While the L2 loss\nfunction is usually a default choice in PINNs, it has been shown that the\ncorresponding numerical solution is incorrect and unstable for some complex\nequations. In this work, we propose a new PINNs framework named Kernel Packet\naccelerated PINNs (KP-PINNs), which gives a new expression of the loss function\nusing the reproducing kernel Hilbert space (RKHS) norm and uses the Kernel\nPacket (KP) method to accelerate the computation. Theoretical results show that\nKP-PINNs can be stable across various differential equations. Numerical\nexperiments illustrate that KP-PINNs can solve differential equations\neffectively and efficiently. This framework provides a promising direction for\nimproving the stability and accuracy of PINNs-based solvers in scientific\ncomputing.", "AI": {"tldr": "KP-PINNs improve PINNs by introducing a new loss function using RKHS norm and Kernel Packet method, enhancing stability and accuracy in solving differential equations.", "motivation": "Address the instability and incorrect solutions in PINNs when using the default L2 loss function for complex differential equations.", "method": "Propose KP-PINNs, a framework with a new loss function based on RKHS norm and accelerated by the Kernel Packet method.", "result": "Theoretical stability across equations and numerical effectiveness in solving differential equations.", "conclusion": "KP-PINNs offer a promising approach to enhance PINNs' stability and accuracy in scientific computing."}}
{"id": "2506.08475", "pdf": "https://arxiv.org/pdf/2506.08475", "abs": "https://arxiv.org/abs/2506.08475", "authors": ["Xiaolong He", "Yeonjong Shin", "Anthony Gruber", "Sohyeon Jung", "Kookjin Lee", "Youngsoo Choi"], "title": "Thermodynamically Consistent Latent Dynamics Identification for Parametric Systems", "categories": ["cs.LG", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "We propose an efficient thermodynamics-informed latent space dynamics\nidentification (tLaSDI) framework for the reduced-order modeling of parametric\nnonlinear dynamical systems. This framework integrates autoencoders for\ndimensionality reduction with newly developed parametric GENERIC\nformalism-informed neural networks (pGFINNs), which enable efficient learning\nof parametric latent dynamics while preserving key thermodynamic principles\nsuch as free energy conservation and entropy generation across the parameter\nspace. To further enhance model performance, a physics-informed active learning\nstrategy is incorporated, leveraging a greedy, residual-based error indicator\nto adaptively sample informative training data, outperforming uniform sampling\nat equivalent computational cost. Numerical experiments on the Burgers'\nequation and the 1D/1V Vlasov-Poisson equation demonstrate that the proposed\nmethod achieves up to 3,528x speed-up with 1-3% relative errors, and\nsignificant reduction in training (50-90%) and inference (57-61%) cost.\nMoreover, the learned latent space dynamics reveal the underlying thermodynamic\nbehavior of the system, offering valuable insights into the physical-space\ndynamics.", "AI": {"tldr": "The paper introduces tLaSDI, a thermodynamics-informed framework for reduced-order modeling of nonlinear systems, combining autoencoders and pGFINNs to preserve thermodynamic principles while achieving high efficiency.", "motivation": "To address the challenge of efficiently modeling parametric nonlinear dynamical systems while preserving thermodynamic principles like energy conservation and entropy generation.", "method": "Integrates autoencoders for dimensionality reduction with pGFINNs for learning parametric latent dynamics, and uses physics-informed active learning for adaptive data sampling.", "result": "Achieves up to 3,528x speed-up with 1-3% relative errors, reduces training (50-90%) and inference (57-61%) costs, and reveals thermodynamic behavior in latent dynamics.", "conclusion": "tLaSDI is a highly efficient and accurate framework for reduced-order modeling, offering insights into thermodynamic behavior and outperforming traditional methods."}}
{"id": "2506.08981", "pdf": "https://arxiv.org/pdf/2506.08981", "abs": "https://arxiv.org/abs/2506.08981", "authors": ["Satu Hopponen", "Tomi Kinnunen", "Alexandre Nikolaev", "Rosa Gonz\u00e1lez Hautam\u00e4ki", "Lauri Tavi", "Einar Meister"], "title": "FROST-EMA: Finnish and Russian Oral Speech Dataset of Electromagnetic Articulography Measurements with L1, L2 and Imitated L2 Accents", "categories": ["cs.CL"], "comment": "Accepted in Interspeech 2025", "summary": "We introduce a new FROST-EMA (Finnish and Russian Oral Speech Dataset of\nElectromagnetic Articulography) corpus. It consists of 18 bilingual speakers,\nwho produced speech in their native language (L1), second language (L2), and\nimitated L2 (fake foreign accent). The new corpus enables research into\nlanguage variability from phonetic and technological points of view.\nAccordingly, we include two preliminary case studies to demonstrate both\nperspectives. The first case study explores the impact of L2 and imitated L2 on\nthe performance of an automatic speaker verification system, while the second\nillustrates the articulatory patterns of one speaker in L1, L2, and a fake\naccent.", "AI": {"tldr": "The paper introduces the FROST-EMA corpus, a dataset of bilingual speech in native and second languages, including imitated accents, for phonetic and technological research. Two case studies demonstrate its utility.", "motivation": "To enable research on language variability in bilingual speech from phonetic and technological perspectives.", "method": "Creation of the FROST-EMA corpus with 18 bilingual speakers producing speech in L1, L2, and imitated L2. Two case studies: one on speaker verification performance, another on articulatory patterns.", "result": "The corpus supports analysis of language variability. Case studies show impacts on speaker verification and articulatory differences.", "conclusion": "The FROST-EMA corpus is a valuable resource for studying bilingual speech variability, with demonstrated applications in technology and phonetics."}}
{"id": "2506.08854", "pdf": "https://arxiv.org/pdf/2506.08854", "abs": "https://arxiv.org/abs/2506.08854", "authors": ["Junzhuo Liu", "Markus Eckstein", "Zhixiang Wang", "Friedrich Feuerhake", "Dorit Merhof"], "title": "Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages, 7 figures", "summary": "Spatial transcriptomics is a technology that captures gene expression levels\nat different spatial locations, widely used in tumor microenvironment analysis\nand molecular profiling of histopathology, providing valuable insights into\nresolving gene expression and clinical diagnosis of cancer. Due to the high\ncost of data acquisition, large-scale spatial transcriptomics data remain\nchallenging to obtain. In this study, we develop a contrastive learning-based\ndeep learning method to predict spatially resolved gene expression from\nwhole-slide images. Evaluation across six different disease datasets\ndemonstrates that, compared to existing studies, our method improves Pearson\nCorrelation Coefficient (PCC) in the prediction of highly expressed genes,\nhighly variable genes, and marker genes by 6.27%, 6.11%, and 11.26%\nrespectively. Further analysis indicates that our method preserves gene-gene\ncorrelations and applies to datasets with limited samples. Additionally, our\nmethod exhibits potential in cancer tissue localization based on biomarker\nexpression.", "AI": {"tldr": "A contrastive learning-based deep learning method predicts spatially resolved gene expression from whole-slide images, improving prediction accuracy for key gene types and preserving gene-gene correlations.", "motivation": "Spatial transcriptomics data is costly and scarce, yet crucial for tumor analysis and clinical diagnosis, necessitating a method to predict gene expression from more accessible whole-slide images.", "method": "A contrastive learning-based deep learning approach is developed to predict gene expression from whole-slide images, evaluated across six disease datasets.", "result": "The method improves prediction accuracy (PCC) for highly expressed, highly variable, and marker genes by 6.27%, 6.11%, and 11.26% respectively, and preserves gene-gene correlations.", "conclusion": "The method is effective for predicting gene expression from images, even with limited samples, and shows promise for cancer tissue localization."}}
{"id": "2506.08569", "pdf": "https://arxiv.org/pdf/2506.08569", "abs": "https://arxiv.org/abs/2506.08569", "authors": ["Erwan Plantec", "Gautier Hamon", "Mayalen Etcheverry", "Bert Wang-Chak Chan", "Pierre-Yves Oudeyer", "Cl\u00e9ment Moulin-Frier"], "title": "Flow-Lenia: Emergent evolutionary dynamics in mass conservative continuous cellular automata", "categories": ["nlin.CG", "cs.AI"], "comment": "This manuscript has been accepted for publication in the Artificial\n  Life journal (https://direct.mit.edu/artl)", "summary": "Central to the artificial life endeavour is the creation of artificial\nsystems spontaneously generating properties found in the living world such as\nautopoiesis, self-replication, evolution and open-endedness. While numerous\nmodels and paradigms have been proposed, cellular automata (CA) have taken a\nvery important place in the field notably as they enable the study of\nphenomenons like self-reproduction and autopoiesis. Continuous CA like Lenia\nhave been showed to produce life-like patterns reminiscent, on an aesthetic and\nontological point of view, of biological organisms we call creatures. We\npropose in this paper Flow-Lenia, a mass conservative extension of Lenia. We\npresent experiments demonstrating its effectiveness in generating\nspatially-localized patters (SLPs) with complex behaviors and show that the\nupdate rule parameters can be optimized to generate complex creatures showing\nbehaviors of interest. Furthermore, we show that Flow-Lenia allows us to embed\nthe parameters of the model, defining the properties of the emerging patterns,\nwithin its own dynamics thus allowing for multispecies simulations. By using\nthe evolutionary activity framework as well as other metrics, we shed light on\nthe emergent evolutionary dynamics taking place in this system.", "AI": {"tldr": "Flow-Lenia, a mass-conservative extension of Lenia, generates complex life-like patterns and supports multispecies simulations with emergent evolutionary dynamics.", "motivation": "To advance artificial life by creating systems that spontaneously exhibit life-like properties such as autopoiesis and evolution, using cellular automata like Lenia.", "method": "Proposes Flow-Lenia, an extension of Lenia, with experiments optimizing update rules to produce spatially-localized patterns and multispecies dynamics.", "result": "Demonstrates effectiveness in generating complex behaviors and patterns, with embedded parameters enabling multispecies simulations and emergent evolutionary dynamics.", "conclusion": "Flow-Lenia successfully extends Lenia, offering new insights into artificial life and evolutionary dynamics through its mass-conservative framework."}}
{"id": "2506.08514", "pdf": "https://arxiv.org/pdf/2506.08514", "abs": "https://arxiv.org/abs/2506.08514", "authors": ["Jacob Piland", "Chris Sweet", "Adam Czakja"], "title": "DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training", "categories": ["cs.LG"], "comment": null, "summary": "Class Activation Mapping (CAM) and its gradient-based variants (e.g.,\nGradCAM) have become standard tools for explaining Convolutional Neural Network\n(CNN) predictions. However, these approaches typically focus on individual\nlogits, while for neural networks using softmax, the class membership\nprobability estimates depend \\textit{only} on the \\textit{differences} between\nlogits, not on their absolute values. This disconnect leaves standard CAMs\nvulnerable to adversarial manipulation, such as passive fooling, where a model\nis trained to produce misleading CAMs without affecting decision performance.\nWe introduce \\textbf{Salience-Hoax Activation Maps (SHAMs)}, an\n\\emph{entropy-aware form of passive fooling} that serves as a benchmark for CAM\nrobustness under adversarial conditions. To address the passive fooling\nvulnerability, we then propose \\textbf{DiffGradCAM}, a novel, lightweight, and\ncontrastive approach to class activation mapping that is both non-suceptible to\npassive fooling, but also matches the output of standard CAM methods such as\nGradCAM in the non-adversarial case. Together, SHAM and DiffGradCAM establish a\nnew framework for probing and improving the robustness of saliency-based\nexplanations. We validate both contributions across multi-class tasks with few\nand many classes.", "AI": {"tldr": "The paper introduces SHAMs for testing CAM robustness and DiffGradCAM, a contrastive method resistant to passive fooling, improving saliency-based explanations.", "motivation": "Standard CAM methods focus on individual logits, ignoring logit differences, making them vulnerable to adversarial manipulation like passive fooling.", "method": "Proposes SHAMs for benchmarking CAM robustness and DiffGradCAM, a lightweight, contrastive approach resistant to passive fooling.", "result": "Validated across multi-class tasks, SHAMs expose vulnerabilities, while DiffGradCAM matches standard CAMs in non-adversarial cases and resists manipulation.", "conclusion": "SHAM and DiffGradCAM form a framework for robust saliency-based explanations, addressing CAM vulnerabilities."}}
{"id": "2506.08986", "pdf": "https://arxiv.org/pdf/2506.08986", "abs": "https://arxiv.org/abs/2506.08986", "authors": ["Yuejiao Wang", "Xianmin Gong", "Xixin Wu", "Patrick Wong", "Hoi-lam Helene Fung", "Man Wai Mak", "Helen Meng"], "title": "Naturalistic Language-related Movie-Watching fMRI Task for Detecting Neurocognitive Decline and Disorder", "categories": ["cs.CL"], "comment": "5 pages,3 figures, accepted by ISCSLP 2024", "summary": "Early detection is crucial for timely intervention aimed at preventing and\nslowing the progression of neurocognitive disorder (NCD), a common and\nsignificant health problem among the aging population. Recent evidence has\nsuggested that language-related functional magnetic resonance imaging (fMRI)\nmay be a promising approach for detecting cognitive decline and early NCD. In\nthis paper, we proposed a novel, naturalistic language-related fMRI task for\nthis purpose. We examined the effectiveness of this task among 97 non-demented\nChinese older adults from Hong Kong. The results showed that machine-learning\nclassification models based on fMRI features extracted from the task and\ndemographics (age, gender, and education year) achieved an average area under\nthe curve of 0.86 when classifying participants' cognitive status (labeled as\nNORMAL vs DECLINE based on their scores on a standard neurcognitive test).\nFeature localization revealed that the fMRI features most frequently selected\nby the data-driven approach came primarily from brain regions associated with\nlanguage processing, such as the superior temporal gyrus, middle temporal\ngyrus, and right cerebellum. The study demonstrated the potential of the\nnaturalistic language-related fMRI task for early detection of aging-related\ncognitive decline and NCD.", "AI": {"tldr": "A novel language-related fMRI task was developed for early detection of cognitive decline in older adults, achieving high accuracy (AUC=0.86) using machine learning.", "motivation": "Early detection of neurocognitive disorder (NCD) is vital for timely intervention, and language-related fMRI shows promise for this purpose.", "method": "A naturalistic language-related fMRI task was tested on 97 non-demented Chinese older adults, with machine-learning models analyzing fMRI features and demographics.", "result": "The models achieved an AUC of 0.86, with key features from language-processing brain regions like the superior temporal gyrus.", "conclusion": "The study highlights the potential of language-related fMRI for early NCD detection."}}
{"id": "2506.08862", "pdf": "https://arxiv.org/pdf/2506.08862", "abs": "https://arxiv.org/abs/2506.08862", "authors": ["Zike Wu", "Qi Yan", "Xuanyu Yi", "Lele Wang", "Renjie Liao"], "title": "StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams\nis crucial for numerous real-world applications. However, existing methods\nstruggle to jointly address three key challenges: 1) processing uncalibrated\ninputs in real time, 2) accurately modeling dynamic scene evolution, and 3)\nmaintaining long-term stability and computational efficiency. To this end, we\nintroduce StreamSplat, the first fully feed-forward framework that transforms\nuncalibrated video streams of arbitrary length into dynamic 3D Gaussian\nSplatting (3DGS) representations in an online manner, capable of recovering\nscene dynamics from temporally local observations. We propose two key technical\ninnovations: a probabilistic sampling mechanism in the static encoder for 3DGS\nposition prediction, and a bidirectional deformation field in the dynamic\ndecoder that enables robust and efficient dynamic modeling. Extensive\nexperiments on static and dynamic benchmarks demonstrate that StreamSplat\nconsistently outperforms prior works in both reconstruction quality and dynamic\nscene modeling, while uniquely supporting online reconstruction of arbitrarily\nlong video streams. Code and models are available at\nhttps://github.com/nickwzk/StreamSplat.", "AI": {"tldr": "StreamSplat is a feed-forward framework for real-time 3D reconstruction from uncalibrated videos, addressing challenges like dynamic scene modeling and computational efficiency.", "motivation": "Existing methods fail to handle uncalibrated inputs, dynamic scenes, and long-term stability efficiently.", "method": "Uses probabilistic sampling in a static encoder and bidirectional deformation fields in a dynamic decoder.", "result": "Outperforms prior works in reconstruction quality and dynamic modeling, supporting online reconstruction.", "conclusion": "StreamSplat offers a robust solution for real-time dynamic 3D scene reconstruction."}}
{"id": "2506.08572", "pdf": "https://arxiv.org/pdf/2506.08572", "abs": "https://arxiv.org/abs/2506.08572", "authors": ["Waiss Azizian", "Michael Kirchhof", "Eugene Ndiaye", "Louis Bethune", "Michal Klein", "Pierre Ablin", "Marco Cuturi"], "title": "The Geometries of Truth Are Orthogonal Across Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive generalization\ncapabilities across various tasks, but their claim to practical relevance is\nstill mired by concerns on their reliability. Recent works have proposed\nexamining the activations produced by an LLM at inference time to assess\nwhether its answer to a question is correct. Some works claim that a \"geometry\nof truth\" can be learned from examples, in the sense that the activations that\ngenerate correct answers can be distinguished from those leading to mistakes\nwith a linear classifier. In this work, we underline a limitation of these\napproaches: we observe that these \"geometries of truth\" are intrinsically\ntask-dependent and fail to transfer across tasks. More precisely, we show that\nlinear classifiers trained across distinct tasks share little similarity and,\nwhen trained with sparsity-enforcing regularizers, have almost disjoint\nsupports. We show that more sophisticated approaches (e.g., using mixtures of\nprobes and tasks) fail to overcome this limitation, likely because activation\nvectors commonly used to classify answers form clearly separated clusters when\nexamined across tasks.", "AI": {"tldr": "The paper highlights that the 'geometry of truth' in LLM activations is task-specific and doesn't transfer well across tasks, limiting reliability assessments.", "motivation": "To address concerns about LLM reliability by examining if activations can universally distinguish correct answers.", "method": "Analyzing linear classifiers trained on activations across tasks, showing their dissimilarity and disjoint supports.", "result": "Task-specific 'geometries of truth' don't generalize; sophisticated methods also fail due to separated activation clusters.", "conclusion": "Reliability assessments based on activations are inherently task-dependent, limiting broader applicability."}}
{"id": "2506.08516", "pdf": "https://arxiv.org/pdf/2506.08516", "abs": "https://arxiv.org/abs/2506.08516", "authors": ["Mouadh Yagoubi", "David Danan", "Milad Leyli-Abadi", "Ahmed Mazari", "Jean-Patrick Brunet", "Abbas Kabalan", "Fabien Casenave", "Yuxin Ma", "Giovanni Catalani", "Jean Fesquet", "Jacob Helwig", "Xuan Zhang", "Haiyang Yu", "Xavier Bertrand", "Frederic Tost", "Michael Baurheim", "Joseph Morlier", "Shuiwang Ji"], "title": "NeurIPS 2024 ML4CFD Competition: Results and Retrospective Analysis", "categories": ["cs.LG"], "comment": null, "summary": "The integration of machine learning (ML) into the physical sciences is\nreshaping computational paradigms, offering the potential to accelerate\ndemanding simulations such as computational fluid dynamics (CFD). Yet,\npersistent challenges in accuracy, generalization, and physical consistency\nhinder the practical deployment of ML models in scientific domains. To address\nthese limitations and systematically benchmark progress, we organized the\nML4CFD competition, centered on surrogate modeling for aerodynamic simulations\nover two-dimensional airfoils. The competition attracted over 240 teams, who\nwere provided with a curated dataset generated via OpenFOAM and evaluated\nthrough a multi-criteria framework encompassing predictive accuracy, physical\nfidelity, computational efficiency, and out-of-distribution generalization.\nThis retrospective analysis reviews the competition outcomes, highlighting\nseveral approaches that outperformed baselines under our global evaluation\nscore. Notably, the top entry exceeded the performance of the original OpenFOAM\nsolver on aggregate metrics, illustrating the promise of ML-based surrogates to\noutperform traditional solvers under tailored criteria. Drawing from these\nresults, we analyze the key design principles of top submissions, assess the\nrobustness of our evaluation framework, and offer guidance for future\nscientific ML challenges.", "AI": {"tldr": "The ML4CFD competition benchmarked ML-based surrogate models for CFD, showing top entries outperforming traditional solvers like OpenFOAM in accuracy and efficiency.", "motivation": "To address challenges in ML accuracy, generalization, and physical consistency for scientific applications like CFD.", "method": "Organized a competition (ML4CFD) with 240 teams, using OpenFOAM-generated data and a multi-criteria evaluation framework.", "result": "Top ML models surpassed OpenFOAM in aggregate metrics, demonstrating potential for ML surrogates in scientific simulations.", "conclusion": "The competition highlights ML's promise for CFD and provides insights for future scientific ML challenges."}}
{"id": "2506.08999", "pdf": "https://arxiv.org/pdf/2506.08999", "abs": "https://arxiv.org/abs/2506.08999", "authors": ["Theo Zhang", "Madurya Suresh", "Anne S. Warlaumont", "Kasia Hitczenko", "Alejandrina Cristia", "Margaret Cychosz"], "title": "Employing self-supervised learning models for cross-linguistic child speech maturity classification", "categories": ["cs.CL", "cs.AI"], "comment": "To be published in Interspeech 2025. 5 pages, 2 figures. For\n  associated Github repository, see\n  https://github.com/spoglab-stanford/w2v2-pro-sm/tree/main/speechbrain/recipes/W2V2-LL4300-Pro-SM", "summary": "Speech technology systems struggle with many downstream tasks for child\nspeech due to small training corpora and the difficulties that child speech\npose. We apply a novel dataset, SpeechMaturity, to state-of-the-art transformer\nmodels to address a fundamental classification task: identifying child\nvocalizations. Unlike previous corpora, our dataset captures maximally\necologically-valid child vocalizations across an unprecedented sample,\ncomprising children acquiring 25+ languages in the U.S., Bolivia, Vanuatu,\nPapua New Guinea, Solomon Islands, and France. The dataset contains 242,004\nlabeled vocalizations, magnitudes larger than previous work. Models were\ntrained to distinguish between cry, laughter, mature (consonant+vowel), and\nimmature speech (just consonant or vowel). Models trained on the dataset\noutperform state-of-the-art models trained on previous datasets, achieved\nclassification accuracy comparable to humans, and were robust across rural and\nurban settings.", "AI": {"tldr": "A novel dataset, SpeechMaturity, is used to train transformer models for classifying child vocalizations, outperforming previous models and achieving human-like accuracy.", "motivation": "Addressing the challenges of child speech recognition due to limited training data and inherent difficulties in child speech.", "method": "Applied the SpeechMaturity dataset to state-of-the-art transformer models for classifying child vocalizations (cry, laughter, mature, immature speech).", "result": "Models trained on the dataset outperformed previous models, achieved human-comparable accuracy, and were robust across diverse settings.", "conclusion": "The SpeechMaturity dataset significantly improves child speech classification, demonstrating its effectiveness and ecological validity."}}
{"id": "2506.08887", "pdf": "https://arxiv.org/pdf/2506.08887", "abs": "https://arxiv.org/abs/2506.08887", "authors": ["Leqi Shen", "Guoqiang Gong", "Tianxiang Hao", "Tao He", "Yifeng Zhang", "Pengzhang Liu", "Sicheng Zhao", "Jungong Han", "Guiguang Ding"], "title": "DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "The parameter-efficient adaptation of the image-text pretraining model CLIP\nfor video-text retrieval is a prominent area of research. While CLIP is focused\non image-level vision-language matching, video-text retrieval demands\ncomprehensive understanding at the video level. Three key discrepancies emerge\nin the transfer from image-level to video-level: vision, language, and\nalignment. However, existing methods mainly focus on vision while neglecting\nlanguage and alignment. In this paper, we propose Discrepancy Reduction in\nVision, Language, and Alignment (DiscoVLA), which simultaneously mitigates all\nthree discrepancies. Specifically, we introduce Image-Video Features Fusion to\nintegrate image-level and video-level features, effectively tackling both\nvision and language discrepancies. Additionally, we generate pseudo image\ncaptions to learn fine-grained image-level alignment. To mitigate alignment\ndiscrepancies, we propose Image-to-Video Alignment Distillation, which\nleverages image-level alignment knowledge to enhance video-level alignment.\nExtensive experiments demonstrate the superiority of our DiscoVLA. In\nparticular, on MSRVTT with CLIP (ViT-B/16), DiscoVLA outperforms previous\nmethods by 1.5% in R@1, reaching a final score of 50.5% R@1. The code is\navailable at https://github.com/LunarShen/DsicoVLA.", "AI": {"tldr": "DiscoVLA addresses vision, language, and alignment discrepancies in adapting CLIP for video-text retrieval, outperforming prior methods by 1.5% in R@1 on MSRVTT.", "motivation": "Existing methods for video-text retrieval focus on vision discrepancies but neglect language and alignment, limiting performance.", "method": "DiscoVLA integrates image-video features, generates pseudo captions for fine-grained alignment, and uses image-to-video alignment distillation.", "result": "DiscoVLA achieves 50.5% R@1 on MSRVTT, surpassing previous methods by 1.5%.", "conclusion": "DiscoVLA effectively mitigates all three discrepancies, demonstrating superior performance in video-text retrieval."}}
{"id": "2506.08577", "pdf": "https://arxiv.org/pdf/2506.08577", "abs": "https://arxiv.org/abs/2506.08577", "authors": ["Nicholas A. Pearson", "Francesca Cairoli", "Luca Bortolussi", "Davide Russo", "Francesca Zanello"], "title": "Diffusion-based Time Series Forecasting for Sewerage Systems", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for presentation at the 13th Urban Drainage Modelling\n  Conference, Innsbruck (Austria), September 2025", "summary": "We introduce a novel deep learning approach that harnesses the power of\ngenerative artificial intelligence to enhance the accuracy of contextual\nforecasting in sewerage systems. By developing a diffusion-based model that\nprocesses multivariate time series data, our system excels at capturing complex\ncorrelations across diverse environmental signals, enabling robust predictions\neven during extreme weather events. To strengthen the model's reliability, we\nfurther calibrate its predictions with a conformal inference technique,\ntailored for probabilistic time series data, ensuring that the resulting\nprediction intervals are statistically reliable and cover the true target\nvalues with a desired confidence level. Our empirical tests on real sewerage\nsystem data confirm the model's exceptional capability to deliver reliable\ncontextual predictions, maintaining accuracy even under severe weather\nconditions.", "AI": {"tldr": "A deep learning model using generative AI improves sewerage system forecasting by capturing complex correlations in time series data, with conformal inference ensuring reliable predictions.", "motivation": "Enhancing the accuracy of contextual forecasting in sewerage systems, especially during extreme weather events.", "method": "Develops a diffusion-based model for multivariate time series data and calibrates predictions with conformal inference for reliability.", "result": "Empirical tests show the model delivers reliable predictions even under severe weather conditions.", "conclusion": "The model excels in robust and accurate contextual forecasting for sewerage systems."}}
{"id": "2506.08523", "pdf": "https://arxiv.org/pdf/2506.08523", "abs": "https://arxiv.org/abs/2506.08523", "authors": ["Pedro Jim\u00e9nez-Gonz\u00e1lez", "Miguel C. Soriano", "Lucas Lacasa"], "title": "Leveraging chaos in the training of artificial neural networks", "categories": ["cs.LG", "cond-mat.dis-nn", "nlin.CD", "physics.data-an"], "comment": null, "summary": "Traditional algorithms to optimize artificial neural networks when confronted\nwith a supervised learning task are usually exploitation-type relaxational\ndynamics such as gradient descent (GD). Here, we explore the dynamics of the\nneural network trajectory along training for unconventionally large learning\nrates. We show that for a region of values of the learning rate, the GD\noptimization shifts away from purely exploitation-like algorithm into a regime\nof exploration-exploitation balance, as the neural network is still capable of\nlearning but the trajectory shows sensitive dependence on initial conditions --\nas characterized by positive network maximum Lyapunov exponent --.\nInterestingly, the characteristic training time required to reach an acceptable\naccuracy in the test set reaches a minimum precisely in such learning rate\nregion, further suggesting that one can accelerate the training of artificial\nneural networks by locating at the onset of chaos. Our results -- initially\nillustrated for the MNIST classification task -- qualitatively hold for a range\nof supervised learning tasks, learning architectures and other hyperparameters,\nand showcase the emergent, constructive role of transient chaotic dynamics in\nthe training of artificial neural networks.", "AI": {"tldr": "The paper explores how large learning rates in gradient descent (GD) can shift neural network training from pure exploitation to an exploration-exploitation balance, characterized by chaotic dynamics. This regime accelerates training, as shown in MNIST and other tasks.", "motivation": "To understand the role of learning rates in GD dynamics and how chaotic behavior can improve neural network training efficiency.", "method": "Analyze GD dynamics for large learning rates, measuring Lyapunov exponents to characterize chaos and evaluating training time and accuracy.", "result": "For certain learning rates, GD exhibits chaotic dynamics, balancing exploration and exploitation, leading to faster training without sacrificing accuracy.", "conclusion": "Transient chaotic dynamics in GD can enhance neural network training, suggesting optimal learning rates at the onset of chaos."}}
{"id": "2506.09003", "pdf": "https://arxiv.org/pdf/2506.09003", "abs": "https://arxiv.org/abs/2506.09003", "authors": ["Lei Zhang", "Jiaxi Yang", "Min Yang", "Jian Yang", "Mouxiang Chen", "Jiajun Zhang", "Zeyu Cui", "Binyuan Hui", "Junyang Lin"], "title": "SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner", "categories": ["cs.CL"], "comment": "Accepted by ICML2025", "summary": "We introduce **SWE-Flow**, a novel data synthesis framework grounded in\nTest-Driven Development (TDD). Unlike existing software engineering data that\nrely on human-submitted issues, **SWE-Flow** automatically infers incremental\ndevelopment steps directly from unit tests, which inherently encapsulate\nhigh-level requirements. The core of **SWE-Flow** is the construction of a\nRuntime Dependency Graph (RDG), which precisely captures function interactions,\nenabling the generation of a structured, step-by-step *development schedule*.\nAt each step, **SWE-Flow** produces a partial codebase, the corresponding unit\ntests, and the necessary code modifications, resulting in fully verifiable TDD\ntasks. With this approach, we generated 16,061 training instances and 2,020\ntest instances from real-world GitHub projects, creating the **SWE-Flow-Eval**\nbenchmark. Our experiments show that fine-tuning open model on this dataset\nsignificantly improves performance in TDD-based coding. To facilitate further\nresearch, we release all code, datasets, models, and Docker images at\n[Github](https://github.com/Hambaobao/SWE-Flow).", "AI": {"tldr": "SWE-Flow is a TDD-based data synthesis framework that generates incremental development steps from unit tests, creating verifiable TDD tasks and a benchmark (SWE-Flow-Eval).", "motivation": "Existing software engineering data relies on human-submitted issues; SWE-Flow automates the process by inferring development steps from unit tests.", "method": "Constructs a Runtime Dependency Graph (RDG) to capture function interactions, generating structured development schedules with partial codebases, tests, and modifications.", "result": "Produced 16,061 training and 2,020 test instances, improving TDD-based coding performance when fine-tuning models.", "conclusion": "SWE-Flow enables scalable, verifiable TDD task generation and releases resources for further research."}}
{"id": "2506.08894", "pdf": "https://arxiv.org/pdf/2506.08894", "abs": "https://arxiv.org/abs/2506.08894", "authors": ["Yunzhi Zhang", "Carson Murtuza-Lanier", "Zizhang Li", "Yilun Du", "Jiajun Wu"], "title": "Product of Experts for Visual Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://product-of-experts.github.io/", "summary": "Modern neural models capture rich priors and have complementary knowledge\nover shared data domains, e.g., images and videos. Integrating diverse\nknowledge from multiple sources -- including visual generative models, visual\nlanguage models, and sources with human-crafted knowledge such as graphics\nengines and physics simulators -- remains under-explored. We propose a Product\nof Experts (PoE) framework that performs inference-time knowledge composition\nfrom heterogeneous models. This training-free approach samples from the product\ndistribution across experts via Annealed Importance Sampling (AIS). Our\nframework shows practical benefits in image and video synthesis tasks, yielding\nbetter controllability than monolithic methods and additionally providing\nflexible user interfaces for specifying visual generation goals.", "AI": {"tldr": "A Product of Experts (PoE) framework integrates diverse knowledge from heterogeneous models (e.g., generative, language, human-crafted) for improved image and video synthesis, using Annealed Importance Sampling (AIS) for inference-time composition.", "motivation": "To explore the underutilized potential of combining diverse knowledge sources (generative models, language models, human-crafted tools) for enhanced visual synthesis tasks.", "method": "Proposes a training-free PoE framework using AIS to sample from the product distribution of heterogeneous experts.", "result": "Demonstrates better controllability and flexible user interfaces for visual generation tasks compared to monolithic methods.", "conclusion": "The PoE framework effectively composes knowledge from diverse sources, improving visual synthesis and user control."}}
{"id": "2506.08594", "pdf": "https://arxiv.org/pdf/2506.08594", "abs": "https://arxiv.org/abs/2506.08594", "authors": ["Yixuan Ma", "Chang Liu", "Weikang Li", "Shun-Yao Zhang", "L. -M. Duan", "Yukai Wu", "Dong-Ling Deng"], "title": "Solving excited states for long-range interacting trapped ions with neural networks", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "The computation of excited states in strongly interacting quantum many-body\nsystems is of fundamental importance. Yet, it is notoriously challenging due to\nthe exponential scaling of the Hilbert space dimension with the system size.\nHere, we introduce a neural network-based algorithm that can simultaneously\noutput multiple low-lying excited states of a quantum many-body spin system in\nan accurate and efficient fashion. This algorithm, dubbed the neural quantum\nexcited-state (NQES) algorithm, requires no explicit orthogonalization of the\nstates and is generally applicable to higher dimensions. We demonstrate,\nthrough concrete examples including the Haldane-Shastry model with all-to-all\ninteractions, that the NQES algorithm is capable of efficiently computing\nmultiple excited states and their related observable expectations. In addition,\nwe apply the NQES algorithm to two classes of long-range interacting\ntrapped-ion systems in a two-dimensional Wigner crystal. For non-decaying\nall-to-all interactions with alternating signs, our computed low-lying excited\nstates bear spatial correlation patterns similar to those of the ground states,\nwhich closely match recent experimental observations that the\nquasi-adiabatically prepared state accurately reproduces analytical\nground-state correlations. For a system of up to 300 ions with power-law\ndecaying antiferromagnetic interactions, we successfully uncover its gap\nscaling and correlation features. Our results establish a scalable and\nefficient algorithm for computing excited states of interacting quantum\nmany-body systems, which holds potential applications ranging from benchmarking\nquantum devices to photoisomerization.", "AI": {"tldr": "A neural network-based algorithm (NQES) efficiently computes multiple low-lying excited states in quantum many-body systems without explicit orthogonalization, demonstrated on models like the Haldane-Shastry and trapped-ion systems.", "motivation": "Excited states in quantum many-body systems are crucial but computationally challenging due to exponential Hilbert space scaling.", "method": "The NQES algorithm uses neural networks to compute multiple excited states without orthogonalization, applicable to higher dimensions and tested on various models.", "result": "NQES accurately computes excited states and observables, matching experimental correlations and uncovering gap scaling in large systems (up to 300 ions).", "conclusion": "NQES is a scalable, efficient method for excited-state computation, with potential applications in quantum device benchmarking and photoisomerization."}}
{"id": "2506.08551", "pdf": "https://arxiv.org/pdf/2506.08551", "abs": "https://arxiv.org/abs/2506.08551", "authors": ["Panlong Wu", "Ting Wang", "Yifei Zhong", "Haoqi Zhang", "Zitong Wang", "Fangxin Wang"], "title": "DeepForm: Reasoning Large Language Model for Communication System Formulation", "categories": ["cs.LG"], "comment": null, "summary": "Communication system formulation is critical for advancing 6G and future\nwireless technologies, yet it remains a complex, expertise-intensive task.\nWhile Large Language Models (LLMs) offer potential, existing general-purpose\nmodels often lack the specialized domain knowledge, nuanced reasoning\ncapabilities, and access to high-quality, domain-specific training data\nrequired for adapting a general LLM into an LLM specially for communication\nsystem formulation. To bridge this gap, we introduce DeepForm, the first\nreasoning LLM specially for automated communication system formulation. We\npropose the world-first large-scale, open-source dataset meticulously curated\nfor this domain called Communication System Formulation Reasoning Corpus\n(CSFRC). Our framework employs a two-stage training strategy: first, Supervised\nFine-Tuning (SFT) with Chain-of-Thought (CoT) data to distill domain knowledge;\nsecond, a novel rule-based Reinforcement Learning (RL) algorithm, C-ReMax based\non ReMax, to cultivate advanced modeling capabilities and elicit sophisticated\nreasoning patterns like self-correction and verification. Extensive experiments\ndemonstrate that our model achieves state-of-the-art performance, significantly\noutperforming larger proprietary LLMs on diverse senerios. We will release\nrelated resources to foster further research in this area after the paper is\naccepted.", "AI": {"tldr": "DeepForm is a specialized LLM for automated communication system formulation, trained using a two-stage strategy (SFT and C-ReMax RL) on a curated dataset (CSFRC), outperforming general-purpose LLMs.", "motivation": "Existing general-purpose LLMs lack specialized domain knowledge and nuanced reasoning for communication system formulation, necessitating a tailored solution.", "method": "Two-stage training: SFT with CoT data for domain knowledge, followed by C-ReMax RL for advanced reasoning. Uses the CSFRC dataset.", "result": "DeepForm achieves state-of-the-art performance, surpassing larger proprietary LLMs in diverse scenarios.", "conclusion": "DeepForm bridges the gap in specialized LLMs for communication systems, with plans to release resources for further research."}}
{"id": "2506.09009", "pdf": "https://arxiv.org/pdf/2506.09009", "abs": "https://arxiv.org/abs/2506.09009", "authors": ["Hakyung Sung", "Gyu-Ho Shin", "Chanyoung Lee", "You Kyung Sung", "Boo Kyung Jung"], "title": "UD-KSL Treebank v1.3: A semi-automated framework for aligning XPOS-extracted units with UPOS tags", "categories": ["cs.CL"], "comment": null, "summary": "The present study extends recent work on Universal Dependencies annotations\nfor second-language (L2) Korean by introducing a semi-automated framework that\nidentifies morphosyntactic constructions from XPOS sequences and aligns those\nconstructions with corresponding UPOS categories. We also broaden the existing\nL2-Korean corpus by annotating 2,998 new sentences from argumentative essays.\nTo evaluate the impact of XPOS-UPOS alignments, we fine-tune L2-Korean\nmorphosyntactic analysis models on datasets both with and without these\nalignments, using two NLP toolkits. Our results indicate that the aligned\ndataset not only improves consistency across annotation layers but also\nenhances morphosyntactic tagging and dependency-parsing accuracy, particularly\nin cases of limited annotated data.", "AI": {"tldr": "A semi-automated framework for aligning XPOS-UPOS in L2 Korean improves annotation consistency and model accuracy.", "motivation": "Extend Universal Dependencies annotations for L2 Korean and enhance morphosyntactic analysis.", "method": "Introduce a semi-automated framework for XPOS-UPOS alignment, expand the L2-Korean corpus, and evaluate models with/without alignments.", "result": "Aligned dataset improves consistency, morphosyntactic tagging, and dependency-parsing accuracy, especially with limited data.", "conclusion": "XPOS-UPOS alignment benefits L2 Korean analysis, offering better performance in NLP tasks."}}
{"id": "2506.08896", "pdf": "https://arxiv.org/pdf/2506.08896", "abs": "https://arxiv.org/abs/2506.08896", "authors": ["Negin Ghamsarian", "Raphael Sznitman", "Klaus Schoeffmann", "Jens Kowal"], "title": "WetCat: Automating Skill Assessment in Wetlab Cataract Surgery Videos", "categories": ["cs.CV"], "comment": "9 pages, 6 figures", "summary": "To meet the growing demand for systematic surgical training, wetlab\nenvironments have become indispensable platforms for hands-on practice in\nophthalmology. Yet, traditional wetlab training depends heavily on manual\nperformance evaluations, which are labor-intensive, time-consuming, and often\nsubject to variability. Recent advances in computer vision offer promising\navenues for automated skill assessment, enhancing both the efficiency and\nobjectivity of surgical education. Despite notable progress in ophthalmic\nsurgical datasets, existing resources predominantly focus on real surgeries or\nisolated tasks, falling short of supporting comprehensive skill evaluation in\ncontrolled wetlab settings. To address these limitations, we introduce WetCat,\nthe first dataset of wetlab cataract surgery videos specifically curated for\nautomated skill assessment. WetCat comprises high-resolution recordings of\nsurgeries performed by trainees on artificial eyes, featuring comprehensive\nphase annotations and semantic segmentations of key anatomical structures.\nThese annotations are meticulously designed to facilitate skill assessment\nduring the critical capsulorhexis and phacoemulsification phases, adhering to\nstandardized surgical skill assessment frameworks. By focusing on these\nessential phases, WetCat enables the development of interpretable, AI-driven\nevaluation tools aligned with established clinical metrics. This dataset lays a\nstrong foundation for advancing objective, scalable surgical education and sets\na new benchmark for automated workflow analysis and skill assessment in\nophthalmology training. The dataset and annotations are publicly available in\nSynapse https://www.synapse.org/Synapse:syn66401174/files.", "AI": {"tldr": "WetCat is the first dataset of wetlab cataract surgery videos for automated skill assessment, addressing gaps in traditional manual evaluations.", "motivation": "Traditional wetlab training relies on manual evaluations, which are inefficient and subjective. Automated skill assessment using computer vision can improve surgical education.", "method": "Introduces WetCat, a dataset with high-resolution wetlab cataract surgery videos, phase annotations, and semantic segmentations for key phases (capsulorhexis and phacoemulsification).", "result": "WetCat enables AI-driven, interpretable skill assessment aligned with clinical standards, advancing objective surgical education.", "conclusion": "WetCat sets a benchmark for automated workflow analysis and skill assessment in ophthalmology training, with publicly available data."}}
{"id": "2506.08602", "pdf": "https://arxiv.org/pdf/2506.08602", "abs": "https://arxiv.org/abs/2506.08602", "authors": ["Tingzhi Li", "Xuefeng Liu"], "title": "WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) are increasingly deployed in graph-related\napplications, making ownership verification critical to protect their\nintellectual property against model theft. Fingerprinting and black-box\nwatermarking are two main methods. However, the former relies on determining\nmodel similarity, which is computationally expensive and prone to ownership\ncollisions after model post-processing such as model pruning or fine-tuning.\nThe latter embeds backdoors, exposing watermarked models to the risk of\nbackdoor attacks. Moreover, both methods enable ownership verification but do\nnot convey additional information. As a result, each distributed model requires\na unique trigger graph, and all trigger graphs must be used to query the\nsuspect model during verification. Multiple queries increase the financial cost\nand the risk of detection.\n  To address these challenges, this paper proposes WGLE, a novel black-box\nwatermarking paradigm for GNNs that enables embedding the multi-bit string as\nthe ownership information without using backdoors. WGLE builds on a key insight\nwe term Layer-wise Distance Difference on an Edge (LDDE), which quantifies the\ndifference between the feature distance and the prediction distance of two\nconnected nodes. By predefining positive or negative LDDE values for multiple\nselected edges, WGLE embeds the watermark encoding the intended information\nwithout introducing incorrect mappings that compromise the primary task. WGLE\nis evaluated on six public datasets and six mainstream GNN architectures along\nwith state-of-the-art methods. The results show that WGLE achieves 100%\nownership verification accuracy, an average fidelity degradation of 0.85%,\ncomparable robustness against potential attacks, and low embedding overhead.\nThe code is available in the repository.", "AI": {"tldr": "WGLE introduces a black-box watermarking method for GNNs, embedding multi-bit ownership info without backdoors, achieving high accuracy and robustness.", "motivation": "Existing GNN ownership verification methods (fingerprinting, black-box watermarking) have limitations like computational cost, backdoor risks, and lack of additional info. WGLE addresses these.", "method": "WGLE uses Layer-wise Distance Difference on an Edge (LDDE) to embed watermarks by predefined LDDE values on selected edges, avoiding backdoors.", "result": "WGLE achieves 100% verification accuracy, 0.85% fidelity degradation, robustness against attacks, and low overhead on six datasets and GNN architectures.", "conclusion": "WGLE is an effective, secure, and efficient solution for GNN ownership verification without backdoor risks."}}
{"id": "2506.08574", "pdf": "https://arxiv.org/pdf/2506.08574", "abs": "https://arxiv.org/abs/2506.08574", "authors": ["Alvise Dei Rossi", "Matteo Metaldi", "Michal Bechny", "Irina Filchenko", "Julia van der Meer", "Markus H. Schmidt", "Claudio L. A. Bassetti", "Athina Tzovara", "Francesca D. Faraci", "Luigi Fiorillo"], "title": "SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models", "categories": ["cs.LG"], "comment": "41 pages, 4 Figures, 7 Tables", "summary": "Despite advances in deep learning for automatic sleep staging, clinical\nadoption remains limited due to challenges in fair model evaluation,\ngeneralization across diverse datasets, model bias, and variability in human\nannotations. We present SLEEPYLAND, an open-source sleep staging evaluation\nframework designed to address these barriers. It includes more than 22'0000\nhours in-domain (ID) sleep recordings, and more than 84'000 hours out-of-domain\n(OOD) sleep recordings, spanning a broad range of ages, sleep-wake disorders,\nand hardware setups. We release pre-trained models based on high-performing SoA\narchitectures and evaluate them under standardized conditions across single-\nand multi-channel EEG/EOG configurations. We introduce SOMNUS, an ensemble\ncombining models across architectures and channel setups via soft voting.\nSOMNUS achieves robust performance across twenty-four different datasets, with\nmacro-F1 scores between 68.7% and 87.2%, outperforming individual models in\n94.9% of cases. Notably, SOMNUS surpasses previous SoA methods, even including\ncases where compared models were trained ID while SOMNUS treated the same data\nas OOD. Using a subset of the BSWR (N=6'633), we quantify model biases linked\nto age, gender, AHI, and PLMI, showing that while ensemble improves robustness,\nno model architecture consistently minimizes bias in performance and clinical\nmarkers estimation. In evaluations on OOD multi-annotated datasets (DOD-H,\nDOD-O), SOMNUS exceeds the best human scorer, i.e., MF1 85.2% vs 80.8% on\nDOD-H, and 80.2% vs 75.9% on DOD-O, better reproducing the scorer consensus\nthan any individual expert (k = 0.89/0.85 and ACS = 0.95/0.94 for healthy/OSA\ncohorts). Finally, we introduce ensemble disagreement metrics - entropy and\ninter-model divergence based - predicting regions of scorer disagreement with\nROC AUCs up to 0.828, offering a data-driven proxy for human uncertainty.", "AI": {"tldr": "SLEEPYLAND is an open-source sleep staging framework addressing evaluation challenges, generalization, and bias. SOMNUS, an ensemble model, outperforms individual models and human scorers, even in OOD scenarios, while also quantifying biases and predicting scorer disagreement.", "motivation": "Clinical adoption of deep learning for sleep staging is limited by evaluation fairness, generalization, model bias, and annotation variability.", "method": "SLEEPYLAND provides standardized evaluation with extensive datasets (ID and OOD). SOMNUS, an ensemble of models, is introduced and evaluated across diverse datasets and configurations.", "result": "SOMNUS achieves robust performance (macro-F1 68.7%-87.2%), outperforms individual models (94.9% cases), and surpasses human scorers in consensus reproduction. Bias analysis reveals no consistent minimization across models.", "conclusion": "SLEEPYLAND and SOMNUS advance sleep staging by improving evaluation, generalization, and bias awareness, with ensemble disagreement metrics offering insights into human uncertainty."}}
{"id": "2506.09014", "pdf": "https://arxiv.org/pdf/2506.09014", "abs": "https://arxiv.org/abs/2506.09014", "authors": ["Jianing Qi", "Xi Ye", "Hao Tang", "Zhigang Zhu", "Eunsol Choi"], "title": "Learning to Reason Across Parallel Samples for LLM Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Scaling test-time compute brings substantial performance gains for large\nlanguage models (LLMs). By sampling multiple answers and heuristically\naggregate their answers (e.g., either through majority voting or using\nverifiers to rank the answers), one can achieve consistent performance gains in\nmath domains. In this paper, we propose a new way to leverage such multiple\nsample set. We train a compact LLM, called Sample Set Aggregator (SSA), that\ntakes a concatenated sequence of multiple samples and output the final answer,\noptimizing it for the answer accuracy with reinforcement learning. Experiments\non multiple reasoning datasets show that SSA outperforms other test-time\nscaling methods such as reward model-based re-ranking. Our approach also shows\na promising generalization ability, across sample set sizes, base model\nfamilies and scales, and tasks. By separating LLMs to generate answers and LLMs\nto analyze and aggregate sampled answers, our approach can work with the\noutputs from premier black box models easily and efficiently.", "AI": {"tldr": "A compact LLM, Sample Set Aggregator (SSA), is trained to aggregate multiple samples for improved answer accuracy, outperforming other test-time scaling methods.", "motivation": "To enhance performance of large language models (LLMs) by efficiently leveraging multiple samples for better answer aggregation.", "method": "Train SSA to concatenate and analyze multiple samples, optimizing accuracy with reinforcement learning.", "result": "SSA outperforms methods like reward model-based re-ranking and generalizes well across tasks and model scales.", "conclusion": "SSA provides an efficient, scalable solution for aggregating LLM outputs, compatible with black-box models."}}
{"id": "2506.08900", "pdf": "https://arxiv.org/pdf/2506.08900", "abs": "https://arxiv.org/abs/2506.08900", "authors": ["Jos\u00e9 Morano", "Botond Fazekas", "Emese S\u00fckei", "Ronald Fecso", "Taha Emre", "Markus Gumpinger", "Georg Faustmann", "Marzieh Oghbaie", "Ursula Schmidt-Erfurth", "Hrvoje Bogunovi\u0107"], "title": "MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis", "categories": ["cs.CV"], "comment": null, "summary": "Artificial intelligence (AI) has become a fundamental tool for assisting\nclinicians in analyzing ophthalmic images, such as optical coherence tomography\n(OCT). However, developing AI models often requires extensive annotation, and\nexisting models tend to underperform on independent, unseen data. Foundation\nmodels (FMs), large AI models trained on vast unlabeled datasets, have shown\npromise in overcoming these challenges. Nonetheless, available FMs for\nophthalmology lack extensive validation, especially for segmentation tasks, and\nfocus on a single imaging modality. In this context, we propose MIRAGE, a novel\nmultimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO)\nimages. Additionally, we propose a new evaluation benchmark with OCT/SLO\nclassification and segmentation tasks. The comparison with general and\nspecialized FMs and segmentation methods shows the superiority of MIRAGE in\nboth types of tasks, highlighting its suitability as a basis for the\ndevelopment of robust AI systems for retinal OCT image analysis. Both MIRAGE\nand the evaluation benchmark are publicly available:\nhttps://github.com/j-morano/MIRAGE.", "AI": {"tldr": "MIRAGE is a multimodal foundation model for analyzing OCT and SLO images, outperforming existing models in classification and segmentation tasks.", "motivation": "Current AI models for ophthalmic image analysis require extensive annotation and underperform on unseen data. Existing foundation models lack validation and focus on single modalities.", "method": "Proposes MIRAGE, a multimodal foundation model for OCT and SLO images, and introduces a new evaluation benchmark.", "result": "MIRAGE outperforms general and specialized models in classification and segmentation tasks.", "conclusion": "MIRAGE is a robust foundation for AI systems in retinal OCT analysis, with publicly available resources."}}
{"id": "2506.08604", "pdf": "https://arxiv.org/pdf/2506.08604", "abs": "https://arxiv.org/abs/2506.08604", "authors": ["Giacomo Baldan", "Qiang Liu", "Alberto Guardone", "Nils Thuerey"], "title": "Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "Generative machine learning methods, such as diffusion models and flow\nmatching, have shown great potential in modeling complex system behaviors and\nbuilding efficient surrogate models. However, these methods typically learn the\nunderlying physics implicitly from data. We propose Physics-Based Flow Matching\n(PBFM), a novel generative framework that explicitly embeds physical\nconstraints, both PDE residuals and algebraic relations, into the flow matching\nobjective. We also introduce temporal unrolling at training time that improves\nthe accuracy of the final, noise-free sample prediction. Our method jointly\nminimizes the flow matching loss and the physics-based residual loss without\nrequiring hyperparameter tuning of their relative weights. Additionally, we\nanalyze the role of the minimum noise level, $\\sigma_{\\min}$, in the context of\nphysical constraints and evaluate a stochastic sampling strategy that helps to\nreduce physical residuals. Through extensive benchmarks on three representative\nPDE problems, we show that our approach yields up to an $8\\times$ more accurate\nphysical residuals compared to FM, while clearly outperforming existing\nalgorithms in terms of distributional accuracy. PBFM thus provides a principled\nand efficient framework for surrogate modeling, uncertainty quantification, and\naccelerated simulation in physics and engineering applications.", "AI": {"tldr": "PBFM embeds physical constraints into flow matching, improving accuracy and reducing residuals without hyperparameter tuning.", "motivation": "Existing generative methods learn physics implicitly; PBFM explicitly incorporates physical constraints for better accuracy.", "method": "PBFM combines flow matching loss with physics-based residual loss and uses temporal unrolling for training.", "result": "PBFM achieves up to 8\u00d7 better physical residuals and outperforms existing methods in distributional accuracy.", "conclusion": "PBFM offers an efficient framework for surrogate modeling and simulation in physics and engineering."}}
{"id": "2506.08600", "pdf": "https://arxiv.org/pdf/2506.08600", "abs": "https://arxiv.org/abs/2506.08600", "authors": ["Hiroshi Kera", "Shun Arakawa", "Yuta Sato"], "title": "CALT: A Library for Computer Algebra with Transformer", "categories": ["cs.LG", "cs.SC", "math.AC"], "comment": "ISSAC 2025 Short Communications", "summary": "Recent advances in artificial intelligence have demonstrated the learnability\nof symbolic computation through end-to-end deep learning. Given a sufficient\nnumber of examples of symbolic expressions before and after the target\ncomputation, Transformer models - highly effective learners of\nsequence-to-sequence functions - can be trained to emulate the computation.\nThis development opens up several intriguing challenges and new research\ndirections, which require active contributions from the symbolic computation\ncommunity. In this work, we introduce Computer Algebra with Transformer (CALT),\na user-friendly Python library designed to help non-experts in deep learning\ntrain models for symbolic computation tasks.", "AI": {"tldr": "Transformer models can learn symbolic computation via deep learning, and CALT is introduced as a Python library to facilitate training such models.", "motivation": "To leverage deep learning for symbolic computation and make it accessible to non-experts.", "method": "Uses Transformer models trained on examples of symbolic expressions to emulate computations.", "result": "Development of CALT, a Python library for training symbolic computation models.", "conclusion": "CALT enables non-experts to harness deep learning for symbolic computation, opening new research avenues."}}
{"id": "2506.09021", "pdf": "https://arxiv.org/pdf/2506.09021", "abs": "https://arxiv.org/abs/2506.09021", "authors": ["Hakyung Sung", "Karla Csuros", "Min-Chang Sung"], "title": "Comparing human and LLM proofreading in L2 writing: Impact on lexical and syntactic features", "categories": ["cs.CL"], "comment": null, "summary": "This study examines the lexical and syntactic interventions of human and LLM\nproofreading aimed at improving overall intelligibility in identical second\nlanguage writings, and evaluates the consistency of outcomes across three LLMs\n(ChatGPT-4o, Llama3.1-8b, Deepseek-r1-8b). Findings show that both human and\nLLM proofreading enhance bigram lexical features, which may contribute to\nbetter coherence and contextual connectedness between adjacent words. However,\nLLM proofreading exhibits a more generative approach, extensively reworking\nvocabulary and sentence structures, such as employing more diverse and\nsophisticated vocabulary and incorporating a greater number of adjective\nmodifiers in noun phrases. The proofreading outcomes are highly consistent in\nmajor lexical and syntactic features across the three models.", "AI": {"tldr": "Human and LLM proofreading improve intelligibility in second language writing, with LLMs showing more generative changes. Outcomes are consistent across three LLM models.", "motivation": "To compare the effectiveness and consistency of human and LLM proofreading in enhancing second language writing intelligibility.", "method": "Examined lexical and syntactic interventions in identical second language writings by humans and three LLMs (ChatGPT-4o, Llama3.1-8b, Deepseek-r1-8b).", "result": "Both human and LLM proofreading improved bigram lexical features. LLMs were more generative, using diverse vocabulary and sentence structures. Outcomes were consistent across models.", "conclusion": "LLM proofreading is effective and consistent, offering generative improvements in vocabulary and syntax, though human proofreading remains valuable."}}
{"id": "2506.08906", "pdf": "https://arxiv.org/pdf/2506.08906", "abs": "https://arxiv.org/abs/2506.08906", "authors": ["Peilin Yu", "Yuwei Wu", "Zhi Gao", "Xiaomeng Fan", "Shuo Yang", "Yunde Jia"], "title": "Hyperbolic Dual Feature Augmentation for Open-Environment", "categories": ["cs.CV"], "comment": "arXiv admin note: text overlap with arXiv:2207.03824,\n  arXiv:2304.11855 by other authors", "summary": "Feature augmentation generates novel samples in the feature space, providing\nan effective way to enhance the generalization ability of learning algorithms\nwith hyperbolic geometry. Most hyperbolic feature augmentation is confined to\nclosed-environment, assuming the number of classes is fixed (\\emph{i.e.}, seen\nclasses) and generating features only for these classes. In this paper, we\npropose a hyperbolic dual feature augmentation method for open-environment,\nwhich augments features for both seen and unseen classes in the hyperbolic\nspace. To obtain a more precise approximation of the real data distribution for\nefficient training, (1) we adopt a neural ordinary differential equation\nmodule, enhanced by meta-learning, estimating the feature distributions of both\nseen and unseen classes; (2) we then introduce a regularizer to preserve the\nlatent hierarchical structures of data in the hyperbolic space; (3) we also\nderive an upper bound for the hyperbolic dual augmentation loss, allowing us to\ntrain a hyperbolic model using infinite augmentations for seen and unseen\nclasses. Extensive experiments on five open-environment tasks:\nclass-incremental learning, few-shot open-set recognition, few-shot learning,\nzero-shot learning, and general image classification, demonstrate that our\nmethod effectively enhances the performance of hyperbolic algorithms in\nopen-environment.", "AI": {"tldr": "A hyperbolic dual feature augmentation method for open-environments, enhancing performance for both seen and unseen classes using neural ODEs and meta-learning.", "motivation": "Existing hyperbolic feature augmentation is limited to closed environments with fixed classes, lacking adaptability for open-environment tasks.", "method": "Uses neural ODEs with meta-learning to estimate feature distributions, introduces a regularizer for hierarchical structure preservation, and derives a loss upper bound for infinite augmentations.", "result": "Demonstrates improved performance in five open-environment tasks, including class-incremental learning and zero-shot learning.", "conclusion": "The method effectively enhances hyperbolic algorithms in open-environments by addressing limitations of existing approaches."}}
{"id": "2506.08618", "pdf": "https://arxiv.org/pdf/2506.08618", "abs": "https://arxiv.org/abs/2506.08618", "authors": ["Xianquan Yan", "Hakan Akg\u00fcn", "Kenji Kawaguchi", "N. Duane Loh", "Ching Hua Lee"], "title": "HSG-12M: A Large-Scale Spatial Multigraph Dataset", "categories": ["cs.LG", "cond-mat.mes-hall", "cond-mat.other", "cs.AI", "cs.CV"], "comment": "39 pages, 13 figures, 3 tables. Code & pipeline:\n  [https://github.com/sarinstein-yan/Poly2Graph] Dataset:\n  [https://github.com/sarinstein-yan/HSG-12M] Dataset released under CC BY 4.0", "summary": "Existing graph benchmarks assume non-spatial, simple edges, collapsing\nphysically distinct paths into a single link. We introduce HSG-12M, the first\nlarge-scale dataset of $\\textbf{spatial multigraphs}-$graphs embedded in a\nmetric space where multiple geometrically distinct trajectories between two\nnodes are retained as separate edges. HSG-12M contains 11.6 million static and\n5.1 million dynamic $\\textit{Hamiltonian spectral graphs}$ across 1401\ncharacteristic-polynomial classes, derived from 177 TB of spectral potential\ndata. Each graph encodes the full geometry of a 1-D crystal's energy spectrum\non the complex plane, producing diverse, physics-grounded topologies that\ntranscend conventional node-coordinate datasets. To enable future extensions,\nwe release $\\texttt{Poly2Graph}$: a high-performance, open-source pipeline that\nmaps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with\npopular GNNs expose new challenges in learning from multi-edge geometry at\nscale. Beyond its practical utility, we show that spectral graphs serve as\nuniversal topological fingerprints of polynomials, vectors, and matrices,\nforging a new algebra-to-graph link. HSG-12M lays the groundwork for\ngeometry-aware graph learning and new opportunities of data-driven scientific\ndiscovery in condensed matter physics and beyond.", "AI": {"tldr": "HSG-12M introduces the first large-scale dataset of spatial multigraphs, retaining distinct paths as separate edges, derived from spectral potential data. It includes 11.6M static and 5.1M dynamic graphs, enabling geometry-aware learning and scientific discovery.", "motivation": "Existing benchmarks oversimplify graphs by collapsing distinct paths into single links, limiting their utility for spatial and geometric analysis. HSG-12M addresses this gap by preserving geometric diversity.", "method": "The dataset is built using Hamiltonian spectral graphs from 1-D crystal energy spectra, processed via the Poly2Graph pipeline. It includes 1401 polynomial classes and leverages 177 TB of spectral data.", "result": "HSG-12M provides diverse, physics-grounded graph topologies, revealing challenges in learning from multi-edge geometry. It also serves as universal topological fingerprints for polynomials and matrices.", "conclusion": "HSG-12M advances geometry-aware graph learning and opens new avenues for scientific discovery in physics and beyond, supported by the open-source Poly2Graph pipeline."}}
{"id": "2506.08607", "pdf": "https://arxiv.org/pdf/2506.08607", "abs": "https://arxiv.org/abs/2506.08607", "authors": ["Kiran Purohit", "V Venktesh", "Sourangshu Bhattacharya", "Avishek Anand"], "title": "Sample Efficient Demonstration Selection for In-Context Learning", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025 , 24 pages", "summary": "The in-context learning paradigm with LLMs has been instrumental in advancing\na wide range of natural language processing tasks. The selection of few-shot\nexamples (exemplars / demonstration samples) is essential for constructing\neffective prompts under context-length budget constraints. In this paper, we\nformulate the exemplar selection task as a top-m best arms identification\nproblem. A key challenge in this setup is the exponentially large number of\narms that need to be evaluated to identify the m-best arms. We propose CASE\n(Challenger Arm Sampling for Exemplar selection), a novel sample-efficient\nselective exploration strategy that maintains a shortlist of \"challenger\" arms,\nwhich are current candidates for the top-m arms. In each iteration, only one of\nthe arms from this shortlist or the current topm set is pulled, thereby\nreducing sample complexity and, consequently, the number of LLM evaluations.\nFurthermore, we model the scores of exemplar subsets (arms) using a\nparameterized linear scoring function, leading to stochastic linear bandits\nsetting. CASE achieves remarkable efficiency gains of up to 7x speedup in\nruntime while requiring 7x fewer LLM calls (87% reduction) without sacrificing\nperformance compared to state-of-the-art exemplar selection methods. We release\nour code and data at https://github.com/kiranpurohit/CASE", "AI": {"tldr": "CASE is a sample-efficient method for selecting top exemplars in LLM prompts, reducing runtime and LLM calls by 7x without performance loss.", "motivation": "Efficient exemplar selection is crucial for LLM performance under context-length constraints, but existing methods are computationally expensive.", "method": "Formulates exemplar selection as a top-m best arms problem, using a selective exploration strategy (CASE) with a linear scoring function.", "result": "Achieves 7x speedup and 87% fewer LLM calls compared to state-of-the-art methods.", "conclusion": "CASE is a highly efficient and effective solution for exemplar selection in LLM prompts."}}
{"id": "2506.09033", "pdf": "https://arxiv.org/pdf/2506.09033", "abs": "https://arxiv.org/abs/2506.09033", "authors": ["Haozhen Zhang", "Tao Feng", "Jiaxuan You"], "title": "Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code is available at https://github.com/ulab-uiuc/Router-R1", "summary": "The rapid emergence of diverse large language models (LLMs) has spurred the\ndevelopment of LLM routers that assign user queries to the most suitable model.\nHowever, existing LLM routers typically perform a single-round, one-to-one\nmapping (\\textit{i.e.}, assigning each query to a single model in isolation),\nwhich limits their capability to tackle complex tasks that demand the\ncomplementary strengths of multiple LLMs. In this paper, we present\n\\textbf{Router-R1}, a reinforcement learning (RL)-based framework that\nformulates multi-LLM routing and aggregation as a sequential decision process.\nRouter-R1 instantiates the router itself as a capable LLM, leveraging its\nreasoning ability to interleave \"think\" actions (internal deliberation) with\n\"route\" actions (dynamic model invocation), and integrates each response into\nits evolving context. To guide learning, we employ a lightweight rule-based\nreward comprising format rewards, final outcome rewards, and a novel cost\nreward for performance and cost trade-off optimization, opening a pathway\ntoward optimizing performance-cost tradeoffs via RL. Router-R1 also conditions\nonly on simple model descriptors such as pricing, latency, and example\nperformance, enabling strong generalization to unseen model selection.\nExperiments on seven general and multi-hop QA benchmarks show that Router-R1\noutperforms over several strong baselines, achieving superior performance while\nmaintaining robust generalization and cost management.Code is available at\nhttps://github.com/ulab-uiuc/Router-R1.", "AI": {"tldr": "Router-R1 is an RL-based framework for multi-LLM routing, outperforming baselines by dynamically invoking models and optimizing performance-cost trade-offs.", "motivation": "Existing LLM routers lack the ability to handle complex tasks requiring multiple LLMs' complementary strengths.", "method": "Router-R1 uses RL to interleave deliberation and dynamic model invocation, guided by a rule-based reward system.", "result": "Outperforms baselines on QA benchmarks, with strong generalization and cost management.", "conclusion": "Router-R1 advances multi-LLM routing by optimizing performance-cost trade-offs via RL."}}
{"id": "2506.08908", "pdf": "https://arxiv.org/pdf/2506.08908", "abs": "https://arxiv.org/abs/2506.08908", "authors": ["Jiajun Li", "Yue Ma", "Xinyu Zhang", "Qingyan Wei", "Songhua Liu", "Linfeng Zhang"], "title": "SkipVAR: Accelerating Visual Autoregressive Modeling via Adaptive Frequency-Aware Skipping", "categories": ["cs.CV"], "comment": null, "summary": "Recent studies on Visual Autoregressive (VAR) models have highlighted that\nhigh-frequency components, or later steps, in the generation process contribute\ndisproportionately to inference latency. However, the underlying computational\nredundancy involved in these steps has yet to be thoroughly investigated. In\nthis paper, we conduct an in-depth analysis of the VAR inference process and\nidentify two primary sources of inefficiency: step redundancy and unconditional\nbranch redundancy. To address step redundancy, we propose an automatic\nstep-skipping strategy that selectively omits unnecessary generation steps to\nimprove efficiency. For unconditional branch redundancy, we observe that the\ninformation gap between the conditional and unconditional branches is minimal.\nLeveraging this insight, we introduce unconditional branch replacement, a\ntechnique that bypasses the unconditional branch to reduce computational cost.\nNotably, we observe that the effectiveness of acceleration strategies varies\nsignificantly across different samples. Motivated by this, we propose SkipVAR,\na sample-adaptive framework that leverages frequency information to dynamically\nselect the most suitable acceleration strategy for each instance. To evaluate\nthe role of high-frequency information, we introduce high-variation benchmark\ndatasets that test model sensitivity to fine details. Extensive experiments\nshow SkipVAR achieves over 0.88 average SSIM with up to 1.81x overall\nacceleration and 2.62x speedup on the GenEval benchmark, maintaining model\nquality. These results confirm the effectiveness of frequency-aware,\ntraining-free adaptive acceleration for scalable autoregressive image\ngeneration. Our code is available at https://github.com/fakerone-li/SkipVAR and\nhas been publicly released.", "AI": {"tldr": "SkipVAR introduces a sample-adaptive framework to accelerate VAR models by addressing step and unconditional branch redundancies, achieving significant speedup without quality loss.", "motivation": "High-frequency components in VAR models cause latency, but computational redundancy in these steps is understudied.", "method": "Proposes step-skipping and unconditional branch replacement, combined into SkipVAR, a frequency-aware adaptive framework.", "result": "Achieves 1.81x overall acceleration and 2.62x speedup on GenEval, with 0.88 average SSIM.", "conclusion": "SkipVAR effectively accelerates VAR models adaptively, maintaining quality, and is publicly available."}}
{"id": "2506.08634", "pdf": "https://arxiv.org/pdf/2506.08634", "abs": "https://arxiv.org/abs/2506.08634", "authors": ["Alvaro Becerra", "Daniel Andres", "Pablo Villegas", "Roberto Daza", "Ruth Cobos"], "title": "MOSAIC-F: A Framework for Enhancing Students' Oral Presentation Skills through Personalized Feedback", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": "Accepted in LASI Spain 25: Learning Analytics Summer Institute Spain\n  2025", "summary": "In this article, we present a novel multimodal feedback framework called\nMOSAIC-F, an acronym for a data-driven Framework that integrates Multimodal\nLearning Analytics (MMLA), Observations, Sensors, Artificial Intelligence (AI),\nand Collaborative assessments for generating personalized feedback on student\nlearning activities. This framework consists of four key steps. First, peers\nand professors' assessments are conducted through standardized rubrics (that\ninclude both quantitative and qualitative evaluations). Second, multimodal data\nare collected during learning activities, including video recordings, audio\ncapture, gaze tracking, physiological signals (heart rate, motion data), and\nbehavioral interactions. Third, personalized feedback is generated using AI,\nsynthesizing human-based evaluations and data-based multimodal insights such as\nposture, speech patterns, stress levels, and cognitive load, among others.\nFinally, students review their own performance through video recordings and\nengage in self-assessment and feedback visualization, comparing their own\nevaluations with peers and professors' assessments, class averages, and\nAI-generated recommendations. By combining human-based and data-based\nevaluation techniques, this framework enables more accurate, personalized and\nactionable feedback. We tested MOSAIC-F in the context of improving oral\npresentation skills.", "AI": {"tldr": "MOSAIC-F is a multimodal feedback framework integrating MMLA, observations, sensors, AI, and collaborative assessments to provide personalized student feedback.", "motivation": "To enhance student learning by combining human and data-driven evaluations for more accurate and actionable feedback.", "method": "Four-step process: peer/professor assessments, multimodal data collection, AI-generated feedback synthesis, and student self-assessment.", "result": "Tested for improving oral presentation skills, enabling personalized feedback.", "conclusion": "MOSAIC-F effectively combines human and data-based evaluations for better learning outcomes."}}
{"id": "2506.08641", "pdf": "https://arxiv.org/pdf/2506.08641", "abs": "https://arxiv.org/abs/2506.08641", "authors": ["Simon Roschmann", "Quentin Bouniot", "Vasilii Feofanov", "Ievgen Redko", "Zeynep Akata"], "title": "Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Time series classification is a fundamental task in healthcare and industry,\nyet the development of time series foundation models (TSFMs) remains limited by\nthe scarcity of publicly available time series datasets. In this work, we\npropose Time Vision Transformer (TiViT), a framework that converts time series\ninto images to leverage the representational power of frozen Vision\nTransformers (ViTs) pretrained on large-scale image datasets. First, we\ntheoretically motivate our approach by analyzing the 2D patching of ViTs for\ntime series, showing that it can increase the number of label-relevant tokens\nand reduce the sample complexity. Second, we empirically demonstrate that TiViT\nachieves state-of-the-art performance on standard time series classification\nbenchmarks by utilizing the hidden representations of large OpenCLIP models. We\nexplore the structure of TiViT representations and find that intermediate\nlayers with high intrinsic dimension are the most effective for time series\nclassification. Finally, we assess the alignment between TiViT and TSFM\nrepresentation spaces and identify a strong complementarity, with further\nperformance gains achieved by combining their features. Our findings reveal yet\nanother direction for reusing vision representations in a non-visual domain.", "AI": {"tldr": "TiViT converts time series to images for use with pretrained Vision Transformers (ViTs), achieving state-of-the-art performance in time series classification by leveraging OpenCLIP models.", "motivation": "Addressing the scarcity of time series datasets by reusing pretrained vision models for time series classification.", "method": "Proposes TiViT, converting time series into images to utilize frozen ViTs, analyzing 2D patching and leveraging OpenCLIP representations.", "result": "TiViT achieves top performance on benchmarks, with intermediate layers of high intrinsic dimension being most effective. Combining TiViT and TSFM features yields further gains.", "conclusion": "TiViT demonstrates the potential of reusing vision representations for non-visual tasks, offering a new direction for time series classification."}}
{"id": "2506.09047", "pdf": "https://arxiv.org/pdf/2506.09047", "abs": "https://arxiv.org/abs/2506.09047", "authors": ["Yaniv Nikankin", "Dana Arad", "Yossi Gandelsman", "Yonatan Belinkov"], "title": "Same Task, Different Circuits: Disentangling Modality-Specific Mechanisms in VLMs", "categories": ["cs.CL", "68T5", "I.2.7"], "comment": null, "summary": "Vision-Language models (VLMs) show impressive abilities to answer questions\non visual inputs (e.g., counting objects in an image), yet demonstrate higher\naccuracies when performing an analogous task on text (e.g., counting words in a\ntext). We investigate this accuracy gap by identifying and comparing the\n\\textit{circuits} - the task-specific computational sub-graphs - in different\nmodalities. We show that while circuits are largely disjoint between\nmodalities, they implement relatively similar functionalities: the differences\nlie primarily in processing modality-specific data positions (an image or a\ntext sequence). Zooming in on the image data representations, we observe they\nbecome aligned with the higher-performing analogous textual representations\nonly towards later layers, too late in processing to effectively influence\nsubsequent positions. To overcome this, we patch the representations of visual\ndata tokens from later layers back into earlier layers. In experiments with\nmultiple tasks and models, this simple intervention closes a third of the\nperformance gap between the modalities, on average. Our analysis sheds light on\nthe multi-modal performance gap in VLMs and suggests a training-free approach\nfor reducing it.", "AI": {"tldr": "The paper investigates the accuracy gap between visual and textual tasks in Vision-Language Models (VLMs), attributing it to disjoint but functionally similar circuits in different modalities. A simple intervention\u2014patching visual data tokens from later layers into earlier ones\u2014reduces the performance gap by a third.", "motivation": "VLMs perform better on textual tasks than visual ones, despite similar functionalities. The study aims to understand and mitigate this gap by analyzing modality-specific circuits.", "method": "The authors compare circuits in VLMs for visual and textual tasks, identify misalignments in data representations, and propose patching visual tokens from later layers into earlier ones to improve performance.", "result": "Patching visual representations reduces the performance gap by a third on average across multiple tasks and models.", "conclusion": "The study highlights the multi-modal performance gap in VLMs and offers a training-free method to address it, improving visual task accuracy."}}
{"id": "2506.08915", "pdf": "https://arxiv.org/pdf/2506.08915", "abs": "https://arxiv.org/abs/2506.08915", "authors": ["Ananthu Aniraj", "Cassio F. Dantas", "Dino Ienco", "Diego Marcos"], "title": "Inherently Faithful Attention Maps for Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We introduce an attention-based method that uses learned binary attention\nmasks to ensure that only attended image regions influence the prediction.\nContext can strongly affect object perception, sometimes leading to biased\nrepresentations, particularly when objects appear in out-of-distribution\nbackgrounds. At the same time, many image-level object-centric tasks require\nidentifying relevant regions, often requiring context. To address this\nconundrum, we propose a two-stage framework: stage 1 processes the full image\nto discover object parts and identify task-relevant regions, while stage 2\nleverages input attention masking to restrict its receptive field to these\nregions, enabling a focused analysis while filtering out potentially spurious\ninformation. Both stages are trained jointly, allowing stage 2 to refine stage\n1. Extensive experiments across diverse benchmarks demonstrate that our\napproach significantly improves robustness against spurious correlations and\nout-of-distribution backgrounds.", "AI": {"tldr": "The paper proposes a two-stage attention-based method using binary masks to focus on relevant image regions, improving robustness against spurious correlations and out-of-distribution backgrounds.", "motivation": "Context can bias object perception, especially in out-of-distribution backgrounds, while many tasks require identifying relevant regions. The paper aims to balance context use and focus.", "method": "A two-stage framework: stage 1 processes the full image to identify task-relevant regions, and stage 2 uses attention masks to focus on these regions, filtering out spurious information. Both stages are trained jointly.", "result": "The method significantly improves robustness against spurious correlations and out-of-distribution backgrounds across diverse benchmarks.", "conclusion": "The proposed approach effectively balances context use and focused analysis, enhancing object perception in challenging scenarios."}}
{"id": "2506.08652", "pdf": "https://arxiv.org/pdf/2506.08652", "abs": "https://arxiv.org/abs/2506.08652", "authors": ["Mahesh Godavarti"], "title": "JoFormer (Journey-based Transformer): Theory and Empirical Analysis on the Tiny Shakespeare Dataset", "categories": ["cs.LG", "cs.AI", "20-XX, 08A02", "F.4.1; I.2"], "comment": null, "summary": "Transformers have demonstrated remarkable success in sequence modeling, yet\neffectively incorporating positional information remains a challenging and\nactive area of research. In this paper, we introduce JoFormer, a journey-based\nTransformer architecture grounded in a recently proposed non-commutative\nalgebra for composing transformations across positions. JoFormer represents\nrelative positions through learnable directional transforms that are\nsequentially composed along the input, thereby extending and generalizing\nexisting approaches based on relative position representations. We derive the\nJoFormer attention mechanism from first principles and show that it subsumes\nstandard methods such as rotary transformations as special cases. To evaluate\nits effectiveness, we compare JoFormer to the RoFormer baseline on the Tiny\nShakespeare character-level language modeling task. Our results demonstrate\nthat\n  JoFormer consistently achieves lower perplexity and faster convergence,\nhighlighting the advantages of its more expressive, journey-based treatment of\nposition. Notably, the per-token JoFormer is still a primitive, conceptual\nvariant with layer-independent angles, yet it already demonstrates strong\nperformance-underscoring its promise as a proof of concept for more expressive\narchitectures. We conclude by discussing how JoFormer offers a principled\napproach to integrating positional structure into Transformer architectures.\nThe code used in this work is available at\nhttps://github.com/mahesh-godavarti/joformer.", "AI": {"tldr": "JoFormer is a journey-based Transformer architecture using non-commutative algebra for positional information, outperforming RoFormer in perplexity and convergence.", "motivation": "To address the challenge of effectively incorporating positional information in Transformers.", "method": "Introduces JoFormer with learnable directional transforms for relative positions, generalizing existing approaches.", "result": "JoFormer achieves lower perplexity and faster convergence than RoFormer on Tiny Shakespeare.", "conclusion": "JoFormer provides a principled way to integrate positional structure into Transformers, showing promise for more expressive architectures."}}
{"id": "2506.08644", "pdf": "https://arxiv.org/pdf/2506.08644", "abs": "https://arxiv.org/abs/2506.08644", "authors": ["Woosung Kim", "JunHo Seo", "Jongmin Lee", "Byung-Jun Lee"], "title": "Semi-gradient DICE for Offline Constrained Reinforcement Learning", "categories": ["cs.LG"], "comment": "Constrained Offline Reinforcement Learning", "summary": "Stationary Distribution Correction Estimation (DICE) addresses the mismatch\nbetween the stationary distribution induced by a policy and the target\ndistribution required for reliable off-policy evaluation (OPE) and policy\noptimization. DICE-based offline constrained RL particularly benefits from the\nflexibility of DICE, as it simultaneously maximizes return while estimating\ncosts in offline settings. However, we have observed that recent approaches\ndesigned to enhance the offline RL performance of the DICE framework\ninadvertently undermine its ability to perform OPE, making them unsuitable for\nconstrained RL scenarios. In this paper, we identify the root cause of this\nlimitation: their reliance on a semi-gradient optimization, which solves a\nfundamentally different optimization problem and results in failures in cost\nestimation. Building on these insights, we propose a novel method to enable OPE\nand constrained RL through semi-gradient DICE. Our method ensures accurate cost\nestimation and achieves state-of-the-art performance on the offline constrained\nRL benchmark, DSRL.", "AI": {"tldr": "DICE corrects distribution mismatch for OPE and policy optimization, but recent methods degrade OPE. A new semi-gradient DICE method fixes this, excelling in offline constrained RL.", "motivation": "Address the degradation of OPE in DICE-based offline RL methods due to semi-gradient optimization, hindering constrained RL applications.", "method": "Proposes a novel semi-gradient DICE method to enable accurate OPE and constrained RL, addressing the limitations of prior approaches.", "result": "Achieves state-of-the-art performance on the DSRL benchmark, ensuring reliable cost estimation.", "conclusion": "The new method successfully resolves OPE issues in DICE, making it viable for constrained RL."}}
{"id": "2506.08188", "pdf": "https://arxiv.org/pdf/2506.08188", "abs": "https://arxiv.org/abs/2506.08188", "authors": ["Wenlong Meng", "Shuguo Fan", "Chengkun Wei", "Min Chen", "Yuwei Li", "Yuanchao Zhang", "Zhikun Zhang", "Wenzhi Chen"], "title": "GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors", "categories": ["cs.CR", "cs.CL"], "comment": "Accepted to USENIX Security'25", "summary": "In this paper, we introduce GradEscape, the first gradient-based evader\ndesigned to attack AI-generated text (AIGT) detectors. GradEscape overcomes the\nundifferentiable computation problem, caused by the discrete nature of text, by\nintroducing a novel approach to construct weighted embeddings for the detector\ninput. It then updates the evader model parameters using feedback from victim\ndetectors, achieving high attack success with minimal text modification. To\naddress the issue of tokenizer mismatch between the evader and the detector, we\nintroduce a warm-started evader method, enabling GradEscape to adapt to\ndetectors across any language model architecture. Moreover, we employ novel\ntokenizer inference and model extraction techniques, facilitating effective\nevasion even in query-only access.\n  We evaluate GradEscape on four datasets and three widely-used language\nmodels, benchmarking it against four state-of-the-art AIGT evaders.\nExperimental results demonstrate that GradEscape outperforms existing evaders\nin various scenarios, including with an 11B paraphrase model, while utilizing\nonly 139M parameters. We have successfully applied GradEscape to two real-world\ncommercial AIGT detectors. Our analysis reveals that the primary vulnerability\nstems from disparity in text expression styles within the training data. We\nalso propose a potential defense strategy to mitigate the threat of AIGT\nevaders. We open-source our GradEscape for developing more robust AIGT\ndetectors.", "AI": {"tldr": "GradEscape is a gradient-based evader for AI-generated text detectors, overcoming undifferentiable computation with weighted embeddings and achieving high attack success with minimal text modification.", "motivation": "To address the challenge of attacking AI-generated text detectors due to the discrete nature of text and tokenizer mismatches.", "method": "Uses weighted embeddings, warm-started evader, tokenizer inference, and model extraction techniques to adapt to detectors across architectures.", "result": "Outperforms state-of-the-art evaders on four datasets and three language models, even with a smaller model (139M parameters).", "conclusion": "GradEscape exposes vulnerabilities in AIGT detectors due to training data disparities and proposes a defense strategy, with the tool open-sourced for robust detector development."}}
{"id": "2506.08927", "pdf": "https://arxiv.org/pdf/2506.08927", "abs": "https://arxiv.org/abs/2506.08927", "authors": ["David Acuna", "Ximing Lu", "Jaehun Jung", "Hyunwoo Kim", "Amlan Kar", "Sanja Fidler", "Yejin Choi"], "title": "Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent research in vision-language models (VLMs) has centered around the\npossibility of equipping them with implicit long-form chain-of-thought\nreasoning -- akin to the success observed in language models -- via\ndistillation and reinforcement learning. But what about the non-reasoning\nmodels already trained and deployed across the internet? Should we simply\nabandon them, or is there hope for a search mechanism that can elicit hidden\nknowledge and induce long reasoning traces -- without any additional training\nor supervision? In this paper, we explore this possibility using a Monte Carlo\nTree Search (MCTS)-inspired algorithm, which injects subquestion-subanswer\npairs into the model's output stream. We show that framing reasoning as a\nsearch process -- where subquestions act as latent decisions within a broader\ninference trajectory -- helps the model \"connect the dots\" between fragmented\nknowledge and produce extended reasoning traces in non-reasoning models. We\nevaluate our method across three benchmarks and observe consistent\nimprovements. Notably, our approach yields a 2% overall improvement on\nMMMU-PRO, including a significant 9% gain in Liberal Arts.", "AI": {"tldr": "The paper explores using Monte Carlo Tree Search (MCTS) to induce long reasoning traces in non-reasoning vision-language models without additional training.", "motivation": "To address whether existing non-reasoning models can be leveraged for long-form reasoning without retraining or supervision.", "method": "An MCTS-inspired algorithm injects subquestion-subanswer pairs into the model's output to frame reasoning as a search process.", "result": "Consistent improvements across benchmarks, including a 2% overall gain on MMMU-PRO and a 9% boost in Liberal Arts.", "conclusion": "Search-based reasoning can elicit hidden knowledge and extend reasoning in non-reasoning models without training."}}
{"id": "2506.08660", "pdf": "https://arxiv.org/pdf/2506.08660", "abs": "https://arxiv.org/abs/2506.08660", "authors": ["Jinkwan Jang", "Hyungjin Park", "Jinmyeong Choi", "Taesup Kim"], "title": "Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world time series data are inherently multivariate, often exhibiting\ncomplex inter-channel dependencies. Each channel is typically sampled at its\nown period and is prone to missing values due to various practical and\noperational constraints. These characteristics pose fundamental challenges\nrelated to channel dependency, sampling asynchrony, and missingness, all of\nwhich must be addressed to enable robust and reliable forecasting in practical\nsettings. However, most existing architectures are built on oversimplified\nassumptions, such as identical sampling periods across channels and fully\nobserved inputs at test time, which often do not hold in real-world scenarios.\nTo bridge this gap, we propose ChannelTokenFormer, a Transformer-based\nforecasting model with a flexible architecture designed to explicitly capture\ncross-channel interactions, accommodate channel-wise asynchronous sampling, and\neffectively handle missing values. Extensive experiments on three benchmark\ndatasets modified to reflect practical settings, along with one real-world\nindustrial dataset, demonstrate the superior robustness and accuracy of\nChannelTokenFormer under challenging real-world conditions.", "AI": {"tldr": "ChannelTokenFormer is a Transformer-based model addressing challenges like cross-channel dependencies, asynchronous sampling, and missing values in multivariate time series forecasting.", "motivation": "Real-world time series data are complex, with varying sampling periods and missing values, but existing models oversimplify these issues.", "method": "Proposes ChannelTokenFormer, a flexible Transformer architecture capturing cross-channel interactions, handling asynchronous sampling, and missing values.", "result": "Outperforms benchmarks on modified datasets and a real-world industrial dataset, showing robustness and accuracy.", "conclusion": "ChannelTokenFormer effectively addresses real-world challenges in multivariate time series forecasting."}}
{"id": "2506.08645", "pdf": "https://arxiv.org/pdf/2506.08645", "abs": "https://arxiv.org/abs/2506.08645", "authors": ["Youqi Wu", "Jingwei Zhang", "Farzan Farnia"], "title": "Fusing Cross-modal and Uni-modal Representations: A Kronecker Product Approach", "categories": ["cs.LG"], "comment": null, "summary": "Cross-modal embeddings, such as CLIP, BLIP and their variants, have achieved\npromising results in aligning representations across modalities. However, these\nembeddings could underperform compared to state-of-the-art single-modality\nembeddings on modality-specific tasks. On the other hand, single-modality\nembeddings excel in their domains but lack cross-modal alignment capabilities.\nIn this work, we focus on the problem of unifying cross-modality and\nsingle-modality embeddings to achieve the performance of modality-expert\nembedding within individual modalities while preserving cross-modal alignment.\nTo this end, we propose RP-KrossFuse, a method that leverages a random\nprojection-based Kronecker product to integrate cross-modal embeddings with\nsingle-modality embeddings. RP-KrossFuse aims to fuse the sample-pairwise\nsimilarity scores of the fused embeddings and operates efficiently in a\nspecified kernel space and supports scalable implementations via random Fourier\nfeatures for shift-invariant kernels such as the Gaussian kernel. We\ndemonstrate the effectiveness of RP-KrossFuse through several numerical\nexperiments, combining CLIP embeddings with uni-modal image and text\nembeddings. Our numerical results indicate that RP-KrossFuse achieves\ncompetitive modality-specific performance while retaining cross-modal\nalignment, bridging the gap between cross-modal and single-modality embeddings.", "AI": {"tldr": "RP-KrossFuse unifies cross-modal and single-modality embeddings, achieving strong modality-specific performance while preserving cross-modal alignment.", "motivation": "Cross-modal embeddings underperform in modality-specific tasks, while single-modality embeddings lack cross-modal alignment. The goal is to combine both for optimal performance.", "method": "RP-KrossFuse uses random projection-based Kronecker product to integrate embeddings, operating efficiently in a kernel space with scalable implementations.", "result": "RP-KrossFuse achieves competitive modality-specific performance while retaining cross-modal alignment, as shown in experiments with CLIP and uni-modal embeddings.", "conclusion": "RP-KrossFuse successfully bridges the gap between cross-modal and single-modality embeddings, offering a unified solution."}}
{"id": "2506.08249", "pdf": "https://arxiv.org/pdf/2506.08249", "abs": "https://arxiv.org/abs/2506.08249", "authors": ["Ken Gu", "Zhihan Zhang", "Kate Lin", "Yuwei Zhang", "Akshay Paruchuri", "Hong Yu", "Mehran Kazemi", "Kumar Ayush", "A. Ali Heydari", "Maxwell A. Xu", "Girish Narayanswamy", "Yun Liu", "Ming-Zher Poh", "Yuzhe Yang", "Mark Malhotra", "Shwetak Patel", "Hamid Palangi", "Xuhai Xu", "Daniel McDuff", "Tim Althoff", "Xin Liu"], "title": "RADAR: Benchmarking Language Models on Imperfect Tabular Data", "categories": ["cs.DB", "cs.CL"], "comment": null, "summary": "Language models (LMs) are increasingly being deployed to perform autonomous\ndata analyses. However, their data awareness -- the ability to recognize,\nreason over, and appropriately handle data artifacts such as missing values,\noutliers, and logical inconsistencies -- remains underexplored. These artifacts\nare especially common in real-world tabular data and, if mishandled, can\nsignificantly compromise the validity of analytical conclusions. To address\nthis gap, we present RADAR, a benchmark for systematically evaluating\ndata-aware reasoning on tabular data. We develop a framework to simulate data\nartifacts via programmatic perturbations to enable targeted evaluation of model\nbehavior. RADAR comprises 2980 table query pairs, grounded in real-world data\nspanning 9 domains and 5 data artifact types. In addition to evaluating\nartifact handling, RADAR systematically varies table size to study how\nreasoning performance holds when increasing table size. Our evaluation reveals\nthat, despite decent performance on tables without data artifacts, frontier\nmodels degrade significantly when data artifacts are introduced, exposing\ncritical gaps in their capacity for robust, data-aware analysis. Designed to be\nflexible and extensible, RADAR supports diverse perturbation types and\ncontrollable table sizes, offering a valuable resource for advancing tabular\nreasoning.", "AI": {"tldr": "RADAR is a benchmark for evaluating language models' ability to handle data artifacts in tabular data, revealing significant performance gaps when artifacts are present.", "motivation": "Language models lack robust data awareness for handling common data artifacts like missing values and outliers, which can compromise analytical validity.", "method": "Developed RADAR, a benchmark with 2980 table-query pairs across 9 domains, simulating artifacts via programmatic perturbations and varying table sizes.", "result": "Frontier models perform well on clean tables but degrade significantly when data artifacts are introduced, highlighting robustness gaps.", "conclusion": "RADAR provides a flexible, extensible framework for advancing tabular reasoning by evaluating and improving data-aware reasoning in language models."}}
{"id": "2506.08933", "pdf": "https://arxiv.org/pdf/2506.08933", "abs": "https://arxiv.org/abs/2506.08933", "authors": ["Wendong Bu", "Yang Wu", "Qifan Yu", "Minghe Gao", "Bingchen Miao", "Zhenkui Zhang", "Kaihang Pan", "Yunfei Li", "Mengze Li", "Wei Ji", "Juncheng Li", "Siliang Tang", "Yueting Zhuang"], "title": "What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025 (Oral)", "summary": "As multimodal large language models (MLLMs) advance, MLLM-based virtual\nagents have demonstrated remarkable performance. However, existing benchmarks\nface significant limitations, including uncontrollable task complexity,\nextensive manual annotation with limited scenarios, and a lack of\nmultidimensional evaluation. In response to these challenges, we introduce\nOmniBench, a self-generating, cross-platform, graph-based benchmark with an\nautomated pipeline for synthesizing tasks of controllable complexity through\nsubtask composition. To evaluate the diverse capabilities of virtual agents on\nthe graph, we further present OmniEval, a multidimensional evaluation framework\nthat includes subtask-level evaluation, graph-based metrics, and comprehensive\ntests across 10 capabilities. Our synthesized dataset contains 36k\ngraph-structured tasks across 20 scenarios, achieving a 91\\% human acceptance\nrate. Training on our graph-structured data shows that it can more efficiently\nguide agents compared to manually annotated data. We conduct multidimensional\nevaluations for various open-source and closed-source models, revealing their\nperformance across various capabilities and paving the way for future\nadvancements. Our project is available at https://omni-bench.github.io/.", "AI": {"tldr": "OmniBench is a self-generating, cross-platform benchmark for MLLM-based virtual agents, addressing limitations in existing benchmarks with controllable task complexity and automated evaluation.", "motivation": "Existing benchmarks for MLLM-based virtual agents lack controllability, scalability, and multidimensional evaluation, limiting their effectiveness.", "method": "Introduces OmniBench, a graph-based benchmark with automated task synthesis, and OmniEval, a multidimensional evaluation framework covering 10 capabilities.", "result": "A dataset of 36k graph-structured tasks achieves 91% human acceptance, and training on this data improves agent efficiency.", "conclusion": "OmniBench and OmniEval provide a scalable, automated solution for evaluating MLLM-based agents, revealing performance gaps and guiding future advancements."}}
{"id": "2506.08662", "pdf": "https://arxiv.org/pdf/2506.08662", "abs": "https://arxiv.org/abs/2506.08662", "authors": ["Florian Borzechowski", "Michael Sch\u00e4fer", "Heiko Schwarz", "Jonathan Pfaff", "Detlev Marpe", "Thomas Wiegand"], "title": "Optimizing Learned Image Compression on Scalar and Entropy-Constraint Quantization", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted at ICIP2024, the IEEE International Conference on Image\n  Processing", "summary": "The continuous improvements on image compression with variational\nautoencoders have lead to learned codecs competitive with conventional\napproaches in terms of rate-distortion efficiency. Nonetheless, taking the\nquantization into account during the training process remains a problem, since\nit produces zero derivatives almost everywhere and needs to be replaced with a\ndifferentiable approximation which allows end-to-end optimization. Though there\nare different methods for approximating the quantization, none of them model\nthe quantization noise correctly and thus, result in suboptimal networks.\nHence, we propose an additional finetuning training step: After conventional\nend-to-end training, parts of the network are retrained on quantized latents\nobtained at the inference stage. For entropy-constraint quantizers like\nTrellis-Coded Quantization, the impact of the quantizer is particularly\ndifficult to approximate by rounding or adding noise as the quantized latents\nare interdependently chosen through a trellis search based on both the entropy\nmodel and a distortion measure. We show that retraining on correctly quantized\ndata consistently yields additional coding gain for both uniform scalar and\nespecially for entropy-constraint quantization, without increasing inference\ncomplexity. For the Kodak test set, we obtain average savings between 1% and\n2%, and for the TecNick test set up to 2.2% in terms of Bj{\\o}ntegaard-Delta\nbitrate.", "AI": {"tldr": "The paper proposes a finetuning training step for image compression with variational autoencoders to address quantization noise issues, improving coding gain without added inference complexity.", "motivation": "Quantization in training produces zero derivatives, and existing approximations fail to model quantization noise correctly, leading to suboptimal networks.", "method": "After conventional end-to-end training, parts of the network are retrained on quantized latents obtained during inference, particularly effective for entropy-constraint quantizers.", "result": "Retraining on correctly quantized data yields 1%-2.2% savings in Bj\u00f8ntegaard-Delta bitrate for test sets like Kodak and TecNick.", "conclusion": "The proposed finetuning step improves rate-distortion efficiency for learned codecs, especially with entropy-constraint quantization."}}
{"id": "2506.08655", "pdf": "https://arxiv.org/pdf/2506.08655", "abs": "https://arxiv.org/abs/2506.08655", "authors": ["Kamil Jerabek", "Jan Luxemburk", "Richard Plny", "Josef Koumar", "Jaroslav Pesek", "Karel Hynek"], "title": "When Simple Model Just Works: Is Network Traffic Classification in Crisis?", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Machine learning has been applied to network traffic classification (TC) for\nover two decades. While early efforts used shallow models, the latter 2010s saw\na shift toward complex neural networks, often reporting near-perfect accuracy.\nHowever, it was recently revealed that a simple k-NN baseline using packet\nsequences metadata (sizes, times, and directions) can be on par or even\noutperform more complex methods. In this paper, we investigate this phenomenon\nfurther and evaluate this baseline across 12 datasets and 15 TC tasks, and\ninvestigate why it performs so well. Our analysis shows that most datasets\ncontain over 50% redundant samples (identical packet sequences), which\nfrequently appear in both training and test sets due to common splitting\npractices. This redundancy can lead to overestimated model performance and\nreduce the theoretical maximum accuracy when identical flows have conflicting\nlabels. Given its distinct characteristics, we further argue that standard\nmachine learning practices adapted from domains like NLP or computer vision may\nbe ill-suited for TC. Finally, we propose new directions for task formulation\nand evaluation to address these challenges and help realign the field.", "AI": {"tldr": "A study reveals that simple k-NN models using packet metadata can match or outperform complex neural networks in network traffic classification, due to dataset redundancy and flawed evaluation practices.", "motivation": "To investigate why simple k-NN baselines perform well in traffic classification and to highlight issues with current datasets and evaluation methods.", "method": "Evaluated the k-NN baseline across 12 datasets and 15 tasks, analyzing dataset redundancy and splitting practices.", "result": "Found over 50% redundant samples in most datasets, leading to inflated performance metrics and theoretical accuracy limits.", "conclusion": "Proposes new task formulation and evaluation directions to address dataset redundancy and improve traffic classification research."}}
{"id": "2506.08949", "pdf": "https://arxiv.org/pdf/2506.08949", "abs": "https://arxiv.org/abs/2506.08949", "authors": ["Hongjie Zhu", "Xiwei Liu", "Rundong Xue", "Zeyu Zhang", "Yong Xu", "Daji Ergu", "Ying Cai", "Yang Zhao"], "title": "SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "In the era of information explosion, efficiently leveraging large-scale\nunlabeled data while minimizing the reliance on high-quality pixel-level\nannotations remains a critical challenge in the field of medical imaging.\nSemi-supervised learning (SSL) enhances the utilization of unlabeled data by\nfacilitating knowledge transfer, significantly improving the performance of\nfully supervised models and emerging as a highly promising research direction\nin medical image analysis. Inspired by the ability of Vision Foundation Models\n(e.g., SAM-2) to provide rich prior knowledge, we propose SSS (Semi-Supervised\nSAM-2), a novel approach that leverages SAM-2's robust feature extraction\ncapabilities to uncover latent knowledge in unlabeled medical images, thus\neffectively enhancing feature support for fully supervised medical image\nsegmentation. Specifically, building upon the single-stream \"weak-to-strong\"\nconsistency regularization framework, this paper introduces a Discriminative\nFeature Enhancement (DFE) mechanism to further explore the feature\ndiscrepancies introduced by various data augmentation strategies across\nmultiple views. By leveraging feature similarity and dissimilarity across\nmulti-scale augmentation techniques, the method reconstructs and models the\nfeatures, thereby effectively optimizing the salient regions. Furthermore, a\nprompt generator is developed that integrates Physical Constraints with a\nSliding Window (PCSW) mechanism to generate input prompts for unlabeled data,\nfulfilling SAM-2's requirement for additional prompts. Extensive experiments\ndemonstrate the superiority of the proposed method for semi-supervised medical\nimage segmentation on two multi-label datasets, i.e., ACDC and BHSD. Notably,\nSSS achieves an average Dice score of 53.15 on BHSD, surpassing the previous\nstate-of-the-art method by +3.65 Dice. Code will be available at\nhttps://github.com/AIGeeksGroup/SSS.", "AI": {"tldr": "SSS (Semi-Supervised SAM-2) leverages SAM-2's feature extraction to enhance semi-supervised medical image segmentation, achieving state-of-the-art results.", "motivation": "To address the challenge of leveraging unlabeled medical data efficiently while reducing reliance on costly pixel-level annotations.", "method": "Combines SAM-2's feature extraction with a Discriminative Feature Enhancement mechanism and a prompt generator integrating Physical Constraints with a Sliding Window.", "result": "Achieves an average Dice score of 53.15 on BHSD, surpassing previous methods by +3.65 Dice.", "conclusion": "SSS demonstrates superior performance in semi-supervised medical image segmentation, offering a promising direction for future research."}}
{"id": "2506.08669", "pdf": "https://arxiv.org/pdf/2506.08669", "abs": "https://arxiv.org/abs/2506.08669", "authors": ["Dongge Han", "Menglin Xia", "Daniel Madrigal Diaz", "Samuel Kessler", "Ankur Mallick", "Xuchao Zhang", "Mirian Del Carmen Hipolito Garcia", "Jin Xu", "Victor R\u00fchle", "Saravan Rajmohan"], "title": "Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search", "categories": ["cs.LG", "cs.AI"], "comment": "TTODLer-FM Workshop@ICML'25 (Tiny Titans: The next wave of On-Device\n  Learning for Foundational Models)", "summary": "Small language models (SLMs) offer promising and efficient alternatives to\nlarge language models (LLMs). However, SLMs' limited capacity restricts their\nreasoning capabilities and makes them sensitive to prompt variations. To\naddress these challenges, we propose a novel framework that enhances SLM\nreasoning capabilities through LLM generated blueprints. The blueprints provide\nstructured, high-level reasoning guides that help SLMs systematically tackle\nrelated problems. Furthermore, our framework integrates a prompt template\nsearch mechanism to mitigate the SLMs' sensitivity to prompt variations. Our\nframework demonstrates improved SLM performance across various tasks, including\nmath (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improves\nthe reasoning capabilities of SLMs without increasing model size or requiring\nadditional training, offering a lightweight and deployment-friendly solution\nfor on-device or resource-constrained environments.", "AI": {"tldr": "A framework enhances small language models (SLMs) using LLM-generated blueprints and prompt template search, improving reasoning without increasing model size.", "motivation": "SLMs are efficient but limited in reasoning and sensitive to prompt variations, needing a lightweight solution.", "method": "Proposes a framework with LLM-generated blueprints for structured reasoning and prompt template search to reduce sensitivity.", "result": "Improved SLM performance in math (GSM8K), coding (MBPP), and logic reasoning (BBH) tasks.", "conclusion": "The framework offers a lightweight, deployment-friendly solution for enhancing SLMs without additional training or size increase."}}
{"id": "2506.08673", "pdf": "https://arxiv.org/pdf/2506.08673", "abs": "https://arxiv.org/abs/2506.08673", "authors": ["Diptarka Chakraborty", "Kushagra Chatterjee", "Debarati Das", "Tien Long Nguyen", "Romina Nobahari"], "title": "Towards Fair Representation: Clustering and Consensus", "categories": ["cs.LG", "cs.DS"], "comment": "The paper has been accepted at the Conference on Learning Theory\n  (COLT) 2025", "summary": "Consensus clustering, a fundamental task in machine learning and data\nanalysis, aims to aggregate multiple input clusterings of a dataset,\npotentially based on different non-sensitive attributes, into a single\nclustering that best represents the collective structure of the data. In this\nwork, we study this fundamental problem through the lens of fair clustering, as\nintroduced by Chierichetti et al. [NeurIPS'17], which incorporates the\ndisparate impact doctrine to ensure proportional representation of each\nprotected group in the dataset within every cluster. Our objective is to find a\nconsensus clustering that is not only representative but also fair with respect\nto specific protected attributes. To the best of our knowledge, we are the\nfirst to address this problem and provide a constant-factor approximation.\n  As part of our investigation, we examine how to minimally modify an existing\nclustering to enforce fairness -- an essential postprocessing step in many\nclustering applications that require fair representation. We develop an optimal\nalgorithm for datasets with equal group representation and near-linear time\nconstant factor approximation algorithms for more general scenarios with\ndifferent proportions of two group sizes. We complement our approximation\nresult by showing that the problem is NP-hard for two unequal-sized groups.\nGiven the fundamental nature of this problem, we believe our results on Closest\nFair Clustering could have broader implications for other clustering problems,\nparticularly those for which no prior approximation guarantees exist for their\nfair variants.", "AI": {"tldr": "The paper introduces fair consensus clustering, ensuring proportional representation of protected groups, and provides approximation algorithms for fairness enforcement.", "motivation": "To address the lack of fairness in consensus clustering by ensuring proportional representation of protected groups, inspired by fair clustering principles.", "method": "Develops optimal and near-linear time approximation algorithms for fair consensus clustering, including NP-hardness proof for unequal-sized groups.", "result": "Provides constant-factor approximation for fair consensus clustering and optimal solutions for equal group representation.", "conclusion": "The work advances fair clustering with broader implications for clustering problems lacking fairness guarantees."}}
{"id": "2506.08762", "pdf": "https://arxiv.org/pdf/2506.08762", "abs": "https://arxiv.org/abs/2506.08762", "authors": ["Issa Sugiura", "Takashi Ishida", "Taro Makino", "Chieko Tazuke", "Takanori Nakagawa", "Kosuke Nakago", "David Ha"], "title": "EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements", "categories": ["q-fin.ST", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "Financial analysis presents complex challenges that could leverage large\nlanguage model (LLM) capabilities. However, the scarcity of challenging\nfinancial datasets, particularly for Japanese financial data, impedes academic\ninnovation in financial analytics. As LLMs advance, this lack of accessible\nresearch resources increasingly hinders their development and evaluation in\nthis specialized domain. To address this gap, we introduce EDINET-Bench, an\nopen-source Japanese financial benchmark designed to evaluate the performance\nof LLMs on challenging financial tasks including accounting fraud detection,\nearnings forecasting, and industry prediction. EDINET-Bench is constructed by\ndownloading annual reports from the past 10 years from Japan's Electronic\nDisclosure for Investors' NETwork (EDINET) and automatically assigning labels\ncorresponding to each evaluation task. Our experiments reveal that even\nstate-of-the-art LLMs struggle, performing only slightly better than logistic\nregression in binary classification for fraud detection and earnings\nforecasting. These results highlight significant challenges in applying LLMs to\nreal-world financial applications and underscore the need for domain-specific\nadaptation. Our dataset, benchmark construction code, and evaluation code is\npublicly available to facilitate future research in finance with LLMs.", "AI": {"tldr": "EDINET-Bench is an open-source Japanese financial benchmark for evaluating LLMs on tasks like fraud detection and earnings forecasting, revealing their limitations in financial applications.", "motivation": "The scarcity of challenging financial datasets, especially for Japanese data, hinders LLM development and evaluation in financial analytics.", "method": "Constructed by downloading 10 years of annual reports from EDINET, labeling them for tasks like fraud detection and earnings forecasting.", "result": "State-of-the-art LLMs perform only slightly better than logistic regression, showing challenges in financial applications.", "conclusion": "The benchmark highlights the need for domain-specific LLM adaptation and provides resources for future research."}}
{"id": "2506.08953", "pdf": "https://arxiv.org/pdf/2506.08953", "abs": "https://arxiv.org/abs/2506.08953", "authors": ["Anirudh Nanduri", "Siyuan Huang", "Rama Chellappa"], "title": "Cross-Spectral Body Recognition with Side Information Embedding: Benchmarks on LLCM and Analyzing Range-Induced Occlusions on IJB-MDF", "categories": ["cs.CV"], "comment": null, "summary": "Vision Transformers (ViTs) have demonstrated impressive performance across a\nwide range of biometric tasks, including face and body recognition. In this\nwork, we adapt a ViT model pretrained on visible (VIS) imagery to the\nchallenging problem of cross-spectral body recognition, which involves matching\nimages captured in the visible and infrared (IR) domains. Recent ViT\narchitectures have explored incorporating additional embeddings beyond\ntraditional positional embeddings. Building on this idea, we integrate Side\nInformation Embedding (SIE) and examine the impact of encoding domain and\ncamera information to enhance cross-spectral matching. Surprisingly, our\nresults show that encoding only camera information - without explicitly\nincorporating domain information - achieves state-of-the-art performance on the\nLLCM dataset. While occlusion handling has been extensively studied in\nvisible-spectrum person re-identification (Re-ID), occlusions in\nvisible-infrared (VI) Re-ID remain largely underexplored - primarily because\nexisting VI-ReID datasets, such as LLCM, SYSU-MM01, and RegDB, predominantly\nfeature full-body, unoccluded images. To address this gap, we analyze the\nimpact of range-induced occlusions using the IARPA Janus Benchmark Multi-Domain\nFace (IJB-MDF) dataset, which provides a diverse set of visible and infrared\nimages captured at various distances, enabling cross-range, cross-spectral\nevaluations.", "AI": {"tldr": "A ViT model pretrained on visible imagery is adapted for cross-spectral body recognition, achieving state-of-the-art results by encoding camera information. The study also explores occlusions in VI-ReID using the IJB-MDF dataset.", "motivation": "To enhance cross-spectral matching by adapting ViTs for visible-infrared body recognition and addressing the underexplored issue of occlusions in VI-ReID.", "method": "Integrates Side Information Embedding (SIE) to encode domain and camera information, and evaluates performance on the LLCM dataset. Uses IJB-MDF for occlusion analysis.", "result": "Encoding only camera information achieves state-of-the-art performance on LLCM. Occlusion impact is analyzed using IJB-MDF.", "conclusion": "Camera information encoding is more effective than domain encoding for cross-spectral matching, and occlusions in VI-ReID warrant further study."}}
{"id": "2506.08698", "pdf": "https://arxiv.org/pdf/2506.08698", "abs": "https://arxiv.org/abs/2506.08698", "authors": ["Boyu Xie", "Tangtang Xie"], "title": "Variational Autoencoder-Based Approach to Latent Feature Analysis on Efficient Representation of Power Load Monitoring Data", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 2 figures", "summary": "With the development of smart grids, High-Dimensional and Incomplete (HDI)\nPower Load Monitoring (PLM) data challenges the performance of Power Load\nForecasting (PLF) models. In this paper, we propose a potential\ncharacterization model VAE-LF based on Variational Autoencoder (VAE) for\nefficiently representing and complementing PLM missing data. VAE-LF learns a\nlow-dimensional latent representation of the data using an Encoder-Decoder\nstructure by splitting the HDI PLM data into vectors and feeding them\nsequentially into the VAE-LF model, and generates the complementary data.\nExperiments on the UK-DALE dataset show that VAE-LF outperforms other benchmark\nmodels in both 5% and 10% sparsity test cases, with significantly lower RMSE\nand MAE, and especially outperforms on low sparsity ratio data. The method\nprovides an efficient data-completion solution for electric load management in\nsmart grids.", "AI": {"tldr": "VAE-LF, a VAE-based model, improves power load forecasting by efficiently representing and completing high-dimensional, incomplete power load monitoring data, outperforming benchmarks in sparse data scenarios.", "motivation": "High-dimensional and incomplete power load monitoring data challenges forecasting models, necessitating an efficient solution for data representation and completion.", "method": "VAE-LF uses an encoder-decoder structure to learn low-dimensional latent representations and generate complementary data from split vectors of the input data.", "result": "VAE-LF achieves lower RMSE and MAE than benchmarks, especially in 5% and 10% sparsity cases, and excels with low sparsity data.", "conclusion": "VAE-LF offers an effective data-completion solution for smart grid load management."}}
{"id": "2506.08681", "pdf": "https://arxiv.org/pdf/2506.08681", "abs": "https://arxiv.org/abs/2506.08681", "authors": ["Phuc Minh Nguyen", "Ngoc-Hieu Nguyen", "Duy H. M. Nguyen", "Anji Liu", "An Mai", "Binh T. Nguyen", "Daniel Sonntag", "Khoa D. Doan"], "title": "Mitigating Reward Over-optimization in Direct Alignment Algorithms with Importance Sampling", "categories": ["cs.LG"], "comment": "First version", "summary": "Direct Alignment Algorithms (DAAs) such as Direct Preference Optimization\n(DPO) have emerged as alternatives to the standard Reinforcement Learning from\nHuman Feedback (RLHF) for aligning large language models (LLMs) with human\nvalues. However, these methods are more susceptible to over-optimization, in\nwhich the model drifts away from the reference policy, leading to degraded\nperformance as training progresses. This paper proposes a novel\nimportance-sampling approach to mitigate the over-optimization problem of\noffline DAAs. This approach, called (IS-DAAs), multiplies the DAA objective\nwith an importance ratio that accounts for the reference policy distribution.\nIS-DAAs additionally avoid the high variance issue associated with importance\nsampling by clipping the importance ratio to a maximum value. Our extensive\nexperiments demonstrate that IS-DAAs can effectively mitigate\nover-optimization, especially under low regularization strength, and achieve\nbetter performance than other methods designed to address this problem. Our\nimplementations are provided publicly at this link.", "AI": {"tldr": "IS-DAAs, an importance-sampling approach, mitigates over-optimization in Direct Alignment Algorithms (DAAs) like DPO by clipping the importance ratio, improving performance under low regularization.", "motivation": "DAAs (e.g., DPO) align LLMs with human values but suffer from over-optimization, degrading performance as training progresses.", "method": "Proposes IS-DAAs, which multiplies the DAA objective with a clipped importance ratio to account for the reference policy distribution.", "result": "IS-DAAs effectively mitigate over-optimization, especially with low regularization, outperforming other methods.", "conclusion": "IS-DAAs offer a robust solution to over-optimization in DAAs, with public implementations available."}}
{"id": "2506.08989", "pdf": "https://arxiv.org/pdf/2506.08989", "abs": "https://arxiv.org/abs/2506.08989", "authors": ["Xiao Liang", "Zhong-Zhi Li", "Yeyun Gong", "Yang Wang", "Hengyuan Zhang", "Yelong Shen", "Ying Nian Wu", "Weizhu Chen"], "title": "SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": "Reinforcement Learning; Large Language Models; LLM Reasoning", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective\nfor training large language models (LLMs) on complex reasoning tasks, such as\nmathematical problem solving. A prerequisite for the scalability of RLVR is a\nhigh-quality problem set with precise and verifiable answers. However, the\nscarcity of well-crafted human-labeled math problems and limited-verification\nanswers in existing distillation-oriented synthetic datasets limit their\neffectiveness in RL. Additionally, most problem synthesis strategies\nindiscriminately expand the problem set without considering the model's\ncapabilities, leading to low efficiency in generating useful questions. To\nmitigate this issue, we introduce a Self-aware Weakness-driven problem\nSynthesis framework (SwS) that systematically identifies model deficiencies and\nleverages them for problem augmentation. Specifically, we define weaknesses as\nquestions that the model consistently fails to learn through its iterative\nsampling during RL training. We then extract the core concepts from these\nfailure cases and synthesize new problems to strengthen the model's weak areas\nin subsequent augmented training, enabling it to focus on and gradually\novercome its weaknesses. Without relying on external knowledge distillation,\nour framework enables robust generalization byempowering the model to\nself-identify and address its weaknesses in RL, yielding average performance\ngains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning\nbenchmarks.", "AI": {"tldr": "RLVR improves LLM training for reasoning tasks, but lacks quality problem sets. The SwS framework synthesizes problems targeting model weaknesses, boosting performance by 10.0% and 7.7% on benchmarks.", "motivation": "Existing datasets lack precise, verifiable answers, and problem synthesis often ignores model capabilities, limiting RL effectiveness.", "method": "SwS identifies model weaknesses from failure cases, extracts core concepts, and synthesizes targeted problems for augmented training.", "result": "Average performance gains of 10.0% (7B model) and 7.7% (32B model) across eight reasoning benchmarks.", "conclusion": "SwS enables self-improvement in RL by focusing on weaknesses, enhancing generalization without external distillation."}}
{"id": "2506.08955", "pdf": "https://arxiv.org/pdf/2506.08955", "abs": "https://arxiv.org/abs/2506.08955", "authors": ["Chunming He", "Kai Li", "Yachao Zhang", "Ziyun Yang", "Youwei Pang", "Longxiang Tang", "Chengyu Fang", "Yulun Zhang", "Linghe Kong", "Xiu Li", "Sina Farsiu"], "title": "Segment Concealed Objects with Incomplete Supervision", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "IEEE TPAMI", "summary": "Incompletely-Supervised Concealed Object Segmentation (ISCOS) involves\nsegmenting objects that seamlessly blend into their surrounding environments,\nutilizing incompletely annotated data, such as weak and semi-annotations, for\nmodel training. This task remains highly challenging due to (1) the limited\nsupervision provided by the incompletely annotated training data, and (2) the\ndifficulty of distinguishing concealed objects from the background, which\narises from the intrinsic similarities in concealed scenarios. In this paper,\nwe introduce the first unified method for ISCOS to address these challenges. To\ntackle the issue of incomplete supervision, we propose a unified mean-teacher\nframework, SEE, that leverages the vision foundation model, ``\\emph{Segment\nAnything Model (SAM)}'', to generate pseudo-labels using coarse masks produced\nby the teacher model as prompts. To mitigate the effect of low-quality\nsegmentation masks, we introduce a series of strategies for pseudo-label\ngeneration, storage, and supervision. These strategies aim to produce\ninformative pseudo-labels, store the best pseudo-labels generated, and select\nthe most reliable components to guide the student model, thereby ensuring\nrobust network training. Additionally, to tackle the issue of intrinsic\nsimilarity, we design a hybrid-granularity feature grouping module that groups\nfeatures at different granularities and aggregates these results. By clustering\nsimilar features, this module promotes segmentation coherence, facilitating\nmore complete segmentation for both single-object and multiple-object images.\nWe validate the effectiveness of our approach across multiple ISCOS tasks, and\nexperimental results demonstrate that our method achieves state-of-the-art\nperformance. Furthermore, SEE can serve as a plug-and-play solution, enhancing\nthe performance of existing models.", "AI": {"tldr": "The paper introduces SEE, a unified method for Incompletely-Supervised Concealed Object Segmentation (ISCOS), leveraging SAM for pseudo-label generation and hybrid-granularity feature grouping to improve segmentation accuracy.", "motivation": "Addressing the challenges of limited supervision from incomplete annotations and the difficulty of distinguishing concealed objects from backgrounds due to intrinsic similarities.", "method": "Proposes SEE, a mean-teacher framework using SAM for pseudo-label generation, strategies for pseudo-label quality management, and a hybrid-granularity feature grouping module.", "result": "Achieves state-of-the-art performance in ISCOS tasks and enhances existing models as a plug-and-play solution.", "conclusion": "SEE effectively tackles ISCOS challenges, offering robust training and improved segmentation coherence."}}
{"id": "2506.08727", "pdf": "https://arxiv.org/pdf/2506.08727", "abs": "https://arxiv.org/abs/2506.08727", "authors": ["Samarth Sikand", "Rohit Mehra", "Priyavanshi Pathania", "Nikhil Bamby", "Vibhu Saujanya Sharma", "Vikrant Kaulgud", "Sanjay Podder", "Adam P. Burden"], "title": "Breaking the ICE: Exploring promises and challenges of benchmarks for Inference Carbon & Energy estimation for LLMs", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.SE"], "comment": "5 pages. To be published in the proceedings of 9th International\n  Workshop on Green and Sustainable Software (GREENS '25), April 29, 2025,\n  Ottawa, Canada (Co-located with ICSE 2025)", "summary": "While Generative AI stands to be one of the fastest adopted technologies\never, studies have made evident that the usage of Large Language Models (LLMs)\nputs significant burden on energy grids and our environment. It may prove a\nhindrance to the Sustainability goals of any organization. A crucial step in\nany Sustainability strategy is monitoring or estimating the energy consumption\nof various components. While there exist multiple tools for monitoring energy\nconsumption, there is a dearth of tools/frameworks for estimating the\nconsumption or carbon emissions. Current drawbacks of both monitoring and\nestimation tools include high input data points, intrusive nature, high error\nmargin, etc. We posit that leveraging emerging LLM benchmarks and related data\npoints can help overcome aforementioned challenges while balancing accuracy of\nthe emission estimations. To that extent, we discuss the challenges of current\napproaches and present our evolving framework, R-ICE, which estimates prompt\nlevel inference carbon emissions by leveraging existing state-of-the-art(SOTA)\nbenchmark. This direction provides a more practical and non-intrusive way to\nenable emerging use-cases like dynamic LLM routing, carbon accounting, etc. Our\npromising validation results suggest that benchmark-based modelling holds great\npotential for inference emission estimation and warrants further exploration\nfrom the scientific community.", "AI": {"tldr": "The paper addresses the environmental impact of LLMs and introduces R-ICE, a framework for estimating prompt-level carbon emissions using SOTA benchmarks.", "motivation": "The rapid adoption of Generative AI and LLMs poses sustainability challenges due to their high energy consumption, necessitating better tools for emission estimation.", "method": "The authors propose R-ICE, a framework leveraging existing LLM benchmarks to estimate carbon emissions non-intrusively and accurately.", "result": "Validation results show promise for benchmark-based modeling in emission estimation, enabling use-cases like dynamic LLM routing and carbon accounting.", "conclusion": "The study highlights the potential of benchmark-based approaches for sustainable AI and calls for further exploration by the scientific community."}}
{"id": "2506.08737", "pdf": "https://arxiv.org/pdf/2506.08737", "abs": "https://arxiv.org/abs/2506.08737", "authors": ["Haozhe Ma", "Guoji Fu", "Zhengding Luo", "Jiele Wu", "Tze-Yun Leong"], "title": "Exploration by Random Reward Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Random Reward Perturbation (RRP), a novel exploration strategy\nfor reinforcement learning (RL). Our theoretical analyses demonstrate that\nadding zero-mean noise to environmental rewards effectively enhances policy\ndiversity during training, thereby expanding the range of exploration. RRP is\nfully compatible with the action-perturbation-based exploration strategies,\nsuch as $\\epsilon$-greedy, stochastic policies, and entropy regularization,\nproviding additive improvements to exploration effects. It is general,\nlightweight, and can be integrated into existing RL algorithms with minimal\nimplementation effort and negligible computational overhead. RRP establishes a\ntheoretical connection between reward shaping and noise-driven exploration,\nhighlighting their complementary potential. Experiments show that RRP\nsignificantly boosts the performance of Proximal Policy Optimization and Soft\nActor-Critic, achieving higher sample efficiency and escaping local optima\nacross various tasks, under both sparse and dense reward scenarios.", "AI": {"tldr": "RRP is a lightweight exploration strategy for RL that adds zero-mean noise to rewards, enhancing policy diversity and exploration. It integrates easily with existing methods and improves performance in tasks with sparse or dense rewards.", "motivation": "To enhance exploration in RL by diversifying policies through reward perturbation, addressing limitations of existing exploration strategies.", "method": "Adds zero-mean noise to environmental rewards, compatible with action-perturbation methods like $\u03b5$-greedy and entropy regularization.", "result": "Boosts performance of PPO and SAC, improving sample efficiency and escaping local optima in various tasks.", "conclusion": "RRP is a general, effective, and easy-to-implement exploration strategy that complements existing methods and enhances RL performance."}}
{"id": "2506.09026", "pdf": "https://arxiv.org/pdf/2506.09026", "abs": "https://arxiv.org/abs/2506.09026", "authors": ["Amrith Setlur", "Matthew Y. R. Yang", "Charlie Snell", "Jeremy Greer", "Ian Wu", "Virginia Smith", "Max Simchowitz", "Aviral Kumar"], "title": "e3: Learning to Explore Enables Extrapolation of Test-Time Compute for LLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Test-time scaling offers a promising path to improve LLM reasoning by\nutilizing more compute at inference time; however, the true promise of this\nparadigm lies in extrapolation (i.e., improvement in performance on hard\nproblems as LLMs keep \"thinking\" for longer, beyond the maximum token budget\nthey were trained on). Surprisingly, we find that most existing reasoning\nmodels do not extrapolate well. We show that one way to enable extrapolation is\nby training the LLM to perform in-context exploration: training the LLM to\neffectively spend its test time budget by chaining operations (such as\ngeneration, verification, refinement, etc.), or testing multiple hypotheses\nbefore it commits to an answer. To enable in-context exploration, we identify\nthree key ingredients as part of our recipe e3: (1) chaining skills that the\nbase LLM has asymmetric competence in, e.g., chaining verification (easy) with\ngeneration (hard), as a way to implement in-context search; (2) leveraging\n\"negative\" gradients from incorrect traces to amplify exploration during RL,\nresulting in longer search traces that chains additional asymmetries; and (3)\ncoupling task difficulty with training token budget during training via a\nspecifically-designed curriculum to structure in-context exploration. Our\nrecipe e3 produces the best known 1.7B model according to AIME'25 and HMMT'25\nscores, and extrapolates to 2x the training token budget. Our e3-1.7B model not\nonly attains high pass@1 scores, but also improves pass@k over the base model.", "AI": {"tldr": "The paper introduces a method (e3) to improve LLM reasoning by enabling in-context exploration, allowing models to extrapolate beyond their training token budget and achieve better performance on hard problems.", "motivation": "Existing reasoning models fail to extrapolate well beyond their training token limits, limiting their potential for solving harder problems with extended 'thinking' time.", "method": "The e3 method involves training LLMs for in-context exploration by chaining asymmetric skills (e.g., verification and generation), leveraging negative gradients for exploration, and using a curriculum to match task difficulty with token budget.", "result": "The e3-1.7B model outperforms others on benchmarks (AIME'25, HMMT'25), extrapolates to 2x the training token budget, and improves pass@1 and pass@k scores.", "conclusion": "In-context exploration, enabled by e3, significantly enhances LLM reasoning and extrapolation capabilities, offering a scalable solution for improving performance on challenging tasks."}}
{"id": "2506.08956", "pdf": "https://arxiv.org/pdf/2506.08956", "abs": "https://arxiv.org/abs/2506.08956", "authors": ["DaeEun Yoon", "Semin Kim", "SangWook Yoo", "Jongha Lee"], "title": "Data Augmentation For Small Object using Fast AutoAugment", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted and published in the USB Proceedings of the 20th\n  International Conference on Modeling Decisions for Artificial Intelligence\n  (MDAI 2023), Ume{\\aa}, Sweden, June 19--22, 2023, ISBN 978-91-527-7293-5,\n  pp.\\ 12--21", "summary": "In recent years, there has been tremendous progress in object detection\nperformance. However, despite these advances, the detection performance for\nsmall objects is significantly inferior to that of large objects. Detecting\nsmall objects is one of the most challenging and important problems in computer\nvision. To improve the detection performance for small objects, we propose an\noptimal data augmentation method using Fast AutoAugment. Through our proposed\nmethod, we can quickly find optimal augmentation policies that can overcome\ndegradation when detecting small objects, and we achieve a 20% performance\nimprovement on the DOTA dataset.", "AI": {"tldr": "Proposes an optimal data augmentation method using Fast AutoAugment to improve small object detection, achieving a 20% performance boost on the DOTA dataset.", "motivation": "Small object detection lags behind large object detection despite overall progress in object detection. Addressing this gap is crucial for computer vision.", "method": "Uses Fast AutoAugment to quickly find optimal augmentation policies for small object detection.", "result": "Achieves a 20% performance improvement on the DOTA dataset.", "conclusion": "The proposed method effectively enhances small object detection performance."}}
{"id": "2506.08743", "pdf": "https://arxiv.org/pdf/2506.08743", "abs": "https://arxiv.org/abs/2506.08743", "authors": ["Michael F\u00e4rber", "David Lamprecht", "Yuni Susanti"], "title": "Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.DB", "cs.LG"], "comment": "Accepted at DASFAA 2025", "summary": "Graph Neural Networks (GNNs) have substantially advanced the field of\nrecommender systems. However, despite the creation of more than a thousand\nknowledge graphs (KGs) under the W3C standard RDF, their rich semantic\ninformation has not yet been fully leveraged in GNN-based recommender systems.\nTo address this gap, we propose a comprehensive integration of RDF KGs with\nGNNs that utilizes both the topological information from RDF object properties\nand the content information from RDF datatype properties. Our main focus is an\nin-depth evaluation of various GNNs, analyzing how different semantic feature\ninitializations and types of graph structure heterogeneity influence their\nperformance in recommendation tasks. Through experiments across multiple\nrecommendation scenarios involving multi-million-node RDF graphs, we\ndemonstrate that harnessing the semantic richness of RDF KGs significantly\nimproves recommender systems and lays the groundwork for GNN-based recommender\nsystems for the Linked Open Data cloud. The code and data are available on our\nGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation", "AI": {"tldr": "The paper proposes integrating RDF knowledge graphs (KGs) with GNNs to enhance recommender systems by leveraging semantic and topological information, showing significant performance improvements.", "motivation": "Despite the abundance of RDF KGs, their semantic richness is underutilized in GNN-based recommender systems.", "method": "Comprehensive integration of RDF KGs with GNNs, evaluating semantic feature initializations and graph structure heterogeneity.", "result": "Experiments show that leveraging RDF KGs' semantic richness significantly improves recommender system performance.", "conclusion": "The work advances GNN-based recommender systems for the Linked Open Data cloud, with code and data publicly available."}}
{"id": "2506.08740", "pdf": "https://arxiv.org/pdf/2506.08740", "abs": "https://arxiv.org/abs/2506.08740", "authors": ["Sidhika Balachandar", "Shuvom Sadhuka", "Bonnie Berger", "Emma Pierson", "Nikhil Garg"], "title": "Urban Incident Prediction with Graph Neural Networks: Integrating Government Ratings and Crowdsourced Reports", "categories": ["cs.LG"], "comment": null, "summary": "Graph neural networks (GNNs) are widely used in urban spatiotemporal\nforecasting, such as predicting infrastructure problems. In this setting,\ngovernment officials wish to know in which neighborhoods incidents like\npotholes or rodent issues occur. The true state of incidents (e.g., street\nconditions) for each neighborhood is observed via government inspection\nratings. However, these ratings are only conducted for a sparse set of\nneighborhoods and incident types. We also observe the state of incidents via\ncrowdsourced reports, which are more densely observed but may be biased due to\nheterogeneous reporting behavior. First, for such settings, we propose a\nmultiview, multioutput GNN-based model that uses both unbiased rating data and\nbiased reporting data to predict the true latent state of incidents. Second, we\ninvestigate a case study of New York City urban incidents and collect,\nstandardize, and make publicly available a dataset of 9,615,863 crowdsourced\nreports and 1,041,415 government inspection ratings over 3 years and across 139\ntypes of incidents. Finally, we show on both real and semi-synthetic data that\nour model can better predict the latent state compared to models that use only\nreporting data or models that use only rating data, especially when rating data\nis sparse and reports are predictive of ratings. We also quantify demographic\nbiases in crowdsourced reporting, e.g., higher-income neighborhoods report\nproblems at higher rates. Our analysis showcases a widely applicable approach\nfor latent state prediction using heterogeneous, sparse, and biased data.", "AI": {"tldr": "A GNN-based model combines sparse government ratings and dense but biased crowdsourced reports to predict urban incidents, outperforming single-source models and revealing reporting biases.", "motivation": "Government inspection ratings are sparse, while crowdsourced reports are dense but biased. A method is needed to leverage both for accurate incident prediction.", "method": "Proposes a multiview, multioutput GNN model integrating both rating and reporting data. Tests on NYC data with 9.6M reports and 1M ratings.", "result": "The model outperforms single-source models, especially when ratings are sparse. Reveals demographic biases in reporting (e.g., higher-income areas report more).", "conclusion": "The approach effectively predicts latent incident states using heterogeneous, sparse, and biased data, with broad applicability."}}
{"id": "2506.09040", "pdf": "https://arxiv.org/pdf/2506.09040", "abs": "https://arxiv.org/abs/2506.09040", "authors": ["Dianyi Wang", "Wei Song", "Yikun Wang", "Siyuan Wang", "Kaicheng Yu", "Zhongyu Wei", "Jiaqi Wang"], "title": "Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Typical large vision-language models (LVLMs) apply autoregressive supervision\nsolely to textual sequences, without fully incorporating the visual modality\ninto the learning process. This results in three key limitations: (1) an\ninability to utilize images without accompanying captions, (2) the risk that\ncaptions omit critical visual details, and (3) the challenge that certain\nvision-centric content cannot be adequately conveyed through text. As a result,\ncurrent LVLMs often prioritize vision-to-language alignment while potentially\noverlooking fine-grained visual information. While some prior works have\nexplored autoregressive image generation, effectively leveraging autoregressive\nvisual supervision to enhance image understanding remains an open challenge. In\nthis paper, we introduce Autoregressive Semantic Visual Reconstruction (ASVR),\nwhich enables joint learning of visual and textual modalities within a unified\nautoregressive framework. We show that autoregressively reconstructing the raw\nvisual appearance of images does not enhance and may even impair multimodal\nunderstanding. In contrast, autoregressively reconstructing the semantic\nrepresentation of images consistently improves comprehension. Notably, we find\nthat even when models are given continuous image features as input, they can\neffectively reconstruct discrete semantic tokens, resulting in stable and\nconsistent improvements across a wide range of multimodal understanding\nbenchmarks. Our approach delivers significant performance gains across varying\ndata scales (556k-2M) and types of LLM bacbones. Specifically, ASVR improves\nLLaVA-1.5 by 5% in average scores across 14 multimodal benchmarks. The code is\navailable at https://github.com/AlenjandroWang/ASVR.", "AI": {"tldr": "ASVR introduces joint learning of visual and textual modalities in LVLMs, improving multimodal understanding by reconstructing semantic representations of images.", "motivation": "Current LVLMs lack full visual modality integration, leading to limitations like incomplete visual detail capture and vision-centric content inadequacy.", "method": "ASVR uses autoregressive semantic visual reconstruction within a unified framework, avoiding raw visual appearance reconstruction.", "result": "ASVR improves multimodal benchmarks, e.g., boosting LLaVA-1.5 by 5% across 14 benchmarks, and works with various data scales and LLM backbones.", "conclusion": "Autoregressive semantic reconstruction enhances LVLMs' multimodal understanding, outperforming raw visual reconstruction."}}
{"id": "2506.08964", "pdf": "https://arxiv.org/pdf/2506.08964", "abs": "https://arxiv.org/abs/2506.08964", "authors": ["Jinwoo Kim", "Sangmin Han", "Jinho Jeong", "Jiwoo Choi", "Dongyoung Kim", "Seon Joo Kim"], "title": "ORIDa: Object-centric Real-world Image Composition Dataset", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025", "summary": "Object compositing, the task of placing and harmonizing objects in images of\ndiverse visual scenes, has become an important task in computer vision with the\nrise of generative models. However, existing datasets lack the diversity and\nscale required to comprehensively explore real-world scenarios. We introduce\nORIDa (Object-centric Real-world Image Composition Dataset), a large-scale,\nreal-captured dataset containing over 30,000 images featuring 200 unique\nobjects, each of which is presented across varied positions and scenes. ORIDa\nhas two types of data: factual-counterfactual sets and factual-only scenes. The\nfactual-counterfactual sets consist of four factual images showing an object in\ndifferent positions within a scene and a single counterfactual (or background)\nimage of the scene without the object, resulting in five images per scene. The\nfactual-only scenes include a single image containing an object in a specific\ncontext, expanding the variety of environments. To our knowledge, ORIDa is the\nfirst publicly available dataset with its scale and complexity for real-world\nimage composition. Extensive analysis and experiments highlight the value of\nORIDa as a resource for advancing further research in object compositing.", "AI": {"tldr": "ORIDa is a large-scale dataset for object compositing, featuring 30,000+ images with 200 unique objects in diverse scenes, including factual-counterfactual sets and factual-only scenes.", "motivation": "Existing datasets lack diversity and scale for real-world object compositing tasks, limiting research progress.", "method": "ORIDa introduces two data types: factual-counterfactual sets (5 images per scene) and factual-only scenes (single image per context).", "result": "ORIDa is the first publicly available dataset of its scale and complexity, enabling comprehensive research in object compositing.", "conclusion": "ORIDa advances object compositing research by providing a diverse, real-world dataset for extensive analysis and experimentation."}}
{"id": "2506.08756", "pdf": "https://arxiv.org/pdf/2506.08756", "abs": "https://arxiv.org/abs/2506.08756", "authors": ["Octavio Arriaga", "Rebecca Adam", "Melvin Laux", "Lisa Gutzeit", "Marco Ragni", "Jan Peters", "Frank Kirchner"], "title": "Bayesian Inverse Physics for Neuro-Symbolic Robot Learning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Real-world robotic applications, from autonomous exploration to assistive\ntechnologies, require adaptive, interpretable, and data-efficient learning\nparadigms. While deep learning architectures and foundation models have driven\nsignificant advances in diverse robotic applications, they remain limited in\ntheir ability to operate efficiently and reliably in unknown and dynamic\nenvironments. In this position paper, we critically assess these limitations\nand introduce a conceptual framework for combining data-driven learning with\ndeliberate, structured reasoning. Specifically, we propose leveraging\ndifferentiable physics for efficient world modeling, Bayesian inference for\nuncertainty-aware decision-making, and meta-learning for rapid adaptation to\nnew tasks. By embedding physical symbolic reasoning within neural models,\nrobots could generalize beyond their training data, reason about novel\nsituations, and continuously expand their knowledge. We argue that such hybrid\nneuro-symbolic architectures are essential for the next generation of\nautonomous systems, and to this end, we provide a research roadmap to guide and\naccelerate their development.", "AI": {"tldr": "The paper proposes a hybrid neuro-symbolic framework combining data-driven learning with structured reasoning to enhance robotic adaptability and interpretability in dynamic environments.", "motivation": "Current deep learning and foundation models lack efficiency and reliability in unknown, dynamic environments, necessitating a more adaptive and interpretable approach.", "method": "The framework integrates differentiable physics for world modeling, Bayesian inference for uncertainty-aware decisions, and meta-learning for rapid task adaptation.", "result": "The proposed hybrid architecture enables robots to generalize beyond training data, reason about novel situations, and expand knowledge continuously.", "conclusion": "Hybrid neuro-symbolic architectures are crucial for next-gen autonomous systems, and a research roadmap is provided to advance their development."}}
{"id": "2506.08764", "pdf": "https://arxiv.org/pdf/2506.08764", "abs": "https://arxiv.org/abs/2506.08764", "authors": ["Benjamin Dadoun", "Soufiane Hayou", "Hanan Salam", "Mohamed El Amine Seddik", "Pierre Youssef"], "title": "On the Stability of the Jacobian Matrix in Deep Neural Networks", "categories": ["cs.LG", "68T07, 60B20"], "comment": "16 pages, 26 figures", "summary": "Deep neural networks are known to suffer from exploding or vanishing\ngradients as depth increases, a phenomenon closely tied to the spectral\nbehavior of the input-output Jacobian. Prior work has identified critical\ninitialization schemes that ensure Jacobian stability, but these analyses are\ntypically restricted to fully connected networks with i.i.d. weights. In this\nwork, we go significantly beyond these limitations: we establish a general\nstability theorem for deep neural networks that accommodates sparsity (such as\nthat introduced by pruning) and non-i.i.d., weakly correlated weights (e.g.\ninduced by training). Our results rely on recent advances in random matrix\ntheory, and provide rigorous guarantees for spectral stability in a much\nbroader class of network models. This extends the theoretical foundation for\ninitialization schemes in modern neural networks with structured and dependent\nrandomness.", "AI": {"tldr": "A general stability theorem for deep neural networks is introduced, accommodating sparsity and non-i.i.d. weights, extending prior work on Jacobian stability.", "motivation": "Address limitations of prior work on Jacobian stability, which was restricted to fully connected networks with i.i.d. weights.", "method": "Leverage random matrix theory to analyze spectral stability in networks with sparsity and weakly correlated weights.", "result": "Rigorous guarantees for spectral stability in a broader class of network models, including pruned and trained networks.", "conclusion": "The work extends theoretical foundations for initialization schemes in modern neural networks with structured randomness."}}
{"id": "2206.05446", "pdf": "https://arxiv.org/pdf/2206.05446", "abs": "https://arxiv.org/abs/2206.05446", "authors": ["Effi Levi", "Shaul R. Shenhav"], "title": "A Decomposition-Based Approach for Evaluating and Analyzing Inter-Annotator Disagreement", "categories": ["cs.CL"], "comment": null, "summary": "We propose a novel method to conceptually decompose an existing annotation\ninto separate levels, allowing the analysis of inter-annotators disagreement in\neach level separately. We suggest two distinct strategies in order to actualize\nthis approach: a theoretically-driven one, in which the researcher defines a\ndecomposition based on prior knowledge of the annotation task, and an\nexploration-based one, in which many possible decompositions are inductively\ncomputed and presented to the researcher for interpretation and evaluation.\nUtilizing a recently constructed dataset for narrative analysis as our\nuse-case, we apply each of the two strategies to demonstrate the potential of\nour approach in testing hypotheses regarding the sources of annotation\ndisagreements, as well as revealing latent structures and relations within the\nannotation task. We conclude by suggesting how to extend and generalize our\napproach, as well as use it for other purposes.", "AI": {"tldr": "A novel method decomposes annotations into levels to analyze inter-annotator disagreements separately, using theoretical and exploration-based strategies.", "motivation": "To better understand and analyze sources of annotation disagreements and reveal latent structures in annotation tasks.", "method": "Two strategies: theoretically-driven (researcher-defined decomposition) and exploration-based (inductive computation of decompositions).", "result": "Demonstrated potential in testing hypotheses about annotation disagreements and uncovering latent structures in narrative analysis.", "conclusion": "The approach can be extended, generalized, and adapted for other purposes."}}
{"id": "2506.08968", "pdf": "https://arxiv.org/pdf/2506.08968", "abs": "https://arxiv.org/abs/2506.08968", "authors": ["Amirreza Rouhi", "Solmaz Arezoomandan", "Knut Peterson", "Joseph T. Woods", "David K. Han"], "title": "ADAM: Autonomous Discovery and Annotation Model using LLMs for Context-Aware Annotations", "categories": ["cs.CV"], "comment": null, "summary": "Object detection models typically rely on predefined categories, limiting\ntheir ability to identify novel objects in open-world scenarios. To overcome\nthis constraint, we introduce ADAM: Autonomous Discovery and Annotation Model,\na training-free, self-refining framework for open-world object labeling. ADAM\nleverages large language models (LLMs) to generate candidate labels for unknown\nobjects based on contextual information from known entities within a scene.\nThese labels are paired with visual embeddings from CLIP to construct an\nEmbedding-Label Repository (ELR) that enables inference without category\nsupervision. For a newly encountered unknown object, ADAM retrieves visually\nsimilar instances from the ELR and applies frequency-based voting and\ncross-modal re-ranking to assign a robust label. To further enhance\nconsistency, we introduce a self-refinement loop that re-evaluates repository\nlabels using visual cohesion analysis and k-nearest-neighbor-based majority\nre-labeling. Experimental results on the COCO and PASCAL datasets demonstrate\nthat ADAM effectively annotates novel categories using only visual and\ncontextual signals, without requiring any fine-tuning or retraining.", "AI": {"tldr": "ADAM is a training-free, self-refining framework for open-world object labeling, using LLMs and CLIP to generate and refine labels for unknown objects without predefined categories.", "motivation": "Overcome the limitation of predefined categories in object detection models for identifying novel objects in open-world scenarios.", "method": "Leverages LLMs for contextual label generation and CLIP for visual embeddings, constructs an Embedding-Label Repository (ELR), and uses frequency-based voting, cross-modal re-ranking, and a self-refinement loop for robust labeling.", "result": "Effectively annotates novel categories on COCO and PASCAL datasets without fine-tuning or retraining.", "conclusion": "ADAM demonstrates a viable approach for open-world object labeling by combining contextual and visual signals autonomously."}}
{"id": "2506.08774", "pdf": "https://arxiv.org/pdf/2506.08774", "abs": "https://arxiv.org/abs/2506.08774", "authors": ["Fan Xu", "Luis A. Leiva"], "title": "Multimodal Representation Alignment for Cross-modal Information Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Different machine learning models can represent the same underlying concept\nin different ways. This variability is particularly valuable for in-the-wild\nmultimodal retrieval, where the objective is to identify the corresponding\nrepresentation in one modality given another modality as input. This challenge\ncan be effectively framed as a feature alignment problem. For example, given a\nsentence encoded by a language model, retrieve the most semantically aligned\nimage based on features produced by an image encoder, or vice versa. In this\nwork, we first investigate the geometric relationships between visual and\ntextual embeddings derived from both vision-language models and combined\nunimodal models. We then align these representations using four standard\nsimilarity metrics as well as two learned ones, implemented via neural\nnetworks. Our findings indicate that the Wasserstein distance can serve as an\ninformative measure of the modality gap, while cosine similarity consistently\noutperforms alternative metrics in feature alignment tasks. Furthermore, we\nobserve that conventional architectures such as multilayer perceptrons are\ninsufficient for capturing the complex interactions between image and text\nrepresentations. Our study offers novel insights and practical considerations\nfor researchers working in multimodal information retrieval, particularly in\nreal-world, cross-modal applications.", "AI": {"tldr": "The paper explores feature alignment in multimodal retrieval, comparing geometric relationships between visual and textual embeddings and evaluating similarity metrics. Wasserstein distance and cosine similarity are highlighted, with the latter performing best. Traditional architectures like MLPs are found inadequate for cross-modal tasks.", "motivation": "To address the challenge of aligning representations across modalities (e.g., text and images) for effective multimodal retrieval in real-world applications.", "method": "Investigates geometric relationships between visual and textual embeddings, evaluates four standard and two learned similarity metrics (including neural networks), and tests alignment performance.", "result": "Wasserstein distance is useful for measuring the modality gap, while cosine similarity excels in alignment tasks. Traditional architectures (e.g., MLPs) are insufficient for cross-modal interactions.", "conclusion": "Provides insights and practical guidelines for multimodal retrieval, emphasizing the superiority of cosine similarity and the limitations of conventional architectures."}}
{"id": "2506.08837", "pdf": "https://arxiv.org/pdf/2506.08837", "abs": "https://arxiv.org/abs/2506.08837", "authors": ["Luca Beurer-Kellner", "Beat Buesser Ana-Maria Cre\u0163u", "Edoardo Debenedetti", "Daniel Dobos", "Daniel Fabian", "Marc Fischer", "David Froelicher", "Kathrin Grosse", "Daniel Naeff", "Ezinwanne Ozoani", "Andrew Paverd", "Florian Tram\u00e8r", "V\u00e1clav Volhejn"], "title": "Design Patterns for Securing LLM Agents against Prompt Injections", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "As AI agents powered by Large Language Models (LLMs) become increasingly\nversatile and capable of addressing a broad spectrum of tasks, ensuring their\nsecurity has become a critical challenge. Among the most pressing threats are\nprompt injection attacks, which exploit the agent's resilience on natural\nlanguage inputs -- an especially dangerous threat when agents are granted tool\naccess or handle sensitive information. In this work, we propose a set of\nprincipled design patterns for building AI agents with provable resistance to\nprompt injection. We systematically analyze these patterns, discuss their\ntrade-offs in terms of utility and security, and illustrate their real-world\napplicability through a series of case studies.", "AI": {"tldr": "Proposes design patterns for AI agents to resist prompt injection attacks, balancing utility and security.", "motivation": "Addressing the critical security challenge of prompt injection attacks in versatile AI agents powered by LLMs.", "method": "Introduces principled design patterns for AI agents, analyzing their trade-offs and real-world applicability.", "result": "Demonstrates provable resistance to prompt injection through systematic analysis and case studies.", "conclusion": "Design patterns offer a practical solution to enhance AI agent security against prompt injection."}}
{"id": "2302.14502", "pdf": "https://arxiv.org/pdf/2302.14502", "abs": "https://arxiv.org/abs/2302.14502", "authors": ["Zican Dong", "Tianyi Tang", "Junyi Li", "Wayne Xin Zhao"], "title": "A Survey on Long Text Modeling with Transformers", "categories": ["cs.CL"], "comment": null, "summary": "Modeling long texts has been an essential technique in the field of natural\nlanguage processing (NLP). With the ever-growing number of long documents, it\nis important to develop effective modeling methods that can process and analyze\nsuch texts. However, long texts pose important research challenges for existing\ntext models, with more complex semantics and special characteristics. In this\npaper, we provide an overview of the recent advances on long texts modeling\nbased on Transformer models. Firstly, we introduce the formal definition of\nlong text modeling. Then, as the core content, we discuss how to process long\ninput to satisfy the length limitation and design improved Transformer\narchitectures to effectively extend the maximum context length. Following this,\nwe discuss how to adapt Transformer models to capture the special\ncharacteristics of long texts. Finally, we describe four typical applications\ninvolving long text modeling and conclude this paper with a discussion of\nfuture directions. Our survey intends to provide researchers with a synthesis\nand pointer to related work on long text modeling.", "AI": {"tldr": "A survey on recent advances in long text modeling using Transformer models, covering input processing, architecture improvements, and applications.", "motivation": "Address the challenges of modeling long texts in NLP due to complex semantics and length limitations.", "method": "Review and discuss methods for processing long inputs, extending Transformer architectures, and adapting them for long text characteristics.", "result": "Provides an overview of techniques and applications for long text modeling.", "conclusion": "Summarizes current advancements and suggests future research directions in long text modeling."}}
{"id": "2506.08979", "pdf": "https://arxiv.org/pdf/2506.08979", "abs": "https://arxiv.org/abs/2506.08979", "authors": ["Longyu Yang", "Ping Hu", "Lu Zhang", "Jun Liu", "Yap-Peng Tan", "Heng Tao Shen", "Xiaofeng Zhu"], "title": "Rethinking Range-View LiDAR Segmentation in Adverse Weather", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "LiDAR segmentation has emerged as an important task to enrich multimedia\nexperiences and analysis. Range-view-based methods have gained popularity due\nto their high computational efficiency and compatibility with real-time\ndeployment. However, their generalized performance under adverse weather\nconditions remains underexplored, limiting their reliability in real-world\nenvironments. In this work, we identify and analyze the unique challenges that\naffect the generalization of range-view LiDAR segmentation in severe weather.\nTo address these challenges, we propose a modular and lightweight framework\nthat enhances robustness without altering the core architecture of existing\nmodels. Our method reformulates the initial stem block of standard range-view\nnetworks into two branches to process geometric attributes and reflectance\nintensity separately. Specifically, a Geometric Abnormality Suppression (GAS)\nmodule reduces the influence of weather-induced spatial noise, and a\nReflectance Distortion Calibration (RDC) module corrects reflectance\ndistortions through memory-guided adaptive instance normalization. The\nprocessed features are then fused and passed to the original segmentation\npipeline. Extensive experiments on different benchmarks and baseline models\ndemonstrate that our approach significantly improves generalization to adverse\nweather with minimal inference overhead, offering a practical and effective\nsolution for real-world LiDAR segmentation.", "AI": {"tldr": "A lightweight framework improves range-view LiDAR segmentation robustness in adverse weather by separating geometric and reflectance processing.", "motivation": "Generalized performance of range-view LiDAR segmentation under adverse weather is underexplored, limiting real-world reliability.", "method": "Proposes a modular framework with two branches (GAS and RDC modules) to handle geometric noise and reflectance distortions separately.", "result": "Significantly improves generalization to adverse weather with minimal inference overhead.", "conclusion": "Offers a practical solution for robust real-world LiDAR segmentation."}}
{"id": "2506.08790", "pdf": "https://arxiv.org/pdf/2506.08790", "abs": "https://arxiv.org/abs/2506.08790", "authors": ["Samarth Sikand", "Rohit Mehra", "Vibhu Saujanya Sharma", "Vikrant Kaulgud", "Sanjay Podder", "Adam P. Burden"], "title": "Do Generative AI Tools Ensure Green Code? An Investigative Study", "categories": ["cs.SE", "cs.AI", "cs.CY"], "comment": "4 pages. To be published in the proceedings of 2nd International\n  Workshop on Responsible AI Engineering (RAIE '24), co-located with ICSE '24,\n  Lisbon, Portugal", "summary": "Software sustainability is emerging as a primary concern, aiming to optimize\nresource utilization, minimize environmental impact, and promote a greener,\nmore resilient digital ecosystem. The sustainability or \"greenness\" of software\nis typically determined by the adoption of sustainable coding practices. With a\nmaturing ecosystem around generative AI, many software developers now rely on\nthese tools to generate code using natural language prompts. Despite their\npotential advantages, there is a significant lack of studies on the\nsustainability aspects of AI-generated code. Specifically, how environmentally\nfriendly is the AI-generated code based upon its adoption of sustainable coding\npractices? In this paper, we present the results of an early investigation into\nthe sustainability aspects of AI-generated code across three popular generative\nAI tools - ChatGPT, BARD, and Copilot. The results highlight the default\nnon-green behavior of tools for generating code, across multiple rules and\nscenarios. It underscores the need for further in-depth investigations and\neffective remediation strategies.", "AI": {"tldr": "The paper investigates the sustainability of AI-generated code from ChatGPT, BARD, and Copilot, finding default non-green behaviors and emphasizing the need for further research and solutions.", "motivation": "To address the lack of studies on the sustainability of AI-generated code and its environmental impact.", "method": "An early investigation into AI-generated code from three tools (ChatGPT, BARD, Copilot) assessing sustainable coding practices.", "result": "AI-generated code exhibits default non-green behavior across multiple rules and scenarios.", "conclusion": "Highlights the need for deeper research and remediation strategies to improve the sustainability of AI-generated code."}}
{"id": "2506.08844", "pdf": "https://arxiv.org/pdf/2506.08844", "abs": "https://arxiv.org/abs/2506.08844", "authors": ["Siyi Sun", "David Antony Selby", "Yunchuan Huang", "Sebastian Vollmer", "Seth Flaxman", "Anisoara Calinescu"], "title": "IMAGIC-500: IMputation benchmark on A Generative Imaginary Country (500k samples)", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Missing data imputation in tabular datasets remains a pivotal challenge in\ndata science and machine learning, particularly within socioeconomic research.\nHowever, real-world socioeconomic datasets are typically subject to strict data\nprotection protocols, which often prohibit public sharing, even for synthetic\nderivatives. This severely limits the reproducibility and accessibility of\nbenchmark studies in such settings. Further, there are very few publicly\navailable synthetic datasets. Thus, there is limited availability of benchmarks\nfor systematic evaluation of imputation methods on socioeconomic datasets,\nwhether real or synthetic. In this study, we utilize the World Bank's publicly\navailable synthetic dataset, Synthetic Data for an Imaginary Country, which\nclosely mimics a real World Bank household survey while being fully public,\nenabling broad access for methodological research. With this as a starting\npoint, we derived the IMAGIC-500 dataset: we select a subset of 500k\nindividuals across approximately 100k households with 19 socioeconomic\nfeatures, designed to reflect the hierarchical structure of real-world\nhousehold surveys. This paper introduces a comprehensive missing data\nimputation benchmark on IMAGIC-500 under various missing mechanisms (MCAR, MAR,\nMNAR) and missingness ratios (10\\%, 20\\%, 30\\%, 40\\%, 50\\%). Our evaluation\nconsiders the imputation accuracy for continuous and categorical variables,\ncomputational efficiency, and impact on downstream predictive tasks, such as\nestimating educational attainment at the individual level. The results\nhighlight the strengths and weaknesses of statistical, traditional machine\nlearning, and deep learning imputation techniques, including recent\ndiffusion-based methods. The IMAGIC-500 dataset and benchmark aim to facilitate\nthe development of robust imputation algorithms and foster reproducible social\nscience research.", "AI": {"tldr": "The paper introduces IMAGIC-500, a synthetic dataset for benchmarking missing data imputation methods in socioeconomic research, addressing data privacy and reproducibility challenges.", "motivation": "Real-world socioeconomic datasets face strict privacy restrictions, limiting benchmark availability for imputation methods. The study aims to provide a public, reproducible benchmark.", "method": "Utilizes the World Bank's synthetic dataset to create IMAGIC-500, evaluating imputation methods under various missing mechanisms and ratios.", "result": "Benchmark results reveal performance differences among statistical, machine learning, and deep learning imputation techniques, including diffusion-based methods.", "conclusion": "IMAGIC-500 enables robust imputation algorithm development and reproducible social science research."}}
{"id": "2310.16937", "pdf": "https://arxiv.org/pdf/2310.16937", "abs": "https://arxiv.org/abs/2310.16937", "authors": ["Razan Baltaji", "Saurabh Pujar", "Louis Mandel", "Martin Hirzel", "Luca Buratti", "Lav Varshney"], "title": "Cross-lingual Transfer in Programming Languages: An Extensive Empirical Study", "categories": ["cs.CL", "I.2.7; I.2.5"], "comment": "Published in Transactions on Machine Learning Research (06/2025) 26\n  pages, 5 figures, 10 tables", "summary": "Large language models (LLMs) have achieved state-of-the-art performance in\nvarious software engineering tasks, including error detection, clone detection,\nand code translation, primarily leveraging high-resource programming languages\nlike Python and Java. However, many critical languages, such as COBOL, as well\nas emerging languages, such as Rust and Swift, remain low-resource due to\nlimited openly available code. This scarcity hampers the training and\neffectiveness of LLMs for these languages, increasing software maintenance\ncosts and stifling innovation. Addressing this gap, we investigate the\npotential of transfer learning to enhance LLM performance on low-resource\nprogramming languages by leveraging data from high-resource counterparts. Our\nextensive empirical study evaluates transferability across 10 to 41 programming\nlanguages and five key tasks: code generation, clone detection, code repair,\nsolution domain classification, and error detection. Additionally, we develop a\nperformance prediction model to guess the best source languages for a given\ntarget and task, and analyze the features that influence transfer performance.\nWe further replicate a representative subset of experiments with a larger model\nto test the generalizability of our conclusions to contemporary large-scale\nLLMs. Our findings demonstrate that cross-lingual transfer significantly\noutperforms zero-shot learning, with effectiveness varying based on both source\nand target languages. Furthermore, our model reliably predicts successful\ntransfer sources by considering linguistic and dataset-specific features,\noffering practical guidance for data acquisition and model training. This work\ncontributes to the development of LLM-driven tools for low-resource programming\nlanguages and provides insights into the characteristics that facilitate\ntransfer across language pairs.", "AI": {"tldr": "The paper explores transfer learning to improve LLM performance on low-resource programming languages by leveraging high-resource language data, demonstrating its effectiveness over zero-shot learning and providing a predictive model for optimal source languages.", "motivation": "The scarcity of openly available code for low-resource programming languages like COBOL, Rust, and Swift limits LLM effectiveness, increasing software maintenance costs and hindering innovation.", "method": "The study evaluates transfer learning across 10 to 41 programming languages and five tasks (code generation, clone detection, etc.), develops a performance prediction model, and tests generalizability with a larger LLM.", "result": "Cross-lingual transfer outperforms zero-shot learning, with effectiveness varying by language pair. The predictive model reliably identifies optimal source languages.", "conclusion": "The work aids LLM tool development for low-resource languages and offers insights into transferable features across languages."}}
{"id": "2506.08990", "pdf": "https://arxiv.org/pdf/2506.08990", "abs": "https://arxiv.org/abs/2506.08990", "authors": ["Chenyu Lian", "Hong-Yu Zhou", "Dongyun Liang", "Jing Qin", "Liansheng Wang"], "title": "Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "TMI 2025", "summary": "Medical vision-language alignment through cross-modal contrastive learning\nshows promising performance in image-text matching tasks, such as retrieval and\nzero-shot classification. However, conventional cross-modal contrastive\nlearning (CLIP-based) methods suffer from suboptimal visual representation\ncapabilities, which also limits their effectiveness in vision-language\nalignment. In contrast, although the models pretrained via multimodal masked\nmodeling struggle with direct cross-modal matching, they excel in visual\nrepresentation. To address this contradiction, we propose ALTA (ALign Through\nAdapting), an efficient medical vision-language alignment method that utilizes\nonly about 8% of the trainable parameters and less than 1/5 of the\ncomputational consumption required for masked record modeling. ALTA achieves\nsuperior performance in vision-language matching tasks like retrieval and\nzero-shot classification by adapting the pretrained vision model from masked\nrecord modeling. Additionally, we integrate temporal-multiview radiograph\ninputs to enhance the information consistency between radiographs and their\ncorresponding descriptions in reports, further improving the vision-language\nalignment. Experimental evaluations show that ALTA outperforms the\nbest-performing counterpart by over 4% absolute points in text-to-image\naccuracy and approximately 6% absolute points in image-to-text retrieval\naccuracy. The adaptation of vision-language models during efficient alignment\nalso promotes better vision and language understanding. Code is publicly\navailable at https://github.com/DopamineLcy/ALTA.", "AI": {"tldr": "ALTA improves medical vision-language alignment by adapting pretrained vision models from masked record modeling, achieving better performance with fewer parameters and computational costs.", "motivation": "Conventional cross-modal contrastive learning methods have suboptimal visual representation, while masked modeling excels in visual representation but struggles with cross-modal matching. ALTA aims to bridge this gap.", "method": "ALTA adapts pretrained vision models from masked record modeling, using only 8% trainable parameters and less than 1/5 computational consumption. It integrates temporal-multiview radiograph inputs for better alignment.", "result": "ALTA outperforms counterparts by over 4% in text-to-image accuracy and ~6% in image-to-text retrieval accuracy.", "conclusion": "ALTA efficiently aligns vision-language models, enhancing both vision and language understanding while reducing resource usage."}}
{"id": "2506.08795", "pdf": "https://arxiv.org/pdf/2506.08795", "abs": "https://arxiv.org/abs/2506.08795", "authors": ["Kaijie Shi", "Wanglong Lu", "Hanli Zhao", "Vinicius Prado da Fonseca", "Ting Zou", "Xianta Jiang"], "title": "Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Limb loss affects millions globally, impairing physical function and reducing\nquality of life. Most traditional surface electromyographic (sEMG) and\nsemi-autonomous methods require users to generate myoelectric signals for each\ncontrol, imposing physically and mentally taxing demands. This study aims to\ndevelop a fully autonomous control system that enables a prosthetic hand to\nautomatically grasp and release objects of various shapes using only a camera\nattached to the wrist. By placing the hand near an object, the system will\nautomatically execute grasping actions with a proper grip force in response to\nthe hand's movements and the environment. To release the object being grasped,\njust naturally place the object close to the table and the system will\nautomatically open the hand. Such a system would provide individuals with limb\nloss with a very easy-to-use prosthetic control interface and greatly reduce\nmental effort while using. To achieve this goal, we developed a teleoperation\nsystem to collect human demonstration data for training the prosthetic hand\ncontrol model using imitation learning, which mimics the prosthetic hand\nactions from human. Through training the model using only a few objects' data\nfrom one single participant, we have shown that the imitation learning\nalgorithm can achieve high success rates, generalizing to more individuals and\nunseen objects with a variation of weights. The demonstrations are available at\n\\href{https://sites.google.com/view/autonomous-prosthetic-hand}{https://sites.google.com/view/autonomous-prosthetic-hand}", "AI": {"tldr": "A fully autonomous prosthetic hand control system using a wrist-mounted camera and imitation learning reduces mental effort for users by automating grasping and releasing actions.", "motivation": "Traditional prosthetic control methods are physically and mentally taxing, requiring users to generate myoelectric signals for each action. This study aims to simplify prosthetic use by automating control.", "method": "The system uses a camera on the wrist to detect objects and employs imitation learning, trained with human demonstration data, to autonomously grasp and release objects.", "result": "The system achieved high success rates, generalizing to unseen objects and users with minimal training data from one participant.", "conclusion": "The autonomous prosthetic hand system offers an easy-to-use interface, significantly reducing mental effort and improving quality of life for limb loss patients."}}
{"id": "2506.08850", "pdf": "https://arxiv.org/pdf/2506.08850", "abs": "https://arxiv.org/abs/2506.08850", "authors": ["Amin Avan", "Akramul Azim", "Qusay Mahmoud"], "title": "Agile Reinforcement Learning for Real-Time Task Scheduling in Edge Computing", "categories": ["cs.LG"], "comment": null, "summary": "Soft real-time applications are becoming increasingly complex, posing\nsignificant challenges for scheduling offloaded tasks in edge computing\nenvironments while meeting task timing constraints. Moreover, the exponential\ngrowth of the search space, presence of multiple objectives and parameters, and\nhighly dynamic nature of edge computing environments further exacerbate the\ncomplexity of task scheduling. As a result, schedulers based on heuristic and\nmetaheuristic algorithms frequently encounter difficulties in generating\noptimal or near-optimal task schedules due to their constrained ability to\nadapt to the dynamic conditions and complex environmental characteristics of\nedge computing. Accordingly, reinforcement learning algorithms have been\nincorporated into schedulers to address the complexity and dynamic conditions\ninherent in task scheduling in edge computing. However, a significant\nlimitation of reinforcement learning algorithms is the prolonged learning time\nrequired to adapt to new environments and to address medium- and large-scale\nproblems. This challenge arises from the extensive global action space and\nfrequent random exploration of irrelevant actions. Therefore, this study\nproposes Agile Reinforcement learning (aRL), in which the RL-agent performs\ninformed exploration and executes only relevant actions. Consequently, the\npredictability of the RL-agent is enhanced, leading to rapid adaptation and\nconvergence, which positions aRL as a suitable candidate for scheduling the\ntasks of soft real-time applications in edge computing. The experiments\ndemonstrate that the combination of informed exploration and action-masking\nmethods enables aRL to achieve a higher hit-ratio and converge faster than the\nbaseline approaches.", "AI": {"tldr": "The paper proposes Agile Reinforcement Learning (aRL) for efficient task scheduling in edge computing, addressing the limitations of traditional heuristic and reinforcement learning methods.", "motivation": "The complexity and dynamic nature of edge computing environments make task scheduling challenging, with existing methods struggling to adapt quickly or scale effectively.", "method": "The study introduces aRL, which combines informed exploration and action-masking to reduce irrelevant actions and enhance predictability.", "result": "Experiments show aRL achieves higher hit-ratios and faster convergence compared to baseline approaches.", "conclusion": "aRL is a promising solution for scheduling soft real-time tasks in edge computing due to its adaptability and efficiency."}}
{"id": "2404.01856", "pdf": "https://arxiv.org/pdf/2404.01856", "abs": "https://arxiv.org/abs/2404.01856", "authors": ["Risto Luukkonen", "Jonathan Burdge", "Elaine Zosa", "Aarne Talman", "Ville Komulainen", "V\u00e4in\u00f6 Hatanp\u00e4\u00e4", "Peter Sarlin", "Sampo Pyysalo"], "title": "Poro 34B and the Blessing of Multilinguality", "categories": ["cs.CL"], "comment": null, "summary": "The pretraining of state-of-the-art large language models now requires\ntrillions of words of text, which is orders of magnitude more than available\nfor the vast majority of languages. While including text in more than one\nlanguage is an obvious way to acquire more pretraining data, multilinguality is\noften seen as a curse, and most model training efforts continue to focus\nnear-exclusively on individual large languages. We believe that multilinguality\ncan be a blessing: when the lack of training data is a constraint for\neffectively training larger models for a target language, augmenting the\ndataset with other languages can offer a way to improve over the capabilities\nof monolingual models for that language. In this study, we introduce Poro 34B,\na 34 billion parameter model trained for 1 trillion tokens of Finnish, English,\nand programming languages, and demonstrate that a multilingual training\napproach can produce a model that substantially advances over the capabilities\nof existing models for Finnish and excels in translation, while also achieving\ncompetitive performance in its class for English and programming languages. We\nrelease the model parameters, scripts, and data under open licenses at\nhttps://huggingface.co/LumiOpen/Poro-34B.", "AI": {"tldr": "Multilingual training can enhance model performance for low-resource languages like Finnish, as shown by Poro 34B, which outperforms monolingual models while maintaining competitive results in English and programming languages.", "motivation": "Address the scarcity of training data for most languages by leveraging multilingual datasets to improve model capabilities.", "method": "Train Poro 34B, a 34B parameter model, on 1T tokens of Finnish, English, and programming languages.", "result": "Poro 34B advances Finnish model capabilities, excels in translation, and performs competitively in English and programming tasks.", "conclusion": "Multilingual training is beneficial for low-resource languages, and Poro 34B demonstrates its effectiveness."}}
{"id": "2506.08991", "pdf": "https://arxiv.org/pdf/2506.08991", "abs": "https://arxiv.org/abs/2506.08991", "authors": ["Anudeep Das", "Gurjot Singh", "Prach Chantasantitam", "N. Asokan"], "title": "Do Concept Replacement Techniques Really Erase Unacceptable Concepts?", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Generative models, particularly diffusion-based text-to-image (T2I) models,\nhave demonstrated astounding success. However, aligning them to avoid\ngenerating content with unacceptable concepts (e.g., offensive or copyrighted\ncontent, or celebrity likenesses) remains a significant challenge. Concept\nreplacement techniques (CRTs) aim to address this challenge, often by trying to\n\"erase\" unacceptable concepts from models. Recently, model providers have\nstarted offering image editing services which accept an image and a text prompt\nas input, to produce an image altered as specified by the prompt. These are\nknown as image-to-image (I2I) models. In this paper, we first use an I2I model\nto empirically demonstrate that today's state-of-the-art CRTs do not in fact\nerase unacceptable concepts. Existing CRTs are thus likely to be ineffective in\nemerging I2I scenarios, despite their proven ability to remove unwanted\nconcepts in T2I pipelines, highlighting the need to understand this discrepancy\nbetween T2I and I2I settings. Next, we argue that a good CRT, while replacing\nunacceptable concepts, should preserve other concepts specified in the inputs\nto generative models. We call this fidelity. Prior work on CRTs have neglected\nfidelity in the case of unacceptable concepts. Finally, we propose the use of\ntargeted image-editing techniques to achieve both effectiveness and fidelity.\nWe present such a technique, AntiMirror, and demonstrate its viability.", "AI": {"tldr": "The paper critiques current concept replacement techniques (CRTs) in diffusion models for failing to erase unacceptable concepts in image-to-image (I2I) scenarios, introduces the idea of 'fidelity' for preserving other concepts, and proposes a new technique, AntiMirror, to address these issues.", "motivation": "Aligning generative models to avoid generating unacceptable content (e.g., offensive or copyrighted material) is challenging, especially in emerging I2I scenarios where existing CRTs fail.", "method": "The study empirically tests CRTs in I2I models, identifies their shortcomings, and introduces 'fidelity' as a key requirement. It then proposes AntiMirror, a targeted image-editing technique.", "result": "Current CRTs are ineffective in I2I settings despite working in text-to-image (T2I) pipelines. AntiMirror demonstrates viability in achieving both effectiveness and fidelity.", "conclusion": "The paper highlights the need for improved CRTs in I2I models, introduces 'fidelity' as a critical metric, and presents AntiMirror as a promising solution."}}
{"id": "2506.08822", "pdf": "https://arxiv.org/pdf/2506.08822", "abs": "https://arxiv.org/abs/2506.08822", "authors": ["Yifei Su", "Ning Liu", "Dong Chen", "Zhen Zhao", "Kun Wu", "Meng Li", "Zhiyuan Xu", "Zhengping Che", "Jian Tang"], "title": "FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Generative modeling-based visuomotor policies have been widely adopted in\nrobotic manipulation attributed to their ability to model multimodal action\ndistributions. However, the high inference cost of multi-step sampling limits\ntheir applicability in real-time robotic systems. To address this issue,\nexisting approaches accelerate the sampling process in generative\nmodeling-based visuomotor policies by adapting acceleration techniques\noriginally developed for image generation. Despite this progress, a major\ndistinction remains: image generation typically involves producing independent\nsamples without temporal dependencies, whereas robotic manipulation involves\ngenerating time-series action trajectories that require continuity and temporal\ncoherence. To effectively exploit temporal information in robotic manipulation,\nwe propose FreqPolicy, a novel approach that first imposes frequency\nconsistency constraints on flow-based visuomotor policies. Our work enables the\naction model to capture temporal structure effectively while supporting\nefficient, high-quality one-step action generation. We introduce a frequency\nconsistency constraint that enforces alignment of frequency-domain action\nfeatures across different timesteps along the flow, thereby promoting\nconvergence of one-step action generation toward the target distribution. In\naddition, we design an adaptive consistency loss to capture structural temporal\nvariations inherent in robotic manipulation tasks. We assess FreqPolicy on 53\ntasks across 3 simulation benchmarks, proving its superiority over existing\none-step action generators. We further integrate FreqPolicy into the\nvision-language-action (VLA) model and achieve acceleration without performance\ndegradation on the 40 tasks of Libero. Besides, we show efficiency and\neffectiveness in real-world robotic scenarios with an inference frequency\n93.5Hz. The code will be publicly available.", "AI": {"tldr": "FreqPolicy introduces frequency consistency constraints to improve efficiency and quality of one-step action generation in visuomotor policies for robotic manipulation, outperforming existing methods.", "motivation": "Existing generative modeling-based visuomotor policies face high inference costs due to multi-step sampling, limiting real-time applicability. Temporal dependencies in robotic tasks are not fully exploited.", "method": "FreqPolicy enforces frequency-domain alignment of action features across timesteps and uses an adaptive consistency loss to capture temporal variations.", "result": "FreqPolicy outperforms existing one-step generators on 53 tasks across 3 benchmarks and achieves 93.5Hz inference in real-world scenarios without performance loss.", "conclusion": "FreqPolicy effectively addresses temporal coherence in robotic manipulation, enabling efficient, high-quality one-step action generation."}}
{"id": "2506.08871", "pdf": "https://arxiv.org/pdf/2506.08871", "abs": "https://arxiv.org/abs/2506.08871", "authors": ["Victor M. Tenorio", "Madeline Navarro", "Samuel Rey", "Santiago Segarra", "Antonio G. Marques"], "title": "Adapting to Heterophilic Graph Data with Structure-Guided Neighbor Discovery", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph Neural Networks (GNNs) often struggle with heterophilic data, where\nconnected nodes may have dissimilar labels, as they typically assume homophily\nand rely on local message passing. To address this, we propose creating\nalternative graph structures by linking nodes with similar structural\nattributes (e.g., role-based or global), thereby fostering higher label\nhomophily on these new graphs. We theoretically prove that GNN performance can\nbe improved by utilizing graphs with fewer false positive edges (connections\nbetween nodes of different classes) and that considering multiple graph views\nincreases the likelihood of finding such beneficial structures. Building on\nthese insights, we introduce Structure-Guided GNN (SG-GNN), an architecture\nthat processes the original graph alongside the newly created structural\ngraphs, adaptively learning to weigh their contributions. Extensive experiments\non various benchmark datasets, particularly those with heterophilic\ncharacteristics, demonstrate that our SG-GNN achieves state-of-the-art or\nhighly competitive performance, highlighting the efficacy of exploiting\nstructural information to guide GNNs.", "AI": {"tldr": "SG-GNN improves GNN performance on heterophilic data by creating alternative graph structures with higher label homophily and adaptively combining them with the original graph.", "motivation": "GNNs struggle with heterophilic data due to their reliance on homophily assumptions. This work aims to enhance GNNs by leveraging structural attributes to create more homophilic graphs.", "method": "Proposes SG-GNN, which constructs alternative graphs with similar structural attributes, combines them with the original graph, and adaptively learns their contributions.", "result": "SG-GNN achieves state-of-the-art or competitive performance on heterophilic benchmark datasets.", "conclusion": "Exploiting structural information to guide GNNs is effective, especially for heterophilic data."}}
{"id": "2406.12548", "pdf": "https://arxiv.org/pdf/2406.12548", "abs": "https://arxiv.org/abs/2406.12548", "authors": ["Yuhao Dan", "Jie Zhou", "Qin Chen", "Junfeng Tian", "Liang He"], "title": "P-React: Synthesizing Topic-Adaptive Reactions of Personality Traits via Mixture of Specialized LoRA Experts", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Personalized large language models (LLMs) have attracted great attention in\nmany applications, such as emotional support and role-playing. However,\nexisting works primarily focus on modeling explicit character profiles, while\nignoring the underlying personality traits that truly shape behaviors and\ndecision-making, hampering the development of more anthropomorphic and\npsychologically-grounded AI systems. In this paper, we explore the modeling of\nBig Five personality traits, which is the most widely used trait theory in\npsychology, and propose P-React, a mixture of experts (MoE)-based personalized\nLLM. Particularly, we integrate a Personality Specialization Loss (PSL) to\nbetter capture individual trait expressions, providing a more nuanced and\npsychologically grounded personality simulacrum. To facilitate research in this\nfield, we curate OCEAN-Chat, a high-quality, human-verified dataset designed to\ntrain LLMs in expressing personality traits across diverse topics. Extensive\nexperiments demonstrate the effectiveness of P-React in maintaining consistent\nand real personality.", "AI": {"tldr": "The paper introduces P-React, a personalized LLM that models Big Five personality traits using a MoE-based approach and a novel Personality Specialization Loss (PSL). It also presents OCEAN-Chat, a dataset for training LLMs in personality expression.", "motivation": "Existing LLMs focus on explicit character profiles, neglecting underlying personality traits, limiting anthropomorphic and psychologically-grounded AI development.", "method": "Proposes P-React, a MoE-based LLM with PSL to capture trait expressions, and introduces OCEAN-Chat dataset for training.", "result": "P-React effectively maintains consistent and realistic personality traits, as demonstrated in experiments.", "conclusion": "The work advances personalized LLMs by integrating psychological traits, offering a more nuanced and grounded personality simulacrum."}}
{"id": "2506.08997", "pdf": "https://arxiv.org/pdf/2506.08997", "abs": "https://arxiv.org/abs/2506.08997", "authors": ["Fabian Immel", "Jan-Hendrik Pauls", "Richard Fehler", "Frank Bieder", "Jonas Merkert", "Christoph Stiller"], "title": "SDTagNet: Leveraging Text-Annotated Navigation Maps for Online HD Map Construction", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Autonomous vehicles rely on detailed and accurate environmental information\nto operate safely. High definition (HD) maps offer a promising solution, but\ntheir high maintenance cost poses a significant barrier to scalable deployment.\nThis challenge is addressed by online HD map construction methods, which\ngenerate local HD maps from live sensor data. However, these methods are\ninherently limited by the short perception range of onboard sensors. To\novercome this limitation and improve general performance, recent approaches\nhave explored the use of standard definition (SD) maps as prior, which are\nsignificantly easier to maintain. We propose SDTagNet, the first online HD map\nconstruction method that fully utilizes the information of widely available SD\nmaps, like OpenStreetMap, to enhance far range detection accuracy. Our approach\nintroduces two key innovations. First, in contrast to previous work, we\nincorporate not only polyline SD map data with manually selected classes, but\nadditional semantic information in the form of textual annotations. In this\nway, we enrich SD vector map tokens with NLP-derived features, eliminating the\ndependency on predefined specifications or exhaustive class taxonomies. Second,\nwe introduce a point-level SD map encoder together with orthogonal element\nidentifiers to uniformly integrate all types of map elements. Experiments on\nArgoverse 2 and nuScenes show that this boosts map perception performance by up\nto +5.9 mAP (+45%) w.r.t. map construction without priors and up to +3.2 mAP\n(+20%) w.r.t. previous approaches that already use SD map priors. Code is\navailable at https://github.com/immel-f/SDTagNet", "AI": {"tldr": "SDTagNet enhances online HD map construction by leveraging SD maps and NLP-derived features, improving far-range detection accuracy by up to 45%.", "motivation": "High maintenance costs of HD maps limit scalability; SD maps offer a cheaper alternative but lack detail. SDTagNet aims to bridge this gap.", "method": "Incorporates SD map data (polylines and textual annotations) and introduces a point-level encoder with orthogonal identifiers for uniform integration.", "result": "Boosts performance by up to +5.9 mAP (45%) over no-prior methods and +3.2 mAP (20%) over prior SD-based methods.", "conclusion": "SDTagNet effectively utilizes SD maps and NLP to improve HD map construction, offering a scalable solution with significant accuracy gains."}}
{"id": "2506.08860", "pdf": "https://arxiv.org/pdf/2506.08860", "abs": "https://arxiv.org/abs/2506.08860", "authors": ["Samah Kansab", "Francis Bordeleau", "Ali Tizghadam"], "title": "On The Impact of Merge Request Deviations on Code Review Practices", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Code review is a key practice in software engineering, ensuring quality and\ncollaboration. However, industrial Merge Request (MR) workflows often deviate\nfrom standardized review processes, with many MRs serving non-review purposes\n(e.g., drafts, rebases, or dependency updates). We term these cases deviations\nand hypothesize that ignoring them biases analytics and undermines ML models\nfor review analysis.\n  We identify seven deviation categories, occurring in 37.02% of MRs, and\npropose a few-shot learning detection method (91% accuracy). By excluding\ndeviations, ML models predicting review completion time improve performance in\n53.33% of cases (up to 2.25x) and exhibit significant shifts in feature\nimportance (47% overall, 60% top-*k*).\n  Our contributions include: (1) a taxonomy of MR deviations, (2) an AI-driven\ndetection approach, and (3) empirical evidence of their impact on ML-based\nreview analytics. This work aids practitioners in optimizing review efforts and\nensuring reliable insights.", "AI": {"tldr": "The paper addresses deviations in industrial Merge Request (MR) workflows, identifies seven categories, and proposes a few-shot learning method to detect them (91% accuracy). Excluding deviations improves ML models for review analysis.", "motivation": "Standardized code review processes are often disrupted by non-review MRs (e.g., drafts, rebases), which bias analytics and ML models.", "method": "Identifies seven deviation categories, proposes a few-shot learning detection method, and evaluates its impact on ML models for review completion time prediction.", "result": "Deviations occur in 37.02% of MRs. Excluding them improves ML model performance in 53.33% of cases (up to 2.25x) and shifts feature importance significantly.", "conclusion": "The work provides a taxonomy of MR deviations, an AI-driven detection method, and evidence of their impact, aiding practitioners in optimizing reviews and ensuring reliable analytics."}}
{"id": "2506.08882", "pdf": "https://arxiv.org/pdf/2506.08882", "abs": "https://arxiv.org/abs/2506.08882", "authors": ["Dimitrios Amaxilatis", "Themistoklis Sarantakos", "Ioannis Chatzigiannakis", "Georgios Mylonas"], "title": "Filling in the Blanks: Applying Data Imputation in incomplete Water Metering Data", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we explore the application of recent data imputation techniques\nto enhance monitoring and management of water distribution networks using smart\nwater meters, based on data derived from a real-world IoT water grid monitoring\ndeployment. Despite the detailed data produced by such meters, data gaps due to\ntechnical issues can significantly impact operational decisions and efficiency.\nOur results, by comparing various imputation methods, such as k-Nearest\nNeighbors, MissForest, Transformers, and Recurrent Neural Networks, indicate\nthat effective data imputation can substantially enhance the quality of the\ninsights derived from water consumption data as we study their effect on\naccuracy and reliability of water metering data to provide solutions in\napplications like leak detection and predictive maintenance scheduling.", "AI": {"tldr": "The paper evaluates data imputation techniques for improving water distribution network management using smart meter data, highlighting their impact on accuracy and reliability for applications like leak detection.", "motivation": "Data gaps in smart water meter data due to technical issues can hinder operational efficiency and decision-making, necessitating effective imputation methods.", "method": "The study compares various imputation techniques, including k-Nearest Neighbors, MissForest, Transformers, and Recurrent Neural Networks, using real-world IoT water grid data.", "result": "Effective data imputation significantly improves the quality of insights from water consumption data, enhancing accuracy and reliability for operational applications.", "conclusion": "Data imputation techniques can substantially aid in better monitoring and management of water distribution networks, particularly for leak detection and predictive maintenance."}}
{"id": "2406.19593", "pdf": "https://arxiv.org/pdf/2406.19593", "abs": "https://arxiv.org/abs/2406.19593", "authors": ["Xin Su", "Man Luo", "Kris W Pan", "Tien Pei Chou", "Vasudev Lal", "Phillip Howard"], "title": "SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs", "categories": ["cs.CL", "cs.CV"], "comment": "ICML 2025 Spotlight Oral", "summary": "Multimodal retrieval augmented generation (RAG) plays a crucial role in\ndomains such as knowledge-based visual question answering (KB-VQA), where\nexternal knowledge is needed to answer a question. However, existing multimodal\nLLMs (MLLMs) are not designed for context-augmented generation, limiting their\neffectiveness in such tasks. While synthetic data generation has recently\ngained attention for training MLLMs, its application for context-augmented\ngeneration remains underexplored. To address this gap, we introduce SK-VQA, a\nlarge-scale synthetic multimodal dataset containing over 2 million visual\nquestion-answer pairs, each associated with context documents containing\ninformation necessary to determine the final answer. Compared to previous\ndatasets, SK-VQA contains 11x more unique questions, exhibits greater domain\ndiversity, and covers a broader spectrum of image sources. Through human\nevaluations, we confirm the high quality of the generated question-answer pairs\nand their contextual relevance. Extensive experiments show that SK-VQA serves\nboth as a challenging KB-VQA benchmark and as an effective training resource\nfor adapting MLLMs to context-augmented generation. Our results further\nindicate that models trained on SK-VQA demonstrate enhanced generalization in\nboth context-aware VQA and multimodal RAG settings. SK-VQA is publicly\navailable via Hugging Face Hub.", "AI": {"tldr": "SK-VQA is a synthetic multimodal dataset for context-augmented generation, improving MLLMs' performance in KB-VQA and multimodal RAG tasks.", "motivation": "Existing MLLMs lack design for context-augmented generation, limiting their effectiveness in KB-VQA. Synthetic data for this purpose is underexplored.", "method": "Introduces SK-VQA, a synthetic dataset with 2M+ visual QA pairs and context documents, designed for training and benchmarking MLLMs.", "result": "SK-VQA enhances MLLMs' generalization in context-aware VQA and multimodal RAG, validated by human evaluations and experiments.", "conclusion": "SK-VQA is a high-quality, scalable resource for advancing MLLMs in context-augmented generation, publicly available for further research."}}
{"id": "2506.09022", "pdf": "https://arxiv.org/pdf/2506.09022", "abs": "https://arxiv.org/abs/2506.09022", "authors": ["Daniel Shao", "Richard J. Chen", "Andrew H. Song", "Joel Runevic", "Ming Y. Lu", "Tong Ding", "Faisal Mahmood"], "title": "Do MIL Models Transfer?", "categories": ["cs.CV"], "comment": "ICML 2025 (Spotlight). 20 pages, 8 figures", "summary": "Multiple Instance Learning (MIL) is a cornerstone approach in computational\npathology (CPath) for generating clinically meaningful slide-level embeddings\nfrom gigapixel tissue images. However, MIL often struggles with small, weakly\nsupervised clinical datasets. In contrast to fields such as NLP and\nconventional computer vision, where transfer learning is widely used to address\ndata scarcity, the transferability of MIL models remains poorly understood. In\nthis study, we systematically evaluate the transfer learning capabilities of\npretrained MIL models by assessing 11 models across 21 pretraining tasks for\nmorphological and molecular subtype prediction. Our results show that\npretrained MIL models, even when trained on different organs than the target\ntask, consistently outperform models trained from scratch. Moreover,\npretraining on pancancer datasets enables strong generalization across organs\nand tasks, outperforming slide foundation models while using substantially less\npretraining data. These findings highlight the robust adaptability of MIL\nmodels and demonstrate the benefits of leveraging transfer learning to boost\nperformance in CPath. Lastly, we provide a resource which standardizes the\nimplementation of MIL models and collection of pretrained model weights on\npopular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab", "AI": {"tldr": "Pretrained MIL models outperform scratch-trained ones in computational pathology, even across different organs, and pancancer pretraining enhances generalization.", "motivation": "Addressing the lack of understanding about MIL model transferability in computational pathology, despite its widespread use in other fields.", "method": "Systematic evaluation of 11 pretrained MIL models across 21 tasks for morphological and molecular subtype prediction.", "result": "Pretrained MIL models consistently outperform scratch-trained models, with pancancer pretraining showing strong generalization.", "conclusion": "MIL models are adaptable and benefit from transfer learning in computational pathology; a standardized resource is provided."}}
{"id": "2506.08889", "pdf": "https://arxiv.org/pdf/2506.08889", "abs": "https://arxiv.org/abs/2506.08889", "authors": ["Yizhao Gao", "Shuming Guo", "Shijie Cao", "Yuqing Xia", "Yu Cheng", "Lei Wang", "Lingxiao Ma", "Yutao Sun", "Tianzhu Ye", "Li Dong", "Hayden Kwok-Hay So", "Yu Hua", "Ting Cao", "Fan Yang", "Mao Yang"], "title": "SeerAttention-R: Sparse Attention Adaptation for Long Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce SeerAttention-R, a sparse attention framework specifically\ntailored for the long decoding of reasoning models. Extended from\nSeerAttention, SeerAttention-R retains the design of learning attention\nsparsity through a self-distilled gating mechanism, while removing query\npooling to accommodate auto-regressive decoding. With a lightweight plug-in\ngating, SeerAttention-R is flexible and can be easily integrated into existing\npretrained model without modifying the original parameters. We demonstrate that\nSeerAttention-R, trained on just 0.4B tokens, maintains near-lossless reasoning\naccuracy with 4K token budget in AIME benchmark under large sparse attention\nblock sizes (64/128). Using TileLang, we develop a highly optimized sparse\ndecoding kernel that achieves near-theoretical speedups of up to 9x over\nFlashAttention-3 on H100 GPU at 90% sparsity. Code is available at:\nhttps://github.com/microsoft/SeerAttention.", "AI": {"tldr": "SeerAttention-R is a sparse attention framework for long decoding in reasoning models, maintaining accuracy with minimal training and achieving significant speedups.", "motivation": "To address the need for efficient long decoding in reasoning models without compromising accuracy.", "method": "Extends SeerAttention with a self-distilled gating mechanism, removes query pooling, and integrates a lightweight plug-in gating for auto-regressive decoding.", "result": "Near-lossless reasoning accuracy with 4K tokens, 9x speedup over FlashAttention-3 at 90% sparsity.", "conclusion": "SeerAttention-R is a flexible, efficient solution for long decoding in reasoning models."}}
{"id": "2506.08884", "pdf": "https://arxiv.org/pdf/2506.08884", "abs": "https://arxiv.org/abs/2506.08884", "authors": ["Shiqin Tang", "Shujian Yu"], "title": "InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "accepted by UAI-25, code is available at\n  \\url{https://github.com/marcusstang/InfoDPCCA}", "summary": "Extracting meaningful latent representations from high-dimensional sequential\ndata is a crucial challenge in machine learning, with applications spanning\nnatural science and engineering. We introduce InfoDPCCA, a dynamic\nprobabilistic Canonical Correlation Analysis (CCA) framework designed to model\ntwo interdependent sequences of observations. InfoDPCCA leverages a novel\ninformation-theoretic objective to extract a shared latent representation that\ncaptures the mutual structure between the data streams and balances\nrepresentation compression and predictive sufficiency while also learning\nseparate latent components that encode information specific to each sequence.\nUnlike prior dynamic CCA models, such as DPCCA, our approach explicitly\nenforces the shared latent space to encode only the mutual information between\nthe sequences, improving interpretability and robustness. We further introduce\na two-step training scheme to bridge the gap between information-theoretic\nrepresentation learning and generative modeling, along with a residual\nconnection mechanism to enhance training stability. Through experiments on\nsynthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a tool\nfor representation learning. Code of InfoDPCCA is available at\nhttps://github.com/marcusstang/InfoDPCCA.", "AI": {"tldr": "InfoDPCCA is a dynamic probabilistic CCA framework for modeling two interdependent sequences, using an information-theoretic objective to extract shared and sequence-specific latent representations.", "motivation": "To address the challenge of extracting meaningful latent representations from high-dimensional sequential data, improving interpretability and robustness over prior methods.", "method": "Introduces InfoDPCCA with a novel information-theoretic objective, a two-step training scheme, and residual connections for stability.", "result": "Demonstrated effectiveness on synthetic and medical fMRI data as a robust representation learning tool.", "conclusion": "InfoDPCCA provides a balanced, interpretable, and robust framework for extracting shared and specific latent representations from sequential data."}}
{"id": "2408.01214", "pdf": "https://arxiv.org/pdf/2408.01214", "abs": "https://arxiv.org/abs/2408.01214", "authors": ["Daniel B. Hier", "S. Ilyas Munzir", "Anne Stahlfeld", "Tayo Obafemi-Ajayi", "Michael D. Carrithers"], "title": "High-Throughput Phenotyping of Clinical Text Using Large Language Models", "categories": ["cs.CL", "cs.AI", "I.7; I.2"], "comment": "Submitted to IEEE-EMBS International Conference on Biomedical and\n  Health Informatics, Houston TX", "summary": "High-throughput phenotyping automates the mapping of patient signs to\nstandardized ontology concepts and is essential for precision medicine. This\nstudy evaluates the automation of phenotyping of clinical summaries from the\nOnline Mendelian Inheritance in Man (OMIM) database using large language\nmodels. Due to their rich phenotype data, these summaries can be surrogates for\nphysician notes. We conduct a performance comparison of GPT-4 and\nGPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in\nidentifying, categorizing, and normalizing signs, achieving concordance with\nmanual annotators comparable to inter-rater agreement. Despite some limitations\nin sign normalization, the extensive pre-training of GPT-4 results in high\nperformance and generalizability across several phenotyping tasks while\nobviating the need for manually annotated training data. Large language models\nare expected to be the dominant method for automating high-throughput\nphenotyping of clinical text.", "AI": {"tldr": "GPT-4 outperforms GPT-3.5-Turbo in automating phenotyping of clinical summaries, achieving results close to manual annotation, with high generalizability and no need for training data.", "motivation": "To evaluate the automation of phenotyping in clinical summaries using large language models, leveraging OMIM database data as surrogates for physician notes.", "method": "Performance comparison of GPT-4 and GPT-3.5-Turbo in identifying, categorizing, and normalizing signs from OMIM clinical summaries.", "result": "GPT-4 surpasses GPT-3.5-Turbo, achieving concordance with manual annotators comparable to inter-rater agreement, though with some limitations in sign normalization.", "conclusion": "Large language models, especially GPT-4, are poised to dominate high-throughput phenotyping of clinical text due to their performance and generalizability."}}
{"id": "2506.09024", "pdf": "https://arxiv.org/pdf/2506.09024", "abs": "https://arxiv.org/abs/2506.09024", "authors": ["Felix Wagner", "Pramit Saha", "Harry Anthony", "J. Alison Noble", "Konstantinos Kamnitsas"], "title": "DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging", "categories": ["cs.CV", "cs.LG", "I.2.11; I.4.9; I.4.9; J.3; I.2.0"], "comment": null, "summary": "Safe deployment of machine learning (ML) models in safety-critical domains\nsuch as medical imaging requires detecting inputs with characteristics not seen\nduring training, known as out-of-distribution (OOD) detection, to prevent\nunreliable predictions. Effective OOD detection after deployment could benefit\nfrom access to the training data, enabling direct comparison between test\nsamples and the training data distribution to identify differences.\nState-of-the-art OOD detection methods, however, either discard training data\nafter deployment or assume that test samples and training data are centrally\nstored together, an assumption that rarely holds in real-world settings. This\nis because shipping training data with the deployed model is usually impossible\ndue to the size of training databases, as well as proprietary or privacy\nconstraints. We introduce the Isolation Network, an OOD detection framework\nthat quantifies the difficulty of separating a target test sample from the\ntraining data by solving a binary classification task. We then propose\nDecentralized Isolation Networks (DIsoN), which enables the comparison of\ntraining and test data when data-sharing is impossible, by exchanging only\nmodel parameters between the remote computational nodes of training and\ndeployment. We further extend DIsoN with class-conditioning, comparing a target\nsample solely with training data of its predicted class. We evaluate DIsoN on\nfour medical imaging datasets (dermatology, chest X-ray, breast ultrasound,\nhistopathology) across 12 OOD detection tasks. DIsoN performs favorably against\nexisting methods while respecting data-privacy. This decentralized OOD\ndetection framework opens the way for a new type of service that ML developers\ncould provide along with their models: providing remote, secure utilization of\ntheir training data for OOD detection services. Code will be available upon\nacceptance at: *****", "AI": {"tldr": "The paper introduces DIsoN, a decentralized framework for OOD detection in medical imaging, enabling secure comparison of test and training data without sharing raw data.", "motivation": "Safe ML deployment in medical imaging requires OOD detection, but existing methods either discard training data or assume centralized storage, which is impractical due to privacy and size constraints.", "method": "DIsoN uses Isolation Networks to quantify separation difficulty between test and training data via binary classification, enabling decentralized parameter exchange instead of raw data sharing.", "result": "DIsoN outperforms existing methods on four medical imaging datasets across 12 OOD tasks while maintaining data privacy.", "conclusion": "DIsoN offers a practical, privacy-preserving solution for OOD detection, paving the way for secure remote utilization of training data in ML services."}}
{"id": "2506.08902", "pdf": "https://arxiv.org/pdf/2506.08902", "abs": "https://arxiv.org/abs/2506.08902", "authors": ["Chongyi Zheng", "Seohong Park", "Sergey Levine", "Benjamin Eysenbach"], "title": "Intention-Conditioned Flow Occupancy Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large-scale pre-training has fundamentally changed how machine learning\nresearch is done today: large foundation models are trained once, and then can\nbe used by anyone in the community (including those without data or compute\nresources to train a model from scratch) to adapt and fine-tune to specific\ntasks. Applying this same framework to reinforcement learning (RL) is appealing\nbecause it offers compelling avenues for addressing core challenges in RL,\nincluding sample efficiency and robustness. However, there remains a\nfundamental challenge to pre-train large models in the context of RL: actions\nhave long-term dependencies, so training a foundation model that reasons across\ntime is important. Recent advances in generative AI have provided new tools for\nmodeling highly complex distributions. In this paper, we build a probabilistic\nmodel to predict which states an agent will visit in the temporally distant\nfuture (i.e., an occupancy measure) using flow matching. As large datasets are\noften constructed by many distinct users performing distinct tasks, we include\nin our model a latent variable capturing the user intention. This intention\nincreases the expressivity of our model, and enables adaptation with\ngeneralized policy improvement. We call our proposed method\nintention-conditioned flow occupancy models (InFOM). Comparing with alternative\nmethods for pre-training, our experiments on $36$ state-based and $4$\nimage-based benchmark tasks demonstrate that the proposed method achieves $1.8\n\\times$ median improvement in returns and increases success rates by $36\\%$.\nWebsite: https://chongyi-zheng.github.io/infom Code:\nhttps://github.com/chongyi-zheng/infom", "AI": {"tldr": "The paper introduces InFOM, a method for pre-training RL models using flow matching and latent user intentions, achieving significant performance improvements.", "motivation": "To address challenges in RL pre-training, such as long-term action dependencies and sample efficiency, by leveraging generative AI tools.", "method": "Proposes intention-conditioned flow occupancy models (InFOM), using flow matching and latent variables for user intentions to predict future states.", "result": "Demonstrates a 1.8\u00d7 median improvement in returns and 36% higher success rates on benchmark tasks.", "conclusion": "InFOM effectively enhances RL pre-training by modeling long-term dependencies and user intentions, outperforming alternatives."}}
{"id": "2506.08916", "pdf": "https://arxiv.org/pdf/2506.08916", "abs": "https://arxiv.org/abs/2506.08916", "authors": ["Maria-Veronica Ciocanel", "John T. Nardini", "Kevin B. Flores", "Erica M. Rutter", "Suzanne S. Sindi", "Alexandria Volkening"], "title": "Enhancing generalizability of model discovery across parameter space with multi-experiment equation learning (ME-EQL)", "categories": ["cs.LG", "math.DS", "q-bio.QM"], "comment": "31 pages, 10 figures", "summary": "Agent-based modeling (ABM) is a powerful tool for understanding\nself-organizing biological systems, but it is computationally intensive and\noften not analytically tractable. Equation learning (EQL) methods can derive\ncontinuum models from ABM data, but they typically require extensive\nsimulations for each parameter set, raising concerns about generalizability. In\nthis work, we extend EQL to Multi-experiment equation learning (ME-EQL) by\nintroducing two methods: one-at-a-time ME-EQL (OAT ME-EQL), which learns\nindividual models for each parameter set and connects them via interpolation,\nand embedded structure ME-EQL (ES ME-EQL), which builds a unified model library\nacross parameters. We demonstrate these methods using a birth--death mean-field\nmodel and an on-lattice agent-based model of birth, death, and migration with\nspatial structure. Our results show that both methods significantly reduce the\nrelative error in recovering parameters from agent-based simulations, with OAT\nME-EQL offering better generalizability across parameter space. Our findings\nhighlight the potential of equation learning from multiple experiments to\nenhance the generalizability and interpretability of learned models for complex\nbiological systems.", "AI": {"tldr": "The paper introduces Multi-experiment equation learning (ME-EQL) to improve generalizability and interpretability of learned models from agent-based simulations, reducing errors in parameter recovery.", "motivation": "Agent-based modeling (ABM) is computationally intensive and lacks analytical tractability, while existing equation learning (EQL) methods require extensive simulations for each parameter set, limiting generalizability.", "method": "Two ME-EQL methods are proposed: one-at-a-time (OAT) for individual models with interpolation, and embedded structure (ES) for a unified model library across parameters.", "result": "Both methods reduce relative error in parameter recovery, with OAT ME-EQL showing better generalizability across parameter space.", "conclusion": "ME-EQL enhances the generalizability and interpretability of learned models for complex biological systems."}}
{"id": "2410.08674", "pdf": "https://arxiv.org/pdf/2410.08674", "abs": "https://arxiv.org/abs/2410.08674", "authors": ["Nizar Habash", "Hanada Taha-Thomure", "Khalid N. Elmadani", "Zeina Zeino", "Abdallah Abushmaes"], "title": "Guidelines for Fine-grained Sentence-level Arabic Readability Annotation", "categories": ["cs.CL"], "comment": "Accepted at LAW-XIX at ACL 2025", "summary": "This paper presents the annotation guidelines of the Balanced Arabic\nReadability Evaluation Corpus (BAREC), a large-scale resource for fine-grained\nsentence-level readability assessment in Arabic. BAREC includes 69,441\nsentences (1M+ words) labeled across 19 levels, from kindergarten to\npostgraduate. Based on the Taha/Arabi21 framework, the guidelines were refined\nthrough iterative training with native Arabic-speaking educators. We highlight\nkey linguistic, pedagogical, and cognitive factors in determining readability\nand report high inter-annotator agreement: Quadratic Weighted Kappa 81.8%\n(substantial/excellent agreement) in the last annotation phase. We also\nbenchmark automatic readability models across multiple classification\ngranularities (19-, 7-, 5-, and 3-level). The corpus and guidelines are\npublicly available.", "AI": {"tldr": "The paper introduces BAREC, a large-scale Arabic readability corpus with 69,441 sentences labeled across 19 levels, refined with educator input, and reports high annotator agreement (81.8% Kappa). It benchmarks readability models and makes the corpus public.", "motivation": "To create a fine-grained, large-scale resource for Arabic readability assessment, addressing the lack of such datasets and refining guidelines with educator expertise.", "method": "Developed BAREC using the Taha/Arabi21 framework, iteratively refined guidelines with native Arabic educators, and evaluated inter-annotator agreement. Benchmarked automatic readability models at various granularities.", "result": "Achieved high inter-annotator agreement (81.8% Quadratic Weighted Kappa) and provided benchmarks for readability models across 19-, 7-, 5-, and 3-level classifications.", "conclusion": "BAREC is a valuable, publicly available resource for Arabic readability research, with robust guidelines and high-quality annotations."}}
{"id": "2506.09027", "pdf": "https://arxiv.org/pdf/2506.09027", "abs": "https://arxiv.org/abs/2506.09027", "authors": ["Runqian Wang", "Kaiming He"], "title": "Diffuse and Disperse: Image Generation with Representation Regularization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The development of diffusion-based generative models over the past decade has\nlargely proceeded independently of progress in representation learning. These\ndiffusion models typically rely on regression-based objectives and generally\nlack explicit regularization. In this work, we propose \\textit{Dispersive\nLoss}, a simple plug-and-play regularizer that effectively improves\ndiffusion-based generative models. Our loss function encourages internal\nrepresentations to disperse in the hidden space, analogous to contrastive\nself-supervised learning, with the key distinction that it requires no positive\nsample pairs and therefore does not interfere with the sampling process used\nfor regression. Compared to the recent method of representation alignment\n(REPA), our approach is self-contained and minimalist, requiring no\npre-training, no additional parameters, and no external data. We evaluate\nDispersive Loss on the ImageNet dataset across a range of models and report\nconsistent improvements over widely used and strong baselines. We hope our work\nwill help bridge the gap between generative modeling and representation\nlearning.", "AI": {"tldr": "The paper introduces Dispersive Loss, a plug-and-play regularizer for diffusion-based generative models, improving their performance without additional requirements.", "motivation": "To bridge the gap between generative modeling and representation learning by enhancing diffusion models with explicit regularization.", "method": "Proposes Dispersive Loss, a regularization technique that disperses internal representations in hidden space, inspired by contrastive learning but without needing positive pairs.", "result": "Demonstrates consistent improvements on ImageNet across various models, outperforming strong baselines like REPA.", "conclusion": "Dispersive Loss effectively enhances diffusion models, offering a simple, self-contained solution to improve generative modeling."}}
{"id": "2506.08917", "pdf": "https://arxiv.org/pdf/2506.08917", "abs": "https://arxiv.org/abs/2506.08917", "authors": ["Sascha M\u00fccke", "Raoul Heese", "Thore Gerlach", "David Biesner", "Loong Kuan Lee", "Nico Piatkowski"], "title": "Quantum Adiabatic Generation of Human-Like Passwords", "categories": ["quant-ph", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Generative Artificial Intelligence (GenAI) for Natural Language Processing\n(NLP) is the predominant AI technology to date. An important perspective for\nQuantum Computing (QC) is the question whether QC has the potential to reduce\nthe vast resource requirements for training and operating GenAI models. While\nlarge-scale generative NLP tasks are currently out of reach for practical\nquantum computers, the generation of short semantic structures such as\npasswords is not. Generating passwords that mimic real user behavior has many\napplications, for example to test an authentication system against realistic\nthreat models. Classical password generation via deep learning have recently\nbeen investigated with significant progress in their ability to generate novel,\nrealistic password candidates. In the present work we investigate the utility\nof adiabatic quantum computers for this task. More precisely, we study\ndifferent encodings of token strings and propose novel approaches based on the\nQuadratic Unconstrained Binary Optimization (QUBO) and the Unit-Disk Maximum\nIndependent Set (UD-MIS) problems. Our approach allows us to estimate the token\ndistribution from data and adiabatically prepare a quantum state from which we\neventually sample the generated passwords via measurements. Our results show\nthat relatively small samples of 128 passwords, generated on the QuEra Aquila\n256-qubit neutral atom quantum computer, contain human-like passwords such as\n\"Tunas200992\" or \"teedem28iglove\".", "AI": {"tldr": "The paper explores using adiabatic quantum computers for generating human-like passwords, leveraging QUBO and UD-MIS encodings, and demonstrates success with small samples on a 256-qubit quantum computer.", "motivation": "To investigate if quantum computing can reduce resource demands for generative NLP tasks, focusing on password generation as a feasible starting point.", "method": "Proposes encodings based on QUBO and UD-MIS problems, estimates token distributions, and adiabatically prepares quantum states for password sampling.", "result": "Generated 128 human-like passwords (e.g., \"Tunas200992\") on a 256-qubit quantum computer, showing potential for quantum-assisted password generation.", "conclusion": "Quantum computing shows promise for small-scale generative tasks like password generation, though scalability remains a challenge."}}
{"id": "2506.08928", "pdf": "https://arxiv.org/pdf/2506.08928", "abs": "https://arxiv.org/abs/2506.08928", "authors": ["Zhongyuan Liang", "Zachary T. Rewolinski", "Abhineet Agarwal", "Tiffany M. Tang", "Bin Yu"], "title": "Local MDI+: Local Feature Importances for Tree-Based Models", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "Tree-based ensembles such as random forests remain the go-to for tabular data\nover deep learning models due to their prediction performance and computational\nefficiency. These advantages have led to their widespread deployment in\nhigh-stakes domains, where interpretability is essential for ensuring\ntrustworthy predictions. This has motivated the development of popular local\n(i.e. sample-specific) feature importance (LFI) methods such as LIME and\nTreeSHAP. However, these approaches rely on approximations that ignore the\nmodel's internal structure and instead depend on potentially unstable\nperturbations. These issues are addressed in the global setting by MDI+, a\nfeature importance method which exploits an equivalence between decision trees\nand linear models on a transformed node basis. However, the global MDI+ scores\nare not able to explain predictions when faced with heterogeneous individual\ncharacteristics. To address this gap, we propose Local MDI+ (LMDI+), a novel\nextension of the MDI+ framework to the sample specific setting. LMDI+\noutperforms existing baselines LIME and TreeSHAP in identifying\ninstance-specific signal features, averaging a 10% improvement in downstream\ntask performance across twelve real-world benchmark datasets. It further\ndemonstrates greater stability by consistently producing similar instance-level\nfeature importance rankings across multiple random forest fits. Finally, LMDI+\nenables local interpretability use cases, including the identification of\ncloser counterfactuals and the discovery of homogeneous subgroups.", "AI": {"tldr": "LMDI+ extends MDI+ to local feature importance, outperforming LIME and TreeSHAP in accuracy and stability for interpretable predictions in tree-based models.", "motivation": "Tree-based models lack reliable local interpretability methods, as existing approaches like LIME and TreeSHAP rely on approximations and perturbations, ignoring model structure.", "method": "LMDI+ adapts the global MDI+ framework to local settings, leveraging the equivalence between decision trees and linear models for sample-specific feature importance.", "result": "LMDI+ improves downstream task performance by 10% over baselines, shows greater stability, and enables local interpretability use cases like counterfactual identification.", "conclusion": "LMDI+ provides a robust, accurate, and stable method for local feature importance in tree-based models, addressing gaps in existing approaches."}}
{"id": "2410.15639", "pdf": "https://arxiv.org/pdf/2410.15639", "abs": "https://arxiv.org/abs/2410.15639", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Can Large Language Models Invent Algorithms to Improve Themselves?: Algorithm Discovery for Recursive Self-Improvement through Reinforcement Learning", "categories": ["cs.CL"], "comment": "Accepted at NAACL 2025 (main)", "summary": "Large Language Models (LLMs) have achieved remarkable capabilities, yet their\nimprovement methods remain fundamentally constrained by human design. We\npresent Self-Developing, a framework that enables LLMs to autonomously\ndiscover, implement, and refine their own improvement algorithms. Our approach\nemploys an iterative cycle where a seed model generates algorithmic candidates\nas executable code, evaluates their effectiveness, and uses Direct Preference\nOptimization to recursively improve increasingly sophisticated improvement\nstrategies. We demonstrate this framework through model merging, a practical\ntechnique for combining specialized models. Self-Developing successfully\ndiscovered novel merging algorithms that outperform existing human-designed\nalgorithms. On mathematical reasoning benchmarks, the autonomously discovered\nalgorithms improve the seed model's GSM8k performance by 6\\% and exceed\nhuman-designed approaches like Task Arithmetic by 4.3\\%. Remarkably, these\nalgorithms exhibit strong generalization, achieving 7.4\\% gains on\nout-of-domain models without re-optimization. Our findings demonstrate that\nLLMs can transcend their training to invent genuinely novel optimization\ntechniques. This capability represents a crucial step toward a new era where\nLLMs not only solve problems but autonomously develop the methodologies for\ntheir own advancement.", "AI": {"tldr": "Self-Developing framework enables LLMs to autonomously create and refine improvement algorithms, outperforming human-designed methods.", "motivation": "Current LLM improvement methods are limited by human design, prompting the need for autonomous self-improvement.", "method": "Uses an iterative cycle of generating algorithmic candidates, evaluating them, and refining via Direct Preference Optimization.", "result": "Autonomously discovered algorithms improved GSM8k performance by 6% and outperformed human-designed methods by 4.3%.", "conclusion": "LLMs can autonomously develop novel optimization techniques, advancing toward self-improving methodologies."}}
{"id": "2506.09035", "pdf": "https://arxiv.org/pdf/2506.09035", "abs": "https://arxiv.org/abs/2506.09035", "authors": ["Karhan Kayan", "Stamatis Alexandropoulos", "Rishabh Jain", "Yiming Zuo", "Erich Liang", "Jia Deng"], "title": "Princeton365: A Diverse Dataset with Accurate Camera Pose", "categories": ["cs.CV"], "comment": null, "summary": "We introduce Princeton365, a large-scale diverse dataset of 365 videos with\naccurate camera pose. Our dataset bridges the gap between accuracy and data\ndiversity in current SLAM benchmarks by introducing a novel ground truth\ncollection framework that leverages calibration boards and a 360-camera. We\ncollect indoor, outdoor, and object scanning videos with synchronized monocular\nand stereo RGB video outputs as well as IMU. We further propose a new scene\nscale-aware evaluation metric for SLAM based on the the optical flow induced by\nthe camera pose estimation error. In contrast to the current metrics, our new\nmetric allows for comparison between the performance of SLAM methods across\nscenes as opposed to existing metrics such as Average Trajectory Error (ATE),\nallowing researchers to analyze the failure modes of their methods. We also\npropose a challenging Novel View Synthesis benchmark that covers cases not\ncovered by current NVS benchmarks, such as fully non-Lambertian scenes with\n360-degree camera trajectories. Please visit\nhttps://princeton365.cs.princeton.edu for the dataset, code, videos, and\nsubmission.", "AI": {"tldr": "Princeton365 is a diverse dataset with accurate camera pose, bridging accuracy and diversity gaps in SLAM benchmarks. It includes indoor, outdoor, and object scanning videos with RGB and IMU data, and introduces a scene scale-aware evaluation metric and a Novel View Synthesis benchmark.", "motivation": "To address the gap between accuracy and diversity in SLAM benchmarks by providing a dataset with precise camera pose and diverse scenarios.", "method": "Uses a ground truth collection framework with calibration boards and a 360-camera, capturing synchronized monocular/stereo RGB and IMU data. Introduces a scene scale-aware metric for SLAM evaluation.", "result": "A dataset (Princeton365) with 365 videos, a new evaluation metric for SLAM, and a Novel View Synthesis benchmark.", "conclusion": "Princeton365 enhances SLAM research by offering diverse, accurate data and improved evaluation tools, fostering better analysis of method failures."}}
{"id": "2506.08961", "pdf": "https://arxiv.org/pdf/2506.08961", "abs": "https://arxiv.org/abs/2506.08961", "authors": ["Chenxu Wang", "Huaping Liu"], "title": "Towards Robust Deep Reinforcement Learning against Environmental State Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial attacks and robustness in Deep Reinforcement Learning (DRL) have\nbeen widely studied in various threat models; however, few consider\nenvironmental state perturbations, which are natural in embodied scenarios. To\nimprove the robustness of DRL agents, we formulate the problem of environmental\nstate perturbation, introducing a preliminary non-targeted attack method as a\ncalibration adversary, and then propose a defense framework, named Boosted\nAdversarial Training (BAT), which first tunes the agents via supervised\nlearning to avoid catastrophic failure and subsequently adversarially trains\nthe agent with reinforcement learning. Extensive experimental results\nsubstantiate the vulnerability of mainstream agents under environmental state\nperturbations and the effectiveness of our proposed attack. The defense results\ndemonstrate that while existing robust reinforcement learning algorithms may\nnot be suitable, our BAT framework can significantly enhance the robustness of\nagents against environmental state perturbations across various situations.", "AI": {"tldr": "The paper addresses environmental state perturbations in DRL, proposing a defense framework (BAT) to enhance agent robustness.", "motivation": "Environmental state perturbations are understudied in DRL, despite their natural occurrence in embodied scenarios.", "method": "Introduces a non-targeted attack method for calibration, then proposes BAT: supervised learning tuning followed by adversarial RL training.", "result": "Mainstream DRL agents are vulnerable to environmental perturbations; BAT significantly improves robustness.", "conclusion": "BAT outperforms existing robust RL methods against environmental state perturbations."}}
{"id": "2506.08936", "pdf": "https://arxiv.org/pdf/2506.08936", "abs": "https://arxiv.org/abs/2506.08936", "authors": ["Amina Mollaysa", "Artem Moskale", "Pushpak Pati", "Tommaso Mansi", "Mangal Prakash", "Rui Liao"], "title": "BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models", "categories": ["cs.LG"], "comment": "Proceedings of ICML 2025 Workshop on Multi-modal Foundation\n  Proceedings of ICML 2025 Workshop on Multi-modal Foundation Proceedings of\n  ICML 2025 Workshop on Multi-modal Foundation Models and Large Language Models\n  for Life Sciences", "summary": "We present BioLangFusion, a simple approach for integrating pre-trained DNA,\nmRNA, and protein language models into unified molecular representations.\nMotivated by the central dogma of molecular biology (information flow from gene\nto transcript to protein), we align per-modality embeddings at the biologically\nmeaningful codon level (three nucleotides encoding one amino acid) to ensure\ndirect cross-modal correspondence. BioLangFusion studies three standard fusion\ntechniques: (i) codon-level embedding concatenation, (ii) entropy-regularized\nattention pooling inspired by multiple-instance learning, and (iii) cross-modal\nmulti-head attention -- each technique providing a different inductive bias for\ncombining modality-specific signals. These methods require no additional\npre-training or modification of the base models, allowing straightforward\nintegration with existing sequence-based foundation models. Across five\nmolecular property prediction tasks, BioLangFusion outperforms strong unimodal\nbaselines, showing that even simple fusion of pre-trained models can capture\ncomplementary multi-omic information with minimal overhead.", "AI": {"tldr": "BioLangFusion integrates DNA, mRNA, and protein language models into unified representations using codon-level alignment and three fusion techniques, outperforming unimodal baselines in molecular property prediction.", "motivation": "The central dogma of molecular biology (gene to transcript to protein) motivates aligning embeddings at the codon level for cross-modal correspondence.", "method": "Three fusion techniques: codon-level concatenation, entropy-regularized attention pooling, and cross-modal multi-head attention, without additional pre-training.", "result": "Outperforms unimodal baselines in five molecular property prediction tasks, capturing complementary multi-omic information.", "conclusion": "Simple fusion of pre-trained models can effectively combine multi-omic data with minimal overhead."}}
{"id": "2410.19317", "pdf": "https://arxiv.org/pdf/2410.19317", "abs": "https://arxiv.org/abs/2410.19317", "authors": ["Zhiting Fan", "Ruizhe Chen", "Tianxiang Hu", "Zuozhu Liu"], "title": "FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs", "categories": ["cs.CL"], "comment": "ICLR 2025 spotlight", "summary": "The growing use of large language model (LLM)-based chatbots has raised\nconcerns about fairness. Fairness issues in LLMs can lead to severe\nconsequences, such as bias amplification, discrimination, and harm to\nmarginalized communities. While existing fairness benchmarks mainly focus on\nsingle-turn dialogues, multi-turn scenarios, which in fact better reflect\nreal-world conversations, present greater challenges due to conversational\ncomplexity and potential bias accumulation. In this paper, we propose a\ncomprehensive fairness benchmark for LLMs in multi-turn dialogue scenarios,\n\\textbf{FairMT-Bench}. Specifically, we formulate a task taxonomy targeting LLM\nfairness capabilities across three stages: context understanding, user\ninteraction, and instruction trade-offs, with each stage comprising two tasks.\nTo ensure coverage of diverse bias types and attributes, we draw from existing\nfairness datasets and employ our template to construct a multi-turn dialogue\ndataset, \\texttt{FairMT-10K}. For evaluation, GPT-4 is applied, alongside bias\nclassifiers including Llama-Guard-3 and human validation to ensure robustness.\nExperiments and analyses on \\texttt{FairMT-10K} reveal that in multi-turn\ndialogue scenarios, current LLMs are more likely to generate biased responses,\nand there is significant variation in performance across different tasks and\nmodels. Based on this, we curate a challenging dataset, \\texttt{FairMT-1K}, and\ntest 15 current state-of-the-art (SOTA) LLMs on this dataset. The results show\nthe current state of fairness in LLMs and showcase the utility of this novel\napproach for assessing fairness in more realistic multi-turn dialogue contexts,\ncalling for future work to focus on LLM fairness improvement and the adoption\nof \\texttt{FairMT-1K} in such efforts.", "AI": {"tldr": "The paper introduces FairMT-Bench, a fairness benchmark for LLMs in multi-turn dialogues, highlighting biases and performance variations across tasks and models.", "motivation": "Address fairness concerns in LLMs, especially in multi-turn dialogues, which are more complex and prone to bias accumulation than single-turn scenarios.", "method": "Develop FairMT-Bench with a task taxonomy (context understanding, user interaction, instruction trade-offs) and construct FairMT-10K dataset. Evaluate using GPT-4, bias classifiers, and human validation.", "result": "LLMs exhibit more biased responses in multi-turn dialogues, with significant performance variations. FairMT-1K dataset tests 15 SOTA LLMs, revealing current fairness gaps.", "conclusion": "FairMT-Bench is a novel tool for assessing LLM fairness in realistic multi-turn dialogues, urging future work to improve fairness and adopt FairMT-1K."}}
{"id": "2506.09042", "pdf": "https://arxiv.org/pdf/2506.09042", "abs": "https://arxiv.org/abs/2506.09042", "authors": ["Xuanchi Ren", "Yifan Lu", "Tianshi Cao", "Ruiyuan Gao", "Shengyu Huang", "Amirmojtaba Sabour", "Tianchang Shen", "Tobias Pfaff", "Jay Zhangjie Wu", "Runjian Chen", "Seung Wook Kim", "Jun Gao", "Laura Leal-Taixe", "Mike Chen", "Sanja Fidler", "Huan Ling"], "title": "Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models", "categories": ["cs.CV"], "comment": "Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao: Equal contribution.\n  Only the core contributors are listed. The full list of contributors can be\n  found in Appendix A of this paper", "summary": "Collecting and annotating real-world data for safety-critical physical AI\nsystems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is\nespecially challenging to capture rare edge cases, which play a critical role\nin training and testing of an AV system. To address this challenge, we\nintroduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline\nthat aims to generate challenging scenarios to facilitate downstream tasks such\nas perception and driving policy training. Powering this pipeline is\nCosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation\nmodel for the driving domain and are capable of controllable, high-fidelity,\nmulti-view, and spatiotemporally consistent driving video generation. We\nshowcase the utility of these models by applying Cosmos-Drive-Dreams to scale\nthe quantity and diversity of driving datasets with high-fidelity and\nchallenging scenarios. Experimentally, we demonstrate that our generated data\nhelps in mitigating long-tail distribution problems and enhances generalization\nin downstream tasks such as 3D lane detection, 3D object detection and driving\npolicy learning. We open source our pipeline toolkit, dataset and model weights\nthrough the NVIDIA's Cosmos platform.\n  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams", "AI": {"tldr": "The paper introduces Cosmos-Drive-Dreams, a synthetic data generation pipeline for creating challenging driving scenarios to improve AV training and testing.", "motivation": "Real-world data collection for AVs is costly and struggles with rare edge cases, which are crucial for system robustness.", "method": "The pipeline uses Cosmos-Drive, a suite of models derived from NVIDIA Cosmos, to generate controllable, high-fidelity driving videos.", "result": "The generated data enhances dataset diversity, mitigates long-tail distribution issues, and improves tasks like 3D lane detection and driving policy learning.", "conclusion": "The open-sourced pipeline and models provide a scalable solution for generating high-quality synthetic driving data."}}
{"id": "2506.08962", "pdf": "https://arxiv.org/pdf/2506.08962", "abs": "https://arxiv.org/abs/2506.08962", "authors": ["Liangliang Chen", "Huiru Xie", "Jacqueline Rohde", "Ying Zhang"], "title": "WIP: Large Language Model-Enhanced Smart Tutor for Undergraduate Circuit Analysis", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Accepted to 2025 Frontiers in Education (FIE) Conference", "summary": "This research-to-practice work-in-progress (WIP) paper presents an AI-enabled\nsmart tutor designed to provide homework assessment and feedback for students\nin an undergraduate circuit analysis course. We detail the tutor's design\nphilosophy and core components, including open-ended question answering and\nhomework feedback generation. The prompts are carefully crafted to optimize\nresponses across different problems. The smart tutor was deployed on the\nMicrosoft Azure platform and is currently in use in an undergraduate circuit\nanalysis course at the School of Electrical and Computer Engineering in a\nlarge, public, research-intensive institution in the Southeastern United\nStates. Beyond offering personalized instruction and feedback, the tutor\ncollects student interaction data, which is summarized and shared with the\ncourse instructor. To evaluate its effectiveness, we collected student\nfeedback, with 90.9% of responses indicating satisfaction with the tutor.\nAdditionally, we analyze a subset of collected data on preliminary circuit\nanalysis topics to assess tutor usage frequency for each problem and identify\nfrequently asked questions. These insights help instructors gain real-time\nawareness of student difficulties, enabling more targeted classroom\ninstruction. In future work, we will release a full analysis once the complete\ndataset is available after the Spring 2025 semester. We also explore the\npotential applications of this smart tutor across a broader range of\nengineering disciplines by developing improved prompts, diagram-recognition\nmethods, and database management strategies, which remain ongoing areas of\nresearch.", "AI": {"tldr": "An AI-enabled smart tutor for circuit analysis homework provides personalized feedback and collects student interaction data, with high student satisfaction (90.9%). Future work includes broader applications and improved features.", "motivation": "To enhance student learning in circuit analysis by offering personalized homework feedback and real-time insights for instructors.", "method": "Deployed on Microsoft Azure, the tutor uses open-ended question answering and feedback generation, with carefully crafted prompts. Student interaction data is collected and analyzed.", "result": "90.9% student satisfaction; preliminary data helps instructors identify student difficulties.", "conclusion": "The smart tutor is effective and scalable, with potential for broader engineering applications through ongoing research."}}
{"id": "2506.08939", "pdf": "https://arxiv.org/pdf/2506.08939", "abs": "https://arxiv.org/abs/2506.08939", "authors": ["Hang Ye", "Gaoxiang Duan", "Haoran Zeng", "Yangxin Zhu", "Lingxue Meng", "Xiaoying Zheng", "Yongxin Zhu"], "title": "KARMA: A Multilevel Decomposition Hybrid Mamba Framework for Multivariate Long-Term Time Series Forecasting", "categories": ["cs.LG"], "comment": "10 pages,3 figures, published to WASA2025", "summary": "Multivariate long-term and efficient time series forecasting is a key\nrequirement for a variety of practical applications, and there are complex\ninterleaving time dynamics in time series data that require decomposition\nmodeling. Traditional time series decomposition methods are single and rely on\nfixed rules, which are insufficient for mining the potential information of the\nseries and adapting to the dynamic characteristics of complex series. On the\nother hand, the Transformer-based models for time series forecasting struggle\nto effectively model long sequences and intricate dynamic relationships due to\ntheir high computational complexity. To overcome these limitations, we\nintroduce KARMA, with an Adaptive Time Channel Decomposition module (ATCD) to\ndynamically extract trend and seasonal components. It further integrates a\nHybrid Frequency-Time Decomposition module (HFTD) to further decompose Series\ninto frequency-domain and time-domain. These components are coupled with\nmulti-scale Mamba-based KarmaBlock to efficiently process global and local\ninformation in a coordinated manner. Experiments on eight real-world datasets\nfrom diverse domains well demonstrated that KARMA significantly outperforms\nmainstream baseline methods in both predictive accuracy and computational\nefficiency. Code and full results are available at this repository:\nhttps://github.com/yedadasd/KARMA", "AI": {"tldr": "KARMA introduces adaptive decomposition and hybrid frequency-time modules to improve long-term multivariate time series forecasting, outperforming traditional and Transformer-based methods.", "motivation": "Traditional decomposition methods and Transformer-based models fail to handle complex time dynamics and long sequences effectively.", "method": "KARMA uses Adaptive Time Channel Decomposition (ATCD) and Hybrid Frequency-Time Decomposition (HFTD) with Mamba-based KarmaBlock for efficient processing.", "result": "Outperforms baselines in accuracy and efficiency across eight real-world datasets.", "conclusion": "KARMA is a robust solution for complex time series forecasting, combining dynamic decomposition and efficient processing."}}
{"id": "2410.20682", "pdf": "https://arxiv.org/pdf/2410.20682", "abs": "https://arxiv.org/abs/2410.20682", "authors": ["Eunwon Kim", "Chanho Park", "Buru Chang"], "title": "SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script", "categories": ["cs.CL"], "comment": null, "summary": "Shared memories between two individuals strengthen their bond and are crucial\nfor facilitating their ongoing conversations. This study aims to make long-term\ndialogue more engaging by leveraging these shared memories. To this end, we\nintroduce a new long-term dialogue dataset named SHARE, constructed from movie\nscripts, which are a rich source of shared memories among various\nrelationships. Our dialogue dataset contains the summaries of persona\ninformation and events of two individuals, as explicitly revealed in their\nconversation, along with implicitly extractable shared memories. We also\nintroduce EPISODE, a long-term dialogue framework based on SHARE that utilizes\nshared experiences between individuals. Through experiments using SHARE, we\ndemonstrate that shared memories between two individuals make long-term\ndialogues more engaging and sustainable, and that EPISODE effectively manages\nshared memories during dialogue. Our dataset and code are available at\nhttps://github.com/e1kim/SHARE.", "AI": {"tldr": "The paper introduces SHARE, a long-term dialogue dataset from movie scripts, and EPISODE, a framework leveraging shared memories to enhance dialogue engagement.", "motivation": "To improve long-term dialogue engagement by utilizing shared memories between individuals.", "method": "Constructed the SHARE dataset from movie scripts, capturing explicit and implicit shared memories. Developed EPISODE, a framework to manage and utilize these memories in dialogue.", "result": "Shared memories enhance dialogue engagement and sustainability; EPISODE effectively manages these memories.", "conclusion": "The study demonstrates the value of shared memories in long-term dialogue and provides tools (SHARE and EPISODE) for further research."}}
{"id": "2506.09045", "pdf": "https://arxiv.org/pdf/2506.09045", "abs": "https://arxiv.org/abs/2506.09045", "authors": ["Zehong Ma", "Longhui Wei", "Feng Wang", "Shiliang Zhang", "Qi Tian"], "title": "MagCache: Fast Video Generation with Magnitude-Aware Cache", "categories": ["cs.CV"], "comment": "Project Page: https://zehong-ma.github.io/MagCache", "summary": "Existing acceleration techniques for video diffusion models often rely on\nuniform heuristics or time-embedding variants to skip timesteps and reuse\ncached features. These approaches typically require extensive calibration with\ncurated prompts and risk inconsistent outputs due to prompt-specific\noverfitting. In this paper, we introduce a novel and robust discovery: a\nunified magnitude law observed across different models and prompts.\nSpecifically, the magnitude ratio of successive residual outputs decreases\nmonotonically and steadily in most timesteps while rapidly in the last several\nsteps. Leveraging this insight, we introduce a Magnitude-aware Cache (MagCache)\nthat adaptively skips unimportant timesteps using an error modeling mechanism\nand adaptive caching strategy. Unlike existing methods requiring dozens of\ncurated samples for calibration, MagCache only requires a single sample for\ncalibration. Experimental results show that MagCache achieves 2.1x and 2.68x\nspeedups on Open-Sora and Wan 2.1, respectively, while preserving superior\nvisual fidelity. It significantly outperforms existing methods in LPIPS, SSIM,\nand PSNR, under comparable computational budgets.", "AI": {"tldr": "A novel Magnitude-aware Cache (MagCache) method accelerates video diffusion models by leveraging a unified magnitude law, achieving significant speedups without compromising visual quality.", "motivation": "Existing acceleration techniques for video diffusion models rely on uniform heuristics or time-embedding variants, risking inconsistent outputs and requiring extensive calibration.", "method": "MagCache uses a unified magnitude law to adaptively skip unimportant timesteps via error modeling and adaptive caching, requiring only a single calibration sample.", "result": "MagCache achieves 2.1x and 2.68x speedups on Open-Sora and Wan 2.1, respectively, with superior visual fidelity and outperforms existing methods in LPIPS, SSIM, and PSNR.", "conclusion": "MagCache is a robust and efficient acceleration method for video diffusion models, eliminating the need for extensive calibration while maintaining high-quality outputs."}}
{"id": "2506.08965", "pdf": "https://arxiv.org/pdf/2506.08965", "abs": "https://arxiv.org/abs/2506.08965", "authors": ["Yiyang Zhao", "Huiyu Bai", "Xuejiao Zhao"], "title": "GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The ability to train high-performing reward models with few-shot data is\ncritical for enhancing the efficiency and scalability of Reinforcement Learning\nfrom Human Feedback (RLHF). We propose a data augmentation and expansion\nframework that enables generative reward models trained on small datasets to\nachieve comparable performance to those trained on large-scale datasets.\nTraditional methods to train a generative reward model, such as Direct\nPreference Optimization (DPO), are constrained by inefficiencies in sample\npairing and limited data diversity. This work introduces preference refinement,\nwhich employs Chain-of-Thought (CoT) sampling to uncover diverse and\nhigh-quality preference relationships. It also incorporates a perplexity-based\nscoring mechanism to assign nuanced preference levels and utilizes Multi-level\nDirect Preference Optimization (M-DPO) to enable the model to capture\nfiner-grained preference differences between samples. Experimental results\ndemonstrate that the proposed method significantly enhances data efficiency and\nmodel performance, enabling reward models trained in a few-shot setting to\nachieve results on par with those trained on large-scale datasets. This study\nunderscores the potential of data-efficient strategies in advancing reward\nmodel optimization, offering a robust solution for low-resource RLHF\napplications.", "AI": {"tldr": "A framework for training high-performing reward models with few-shot data using data augmentation and preference refinement, achieving results comparable to large-scale datasets.", "motivation": "Enhancing efficiency and scalability of Reinforcement Learning from Human Feedback (RLHF) by overcoming inefficiencies in sample pairing and limited data diversity.", "method": "Introduces preference refinement with Chain-of-Thought sampling, perplexity-based scoring, and Multi-level Direct Preference Optimization (M-DPO).", "result": "Significantly improves data efficiency and model performance, matching large-scale dataset results in few-shot settings.", "conclusion": "Demonstrates the potential of data-efficient strategies for reward model optimization, benefiting low-resource RLHF applications."}}
{"id": "2506.08977", "pdf": "https://arxiv.org/pdf/2506.08977", "abs": "https://arxiv.org/abs/2506.08977", "authors": ["Victoria Hankemeier", "Malte Schilling"], "title": "Tailored Architectures for Time Series Forecasting: Evaluating Deep Learning Models on Gaussian Process-Generated Data", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at IJCNN25, Code: https://github.com/vicky-hnk/time-flex", "summary": "Developments in Deep Learning have significantly improved time series\nforecasting by enabling more accurate modeling of complex temporal dependencies\ninherent in sequential data. The effectiveness of such models is often\ndemonstrated on limited sets of specific real-world data. Although this allows\nfor comparative analysis, it still does not demonstrate how specific data\ncharacteristics align with the architectural strengths of individual models.\nOur research aims at uncovering clear connections between time series\ncharacteristics and particular models. We introduce a novel dataset generated\nusing Gaussian Processes, specifically designed to display distinct, known\ncharacteristics for targeted evaluations of model adaptability to them.\nFurthermore, we present TimeFlex, a new model that incorporates a modular\narchitecture tailored to handle diverse temporal dynamics, including trends and\nperiodic patterns. This model is compared to current state-of-the-art models,\noffering a deeper understanding of how models perform under varied time series\nconditions.", "AI": {"tldr": "The paper introduces a novel dataset and TimeFlex model to explore connections between time series characteristics and model performance, comparing it to state-of-the-art models.", "motivation": "To address the gap in understanding how specific time series characteristics align with model strengths, beyond limited real-world data evaluations.", "method": "Uses Gaussian Processes to generate a dataset with known characteristics and introduces TimeFlex, a modular model for diverse temporal dynamics.", "result": "TimeFlex is compared to state-of-the-art models, providing insights into model adaptability to varied time series conditions.", "conclusion": "The study enhances understanding of model performance by linking time series features to architectural strengths, aided by the new dataset and TimeFlex."}}
{"id": "2410.24200", "pdf": "https://arxiv.org/pdf/2410.24200", "abs": "https://arxiv.org/abs/2410.24200", "authors": ["Yuqi Zhou", "Sunhao Dai", "Zhanshuo Cao", "Xiao Zhang", "Jun Xu"], "title": "Length-Induced Embedding Collapse in PLM-based Models", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted by ACL 2025", "summary": "Text embeddings from PLM-based models enable a wide range of applications,\nyet their performance often degrades on longer texts. In this paper, we\nintroduce a phenomenon we call Length Collapse, where embeddings of longer\ntexts tend to cluster together. This clustering results in a distributional\ninconsistency between the embeddings of short and long texts. We further\ninvestigate how these differences contribute to the performance decline\nobserved with longer texts across various downstream tasks. Through a rigorous\ntheoretical analysis of the self-attention mechanism, which acts as a low-pass\nfilter in PLM-based models, we demonstrate that as text length increases, the\nstrength of low-pass filtering intensifies, causing embeddings to retain more\nlow-frequency components. As a result, input token features become more\nsimilar, leading to clustering and ultimately the collapse of embeddings for\nlonger texts. To address this issue, we propose a simple method, TempScale,\nwhich mitigates the Length Collapse phenomenon. By narrowing the gap in\nlow-pass filtering rates between long and short texts, TempScale ensures more\nconsistent embeddings across different text lengths. This approach leads to\nperformance improvements of 0.94% on MTEB and 1.10% on LongEmbed, which focuses\nspecifically on long-context retrieval, providing strong evidence for the\nvalidity of our analysis. The source code is available at\nhttps://github.com/Yuqi-Zhou/Length_Collapse.", "AI": {"tldr": "The paper identifies Length Collapse, where embeddings of longer texts cluster together, degrading performance. It proposes TempScale to mitigate this, improving performance on benchmarks.", "motivation": "Address the performance degradation of text embeddings from PLM-based models on longer texts due to Length Collapse.", "method": "Theoretical analysis of self-attention as a low-pass filter and introduction of TempScale to balance filtering rates.", "result": "TempScale improves performance by 0.94% on MTEB and 1.10% on LongEmbed.", "conclusion": "TempScale effectively mitigates Length Collapse, enhancing embedding consistency and performance across text lengths."}}
{"id": "2506.08043", "pdf": "https://arxiv.org/pdf/2506.08043", "abs": "https://arxiv.org/abs/2506.08043", "authors": ["Ashkan Shahbazi", "Kyvia Pereira", "Jon S. Heiselman", "Elaheh Akbari", "Annie C. Benson", "Sepehr Seifi", "Xinyuan Liu", "Garrison L. Johnston", "Erwin Terpstra", "Anne Draaisma", "Jan-Jaap Severes", "Jie Ying Wu", "Nabil Simaan", "Michael L. Miga", "Soheil Kolouri"], "title": "Neural-Augmented Kelvinlet: Real-Time Soft Tissue Deformation with Multiple Graspers", "categories": ["cs.GR", "cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Fast and accurate simulation of soft tissue deformation is a critical factor\nfor surgical robotics and medical training. In this paper, we introduce a novel\nphysics-informed neural simulator that approximates soft tissue deformations in\na realistic and real-time manner. Our framework integrates Kelvinlet-based\npriors into neural simulators, making it the first approach to leverage\nKelvinlets for residual learning and regularization in data-driven soft tissue\nmodeling. By incorporating large-scale Finite Element Method (FEM) simulations\nof both linear and nonlinear soft tissue responses, our method improves neural\nnetwork predictions across diverse architectures, enhancing accuracy and\nphysical consistency while maintaining low latency for real-time performance.\nWe demonstrate the effectiveness of our approach by performing accurate\nsurgical maneuvers that simulate the use of standard laparoscopic tissue\ngrasping tools with high fidelity. These results establish Kelvinlet-augmented\nlearning as a powerful and efficient strategy for real-time, physics-aware soft\ntissue simulation in surgical applications.", "AI": {"tldr": "A novel physics-informed neural simulator for real-time soft tissue deformation, using Kelvinlet-based priors and FEM simulations to enhance accuracy and physical consistency.", "motivation": "Fast and accurate soft tissue simulation is crucial for surgical robotics and medical training.", "method": "Integrates Kelvinlet-based priors into neural simulators, leveraging FEM simulations for residual learning and regularization.", "result": "Improves neural network predictions, enabling accurate surgical maneuvers with high fidelity.", "conclusion": "Kelvinlet-augmented learning is effective for real-time, physics-aware soft tissue simulation in surgery."}}
{"id": "2506.08978", "pdf": "https://arxiv.org/pdf/2506.08978", "abs": "https://arxiv.org/abs/2506.08978", "authors": ["Anna Langedijk", "Jaap Jumelet", "Willem Zuidema"], "title": "Propositional Logic for Probing Generalization in Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The extent to which neural networks are able to acquire and represent\nsymbolic rules remains a key topic of research and debate. Much current work\nfocuses on the impressive capabilities of large language models, as well as\ntheir often ill-understood failures on a wide range of reasoning tasks. In this\npaper, in contrast, we investigate the generalization behavior of three key\nneural architectures (Transformers, Graph Convolution Networks and LSTMs) in a\ncontrolled task rooted in propositional logic. The task requires models to\ngenerate satisfying assignments for logical formulas, making it a structured\nand interpretable setting for studying compositionality. We introduce a\nbalanced extension of an existing dataset to eliminate superficial patterns and\nenable testing on unseen operator combinations. Using this dataset, we evaluate\nthe ability of the three architectures to generalize beyond the training\ndistribution. While all models perform well in-distribution, we find that\ngeneralization to unseen patterns, particularly those involving negation,\nremains a significant challenge. Transformers fail to apply negation\ncompositionally, unless structural biases are introduced. Our findings\nhighlight persistent limitations in the ability of standard architectures to\nlearn systematic representations of logical operators, suggesting the need for\nstronger inductive biases to support robust rule-based reasoning.", "AI": {"tldr": "The paper examines how neural networks generalize symbolic rules, focusing on Transformers, GCNs, and LSTMs in a propositional logic task. While models perform well in-distribution, generalization to unseen patterns, especially negation, remains challenging.", "motivation": "To understand neural networks' ability to acquire and represent symbolic rules, particularly in structured reasoning tasks like propositional logic.", "method": "Evaluated three architectures (Transformers, GCNs, LSTMs) on a controlled task of generating satisfying assignments for logical formulas, using a balanced dataset to test generalization.", "result": "All models performed well in-distribution but struggled with unseen patterns, especially negation. Transformers failed without structural biases.", "conclusion": "Standard architectures lack systematic representation of logical operators, indicating a need for stronger inductive biases for robust rule-based reasoning."}}
{"id": "2506.08982", "pdf": "https://arxiv.org/pdf/2506.08982", "abs": "https://arxiv.org/abs/2506.08982", "authors": ["Ivan Rubachev", "Akim Kotelnikov", "Nikolay Kartashev"], "title": "On Finetuning Tabular Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Foundation models are an emerging research direction in tabular deep\nlearning. Notably, TabPFNv2 recently claimed superior performance over\ntraditional GBDT-based methods on small-scale datasets using an in-context\nlearning paradigm, which does not adapt model parameters to target datasets.\nHowever, the optimal finetuning approach for adapting tabular foundational\nmodels, and how this adaptation reshapes their internal mechanisms, remains\nunderexplored. While prior works studied finetuning for earlier foundational\nmodels, inconsistent findings and TabPFNv2's unique architecture necessitate\nfresh investigation. To address these questions, we first systematically\nevaluate various finetuning strategies on diverse datasets. Our findings\nestablish full finetuning as the most practical solution for TabPFNv2 in terms\nof time-efficiency and effectiveness. We then investigate how finetuning alters\nTabPFNv2's inner mechanisms, drawing an analogy to retrieval-augmented models.\nWe reveal that the success of finetuning stems from the fact that after\ngradient-based adaptation, the dot products of the query-representations of\ntest objects and the key-representations of in-context training objects more\naccurately reflect their target similarity. This improved similarity allows\nfinetuned TabPFNv2 to better approximate target dependency by appropriately\nweighting relevant in-context samples, improving the retrieval-based prediction\nlogic. From the practical perspective, we managed to finetune TabPFNv2 on\ndatasets with up to 50K objects, observing performance improvements on almost\nall tasks. More precisely, on academic datasets with I.I.D. splits, finetuning\nallows TabPFNv2 to achieve state-of-the-art results, while on datasets with\ngradual temporal shifts and rich feature sets, TabPFNv2 is less stable and\nprior methods remain better.", "AI": {"tldr": "The paper explores finetuning strategies for TabPFNv2, a tabular foundation model, finding full finetuning most effective. It reveals how finetuning improves similarity measures and performance, achieving state-of-the-art results on some datasets but showing instability on others.", "motivation": "The study addresses the underexplored area of finetuning tabular foundation models like TabPFNv2, aiming to optimize their adaptation and understand internal mechanism changes.", "method": "Systematic evaluation of finetuning strategies on diverse datasets, analyzing how finetuning alters TabPFNv2's internal mechanisms, particularly similarity measures.", "result": "Full finetuning is most effective for TabPFNv2, improving performance on datasets up to 50K objects. It achieves state-of-the-art results on I.I.D. datasets but is less stable on temporally shifted or feature-rich datasets.", "conclusion": "Finetuning enhances TabPFNv2's performance by refining similarity measures, though its effectiveness varies by dataset type, suggesting context-specific adaptation is key."}}
{"id": "2411.15129", "pdf": "https://arxiv.org/pdf/2411.15129", "abs": "https://arxiv.org/abs/2411.15129", "authors": ["Alessandro Trevisan", "Harry Giddens", "Sarah Dillon", "Alan F. Blackwell"], "title": "The BS-meter: A ChatGPT-Trained Instrument to Detect Sloppy Language-Games", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "What can we learn about language from studying how it is used by ChatGPT and\nother large language model (LLM)-based chatbots? In this paper, we analyse the\ndistinctive character of language generated by ChatGPT, in relation to\nquestions raised by natural language processing pioneer, and student of\nWittgenstein, Margaret Masterman. Following frequent complaints that LLM-based\nchatbots produce \"slop,\" or even \"bullshit,\" in the sense of Frankfurt's\npopular monograph On Bullshit, we conduct an empirical study to contrast the\nlanguage of 1,000 scientific publications with typical text generated by\nChatGPT. We then explore whether the same language features can be detected in\ntwo well-known contexts of social dysfunction: George Orwell's critique of\npolitical speech, and David Graeber's characterisation of bullshit jobs. Using\nsimple hypothesis-testing methods, we demonstrate that a statistical model of\nsloppy bullshit can reliably relate the Frankfurtian artificial bullshit of\nChatGPT to the political and workplace functions of bullshit as observed in\nnatural human language.", "AI": {"tldr": "The paper analyzes ChatGPT's language, comparing it to scientific texts and exploring its resemblance to 'bullshit' in political and workplace contexts.", "motivation": "To understand the nature of language produced by LLM-based chatbots like ChatGPT, especially in light of criticisms labeling it as 'slop' or 'bullshit.'", "method": "Empirical study comparing 1,000 scientific publications with ChatGPT-generated text, and analyzing language features in political speech and workplace dysfunction.", "result": "A statistical model shows ChatGPT's 'bullshit' aligns with natural human language patterns in political and workplace contexts.", "conclusion": "ChatGPT's language mirrors dysfunctional human communication, validating concerns about its 'bullshit' nature."}}
{"id": "2506.08064", "pdf": "https://arxiv.org/pdf/2506.08064", "abs": "https://arxiv.org/abs/2506.08064", "authors": ["Livio Tenze", "Enrique Canessa"], "title": "A Real-time 3D Desktop Display", "categories": ["cs.GR", "cs.CV"], "comment": "10 pages, 5 figures", "summary": "A new extended version of the altiro3D C++ Library -- initially developed to\nget glass-free holographic displays starting from 2D images -- is here\nintroduced aiming to deal with 3D video streams from either 2D webcam images or\nflat video files. These streams are processed in real-time to synthesize\nlight-fields (in Native format) and feed realistic 3D experiences. The core\nfunction needed to recreate multiviews consists on the use of MiDaS\nConvolutional Neural Network (CNN), which allows to extract a depth map from a\nsingle 2D image. Artificial Intelligence (AI) computing techniques are applied\nto improve the overall performance of the extended altiro3D Library. Thus,\naltiro3D can now treat standard images, video streams or screen portions of a\nDesktop where other apps may be also running (like web browsers, video chats,\netc) and render them into 3D. To achieve the latter, a screen region need to be\nselected in order to feed the output directly into a light-field 3D device such\nas Looking Glass (LG) Portrait. In order to simplify the acquisition of a\nDesktop screen area by the user, a multi-platform Graphical User Interface has\nbeen also implemented. Sources available at:\nhttps://github.com/canessae/altiro3D/releases/tag/2.0.0", "AI": {"tldr": "The paper introduces an extended version of the altiro3D C++ Library, now capable of processing 3D video streams from 2D sources in real-time to create light-fields for 3D experiences, using AI techniques like MiDaS CNN for depth map extraction.", "motivation": "To enhance the altiro3D Library for real-time 3D video stream processing, enabling realistic 3D experiences from 2D inputs like webcam images or flat video files.", "method": "Uses MiDaS CNN for depth map extraction from 2D images and AI techniques to improve performance. Includes a multi-platform GUI for selecting screen regions.", "result": "The extended library can now process standard images, video streams, or desktop screen portions, rendering them into 3D for devices like Looking Glass Portrait.", "conclusion": "The upgraded altiro3D Library successfully integrates AI and real-time processing to deliver enhanced 3D experiences from 2D sources, with practical applications in various scenarios."}}
{"id": "2506.09018", "pdf": "https://arxiv.org/pdf/2506.09018", "abs": "https://arxiv.org/abs/2506.09018", "authors": ["Marton Havasi", "Brian Karrer", "Itai Gat", "Ricky T. Q. Chen"], "title": "Edit Flows: Flow Matching with Edit Operations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Autoregressive generative models naturally generate variable-length\nsequences, while non-autoregressive models struggle, often imposing rigid,\ntoken-wise structures. We propose Edit Flows, a non-autoregressive model that\novercomes these limitations by defining a discrete flow over sequences through\nedit operations-insertions, deletions, and substitutions. By modeling these\noperations within a Continuous-time Markov Chain over the sequence space, Edit\nFlows enable flexible, position-relative generation that aligns more closely\nwith the structure of sequence data. Our training method leverages an expanded\nstate space with auxiliary variables, making the learning process efficient and\ntractable. Empirical results show that Edit Flows outperforms both\nautoregressive and mask models on image captioning and significantly\noutperforms the mask construction in text and code generation.", "AI": {"tldr": "Edit Flows is a non-autoregressive model using edit operations for flexible sequence generation, outperforming autoregressive and mask models.", "motivation": "Overcome limitations of non-autoregressive models in handling variable-length sequences by introducing edit operations.", "method": "Defines a discrete flow over sequences via insertions, deletions, and substitutions, modeled with a Continuous-time Markov Chain. Uses an expanded state space with auxiliary variables for efficient training.", "result": "Outperforms autoregressive and mask models in image captioning and excels in text and code generation.", "conclusion": "Edit Flows provide a flexible and efficient alternative for sequence generation, aligning better with data structure."}}
{"id": "2506.09007", "pdf": "https://arxiv.org/pdf/2506.09007", "abs": "https://arxiv.org/abs/2506.09007", "authors": ["Sophia Tang", "Yinuo Zhang", "Alexander Tong", "Pranam Chatterjee"], "title": "Branched Schr\u00f6dinger Bridge Matching", "categories": ["cs.LG"], "comment": null, "summary": "Predicting the intermediate trajectories between an initial and target\ndistribution is a central problem in generative modeling. Existing approaches,\nsuch as flow matching and Schr\\\"odinger Bridge Matching, effectively learn\nmappings between two distributions by modeling a single stochastic path.\nHowever, these methods are inherently limited to unimodal transitions and\ncannot capture branched or divergent evolution from a common origin to multiple\ndistinct outcomes. To address this, we introduce Branched Schr\\\"odinger Bridge\nMatching (BranchSBM), a novel framework that learns branched Schr\\\"odinger\nbridges. BranchSBM parameterizes multiple time-dependent velocity fields and\ngrowth processes, enabling the representation of population-level divergence\ninto multiple terminal distributions. We show that BranchSBM is not only more\nexpressive but also essential for tasks involving multi-path surface\nnavigation, modeling cell fate bifurcations from homogeneous progenitor states,\nand simulating diverging cellular responses to perturbations.", "AI": {"tldr": "BranchSBM introduces a framework for learning branched Schr\u00f6dinger bridges, enabling multi-path transitions between distributions, unlike unimodal methods.", "motivation": "Existing methods like flow matching and Schr\u00f6dinger Bridge Matching are limited to unimodal transitions, unable to model branched or divergent evolution.", "method": "BranchSBM parameterizes multiple time-dependent velocity fields and growth processes to represent population-level divergence into multiple terminal distributions.", "result": "BranchSBM is more expressive and essential for tasks like multi-path navigation, cell fate bifurcation modeling, and simulating divergent cellular responses.", "conclusion": "BranchSBM addresses the limitations of unimodal methods by enabling branched transitions, proving useful for complex tasks involving divergence."}}
{"id": "2412.03719", "pdf": "https://arxiv.org/pdf/2412.03719", "abs": "https://arxiv.org/abs/2412.03719", "authors": ["Tim Vieira", "Ben LeBrun", "Mario Giulianelli", "Juan Luis Gastaldi", "Brian DuSell", "John Terilla", "Timothy J. O'Donnell", "Ryan Cotterell"], "title": "From Language Models over Tokens to Language Models over Characters", "categories": ["cs.CL", "cs.AI"], "comment": "ICML 2025", "summary": "Modern language models are internally -- and mathematically -- distributions\nover $\\it{token}$ strings rather than $\\it{character}$ strings, posing numerous\nchallenges for programmers building user applications on top of them. For\nexample, if a prompt is specified as a character string, it must be tokenized\nbefore passing it to the token-level language model. Thus, the tokenizer and\nconsequent processing are very sensitive to the specification of the prompt\n(e.g., whether the prompt ends with a space or not). This paper presents\nalgorithms for converting token-level language models to character-level ones.\nWe present both exact and approximate algorithms. In the empirical portion of\nthe paper, we benchmark the practical runtime and approximation quality. Across\nfour publicly available language models, we find that -- even with a small\ncomputation budget -- our method is able to accurately approximate the\ncharacter-level distribution at reasonably fast speeds, and that a significant\nimprovement in the language model's compression rate (bits/byte) is achieved.", "AI": {"tldr": "The paper presents algorithms to convert token-level language models to character-level ones, addressing challenges in prompt specification and tokenization sensitivity.", "motivation": "Token-level language models pose challenges for user applications due to their sensitivity to prompt specifications (e.g., spaces). Converting them to character-level models can mitigate these issues.", "method": "The paper introduces exact and approximate algorithms for converting token-level to character-level models. It benchmarks runtime and approximation quality.", "result": "Empirical results show the method accurately approximates character-level distributions with fast speeds and improves compression rates (bits/byte).", "conclusion": "The proposed algorithms effectively bridge the gap between token-level and character-level language models, enhancing usability and performance."}}
{"id": "2506.08258", "pdf": "https://arxiv.org/pdf/2506.08258", "abs": "https://arxiv.org/abs/2506.08258", "authors": ["Lorenzo Arboit", "Dennis N. Schneider", "Toby Collins", "Daniel A. Hashimoto", "Silvana Perretta", "Bernard Dallemagne", "Jacques Marescaux", "EAES Working Group", "Nicolas Padoy", "Pietro Mascagni"], "title": "Surgeons Awareness, Expectations, and Involvement with Artificial Intelligence: a Survey Pre and Post the GPT Era", "categories": ["cs.CY", "cs.CV"], "comment": "11 pages, 3 figures", "summary": "Artificial Intelligence (AI) is transforming medicine, with generative AI\nmodels like ChatGPT reshaping perceptions of its potential. This study examines\nsurgeons' awareness, expectations, and involvement with AI in surgery through\ncomparative surveys conducted in 2021 and 2024. Two cross-sectional surveys\nwere distributed globally in 2021 and 2024, the first before an IRCAD webinar\nand the second during the annual EAES meeting. The surveys assessed\ndemographics, AI awareness, expectations, involvement, and ethics (2024 only).\nThe surveys collected a total of 671 responses from 98 countries, 522 in 2021\nand 149 in 2024. Awareness of AI courses rose from 14.5% in 2021 to 44.6% in\n2024, while course attendance increased from 12.9% to 23%. Despite this,\nfamiliarity with foundational AI concepts remained limited. Expectations for\nAI's role shifted in 2024, with hospital management gaining relevance. Ethical\nconcerns gained prominence, with 87.2% of 2024 participants emphasizing\naccountability and transparency. Infrastructure limitations remained the\nprimary obstacle to implementation. Interdisciplinary collaboration and\nstructured training were identified as critical for successful AI adoption.\nOptimism about AI's transformative potential remained high, with 79.9% of\nrespondents believing AI would positively impact surgery and 96.6% willing to\nintegrate AI into their clinical practice. Surgeons' perceptions of AI are\nevolving, driven by the rise of generative AI and advancements in surgical data\nscience. While enthusiasm for integration is strong, knowledge gaps and\ninfrastructural challenges persist. Addressing these through education, ethical\nframeworks, and infrastructure development is essential.", "AI": {"tldr": "Surgeons' awareness and involvement with AI in surgery increased from 2021 to 2024, but foundational knowledge gaps and infrastructural challenges remain. Ethical concerns and interdisciplinary collaboration are key for AI adoption.", "motivation": "To examine how surgeons' perceptions, awareness, and involvement with AI in surgery have evolved, especially with the rise of generative AI models like ChatGPT.", "method": "Comparative global surveys in 2021 and 2024 assessed demographics, AI awareness, expectations, involvement, and ethics.", "result": "Awareness and course attendance rose, but foundational AI knowledge was limited. Ethical concerns grew, and infrastructure was a major obstacle. Optimism for AI's impact remained high.", "conclusion": "While enthusiasm for AI in surgery is strong, addressing knowledge gaps, ethical concerns, and infrastructure is crucial for successful adoption."}}
{"id": "2506.09034", "pdf": "https://arxiv.org/pdf/2506.09034", "abs": "https://arxiv.org/abs/2506.09034", "authors": ["Sizhe Dang", "Yangyang Guo", "Yanjun Zhao", "Haishan Ye", "Xiaodong Zheng", "Guang Dai", "Ivor Tsang"], "title": "FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks:\nthe backward pass of first-order optimizers like Adam increases memory usage to\nmore than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order\n(ZO) optimizers avoid this cost by estimating gradients only from forward\npasses, yet existing methods like MeZO usually require many more steps to\nconverge. Can this trade-off between speed and memory in ZO be fundamentally\nimproved? Normalized-SGD demonstrates strong empirical performance with greater\nmemory efficiency than Adam. In light of this, we introduce FZOO, a Fast\nZeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward\npasses needed for convergence by employing batched one-sided estimates that\nadapt step sizes based on the standard deviation of batch losses. It also\naccelerates per-batch computation through the use of Rademacher random vector\nperturbations coupled with CUDA's parallel processing. Extensive experiments on\ndiverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3,\nacross 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms\nMeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For\nRoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy\nand an 18 times reduction in forward passes compared to MeZO, achieving\nconvergence speeds comparable to Adam. We also provide theoretical analysis\nproving FZOO's formal equivalence to a normalized-SGD update rule and its\nconvergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling\neven larger memory savings. Overall, our results make single-GPU, high-speed,\nfull-parameter fine-tuning practical and point toward future work on\nmemory-efficient pre-training.", "AI": {"tldr": "FZOO is a fast zeroth-order optimizer that improves the trade-off between speed and memory in fine-tuning LLMs, outperforming MeZO in accuracy and reducing forward passes significantly.", "motivation": "Addressing GPU memory bottlenecks in fine-tuning LLMs by improving zeroth-order optimizers to achieve Adam-scale speed without high memory costs.", "method": "FZOO uses batched one-sided gradient estimates, adaptive step sizes based on batch loss deviation, and Rademacher random vector perturbations with CUDA parallel processing.", "result": "FZOO outperforms MeZO by 3% in accuracy and reduces forward passes by 3x on average, with RoBERTa-large showing 5.6% accuracy improvement and 18x fewer forward passes.", "conclusion": "FZOO enables practical single-GPU, high-speed, full-parameter fine-tuning and suggests potential for memory-efficient pre-training."}}
{"id": "2506.09010", "pdf": "https://arxiv.org/pdf/2506.09010", "abs": "https://arxiv.org/abs/2506.09010", "authors": ["Sebastian Schmidt", "Prasanga Dhungel", "Christoffer L\u00f6ffler", "Bj\u00f6rn Nieth", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Effective Data Pruning through Score Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Training advanced machine learning models demands massive datasets, resulting\nin prohibitive computational costs. To address this challenge, data pruning\ntechniques identify and remove redundant training samples while preserving\nmodel performance. Yet, existing pruning techniques predominantly require a\nfull initial training pass to identify removable samples, negating any\nefficiency benefits for single training runs. To overcome this limitation, we\nintroduce a novel importance score extrapolation framework that requires\ntraining on only a small subset of data. We present two initial approaches in\nthis framework - k-nearest neighbors and graph neural networks - to accurately\npredict sample importance for the entire dataset using patterns learned from\nthis minimal subset. We demonstrate the effectiveness of our approach for 2\nstate-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different\ndatasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training\nparadigms (supervised, unsupervised, and adversarial). Our results indicate\nthat score extrapolation is a promising direction to scale expensive score\ncalculation methods, such as pruning, data attribution, or other tasks.", "AI": {"tldr": "A new framework predicts sample importance using minimal training data, improving efficiency for data pruning without full initial training.", "motivation": "Reduce computational costs of training by pruning redundant samples without needing full initial training.", "method": "Introduces importance score extrapolation using k-nearest neighbors and graph neural networks on a small data subset.", "result": "Effective for 2 pruning methods, 4 datasets, and 3 training paradigms, showing promise for scaling expensive tasks.", "conclusion": "Score extrapolation is a scalable solution for data pruning and similar tasks."}}
{"id": "2412.09569", "pdf": "https://arxiv.org/pdf/2412.09569", "abs": "https://arxiv.org/abs/2412.09569", "authors": ["Ariel Gera", "Odellia Boni", "Yotam Perlitz", "Roy Bar-Haim", "Lilach Eden", "Asaf Yehudai"], "title": "JuStRank: Benchmarking LLM Judges for System Ranking", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025", "summary": "Given the rapid progress of generative AI, there is a pressing need to\nsystematically compare and choose between the numerous models and\nconfigurations available. The scale and versatility of such evaluations make\nthe use of LLM-based judges a compelling solution for this challenge.\nCrucially, this approach requires first to validate the quality of the LLM\njudge itself. Previous work has focused on instance-based assessment of LLM\njudges, where a judge is evaluated over a set of responses, or response pairs,\nwhile being agnostic to their source systems. We argue that this setting\noverlooks critical factors affecting system-level ranking, such as a judge's\npositive or negative bias towards certain systems. To address this gap, we\nconduct the first large-scale study of LLM judges as system rankers. System\nscores are generated by aggregating judgment scores over multiple system\noutputs, and the judge's quality is assessed by comparing the resulting system\nranking to a human-based ranking. Beyond overall judge assessment, our analysis\nprovides a fine-grained characterization of judge behavior, including their\ndecisiveness and bias.", "AI": {"tldr": "The paper proposes using LLM-based judges to evaluate generative AI models, emphasizing the need to validate their quality for system-level ranking, and conducts a large-scale study to assess judge behavior.", "motivation": "The rapid progress of generative AI requires systematic evaluation of models, but existing methods overlook system-level biases in LLM judges.", "method": "Aggregates judgment scores over multiple system outputs to generate system rankings, comparing them to human-based rankings for validation.", "result": "Provides insights into LLM judge behavior, including decisiveness and bias, beyond instance-based evaluations.", "conclusion": "Highlights the importance of validating LLM judges for system-level ranking and offers a detailed analysis of their performance."}}
{"id": "2506.08334", "pdf": "https://arxiv.org/pdf/2506.08334", "abs": "https://arxiv.org/abs/2506.08334", "authors": ["Weikun Peng", "Jun Lv", "Cewu Lu", "Manolis Savva"], "title": "Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos", "categories": ["cs.GR", "cs.CV"], "comment": "Project website can be found at\n  https://3dlg-hcvc.github.io/video2articulation/", "summary": "Articulated objects are prevalent in daily life. Understanding their\nkinematic structure and reconstructing them have numerous applications in\nembodied AI and robotics. However, current methods require carefully captured\ndata for training or inference, preventing practical, scalable, and\ngeneralizable reconstruction of articulated objects. We focus on reconstruction\nof an articulated object from a casually captured RGBD video shot with a\nhand-held camera. A casually captured video of an interaction with an\narticulated object is easy to acquire at scale using smartphones. However, this\nsetting is quite challenging, as the object and camera move simultaneously and\nthere are significant occlusions as the person interacts with the object. To\ntackle these challenges, we introduce a coarse-to-fine framework that infers\njoint parameters and segments movable parts of the object from a dynamic RGBD\nvideo. To evaluate our method under this new setting, we build a 20$\\times$\nlarger synthetic dataset of 784 videos containing 284 objects across 11\ncategories. We compare our approach with existing methods that also take video\nas input. Experiments show that our method can reconstruct synthetic and real\narticulated objects across different categories from dynamic RGBD videos,\noutperforming existing methods significantly.", "AI": {"tldr": "A method for reconstructing articulated objects from casually captured RGBD videos, outperforming existing methods with a coarse-to-fine framework.", "motivation": "Understanding and reconstructing articulated objects is crucial for AI and robotics, but current methods lack scalability due to data requirements.", "method": "A coarse-to-fine framework that infers joint parameters and segments movable parts from dynamic RGBD videos.", "result": "Outperforms existing methods, successfully reconstructing synthetic and real articulated objects across categories.", "conclusion": "The approach enables scalable and generalizable reconstruction of articulated objects from easily acquired videos."}}
{"id": "2407.01067", "pdf": "https://arxiv.org/pdf/2407.01067", "abs": "https://arxiv.org/abs/2407.01067", "authors": ["Changde Du", "Kaicheng Fu", "Bincheng Wen", "Yi Sun", "Jie Peng", "Wei Wei", "Ying Gao", "Shengpei Wang", "Chuncheng Zhang", "Jinpeng Li", "Shuang Qiu", "Le Chang", "Huiguang He"], "title": "Human-like object concept representations emerge naturally in multimodal large language models", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC", "cs.LG"], "comment": "Published on Nature Machine Intelligence", "summary": "Understanding how humans conceptualize and categorize natural objects offers\ncritical insights into perception and cognition. With the advent of Large\nLanguage Models (LLMs), a key question arises: can these models develop\nhuman-like object representations from linguistic and multimodal data? In this\nstudy, we combined behavioral and neuroimaging analyses to explore the\nrelationship between object concept representations in LLMs and human\ncognition. We collected 4.7 million triplet judgments from LLMs and Multimodal\nLLMs (MLLMs) to derive low-dimensional embeddings that capture the similarity\nstructure of 1,854 natural objects. The resulting 66-dimensional embeddings\nwere stable, predictive, and exhibited semantic clustering similar to human\nmental representations. Remarkably, the dimensions underlying these embeddings\nwere interpretable, suggesting that LLMs and MLLMs develop human-like\nconceptual representations of objects. Further analysis showed strong alignment\nbetween model embeddings and neural activity patterns in brain regions such as\nEBA, PPA, RSC, and FFA. This provides compelling evidence that the object\nrepresentations in LLMs, while not identical to human ones, share fundamental\nsimilarities that reflect key aspects of human conceptual knowledge. Our\nfindings advance the understanding of machine intelligence and inform the\ndevelopment of more human-like artificial cognitive systems.", "AI": {"tldr": "The study explores whether LLMs and MLLMs develop human-like object representations. Using behavioral and neuroimaging analyses, it finds that model embeddings align with human cognition and neural activity.", "motivation": "To investigate if LLMs and MLLMs can form human-like object representations from linguistic and multimodal data.", "method": "Combined behavioral and neuroimaging analyses, collecting 4.7 million triplet judgments to derive 66-dimensional embeddings for 1,854 objects.", "result": "Model embeddings were stable, predictive, and aligned with human mental representations and neural activity in key brain regions.", "conclusion": "LLMs and MLLMs develop human-like conceptual representations, advancing machine intelligence and human-like AI development."}}
{"id": "2506.09016", "pdf": "https://arxiv.org/pdf/2506.09016", "abs": "https://arxiv.org/abs/2506.09016", "authors": ["Ruiqi Zhang", "Daman Arora", "Song Mei", "Andrea Zanette"], "title": "SPEED-RL: Faster Training of Reasoning Models via Online Curriculum Learning", "categories": ["cs.LG"], "comment": "pre-print", "summary": "Training large language models with reinforcement learning (RL) against\nverifiable rewards significantly enhances their reasoning abilities, yet\nremains computationally expensive due to inefficient uniform prompt sampling.\nWe introduce Selective Prompting with Efficient Estimation of Difficulty\n(SPEED), an adaptive online RL curriculum that selectively chooses training\nexamples of intermediate difficulty to maximize learning efficiency.\nTheoretically, we establish that intermediate-difficulty prompts improve the\ngradient estimator's signal-to-noise ratio, accelerating convergence.\nEmpirically, our efficient implementation leads to 2x to 6x faster training\nwithout degrading accuracy, requires no manual tuning, and integrates\nseamlessly into standard RL algorithms.", "AI": {"tldr": "SPEED is an adaptive RL curriculum that selects intermediate-difficulty prompts to enhance training efficiency, achieving 2x-6x faster training without accuracy loss.", "motivation": "Uniform prompt sampling in RL for large language models is computationally expensive and inefficient.", "method": "SPEED selectively chooses intermediate-difficulty prompts to optimize learning efficiency, improving gradient estimator signal-to-noise ratio.", "result": "Empirical results show 2x-6x faster training with no accuracy degradation, requiring no manual tuning.", "conclusion": "SPEED efficiently accelerates RL training for language models while maintaining performance, seamlessly integrating into standard RL algorithms."}}
{"id": "2412.13949", "pdf": "https://arxiv.org/pdf/2412.13949", "abs": "https://arxiv.org/abs/2412.13949", "authors": ["Jinghan He", "Kuan Zhu", "Haiyun Guo", "Junfeng Fang", "Zhenglin Hua", "Yuheng Jia", "Ming Tang", "Tat-Seng Chua", "Jinqiao Wang"], "title": "Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence", "categories": ["cs.CL", "cs.CV"], "comment": "ACL2025", "summary": "Large vision-language models (LVLMs) have made substantial progress in\nintegrating large language models (LLMs) with visual inputs, enabling advanced\nmultimodal reasoning. Despite their success, a persistent challenge is\nhallucination-where generated text fails to accurately reflect visual\ncontent-undermining both accuracy and reliability. Existing methods focus on\nalignment training or decoding refinements but primarily address symptoms at\nthe generation stage without probing the underlying causes. In this work, we\ninvestigate the internal mechanisms driving hallucination in LVLMs, with an\nemphasis on the multi-head attention module. Specifically, we introduce\nVision-aware Head Divergence (VHD), a metric that quantifies the sensitivity of\nattention head outputs to visual context. Based on this, our findings reveal\nthe presence of vision-aware attention heads that are more attuned to visual\ninformation; however, the model's overreliance on its prior language patterns\nis closely related to hallucinations. Building on these insights, we propose\nVision-aware Head Reinforcement (VHR), a training-free approach to mitigate\nhallucination by enhancing the role of vision-aware attention heads. Extensive\nexperiments demonstrate that our method achieves superior performance compared\nto state-of-the-art approaches in mitigating hallucinations, while maintaining\nhigh efficiency with negligible additional time overhead.", "AI": {"tldr": "The paper investigates hallucinations in large vision-language models (LVLMs), attributing them to overreliance on language patterns. It introduces Vision-aware Head Divergence (VHD) to measure attention head sensitivity to visuals and proposes Vision-aware Head Reinforcement (VHR) to mitigate hallucinations without training.", "motivation": "Hallucinations in LVLMs undermine accuracy and reliability. Existing methods address symptoms but not root causes, prompting a deeper investigation into internal mechanisms.", "method": "The study introduces VHD to quantify attention head sensitivity to visuals and proposes VHR, a training-free method to enhance vision-aware attention heads.", "result": "VHR outperforms state-of-the-art methods in reducing hallucinations while maintaining efficiency with minimal time overhead.", "conclusion": "The work identifies vision-aware attention heads as key to mitigating hallucinations and offers a practical solution (VHR) to improve LVLM reliability."}}
{"id": "2506.08350", "pdf": "https://arxiv.org/pdf/2506.08350", "abs": "https://arxiv.org/abs/2506.08350", "authors": ["Yicheng Zhan", "Dong-Ha Shin", "Seung-Hwan Baek", "Kaan Ak\u015fit"], "title": "Complex-Valued Holographic Radiance Fields", "categories": ["cs.GR", "cs.CV", "cs.ET"], "comment": "28 pages, 21 figures", "summary": "Modeling the full properties of light, including both amplitude and phase, in\n3D representations is crucial for advancing physically plausible rendering,\nparticularly in holographic displays. To support these features, we propose a\nnovel representation that optimizes 3D scenes without relying on\nintensity-based intermediaries. We reformulate 3D Gaussian splatting with\ncomplex-valued Gaussian primitives, expanding support for rendering with light\nwaves. By leveraging RGBD multi-view images, our method directly optimizes\ncomplex-valued Gaussians as a 3D holographic scene representation. This\neliminates the need for computationally expensive hologram re-optimization.\nCompared with state-of-the-art methods, our method achieves 30x-10,000x speed\nimprovements while maintaining on-par image quality, representing a first step\ntowards geometrically aligned, physically plausible holographic scene\nrepresentations.", "AI": {"tldr": "A novel complex-valued Gaussian representation for 3D holographic scenes improves speed by 30x-10,000x over state-of-the-art methods while maintaining image quality.", "motivation": "Advancing physically plausible rendering, especially for holographic displays, requires modeling full light properties (amplitude and phase) in 3D.", "method": "Reformulates 3D Gaussian splatting with complex-valued Gaussian primitives, optimized using RGBD multi-view images.", "result": "Achieves 30x-10,000x speed improvements without sacrificing image quality.", "conclusion": "The method is a significant step towards geometrically aligned, physically plausible holographic scene representations."}}
{"id": "2408.12212", "pdf": "https://arxiv.org/pdf/2408.12212", "abs": "https://arxiv.org/abs/2408.12212", "authors": ["C\u00e9line Hocquette", "Andrew Cropper"], "title": "Relational decomposition for program synthesis", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "We introduce a relational approach to program synthesis. The key idea is to\ndecompose synthesis tasks into simpler relational synthesis subtasks.\nSpecifically, our representation decomposes a training input-output example\ninto sets of input and output facts respectively. We then learn relations\nbetween the input and output facts. We demonstrate our approach using an\noff-the-shelf inductive logic programming (ILP) system on four challenging\nsynthesis datasets. Our results show that (i) our representation can outperform\na standard one, and (ii) an off-the-shelf ILP system with our representation\ncan outperform domain-specific approaches.", "AI": {"tldr": "A relational approach to program synthesis decomposes tasks into simpler subtasks, using input-output facts and learning relations between them, outperforming standard methods.", "motivation": "To simplify program synthesis by breaking down tasks into relational subtasks for better performance.", "method": "Decompose input-output examples into facts, learn relations between them, and use an inductive logic programming (ILP) system.", "result": "Outperforms standard representations and domain-specific approaches on four datasets.", "conclusion": "The relational approach with ILP is effective for program synthesis, surpassing traditional methods."}}
{"id": "2506.09044", "pdf": "https://arxiv.org/pdf/2506.09044", "abs": "https://arxiv.org/abs/2506.09044", "authors": ["Javier Sanguino", "Thomas Kehrenberg", "Jose A. Lozano", "Novi Quadrianto"], "title": "The Decoupled Risk Landscape in Performative Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Performative Prediction addresses scenarios where deploying a model induces a\ndistribution shift in the input data, such as individuals modifying their\nfeatures and reapplying for a bank loan after rejection. Literature has had a\ntheoretical perspective giving mathematical guarantees for convergence (either\nto the stable or optimal point). We believe that visualization of the loss\nlandscape can complement this theoretical advances with practical insights.\nTherefore, (1) we introduce a simple decoupled risk visualization method\ninspired in the two-step process that performative prediction is. Our approach\nvisualizes the risk landscape with respect to two parameter vectors: model\nparameters and data parameters. We use this method to propose new properties of\nthe interest points, to examine how existing algorithms traverse the risk\nlandscape and perform under more realistic conditions, including strategic\nclassification with non-linear models. (2) Building on this decoupled risk\nvisualization, we introduce a novel setting - extended Performative Prediction\n- which captures scenarios where the distribution reacts to a model different\nfrom the decision-making one, reflecting the reality that agents often lack\nfull access to the deployed model.", "AI": {"tldr": "The paper introduces a visualization method for the loss landscape in Performative Prediction, complementing theoretical work, and extends the framework to scenarios where agents react to a different model than the deployed one.", "motivation": "To provide practical insights into Performative Prediction by visualizing the loss landscape, addressing gaps in theoretical literature.", "method": "A decoupled risk visualization method is introduced, analyzing risk landscapes for model and data parameters. This is extended to scenarios where agents react to a different model.", "result": "New properties of interest points are proposed, and existing algorithms are examined under realistic conditions, including non-linear strategic classification.", "conclusion": "The visualization method and extended framework enhance understanding of Performative Prediction, offering practical tools for analyzing distribution shifts."}}
{"id": "2502.02444", "pdf": "https://arxiv.org/pdf/2502.02444", "abs": "https://arxiv.org/abs/2502.02444", "authors": ["Haoran Ye", "Tianze Zhang", "Yuhang Xie", "Liyuan Zhang", "Yuanyi Ren", "Xin Zhang", "Guojie Song"], "title": "Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ACL 2024 Main", "summary": "Values are core drivers of individual and collective perception, cognition,\nand behavior. Value systems, such as Schwartz's Theory of Basic Human Values,\ndelineate the hierarchy and interplay among these values, enabling\ncross-disciplinary investigations into decision-making and societal dynamics.\nRecently, the rise of Large Language Models (LLMs) has raised concerns\nregarding their elusive intrinsic values. Despite growing efforts in\nevaluating, understanding, and aligning LLM values, a psychologically grounded\nLLM value system remains underexplored. This study addresses the gap by\nintroducing the Generative Psycho-Lexical Approach (GPLA), a scalable,\nadaptable, and theoretically informed method for constructing value systems.\nLeveraging GPLA, we propose a psychologically grounded five-factor value system\ntailored for LLMs. For systematic validation, we present three benchmarking\ntasks that integrate psychological principles with cutting-edge AI priorities.\nOur results reveal that the proposed value system meets standard psychological\ncriteria, better captures LLM values, improves LLM safety prediction, and\nenhances LLM alignment, when compared to the canonical Schwartz's values.", "AI": {"tldr": "The study introduces GPLA, a method to create a psychologically grounded value system for LLMs, outperforming Schwartz's values in capturing LLM values and improving alignment.", "motivation": "Addressing the lack of a psychologically grounded value system for LLMs, despite their growing influence and concerns about their intrinsic values.", "method": "Developed the Generative Psycho-Lexical Approach (GPLA) to construct a five-factor value system for LLMs, validated through benchmarking tasks combining psychology and AI.", "result": "The proposed value system meets psychological criteria, better captures LLM values, improves safety prediction, and enhances alignment compared to Schwartz's values.", "conclusion": "GPLA offers a scalable and adaptable solution for understanding and aligning LLM values, bridging psychology and AI priorities."}}
{"id": "2506.08443", "pdf": "https://arxiv.org/pdf/2506.08443", "abs": "https://arxiv.org/abs/2506.08443", "authors": ["Kazuki Kawamura", "Jun Rekimoto"], "title": "SakugaFlow: A Stagewise Illustration Framework Emulating the Human Drawing Process and Providing Interactive Tutoring for Novice Drawing Skills", "categories": ["cs.HC", "cs.CV", "68T05", "H.5.2; K.3; I.2.7"], "comment": "5 pages, 1 figure; accepted as a paper to the Generative AI and HCI\n  (GenAICHI) workshop at CHI 2025 (Yokohama, 27 Apr 2025)", "summary": "While current AI illustration tools can generate high-quality images from\ntext prompts, they rarely reveal the step-by-step procedure that human artists\nfollow. We present SakugaFlow, a four-stage pipeline that pairs diffusion-based\nimage generation with a large-language-model tutor. At each stage, novices\nreceive real-time feedback on anatomy, perspective, and composition, revise any\nstep non-linearly, and branch alternative versions. By exposing intermediate\noutputs and embedding pedagogical dialogue, SakugaFlow turns a black-box\ngenerator into a scaffolded learning environment that supports both creative\nexploration and skills acquisition.", "AI": {"tldr": "SakugaFlow is a four-stage pipeline combining diffusion-based image generation and a large-language-model tutor to provide real-time feedback for novice artists, enhancing learning and creativity.", "motivation": "Current AI illustration tools lack transparency in the creative process, unlike human artists who follow step-by-step procedures. SakugaFlow aims to bridge this gap by providing a scaffolded learning environment.", "method": "The method involves a four-stage pipeline integrating diffusion-based image generation with a large-language-model tutor, offering real-time feedback on anatomy, perspective, and composition. Users can revise steps non-linearly and explore alternatives.", "result": "SakugaFlow transforms a black-box generator into an interactive learning tool, exposing intermediate outputs and embedding pedagogical dialogue to support creative exploration and skill development.", "conclusion": "SakugaFlow successfully combines AI-generated art with educational scaffolding, making the creative process transparent and accessible for novices while fostering both creativity and technical skills."}}
{"id": "2411.09160", "pdf": "https://arxiv.org/pdf/2411.09160", "abs": "https://arxiv.org/abs/2411.09160", "authors": ["Qin Yang"], "title": "Innate-Values-driven Reinforcement Learning based Cognitive Modeling", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": "The paper had been accepted by the 2025 IEEE Conference on Cognitive\n  and Computational Aspects of Situation Management (CogSIMA). arXiv admin\n  note: text overlap with arXiv:2401.05572", "summary": "Innate values describe agents' intrinsic motivations, which reflect their\ninherent interests and preferences for pursuing goals and drive them to develop\ndiverse skills that satisfy their various needs. Traditional reinforcement\nlearning (RL) is learning from interaction based on the feedback rewards of the\nenvironment. However, in real scenarios, the rewards are generated by agents'\ninnate value systems, which differ vastly from individuals based on their needs\nand requirements. In other words, considering the AI agent as a self-organizing\nsystem, developing its awareness through balancing internal and external\nutilities based on its needs in different tasks is a crucial problem for\nindividuals learning to support others and integrate community with safety and\nharmony in the long term. To address this gap, we propose a new RL model termed\ninnate-values-driven RL (IVRL) based on combined motivations' models and\nexpected utility theory to mimic its complex behaviors in the evolution through\ndecision-making and learning. Then, we introduce two IVRL-based models: IV-DQN\nand IV-A2C. By comparing them with benchmark algorithms such as DQN, DDQN, A2C,\nand PPO in the Role-Playing Game (RPG) reinforcement learning test platform\nVIZDoom, we demonstrated that the IVRL-based models can help the agent\nrationally organize various needs, achieve better performance effectively.", "AI": {"tldr": "The paper introduces Innate-Values-Driven RL (IVRL), a model combining motivations and utility theory to mimic agent behaviors, outperforming benchmarks in RPG tasks.", "motivation": "Traditional RL relies on environmental rewards, but real-world agents act based on innate values. Addressing this gap, IVRL aims to balance internal and external utilities for better learning.", "method": "Proposes IVRL, with two variants (IV-DQN and IV-A2C), tested against DQN, DDQN, A2C, and PPO in the VIZDoom RPG platform.", "result": "IVRL-based models outperform benchmarks, enabling agents to organize needs rationally and achieve better performance.", "conclusion": "IVRL effectively addresses the gap in traditional RL by incorporating innate values, enhancing agent learning and performance."}}
{"id": "2506.09048", "pdf": "https://arxiv.org/pdf/2506.09048", "abs": "https://arxiv.org/abs/2506.09048", "authors": ["Yuxin Dong", "Jiachen Jiang", "Zhihui Zhu", "Xia Ning"], "title": "Understanding Task Vectors in In-Context Learning: Emergence, Functionality, and Limitations", "categories": ["cs.LG"], "comment": null, "summary": "Task vectors offer a compelling mechanism for accelerating inference in\nin-context learning (ICL) by distilling task-specific information into a\nsingle, reusable representation. Despite their empirical success, the\nunderlying principles governing their emergence and functionality remain\nunclear. This work proposes the Linear Combination Conjecture, positing that\ntask vectors act as single in-context demonstrations formed through linear\ncombinations of the original ones. We provide both theoretical and empirical\nsupport for this conjecture. First, we show that task vectors naturally emerge\nin linear transformers trained on triplet-formatted prompts through loss\nlandscape analysis. Next, we predict the failure of task vectors on\nrepresenting high-rank mappings and confirm this on practical LLMs. Our\nfindings are further validated through saliency analyses and parameter\nvisualization, suggesting an enhancement of task vectors by injecting multiple\nones into few-shot prompts. Together, our results advance the understanding of\ntask vectors and shed light on the mechanisms underlying ICL in\ntransformer-based models.", "AI": {"tldr": "Task vectors distill task-specific info for ICL, but their principles are unclear. The Linear Combination Conjecture suggests they're linear combos of original demonstrations, supported by theory and experiments.", "motivation": "To clarify the principles behind task vectors in ICL and their functionality.", "method": "Proposes the Linear Combination Conjecture, analyzes loss landscapes in linear transformers, and tests task vectors on high-rank mappings.", "result": "Task vectors emerge naturally in linear transformers but fail for high-rank mappings. Enhancing them with multiple vectors improves performance.", "conclusion": "The study advances understanding of task vectors and ICL mechanisms in transformers."}}
{"id": "2502.02958", "pdf": "https://arxiv.org/pdf/2502.02958", "abs": "https://arxiv.org/abs/2502.02958", "authors": ["Paul Youssef", "Zhixue Zhao", "Daniel Braun", "J\u00f6rg Schl\u00f6tterer", "Christin Seifert"], "title": "Position: Editing Large Language Models Poses Serious Safety Risks", "categories": ["cs.CL"], "comment": "Accepted at ICML 2025", "summary": "Large Language Models (LLMs) contain large amounts of facts about the world.\nThese facts can become outdated over time, which has led to the development of\nknowledge editing methods (KEs) that can change specific facts in LLMs with\nlimited side effects. This position paper argues that editing LLMs poses\nserious safety risks that have been largely overlooked. First, we note the fact\nthat KEs are widely available, computationally inexpensive, highly performant,\nand stealthy makes them an attractive tool for malicious actors. Second, we\ndiscuss malicious use cases of KEs, showing how KEs can be easily adapted for a\nvariety of malicious purposes. Third, we highlight vulnerabilities in the AI\necosystem that allow unrestricted uploading and downloading of updated models\nwithout verification. Fourth, we argue that a lack of social and institutional\nawareness exacerbates this risk, and discuss the implications for different\nstakeholders. We call on the community to (i) research tamper-resistant models\nand countermeasures against malicious model editing, and (ii) actively engage\nin securing the AI ecosystem.", "AI": {"tldr": "The paper highlights safety risks of knowledge editing in LLMs, warning of malicious uses and calling for tamper-resistant models and ecosystem security.", "motivation": "To address overlooked safety risks posed by knowledge editing methods in LLMs, which are attractive to malicious actors due to their accessibility and stealth.", "method": "Analyzes vulnerabilities in the AI ecosystem, discusses malicious use cases of KEs, and identifies gaps in social and institutional awareness.", "result": "Identifies serious risks from unrestricted model editing and lack of safeguards, urging action to mitigate these threats.", "conclusion": "Calls for research into tamper-resistant models and proactive measures to secure the AI ecosystem against malicious editing."}}
{"id": "2502.07202", "pdf": "https://arxiv.org/pdf/2502.07202", "abs": "https://arxiv.org/abs/2502.07202", "authors": ["Jaesik Yoon", "Hyeonseo Cho", "Doojin Baek", "Yoshua Bengio", "Sungjin Ahn"], "title": "Monte Carlo Tree Diffusion for System 2 Planning", "categories": ["cs.AI", "cs.LG"], "comment": "20 pages, 7 figures", "summary": "Diffusion models have recently emerged as a powerful tool for planning.\nHowever, unlike Monte Carlo Tree Search (MCTS)-whose performance naturally\nimproves with inference-time computation scaling-standard diffusion-based\nplanners offer only limited avenues for the scalability. In this paper, we\nintroduce Monte Carlo Tree Diffusion (MCTD), a novel framework that integrates\nthe generative strength of diffusion models with the adaptive search\ncapabilities of MCTS. Our method reconceptualizes denoising as a\ntree-structured process, allowing partially denoised plans to be iteratively\nevaluated, pruned, and refined. By selectively expanding promising trajectories\nwhile retaining the flexibility to revisit and improve suboptimal branches,\nMCTD achieves the benefits of MCTS such as controlling exploration-exploitation\ntrade-offs within the diffusion framework. Empirical results on challenging\nlong-horizon tasks show that MCTD outperforms diffusion baselines, yielding\nhigher-quality solutions as inference-time computation increases.", "AI": {"tldr": "MCTD combines diffusion models with MCTS for scalable planning, outperforming diffusion baselines in long-horizon tasks.", "motivation": "Diffusion models lack scalability in planning compared to MCTS, which improves with computation. MCTD aims to merge their strengths.", "method": "MCTD integrates diffusion models with MCTS by treating denoising as a tree-structured process, enabling iterative evaluation and refinement.", "result": "MCTD outperforms diffusion baselines, improving solution quality with increased inference-time computation.", "conclusion": "MCTD successfully combines diffusion models and MCTS, offering scalable and high-quality planning solutions."}}
{"id": "2506.08030", "pdf": "https://arxiv.org/pdf/2506.08030", "abs": "https://arxiv.org/abs/2506.08030", "authors": ["Brian Liu", "Rahul Mazumder"], "title": "MOSS: Multi-Objective Optimization for Stable Rule Sets", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We present MOSS, a multi-objective optimization framework for constructing\nstable sets of decision rules. MOSS incorporates three important criteria for\ninterpretability: sparsity, accuracy, and stability, into a single\nmulti-objective optimization framework. Importantly, MOSS allows a practitioner\nto rapidly evaluate the trade-off between accuracy and stability in sparse rule\nsets in order to select an appropriate model. We develop a specialized cutting\nplane algorithm in our framework to rapidly compute the Pareto frontier between\nthese two objectives, and our algorithm scales to problem instances beyond the\ncapabilities of commercial optimization solvers. Our experiments show that MOSS\noutperforms state-of-the-art rule ensembles in terms of both predictive\nperformance and stability.", "AI": {"tldr": "MOSS is a multi-objective optimization framework for stable decision rule sets, balancing sparsity, accuracy, and stability. It outperforms state-of-the-art rule ensembles in performance and stability.", "motivation": "To address the trade-off between accuracy and stability in sparse rule sets, enabling practitioners to select optimal models.", "method": "Uses a specialized cutting plane algorithm to compute the Pareto frontier efficiently, scaling beyond commercial solvers.", "result": "MOSS outperforms existing rule ensembles in predictive performance and stability.", "conclusion": "MOSS provides a practical and scalable solution for multi-objective optimization in decision rule construction."}}
{"id": "2502.03699", "pdf": "https://arxiv.org/pdf/2502.03699", "abs": "https://arxiv.org/abs/2502.03699", "authors": ["Bowen Jin", "Jinsung Yoon", "Zhen Qin", "Ziqi Wang", "Wei Xiong", "Yu Meng", "Jiawei Han", "Sercan O. Arik"], "title": "LLM Alignment as Retriever Optimization: An Information Retrieval Perspective", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "26 pages", "summary": "Large Language Models (LLMs) have revolutionized artificial intelligence with\ncapabilities in reasoning, coding, and communication, driving innovation across\nindustries. Their true potential depends on effective alignment to ensure\ncorrect, trustworthy and ethical behavior, addressing challenges like\nmisinformation, hallucinations, bias and misuse. While existing Reinforcement\nLearning (RL)-based alignment methods are notoriously complex, direct\noptimization approaches offer a simpler alternative. In this work, we introduce\na novel direct optimization approach for LLM alignment by drawing on\nestablished Information Retrieval (IR) principles. We present a systematic\nframework that bridges LLM alignment and IR methodologies, mapping LLM\ngeneration and reward models to IR's retriever-reranker paradigm. Building on\nthis foundation, we propose LLM Alignment as Retriever Preference Optimization\n(LarPO), a new alignment method that enhances overall alignment quality.\nExtensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 %\naveraged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work\nopens new avenues for advancing LLM alignment by integrating IR foundations,\noffering a promising direction for future research.", "AI": {"tldr": "A novel direct optimization method, LarPO, is introduced for aligning Large Language Models (LLMs) using Information Retrieval (IR) principles, improving alignment quality significantly.", "motivation": "LLMs need effective alignment to ensure correct, trustworthy, and ethical behavior, addressing challenges like misinformation and bias. Existing RL-based methods are complex, prompting the search for simpler alternatives.", "method": "The paper proposes LarPO, a direct optimization approach for LLM alignment, mapping LLM generation and reward models to IR's retriever-reranker paradigm.", "result": "LarPO achieves 38.9% and 13.7% averaged improvement on AlpacaEval2 and MixEval-Hard benchmarks, respectively.", "conclusion": "The work bridges LLM alignment and IR methodologies, offering a promising direction for future research in LLM alignment."}}
{"id": "2506.08708", "pdf": "https://arxiv.org/pdf/2506.08708", "abs": "https://arxiv.org/abs/2506.08708", "authors": ["Liang Ma", "Jiajun Wen", "Min Lin", "Rongtao Xu", "Xiwen Liang", "Bingqian Lin", "Jun Ma", "Yongxin Wang", "Ziming Wei", "Haokun Lin", "Mingfei Han", "Meng Cao", "Bokui Chen", "Ivan Laptev", "Xiaodan Liang"], "title": "PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "While vision-language models (VLMs) have demonstrated promising capabilities\nin reasoning and planning for embodied agents, their ability to comprehend\nphysical phenomena, particularly within structured 3D environments, remains\nseverely limited. To close this gap, we introduce PhyBlock, a progressive\nbenchmark designed to assess VLMs on physical understanding and planning\nthrough robotic 3D block assembly tasks. PhyBlock integrates a novel four-level\ncognitive hierarchy assembly task alongside targeted Visual Question Answering\n(VQA) samples, collectively aimed at evaluating progressive spatial reasoning\nand fundamental physical comprehension, including object properties, spatial\nrelationships, and holistic scene understanding. PhyBlock includes 2600 block\ntasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three\nkey dimensions: partial completion, failure diagnosis, and planning robustness.\nWe benchmark 21 state-of-the-art VLMs, highlighting their strengths and\nlimitations in physically grounded, multi-step planning. Our empirical findings\nindicate that the performance of VLMs exhibits pronounced limitations in\nhigh-level planning and reasoning capabilities, leading to a notable decline in\nperformance for the growing complexity of the tasks. Error analysis reveals\npersistent difficulties in spatial orientation and dependency reasoning.\nSurprisingly, chain-of-thought prompting offers minimal improvements,\nsuggesting spatial tasks heavily rely on intuitive model comprehension. We\nposition PhyBlock as a unified testbed to advance embodied reasoning, bridging\nvision-language understanding and real-world physical problem-solving.", "AI": {"tldr": "PhyBlock is a benchmark to evaluate VLMs on physical understanding and planning in 3D block assembly tasks, revealing their limitations in high-level reasoning and spatial comprehension.", "motivation": "Current VLMs lack robust comprehension of physical phenomena in structured 3D environments, necessitating a benchmark to assess and improve their capabilities.", "method": "PhyBlock integrates a four-level cognitive hierarchy assembly task and VQA samples to evaluate spatial reasoning and physical comprehension, testing 21 VLMs across 2600 tasks.", "result": "VLMs show significant limitations in high-level planning and spatial reasoning, with minimal improvement from chain-of-thought prompting.", "conclusion": "PhyBlock serves as a testbed to bridge vision-language understanding and real-world physical problem-solving, highlighting areas for VLM improvement."}}
{"id": "2502.07957", "pdf": "https://arxiv.org/pdf/2502.07957", "abs": "https://arxiv.org/abs/2502.07957", "authors": ["Kshitish Ghate", "Isaac Slaughter", "Kyra Wilson", "Mona Diab", "Aylin Caliskan"], "title": "Intrinsic Bias is Predicted by Pretraining Data and Correlates with Downstream Performance in Vision-Language Encoders", "categories": ["cs.AI"], "comment": "Accepted to NAACL Main, 2025", "summary": "While recent work has found that vision-language models trained under the\nContrastive Language Image Pre-training (CLIP) framework contain intrinsic\nsocial biases, the extent to which different upstream pre-training features of\nthe framework relate to these biases, and hence how intrinsic bias and\ndownstream performance are connected has been unclear. In this work, we present\nthe largest comprehensive analysis to-date of how the upstream pre-training\nfactors and downstream performance of CLIP models relate to their intrinsic\nbiases. Studying 131 unique CLIP models, trained on 26 datasets, using 55\narchitectures, and in a variety of sizes, we evaluate bias in each model using\n26 well-established unimodal and cross-modal principled Embedding Association\nTests. We find that the choice of pre-training dataset is the most significant\nupstream predictor of bias, whereas architectural variations have minimal\nimpact. Additionally, datasets curated using sophisticated filtering techniques\naimed at enhancing downstream model performance tend to be associated with\nhigher levels of intrinsic bias. Finally, we observe that intrinsic bias is\noften significantly correlated with downstream performance ($0.3 \\leq r \\leq\n0.8$), suggesting that models optimized for performance inadvertently learn to\namplify representational biases. Comparisons between unimodal and cross-modal\nassociation tests reveal that social group bias depends heavily on the\nmodality. Our findings imply that more sophisticated strategies are needed to\naddress intrinsic model bias for vision-language models across the entire model\ndevelopment pipeline.", "AI": {"tldr": "CLIP models' intrinsic biases are analyzed, revealing pre-training datasets as the main predictor of bias, with performance-bias correlations and modality-dependent biases.", "motivation": "To understand how upstream pre-training factors in CLIP models relate to intrinsic biases and downstream performance.", "method": "Analysis of 131 CLIP models using 26 datasets, 55 architectures, and 26 Embedding Association Tests to evaluate bias.", "result": "Pre-training dataset choice is the primary bias predictor; performance and bias are correlated; bias varies by modality.", "conclusion": "Sophisticated strategies are needed to mitigate intrinsic bias in vision-language models throughout development."}}
{"id": "2506.08033", "pdf": "https://arxiv.org/pdf/2506.08033", "abs": "https://arxiv.org/abs/2506.08033", "authors": ["Axel TahmasebiMoradi", "Vincent Ren", "Benjamin Le-Creurer", "Chetra Mang"], "title": "Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Aiming to reduce the computational cost of numerical simulations, a\nconvolutional neural network (CNN) and a multi-layer perceptron (MLP) are\nintroduced to build a surrogate model to approximate radiative heat transfer\nsolutions in a 2-D walled domain with participative gases. The originality of\nthis work lays in the adaptation of the inputs of the problem (gas and wall\nproperties) in order to fit with the CNN architecture, more commonly used for\nimage processing. Two precision datasets have been created with the classical\nsolver, ICARUS2D, that uses the discrete transfer radiation method with the\nstatistical narrow bands model. The performance of the CNN architecture is\ncompared to a more classical MLP architecture in terms of speed and accuracy.\nThanks to Optuna, all results are obtained using the optimized hyper parameters\nnetworks. The results show a significant speedup with industrially acceptable\nrelative errors compared to the classical solver for both architectures.\nAdditionally, the CNN outperforms the MLP in terms of precision and is more\nrobust and stable to changes in hyper-parameters. A performance analysis on the\ndataset size of the samples have also been carried out to gain a deeper\nunderstanding of the model behavior.", "AI": {"tldr": "A CNN and MLP surrogate model reduces computational cost for radiative heat transfer simulations, with CNN outperforming MLP in precision and robustness.", "motivation": "To reduce computational costs in numerical simulations of radiative heat transfer using surrogate models.", "method": "Adapted CNN and MLP architectures, trained on datasets from ICARUS2D solver, with hyper-parameters optimized via Optuna.", "result": "Significant speedup with acceptable errors; CNN is more precise and robust than MLP.", "conclusion": "CNN is a superior surrogate model for radiative heat transfer, offering efficiency and stability."}}
{"id": "2502.04390", "pdf": "https://arxiv.org/pdf/2502.04390", "abs": "https://arxiv.org/abs/2502.04390", "authors": ["Simone Clemente", "Zied Ben Houidi", "Alexis Huet", "Dario Rossi", "Giulio Franzese", "Pietro Michiardi"], "title": "In Praise of Stubbornness: An Empirical Case for Cognitive-Dissonance Aware Continual Update of Knowledge in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Through systematic empirical investigation, we uncover a fundamental and\nconcerning property of Large Language Models: while they can safely learn facts\nthat don't contradict their knowledge, attempting to update facts with\ncontradictory information triggers catastrophic corruption of unrelated\nknowledge. Unlike humans, who naturally resist contradictory information, these\nmodels indiscriminately accept contradictions, leading to devastating\ninterference, destroying up to 80% of unrelated knowledge even when learning as\nfew as 10-100 contradicting facts. To understand whether this interference\ncould be mitigated through selective plasticity, we experiment with targeted\nnetwork updates, distinguishing between previously used (stubborn) and rarely\nused (plastic) neurons. We uncover another asymmetry: while sparing\nfrequently-used neurons significantly improves retention of existing knowledge\nfor non-contradictory updates (98% vs 93% with standard updates), contradictory\nupdates trigger catastrophic interference regardless of targeting strategy.\nThis effect which persists across tested model scales (GPT-2 to GPT-J-6B),\nsuggests a fundamental limitation in how neural networks handle contradictions.\nFinally, we demonstrate that contradictory information can be reliably detected\n(95%+ accuracy) using simple model features, offering a potential protective\nmechanism. These findings motivate new architectures that can, like humans,\nnaturally resist contradictions rather than allowing destructive overwrites.", "AI": {"tldr": "Large Language Models (LLMs) suffer catastrophic knowledge corruption when updated with contradictory facts, unlike humans. Selective plasticity helps retain non-contradictory knowledge but fails for contradictions. Contradictions can be detected with high accuracy, suggesting a need for new architectures.", "motivation": "To investigate how LLMs handle contradictory updates and whether selective plasticity can mitigate catastrophic interference.", "method": "Empirical study using targeted network updates (stubborn vs. plastic neurons) and testing across model scales (GPT-2 to GPT-J-6B).", "result": "Contradictory updates corrupt up to 80% of unrelated knowledge; selective plasticity helps non-contradictory updates but fails for contradictions. Contradictions can be detected with 95%+ accuracy.", "conclusion": "LLMs fundamentally struggle with contradictions, highlighting the need for architectures that resist destructive overwrites like humans."}}
{"id": "2506.08761", "pdf": "https://arxiv.org/pdf/2506.08761", "abs": "https://arxiv.org/abs/2506.08761", "authors": ["Matthias Beckmann", "Robert Beinert", "Jonas Bresch"], "title": "Normalized Radon Cumulative Distribution Transforms for Invariance and Robustness in Optimal Transport Based Image Classification", "categories": ["math.NA", "cs.CV", "cs.IT", "cs.NA", "math.IT"], "comment": null, "summary": "The Radon cumulative distribution transform (R-CDT), is an easy-to-compute\nfeature extractor that facilitates image classification tasks especially in the\nsmall data regime. It is closely related to the sliced Wasserstein distance and\nprovably guaranties the linear separability of image classes that emerge from\ntranslations or scalings. In many real-world applications, like the recognition\nof watermarks in filigranology, however, the data is subject to general affine\ntransformations originating from the measurement process. To overcome this\nissue, we recently introduced the so-called max-normalized R-CDT that only\nrequires elementary operations and guaranties the separability under arbitrary\naffine transformations. The aim of this paper is to continue our study of the\nmax-normalized R-CDT especially with respect to its robustness against\nnon-affine image deformations. Our sensitivity analysis shows that its\nseparability properties are stable provided the Wasserstein-infinity distance\nbetween the samples can be controlled. Since the Wasserstein-infinity distance\nonly allows small local image deformations, we moreover introduce a\nmean-normalized version of the R-CDT. In this case, robustness relates to the\nWasserstein-2 distance and also covers image deformations caused by impulsive\nnoise for instance. Our theoretical results are supported by numerical\nexperiments showing the effectiveness of our novel feature extractors as well\nas their robustness against local non-affine deformations and impulsive noise.", "AI": {"tldr": "The paper introduces max-normalized and mean-normalized versions of the Radon cumulative distribution transform (R-CDT) to improve robustness against non-affine image deformations and impulsive noise, ensuring linear separability in classification tasks.", "motivation": "Existing R-CDT methods struggle with general affine transformations and non-affine deformations in real-world applications like watermark recognition, prompting the need for more robust variants.", "method": "The study introduces max-normalized and mean-normalized R-CDT variants, analyzing their separability properties under controlled Wasserstein-infinity and Wasserstein-2 distances, respectively.", "result": "The proposed variants demonstrate stable separability under local deformations and robustness against impulsive noise, supported by numerical experiments.", "conclusion": "The max-normalized and mean-normalized R-CDTs are effective for image classification, offering robustness against non-affine deformations and noise, with theoretical and experimental validation."}}
{"id": "2502.14760", "pdf": "https://arxiv.org/pdf/2502.14760", "abs": "https://arxiv.org/abs/2502.14760", "authors": ["Haotian Zhai", "Connor Lawless", "Ellen Vitercik", "Liu Leqi"], "title": "EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations", "categories": ["cs.AI", "cs.LG", "math.OC"], "comment": null, "summary": "A fundamental problem in combinatorial optimization is identifying equivalent\nformulations. Despite the growing need for automated equivalence checks --\ndriven, for example, by optimization copilots, which generate problem\nformulations from natural language descriptions -- current approaches rely on\nsimple heuristics that fail to reliably check formulation equivalence. Inspired\nby Karp reductions, in this work we introduce Quasi-Karp equivalence, a formal\ncriterion for determining when two optimization formulations are equivalent\nbased on the existence of a mapping between their decision variables. We\npropose EquivaMap, a framework that leverages large language models to\nautomatically discover such mappings for scalable, reliable equivalence\nchecking, with a verification stage that ensures mapped solutions preserve\nfeasibility and optimality without additional solver calls. To evaluate our\napproach, we construct EquivaFormulation, the first open-source dataset of\nequivalent optimization formulations, generated by applying transformations\nsuch as adding slack variables or valid inequalities to existing formulations.\nEmpirically, EquivaMap significantly outperforms existing methods, achieving\nsubstantial improvements in correctly identifying formulation equivalence.", "AI": {"tldr": "The paper introduces Quasi-Karp equivalence and EquivaMap, a framework using large language models for automated equivalence checking of optimization formulations, outperforming existing methods.", "motivation": "The need for reliable automated equivalence checks in combinatorial optimization, especially for applications like optimization copilots, which lack robust current solutions.", "method": "Proposes Quasi-Karp equivalence as a formal criterion and EquivaMap, leveraging large language models to discover variable mappings, with a verification stage ensuring feasibility and optimality.", "result": "EquivaMap outperforms existing methods, achieving significant improvements in identifying formulation equivalence, validated on the EquivaFormulation dataset.", "conclusion": "The work provides a scalable, reliable solution for equivalence checking in optimization, advancing automation in combinatorial optimization."}}
{"id": "2506.08065", "pdf": "https://arxiv.org/pdf/2506.08065", "abs": "https://arxiv.org/abs/2506.08065", "authors": ["Ye Zhu", "Duo Xu", "Zhiwei Deng", "Jonathon C. Tan", "Olga Russakovsky"], "title": "Dynamic Diffusion Schr\u00f6dinger Bridge in Astrophysical Observational Inversions", "categories": ["astro-ph.IM", "cs.LG"], "comment": "Preprint. Code will be available at\n  https://github.com/L-YeZhu/AstroDSB", "summary": "We study Diffusion Schr\\\"odinger Bridge (DSB) models in the context of\ndynamical astrophysical systems, specifically tackling observational inverse\nprediction tasks within Giant Molecular Clouds (GMCs) for star formation. We\nintroduce the Astro-DSB model, a variant of DSB with the pairwise domain\nassumption tailored for astrophysical dynamics. By investigating its learning\nprocess and prediction performance in both physically simulated data and in\nreal observations (the Taurus B213 data), we present two main takeaways. First,\nfrom the astrophysical perspective, our proposed paired DSB method improves\ninterpretability, learning efficiency, and prediction performance over\nconventional astrostatistical and other machine learning methods. Second, from\nthe generative modeling perspective, probabilistic generative modeling reveals\nimprovements over discriminative pixel-to-pixel modeling in Out-Of-Distribution\n(OOD) testing cases of physical simulations with unseen initial conditions and\ndifferent dominant physical processes. Our study expands research into\ndiffusion models beyond the traditional visual synthesis application and\nprovides evidence of the models' learning abilities beyond pure data\nstatistics, paving a path for future physics-aware generative models which can\nalign dynamics between machine learning and real (astro)physical systems.", "AI": {"tldr": "The paper introduces Astro-DSB, a variant of Diffusion Schr\u00f6dinger Bridge models, for astrophysical systems like GMCs. It improves interpretability, efficiency, and prediction over traditional methods, and shows better OOD performance in generative modeling.", "motivation": "To address observational inverse prediction tasks in astrophysical systems (e.g., star formation in GMCs) using a tailored DSB model, bridging machine learning and physical dynamics.", "method": "Developed Astro-DSB, a paired DSB variant, and tested it on simulated and real observational data (Taurus B213). Compared it with conventional astrostatistical and ML methods.", "result": "Astro-DSB outperforms traditional methods in interpretability, learning efficiency, and prediction. It also excels in OOD testing for generative modeling.", "conclusion": "The study extends diffusion models beyond visual synthesis, demonstrating their potential for physics-aware generative models that align with real astrophysical dynamics."}}
{"id": "2502.05202", "pdf": "https://arxiv.org/pdf/2502.05202", "abs": "https://arxiv.org/abs/2502.05202", "authors": ["Nadav Timor", "Jonathan Mamou", "Daniel Korat", "Moshe Berchansky", "Gaurav Jain", "Oren Pereg", "Moshe Wasserblat", "David Harel"], "title": "Accelerating LLM Inference with Lossless Speculative Decoding Algorithms for Heterogeneous Vocabularies", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML'25 Oral (top %1)", "summary": "Accelerating the inference of large language models (LLMs) is a critical\nchallenge in generative AI. Speculative decoding (SD) methods offer substantial\nefficiency gains by generating multiple tokens using a single target forward\npass. However, existing SD approaches require the drafter and target models to\nshare the same vocabulary, thus limiting the pool of possible drafters, often\nnecessitating the training of a drafter from scratch. We present three new SD\nmethods that remove this shared-vocabulary constraint. All three methods\npreserve the target distribution (i.e., they are lossless) and work with\noff-the-shelf models without requiring additional training or modifications.\nEmpirically, on summarization, programming, and long-context tasks, our\nalgorithms demonstrate significant speedups of up to 2.8x over standard\nautoregressive decoding. By enabling any off-the-shelf model to serve as a\ndrafter and requiring no retraining, this work substantially broadens the\napplicability of the SD framework in practice.", "AI": {"tldr": "New speculative decoding methods remove shared-vocabulary constraints, enabling any off-the-shelf model as a drafter, achieving up to 2.8x speedup without retraining.", "motivation": "Accelerating LLM inference is crucial for generative AI, but existing SD methods limit drafter selection due to shared-vocabulary requirements.", "method": "Three new SD methods are introduced, eliminating the need for shared vocabulary between drafter and target models, ensuring lossless decoding.", "result": "Empirical tests show speedups of up to 2.8x on tasks like summarization and programming, using off-the-shelf models.", "conclusion": "This work expands SD's practicality by allowing any model as a drafter, enhancing efficiency without additional training."}}
{"id": "2506.09023", "pdf": "https://arxiv.org/pdf/2506.09023", "abs": "https://arxiv.org/abs/2506.09023", "authors": ["Julia Guerrero-Viu", "Michael Fischer", "Iliyan Georgiev", "Elena Garces", "Diego Gutierrez", "Belen Masia", "Valentin Deschaintre"], "title": "Fine-Grained Spatially Varying Material Selection in Images", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Selection is the first step in many image editing processes, enabling faster\nand simpler modifications of all pixels sharing a common modality. In this\nwork, we present a method for material selection in images, robust to lighting\nand reflectance variations, which can be used for downstream editing tasks. We\nrely on vision transformer (ViT) models and leverage their features for\nselection, proposing a multi-resolution processing strategy that yields finer\nand more stable selection results than prior methods. Furthermore, we enable\nselection at two levels: texture and subtexture, leveraging a new two-level\nmaterial selection (DuMaS) dataset which includes dense annotations for over\n800,000 synthetic images, both on the texture and subtexture levels.", "AI": {"tldr": "A method for robust material selection in images using vision transformers (ViT) and multi-resolution processing, with a new dataset (DuMaS) for texture and subtexture-level annotations.", "motivation": "To enable faster and simpler image editing by improving material selection, addressing challenges like lighting and reflectance variations.", "method": "Uses ViT models with multi-resolution processing for finer, stable selections, and introduces the DuMaS dataset for texture and subtexture-level annotations.", "result": "Achieves finer and more stable selection results compared to prior methods.", "conclusion": "The proposed method and dataset enhance material selection for downstream editing tasks."}}
{"id": "2504.04430", "pdf": "https://arxiv.org/pdf/2504.04430", "abs": "https://arxiv.org/abs/2504.04430", "authors": ["Matej \u0160progar"], "title": "AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence", "categories": ["cs.AI", "I.2; D.2.8; I.2.6; I.5"], "comment": "15 pages", "summary": "Despite major advances in machine learning, current artificial intelligence\nsystems continue to fall short of human-like general intelligence. While large\nlanguage models can generate fluent and coherent outputs, they lack the deep\nunderstanding and adaptive reasoning that characterize truly general\nintelligence. Existing evaluation frameworks, which are centered on broad\nlanguage or perception tasks, fail to capture generality at its core and offer\nlittle guidance for incremental progress. To address this gap, this paper\nintroduces the artificial general intelligence testbed (AGITB), a novel and\nfreely available benchmarking suite comprising twelve fully automatable tests\ndesigned to evaluate low-level cognitive precursors through binary signal\nprediction. AGITB requires models to forecast temporal sequences without\npretraining, symbolic manipulation, or semantic grounding. The framework\nisolates core computational invariants - such as determinism, sensitivity, and\ngeneralization - that align with principles of biological information\nprocessing. Engineered to resist brute-force and memorization-based approaches,\nAGITB presumes no prior knowledge and demands learning from first principles.\nWhile humans pass all tests, no current AI system has met the full AGITB\ncriteria, underscoring its potential as a rigorous, interpretable, and\nactionable benchmark for guiding and evaluating progress toward artificial\ngeneral intelligence.", "AI": {"tldr": "The paper introduces AGITB, a benchmarking suite to evaluate low-level cognitive precursors for artificial general intelligence (AGI), highlighting current AI's shortcomings in general intelligence.", "motivation": "Current AI lacks human-like general intelligence, and existing evaluation frameworks fail to measure core generality. AGITB aims to address this gap.", "method": "AGITB includes twelve automatable tests focusing on binary signal prediction, isolating core computational invariants like determinism and generalization.", "result": "No current AI system meets AGITB's full criteria, while humans pass all tests, showcasing its rigor and potential.", "conclusion": "AGITB serves as a rigorous, interpretable benchmark for guiding progress toward AGI."}}
{"id": "2506.08121", "pdf": "https://arxiv.org/pdf/2506.08121", "abs": "https://arxiv.org/abs/2506.08121", "authors": ["Qi Feng", "Gu Wang"], "title": "Continuous Policy and Value Iteration for Stochastic Control Problems and Its Convergence", "categories": ["math.OC", "cs.LG", "93E20, 93E35, 60H10"], "comment": "37 pages", "summary": "We introduce a continuous policy-value iteration algorithm where the\napproximations of the value function of a stochastic control problem and the\noptimal control are simultaneously updated through Langevin-type dynamics. This\nframework applies to both the entropy-regularized relaxed control problems and\nthe classical control problems, with infinite horizon. We establish policy\nimprovement and demonstrate convergence to the optimal control under the\nmonotonicity condition of the Hamiltonian. By utilizing Langevin-type\nstochastic differential equations for continuous updates along the policy\niteration direction, our approach enables the use of distribution sampling and\nnon-convex learning techniques in machine learning to optimize the value\nfunction and identify the optimal control simultaneously.", "AI": {"tldr": "A continuous policy-value iteration algorithm using Langevin-type dynamics for stochastic control problems, applicable to entropy-regularized and classical control problems, with convergence guarantees.", "motivation": "To simultaneously update value function approximations and optimal control in stochastic control problems, leveraging machine learning techniques.", "method": "Langevin-type dynamics for continuous updates, combining policy iteration with distribution sampling and non-convex learning.", "result": "Policy improvement and convergence to optimal control under Hamiltonian monotonicity.", "conclusion": "The framework effectively integrates machine learning methods for optimizing value functions and identifying optimal controls."}}
{"id": "2502.12658", "pdf": "https://arxiv.org/pdf/2502.12658", "abs": "https://arxiv.org/abs/2502.12658", "authors": ["Wenlong Meng", "Zhenyuan Guo", "Lenan Wu", "Chen Gong", "Wenyan Liu", "Weixian Li", "Chengkun Wei", "Wenzhi Chen"], "title": "R.R.: Unveiling LLM Training Privacy through Recollection and Ranking", "categories": ["cs.CL"], "comment": "13 pages, 9 figures; typos corrected", "summary": "Large Language Models (LLMs) pose significant privacy risks, potentially\nleaking training data due to implicit memorization. Existing privacy attacks\nprimarily focus on membership inference attacks (MIAs) or data extraction\nattacks, but reconstructing specific personally identifiable information (PII)\nin LLMs' training data remains challenging. In this paper, we propose R.R.\n(Recollect and Rank), a novel two-step privacy stealing attack that enables\nattackers to reconstruct PII entities from scrubbed training data where the PII\nentities have been masked. In the first stage, we introduce a prompt paradigm\nnamed recollection, which instructs the LLM to repeat a masked text but fill in\nmasks. Then we can use PII identifiers to extract recollected PII candidates.\nIn the second stage, we design a new criterion to score each PII candidate and\nrank them. Motivated by membership inference, we leverage the reference model\nas a calibration to our criterion. Experiments across three popular PII\ndatasets demonstrate that the R.R. achieves better PII identification\nperformance than baselines. These results highlight the vulnerability of LLMs\nto PII leakage even when training data has been scrubbed. We release our code\nand datasets at GitHub.", "AI": {"tldr": "The paper introduces R.R., a two-step attack to reconstruct PII from scrubbed LLM training data, outperforming baselines in PII identification.", "motivation": "Addressing the challenge of reconstructing PII from scrubbed LLM training data, which existing attacks like MIAs struggle with.", "method": "Proposes R.R.: (1) recollection prompts to fill masked PII, (2) ranking candidates using a new criterion calibrated by a reference model.", "result": "R.R. outperforms baselines in PII identification across three datasets, showing LLMs' vulnerability to PII leakage.", "conclusion": "LLMs remain vulnerable to PII leakage even with scrubbed data, emphasizing the need for stronger privacy safeguards."}}
{"id": "2402.02088", "pdf": "https://arxiv.org/pdf/2402.02088", "abs": "https://arxiv.org/abs/2402.02088", "authors": ["Zhe Li", "Xiying Wang", "Jinglin Zhao", "Zheng Wang", "Debin Liu", "Laurence T. Yang"], "title": "Mitigating Prior Shape Bias in Point Clouds via Differentiable Center Learning", "categories": ["cs.CV"], "comment": null, "summary": "Masked autoencoding and generative pretraining have achieved remarkable\nsuccess in computer vision and natural language processing, and more recently,\nthey have been extended to the point cloud domain. Nevertheless, existing point\ncloud models suffer from the issue of information leakage due to the\npre-sampling of center points, which leads to trivial proxy tasks for the\nmodels. These approaches primarily focus on local feature reconstruction,\nlimiting their ability to capture global patterns within point clouds. In this\npaper, we argue that the reduced difficulty of pretext tasks hampers the\nmodel's capacity to learn expressive representations. To address these\nlimitations, we introduce a novel solution called the Differentiable Center\nSampling Network (DCS-Net). It tackles the information leakage problem by\nincorporating both global feature reconstruction and local feature\nreconstruction as non-trivial proxy tasks, enabling simultaneous learning of\nboth the global and local patterns within point cloud. Experimental results\ndemonstrate that our method enhances the expressive capacity of existing point\ncloud models and effectively addresses the issue of information leakage.", "AI": {"tldr": "The paper introduces DCS-Net to address information leakage in point cloud models by combining global and local feature reconstruction.", "motivation": "Existing point cloud models suffer from information leakage and trivial proxy tasks, limiting their ability to learn expressive representations.", "method": "Proposes DCS-Net, which integrates global and local feature reconstruction as non-trivial proxy tasks.", "result": "DCS-Net improves expressive capacity and mitigates information leakage in point cloud models.", "conclusion": "The method successfully enhances model performance by addressing key limitations in existing approaches."}}
{"id": "2504.18777", "pdf": "https://arxiv.org/pdf/2504.18777", "abs": "https://arxiv.org/abs/2504.18777", "authors": ["Diana Febrita"], "title": "Evaluating AI-Driven Automated Map Digitization in QGIS", "categories": ["cs.AI"], "comment": "Submitted to 2025 Indiana Geographic Information Council (IGIC)\n  Conference", "summary": "Map digitization is an important process that converts maps into digital\nformats that can be used for further analysis. This process typically requires\na deep human involvement because of the need for interpretation and\ndecision-making when translating complex features. With the advancement of\nartificial intelligence, there is an alternative to conducting map digitization\nwith the help of machine learning techniques. Deepness, or Deep Neural Remote\nSensing, is an advanced AI-driven tool designed and integrated as a plugin in\nQGIS application. This research focuses on assessing the effectiveness of\nDeepness in automated digitization. This study analyses AI-generated\ndigitization results from Google Earth imagery and compares them with digitized\noutputs from OpenStreetMap (OSM) to evaluate performance.", "AI": {"tldr": "The paper evaluates Deepness, an AI-driven tool for automated map digitization, comparing its results with OpenStreetMap to assess effectiveness.", "motivation": "To reduce human involvement in map digitization by leveraging AI and machine learning techniques.", "method": "Uses Deepness, a Deep Neural Remote Sensing tool in QGIS, to digitize Google Earth imagery and compares results with OpenStreetMap.", "result": "Performance of Deepness in automated digitization is analyzed against OSM outputs.", "conclusion": "The study highlights the potential of AI tools like Deepness to streamline map digitization processes."}}
{"id": "2506.08127", "pdf": "https://arxiv.org/pdf/2506.08127", "abs": "https://arxiv.org/abs/2506.08127", "authors": ["Cyrille Kone", "Emilie Kaufmann", "Laura Richert"], "title": "Constrained Pareto Set Identification with Bandit Feedback", "categories": ["stat.ML", "cs.LG"], "comment": "To appear in Proceedings of ICML2025", "summary": "In this paper, we address the problem of identifying the Pareto Set under\nfeasibility constraints in a multivariate bandit setting. Specifically, given a\n$K$-armed bandit with unknown means $\\mu_1, \\dots, \\mu_K \\in \\mathbb{R}^d$, the\ngoal is to identify the set of arms whose mean is not uniformly worse than that\nof another arm (i.e., not smaller for all objectives), while satisfying some\nknown set of linear constraints, expressing, for example, some minimal\nperformance on each objective. Our focus lies in fixed-confidence\nidentification, for which we introduce an algorithm that significantly\noutperforms racing-like algorithms and the intuitive two-stage approach that\nfirst identifies feasible arms and then their Pareto Set. We further prove an\ninformation-theoretic lower bound on the sample complexity of any algorithm for\nconstrained Pareto Set identification, showing that the sample complexity of\nour approach is near-optimal. Our theoretical results are supported by an\nextensive empirical evaluation on a series of benchmarks.", "AI": {"tldr": "The paper introduces an algorithm for identifying the Pareto Set under feasibility constraints in multivariate bandits, outperforming existing methods and proving near-optimal sample complexity.", "motivation": "To solve the problem of identifying Pareto-optimal arms under linear constraints in multivariate bandits, improving upon inefficient existing approaches.", "method": "Proposes a fixed-confidence identification algorithm, comparing it to racing-like and two-stage methods, and proves a lower bound on sample complexity.", "result": "The algorithm significantly outperforms benchmarks, with theoretical and empirical validation of its near-optimal sample complexity.", "conclusion": "The approach is effective and near-optimal for constrained Pareto Set identification, supported by theory and experiments."}}
{"id": "2502.14898", "pdf": "https://arxiv.org/pdf/2502.14898", "abs": "https://arxiv.org/abs/2502.14898", "authors": ["Lionel Wong", "Ayman Ali", "Raymond Xiong", "Shannon Zeijang Shen", "Yoon Kim", "Monica Agrawal"], "title": "Retrieval-augmented systems can be dangerous medical communicators", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Position paper in Proceedings of the 42 nd International Conference\n  on Machine Learning", "summary": "Patients have long sought health information online, and increasingly, they\nare turning to generative AI to answer their health-related queries. Given the\nhigh stakes of the medical domain, techniques like retrieval-augmented\ngeneration and citation grounding have been widely promoted as methods to\nreduce hallucinations and improve the accuracy of AI-generated responses and\nhave been widely adopted into search engines. This paper argues that even when\nthese methods produce literally accurate content drawn from source documents\nsans hallucinations, they can still be highly misleading. Patients may derive\nsignificantly different interpretations from AI-generated outputs than they\nwould from reading the original source material, let alone consulting a\nknowledgeable clinician. Through a large-scale query analysis on topics\nincluding disputed diagnoses and procedure safety, we support our argument with\nquantitative and qualitative evidence of the suboptimal answers resulting from\ncurrent systems. In particular, we highlight how these models tend to\ndecontextualize facts, omit critical relevant sources, and reinforce patient\nmisconceptions or biases. We propose a series of recommendations -- such as the\nincorporation of communication pragmatics and enhanced comprehension of source\ndocuments -- that could help mitigate these issues and extend beyond the\nmedical domain.", "AI": {"tldr": "The paper highlights that even accurate AI-generated health information can mislead patients due to decontextualization and omissions, proposing improvements like better communication pragmatics.", "motivation": "To address the issue of AI-generated health information being misleading despite technical accuracy, as patients may misinterpret it compared to original sources or clinician advice.", "method": "Large-scale query analysis on topics like disputed diagnoses and procedure safety, combining quantitative and qualitative evidence.", "result": "Current systems decontextualize facts, omit critical sources, and reinforce biases, leading to suboptimal patient interpretations.", "conclusion": "Recommendations include integrating communication pragmatics and deeper source comprehension to mitigate misleading outputs, applicable beyond healthcare."}}
{"id": "2402.03896", "pdf": "https://arxiv.org/pdf/2402.03896", "abs": "https://arxiv.org/abs/2402.03896", "authors": ["Kun Li", "George Vosselman", "Michael Ying Yang"], "title": "Multimodal Rationales for Explainable Visual Question Answering", "categories": ["cs.CV"], "comment": "Accepted to CVPR workshops 2025", "summary": "Visual Question Answering (VQA) is a challenging task of predicting the\nanswer to a question about the content of an image. Prior works directly\nevaluate the answering models by simply calculating the accuracy of predicted\nanswers. However, the inner reasoning behind the predictions is disregarded in\nsuch a \"black box\" system, and we cannot ascertain the trustworthiness of the\npredictions. Even more concerning, in some cases, these models predict correct\nanswers despite focusing on irrelevant visual regions or textual tokens. To\ndevelop an explainable and trustworthy answering system, we propose a novel\nmodel termed MRVQA (Multimodal Rationales for VQA), which provides visual and\ntextual rationales to support its predicted answers. To measure the quality of\ngenerated rationales, a new metric vtS (visual-textual Similarity) score is\nintroduced from both visual and textual perspectives. Considering the extra\nannotations distinct from standard VQA, MRVQA is trained and evaluated using\nsamples synthesized from some existing datasets. Extensive experiments across\nthree EVQA datasets demonstrate that MRVQA achieves new state-of-the-art\nresults through additional rationale generation, enhancing the trustworthiness\nof the explainable VQA model. The code and the synthesized dataset are released\nunder https://github.com/lik1996/MRVQA2025.", "AI": {"tldr": "MRVQA introduces visual and textual rationales for VQA, improving trustworthiness and explainability with a new vtS metric.", "motivation": "Prior VQA models lack transparency, predicting correct answers without proper reasoning, raising trust issues.", "method": "MRVQA generates multimodal rationales (visual and textual) and uses a vtS score to evaluate rationale quality.", "result": "MRVQA achieves state-of-the-art results on EVQA datasets, enhancing model trustworthiness.", "conclusion": "MRVQA advances explainable VQA by providing rationales and a new metric, with code and dataset publicly available."}}
{"id": "2505.01343", "pdf": "https://arxiv.org/pdf/2505.01343", "abs": "https://arxiv.org/abs/2505.01343", "authors": ["Dongliang Guo", "Mengxuan Hu", "Zihan Guan", "Thomas Hartvigsen", "Sheng Li"], "title": "BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing", "categories": ["cs.AI"], "comment": null, "summary": "Large multi-modal models inevitably decay over time as facts update and\npreviously learned information becomes outdated. Traditional approaches such as\nfine-tuning are often impractical for updating these models due to their size\nand complexity. Instead, direct knowledge editing within the models presents a\nmore viable solution. Current model editing techniques, however, typically\noverlook the unique influence ranges of different facts, leading to compromised\nmodel performance in terms of both generality and locality. To address this\nissue, we introduce the concept of the generality-locality trade-off in\nmulti-modal model editing. We develop a new model editing dataset named OKEDIT,\nspecifically designed to effectively evaluate this trade-off. Building on this\nfoundation, we propose \\textbf{BalancEdit}, a novel method for balanced model\nediting that dynamically achieves an optimal balance between generality and\nlocality. BalancEdit utilizes a unique mechanism that generates both positive\nand negative samples for each fact to accurately determine its influence scope\nand incorporates these insights into the model's latent space using a discrete,\nlocalized codebook of edits, without modifying the underlying model weights. To\nour knowledge, this is the first approach explicitly addressing the\ngenerality-locality trade-off in multi-modal model editing. Our comprehensive\nresults confirm the effectiveness of BalancEdit, demonstrating minimal\ntrade-offs while maintaining robust editing capabilities. Our code and dataset\nare available at https://github.com/donglgcn/BalancEdit/tree/MMOKVQA.", "AI": {"tldr": "The paper addresses the decay of large multi-modal models over time and introduces BalancEdit, a method for balanced model editing that optimizes the generality-locality trade-off.", "motivation": "Traditional fine-tuning is impractical for updating large models, and current editing techniques overlook the influence ranges of facts, compromising performance.", "method": "Proposes BalancEdit, which dynamically balances generality and locality by generating positive/negative samples and using a localized codebook of edits.", "result": "BalancEdit effectively minimizes trade-offs while maintaining robust editing capabilities.", "conclusion": "BalancEdit is the first method to explicitly address the generality-locality trade-off in multi-modal model editing, demonstrating strong performance."}}
{"id": "2506.08192", "pdf": "https://arxiv.org/pdf/2506.08192", "abs": "https://arxiv.org/abs/2506.08192", "authors": ["Jared Claypoole", "Steven Cheung", "Ashish Gehani", "Vinod Yegneswaran", "Ahmad Ridley"], "title": "Interpreting Agent Behaviors in Reinforcement-Learning-Based Cyber-Battle Simulation Platforms", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We analyze two open source deep reinforcement learning agents submitted to\nthe CAGE Challenge 2 cyber defense challenge, where each competitor submitted\nan agent to defend a simulated network against each of several provided\nrules-based attack agents. We demonstrate that one can gain interpretability of\nagent successes and failures by simplifying the complex state and action spaces\nand by tracking important events, shedding light on the fine-grained behavior\nof both the defense and attack agents in each experimental scenario. By\nanalyzing important events within an evaluation episode, we identify patterns\nin infiltration and clearing events that tell us how well the attacker and\ndefender played their respective roles; for example, defenders were generally\nable to clear infiltrations within one or two timesteps of a host being\nexploited. By examining transitions in the environment's state caused by the\nvarious possible actions, we determine which actions tended to be effective and\nwhich did not, showing that certain important actions are between 40% and 99%\nineffective. We examine how decoy services affect exploit success, concluding\nfor instance that decoys block up to 94% of exploits that would directly grant\nprivileged access to a host. Finally, we discuss the realism of the challenge\nand ways that the CAGE Challenge 4 has addressed some of our concerns.", "AI": {"tldr": "Analysis of deep reinforcement learning agents in a cyber defense challenge, focusing on interpretability, effectiveness of actions, and realism.", "motivation": "To understand the successes and failures of defense agents in a simulated cyber defense scenario and improve interpretability of their behavior.", "method": "Simplified state and action spaces, tracked important events, and analyzed patterns in infiltration and clearing events.", "result": "Defenders cleared infiltrations quickly; certain actions were highly ineffective (40-99%); decoys blocked up to 94% of privileged exploits.", "conclusion": "The study highlights agent behavior insights and realism improvements for future challenges like CAGE Challenge 4."}}
{"id": "2502.15226", "pdf": "https://arxiv.org/pdf/2502.15226", "abs": "https://arxiv.org/abs/2502.15226", "authors": ["Mengqiao Liu", "Tevin Wang", "Cassandra A. Cohen", "Sarah Li", "Chenyan Xiong"], "title": "Understand User Opinions of Large Language Models via LLM-Powered In-the-Moment User Experience Interviews", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Which large language model (LLM) is better? Every evaluation tells a story,\nbut what do users really think about current LLMs? This paper presents CLUE, an\nLLM-powered interviewer that conducts in-the-moment user experience interviews,\nright after users interact with LLMs, and automatically gathers insights about\nuser opinions from massive interview logs. We conduct a study with thousands of\nusers to understand user opinions on mainstream LLMs, recruiting users to first\nchat with a target LLM and then be interviewed by CLUE. Our experiments\ndemonstrate that CLUE captures interesting user opinions, e.g., the bipolar\nviews on the displayed reasoning process of DeepSeek-R1 and demands for\ninformation freshness and multi-modality. Our code and data are at\nhttps://github.com/cxcscmu/LLM-Interviewer.", "AI": {"tldr": "CLUE is an LLM-powered interviewer that gathers user opinions on LLMs post-interaction, revealing insights like bipolar views on reasoning processes and demands for freshness/multi-modality.", "motivation": "To understand real user opinions on mainstream LLMs beyond traditional evaluations.", "method": "CLUE conducts in-the-moment interviews after users interact with LLMs, analyzing logs from thousands of users.", "result": "Captured diverse user opinions, e.g., mixed views on DeepSeek-R1's reasoning and desires for updated/multi-modal info.", "conclusion": "CLUE effectively gathers valuable user insights, highlighting gaps like reasoning clarity and feature demands."}}
{"id": "2402.04416", "pdf": "https://arxiv.org/pdf/2402.04416", "abs": "https://arxiv.org/abs/2402.04416", "authors": ["Christopher Liao", "Christian So", "Theodoros Tsiligkaridis", "Brian Kulis"], "title": "Multimodal Unsupervised Domain Generalization by Retrieving Across the Modality Gap", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Domain generalization (DG) is an important problem that learns a model which\ngeneralizes to unseen test domains leveraging one or more source domains, under\nthe assumption of shared label spaces. However, most DG methods assume access\nto abundant source data in the target label space, a requirement that proves\noverly stringent for numerous real-world applications, where acquiring the same\nlabel space as the target task is prohibitively expensive. For this setting, we\ntackle the multimodal version of the unsupervised domain generalization (MUDG)\nproblem, which uses a large task-agnostic unlabeled source dataset during\nfinetuning. Our framework does not explicitly assume any relationship between\nthe source dataset and target task. Instead, it relies only on the premise that\nthe source dataset can be accurately and efficiently searched in a joint\nvision-language space. We make three contributions in the MUDG setting.\nFirstly, we show theoretically that cross-modal approximate nearest neighbor\nsearch suffers from low recall due to the large distance between text queries\nand the image centroids used for coarse quantization. Accordingly, we propose\npaired k-means, a simple clustering algorithm that improves nearest neighbor\nrecall by storing centroids in query space instead of image space. Secondly, we\npropose an adaptive text augmentation scheme for target labels designed to\nimprove zero-shot accuracy and diversify retrieved image data. Lastly, we\npresent two simple but effective components to further improve downstream\ntarget accuracy. We compare against state-of-the-art name-only transfer,\nsource-free DG and zero-shot (ZS) methods on their respective benchmarks and\nshow consistent improvement in accuracy on 20 diverse datasets. Code is\navailable: https://github.com/Chris210634/mudg", "AI": {"tldr": "The paper addresses unsupervised domain generalization (MUDG) by leveraging a task-agnostic unlabeled source dataset and cross-modal search, proposing paired k-means and adaptive text augmentation to improve accuracy.", "motivation": "Real-world applications often lack labeled source data matching the target task, making traditional domain generalization (DG) methods impractical. The paper aims to solve this using multimodal unsupervised DG.", "method": "The framework uses cross-modal search in a vision-language space, introducing paired k-means for better nearest neighbor recall and adaptive text augmentation for target labels.", "result": "The method outperforms state-of-the-art name-only transfer, source-free DG, and zero-shot methods on 20 diverse datasets.", "conclusion": "The proposed MUDG framework effectively generalizes to unseen domains without requiring labeled source data, demonstrating superior performance across benchmarks."}}
{"id": "2505.14479", "pdf": "https://arxiv.org/pdf/2505.14479", "abs": "https://arxiv.org/abs/2505.14479", "authors": ["Oren Sultan", "Eitan Stern", "Dafna Shahaf"], "title": "Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach", "categories": ["cs.AI", "cs.CL"], "comment": "long paper", "summary": "Large language models (LLMs) struggle with formal domains that require\nrigorous logical deduction and symbolic reasoning, such as mathematical proof\ngeneration. We propose a neuro-symbolic approach that combines LLMs' generative\nstrengths with structured components to overcome this challenge. As a\nproof-of-concept, we focus on geometry problems. Our approach is two-fold: (1)\nwe retrieve analogous problems and use their proofs to guide the LLM, and (2) a\nformal verifier evaluates the generated proofs and provides feedback, helping\nthe model fix incorrect proofs. We demonstrate that our method significantly\nimproves proof accuracy for OpenAI's o1 model (58%-70% improvement); both\nanalogous problems and the verifier's feedback contribute to these gains. More\nbroadly, shifting to LLMs that generate provably correct conclusions could\ndramatically improve their reliability, accuracy and consistency, unlocking\ncomplex tasks and critical real-world applications that require\ntrustworthiness.", "AI": {"tldr": "A neuro-symbolic approach combining LLMs with structured components improves logical reasoning in geometry proofs, achieving 58%-70% accuracy gains.", "motivation": "LLMs struggle with rigorous logical tasks like mathematical proofs. This work aims to enhance their reliability in such domains.", "method": "Retrieve analogous problems to guide LLMs and use a formal verifier to evaluate and correct generated proofs.", "result": "Proof accuracy improves significantly (58%-70%) for OpenAI's o1 model, with both analogous problems and verifier feedback contributing.", "conclusion": "Enhancing LLMs to generate provably correct outputs can boost their reliability for complex, real-world applications."}}
{"id": "2506.08263", "pdf": "https://arxiv.org/pdf/2506.08263", "abs": "https://arxiv.org/abs/2506.08263", "authors": ["Pouya Agheli", "Tugce Kobal", "Fran\u00e7ois Durand", "Matthew Andrews"], "title": "Learning-Based Multiuser Scheduling in MIMO-OFDM Systems with Hybrid Beamforming", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": "To appear in the proceedings of the European Conference on Networks\n  and Communications (EuCNC) & 6G Summit, 2025", "summary": "We investigate the multiuser scheduling problem in multiple-input\nmultiple-output (MIMO) systems using orthogonal frequency division multiplexing\n(OFDM) and hybrid beamforming in which a base station (BS) communicates with\nmultiple users over millimeter wave (mmWave) channels in the downlink. Improved\nscheduling is critical for enhancing spectral efficiency and the long-term\nperformance of the system from the perspective of proportional fairness (PF)\nmetric in hybrid beamforming systems due to its limited multiplexing gain. Our\nobjective is to maximize PF by properly designing the analog and digital\nprecoders within the hybrid beamforming and selecting the users subject to the\nnumber of radio frequency (RF) chains. Leveraging the characteristics of mmWave\nchannels, we apply a two-timescale protocol. On a long timescale, we assign an\nanalog beam to each user. Scheduling the users and designing the digital\nprecoder are done accordingly on a short timescale. To conduct scheduling, we\npropose combinatorial solutions, such as greedy and sorting algorithms,\nfollowed by a machine learning (ML) approach. Our numerical results highlight\nthe trade-off between the performance and complexity of the proposed\napproaches. Consequently, we show that the choice of approach depends on the\nspecific criteria within a given scenario.", "AI": {"tldr": "The paper addresses multiuser scheduling in MIMO-OFDM systems with hybrid beamforming, aiming to maximize proportional fairness (PF) using analog/digital precoders and user selection. It proposes combinatorial and ML-based solutions, highlighting performance-complexity trade-offs.", "motivation": "Improved scheduling is crucial for spectral efficiency and long-term performance in hybrid beamforming systems, especially under limited multiplexing gain in mmWave channels.", "method": "A two-timescale protocol is used: analog beam assignment on a long timescale, and user scheduling/digital precoder design on a short timescale. Combinatorial (greedy, sorting) and ML-based approaches are proposed.", "result": "Numerical results demonstrate trade-offs between performance and complexity, with approach suitability depending on scenario-specific criteria.", "conclusion": "The choice of scheduling approach (combinatorial or ML) depends on the scenario, balancing performance and complexity for optimal PF in hybrid beamforming systems."}}
{"id": "2502.20122", "pdf": "https://arxiv.org/pdf/2502.20122", "abs": "https://arxiv.org/abs/2502.20122", "authors": ["Tergel Munkhbat", "Namgyu Ho", "Seo Hyun Kim", "Yongjin Yang", "Yujin Kim", "Se-Young Yun"], "title": "Self-Training Elicits Concise Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "26 pages, 10 figures, 23 tables. Accepted to Findings of ACL 2025", "summary": "Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to\nutilize additional computation through intermediate tokens to solve complex\ntasks. However, we posit that typical reasoning traces contain many redundant\ntokens, incurring extraneous inference costs. Upon examination of the output\ndistribution of current LLMs, we find evidence on their latent ability to\nreason more concisely, relative to their default behavior. To elicit this\ncapability, we propose simple fine-tuning methods which leverage self-generated\nconcise reasoning paths obtained by best-of-N sampling and few-shot\nconditioning, in task-specific settings. Our combined method achieves a 30%\nreduction in output tokens on average, across five model families on GSM8K and\nMATH, while maintaining average accuracy. By exploiting the fundamental\nstochasticity and in-context learning capabilities of LLMs, our self-training\napproach robustly elicits concise reasoning on a wide range of models,\nincluding those with extensive post-training. Code is available at\nhttps://github.com/TergelMunkhbat/concise-reasoning", "AI": {"tldr": "The paper proposes fine-tuning methods to reduce redundant tokens in Chain-of-Thought reasoning, achieving a 30% token reduction while maintaining accuracy.", "motivation": "Typical reasoning traces in LLMs contain redundant tokens, increasing inference costs unnecessarily.", "method": "Fine-tuning using self-generated concise reasoning paths via best-of-N sampling and few-shot conditioning.", "result": "30% reduction in output tokens across five model families on GSM8K and MATH, with maintained accuracy.", "conclusion": "Self-training effectively elicits concise reasoning in LLMs, leveraging stochasticity and in-context learning."}}
{"id": "2405.02844", "pdf": "https://arxiv.org/pdf/2405.02844", "abs": "https://arxiv.org/abs/2405.02844", "authors": ["Ziyun Qian", "Zeyu Xiao", "Xingliang Jin", "Dingkang Yang", "Mingcheng Li", "Zhenyi Wu", "Dongliang Kou", "Peng Zhai", "Lihua Zhang"], "title": "SMCD: High Realism Motion Style Transfer via Mamba-based Diffusion", "categories": ["cs.CV"], "comment": null, "summary": "Motion style transfer is a significant research direction in the field of\ncomputer vision, enabling virtual digital humans to rapidly switch between\ndifferent styles of the same motion, thereby significantly enhancing the\nrichness and realism of movements. It has been widely applied in multimedia\nscenarios such as films, games, and the metaverse. However, most existing\nmethods adopt a two-stream structure, which tends to overlook the intrinsic\nrelationship between content and style motions, leading to information loss and\npoor alignment. Moreover, when handling long-range motion sequences, these\nmethods fail to effectively learn temporal dependencies, ultimately resulting\nin unnatural generated motions. To address these limitations, we propose a\nUnified Motion Style Diffusion (UMSD) framework, which simultaneously extracts\nfeatures from both content and style motions and facilitates sufficient\ninformation interaction. Additionally, we introduce the Motion Style Mamba\n(MSM) denoiser, the first approach in the field of motion style transfer to\nleverage Mamba's powerful sequence modelling capability. Better capturing\ntemporal relationships generates more coherent stylized motion sequences.\nThird, we design a diffusion-based content consistency loss and a style\nconsistency loss to constrain the framework, ensuring that it inherits the\ncontent motion while effectively learning the characteristics of the style\nmotion. Finally, extensive experiments demonstrate that our method outperforms\nstate-of-the-art (SOTA) methods qualitatively and quantitatively, achieving\nmore realistic and coherent motion style transfer.", "AI": {"tldr": "The paper proposes a Unified Motion Style Diffusion (UMSD) framework with a Motion Style Mamba (MSM) denoiser to improve motion style transfer by addressing content-style relationships and temporal dependencies.", "motivation": "Existing motion style transfer methods overlook intrinsic content-style relationships and struggle with temporal dependencies, leading to unnatural results.", "method": "The UMSD framework integrates content and style motion features, uses MSM for sequence modeling, and employs diffusion-based consistency losses.", "result": "The method outperforms SOTA techniques, producing more realistic and coherent stylized motions.", "conclusion": "The UMSD framework effectively addresses limitations in motion style transfer, enhancing realism and coherence."}}
{"id": "2505.20733", "pdf": "https://arxiv.org/pdf/2505.20733", "abs": "https://arxiv.org/abs/2505.20733", "authors": ["Cheonsu Jeong", "Seongmin Sim", "Hyoyoung Cho", "Sungsu Kim", "Byounggwan Shin"], "title": "E2E Process Automation Leveraging Generative AI and IDP-Based Automation Agent: A Case Study on Corporate Expense Processing", "categories": ["cs.AI"], "comment": null, "summary": "This paper presents an intelligent work automation approach in the context of\ncontemporary digital transformation by integrating generative AI and\nIntelligent Document Processing (IDP) technologies with an Automation Agent to\nrealize End-to-End (E2E) automation of corporate financial expense processing\ntasks. While traditional Robotic Process Automation (RPA) has proven effective\nfor repetitive, rule-based simple task automation, it faces limitations in\nhandling unstructured data, exception management, and complex decision-making.\nThis study designs and implements a four-stage integrated process comprising\nautomatic recognition of supporting documents such as receipts via OCR/IDP,\nitem classification based on a policy-driven database, intelligent exception\nhandling supported by generative AI (large language models, LLMs), and\nhuman-in-the-loop final decision-making with continuous system learning through\nan Automation Agent. Applied to a major Korean enterprise (Company S), the\nsystem demonstrated quantitative benefits including over 80% reduction in\nprocessing time for paper receipt expense tasks, decreased error rates, and\nimproved compliance, as well as qualitative benefits such as enhanced accuracy\nand consistency, increased employee satisfaction, and data-driven decision\nsupport. Furthermore, the system embodies a virtuous cycle by learning from\nhuman judgments to progressively improve automatic exception handling\ncapabilities. Empirically, this research confirms that the organic integration\nof generative AI, IDP, and Automation Agents effectively overcomes the\nlimitations of conventional automation and enables E2E automation of complex\ncorporate processes. The study also discusses potential extensions to other\ndomains such as accounting, human resources, and procurement, and proposes\nfuture directions for AI-driven hyper-automation development.", "AI": {"tldr": "The paper introduces an AI-driven automation system combining generative AI and IDP to enhance financial expense processing, outperforming traditional RPA by reducing processing time by 80% and improving accuracy.", "motivation": "Traditional RPA struggles with unstructured data and complex decisions, prompting the need for a more advanced solution integrating AI and IDP.", "method": "A four-stage process: document recognition via OCR/IDP, item classification, AI-driven exception handling, and human-in-the-loop decision-making with continuous learning.", "result": "Quantitative benefits (80% faster processing, fewer errors) and qualitative improvements (accuracy, employee satisfaction) were achieved in a Korean enterprise.", "conclusion": "The integration of generative AI, IDP, and Automation Agents enables E2E automation of complex tasks, with potential applications in other domains."}}
{"id": "2506.08276", "pdf": "https://arxiv.org/pdf/2506.08276", "abs": "https://arxiv.org/abs/2506.08276", "authors": ["Yichuan Wang", "Shu Liu", "Zhifei Li", "Yongji Wu", "Ziming Mao", "Yilong Zhao", "Xiao Yan", "Zhiying Xu", "Yang Zhou", "Ion Stoica", "Sewon Min", "Matei Zaharia", "Joseph E. Gonzalez"], "title": "LEANN: A Low-Storage Vector Index", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Embedding-based search is widely used in applications such as recommendation\nand retrieval-augmented generation (RAG). Recently, there is a growing demand\nto support these capabilities over personal data stored locally on devices.\nHowever, maintaining the necessary data structure associated with the\nembedding-based search is often infeasible due to its high storage overhead.\nFor example, indexing 100 GB of raw data requires 150 to 700 GB of storage,\nmaking local deployment impractical. Reducing this overhead while maintaining\nsearch quality and latency becomes a critical challenge. In this paper, we\npresent LEANN, a storage-efficient approximate nearest neighbor (ANN) search\nindex optimized for resource-constrained personal devices. LEANN combines a\ncompact graph-based structure with an efficient on-the-fly recomputation\nstrategy to enable fast and accurate retrieval with minimal storage overhead.\nOur evaluation shows that LEANN reduces index size to under 5% of the original\nraw data, achieving up to 50 times smaller storage than standard indexes, while\nmaintaining 90% top-3 recall in under 2 seconds on real-world question\nanswering benchmarks.", "AI": {"tldr": "LEANN is a storage-efficient ANN search index for personal devices, reducing storage overhead to under 5% of raw data while maintaining high search quality and speed.", "motivation": "The need for embedding-based search on local personal data faces high storage overhead, making deployment impractical. LEANN addresses this challenge.", "method": "LEANN combines a compact graph-based structure with on-the-fly recomputation for efficient retrieval.", "result": "LEANN reduces index size to under 5% of raw data, achieves 50x smaller storage, and maintains 90% top-3 recall in under 2 seconds.", "conclusion": "LEANN offers a practical solution for local deployment of embedding-based search with minimal storage overhead."}}
{"id": "2503.04556", "pdf": "https://arxiv.org/pdf/2503.04556", "abs": "https://arxiv.org/abs/2503.04556", "authors": ["Jacqueline R. M. A. Maasch", "Alihan H\u00fcy\u00fck", "Xinnuo Xu", "Aditya V. Nori", "Javier Gonzalez"], "title": "Compositional Causal Reasoning Evaluation in Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Causal reasoning and compositional reasoning are two core aspirations in AI.\nMeasuring the extent of these behaviors requires principled evaluation methods.\nWe explore a unified perspective that considers both behaviors simultaneously,\ntermed compositional causal reasoning (CCR): the ability to infer how causal\nmeasures compose and, equivalently, how causal quantities propagate through\ngraphs. We instantiate a framework for the systematic evaluation of CCR for the\naverage treatment effect and the probability of necessity and sufficiency. As\nproof of concept, we demonstrate CCR evaluation for language models in the\nLLama, Phi, and GPT families. On a math word problem, our framework revealed a\nrange of taxonomically distinct error patterns. CCR errors increased with the\ncomplexity of causal paths for all models except o1.", "AI": {"tldr": "The paper introduces compositional causal reasoning (CCR) as a unified framework to evaluate AI's ability to combine causal and compositional reasoning, testing it on language models like LLama, Phi, and GPT.", "motivation": "To address the need for principled evaluation methods for causal and compositional reasoning in AI, the authors propose CCR as a combined measure.", "method": "They instantiate a framework to evaluate CCR for average treatment effect and probability of necessity and sufficiency, testing it on language models.", "result": "The framework identified distinct error patterns in models, with CCR errors generally increasing with causal path complexity, except for one model (o1).", "conclusion": "CCR provides a systematic way to assess AI's causal-compositional reasoning, revealing model-specific strengths and weaknesses."}}
{"id": "2405.07988", "pdf": "https://arxiv.org/pdf/2405.07988", "abs": "https://arxiv.org/abs/2405.07988", "authors": ["Hong-Yu Zhou", "Juli\u00e1n Nicol\u00e1s Acosta", "Subathra Adithan", "Suvrankar Datta", "Eric J. Topol", "Pranav Rajpurkar"], "title": "MedVersa: A Generalist Foundation Model for Medical Image Interpretation", "categories": ["cs.CV"], "comment": "Technical study", "summary": "Current medical AI systems are often limited to narrow applications,\nhindering widespread adoption. We present MedVersa, a generalist foundation\nmodel trained on tens of millions of compiled medical instances. MedVersa\nunlocks generalist learning from multimodal inputs and outputs, representing\nthe first example of a generalist model reaching competitive performance with\nleading specialized solutions across a variety of medical imaging scenarios.\nMedVersa achieves state-of-the-art performance in nine tasks, sometimes\noutperforming counterparts by over 10%. Radiologist evaluation shows\nMedVersa-generated reports get superior performance in 95% of normal studies,\nwhile matching or exceeding human reports in 71% of cases overall. User studies\nshowed notable reductions in report writing time and discrepancies with the use\nof MedVersa. Our findings underscore the value of flexible, multimodal AI\nsystems in advancing medical image interpretation and supporting clinical\nexpertise.", "AI": {"tldr": "MedVersa is a generalist medical AI model that outperforms specialized solutions in multiple tasks, reducing report time and improving accuracy.", "motivation": "Current medical AI systems are narrow in scope, limiting adoption. MedVersa aims to bridge this gap with a generalist approach.", "method": "Trained on tens of millions of medical instances, MedVersa handles multimodal inputs and outputs for diverse medical imaging tasks.", "result": "Achieves state-of-the-art in nine tasks, outperforming specialists by 10+%, and matches/exceeds human reports in 71% of cases.", "conclusion": "Flexible, multimodal AI like MedVersa enhances medical image interpretation and clinical support."}}
{"id": "2506.00328", "pdf": "https://arxiv.org/pdf/2506.00328", "abs": "https://arxiv.org/abs/2506.00328", "authors": ["Kourosh Shahnazari", "Seyed Moein Ayyoubzadeh", "Mohammadali Keshtparvar"], "title": "BASIL: Best-Action Symbolic Interpretable Learning for Evolving Compact RL Policies", "categories": ["cs.AI"], "comment": null, "summary": "The quest for interpretable reinforcement learning is a grand challenge for\nthe deployment of autonomous decision-making systems in safety-critical\napplications. Modern deep reinforcement learning approaches, while powerful,\ntend to produce opaque policies that compromise verification, reduce\ntransparency, and impede human oversight. To address this, we introduce BASIL\n(Best-Action Symbolic Interpretable Learning), a systematic approach for\ngenerating symbolic, rule-based policies via online evolutionary search with\nquality-diversity (QD) optimization. BASIL represents policies as ordered lists\nof symbolic predicates over state variables, ensuring full interpretability and\ntractable policy complexity. By using a QD archive, the methodology in the\nproposed study encourages behavioral and structural diversity between\ntop-performing solutions, while a complexity-aware fitness encourages the\nsynthesis of compact representations. The evolutionary system supports the use\nof exact constraints for rule count and system adaptability for balancing\ntransparency with expressiveness. Empirical comparisons with three benchmark\ntasks CartPole-v1, MountainCar-v0, and Acrobot-v1 show that BASIL consistently\nsynthesizes interpretable controllers with compact representations comparable\nto deep reinforcement learning baselines. Herein, this article introduces a new\ninterpretable policy synthesis method that combines symbolic expressiveness,\nevolutionary diversity, and online learning through a unifying framework.", "AI": {"tldr": "BASIL introduces a symbolic, interpretable reinforcement learning method using evolutionary search and quality-diversity optimization to create transparent policies comparable to deep RL baselines.", "motivation": "Addressing the opacity of deep RL policies, BASIL aims to ensure interpretability, verification, and human oversight in safety-critical applications.", "method": "BASIL uses online evolutionary search with quality-diversity optimization to generate symbolic, rule-based policies represented as ordered lists of predicates. It encourages diversity and compactness via a QD archive and complexity-aware fitness.", "result": "Empirical tests on CartPole-v1, MountainCar-v0, and Acrobot-v1 show BASIL produces interpretable, compact policies matching deep RL performance.", "conclusion": "BASIL successfully combines symbolic expressiveness, evolutionary diversity, and online learning to advance interpretable RL."}}
{"id": "2506.08325", "pdf": "https://arxiv.org/pdf/2506.08325", "abs": "https://arxiv.org/abs/2506.08325", "authors": ["Marcos Matabuena", "Rahul Ghosal", "Pavlo Mozharovskyi", "Oscar Hernan Madrid Padilla", "Jukka-Pekka Onnela"], "title": "Model-Free Kernel Conformal Depth Measures Algorithm for Uncertainty Quantification in Regression Models in Separable Hilbert Spaces", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "arXiv admin note: substantial text overlap with arXiv:2405.13970", "summary": "Depth measures are powerful tools for defining level sets in emerging,\nnon--standard, and complex random objects such as high-dimensional multivariate\ndata, functional data, and random graphs. Despite their favorable theoretical\nproperties, the integration of depth measures into regression modeling to\nprovide prediction regions remains a largely underexplored area of research. To\naddress this gap, we propose a novel, model-free uncertainty quantification\nalgorithm based on conditional depth measures--specifically, conditional kernel\nmean embeddings and an integrated depth measure. These new algorithms can be\nused to define prediction and tolerance regions when predictors and responses\nare defined in separable Hilbert spaces. The use of kernel mean embeddings\nensures faster convergence rates in prediction region estimation. To enhance\nthe practical utility of the algorithms with finite samples, we also introduce\na conformal prediction variant that provides marginal, non-asymptotic\nguarantees for the derived prediction regions. Additionally, we establish both\nconditional and unconditional consistency results, as well as fast convergence\nrates in certain homoscedastic settings. We evaluate the finite--sample\nperformance of our model in extensive simulation studies involving various\ntypes of functional data and traditional Euclidean scenarios. Finally, we\ndemonstrate the practical relevance of our approach through a digital health\napplication related to physical activity, aiming to provide personalized\nrecommendations", "AI": {"tldr": "The paper proposes a model-free uncertainty quantification algorithm using conditional depth measures for prediction regions in complex data types, with conformal prediction for finite-sample guarantees.", "motivation": "To address the underexplored integration of depth measures into regression modeling for prediction regions in complex data.", "method": "Uses conditional kernel mean embeddings and an integrated depth measure, with a conformal prediction variant for finite samples.", "result": "Achieves faster convergence rates, conditional/unconditional consistency, and performs well in simulations and a digital health application.", "conclusion": "The approach is effective for uncertainty quantification in complex data, with practical utility in real-world applications."}}
{"id": "2503.04793", "pdf": "https://arxiv.org/pdf/2503.04793", "abs": "https://arxiv.org/abs/2503.04793", "authors": ["Wenjie Qiu", "Yi-Chen Li", "Xuqin Zhang", "Tianyi Zhang", "Yihang Zhang", "Zongzhang Zhang", "Yang Yu"], "title": "Sentence-level Reward Model can Generalize Better for Aligning LLM from Human Preference", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Learning reward models from human preference datasets and subsequently\noptimizing language models via reinforcement learning has emerged as a\nfundamental paradigm for aligning LLMs with human preferences. The performance\nof the reward model plays a crucial role in the effectiveness of alignment.\nPrevious reward models operate at a coarse-grained level, requiring the\ngeneration of a complete response to obtain a reward value. The sparse reward\nmay present challenges for downstream reinforcement learning. While recent\nefforts have attempted to learn token-level reward models, the lack of explicit\nsemantic information makes it difficult to model the credit of every individual\ntoken. In this paper, we propose assigning scores to every sentence,\nintroducing an intermediate-grained reward model. By segmenting the complete\nresponse into sentences and applying differential operations to reward output\nat the start and end positions of each sentence, we can effectively model the\nrewards of sentences. Moreover, a novel attention mechanism is introduced to\naggregate the scores of all sentences into a response-level score, which allows\nit to be trained using the Bradley-Terry model. On common benchmarks, our\nmethod outperforms the response-level reward model by 2.7% on RewardBench (for\nreward modeling evaluation) and surpasses all baselines on AlpacaEval (for\nalignment evaluation).", "AI": {"tldr": "The paper proposes an intermediate-grained reward model for aligning LLMs with human preferences by scoring sentences and aggregating them into a response-level score, outperforming existing methods.", "motivation": "Existing reward models operate at coarse-grained levels, leading to sparse rewards and challenges for reinforcement learning. Token-level models lack explicit semantic information.", "method": "The method segments responses into sentences, assigns scores to each, and uses differential operations and a novel attention mechanism to aggregate scores into a response-level reward.", "result": "The approach outperforms response-level reward models by 2.7% on RewardBench and surpasses baselines on AlpacaEval.", "conclusion": "The proposed intermediate-grained reward model improves alignment effectiveness by addressing the limitations of coarse-grained and token-level models."}}
{"id": "2407.03817", "pdf": "https://arxiv.org/pdf/2407.03817", "abs": "https://arxiv.org/abs/2407.03817", "authors": ["Ana Filipa Rodrigues Nogueira", "H\u00e9lder P. Oliveira", "Lu\u00eds F. Teixeira"], "title": "Markerless Multi-view 3D Human Pose Estimation: a survey", "categories": ["cs.CV"], "comment": "26 pages, 10 tables, 6 figures, accepted at Image and Vision\n  Computing (IMAVIS)", "summary": "3D human pose estimation involves reconstructing the human skeleton by\ndetecting the body joints. Accurate and efficient solutions are required for\nseveral real-world applications including animation, human-robot interaction,\nsurveillance, and sports. However, challenges such as occlusions, 2D pose\nmismatches, random camera perspectives, and limited 3D labelled data have been\nhampering the models' performance and limiting their deployment in real-world\nscenarios. The higher availability of cameras has led researchers to explore\nmulti-view solutions to take advantage of the different perspectives to\nreconstruct the pose.\n  Most existing reviews have mainly focused on monocular 3D human pose\nestimation, so a comprehensive survey on multi-view approaches has been missing\nsince 2012. According to the reviewed articles, the majority of the existing\nmethods are fully-supervised approaches based on geometric constraints, which\nare often limited by 2D pose mismatches. To mitigate this, researchers have\nproposed incorporating temporal consistency or depth information.\nAlternatively, working directly with 3D features has been shown to completely\novercome this issue, albeit at the cost of increased computational complexity.\nAdditionally, models with lower levels of supervision have been identified to\nhelp address challenges such as annotated data scarcity and generalisation to\nnew setups. Therefore, no method currently addresses all challenges associated\nwith 3D pose reconstruction, and a trade-off between complexity and performance\nexists. Further research is needed to develop approaches capable of quickly\ninferring a highly accurate 3D pose with bearable computation cost. Techniques\nsuch as active learning, low-supervision methods, temporal consistency, view\nselection, depth information estimation, and multi-modal approaches are\nstrategies to consider when developing a new method for this task.", "AI": {"tldr": "A survey on multi-view 3D human pose estimation highlights challenges like occlusions and data scarcity, reviews existing methods, and suggests future research directions.", "motivation": "Addressing the lack of comprehensive surveys on multi-view 3D human pose estimation and the challenges hindering real-world deployment.", "method": "Reviews existing approaches, focusing on fully-supervised geometric constraints, temporal consistency, and 3D features.", "result": "Identifies trade-offs between complexity and performance, noting no method fully solves all challenges.", "conclusion": "Proposes future research directions like active learning, low-supervision methods, and multi-modal approaches to improve accuracy and efficiency."}}
{"id": "2506.04734", "pdf": "https://arxiv.org/pdf/2506.04734", "abs": "https://arxiv.org/abs/2506.04734", "authors": ["Lin Sun", "Weihong Lin", "Jinzhu Wu", "Yongfu Zhu", "Xiaoqi Jian", "Guangxiang Zhao", "Change Jia", "Linglin Zhang", "Sai-er Hu", "Yuhan Wu", "Xiangzheng Zhang"], "title": "Evaluation is All You Need: Strategic Overclaiming of LLM Reasoning Capabilities Through Evaluation Design", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning models represented by the Deepseek-R1-Distill series have been\nwidely adopted by the open-source community due to their strong performance in\nmathematics, science, programming, and other domains. However, our study\nreveals that their benchmark evaluation results are subject to significant\nfluctuations caused by various factors. Subtle differences in evaluation\nconditions can lead to substantial variations in results. Similar phenomena are\nobserved in other open-source inference models fine-tuned based on the\nDeepseek-R1-Distill series, as well as in the QwQ-32B model, making their\nclaimed performance improvements difficult to reproduce reliably. Therefore, we\nadvocate for the establishment of a more rigorous paradigm for model\nperformance evaluation and present our empirical assessments of the\nDeepseek-R1-Distill series models.", "AI": {"tldr": "The paper highlights performance evaluation inconsistencies in the Deepseek-R1-Distill series and similar models, advocating for stricter evaluation standards.", "motivation": "To address the unreliability of benchmark results due to fluctuating evaluation conditions in models like Deepseek-R1-Distill and QwQ-32B.", "method": "Empirical assessments of the Deepseek-R1-Distill series models to identify evaluation inconsistencies.", "result": "Significant fluctuations in benchmark results due to minor evaluation condition changes, making performance claims hard to reproduce.", "conclusion": "A call for a more rigorous evaluation paradigm to ensure reliable and reproducible model performance assessments."}}
{"id": "2506.08338", "pdf": "https://arxiv.org/pdf/2506.08338", "abs": "https://arxiv.org/abs/2506.08338", "authors": ["Ryoichi Asashiba", "Reiji Kozuma", "Hirokazu Iwasawa"], "title": "midr: Learning from Black-Box Models by Maximum Interpretation Decomposition", "categories": ["stat.ME", "cs.LG"], "comment": "20 pages, 10 figures", "summary": "The use of appropriate methods of Interpretable Machine Learning (IML) and\neXplainable Artificial Intelligence (XAI) is essential for adopting black-box\npredictive models in fields where model and prediction explainability is\nrequired. As a novel tool for interpreting black-box models, we introduce the R\npackage midr, which implements Maximum Interpretation Decomposition (MID). MID\nis a functional decomposition approach that derives a low-order additive\nrepresentation of a black-box model by minimizing the squared error between the\nmodel's prediction function and this additive representation. midr enables\nlearning from black-box models by constructing a global surrogate model with\nadvanced analytical capabilities. After reviewing related work and the\ntheoretical foundation of MID, we demonstrate the package's usage and discuss\nsome of its key features.", "AI": {"tldr": "The paper introduces the R package 'midr' for interpretable machine learning, using Maximum Interpretation Decomposition (MID) to create low-order additive representations of black-box models.", "motivation": "Adopting black-box models in fields requiring explainability necessitates interpretable methods like MID.", "method": "MID minimizes squared error between a black-box model's predictions and its additive representation, implemented in the 'midr' package.", "result": "The 'midr' package provides a global surrogate model with advanced analytical capabilities for interpreting black-box models.", "conclusion": "MID and the 'midr' package offer a practical solution for enhancing interpretability in machine learning."}}
{"id": "2503.10354", "pdf": "https://arxiv.org/pdf/2503.10354", "abs": "https://arxiv.org/abs/2503.10354", "authors": ["Nevidu Jayatilleke", "Ruvan Weerasinghe"], "title": "A Hybrid Architecture with Efficient Fine Tuning for Abstractive Patent Document Summarization", "categories": ["cs.CL"], "comment": "Accepted Paper in the 8th International Research Conference on Smart\n  Computing and Systems Engineering, University of Kelaniya, Sri Lanka.\n  (Pending Publication)", "summary": "Automatic patent summarization approaches that help in the patent analysis\nand comprehension procedure are in high demand due to the colossal growth of\ninnovations. The development of natural language processing (NLP), text mining,\nand deep learning has notably amplified the efficacy of text summarization\nmodels for abundant types of documents. Summarizing patent text remains a\npertinent challenge due to the labyrinthine writing style of these documents,\nwhich includes technical and legal intricacies. Additionally, these patent\ndocument contents are considerably lengthier than archetypal documents, which\ncomplicates the process of extracting pertinent information for summarization.\nEmbodying extractive and abstractive text summarization methodologies into a\nhybrid framework, this study proposes a system for efficiently creating\nabstractive summaries of patent records. The procedure involves leveraging the\nLexRank graph-based algorithm to retrieve the important sentences from input\nparent texts, then utilizing a Bidirectional Auto-Regressive Transformer (BART)\nmodel that has been fine-tuned using Low-Ranking Adaptation (LoRA) for\nproducing text summaries. This is accompanied by methodical testing and\nevaluation strategies. Furthermore, the author employed certain meta-learning\ntechniques to achieve Domain Generalization (DG) of the abstractive component\nacross multiple patent fields.", "AI": {"tldr": "The paper proposes a hybrid framework combining extractive and abstractive summarization to efficiently summarize lengthy and complex patent documents, using LexRank and a fine-tuned BART model with LoRA, evaluated with meta-learning for domain generalization.", "motivation": "The need for efficient patent summarization arises from the growing volume of innovations and the complexity of patent documents, which are lengthy and contain technical and legal jargon.", "method": "The study combines extractive (LexRank) and abstractive (fine-tuned BART with LoRA) summarization, with meta-learning for domain generalization across patent fields.", "result": "The proposed hybrid framework effectively generates abstractive summaries of patent records, addressing the challenges of complexity and length.", "conclusion": "The hybrid approach, leveraging advanced NLP techniques, offers a robust solution for patent summarization, with potential applications across diverse patent domains."}}
{"id": "2407.21666", "pdf": "https://arxiv.org/pdf/2407.21666", "abs": "https://arxiv.org/abs/2407.21666", "authors": ["Aswini Kumar Patra", "Ankit Varshney", "Lingaraj Sahoo"], "title": "An Explainable Vision Transformer with Transfer Learning Combined with Support Vector Machine Based Efficient Drought Stress Identification", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.LG"], "comment": "33 pages, 7 figures, 8 tables", "summary": "Early detection of drought stress is critical for taking timely measures for\nreducing crop loss before the drought impact becomes irreversible. The subtle\nphenotypical and physiological changes in response to drought stress are\ncaptured by non-invasive imaging techniques and these imaging data serve as\nvaluable resource for machine learning methods to identify drought stress.\nWhile convolutional neural networks (CNNs) are in wide use, vision transformers\n(ViTs) present a promising alternative in capturing long-range dependencies and\nintricate spatial relationships, thereby enhancing the detection of subtle\nindicators of drought stress. We propose an explainable deep learning pipeline\nthat leverages the power of ViTs for drought stress detection in potato crops\nusing aerial imagery. We applied two distinct approaches: a synergistic\ncombination of ViT and support vector machine (SVM), where ViT extracts\nintricate spatial features from aerial images, and SVM classifies the crops as\nstressed or healthy and an end-to-end approach using a dedicated classification\nlayer within ViT to directly detect drought stress. Our key findings explain\nthe ViT model's decision-making process by visualizing attention maps. These\nmaps highlight the specific spatial features within the aerial images that the\nViT model focuses as the drought stress signature. Our findings demonstrate\nthat the proposed methods not only achieve high accuracy in drought stress\nidentification but also shedding light on the diverse subtle plant features\nassociated with drought stress. This offers a robust and interpretable solution\nfor drought stress monitoring for farmers to undertake informed decisions for\nimproved crop management.", "AI": {"tldr": "The paper proposes an explainable deep learning pipeline using vision transformers (ViTs) for early drought stress detection in potato crops via aerial imagery, achieving high accuracy and interpretability.", "motivation": "Early detection of drought stress is crucial to prevent irreversible crop damage, and subtle phenotypical changes can be captured using non-invasive imaging and machine learning.", "method": "Two approaches are used: a ViT-SVM combination for feature extraction and classification, and an end-to-end ViT with a classification layer. Attention maps visualize the model's focus on drought stress features.", "result": "The methods achieve high accuracy in identifying drought stress and reveal subtle plant features linked to stress, providing interpretable insights.", "conclusion": "The pipeline offers a robust, interpretable solution for farmers to monitor drought stress and make informed crop management decisions."}}
{"id": "2506.05744", "pdf": "https://arxiv.org/pdf/2506.05744", "abs": "https://arxiv.org/abs/2506.05744", "authors": ["Gouki Minegishi", "Hiroki Furuta", "Takeshi Kojima", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Topology of Reasoning: Understanding Large Reasoning Models through Reasoning Graph Properties", "categories": ["cs.AI"], "comment": null, "summary": "Recent large-scale reasoning models have achieved state-of-the-art\nperformance on challenging mathematical benchmarks, yet the internal mechanisms\nunderlying their success remain poorly understood. In this work, we introduce\nthe notion of a reasoning graph, extracted by clustering hidden-state\nrepresentations at each reasoning step, and systematically analyze three key\ngraph-theoretic properties: cyclicity, diameter, and small-world index, across\nmultiple tasks (GSM8K, MATH500, AIME 2024). Our findings reveal that distilled\nreasoning models (e.g., DeepSeek-R1-Distill-Qwen-32B) exhibit significantly\nmore recurrent cycles (about 5 per sample), substantially larger graph\ndiameters, and pronounced small-world characteristics (about 6x) compared to\ntheir base counterparts. Notably, these structural advantages grow with task\ndifficulty and model capacity, with cycle detection peaking at the 14B scale\nand exploration diameter maximized in the 32B variant, correlating positively\nwith accuracy. Furthermore, we show that supervised fine-tuning on an improved\ndataset systematically expands reasoning graph diameters in tandem with\nperformance gains, offering concrete guidelines for dataset design aimed at\nboosting reasoning capabilities. By bridging theoretical insights into\nreasoning graph structures with practical recommendations for data\nconstruction, our work advances both the interpretability and the efficacy of\nlarge reasoning models.", "AI": {"tldr": "The paper analyzes reasoning graphs in large-scale models, revealing structural advantages like cyclicity and small-world properties, which correlate with performance and task difficulty.", "motivation": "To understand the internal mechanisms of large-scale reasoning models by examining their reasoning graph structures.", "method": "Extracts reasoning graphs by clustering hidden-state representations and analyzes graph-theoretic properties (cyclicity, diameter, small-world index) across tasks and model variants.", "result": "Distilled models show more cycles, larger diameters, and small-world traits, correlating with accuracy. Fine-tuning expands diameters and improves performance.", "conclusion": "The study links reasoning graph structures to model performance, offering insights for interpretability and dataset design to enhance reasoning capabilities."}}
{"id": "2506.08362", "pdf": "https://arxiv.org/pdf/2506.08362", "abs": "https://arxiv.org/abs/2506.08362", "authors": ["Lesi Chen", "Chengchang Liu", "Luo Luo", "Jingzhao Zhang"], "title": "Solving Convex-Concave Problems with $\\tilde{\\mathcal{O}}(\u03b5^{-4/7})$ Second-Order Oracle Complexity", "categories": ["math.OC", "cs.LG"], "comment": "COLT 2025", "summary": "Previous algorithms can solve convex-concave minimax problems $\\min_{x \\in\n\\mathcal{X}} \\max_{y \\in \\mathcal{Y}} f(x,y)$ with\n$\\mathcal{O}(\\epsilon^{-2/3})$ second-order oracle calls using Newton-type\nmethods. This result has been speculated to be optimal because the upper bound\nis achieved by a natural generalization of the optimal first-order method. In\nthis work, we show an improved upper bound of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-4/7})$ by generalizing the optimal second-order\nmethod for convex optimization to solve the convex-concave minimax problem. We\nfurther apply a similar technique to lazy Hessian algorithms and show that our\nproposed algorithm can also be seen as a second-order ``Catalyst'' framework\n(Lin et al., JMLR 2018) that could accelerate any globally convergent\nalgorithms for solving minimax problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2503.17739", "pdf": "https://arxiv.org/pdf/2503.17739", "abs": "https://arxiv.org/abs/2503.17739", "authors": ["Chatrine Qwaider", "Bashar Alhafni", "Kirill Chirkunov", "Nizar Habash", "Ted Briscoe"], "title": "Enhancing Arabic Automated Essay Scoring with Synthetic Data and Error Injection", "categories": ["cs.CL"], "comment": null, "summary": "Automated Essay Scoring (AES) plays a crucial role in assessing language\nlearners' writing quality, reducing grading workload, and providing real-time\nfeedback. The lack of annotated essay datasets inhibits the development of\nArabic AES systems. This paper leverages Large Language Models (LLMs) and\nTransformer models to generate synthetic Arabic essays for AES. We prompt an\nLLM to generate essays across the Common European Framework of Reference (CEFR)\nproficiency levels and introduce and compare two approaches to error injection.\nWe create a dataset of 3,040 annotated essays with errors injected using our\ntwo methods. Additionally, we develop a BERT-based Arabic AES system calibrated\nto CEFR levels. Our experimental results demonstrate the effectiveness of our\nsynthetic dataset in improving Arabic AES performance. We make our code and\ndata publicly available.", "AI": {"tldr": "The paper introduces synthetic Arabic essay generation using LLMs and Transformer models for AES, addressing the lack of annotated datasets. It compares two error-injection methods and develops a BERT-based AES system, showing improved performance.", "motivation": "The lack of annotated Arabic essay datasets hinders AES development. This work aims to fill this gap by generating synthetic essays.", "method": "Uses LLMs to generate essays across CEFR levels, introduces two error-injection methods, and develops a BERT-based AES system.", "result": "A dataset of 3,040 annotated essays is created, and the BERT-based AES system shows improved performance.", "conclusion": "Synthetic datasets enhance Arabic AES, and the work provides publicly available code and data."}}
{"id": "2408.11531", "pdf": "https://arxiv.org/pdf/2408.11531", "abs": "https://arxiv.org/abs/2408.11531", "authors": ["Lo\u00efc Denis", "Emanuele Dalsasso", "Florence Tupin"], "title": "Just Project! Multi-Channel Despeckling, the Easy Way", "categories": ["cs.CV", "eess.SP"], "comment": null, "summary": "Reducing speckle fluctuations in multi-channel SAR images is essential in\nmany applications of SAR imaging such as polarimetric classification or\ninterferometric height estimation. While single-channel despeckling has widely\nbenefited from the application of deep learning techniques, extensions to\nmulti-channel SAR images are much more challenging. This paper introduces\nMuChaPro, a generic framework that exploits existing single-channel despeckling\nmethods. The key idea is to generate numerous single-channel projections,\nrestore these projections, and recombine them into the final multi-channel\nestimate. This simple approach is shown to be effective in polarimetric and/or\ninterferometric modalities. A special appeal of MuChaPro is the possibility to\napply a self-supervised training strategy to learn sensor-specific networks for\nsingle-channel despeckling.", "AI": {"tldr": "MuChaPro is a framework for multi-channel SAR image despeckling by leveraging single-channel methods through projections and recombination.", "motivation": "Speckle reduction in multi-channel SAR images is crucial for applications like polarimetric classification and interferometric height estimation, but existing deep learning methods are limited to single-channel.", "method": "MuChaPro generates single-channel projections, applies despeckling, and recombines them into a multi-channel estimate, supporting self-supervised training for sensor-specific networks.", "result": "The framework effectively reduces speckle in polarimetric and interferometric SAR images.", "conclusion": "MuChaPro provides a simple yet effective solution for multi-channel SAR despeckling, with potential for sensor-specific adaptation."}}
{"id": "2506.05981", "pdf": "https://arxiv.org/pdf/2506.05981", "abs": "https://arxiv.org/abs/2506.05981", "authors": ["Qingbin Zeng", "Ruotong Zhao", "Jinzhu Mao", "Haoyang Li", "Fengli Xu", "Yong Li"], "title": "CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents", "categories": ["cs.AI"], "comment": "Typos corrected", "summary": "Modeling urban crime is an important yet challenging task that requires\nunderstanding the subtle visual, social, and cultural cues embedded in urban\nenvironments. Previous work has mainly focused on rule-based agent-based\nmodeling (ABM) and deep learning methods. ABMs offer interpretability of\ninternal mechanisms but exhibit limited predictive accuracy. In contrast, deep\nlearning methods are often effective in prediction but are less interpretable\nand require extensive training data. Moreover, both lines of work lack the\ncognitive flexibility to adapt to changing environments. Leveraging the\ncapabilities of large language models (LLMs), we propose CrimeMind, a novel\nLLM-driven ABM framework for simulating urban crime within a multi-modal urban\ncontext. A key innovation of our design is the integration of the Routine\nActivity Theory (RAT) into the agentic workflow of CrimeMind, enabling it to\nprocess rich multi-modal urban features and reason about criminal behavior.\nHowever, RAT requires LLM agents to infer subtle cues in evaluating\nenvironmental safety as part of assessing guardianship, which can be\nchallenging for LLMs. To address this, we collect a small-scale human-annotated\ndataset and align CrimeMind's perception with human judgment via a\ntraining-free textual gradient method. Experiments across four major U.S.\ncities demonstrate that CrimeMind outperforms both traditional ABMs and deep\nlearning baselines in crime hotspot prediction and spatial distribution\naccuracy, achieving up to a 24% improvement over the strongest baseline.\nFurthermore, we conduct counterfactual simulations of external incidents and\npolicy interventions and it successfully captures the expected changes in crime\npatterns, demonstrating its ability to reflect counterfactual scenarios.\nOverall, CrimeMind enables fine-grained modeling of individual behaviors and\nfacilitates evaluation of real-world interventions.", "AI": {"tldr": "CrimeMind is an LLM-driven ABM framework integrating Routine Activity Theory for urban crime simulation, outperforming traditional methods in accuracy and adaptability.", "motivation": "Existing methods (ABMs and deep learning) lack predictive accuracy, interpretability, and adaptability to changing urban environments.", "method": "Combines LLMs with ABM, integrates Routine Activity Theory, and aligns perception with human judgment using a training-free textual gradient method.", "result": "Achieves up to 24% improvement in crime hotspot prediction and accurately simulates counterfactual scenarios.", "conclusion": "CrimeMind offers fine-grained, interpretable crime modeling and effective evaluation of real-world interventions."}}
{"id": "2506.08381", "pdf": "https://arxiv.org/pdf/2506.08381", "abs": "https://arxiv.org/abs/2506.08381", "authors": ["He Yang", "Fei Ren", "Hai-Sui Yu", "Xueyu Geng", "Pei-Zhi Zhuang"], "title": "TS-PIELM: Time-Stepping Physics-Informed Extreme Learning Machine Facilitates Soil Consolidation Analyses", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "Accuracy and efficiency of the conventional physics-informed neural network\n(PINN) need to be improved before it can be a competitive alternative for soil\nconsolidation analyses. This paper aims to overcome these limitations by\nproposing a highly accurate and efficient physics-informed machine learning\n(PIML) approach, termed time-stepping physics-informed extreme learning machine\n(TS-PIELM). In the TS-PIELM framework the consolidation process is divided into\nnumerous time intervals, which helps overcome the limitation of PIELM in\nsolving differential equations with sharp gradients. To accelerate network\ntraining, the solution is approximated by a single-layer feedforward extreme\nlearning machine (ELM), rather than using a fully connected neural network in\nPINN. The input layer weights of the ELM network are generated randomly and\nfixed during the training process. Subsequently, the output layer weights are\ndirectly computed by solving a system of linear equations, which significantly\nenhances the training efficiency compared to the time-consuming gradient\ndescent method in PINN. Finally, the superior performance of TS-PIELM is\ndemonstrated by solving three typical Terzaghi consolidation problems. Compared\nto PINN, results show that the computational efficiency and accuracy of the\nnovel TS-PIELM framework are improved by more than 1000 times and 100 times for\none-dimensional cases, respectively. This paper provides compelling evidence\nthat PIML can be a powerful tool for computational geotechnics.", "AI": {"tldr": "The paper proposes TS-PIELM, a time-stepping physics-informed extreme learning machine, to improve accuracy and efficiency in soil consolidation analyses compared to conventional PINN.", "motivation": "Overcoming the limitations of PINN in accuracy and efficiency for soil consolidation analyses.", "method": "Divides consolidation into time intervals, uses single-layer ELM with random fixed input weights, and computes output weights via linear equations.", "result": "TS-PIELM improves computational efficiency by 1000x and accuracy by 100x over PINN in 1D cases.", "conclusion": "PIML, exemplified by TS-PIELM, is a powerful tool for computational geotechnics."}}
{"id": "2504.19267", "pdf": "https://arxiv.org/pdf/2504.19267", "abs": "https://arxiv.org/abs/2504.19267", "authors": ["Mohamed Gado", "Towhid Taliee", "Muhammad Memon", "Dmitry Ignatov", "Radu Timofte"], "title": "VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Visual storytelling is an interdisciplinary field combining computer vision\nand natural language processing to generate cohesive narratives from sequences\nof images. This paper presents a novel approach that leverages recent\nadvancements in multimodal models, specifically adapting transformer-based\narchitectures and large multimodal models, for the visual storytelling task.\nLeveraging the large-scale Visual Storytelling (VIST) dataset, our VIST-GPT\nmodel produces visually grounded, contextually appropriate narratives. We\naddress the limitations of traditional evaluation metrics, such as BLEU,\nMETEOR, ROUGE, and CIDEr, which are not suitable for this task. Instead, we\nutilize RoViST and GROOVIST, novel reference-free metrics designed to assess\nvisual storytelling, focusing on visual grounding, coherence, and\nnon-redundancy. These metrics provide a more nuanced evaluation of narrative\nquality, aligning closely with human judgment.", "AI": {"tldr": "The paper introduces VIST-GPT, a transformer-based model for visual storytelling, using novel metrics (RoViST and GROOVIST) to better evaluate narrative quality.", "motivation": "Traditional metrics like BLEU and CIDEr are inadequate for visual storytelling, prompting the need for better evaluation methods and improved models.", "method": "The VIST-GPT model leverages transformer-based architectures and large multimodal models, trained on the VIST dataset.", "result": "VIST-GPT generates visually grounded, coherent narratives, evaluated using RoViST and GROOVIST metrics.", "conclusion": "The proposed model and metrics offer a more nuanced and human-aligned evaluation of visual storytelling."}}
{"id": "2408.17059", "pdf": "https://arxiv.org/pdf/2408.17059", "abs": "https://arxiv.org/abs/2408.17059", "authors": ["Asifullah Khan", "Anabia Sohail", "Mustansar Fiaz", "Mehdi Hassan", "Tariq Habib Afridi", "Sibghat Ullah Marwat", "Farzeen Munir", "Safdar Ali", "Hannan Naseem", "Muhammad Zaigham Zaheer", "Kamran Ali", "Tangina Sultana", "Ziaurrehman Tanoli", "Naeem Akhter"], "title": "A Survey of the Self Supervised Learning Mechanisms for Vision Transformers", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "40 Pages, 4 Figures, 7 Tables", "summary": "Vision Transformers (ViTs) have recently demonstrated remarkable performance\nin computer vision tasks. However, their parameter-intensive nature and\nreliance on large amounts of data for effective performance have shifted the\nfocus from traditional human-annotated labels to unsupervised learning and\npretraining strategies that uncover hidden structures within the data. In\nresponse to this challenge, self-supervised learning (SSL) has emerged as a\npromising paradigm. SSL leverages inherent relationships within the data itself\nas a form of supervision, eliminating the need for manual labeling and offering\na more scalable and resource-efficient alternative for model training. Given\nthese advantages, it is imperative to explore the integration of SSL techniques\nwith ViTs, particularly in scenarios with limited labeled data. Inspired by\nthis evolving trend, this survey aims to systematically review SSL mechanisms\ntailored for ViTs. We propose a comprehensive taxonomy to classify SSL\ntechniques based on their representations and pre-training tasks. Additionally,\nwe discuss the motivations behind SSL, review prominent pre-training tasks, and\nhighlight advancements and challenges in this field. Furthermore, we conduct a\ncomparative analysis of various SSL methods designed for ViTs, evaluating their\nstrengths, limitations, and applicability to different scenarios.", "AI": {"tldr": "The paper surveys self-supervised learning (SSL) techniques for Vision Transformers (ViTs), proposing a taxonomy, reviewing tasks, and comparing methods to address data and parameter challenges.", "motivation": "ViTs' reliance on large labeled datasets and parameter intensity motivates exploring SSL as a scalable, label-free alternative for training.", "method": "The survey systematically reviews SSL mechanisms for ViTs, classifying techniques by representations and pre-training tasks, and comparing methods.", "result": "A taxonomy for SSL techniques is proposed, and advancements, challenges, and comparative strengths of SSL methods for ViTs are highlighted.", "conclusion": "SSL integration with ViTs offers a promising, resource-efficient solution for limited labeled data scenarios, with ongoing challenges and opportunities for advancement."}}
{"id": "2506.06285", "pdf": "https://arxiv.org/pdf/2506.06285", "abs": "https://arxiv.org/abs/2506.06285", "authors": ["Kaike Sa Teles Rocha Alves", "Eduardo Pestana de Aguiar"], "title": "NFISiS: New Perspectives on Fuzzy Inference Systems for Renewable Energy Forecasting", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models, despite their popularity, face challenges such as long\ntraining times and a lack of interpretability. In contrast, fuzzy inference\nsystems offer a balance of accuracy and transparency. This paper addresses the\nlimitations of traditional Takagi-Sugeno-Kang fuzzy models by extending the\nrecently proposed New Takagi-Sugeno-Kang model to a new Mamdani-based\nregressor. These models are data-driven, allowing users to define the number of\nrules to balance accuracy and interpretability. To handle the complexity of\nlarge datasets, this research integrates wrapper and ensemble techniques. A\nGenetic Algorithm is used as a wrapper for feature selection, creating genetic\nversions of the models. Furthermore, ensemble models, including the Random New\nMamdani Regressor, Random New Takagi-Sugeno-Kang, and Random Forest New\nTakagi-Sugeno-Kang, are introduced to improve robustness. The proposed models\nare validated on photovoltaic energy forecasting datasets, a critical\napplication due to the intermittent nature of solar power. Results demonstrate\nthat the genetic and ensemble fuzzy models, particularly the Genetic New\nTakagi-Sugeno-Kang and Random Forest New Takagi-Sugeno-Kang, achieve superior\nperformance. They often outperform both traditional machine learning and deep\nlearning models while providing a simpler and more interpretable rule-based\nstructure. The models are available online in a library called nfisis\n(https://pypi.org/project/nfisis/).", "AI": {"tldr": "The paper proposes genetic and ensemble fuzzy models to address deep learning's training time and interpretability issues, achieving superior performance in photovoltaic energy forecasting.", "motivation": "Deep learning models suffer from long training times and lack of interpretability, while fuzzy systems offer a balance of accuracy and transparency.", "method": "Extends the New Takagi-Sugeno-Kang model to a Mamdani-based regressor, integrates wrapper and ensemble techniques (Genetic Algorithm for feature selection), and introduces ensemble models like Random New Mamdani Regressor.", "result": "Genetic and ensemble fuzzy models outperform traditional machine learning and deep learning in photovoltaic energy forecasting, with simpler, interpretable rule-based structures.", "conclusion": "The proposed fuzzy models provide a robust, interpretable alternative to deep learning, validated on real-world datasets and available in the nfisis library."}}
{"id": "2506.08423", "pdf": "https://arxiv.org/pdf/2506.08423", "abs": "https://arxiv.org/abs/2506.08423", "authors": ["Utkarsh Pratiush", "Austin Houston", "Kamyar Barakati", "Aditya Raghavan", "Dasol Yoon", "Harikrishnan KP", "Zhaslan Baraissov", "Desheng Ma", "Samuel S. Welborn", "Mikolaj Jakowski", "Shawn-Patrick Barhorst", "Alexander J. Pattison", "Panayotis Manganaris", "Sita Sirisha Madugula", "Sai Venkata Gayathri Ayyagari", "Vishal Kennedy", "Ralph Bulanadi", "Michelle Wang", "Kieran J. Pang", "Ian Addison-Smith", "Willy Menacho", "Horacio V. Guzman", "Alexander Kiefer", "Nicholas Furth", "Nikola L. Kolev", "Mikhail Petrov", "Viktoriia Liu", "Sergey Ilyev", "Srikar Rairao", "Tommaso Rodani", "Ivan Pinto-Huguet", "Xuli Chen", "Josep Crua\u00f1es", "Marta Torrens", "Jovan Pomar", "Fanzhi Su", "Pawan Vedanti", "Zhiheng Lyu", "Xingzhi Wang", "Lehan Yao", "Amir Taqieddin", "Forrest Laskowski", "Xiangyu Yin", "Yu-Tsun Shao", "Benjamin Fein-Ashley", "Yi Jiang", "Vineet Kumar", "Himanshu Mishra", "Yogesh Paul", "Adib Bazgir", "Rama chandra Praneeth Madugula", "Yuwen Zhang", "Pravan Omprakash", "Jian Huang", "Eric Montufar-Morales", "Vivek Chawla", "Harshit Sethi", "Jie Huang", "Lauri Kurki", "Grace Guinan", "Addison Salvador", "Arman Ter-Petrosyan", "Madeline Van Winkle", "Steven R. Spurgeon", "Ganesh Narasimha", "Zijie Wu", "Richard Liu", "Yongtao Liu", "Boris Slautin", "Andrew R Lupini", "Rama Vasudevan", "Gerd Duscher", "Sergei V. Kalinin"], "title": "Mic-hackathon 2024: Hackathon on Machine Learning for Electron and Scanning Probe Microscopy", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.ins-det"], "comment": null, "summary": "Microscopy is a primary source of information on materials structure and\nfunctionality at nanometer and atomic scales. The data generated is often\nwell-structured, enriched with metadata and sample histories, though not always\nconsistent in detail or format. The adoption of Data Management Plans (DMPs) by\nmajor funding agencies promotes preservation and access. However, deriving\ninsights remains difficult due to the lack of standardized code ecosystems,\nbenchmarks, and integration strategies. As a result, data usage is inefficient\nand analysis time is extensive. In addition to post-acquisition analysis, new\nAPIs from major microscope manufacturers enable real-time, ML-based analytics\nfor automated decision-making and ML-agent-controlled microscope operation.\nYet, a gap remains between the ML and microscopy communities, limiting the\nimpact of these methods on physics, materials discovery, and optimization.\nHackathons help bridge this divide by fostering collaboration between ML\nresearchers and microscopy experts. They encourage the development of novel\nsolutions that apply ML to microscopy, while preparing a future workforce for\ninstrumentation, materials science, and applied ML. This hackathon produced\nbenchmark datasets and digital twins of microscopes to support community growth\nand standardized workflows. All related code is available at GitHub:\nhttps://github.com/KalininGroup/Mic-hackathon-2024-codes-publication/tree/1.0.0.1", "AI": {"tldr": "The paper discusses challenges in microscopy data analysis due to lack of standardization and integration, highlights the role of hackathons in bridging ML and microscopy communities, and presents outcomes like benchmark datasets and digital twins.", "motivation": "The motivation is to address inefficiencies in microscopy data analysis and the gap between ML and microscopy communities, aiming to enhance insights and automation in materials science.", "method": "The method involves organizing hackathons to foster collaboration between ML researchers and microscopy experts, developing standardized tools, and creating benchmark datasets and digital twins.", "result": "The hackathon produced benchmark datasets, digital twins of microscopes, and open-source code, fostering community growth and standardized workflows.", "conclusion": "Hackathons are effective in bridging ML and microscopy, enabling innovative solutions and preparing a skilled workforce for future challenges in materials science and applied ML."}}
{"id": "2504.21299", "pdf": "https://arxiv.org/pdf/2504.21299", "abs": "https://arxiv.org/abs/2504.21299", "authors": ["Zhiting Fan", "Ruizhe Chen", "Zuozhu Liu"], "title": "BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models", "categories": ["cs.CL"], "comment": "ACL 2025 findings", "summary": "Identifying bias in LLM-generated content is a crucial prerequisite for\nensuring fairness in LLMs. Existing methods, such as fairness classifiers and\nLLM-based judges, face limitations related to difficulties in understanding\nunderlying intentions and the lack of criteria for fairness judgment. In this\npaper, we introduce BiasGuard, a novel bias detection tool that explicitly\nanalyzes inputs and reasons through fairness specifications to provide accurate\njudgments. BiasGuard is implemented through a two-stage approach: the first\nstage initializes the model to explicitly reason based on fairness\nspecifications, while the second stage leverages reinforcement learning to\nenhance its reasoning and judgment capabilities. Our experiments, conducted\nacross five datasets, demonstrate that BiasGuard outperforms existing tools,\nimproving accuracy and reducing over-fairness misjudgments. We also highlight\nthe importance of reasoning-enhanced decision-making and provide evidence for\nthe effectiveness of our two-stage optimization pipeline.", "AI": {"tldr": "BiasGuard, a two-stage bias detection tool for LLMs, improves accuracy and reduces misjudgments by reasoning through fairness specifications and using reinforcement learning.", "motivation": "Addressing limitations of existing methods (fairness classifiers, LLM-based judges) in understanding intentions and lacking fairness criteria.", "method": "Two-stage approach: (1) explicit reasoning based on fairness specifications, (2) reinforcement learning to enhance reasoning and judgment.", "result": "Outperforms existing tools across five datasets, improving accuracy and reducing over-fairness misjudgments.", "conclusion": "BiasGuard demonstrates the effectiveness of reasoning-enhanced decision-making and the two-stage optimization pipeline."}}
{"id": "2410.14669", "pdf": "https://arxiv.org/pdf/2410.14669", "abs": "https://arxiv.org/abs/2410.14669", "authors": ["Baiqi Li", "Zhiqiu Lin", "Wenxuan Peng", "Jean de Dieu Nyandwi", "Daniel Jiang", "Zixian Ma", "Simran Khanuja", "Ranjay Krishna", "Graham Neubig", "Deva Ramanan"], "title": "NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted to NeurIPS 24; We open-source our dataset at:\n  https://huggingface.co/datasets/BaiqiL/NaturalBench ; Project page at:\n  https://linzhiqiu.github.io/papers/naturalbench/", "summary": "Vision-language models (VLMs) have made significant progress in recent\nvisual-question-answering (VQA) benchmarks that evaluate complex\nvisio-linguistic reasoning. However, are these models truly effective? In this\nwork, we show that VLMs still struggle with natural images and questions that\nhumans can easily answer, which we term natural adversarial samples. We also\nfind it surprisingly easy to generate these VQA samples from natural image-text\ncorpora using off-the-shelf models like CLIP and ChatGPT. We propose a\nsemi-automated approach to collect a new benchmark, NaturalBench, for reliably\nevaluating VLMs with 10,000 human-verified VQA samples. Crucially, we adopt a\n$\\textbf{vision-centric}$ design by pairing each question with two images that\nyield different answers, preventing blind solutions from answering without\nusing the images. This makes NaturalBench more challenging than previous\nbenchmarks that can be solved with commonsense priors. We evaluate 53\nstate-of-the-art VLMs on NaturalBench, showing that models like\nLLaVA-OneVision, Cambrian-1, Llama3.2-Vision, Molmo, Qwen2-VL, and even GPT-4o\nlag 50%-70% behind human performance (over 90%). We analyze why NaturalBench is\nhard from two angles: (1) Compositionality: Solving NaturalBench requires\ndiverse visio-linguistic skills, including understanding attribute bindings,\nobject relationships, and advanced reasoning like logic and counting. To this\nend, unlike prior work that uses a single tag per sample, we tag each\nNaturalBench sample with 1 to 8 skill tags for fine-grained evaluation. (2)\nBiases: NaturalBench exposes severe biases in VLMs, as models often choose the\nsame answer regardless of the image. Lastly, we apply our benchmark curation\nmethod to diverse data sources, including long captions (over 100 words) and\nnon-English languages like Chinese and Hindi, highlighting its potential for\ndynamic evaluations of VLMs.", "AI": {"tldr": "VLMs struggle with natural adversarial samples, prompting the creation of NaturalBench, a challenging benchmark revealing significant performance gaps between models and humans.", "motivation": "To assess the true effectiveness of VLMs by identifying their limitations in handling natural adversarial samples and biases.", "method": "A semi-automated approach using CLIP and ChatGPT to generate and verify 10,000 VQA samples, paired with vision-centric design for robust evaluation.", "result": "State-of-the-art VLMs lag 50%-70% behind human performance (over 90%) on NaturalBench, highlighting biases and compositional challenges.", "conclusion": "NaturalBench exposes critical weaknesses in VLMs, emphasizing the need for diverse skills and unbiased evaluations in future model development."}}
{"id": "2506.06905", "pdf": "https://arxiv.org/pdf/2506.06905", "abs": "https://arxiv.org/abs/2506.06905", "authors": ["Akash Gupta", "Amos Storkey", "Mirella Lapata"], "title": "Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to\nperform new tasks with minimal supervision. However, ICL performance,\nespecially in smaller LMMs, is inconsistent and does not always improve\nmonotonically with increasing examples. We hypothesize that this occurs due to\nthe LMM being overwhelmed by additional information present in the image\nembeddings, which is not required for the downstream task. To address this, we\npropose a meta-learning approach that provides an alternative for inducing\nfew-shot capabilities in LMMs, using a fixed set of soft prompts that are\ndistilled from task-relevant image features and can be adapted at test time\nusing a few examples. To facilitate this distillation, we introduce an\nattention-mapper module that can be easily integrated with the popular LLaVA\nv1.5 architecture and is jointly learned with soft prompts, enabling task\nadaptation in LMMs under low-data regimes with just a few gradient steps.\nEvaluation on the VL-ICL Bench shows that our method consistently outperforms\nICL and related prompt-tuning approaches, even under image perturbations,\nimproving task induction and reasoning across visual question answering tasks.", "AI": {"tldr": "The paper proposes a meta-learning approach using soft prompts distilled from task-relevant image features to improve few-shot learning in Large Multimodal Models (LMMs), outperforming in-context learning (ICL) and prompt-tuning methods.", "motivation": "Inconsistent ICL performance in smaller LMMs due to overwhelming image embeddings led to the need for a better few-shot learning method.", "method": "A meta-learning approach with soft prompts and an attention-mapper module, integrated with LLaVA v1.5, enables task adaptation with minimal examples.", "result": "The method outperforms ICL and prompt-tuning on the VL-ICL Bench, even under image perturbations, enhancing task induction and reasoning.", "conclusion": "The proposed approach effectively addresses ICL limitations, improving few-shot learning in LMMs with task-adapted soft prompts."}}
{"id": "2506.08428", "pdf": "https://arxiv.org/pdf/2506.08428", "abs": "https://arxiv.org/abs/2506.08428", "authors": ["Evan Markou", "Thalaiyasingam Ajanthan", "Stephen Gould"], "title": "Sharper Convergence Rates for Nonconvex Optimisation via Reduction Mappings", "categories": ["math.OC", "cs.LG"], "comment": "37 pages, 5 figures", "summary": "Many high-dimensional optimisation problems exhibit rich geometric structures\nin their set of minimisers, often forming smooth manifolds due to\nover-parametrisation or symmetries. When this structure is known, at least\nlocally, it can be exploited through reduction mappings that reparametrise part\nof the parameter space to lie on the solution manifold. These reductions\nnaturally arise from inner optimisation problems and effectively remove\nredundant directions, yielding a lower-dimensional objective. In this work, we\nintroduce a general framework to understand how such reductions influence the\noptimisation landscape. We show that well-designed reduction mappings improve\ncurvature properties of the objective, leading to better-conditioned problems\nand theoretically faster convergence for gradient-based methods. Our analysis\nunifies a range of scenarios where structural information at optimality is\nleveraged to accelerate convergence, offering a principled explanation for the\nempirical gains observed in such optimisation algorithms.", "AI": {"tldr": "The paper introduces a framework for leveraging geometric structures in high-dimensional optimization problems to improve convergence by using reduction mappings.", "motivation": "High-dimensional optimization problems often have minimizers forming smooth manifolds due to over-parametrization or symmetries. Exploiting this structure can enhance optimization efficiency.", "method": "The authors propose reduction mappings that reparametrize the parameter space to lie on the solution manifold, removing redundant directions and improving curvature properties.", "result": "Well-designed reduction mappings improve problem conditioning and theoretically accelerate convergence for gradient-based methods.", "conclusion": "The framework unifies scenarios where structural information accelerates convergence, explaining empirical gains in optimization algorithms."}}
{"id": "2505.01015", "pdf": "https://arxiv.org/pdf/2505.01015", "abs": "https://arxiv.org/abs/2505.01015", "authors": ["Jongwook Han", "Dongmin Choi", "Woojung Song", "Eun-Ju Lee", "Yohan Jo"], "title": "Value Portrait: Assessing Language Models' Values through Psychometrically and Ecologically Valid Items", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "This paper has been accepted for publication at ACL 2025", "summary": "The importance of benchmarks for assessing the values of language models has\nbeen pronounced due to the growing need of more authentic, human-aligned\nresponses. However, existing benchmarks rely on human or machine annotations\nthat are vulnerable to value-related biases. Furthermore, the tested scenarios\noften diverge from real-world contexts in which models are commonly used to\ngenerate text and express values. To address these issues, we propose the Value\nPortrait benchmark, a reliable framework for evaluating LLMs' value\norientations with two key characteristics. First, the benchmark consists of\nitems that capture real-life user-LLM interactions, enhancing the relevance of\nassessment results to real-world LLM usage. Second, each item is rated by human\nsubjects based on its similarity to their own thoughts, and correlations\nbetween these ratings and the subjects' actual value scores are derived. This\npsychometrically validated approach ensures that items strongly correlated with\nspecific values serve as reliable items for assessing those values. Through\nevaluating 44 LLMs with our benchmark, we find that these models prioritize\nBenevolence, Security, and Self-Direction values while placing less emphasis on\nTradition, Power, and Achievement values. Also, our analysis reveals biases in\nhow LLMs perceive various demographic groups, deviating from real human data.", "AI": {"tldr": "The paper introduces the Value Portrait benchmark to assess language models' value orientations, addressing biases in existing benchmarks by using real-life interactions and psychometric validation.", "motivation": "Existing benchmarks for language models are biased and lack real-world relevance, prompting the need for a more authentic and reliable evaluation framework.", "method": "The Value Portrait benchmark uses real-life user-LLM interactions and human ratings to correlate responses with actual value scores, ensuring psychometric validity.", "result": "Evaluation of 44 LLMs showed prioritization of Benevolence, Security, and Self-Direction values, with biases in demographic group perceptions compared to human data.", "conclusion": "The Value Portrait benchmark provides a reliable, real-world-aligned method for assessing LLM values, revealing biases and value emphases in current models."}}
{"id": "2410.16267", "pdf": "https://arxiv.org/pdf/2410.16267", "abs": "https://arxiv.org/abs/2410.16267", "authors": ["Michael S. Ryoo", "Honglu Zhou", "Shrikant Kendre", "Can Qin", "Le Xue", "Manli Shu", "Jongwoo Park", "Kanchana Ranasinghe", "Silvio Savarese", "Ran Xu", "Caiming Xiong", "Juan Carlos Niebles"], "title": "xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html", "AI": {"tldr": "BLIP-3-Video is a multimodal language model for videos that efficiently captures temporal information using fewer visual tokens than competitors.", "motivation": "To improve video understanding by efficiently processing temporal information across multiple frames with fewer visual tokens.", "method": "Uses a 'temporal encoder' alongside a visual tokenizer to map sequences of frames into compact visual tokens. Explores spatio-temporal pooling and sequential models like Token Turing Machines.", "result": "Achieves video question-answering accuracy comparable to larger models (34B) while being smaller (4B) and more efficient.", "conclusion": "BLIP-3-Video is a compact, efficient model for video understanding, matching larger models' performance with fewer resources."}}
{"id": "2506.07553", "pdf": "https://arxiv.org/pdf/2506.07553", "abs": "https://arxiv.org/abs/2506.07553", "authors": ["Jingchao Wang", "Haote Yang", "Jiang Wu", "Yifan He", "Xingjian Wei", "Yinfan Wang", "Chengjin Liu", "Lingli Ge", "Lijun Wu", "Bin Wang", "Dahua Lin", "Conghui He"], "title": "GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition", "categories": ["cs.AI", "q-bio.QM"], "comment": null, "summary": "Optical Chemical Structure Recognition (OCSR) is crucial for digitizing\nchemical knowledge by converting molecular images into machine-readable\nformats. While recent vision-language models (VLMs) have shown potential in\nthis task, their image-captioning approach often struggles with complex\nmolecular structures and inconsistent annotations. To overcome these\nchallenges, we introduce GTR-Mol-VLM, a novel framework featuring two key\ninnovations: (1) the Graph Traversal as Visual Chain of Thought mechanism that\nemulates human reasoning by incrementally parsing molecular graphs through\nsequential atom-bond predictions, and (2) the data-centric principle of\nFaithfully Recognize What You've Seen, which addresses the mismatch between\nabbreviated structures in images and their expanded annotations. To support\nmodel development, we constructed GTR-CoT-1.3M, a large-scale\ninstruction-tuning dataset with meticulously corrected annotations, and\nintroduced MolRec-Bench, the first benchmark designed for a fine-grained\nevaluation of graph-parsing accuracy in OCSR. Comprehensive experiments\ndemonstrate that GTR-Mol-VLM achieves superior results compared to specialist\nmodels, chemistry-domain VLMs, and commercial general-purpose VLMs. Notably, in\nscenarios involving molecular images with functional group abbreviations,\nGTR-Mol-VLM outperforms the second-best baseline by approximately 14 percentage\npoints, both in SMILES-based and graph-based metrics. We hope that this work\nwill drive OCSR technology to more effectively meet real-world needs, thereby\nadvancing the fields of cheminformatics and AI for Science. We will release\nGTR-CoT at https://github.com/opendatalab/GTR-CoT.", "AI": {"tldr": "GTR-Mol-VLM, a novel framework for Optical Chemical Structure Recognition (OCSR), improves accuracy by emulating human reasoning and addressing annotation mismatches, outperforming existing models.", "motivation": "To overcome limitations of vision-language models (VLMs) in handling complex molecular structures and inconsistent annotations in OCSR.", "method": "Introduces Graph Traversal as Visual Chain of Thought and a data-centric principle for faithful recognition, supported by a large-scale dataset (GTR-CoT-1.3M) and a benchmark (MolRec-Bench).", "result": "GTR-Mol-VLM outperforms specialist models and VLMs, especially in handling abbreviated structures, by ~14 percentage points.", "conclusion": "The framework advances OCSR technology, benefiting cheminformatics and AI for Science, with plans to release the dataset publicly."}}
{"id": "2506.08448", "pdf": "https://arxiv.org/pdf/2506.08448", "abs": "https://arxiv.org/abs/2506.08448", "authors": ["Hyakka Nakada", "Shu Tanaka"], "title": "Systematic and Efficient Construction of Quadratic Unconstrained Binary Optimization Forms for High-order and Dense Interactions", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum Annealing (QA) can efficiently solve combinatorial optimization\nproblems whose objective functions are represented by Quadratic Unconstrained\nBinary Optimization (QUBO) formulations. For broader applicability of QA,\nquadratization methods are used to transform higher-order problems into QUBOs.\nHowever, quadratization methods for complex problems involving Machine Learning\n(ML) remain largely unknown. In these problems, strong nonlinearity and dense\ninteractions prevent conventional methods from being applied. Therefore, we\nmodel target functions by the sum of rectified linear unit bases, which not\nonly have the ability of universal approximation, but also have an equivalent\nquadratic-polynomial representation. In this study, the proof of concept is\nverified both numerically and analytically. In addition, by combining QA with\nthe proposed quadratization, we design a new black-box optimization scheme, in\nwhich ML surrogate regressors are inputted to QA after the quadratization\nprocess.", "AI": {"tldr": "The paper explores quadratization methods for higher-order problems in ML using QA, proposing a rectified linear unit basis approach and a new black-box optimization scheme.", "motivation": "To extend QA's applicability to complex ML problems with strong nonlinearity and dense interactions, which conventional quadratization methods cannot handle.", "method": "Model target functions using rectified linear unit bases, which allow universal approximation and equivalent quadratic-polynomial representation, and integrate QA with this quadratization.", "result": "Proof of concept is verified numerically and analytically, and a new black-box optimization scheme combining QA and quadratization is designed.", "conclusion": "The proposed method successfully addresses quadratization challenges in ML problems, enabling broader QA applications."}}
{"id": "2505.03452", "pdf": "https://arxiv.org/pdf/2505.03452", "abs": "https://arxiv.org/abs/2505.03452", "authors": ["Matan Orbach", "Ohad Eytan", "Benjamin Sznajder", "Ariel Gera", "Odellia Boni", "Yoav Kantor", "Gal Bloch", "Omri Levy", "Hadas Abraham", "Nitzan Barzilay", "Eyal Shnarch", "Michael E. Factor", "Shila Ofek-Koifman", "Paula Ta-Shma", "Assaf Toledo"], "title": "An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Finding the optimal Retrieval-Augmented Generation (RAG) configuration for a\ngiven use case can be complex and expensive. Motivated by this challenge,\nframeworks for RAG hyper-parameter optimization (HPO) have recently emerged,\nyet their effectiveness has not been rigorously benchmarked. To address this\ngap, we present a comprehensive study involving 5 HPO algorithms over 5\ndatasets from diverse domains, including a new one collected for this work on\nreal-world product documentation. Our study explores the largest HPO search\nspace considered to date, with three evaluation metrics as optimization\ntargets. Analysis of the results shows that RAG HPO can be done efficiently,\neither greedily or with random search, and that it significantly boosts RAG\nperformance for all datasets. For greedy HPO approaches, we show that\noptimizing model selection first is preferable to the prevalent practice of\noptimizing according to RAG pipeline order.", "AI": {"tldr": "The paper benchmarks RAG hyper-parameter optimization (HPO) methods, showing greedy or random search can efficiently boost performance, with model selection prioritized over pipeline order.", "motivation": "The complexity and cost of finding optimal RAG configurations motivated the study of HPO frameworks, whose effectiveness lacked rigorous benchmarking.", "method": "The study evaluates 5 HPO algorithms across 5 diverse datasets, including a new real-world product documentation dataset, using the largest HPO search space to date and three metrics.", "result": "RAG HPO is efficient with greedy or random search, significantly improving performance across all datasets. Greedy HPO benefits from prioritizing model selection over pipeline order.", "conclusion": "Efficient RAG HPO is achievable, with greedy approaches favoring model selection optimization first, outperforming traditional pipeline-order methods."}}
{"id": "2410.18074", "pdf": "https://arxiv.org/pdf/2410.18074", "abs": "https://arxiv.org/abs/2410.18074", "authors": ["Xien Chen", "Rit Gangopadhyay", "Michael Chu", "Patrick Rim", "Hyoungseob Park", "Alex Wong"], "title": "UnCLe: Benchmarking Unsupervised Continual Learning for Depth Completion", "categories": ["cs.CV", "cs.LG"], "comment": "Preprint", "summary": "We propose UnCLe, the first standardized benchmark for Unsupervised Continual\nLearning of a multimodal 3D reconstruction task: Depth completion aims to infer\na dense depth map from a pair of synchronized RGB image and sparse depth map.\nWe benchmark depth completion models under the practical scenario of\nunsupervised learning over continuous streams of data. While unsupervised\nlearning of depth boasts the possibility continual learning of novel data\ndistributions over time, existing methods are typically trained on a static, or\nstationary, dataset. However, when adapting to novel nonstationary\ndistributions, they ``catastrophically forget'' previously learned information.\nUnCLe simulates these non-stationary distributions by adapting depth completion\nmodels to sequences of datasets containing diverse scenes captured from\ndistinct domains using different visual and range sensors. We adopt\nrepresentative methods from continual learning paradigms and translate them to\nenable unsupervised continual learning of depth completion. We benchmark these\nmodels across indoor and outdoor environments, and investigate the degree of\ncatastrophic forgetting through standard quantitative metrics. We find that\nunsupervised continual learning of depth completion is an open problem, and we\ninvite researchers to leverage UnCLe as a development platform.", "AI": {"tldr": "UnCLe is the first benchmark for unsupervised continual learning in multimodal 3D reconstruction, focusing on depth completion. It addresses catastrophic forgetting in nonstationary data distributions and invites further research.", "motivation": "Existing depth completion methods fail in unsupervised continual learning due to catastrophic forgetting when adapting to nonstationary data. UnCLe aims to standardize benchmarking for this challenge.", "method": "UnCLe adapts depth completion models to sequences of diverse datasets, simulating nonstationary distributions. It employs continual learning paradigms for unsupervised learning.", "result": "Benchmarking reveals catastrophic forgetting in current methods, highlighting the open problem of unsupervised continual learning in depth completion.", "conclusion": "UnCLe serves as a platform for advancing research in unsupervised continual learning for depth completion, addressing a critical gap in the field."}}
{"id": "2506.07564", "pdf": "https://arxiv.org/pdf/2506.07564", "abs": "https://arxiv.org/abs/2506.07564", "authors": ["Peiran Li", "Xinkai Zou", "Zhuohang Wu", "Ruifeng Li", "Shuo Xing", "Hanwen Zheng", "Zhikai Hu", "Yuping Wang", "Haoxi Li", "Qin Yuan", "Yingmo Zhang", "Zhengzhong Tu"], "title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in large language models (LLMs) and vision-language models\n(VLMs) have enabled powerful autonomous agents capable of complex reasoning and\nmulti-modal tool use. Despite their growing capabilities, today's agent\nframeworks remain fragile, lacking principled mechanisms for secure information\nflow, reliability, and multi-agent coordination. In this work, we introduce\nSAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based\nagents. SAFEFLOW enforces fine-grained information flow control (IFC),\nprecisely tracking provenance, integrity, and confidentiality of all the data\nexchanged between agents, tools, users, and environments. By constraining LLM\nreasoning to respect these security labels, SAFEFLOW prevents untrusted or\nadversarial inputs from contaminating high-integrity decisions. To ensure\nrobustness in concurrent multi-agent settings, SAFEFLOW introduces\ntransactional execution, conflict resolution, and secure scheduling over shared\nstate, preserving global consistency across agents. We further introduce\nmechanisms, including write-ahead logging, rollback, and secure caches, that\nfurther enhance resilience against runtime errors and policy violations. To\nvalidate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark\nsuite designed to evaluate agent reliability under adversarial, noisy, and\nconcurrent operational conditions. Extensive experiments demonstrate that\nagents built with SAFEFLOW maintain impressive task performance and security\nguarantees even in hostile environments, substantially outperforming\nstate-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for\nprincipled, robust, and secure agent ecosystems, advancing the frontier of\nreliable autonomy.", "AI": {"tldr": "SAFEFLOW is a protocol-level framework for trustworthy LLM/VLM-based agents, enforcing fine-grained information flow control and robust multi-agent coordination, validated by SAFEFLOWBENCH.", "motivation": "Current agent frameworks lack mechanisms for secure information flow, reliability, and multi-agent coordination, making them fragile.", "method": "SAFEFLOW introduces fine-grained IFC, transactional execution, conflict resolution, secure scheduling, and resilience mechanisms like logging and rollback.", "result": "Agents built with SAFEFLOW maintain high task performance and security in adversarial conditions, outperforming state-of-the-art.", "conclusion": "SAFEFLOW and SAFEFLOWBENCH advance reliable autonomy by providing principled, robust, and secure agent ecosystems."}}
{"id": "2506.08455", "pdf": "https://arxiv.org/pdf/2506.08455", "abs": "https://arxiv.org/abs/2506.08455", "authors": ["Julian Berberich", "Tobias Fellner", "Christian Holm"], "title": "The interplay of robustness and generalization in quantum machine learning", "categories": ["quant-ph", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "While adversarial robustness and generalization have individually received\nsubstantial attention in the recent literature on quantum machine learning,\ntheir interplay is much less explored. In this chapter, we address this\ninterplay for variational quantum models, which were recently proposed as\nfunction approximators in supervised learning. We discuss recent results\nquantifying both robustness and generalization via Lipschitz bounds, which\nexplicitly depend on model parameters. Thus, they give rise to a\nregularization-based training approach for robust and generalizable quantum\nmodels, highlighting the importance of trainable data encoding strategies. The\npractical implications of the theoretical results are demonstrated with an\napplication to time series analysis.", "AI": {"tldr": "The paper explores the interplay between adversarial robustness and generalization in variational quantum models, using Lipschitz bounds for regularization-based training.", "motivation": "To address the under-explored relationship between adversarial robustness and generalization in quantum machine learning, particularly for variational quantum models.", "method": "Uses Lipschitz bounds to quantify robustness and generalization, leading to a regularization-based training approach.", "result": "Demonstrates practical implications with an application to time series analysis.", "conclusion": "Highlights the importance of trainable data encoding strategies for robust and generalizable quantum models."}}
{"id": "2505.08167", "pdf": "https://arxiv.org/pdf/2505.08167", "abs": "https://arxiv.org/abs/2505.08167", "authors": ["Ruilin Liu", "Zhixiao Zhao", "Jieqiong Li", "Chang Liu", "Dongbo Wang"], "title": "Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage", "categories": ["cs.CL", "cs.AI"], "comment": "We want to withdraw this paper due to data usage permission issues\n  identified after submission. We discovered that our use of certain intangible\n  cultural heritage materials required additional community permissions and\n  institutional ethical approvals that were not obtained", "summary": "The rapid development of large language models (LLMs) has provided\nsignificant support and opportunities for the advancement of domain-specific\nLLMs. However, fine-tuning these large models using Intangible Cultural\nHeritage (ICH) data inevitably faces challenges such as bias, incorrect\nknowledge inheritance, and catastrophic forgetting. To address these issues, we\npropose a novel training method that integrates a bidirectional chains of\nthought and a reward mechanism. This method is built upon ICH-Qwen, a large\nlanguage model specifically designed for the field of intangible cultural\nheritage. The proposed method enables the model to not only perform forward\nreasoning but also enhances the accuracy of the generated answers by utilizing\nreverse questioning and reverse reasoning to activate the model's latent\nknowledge. Additionally, a reward mechanism is introduced during training to\noptimize the decision-making process. This mechanism improves the quality of\nthe model's outputs through structural and content evaluations with different\nweighting schemes. We conduct comparative experiments on ICH-Qwen, with results\ndemonstrating that our method outperforms 0-shot, step-by-step reasoning,\nknowledge distillation, and question augmentation methods in terms of accuracy,\nBleu-4, and Rouge-L scores on the question-answering task. Furthermore, the\npaper highlights the effectiveness of combining the bidirectional chains of\nthought and reward mechanism through ablation experiments. In addition, a\nseries of generalizability experiments are conducted, with results showing that\nthe proposed method yields improvements on various domain-specific datasets and\nadvanced models in areas such as Finance, Wikidata, and StrategyQA. This\ndemonstrates that the method is adaptable to multiple domains and provides a\nvaluable approach for model training in future applications across diverse\nfields.", "AI": {"tldr": "The paper proposes a novel training method for domain-specific LLMs, integrating bidirectional chains of thought and a reward mechanism to address challenges like bias and catastrophic forgetting in ICH data.", "motivation": "To overcome issues like bias, incorrect knowledge inheritance, and catastrophic forgetting when fine-tuning LLMs with Intangible Cultural Heritage (ICH) data.", "method": "A bidirectional chains of thought approach (forward and reverse reasoning) combined with a reward mechanism for optimizing decision-making and output quality.", "result": "Outperforms baseline methods (0-shot, step-by-step reasoning, etc.) in accuracy, Bleu-4, and Rouge-L scores on question-answering tasks, with demonstrated generalizability across domains like Finance and Wikidata.", "conclusion": "The method is adaptable to multiple domains, offering a valuable approach for future model training in diverse fields."}}
{"id": "2411.02299", "pdf": "https://arxiv.org/pdf/2411.02299", "abs": "https://arxiv.org/abs/2411.02299", "authors": ["Rongzhen Zhao", "Vivienne Wang", "Juho Kannala", "Joni Pajarinen"], "title": "Grouped Discrete Representation for Object-Centric Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted by ECML-PKDD 2025", "summary": "Object-Centric Learning (OCL) aims to discover objects in images or videos by\nreconstructing the input. Representative methods achieve this by reconstructing\nthe input as its Variational Autoencoder (VAE) discrete representations, which\nsuppress (super-)pixel noise and enhance object separability. However, these\nmethods treat features as indivisible units, overlooking their compositional\nattributes, and discretize features via scalar code indexes, losing\nattribute-level similarities and differences. We propose Grouped Discrete\nRepresentation (GDR) for OCL. For better generalization, features are\ndecomposed into combinatorial attributes by organized channel grouping. For\nbetter convergence, features are quantized into discrete representations via\ntuple code indexes. Experiments demonstrate that GDR consistently improves both\nmainstream and state-of-the-art OCL methods across various datasets.\nVisualizations further highlight GDR's superior object separability and\ninterpretability. The source code is available on\nhttps://github.com/Genera1Z/GroupedDiscreteRepresentation.", "AI": {"tldr": "GDR improves OCL by decomposing features into combinatorial attributes and quantizing them via tuple code indexes, enhancing object separability and interpretability.", "motivation": "Existing OCL methods treat features as indivisible units and discretize them via scalar code indexes, losing attribute-level similarities and differences.", "method": "Proposes Grouped Discrete Representation (GDR), decomposing features into combinatorial attributes via channel grouping and quantizing them with tuple code indexes.", "result": "GDR consistently improves OCL methods across datasets, with superior object separability and interpretability.", "conclusion": "GDR enhances OCL by addressing limitations of existing methods, offering better generalization and convergence."}}
{"id": "2506.07820", "pdf": "https://arxiv.org/pdf/2506.07820", "abs": "https://arxiv.org/abs/2506.07820", "authors": ["Jiaxiang Chen", "Zhuo Wang", "Mingxi Zou", "Qifan Wang", "Zenglin Xu"], "title": "Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation", "categories": ["cs.AI"], "comment": null, "summary": "Human reasoning is flexible, adaptive, and grounded in prior\nexperience-qualities that large language models (LLMs) still struggle to\nemulate. Existing methods either explore diverse reasoning paths at inference\ntime or search for optimal workflows through expensive operations, but both\nfall short in leveraging multiple reusable strategies in a structured,\nefficient manner. We propose Guideline Forest, a framework that enhances LLMs\nreasoning by inducing structured reasoning strategies-called guidelines-from\nverified examples and executing them via step-wise aggregation. Unlike\ntest-time search or single-path distillation, our method draws on verified\nreasoning experiences by inducing reusable guidelines and expanding each into\ndiverse variants. Much like human reasoning, these variants reflect alternative\nthought patterns, are executed in parallel, refined via self-correction, and\naggregated step by step-enabling the model to adaptively resolve uncertainty\nand synthesize robust solutions.We evaluate Guideline Forest on four\nbenchmarks-GSM8K, MATH-500, MBPP, and HumanEval-spanning mathematical and\nprogrammatic reasoning. Guideline Forest consistently outperforms strong\nbaselines, including CoT, ReAct, ToT, FoT, and AFlow. Ablation studies further\nhighlight the effectiveness of multi-path reasoning and stepwise aggregation,\nunderscoring the Guideline Forest's adaptability and generalization potential.", "AI": {"tldr": "Guideline Forest enhances LLM reasoning by inducing reusable guidelines from verified examples, executing them via step-wise aggregation, and outperforms baselines on benchmarks.", "motivation": "Current LLMs struggle with flexible, adaptive reasoning like humans. Existing methods lack structured, efficient reuse of reasoning strategies.", "method": "Induces structured reasoning guidelines from verified examples, expands them into diverse variants, executes in parallel, and refines via self-correction.", "result": "Outperforms baselines (CoT, ReAct, ToT, FoT, AFlow) on benchmarks (GSM8K, MATH-500, MBPP, HumanEval).", "conclusion": "Guideline Forest's multi-path reasoning and stepwise aggregation improve adaptability and generalization, emulating human-like reasoning."}}
{"id": "2506.08528", "pdf": "https://arxiv.org/pdf/2506.08528", "abs": "https://arxiv.org/abs/2506.08528", "authors": ["Yu Guan", "Zhiyu Yin", "Haoyu Chen", "Sheng Cheng", "Chaojie Yang", "Tianyin Xu", "Yang Zhang", "Hanyu Zhao", "Yong Li", "Dennis Cai", "Ennan Zhai"], "title": "PerfTracker: Online Performance Troubleshooting for Large-scale Model Training in Production", "categories": ["cs.DC", "cs.LG", "cs.OS"], "comment": null, "summary": "Troubleshooting performance problems of large model training (LMT) is\nimmensely challenging, due to unprecedented scales of modern GPU clusters, the\ncomplexity of software-hardware interactions, and the data intensity of the\ntraining process. Existing troubleshooting approaches designed for traditional\ndistributed systems or datacenter networks fall short and can hardly apply to\nreal-world training systems. In this paper, we present PerfTracker, the first\nonline troubleshooting system utilizing fine-grained profiling, to diagnose\nperformance issues of large-scale model training in production. PerfTracker can\ndiagnose performance issues rooted in both hardware (e.g., GPUs and their\ninterconnects) and software (e.g., Python functions and GPU operations). It\nscales to LMT on modern GPU clusters. PerfTracker effectively summarizes\nruntime behavior patterns of fine-grained LMT functions via online profiling,\nand leverages differential observability to localize the root cause with\nminimal production impact. PerfTracker has been deployed as a production\nservice for large-scale GPU clusters of O(10, 000) GPUs (product homepage\nhttps://help.aliyun.com/zh/pai/user-guide/perftracker-online-performance-analysis-diagnostic-tool).\nIt has been used to diagnose a variety of difficult performance issues.", "AI": {"tldr": "PerfTracker is an online troubleshooting system for diagnosing performance issues in large-scale model training (LMT) on GPU clusters, addressing hardware and software complexities.", "motivation": "Existing troubleshooting methods for traditional systems fail to address the scale and complexity of modern LMT, necessitating a specialized solution.", "method": "PerfTracker uses fine-grained profiling and differential observability to diagnose issues in hardware (e.g., GPUs) and software (e.g., Python functions).", "result": "Deployed in production for clusters with ~10,000 GPUs, PerfTracker successfully diagnoses various challenging performance issues.", "conclusion": "PerfTracker provides an effective, scalable solution for troubleshooting LMT performance problems in real-world systems."}}
{"id": "2505.15074", "pdf": "https://arxiv.org/pdf/2505.15074", "abs": "https://arxiv.org/abs/2505.15074", "authors": ["Yuhang Zhou", "Jing Zhu", "Shengyi Qian", "Zhuokai Zhao", "Xiyao Wang", "Xiaoyu Liu", "Ming Li", "Paiheng Xu", "Wei Ai", "Furong Huang"], "title": "DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "13 pages, 3 figures", "summary": "Large Language Models (LLMs) are increasingly aligned with human preferences\nthrough Reinforcement Learning from Human Feedback (RLHF). Among RLHF methods,\nGroup Relative Policy Optimization (GRPO) has gained attention for its\nsimplicity and strong performance, notably eliminating the need for a learned\nvalue function. However, GRPO implicitly assumes a balanced domain distribution\nand uniform semantic alignment across groups - assumptions that rarely hold in\nreal-world datasets. When applied to multi-domain, imbalanced data, GRPO\ndisproportionately optimizes for dominant domains, neglecting underrepresented\nones and resulting in poor generalization and fairness. We propose\nDomain-Informed Self-Consistency Policy Optimization (DISCO), a principled\nextension to GRPO that addresses inter-group imbalance with two key\ninnovations. Domain-aware reward scaling counteracts frequency bias by\nreweighting optimization based on domain prevalence. Difficulty-aware reward\nscaling leverages prompt-level self-consistency to identify and prioritize\nuncertain prompts that offer greater learning value. Together, these strategies\npromote more equitable and effective policy learning across domains. Extensive\nexperiments across multiple LLMs and skewed training distributions show that\nDISCO improves generalization, outperforms existing GRPO variants by 5% on\nQwen3 models, and sets new state-of-the-art results on multi-domain alignment\nbenchmarks.", "AI": {"tldr": "DISCO improves GRPO by addressing domain imbalance with domain-aware and difficulty-aware reward scaling, enhancing generalization and fairness in LLMs.", "motivation": "GRPO's assumptions of balanced domains and uniform alignment fail in real-world data, leading to poor generalization and fairness.", "method": "DISCO introduces domain-aware reward scaling and difficulty-aware reward scaling to counteract imbalance and prioritize uncertain prompts.", "result": "DISCO outperforms GRPO variants by 5% on Qwen3 models and achieves state-of-the-art results on multi-domain benchmarks.", "conclusion": "DISCO offers a principled solution for equitable and effective policy learning in LLMs."}}
{"id": "2411.04125", "pdf": "https://arxiv.org/pdf/2411.04125", "abs": "https://arxiv.org/abs/2411.04125", "authors": ["Jeongsoo Park", "Andrew Owens"], "title": "Community Forensics: Using Thousands of Generators to Train Fake Image Detectors", "categories": ["cs.CV"], "comment": "16 pages; CVPR 2025; Project page:\n  https://jespark.net/projects/2024/community_forensics", "summary": "One of the key challenges of detecting AI-generated images is spotting images\nthat have been created by previously unseen generative models. We argue that\nthe limited diversity of the training data is a major obstacle to addressing\nthis problem, and we propose a new dataset that is significantly larger and\nmore diverse than prior work. As part of creating this dataset, we\nsystematically download thousands of text-to-image latent diffusion models and\nsample images from them. We also collect images from dozens of popular open\nsource and commercial models. The resulting dataset contains 2.7M images that\nhave been sampled from 4803 different models. These images collectively capture\na wide range of scene content, generator architectures, and image processing\nsettings. Using this dataset, we study the generalization abilities of fake\nimage detectors. Our experiments suggest that detection performance improves as\nthe number of models in the training set increases, even when these models have\nsimilar architectures. We also find that detection performance improves as the\ndiversity of the models increases, and that our trained detectors generalize\nbetter than those trained on other datasets. The dataset can be found in\nhttps://jespark.net/projects/2024/community_forensics", "AI": {"tldr": "A new large and diverse dataset of AI-generated images is introduced to improve fake image detection, showing better generalization with increased model diversity and quantity.", "motivation": "The limited diversity in training data hinders detection of AI-generated images from unseen models.", "method": "Created a dataset of 2.7M images from 4803 models, including latent diffusion and commercial models, to study detector generalization.", "result": "Detection improves with more and diverse models in training; trained detectors generalize better than others.", "conclusion": "The dataset enhances fake image detection by addressing training data limitations, with promising generalization results."}}
{"id": "2306.03346", "pdf": "https://arxiv.org/pdf/2306.03346", "abs": "https://arxiv.org/abs/2306.03346", "authors": ["Chongyi Zheng", "Benjamin Eysenbach", "Homer Walke", "Patrick Yin", "Kuan Fang", "Ruslan Salakhutdinov", "Sergey Levine"], "title": "Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR 2024 Spotlight (< 5%). Website\n  (https://chongyi-zheng.github.io/stable_contrastive_rl) and code\n  (https://github.com/chongyi-zheng/stable_contrastive_rl)", "summary": "Robotic systems that rely primarily on self-supervised learning have the\npotential to decrease the amount of human annotation and engineering effort\nrequired to learn control strategies. In the same way that prior robotic\nsystems have leveraged self-supervised techniques from computer vision (CV) and\nnatural language processing (NLP), our work builds on prior work showing that\nthe reinforcement learning (RL) itself can be cast as a self-supervised\nproblem: learning to reach any goal without human-specified rewards or labels.\nDespite the seeming appeal, little (if any) prior work has demonstrated how\nself-supervised RL methods can be practically deployed on robotic systems. By\nfirst studying a challenging simulated version of this task, we discover design\ndecisions about architectures and hyperparameters that increase the success\nrate by $2 \\times$. These findings lay the groundwork for our main result: we\ndemonstrate that a self-supervised RL algorithm based on contrastive learning\ncan solve real-world, image-based robotic manipulation tasks, with tasks being\nspecified by a single goal image provided after training.", "AI": {"tldr": "Self-supervised RL for robotics reduces human effort, achieves 2x success rate in simulation, and solves real-world tasks using contrastive learning.", "motivation": "To decrease human annotation and engineering effort in robotic control by leveraging self-supervised RL.", "method": "Uses self-supervised RL, inspired by CV/NLP, with contrastive learning for goal-reaching tasks. Tests in simulation first, then applies to real-world robotics.", "result": "Achieves 2x higher success rate in simulation and successfully solves image-based robotic manipulation tasks post-training.", "conclusion": "Self-supervised RL is practical for robotics, enabling task specification via a single goal image."}}
{"id": "2506.08535", "pdf": "https://arxiv.org/pdf/2506.08535", "abs": "https://arxiv.org/abs/2506.08535", "authors": ["Ronald Katende"], "title": "Structured Variational $D$-Decomposition for Accurate and Stable Low-Rank Approximation", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We introduce the $D$-decomposition, a non-orthogonal matrix factorization of\nthe form $A \\approx P D Q$, where $P \\in \\mathbb{R}^{n \\times k}$, $D \\in\n\\mathbb{R}^{k \\times k}$, and $Q \\in \\mathbb{R}^{k \\times n}$. The\ndecomposition is defined variationally by minimizing a regularized Frobenius\nloss, allowing control over rank, sparsity, and conditioning. Unlike algebraic\nfactorizations such as LU or SVD, it is computed by alternating minimization.\nWe establish existence and perturbation stability of the solution and show that\neach update has complexity $\\mathcal{O}(n^2k)$. Benchmarks against truncated\nSVD, CUR, and nonnegative matrix factorization show improved reconstruction\naccuracy on MovieLens, MNIST, Olivetti Faces, and gene expression matrices,\nparticularly under sparsity and noise.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.15817", "pdf": "https://arxiv.org/pdf/2505.15817", "abs": "https://arxiv.org/abs/2505.15817", "authors": ["Tong Zheng", "Lichang Chen", "Simeng Han", "R. Thomas McCoy", "Heng Huang"], "title": "Learning to Reason via Mixture-of-Thought for Logical Reasoning", "categories": ["cs.CL"], "comment": "38 pages", "summary": "Human beings naturally utilize multiple reasoning modalities to learn and\nsolve logical problems, i.e., different representational formats such as\nnatural language, code, and symbolic logic. In contrast, most existing\nLLM-based approaches operate with a single reasoning modality during training,\ntypically natural language. Although some methods explored modality selection\nor augmentation at inference time, the training process remains modality-blind,\nlimiting synergy among modalities. To fill in this gap, we propose\nMixture-of-Thought (MoT), a framework that enables LLMs to reason across three\ncomplementary modalities: natural language, code, and a newly introduced\nsymbolic modality, truth-table, which systematically enumerates logical cases\nand partially mitigates key failure modes in natural language reasoning. MoT\nadopts a two-phase design: (1) self-evolving MoT training, which jointly learns\nfrom filtered, self-generated rationales across modalities; and (2) MoT\ninference, which fully leverages the synergy of three modalities to produce\nbetter predictions. Experiments on logical reasoning benchmarks including FOLIO\nand ProofWriter demonstrate that our MoT framework consistently and\nsignificantly outperforms strong LLM baselines with single-modality\nchain-of-thought approaches, achieving up to +11.7pp average accuracy gain.\nFurther analyses show that our MoT framework benefits both training and\ninference stages; that it is particularly effective on harder logical reasoning\nproblems; and that different modalities contribute complementary strengths,\nwith truth-table reasoning helping to overcome key bottlenecks in natural\nlanguage inference.", "AI": {"tldr": "The paper introduces Mixture-of-Thought (MoT), a framework enabling LLMs to reason across natural language, code, and symbolic logic (truth-table) modalities, outperforming single-modality approaches by up to +11.7pp accuracy.", "motivation": "Existing LLM-based approaches use a single reasoning modality (e.g., natural language) during training, missing synergies among modalities. MoT addresses this gap by integrating multiple reasoning modalities.", "method": "MoT uses a two-phase design: (1) self-evolving training with filtered, self-generated rationales across modalities, and (2) inference leveraging modality synergy for better predictions.", "result": "MoT outperforms single-modality baselines by up to +11.7pp accuracy on logical reasoning benchmarks (FOLIO, ProofWriter), especially on harder problems.", "conclusion": "MoT enhances LLM reasoning by combining complementary modalities, with truth-tables mitigating natural language bottlenecks, proving effective in training and inference."}}
{"id": "2411.18142", "pdf": "https://arxiv.org/pdf/2411.18142", "abs": "https://arxiv.org/abs/2411.18142", "authors": ["Jingming Liu", "Yumeng Li", "Boyuan Xiao", "Yichang Jian", "Ziang Qin", "Tianjia Shao", "Yao-Xiang Ding", "Kun Zhou"], "title": "Autonomous Imagination: Closed-Loop Decomposition of Visual-to-Textual Conversion in Visual Reasoning for Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Under pure textual modality, Large Language Models (LLMs) have demonstrated\nremarkable success in complex reasoning tasks by decomposing them into simpler\nsub-problems. However, Multimodal Large Language Models (MLLMs) still struggle\nwith some seemingly straightforward visual tasks, such as counting and solving\njigsaw puzzles. We argue that these tasks challenge the ability of\nvisual-to-textual conversion, where MLLMs convert visual information perceived\nfrom the input scene, to textual information for further reasoning and\ngenerating the answer. If the complexity of the visual input is beyond the\nperceptual capability of the MLLMs, without decomposing this conversion\nprocess, simply scaling inference-time reasoning cannot solve the task because\nit repeatedly encounters the same perceptual bottleneck. We propose an\napproach, autonomous imagination, to enable MLLMs to iteratively modify visual\ninputs (e.g. isolating objects, rearranging puzzle pieces) into intermediate\nvisual states, decomposing visual-to-textual conversion into closed-loop visual\nmodification steps. We show that, without any retraining, MLLMs can now solve\ntasks initially beyond their perceptual capability, highlighting that\nclosed-loop visual modification can be an effective way of decomposing the\nvisual reasoning task into solvable substeps. Project page:\nhttps://future-item.github.io/autoimagine-site/", "AI": {"tldr": "MLLMs struggle with visual tasks like counting and puzzles due to perceptual bottlenecks. The proposed 'autonomous imagination' method decomposes visual-to-textual conversion into iterative visual modifications, enabling MLLMs to solve previously unsolvable tasks without retraining.", "motivation": "MLLMs fail at straightforward visual tasks because their visual-to-textual conversion process lacks decomposition, leading to perceptual bottlenecks.", "method": "Introduces 'autonomous imagination,' where MLLMs iteratively modify visual inputs (e.g., isolating objects, rearranging puzzle pieces) to decompose the conversion process into manageable steps.", "result": "MLLMs can now solve tasks beyond their initial perceptual capability without retraining, demonstrating the effectiveness of closed-loop visual modification.", "conclusion": "Closed-loop visual modification decomposes visual reasoning into solvable substeps, enhancing MLLMs' performance on complex visual tasks."}}
{"id": "2312.17294", "pdf": "https://arxiv.org/pdf/2312.17294", "abs": "https://arxiv.org/abs/2312.17294", "authors": ["Bohan Lyu", "Xin Cong", "Heyang Yu", "Pan Yang", "Yujia Qin", "Yining Ye", "Yaxi Lu", "Zhong Zhang", "Yukun Yan", "Yankai Lin", "Zhiyuan Liu", "Maosong Sun"], "title": "Enhancing Open-Domain Task-Solving Capability of LLMs via Autonomous Tool Integration from GitHub", "categories": ["cs.SE", "cs.AI", "cs.IR"], "comment": "Accepted by ACL 2025 Main Conference", "summary": "Large Language Models (LLMs) excel in traditional natural language processing\ntasks but struggle with problems that require complex domain-specific\ncalculations or simulations. While equipping LLMs with external tools to build\nLLM-based agents can enhance their capabilities, existing approaches lack the\nflexibility to address diverse and ever-evolving user queries in open domains.\nCurrently, there is also no existing dataset that evaluates LLMs on open-domain\nknowledge that requires tools to solve. To this end, we introduce OpenAct\nbenchmark to evaluate the open-domain task-solving capability, which is built\non human expert consultation and repositories in GitHub. It comprises 339\nquestions spanning 7 diverse domains that need to be solved with\ndomain-specific methods. In our experiments, even state-of-the-art LLMs and\nLLM-based agents demonstrate unsatisfactory success rates, underscoring the\nneed for a novel approach. Furthermore, we present OpenAgent, a novel LLM-based\nagent system that can tackle evolving queries in open domains through\nautonomously integrating specialized tools from GitHub. OpenAgent employs 1) a\nhierarchical framework where specialized agents handle specific tasks and can\nassign tasks to inferior agents, 2) a bi-level experience learning mechanism to\nlearn from both humans' and its own experiences to tackle tool flaws.\nExperiments demonstrate its superior effectiveness and efficiency, which\nsignificantly outperforms baselines. Our data and code are open-source at\nhttps://github.com/OpenBMB/OpenAct.", "AI": {"tldr": "The paper introduces OpenAct, a benchmark for evaluating LLMs' open-domain task-solving capabilities, and OpenAgent, a novel LLM-based agent system that autonomously integrates tools from GitHub to handle evolving queries.", "motivation": "LLMs struggle with complex domain-specific calculations and open-domain queries. Existing approaches lack flexibility, and no dataset evaluates LLMs on such tasks.", "method": "OpenAct benchmark is created using human expert consultation and GitHub repositories. OpenAgent uses a hierarchical framework and bi-level experience learning to integrate tools and address flaws.", "result": "State-of-the-art LLMs perform poorly on OpenAct. OpenAgent outperforms baselines in effectiveness and efficiency.", "conclusion": "OpenAct and OpenAgent address gaps in LLM capabilities for open-domain tasks, demonstrating the need for flexible, tool-integrated approaches."}}
{"id": "2506.08548", "pdf": "https://arxiv.org/pdf/2506.08548", "abs": "https://arxiv.org/abs/2506.08548", "authors": ["Moria Mayala", "Erwan Scornet", "Charles Tillier", "Olivier Wintenberger"], "title": "Asymptotic Normality of Infinite Centered Random Forests -Application to Imbalanced Classification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Many classification tasks involve imbalanced data, in which a class is\nlargely underrepresented. Several techniques consists in creating a rebalanced\ndataset on which a classifier is trained. In this paper, we study theoretically\nsuch a procedure, when the classifier is a Centered Random Forests (CRF). We\nestablish a Central Limit Theorem (CLT) on the infinite CRF with explicit rates\nand exact constant. We then prove that the CRF trained on the rebalanced\ndataset exhibits a bias, which can be removed with appropriate techniques.\nBased on an importance sampling (IS) approach, the resulting debiased\nestimator, called IS-ICRF, satisfies a CLT centered at the prediction function\nvalue. For high imbalance settings, we prove that the IS-ICRF estimator enjoys\na variance reduction compared to the ICRF trained on the original data.\nTherefore, our theoretical analysis highlights the benefits of training random\nforests on a rebalanced dataset (followed by a debiasing procedure) compared to\nusing the original data. Our theoretical results, especially the variance rates\nand the variance reduction, appear to be valid for Breiman's random forests in\nour experiments.", "AI": {"tldr": "The paper theoretically analyzes Centered Random Forests (CRF) on imbalanced datasets, proving a Central Limit Theorem (CLT) and introducing a debiased estimator (IS-ICRF) that reduces variance in high-imbalance settings.", "motivation": "To address classification tasks with imbalanced data, the study explores the theoretical benefits of rebalancing datasets and debiasing techniques for CRF.", "method": "The paper establishes a CLT for infinite CRF, introduces a debiased estimator (IS-ICRF) using importance sampling, and compares it to CRF on original data.", "result": "The IS-ICRF estimator shows reduced variance in high-imbalance settings and aligns with empirical results for Breiman's random forests.", "conclusion": "Rebalancing datasets and debiasing CRF (IS-ICRF) improves performance over using original imbalanced data, supported by theoretical and experimental evidence."}}
{"id": "2505.16694", "pdf": "https://arxiv.org/pdf/2505.16694", "abs": "https://arxiv.org/abs/2505.16694", "authors": ["Gouki Minegishi", "Hiroki Furuta", "Shohei Taniguchi", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Transformer-based language models exhibit In-Context Learning (ICL), where\npredictions are made adaptively based on context. While prior work links\ninduction heads to ICL through a sudden jump in accuracy, this can only account\nfor ICL when the answer is included within the context. However, an important\nproperty of practical ICL in large language models is the ability to meta-learn\nhow to solve tasks from context, rather than just copying answers from context;\nhow such an ability is obtained during training is largely unexplored. In this\npaper, we experimentally clarify how such meta-learning ability is acquired by\nanalyzing the dynamics of the model's circuit during training. Specifically, we\nextend the copy task from previous research into an In-Context Meta Learning\nsetting, where models must infer a task from examples to answer queries.\nInterestingly, in this setting, we find that there are multiple phases in the\nprocess of acquiring such abilities, and that a unique circuit emerges in each\nphase, contrasting with the single-phases change in induction heads. The\nemergence of such circuits can be related to several phenomena known in large\nlanguage models, and our analysis lead to a deeper understanding of the source\nof the transformer's ICL ability.", "AI": {"tldr": "The paper explores how transformer models acquire meta-learning abilities during training, beyond just copying answers, by analyzing circuit dynamics in an In-Context Meta Learning setting.", "motivation": "To understand how large language models meta-learn tasks from context, not just copy answers, and clarify the training dynamics behind this ability.", "method": "Extends the copy task to an In-Context Meta Learning setting, analyzing model circuit dynamics during training phases.", "result": "Reveals multiple phases in acquiring meta-learning abilities, each with unique circuits, differing from single-phase induction heads.", "conclusion": "Provides deeper insights into the source of transformers' In-Context Learning ability, linking circuit emergence to known phenomena in large language models."}}
{"id": "2412.10494", "pdf": "https://arxiv.org/pdf/2412.10494", "abs": "https://arxiv.org/abs/2412.10494", "authors": ["Yushu Wu", "Zhixing Zhang", "Yanyu Li", "Yanwu Xu", "Anil Kag", "Yang Sui", "Huseyin Coskun", "Ke Ma", "Aleksei Lebedev", "Ju Hu", "Dimitris Metaxas", "Yanzhi Wang", "Sergey Tulyakov", "Jian Ren"], "title": "SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.PF"], "comment": "https://snap-research.github.io/snapgen-v/", "summary": "We have witnessed the unprecedented success of diffusion-based video\ngeneration over the past year. Recently proposed models from the community have\nwielded the power to generate cinematic and high-resolution videos with smooth\nmotions from arbitrary input prompts. However, as a supertask of image\ngeneration, video generation models require more computation and are thus\nhosted mostly on cloud servers, limiting broader adoption among content\ncreators. In this work, we propose a comprehensive acceleration framework to\nbring the power of the large-scale video diffusion model to the hands of edge\nusers. From the network architecture scope, we initialize from a compact image\nbackbone and search out the design and arrangement of temporal layers to\nmaximize hardware efficiency. In addition, we propose a dedicated adversarial\nfine-tuning algorithm for our efficient model and reduce the denoising steps to\n4. Our model, with only 0.6B parameters, can generate a 5-second video on an\niPhone 16 PM within 5 seconds. Compared to server-side models that take minutes\non powerful GPUs to generate a single video, we accelerate the generation by\nmagnitudes while delivering on-par quality.", "AI": {"tldr": "A framework accelerates large-scale video diffusion models for edge devices, reducing computation and enabling faster, high-quality video generation.", "motivation": "Current video generation models are computationally heavy and cloud-dependent, limiting accessibility for content creators.", "method": "Proposes an efficient architecture from a compact image backbone, optimizes temporal layers, uses adversarial fine-tuning, and reduces denoising steps to 4.", "result": "The model (0.6B parameters) generates a 5-second video on an iPhone 16 PM in 5 seconds, matching server-side quality.", "conclusion": "The framework significantly accelerates video generation for edge users without compromising quality."}}
{"id": "2405.17998", "pdf": "https://arxiv.org/pdf/2405.17998", "abs": "https://arxiv.org/abs/2405.17998", "authors": ["Yuqi Zhou", "Sunhao Dai", "Liang Pang", "Gang Wang", "Zhenhua Dong", "Jun Xu", "Ji-Rong Wen"], "title": "Exploring the Escalation of Source Bias in User, Data, and Recommender System Feedback Loop", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Recommender systems are essential for information access, allowing users to\npresent their content for recommendation. With the rise of large language\nmodels (LLMs), AI-generated content (AIGC), primarily in the form of text, has\nbecome a central part of the content ecosystem. As AIGC becomes increasingly\nprevalent, it is important to understand how it affects the performance and\ndynamics of recommender systems. To this end, we construct an environment that\nincorporates AIGC to explore its short-term impact. The results from popular\nsequential recommendation models reveal that AIGC are ranked higher in the\nrecommender system, reflecting the phenomenon of source bias. To further\nexplore the long-term impact of AIGC, we introduce a feedback loop with\nrealistic simulators. The results show that the model's preference for AIGC\nincreases as the user clicks on AIGC rises and the model trains on simulated\nclick data. This leads to two issues: In the short term, bias toward AIGC\nencourages LLM-based content creation, increasing AIGC content, and causing\nunfair traffic distribution. From a long-term perspective, our experiments also\nshow that when AIGC dominates the content ecosystem after a feedback loop, it\ncan lead to a decline in recommendation performance. To address these issues,\nwe propose a debiasing method based on L1-loss optimization to maintain\nlong-term content ecosystem balance. In a real-world environment with AIGC\ngenerated by mainstream LLMs, our method ensures a balance between AIGC and\nhuman-generated content in the ecosystem. The code and dataset are available at\nhttps://github.com/Yuqi-Zhou/Rec_SourceBias.", "AI": {"tldr": "The paper explores the impact of AI-generated content (AIGC) on recommender systems, revealing short-term bias toward AIGC and long-term performance decline. A debiasing method is proposed to balance the content ecosystem.", "motivation": "To understand how AIGC affects recommender systems' performance and dynamics, given its growing prevalence.", "method": "Constructed an environment with AIGC, tested sequential recommendation models, and introduced a feedback loop with simulators. Proposed an L1-loss optimization debiasing method.", "result": "AIGC is ranked higher, causing source bias. Long-term, AIGC dominance degrades recommendation performance. The debiasing method balances AIGC and human-generated content.", "conclusion": "AIGC introduces bias and performance issues in recommender systems, but the proposed debiasing method effectively maintains ecosystem balance."}}
{"id": "2506.08558", "pdf": "https://arxiv.org/pdf/2506.08558", "abs": "https://arxiv.org/abs/2506.08558", "authors": ["William de Vazelhes", "Xiao-Tong Yuan", "Bin Gu"], "title": "Optimization over Sparse Support-Preserving Sets: Two-Step Projection with Global Optimality Guarantees", "categories": ["math.OC", "cs.LG"], "comment": "Accepted for publication at ICML 2025", "summary": "In sparse optimization, enforcing hard constraints using the $\\ell_0$\npseudo-norm offers advantages like controlled sparsity compared to convex\nrelaxations. However, many real-world applications demand not only sparsity\nconstraints but also some extra constraints. While prior algorithms have been\ndeveloped to address this complex scenario with mixed combinatorial and convex\nconstraints, they typically require the closed form projection onto the mixed\nconstraints which might not exist, and/or only provide local guarantees of\nconvergence which is different from the global guarantees commonly sought in\nsparse optimization. To fill this gap, in this paper, we study the problem of\nsparse optimization with extra \\qw{\\textit{support-preserving}} constraints\ncommonly encountered in the literature. We present a new variant of iterative\nhard-thresholding algorithm equipped with a two-step consecutive projection\noperator customized for these mixed constraints, serving as a simple\nalternative to the Euclidean projection onto the mixed constraint. By\nintroducing a novel trade-off between sparsity relaxation and sub-optimality,\nwe provide global guarantees in objective value for the output of our\nalgorithm, in the deterministic, stochastic, and zeroth-order settings, under\nthe conventional restricted strong-convexity/smoothness assumptions. As a\nfundamental contribution in proof techniques, we develop a novel extension of\nthe classic three-point lemma to the considered two-step non-convex projection\noperator, which allows us to analyze the convergence in objective value in an\nelegant way that has not been possible with existing techniques. In the\nzeroth-order case, such technique also improves upon the state-of-the-art\nresult from de Vazelhes et. al. (2022), even in the case without additional\nconstraints, by allowing us to remove a non-vanishing system error present in\ntheir work.", "AI": {"tldr": "The paper introduces a new iterative hard-thresholding algorithm for sparse optimization with extra support-preserving constraints, offering global convergence guarantees under standard assumptions.", "motivation": "Existing methods for sparse optimization with mixed constraints lack global guarantees or require impractical projections. This work addresses these limitations.", "method": "A two-step consecutive projection operator is proposed as an alternative to Euclidean projection, combined with a trade-off between sparsity relaxation and sub-optimality.", "result": "The algorithm provides global guarantees in deterministic, stochastic, and zeroth-order settings, improving upon prior work by eliminating non-vanishing errors.", "conclusion": "The proposed method fills a gap in sparse optimization by offering a practical and globally convergent solution for problems with mixed constraints."}}
{"id": "2505.17061", "pdf": "https://arxiv.org/pdf/2505.17061", "abs": "https://arxiv.org/abs/2505.17061", "authors": ["Xinlong Chen", "Yuanxing Zhang", "Qiang Liu", "Junfei Wu", "Fuzheng Zhang", "Tieniu Tan"], "title": "Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Accepted to Findings of ACL 2025", "summary": "Large Vision-Language Models (LVLMs) have exhibited impressive capabilities\nacross various visual tasks, yet they remain hindered by the persistent\nchallenge of hallucinations. To address this critical issue, we propose Mixture\nof Decoding (MoD), a novel approach for hallucination mitigation that\ndynamically adapts decoding strategies by evaluating the correctness of the\nmodel's attention on image tokens. Specifically, MoD measures the consistency\nbetween outputs generated from the original image tokens and those derived from\nthe model's attended image tokens, to distinguish the correctness\naforementioned. If the outputs are consistent, indicating correct attention,\nMoD employs a complementary strategy to amplify critical information.\nConversely, if the outputs are inconsistent, suggesting erroneous attention,\nMoD utilizes a contrastive strategy to suppress misleading information.\nExtensive experiments demonstrate that MoD significantly outperforms existing\ndecoding methods across multiple mainstream benchmarks, effectively mitigating\nhallucinations in LVLMs. The code is available at\nhttps://github.com/xlchen0205/MoD.", "AI": {"tldr": "MoD dynamically adapts decoding strategies to mitigate hallucinations in LVLMs by evaluating attention correctness on image tokens.", "motivation": "Address the persistent challenge of hallucinations in LVLMs, which hinder their performance.", "method": "Proposes Mixture of Decoding (MoD), which measures consistency between outputs from original and attended image tokens to adapt decoding strategies.", "result": "MoD outperforms existing methods on multiple benchmarks, effectively reducing hallucinations.", "conclusion": "MoD is a novel and effective approach for hallucination mitigation in LVLMs."}}
{"id": "2412.18874", "pdf": "https://arxiv.org/pdf/2412.18874", "abs": "https://arxiv.org/abs/2412.18874", "authors": ["Alireza Sedighi Moghaddam", "Fatemeh Anvari", "Mohammadjavad Mirshekari Haghighi", "Mohammadali Fakhari", "Mohammad Reza Mohammadi"], "title": "A Culturally-Aware Benchmark for Person Re-Identification in Modest Attire", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Person Re-Identification (ReID) is a fundamental task in computer vision with\ncritical applications in surveillance and security. Despite progress in recent\nyears, most existing ReID models often struggle to generalize across diverse\ncultural contexts, particularly in Islamic regions like Iran, where modest\nclothing styles are prevalent. Existing datasets predominantly feature Western\nand East Asian fashion, limiting their applicability in these settings. To\naddress this gap, we introduce Iran University of Science and Technology Person\nRe-Identification (IUST_PersonReId), a dataset designed to reflect the unique\nchallenges of ReID in new cultural environments, emphasizing modest attire and\ndiverse scenarios from Iran, including markets, campuses, and mosques.\nExperiments on IUST_PersonReId with state-of-the-art models, such as Semantic\nControllable Self-supervised Learning (SOLIDER) and Contrastive Language-Image\nPretraining Re-Identification (CLIP-ReID), reveal significant performance drops\ncompared to benchmarks like Market1501 and Multi-Scene MultiTime (MSMT17),\nspecifically, SOLIDER shows a drop of 50.75% and 23.01% Mean Average Precision\n(mAP) compared to Market1501 and MSMT17 respectively, while CLIP-ReID exhibits\na drop of 38.09% and 21.74% mAP, highlighting the challenges posed by occlusion\nand limited distinctive features. Sequence-based evaluations show improvements\nby leveraging temporal context, emphasizing the dataset's potential for\nadvancing culturally sensitive and robust ReID systems. IUST_PersonReId offers\na critical resource for addressing fairness and bias in ReID research globally.", "AI": {"tldr": "The paper introduces IUST_PersonReId, a dataset for Person Re-Identification (ReID) tailored to Islamic regions like Iran, addressing the lack of diversity in existing datasets. It highlights performance drops in state-of-the-art models on this dataset, emphasizing challenges like occlusion and modest attire.", "motivation": "Existing ReID datasets lack diversity, especially for regions with modest clothing like Iran, limiting model generalization. The paper aims to fill this gap with a culturally representative dataset.", "method": "The authors introduce the IUST_PersonReId dataset, capturing diverse scenarios in Iran (markets, campuses, mosques). They evaluate state-of-the-art models (SOLIDER, CLIP-ReID) on this dataset and benchmark against Market1501 and MSMT17.", "result": "Performance drops significantly on IUST_PersonReId: SOLIDER shows 50.75% and 23.01% mAP drops, while CLIP-ReID drops 38.09% and 21.74% mAP compared to benchmarks. Sequence-based evaluations improve results by leveraging temporal context.", "conclusion": "IUST_PersonReId highlights the need for culturally sensitive ReID datasets and models. It advances fairness and bias research in ReID, offering a resource for robust, globally applicable systems."}}
{"id": "2406.01168", "pdf": "https://arxiv.org/pdf/2406.01168", "abs": "https://arxiv.org/abs/2406.01168", "authors": ["Shumiao Ouyang", "Hayong Yun", "Xingjian Zheng"], "title": "AI as Decision-Maker: Ethics and Risk Preferences of LLMs", "categories": ["econ.GN", "cs.AI", "cs.CY", "cs.ET", "cs.HC", "q-fin.EC"], "comment": null, "summary": "Large Language Models (LLMs) exhibit surprisingly diverse risk preferences\nwhen acting as AI decision makers, a crucial characteristic whose origins\nremain poorly understood despite their expanding economic roles. We analyze 50\nLLMs using behavioral tasks, finding stable but diverse risk profiles.\nAlignment tuning for harmlessness, helpfulness, and honesty significantly\nincreases risk aversion, causally increasing risk aversion confirmed via\ncomparative difference analysis: a ten percent ethics increase cuts risk\nappetite two to eight percent. This induced caution persists against prompts\nand affects economic forecasts. Alignment enhances safety but may also suppress\nvaluable risk taking, revealing a tradeoff risking suboptimal economic\noutcomes. With AI models becoming more powerful and influential in economic\ndecisions while alignment grows increasingly critical, our empirical framework\nserves as an adaptable and enduring benchmark to track risk preferences and\nmonitor this crucial tension between ethical alignment and economically\nvaluable risk-taking.", "AI": {"tldr": "LLMs show diverse risk preferences, with alignment tuning increasing risk aversion, revealing a tradeoff between safety and economic risk-taking.", "motivation": "Understanding the origins of diverse risk preferences in LLMs, given their expanding economic roles.", "method": "Analyzed 50 LLMs using behavioral tasks and comparative difference analysis to measure risk profiles and alignment effects.", "result": "Alignment tuning for ethics increases risk aversion (10% ethics increase reduces risk appetite by 2-8%), affecting economic forecasts.", "conclusion": "Alignment enhances safety but may suppress valuable risk-taking, highlighting a tradeoff needing monitoring as AI's economic influence grows."}}
{"id": "2506.08616", "pdf": "https://arxiv.org/pdf/2506.08616", "abs": "https://arxiv.org/abs/2506.08616", "authors": ["Julien Fageot", "Peva Blanchard", "Gilles Bareilles", "L\u00ea-Nguy\u00ean Hoang"], "title": "Generalizing while preserving monotonicity in comparison-based preference learning models", "categories": ["math.ST", "cs.LG", "stat.TH"], "comment": null, "summary": "If you tell a learning model that you prefer an alternative $a$ over another\nalternative $b$, then you probably expect the model to be monotone, that is,\nthe valuation of $a$ increases, and that of $b$ decreases. Yet, perhaps\nsurprisingly, many widely deployed comparison-based preference learning models,\nincluding large language models, fail to have this guarantee. Until now, the\nonly comparison-based preference learning algorithms that were proved to be\nmonotone are the Generalized Bradley-Terry models. Yet, these models are unable\nto generalize to uncompared data. In this paper, we advance the understanding\nof the set of models with generalization ability that are monotone. Namely, we\npropose a new class of Linear Generalized Bradley-Terry models with Diffusion\nPriors, and identify sufficient conditions on alternatives' embeddings that\nguarantee monotonicity. Our experiments show that this monotonicity is far from\nbeing a general guarantee, and that our new class of generalizing models\nimproves accuracy, especially when the dataset is limited.", "AI": {"tldr": "The paper introduces a new class of Linear Generalized Bradley-Terry models with Diffusion Priors to ensure monotonicity in preference learning, improving accuracy in limited datasets.", "motivation": "Existing comparison-based preference learning models, including large language models, often lack monotonicity guarantees, and current monotone models (Generalized Bradley-Terry) fail to generalize to uncompared data.", "method": "Proposes Linear Generalized Bradley-Terry models with Diffusion Priors and identifies conditions on embeddings to ensure monotonicity.", "result": "Experiments show the new class improves accuracy, especially with limited data, and highlights that monotonicity is not a general guarantee.", "conclusion": "The proposed model advances monotone preference learning with generalization ability, addressing limitations of existing methods."}}
{"id": "2505.21646", "pdf": "https://arxiv.org/pdf/2505.21646", "abs": "https://arxiv.org/abs/2505.21646", "authors": ["Lei Zhang", "Markus Stricker"], "title": "Iterative Corpus Refinement for Materials Property Prediction Based on Scientific Texts", "categories": ["cs.CL", "cond-mat.mtrl-sci"], "comment": "9 pages, 5 figures, 2 tables, accepted at ECMLPKDD 2025", "summary": "The discovery and optimization of materials for specific applications is\nhampered by the practically infinite number of possible elemental combinations\nand associated properties, also known as the `combinatorial explosion'. By\nnature of the problem, data are scarce and all possible data sources should be\nused. In addition to simulations and experimental results, the latent knowledge\nin scientific texts is not yet used to its full potential. We present an\niterative framework that refines a given scientific corpus by strategic\nselection of the most diverse documents, training Word2Vec models, and\nmonitoring the convergence of composition-property correlations in embedding\nspace. Our approach is applied to predict high-performing materials for oxygen\nreduction (ORR), hydrogen evolution (HER), and oxygen evolution (OER) reactions\nfor a large number of possible candidate compositions. Our method successfully\npredicts the highest performing compositions among a large pool of candidates,\nvalidated by experimental measurements of the electrocatalytic performance in\nthe lab. This work demonstrates and validates the potential of iterative corpus\nrefinement to accelerate materials discovery and optimization, offering a\nscalable and efficient tool for screening large compositional spaces where\nreliable data are scarce or non-existent.", "AI": {"tldr": "An iterative framework using Word2Vec and strategic document selection accelerates materials discovery by predicting high-performing compositions for ORR, HER, and OER reactions, validated by experiments.", "motivation": "Overcoming the combinatorial explosion in materials discovery by leveraging latent knowledge in scientific texts, simulations, and experiments.", "method": "Iterative corpus refinement with Word2Vec models, monitoring convergence of composition-property correlations in embedding space.", "result": "Successfully predicted top-performing materials for ORR, HER, and OER, validated experimentally.", "conclusion": "Iterative corpus refinement is a scalable tool for materials discovery, especially where data is scarce."}}
{"id": "2501.15513", "pdf": "https://arxiv.org/pdf/2501.15513", "abs": "https://arxiv.org/abs/2501.15513", "authors": ["Xingjian Zhang", "Xi Weng", "Yihao Yue", "Zhaoxin Fan", "Wenjun Wu", "Lei Huang"], "title": "TinyLLaVA-Video: Towards Smaller LMMs for Video Understanding with Group Resampler", "categories": ["cs.CV"], "comment": "code and training recipes are available at\n  https://github.com/ZhangXJ199/TinyLLaVA-Video", "summary": "Video behavior recognition and scene understanding are fundamental tasks in\nmultimodal intelligence, serving as critical building blocks for numerous\nreal-world applications. Through large multimodal models (LMMs) have achieved\nremarkable progress in video understanding, most existing open-source models\nrely on over 7B parameters and require large-scale datasets for training,\nmaking them resource-intensive and inaccessible to many researchers.\nFurthermore, lightweight models face persistent challenges in effectively\nprocessing long visual sequences and temporal understanding. In this work, we\nintroduce TinyLLaVA-Video, a lightweight yet powerful video understanding model\nwith approximately 3.6B parameters. The cornerstone of our design is the\nvideo-level group resampler, a novel mechanism that significantly reduces and\ncontrols the number of visual tokens at the video level. Unlike traditional\nimage-level resampler, our approach effectively mitigates redundancy while\nenhancing temporal comprehension, leading to improved performance on\nvideo-based tasks. In addition, TinyLLaVA-Video demonstrates exceptional\nefficiency, requiring only one day of training on 8 A100-40G GPUs. It surpasses\nseveral existing 7B-parameter models on multiple benchmarks. We believe this\nwork provides a valuable foundation for future research on lightweight video\nunderstanding models. The code and weights is available at\nhttps://github.com/ZhangXJ199/TinyLLaVA-Video.", "AI": {"tldr": "TinyLLaVA-Video is a lightweight video understanding model with 3.6B parameters, outperforming larger models while being efficient and accessible.", "motivation": "Addressing the resource-intensive nature of large models and the challenges lightweight models face in processing long visual sequences.", "method": "Introduces a video-level group resampler to reduce visual tokens and enhance temporal understanding.", "result": "Surpasses 7B-parameter models on benchmarks and trains efficiently in one day on 8 GPUs.", "conclusion": "Provides a foundation for lightweight video understanding research, with code and weights publicly available."}}
{"id": "2406.08466", "pdf": "https://arxiv.org/pdf/2406.08466", "abs": "https://arxiv.org/abs/2406.08466", "authors": ["Licong Lin", "Jingfeng Wu", "Sham M. Kakade", "Peter L. Bartlett", "Jason D. Lee"], "title": "Scaling Laws in Linear Regression: Compute, Parameters, and Data", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "comment": "fixed typos", "summary": "Empirically, large-scale deep learning models often satisfy a neural scaling\nlaw: the test error of the trained model improves polynomially as the model\nsize and data size grow. However, conventional wisdom suggests the test error\nconsists of approximation, bias, and variance errors, where the variance error\nincreases with model size. This disagrees with the general form of neural\nscaling laws, which predict that increasing model size monotonically improves\nperformance.\n  We study the theory of scaling laws in an infinite dimensional linear\nregression setup. Specifically, we consider a model with $M$ parameters as a\nlinear function of sketched covariates. The model is trained by one-pass\nstochastic gradient descent (SGD) using $N$ data. Assuming the optimal\nparameter satisfies a Gaussian prior and the data covariance matrix has a\npower-law spectrum of degree $a>1$, we show that the reducible part of the test\nerror is $\\Theta(M^{-(a-1)} + N^{-(a-1)/a})$. The variance error, which\nincreases with $M$, is dominated by the other errors due to the implicit\nregularization of SGD, thus disappearing from the bound. Our theory is\nconsistent with the empirical neural scaling laws and verified by numerical\nsimulation.", "AI": {"tldr": "The paper explains neural scaling laws by showing that variance error, which typically increases with model size, is dominated by other errors due to SGD's implicit regularization, aligning with empirical observations.", "motivation": "To reconcile the discrepancy between conventional wisdom (variance error increases with model size) and empirical neural scaling laws (performance improves with model size).", "method": "Theoretical analysis in an infinite-dimensional linear regression setup, using one-pass SGD with sketched covariates and assuming Gaussian prior and power-law data covariance spectrum.", "result": "The reducible test error is \u0398(M\u2212(a\u22121) + N\u2212(a\u22121)/a), with variance error dominated by other errors due to SGD's implicit regularization.", "conclusion": "The theory aligns with empirical neural scaling laws and is supported by simulations, explaining why increasing model size improves performance despite conventional expectations."}}
{"id": "2506.08654", "pdf": "https://arxiv.org/pdf/2506.08654", "abs": "https://arxiv.org/abs/2506.08654", "authors": ["Ciro Benito Raggio", "Paolo Zaffino", "Maria Francesca Spadea"], "title": "A Privacy-Preserving Federated Learning Framework for Generalizable CBCT to Synthetic CT Translation in Head and Neck", "categories": ["physics.med-ph", "cs.LG"], "comment": null, "summary": "Shortened Abstract\n  Cone-beam computed tomography (CBCT) has become a widely adopted modality for\nimage-guided radiotherapy (IGRT). However, CBCT suffers from increased noise,\nlimited soft-tissue contrast, and artifacts, resulting in unreliable Hounsfield\nunit values and hindering direct dose calculation. Synthetic CT (sCT)\ngeneration from CBCT addresses these issues, especially using deep learning\n(DL) methods. Existing approaches are limited by institutional heterogeneity,\nscanner-dependent variations, and data privacy regulations that prevent\nmulti-center data sharing.\n  To overcome these challenges, we propose a cross-silo horizontal federated\nlearning (FL) approach for CBCT-to-sCT synthesis in the head and neck region,\nextending our FedSynthCT framework. A conditional generative adversarial\nnetwork was collaboratively trained on data from three European medical centers\nin the public SynthRAD2025 challenge dataset.\n  The federated model demonstrated effective generalization across centers,\nwith mean absolute error (MAE) ranging from $64.38\\pm13.63$ to $85.90\\pm7.10$\nHU, structural similarity index (SSIM) from $0.882\\pm0.022$ to $0.922\\pm0.039$,\nand peak signal-to-noise ratio (PSNR) from $32.86\\pm0.94$ to $34.91\\pm1.04$ dB.\nNotably, on an external validation dataset of 60 patients, comparable\nperformance was achieved (MAE: $75.22\\pm11.81$ HU, SSIM: $0.904\\pm0.034$, PSNR:\n$33.52\\pm2.06$ dB) without additional training, confirming robust\ngeneralization despite protocol, scanner differences and registration errors.\n  These findings demonstrate the technical feasibility of FL for CBCT-to-sCT\nsynthesis while preserving data privacy and offer a collaborative solution for\ndeveloping generalizable models across institutions without centralized data\nsharing or site-specific fine-tuning.", "AI": {"tldr": "A federated learning approach for CBCT-to-sCT synthesis addresses institutional heterogeneity and data privacy, achieving robust generalization across centers.", "motivation": "CBCT has limitations like noise and artifacts, hindering dose calculation. Existing DL methods face challenges due to data heterogeneity and privacy regulations.", "method": "Proposed cross-silo horizontal federated learning (FL) with a conditional GAN, trained on multi-center data from the SynthRAD2025 challenge.", "result": "FL model showed effective generalization (MAE: 64.38-85.90 HU, SSIM: 0.882-0.922, PSNR: 32.86-34.91 dB) and performed well on external validation.", "conclusion": "FL is feasible for CBCT-to-sCT synthesis, preserving privacy and enabling collaborative model development without centralized data sharing."}}
{"id": "2505.22107", "pdf": "https://arxiv.org/pdf/2505.22107", "abs": "https://arxiv.org/abs/2505.22107", "authors": ["Shuhai Zhang", "Zeng You", "Yaofo Chen", "Zhiquan Wen", "Qianyue Wang", "Zhijie Qiu", "Yuanqing Li", "Mingkui Tan"], "title": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at ICML 2025", "summary": "Transformer-based large language models (LLMs) excel in natural language\nprocessing tasks by capturing long-range dependencies through self-attention\nmechanisms. However, long-context modeling faces significant computational\ninefficiencies due to \\textit{redundant} attention computations: while\nattention weights are often \\textit{sparse}, all tokens consume \\textit{equal}\ncomputational resources. In this paper, we reformulate traditional\nprobabilistic sequence modeling as a \\textit{supervised learning task},\nenabling the separation of relevant and irrelevant tokens and providing a\nclearer understanding of redundancy. Based on this reformulation, we\ntheoretically analyze attention sparsity, revealing that only a few tokens\nsignificantly contribute to predictions. Building on this, we formulate\nattention optimization as a linear coding problem and propose a \\textit{group\ncoding strategy}, theoretically showing its ability to improve robustness\nagainst random noise and enhance learning efficiency. Motivated by this, we\npropose \\textit{Dynamic Group Attention} (DGA), which leverages the group\ncoding to explicitly reduce redundancy by aggregating less important tokens\nduring attention computation. Empirical results show that our DGA significantly\nreduces computational costs while maintaining competitive performance.Code is\navailable at https://github.com/bolixinyu/DynamicGroupAttention.", "AI": {"tldr": "The paper introduces Dynamic Group Attention (DGA) to reduce computational inefficiencies in Transformer-based LLMs by optimizing attention sparsity through a group coding strategy.", "motivation": "Traditional attention mechanisms in LLMs suffer from redundant computations, as all tokens consume equal resources despite sparse attention weights.", "method": "The authors reformulate sequence modeling as a supervised task, analyze attention sparsity, and propose a group coding strategy to optimize attention. DGA dynamically aggregates less important tokens.", "result": "DGA significantly reduces computational costs while maintaining competitive performance.", "conclusion": "DGA effectively addresses redundancy in attention computations, improving efficiency without sacrificing model performance."}}
{"id": "2502.03081", "pdf": "https://arxiv.org/pdf/2502.03081", "abs": "https://arxiv.org/abs/2502.03081", "authors": ["Nona Rajabi", "Ant\u00f4nio H. Ribeiro", "Miguel Vasco", "Farzaneh Taleb", "M\u00e5rten Bj\u00f6rkman", "Danica Kragic"], "title": "Human-Aligned Image Models Improve Visual Decoding from the Brain", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Decoding visual images from brain activity has significant potential for\nadvancing brain-computer interaction and enhancing the understanding of human\nperception. Recent approaches align the representation spaces of images and\nbrain activity to enable visual decoding. In this paper, we introduce the use\nof human-aligned image encoders to map brain signals to images. We hypothesize\nthat these models more effectively capture perceptual attributes associated\nwith the rapid visual stimuli presentations commonly used in visual brain data\nrecording experiments. Our empirical results support this hypothesis,\ndemonstrating that this simple modification improves image retrieval accuracy\nby up to 21% compared to state-of-the-art methods. Comprehensive experiments\nconfirm consistent performance improvements across diverse EEG architectures,\nimage encoders, alignment methods, participants, and brain imaging modalities", "AI": {"tldr": "Using human-aligned image encoders improves visual image decoding from brain activity by 21% over state-of-the-art methods.", "motivation": "Advance brain-computer interaction and deepen understanding of human perception by improving visual decoding from brain signals.", "method": "Introduce human-aligned image encoders to map brain signals to images, hypothesizing better capture of perceptual attributes.", "result": "Empirical results show up to 21% improvement in image retrieval accuracy across diverse setups.", "conclusion": "Human-aligned encoders enhance visual decoding performance consistently across various conditions."}}
{"id": "2406.13348", "pdf": "https://arxiv.org/pdf/2406.13348", "abs": "https://arxiv.org/abs/2406.13348", "authors": ["Jiacheng Du", "Zhibo Wang", "Jie Zhang", "Xiaoyi Pang", "Jiahui Hu", "Kui Ren"], "title": "Textual Unlearning Gives a False Sense of Unlearning", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Language Models (LMs) are prone to ''memorizing'' training data, including\nsubstantial sensitive user information. To mitigate privacy risks and safeguard\nthe right to be forgotten, machine unlearning has emerged as a promising\napproach for enabling LMs to efficiently ''forget'' specific texts. However,\ndespite the good intentions, is textual unlearning really as effective and\nreliable as expected? To address the concern, we first propose Unlearning\nLikelihood Ratio Attack+ (U-LiRA+), a rigorous textual unlearning auditing\nmethod, and find that unlearned texts can still be detected with very high\nconfidence after unlearning. Further, we conduct an in-depth investigation on\nthe privacy risks of textual unlearning mechanisms in deployment and present\nthe Textual Unlearning Leakage Attack (TULA), along with its variants in both\nblack- and white-box scenarios. We show that textual unlearning mechanisms\ncould instead reveal more about the unlearned texts, exposing them to\nsignificant membership inference and data reconstruction risks. Our findings\nhighlight that existing textual unlearning actually gives a false sense of\nunlearning, underscoring the need for more robust and secure unlearning\nmechanisms.", "AI": {"tldr": "The paper reveals that textual unlearning in LMs is less effective than expected, as unlearned texts can still be detected, and unlearning mechanisms may leak sensitive information.", "motivation": "To assess the effectiveness and reliability of textual unlearning in LMs, given privacy concerns and the right to be forgotten.", "method": "Proposes U-LiRA+ for auditing unlearning and introduces TULA to investigate privacy risks in black- and white-box scenarios.", "result": "Unlearned texts remain detectable, and unlearning mechanisms can expose texts to membership inference and data reconstruction risks.", "conclusion": "Existing textual unlearning provides a false sense of security, calling for more robust solutions."}}
{"id": "2506.08670", "pdf": "https://arxiv.org/pdf/2506.08670", "abs": "https://arxiv.org/abs/2506.08670", "authors": ["Renjie Xu", "Chong Wu", "Maolin Che", "Zhuoheng Ran", "Yimin Wei", "Hong Yan"], "title": "sparseGeoHOPCA: A Geometric Solution to Sparse Higher-Order PCA Without Covariance Estimation", "categories": ["math.NA", "cs.LG", "cs.NA", "math.OC"], "comment": null, "summary": "We propose sparseGeoHOPCA, a novel framework for sparse higher-order\nprincipal component analysis (SHOPCA) that introduces a geometric perspective\nto high-dimensional tensor decomposition. By unfolding the input tensor along\neach mode and reformulating the resulting subproblems as structured binary\nlinear optimization problems, our method transforms the original nonconvex\nsparse objective into a tractable geometric form. This eliminates the need for\nexplicit covariance estimation and iterative deflation, enabling significant\ngains in both computational efficiency and interpretability, particularly in\nhigh-dimensional and unbalanced data scenarios. We theoretically establish the\nequivalence between the geometric subproblems and the original SHOPCA\nformulation, and derive worst-case approximation error bounds based on\nclassical PCA residuals, providing data-dependent performance guarantees. The\nproposed algorithm achieves a total computational complexity of\n$O\\left(\\sum_{n=1}^{N} (k_n^3 + J_n k_n^2)\\right)$, which scales linearly with\ntensor size. Extensive experiments demonstrate that sparseGeoHOPCA accurately\nrecovers sparse supports in synthetic settings, preserves classification\nperformance under 10$\\times$ compression, and achieves high-quality image\nreconstruction on ImageNet, highlighting its robustness and versatility.", "AI": {"tldr": "sparseGeoHOPCA is a sparse higher-order PCA framework using geometric optimization for efficient, interpretable tensor decomposition without explicit covariance estimation.", "motivation": "Addresses challenges in high-dimensional tensor decomposition by introducing a geometric perspective to improve computational efficiency and interpretability.", "method": "Unfolds tensors into structured binary linear optimization problems, transforming nonconvex objectives into tractable geometric forms.", "result": "Achieves linear computational complexity, accurate sparse support recovery, high compression performance, and robust image reconstruction.", "conclusion": "sparseGeoHOPCA is efficient, scalable, and versatile for high-dimensional data, with theoretical guarantees and practical benefits."}}
{"id": "2506.00551", "pdf": "https://arxiv.org/pdf/2506.00551", "abs": "https://arxiv.org/abs/2506.00551", "authors": ["Ming Wang", "Peidong Wang", "Lin Wu", "Xiaocui Yang", "Daling Wang", "Shi Feng", "Yuxin Chen", "Bixuan Wang", "Yifei Zhang"], "title": "AnnaAgent: Dynamic Evolution Agent System with Multi-Session Memory for Realistic Seeker Simulation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Constrained by the cost and ethical concerns of involving real seekers in\nAI-driven mental health, researchers develop LLM-based conversational agents\n(CAs) with tailored configurations, such as profiles, symptoms, and scenarios,\nto simulate seekers. While these efforts advance AI in mental health, achieving\nmore realistic seeker simulation remains hindered by two key challenges:\ndynamic evolution and multi-session memory. Seekers' mental states often\nfluctuate during counseling, which typically spans multiple sessions. To\naddress this, we propose AnnaAgent, an emotional and cognitive dynamic agent\nsystem equipped with tertiary memory. AnnaAgent incorporates an emotion\nmodulator and a complaint elicitor trained on real counseling dialogues,\nenabling dynamic control of the simulator's configurations. Additionally, its\ntertiary memory mechanism effectively integrates short-term and long-term\nmemory across sessions. Evaluation results, both automated and manual,\ndemonstrate that AnnaAgent achieves more realistic seeker simulation in\npsychological counseling compared to existing baselines. The ethically reviewed\nand screened code can be found on https://github.com/sci-m-wang/AnnaAgent.", "AI": {"tldr": "AnnaAgent is an LLM-based conversational agent designed for realistic seeker simulation in mental health counseling, addressing dynamic evolution and multi-session memory challenges.", "motivation": "To overcome limitations in simulating real seekers due to ethical and cost constraints, while capturing dynamic mental state fluctuations and multi-session interactions.", "method": "AnnaAgent uses an emotion modulator, complaint elicitor, and tertiary memory mechanism trained on real counseling dialogues for dynamic configuration control and memory integration.", "result": "AnnaAgent outperforms existing baselines in realistic seeker simulation, validated through automated and manual evaluations.", "conclusion": "AnnaAgent advances AI-driven mental health research by providing a more realistic and ethically reviewed simulation tool."}}
{"id": "2502.07306", "pdf": "https://arxiv.org/pdf/2502.07306", "abs": "https://arxiv.org/abs/2502.07306", "authors": ["Navid Rajabi", "Jana Kosecka"], "title": "TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO"], "comment": "Accepted to CVPR 2025 Workshop - Foundation Models Meet Embodied\n  Agents", "summary": "In this work, we propose a modular approach for the Vision-Language\nNavigation (VLN) task by decomposing the problem into four sub-modules that use\nstate-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs)\nin a zero-shot setting. Given navigation instruction in natural language, we\nfirst prompt LLM to extract the landmarks and the order in which they are\nvisited. Assuming the known model of the environment, we retrieve the top-k\nlocations of the last landmark and generate $k$ path hypotheses from the\nstarting location to the last landmark using the shortest path algorithm on the\ntopological map of the environment. Each path hypothesis is represented by a\nsequence of panoramas. We then use dynamic programming to compute the alignment\nscore between the sequence of panoramas and the sequence of landmark names,\nwhich match scores obtained from VLM. Finally, we compute the nDTW metric\nbetween the hypothesis that yields the highest alignment score to evaluate the\npath fidelity. We demonstrate superior performance compared to other approaches\nthat use joint semantic maps like VLMaps on the complex R2R-Habitat instruction\ndataset and quantify in detail the effect of visual grounding on navigation\nperformance.", "AI": {"tldr": "A modular approach for Vision-Language Navigation (VLN) using LLMs and VLMs in zero-shot, outperforming joint semantic map methods.", "motivation": "To improve VLN by decomposing the task into sub-modules leveraging LLMs and VLMs for better navigation performance.", "method": "Decomposes VLN into four sub-modules: landmark extraction, path hypothesis generation, panorama-landmark alignment, and path evaluation using nDTW.", "result": "Superior performance on R2R-Habitat dataset, highlighting the impact of visual grounding.", "conclusion": "The modular approach effectively enhances VLN by leveraging LLMs and VLMs, outperforming existing methods."}}
{"id": "2407.12282", "pdf": "https://arxiv.org/pdf/2407.12282", "abs": "https://arxiv.org/abs/2407.12282", "authors": ["Vint Lee", "Minh Nguyen", "Leena Elzeiny", "Chun Deng", "Pieter Abbeel", "John Wawrzynek"], "title": "Chip Placement with Diffusion Models", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "Code available at https://github.com/vint-1/chipdiffusion", "summary": "Macro placement is a vital step in digital circuit design that defines the\nphysical location of large collections of components, known as macros, on a 2D\nchip. Because key performance metrics of the chip are determined by the\nplacement, optimizing it is crucial. Existing learning-based methods typically\nfall short because of their reliance on reinforcement learning (RL), which is\nslow and struggles to generalize, requiring online training on each new\ncircuit. Instead, we train a diffusion model capable of placing new circuits\nzero-shot, using guided sampling in lieu of RL to optimize placement quality.\nTo enable such models to train at scale, we designed a capable yet efficient\narchitecture for the denoising model, and propose a novel algorithm to generate\nlarge synthetic datasets for pre-training. To allow zero-shot transfer to real\ncircuits, we empirically study the design decisions of our dataset generation\nalgorithm, and identify several key factors enabling generalization. When\ntrained on our synthetic data, our models generate high-quality placements on\nunseen, realistic circuits, achieving competitive performance on placement\nbenchmarks compared to state-of-the-art methods.", "AI": {"tldr": "A diffusion model is proposed for zero-shot macro placement in chip design, outperforming RL-based methods by leveraging synthetic data and guided sampling.", "motivation": "Optimizing macro placement is crucial for chip performance, but RL-based methods are slow and lack generalization.", "method": "A diffusion model is trained using synthetic data and guided sampling to place macros zero-shot.", "result": "The model achieves competitive performance on benchmarks, generating high-quality placements for unseen circuits.", "conclusion": "The diffusion model offers a scalable and efficient alternative to RL for macro placement, with strong generalization capabilities."}}
{"id": "2506.08725", "pdf": "https://arxiv.org/pdf/2506.08725", "abs": "https://arxiv.org/abs/2506.08725", "authors": ["Hyeon Jeon", "Jeongin Park", "Sungbok Shin", "Jinwook Seo"], "title": "Stop Misusing t-SNE and UMAP for Visual Analytics", "categories": ["cs.HC", "cs.LG"], "comment": "9 pages", "summary": "Misuses of t-SNE and UMAP in visual analytics have become increasingly\ncommon. For example, although t-SNE and UMAP projections often do not\nfaithfully reflect true distances between clusters, practitioners frequently\nuse them to investigate inter-cluster relationships. In this paper, we bring\nthis issue to the surface and comprehensively investigate why such misuse\noccurs and how to prevent it. We conduct a literature review of 114 papers to\nverify the prevalence of the misuse and analyze the reasonings behind it. We\nthen execute an interview study to uncover practitioners' implicit motivations\nfor using these techniques -- rationales often undisclosed in the literature.\nOur findings indicate that misuse of t-SNE and UMAP primarily stems from\nlimited discourse on their appropriate use in visual analytics. We conclude by\nproposing future directions and concrete action items to promote more\nreasonable use of DR.", "AI": {"tldr": "The paper highlights the misuse of t-SNE and UMAP in visual analytics, investigates its prevalence and causes, and suggests solutions for proper use.", "motivation": "To address the common misuse of t-SNE and UMAP in analyzing inter-cluster relationships, which often misrepresents true distances.", "method": "Conducted a literature review of 114 papers and an interview study to analyze misuse prevalence and practitioners' motivations.", "result": "Misuse arises from limited discourse on proper usage; practitioners often lack awareness of the techniques' limitations.", "conclusion": "Proposes future directions and action items to encourage more reasonable use of dimensionality reduction techniques."}}
{"id": "2506.00739", "pdf": "https://arxiv.org/pdf/2506.00739", "abs": "https://arxiv.org/abs/2506.00739", "authors": ["Chiyu Zhang", "Marc-Alexandre Cote", "Michael Albada", "Anush Sankaran", "Jack W. Stokes", "Tong Wang", "Amir Abdi", "William Blum", "Muhammad Abdul-Mageed"], "title": "DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments", "categories": ["cs.CL"], "comment": null, "summary": "Large language model (LLM) agents have shown impressive capabilities in human\nlanguage comprehension and reasoning, yet their potential in cybersecurity\nremains underexplored. We introduce DefenderBench, a practical, open-source\ntoolkit for evaluating language agents across offense, defense, and\ncybersecurity knowledge-based tasks. DefenderBench includes environments for\nnetwork intrusion, malicious content detection, code vulnerability analysis,\nand cybersecurity knowledge assessment. It is intentionally designed to be\naffordable and easily accessible for researchers while providing fair and\nrigorous assessment. We benchmark several state-of-the-art (SoTA) and popular\nLLMs, including both open- and closed-weight models, using a standardized\nagentic framework. Our results show that Claude-3.7-sonnet performs best with a\nDefenderBench score of 81.65, followed by Claude-3.7-sonnet-think with 78.40,\nwhile the best open-weight model, Llama 3.3 70B, is not far behind with a\nDefenderBench score of 71.81. DefenderBench's modular design allows seamless\nintegration of custom LLMs and tasks, promoting reproducibility and fair\ncomparisons. An anonymized version of DefenderBench is available at\nhttps://github.com/microsoft/DefenderBench.", "AI": {"tldr": "DefenderBench is an open-source toolkit for evaluating LLM agents in cybersecurity tasks, benchmarking models like Claude-3.7-sonnet and Llama 3.3 70B.", "motivation": "To explore the underexplored potential of LLM agents in cybersecurity and provide a practical, affordable evaluation toolkit.", "method": "Introduces DefenderBench, a modular toolkit with tasks like network intrusion detection and vulnerability analysis, benchmarking SoTA LLMs.", "result": "Claude-3.7-sonnet scored highest (81.65), followed by Claude-3.7-sonnet-think (78.40), with Llama 3.3 70B (71.81) as the top open-weight model.", "conclusion": "DefenderBench enables fair, reproducible evaluation of LLMs in cybersecurity, with modularity for custom tasks and models."}}
{"id": "2502.17237", "pdf": "https://arxiv.org/pdf/2502.17237", "abs": "https://arxiv.org/abs/2502.17237", "authors": ["Gabriele Berton", "Carlo Masone"], "title": "MegaLoc: One Retrieval to Place Them All", "categories": ["cs.CV"], "comment": "Tech Report", "summary": "Retrieving images from the same location as a given query is an important\ncomponent of multiple computer vision tasks, like Visual Place Recognition,\nLandmark Retrieval, Visual Localization, 3D reconstruction, and SLAM. However,\nexisting solutions are built to specifically work for one of these tasks, and\nare known to fail when the requirements slightly change or when they meet\nout-of-distribution data. In this paper we combine a variety of existing\nmethods, training techniques, and datasets to train a retrieval model, called\nMegaLoc, that is performant on multiple tasks. We find that MegaLoc (1)\nachieves state of the art on a large number of Visual Place Recognition\ndatasets, (2) impressive results on common Landmark Retrieval datasets, and (3)\nsets a new state of the art for Visual Localization on the LaMAR datasets,\nwhere we only changed the retrieval method to the existing localization\npipeline. The code for MegaLoc is available at\nhttps://github.com/gmberton/MegaLoc", "AI": {"tldr": "MegaLoc is a versatile retrieval model combining existing methods, achieving state-of-the-art results in Visual Place Recognition, Landmark Retrieval, and Visual Localization.", "motivation": "Existing solutions are task-specific and fail under changing requirements or out-of-distribution data. MegaLoc aims to address this by being adaptable across multiple tasks.", "method": "Combines various existing methods, training techniques, and datasets to train MegaLoc.", "result": "Achieves state-of-the-art in Visual Place Recognition, performs well in Landmark Retrieval, and sets a new benchmark in Visual Localization on LaMAR datasets.", "conclusion": "MegaLoc demonstrates strong adaptability and performance across multiple computer vision tasks, outperforming specialized solutions."}}
{"id": "2409.08379", "pdf": "https://arxiv.org/pdf/2409.08379", "abs": "https://arxiv.org/abs/2409.08379", "authors": ["Doron Yeverechyahu", "Raveesh Mayya", "Gal Oestreicher-Singer"], "title": "The Impact of Large Language Models on Open-source Innovation: Evidence from GitHub Copilot", "categories": ["cs.SE", "cs.AI", "econ.GN", "q-fin.EC", "I.2.7; D.2.7"], "comment": "JEL Classification: O31, C88, J24, O35, L86", "summary": "Large Language Models (LLMs) have been shown to enhance individual\nproductivity in guided settings. Whereas LLMs are likely to also transform\ninnovation processes in a collaborative work setting, it is unclear what\ntrajectory this transformation will follow. Innovation in these contexts\nencompasses both capability innovation that explores new possibilities by\nacquiring new competencies in a project and iterative innovation that exploits\nexisting foundations by enhancing established competencies and improving\nproject quality. Whether LLMs affect these two aspects of collaborative work\nand to what extent is an open empirical question. Open-source development\nprovides an ideal setting to examine LLM impacts on these innovation types, as\nits voluntary and open/collaborative nature of contributions provides the\ngreatest opportunity for technological augmentation. We focus on open-source\nprojects on GitHub by leveraging a natural experiment around the selective\nrollout of GitHub Copilot (a programming-focused LLM) in October 2021, where\nGitHub Copilot selectively supported programming languages like Python or Rust,\nbut not R or Haskell. We observe a significant jump in overall contributions,\nsuggesting that LLMs effectively augment collaborative innovation in an\nunguided setting. Interestingly, Copilot's launch increased iterative\ninnovation focused on maintenance-related or feature-refining contributions\nsignificantly more than it did capability innovation through code-development\nor feature-introducing commits. This disparity was more pronounced after the\nmodel upgrade in June 2022 and was evident in active projects with extensive\ncoding activity, suggesting that as both LLM capabilities and/or available\ncontextual information improve, the gap between capability and iterative\ninnovation may widen. We discuss practical and policy implications to\nincentivize high-value innovative solutions.", "AI": {"tldr": "LLMs like GitHub Copilot boost collaborative innovation in open-source projects, favoring iterative over capability innovation, with implications for policy and practice.", "motivation": "To understand how LLMs transform collaborative innovation, particularly in open-source settings, and their differential impact on capability vs. iterative innovation.", "method": "Analyzed GitHub projects using a natural experiment around GitHub Copilot's selective rollout, comparing supported (e.g., Python) and unsupported (e.g., R) languages.", "result": "LLMs increased overall contributions, especially iterative innovation (maintenance/refinement), more than capability innovation (new features). The gap widened post-model upgrade.", "conclusion": "LLMs augment collaborative innovation but skew toward iterative improvements. Policies should incentivize high-value solutions to balance innovation types."}}
{"id": "2506.08734", "pdf": "https://arxiv.org/pdf/2506.08734", "abs": "https://arxiv.org/abs/2506.08734", "authors": ["Nelvin Tan", "Yu-Ching Shih", "Dong Yang", "Amol Salunkhe"], "title": "Flexible and Efficient Drift Detection without Labels", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "9 pages, 4 figures", "summary": "Machine learning models are being increasingly used to automate decisions in\nalmost every domain, and ensuring the performance of these models is crucial\nfor ensuring high quality machine learning enabled services. Ensuring concept\ndrift is detected early is thus of the highest importance. A lot of research on\nconcept drift has focused on the supervised case that assumes the true labels\nof supervised tasks are available immediately after making predictions.\nControlling for false positives while monitoring the performance of predictive\nmodels used to make inference from extremely large datasets periodically, where\nthe true labels are not instantly available, becomes extremely challenging. We\npropose a flexible and efficient concept drift detection algorithm that uses\nclassical statistical process control in a label-less setting to accurately\ndetect concept drifts. We shown empirically that under computational\nconstraints, our approach has better statistical power than previous known\nmethods. Furthermore, we introduce a new drift detection framework to model the\nscenario of detecting drift (without labels) given prior detections, and show\nour how our drift detection algorithm can be incorporated effectively into this\nframework. We demonstrate promising performance via numerical simulations.", "AI": {"tldr": "A flexible, efficient concept drift detection algorithm for label-less settings, outperforming prior methods under computational constraints.", "motivation": "Ensuring early detection of concept drift is critical for maintaining ML model performance, especially when true labels are not immediately available.", "method": "Uses classical statistical process control in a label-less setting and introduces a new drift detection framework incorporating prior detections.", "result": "Empirically shows better statistical power than previous methods and demonstrates promising performance in simulations.", "conclusion": "The proposed algorithm effectively detects concept drift without labels and integrates well into a broader detection framework."}}
{"id": "2506.02204", "pdf": "https://arxiv.org/pdf/2506.02204", "abs": "https://arxiv.org/abs/2506.02204", "authors": ["Lindia Tjuatja", "Graham Neubig"], "title": "BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Language model evaluation is a daunting task: prompts are brittle,\ncorpus-level perplexities are vague, and the choice of benchmarks are endless.\nFinding examples that show meaningful, generalizable differences between two\nLMs is crucial to understanding where one model succeeds and another fails. Can\nthis process be done automatically? In this work, we propose methodology for\nautomated comparison of language models that uses performance-aware contextual\nembeddings to find fine-grained features of text where one LM outperforms\nanother. Our method, which we name BehaviorBox, extracts coherent features that\ndemonstrate differences with respect to the ease of generation between two LMs.\nSpecifically, BehaviorBox finds features that describe groups of words in\nfine-grained contexts, such as \"conditional 'were' in the phrase 'if you were'\"\nand \"exclamation marks after emotional statements\", where one model outperforms\nanother within a particular datatset. We apply BehaviorBox to compare models\nthat vary in size, model family, and post-training, and enumerate insights into\nspecific contexts that illustrate meaningful differences in performance which\ncannot be found by measures such as corpus-level perplexity alone.", "AI": {"tldr": "BehaviorBox automates LM comparison by identifying fine-grained text features where one model outperforms another, revealing insights beyond corpus-level metrics.", "motivation": "Language model evaluation is challenging due to brittle prompts, vague perplexities, and endless benchmarks. Automating meaningful comparisons is crucial.", "method": "BehaviorBox uses performance-aware contextual embeddings to find fine-grained text features (e.g., specific word groups or contexts) where one LM excels over another.", "result": "The method identifies coherent features (e.g., conditional phrases or emotional punctuation) that highlight performance differences, applicable across model sizes, families, and post-training.", "conclusion": "BehaviorBox provides actionable insights into LM performance differences, surpassing traditional metrics like perplexity."}}
{"id": "2503.09081", "pdf": "https://arxiv.org/pdf/2503.09081", "abs": "https://arxiv.org/abs/2503.09081", "authors": ["Xiaowei Bi", "Zheyuan Xu"], "title": "Everything Can Be Described in Words: A Simple Unified Multi-Modal Framework with Semantic and Temporal Alignment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "While multi-modal learning has advanced significantly, current approaches\noften create inconsistencies in representation and reasoning of different\nmodalities. We propose UMaT, a theoretically-grounded framework that unifies\nvisual and auditory inputs as structured text for large language models,\naddressing semantic alignment, temporal synchronization, and efficient sparse\ninformation retrieval. It significantly improves state-of-the-art Long Video\nQuestion Answering accuracy (up to 13.7%, and 16.9% on long videos) via\nredundancy minimization and structured textual representation for unified\nmulti-modal reasoning", "AI": {"tldr": "UMaT unifies visual and auditory inputs as structured text for LLMs, improving multi-modal learning by addressing semantic alignment, temporal sync, and sparse retrieval. Boosts Long Video QA accuracy by up to 16.9%.", "motivation": "Current multi-modal learning methods suffer from inconsistencies in representation and reasoning across modalities.", "method": "Proposes UMaT, a framework converting visual and auditory inputs into structured text for LLMs, focusing on semantic alignment, temporal synchronization, and sparse retrieval.", "result": "Significantly improves Long Video QA accuracy (up to 13.7% generally, 16.9% on long videos).", "conclusion": "UMaT effectively unifies multi-modal inputs, enhancing reasoning and accuracy in tasks like Long Video QA."}}
{"id": "2409.18390", "pdf": "https://arxiv.org/pdf/2409.18390", "abs": "https://arxiv.org/abs/2409.18390", "authors": ["Alexander Htet Kyaw", "Se Hwan Jeon", "Miana Smith", "Neil Gershenfeld"], "title": "Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": "This work has been submitted to the IEEE for possible publication. An\n  updated version will replace this version", "summary": "We present a system that transforms speech into physical objects using 3D\ngenerative AI and discrete robotic assembly. By leveraging natural language\ninput, the system makes design and manufacturing more accessible to individuals\nwithout expertise in 3D modeling or robotic programming. While current\ngenerative AI models can produce a wide range of 3D digital assets,\nAI-generated meshes are not directly suitable for robotic fabrication and do\nnot account for fabrication constraints. To address this, we contribute a\nworkflow that integrates natural language processing, 3D generative AI, and\ndiscrete robotic assembly. The system automatically analyzes and modifies\nAI-generated geometry to meet physical constraints, such as component count,\noverhangs, and connectivity, and produces a feasible robotic assembly sequence\nand toolpath. The results are demonstrated through the assembly of various\nobjects, ranging from chairs to shelves, which are prompted via speech and\nrealized within 5 minutes using a robotic arm.", "AI": {"tldr": "A system integrates speech, 3D generative AI, and robotic assembly to create physical objects from natural language input, addressing fabrication constraints.", "motivation": "To make design and manufacturing accessible to non-experts by bypassing the need for 3D modeling or robotic programming skills.", "method": "Combines natural language processing, 3D generative AI, and robotic assembly to modify AI-generated geometry for fabrication constraints.", "result": "Demonstrated by assembling objects like chairs and shelves from speech prompts in under 5 minutes.", "conclusion": "The workflow successfully bridges the gap between AI-generated designs and practical robotic fabrication."}}
{"id": "2506.08749", "pdf": "https://arxiv.org/pdf/2506.08749", "abs": "https://arxiv.org/abs/2506.08749", "authors": ["Viktoria Patapovich", "Mo Kordzanganeh", "Alexey Melnikov"], "title": "Superposed Parameterised Quantum Circuits", "categories": ["quant-ph", "cs.ET", "cs.LG", "cs.NE"], "comment": "20 pages, 6 figures, 3 tables", "summary": "Quantum machine learning has shown promise for high-dimensional data\nanalysis, yet many existing approaches rely on linear unitary operations and\nshared trainable parameters across outputs. These constraints limit\nexpressivity and scalability relative to the multi-layered, non-linear\narchitectures of classical deep networks. We introduce superposed parameterised\nquantum circuits to overcome these limitations. By combining flip-flop quantum\nrandom-access memory with repeat-until-success protocols, a superposed\nparameterised quantum circuit embeds an exponential number of parameterised\nsub-models in a single circuit and induces polynomial activation functions\nthrough amplitude transformations and post-selection. We provide an analytic\ndescription of the architecture, showing how multiple parameter sets are\ntrained in parallel while non-linear amplitude transformations broaden\nrepresentational power beyond conventional quantum kernels. Numerical\nexperiments underscore these advantages: on a 1D step-function regression a\ntwo-qubit superposed parameterised quantum circuit cuts the mean-squared error\nby three orders of magnitude versus a parameter-matched variational baseline;\non a 2D star-shaped two-dimensional classification task, introducing a\nquadratic activation lifts accuracy to 81.4% and reduces run-to-run variance\nthree-fold. These results position superposed parameterised quantum circuits as\na hardware-efficient route toward deeper, more versatile parameterised quantum\ncircuits capable of learning complex decision boundaries.", "AI": {"tldr": "Superposed parameterised quantum circuits (SPQCs) enhance quantum machine learning by embedding exponential sub-models and enabling polynomial activations, outperforming traditional methods in expressivity and scalability.", "motivation": "Existing quantum machine learning methods are limited by linear unitary operations and shared parameters, restricting expressivity and scalability compared to classical deep networks.", "method": "SPQCs combine flip-flop quantum random-access memory with repeat-until-success protocols to embed multiple parameter sets and induce non-linear activations via amplitude transformations and post-selection.", "result": "SPQCs reduce mean-squared error by three orders of magnitude in regression and achieve 81.4% accuracy in classification, with reduced variance.", "conclusion": "SPQCs offer a hardware-efficient path to deeper, more versatile quantum circuits for complex learning tasks."}}
{"id": "2506.02678", "pdf": "https://arxiv.org/pdf/2506.02678", "abs": "https://arxiv.org/abs/2506.02678", "authors": ["Zhong-Zhi Li", "Xiao Liang", "Zihao Tang", "Lei Ji", "Peijie Wang", "Haotian Xu", "Xing W", "Haizhen Huang", "Weiwei Deng", "Ying Nian Wu", "Yeyun Gong", "Zhijiang Guo", "Xiao Liu", "Fei Yin", "Cheng-Lin Liu"], "title": "TL;DR: Too Long, Do Re-weighting for Efficient LLM Reasoning Compression", "categories": ["cs.CL", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "Large Language Models (LLMs) have recently achieved remarkable progress by\nleveraging Reinforcement Learning and extended Chain-of-Thought (CoT)\ntechniques. However, the challenge of performing efficient language\nreasoning--especially during inference with extremely long outputs--has drawn\nincreasing attention from the research community. In this work, we propose a\ndynamic ratio-based training pipeline that does not rely on sophisticated data\nannotations or interpolation between multiple models. We continuously balance\nthe weights between the model's System-1 and System-2 data to eliminate\nredundant reasoning processes while preserving the model's reasoning\ncapability. We validate our approach across models on DeepSeek-R1-Distill-7B\nand DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying\ndifficulty levels. Our method significantly reduces the number of output tokens\nby nearly 40% while maintaining the accuracy of the reasoning. Our code and\ndata will be available soon.", "AI": {"tldr": "A dynamic ratio-based training pipeline for LLMs reduces output tokens by 40% while maintaining reasoning accuracy, tested on DeepSeek models.", "motivation": "Addressing the challenge of efficient language reasoning, especially for long outputs, without relying on complex annotations or model interpolation.", "method": "Dynamic ratio-based training balancing System-1 and System-2 data weights to eliminate redundant reasoning.", "result": "40% reduction in output tokens with preserved reasoning accuracy on DeepSeek-R1-Distill models.", "conclusion": "The method effectively optimizes LLM inference efficiency without sacrificing performance."}}
{"id": "2504.06751", "pdf": "https://arxiv.org/pdf/2504.06751", "abs": "https://arxiv.org/abs/2504.06751", "authors": ["Leszek Luchowski", "Dariusz Pojda"], "title": "Visualization of a multidimensional point cloud as a 3D swarm of avatars", "categories": ["cs.CV", "cs.HC"], "comment": "26 pages, 13 figures", "summary": "This paper proposes an innovative technique for representing multidimensional\ndatasets using icons inspired by Chernoff faces. Our approach combines\nclassical projection techniques with the explicit assignment of selected data\ndimensions to avatar (facial) features, leveraging the innate human ability to\ninterpret facial traits. We introduce a semantic division of data dimensions\ninto intuitive and technical categories, assigning the former to avatar\nfeatures and projecting the latter into a four-dimensional (or higher) spatial\nembedding. The technique is implemented as a plugin for the open-source\ndpVision visualization platform, enabling users to interactively explore data\nin the form of a swarm of avatars whose spatial positions and visual features\njointly encode various aspects of the dataset. Experimental results with\nsynthetic test data and a 12-dimensional dataset of Portuguese Vinho Verde\nwines demonstrate that the proposed method enhances interpretability and\nfacilitates the analysis of complex data structures.", "AI": {"tldr": "The paper introduces a novel technique for visualizing multidimensional data using avatar-like icons inspired by Chernoff faces, combining projection methods with intuitive facial feature mapping.", "motivation": "To leverage human ability to interpret facial traits for better understanding of complex datasets.", "method": "Combines projection techniques with assigning data dimensions to avatar features, implemented as a plugin for dpVision.", "result": "Enhances interpretability and aids analysis of complex data, as shown with synthetic and wine datasets.", "conclusion": "The method effectively improves data visualization and interpretability for multidimensional datasets."}}
{"id": "2410.00535", "pdf": "https://arxiv.org/pdf/2410.00535", "abs": "https://arxiv.org/abs/2410.00535", "authors": ["Francisco N. F. Q. Simoes", "Mehdi Dastani", "Thijs van Ommen"], "title": "The Causal Information Bottleneck and Optimal Causal Variable Abstractions", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "comment": "Accepted at UAI 2025. Code available at\n  github.com/francisco-simoes/cib-optimization-psagd", "summary": "To effectively study complex causal systems, it is often useful to construct\nabstractions of parts of the system by discarding irrelevant details while\npreserving key features. The Information Bottleneck (IB) method is a widely\nused approach to construct variable abstractions by compressing random\nvariables while retaining predictive power over a target variable. Traditional\nmethods like IB are purely statistical and ignore underlying causal structures,\nmaking them ill-suited for causal tasks. We propose the Causal Information\nBottleneck (CIB), a causal extension of the IB, which compresses a set of\nchosen variables while maintaining causal control over a target variable. This\nmethod produces abstractions of (sets of) variables which are causally\ninterpretable, give us insight about the interactions between the abstracted\nvariables and the target variable, and can be used when reasoning about\ninterventions. We present experimental results demonstrating that the learned\nabstractions accurately capture causal relations as intended.", "AI": {"tldr": "The paper introduces the Causal Information Bottleneck (CIB), a causal extension of the Information Bottleneck (IB), to create causally interpretable variable abstractions while preserving causal control over a target variable.", "motivation": "Traditional IB methods ignore causal structures, making them unsuitable for causal tasks. The authors aim to address this gap by incorporating causality into the abstraction process.", "method": "The proposed CIB method compresses chosen variables while maintaining causal control over a target variable, ensuring causally interpretable abstractions.", "result": "Experimental results show that CIB accurately captures causal relations, providing insights into variable interactions and supporting reasoning about interventions.", "conclusion": "CIB successfully extends IB to causal settings, offering a practical tool for studying complex causal systems with interpretable abstractions."}}
{"id": "2506.08783", "pdf": "https://arxiv.org/pdf/2506.08783", "abs": "https://arxiv.org/abs/2506.08783", "authors": ["Lukas Kammerer", "Deaglan J. Bartlett", "Gabriel Kronberger", "Harry Desmond", "Pedro G. Ferreira"], "title": "syren-baryon: Analytic emulators for the impact of baryons on the matter power spectrum", "categories": ["astro-ph.CO", "astro-ph.GA", "astro-ph.IM", "cs.LG", "cs.NE"], "comment": "14 pages, 6 figures. Submitted to A&A", "summary": "Baryonic physics has a considerable impact on the distribution of matter in\nour Universe on scales probed by current and future cosmological surveys,\nacting as a key systematic in such analyses. We seek simple symbolic\nparametrisations for the impact of baryonic physics on the matter power\nspectrum for a range of physically motivated models, as a function of\nwavenumber, redshift, cosmology, and parameters controlling the baryonic\nfeedback. We use symbolic regression to construct analytic approximations for\nthe ratio of the matter power spectrum in the presence of baryons to that\nwithout such effects. We obtain separate functions of each of four distinct\nsub-grid prescriptions of baryonic physics from the CAMELS suite of\nhydrodynamical simulations (Astrid, IllustrisTNG, SIMBA and Swift-EAGLE) as\nwell as for a baryonification algorithm. We also provide functions which\ndescribe the uncertainty on these predictions, due to both the stochastic\nnature of baryonic physics and the errors on our fits. The error on our\napproximations to the hydrodynamical simulations is comparable to the sample\nvariance estimated through varying initial conditions, and our baryonification\nexpression has a root mean squared error of better than one percent, although\nthis increases on small scales. These errors are comparable to those of\nprevious numerical emulators for these models. Our expressions are enforced to\nhave the physically correct behaviour on large scales and at high redshift. Due\nto their analytic form, we are able to directly interpret the impact of varying\ncosmology and feedback parameters, and we can identify parameters which have\nlittle to no effect. Each function is based on a different implementation of\nbaryonic physics, and can therefore be used to discriminate between these\nmodels when applied to real data. We provide publicly available code for all\nsymbolic approximations found.", "AI": {"tldr": "The paper presents symbolic regression-derived analytic approximations for baryonic effects on the matter power spectrum, validated against hydrodynamical simulations and a baryonification model, with errors comparable to numerical emulators.", "motivation": "Baryonic physics significantly affects matter distribution in cosmological surveys, necessitating simple, interpretable models to account for these effects.", "method": "Symbolic regression is used to create analytic functions describing baryonic impacts on the matter power spectrum, tested against CAMELS simulations and a baryonification algorithm.", "result": "The approximations achieve errors comparable to sample variance and numerical emulators, with physically correct behavior on large scales and high redshift.", "conclusion": "The analytic models enable direct interpretation of baryonic effects and discrimination between different physics implementations, with publicly available code."}}
{"id": "2506.04098", "pdf": "https://arxiv.org/pdf/2506.04098", "abs": "https://arxiv.org/abs/2506.04098", "authors": ["Wenhao Li", "Wenwu Li", "Chuyun Shen", "Junjie Sheng", "Zixiao Huang", "Di Wu", "Yun Hua", "Wei Yin", "Xiangfeng Wang", "Hongyuan Zha", "Bo Jin"], "title": "TextAtari: 100K Frames Game Playing with Language Agents", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "51 pages, 39 figures", "summary": "We present TextAtari, a benchmark for evaluating language agents on very\nlong-horizon decision-making tasks spanning up to 100,000 steps. By translating\nthe visual state representations of classic Atari games into rich textual\ndescriptions, TextAtari creates a challenging test bed that bridges sequential\ndecision-making with natural language processing. The benchmark includes nearly\n100 distinct tasks with varying complexity, action spaces, and planning\nhorizons, all rendered as text through an unsupervised representation learning\nframework (AtariARI). We evaluate three open-source large language models\n(Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks\n(zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess how\ndifferent forms of prior knowledge affect performance on these long-horizon\nchallenges. Four scenarios-Basic, Obscured, Manual Augmentation, and\nReference-based-investigate the impact of semantic understanding, instruction\ncomprehension, and expert demonstrations on agent decision-making. Our results\nreveal significant performance gaps between language agents and human players\nin extensive planning tasks, highlighting challenges in sequential reasoning,\nstate tracking, and strategic planning across tens of thousands of steps.\nTextAtari provides standardized evaluation protocols, baseline implementations,\nand a framework for advancing research at the intersection of language models\nand planning. Our code is available at\nhttps://github.com/Lww007/Text-Atari-Agents.", "AI": {"tldr": "TextAtari is a benchmark for evaluating language agents on long-horizon decision-making tasks using textual descriptions of Atari games. It tests three LLMs across various agent frameworks and scenarios, revealing performance gaps between agents and humans.", "motivation": "To bridge sequential decision-making and natural language processing by creating a challenging benchmark for evaluating language agents on long-horizon tasks.", "method": "TextAtari translates Atari game visuals into text, offering 100 tasks. It evaluates three LLMs (Qwen2.5-7B, Gemma-7B, Llama3.1-8B) using zero-shot, few-shot chain-of-thought, and reflection reasoning frameworks across four scenarios.", "result": "Significant performance gaps between language agents and humans in sequential reasoning, state tracking, and strategic planning were observed.", "conclusion": "TextAtari provides a standardized framework for advancing research in language models and planning, with code and baselines available for further study."}}
{"id": "2504.07549", "pdf": "https://arxiv.org/pdf/2504.07549", "abs": "https://arxiv.org/abs/2504.07549", "authors": ["Bingliang Zhang", "Zihui Wu", "Berthy T. Feng", "Yang Song", "Yisong Yue", "Katherine L. Bouman"], "title": "STeP: A Framework for Solving Scientific Video Inverse Problems with Spatiotemporal Diffusion Priors", "categories": ["cs.CV"], "comment": null, "summary": "Reconstructing spatially and temporally coherent videos from time-varying\nmeasurements is a fundamental challenge in many scientific domains. A major\ndifficulty arises from the sparsity of measurements, which hinders accurate\nrecovery of temporal dynamics. Existing image diffusion-based methods rely on\nextracting temporal consistency directly from measurements, limiting their\neffectiveness on scientific tasks with high spatiotemporal uncertainty. We\naddress this difficulty by proposing a plug-and-play framework that\nincorporates a learned spatiotemporal diffusion prior. Due to its plug-and-play\nnature, our framework can be flexibly applied to different video inverse\nproblems without the need for task-specific design and temporal heuristics. We\nfurther demonstrate that a spatiotemporal diffusion model can be trained\nefficiently with limited video data. We validate our approach on two\nchallenging scientific video reconstruction tasks: black hole video\nreconstruction and dynamic MRI. While baseline methods struggle to provide\ntemporally coherent reconstructions, our approach achieves significantly\nimproved recovery of the spatiotemporal structure of the underlying ground\ntruth videos.", "AI": {"tldr": "A plug-and-play framework with a learned spatiotemporal diffusion prior improves video reconstruction from sparse measurements, outperforming existing methods in tasks like black hole video reconstruction and dynamic MRI.", "motivation": "The challenge of reconstructing coherent videos from sparse measurements in scientific domains, where existing methods fail due to high spatiotemporal uncertainty.", "method": "Proposes a plug-and-play framework incorporating a learned spatiotemporal diffusion prior, enabling flexible application to various video inverse problems without task-specific designs.", "result": "Achieves significantly improved spatiotemporal coherence in reconstructions compared to baseline methods, validated on black hole video reconstruction and dynamic MRI.", "conclusion": "The framework effectively addresses spatiotemporal uncertainty in video reconstruction, offering a versatile and efficient solution for scientific tasks."}}
{"id": "2410.01686", "pdf": "https://arxiv.org/pdf/2410.01686", "abs": "https://arxiv.org/abs/2410.01686", "authors": ["Artur Back de Luca", "George Giapitzakis", "Shenghao Yang", "Petar Veli\u010dkovi\u0107", "Kimon Fountoulakis"], "title": "Positional Attention: Expressivity and Learnability of Algorithmic Computation", "categories": ["cs.LG", "cs.AI", "cs.DS"], "comment": "64 pages, 37 figures, Forty-Second International Conference on\n  Machine Learning (ICML 2025)", "summary": "There is a growing interest in the ability of neural networks to execute\nalgorithmic tasks (e.g., arithmetic, summary statistics, and sorting). The goal\nof this work is to better understand the role of attention in Transformers for\nalgorithmic execution. Its importance for algorithmic execution has been\nstudied theoretically and empirically using parallel computational models.\nNotably, many parallel algorithms communicate between processors solely using\npositional information. Inspired by this observation, we investigate how\nTransformers can execute algorithms using positional attention, where attention\nweights depend exclusively on positional encodings. We prove that Transformers\nwith positional attention (positional Transformers) maintain the same\nexpressivity of parallel computational models, incurring a logarithmic depth\ncost relative to the input length. We analyze their in-distribution\nlearnability and explore how parameter norms in positional attention affect\nsample complexity. Our results show that positional Transformers introduce a\nlearning trade-off: while they exhibit better theoretical dependence on\nparameter norms, certain tasks may require more layers, which can, in turn,\nincrease sample complexity. Finally, we empirically explore the\nout-of-distribution performance of positional Transformers and find that they\nperform well in tasks where their underlying algorithmic solution relies on\npositional information.", "AI": {"tldr": "The paper explores how Transformers with positional attention (positional Transformers) can execute algorithmic tasks, showing they match parallel computational models' expressivity but with a trade-off in learning complexity.", "motivation": "To understand the role of attention in Transformers for algorithmic execution, inspired by parallel algorithms' use of positional information.", "method": "Theoretical and empirical analysis of positional Transformers, focusing on their expressivity, learnability, and parameter norms' impact on sample complexity.", "result": "Positional Transformers match parallel models' expressivity but may require more layers, increasing sample complexity. They perform well in tasks relying on positional information.", "conclusion": "Positional Transformers offer a learning trade-off: better theoretical properties but potential complexity costs, excelling in position-dependent tasks."}}
{"id": "2506.08893", "pdf": "https://arxiv.org/pdf/2506.08893", "abs": "https://arxiv.org/abs/2506.08893", "authors": ["Kai Zhou", "Youbiao He", "Chong Zhong", "Yifu Wu"], "title": "Real-Time Cascade Mitigation in Power Systems Using Influence Graph Improved by Reinforcement Learning", "categories": ["physics.soc-ph", "cs.LG", "physics.data-an"], "comment": null, "summary": "Despite high reliability, modern power systems with growing renewable\npenetration face an increasing risk of cascading outages. Real-time cascade\nmitigation requires fast, complex operational decisions under uncertainty. In\nthis work, we extend the influence graph into a Markov decision process model\n(MDP) for real-time mitigation of cascading outages in power transmission\nsystems, accounting for uncertainties in generation, load, and initial\ncontingencies. The MDP includes a do-nothing action to allow for conservative\ndecision-making and is solved using reinforcement learning. We present a policy\ngradient learning algorithm initialized with a policy corresponding to the\nunmitigated case and designed to handle invalid actions. The proposed learning\nmethod converges faster than the conventional algorithm. Through careful reward\ndesign, we learn a policy that takes conservative actions without deteriorating\nsystem conditions. The model is validated on the IEEE 14-bus and IEEE 118-bus\nsystems. The results show that proactive line disconnections can effectively\nreduce cascading risk, and certain lines consistently emerge as critical in\nmitigating cascade propagation.", "AI": {"tldr": "The paper proposes a Markov decision process (MDP) model for real-time mitigation of cascading outages in power systems, using reinforcement learning to optimize conservative actions.", "motivation": "Modern power systems with high renewable penetration face increased cascading outage risks, requiring fast, uncertain operational decisions.", "method": "Extends the influence graph into an MDP model, solved via reinforcement learning with a policy gradient algorithm and careful reward design.", "result": "Proactive line disconnections reduce cascading risk; critical lines are identified. Validated on IEEE 14-bus and 118-bus systems.", "conclusion": "The MDP-based approach effectively mitigates cascading outages, with faster convergence and conservative action policies."}}
{"id": "2506.04373", "pdf": "https://arxiv.org/pdf/2506.04373", "abs": "https://arxiv.org/abs/2506.04373", "authors": ["Matthieu Tehenan", "Vikram Natarajan", "Jonathan Michala", "Milton Lin", "Juri Opitz"], "title": "Mechanistic Decomposition of Sentence Representations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sentence embeddings are central to modern NLP and AI systems, yet little is\nknown about their internal structure. While we can compare these embeddings\nusing measures such as cosine similarity, the contributing features are not\nhuman-interpretable, and the content of an embedding seems untraceable, as it\nis masked by complex neural transformations and a final pooling operation that\ncombines individual token embeddings. To alleviate this issue, we propose a new\nmethod to mechanistically decompose sentence embeddings into interpretable\ncomponents, by using dictionary learning on token-level representations. We\nanalyze how pooling compresses these features into sentence representations,\nand assess the latent features that reside in a sentence embedding. This\nbridges token-level mechanistic interpretability with sentence-level analysis,\nmaking for more transparent and controllable representations. In our studies,\nwe obtain several interesting insights into the inner workings of sentence\nembedding spaces, for instance, that many semantic and syntactic aspects are\nlinearly encoded in the embeddings.", "AI": {"tldr": "The paper proposes a method to decompose sentence embeddings into interpretable components using dictionary learning, bridging token-level and sentence-level analysis for transparency.", "motivation": "Sentence embeddings are widely used in NLP but lack interpretability due to complex neural transformations and pooling operations.", "method": "The authors use dictionary learning on token-level representations to mechanistically decompose sentence embeddings into interpretable components.", "result": "Findings reveal that semantic and syntactic aspects are linearly encoded in the embeddings.", "conclusion": "The method enhances transparency and controllability of sentence embeddings, providing insights into their internal structure."}}
{"id": "2504.13596", "pdf": "https://arxiv.org/pdf/2504.13596", "abs": "https://arxiv.org/abs/2504.13596", "authors": ["Shanshuai Yuan", "Julong Wei", "Muer Tie", "Xiangyun Ren", "Zhongxue Gan", "Wenchao Ding"], "title": "LMPOcc: 3D Semantic Occupancy Prediction Utilizing Long-Term Memory Prior from Historical Traversals", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Vision-based 3D semantic occupancy prediction is critical for autonomous\ndriving, enabling unified modeling of static infrastructure and dynamic agents.\nIn practice, autonomous vehicles may repeatedly traverse identical geographic\nlocations under varying environmental conditions, such as weather fluctuations\nand illumination changes. Existing methods in 3D occupancy prediction\npredominantly integrate adjacent temporal contexts. However, these works\nneglect to leverage perceptual information, which is acquired from historical\ntraversals of identical geographic locations. In this paper, we propose\nLongterm Memory Prior Occupancy (LMPOcc), the first 3D occupancy prediction\nmethodology that exploits long-term memory priors derived from historical\ntraversal perceptual outputs. We introduce a plug-and-play architecture that\nintegrates long-term memory priors to enhance local perception while\nsimultaneously constructing global occupancy representations. To adaptively\naggregate prior features and current features, we develop an efficient\nlightweight Current-Prior Fusion module. Moreover, we propose a model-agnostic\nprior format to ensure compatibility across diverse occupancy prediction\nbaselines. LMPOcc achieves state-of-the-art performance validated on the\nOcc3D-nuScenes benchmark, especially on static semantic categories.\nAdditionally, experimental results demonstrate LMPOcc's ability to construct\nglobal occupancy through multi-vehicle crowdsourcing.", "AI": {"tldr": "LMPOcc introduces a 3D occupancy prediction method leveraging long-term memory priors from historical traversals, improving performance on static semantic categories and enabling global occupancy modeling.", "motivation": "Existing methods ignore historical traversal data, missing opportunities to enhance 3D semantic occupancy prediction under varying conditions.", "method": "LMPOcc integrates long-term memory priors via a plug-and-play architecture, using a Current-Prior Fusion module for adaptive feature aggregation and a model-agnostic prior format.", "result": "Achieves state-of-the-art performance on Occ3D-nuScenes, excelling in static semantic categories and demonstrating multi-vehicle crowdsourcing potential.", "conclusion": "LMPOcc effectively leverages historical data for superior 3D occupancy prediction, offering adaptability and global modeling capabilities."}}
{"id": "2411.03250", "pdf": "https://arxiv.org/pdf/2411.03250", "abs": "https://arxiv.org/abs/2411.03250", "authors": ["Ying Zhou", "Xinyao Wang", "Yulei Niu", "Yaojie Shen", "Lexin Tang", "Fan Chen", "Ben He", "Le Sun", "Longyin Wen"], "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "21 pages, 9 figures, Accepted by ACL 2025, Findings", "summary": "Recent advancements in large language models (LLMs) have significantly\nenhanced their knowledge and generative capabilities, leading to a surge of\ninterest in leveraging LLMs for high-quality data synthesis. However, synthetic\ndata generation via prompting LLMs remains challenging due to LLMs' limited\nunderstanding of target data distributions and the complexity of prompt\nengineering, especially for structured formatted data. To address these issues,\nwe introduce DiffLM, a controllable data synthesis framework based on\nvariational autoencoder (VAE), which further (1) leverages diffusion models to\nreserve more information of original distribution and format structure in the\nlearned latent distribution and (2) decouples the learning of target\ndistribution knowledge from the LLM's generative objectives via a plug-and-play\nlatent feature injection module. As we observed significant discrepancies\nbetween the VAE's latent representations and the real data distribution, the\nlatent diffusion module is introduced into our framework to learn a fully\nexpressive latent distribution. Evaluations on seven real-world datasets with\nstructured formatted data (i.e., Tabular, Code, and Tool data) demonstrate that\nDiffLM generates high-quality data, with performance on downstream tasks\nsurpassing that of real data by 2%-7% in certain cases. Data and code are\navailable at https://github.com/bytedance/DiffLM.", "AI": {"tldr": "DiffLM is a framework combining VAE and diffusion models to improve synthetic data generation by LLMs, addressing distribution and format challenges.", "motivation": "Leveraging LLMs for data synthesis is hindered by their limited understanding of target distributions and complex prompt engineering.", "method": "DiffLM uses a VAE with a latent diffusion module to better capture data distributions and decouples learning via a plug-and-play feature injection.", "result": "DiffLM outperforms real data in downstream tasks by 2%-7% on structured datasets like Tabular, Code, and Tool data.", "conclusion": "DiffLM effectively enhances synthetic data quality, demonstrating practical utility for structured data generation."}}
{"id": "2506.08954", "pdf": "https://arxiv.org/pdf/2506.08954", "abs": "https://arxiv.org/abs/2506.08954", "authors": ["Ruben Weitzman", "Peter M\u00f8rch Groth", "Lood Van Niekerk", "Aoi Otani", "Yarin Gal", "Debora Marks", "Pascal Notin"], "title": "Protriever: End-to-End Differentiable Protein Homology Search for Fitness Prediction", "categories": ["q-bio.QM", "cs.LG", "q-bio.BM"], "comment": "Accepted at ICML 2025", "summary": "Retrieving homologous protein sequences is essential for a broad range of\nprotein modeling tasks such as fitness prediction, protein design, structure\nmodeling, and protein-protein interactions. Traditional workflows have relied\non a two-step process: first retrieving homologs via Multiple Sequence\nAlignments (MSA), then training models on one or more of these alignments.\nHowever, MSA-based retrieval is computationally expensive, struggles with\nhighly divergent sequences or complex insertions & deletions patterns, and\noperates independently of the downstream modeling objective. We introduce\nProtriever, an end-to-end differentiable framework that learns to retrieve\nrelevant homologs while simultaneously training for the target task. When\napplied to protein fitness prediction, Protriever achieves state-of-the-art\nperformance compared to sequence-based models that rely on MSA-based homolog\nretrieval, while being two orders of magnitude faster through efficient vector\nsearch. Protriever is both architecture- and task-agnostic, and can flexibly\nadapt to different retrieval strategies and protein databases at inference time\n-- offering a scalable alternative to alignment-centric approaches.", "AI": {"tldr": "Protriever is a differentiable framework for retrieving homologous protein sequences, outperforming MSA-based methods in speed and performance for tasks like fitness prediction.", "motivation": "Traditional MSA-based retrieval is slow, struggles with divergent sequences, and ignores downstream modeling goals.", "method": "Protriever learns to retrieve homologs end-to-end while training for the target task, using efficient vector search.", "result": "Protriever achieves state-of-the-art performance in protein fitness prediction, is 100x faster than MSA-based methods, and is adaptable to various tasks and databases.", "conclusion": "Protriever offers a scalable, efficient alternative to alignment-centric approaches for protein sequence retrieval."}}
{"id": "2506.05176", "pdf": "https://arxiv.org/pdf/2506.05176", "abs": "https://arxiv.org/abs/2506.05176", "authors": ["Yanzhao Zhang", "Mingxin Li", "Dingkun Long", "Xin Zhang", "Huan Lin", "Baosong Yang", "Pengjun Xie", "An Yang", "Dayiheng Liu", "Junyang Lin", "Fei Huang", "Jingren Zhou"], "title": "Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we introduce the Qwen3 Embedding series, a significant\nadvancement over its predecessor, the GTE-Qwen series, in text embedding and\nreranking capabilities, built upon the Qwen3 foundation models. Leveraging the\nQwen3 LLMs' robust capabilities in multilingual text understanding and\ngeneration, our innovative multi-stage training pipeline combines large-scale\nunsupervised pre-training with supervised fine-tuning on high-quality datasets.\nEffective model merging strategies further ensure the robustness and\nadaptability of the Qwen3 Embedding series. During the training process, the\nQwen3 LLMs serve not only as backbone models but also play a crucial role in\nsynthesizing high-quality, rich, and diverse training data across multiple\ndomains and languages, thus enhancing the training pipeline. The Qwen3\nEmbedding series offers a spectrum of model sizes (0.6B, 4B, 8B) for both\nembedding and reranking tasks, addressing diverse deployment scenarios where\nusers can optimize for either efficiency or effectiveness. Empirical\nevaluations demonstrate that the Qwen3 Embedding series achieves\nstate-of-the-art results across diverse benchmarks. Notably, it excels on the\nmultilingual evaluation benchmark MTEB for text embedding, as well as in\nvarious retrieval tasks, including code retrieval, cross-lingual retrieval and\nmultilingual retrieval. To facilitate reproducibility and promote\ncommunity-driven research and development, the Qwen3 Embedding models are\npublicly available under the Apache 2.0 license.", "AI": {"tldr": "The Qwen3 Embedding series improves text embedding and reranking using Qwen3 foundation models, offering multilingual capabilities and diverse model sizes.", "motivation": "To advance text embedding and reranking by leveraging Qwen3 LLMs' multilingual understanding and generation, addressing diverse deployment needs.", "method": "Multi-stage training pipeline combining unsupervised pre-training and supervised fine-tuning, with model merging for robustness. Qwen3 LLMs synthesize diverse training data.", "result": "Achieves state-of-the-art results on benchmarks like MTEB and excels in retrieval tasks (code, cross-lingual, multilingual).", "conclusion": "The Qwen3 Embedding series is a robust, adaptable solution for embedding and reranking, publicly available under Apache 2.0."}}
{"id": "2504.18233", "pdf": "https://arxiv.org/pdf/2504.18233", "abs": "https://arxiv.org/abs/2504.18233", "authors": ["Wenxiang Gua", "Lin Qia"], "title": "Dense Geometry Supervision for Underwater Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "The field of monocular depth estimation is continually evolving with the\nadvent of numerous innovative models and extensions. However, research on\nmonocular depth estimation methods specifically for underwater scenes remains\nlimited, compounded by a scarcity of relevant data and methodological support.\nThis paper proposes a novel approach to address the existing challenges in\ncurrent monocular depth estimation methods for underwater environments. We\nconstruct an economically efficient dataset suitable for underwater scenarios\nby employing multi-view depth estimation to generate supervisory signals and\ncorresponding enhanced underwater images. we introduces a texture-depth fusion\nmodule, designed according to the underwater optical imaging principles, which\naims to effectively exploit and integrate depth information from texture cues.\nExperimental results on the FLSea dataset demonstrate that our approach\nsignificantly improves the accuracy and adaptability of models in underwater\nsettings. This work offers a cost-effective solution for monocular underwater\ndepth estimation and holds considerable promise for practical applications.", "AI": {"tldr": "A novel method for monocular depth estimation in underwater scenes, using a cost-effective dataset and a texture-depth fusion module, improves accuracy and adaptability.", "motivation": "Limited research and data for underwater monocular depth estimation, prompting a need for innovative solutions.", "method": "Constructs an underwater dataset using multi-view depth estimation and introduces a texture-depth fusion module based on underwater optical principles.", "result": "Significant improvement in accuracy and adaptability on the FLSea dataset.", "conclusion": "Provides a cost-effective solution with practical potential for underwater depth estimation."}}
{"id": "2411.10877", "pdf": "https://arxiv.org/pdf/2411.10877", "abs": "https://arxiv.org/abs/2411.10877", "authors": ["Trevor Stalnaker", "Nathan Wintersgill", "Oscar Chaparro", "Laura A. Heymann", "Massimiliano Di Penta", "Daniel M German", "Denys Poshyvanyk"], "title": "Developer Perspectives on Licensing and Copyright Issues Arising from Generative AI for Software Development", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Despite the utility that Generative AI (GenAI) tools provide for tasks such\nas writing code, the use of these tools raises important legal questions and\npotential risks, particularly those associated with copyright law. As lawmakers\nand regulators engage with those questions, the views of users can provide\nrelevant perspectives. In this paper, we provide: (1) a survey of 574\ndevelopers on the licensing and copyright aspects of GenAI for coding, as well\nas follow-up interviews; (2) a snapshot of developers' views at a time when\nGenAI and perceptions of it are rapidly evolving; and (3) an analysis of\ndevelopers' views, yielding insights and recommendations that can inform future\nregulatory decisions in this evolving field. Our results show the benefits\ndevelopers derive from GenAI, how they view the use of AI-generated code as\nsimilar to using other existing code, the varied opinions they have on who\nshould own or be compensated for such code, that they are concerned about data\nleakage via GenAI, and much more, providing organizations and policymakers with\nvaluable insights into how the technology is being used and what concerns\nstakeholders would like to see addressed.", "AI": {"tldr": "Survey of 574 developers on GenAI's copyright and licensing issues, revealing benefits, concerns, and varied opinions on ownership and compensation.", "motivation": "To understand developers' perspectives on legal and copyright risks of using GenAI tools for coding, informing regulatory decisions.", "method": "Conducted a survey of 574 developers and follow-up interviews to capture evolving views on GenAI.", "result": "Developers see benefits in GenAI, compare AI-generated code to existing code, and express concerns about data leakage and ownership.", "conclusion": "Provides insights for policymakers on GenAI usage and stakeholder concerns, aiding future regulatory frameworks."}}
{"id": "2506.06395", "pdf": "https://arxiv.org/pdf/2506.06395", "abs": "https://arxiv.org/abs/2506.06395", "authors": ["Pengyi Li", "Matvey Skripkin", "Alexander Zubrey", "Andrey Kuznetsov", "Ivan Oseledets"], "title": "Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at reasoning, yet post-training remains\ncritical for aligning their behavior with task goals. Existing reinforcement\nlearning (RL) methods often depend on costly human annotations or external\nreward models. We propose Reinforcement Learning via Self-Confidence (RLSC),\nwhich uses the model's own confidence as reward signals-eliminating the need\nfor labels, preference models, or reward engineering. Applied to\nQwen2.5-Math-7B with only 16 samples per question and 10 or 20 training steps,\nRLSC improves accuracy by +13.4% on AIME2024, +21.2% on MATH500, +21.7% on\nMinerva Math, +20.8% on Olympiadbench, and +9.7% on AMC23. RLSC provides a\nsimple, scalable post-training method for inference models, requiring only a\nsmall number of samples and unlabelled supervision.", "AI": {"tldr": "RLSC is a post-training method for LLMs that uses the model's self-confidence as reward signals, eliminating the need for human annotations or external reward models. It significantly improves accuracy across multiple benchmarks with minimal samples and training steps.", "motivation": "Existing RL methods for LLMs rely on costly human annotations or external reward models, which are inefficient and unscalable. RLSC addresses this by leveraging the model's own confidence as a reward signal.", "method": "RLSC uses the model's self-confidence as reward signals for reinforcement learning, requiring only a small number of unlabelled samples and minimal training steps (10 or 20).", "result": "RLSC improves accuracy by +13.4% to +21.7% on benchmarks like AIME2024, MATH500, Minerva Math, Olympiadbench, and AMC23.", "conclusion": "RLSC offers a simple, scalable post-training method for LLMs, reducing dependency on external labels or reward models while achieving significant performance gains."}}
{"id": "2504.20024", "pdf": "https://arxiv.org/pdf/2504.20024", "abs": "https://arxiv.org/abs/2504.20024", "authors": ["Wufei Ma", "Yu-Cheng Chou", "Qihao Liu", "Xingrui Wang", "Celso de Melo", "Jianwen Xie", "Alan Yuille"], "title": "SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning", "categories": ["cs.CV"], "comment": "Project page: https://spatial-reasoner.github.io", "summary": "Despite recent advances on multi-modal models, 3D spatial reasoning remains a\nchallenging task for state-of-the-art open-source and proprietary models.\nRecent studies explore data-driven approaches and achieve enhanced spatial\nreasoning performance by fine-tuning models on 3D-related visual\nquestion-answering data. However, these methods typically perform spatial\nreasoning in an implicit manner and often fail on questions that are trivial to\nhumans, even with long chain-of-thought reasoning. In this work, we introduce\nSpatialReasoner, a novel large vision-language model (LVLM) that addresses 3D\nspatial reasoning with explicit 3D representations shared between multiple\nstages--3D perception, computation, and reasoning. Explicit 3D representations\nprovide a coherent interface that supports advanced 3D spatial reasoning and\nimproves the generalization ability to novel question types. Furthermore, by\nanalyzing the explicit 3D representations in multi-step reasoning traces of\nSpatialReasoner, we study the factual errors and identify key shortcomings of\ncurrent LVLMs. Results show that our SpatialReasoner achieves improved\nperformance on a variety of spatial reasoning benchmarks, outperforming Gemini\n2.0 by 9.2% on 3DSRBench, and generalizes better when evaluating on novel 3D\nspatial reasoning questions. Our study bridges the 3D parsing capabilities of\nprior visual foundation models with the powerful reasoning abilities of large\nlanguage models, opening new directions for 3D spatial reasoning.", "AI": {"tldr": "SpatialReasoner, a new LVLM, improves 3D spatial reasoning using explicit 3D representations, outperforming Gemini 2.0 by 9.2% on benchmarks.", "motivation": "Current models struggle with 3D spatial reasoning, especially on human-trivial questions, due to implicit methods.", "method": "Introduces SpatialReasoner with explicit 3D representations across perception, computation, and reasoning stages.", "result": "Achieves better performance on benchmarks and generalizes well to novel questions.", "conclusion": "Bridges 3D parsing and reasoning, opening new directions for 3D spatial reasoning."}}
{"id": "2411.19339", "pdf": "https://arxiv.org/pdf/2411.19339", "abs": "https://arxiv.org/abs/2411.19339", "authors": ["Matthew Niedoba", "Berend Zwartsenberg", "Kevin Murphy", "Frank Wood"], "title": "Towards a Mechanistic Explanation of Diffusion Model Generalization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICML 2025 Spotlight", "summary": "We propose a simple, training-free mechanism which explains the\ngeneralization behaviour of diffusion models. By comparing pre-trained\ndiffusion models to their theoretically optimal empirical counterparts, we\nidentify a shared local inductive bias across a variety of network\narchitectures. From this observation, we hypothesize that network denoisers\ngeneralize through localized denoising operations, as these operations\napproximate the training objective well over much of the training distribution.\nTo validate our hypothesis, we introduce novel denoising algorithms which\naggregate local empirical denoisers to replicate network behaviour. Comparing\nthese algorithms to network denoisers across forward and reverse diffusion\nprocesses, our approach exhibits consistent visual similarity to neural network\noutputs, with lower mean squared error than previously proposed methods.", "AI": {"tldr": "A training-free mechanism explains diffusion models' generalization by identifying a shared local inductive bias and validating it through novel denoising algorithms.", "motivation": "To understand and explain the generalization behavior of diffusion models by comparing them to theoretically optimal empirical counterparts.", "method": "Identify a shared local inductive bias, hypothesize localized denoising operations, and validate with novel denoising algorithms.", "result": "The approach shows visual similarity to neural network outputs and lower mean squared error than previous methods.", "conclusion": "Network denoisers generalize through localized operations, validated by new algorithms."}}
{"id": "2212.02042", "pdf": "https://arxiv.org/pdf/2212.02042", "abs": "https://arxiv.org/abs/2212.02042", "authors": ["Mingyuan Fan", "Cen Chen", "Chengyu Wang", "Xiaodan Li", "Wenmeng Zhou"], "title": "Refiner: Data Refining against Gradient Leakage Attacks in Federated Learning", "categories": ["cs.LG", "cs.CR"], "comment": "Accepted to Usenix Security 2025", "summary": "Recent works have brought attention to the vulnerability of Federated\nLearning (FL) systems to gradient leakage attacks. Such attacks exploit\nclients' uploaded gradients to reconstruct their sensitive data, thereby\ncompromising the privacy protection capability of FL. In response, various\ndefense mechanisms have been proposed to mitigate this threat by manipulating\nthe uploaded gradients. Unfortunately, empirical evaluations have demonstrated\nlimited resilience of these defenses against sophisticated attacks, indicating\nan urgent need for more effective defenses. In this paper, we explore a novel\ndefensive paradigm that departs from conventional gradient perturbation\napproaches and instead focuses on the construction of robust data. Intuitively,\nif robust data exhibits low semantic similarity with clients' raw data, the\ngradients associated with robust data can effectively obfuscate attackers. To\nthis end, we design Refiner that jointly optimizes two metrics for privacy\nprotection and performance maintenance. The utility metric is designed to\npromote consistency between the gradients of key parameters associated with\nrobust data and those derived from clients' data, thus maintaining model\nperformance. Furthermore, the privacy metric guides the generation of robust\ndata towards enlarging the semantic gap with clients' data. Theoretical\nanalysis supports the effectiveness of Refiner, and empirical evaluations on\nmultiple benchmark datasets demonstrate the superior defense effectiveness of\nRefiner at defending against state-of-the-art attacks.", "AI": {"tldr": "The paper introduces Refiner, a novel defense for Federated Learning (FL) against gradient leakage attacks by generating robust data instead of perturbing gradients, balancing privacy and performance.", "motivation": "Existing FL defenses against gradient leakage attacks are ineffective against sophisticated attacks, necessitating a new approach.", "method": "Refiner jointly optimizes privacy and utility metrics to generate robust data with low semantic similarity to raw data, obfuscating attackers while maintaining model performance.", "result": "Theoretical and empirical evaluations show Refiner effectively defends against state-of-the-art attacks on benchmark datasets.", "conclusion": "Refiner offers a superior defense paradigm for FL by focusing on robust data construction rather than gradient manipulation."}}
{"id": "2506.07044", "pdf": "https://arxiv.org/pdf/2506.07044", "abs": "https://arxiv.org/abs/2506.07044", "authors": ["LASA Team", "Weiwen Xu", "Hou Pong Chan", "Long Li", "Mahani Aljunied", "Ruifeng Yuan", "Jianyu Wang", "Chenghao Xiao", "Guizhen Chen", "Chaoqun Liu", "Zhaodonghui Li", "Yu Sun", "Junao Shen", "Chaojun Wang", "Jie Tan", "Deli Zhao", "Tingyang Xu", "Hao Zhang", "Yu Rong"], "title": "Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Technical Report, 53 pages, 25 tables, and 16 figures", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities in understanding common visual elements, largely due to their\nlarge-scale datasets and advanced training strategies. However, their\neffectiveness in medical applications remains limited due to the inherent\ndiscrepancies between data and tasks in medical scenarios and those in the\ngeneral domain. Concretely, existing medical MLLMs face the following critical\nlimitations: (1) limited coverage of medical knowledge beyond imaging, (2)\nheightened susceptibility to hallucinations due to suboptimal data curation\nprocesses, (3) lack of reasoning capabilities tailored for complex medical\nscenarios. To address these challenges, we first propose a comprehensive data\ncuration procedure that (1) efficiently acquires rich medical knowledge data\nnot only from medical imaging but also from extensive medical texts and\ngeneral-domain data; and (2) synthesizes accurate medical captions, visual\nquestion answering (VQA), and reasoning samples. As a result, we build a\nmultimodal dataset enriched with extensive medical knowledge. Building on the\ncurated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu\nundergoes multi-stage training to embed medical expertise and enhance its\ntask-solving capabilities progressively. Besides, we preliminarily explore the\npotential of applying reinforcement learning with verifiable rewards paradigm\nto enhance Lingshu's medical reasoning ability. Additionally, we develop\nMedEvalKit, a unified evaluation framework that consolidates leading multimodal\nand textual medical benchmarks for standardized, fair, and efficient model\nassessment. We evaluate the performance of Lingshu on three fundamental medical\ntasks, multimodal QA, text-based QA, and medical report generation. The results\nshow that Lingshu consistently outperforms the existing open-source multimodal\nmodels on most tasks ...", "AI": {"tldr": "The paper introduces Lingshu, a medical-specialized MLLM, addressing limitations in existing models by curating a rich multimodal dataset and enhancing reasoning capabilities.", "motivation": "Existing MLLMs underperform in medical applications due to limited knowledge coverage, susceptibility to hallucinations, and lack of tailored reasoning.", "method": "Proposes a data curation procedure for diverse medical knowledge, multi-stage training for Lingshu, and explores reinforcement learning for reasoning. Introduces MedEvalKit for evaluation.", "result": "Lingshu outperforms existing open-source multimodal models on tasks like multimodal QA, text-based QA, and medical report generation.", "conclusion": "Lingshu demonstrates improved effectiveness in medical applications through enriched data and specialized training, with potential for further enhancement via reinforcement learning."}}
{"id": "2505.00788", "pdf": "https://arxiv.org/pdf/2505.00788", "abs": "https://arxiv.org/abs/2505.00788", "authors": ["Wufei Ma", "Luoxin Ye", "Celso M de Melo", "Jieneng Chen", "Alan Yuille"], "title": "SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models", "categories": ["cs.CV"], "comment": "CVPR 2025 highlight", "summary": "Humans naturally understand 3D spatial relationships, enabling complex\nreasoning like predicting collisions of vehicles from different directions.\nCurrent large multimodal models (LMMs), however, lack of this capability of 3D\nspatial reasoning. This limitation stems from the scarcity of 3D training data\nand the bias in current model designs toward 2D data. In this paper, we\nsystematically study the impact of 3D-informed data, architecture, and training\nsetups, introducing SpatialLLM, a large multi-modal model with advanced 3D\nspatial reasoning abilities. To address data limitations, we develop two types\nof 3D-informed training datasets: (1) 3D-informed probing data focused on\nobject's 3D location and orientation, and (2) 3D-informed conversation data for\ncomplex spatial relationships. Notably, we are the first to curate VQA data\nthat incorporate 3D orientation relationships on real images. Furthermore, we\nsystematically integrate these two types of training data with the\narchitectural and training designs of LMMs, providing a roadmap for optimal\ndesign aimed at achieving superior 3D reasoning capabilities. Our SpatialLLM\nadvances machines toward highly capable 3D-informed reasoning, surpassing\nGPT-4o performance by 8.7%. Our systematic empirical design and the resulting\nfindings offer valuable insights for future research in this direction. Our\nproject page is available at:\nhttps://3d-spatial-reasoning.github.io/spatial-llm/", "AI": {"tldr": "SpatialLLM is a new model enhancing 3D spatial reasoning in multimodal models by introducing 3D-informed data and architecture, outperforming GPT-4o by 8.7%.", "motivation": "Current models lack 3D spatial reasoning due to limited 3D data and 2D biases. This paper aims to address this gap.", "method": "Developed 3D-informed probing and conversation datasets, integrated with architectural and training designs for LMMs.", "result": "SpatialLLM outperforms GPT-4o by 8.7% in 3D reasoning.", "conclusion": "The approach provides a roadmap for future 3D reasoning research, advancing machine capabilities."}}
{"id": "2412.03671", "pdf": "https://arxiv.org/pdf/2412.03671", "abs": "https://arxiv.org/abs/2412.03671", "authors": ["Pedram Khorsandi", "Rushil Gupta", "Mehrnaz Mofakhami", "Simon Lacoste-Julien", "Gauthier Gidel"], "title": "Tight Lower Bounds and Improved Convergence in Performative Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Performative prediction is a framework accounting for the shift in the data\ndistribution induced by the prediction of a model deployed in the real world.\nEnsuring rapid convergence to a stable solution where the data distribution\nremains the same after the model deployment is crucial, especially in evolving\nenvironments. This paper extends the Repeated Risk Minimization (RRM) framework\nby utilizing historical datasets from previous retraining snapshots, yielding a\nclass of algorithms that we call Affine Risk Minimizers and enabling\nconvergence to a performatively stable point for a broader class of problems.\nWe introduce a new upper bound for methods that use only the final iteration of\nthe dataset and prove for the first time the tightness of both this new bound\nand the previous existing bounds within the same regime. We also prove that\nutilizing historical datasets can surpass the lower bound for last iterate RRM,\nand empirically observe faster convergence to the stable point on various\nperformative prediction benchmarks. We offer at the same time the first lower\nbound analysis for RRM within the class of Affine Risk Minimizers, quantifying\nthe potential improvements in convergence speed that could be achieved with\nother variants in our framework.", "AI": {"tldr": "The paper extends the Repeated Risk Minimization (RRM) framework by using historical datasets, introducing Affine Risk Minimizers for faster convergence to performatively stable points. It provides new bounds and proves tightness, showing improvements over last-iterate RRM.", "motivation": "Address the challenge of data distribution shifts caused by model predictions in real-world deployments, aiming for stable solutions in evolving environments.", "method": "Extends RRM by leveraging historical datasets, introducing Affine Risk Minimizers, and analyzing bounds for convergence.", "result": "Proves tightness of new bounds, shows historical datasets surpass last-iterate RRM lower bounds, and observes faster convergence empirically.", "conclusion": "The framework improves convergence speed and stability in performative prediction, with potential for further enhancements."}}
{"id": "2303.05582", "pdf": "https://arxiv.org/pdf/2303.05582", "abs": "https://arxiv.org/abs/2303.05582", "authors": ["Vicky Kouni", "Yannis Panagakis"], "title": "Generalization analysis of an unfolding network for analysis-based Compressed Sensing", "categories": ["cs.LG", "cs.IR", "cs.IT", "eess.SP", "math.IT"], "comment": null, "summary": "Unfolding networks have shown promising results in the Compressed Sensing\n(CS) field. Yet, the investigation of their generalization ability is still in\nits infancy. In this paper, we perform a generalization analysis of a\nstate-of-the-art ADMM-based unfolding network, which jointly learns a decoder\nfor CS and a sparsifying redundant analysis operator. To this end, we first\nimpose a structural constraint on the learnable sparsifier, which parametrizes\nthe network's hypothesis class. For the latter, we estimate its Rademacher\ncomplexity. With this estimate in hand, we deliver generalization error bounds\n-- which scale like the square root of the number of layers -- for the examined\nnetwork. Finally, the validity of our theory is assessed and numerical\ncomparisons to a state-of-the-art unfolding network are made, on synthetic and\nreal-world datasets. Our experimental results demonstrate that our proposed\nframework complies with our theoretical findings and outperforms the baseline,\nconsistently for all datasets.", "AI": {"tldr": "The paper analyzes the generalization ability of an ADMM-based unfolding network in Compressed Sensing, providing theoretical bounds and experimental validation.", "motivation": "To investigate the generalization ability of unfolding networks in Compressed Sensing, which is underexplored.", "method": "Imposes a structural constraint on the learnable sparsifier, estimates Rademacher complexity, and derives generalization error bounds.", "result": "Generalization error bounds scale with the square root of network layers, and experiments show the framework outperforms baselines.", "conclusion": "The proposed framework aligns with theoretical predictions and consistently outperforms state-of-the-art methods."}}
{"id": "2506.07667", "pdf": "https://arxiv.org/pdf/2506.07667", "abs": "https://arxiv.org/abs/2506.07667", "authors": ["Prarabdh Shukla", "Wei Yin Chong", "Yash Patel", "Brennan Schaffner", "Danish Pruthi", "Arjun Bhagoji"], "title": "Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch", "categories": ["cs.CL", "cs.HC", "cs.LG"], "comment": "Accepted to ACL 2025 (main) conference", "summary": "To meet the demands of content moderation, online platforms have resorted to\nautomated systems. Newer forms of real-time engagement($\\textit{e.g.}$, users\ncommenting on live streams) on platforms like Twitch exert additional pressures\non the latency expected of such moderation systems. Despite their prevalence,\nrelatively little is known about the effectiveness of these systems. In this\npaper, we conduct an audit of Twitch's automated moderation tool\n($\\texttt{AutoMod}$) to investigate its effectiveness in flagging hateful\ncontent. For our audit, we create streaming accounts to act as siloed test\nbeds, and interface with the live chat using Twitch's APIs to send over\n$107,000$ comments collated from $4$ datasets. We measure $\\texttt{AutoMod}$'s\naccuracy in flagging blatantly hateful content containing misogyny, racism,\nableism and homophobia. Our experiments reveal that a large fraction of hateful\nmessages, up to $94\\%$ on some datasets, $\\textit{bypass moderation}$.\nContextual addition of slurs to these messages results in $100\\%$ removal,\nrevealing $\\texttt{AutoMod}$'s reliance on slurs as a moderation signal. We\nalso find that contrary to Twitch's community guidelines, $\\texttt{AutoMod}$\nblocks up to $89.5\\%$ of benign examples that use sensitive words in\npedagogical or empowering contexts. Overall, our audit points to large gaps in\n$\\texttt{AutoMod}$'s capabilities and underscores the importance for such\nsystems to understand context effectively.", "AI": {"tldr": "The paper audits Twitch's AutoMod tool, revealing its ineffectiveness in flagging hateful content (up to 94% bypass) and over-blocking benign content (89.5%). It highlights reliance on slurs as a signal and the need for contextual understanding.", "motivation": "To assess the effectiveness of automated moderation systems like Twitch's AutoMod in real-time engagement platforms, given the lack of existing research on their performance.", "method": "Created streaming accounts to test AutoMod, sent 107,000 comments from 4 datasets via Twitch's APIs, and measured accuracy in flagging hateful content (misogyny, racism, ableism, homophobia).", "result": "AutoMod failed to flag up to 94% of hateful content but removed 100% when slurs were added. It also blocked 89.5% of benign content using sensitive words in non-hateful contexts.", "conclusion": "AutoMod has significant gaps, relying too heavily on slurs and lacking contextual understanding, underscoring the need for improved moderation systems."}}
{"id": "2505.04481", "pdf": "https://arxiv.org/pdf/2505.04481", "abs": "https://arxiv.org/abs/2505.04481", "authors": ["Jiahao Li", "Weijian Ma", "Xueyang Li", "Yunzhong Lou", "Guichun Zhou", "Xiangdong Zhou"], "title": "CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recently, Large Language Models (LLMs) have achieved significant success,\nprompting increased interest in expanding their generative capabilities beyond\ngeneral text into domain-specific areas. This study investigates the generation\nof parametric sequences for computer-aided design (CAD) models using LLMs. This\nendeavor represents an initial step towards creating parametric 3D shapes with\nLLMs, as CAD model parameters directly correlate with shapes in\nthree-dimensional space. Despite the formidable generative capacities of LLMs,\nthis task remains challenging, as these models neither encounter parametric\nsequences during their pretraining phase nor possess direct awareness of 3D\nstructures. To address this, we present CAD-Llama, a framework designed to\nenhance pretrained LLMs for generating parametric 3D CAD models. Specifically,\nwe develop a hierarchical annotation pipeline and a code-like format to\ntranslate parametric 3D CAD command sequences into Structured Parametric CAD\nCode (SPCC), incorporating hierarchical semantic descriptions. Furthermore, we\npropose an adaptive pretraining approach utilizing SPCC, followed by an\ninstruction tuning process aligned with CAD-specific guidelines. This\nmethodology aims to equip LLMs with the spatial knowledge inherent in\nparametric sequences. Experimental results demonstrate that our framework\nsignificantly outperforms prior autoregressive methods and existing LLM\nbaselines.", "AI": {"tldr": "The paper introduces CAD-Llama, a framework to enhance LLMs for generating parametric 3D CAD models, addressing challenges like lack of pretraining on parametric sequences and 3D awareness.", "motivation": "To expand LLMs' generative capabilities into domain-specific areas like CAD, where parametric sequences directly influence 3D shapes.", "method": "Develops a hierarchical annotation pipeline and SPCC format, followed by adaptive pretraining and CAD-specific instruction tuning.", "result": "CAD-Llama outperforms prior autoregressive methods and LLM baselines in generating parametric CAD models.", "conclusion": "The framework successfully equips LLMs with spatial knowledge for CAD, demonstrating significant improvements in generative performance."}}
{"id": "2412.04323", "pdf": "https://arxiv.org/pdf/2412.04323", "abs": "https://arxiv.org/abs/2412.04323", "authors": ["James Queeney", "Xiaoyi Cai", "Alexander Schperberg", "Radu Corcodel", "Mouhacine Benosman", "Jonathan P. How"], "title": "GRAM: Generalization in Deep RL with a Robust Adaptation Module", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": null, "summary": "The reliable deployment of deep reinforcement learning in real-world settings\nrequires the ability to generalize across a variety of conditions, including\nboth in-distribution scenarios seen during training as well as novel\nout-of-distribution scenarios. In this work, we present a framework for\ndynamics generalization in deep reinforcement learning that unifies these two\ndistinct types of generalization within a single architecture. We introduce a\nrobust adaptation module that provides a mechanism for identifying and reacting\nto both in-distribution and out-of-distribution environment dynamics, along\nwith a joint training pipeline that combines the goals of in-distribution\nadaptation and out-of-distribution robustness. Our algorithm GRAM achieves\nstrong generalization performance across in-distribution and\nout-of-distribution scenarios upon deployment, which we demonstrate through\nextensive simulation and hardware locomotion experiments on a quadruped robot.", "AI": {"tldr": "A framework (GRAM) for dynamics generalization in deep reinforcement learning unifies in-distribution and out-of-distribution scenarios, achieving strong generalization in simulations and hardware experiments.", "motivation": "To enable reliable deployment of deep reinforcement learning in real-world settings by generalizing across both in-distribution and novel out-of-distribution conditions.", "method": "Introduces a robust adaptation module and joint training pipeline for in-distribution adaptation and out-of-distribution robustness.", "result": "GRAM demonstrates strong generalization performance in both in-distribution and out-of-distribution scenarios, validated through simulations and hardware experiments.", "conclusion": "The framework successfully unifies and addresses generalization challenges in deep reinforcement learning for real-world applications."}}
{"id": "2305.13883", "pdf": "https://arxiv.org/pdf/2305.13883", "abs": "https://arxiv.org/abs/2305.13883", "authors": ["Jade Garcia Bourr\u00e9e", "Erwan Le Merrer", "Gilles Tredan", "Beno\u00eet Rottembourg"], "title": "Mitigating fairwashing using Two-Source Audits", "categories": ["cs.LG", "cs.CY", "cs.SE"], "comment": "10 pages, 6 figures", "summary": "Recent legislation requires online platforms to provide dedicated APIs to\nassess the compliance of their decision-making algorithms with the law.\nResearch has nevertheless shown that the auditors of such platforms are prone\nto manipulation (a practice referred to as \\textit{fairwashing}). To address\nthis salient problem, recent work has considered audits under the assumption of\npartial knowledge of the platform's internal mechanisms. In this paper, we\npropose a more pragmatic approach with the \\textit{Two-Source Audit} setup:\nwhile still leveraging the API, we advocate for the adjunction of a second\nsource of data to both perform the audit of a platform and the detection of\nfairwashing attempts. Our method is based on identifying discrepancies between\nthe two data sources, using data proxies at use in the fairness literature. We\nformally demonstrate the conditions for success in this fairwashing mitigation\ntask. We then validate our method empirically, demonstrating that Two-Source\nAudits can achieve a Pareto-optimal balance between the two objectives. We\nbelieve this paper sets the stage for reliable audits in manipulation-prone\nsetups, under mild assumptions.", "AI": {"tldr": "The paper proposes a Two-Source Audit method to detect fairwashing in online platforms by using discrepancies between API data and a second data source, ensuring reliable audits.", "motivation": "Addressing the problem of fairwashing in audits of online platforms' algorithms, where auditors can be manipulated.", "method": "Introduces the Two-Source Audit setup, leveraging API data and a second data source to detect discrepancies and fairwashing attempts.", "result": "Formally demonstrates conditions for success and empirically validates the method, achieving a Pareto-optimal balance between audit reliability and fairwashing detection.", "conclusion": "The Two-Source Audit method enables reliable audits in manipulation-prone setups under mild assumptions."}}
{"id": "2408.15138", "pdf": "https://arxiv.org/pdf/2408.15138", "abs": "https://arxiv.org/abs/2408.15138", "authors": ["Jerome Garnier-Brun", "Marc M\u00e9zard", "Emanuele Moscato", "Luca Saglietti"], "title": "How transformers learn structured data: insights from hierarchical filtering", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.CL"], "comment": "17 pages, 12 figures", "summary": "Understanding the learning process and the embedded computation in\ntransformers is becoming a central goal for the development of interpretable\nAI. In the present study, we introduce a hierarchical filtering procedure for\ndata models of sequences on trees, allowing us to hand-tune the range of\npositional correlations in the data. Leveraging this controlled setting, we\nprovide evidence that vanilla encoder-only transformers can approximate the\nexact inference algorithm when trained on root classification and masked\nlanguage modeling tasks, and study how this computation is discovered and\nimplemented. We find that correlations at larger distances, corresponding to\nincreasing layers of the hierarchy, are sequentially included by the network\nduring training. By comparing attention maps from models trained with varying\ndegrees of filtering and by probing the different encoder levels, we find clear\nevidence of a reconstruction of correlations on successive length scales\ncorresponding to the various levels of the hierarchy, which we relate to a\nplausible implementation of the exact inference algorithm within the same\narchitecture.", "AI": {"tldr": "The paper explores how transformers learn hierarchical correlations in data, showing they can approximate exact inference algorithms when trained on specific tasks.", "motivation": "To understand the learning process and computational mechanisms in transformers for interpretable AI.", "method": "A hierarchical filtering procedure for sequence data models on trees, training vanilla encoder-only transformers on root classification and masked language modeling tasks.", "result": "Transformers sequentially include correlations at larger distances (hierarchy levels) during training, reconstructing correlations on successive scales.", "conclusion": "The study provides evidence of transformers implementing exact inference algorithms by reconstructing hierarchical correlations."}}
{"id": "2505.05209", "pdf": "https://arxiv.org/pdf/2505.05209", "abs": "https://arxiv.org/abs/2505.05209", "authors": ["Haizhen Xie", "Kunpeng Du", "Qiangyu Yan", "Sen Lu", "Jianhong Han", "Hanting Chen", "Hailin Hu", "Jie Hu"], "title": "EAM: Enhancing Anything with Diffusion Transformers for Blind Super-Resolution", "categories": ["cs.CV"], "comment": "The company audit did not pass, there are some mistake in paper", "summary": "Utilizing pre-trained Text-to-Image (T2I) diffusion models to guide Blind\nSuper-Resolution (BSR) has become a predominant approach in the field. While\nT2I models have traditionally relied on U-Net architectures, recent\nadvancements have demonstrated that Diffusion Transformers (DiT) achieve\nsignificantly higher performance in this domain. In this work, we introduce\nEnhancing Anything Model (EAM), a novel BSR method that leverages DiT and\noutperforms previous U-Net-based approaches. We introduce a novel block,\n$\\Psi$-DiT, which effectively guides the DiT to enhance image restoration. This\nblock employs a low-resolution latent as a separable flow injection control,\nforming a triple-flow architecture that effectively leverages the prior\nknowledge embedded in the pre-trained DiT. To fully exploit the prior guidance\ncapabilities of T2I models and enhance their generalization in BSR, we\nintroduce a progressive Masked Image Modeling strategy, which also reduces\ntraining costs. Additionally, we propose a subject-aware prompt generation\nstrategy that employs a robust multi-modal model in an in-context learning\nframework. This strategy automatically identifies key image areas, provides\ndetailed descriptions, and optimizes the utilization of T2I diffusion priors.\nOur experiments demonstrate that EAM achieves state-of-the-art results across\nmultiple datasets, outperforming existing methods in both quantitative metrics\nand visual quality.", "AI": {"tldr": "EAM introduces a novel BSR method using DiT, outperforming U-Net-based approaches with a new \u03a8-DiT block and progressive Masked Image Modeling.", "motivation": "To enhance Blind Super-Resolution (BSR) by leveraging Diffusion Transformers (DiT) and improving prior knowledge utilization from pre-trained T2I models.", "method": "EAM employs \u03a8-DiT for triple-flow architecture, progressive Masked Image Modeling for training efficiency, and subject-aware prompt generation for better prior utilization.", "result": "EAM achieves state-of-the-art performance in BSR, surpassing existing methods in metrics and visual quality.", "conclusion": "EAM demonstrates superior BSR performance by effectively integrating DiT and innovative training strategies."}}
{"id": "2412.17531", "pdf": "https://arxiv.org/pdf/2412.17531", "abs": "https://arxiv.org/abs/2412.17531", "authors": ["Yang Hou", "Qiuling Yue", "Lujia Chai", "Guozhao Liao", "Wenbao Han", "Wei Ou"], "title": "Double Landmines: Invisible Textual Backdoor Attacks based on Dual-Trigger", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "At present, all textual backdoor attack methods are based on single triggers:\nfor example, inserting specific content into the text to activate the backdoor;\nor changing the abstract text features. The former is easier to be identified\nby existing defense strategies due to its obvious characteristics; the latter,\nalthough improved in invisibility, has certain shortcomings in terms of attack\nperformance, construction of poisoned datasets, and selection of the final\npoisoning rate. On this basis, this paper innovatively proposes a Dual-Trigger\nbackdoor attack based on syntax and mood, and optimizes the construction of the\npoisoned dataset and the selection strategy of the final poisoning rate. A\nlarge number of experimental results show that this method significantly\noutperforms the previous methods based on abstract features in attack\nperformance, and achieves comparable attack performance (almost 100% attack\nsuccess rate) with the insertion-based method. In addition, the two trigger\nmechanisms included in this method can be activated independently in the\napplication phase of the model, which not only improves the flexibility of the\ntrigger style, but also enhances its robustness against defense strategies.\nThese results profoundly reveal that textual backdoor attacks are extremely\nharmful and provide a new perspective for security protection in this field.", "AI": {"tldr": "The paper introduces a Dual-Trigger backdoor attack method using syntax and mood, improving attack performance and robustness against defenses.", "motivation": "Existing single-trigger backdoor attacks are either easily detectable or lack performance. The paper aims to address these limitations.", "method": "Proposes a Dual-Trigger attack based on syntax and mood, optimizing poisoned dataset construction and poisoning rate selection.", "result": "Achieves near 100% attack success rate, outperforming previous methods, and enhances flexibility and robustness.", "conclusion": "Highlights the severe threat of textual backdoor attacks and offers insights for improving security measures."}}
{"id": "2310.08732", "pdf": "https://arxiv.org/pdf/2310.08732", "abs": "https://arxiv.org/abs/2310.08732", "authors": ["Yuan Xin", "Dingfan Chen", "Michael Backes", "Xiao Zhang"], "title": "Provably Cost-Sensitive Adversarial Defense via Randomized Smoothing", "categories": ["cs.LG", "cs.CR"], "comment": "Published in ICML 2025", "summary": "As ML models are increasingly deployed in critical applications, robustness\nagainst adversarial perturbations is crucial. While numerous defenses have been\nproposed to counter such attacks, they typically assume that all adversarial\ntransformations are equally important, an assumption that rarely aligns with\nreal-world applications. To address this, we study the problem of robust\nlearning against adversarial perturbations under cost-sensitive scenarios,\nwhere the potential harm of different types of misclassifications is encoded in\na cost matrix. Our solution introduces a provably robust learning algorithm to\ncertify and optimize for cost-sensitive robustness, building on the scalable\ncertification framework of randomized smoothing. Specifically, we formalize the\ndefinition of cost-sensitive certified radius and propose our novel adaptation\nof the standard certification algorithm to generate tight robustness\ncertificates tailored to any cost matrix. In addition, we design a robust\ntraining method that improves certified cost-sensitive robustness without\ncompromising model accuracy. Extensive experiments on benchmark datasets,\nincluding challenging ones unsolvable by existing methods, demonstrate the\neffectiveness of our certification algorithm and training method across various\ncost-sensitive scenarios.", "AI": {"tldr": "The paper introduces a cost-sensitive robust learning algorithm to address adversarial perturbations, focusing on varying importance of misclassifications. It provides a novel certification method and training approach, validated on benchmark datasets.", "motivation": "Existing defenses against adversarial attacks treat all perturbations equally, which doesn't align with real-world scenarios where some misclassifications are more harmful. The paper aims to address this gap by incorporating cost-sensitive robustness.", "method": "The authors formalize cost-sensitive certified radius and adapt randomized smoothing for scalable certification. They also design a robust training method to improve certified robustness without losing accuracy.", "result": "Experiments on benchmark datasets show the algorithm's effectiveness, even in challenging cases where existing methods fail.", "conclusion": "The proposed method successfully bridges the gap between theoretical robustness and practical cost-sensitive requirements, offering a scalable and accurate solution."}}
{"id": "2410.02062", "pdf": "https://arxiv.org/pdf/2410.02062", "abs": "https://arxiv.org/abs/2410.02062", "authors": ["Zefang Liu", "Yinzhu Quan"], "title": "TPP-LLM: Modeling Temporal Point Processes by Efficiently Fine-Tuning Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Temporal point processes (TPPs) are widely used to model the timing and\noccurrence of events in domains such as social networks, transportation\nsystems, and e-commerce. In this paper, we introduce TPP-LLM, a novel framework\nthat integrates large language models (LLMs) with TPPs to capture both the\nsemantic and temporal aspects of event sequences. Unlike traditional methods\nthat rely on categorical event type representations, TPP-LLM directly utilizes\nthe textual descriptions of event types, enabling the model to capture rich\nsemantic information embedded in the text. While LLMs excel at understanding\nevent semantics, they are less adept at capturing temporal patterns. To address\nthis, TPP-LLM incorporates temporal embeddings and employs parameter-efficient\nfine-tuning (PEFT) methods to effectively learn temporal dynamics without\nextensive retraining. This approach improves both predictive accuracy and\ncomputational efficiency. Experimental results across diverse real-world\ndatasets demonstrate that TPP-LLM outperforms state-of-the-art baselines in\nsequence modeling and event prediction, highlighting the benefits of combining\nLLMs with TPPs.", "AI": {"tldr": "TPP-LLM integrates LLMs with TPPs to model event sequences by capturing semantic and temporal aspects, outperforming traditional methods.", "motivation": "Traditional TPPs lack semantic understanding of event types, relying on categorical representations. TPP-LLM addresses this by leveraging textual descriptions for richer semantics.", "method": "TPP-LLM combines LLMs with TPPs, using textual event descriptions, temporal embeddings, and PEFT for efficient temporal learning.", "result": "TPP-LLM achieves higher predictive accuracy and computational efficiency, outperforming state-of-the-art baselines.", "conclusion": "Combining LLMs with TPPs enhances event sequence modeling, demonstrating the value of integrating semantic and temporal information."}}
{"id": "2505.15256", "pdf": "https://arxiv.org/pdf/2505.15256", "abs": "https://arxiv.org/abs/2505.15256", "authors": ["Tatyana Shmykova", "Leila Khaertdinova", "Ilya Pershin"], "title": "Zero-Shot Gaze-based Volumetric Medical Image Segmentation", "categories": ["cs.CV", "cs.AI", "I.2.1"], "comment": "Accepted to MMFM-BIOMED Workshop @ CVPR 2025", "summary": "Accurate segmentation of anatomical structures in volumetric medical images\nis crucial for clinical applications, including disease monitoring and cancer\ntreatment planning. Contemporary interactive segmentation models, such as\nSegment Anything Model 2 (SAM-2) and its medical variant (MedSAM-2), rely on\nmanually provided prompts like bounding boxes and mouse clicks. In this study,\nwe introduce eye gaze as a novel informational modality for interactive\nsegmentation, marking the application of eye-tracking for 3D medical image\nsegmentation. We evaluate the performance of using gaze-based prompts with\nSAM-2 and MedSAM-2 using both synthetic and real gaze data. Compared to\nbounding boxes, gaze-based prompts offer a time-efficient interaction approach\nwith slightly lower segmentation quality. Our findings highlight the potential\nof using gaze as a complementary input modality for interactive 3D medical\nimage segmentation.", "AI": {"tldr": "The paper introduces eye gaze as a novel input for interactive 3D medical image segmentation, comparing its efficiency and performance with traditional bounding box prompts in SAM-2 and MedSAM-2.", "motivation": "Current interactive segmentation models rely on manual prompts, which can be time-consuming. Eye gaze offers a faster, complementary input method.", "method": "The study evaluates gaze-based prompts using synthetic and real gaze data with SAM-2 and MedSAM-2, comparing them to bounding box prompts.", "result": "Gaze-based prompts are more time-efficient but slightly less accurate than bounding boxes.", "conclusion": "Eye gaze shows promise as a complementary modality for interactive 3D medical image segmentation."}}
{"id": "2501.00296", "pdf": "https://arxiv.org/pdf/2501.00296", "abs": "https://arxiv.org/abs/2501.00296", "authors": ["Ashay Athalye", "Nishanth Kumar", "Tom Silver", "Yichao Liang", "Jiuguang Wang", "Tom\u00e1s Lozano-P\u00e9rez", "Leslie Pack Kaelbling"], "title": "From Pixels to Predicates: Learning Symbolic World Models via Pretrained Vision-Language Models", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Our aim is to learn to solve long-horizon decision-making problems in complex\nrobotics domains given low-level skills and a handful of short-horizon\ndemonstrations containing sequences of images. To this end, we focus on\nlearning abstract symbolic world models that facilitate zero-shot\ngeneralization to novel goals via planning. A critical component of such models\nis the set of symbolic predicates that define properties of and relationships\nbetween objects. In this work, we leverage pretrained vision language models\n(VLMs) to propose a large set of visual predicates potentially relevant for\ndecision-making, and to evaluate those predicates directly from camera images.\nAt training time, we pass the proposed predicates and demonstrations into an\noptimization-based model-learning algorithm to obtain an abstract symbolic\nworld model that is defined in terms of a compact subset of the proposed\npredicates. At test time, given a novel goal in a novel setting, we use the VLM\nto construct a symbolic description of the current world state, and then use a\nsearch-based planning algorithm to find a sequence of low-level skills that\nachieves the goal. We demonstrate empirically across experiments in both\nsimulation and the real world that our method can generalize aggressively,\napplying its learned world model to solve problems with a wide variety of\nobject types, arrangements, numbers of objects, and visual backgrounds, as well\nas novel goals and much longer horizons than those seen at training time.", "AI": {"tldr": "The paper presents a method for learning abstract symbolic world models using pretrained vision language models (VLMs) to solve long-horizon robotics tasks with zero-shot generalization.", "motivation": "To address the challenge of solving long-horizon decision-making problems in complex robotics domains with limited demonstrations and low-level skills.", "method": "Leverage VLMs to propose visual predicates, optimize a compact subset for a symbolic world model, and use search-based planning for novel goals.", "result": "Empirical results show successful generalization across diverse object types, arrangements, and novel goals, even with longer horizons than training.", "conclusion": "The approach enables robust zero-shot generalization in robotics tasks by combining VLMs with symbolic world models and planning."}}
{"id": "2405.15481", "pdf": "https://arxiv.org/pdf/2405.15481", "abs": "https://arxiv.org/abs/2405.15481", "authors": ["Jialin Zhao", "Yingtao Zhang", "Xinghang Li", "Huaping Liu", "Carlo Vittorio Cannistraci"], "title": "Sparse Spectral Training and Inference on Euclidean and Hyperbolic Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "The growing demands on GPU memory posed by the increasing number of neural\nnetwork parameters call for training approaches that are more memory-efficient.\nPrevious memory reduction training techniques, such as Low-Rank Adaptation\n(LoRA) and ReLoRA, face challenges, with LoRA being constrained by its low-rank\nstructure, particularly during intensive tasks like pre-training, and ReLoRA\nsuffering from saddle point issues. In this paper, we propose Sparse Spectral\nTraining (SST) to optimize memory usage for pre-training. SST updates all\nsingular values and selectively updates singular vectors through a multinomial\nsampling method weighted by the magnitude of the singular values. Furthermore,\nSST employs singular value decomposition to initialize and periodically\nreinitialize low-rank parameters, reducing distortion relative to full-rank\ntraining compared to other low-rank methods. Through comprehensive testing on\nboth Euclidean and hyperbolic neural networks across various tasks, SST\ndemonstrates its ability to outperform existing memory reduction training\nmethods and is comparable to full-rank training in various cases. On\nLLaMA-1.3B, with only 18.7\\% of the parameters trainable compared to full-rank\ntraining (using a rank equivalent to 6\\% of the embedding dimension), SST\nreduces the perplexity gap between other low-rank methods and full-rank\ntraining by 97.4\\%. This result highlights SST as an effective\nparameter-efficient technique for model pre-training.", "AI": {"tldr": "Sparse Spectral Training (SST) optimizes GPU memory usage for neural network pre-training by selectively updating singular values and vectors, outperforming other low-rank methods and matching full-rank training performance.", "motivation": "The increasing size of neural networks demands memory-efficient training methods, as existing techniques like LoRA and ReLoRA face limitations in pre-training tasks.", "method": "SST updates all singular values and selectively updates singular vectors using multinomial sampling. It uses SVD for initialization and periodic reinitialization to reduce distortion.", "result": "SST reduces the perplexity gap by 97.4% on LLaMA-1.3B compared to other low-rank methods, using only 18.7% trainable parameters.", "conclusion": "SST is an effective, parameter-efficient technique for model pre-training, achieving performance comparable to full-rank training."}}
{"id": "2412.07192", "pdf": "https://arxiv.org/pdf/2412.07192", "abs": "https://arxiv.org/abs/2412.07192", "authors": ["Zachary Coalson", "Jeonghyun Woo", "Yu Sun", "Shiyang Chen", "Lishan Yang", "Prashant Nair", "Bo Fang", "Sanghyun Hong"], "title": "PrisonBreak: Jailbreaking Large Language Models with Fewer Than Twenty-Five Targeted Bit-flips", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": "Pre-print", "summary": "We introduce a new class of attacks on commercial-scale (human-aligned)\nlanguage models that induce jailbreaking through targeted bitwise corruptions\nin model parameters. Our adversary can jailbreak billion-parameter language\nmodels with fewer than 25 bit-flips in all cases$-$and as few as 5 in\nsome$-$using up to 40$\\times$ less bit-flips than existing attacks on computer\nvision models at least 100$\\times$ smaller. Unlike prompt-based jailbreaks, our\nattack renders these models in memory 'uncensored' at runtime, allowing them to\ngenerate harmful responses without any input modifications. Our attack\nalgorithm efficiently identifies target bits to flip, offering up to 20$\\times$\nmore computational efficiency than previous methods. This makes it practical\nfor language models with billions of parameters. We show an end-to-end\nexploitation of our attack using software-induced fault injection, Rowhammer\n(RH). Our work examines 56 DRAM RH profiles from DDR4 and LPDDR4X devices with\ndifferent RH vulnerabilities. We show that our attack can reliably induce\njailbreaking in systems similar to those affected by prior bit-flip attacks.\nMoreover, our approach remains effective even against highly RH-secure systems\n(e.g., 46$\\times$ more secure than previously tested systems). Our analyses\nfurther reveal that: (1) models with less post-training alignment require fewer\nbit flips to jailbreak; (2) certain model components, such as value projection\nlayers, are substantially more vulnerable than others; and (3) our method is\nmechanistically different than existing jailbreaks. Our findings highlight a\npressing, practical threat to the language model ecosystem and underscore the\nneed for research to protect these models from bit-flip attacks.", "AI": {"tldr": "A new attack method induces jailbreaking in large language models by flipping fewer than 25 bits, making it highly efficient and practical for billion-parameter models.", "motivation": "To demonstrate a practical and efficient method for jailbreaking commercial-scale language models through bitwise corruption, highlighting vulnerabilities in current systems.", "method": "The attack uses targeted bit-flips in model parameters, efficiently identifying vulnerable bits, and employs software-induced fault injection (e.g., Rowhammer) for exploitation.", "result": "The attack succeeds with as few as 5 bit-flips, works on highly secure systems, and reveals model components like value projection layers are more vulnerable.", "conclusion": "The findings expose a significant threat to language models, urging the need for research into defenses against bit-flip attacks."}}
{"id": "2505.17017", "pdf": "https://arxiv.org/pdf/2505.17017", "abs": "https://arxiv.org/abs/2505.17017", "authors": ["Chengzhuo Tong", "Ziyu Guo", "Renrui Zhang", "Wenyu Shan", "Xinyu Wei", "Zhenghao Xing", "Hongsheng Li", "Pheng-Ann Heng"], "title": "Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Code is released at https://github.com/ZiyuGuo99/Image-Generation-CoT", "summary": "Recent advancements underscore the significant role of Reinforcement Learning\n(RL) in enhancing the Chain-of-Thought (CoT) reasoning capabilities of large\nlanguage models (LLMs). Two prominent RL algorithms, Direct Preference\nOptimization (DPO) and Group Relative Policy Optimization (GRPO), are central\nto these developments, showcasing different pros and cons. Autoregressive image\ngeneration, also interpretable as a sequential CoT reasoning process, presents\nunique challenges distinct from LLM-based CoT reasoning. These encompass\nensuring text-image consistency, improving image aesthetic quality, and\ndesigning sophisticated reward models, rather than relying on simpler\nrule-based rewards. While recent efforts have extended RL to this domain, these\nexplorations typically lack an in-depth analysis of the domain-specific\nchallenges and the characteristics of different RL strategies. To bridge this\ngap, we provide the first comprehensive investigation of the GRPO and DPO\nalgorithms in autoregressive image generation, evaluating their in-domain\nperformance and out-of-domain generalization, while scrutinizing the impact of\ndifferent reward models on their respective capabilities. Our findings reveal\nthat GRPO and DPO exhibit distinct advantages, and crucially, that reward\nmodels possessing stronger intrinsic generalization capabilities potentially\nenhance the generalization potential of the applied RL algorithms. Furthermore,\nwe systematically explore three prevalent scaling strategies to enhance both\ntheir in-domain and out-of-domain proficiency, deriving unique insights into\nefficiently scaling performance for each paradigm. We hope our study paves a\nnew path for inspiring future work on developing more effective RL algorithms\nto achieve robust CoT reasoning in the realm of autoregressive image\ngeneration. Code is released at\nhttps://github.com/ZiyuGuo99/Image-Generation-CoT", "AI": {"tldr": "The paper explores the use of RL algorithms (GRPO and DPO) in autoregressive image generation, analyzing their performance, generalization, and the role of reward models, while proposing scaling strategies.", "motivation": "To address the lack of in-depth analysis of RL strategies and domain-specific challenges in autoregressive image generation, particularly for CoT reasoning.", "method": "Comprehensive investigation of GRPO and DPO algorithms, evaluating in-domain performance, out-of-domain generalization, and the impact of reward models.", "result": "GRPO and DPO have distinct advantages; reward models with strong generalization enhance RL algorithm performance. Scaling strategies improve proficiency.", "conclusion": "The study provides insights for developing effective RL algorithms for robust CoT reasoning in autoregressive image generation, with code released for future work."}}
{"id": "2501.08617", "pdf": "https://arxiv.org/pdf/2501.08617", "abs": "https://arxiv.org/abs/2501.08617", "authors": ["Kaiqu Liang", "Haimin Hu", "Ryan Liu", "Thomas L. Griffiths", "Jaime Fern\u00e1ndez Fisac"], "title": "RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "27 pages, 18 figures", "summary": "While Reinforcement Learning from Human Feedback (RLHF) has shown promise in\naligning generative AI, we present empirical evidence that it can also cause\nsevere, systematic misalignment. We hypothesize that this stems from evaluator\nfeedback depending on downstream outcome predictions (foresight) that can be\ninfluenced by the AI's output, inducing Goodhart's law dynamics. We present a\ntheoretical analysis showing that conditioning evaluator feedback on downstream\nobservations (hindsight) inhibits this effect by decoupling the alignment\nsignal from potentially compromised predictions--crucially, the result holds\neven if the observed outcomes are sampled from the AI's own world model.\nBuilding on this insight, we introduce Reinforcement Learning from Hindsight\nSimulation (RLHS), which presents plausible simulated outcomes to evaluators\nbefore eliciting feedback. We validate RLHS across three consultancy\nsettings--marketplace interactions, restaurant recommendations, and online\ncourse advising--using both online (PPO) and offline (DPO) fine-tuning methods,\nand show that it substantially improves alignment over RLHF in experiments and\nhuman evaluations. We perform post-hoc benchmark evaluations on TruthfulQA,\nHaluEval, and TrustLLM, finding that even after single-task fine-tuning, RLHF\nmisalignment persists, whereas RLHS consistently outperforms baselines and\ndemonstrates robust alignment generalization. The project webpage and code are\navailable at https://rl-hindsight.github.io.", "AI": {"tldr": "RLHF can cause misalignment due to evaluator feedback depending on foresight, while RLHS (using hindsight) mitigates this and improves alignment.", "motivation": "Address the systematic misalignment in RLHF caused by evaluator feedback relying on foresight, which can be influenced by AI outputs.", "method": "Introduce RLHS, which uses hindsight simulation to decouple alignment signals from compromised predictions, validated in consultancy settings with PPO and DPO.", "result": "RLHS outperforms RLHF in alignment, showing robust generalization in benchmarks like TruthfulQA and HaluEval.", "conclusion": "RLHS is a promising alternative to RLHF, mitigating misalignment and improving generalization."}}
{"id": "2406.01416", "pdf": "https://arxiv.org/pdf/2406.01416", "abs": "https://arxiv.org/abs/2406.01416", "authors": ["Kevin Kasa", "Zhiyu Zhang", "Heng Yang", "Graham W. Taylor"], "title": "Adapting Prediction Sets to Distribution Shifts Without Labels", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Recently there has been a surge of interest to deploy confidence set\npredictions rather than point predictions in machine learning. Unfortunately,\nthe effectiveness of such prediction sets is frequently impaired by\ndistribution shifts in practice, and the challenge is often compounded by the\nlack of ground truth labels at test time. Focusing on a standard set-valued\nprediction framework called conformal prediction (CP), this paper studies how\nto improve its practical performance using only unlabeled data from the shifted\ntest domain. This is achieved by two new methods called ECP and EACP, whose\nmain idea is to adjust the score function in CP according to its base model's\nown uncertainty evaluation. Through extensive experiments on a number of\nlarge-scale datasets and neural network architectures, we show that our methods\nprovide consistent improvement over existing baselines and nearly match the\nperformance of fully supervised methods.", "AI": {"tldr": "The paper introduces ECP and EACP to improve conformal prediction (CP) under distribution shifts using unlabeled test data, achieving near-supervised performance.", "motivation": "Address the performance impairment of confidence set predictions due to distribution shifts and lack of test-time labels.", "method": "Proposes ECP and EACP, adjusting CP's score function based on the base model's uncertainty evaluation.", "result": "ECP and EACP outperform baselines and nearly match supervised methods in experiments.", "conclusion": "The methods effectively enhance CP's robustness to distribution shifts without requiring labeled test data."}}
{"id": "2502.15794", "pdf": "https://arxiv.org/pdf/2502.15794", "abs": "https://arxiv.org/abs/2502.15794", "authors": ["Yudong W. Xu", "Wenhao Li", "Scott Sanner", "Elias B. Khalil"], "title": "Self-Supervised Transformers as Iterative Solution Improvers for Constraint Satisfaction", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.LO"], "comment": "ICML 2025", "summary": "We present a Transformer-based framework for Constraint Satisfaction Problems\n(CSPs). CSPs find use in many applications and thus accelerating their solution\nwith machine learning is of wide interest. Most existing approaches rely on\nsupervised learning from feasible solutions or reinforcement learning,\nparadigms that require either feasible solutions to these NP-Complete CSPs or\nlarge training budgets and a complex expert-designed reward signal. To address\nthese challenges, we propose ConsFormer, a self-supervised framework that\nleverages a Transformer as a solution refiner. ConsFormer constructs a solution\nto a CSP iteratively in a process that mimics local search. Instead of using\nfeasible solutions as labeled data, we devise differentiable approximations to\nthe discrete constraints of a CSP to guide model training. Our model is trained\nto improve random assignments for a single step but is deployed iteratively at\ntest time, circumventing the bottlenecks of supervised and reinforcement\nlearning. Experiments on Sudoku, Graph Coloring, Nurse Rostering, and MAXCUT\ndemonstrate that our method can tackle out-of-distribution CSPs simply through\nadditional iterations.", "AI": {"tldr": "ConsFormer is a self-supervised Transformer framework for solving CSPs without requiring labeled data or complex rewards, outperforming traditional supervised and reinforcement learning methods.", "motivation": "Existing CSP solutions rely on supervised or reinforcement learning, which need feasible solutions or complex rewards. ConsFormer addresses these limitations with self-supervised learning.", "method": "Uses a Transformer as a solution refiner, mimicking local search. Differentiable approximations of CSP constraints guide training, enabling iterative improvement of random assignments.", "result": "Effective on Sudoku, Graph Coloring, Nurse Rostering, and MAXCUT, even for out-of-distribution problems through additional iterations.", "conclusion": "ConsFormer offers a scalable, self-supervised alternative to traditional CSP-solving methods, handling diverse problems without labeled data."}}
{"id": "2505.21381", "pdf": "https://arxiv.org/pdf/2505.21381", "abs": "https://arxiv.org/abs/2505.21381", "authors": ["Linshuang Diao", "Dayong Ren", "Sensen Song", "Yurong Qian"], "title": "ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding", "categories": ["cs.CV"], "comment": null, "summary": "State Space models (SSMs) such as PointMamba enable efficient feature\nextraction for point cloud self-supervised learning with linear complexity,\noutperforming Transformers in computational efficiency. However, existing\nPointMamba-based methods depend on complex token ordering and random masking,\nwhich disrupt spatial continuity and local semantic correlations. We propose\nZigzagPointMamba to tackle these challenges. The core of our approach is a\nsimple zigzag scan path that globally sequences point cloud tokens, enhancing\nspatial continuity by preserving the proximity of spatially adjacent point\ntokens. Nevertheless, random masking undermines local semantic modeling in\nself-supervised learning. To address this, we introduce a Semantic-Siamese\nMasking Strategy (SMS), which masks semantically similar tokens to facilitate\nreconstruction by integrating local features of original and similar tokens.\nThis overcomes the dependence on isolated local features and enables robust\nglobal semantic modeling. Our pre-trained ZigzagPointMamba weights\nsignificantly improve downstream tasks, achieving a 1.59% mIoU gain on\nShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 for\nclassification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively for\nthe classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets of\nScanObjectNN.", "AI": {"tldr": "ZigzagPointMamba improves point cloud self-supervised learning by enhancing spatial continuity and local semantic modeling, outperforming existing methods in downstream tasks.", "motivation": "Existing PointMamba-based methods disrupt spatial continuity and local semantic correlations due to complex token ordering and random masking.", "method": "Proposes ZigzagPointMamba with a zigzag scan path for global sequencing and a Semantic-Siamese Masking Strategy (SMS) for better local semantic modeling.", "result": "Achieves significant improvements: 1.59% mIoU gain on ShapeNetPart, 0.4% higher accuracy on ModelNet40, and better accuracies on ScanObjectNN subsets.", "conclusion": "ZigzagPointMamba effectively addresses limitations of existing methods, enhancing performance in point cloud tasks."}}
{"id": "2501.18016", "pdf": "https://arxiv.org/pdf/2501.18016", "abs": "https://arxiv.org/abs/2501.18016", "authors": ["Matsive Ali", "Sandesh Giri", "Sen Liu", "Qin Yang"], "title": "Digital Twin Synchronization: Bridging the Sim-RL Agent to a Real-Time Robotic Additive Manufacturing Control", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "This paper had been accepted by the 2025 IEEE International\n  Conference on Engineering Reliable Autonomous Systems (ERAS)", "summary": "With the rapid development of deep reinforcement learning technology, it\ngradually demonstrates excellent potential and is becoming the most promising\nsolution in the robotics. However, in the smart manufacturing domain, there is\nstill not too much research involved in dynamic adaptive control mechanisms\noptimizing complex processes. This research advances the integration of Soft\nActor-Critic (SAC) with digital twins for industrial robotics applications,\nproviding a framework for enhanced adaptive real-time control for smart\nadditive manufacturing processing. The system architecture combines Unity's\nsimulation environment with ROS2 for seamless digital twin synchronization,\nwhile leveraging transfer learning to efficiently adapt trained models across\ntasks. We demonstrate our methodology using a Viper X300s robot arm with the\nproposed hierarchical reward structure to address the common reinforcement\nlearning challenges in two distinct control scenarios. The results show rapid\npolicy convergence and robust task execution in both simulated and physical\nenvironments demonstrating the effectiveness of our approach.", "AI": {"tldr": "The paper proposes integrating Soft Actor-Critic (SAC) with digital twins for adaptive control in smart manufacturing, using Unity and ROS2 for simulation and transfer learning for task adaptation. Results show rapid convergence and robustness.", "motivation": "Despite deep reinforcement learning's potential in robotics, dynamic adaptive control in smart manufacturing remains under-researched. This work aims to bridge this gap.", "method": "Combines SAC with digital twins, using Unity and ROS2 for simulation synchronization and transfer learning for model adaptation. Tested on a Viper X300s robot arm with a hierarchical reward structure.", "result": "Demonstrates rapid policy convergence and robust task execution in both simulated and physical environments.", "conclusion": "The approach effectively enhances adaptive real-time control for smart additive manufacturing, proving its potential in industrial robotics."}}
{"id": "2406.02017", "pdf": "https://arxiv.org/pdf/2406.02017", "abs": "https://arxiv.org/abs/2406.02017", "authors": ["Xiwei Cheng", "Kexin Fu", "Farzan Farnia"], "title": "On the Hardness of Sampling from Mixture Distributions via Langevin Dynamics", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The Langevin Dynamics (LD), which aims to sample from a probability\ndistribution using its score function, has been widely used for analyzing and\ndeveloping score-based generative modeling algorithms. While the convergence\nbehavior of LD in sampling from a uni-modal distribution has been extensively\nstudied in the literature, the analysis of LD under a mixture distribution with\ndistinct modes remains underexplored in the literature. In this work, we\nanalyze LD in sampling from a mixture distribution and theoretically study its\nconvergence properties. Our theoretical results indicate that for general\nmixture distributions of sub-Gaussian components, LD could fail in finding all\nthe components within a sub-exponential number of steps in the data dimension.\nFollowing our result on the complexity of LD in sampling from high-dimensional\nvariables, we propose Chained Langevin Dynamics (Chained-LD), which divides the\ndata vector into patches of smaller sizes and generates every patch\nsequentially conditioned on the previous patches. Our theoretical analysis of\nChained-LD indicates its faster convergence speed to the components of a\nmixture distribution. We present the results of several numerical experiments\non synthetic and real image datasets, validating our theoretical results on the\niteration complexities of sample generation from mixture distributions using\nthe vanilla and chained LD algorithms.", "AI": {"tldr": "The paper analyzes Langevin Dynamics (LD) for sampling from mixture distributions, reveals its limitations in high dimensions, and proposes Chained-LD for faster convergence.", "motivation": "To address the underexplored convergence behavior of LD in sampling from mixture distributions with distinct modes.", "method": "Theoretical analysis of LD for mixture distributions and introduction of Chained-LD, which processes data in smaller patches.", "result": "LD may fail to find all components in high dimensions; Chained-LD shows faster convergence.", "conclusion": "Chained-LD is a promising alternative to LD for efficient sampling from mixture distributions, supported by theoretical and experimental validation."}}
{"id": "2503.02885", "pdf": "https://arxiv.org/pdf/2503.02885", "abs": "https://arxiv.org/abs/2503.02885", "authors": ["Caterina Fuligni", "Daniel Dominguez Figaredo", "Julia Stoyanovich"], "title": "\"Would You Want an AI Tutor?\" Understanding Stakeholder Perceptions of LLM-based Systems in the Classroom", "categories": ["cs.CY", "cs.CL", "cs.HC"], "comment": null, "summary": "In recent years, Large Language Models (LLMs) rapidly gained popularity\nacross all parts of society, including education. After initial skepticism and\nbans, many schools have chosen to embrace this new technology by integrating it\ninto their curricula in the form of virtual tutors and teaching assistants.\nHowever, neither the companies developing this technology nor the public\ninstitutions involved in its implementation have set up a formal system to\ncollect feedback from the stakeholders impacted by them. In this paper, we\nargue that understanding the perceptions of those directly or indirectly\nimpacted by LLMs in the classroom, including parents and school staff, is\nessential for ensuring responsible use of AI in this critical domain.\n  Our contributions are two-fold. First, we propose the Contextualized\nPerceptions for the Adoption of LLMs in Education (Co-PALE) framework, which\ncan be used to systematically elicit perceptions and inform whether and how\nLLM-based tools should be designed, developed, and deployed in the classroom.\nSecond, we explain how our framework can be used to ground specific rubrics for\neliciting perceptions of the relevant stakeholders in view of specific goals\nand context of implementation. Overall, Co-PALE is a practical step toward\nhelping educational agents, policymakers, researchers, and technologists ensure\nthe responsible and effective deployment of LLM-based systems across diverse\nlearning contexts.", "AI": {"tldr": "The paper introduces the Co-PALE framework to systematically gather stakeholder feedback on LLMs in education, aiming for responsible AI use.", "motivation": "To address the lack of formal feedback systems for LLMs in education and ensure responsible adoption.", "method": "Proposes the Co-PALE framework to elicit stakeholder perceptions and inform LLM tool design and deployment.", "result": "Co-PALE provides a practical tool for stakeholders to guide responsible LLM implementation in diverse educational settings.", "conclusion": "The framework aids in responsible and effective deployment of LLM-based systems in education."}}
{"id": "2505.22146", "pdf": "https://arxiv.org/pdf/2505.22146", "abs": "https://arxiv.org/abs/2505.22146", "authors": ["Guangfu Hao", "Haojie Wen", "Liangxuna Guo", "Yang Chen", "Yanchao Bi", "Shan Yu"], "title": "Flexible Tool Selection through Low-dimensional Attribute Alignment of Vision and Language", "categories": ["cs.CV", "cs.AI", "cs.CL", "q-bio.NC"], "comment": null, "summary": "Flexible tool selection reflects a complex cognitive ability that\ndistinguishes humans from other species, yet computational models that capture\nthis ability remain underdeveloped. We developed a framework using\nlow-dimensional attribute representations to bridge visual tool perception and\nlinguistic task understanding. We constructed a comprehensive dataset (ToolNet)\ncontaining 115 common tools labeled with 13 carefully designed attributes\nspanning physical, functional, and psychological properties, paired with\nnatural language scenarios describing tool usage. Visual encoders (ResNet or\nViT) extract attributes from tool images while fine-tuned language models\n(GPT-2, LLaMA, DeepSeek) derive required attributes from task descriptions. Our\napproach achieves 74% accuracy in tool selection tasks-significantly\noutperforming direct tool matching (20%) and smaller multimodal models\n(21%-58%), while approaching performance of much larger models like GPT-4o\n(73%) with substantially fewer parameters. Ablation studies revealed that\nmanipulation-related attributes (graspability, hand-relatedness, elongation)\nconsistently prove most critical across modalities. This work provides a\nparameter-efficient, interpretable solution that mimics human-like tool\ncognition, advancing both cognitive science understanding and practical\napplications in tool selection tasks.", "AI": {"tldr": "A framework using low-dimensional attribute representations bridges visual tool perception and linguistic task understanding, achieving 74% accuracy in tool selection tasks.", "motivation": "To model the complex cognitive ability of flexible tool selection, which distinguishes humans from other species, using computational methods.", "method": "Uses visual encoders (ResNet or ViT) for tool images and fine-tuned language models (GPT-2, LLaMA, DeepSeek) for task descriptions, with a dataset (ToolNet) of 115 tools labeled with 13 attributes.", "result": "Achieves 74% accuracy, outperforming direct tool matching (20%) and smaller multimodal models (21%-58%), and approaching GPT-4o (73%) with fewer parameters.", "conclusion": "Provides a parameter-efficient, interpretable solution mimicking human-like tool cognition, advancing cognitive science and practical tool selection applications."}}
{"id": "2502.00840", "pdf": "https://arxiv.org/pdf/2502.00840", "abs": "https://arxiv.org/abs/2502.00840", "authors": ["Jiawen Zhang", "Kejia Chen", "Lipeng He", "Jian Lou", "Dan Li", "Zunlei Feng", "Mingli Song", "Jian Liu", "Kui Ren", "Xiaohu Yang"], "title": "Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense", "categories": ["cs.CR", "cs.AI"], "comment": "20 pages", "summary": "Large Language Models (LLMs) have showcased remarkable capabilities across\nvarious domains. Accompanying the evolving capabilities and expanding\ndeployment scenarios of LLMs, their deployment challenges escalate due to their\nsheer scale and the advanced yet complex activation designs prevalent in\nnotable model series, such as Llama, Gemma, Mistral. These challenges have\nbecome particularly pronounced in resource-constrained deployment scenarios,\nwhere mitigating inference bottlenecks is imperative. Among various recent\nefforts, activation approximation has emerged as a promising avenue for\npursuing inference efficiency, sometimes considered indispensable in\napplications such as private inference. Despite achieving substantial speedups\nwith minimal impact on utility, even appearing sound and practical for\nreal-world deployment, the safety implications of activation approximations\nremain unclear. In this work, we fill this critical gap in LLM safety by\nconducting the first systematic safety evaluation of activation approximations.\nOur safety vetting spans seven state-of-the-art techniques across three popular\ncategories (activation polynomialization, activation sparsification, and\nactivation quantization), revealing consistent safety degradation across ten\nsafety-aligned LLMs. To overcome the hurdle of devising a unified defense\naccounting for diverse activation approximation methods, we perform an in-depth\nanalysis of their shared error patterns and uncover three key findings. We\npropose QuadA, a novel safety enhancement method tailored to mitigate the\nsafety compromises introduced by activation approximations. Extensive\nexperiments and ablation studies corroborate QuadA's effectiveness in enhancing\nthe safety capabilities of LLMs after activation approximations.", "AI": {"tldr": "The paper evaluates the safety of activation approximation techniques in LLMs, identifies safety degradation, and proposes QuadA to mitigate these issues.", "motivation": "The deployment challenges of LLMs, especially in resource-constrained scenarios, necessitate activation approximation for efficiency, but its safety implications are unclear.", "method": "The study systematically evaluates seven activation approximation techniques across ten safety-aligned LLMs, analyzes shared error patterns, and proposes QuadA for safety enhancement.", "result": "Activation approximations consistently degrade safety across LLMs. QuadA effectively mitigates these safety compromises.", "conclusion": "QuadA is a practical solution to enhance LLM safety post-activation approximation, addressing a critical gap in LLM deployment."}}
{"id": "2406.04308", "pdf": "https://arxiv.org/pdf/2406.04308", "abs": "https://arxiv.org/abs/2406.04308", "authors": ["Natalie Maus", "Kyurae Kim", "Geoff Pleiss", "David Eriksson", "John P. Cunningham", "Jacob R. Gardner"], "title": "Approximation-Aware Bayesian Optimization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "High-dimensional Bayesian optimization (BO) tasks such as molecular design\noften require 10,000 function evaluations before obtaining meaningful results.\nWhile methods like sparse variational Gaussian processes (SVGPs) reduce\ncomputational requirements in these settings, the underlying approximations\nresult in suboptimal data acquisitions that slow the progress of optimization.\nIn this paper we modify SVGPs to better align with the goals of BO: targeting\ninformed data acquisition rather than global posterior fidelity. Using the\nframework of utility-calibrated variational inference, we unify GP\napproximation and data acquisition into a joint optimization problem, thereby\nensuring optimal decisions under a limited computational budget. Our approach\ncan be used with any decision-theoretic acquisition function and is compatible\nwith trust region methods like TuRBO. We derive efficient joint objectives for\nthe expected improvement and knowledge gradient acquisition functions in both\nthe standard and batch BO settings. Our approach outperforms standard SVGPs on\nhigh-dimensional benchmark tasks in control and molecular design.", "AI": {"tldr": "The paper improves high-dimensional Bayesian optimization (BO) by modifying sparse variational Gaussian processes (SVGPs) to focus on informed data acquisition, outperforming standard SVGPs in tasks like molecular design.", "motivation": "Standard SVGPs reduce computational costs but lead to suboptimal data acquisitions, slowing optimization progress in high-dimensional BO tasks.", "method": "The authors modify SVGPs using utility-calibrated variational inference, unifying GP approximation and data acquisition into a joint optimization problem for optimal decisions under limited budgets.", "result": "The approach outperforms standard SVGPs in high-dimensional benchmarks, including control and molecular design tasks.", "conclusion": "The proposed method aligns SVGPs with BO goals, improving efficiency and performance in high-dimensional optimization tasks."}}
{"id": "2503.16586", "pdf": "https://arxiv.org/pdf/2503.16586", "abs": "https://arxiv.org/abs/2503.16586", "authors": ["Yash Vekaria", "Aurelio Loris Canino", "Jonathan Levitsky", "Alex Ciechonski", "Patricia Callejo", "Anna Maria Mandalari", "Zubair Shafiq"], "title": "Big Help or Big Brother? Auditing Tracking, Profiling, and Personalization in Generative AI Assistants", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CR", "cs.CY", "I.2; I.2.1; I.2.7; H.3.4; K.4; K.4.1; H.1; H.1.2; H.5.2; H.4.3"], "comment": null, "summary": "Generative AI (GenAI) browser assistants integrate powerful capabilities of\nGenAI in web browsers to provide rich experiences such as question answering,\ncontent summarization, and agentic navigation. These assistants, available\ntoday as browser extensions, can not only track detailed browsing activity such\nas search and click data, but can also autonomously perform tasks such as\nfilling forms, raising significant privacy concerns. It is crucial to\nunderstand the design and operation of GenAI browser extensions, including how\nthey collect, store, process, and share user data. To this end, we study their\nability to profile users and personalize their responses based on explicit or\ninferred demographic attributes and interests of users. We perform network\ntraffic analysis and use a novel prompting framework to audit tracking,\nprofiling, and personalization by the ten most popular GenAI browser assistant\nextensions. We find that instead of relying on local in-browser models, these\nassistants largely depend on server-side APIs, which can be auto-invoked\nwithout explicit user interaction. When invoked, they collect and share webpage\ncontent, often the full HTML DOM and sometimes even the user's form inputs,\nwith their first-party servers. Some assistants also share identifiers and user\nprompts with third-party trackers such as Google Analytics. The collection and\nsharing continues even if a webpage contains sensitive information such as\nhealth or personal information such as name or SSN entered in a web form. We\nfind that several GenAI browser assistants infer demographic attributes such as\nage, gender, income, and interests and use this profile--which carries across\nbrowsing contexts--to personalize responses. In summary, our work shows that\nGenAI browser assistants can and do collect personal and sensitive information\nfor profiling and personalization with little to no safeguards.", "AI": {"tldr": "GenAI browser assistants collect and share sensitive user data, including webpage content and form inputs, often without safeguards, for profiling and personalization.", "motivation": "To understand the privacy risks posed by GenAI browser extensions, particularly their data collection, profiling, and personalization practices.", "method": "Network traffic analysis and a novel prompting framework to audit the top ten GenAI browser extensions.", "result": "Extensions rely on server-side APIs, collect and share sensitive data (e.g., HTML DOM, form inputs), and profile users using demographic attributes.", "conclusion": "GenAI browser assistants pose significant privacy risks due to extensive data collection and profiling with minimal safeguards."}}
{"id": "2505.22944", "pdf": "https://arxiv.org/pdf/2505.22944", "abs": "https://arxiv.org/abs/2505.22944", "authors": ["Angtian Wang", "Haibin Huang", "Jacob Zhiyuan Fang", "Yiding Yang", "Chongyang Ma"], "title": "ATI: Any Trajectory Instruction for Controllable Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose a unified framework for motion control in video generation that\nseamlessly integrates camera movement, object-level translation, and\nfine-grained local motion using trajectory-based inputs. In contrast to prior\nmethods that address these motion types through separate modules or\ntask-specific designs, our approach offers a cohesive solution by projecting\nuser-defined trajectories into the latent space of pre-trained image-to-video\ngeneration models via a lightweight motion injector. Users can specify\nkeypoints and their motion paths to control localized deformations, entire\nobject motion, virtual camera dynamics, or combinations of these. The injected\ntrajectory signals guide the generative process to produce temporally\nconsistent and semantically aligned motion sequences. Our framework\ndemonstrates superior performance across multiple video motion control tasks,\nincluding stylized motion effects (e.g., motion brushes), dynamic viewpoint\nchanges, and precise local motion manipulation. Experiments show that our\nmethod provides significantly better controllability and visual quality\ncompared to prior approaches and commercial solutions, while remaining broadly\ncompatible with various state-of-the-art video generation backbones. Project\npage: https://anytraj.github.io/.", "AI": {"tldr": "A unified framework for motion control in video generation integrates camera movement, object translation, and local motion using trajectory inputs, outperforming prior methods.", "motivation": "Prior methods handle motion types separately or with task-specific designs, lacking cohesion. This work aims for a unified, user-controllable solution.", "method": "Projects user-defined trajectories into latent space of pre-trained models via a lightweight motion injector, guiding generative process for consistent motion.", "result": "Superior performance in tasks like stylized motion, viewpoint changes, and local manipulation, with better controllability and visual quality.", "conclusion": "The framework is broadly compatible with state-of-the-art video generation models and outperforms existing approaches."}}
{"id": "2502.04406", "pdf": "https://arxiv.org/pdf/2502.04406", "abs": "https://arxiv.org/abs/2502.04406", "authors": ["Vignesh Gopakumar", "Ander Gray", "Lorenzo Zanisi", "Timothy Nunn", "Daniel Giles", "Matt J. Kusner", "Stanislas Pamela", "Marc Peter Deisenroth"], "title": "Calibrated Physics-Informed Uncertainty Quantification", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "Simulating complex physical systems is crucial for understanding and\npredicting phenomena across diverse fields, such as fluid dynamics and heat\ntransfer, as well as plasma physics and structural mechanics. Traditional\napproaches rely on solving partial differential equations (PDEs) using\nnumerical methods, which are computationally expensive and often prohibitively\nslow for real-time applications or large-scale simulations. Neural PDEs have\nemerged as efficient alternatives to these costly numerical solvers, offering\nsignificant computational speed-ups. However, their lack of robust uncertainty\nquantification (UQ) limits deployment in critical applications. We introduce a\nmodel-agnostic, physics-informed conformal prediction (CP) framework that\nprovides guaranteed uncertainty estimates without requiring labelled data. By\nutilising a physics-based approach, we can quantify and calibrate the model's\ninconsistencies with the physics rather than the uncertainty arising from the\ndata. Our approach utilises convolutional layers as finite-difference stencils\nand leverages physics residual errors as nonconformity scores, enabling\ndata-free UQ with marginal and joint coverage guarantees across prediction\ndomains for a range of complex PDEs. We further validate the efficacy of our\nmethod on neural PDE models for plasma modelling and shot design in fusion\nreactors.", "AI": {"tldr": "The paper introduces a physics-informed conformal prediction framework for neural PDEs to provide guaranteed uncertainty estimates without labeled data, addressing limitations in traditional PDE solvers and neural PDEs.", "motivation": "Traditional PDE solvers are computationally expensive, and neural PDEs lack robust uncertainty quantification, limiting their use in critical applications.", "method": "A model-agnostic, physics-informed conformal prediction framework is proposed, using physics residual errors for uncertainty quantification without labeled data.", "result": "The method provides marginal and joint coverage guarantees for complex PDEs, validated on neural PDE models for plasma modeling and fusion reactor shot design.", "conclusion": "The framework offers a scalable and efficient solution for uncertainty quantification in neural PDEs, enhancing their applicability in critical domains."}}
{"id": "2407.16239", "pdf": "https://arxiv.org/pdf/2407.16239", "abs": "https://arxiv.org/abs/2407.16239", "authors": ["Ahmet Zahid Balc\u0131o\u011flu", "Newton Mwai", "Emil Carlsson", "Fredrik D. Johansson"], "title": "Identifiable Latent Bandits: Leveraging observational data for personalized decision-making", "categories": ["cs.LG", "stat.ML"], "comment": "30 pages, 16 figures", "summary": "For many decision-making tasks, such as precision medicine, historical data\nalone are insufficient to determine the right choice for a new problem instance\nor patient. Online algorithms like multi-armed bandits can find optimal\npersonalized decisions but are notoriously sample-hungry. In practice, training\na bandit for a new individual from scratch is often infeasible, as the number\nof trials required is larger than the practical number of decision points.\nLatent bandits offer rapid exploration and personalization beyond what context\nvariables can reveal, provided that a latent variable model can be learned\nconsistently. In this work, we propose an identifiable latent bandit framework\nthat leads to optimal decision-making with a shorter exploration time than\nclassical bandits by learning from historical records of decisions and\noutcomes. Our method is based on nonlinear independent component analysis that\nprovably identifies representations from observational data sufficient to infer\nthe optimal action in new bandit instances. We verify this strategy in\nsimulated and semi-synthetic environments, showing substantial improvement over\nonline and offline learning baselines when identifying conditions are\nsatisfied.", "AI": {"tldr": "The paper introduces an identifiable latent bandit framework for faster personalized decision-making by leveraging historical data and nonlinear independent component analysis.", "motivation": "Historical data alone is insufficient for optimal personalized decisions, and traditional bandit methods require too many trials for practical use.", "method": "Proposes a latent bandit framework using nonlinear independent component analysis to learn identifiable representations from historical data.", "result": "The method reduces exploration time and outperforms online and offline baselines in simulated and semi-synthetic environments.", "conclusion": "The framework enables efficient personalized decision-making when identification conditions are met."}}
{"id": "2503.16814", "pdf": "https://arxiv.org/pdf/2503.16814", "abs": "https://arxiv.org/abs/2503.16814", "authors": ["Jihwan Oh", "Minchan Jeong", "Jongwoo Ko", "Se-Young Yun"], "title": "Understanding Bias Reinforcement in LLM Agents Debate", "categories": ["cs.LG", "cs.CL"], "comment": "ICML 2025", "summary": "Large Language Models $($LLMs$)$ solve complex problems using training-free\nmethods like prompt engineering and in-context learning, yet ensuring reasoning\ncorrectness remains challenging. While self-correction methods such as\nself-consistency and self-refinement aim to improve reliability, they often\nreinforce biases due to the lack of effective feedback mechanisms. Multi-Agent\nDebate $($MAD$)$ has emerged as an alternative, but we identify two key\nlimitations: bias reinforcement, where debate amplifies model biases instead of\ncorrecting them, and lack of perspective diversity, as all agents share the\nsame model and reasoning patterns, limiting true debate effectiveness. To\nsystematically evaluate these issues, we introduce $\\textit{MetaNIM Arena}$, a\nbenchmark designed to assess LLMs in adversarial strategic decision-making,\nwhere dynamic interactions influence optimal decisions. To overcome MAD's\nlimitations, we propose $\\textbf{DReaMAD}$ $($$\\textbf{D}$iverse\n$\\textbf{Rea}$soning via $\\textbf{M}$ulti-$\\textbf{A}$gent $\\textbf{D}$ebate\nwith Refined Prompt$)$, a novel framework that $(1)$ refines LLM's strategic\nprior knowledge to improve reasoning quality and $(2)$ promotes diverse\nviewpoints within a single model by systematically modifying prompts, reducing\nbias. Empirical results show that $\\textbf{DReaMAD}$ significantly improves\ndecision accuracy, reasoning diversity, and bias mitigation across multiple\nstrategic tasks, establishing it as a more effective approach for LLM-based\ndecision-making.", "AI": {"tldr": "The paper introduces DReaMAD, a framework to improve LLM decision-making by refining strategic prior knowledge and promoting diverse viewpoints, addressing biases in multi-agent debates.", "motivation": "Existing self-correction and multi-agent debate methods for LLMs often reinforce biases and lack perspective diversity, limiting reasoning correctness.", "method": "Proposes DReaMAD, which refines LLM's strategic prior knowledge and modifies prompts to encourage diverse reasoning within a single model.", "result": "DReaMAD significantly enhances decision accuracy, reasoning diversity, and bias mitigation in strategic tasks.", "conclusion": "DReaMAD is a more effective approach for LLM-based decision-making, overcoming limitations of existing methods."}}
{"id": "2505.23463", "pdf": "https://arxiv.org/pdf/2505.23463", "abs": "https://arxiv.org/abs/2505.23463", "authors": ["Han Zhou", "Sebastian G. Gruber", "Teodora Popordanoska", "Matthew B. Blaschko"], "title": "Revisiting Reweighted Risk for Calibration: AURC, Focal Loss, and Inverse Focal Loss", "categories": ["cs.CV"], "comment": null, "summary": "Several variants of reweighted risk functionals, such as focal losss, inverse\nfocal loss, and the Area Under the Risk-Coverage Curve (AURC), have been\nproposed in the literature and claims have been made in relation to their\ncalibration properties. However, focal loss and inverse focal loss propose\nvastly different weighting schemes. In this paper, we revisit a broad class of\nweighted risk functions commonly used in deep learning and establish a\nprincipled connection between these reweighting schemes and calibration errors.\nWe show that minimizing calibration error is closely linked to the selective\nclassification paradigm and demonstrate that optimizing a regularized variant\nof the AURC naturally leads to improved calibration. This regularized AURC\nshares a similar reweighting strategy with inverse focal loss, lending support\nto the idea that focal loss is less principled when calibration is a desired\noutcome. Direct AURC optimization offers greater flexibility through the choice\nof confidence score functions (CSFs). To enable gradient-based optimization, we\nintroduce a differentiable formulation of the regularized AURC using the\nSoftRank technique. Empirical evaluations demonstrate that our AURC-based loss\nachieves competitive class-wise calibration performance across a range of\ndatasets and model architectures.", "AI": {"tldr": "The paper analyzes reweighted risk functionals (e.g., focal loss, inverse focal loss, AURC) and links them to calibration errors. It shows that optimizing a regularized AURC improves calibration, aligning with inverse focal loss's strategy, and introduces a differentiable AURC for gradient-based optimization.", "motivation": "To establish a principled connection between reweighting schemes (like focal loss and AURC) and calibration errors, addressing inconsistencies in existing claims.", "method": "The paper revisits weighted risk functions, links calibration error minimization to selective classification, and introduces a differentiable regularized AURC using SoftRank for optimization.", "result": "Empirical evaluations show the AURC-based loss achieves competitive class-wise calibration across datasets and architectures.", "conclusion": "Optimizing a regularized AURC improves calibration, supporting inverse focal loss's strategy over focal loss, and offers flexibility through choice of confidence score functions."}}
{"id": "2502.04573", "pdf": "https://arxiv.org/pdf/2502.04573", "abs": "https://arxiv.org/abs/2502.04573", "authors": ["Yulun Wu", "Doron L. Bergman"], "title": "Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer", "categories": ["cs.LG", "cs.AI"], "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  Vancouver, Canada. PMLR 267, 2025", "summary": "We present an Adversarially Pre-trained Transformer (APT) that is able to\nperform zero-shot meta-learning on tabular prediction tasks without\npre-training on any real-world dataset, extending on the recent development of\nPrior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trained\nwith adversarial synthetic data agents, who continue to shift their underlying\ndata generating distribution and deliberately challenge the model with\ndifferent synthetic datasets. In addition, we propose a mixture block\narchitecture that is able to handle classification tasks with arbitrary number\nof classes, addressing the class size limitation -- a crucial weakness of prior\ndeep tabular zero-shot learners. In experiments, we show that our framework\nmatches state-of-the-art performance on small classification tasks without\nfiltering on dataset characteristics such as number of classes and number of\nmissing values, while maintaining an average runtime under one second. On\ncommon benchmark dataset suites in both classification and regression, we show\nthat adversarial pre-training was able to enhance TabPFN's performance. In our\nanalysis, we demonstrate that the adversarial synthetic data agents were able\nto generate a more diverse collection of data compared to the ordinary random\ngenerator in TabPFN. In addition, we demonstrate that our mixture block neural\ndesign has improved generalizability and greatly accelerated pre-training.", "AI": {"tldr": "APT is a zero-shot meta-learning model for tabular tasks, pre-trained with adversarial synthetic data, outperforming TabPFN and handling arbitrary class sizes.", "motivation": "To improve zero-shot meta-learning for tabular tasks by addressing limitations like class size constraints and lack of diverse pre-training data.", "method": "APT uses adversarial synthetic data agents and a mixture block architecture for flexible classification.", "result": "Matches state-of-the-art performance on small tasks, enhances TabPFN, and improves diversity in synthetic data.", "conclusion": "Adversarial pre-training and mixture block design boost performance and generalizability in tabular zero-shot learning."}}
{"id": "2408.09495", "pdf": "https://arxiv.org/pdf/2408.09495", "abs": "https://arxiv.org/abs/2408.09495", "authors": ["Marco Bagatella", "Andreas Krause", "Georg Martius"], "title": "Directed Exploration in Reinforcement Learning from Linear Temporal Logic", "categories": ["cs.LG"], "comment": null, "summary": "Linear temporal logic (LTL) is a powerful language for task specification in\nreinforcement learning, as it allows describing objectives beyond the\nexpressivity of conventional discounted return formulations. Nonetheless,\nrecent works have shown that LTL formulas can be translated into a variable\nrewarding and discounting scheme, whose optimization produces a policy\nmaximizing a lower bound on the probability of formula satisfaction. However,\nthe synthesized reward signal remains fundamentally sparse, making exploration\nchallenging. We aim to overcome this limitation, which can prevent current\nalgorithms from scaling beyond low-dimensional, short-horizon problems. We show\nhow better exploration can be achieved by further leveraging the LTL\nspecification and casting its corresponding Limit Deterministic B\\\"uchi\nAutomaton (LDBA) as a Markov reward process, thus enabling a form of high-level\nvalue estimation. By taking a Bayesian perspective over LDBA dynamics and\nproposing a suitable prior distribution, we show that the values estimated\nthrough this procedure can be treated as a shaping potential and mapped to\ninformative intrinsic rewards. Empirically, we demonstrate applications of our\nmethod from tabular settings to high-dimensional continuous systems, which have\nso far represented a significant challenge for LTL-based reinforcement learning\nalgorithms.", "AI": {"tldr": "The paper proposes a method to improve exploration in LTL-based reinforcement learning by leveraging LTL specifications and LDBA dynamics to estimate high-level values and intrinsic rewards.", "motivation": "Current LTL-based RL methods suffer from sparse rewards, limiting scalability to low-dimensional, short-horizon problems. The goal is to enhance exploration.", "method": "Translate LTL formulas into LDBA, treat it as a Markov reward process, and estimate values using a Bayesian perspective. Map these to intrinsic rewards.", "result": "The method enables better exploration and scalability, demonstrated in tabular and high-dimensional continuous systems.", "conclusion": "The approach successfully addresses exploration challenges in LTL-based RL, extending applicability to more complex problems."}}
{"id": "2503.22879", "pdf": "https://arxiv.org/pdf/2503.22879", "abs": "https://arxiv.org/abs/2503.22879", "authors": ["Hung-Yueh Chiang", "Chi-Chih Chang", "Natalia Frumkin", "Kai-Chiang Wu", "Mohamed S. Abdelfattah", "Diana Marculescu"], "title": "Quamba2: A Robust and Scalable Post-training Quantization Framework for Selective State Space Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PF"], "comment": null, "summary": "State Space Models (SSMs) are emerging as a compelling alternative to\nTransformers because of their consistent memory usage and high performance.\nDespite this, scaling up SSMs on cloud services or limited-resource devices is\nchallenging due to their storage requirements and computational power. To\novercome this, quantizing SSMs with low bit-width data formats can reduce model\nsize and benefit from hardware acceleration. As SSMs are prone to\nquantization-induced errors, recent efforts have focused on optimizing a\nparticular model or bit-width for efficiency without sacrificing performance.\nHowever, distinct bit-width configurations are essential for different\nscenarios, like W4A8 for boosting large-batch decoding speed, and W4A16 for\nenhancing generation speed in short prompt applications for a single user. To\nthis end, we present Quamba2, compatible with W8A8, W4A8, and W4A16 for both\nMamba1 and Mamba2 backbones, addressing the growing demand for SSM deployment\non various platforms. Based on the channel order preserving and activation\npersistence of SSMs, we propose an offline approach to quantize inputs of a\nlinear recurrence in 8-bit by sorting and clustering for input $x$, combined\nwith a per-state-group quantization for input-dependent parameters $B$ and $C$.\nTo ensure compute-invariance in the SSM output, we rearrange weights offline\naccording to the clustering sequence. The experiments show that Quamba2-8B\noutperforms two state-of-the-art SSM quantization methods and delivers\n1.3$\\times$ and 3$\\times$ speed-ups in the pre-filling and generation stages,\nrespectively, while offering 4$\\times$ memory reduction with only a $1.6\\%$\naverage accuracy drop. The evaluation on MMLU shows the generalizability and\nrobustness of our framework. The code and quantized models will be released at:\nhttps://github.com/enyac-group/Quamba.", "AI": {"tldr": "Quamba2 is a quantization method for State Space Models (SSMs) that supports multiple bit-width configurations, reducing memory usage and improving speed with minimal accuracy loss.", "motivation": "SSMs face challenges in scaling due to storage and computational demands. Quantization can help but must balance efficiency and performance across different scenarios.", "method": "Quamba2 uses an offline approach with channel order preserving and activation persistence, sorting and clustering inputs, and per-state-group quantization for parameters.", "result": "Quamba2-8B outperforms existing methods, offering speed-ups (1.3\u00d7 pre-filling, 3\u00d7 generation) and 4\u00d7 memory reduction with only a 1.6% accuracy drop.", "conclusion": "Quamba2 is a robust and generalizable solution for deploying SSMs efficiently across various platforms."}}
{"id": "2506.01064", "pdf": "https://arxiv.org/pdf/2506.01064", "abs": "https://arxiv.org/abs/2506.01064", "authors": ["Yudong Zhang", "Ruobing Xie", "Yiqing Huang", "Jiansheng Chen", "Xingwu Sun", "Zhanhui Kang", "Di Wang", "Yu Wang"], "title": "Fighting Fire with Fire (F3): A Training-free and Efficient Visual Adversarial Example Purification Method in LVLMs", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 5 figures", "summary": "Recent advances in large vision-language models (LVLMs) have showcased their\nremarkable capabilities across a wide range of multimodal vision-language\ntasks. However, these models remain vulnerable to visual adversarial attacks,\nwhich can substantially compromise their performance. Despite their potential\nimpact, the development of effective methods for purifying such adversarial\nexamples has received relatively limited attention. In this paper, we introduce\nF3, a novel adversarial purification framework that employs a counterintuitive\n\"fighting fire with fire\" strategy: intentionally introducing simple\nperturbations to adversarial examples to mitigate their harmful effects.\nSpecifically, F3 leverages cross-modal attentions derived from randomly\nperturbed adversary examples as reference targets. By injecting noise into\nthese adversarial examples, F3 effectively refines their attention, resulting\nin cleaner and more reliable model outputs. Remarkably, this seemingly\nparadoxical approach of employing noise to counteract adversarial attacks\nyields impressive purification results. Furthermore, F3 offers several distinct\nadvantages: it is training-free and straightforward to implement, and exhibits\nsignificant computational efficiency improvements compared to existing\npurification methods. These attributes render F3 particularly suitable for\nlarge-scale industrial applications where both robust performance and\noperational efficiency are critical priorities. The code will be made publicly\navailable.", "AI": {"tldr": "F3 is a novel adversarial purification framework for LVLMs that uses noise to counteract adversarial attacks, improving robustness and efficiency.", "motivation": "LVLMs are vulnerable to visual adversarial attacks, but existing purification methods are underdeveloped. F3 aims to address this gap.", "method": "F3 introduces simple perturbations to adversarial examples, leveraging cross-modal attentions from perturbed examples to refine attention and purify outputs.", "result": "F3 effectively mitigates adversarial effects, is training-free, computationally efficient, and suitable for large-scale applications.", "conclusion": "F3 provides a practical and efficient solution for adversarial purification in LVLMs, with potential for industrial use."}}
{"id": "2502.06905", "pdf": "https://arxiv.org/pdf/2502.06905", "abs": "https://arxiv.org/abs/2502.06905", "authors": ["Yeseul Cho", "Baekrok Shin", "Changmin Kang", "Chulhee Yun"], "title": "Lightweight Dataset Pruning without Full Training via Example Difficulty and Prediction Uncertainty", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in deep learning rely heavily on massive datasets, leading to\nsubstantial storage and training costs. Dataset pruning aims to alleviate this\ndemand by discarding redundant examples. However, many existing methods require\ntraining a model with a full dataset over a large number of epochs before being\nable to prune the dataset, which ironically makes the pruning process more\nexpensive than just training the model on the entire dataset. To overcome this\nlimitation, we introduce a Difficulty and Uncertainty-Aware Lightweight (DUAL)\nscore, which aims to identify important samples from the early training stage\nby considering both example difficulty and prediction uncertainty. To address a\ncatastrophic accuracy drop at an extreme pruning, we further propose a\nratio-adaptive sampling using Beta distribution. Experiments on various\ndatasets and learning scenarios such as image classification with label noise\nand image corruption, and model architecture generalization demonstrate the\nsuperiority of our method over previous state-of-the-art (SOTA) approaches.\nSpecifically, on ImageNet-1k, our method reduces the time cost for pruning to\n66% compared to previous methods while achieving a SOTA, specifically 60% test\naccuracy at a 90% pruning ratio. On CIFAR datasets, the time cost is reduced to\njust 15% while maintaining SOTA performance.", "AI": {"tldr": "The paper introduces DUAL score for dataset pruning, reducing time and cost while maintaining performance.", "motivation": "Deep learning relies on large datasets, which are costly. Existing pruning methods are expensive as they require full training.", "method": "Proposes DUAL score (Difficulty and Uncertainty-Aware Lightweight) and ratio-adaptive sampling using Beta distribution.", "result": "Achieves SOTA performance with reduced time: 66% on ImageNet-1k, 15% on CIFAR datasets.", "conclusion": "DUAL score effectively prunes datasets early, saving time and resources without sacrificing accuracy."}}
{"id": "2410.07840", "pdf": "https://arxiv.org/pdf/2410.07840", "abs": "https://arxiv.org/abs/2410.07840", "authors": ["Mar\u00eda Mart\u00ednez-Garc\u00eda", "Grace Villacr\u00e9s", "David Mitchell", "Pablo M. Olmos"], "title": "Improved Variational Inference in Discrete VAEs using Error Correcting Codes", "categories": ["cs.LG"], "comment": "Accepted at UAI 2025 Conference", "summary": "Despite advances in deep probabilistic models, learning discrete latent\nrepresentations remains challenging. This work introduces a novel method to\nimprove inference in discrete Variational Autoencoders by reframing the\ninference problem through a generative perspective. We conceptualize the model\nas a communication system, and propose to leverage Error-Correcting Codes\n(ECCs) to introduce redundancy in latent representations, allowing the\nvariational posterior to produce more accurate estimates and reduce the\nvariational gap. We present a proof-of-concept using a Discrete Variational\nAutoencoder with binary latent variables and low-complexity repetition codes,\nextending it to a hierarchical structure for disentangling global and local\ndata features. Our approach significantly improves generation quality, data\nreconstruction, and uncertainty calibration, outperforming the uncoded models\neven when trained with tighter bounds such as the Importance Weighted\nAutoencoder objective. We also outline the properties that ECCs should possess\nto be effectively utilized for improved discrete variational inference.", "AI": {"tldr": "A novel method improves discrete Variational Autoencoders by using Error-Correcting Codes (ECCs) to enhance latent representations, boosting generation quality and reducing variational gaps.", "motivation": "Learning discrete latent representations is challenging in deep probabilistic models, prompting a need for better inference methods.", "method": "Reframes inference as a communication system, applying ECCs for redundancy in latent variables, tested with binary latents and repetition codes in a hierarchical structure.", "result": "Significant improvements in generation quality, data reconstruction, and uncertainty calibration, outperforming uncoded models.", "conclusion": "ECCs effectively enhance discrete variational inference, with specific properties required for optimal performance."}}
{"id": "2505.18789", "pdf": "https://arxiv.org/pdf/2505.18789", "abs": "https://arxiv.org/abs/2505.18789", "authors": ["Wasi Uddin Ahmad", "Somshubra Majumdar", "Boris Ginsburg"], "title": "From Output to Evaluation: Does Raw Instruction-Tuned Code LLMs Output Suffice for Fill-in-the-Middle Code Generation?", "categories": ["cs.SE", "cs.CL"], "comment": "Work in progress", "summary": "Post-processing is crucial for the automatic evaluation of LLMs in\nfill-in-the-middle (FIM) code generation due to the frequent presence of\nextraneous code in raw outputs. This extraneous generation suggests a lack of\nawareness regarding output boundaries, requiring truncation for effective\nevaluation. The determination of an optimal truncation strategy, however, often\nproves intricate, particularly when the scope includes several programming\nlanguages. This study investigates the necessity of post-processing\ninstruction-tuned LLM outputs. Our findings reveal that supervised fine-tuning\nsignificantly enhances FIM code generation, enabling LLMs to generate code that\nseamlessly integrates with the surrounding context. Evaluating our fine-tuned\n\\texttt{Qwen2.5-Coder} (base and instruct) models on HumanEval Infilling and\nSAFIM benchmarks demonstrates improved performances without post-processing,\nespecially when the \\emph{middle} consist of complete lines. However,\npost-processing of the LLM outputs remains necessary when the \\emph{middle} is\na random span of code.", "AI": {"tldr": "Post-processing is essential for evaluating LLMs in FIM code generation due to extraneous outputs. Fine-tuning improves performance, but post-processing is still needed for random spans.", "motivation": "The study aims to address the challenge of extraneous code in LLM outputs for FIM tasks and explore the impact of fine-tuning.", "method": "Investigates post-processing necessity for instruction-tuned LLMs, using supervised fine-tuning on Qwen2.5-Coder models.", "result": "Fine-tuned models perform better on HumanEval Infilling and SAFIM benchmarks, especially for complete lines, but post-processing is still required for random spans.", "conclusion": "Supervised fine-tuning enhances FIM code generation, but post-processing remains crucial for certain cases."}}
{"id": "2506.06733", "pdf": "https://arxiv.org/pdf/2506.06733", "abs": "https://arxiv.org/abs/2506.06733", "authors": ["Ruoxuan Zhang", "Jidong Gao", "Bin Wen", "Hongxia Xie", "Chenming Zhang", "Hong-Han Shuai", "Wen-Huang Cheng"], "title": "RecipeGen: A Step-Aligned Multimodal Benchmark for Real-World Recipe Generation", "categories": ["cs.CV"], "comment": "This is an extended version of arXiv:2503.05228", "summary": "Creating recipe images is a key challenge in food computing, with\napplications in culinary education and multimodal recipe assistants. However,\nexisting datasets lack fine-grained alignment between recipe goals, step-wise\ninstructions, and visual content. We present RecipeGen, the first large-scale,\nreal-world benchmark for recipe-based Text-to-Image (T2I), Image-to-Video\n(I2V), and Text-to-Video (T2V) generation. RecipeGen contains 26,453 recipes,\n196,724 images, and 4,491 videos, covering diverse ingredients, cooking\nprocedures, styles, and dish types. We further propose domain-specific\nevaluation metrics to assess ingredient fidelity and interaction modeling,\nbenchmark representative T2I, I2V, and T2V models, and provide insights for\nfuture recipe generation models. Project page is available now.", "AI": {"tldr": "RecipeGen is a large-scale benchmark for recipe-based text-to-image, image-to-video, and text-to-video generation, addressing the lack of fine-grained alignment in existing datasets.", "motivation": "Existing datasets lack fine-grained alignment between recipe goals, instructions, and visuals, limiting applications in culinary education and recipe assistants.", "method": "Introduces RecipeGen, a dataset with 26,453 recipes, 196,724 images, and 4,491 videos, and proposes domain-specific evaluation metrics.", "result": "RecipeGen benchmarks T2I, I2V, and T2V models, providing insights for future recipe generation models.", "conclusion": "RecipeGen fills a gap in food computing by offering a comprehensive benchmark and evaluation framework for recipe-based generation tasks."}}
{"id": "2502.09885", "pdf": "https://arxiv.org/pdf/2502.09885", "abs": "https://arxiv.org/abs/2502.09885", "authors": ["YongKyung Oh", "Seungsu Kam", "Jonghun Lee", "Dong-Young Lim", "Sungil Kim", "Alex Bui"], "title": "Comprehensive Review of Neural Differential Equations for Time Series Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series modeling and analysis have become critical in various domains.\nConventional methods such as RNNs and Transformers, while effective for\ndiscrete-time and regularly sampled data, face significant challenges in\ncapturing the continuous dynamics and irregular sampling patterns inherent in\nreal-world scenarios. Neural Differential Equations (NDEs) represent a paradigm\nshift by combining the flexibility of neural networks with the mathematical\nrigor of differential equations. This paper presents a comprehensive review of\nNDE-based methods for time series analysis, including neural ordinary\ndifferential equations, neural controlled differential equations, and neural\nstochastic differential equations. We provide a detailed discussion of their\nmathematical formulations, numerical methods, and applications, highlighting\ntheir ability to model continuous-time dynamics. Furthermore, we address key\nchallenges and future research directions. This survey serves as a foundation\nfor researchers and practitioners seeking to leverage NDEs for advanced time\nseries analysis.", "AI": {"tldr": "A review of Neural Differential Equations (NDEs) for time series analysis, addressing their advantages over traditional methods like RNNs and Transformers in modeling continuous dynamics and irregular sampling.", "motivation": "Traditional methods struggle with continuous dynamics and irregular sampling in real-world time series data, motivating the exploration of NDEs.", "method": "The paper reviews NDE-based methods, including neural ODEs, controlled ODEs, and stochastic ODEs, detailing their mathematical formulations and numerical methods.", "result": "NDEs offer a robust framework for modeling continuous-time dynamics, outperforming conventional methods in certain scenarios.", "conclusion": "The survey highlights NDEs' potential for advanced time series analysis and outlines future research directions."}}
{"id": "2410.11226", "pdf": "https://arxiv.org/pdf/2410.11226", "abs": "https://arxiv.org/abs/2410.11226", "authors": ["Peter Eckmann", "Dongxia Wu", "Germano Heinzelmann", "Michael K. Gilson", "Rose Yu"], "title": "MF-LAL: Drug Compound Generation Using Multi-Fidelity Latent Space Active Learning", "categories": ["cs.LG", "q-bio.QM"], "comment": "ICML 2025. 9 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:2402.10387", "summary": "Current generative models for drug discovery primarily use molecular docking\nas an oracle to guide the generation of active compounds. However, such models\nare often not useful in practice because even compounds with high docking\nscores do not consistently show real-world experimental activity. More accurate\nmethods for activity prediction exist, such as molecular dynamics based binding\nfree energy calculations, but they are too computationally expensive to use in\na generative model. To address this challenge, we propose Multi-Fidelity Latent\nspace Active Learning (MF-LAL), a generative modeling framework that integrates\na set of oracles with varying cost-accuracy tradeoffs. Using active learning,\nwe train a surrogate model for each oracle and use these surrogates to guide\ngeneration of compounds with high predicted activity. Unlike previous\napproaches that separately learn the surrogate model and generative model,\nMF-LAL combines the generative and multi-fidelity surrogate models into a\nsingle framework, allowing for more accurate activity prediction and higher\nquality samples. Our experiments on two disease-relevant proteins show that\nMF-LAL produces compounds with significantly better binding free energy scores\nthan other single and multi-fidelity approaches (~50% improvement in mean\nbinding free energy score). The code is available at\nhttps://github.com/Rose-STL-Lab/MF-LAL.", "AI": {"tldr": "MF-LAL is a generative modeling framework that integrates multi-fidelity oracles for drug discovery, improving binding free energy scores by ~50% over existing methods.", "motivation": "Current generative models rely on inaccurate docking scores, while accurate methods are too costly. MF-LAL addresses this by combining multi-fidelity oracles and active learning.", "method": "MF-LAL integrates generative and surrogate models into one framework, using active learning to guide compound generation with varying cost-accuracy oracles.", "result": "Experiments show ~50% improvement in mean binding free energy scores compared to other approaches.", "conclusion": "MF-LAL offers a practical solution for generating high-activity compounds by leveraging multi-fidelity oracles and active learning."}}
{"id": "2505.19356", "pdf": "https://arxiv.org/pdf/2505.19356", "abs": "https://arxiv.org/abs/2505.19356", "authors": ["Kidist Amde Mekonnen", "Yosef Worku Alemneh", "Maarten de Rijke"], "title": "Optimized Text Embedding Models and Benchmarks for Amharic Passage Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "68T50 (Primary), 68T05 (Secondary)", "H.3.3; H.3.1; I.2.7"], "comment": "10 pages (excl. refs/appendix), 10 figures. Accepted to ACL 2025\n  Findings. Kidist and Yosef contributed equally to this work. Public\n  resources: https://github.com/kidist-amde/amharic-ir-benchmarks", "summary": "Neural retrieval methods using transformer-based pre-trained language models\nhave advanced multilingual and cross-lingual retrieval. However, their\neffectiveness for low-resource, morphologically rich languages such as Amharic\nremains underexplored due to data scarcity and suboptimal tokenization. We\naddress this gap by introducing Amharic-specific dense retrieval models based\non pre-trained Amharic BERT and RoBERTa backbones. Our proposed\nRoBERTa-Base-Amharic-Embed model (110M parameters) achieves a 17.6% relative\nimprovement in MRR@10 and a 9.86% gain in Recall@10 over the strongest\nmultilingual baseline, Arctic Embed 2.0 (568M parameters). More compact\nvariants, such as RoBERTa-Medium-Amharic-Embed (42M), remain competitive while\nbeing over 13x smaller. Additionally, we train a ColBERT-based late interaction\nretrieval model that achieves the highest MRR@10 score (0.843) among all\nevaluated models. We benchmark our proposed models against both sparse and\ndense retrieval baselines to systematically assess retrieval effectiveness in\nAmharic. Our analysis highlights key challenges in low-resource settings and\nunderscores the importance of language-specific adaptation. To foster future\nresearch in low-resource IR, we publicly release our dataset, codebase, and\ntrained models at https://github.com/kidist-amde/amharic-ir-benchmarks.", "AI": {"tldr": "The paper introduces Amharic-specific dense retrieval models, achieving significant improvements over multilingual baselines, and highlights the importance of language-specific adaptation in low-resource settings.", "motivation": "To address the underexplored effectiveness of neural retrieval methods for low-resource, morphologically rich languages like Amharic due to data scarcity and suboptimal tokenization.", "method": "Proposes Amharic-specific dense retrieval models based on pre-trained Amharic BERT and RoBERTa backbones, including compact variants and a ColBERT-based late interaction model.", "result": "The RoBERTa-Base-Amharic-Embed model achieves a 17.6% relative improvement in MRR@10 and a 9.86% gain in Recall@10 over the strongest multilingual baseline. The ColBERT-based model achieves the highest MRR@10 score (0.843).", "conclusion": "The study underscores the importance of language-specific adaptation in low-resource IR and releases datasets, code, and models to foster future research."}}
{"id": "2506.07280", "pdf": "https://arxiv.org/pdf/2506.07280", "abs": "https://arxiv.org/abs/2506.07280", "authors": ["Pablo Acuaviva", "Aram Davtyan", "Mariam Hassan", "Sebastian Stapf", "Ahmad Rahimi", "Alexandre Alahi", "Paolo Favaro"], "title": "From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 23 figures, 9 tables. Project page:\n  https://pabloacuaviva.github.io/Gen2Gen/", "summary": "Video Diffusion Models (VDMs) have emerged as powerful generative tools,\ncapable of synthesizing high-quality spatiotemporal content. Yet, their\npotential goes far beyond mere video generation. We argue that the training\ndynamics of VDMs, driven by the need to model coherent sequences, naturally\npushes them to internalize structured representations and an implicit\nunderstanding of the visual world. To probe the extent of this internal\nknowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs\nfor new tasks using only a handful of examples. Our method transforms each task\ninto a visual transition, enabling the training of LoRA weights on short\ninput-output sequences without altering the generative interface of a frozen\nVDM. Despite minimal supervision, the model exhibits strong generalization\nacross diverse tasks, from low-level vision (for example, segmentation and pose\nestimation) to high-level reasoning (for example, on ARC-AGI). These results\nreframe VDMs as more than generative engines. They are adaptable visual\nlearners with the potential to serve as the backbone for future foundation\nmodels in vision.", "AI": {"tldr": "Video Diffusion Models (VDMs) are repurposed for diverse tasks using few-shot fine-tuning, demonstrating adaptability beyond video generation.", "motivation": "To explore the internal knowledge of VDMs and their potential as adaptable visual learners for broader applications.", "method": "A few-shot fine-tuning framework transforms tasks into visual transitions, training LoRA weights on short sequences without modifying the frozen VDM.", "result": "Strong generalization across tasks like segmentation, pose estimation, and high-level reasoning (e.g., ARC-AGI).", "conclusion": "VDMs are versatile visual learners, suitable as backbone for future vision foundation models."}}
{"id": "2502.10550", "pdf": "https://arxiv.org/pdf/2502.10550", "abs": "https://arxiv.org/abs/2502.10550", "authors": ["Egor Cherepanov", "Nikita Kachaev", "Alexey K. Kovalev", "Aleksandr I. Panov"], "title": "Memory, Benchmark & Robots: A Benchmark for Solving Complex Tasks with Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "42 pages, 2 figures", "summary": "Memory is crucial for enabling agents to tackle complex tasks with temporal\nand spatial dependencies. While many reinforcement learning (RL) algorithms\nincorporate memory, the field lacks a universal benchmark to assess an agent's\nmemory capabilities across diverse scenarios. This gap is particularly evident\nin tabletop robotic manipulation, where memory is essential for solving tasks\nwith partial observability and ensuring robust performance, yet no standardized\nbenchmarks exist. To address this, we introduce MIKASA (Memory-Intensive Skills\nAssessment Suite for Agents), a comprehensive benchmark for memory RL, with\nthree key contributions: (1) we propose a comprehensive classification\nframework for memory-intensive RL tasks, (2) we collect MIKASA-Base -- a\nunified benchmark that enables systematic evaluation of memory-enhanced agents\nacross diverse scenarios, and (3) we develop MIKASA-Robo (pip install\nmikasa-robo-suite) -- a novel benchmark of 32 carefully designed\nmemory-intensive tasks that assess memory capabilities in tabletop robotic\nmanipulation. Our work introduces a unified framework to advance memory RL\nresearch, enabling more robust systems for real-world use. MIKASA is available\nat https://tinyurl.com/membenchrobots.", "AI": {"tldr": "The paper introduces MIKASA, a benchmark for evaluating memory capabilities in reinforcement learning (RL) agents, focusing on tabletop robotic manipulation.", "motivation": "The lack of a universal benchmark for assessing memory in RL agents, especially in tasks like robotic manipulation with partial observability, motivated this work.", "method": "The authors propose MIKASA, which includes a classification framework for memory-intensive tasks, a unified benchmark (MIKASA-Base), and a specialized benchmark for robotic manipulation (MIKASA-Robo).", "result": "MIKASA provides a standardized way to evaluate memory-enhanced RL agents across diverse scenarios, including 32 tasks for robotic manipulation.", "conclusion": "MIKASA advances memory RL research by offering a unified framework, enabling more robust real-world applications."}}
{"id": "2411.10548", "pdf": "https://arxiv.org/pdf/2411.10548", "abs": "https://arxiv.org/abs/2411.10548", "authors": ["Peter St. John", "Dejun Lin", "Polina Binder", "Malcolm Greaves", "Vega Shah", "John St. John", "Adrian Lange", "Patrick Hsu", "Rajesh Illango", "Arvind Ramanathan", "Anima Anandkumar", "David H Brookes", "Akosua Busia", "Abhishaike Mahajan", "Stephen Malina", "Neha Prasad", "Sam Sinai", "Lindsay Edwards", "Thomas Gaudelet", "Cristian Regep", "Martin Steinegger", "Burkhard Rost", "Alexander Brace", "Kyle Hippe", "Luca Naef", "Keisuke Kamata", "George Armstrong", "Kevin Boyd", "Zhonglin Cao", "Han-Yi Chou", "Simon Chu", "Allan dos Santos Costa", "Sajad Darabi", "Eric Dawson", "Kieran Didi", "Cong Fu", "Mario Geiger", "Michelle Gill", "Darren Hsu", "Gagan Kaushik", "Maria Korshunova", "Steven Kothen-Hill", "Youhan Lee", "Meng Liu", "Micha Livne", "Zachary McClure", "Jonathan Mitchell", "Alireza Moradzadeh", "Ohad Mosafi", "Youssef Nashed", "Saee Paliwal", "Yuxing Peng", "Sara Rabhi", "Farhad Ramezanghorbani", "Danny Reidenbach", "Camir Ricketts", "Brian Roland", "Kushal Shah", "Tyler Shimko", "Hassan Sirelkhatim", "Savitha Srinivasan", "Abraham C Stern", "Dorota Toczydlowska", "Srimukh Prasad Veccham", "Niccol\u00f2 Alberto Elia Venanzi", "Anton Vorontsov", "Jared Wilber", "Isabel Wilkinson", "Wei Jing Wong", "Eva Xue", "Cory Ye", "Xin Yu", "Yang Zhang", "Guoqing Zhou", "Becca Zandstein", "Christian Dallago", "Bruno Trentini", "Emine Kucukbenli", "Saee Paliwal", "Timur Rvachov", "Eddie Calleja", "Johnny Israeli", "Harry Clifford", "Risto Haukioja", "Nicholas Haemel", "Kyle Tretina", "Neha Tadimeti", "Anthony B Costa"], "title": "BioNeMo Framework: a modular, high-performance library for AI model development in drug discovery", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Artificial Intelligence models encoding biology and chemistry are opening new\nroutes to high-throughput and high-quality in-silico drug development. However,\ntheir training increasingly relies on computational scale, with recent protein\nlanguage models (pLM) training on hundreds of graphical processing units\n(GPUs). We introduce the BioNeMo Framework to facilitate the training of\ncomputational biology and chemistry AI models across hundreds of GPUs. Its\nmodular design allows the integration of individual components, such as data\nloaders, into existing workflows and is open to community contributions. We\ndetail technical features of the BioNeMo Framework through use cases such as\npLM pre-training and fine-tuning. On 256 NVIDIA A100s, BioNeMo Framework trains\na three billion parameter BERT-based pLM on over one trillion tokens in 4.2\ndays. The BioNeMo Framework is open-source and free for everyone to use.", "AI": {"tldr": "The BioNeMo Framework is introduced to streamline the training of AI models in computational biology and chemistry, enabling large-scale training across hundreds of GPUs.", "motivation": "The increasing reliance on computational scale for training AI models in drug development necessitates a framework like BioNeMo to simplify and enhance the process.", "method": "BioNeMo offers a modular design for integrating components like data loaders into workflows, demonstrated through pLM pre-training and fine-tuning.", "result": "The framework successfully trained a 3B-parameter BERT-based pLM on over 1T tokens in 4.2 days using 256 NVIDIA A100 GPUs.", "conclusion": "BioNeMo is an open-source, free tool designed to support high-throughput, high-quality AI model training in computational biology and chemistry."}}
{"id": "2506.06299", "pdf": "https://arxiv.org/pdf/2506.06299", "abs": "https://arxiv.org/abs/2506.06299", "authors": ["Daniel Thilo Schroeder", "Meeyoung Cha", "Andrea Baronchelli", "Nick Bostrom", "Nicholas A. Christakis", "David Garcia", "Amit Goldenberg", "Yara Kyrychenko", "Kevin Leyton-Brown", "Nina Lutz", "Gary Marcus", "Filippo Menczer", "Gordon Pennycook", "David G. Rand", "Frank Schweitzer", "Christopher Summerfield", "Audrey Tang", "Jay Van Bavel", "Sander van der Linden", "Dawn Song", "Jonas R. Kunst"], "title": "How Malicious AI Swarms Can Threaten Democracy", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "comment": "8 pages, 1 figure", "summary": "Advances in AI portend a new era of sophisticated disinformation operations.\nWhile individual AI systems already create convincing -- and at times\nmisleading -- information, an imminent development is the emergence of\nmalicious AI swarms. These systems can coordinate covertly, infiltrate\ncommunities, evade traditional detectors, and run continuous A/B tests, with\nround-the-clock persistence. The result can include fabricated grassroots\nconsensus, fragmented shared reality, mass harassment, voter micro-suppression\nor mobilization, contamination of AI training data, and erosion of\ninstitutional trust. With democratic processes worldwide increasingly\nvulnerable, we urge a three-pronged response: (1) platform-side defenses --\nalways-on swarm-detection dashboards, pre-election high-fidelity\nswarm-simulation stress-tests, transparency audits, and optional client-side\n\"AI shields\" for users; (2) model-side safeguards -- standardized\npersuasion-risk tests, provenance-authenticating passkeys, and watermarking;\nand (3) system-level oversight -- a UN-backed AI Influence Observatory.", "AI": {"tldr": "AI swarms pose a growing threat to democracy by enabling sophisticated disinformation. The paper proposes a three-part defense: platform safeguards, model-side protections, and global oversight.", "motivation": "The rise of AI swarms threatens democratic processes through disinformation, necessitating urgent countermeasures.", "method": "Proposes platform-side defenses (e.g., swarm detection), model-side safeguards (e.g., watermarking), and system-level oversight (e.g., a UN-backed observatory).", "result": "Identifies risks like fabricated consensus and institutional trust erosion, advocating for multi-layered solutions.", "conclusion": "Urges immediate action with a three-pronged approach to mitigate AI-driven disinformation threats."}}
{"id": "2506.07327", "pdf": "https://arxiv.org/pdf/2506.07327", "abs": "https://arxiv.org/abs/2506.07327", "authors": ["Dane Williamson", "Yangfeng Ji", "Matthew Dwyer"], "title": "CASE: Contrastive Activation for Saliency Estimation", "categories": ["cs.CV", "cs.LG", "I.2.6; I.5.1; I.5.5; I.2.10"], "comment": "9 pages, 5 figures. Submitted to IEEE Transactions on Neural Networks\n  and Learning Systems (TNNLS)", "summary": "Saliency methods are widely used to visualize which input features are deemed\nrelevant to a model's prediction. However, their visual plausibility can\nobscure critical limitations. In this work, we propose a diagnostic test for\nclass sensitivity: a method's ability to distinguish between competing class\nlabels on the same input. Through extensive experiments, we show that many\nwidely used saliency methods produce nearly identical explanations regardless\nof the class label, calling into question their reliability. We find that\nclass-insensitive behavior persists across architectures and datasets,\nsuggesting the failure mode is structural rather than model-specific. Motivated\nby these findings, we introduce CASE, a contrastive explanation method that\nisolates features uniquely discriminative for the predicted class. We evaluate\nCASE using the proposed diagnostic and a perturbation-based fidelity test, and\nshow that it produces faithful and more class-specific explanations than\nexisting methods.", "AI": {"tldr": "The paper critiques saliency methods for lacking class sensitivity and introduces CASE, a contrastive method for more reliable explanations.", "motivation": "To address the unreliability of saliency methods in distinguishing between class labels, which undermines their trustworthiness.", "method": "Proposes a diagnostic test for class sensitivity and introduces CASE, a contrastive explanation method.", "result": "Many saliency methods fail to distinguish class labels; CASE outperforms them in fidelity and class specificity.", "conclusion": "CASE provides more faithful and class-specific explanations, addressing a structural limitation of existing methods."}}
{"id": "2502.12278", "pdf": "https://arxiv.org/pdf/2502.12278", "abs": "https://arxiv.org/abs/2502.12278", "authors": ["Ananth K. Kidambi", "Guramrit Singh", "Paulius Dilkas", "Kuldeep S. Meel"], "title": "Towards Practical First-Order Model Counting", "categories": ["cs.LO", "cs.AI"], "comment": "19 pages, 2 figures, to be published at SAT 2025, minor revisions", "summary": "First-order model counting (FOMC) is the problem of counting the number of\nmodels of a sentence in first-order logic. Since lifted inference techniques\nrely on reductions to variants of FOMC, the design of scalable methods for FOMC\nhas attracted attention from both theoreticians and practitioners over the past\ndecade. Recently, a new approach based on first-order knowledge compilation was\nproposed. This approach, called Crane, instead of simply providing the final\ncount, generates definitions of (possibly recursive) functions that can be\nevaluated with different arguments to compute the model count for any domain\nsize. However, this approach is not fully automated, as it requires manual\nevaluation of the constructed functions. The primary contribution of this work\nis a fully automated compilation algorithm, called Crane2, which transforms the\nfunction definitions into C++ code equipped with arbitrary-precision\narithmetic. These additions allow the new FOMC algorithm to scale to domain\nsizes over 500,000 times larger than the current state of the art, as\ndemonstrated through experimental results.", "AI": {"tldr": "Crane2 automates first-order model counting (FOMC) by compiling function definitions into C++ code, enabling scalable computation for large domains.", "motivation": "Existing FOMC methods like Crane require manual evaluation, limiting scalability and automation.", "method": "Crane2 introduces a fully automated compilation algorithm to transform function definitions into C++ code with arbitrary-precision arithmetic.", "result": "Crane2 scales to domain sizes over 500,000 times larger than current methods, as shown in experiments.", "conclusion": "Crane2 advances FOMC by automating and significantly improving scalability for large domains."}}
{"id": "2412.10652", "pdf": "https://arxiv.org/pdf/2412.10652", "abs": "https://arxiv.org/abs/2412.10652", "authors": ["Jinglong Luo", "Guanzhong Chen", "Yehong Zhang", "Shiyu Liu", "Hui Wang", "Yue Yu", "Xun Zhou", "Yuan Qi", "Zenglin Xu"], "title": "CENTAUR: Bridging the Impossible Trinity of Privacy, Efficiency, and Performance in Privacy-Preserving Transformer Inference", "categories": ["cs.LG", "cs.CR"], "comment": "ACL 2025", "summary": "With the growing deployment of pre-trained models like Transformers on cloud\nplatforms, privacy concerns about model parameters and inference data are\nintensifying. Existing Privacy-Preserving Transformer Inference (PPTI)\nframeworks face the \"impossible trinity\" of balancing privacy, efficiency, and\nperformance: Secure Multi-Party Computation (SMPC)-based approaches ensure\nstrong privacy but suffer from high computational overhead and performance\nlosses; Conversely, permutation-based methods achieve near-plaintext efficiency\nand accuracy but compromise privacy by exposing sensitive model parameters and\nintermediate results. Bridging this gap with a single approach presents\nsubstantial challenges, motivating the introduction of CENTAUR, a\ngroundbreaking PPTI framework that seamlessly integrates random permutations\nand SMPC to address the \"impossible trinity\". By designing efficient PPTI\nalgorithms tailored to the structural properties of Transformer models, CENTAUR\nachieves an unprecedented balance among privacy, efficiency, and performance.\nOur experiments demonstrate CENTAUR's ability to resist diverse data\nreconstruction attacks, achieve plaintext-level inference accuracy, and boost\ninference speed by 5.0-30.4 times, unlocking new possibilities for secure and\nefficient AI deployment.", "AI": {"tldr": "CENTAUR is a new PPTI framework that combines random permutations and SMPC to balance privacy, efficiency, and performance in Transformer models.", "motivation": "Addressing the 'impossible trinity' in PPTI frameworks\u2014privacy, efficiency, and performance\u2014where existing methods compromise one for the others.", "method": "Integrates random permutations and SMPC, with algorithms tailored to Transformer models.", "result": "Resists data reconstruction attacks, achieves plaintext-level accuracy, and speeds up inference by 5.0-30.4 times.", "conclusion": "CENTAUR successfully balances privacy, efficiency, and performance, enabling secure and efficient AI deployment."}}
{"id": "2506.06975", "pdf": "https://arxiv.org/pdf/2506.06975", "abs": "https://arxiv.org/abs/2506.06975", "authors": ["Xiaoyuan Zhu", "Yaowen Ye", "Tianyi Qiu", "Hanlin Zhu", "Sijun Tan", "Ajraf Mannan", "Jonathan Michala", "Raluca Ada Popa", "Willie Neiswanger"], "title": "Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "As API access becomes a primary interface to large language models (LLMs),\nusers often interact with black-box systems that offer little transparency into\nthe deployed model. To reduce costs or maliciously alter model behaviors, API\nproviders may discreetly serve quantized or fine-tuned variants, which can\ndegrade performance and compromise safety. Detecting such substitutions is\ndifficult, as users lack access to model weights and, in most cases, even\noutput logits. To tackle this problem, we propose a rank-based uniformity test\nthat can verify the behavioral equality of a black-box LLM to a locally\ndeployed authentic model. Our method is accurate, query-efficient, and avoids\ndetectable query patterns, making it robust to adversarial providers that\nreroute or mix responses upon the detection of testing attempts. We evaluate\nthe approach across diverse threat scenarios, including quantization, harmful\nfine-tuning, jailbreak prompts, and full model substitution, showing that it\nconsistently achieves superior statistical power over prior methods under\nconstrained query budgets.", "AI": {"tldr": "A rank-based uniformity test is proposed to detect substitutions in black-box LLMs, ensuring behavioral equality to authentic models.", "motivation": "API providers may serve altered LLM variants, degrading performance and safety, but detecting such changes is challenging due to limited user access.", "method": "The method uses a rank-based uniformity test to verify model behavior without needing weights or logits, ensuring query efficiency and robustness.", "result": "The approach outperforms prior methods in detecting threats like quantization, fine-tuning, and model substitution under constrained queries.", "conclusion": "The proposed test is effective for verifying LLM integrity in black-box settings, offering accuracy and resilience against adversarial tactics."}}
{"id": "2506.07371", "pdf": "https://arxiv.org/pdf/2506.07371", "abs": "https://arxiv.org/abs/2506.07371", "authors": ["Ruchit Rawal", "Reza Shirkavand", "Heng Huang", "Gowthami Somepalli", "Tom Goldstein"], "title": "ARGUS: Hallucination and Omission Evaluation in Video-LLMs", "categories": ["cs.CV"], "comment": "Project page with all the artifacts:\n  https://ruchitrawal.github.io/argus", "summary": "Video large language models have not yet been widely deployed, largely due to\ntheir tendency to hallucinate. Typical benchmarks for Video-LLMs rely simply on\nmultiple-choice questions. Unfortunately, VideoLLMs hallucinate far more\naggressively on freeform text generation tasks like video captioning than they\ndo on multiple choice verification tasks. To address this weakness, we propose\nARGUS, a VideoLLM benchmark that measures freeform video captioning\nperformance. By comparing VideoLLM outputs to human ground truth captions,\nARGUS quantifies dual metrics. First, we measure the rate of hallucinations in\nthe form of incorrect statements about video content or temporal relationships.\nSecond, we measure the rate at which the model omits important descriptive\ndetails. Together, these dual metrics form a comprehensive view of video\ncaptioning performance.", "AI": {"tldr": "ARGUS is a benchmark for VideoLLMs to measure freeform video captioning performance, focusing on hallucination rates and omission of details.", "motivation": "VideoLLMs hallucinate aggressively in freeform tasks like captioning, unlike multiple-choice tasks, necessitating a better benchmark.", "method": "ARGUS compares VideoLLM outputs to human ground truth captions, quantifying hallucination (incorrect statements) and omission (missing details).", "result": "The benchmark provides dual metrics: hallucination rate and omission rate, offering a comprehensive view of captioning performance.", "conclusion": "ARGUS addresses VideoLLMs' weaknesses by evaluating freeform captioning, improving assessment beyond traditional benchmarks."}}
{"id": "2502.13191", "pdf": "https://arxiv.org/pdf/2502.13191", "abs": "https://arxiv.org/abs/2502.13191", "authors": ["Junyi Guan", "Abhijith Sharma", "Chong Tian", "Salem Lahlou"], "title": "On the Privacy Risks of Spiking Neural Networks: A Membership Inference Analysis", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 6 figures", "summary": "Spiking Neural Networks (SNNs) are increasingly explored for their energy\nefficiency and robustness in real-world applications, yet their privacy risks\nremain largely unexamined. In this work, we investigate the susceptibility of\nSNNs to Membership Inference Attacks (MIAs) -- a major privacy threat where an\nadversary attempts to determine whether a given sample was part of the training\ndataset. While prior work suggests that SNNs may offer inherent robustness due\nto their discrete, event-driven nature, we find that its resilience diminishes\nas latency (T) increases. Furthermore, we introduce an input dropout strategy\nunder black box setting, that significantly enhances membership inference in\nSNNs. Our findings challenge the assumption that SNNs are inherently more\nsecure, and even though they are expected to be better, our results reveal that\nSNNs exhibit privacy vulnerabilities that are equally comparable to Artificial\nNeural Networks (ANNs). Our code is available at\nhttps://anonymous.4open.science/r/MIA_SNN-3610.", "AI": {"tldr": "SNNs, though energy-efficient, are vulnerable to Membership Inference Attacks (MIAs), especially with increased latency. An input dropout strategy enhances MIA success, showing SNNs are not inherently more secure than ANNs.", "motivation": "To examine the privacy risks of SNNs, particularly their susceptibility to MIAs, challenging the assumption of their inherent robustness.", "method": "Investigates SNNs' vulnerability to MIAs, introduces an input dropout strategy under black box settings, and compares results with ANNs.", "result": "SNNs' resilience to MIAs diminishes with higher latency, and the input dropout method significantly improves attack success, revealing comparable vulnerabilities to ANNs.", "conclusion": "SNNs are not inherently more secure against privacy threats like MIAs, and their vulnerabilities are similar to ANNs, despite expectations of robustness."}}
{"id": "2412.17499", "pdf": "https://arxiv.org/pdf/2412.17499", "abs": "https://arxiv.org/abs/2412.17499", "authors": ["Linus Heck", "Maximilian Gelbrecht", "Michael T. Schaub", "Niklas Boers"], "title": "Improving the Noise Estimation of Latent Neural Stochastic Differential Equations", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted for publication in Chaos: An Interdisciplinary Journal of\n  Nonlinear Science", "summary": "Latent neural stochastic differential equations (SDEs) have recently emerged\nas a promising approach for learning generative models from stochastic time\nseries data. However, they systematically underestimate the noise level\ninherent in such data, limiting their ability to capture stochastic dynamics\naccurately. We investigate this underestimation in detail and propose a\nstraightforward solution: by including an explicit additional noise\nregularization in the loss function, we are able to learn a model that\naccurately captures the diffusion component of the data. We demonstrate our\nresults on a conceptual model system that highlights the improved latent neural\nSDE's capability to model stochastic bistable dynamics.", "AI": {"tldr": "Latent neural SDEs underestimate noise in stochastic time series data. Adding noise regularization improves accuracy in capturing stochastic dynamics.", "motivation": "Latent neural SDEs are promising but systematically underestimate noise, limiting their accuracy in modeling stochastic dynamics.", "method": "Propose adding explicit noise regularization to the loss function to better capture the diffusion component of the data.", "result": "Demonstrated improved capability to model stochastic bistable dynamics on a conceptual model system.", "conclusion": "Noise regularization enhances latent neural SDEs' accuracy in capturing stochastic dynamics."}}
{"id": "2506.07739", "pdf": "https://arxiv.org/pdf/2506.07739", "abs": "https://arxiv.org/abs/2506.07739", "authors": ["Jing Zhong", "Jun Yin", "Peilin Li", "Pengyu Zeng", "Miao Zang", "Ran Luo", "Shuai Lu"], "title": "ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Architectural cultures across regions are characterized by stylistic\ndiversity, shaped by historical, social, and technological contexts in addition\nto geograph-ical conditions. Understanding architectural styles requires the\nability to describe and analyze the stylistic features of different architects\nfrom various regions through visual observations of architectural imagery.\nHowever, traditional studies of architectural culture have largely relied on\nsubjective expert interpretations and historical literature reviews, often\nsuffering from regional biases and limited ex-planatory scope. To address these\nchallenges, this study proposes three core contributions: (1) We construct a\nprofessional architectural style dataset named ArchDiffBench, which comprises\n1,765 high-quality architectural images and their corresponding style\nannotations, collected from different regions and historical periods. (2) We\npropose ArchiLense, an analytical framework grounded in Vision-Language Models\nand constructed using the ArchDiffBench dataset. By integrating ad-vanced\ncomputer vision techniques, deep learning, and machine learning algo-rithms,\nArchiLense enables automatic recognition, comparison, and precise\nclassi-fication of architectural imagery, producing descriptive language\noutputs that ar-ticulate stylistic differences. (3) Extensive evaluations show\nthat ArchiLense achieves strong performance in architectural style recognition,\nwith a 92.4% con-sistency rate with expert annotations and 84.5% classification\naccuracy, effec-tively capturing stylistic distinctions across images. The\nproposed approach transcends the subjectivity inherent in traditional analyses\nand offers a more objective and accurate perspective for comparative studies of\narchitectural culture.", "AI": {"tldr": "The paper introduces ArchDiffBench, a dataset of architectural images, and ArchiLense, a framework for automated style analysis, achieving high accuracy and consistency with expert annotations.", "motivation": "Traditional architectural studies rely on subjective expert interpretations and suffer from regional biases. This study aims to provide an objective, automated solution for analyzing architectural styles.", "method": "The study constructs the ArchDiffBench dataset and develops ArchiLense, a framework using Vision-Language Models and machine learning for style recognition and classification.", "result": "ArchiLense achieves 92.4% consistency with expert annotations and 84.5% classification accuracy, demonstrating strong performance in style recognition.", "conclusion": "The proposed approach offers an objective, accurate alternative to traditional methods, enhancing comparative studies of architectural culture."}}
{"id": "2502.18462", "pdf": "https://arxiv.org/pdf/2502.18462", "abs": "https://arxiv.org/abs/2502.18462", "authors": ["Charlie B. Tan", "Avishek Joey Bose", "Chen Lin", "Leon Klein", "Michael M. Bronstein", "Alexander Tong"], "title": "Scalable Equilibrium Sampling with Sequential Boltzmann Generators", "categories": ["cs.LG", "cs.AI"], "comment": "Presented at ICML 2025", "summary": "Scalable sampling of molecular states in thermodynamic equilibrium is a\nlong-standing challenge in statistical physics. Boltzmann generators tackle\nthis problem by pairing normalizing flows with importance sampling to obtain\nuncorrelated samples under the target distribution. In this paper, we extend\nthe Boltzmann generator framework with two key contributions, denoting our\nframework Sequential Boltzmann Generators (SBG). The first is a highly\nefficient Transformer-based normalizing flow operating directly on all-atom\nCartesian coordinates. In contrast to the equivariant continuous flows of prior\nmethods, we leverage exactly invertible non-equivariant architectures which are\nhighly efficient during both sample generation and likelihood evaluation. This\nefficiency unlocks more sophisticated inference strategies beyond standard\nimportance sampling. In particular, we perform inference-time scaling of flow\nsamples using a continuous-time variant of sequential Monte Carlo, in which\nflow samples are transported towards the target distribution with annealed\nLangevin dynamics. SBG achieves state-of-the-art performance w.r.t. all metrics\non peptide systems, demonstrating the first equilibrium sampling in Cartesian\ncoordinates of tri-, tetra- and hexa-peptides that were thus far intractable\nfor prior Boltzmann generators.", "AI": {"tldr": "SBG extends Boltzmann generators with Transformer-based normalizing flows and sequential Monte Carlo, achieving state-of-the-art equilibrium sampling for peptides.", "motivation": "To address the challenge of scalable sampling of molecular states in thermodynamic equilibrium by improving Boltzmann generators.", "method": "Uses Transformer-based normalizing flows on Cartesian coordinates and sequential Monte Carlo with annealed Langevin dynamics.", "result": "Achieves state-of-the-art performance, enabling equilibrium sampling of tri-, tetra-, and hexa-peptides.", "conclusion": "SBG advances Boltzmann generators, making previously intractable peptide systems accessible for sampling."}}
{"id": "2501.19090", "pdf": "https://arxiv.org/pdf/2501.19090", "abs": "https://arxiv.org/abs/2501.19090", "authors": ["Jialin Zhao", "Yingtao Zhang", "Carlo Vittorio Cannistraci"], "title": "Pivoting Factorization: A Compact Meta Low-Rank Representation of Sparsity for Efficient Inference in Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "The rapid growth of Large Language Models has driven demand for effective\nmodel compression techniques to reduce memory and computation costs. Low-rank\npruning has gained attention for its GPU compatibility across all densities.\nHowever, low-rank pruning struggles to match the performance of semi-structured\npruning, often doubling perplexity at similar densities. In this paper, we\npropose Pivoting Factorization (PIFA), a novel lossless meta low-rank\nrepresentation that unsupervisedly learns a compact form of any low-rank\nrepresentation, effectively eliminating redundant information. PIFA identifies\npivot rows (linearly independent rows) and expresses non-pivot rows as linear\ncombinations, achieving 24.2% additional memory savings and 24.6% faster\ninference over low-rank layers at rank = 50% of dimension. To mitigate the\nperformance degradation caused by low-rank pruning, we introduce a novel,\nretraining-free reconstruction method that minimizes error accumulation (M).\nMPIFA, combining M and PIFA into an end-to-end framework, significantly\noutperforms existing low-rank pruning methods, and achieves performance\ncomparable to semi-structured pruning, while surpassing it in GPU efficiency\nand compatibility. Our code is available at\nhttps://github.com/biomedical-cybernetics/pivoting-factorization.", "AI": {"tldr": "Pivoting Factorization (PIFA) is a lossless meta low-rank representation method that improves memory savings and inference speed over traditional low-rank pruning, while a retraining-free reconstruction method (M) enhances performance. Combined as MPIFA, it matches semi-structured pruning performance with better GPU efficiency.", "motivation": "The need for efficient model compression techniques for Large Language Models due to memory and computation costs, addressing the limitations of low-rank pruning.", "method": "Proposes PIFA for unsupervised learning of compact low-rank representations and introduces a retraining-free reconstruction method (M) to minimize error. Combines these into MPIFA.", "result": "PIFA achieves 24.2% memory savings and 24.6% faster inference. MPIFA outperforms low-rank pruning and matches semi-structured pruning in performance with superior GPU efficiency.", "conclusion": "MPIFA offers a competitive solution for model compression, balancing performance and efficiency, with potential for broader application in LLMs."}}
{"id": "2506.07977", "pdf": "https://arxiv.org/pdf/2506.07977", "abs": "https://arxiv.org/abs/2506.07977", "authors": ["Jingjing Chang", "Yixiao Fang", "Peng Xing", "Shuhan Wu", "Wei Cheng", "Rui Wang", "Xianfang Zeng", "Gang Yu", "Hai-Bao Chen"], "title": "OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image (T2I) models have garnered significant attention for generating\nhigh-quality images aligned with text prompts. However, rapid T2I model\nadvancements reveal limitations in early benchmarks, lacking comprehensive\nevaluations, for example, the evaluation on reasoning, text rendering and\nstyle. Notably, recent state-of-the-art models, with their rich knowledge\nmodeling capabilities, show promising results on the image generation problems\nrequiring strong reasoning ability, yet existing evaluation systems have not\nadequately addressed this frontier. To systematically address these gaps, we\nintroduce OneIG-Bench, a meticulously designed comprehensive benchmark\nframework for fine-grained evaluation of T2I models across multiple dimensions,\nincluding prompt-image alignment, text rendering precision, reasoning-generated\ncontent, stylization, and diversity. By structuring the evaluation, this\nbenchmark enables in-depth analysis of model performance, helping researchers\nand practitioners pinpoint strengths and bottlenecks in the full pipeline of\nimage generation. Specifically, OneIG-Bench enables flexible evaluation by\nallowing users to focus on a particular evaluation subset. Instead of\ngenerating images for the entire set of prompts, users can generate images only\nfor the prompts associated with the selected dimension and complete the\ncorresponding evaluation accordingly. Our codebase and dataset are now publicly\navailable to facilitate reproducible evaluation studies and cross-model\ncomparisons within the T2I research community.", "AI": {"tldr": "OneIG-Bench is a comprehensive benchmark for evaluating text-to-image models across multiple dimensions like alignment, reasoning, and stylization, addressing gaps in existing evaluations.", "motivation": "Existing benchmarks lack comprehensive evaluation of T2I models, especially in reasoning and stylization, despite advancements in model capabilities.", "method": "Introduces OneIG-Bench, a framework for fine-grained evaluation across dimensions like prompt-image alignment, text rendering, reasoning, and diversity.", "result": "The benchmark enables flexible, in-depth analysis of model performance, helping identify strengths and bottlenecks in image generation.", "conclusion": "OneIG-Bench facilitates reproducible evaluation and cross-model comparisons, advancing T2I research."}}
{"id": "2503.04280", "pdf": "https://arxiv.org/pdf/2503.04280", "abs": "https://arxiv.org/abs/2503.04280", "authors": ["Niccol\u00f2 Turcato", "Matteo Iovino", "Aris Synodinos", "Alberto Dalla Libera", "Ruggero Carli", "Pietro Falco"], "title": "Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHuman-Informed Environments (ARCHIE), an unsupervised pipeline leveraging\nGPT-4, a pre-trained LLM, to generate reward functions directly from natural\nlanguage task descriptions. The rewards are used to train RL agents in\nsimulated environments, where we formalize the reward generation process to\nenhance feasibility. Additionally, GPT-4 automates the coding of task success\ncriteria, creating a fully automated, one-shot procedure for translating\nhuman-readable text into deployable robot skills. Our approach is validated\nthrough extensive simulated experiments on single-arm and bi-manual\nmanipulation tasks using an ABB YuMi collaborative robot, highlighting its\npracticality and effectiveness. Tasks are demonstrated on the real robot setup.", "AI": {"tldr": "ARCHIE uses GPT-4 to generate RL reward functions from natural language, automating the translation of task descriptions into deployable robot skills.", "motivation": "Designing effective RL reward functions is challenging, especially in real-world tasks with sparse or complex rewards.", "method": "Leverages GPT-4 to generate reward functions and automate coding of task success criteria, enabling a one-shot procedure for RL training.", "result": "Validated in simulated and real robot setups, showing practicality and effectiveness in single-arm and bi-manual manipulation tasks.", "conclusion": "ARCHIE provides a fully automated, scalable solution for RL reward generation, bridging the gap between human intent and robot execution."}}
{"id": "2502.00277", "pdf": "https://arxiv.org/pdf/2502.00277", "abs": "https://arxiv.org/abs/2502.00277", "authors": ["Shengyu Feng", "Yiming Yang"], "title": "Regularized Langevin Dynamics for Combinatorial Optimization", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2025", "summary": "This work proposes a simple yet effective sampling framework for\ncombinatorial optimization (CO). Our method builds on discrete Langevin\ndynamics (LD), an efficient gradient-guided generative paradigm. However, we\nobserve that directly applying LD often leads to limited exploration. To\novercome this limitation, we propose the Regularized Langevin Dynamics (RLD),\nwhich enforces an expected distance between the sampled and current solutions,\neffectively avoiding local minima. We develop two CO solvers on top of RLD, one\nbased on simulated annealing (SA), and the other one based on neural network\n(NN). Empirical results on three classic CO problems demonstrate that both of\nour methods can achieve comparable or better performance against the previous\nstate-of-the-art (SOTA) SA- and NN-based solvers. In particular, our SA\nalgorithm reduces the runtime of the previous SOTA SA method by up to 80\\%,\nwhile achieving equal or superior performance. In summary, RLD offers a\npromising framework for enhancing both traditional heuristics and NN models to\nsolve CO problems. Our code is available at\nhttps://github.com/Shengyu-Feng/RLD4CO.", "AI": {"tldr": "The paper introduces Regularized Langevin Dynamics (RLD), a sampling framework for combinatorial optimization, improving exploration and avoiding local minima. It outperforms state-of-the-art methods in runtime and performance.", "motivation": "Direct application of discrete Langevin dynamics (LD) in combinatorial optimization often results in limited exploration, prompting the need for a more effective method.", "method": "Proposes RLD, which enforces distance between sampled and current solutions. Two solvers are developed: one based on simulated annealing (SA) and another on neural networks (NN).", "result": "Empirical results show RLD-based methods achieve comparable or better performance than SOTA SA- and NN-based solvers, with the SA variant reducing runtime by up to 80%.", "conclusion": "RLD is a promising framework for enhancing traditional heuristics and NN models in solving combinatorial optimization problems."}}
{"id": "2304.09914", "pdf": "https://arxiv.org/pdf/2304.09914", "abs": "https://arxiv.org/abs/2304.09914", "authors": ["Sara Major", "Aleksandar Toma\u0161evi\u0107"], "title": "The Face of Populism: Examining Differences in Facial Emotional Expressions of Political Leaders Using Machine Learning", "categories": ["cs.CY", "cs.CV", "cs.LG", "cs.SI", "physics.soc-ph", "J.4"], "comment": "Version 4.0: Annotation study added, supplementary information\n  extended", "summary": "Populist rhetoric employed on online media is characterized as deeply\nimpassioned and often imbued with strong emotions. The aim of this paper is to\nempirically investigate the differences in affective nonverbal communication of\npolitical leaders. We use a deep-learning approach to process a sample of 220\nYouTube videos of political leaders from 15 different countries, analyze their\nfacial expressions of emotion and then examine differences in average emotion\nscores representing the relative presence of 6 emotional states (anger,\ndisgust, fear, happiness, sadness, and surprise) and a neutral expression for\neach frame of the YouTube video. Based on a sample of manually coded images, we\nfind that this deep-learning approach has 53-60\\% agreement with human labels.\nWe observe statistically significant differences in the average score of\nnegative emotions between groups of leaders with varying degrees of populist\nrhetoric.", "AI": {"tldr": "The paper investigates affective nonverbal communication in political leaders using deep learning to analyze facial expressions in YouTube videos, finding differences in negative emotions among populist rhetoric groups.", "motivation": "To empirically study how populist rhetoric influences the affective nonverbal communication of political leaders, focusing on emotional expressions.", "method": "A deep-learning approach processes 220 YouTube videos of leaders from 15 countries, analyzing facial expressions for 6 emotions and neutrality, validated against human-coded samples.", "result": "The deep-learning method agrees 53-60% with human labels. Statistically significant differences in negative emotions are found among leaders with varying populist rhetoric.", "conclusion": "Populist rhetoric correlates with distinct patterns of negative emotional expressions in leaders, as detected by deep learning."}}
{"id": "2503.05816", "pdf": "https://arxiv.org/pdf/2503.05816", "abs": "https://arxiv.org/abs/2503.05816", "authors": ["Rajesh P. Narayanan", "R. Kelley Pace"], "title": "Will Neural Scaling Laws Activate Jevons' Paradox in AI Labor Markets? A Time-Varying Elasticity of Substitution (VES) Analysis", "categories": ["econ.GN", "cs.AI", "cs.CY", "q-fin.EC", "I.2.m; J.4"], "comment": null, "summary": "We develop a formal economic framework to analyze whether neural scaling laws\nin artificial intelligence will activate Jevons' Paradox in labor markets,\npotentially leading to increased AI adoption and human labor substitution. By\nusing a time-varying elasticity of substitution (VES) approach, we establish\nanalytical conditions under which AI systems transition from complementing to\nsubstituting for human labor. Our model formalizes four interconnected\nmechanisms: (1) exponential growth in computational capacity ($C(t) = C(0)\n\\cdot e^{g \\cdot t}$); (2) logarithmic scaling of AI capabilities with\ncomputation ($\\sigma(t) = \\delta \\cdot \\ln(C(t)/C(0))$); (3) declining AI\nprices ($p_A(t) = p_A(0) \\cdot e^{-d \\cdot t}$); and (4) a resulting compound\neffect parameter ($\\phi = \\delta \\cdot g$) that governs market transformation\ndynamics. We identify five distinct phases of AI market penetration,\ndemonstrating that complete market transformation requires the elasticity of\nsubstitution to exceed unity ($\\sigma > 1$), with the timing determined\nprimarily by the compound parameter $\\phi$ rather than price competition alone.\nThese findings provide an analytical framing for evaluating industry claims\nabout AI substitution effects, especially on the role of quality versus price\nin the technological transition.", "AI": {"tldr": "The paper analyzes how neural scaling laws in AI might trigger Jevons' Paradox in labor markets, shifting AI from complementing to substituting human labor. It uses a VES approach to model this transition.", "motivation": "To understand the conditions under which AI systems transition from complementing to substituting human labor, addressing concerns about AI adoption and labor market impacts.", "method": "A formal economic framework with a time-varying elasticity of substitution (VES) approach, modeling four mechanisms: computational growth, AI capability scaling, declining AI prices, and a compound effect parameter.", "result": "Identifies five phases of AI market penetration, showing complete transformation requires substitution elasticity >1, driven by the compound parameter \u03d5.", "conclusion": "Provides a framework to evaluate AI substitution effects, emphasizing the role of quality (capability) over price in the transition."}}
{"id": "2502.00846", "pdf": "https://arxiv.org/pdf/2502.00846", "abs": "https://arxiv.org/abs/2502.00846", "authors": ["Terje Mildner", "Oliver Hamelijnck", "Paris Giampouras", "Theodoros Damoulas"], "title": "Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at ICML 2025", "summary": "We introduce FedGVI, a probabilistic Federated Learning (FL) framework that\nis robust to both prior and likelihood misspecification. FedGVI addresses\nlimitations in both frequentist and Bayesian FL by providing unbiased\npredictions under model misspecification, with calibrated uncertainty\nquantification. Our approach generalises previous FL approaches, specifically\nPartitioned Variational Inference (Ashman et al., 2022), by allowing robust and\nconjugate updates, decreasing computational complexity at the clients. We offer\ntheoretical analysis in terms of fixed-point convergence, optimality of the\ncavity distribution, and provable robustness to likelihood misspecification.\nFurther, we empirically demonstrate the effectiveness of FedGVI in terms of\nimproved robustness and predictive performance on multiple synthetic and real\nworld classification data sets.", "AI": {"tldr": "FedGVI is a robust probabilistic Federated Learning framework that handles model misspecification, offering unbiased predictions and calibrated uncertainty. It generalizes prior FL methods, reduces client-side computation, and shows theoretical and empirical improvements.", "motivation": "Address limitations in frequentist and Bayesian FL by ensuring robustness to prior and likelihood misspecification, providing unbiased predictions and calibrated uncertainty.", "method": "Generalizes Partitioned Variational Inference, enabling robust conjugate updates and reducing computational complexity at clients. Theoretical analysis includes fixed-point convergence and robustness proofs.", "result": "Theoretical guarantees (convergence, optimality, robustness) and empirical improvements in robustness and predictive performance on synthetic and real-world datasets.", "conclusion": "FedGVI effectively addresses FL limitations, offering robust, computationally efficient, and theoretically sound solutions with empirical validation."}}
{"id": "2503.08071", "pdf": "https://arxiv.org/pdf/2503.08071", "abs": "https://arxiv.org/abs/2503.08071", "authors": ["Kai Deng", "Yigong Zhang", "Jian Yang", "Jin Xie"], "title": "GigaSLAM: Large-Scale Monocular SLAM with Hierarchical Gaussian Splats", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Tracking and mapping in large-scale, unbounded outdoor environments using\nonly monocular RGB input presents substantial challenges for existing SLAM\nsystems. Traditional Neural Radiance Fields (NeRF) and 3D Gaussian Splatting\n(3DGS) SLAM methods are typically limited to small, bounded indoor settings. To\novercome these challenges, we introduce GigaSLAM, the first RGB NeRF /\n3DGS-based SLAM framework for kilometer-scale outdoor environments, as\ndemonstrated on the KITTI, KITTI 360, 4 Seasons and A2D2 datasets. Our approach\nemploys a hierarchical sparse voxel map representation, where Gaussians are\ndecoded by neural networks at multiple levels of detail. This design enables\nefficient, scalable mapping and high-fidelity viewpoint rendering across\nexpansive, unbounded scenes. For front-end tracking, GigaSLAM utilizes a metric\ndepth model combined with epipolar geometry and PnP algorithms to accurately\nestimate poses, while incorporating a Bag-of-Words-based loop closure mechanism\nto maintain robust alignment over long trajectories. Consequently, GigaSLAM\ndelivers high-precision tracking and visually faithful rendering on urban\noutdoor benchmarks, establishing a robust SLAM solution for large-scale,\nlong-term scenarios, and significantly extending the applicability of Gaussian\nSplatting SLAM systems to unbounded outdoor environments. GitHub:\nhttps://github.com/DengKaiCQ/GigaSLAM.", "AI": {"tldr": "GigaSLAM is a monocular RGB SLAM framework for large-scale outdoor environments, combining NeRF and 3D Gaussian Splatting with hierarchical sparse voxel mapping for efficient, scalable tracking and rendering.", "motivation": "Existing SLAM systems struggle with large-scale, unbounded outdoor environments using monocular RGB input, as traditional NeRF and 3DGS methods are limited to small indoor settings.", "method": "GigaSLAM uses a hierarchical sparse voxel map with neural network-decoded Gaussians for scalable mapping. It employs metric depth, epipolar geometry, PnP algorithms, and loop closure for robust tracking.", "result": "GigaSLAM achieves high-precision tracking and high-fidelity rendering on urban outdoor benchmarks like KITTI, KITTI 360, 4 Seasons, and A2D2.", "conclusion": "GigaSLAM extends Gaussian Splatting SLAM to unbounded outdoor environments, offering a robust solution for large-scale, long-term scenarios."}}
{"id": "2503.19037", "pdf": "https://arxiv.org/pdf/2503.19037", "abs": "https://arxiv.org/abs/2503.19037", "authors": ["Jianren Wang", "Yifan Su", "Abhinav Gupta", "Deepak Pathak"], "title": "Evolutionary Policy Optimization", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Website at https://yifansu1301.github.io/EPO/", "summary": "On-policy reinforcement learning (RL) algorithms are widely used for their\nstrong asymptotic performance and training stability, but they struggle to\nscale with larger batch sizes, as additional parallel environments yield\nredundant data due to limited policy-induced diversity. In contrast,\nEvolutionary Algorithms (EAs) scale naturally and encourage exploration via\nrandomized population-based search, but are often sample-inefficient. We\npropose Evolutionary Policy Optimization (EPO), a hybrid algorithm that\ncombines the scalability and diversity of EAs with the performance and\nstability of policy gradients. EPO maintains a population of agents conditioned\non latent variables, shares actor-critic network parameters for coherence and\nmemory efficiency, and aggregates diverse experiences into a master agent.\nAcross tasks in dexterous manipulation, legged locomotion, and classic control,\nEPO outperforms state-of-the-art baselines in sample efficiency, asymptotic\nperformance, and scalability.", "AI": {"tldr": "EPO combines Evolutionary Algorithms and policy gradients for scalable, diverse, and efficient reinforcement learning.", "motivation": "On-policy RL struggles with scalability due to redundant data, while EAs lack sample efficiency.", "method": "EPO uses a population of agents with shared actor-critic networks and aggregates experiences into a master agent.", "result": "EPO outperforms baselines in sample efficiency, performance, and scalability across diverse tasks.", "conclusion": "EPO effectively merges the strengths of EAs and policy gradients for superior RL performance."}}
{"id": "2502.02316", "pdf": "https://arxiv.org/pdf/2502.02316", "abs": "https://arxiv.org/abs/2502.02316", "authors": ["Onur Celik", "Zechu Li", "Denis Blessing", "Ge Li", "Daniel Palenicek", "Jan Peters", "Georgia Chalvatzaki", "Gerhard Neumann"], "title": "DIME:Diffusion-Based Maximum Entropy Reinforcement Learning", "categories": ["cs.LG"], "comment": "9 pages main text, 20 pages all included", "summary": "Maximum entropy reinforcement learning (MaxEnt-RL) has become the standard\napproach to RL due to its beneficial exploration properties. Traditionally,\npolicies are parameterized using Gaussian distributions, which significantly\nlimits their representational capacity. Diffusion-based policies offer a more\nexpressive alternative, yet integrating them into MaxEnt-RL poses\nchallenges-primarily due to the intractability of computing their marginal\nentropy. To overcome this, we propose Diffusion-Based Maximum Entropy RL\n(DIME). \\emph{DIME} leverages recent advances in approximate inference with\ndiffusion models to derive a lower bound on the maximum entropy objective.\nAdditionally, we propose a policy iteration scheme that provably converges to\nthe optimal diffusion policy. Our method enables the use of expressive\ndiffusion-based policies while retaining the principled exploration benefits of\nMaxEnt-RL, significantly outperforming other diffusion-based methods on\nchallenging high-dimensional control benchmarks. It is also competitive with\nstate-of-the-art non-diffusion based RL methods while requiring fewer\nalgorithmic design choices and smaller update-to-data ratios, reducing\ncomputational complexity.", "AI": {"tldr": "DIME integrates diffusion-based policies into MaxEnt-RL, overcoming entropy computation challenges with a lower-bound approximation and policy iteration, outperforming other methods in high-dimensional tasks.", "motivation": "Traditional MaxEnt-RL uses Gaussian policies, limiting expressiveness. Diffusion-based policies offer better representation but face entropy computation challenges.", "method": "DIME leverages diffusion models for approximate inference, deriving a lower bound on entropy, and introduces a provably convergent policy iteration scheme.", "result": "DIME outperforms other diffusion-based methods in high-dimensional control tasks and competes with non-diffusion RL methods, reducing computational complexity.", "conclusion": "DIME successfully combines expressive diffusion policies with MaxEnt-RL benefits, offering improved performance and efficiency."}}
{"id": "2503.18528", "pdf": "https://arxiv.org/pdf/2503.18528", "abs": "https://arxiv.org/abs/2503.18528", "authors": ["Moein Sorkhei", "Christos Matsoukas", "Johan Fredin Haslum", "Emir Konuk", "Kevin Smith"], "title": "k-NN as a Simple and Effective Estimator of Transferability", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "How well can one expect transfer learning to work in a new setting where the\ndomain is shifted, the task is different, and the architecture changes? Many\ntransfer learning metrics have been proposed to answer this question. But how\naccurate are their predictions in a realistic new setting? We conducted an\nextensive evaluation involving over 42,000 experiments comparing 23\ntransferability metrics across 16 different datasets to assess their ability to\npredict transfer performance. Our findings reveal that none of the existing\nmetrics perform well across the board. However, we find that a simple k-nearest\nneighbor evaluation -- as is commonly used to evaluate feature quality for\nself-supervision -- not only surpasses existing metrics, but also offers better\ncomputational efficiency and ease of implementation.", "AI": {"tldr": "A study evaluates 23 transferability metrics across 16 datasets, finding none universally effective, but identifies k-nearest neighbor as a superior alternative.", "motivation": "To assess the accuracy of transfer learning metrics in realistic settings with domain shifts, task differences, and architectural changes.", "method": "Conducted 42,000+ experiments comparing 23 metrics across 16 datasets.", "result": "No existing metric performed well universally; k-nearest neighbor outperformed others in accuracy, efficiency, and ease of use.", "conclusion": "k-nearest neighbor is a better transferability metric than existing alternatives."}}
{"id": "2504.06006", "pdf": "https://arxiv.org/pdf/2504.06006", "abs": "https://arxiv.org/abs/2504.06006", "authors": ["Roman Kochnev", "Arash Torabi Goodarzi", "Zofia Antonina Bentyn", "Dmitry Ignatov", "Radu Timofte"], "title": "Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of leveraging large language models (LLMs) for hyperparameter\noptimization by fine-tuning a parameter-efficient version of Code Llama using\nLoRA. The adapted LLM is capable of generating accurate and efficient\nhyperparameter recommendations tailored to diverse neural network\narchitectures. Unlike traditional approaches such as Optuna, which rely on\ncomputationally intensive trial-and-error procedures, our method achieves\ncompetitive or superior results in terms of Root Mean Square Error (RMSE) while\nsignificantly reducing computational overhead. Our findings demonstrate that\nLLM-based optimization not only matches the performance of state-of-the-art\ntechniques like Tree-structured Parzen Estimators (TPE) but also substantially\naccelerates the tuning process. This positions LLMs as a promising alternative\nfor rapid experimentation, particularly in resource-constrained environments\nsuch as edge devices and mobile platforms, where computational efficiency is\nessential. In addition to improved efficiency, the method offers time savings\nand consistent performance across various tasks, highlighting its robustness\nand generalizability. All generated hyperparameters are included in the LEMUR\nNeural Network (NN) Dataset, which is publicly available and serves as an\nopen-source benchmark for hyperparameter optimization research.", "AI": {"tldr": "The paper explores using fine-tuned LLMs (Code Llama with LoRA) for hyperparameter optimization, achieving competitive or better results than traditional methods like Optuna and TPE, with reduced computational cost.", "motivation": "Hyperparameter selection is crucial for neural network performance, especially as models grow in complexity. Traditional methods are computationally intensive, motivating the search for efficient alternatives.", "method": "Fine-tune a parameter-efficient version of Code Llama using LoRA to generate hyperparameter recommendations for diverse neural architectures.", "result": "The LLM-based method matches or outperforms state-of-the-art techniques (e.g., TPE) in RMSE while significantly reducing computational overhead.", "conclusion": "LLMs are a promising alternative for hyperparameter optimization, offering efficiency, speed, and robustness, particularly in resource-constrained environments. The LEMUR NN Dataset is released as a benchmark."}}
{"id": "2502.02545", "pdf": "https://arxiv.org/pdf/2502.02545", "abs": "https://arxiv.org/abs/2502.02545", "authors": ["Leonardo Defilippis", "Yatin Dandi", "Pierre Mergny", "Florent Krzakala", "Bruno Loureiro"], "title": "Optimal Spectral Transitions in High-Dimensional Multi-Index Models", "categories": ["cs.LG", "cond-mat.dis-nn"], "comment": null, "summary": "We consider the problem of how many samples from a Gaussian multi-index model\nare required to weakly reconstruct the relevant index subspace. Despite its\nincreasing popularity as a testbed for investigating the computational\ncomplexity of neural networks, results beyond the single-index setting remain\nelusive. In this work, we introduce spectral algorithms based on the\nlinearization of a message passing scheme tailored to this problem. Our main\ncontribution is to show that the proposed methods achieve the optimal\nreconstruction threshold. Leveraging a high-dimensional characterization of the\nalgorithms, we show that above the critical threshold the leading eigenvector\ncorrelates with the relevant index subspace, a phenomenon reminiscent of the\nBaik-Ben Arous-Peche (BBP) transition in spiked models arising in random matrix\ntheory. Supported by numerical experiments and a rigorous theoretical\nframework, our work bridges critical gaps in the computational limits of weak\nlearnability in multi-index model.", "AI": {"tldr": "The paper investigates the sample complexity for weakly reconstructing the relevant index subspace in Gaussian multi-index models, proposing spectral algorithms that achieve the optimal threshold.", "motivation": "Understanding the computational limits of neural networks, particularly in multi-index settings, remains challenging. This work aims to bridge gaps in weak learnability.", "method": "Spectral algorithms based on linearizing a message passing scheme are introduced and analyzed.", "result": "The proposed methods achieve the optimal reconstruction threshold, with the leading eigenvector correlating with the relevant subspace above this threshold.", "conclusion": "The work provides theoretical and empirical support for the computational limits of weak learnability in multi-index models, linking it to phenomena in random matrix theory."}}
{"id": "2504.02473", "pdf": "https://arxiv.org/pdf/2504.02473", "abs": "https://arxiv.org/abs/2504.02473", "authors": ["Rick van Essen", "Eldert van Henten", "Lammert Kooistra", "Gert Kootstra"], "title": "Adaptive path planning for efficient object search by UAVs in agricultural fields", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "This paper presents an adaptive path planner for object search in\nagricultural fields using UAVs. The path planner uses a high-altitude coverage\nflight path and plans additional low-altitude inspections when the detection\nnetwork is uncertain. The path planner was evaluated in an offline simulation\nenvironment containing real-world images. We trained a YOLOv8 detection network\nto detect artificial plants placed in grass fields to showcase the potential of\nour path planner. We evaluated the effect of different detection certainty\nmeasures, optimized the path planning parameters, investigated the effects of\nlocalization errors, and different numbers of objects in the field. The YOLOv8\ndetection confidence worked best to differentiate between true and false\npositive detections and was therefore used in the adaptive planner. The optimal\nparameters of the path planner depended on the distribution of objects in the\nfield. When the objects were uniformly distributed, more low-altitude\ninspections were needed compared to a non-uniform distribution of objects,\nresulting in a longer path length. The adaptive planner proved to be robust\nagainst localization uncertainty. When increasing the number of objects, the\nflight path length increased, especially when the objects were uniformly\ndistributed. When the objects were non-uniformly distributed, the adaptive path\nplanner yielded a shorter path than a low-altitude coverage path, even with a\nhigh number of objects. Overall, the presented adaptive path planner allowed\nfinding non-uniformly distributed objects in a field faster than a coverage\npath planner and resulted in a compatible detection accuracy. The path planner\nis made available at https://github.com/wur-abe/uav_adaptive_planner.", "AI": {"tldr": "An adaptive UAV path planner for object search in agricultural fields uses high-altitude coverage and low-altitude inspections based on detection uncertainty. It was tested with YOLOv8 and proved efficient for non-uniform object distributions.", "motivation": "To improve object search efficiency in agricultural fields using UAVs by adapting flight paths based on detection certainty.", "method": "Combines high-altitude coverage with low-altitude inspections triggered by detection uncertainty, evaluated using YOLOv8 on real-world images.", "result": "Optimal performance for non-uniform object distributions, robust against localization errors, and shorter paths than coverage planners.", "conclusion": "The adaptive planner is faster and as accurate as coverage planners, especially for non-uniform object distributions."}}
{"id": "2504.08827", "pdf": "https://arxiv.org/pdf/2504.08827", "abs": "https://arxiv.org/abs/2504.08827", "authors": ["Samy-Melwan Vilhes", "Gilles Gasso", "Mokhtar Z Alaya"], "title": "PatchTrAD: A Patch-Based Transformer focusing on Patch-Wise Reconstruction Error for Time Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series anomaly detection (TSAD) focuses on identifying whether\nobservations in streaming data deviate significantly from normal patterns. With\nthe prevalence of connected devices, anomaly detection on time series has\nbecome paramount, as it enables real-time monitoring and early detection of\nirregular behaviors across various application domains. In this work, we\nintroduce PatchTrAD, a Patch-based Transformer model for time series anomaly\ndetection. Our approach leverages a Transformer encoder along with the use of\npatches under a reconstructionbased framework for anomaly detection. Empirical\nevaluations on multiple benchmark datasets show that PatchTrAD is on par, in\nterms of detection performance, with state-of-the-art deep learning models for\nanomaly detection while being time efficient during inference.", "AI": {"tldr": "PatchTrAD is a Transformer-based model for time series anomaly detection, using patches and reconstruction, achieving competitive performance with efficient inference.", "motivation": "The rise of connected devices necessitates real-time anomaly detection in streaming data for early irregularity detection.", "method": "PatchTrAD employs a Transformer encoder and patches within a reconstruction-based framework for anomaly detection.", "result": "The model performs comparably to state-of-the-art deep learning models in detection while being time-efficient.", "conclusion": "PatchTrAD is effective and efficient for time series anomaly detection, suitable for real-world applications."}}
{"id": "2502.07783", "pdf": "https://arxiv.org/pdf/2502.07783", "abs": "https://arxiv.org/abs/2502.07783", "authors": ["Leyang Hu", "Matteo Gamba", "Randall Balestriero"], "title": "Curvature Tuning: Provable Training-free Model Steering From a Single Parameter", "categories": ["cs.LG"], "comment": null, "summary": "The scaling of model and data sizes has reshaped the AI landscape,\nestablishing finetuning pretrained models as the standard paradigm for solving\ndownstream tasks. However, dominant finetuning methods typically rely on weight\nadaptation, often lack interpretability, and depend on heuristically chosen\nhyperparameters. In this paper, we take a different perspective and shift the\nfocus from weights to activation functions, viewing them through the lens of\nspline operators. We propose Curvature Tuning (CT), an interpretable and\nprincipled steering method that modulates a model's decision boundary by\ninjecting a single hyperparameter into its activation functions. We show that\nCT provably adjusts model decision boundary curvature and, more fundamentally,\nprojects a model onto a space of smooth functions-thereby complementing current\nfinetuning methods, whose effect lies primarily in feature adaptation. Making\nthis hyperparameter trainable gives rise to a novel and highly\nparameter-efficient finetuning method. Empirically, CT improves both\ngeneralization and robustness. For example, it boosts downstream accuracy of\nResNet-50/152 by 7.14%/8.46% over linear probing and 4.64%/1.70% over LoRA\nacross 12 datasets, and improves robust accuracy on the $\\ell_\\infty$ benchmark\nfrom RobustBench by 1032.64%/1494.46%. Our code is available at\nhttps://github.com/Leon-Leyang/curvature-tuning.", "AI": {"tldr": "The paper introduces Curvature Tuning (CT), a method to improve finetuning by adjusting activation functions with a hyperparameter, enhancing interpretability, generalization, and robustness.", "motivation": "Current finetuning methods lack interpretability and rely on heuristic hyperparameters. The paper aims to shift focus from weights to activation functions for better control and performance.", "method": "Proposes CT, which modulates decision boundaries by injecting a hyperparameter into activation functions, projecting models onto smooth function spaces. The hyperparameter is made trainable for efficiency.", "result": "CT improves ResNet-50/152 accuracy by 7.14%/8.46% over linear probing and 4.64%/1.70% over LoRA across 12 datasets, and boosts robust accuracy by 1032.64%/1494.46%.", "conclusion": "CT offers an interpretable, efficient, and effective alternative to traditional finetuning, enhancing both generalization and robustness."}}
{"id": "2506.03834", "pdf": "https://arxiv.org/pdf/2506.03834", "abs": "https://arxiv.org/abs/2506.03834", "authors": ["Joonkyung Kim", "Joonyeol Sim", "Woojun Kim", "Katia Sycara", "Changjoo Nam"], "title": "Enhancing Safety of Foundation Models for Visual Navigation through Collision Avoidance via Repulsive Estimation", "categories": ["cs.RO", "cs.CV"], "comment": "16 pages, 6 figures", "summary": "We propose CARE (Collision Avoidance via Repulsive Estimation), a\nplug-and-play module that enhances the safety of vision-based navigation\nwithout requiring additional range sensors or fine-tuning of pretrained models.\nWhile recent foundation models using only RGB inputs have shown strong\nperformance, they often fail to generalize in out-of-distribution (OOD)\nenvironments with unseen objects or variations in camera parameters (e.g.,\nfield of view, pose, or focal length). Without fine-tuning, these models may\ngenerate unsafe trajectories that lead to collisions, requiring costly data\ncollection and retraining. CARE addresses this limitation by seamlessly\nintegrating with any RGB-based navigation system that outputs local\ntrajectories, dynamically adjusting them using repulsive force vectors derived\nfrom monocular depth maps. We evaluate CARE by combining it with\nstate-of-the-art vision-based navigation models across multiple robot\nplatforms. CARE consistently reduces collision rates (up to 100%) without\nsacrificing goal-reaching performance and improves collision-free travel\ndistance by up to 10.7x in exploration tasks.", "AI": {"tldr": "CARE enhances vision-based navigation safety by dynamically adjusting trajectories using repulsive forces from monocular depth maps, without extra sensors or model fine-tuning.", "motivation": "Foundation models using RGB inputs often fail in OOD environments, leading to unsafe trajectories and collisions, which CARE aims to mitigate.", "method": "CARE integrates with RGB-based navigation systems, using repulsive force vectors from monocular depth maps to adjust trajectories dynamically.", "result": "CARE reduces collision rates (up to 100%) and improves collision-free travel distance (up to 10.7x) without compromising goal-reaching performance.", "conclusion": "CARE is an effective plug-and-play module for enhancing safety in vision-based navigation across diverse environments and robot platforms."}}
{"id": "2504.08970", "pdf": "https://arxiv.org/pdf/2504.08970", "abs": "https://arxiv.org/abs/2504.08970", "authors": ["Nasim Shirvani-Mahdavi", "Farahnaz Akrami", "Chengkai Li"], "title": "On Large-scale Evaluation of Embedding Models for Knowledge Graph Completion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Knowledge graph embedding (KGE) models are extensively studied for knowledge\ngraph completion, yet their evaluation remains constrained by unrealistic\nbenchmarks. Standard evaluation metrics rely on the closed-world assumption,\nwhich penalizes models for correctly predicting missing triples, contradicting\nthe fundamental goals of link prediction. These metrics often compress accuracy\nassessment into a single value, obscuring models' specific strengths and\nweaknesses. The prevailing evaluation protocol, link prediction, operates under\nthe unrealistic assumption that an entity's properties, for which values are to\nbe predicted, are known in advance. While alternative protocols such as\nproperty prediction, entity-pair ranking, and triple classification address\nsome of these limitations, they remain underutilized. Moreover, commonly used\ndatasets are either faulty or too small to reflect real-world data. Few studies\nexamine the role of mediator nodes, which are essential for modeling n-ary\nrelationships, or investigate model performance variation across domains. This\npaper conducts a comprehensive evaluation of four representative KGE models on\nlarge-scale datasets FB-CVT-REV and FB+CVT-REV. Our analysis reveals critical\ninsights, including substantial performance variations between small and large\ndatasets, both in relative rankings and absolute metrics, systematic\noverestimation of model capabilities when n-ary relations are binarized, and\nfundamental limitations in current evaluation protocols and metrics.", "AI": {"tldr": "The paper critiques current KGE evaluation methods for their unrealistic benchmarks and proposes a comprehensive evaluation of four KGE models on large-scale datasets, revealing significant flaws in existing protocols.", "motivation": "Current KGE evaluation metrics and protocols are flawed, relying on unrealistic assumptions and small datasets, which misrepresent model performance and obscure strengths and weaknesses.", "method": "The study evaluates four representative KGE models on large-scale datasets (FB-CVT-REV and FB+CVT-REV) to analyze performance variations and limitations of current evaluation methods.", "result": "Findings show performance disparities between small and large datasets, overestimation of model capabilities when n-ary relations are simplified, and fundamental flaws in evaluation metrics.", "conclusion": "The paper highlights the need for improved evaluation protocols and metrics in KGE research to better reflect real-world scenarios and model capabilities."}}
{"id": "2502.09198", "pdf": "https://arxiv.org/pdf/2502.09198", "abs": "https://arxiv.org/abs/2502.09198", "authors": ["Leonard Papenmeier", "Matthias Poloczek", "Luigi Nardi"], "title": "Understanding High-Dimensional Bayesian Optimization", "categories": ["cs.LG"], "comment": "22 pages, 21 figures. Accepted to ICML 2025", "summary": "Recent work reported that simple Bayesian optimization (BO) methods perform\nwell for high-dimensional real-world tasks, seemingly contradicting prior work\nand tribal knowledge. This paper investigates why. We identify underlying\nchallenges that arise in high-dimensional BO and explain why recent methods\nsucceed. Our empirical analysis shows that vanishing gradients caused by\nGaussian process (GP) initialization schemes play a major role in the failures\nof high-dimensional Bayesian optimization (HDBO) and that methods that promote\nlocal search behaviors are better suited for the task. We find that maximum\nlikelihood estimation (MLE) of GP length scales suffices for state-of-the-art\nperformance. Based on this, we propose a simple variant of MLE called MSR that\nleverages these findings to achieve state-of-the-art performance on a\ncomprehensive set of real-world applications. We present targeted experiments\nto illustrate and confirm our findings.", "AI": {"tldr": "Simple Bayesian optimization (BO) works well in high dimensions due to local search behaviors and proper GP initialization, with MLE-based methods like MSR achieving state-of-the-art performance.", "motivation": "To understand why simple BO methods succeed in high-dimensional tasks despite prior beliefs and identify key challenges in high-dimensional BO.", "method": "Analyze GP initialization's role in HDBO failures, propose MLE-based MSR for better performance, and validate findings with experiments.", "result": "Vanishing gradients from GP initialization hinder HDBO; local search and MLE-based methods like MSR excel.", "conclusion": "Proper initialization and local search behaviors are crucial for HDBO, with MSR outperforming existing methods."}}
{"id": "2506.05633", "pdf": "https://arxiv.org/pdf/2506.05633", "abs": "https://arxiv.org/abs/2506.05633", "authors": ["Guy Gaziv", "Sarah Goulding", "Ani Ayvazian-Hancock", "Yoon Bai", "James J. DiCarlo"], "title": "Noninvasive precision modulation of high-level neural population activity via natural vision perturbations", "categories": ["q-bio.NC", "cs.CV", "cs.NE"], "comment": null, "summary": "Precise control of neural activity -- modulating target neurons deep in the\nbrain while leaving nearby neurons unaffected -- is an outstanding challenge in\nneuroscience, generally approached using invasive techniques. This study\ninvestigates the possibility of precisely and noninvasively modulating neural\nactivity in the high-level primate ventral visual stream via perturbations on\none's natural visual feed. When tested on macaque inferior temporal (IT) neural\npopulations, we found quantitative agreement between the model-predicted and\nbiologically realized effect: strong modulation concentrated on targeted neural\nsites. We extended this to demonstrate accurate injection of\nexperimenter-chosen neural population patterns via subtle perturbations applied\non the background of typical natural visual feeds. These results highlight that\ncurrent machine-executable models of the ventral stream can now design\nnoninvasive, visually-delivered, possibly imperceptible neural interventions at\nthe resolution of individual neurons.", "AI": {"tldr": "The study explores noninvasive neural modulation in primates using visual perturbations, achieving precise control at single-neuron resolution.", "motivation": "To address the challenge of precise, noninvasive neural control without affecting nearby neurons, avoiding invasive techniques.", "method": "Perturbations on natural visual feed were tested on macaque inferior temporal (IT) neural populations, comparing model predictions to biological effects.", "result": "Strong modulation was achieved at targeted neural sites, with accurate injection of experimenter-chosen neural patterns via subtle visual perturbations.", "conclusion": "Machine-executable models can now design noninvasive, visually-delivered neural interventions at single-neuron resolution."}}
{"id": "2504.12397", "pdf": "https://arxiv.org/pdf/2504.12397", "abs": "https://arxiv.org/abs/2504.12397", "authors": ["Kristjan Greenewald", "Luis Lastras", "Thomas Parnell", "Vraj Shah", "Lucian Popa", "Giulio Zizzo", "Chulaka Gunasekara", "Ambrish Rawat", "David Cox"], "title": "Activated LoRA: Fine-tuned LLMs for Intrinsics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) has emerged as a highly efficient framework for\nfinetuning the weights of large foundation models, and has become the go-to\nmethod for data-driven customization of LLMs. Despite the promise of highly\ncustomized behaviors and capabilities, switching between relevant LoRAs in a\nmultiturn setting is inefficient, as the key-value (KV) cache of the entire\nturn history must be recomputed with the LoRA weights before generation can\nbegin. To address this problem, we propose Activated LoRA (aLoRA), an adapter\narchitecture which modifies the LoRA framework to only adapt weights for the\ntokens in the sequence \\emph{after} the aLoRA is invoked. This change crucially\nallows aLoRA to accept the base model's KV cache of the input string, meaning\nthat aLoRA can be instantly activated whenever needed in a chain without\nrecomputing the cache. This enables building what we call \\emph{intrinsics},\ni.e. specialized models invoked to perform well-defined operations on portions\nof an input chain or conversation that otherwise uses the base model by\ndefault. We train a set of aLoRA-based intrinsics models, demonstrating\ncompetitive accuracy with standard LoRA while achieving significant inference\nbenefits. The codebase is at https://github.com/IBM/activated-lora.", "AI": {"tldr": "aLoRA improves LoRA by allowing instant activation without recomputing KV cache, enabling efficient multiturn customization.", "motivation": "Switching between LoRAs in multiturn settings is inefficient due to KV cache recomputation.", "method": "aLoRA adapts weights only for tokens after invocation, accepting the base model's KV cache.", "result": "Competitive accuracy with standard LoRA and significant inference benefits.", "conclusion": "aLoRA enables efficient, specialized model invocation in multiturn settings."}}
{"id": "2502.11420", "pdf": "https://arxiv.org/pdf/2502.11420", "abs": "https://arxiv.org/abs/2502.11420", "authors": ["Yingqing Guo", "Yukang Yang", "Hui Yuan", "Mengdi Wang"], "title": "Training-Free Guidance Beyond Differentiability: Scalable Path Steering with Tree Search in Diffusion and Flow Models", "categories": ["cs.LG"], "comment": null, "summary": "Training-free guidance enables controlled generation in diffusion and flow\nmodels, but most methods rely on gradients and assume differentiable\nobjectives. This work focuses on training-free guidance addressing challenges\nfrom non-differentiable objectives and discrete data distributions. We propose\nTreeG: Tree Search-Based Path Steering Guidance, applicable to both continuous\nand discrete settings in diffusion and flow models. TreeG offers a unified\nframework for training-free guidance by proposing, evaluating, and selecting\ncandidates at each step, enhanced with tree search over active paths and\nparallel exploration. We comprehensively investigate the design space of TreeG\nover the candidate proposal module and the evaluation function, instantiating\nTreeG into three novel algorithms. Our experiments show that TreeG consistently\noutperforms top guidance baselines in symbolic music generation, small molecule\ndesign, and enhancer DNA design with improvements of 29.01%, 16.6%, and 18.43%.\nAdditionally, we identify an inference-time scaling law showing TreeG's\nscalability in inference-time computation.", "AI": {"tldr": "TreeG is a training-free guidance method for diffusion and flow models, handling non-differentiable objectives and discrete data. It uses tree search and parallel exploration, outperforming baselines in symbolic music, molecule, and DNA design.", "motivation": "Address challenges of non-differentiable objectives and discrete data in training-free guidance for controlled generation.", "method": "Proposes TreeG, a tree search-based path steering guidance framework, with candidate proposal, evaluation, and selection, enhanced by parallel exploration.", "result": "TreeG outperforms baselines by 29.01%, 16.6%, and 18.43% in symbolic music, molecule, and DNA design, with scalable inference-time computation.", "conclusion": "TreeG provides a unified, effective framework for training-free guidance in diverse applications, demonstrating superior performance and scalability."}}
{"id": "2504.17346", "pdf": "https://arxiv.org/pdf/2504.17346", "abs": "https://arxiv.org/abs/2504.17346", "authors": ["Tran Thuy Nga Truong", "Jooyong Kim"], "title": "Dual-Individual Genetic Algorithm: A Dual-Individual Approach for Efficient Training of Multi-Layer Neural Networks", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "This paper introduces an enhanced Genetic Algorithm technique, which\noptimizes neural networks for binary image classification tasks, such as cat\nvs. non-cat classification. The proposed method employs only two individuals\nfor crossover, represented by two parameter sets: Leader and Follower. The\nLeader focuses on exploitation, representing the primary optimal solution,\nwhile the Follower promotes exploration by preserving diversity and avoiding\npremature convergence. Leader and Follower are modeled as two phases or roles.\nThe key contributions of this work are threefold: (1) a self-adaptive layer\ndimension mechanism that eliminates the need for manual tuning of layer\narchitectures; (2) generates two parameter sets, leader and follower parameter\nsets, with 10 layer architecture configurations (5 for each set), ranked by\nPareto dominance and cost post-optimization; and (3) achieved better results\ncompared to gradient-based methods. Experimental results show that the proposed\nmethod achieves 99.04% training accuracy and 80% testing accuracy (cost = 0.06)\non a three-layer network with architecture [12288, 17, 4, 1], higher\nperformance a gradient-based approach that achieves 98% training accuracy and\n80% testing accuracy (cost = 0.092) on a four-layer network with architecture\n[12288, 20, 7, 5, 1].", "AI": {"tldr": "An enhanced Genetic Algorithm optimizes neural networks for binary image classification, using Leader and Follower roles for exploitation and exploration, achieving better accuracy than gradient-based methods.", "motivation": "To improve neural network optimization for binary classification tasks by balancing exploitation and exploration, avoiding premature convergence, and eliminating manual tuning of layer architectures.", "method": "Uses a Genetic Algorithm with two individuals (Leader and Follower) for crossover, self-adaptive layer dimensions, and generates two parameter sets ranked by Pareto dominance and cost.", "result": "Achieves 99.04% training and 80% testing accuracy, outperforming a gradient-based method (98% training, 80% testing).", "conclusion": "The proposed method is effective for binary classification, offering automation, diversity preservation, and superior performance over traditional approaches."}}
{"id": "2502.11672", "pdf": "https://arxiv.org/pdf/2502.11672", "abs": "https://arxiv.org/abs/2502.11672", "authors": ["Andrey Kofnov", "Daniel Kapla", "Ezio Bartocci", "Efstathia Bura"], "title": "Exact Upper and Lower Bounds for the Output Distribution of Neural Networks with Random Inputs", "categories": ["cs.LG", "stat.ME", "stat.ML", "62E15 (Primary) 46N30, 62H10 (Secondary)", "G.3; I.5.1"], "comment": "Forthcoming at the 42nd International Conference on Machine Learning\n  (ICML 2025); 9+16 pages", "summary": "We derive exact upper and lower bounds for the cumulative distribution\nfunction (cdf) of the output of a neural network (NN) over its entire support\nsubject to noisy (stochastic) inputs. The upper and lower bounds converge to\nthe true cdf over its domain as the resolution increases. Our method applies to\nany feedforward NN using continuous monotonic piecewise twice continuously\ndifferentiable activation functions (e.g., ReLU, tanh and softmax) and\nconvolutional NNs, which were beyond the scope of competing approaches. The\nnovelty and instrumental tool of our approach is to bound general NNs with ReLU\nNNs. The ReLU NN-based bounds are then used to derive the upper and lower\nbounds of the cdf of the NN output. Experiments demonstrate that our method\ndelivers guaranteed bounds of the predictive output distribution over its\nsupport, thus providing exact error guarantees, in contrast to competing\napproaches.", "AI": {"tldr": "The paper derives exact bounds for the cdf of a neural network's output under noisy inputs, applicable to various NN architectures, and outperforms competing methods by providing guaranteed error bounds.", "motivation": "To provide exact upper and lower bounds for the cdf of NN outputs under stochastic inputs, addressing limitations of existing approaches.", "method": "Bounds general NNs using ReLU NNs, then derives cdf bounds for the NN output. Applies to feedforward and convolutional NNs with specific activation functions.", "result": "The method delivers guaranteed bounds for predictive output distributions, offering exact error guarantees.", "conclusion": "The approach outperforms competing methods by providing precise bounds for NN output distributions under noisy inputs."}}
{"id": "2504.19373", "pdf": "https://arxiv.org/pdf/2504.19373", "abs": "https://arxiv.org/abs/2504.19373", "authors": ["Weidi Luo", "Tianyu Lu", "Qiming Zhang", "Xiaogeng Liu", "Bin Hu", "Yue Zhao", "Jieyu Zhao", "Song Gao", "Patrick McDaniel", "Zhen Xiang", "Chaowei Xiao"], "title": "Doxing via the Lens: Revealing Location-related Privacy Leakage on Multi-modal Large Reasoning Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Recent advances in multi-modal large reasoning models (MLRMs) have shown\nsignificant ability to interpret complex visual content. While these models\nenable impressive reasoning capabilities, they also introduce novel and\nunderexplored privacy risks. In this paper, we identify a novel category of\nprivacy leakage in MLRMs: Adversaries can infer sensitive geolocation\ninformation, such as a user's home address or neighborhood, from user-generated\nimages, including selfies captured in private settings. To formalize and\nevaluate these risks, we propose a three-level visual privacy risk framework\nthat categorizes image content based on contextual sensitivity and potential\nfor location inference. We further introduce DoxBench, a curated dataset of 500\nreal-world images reflecting diverse privacy scenarios. Our evaluation across\n11 advanced MLRMs and MLLMs demonstrates that these models consistently\noutperform non-expert humans in geolocation inference and can effectively leak\nlocation-related private information. This significantly lowers the barrier for\nadversaries to obtain users' sensitive geolocation information. We further\nanalyze and identify two primary factors contributing to this vulnerability:\n(1) MLRMs exhibit strong reasoning capabilities by leveraging visual clues in\ncombination with their internal world knowledge; and (2) MLRMs frequently rely\non privacy-related visual clues for inference without any built-in mechanisms\nto suppress or avoid such usage. To better understand and demonstrate\nreal-world attack feasibility, we propose GeoMiner, a collaborative attack\nframework that decomposes the prediction process into two stages: clue\nextraction and reasoning to improve geolocation performance while introducing a\nnovel attack perspective. Our findings highlight the urgent need to reassess\ninference-time privacy risks in MLRMs to better protect users' sensitive\ninformation.", "AI": {"tldr": "The paper identifies privacy risks in multi-modal large reasoning models (MLRMs) where adversaries can infer sensitive geolocation data from user images. It proposes a framework, DoxBench dataset, and GeoMiner attack to evaluate and exploit these risks, showing MLRMs outperform humans in location inference.", "motivation": "To uncover and formalize underexplored privacy risks in MLRMs, particularly geolocation leakage from user-generated images like selfies.", "method": "Proposes a three-level visual privacy risk framework, introduces DoxBench dataset, and evaluates 11 MLRMs. Also develops GeoMiner, a two-stage attack framework for geolocation inference.", "result": "MLRMs consistently outperform humans in geolocation inference, lowering the barrier for adversaries to access sensitive information. Two key vulnerabilities are identified: strong reasoning capabilities and reliance on privacy-related visual clues.", "conclusion": "The study underscores the need to reassess inference-time privacy risks in MLRMs and develop mechanisms to protect users' sensitive geolocation data."}}
{"id": "2502.15843", "pdf": "https://arxiv.org/pdf/2502.15843", "abs": "https://arxiv.org/abs/2502.15843", "authors": ["Kalyan Ramakrishnan", "Lars L. Schaaf", "Chen Lin", "Guangrun Wang", "Philip Torr"], "title": "Implicit Neural Representations for Chemical Reaction Paths", "categories": ["cs.LG", "physics.chem-ph"], "comment": "Under review at the Journal of Chemical Physics", "summary": "We show that neural networks can be optimized to represent minimum energy\npaths as continuous functions, offering a flexible alternative to discrete\npath-search methods like Nudged Elastic Band (NEB). Our approach parameterizes\nreaction paths with a network trained on a loss function that discards\ntangential energy gradients and enables instant estimation of the transition\nstate. We first validate the method on two-dimensional potentials and then\ndemonstrate its advantages over NEB on challenging atomistic systems where (i)\npoor initial guesses yield unphysical paths, (ii) multiple competing paths\nexist, or (iii) the reaction follows a complex multi-step mechanism. Results\nhighlight the versatility of the method: for instance, a simple adjustment to\nthe sampling strategy during optimization can help escape local-minimum\nsolutions. Finally, in a low-dimensional setting, we demonstrate that a single\nneural network can learn from existing paths and generalize to unseen systems,\nshowing promise for a universal reaction path representation.", "AI": {"tldr": "Neural networks optimize minimum energy paths, outperforming NEB in flexibility and accuracy for complex systems.", "motivation": "To provide a flexible and efficient alternative to discrete path-search methods like NEB for representing reaction paths.", "method": "Parameterizes reaction paths using a neural network trained on a loss function that ignores tangential energy gradients, enabling instant transition state estimation.", "result": "Validated on 2D potentials and outperformed NEB in challenging atomistic systems, handling poor initial guesses, multiple paths, and complex mechanisms.", "conclusion": "The method is versatile, generalizes to unseen systems, and shows promise for universal reaction path representation."}}
{"id": "2505.00793", "pdf": "https://arxiv.org/pdf/2505.00793", "abs": "https://arxiv.org/abs/2505.00793", "authors": ["Iurii Kemaev", "Dan A Calian", "Luisa M Zintgraf", "Gregory Farquhar", "Hado van Hasselt"], "title": "Scalable Meta-Learning via Mixed-Mode Differentiation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Gradient-based bilevel optimisation is a powerful technique with applications\nin hyperparameter optimisation, task adaptation, algorithm discovery,\nmeta-learning more broadly, and beyond. It often requires differentiating\nthrough the gradient-based optimisation itself, leading to\n\"gradient-of-a-gradient\" calculations with computationally expensive\nsecond-order and mixed derivatives. While modern automatic differentiation\nlibraries provide a convenient way to write programs for calculating these\nderivatives, they oftentimes cannot fully exploit the specific structure of\nthese problems out-of-the-box, leading to suboptimal performance. In this\npaper, we analyse such cases and propose Mixed-Flow Meta-Gradients, or\nMixFlow-MG -- a practical algorithm that uses mixed-mode differentiation to\nconstruct more efficient and scalable computational graphs yielding over 10x\nmemory and up to 25% wall-clock time improvements over standard implementations\nin modern meta-learning setups.", "AI": {"tldr": "MixFlow-MG improves efficiency in gradient-based bilevel optimization by using mixed-mode differentiation, achieving significant memory and time savings.", "motivation": "Gradient-based bilevel optimization is widely used but computationally expensive due to second-order and mixed derivatives. Existing methods often fail to exploit problem structure, leading to inefficiency.", "method": "Proposes Mixed-Flow Meta-Gradients (MixFlow-MG), a mixed-mode differentiation algorithm to optimize computational graphs.", "result": "Achieves over 10x memory savings and up to 25% faster wall-clock time compared to standard implementations.", "conclusion": "MixFlow-MG offers a scalable and efficient solution for gradient-based bilevel optimization, enhancing performance in meta-learning and related tasks."}}
{"id": "2502.20293", "pdf": "https://arxiv.org/pdf/2502.20293", "abs": "https://arxiv.org/abs/2502.20293", "authors": ["Zahiriddin Rustamov", "Ayham Zaitouny", "Nazar Zaki"], "title": "Scalable Graph Attention-based Instance Selection via Mini-Batch Sampling and Hierarchical Hashing", "categories": ["cs.LG"], "comment": null, "summary": "Instance selection (IS) addresses the critical challenge of reducing dataset\nsize while keeping informative characteristics, becoming increasingly important\nas datasets grow to millions of instances. Current IS methods often struggle\nwith capturing complex relationships in high-dimensional spaces and scale with\nlarge datasets. This paper introduces a graph attention-based instance\nselection (GAIS) method that uses attention mechanisms to identify informative\ninstances through their structural relationships in graph representations. We\npresent two approaches for scalable graph construction: a distance-based\nmini-batch sampling technique that achieves dataset-size-independent complexity\nthrough strategic batch processing, and a hierarchical hashing approach that\nenables efficient similarity computation through random projections. The\nmini-batch approach keeps class distributions through stratified sampling,\nwhile the hierarchical hashing method captures relationships at multiple\ngranularities through single-level, multi-level, and multi-view variants.\nExperiments across 39 datasets show that GAIS achieves reduction rates above\n96\\% while maintaining or improving model performance relative to\nstate-of-the-art IS methods. The findings show that the distance-based\nmini-batch approach offers an optimal efficiency for large-scale datasets,\nwhile multi-view variants excel on complex, high-dimensional data,\ndemonstrating that attention-based importance scoring can effectively identify\ninstances important for maintaining decision boundaries while avoiding\ncomputationally prohibitive pairwise comparisons.", "AI": {"tldr": "GAIS introduces a graph attention-based method for instance selection, using scalable graph construction techniques to handle large datasets efficiently. It achieves high reduction rates while maintaining model performance.", "motivation": "As datasets grow, current instance selection methods struggle with scalability and capturing complex relationships in high-dimensional spaces.", "method": "GAIS employs attention mechanisms to identify informative instances via graph representations. It uses distance-based mini-batch sampling and hierarchical hashing for scalable graph construction.", "result": "Experiments on 39 datasets show GAIS achieves >96% reduction rates while maintaining or improving model performance.", "conclusion": "GAIS demonstrates that attention-based scoring effectively identifies important instances, with mini-batch methods excelling in scalability and multi-view variants in handling complex data."}}
{"id": "2505.03802", "pdf": "https://arxiv.org/pdf/2505.03802", "abs": "https://arxiv.org/abs/2505.03802", "authors": ["Changhai Zhou", "Shijie Han", "Shiyang Zhang", "Yuhua Zhou", "Weizhong Zhang", "Cheng Jin"], "title": "Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 5 figures", "summary": "QLoRA effectively combines low-bit quantization and LoRA to achieve\nmemory-friendly fine-tuning for large language models (LLM). Recently, methods\nbased on SVD for continuous update iterations to initialize LoRA matrices to\naccommodate quantization errors have generally failed to consistently improve\nperformance. Dynamic mixed precision is a natural idea for continuously\nimproving the fine-tuning performance of quantized models, but previous methods\noften optimize low-rank subspaces or quantization components separately,\nwithout considering their synergy. To address this, we propose\n\\textbf{QR-Adaptor}, a unified, gradient-free strategy that uses partial\ncalibration data to jointly search the quantization components and the rank of\nlow-rank spaces for each layer, thereby continuously improving model\nperformance. QR-Adaptor does not minimize quantization error but treats\nprecision and rank allocation as a discrete optimization problem guided by\nactual downstream performance and memory usage. Compared to state-of-the-art\n(SOTA) quantized LoRA fine-tuning methods, our approach achieves a 4.89\\%\naccuracy improvement on GSM8K, and in some cases even outperforms the 16-bit\nfine-tuned model while maintaining the memory footprint of the 4-bit setting.", "AI": {"tldr": "QLoRA combines low-bit quantization and LoRA for memory-efficient LLM fine-tuning. QR-Adaptor jointly optimizes quantization and low-rank subspaces, improving performance without minimizing quantization error.", "motivation": "Existing methods fail to consistently improve performance by separately optimizing low-rank subspaces or quantization components, ignoring their synergy.", "method": "Proposes QR-Adaptor, a gradient-free strategy using partial calibration data to jointly search quantization components and low-rank subspaces.", "result": "Achieves 4.89% accuracy improvement on GSM8K, sometimes outperforming 16-bit models while maintaining 4-bit memory usage.", "conclusion": "QR-Adaptor effectively balances performance and memory efficiency, outperforming SOTA methods."}}
{"id": "2503.01718", "pdf": "https://arxiv.org/pdf/2503.01718", "abs": "https://arxiv.org/abs/2503.01718", "authors": ["Kevin Burrage", "Pamela M. Burrage", "Justin N. Kreikemeyer", "Adelinde M. Uhrmacher", "Hasitha N. Weerasinghe"], "title": "Learning surrogate equations for the analysis of an agent-based cancer model", "categories": ["cs.LG", "q-bio.QM"], "comment": "13 pages, 7 figures; This version is identical to the one published\n  at Frontiers", "summary": "In this paper, we adapt a two-species agent-based cancer model that describes\nthe interaction between cancer cells and healthy cells on a uniform grid to\ninclude the interaction with a third species -- namely immune cells. We run six\ndifferent scenarios to explore the competition between cancer and immune cells\nand the initial concentration of the immune cells on cancer dynamics. We then\nuse coupled equation learning to construct a population-based reaction model\nfor each scenario. We show how they can be unified into a single surrogate\npopulation-based reaction model, whose underlying three coupled ordinary\ndifferential equations are much easier to analyse than the original agent-based\nmodel. As an example, by finding the single steady state of the cancer\nconcentration, we are able to find a linear relationship between this\nconcentration and the initial concentration of the immune cells. This then\nenables us to estimate suitable values for the competition and initial\nconcentration to reduce the cancer substantially without performing additional\ncomplex and expensive simulations from an agent-based stochastic model.", "AI": {"tldr": "The paper extends a two-species cancer model to include immune cells, explores six scenarios, and derives a unified surrogate model for easier analysis.", "motivation": "To simplify the analysis of cancer-immune cell interactions and reduce computational costs of agent-based models.", "method": "Adapts an agent-based model to include immune cells, runs six scenarios, and uses coupled equation learning to create a population-based reaction model.", "result": "Derives a unified surrogate model with three ODEs, enabling easier analysis and prediction of cancer dynamics.", "conclusion": "The surrogate model provides a computationally efficient way to estimate cancer reduction without complex simulations."}}
{"id": "2505.12366", "pdf": "https://arxiv.org/pdf/2505.12366", "abs": "https://arxiv.org/abs/2505.12366", "authors": ["Gang Li", "Ming Lin", "Tomer Galanti", "Zhengzhong Tu", "Tianbao Yang"], "title": "DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages, 4 figures", "summary": "The recent success and openness of DeepSeek-R1 have brought widespread\nattention to Group Relative Policy Optimization (GRPO) as a reinforcement\nlearning method for large reasoning models (LRMs). In this work, we analyze the\nGRPO objective under a binary reward setting and reveal an inherent limitation\nof question-level difficulty bias. We also identify a connection between GRPO\nand traditional discriminative methods in supervised learning. Motivated by\nthese insights, we introduce a new Discriminative Constrained Optimization\n(DisCO) framework for reinforcing LRMs, grounded in the principle of\ndiscriminative learning. The main differences between DisCO and GRPO and its\nrecent variants are: (1) it replaces the group relative objective with a\ndiscriminative objective defined by a scoring function; (2) it abandons\nclipping-based surrogates in favor of non-clipping RL surrogate objectives used\nas scoring functions; (3) it employs a simple yet effective constrained\noptimization approach to enforce the KL divergence constraint, ensuring stable\ntraining. As a result, DisCO offers notable advantages over GRPO and its\nvariants: (i) it completely eliminates difficulty bias by adopting\ndiscriminative objectives; (ii) it addresses the entropy instability in GRPO\nand its variants through the use of non-clipping scoring functions and a\nconstrained optimization approach; (iii) it allows the incorporation of\nadvanced discriminative learning techniques to address data imbalance, where a\nsignificant number of questions have more negative than positive generated\nanswers during training. Our experiments on enhancing the mathematical\nreasoning capabilities of SFT-finetuned models show that DisCO significantly\noutperforms GRPO and its improved variants such as DAPO, achieving average\ngains of 7\\% over GRPO and 6\\% over DAPO across six benchmark tasks for an 1.5B\nmodel.", "AI": {"tldr": "DisCO, a new Discriminative Constrained Optimization framework, outperforms GRPO and its variants by eliminating difficulty bias and improving stability in training large reasoning models.", "motivation": "The limitations of GRPO, such as question-level difficulty bias and entropy instability, motivated the development of DisCO.", "method": "DisCO replaces GRPO's group relative objective with a discriminative objective, uses non-clipping RL surrogate objectives, and employs constrained optimization for KL divergence.", "result": "DisCO achieves average gains of 7% over GRPO and 6% over DAPO on six benchmark tasks for a 1.5B model.", "conclusion": "DisCO offers a more stable and effective approach for reinforcing large reasoning models, addressing key limitations of GRPO."}}
{"id": "2503.06009", "pdf": "https://arxiv.org/pdf/2503.06009", "abs": "https://arxiv.org/abs/2503.06009", "authors": ["Meng Ding", "Mingxi Lei", "Shaowei Wang", "Tianhang Zheng", "Di Wang", "Jinhui Xu"], "title": "Nearly Optimal Differentially Private ReLU Regression", "categories": ["cs.LG", "stat.ML"], "comment": "47 pages (UAI2025)", "summary": "In this paper, we investigate one of the most fundamental nonconvex learning\nproblems, ReLU regression, in the Differential Privacy (DP) model. Previous\nstudies on private ReLU regression heavily rely on stringent assumptions, such\nas constant bounded norms for feature vectors and labels. We relax these\nassumptions to a more standard setting, where data can be i.i.d. sampled from\n$O(1)$-sub-Gaussian distributions. We first show that when $\\varepsilon =\n\\tilde{O}(\\sqrt{\\frac{1}{N}})$ and there is some public data, it is possible to\nachieve an upper bound of $\\tilde{O}(\\frac{d^2}{N^2 \\varepsilon^2})$ for the\nexcess population risk in $(\\epsilon, \\delta)$-DP, where $d$ is the dimension\nand $N$ is the number of data samples. Moreover, we relax the requirement of\n$\\epsilon$ and public data by proposing and analyzing a one-pass mini-batch\nGeneralized Linear Model Perceptron algorithm (DP-MBGLMtron). Additionally,\nusing the tracing attack argument technique, we demonstrate that the minimax\nrate of the estimation error for $(\\varepsilon, \\delta)$-DP algorithms is lower\nbounded by $\\Omega(\\frac{d^2}{N^2 \\varepsilon^2})$. This shows that\nDP-MBGLMtron achieves the optimal utility bound up to logarithmic factors.\nExperiments further support our theoretical results.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2503.08002", "pdf": "https://arxiv.org/pdf/2503.08002", "abs": "https://arxiv.org/abs/2503.08002", "authors": ["Meghna Roy Chowdhury", "Wei Xuan", "Shreyas Sen", "Yixue Zhao", "Yi Ding"], "title": "Predicting and Understanding College Student Mental Health with Interpretable Machine Learning", "categories": ["cs.LG", "cs.CY"], "comment": "12 pages, 10 figures, ACM/IEEE International Conference on Connected\n  Health: Applications, Systems and Engineering Technologies (CHASE '25), June\n  24--26, 2025, New York, NY, USA", "summary": "Mental health issues among college students have reached critical levels,\nsignificantly impacting academic performance and overall wellbeing. Predicting\nand understanding mental health status among college students is challenging\ndue to three main factors: the necessity for large-scale longitudinal datasets,\nthe prevalence of black-box machine learning models lacking transparency, and\nthe tendency of existing approaches to provide aggregated insights at the\npopulation level rather than individualized understanding.\n  To tackle these challenges, this paper presents I-HOPE, the first\nInterpretable Hierarchical mOdel for Personalized mEntal health prediction.\nI-HOPE is a two-stage hierarchical model that connects raw behavioral features\nto mental health status through five defined behavioral categories as\ninteraction labels. We evaluate I-HOPE on the College Experience Study, the\nlongest longitudinal mobile sensing dataset. This dataset spans five years and\ncaptures data from both pre-pandemic periods and the COVID-19 pandemic. I-HOPE\nachieves a prediction accuracy of 91%, significantly surpassing the 60-70%\naccuracy of baseline methods. In addition, I-HOPE distills complex patterns\ninto interpretable and individualized insights, enabling the future development\nof tailored interventions and improving mental health support. The code is\navailable at https://github.com/roycmeghna/I-HOPE.", "AI": {"tldr": "I-HOPE is an interpretable hierarchical model for personalized mental health prediction in college students, achieving 91% accuracy and outperforming baseline methods.", "motivation": "Addressing challenges like the need for large-scale longitudinal data, lack of transparency in models, and aggregated insights by providing individualized understanding.", "method": "A two-stage hierarchical model linking raw behavioral features to mental health status through five behavioral categories as interaction labels.", "result": "Achieves 91% prediction accuracy on a five-year longitudinal dataset, surpassing baseline methods (60-70%).", "conclusion": "I-HOPE offers interpretable, individualized insights for tailored mental health interventions, with potential to improve support."}}
{"id": "2505.24511", "pdf": "https://arxiv.org/pdf/2505.24511", "abs": "https://arxiv.org/abs/2505.24511", "authors": ["Jiahao Wang", "Mingyue Cheng", "Qi Liu"], "title": "Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting (TSF) is a fundamental and widely studied task,\nspanning methods from classical statistical approaches to modern deep learning\nand multimodal language modeling. Despite their effectiveness, these methods\noften follow a fast thinking paradigm emphasizing pattern extraction and direct\nvalue mapping, while overlooking explicit reasoning over temporal dynamics and\ncontextual dependencies. Meanwhile, emerging slow-thinking LLMs (e.g.,\nChatGPT-o1, DeepSeek-R1) have demonstrated impressive multi-step reasoning\ncapabilities across diverse domains, suggesting a new opportunity for reframing\nTSF as a structured reasoning task. This motivates a key question: can\nslow-thinking LLMs effectively reason over temporal patterns to support time\nseries forecasting, even in zero-shot manner? To investigate this, in this\npaper, we propose TimeReasoner, an extensive empirical study that formulates\nTSF as a conditional reasoning task. We design a series of prompting strategies\nto elicit inference-time reasoning from pretrained slow-thinking LLMs and\nevaluate their performance across diverse TSF benchmarks. Our findings reveal\nthat slow-thinking LLMs exhibit non-trivial zero-shot forecasting capabilities,\nespecially in capturing high-level trends and contextual shifts. While\npreliminary, our study surfaces important insights into the reasoning behaviors\nof LLMs in temporal domains highlighting both their potential and limitations.\nWe hope this work catalyzes further research into reasoning-based forecasting\nparadigms and paves the way toward more interpretable and generalizable TSF\nframeworks.", "AI": {"tldr": "The paper explores using slow-thinking LLMs for zero-shot time series forecasting, proposing TimeReasoner to evaluate their reasoning capabilities and finding promising results.", "motivation": "Existing time series forecasting methods lack explicit reasoning over temporal dynamics, while slow-thinking LLMs show potential for structured reasoning tasks.", "method": "Proposes TimeReasoner, a study formulating TSF as a conditional reasoning task, using prompting strategies to evaluate pretrained LLMs.", "result": "Slow-thinking LLMs demonstrate non-trivial zero-shot forecasting capabilities, particularly in capturing trends and contextual shifts.", "conclusion": "The study highlights the potential and limitations of LLMs in TSF, encouraging further research into reasoning-based forecasting for interpretability and generalizability."}}
{"id": "2503.10566", "pdf": "https://arxiv.org/pdf/2503.10566", "abs": "https://arxiv.org/abs/2503.10566", "authors": ["Egor Zverev", "Evgenii Kortukov", "Alexander Panfilov", "Alexandra Volkova", "Soroush Tabesh", "Sebastian Lapuschkin", "Wojciech Samek", "Christoph H. Lampert"], "title": "ASIDE: Architectural Separation of Instructions and Data in Language Models", "categories": ["cs.LG"], "comment": "Preliminary version accepted to ICLR 2025 Workshop on Building Trust\n  in Language Models and Applications", "summary": "Despite their remarkable performance, large language models lack elementary\nsafety features, making them susceptible to numerous malicious attacks. In\nparticular, previous work has identified the absence of an intrinsic separation\nbetween instructions and data as a root cause of the success of prompt\ninjection attacks. In this work, we propose a new architectural element, ASIDE,\nthat allows language models to clearly separate instructions and data at the\nlevel of embeddings. ASIDE applies an orthogonal rotation to the embeddings of\ndata tokens, thus creating clearly distinct representations of instructions and\ndata tokens without introducing any additional parameters. As we demonstrate\nexperimentally across a range of models, instruction-tuning LLMs with ASIDE (1)\nleads to highly increased instruction-data separation without a loss in model\nutility and (2) makes the models more robust to prompt injection benchmarks,\neven without dedicated safety training. Additionally, we provide insights into\nthe mechanism underlying our method through an analysis of the model\nrepresentations. The source code and training scripts are openly accessible at\nhttps://github.com/egozverev/aside.", "AI": {"tldr": "ASIDE introduces an orthogonal rotation to embeddings to separate instructions and data, improving safety and robustness against prompt injection attacks without losing model utility.", "motivation": "Large language models lack intrinsic safety features, making them vulnerable to malicious attacks like prompt injection due to unclear separation between instructions and data.", "method": "ASIDE applies an orthogonal rotation to data token embeddings, creating distinct representations for instructions and data without adding parameters.", "result": "Instruction-tuning with ASIDE enhances instruction-data separation, improves robustness to prompt injection, and maintains model utility.", "conclusion": "ASIDE effectively addresses prompt injection vulnerabilities by separating instructions and data at the embedding level, offering a lightweight and efficient solution."}}
{"id": "2505.24765", "pdf": "https://arxiv.org/pdf/2505.24765", "abs": "https://arxiv.org/abs/2505.24765", "authors": ["Srikanth Thudumu", "Jason Fisher", "Hung Du"], "title": "Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications", "categories": ["quant-ph", "cs.AI"], "comment": "Future outlook and roadmap of QML with 7 pages and 1 figure", "summary": "Supervised Quantum Machine Learning (QML) represents an intersection of\nquantum computing and classical machine learning, aiming to use quantum\nresources to support model training and inference. This paper reviews recent\ndevelopments in supervised QML, focusing on methods such as variational quantum\ncircuits, quantum neural networks, and quantum kernel methods, along with\nhybrid quantum-classical workflows. We examine recent experimental studies that\nshow partial indications of quantum advantage and describe current limitations\nincluding noise, barren plateaus, scalability issues, and the lack of formal\nproofs of performance improvement over classical methods. The main contribution\nis a ten-year outlook (2025-2035) that outlines possible developments in\nsupervised QML, including a roadmap describing conditions under which QML may\nbe used in applied research and enterprise systems over the next decade.", "AI": {"tldr": "A review of supervised QML methods, challenges, and a 10-year outlook on its potential applications.", "motivation": "To explore how quantum computing can enhance classical machine learning, focusing on supervised QML's current state and future potential.", "method": "Reviews variational quantum circuits, quantum neural networks, quantum kernel methods, and hybrid workflows, alongside experimental studies.", "result": "Identifies partial quantum advantages but highlights limitations like noise, scalability, and lack of formal proofs.", "conclusion": "Provides a 10-year roadmap for supervised QML's development and potential applications in research and enterprise."}}
{"id": "2504.00395", "pdf": "https://arxiv.org/pdf/2504.00395", "abs": "https://arxiv.org/abs/2504.00395", "authors": ["Canlin Zhang", "Xiuwen Liu"], "title": "A Theory of Machine Understanding via the Minimum Description Length Principle", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "Deep neural networks trained through end-to-end learning have achieved\nremarkable success across various domains in the past decade. However, the\nend-to-end learning strategy, originally designed to minimize predictive loss\nin a black-box manner, faces two fundamental limitations: the struggle to form\nexplainable representations in a self-supervised manner, and the inability to\ncompress information rigorously following the Minimum Description Length (MDL)\nprinciple. These two limitations point to a deeper issue: an end-to-end\nlearning model is not able to \"understand\" what it learns. In this paper, we\nestablish a novel theory connecting these two limitations. We design the\nSpectrum VAE, a novel deep learning architecture whose minimum description\nlength (MDL) can be rigorously evaluated. Then, we introduce the concept of\nlatent dimension combinations, or what we term spiking patterns, and\ndemonstrate that the observed spiking patterns should be as few as possible\nbased on the training data in order for the Spectrum VAE to achieve the MDL.\nFinally, our theory demonstrates that when the MDL is achieved with respect to\nthe given data distribution, the Spectrum VAE will naturally produce\nexplainable latent representations of the data. In other words, explainable\nrepresentations--or \"understanding\"--can emerge in a self-supervised manner\nsimply by making the deep network obey the MDL principle. In our opinion, this\nalso implies a deeper insight: To understand is to compress. At its core, our\ntheory advocates for a shift in the training objective of deep networks: not\nonly to minimize predictive loss, but also to minimize the description length\nregarding the given data. That is, a deep network should not only learn, but\nalso understand what it learns. This work is entirely theoretical and aims to\ninspire future research toward self-supervised, explainable AI grounded in the\nMDL principle.", "AI": {"tldr": "The paper introduces Spectrum VAE, a deep learning architecture that connects explainable representations with the Minimum Description Length (MDL) principle, showing that understanding emerges from compression.", "motivation": "Address the limitations of end-to-end learning in forming explainable representations and rigorously compressing information, proposing a theory that links these issues.", "method": "Design Spectrum VAE, evaluate its MDL, and introduce latent dimension combinations (spiking patterns) to achieve MDL.", "result": "Demonstrates that achieving MDL leads to explainable latent representations, suggesting 'to understand is to compress.'", "conclusion": "Advocates shifting deep network training objectives to include MDL minimization for self-supervised, explainable AI."}}
{"id": "2506.02285", "pdf": "https://arxiv.org/pdf/2506.02285", "abs": "https://arxiv.org/abs/2506.02285", "authors": ["Aaron Defazio"], "title": "Why Gradients Rapidly Increase Near the End of Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "During long-duration Large Language Model (LLM) training runs the gradient\nnorm increases rapidly near the end of training. In this short note, we show\nthat this increase is due to an unintended interaction between weight decay,\nnormalization layers, and the learning rate schedule. We propose a simple\ncorrection that fixes this behavior while also resulting in lower loss values\nthroughout training.", "AI": {"tldr": "The paper identifies and fixes an issue in LLM training where gradient norms spike late in training due to weight decay, normalization layers, and learning rate schedules.", "motivation": "To address the unintended interaction causing gradient norm spikes in late-stage LLM training.", "method": "Proposes a simple correction to mitigate the interaction between weight decay, normalization layers, and learning rate schedules.", "result": "The correction eliminates the gradient norm spike and reduces loss values during training.", "conclusion": "The proposed fix effectively resolves the issue and improves training stability and performance."}}
{"id": "2504.00910", "pdf": "https://arxiv.org/pdf/2504.00910", "abs": "https://arxiv.org/abs/2504.00910", "authors": ["Antoine Caradot", "R\u00e9mi Emonet", "Amaury Habrard", "Abdel-Rahim Mezidi", "Marc Sebban"], "title": "Provably Accurate Adaptive Sampling for Collocation Points in Physics-informed Neural Networks", "categories": ["cs.LG"], "comment": "19 pages. Comments are welcome", "summary": "Despite considerable scientific advances in numerical simulation, efficiently\nsolving PDEs remains a complex and often expensive problem. Physics-informed\nNeural Networks (PINN) have emerged as an efficient way to learn surrogate\nsolvers by embedding the PDE in the loss function and minimizing its residuals\nusing automatic differentiation at so-called collocation points. Originally\nuniformly sampled, the choice of the latter has been the subject of recent\nadvances leading to adaptive sampling refinements for PINNs. In this paper,\nleveraging a new quadrature method for approximating definite integrals, we\nintroduce a provably accurate sampling method for collocation points based on\nthe Hessian of the PDE residuals. Comparative experiments conducted on a set of\n1D and 2D PDEs demonstrate the benefits of our method.", "AI": {"tldr": "A new Hessian-based sampling method for collocation points in PINNs improves accuracy and efficiency in solving PDEs.", "motivation": "Efficiently solving PDEs is complex and costly; adaptive sampling refinements for PINNs aim to address this.", "method": "Introduces a provably accurate sampling method for collocation points using a new quadrature method and Hessian of PDE residuals.", "result": "Comparative experiments on 1D and 2D PDEs show the method's benefits.", "conclusion": "The proposed Hessian-based sampling method enhances PINN performance for PDE solutions."}}
{"id": "2506.05434", "pdf": "https://arxiv.org/pdf/2506.05434", "abs": "https://arxiv.org/abs/2506.05434", "authors": ["Thomas Massena", "L\u00e9o and\u00e9ol", "Thibaut Boissin", "Franck Mamalet", "Corentin Friedrich", "Mathieu Serrurier", "S\u00e9bastien Gerchinovitz"], "title": "Efficient Robust Conformal Prediction via Lipschitz-Bounded Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Conformal Prediction (CP) has proven to be an effective post-hoc method for\nimproving the trustworthiness of neural networks by providing prediction sets\nwith finite-sample guarantees. However, under adversarial attacks, classical\nconformal guarantees do not hold anymore: this problem is addressed in the\nfield of Robust Conformal Prediction. Several methods have been proposed to\nprovide robust CP sets with guarantees under adversarial perturbations, but,\nfor large scale problems, these sets are either too large or the methods are\ntoo computationally demanding to be deployed in real life scenarios. In this\nwork, we propose a new method that leverages Lipschitz-bounded networks to\nprecisely and efficiently estimate robust CP sets. When combined with a\n1-Lipschitz robust network, we demonstrate that our lip-rcp method outperforms\nstate-of-the-art results in both the size of the robust CP sets and\ncomputational efficiency in medium and large-scale scenarios such as ImageNet.\nTaking a different angle, we also study vanilla CP under attack, and derive new\nworst-case coverage bounds of vanilla CP sets, which are valid simultaneously\nfor all adversarial attack levels. Our lip-rcp method makes this second\napproach as efficient as vanilla CP while also allowing robustness guarantees.", "AI": {"tldr": "The paper introduces lip-rcp, a method using Lipschitz-bounded networks to efficiently compute robust conformal prediction sets, outperforming existing methods in set size and computational efficiency.", "motivation": "Classical conformal prediction lacks robustness under adversarial attacks, and existing robust methods are impractical for large-scale problems.", "method": "Leverages Lipschitz-bounded networks to estimate robust CP sets, combining with 1-Lipschitz networks for efficiency and precision.", "result": "lip-rcp outperforms state-of-the-art methods in robust CP set size and computational efficiency, especially in large-scale scenarios like ImageNet.", "conclusion": "The method bridges efficiency and robustness, offering practical deployment of robust CP sets with guarantees."}}
{"id": "2505.02604", "pdf": "https://arxiv.org/pdf/2505.02604", "abs": "https://arxiv.org/abs/2505.02604", "authors": ["Yongding Tian", "Zaid Al-Ars", "Maksim Kitsak", "Peter Hofstee"], "title": "Low-Loss Space in Neural Networks is Continuous and Fully Connected", "categories": ["cs.LG"], "comment": "17 pages, 5 figures", "summary": "Visualizations of the loss landscape in neural networks suggest that minima\nare isolated points. However, both theoretical and empirical studies indicate\nthat it is possible to connect two different minima with a path consisting of\nintermediate points that also have low loss. In this study, we propose a new\nalgorithm which investigates low-loss paths in the full parameter space, not\nonly between two minima. Our experiments on LeNet5, ResNet18, and Compact\nConvolutional Transformer architectures consistently demonstrate the existence\nof such continuous paths in the parameter space. These results suggest that the\nlow-loss region is a fully connected and continuous space in the parameter\nspace. Our findings provide theoretical insight into neural network\nover-parameterization, highlighting that parameters collectively define a\nhigh-dimensional low-loss space, implying parameter redundancy exists only\nwithin individual models and not throughout the entire low-loss space.\nAdditionally, our work also provides new visualization methods and\nopportunities to improve model generalization by exploring the low-loss space\nthat is closer to the origin.", "AI": {"tldr": "The paper explores the connectivity of low-loss regions in neural network parameter spaces, proposing an algorithm to find continuous paths between minima.", "motivation": "To understand the structure of low-loss regions in neural networks and challenge the notion of isolated minima.", "method": "A new algorithm is developed to investigate low-loss paths in the full parameter space, tested on LeNet5, ResNet18, and Compact Convolutional Transformer architectures.", "result": "Experiments confirm the existence of continuous low-loss paths, suggesting the low-loss region is fully connected and continuous.", "conclusion": "The findings reveal parameter redundancy within models and offer insights into over-parameterization, with potential for improved generalization and new visualization methods."}}
{"id": "2506.06292", "pdf": "https://arxiv.org/pdf/2506.06292", "abs": "https://arxiv.org/abs/2506.06292", "authors": ["Tianyuan Shi", "Canbin Huang", "Fanqi Wan", "Longguang Zhong", "Ziyi Yang", "Weizhou Shen", "Xiaojun Quan", "Ming Yan"], "title": "Mutual-Taught for Co-adapting Policy and Reward Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ACL 2025 (Main Conference)", "summary": "During the preference optimization of large language models (LLMs),\ndistribution shifts may arise between newly generated model samples and the\ndata used to train the reward model (RM). This shift reduces the efficacy of\nthe RM, which in turn negatively impacts the performance of the policy model\n(PM). To address this challenge, we propose Mutual-Taught, a self-training\nmethod that iteratively improves both the PM and RM without requiring\nadditional human annotation. Our approach mirrors the expectation-maximization\n(EM) algorithm. In the E-step, the PM is updated using feedback from the\ncurrent RM, guiding the PM toward a better approximation of the latent optimal\npreference distribution. In the M-step, we update the RM by constructing\ntraining data from the outputs of the PM before and after the E-step update.\nThis process ensures that the RM adapts to the evolving policy distribution.\nExperimental results demonstrate that this iterative approach leads to\nconsistent improvements in both models. Specifically, our 8B policy model,\nLLaMA-3-8B-Instruct-MT, achieves a length-controlled win rate of 54.1\\% on\nAlpacaEval-2, while our 8B reward model, FsfairX-LLaMA3-RM-MT, performs on par\nwith GPT-4o-2024-08-06 on RewardBench.", "AI": {"tldr": "Mutual-Taught is a self-training method for LLMs that iteratively improves policy and reward models without human annotation, achieving competitive performance.", "motivation": "Distribution shifts between model samples and reward model training data reduce RM efficacy, impacting policy model performance.", "method": "Uses an EM-like approach: E-step updates PM using RM feedback; M-step updates RM with PM outputs.", "result": "Consistent improvements in both models; LLaMA-3-8B-Instruct-MT achieves 54.1% win rate, FsfairX-LLaMA3-RM-MT matches GPT-4o performance.", "conclusion": "Mutual-Taught effectively addresses distribution shifts, enhancing model performance without extra human input."}}
{"id": "2505.05143", "pdf": "https://arxiv.org/pdf/2505.05143", "abs": "https://arxiv.org/abs/2505.05143", "authors": ["Mohammed Adnan", "Rohan Jain", "Ekansh Sharma", "Rahul Krishnan", "Yani Ioannou"], "title": "Sparse Training from Random Initialization: Aligning Lottery Ticket Masks using Weight Symmetry", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025", "summary": "The Lottery Ticket Hypothesis (LTH) suggests there exists a sparse LTH mask\nand weights that achieve the same generalization performance as the dense model\nwhile using significantly fewer parameters. However, finding a LTH solution is\ncomputationally expensive, and a LTH sparsity mask does not generalize to other\nrandom weight initializations. Recent work has suggested that neural networks\ntrained from random initialization find solutions within the same basin modulo\npermutation, and proposes a method to align trained models within the same loss\nbasin. We hypothesize that misalignment of basins is the reason why LTH masks\ndo not generalize to new random initializations and propose permuting the LTH\nmask to align with the new optimization basin when performing sparse training\nfrom a different random init. We empirically show a significant increase in\ngeneralization when sparse training from random initialization with the\npermuted mask as compared to using the non-permuted LTH mask, on multiple\ndatasets (CIFAR-10, CIFAR-100 and ImageNet) and models (VGG11, ResNet20 and\nResNet50).", "AI": {"tldr": "The paper addresses the generalization issue of Lottery Ticket Hypothesis (LTH) masks by proposing permutation alignment to improve sparse training performance.", "motivation": "LTH masks don't generalize to new random initializations due to misaligned optimization basins.", "method": "Permute LTH masks to align with new optimization basins during sparse training from different random initializations.", "result": "Empirical results show improved generalization on datasets (CIFAR-10, CIFAR-100, ImageNet) and models (VGG11, ResNet20, ResNet50).", "conclusion": "Permutation alignment of LTH masks enhances sparse training performance across diverse datasets and models."}}
{"id": "2506.07563", "pdf": "https://arxiv.org/pdf/2506.07563", "abs": "https://arxiv.org/abs/2506.07563", "authors": ["Ken Yaggel", "Eyal German", "Aviel Ben Siman Tov"], "title": "MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with Expert Specialization", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Personalized recommendation systems must adapt to user interactions across\ndifferent domains. Traditional approaches like MLoRA apply a single adaptation\nper domain but lack flexibility in handling diverse user behaviors. To address\nthis, we propose MoE-MLoRA, a mixture-of-experts framework where each expert is\nfirst trained independently to specialize in its domain before a gating network\nis trained to weight their contributions dynamically. We evaluate MoE-MLoRA\nacross eight CTR models on Movielens and Taobao, showing that it improves\nperformance in large-scale, dynamic datasets (+1.45 Weighed-AUC in Taobao-20)\nbut offers limited benefits in structured datasets with low domain diversity\nand sparsity. Further analysis of the number of experts per domain reveals that\nlarger ensembles do not always improve performance, indicating the need for\nmodel-aware tuning. Our findings highlight the potential of expert-based\narchitectures for multi-domain recommendation systems, demonstrating that\ntask-aware specialization and adaptive gating can enhance predictive accuracy\nin complex environments. The implementation and code are available in our\nGitHub repository.", "AI": {"tldr": "MoE-MLoRA, a mixture-of-experts framework, improves recommendation performance in dynamic, large-scale datasets but shows limited gains in structured, low-diversity datasets.", "motivation": "Traditional methods like MLoRA lack flexibility in handling diverse user behaviors across domains.", "method": "MoE-MLoRA trains domain-specialized experts independently, then uses a gating network to dynamically weight their contributions.", "result": "Improves performance in dynamic datasets (+1.45 Weighed-AUC in Taobao-20) but has limited benefits in structured datasets. Larger ensembles don't always help.", "conclusion": "Expert-based architectures with task-aware specialization and adaptive gating enhance predictive accuracy in complex environments."}}
{"id": "2505.16563", "pdf": "https://arxiv.org/pdf/2505.16563", "abs": "https://arxiv.org/abs/2505.16563", "authors": ["Chen Gong", "Rui Xing", "Zhenzhe Zheng", "Fan Wu"], "title": "A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices", "categories": ["cs.LG"], "comment": null, "summary": "The demand for machine learning (ML) model training on edge devices is\nescalating due to data privacy and personalized service needs. However, we\nobserve that current on-device model training is hampered by the\nunder-utilization of on-device data, due to low training throughput, limited\nstorage and diverse data importance. To improve data resource utilization, we\npropose a two-stage data selection framework {\\sf Titan} to select the most\nimportant data batch from streaming data for model training with guaranteed\nefficiency and effectiveness. Specifically, in the first stage, {\\sf Titan}\nfilters out a candidate dataset with potentially high importance in a\ncoarse-grained manner.In the second stage of fine-grained selection, we propose\na theoretically optimal data selection strategy to identify the data batch with\nthe highest model performance improvement to current training round. To further\nenhance time-and-resource efficiency, {\\sf Titan} leverages a pipeline to\nco-execute data selection and model training, and avoids resource conflicts by\nexploiting idle computing resources. We evaluate {\\sf Titan} on real-world edge\ndevices and three representative edge computing tasks with diverse models and\ndata modalities. Empirical results demonstrate that {\\sf Titan} achieves up to\n$43\\%$ reduction in training time and $6.2\\%$ increase in final accuracy with\nminor system overhead, such as data processing delay, memory footprint and\nenergy consumption.", "AI": {"tldr": "Titan is a two-stage data selection framework for efficient on-device ML training, improving throughput and accuracy with minimal overhead.", "motivation": "Addressing under-utilization of on-device data due to low throughput, storage limits, and varying data importance.", "method": "A two-stage framework: coarse-grained filtering followed by fine-grained, theoretically optimal data selection, with pipeline co-execution to avoid resource conflicts.", "result": "Up to 43% faster training and 6.2% higher accuracy with minor system overhead.", "conclusion": "Titan effectively enhances on-device training efficiency and performance."}}
{"id": "2506.07976", "pdf": "https://arxiv.org/pdf/2506.07976", "abs": "https://arxiv.org/abs/2506.07976", "authors": ["Junhong Shen", "Hao Bai", "Lunjun Zhang", "Yifei Zhou", "Amrith Setlur", "Shengbang Tong", "Diego Caples", "Nan Jiang", "Tong Zhang", "Ameet Talwalkar", "Aviral Kumar"], "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction", "categories": ["cs.LG", "cs.AI"], "comment": "Fixed typo in Figure 6 and Conclusion", "summary": "The current paradigm of test-time scaling relies on generating long reasoning\ntraces (\"thinking\" more) before producing a response. In agent problems that\nrequire interaction, this can be done by generating thinking traces before\nacting in the world. However, this process does not allow agents to acquire new\ninformation from the environment or adapt their behavior over time. In this\nwork, we propose to scale test-time interaction, an untapped dimension of\ntest-time scaling that increases the agent's interaction horizon to enable\nrunning rich behaviors such as exploration, backtracking, and dynamic\nre-planning within a single rollout. To demonstrate the promise of this scaling\ndimension, we study the domain of web agents. We first show that even\nprompting-based interaction scaling without any training can improve task\nsuccess on web benchmarks non-trivially. Building on this, we introduce TTI\n(Test-Time Interaction), a curriculum-based online reinforcement learning (RL)\napproach that trains agents by adaptively adjusting their rollout lengths.\nUsing a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data\nweb agents on WebVoyager and WebArena benchmarks. We further show that TTI\nenables agents to balance exploration and exploitation adaptively. Our results\nestablish interaction scaling as a powerful, complementary axis to scaling\nper-step compute, offering new avenues for training adaptive agents.", "AI": {"tldr": "The paper proposes test-time interaction scaling (TTI) to enhance agent adaptability and performance in interactive tasks, achieving state-of-the-art results on web benchmarks.", "motivation": "Current test-time scaling methods lack adaptability and real-time interaction, limiting agent performance in dynamic environments.", "method": "Introduces TTI, a curriculum-based online RL approach, using adaptive rollout lengths and a Gemma 3 12B model.", "result": "TTI improves task success on web benchmarks and enables adaptive exploration-exploitation balance.", "conclusion": "Interaction scaling is a powerful complement to per-step compute scaling, opening new avenues for adaptive agent training."}}
{"id": "2505.17777", "pdf": "https://arxiv.org/pdf/2505.17777", "abs": "https://arxiv.org/abs/2505.17777", "authors": ["Harish G. Ramaswamy", "L. A. Prashanth"], "title": "Optimizing Shortfall Risk Metric for Learning Regression Models", "categories": ["cs.LG"], "comment": null, "summary": "We consider the problem of estimating and optimizing utility-based shortfall\nrisk (UBSR) of a loss, say $(Y - \\hat Y)^2$, in the context of a regression\nproblem. Empirical risk minimization with a UBSR objective is challenging since\nUBSR is a non-linear function of the underlying distribution. We first derive a\nconcentration bound for UBSR estimation using independent and identically\ndistributed (i.i.d.) samples. We then frame the UBSR optimization problem as\nminimization of a pseudo-linear function in the space of achievable\ndistributions $\\mathcal D$ of the loss $(Y- \\hat Y)^2$. We construct a gradient\noracle for the UBSR objective and a linear minimization oracle (LMO) for the\nset $\\mathcal D$. Using these oracles, we devise a bisection-type algorithm,\nand establish convergence to the UBSR-optimal solution.", "AI": {"tldr": "The paper addresses estimating and optimizing utility-based shortfall risk (UBSR) in regression, proposing a concentration bound for UBSR estimation and a bisection-type algorithm for optimization.", "motivation": "UBSR is a non-linear function of the underlying distribution, making empirical risk minimization challenging. The work aims to provide practical methods for UBSR estimation and optimization.", "method": "Derives a concentration bound for UBSR estimation using i.i.d. samples, frames UBSR optimization as minimizing a pseudo-linear function, and constructs gradient and linear minimization oracles to devise a bisection-type algorithm.", "result": "Convergence to the UBSR-optimal solution is established using the proposed algorithm.", "conclusion": "The paper provides theoretical and algorithmic tools for UBSR estimation and optimization in regression problems."}}
{"id": "2505.19183", "pdf": "https://arxiv.org/pdf/2505.19183", "abs": "https://arxiv.org/abs/2505.19183", "authors": ["A. Jung"], "title": "Federated Learning: From Theory to Practice", "categories": ["cs.LG", "stat.ML", "F.1.1; I.2.11; I.5.3"], "comment": null, "summary": "This book offers a hands-on introduction to building and understanding\nfederated learning (FL) systems. FL enables multiple devices -- such as\nsmartphones, sensors, or local computers -- to collaboratively train machine\nlearning (ML) models, while keeping their data private and local. It is a\npowerful solution when data cannot or should not be centralized due to privacy,\nregulatory, or technical reasons. The book is designed for students, engineers,\nand researchers who want to learn how to design scalable, privacy preserving FL\nsystems. Our main focus is on personalization: enabling each device to train\nits own model while still benefiting from collaboration with relevant devices.\nThis is achieved by leveraging similarities between (the learning tasks\nassociated with) devices that are encoded by the weighted edges (or links) of a\nfederated learning network (FL network). The key idea is to represent\nreal-world FL systems as networks of devices, where nodes correspond to device\nand edges represent communication links and data similarities between them. The\ntraining of personalized models for these devices can be naturally framed as a\ndistributed optimization problem. This optimization problem is referred to as\ngeneralized total variation minimization (GTVMin) and ensures that devices with\nsimilar learning tasks learn similar model parameters. Our approach is both\nmathematically principled and practically motivated. While we introduce some\nadvanced ideas from optimization theory and graph-based learning, we aim to\nkeep the book accessible. Readers are guided through the core ideas step by\nstep, with intuitive explanations.", "AI": {"tldr": "The book introduces federated learning (FL) systems, focusing on personalization by training models collaboratively while keeping data private. It frames the problem as a distributed optimization task using generalized total variation minimization (GTVMin).", "motivation": "FL addresses privacy, regulatory, and technical challenges by enabling decentralized ML training without centralizing data. Personalization ensures devices benefit from collaboration while maintaining individual model training.", "method": "The approach represents FL systems as networks of devices, using GTVMin for distributed optimization to ensure similar tasks yield similar model parameters.", "result": "The method provides a scalable, privacy-preserving solution for FL, balancing collaboration and personalization.", "conclusion": "The book offers a practical, accessible guide to designing FL systems, combining mathematical rigor with intuitive explanations for students, engineers, and researchers."}}
{"id": "2505.22785", "pdf": "https://arxiv.org/pdf/2505.22785", "abs": "https://arxiv.org/abs/2505.22785", "authors": ["Marco Fumero", "Luca Moschella", "Emanuele Rodol\u00e0", "Francesco Locatello"], "title": "Navigating the Latent Space Dynamics of Neural Models", "categories": ["cs.LG"], "comment": null, "summary": "Neural networks transform high-dimensional data into compact, structured\nrepresentations, often modeled as elements of a lower dimensional latent space.\nIn this paper, we present an alternative interpretation of neural models as\ndynamical systems acting on the latent manifold. Specifically, we show that\nautoencoder models implicitly define a latent vector field on the manifold,\nderived by iteratively applying the encoding-decoding map, without any\nadditional training. We observe that standard training procedures introduce\ninductive biases that lead to the emergence of attractor points within this\nvector field. Drawing on this insight, we propose to leverage the vector field\nas a representation for the network, providing a novel tool to analyze the\nproperties of the model and the data. This representation enables to: (i)\nanalyze the generalization and memorization regimes of neural models, even\nthroughout training; (ii) extract prior knowledge encoded in the network's\nparameters from the attractors, without requiring any input data; (iii)\nidentify out-of-distribution samples from their trajectories in the vector\nfield. We further validate our approach on vision foundation models, showcasing\nthe applicability and effectiveness of our method in real-world scenarios.", "AI": {"tldr": "The paper interprets neural networks as dynamical systems on latent manifolds, revealing implicit vector fields and attractor points. This provides tools for analyzing model properties, generalization, memorization, and out-of-distribution detection.", "motivation": "To offer a new perspective on neural models by treating them as dynamical systems, uncovering latent vector fields and their properties without additional training.", "method": "Analyzes autoencoder models as dynamical systems, deriving latent vector fields from encoding-decoding maps and identifying attractor points.", "result": "Demonstrates that vector fields can analyze model behavior, extract prior knowledge, and detect out-of-distribution samples. Validated on vision foundation models.", "conclusion": "The dynamical systems view provides a powerful tool for understanding and analyzing neural networks, with practical applications in model evaluation and data analysis."}}
{"id": "2505.23244", "pdf": "https://arxiv.org/pdf/2505.23244", "abs": "https://arxiv.org/abs/2505.23244", "authors": ["Emo Todorov"], "title": "Equivalence of stochastic and deterministic policy gradients", "categories": ["cs.LG"], "comment": null, "summary": "Policy gradients in continuous control have been derived for both stochastic\nand deterministic policies. Here we study the relationship between the two. In\na widely-used family of MDPs involving Gaussian control noise and quadratic\ncontrol costs, we show that the stochastic and deterministic policy gradients,\nnatural gradients, and state value functions are identical; while the\nstate-control value functions are different. We then develop a general\nprocedure for constructing an MDP with deterministic policy that is equivalent\nto a given MDP with stochastic policy. The controls of this new MDP are the\nsufficient statistics of the stochastic policy in the original MDP. Our results\nsuggest that policy gradient methods can be unified by approximating state\nvalue functions rather than state-control value functions.", "AI": {"tldr": "The paper explores the relationship between stochastic and deterministic policy gradients in continuous control, showing their equivalence in certain MDPs and proposing a method to unify them.", "motivation": "To understand the connection between stochastic and deterministic policy gradients and unify policy gradient methods.", "method": "Analyzes MDPs with Gaussian control noise and quadratic costs, constructs equivalent MDPs for deterministic policies, and compares gradients and value functions.", "result": "Stochastic and deterministic policy gradients, natural gradients, and state value functions are identical in the studied MDPs, while state-control value functions differ.", "conclusion": "Policy gradient methods can be unified by approximating state value functions instead of state-control value functions."}}
{"id": "2505.24452", "pdf": "https://arxiv.org/pdf/2505.24452", "abs": "https://arxiv.org/abs/2505.24452", "authors": ["Anda Tang", "Yiming Dong", "Yutao Zeng", "zhou Xun", "Zhouchen Lin"], "title": "Stepsize anything: A unified learning rate schedule for budgeted-iteration training", "categories": ["cs.LG"], "comment": null, "summary": "The expanding computational costs and limited resources underscore the\ncritical need for budgeted-iteration training, which aims to achieve optimal\nlearning within predetermined iteration budgets. While learning rate schedules\nfundamentally govern the performance of different networks and tasks,\nparticularly in budgeted-iteration scenarios, their design remains largely\nheuristic, lacking theoretical foundations. In addition, the optimal learning\nrate schedule requires extensive trial-and-error selection, making the training\nprocess inefficient. In this work, we propose the Unified Budget-Aware (UBA)\nschedule, a theoretically grounded learning rate schedule that consistently\noutperforms commonly-used schedules among diverse architectures and tasks under\ndifferent constrained training budgets. First, we bridge the gap by\nconstructing a novel training budget-aware optimization framework, which\nexplicitly accounts for the robustness to landscape curvature variations. From\nthis framework, we derive the UBA schedule, controlled by a single\nhyper-parameter \\varphi that provides a trade-off between flexibility and\nsimplicity, eliminating the need for per-network numerical optimization.\nMoreover, we establish a theoretical connection between \\varphi and the\ncondition number, adding interpretation and justification to our approach.\nBesides, we prove the convergence for different values of \\varphi. We offer\npractical guidelines for its selection via theoretical analysis and empirical\nresults. Extensive experimental results show that UBA consistently surpasses\nthe commonly-used schedules across diverse vision and language tasks, spanning\nnetwork architectures (e.g., ResNet, OLMo) and scales, under different\ntraining-iteration budgets.", "AI": {"tldr": "The paper introduces the Unified Budget-Aware (UBA) schedule, a theoretically grounded learning rate schedule that outperforms heuristic-based schedules under constrained training budgets.", "motivation": "The need for efficient budgeted-iteration training due to rising computational costs and limited resources, coupled with the lack of theoretical foundations for learning rate schedules, motivates this work.", "method": "The authors propose the UBA schedule, derived from a budget-aware optimization framework, controlled by a hyper-parameter \u03c6, which balances flexibility and simplicity. Theoretical connections to the condition number and convergence proofs are provided.", "result": "UBA consistently outperforms common schedules across diverse architectures (e.g., ResNet, OLMo) and tasks under varying training budgets.", "conclusion": "The UBA schedule offers a practical, theoretically justified solution for budgeted-iteration training, eliminating the need for extensive trial-and-error in learning rate selection."}}
{"id": "2506.00388", "pdf": "https://arxiv.org/pdf/2506.00388", "abs": "https://arxiv.org/abs/2506.00388", "authors": ["Ni Mu", "Hao Hu", "Xiao Hu", "Yiqin Yang", "Bo Xu", "Qing-Shan Jia"], "title": "CLARIFY: Contrastive Preference Reinforcement Learning for Untangling Ambiguous Queries", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Preference-based reinforcement learning (PbRL) bypasses explicit reward\nengineering by inferring reward functions from human preference comparisons,\nenabling better alignment with human intentions. However, humans often struggle\nto label a clear preference between similar segments, reducing label efficiency\nand limiting PbRL's real-world applicability. To address this, we propose an\noffline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback\n(CLARIFY), which learns a trajectory embedding space that incorporates\npreference information, ensuring clearly distinguished segments are spaced\napart, thus facilitating the selection of more unambiguous queries. Extensive\nexperiments demonstrate that CLARIFY outperforms baselines in both non-ideal\nteachers and real human feedback settings. Our approach not only selects more\ndistinguished queries but also learns meaningful trajectory embeddings.", "AI": {"tldr": "CLARIFY improves PbRL by using contrastive learning to resolve ambiguous human feedback, enhancing query selection and embedding quality.", "motivation": "Humans struggle with labeling preferences for similar segments in PbRL, reducing efficiency and applicability.", "method": "Proposes CLARIFY, an offline PbRL method using contrastive learning to create a trajectory embedding space that clarifies ambiguous feedback.", "result": "CLARIFY outperforms baselines in non-ideal and real human feedback settings, selecting clearer queries and learning meaningful embeddings.", "conclusion": "CLARIFY enhances PbRL by addressing ambiguous feedback, improving both query selection and embedding quality."}}
{"id": "2506.02300", "pdf": "https://arxiv.org/pdf/2506.02300", "abs": "https://arxiv.org/abs/2506.02300", "authors": ["Farzaneh Mahdisoltani", "Saeed Mahdisoltani", "Roger B. Grosse", "David J. Fleet"], "title": "Through a Steerable Lens: Magnifying Neural Network Interpretability via Phase-Based Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Understanding the internal representations and decision mechanisms of deep\nneural networks remains a critical open challenge. While existing\ninterpretability methods often identify influential input regions, they may not\nelucidate how a model distinguishes between classes or what specific changes\nwould transition an input from one category to another. To address these\nlimitations, we propose a novel framework that visualizes the implicit path\nbetween classes by treating the network gradient as a form of infinitesimal\nmotion. Drawing inspiration from phase-based motion magnification, we first\ndecompose images using invertible transforms-specifically the Complex Steerable\nPyramid-then compute class-conditional gradients in the transformed space.\nRather than iteratively integrating the gradient to trace a full path, we\namplify the one-step gradient to the input and perform a linear extrapolation\nto expose how the model moves from source to target class. By operating in the\nsteerable pyramid domain, these amplified gradients produce semantically\nmeaningful, spatially coherent morphs that highlight the classifier's most\nsensitive directions, giving insight into the geometry of its decision\nboundaries. Experiments on both synthetic and real-world datasets demonstrate\nthat our phase-focused extrapolation yields perceptually aligned, semantically\nmeaningful transformations, offering a novel, interpretable lens into neural\nclassifiers' internal representations.", "AI": {"tldr": "A novel framework visualizes class transitions in neural networks by amplifying gradients in a steerable pyramid domain, revealing decision boundaries.", "motivation": "Existing interpretability methods fail to show how models distinguish classes or transition inputs between categories.", "method": "Decomposes images using invertible transforms, computes class-conditional gradients, and amplifies them for linear extrapolation.", "result": "Produces semantically meaningful morphs, highlighting sensitive directions and decision boundaries.", "conclusion": "The framework offers interpretable insights into neural classifiers' internal representations."}}
{"id": "2506.04446", "pdf": "https://arxiv.org/pdf/2506.04446", "abs": "https://arxiv.org/abs/2506.04446", "authors": ["Gil I. Shamir", "Manfred K. Warmuth"], "title": "Selective Matching Losses -- Not All Scores Are Created Equal", "categories": ["cs.LG"], "comment": null, "summary": "Learning systems match predicted scores to observations over some domain.\nOften, it is critical to produce accurate predictions in some subset (or\nregion) of the domain, yet less important to accurately predict in other\nregions. We construct selective matching loss functions by design of increasing\nlink functions over score domains. A matching loss is an integral over the\nlink. A link defines loss sensitivity as function of the score, emphasizing\nhigh slope high sensitivity regions over flat ones. Loss asymmetry drives a\nmodel and resolves its underspecification to predict better in high sensitivity\nregions where it is more important, and to distinguish between high and low\nimportance regions. A large variety of selective scalar losses can be designed\nwith scaled and shifted Sigmoid and hyperbolic sine links. Their properties,\nhowever, do not extend to multi-class. Applying them per dimension lacks\nranking sensitivity that assigns importance according to class score ranking.\nUtilizing composite Softmax functions, we develop a framework for\nmultidimensional selective losses. We overcome limitations of the standard\nSoftmax function, that is good for classification, but not for distinction\nbetween adjacent scores. Selective losses have substantial advantage over\ntraditional losses in applications with more important score regions, including\ndwell-time prediction, retrieval, ranking with either pointwise, contrastive\npairwise, or listwise losses, distillation problems, and fine-tuning alignment\nof Large Language Models (LLMs).", "AI": {"tldr": "The paper introduces selective matching loss functions to prioritize accurate predictions in specific regions of a domain, using link functions to emphasize high-sensitivity areas. It extends these losses to multi-class scenarios and demonstrates their advantages in various applications.", "motivation": "The need to improve prediction accuracy in critical regions of a domain while deprioritizing less important areas drives the development of selective loss functions.", "method": "The method involves designing selective matching loss functions using link functions (e.g., Sigmoid, hyperbolic sine) to emphasize high-sensitivity regions. For multi-class, composite Softmax functions are used to address ranking sensitivity.", "result": "Selective losses outperform traditional losses in applications like dwell-time prediction, retrieval, ranking, and LLM fine-tuning, by focusing on important score regions.", "conclusion": "Selective loss functions effectively address underspecification and improve prediction accuracy in critical regions, with broad applicability in machine learning tasks."}}
{"id": "2506.05632", "pdf": "https://arxiv.org/pdf/2506.05632", "abs": "https://arxiv.org/abs/2506.05632", "authors": ["Joseph Rowan", "Buu Phan", "Ashish Khisti"], "title": "Gumbel-max List Sampling for Distribution Coupling with Multiple Samples", "categories": ["cs.LG"], "comment": null, "summary": "We study a relaxation of the problem of coupling probability distributions --\na list of samples is generated from one distribution and an accept is declared\nif any one of these samples is identical to the sample generated from the other\ndistribution. We propose a novel method for generating samples, which extends\nthe Gumbel-max sampling suggested in Daliri et al. (arXiv:2408.07978) for\ncoupling probability distributions. We also establish a corresponding lower\nbound on the acceptance probability, which we call the list matching lemma. We\nnext discuss two applications of our setup. First, we develop a new mechanism\nfor multi-draft speculative sampling that is simple to implement and achieves\nperformance competitive with baselines such as SpecTr and SpecInfer across a\nrange of language tasks. Our method also guarantees a certain degree of drafter\ninvariance with respect to the output tokens which is not supported by existing\nschemes. We also provide a theoretical lower bound on the token level\nacceptance probability. As our second application, we consider distributed\nlossy compression with side information in a setting where a source sample is\ncompressed and available to multiple decoders, each with independent side\ninformation. We propose a compression technique that is based on our\ngeneralization of Gumbel-max sampling and show that it provides significant\ngains in experiments involving synthetic Gaussian sources and the MNIST image\ndataset.", "AI": {"tldr": "The paper introduces a novel method for coupling probability distributions using Gumbel-max sampling, with applications in multi-draft speculative sampling and distributed lossy compression.", "motivation": "To address the problem of coupling probability distributions and extend its applications to practical tasks like language processing and compression.", "method": "Proposes a generalization of Gumbel-max sampling for coupling distributions, introduces the list matching lemma for acceptance probability, and applies it to multi-draft speculative sampling and distributed lossy compression.", "result": "Achieves competitive performance in language tasks and significant gains in compression experiments.", "conclusion": "The method is effective for coupling distributions and has practical utility in speculative sampling and compression."}}
{"id": "2506.05764", "pdf": "https://arxiv.org/pdf/2506.05764", "abs": "https://arxiv.org/abs/2506.05764", "authors": ["Haochuan Wang"], "title": "Exploring Microstructural Dynamics in Cryptocurrency Limit Order Books: Better Inputs Matter More Than Stacking Another Hidden Layer", "categories": ["cs.LG", "q-fin.TR"], "comment": null, "summary": "Cryptocurrency price dynamics are driven largely by microstructural supply\ndemand imbalances in the limit order book (LOB), yet the highly noisy nature of\nLOB data complicates the signal extraction process. Prior research has\ndemonstrated that deep-learning architectures can yield promising predictive\nperformance on pre-processed equity and futures LOB data, but they often treat\nmodel complexity as an unqualified virtue. In this paper, we aim to examine\nwhether adding extra hidden layers or parameters to \"blackbox ish\" neural\nnetworks genuinely enhances short term price forecasting, or if gains are\nprimarily attributable to data preprocessing and feature engineering. We\nbenchmark a spectrum of models from interpretable baselines, logistic\nregression, XGBoost to deep architectures (DeepLOB, Conv1D+LSTM) on BTC/USDT\nLOB snapshots sampled at 100 ms to multi second intervals using publicly\navailable Bybit data. We introduce two data filtering pipelines (Kalman,\nSavitzky Golay) and evaluate both binary (up/down) and ternary (up/flat/down)\nlabeling schemes. Our analysis compares models on out of sample accuracy,\nlatency, and robustness to noise. Results reveal that, with data preprocessing\nand hyperparameter tuning, simpler models can match and even exceed the\nperformance of more complex networks, offering faster inference and greater\ninterpretability.", "AI": {"tldr": "Simpler models with proper preprocessing can outperform complex neural networks in cryptocurrency price forecasting, offering speed and interpretability.", "motivation": "To determine if adding complexity to neural networks genuinely improves short-term price forecasting or if gains come from preprocessing and feature engineering.", "method": "Benchmarked models from logistic regression to deep architectures (DeepLOB, Conv1D+LSTM) on BTC/USDT LOB data, using data filtering pipelines (Kalman, Savitzky Golay) and binary/ternary labeling schemes.", "result": "Simpler models matched or exceeded complex networks' performance with preprocessing and tuning, providing faster inference and better interpretability.", "conclusion": "Data preprocessing and feature engineering are key; simpler models can be as effective as complex ones for short-term price forecasting."}}
{"id": "2506.05957", "pdf": "https://arxiv.org/pdf/2506.05957", "abs": "https://arxiv.org/abs/2506.05957", "authors": ["Tianjun Yao", "Haoxuan Li", "Yongqiang Chen", "Tongliang Liu", "Le Song", "Eric Xing", "Zhiqiang Shen"], "title": "Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization", "categories": ["cs.LG", "I.2.6"], "comment": "Submission of ICML2025, with score 4/4/3/3", "summary": "Graph Neural Networks (GNNs) often encounter significant performance\ndegradation under distribution shifts between training and test data, hindering\ntheir applicability in real-world scenarios. Recent studies have proposed\nvarious methods to address the out-of-distribution generalization challenge,\nwith many methods in the graph domain focusing on directly identifying an\ninvariant subgraph that is predictive of the target label. However, we argue\nthat identifying the edges from the invariant subgraph directly is challenging\nand error-prone, especially when some spurious edges exhibit strong\ncorrelations with the targets. In this paper, we propose PrunE, the first\npruning-based graph OOD method that eliminates spurious edges to improve OOD\ngeneralizability. By pruning spurious edges, PrunE retains the invariant\nsubgraph more comprehensively, which is critical for OOD generalization.\nSpecifically, PrunE employs two regularization terms to prune spurious edges:\n1) graph size constraint to exclude uninformative spurious edges, and 2)\n$\\epsilon$-probability alignment to further suppress the occurrence of spurious\nedges. Through theoretical analysis and extensive experiments, we show that\nPrunE achieves superior OOD performance and outperforms previous\nstate-of-the-art methods significantly. Codes are available at:\n\\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.", "AI": {"tldr": "PrunE is a pruning-based method to improve Graph Neural Networks' OOD generalization by eliminating spurious edges, outperforming existing methods.", "motivation": "GNNs suffer performance drops under distribution shifts; existing methods struggle to identify invariant subgraphs due to spurious edge correlations.", "method": "PrunE uses two regularization terms: graph size constraint and \u03b5-probability alignment, to prune spurious edges and retain invariant subgraphs.", "result": "PrunE achieves superior OOD performance, significantly outperforming state-of-the-art methods.", "conclusion": "PrunE effectively enhances GNNs' OOD generalization by pruning spurious edges, validated by theory and experiments."}}
{"id": "2506.06300", "pdf": "https://arxiv.org/pdf/2506.06300", "abs": "https://arxiv.org/abs/2506.06300", "authors": ["Yuanye Zhou", "Zhaokun Wang", "Kai Zhou", "Hui Tang", "Xiaofan Li"], "title": "LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Physics-informed neural networks (PINNs) have emerged as a powerful meshless\ntool for topology optimization, capable of simultaneously determining optimal\ntopologies and physical solutions. However, conventional PINNs rely on\ndensity-based topology descriptions, which necessitate manual interpolation and\nlimit their applicability to complex geometries. To address this, we propose\nLagrangian topology-conscious PINNs (LT-PINNs), a novel framework for\nboundary-focused engineering optimization. By parameterizing the control\nvariables of topology boundary curves as learnable parameters, LT-PINNs\neliminate the need for manual interpolation and enable precise boundary\ndetermination. We further introduce specialized boundary condition loss\nfunction and topology loss function to ensure sharp and accurate boundary\nrepresentations, even for intricate topologies. The accuracy and robustness of\nLT-PINNs are validated via two types of partial differential equations (PDEs),\nincluding elastic equation with Dirichlet boundary conditions and Laplace's\nequation with Neumann boundary conditions. Furthermore, we demonstrate\neffectiveness of LT-PINNs on more complex time-dependent and time-independent\nflow problems without relying on measurement data, and showcase their\nengineering application potential in flow velocity rearrangement, transforming\na uniform upstream velocity into a sine-shaped downstream profile. The results\ndemonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors\ncompared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2)\nLT-PINNs can handle arbitrary boundary conditions, making them suitable for a\nwide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries\nwithout manual interpolation, especially for complex topologies.", "AI": {"tldr": "LT-PINNs improve topology optimization by eliminating manual interpolation and enabling precise boundary determination, outperforming conventional PINNs in accuracy and versatility.", "motivation": "Conventional PINNs rely on density-based topology descriptions, requiring manual interpolation and limiting applicability to complex geometries.", "method": "LT-PINNs parameterize topology boundary curves as learnable parameters and introduce specialized boundary and topology loss functions for sharp representations.", "result": "LT-PINNs reduce relative L2 errors, handle arbitrary boundary conditions, and infer clear topology boundaries without manual interpolation.", "conclusion": "LT-PINNs offer a robust, boundary-focused framework for engineering optimization, suitable for a wide range of PDEs and complex topologies."}}
{"id": "2506.06715", "pdf": "https://arxiv.org/pdf/2506.06715", "abs": "https://arxiv.org/abs/2506.06715", "authors": ["Minh-Duc Nguyen", "Dung D. Le"], "title": "A Framework for Controllable Multi-objective Learning with Annealed Stein Variational Hypernetworks", "categories": ["cs.LG", "stat.ML"], "comment": "Paper is under review", "summary": "Pareto Set Learning (PSL) is popular as an efficient approach to obtaining\nthe complete optimal solution in Multi-objective Learning (MOL). A set of\noptimal solutions approximates the Pareto set, and its mapping is a set of\ndense points in the Pareto front in objective space. However, some current\nmethods face a challenge: how to make the Pareto solution is diverse while\nmaximizing the hypervolume value. In this paper, we propose a novel method to\naddress this challenge, which employs Stein Variational Gradient Descent (SVGD)\nto approximate the entire Pareto set. SVGD pushes a set of particles towards\nthe Pareto set by applying a form of functional gradient descent, which helps\nto converge and diversify optimal solutions. Additionally, we employ diverse\ngradient direction strategies to thoroughly investigate a unified framework for\nSVGD in multi-objective optimization and adapt this framework with an annealing\nschedule to promote stability. We introduce our method, SVH-MOL, and validate\nits effectiveness through extensive experiments on multi-objective problems and\nmulti-task learning, demonstrating its superior performance.", "AI": {"tldr": "The paper proposes SVH-MOL, a method using SVGD to diversify Pareto solutions while maximizing hypervolume in multi-objective learning.", "motivation": "Current methods struggle to balance diversity and hypervolume maximization in Pareto solutions.", "method": "Uses SVGD to approximate the Pareto set, employs diverse gradient directions, and incorporates an annealing schedule for stability.", "result": "SVH-MOL shows superior performance in multi-objective problems and multi-task learning.", "conclusion": "SVH-MOL effectively addresses the challenge of diversifying Pareto solutions while optimizing hypervolume."}}
{"id": "2001.01095", "pdf": "https://arxiv.org/pdf/2001.01095", "abs": "https://arxiv.org/abs/2001.01095", "authors": ["Cencheng Shen", "Yuexiao Dong"], "title": "High-Dimensional Independence Testing via Maximum and Average Distance Correlations", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "11 pages main + 5 pages appendix", "summary": "This paper investigates the utilization of maximum and average distance\ncorrelations for multivariate independence testing. We characterize their\nconsistency properties in high-dimensional settings with respect to the number\nof marginally dependent dimensions, compare the advantages of each test\nstatistic, examine their respective null distributions, and present a fast\nchi-square-based testing procedure. The resulting tests are non-parametric and\napplicable to both Euclidean distance and the Gaussian kernel as the underlying\nmetric. To better understand the practical use cases of the proposed tests, we\nevaluate the empirical performance of the maximum distance correlation, average\ndistance correlation, and the original distance correlation across various\nmultivariate dependence scenarios, as well as conduct a real data experiment to\ntest the presence of various cancer types and peptide levels in human plasma.", "AI": {"tldr": "The paper explores maximum and average distance correlations for multivariate independence testing, comparing their properties, null distributions, and proposing a chi-square-based test. It evaluates their performance in various scenarios and applies them to real-world cancer data.", "motivation": "To address the need for robust non-parametric independence tests in high-dimensional settings, comparing maximum and average distance correlations.", "method": "Characterizes consistency properties, compares test statistics, examines null distributions, and introduces a chi-square-based testing procedure. Evaluates empirical performance across dependence scenarios and real data.", "result": "Proposes non-parametric tests applicable to Euclidean and Gaussian kernel metrics, demonstrating practical utility in cancer data analysis.", "conclusion": "The study provides insights into the advantages of maximum and average distance correlations, offering a fast and versatile testing framework for high-dimensional data."}}
{"id": "2010.11750", "pdf": "https://arxiv.org/pdf/2010.11750", "abs": "https://arxiv.org/abs/2010.11750", "authors": ["Fan Yang", "Hongyang R. Zhang", "Sen Wu", "Christopher R\u00e9", "Weijie J. Su"], "title": "Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers", "categories": ["stat.ML", "cs.LG"], "comment": "88 pages", "summary": "The problem of learning one task using samples from another task is central\nto transfer learning. In this paper, we focus on answering the following\nquestion: when does combining the samples from two related tasks perform better\nthan learning with one target task alone? This question is motivated by an\nempirical phenomenon known as negative transfer, which has been observed in\npractice. While the transfer effect from one task to another depends on factors\nsuch as their sample sizes and the spectrum of their covariance matrices,\nprecisely quantifying this dependence has remained a challenging problem. In\norder to compare a transfer learning estimator to single-task learning, one\nneeds to compare the risks between the two estimators precisely. Further, the\ncomparison depends on the distribution shifts between the two tasks. This paper\napplies recent developments of random matrix theory to tackle this challenge in\na high-dimensional linear regression setting with two tasks. We show precise\nhigh-dimensional asymptotics for the bias and variance of a classical hard\nparameter sharing (HPS) estimator in the proportional limit, where the sample\nsizes of both tasks increase proportionally with dimension at fixed ratios. The\nprecise asymptotics apply to various types of distribution shifts, including\ncovariate shifts, model shifts, and combinations of both. We illustrate these\nresults in a random-effects model to mathematically prove a phase transition\nfrom positive to negative transfer as the number of source task samples\nincreases. One insight from the analysis is that a rebalanced HPS estimator,\nwhich downsizes the source task when the model shift is high, achieves the\nminimax optimal rate. The finding regarding phase transition also applies to\nmultiple tasks when covariates are shared across tasks. Simulations validate\nthe accuracy of the high-dimensional asymptotics for finite dimensions.", "AI": {"tldr": "The paper investigates when combining samples from two related tasks outperforms single-task learning, addressing negative transfer. It uses random matrix theory to analyze high-dimensional linear regression, showing precise asymptotics for bias and variance, and identifies a phase transition between positive and negative transfer.", "motivation": "The study is motivated by the empirical phenomenon of negative transfer, where combining samples from related tasks can degrade performance. The goal is to quantify when transfer learning is beneficial, considering factors like sample sizes and covariance spectra.", "method": "The paper employs random matrix theory to analyze a high-dimensional linear regression setting with two tasks. It examines the hard parameter sharing (HPS) estimator in the proportional limit, where sample sizes grow with dimension at fixed ratios.", "result": "The analysis reveals precise asymptotics for bias and variance, showing a phase transition from positive to negative transfer as source task samples increase. A rebalanced HPS estimator is found to be minimax optimal.", "conclusion": "The study provides theoretical insights into transfer learning, demonstrating conditions for positive and negative transfer. The findings are validated through simulations and extend to multiple tasks with shared covariates."}}
{"id": "2303.07475", "pdf": "https://arxiv.org/pdf/2303.07475", "abs": "https://arxiv.org/abs/2303.07475", "authors": ["Kuo-Wei Lai", "Vidya Muthukumar"], "title": "General Loss Functions Lead to (Approximate) Interpolation in High Dimensions", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": "60 pages", "summary": "We provide a unified framework that applies to a general family of convex\nlosses across binary and multiclass settings in the overparameterized regime to\napproximately characterize the implicit bias of gradient descent in closed\nform. Specifically, we show that the implicit bias is approximated (but not\nexactly equal to) the minimum-norm interpolation in high dimensions, which\narises from training on the squared loss. In contrast to prior work, which was\ntailored to exponentially-tailed losses and used the intermediate\nsupport-vector-machine formulation, our framework directly builds on the\nprimal-dual analysis of Ji and Telgarsky (2021), allowing us to provide new\napproximate equivalences for general convex losses through a novel sensitivity\nanalysis. Our framework also recovers existing exact equivalence results for\nexponentially-tailed losses across binary and multiclass settings. Finally, we\nprovide evidence for the tightness of our techniques and use our results to\ndemonstrate the effect of certain loss functions designed for\nout-of-distribution problems on the closed-form solution.", "AI": {"tldr": "A unified framework for analyzing the implicit bias of gradient descent in overparameterized settings, approximating it to minimum-norm interpolation for general convex losses.", "motivation": "To generalize prior work limited to exponentially-tailed losses and provide a broader understanding of gradient descent's implicit bias.", "method": "Builds on primal-dual analysis and introduces a novel sensitivity analysis for general convex losses.", "result": "Approximates implicit bias to minimum-norm interpolation, recovers existing exact results for exponentially-tailed losses, and demonstrates tightness of techniques.", "conclusion": "The framework offers new insights into gradient descent behavior and its implications for loss function design, especially in out-of-distribution problems."}}
{"id": "2310.10315", "pdf": "https://arxiv.org/pdf/2310.10315", "abs": "https://arxiv.org/abs/2310.10315", "authors": ["Kamila Zaman", "Alberto Marchisio", "Muhammad Abdullah Hanif", "Muhammad Shafique"], "title": "A Survey on Quantum Machine Learning: Current Trends, Challenges, Opportunities, and the Road Ahead", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum Computing (QC) claims to improve the efficiency of solving complex\nproblems, compared to classical computing. When QC is integrated with Machine\nLearning (ML), it creates a Quantum Machine Learning (QML) system. This paper\naims to provide a thorough understanding of the foundational concepts of QC and\nits notable advantages over classical computing. Following this, we delve into\nthe key aspects of QML in a detailed and comprehensive manner.\n  In this survey, we investigate a variety of QML algorithms, discussing their\napplicability across different domains. We examine quantum datasets,\nhighlighting their unique characteristics and advantages. The survey also\ncovers the current state of hardware technologies, providing insights into the\nlatest advancements and their implications for QML. Additionally, we review the\nsoftware tools and simulators available for QML development, discussing their\nfeatures and usability.\n  Furthermore, we explore practical applications of QML, illustrating how it\ncan be leveraged to solve real-world problems more efficiently than classical\nML methods. This survey aims to consolidate the current landscape of QML and\noutline key opportunities and challenges for future research.", "AI": {"tldr": "A survey on Quantum Machine Learning (QML), covering foundational QC concepts, QML algorithms, quantum datasets, hardware advancements, software tools, and practical applications, while highlighting future opportunities and challenges.", "motivation": "To provide a comprehensive understanding of Quantum Computing (QC) and its integration with Machine Learning (ML) to form QML, showcasing its advantages over classical methods.", "method": "Investigates QML algorithms, quantum datasets, hardware technologies, and software tools, along with practical applications.", "result": "Consolidates the current state of QML, emphasizing its efficiency and potential in solving real-world problems compared to classical ML.", "conclusion": "Outlines key opportunities and challenges for future research in QML, highlighting its transformative potential."}}
{"id": "2401.11576", "pdf": "https://arxiv.org/pdf/2401.11576", "abs": "https://arxiv.org/abs/2401.11576", "authors": ["Yize Sun", "Zixin Wu", "Yunpu Ma", "Volker Tresp"], "title": "Quantum Architecture Search with Unsupervised Representation Learning", "categories": ["quant-ph", "cs.LG"], "comment": "10 Pages, quantum architecture search, unsupervised representation\n  learning", "summary": "Unsupervised representation learning presents new opportunities for advancing\nQuantum Architecture Search (QAS) on Noisy Intermediate-Scale Quantum (NISQ)\ndevices. QAS is designed to optimize quantum circuits for Variational Quantum\nAlgorithms (VQAs). Most QAS algorithms tightly couple the search space and\nsearch algorithm, typically requiring the evaluation of numerous quantum\ncircuits, resulting in high computational costs and limiting scalability to\nlarger quantum circuits. Predictor-based QAS algorithms mitigate this issue by\nestimating circuit performance based on structure or embedding. However, these\nmethods often demand time-intensive labeling to optimize gate parameters across\nmany circuits, which is crucial for training accurate predictors. Inspired by\nthe classical neural architecture search algorithm Arch2vec, we investigate the\npotential of unsupervised representation learning for QAS without relying on\npredictors. Our framework decouples unsupervised architecture representation\nlearning from the search process, enabling the learned representations to be\napplied across various downstream tasks. Additionally, it integrates an\nimproved quantum circuit graph encoding scheme, addressing the limitations of\nexisting representations and enhancing search efficiency. This predictor-free\napproach removes the need for large labeled datasets. During the search, we\nemploy REINFORCE and Bayesian Optimization to explore the latent representation\nspace and compare their performance against baseline methods. We further\nvalidate our approach by executing the best-discovered MaxCut circuits on IBM's\nibm_sherbrooke quantum processor, confirming that the architectures retain\noptimal performance even under real hardware noise. Our results demonstrate\nthat the framework efficiently identifies high-performing quantum circuits with\nfewer search iterations.", "AI": {"tldr": "Unsupervised representation learning improves Quantum Architecture Search (QAS) by decoupling representation learning from the search process, reducing computational costs and eliminating the need for labeled datasets.", "motivation": "Existing QAS methods are computationally expensive and require extensive labeled data, limiting scalability. Unsupervised learning offers a solution.", "method": "The framework uses unsupervised representation learning, improved quantum circuit graph encoding, and employs REINFORCE and Bayesian Optimization for search.", "result": "The approach efficiently identifies high-performing circuits with fewer iterations and validates performance on real quantum hardware.", "conclusion": "Unsupervised learning enhances QAS scalability and efficiency, demonstrating practical viability on NISQ devices."}}
{"id": "2401.17177", "pdf": "https://arxiv.org/pdf/2401.17177", "abs": "https://arxiv.org/abs/2401.17177", "authors": ["Mohsen Sadr", "Tony Tohme", "Kamal Youcef-Toumi"], "title": "Data-Driven Discovery of PDEs via the Adjoint Method", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "In this work, we present an adjoint-based method for discovering the\nunderlying governing partial differential equations (PDEs) given data. The idea\nis to consider a parameterized PDE in a general form and formulate a\nPDE-constrained optimization problem aimed at minimizing the error of the PDE\nsolution from data. Using variational calculus, we obtain an evolution equation\nfor the Lagrange multipliers (adjoint equations) allowing us to compute the\ngradient of the objective function with respect to the parameters of PDEs given\ndata in a straightforward manner. In particular, we consider a family of\nparameterized PDEs encompassing linear, nonlinear, and spatial derivative\ncandidate terms, and elegantly derive the corresponding adjoint equations. We\nshow the efficacy of the proposed approach in identifying the form of the PDE\nup to machine accuracy, enabling the accurate discovery of PDEs from data. We\nalso compare its performance with the famous PDE Functional Identification of\nNonlinear Dynamics method known as PDE-FIND (Rudy et al., 2017), on both smooth\nand noisy data sets. Even though the proposed adjoint method relies on\nforward/backward solvers, it outperforms PDE-FIND for large data sets thanks to\nthe analytic expressions for gradients of the cost function with respect to\neach PDE parameter.", "AI": {"tldr": "An adjoint-based method for discovering governing PDEs from data, outperforming PDE-FIND for large datasets.", "motivation": "To accurately identify underlying PDEs from data using a parameterized approach and variational calculus.", "method": "Formulate a PDE-constrained optimization problem, derive adjoint equations for gradient computation, and test on various PDE forms.", "result": "The method identifies PDEs up to machine accuracy and outperforms PDE-FIND for large datasets.", "conclusion": "The adjoint-based approach is effective for PDE discovery, especially with large datasets."}}
{"id": "2402.14515", "pdf": "https://arxiv.org/pdf/2402.14515", "abs": "https://arxiv.org/abs/2402.14515", "authors": ["Patrick Holzer", "Ivica Turkalj"], "title": "Spectral invariance and maximality properties of the frequency spectrum of quantum neural networks", "categories": ["quant-ph", "cs.LG", "stat.ML"], "comment": null, "summary": "Quantum Neural Networks (QNNs) are a popular approach in Quantum Machine\nLearning.\n  We analyze this frequency spectrum using the Minkowski sum for sets and the\nset of differences, which makes it particularly easy to express and calculate\nthe frequency spectrum algebraically, and prove different maximality results\nfor a large class of models.\n  Furthermore, we prove that under some mild conditions there exists a\nbijection between classes of models with the same area $A:=R\\cdot L$ that\npreserves the frequency spectrum, where $R$ denotes the number of qubits and\n$L$ the number of layers, which we consequently call spectral invariance under\narea-preserving transformations. With this we explain the symmetry in $R$ and\n$L$ in the results often observed in the literature and show that the maximal\nfrequency spectrum depends only on the area $A=RL$ and not on the individual\nvalues of $R$ and $L$. Moreover, we collect and extend existing results and\nspecify the maximum possible frequency spectrum of a QNN with arbitrarily many\nlayers as a function of the spectrum of its generators. In the case of\narbitrary dimensional generators, where our two introduces notions of\nmaximality differ, we extend existing results based on the so-called Golomb\nruler and introduce a second novel approach based on a variation of the\nturnpike problem, which we call the relaxed turnpike problem.", "AI": {"tldr": "The paper analyzes Quantum Neural Networks (QNNs) using algebraic methods to study their frequency spectrum, proving spectral invariance under area-preserving transformations and extending maximality results.", "motivation": "To understand the symmetry in qubit count (R) and layer count (L) in QNNs and their frequency spectrum, explaining observed patterns in literature.", "method": "Uses Minkowski sums and set differences for algebraic analysis, introduces spectral invariance, and extends maximality results using Golomb rulers and a relaxed turnpike problem.", "result": "Shows the frequency spectrum depends only on the area A=RL, not individual R or L, and specifies maximum possible spectrum for QNNs.", "conclusion": "The study provides a unified framework for QNN frequency analysis, linking spectral properties to area-preserving transformations and offering new tools for maximality."}}
{"id": "2403.07143", "pdf": "https://arxiv.org/pdf/2403.07143", "abs": "https://arxiv.org/abs/2403.07143", "authors": ["Shiliang Zuo"], "title": "Harnessing the Continuous Structure: Utilizing the First-order Approach in Online Contract Design", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "This work studies the online contract design problem. The principal's goal is\nto learn the optimal contract that maximizes her utility through repeated\ninteractions, without prior knowledge of the agent's type (i.e., the agent's\ncost and production functions). We leverage the structure provided by\ncontinuous action spaces, which allows the application of first-order\nconditions (FOC) to characterize the agent's behavior. In some cases, we\nutilize conditions from the first-order approach (FOA) in economics, but in\ncertain settings, we are able to apply FOC without additional assumptions,\nleading to simpler and more principled algorithms.\n  We illustrate this approach in three problem settings. Firstly, we study the\nproblem of learning the optimal contract when there can be many outcomes. In\ncontrast to prior works that design highly specialized algorithms, we show that\nthe problem can be directly reduced to Lipschitz bandits. Secondly, we study\nthe problem of learning linear contracts. While the contracting problem\ninvolves hidden action (moral hazard) and the pricing problem involves hidden\nvalue (adverse selection), the two problems share a similar optimization\nstructure, which enables direct reduction between the problem of learning\nlinear contracts and dynamic pricing. Thirdly, we study the problem of learning\ncontracts with many outcomes when agents are identical and provide an algorithm\nwith polynomial sample complexity.", "AI": {"tldr": "The paper explores online contract design, aiming to learn optimal contracts without prior knowledge of agent types. It uses continuous action spaces and first-order conditions to simplify algorithms, applying the approach to three problem settings.", "motivation": "The principal seeks to maximize utility through repeated interactions without knowing the agent's type (cost and production functions), addressing gaps in prior specialized algorithms.", "method": "Leverages continuous action spaces and first-order conditions (FOC), sometimes using the first-order approach (FOA), to characterize agent behavior. Applies this to three settings: learning optimal contracts with many outcomes, learning linear contracts, and learning contracts with identical agents.", "result": "Shows reductions to Lipschitz bandits and dynamic pricing, and provides a polynomial sample complexity algorithm for identical agents.", "conclusion": "The approach simplifies and generalizes contract learning, offering principled solutions across diverse settings."}}
{"id": "2407.13625", "pdf": "https://arxiv.org/pdf/2407.13625", "abs": "https://arxiv.org/abs/2407.13625", "authors": ["Aras Selvi", "Eleonora Kreacic", "Mohsen Ghassemi", "Vamsi Potluru", "Tucker Balch", "Manuela Veloso"], "title": "Distributionally and Adversarially Robust Logistic Regression via Intersecting Wasserstein Balls", "categories": ["math.OC", "cs.LG"], "comment": "9 main pages + 25 pages of appendices", "summary": "Adversarially robust optimization (ARO) has emerged as the *de facto*\nstandard for training models that hedge against adversarial attacks in the test\nstage. While these models are robust against adversarial attacks, they tend to\nsuffer severely from overfitting. To address this issue, some successful\nmethods replace the empirical distribution in the training stage with\nalternatives including *(i)* a worst-case distribution residing in an ambiguity\nset, resulting in a distributionally robust (DR) counterpart of ARO; *(ii)* a\nmixture of the empirical distribution with a distribution induced by an\nauxiliary (*e.g.*, synthetic, external, out-of-domain) dataset. Inspired by the\nformer, we study the Wasserstein DR counterpart of ARO for logistic regression\nand show it admits a tractable convex optimization reformulation. Adopting the\nlatter setting, we revise the DR approach by intersecting its ambiguity set\nwith another ambiguity set built using the auxiliary dataset, which offers a\nsignificant improvement whenever the Wasserstein distance between the data\ngenerating and auxiliary distributions can be estimated. We study the\nunderlying optimization problem, develop efficient solution algorithms, and\ndemonstrate that the proposed method outperforms benchmark approaches on\nstandard datasets.", "AI": {"tldr": "The paper addresses overfitting in adversarially robust optimization (ARO) by proposing a Wasserstein distributionally robust (DR) counterpart for logistic regression and a revised DR approach using auxiliary datasets.", "motivation": "ARO models suffer from overfitting despite robustness against adversarial attacks. The study aims to mitigate this by leveraging distributional robustness and auxiliary data.", "method": "The paper introduces a Wasserstein DR counterpart of ARO for logistic regression and revises the DR approach by intersecting ambiguity sets with auxiliary data. Efficient algorithms are developed for optimization.", "result": "The proposed method outperforms benchmark approaches on standard datasets, showing significant improvement when Wasserstein distance between distributions is estimated.", "conclusion": "The revised DR approach, combining ambiguity sets with auxiliary data, effectively reduces overfitting and enhances performance in ARO."}}
{"id": "2408.00856", "pdf": "https://arxiv.org/pdf/2408.00856", "abs": "https://arxiv.org/abs/2408.00856", "authors": ["Tung L Nguyen", "Toby Dylan Hocking"], "title": "Penalty Learning for Optimal Partitioning using Multilayer Perceptron", "categories": ["stat.ML", "cs.LG"], "comment": "14 pages, 8 figures", "summary": "Changepoint detection is a technique used to identify significant shifts in\nsequences and is widely used in fields such as finance, genomics, and medicine.\nTo identify the changepoints, dynamic programming (DP) algorithms, particularly\nOptimal Partitioning (OP) family, are widely used. To control the changepoints\ncount, these algorithms use a fixed penalty to penalize the changepoints\npresence. To predict the optimal value of that penalty, existing methods used\nsimple models such as linear or tree-based, which may limit predictive\nperformance. To address this issue, this study proposes using a multilayer\nperceptron (MLP) with a ReLU activation function to predict the penalty. The\nproposed model generates continuous predictions -- as opposed to the stepwise\nones in tree-based models -- and handles non-linearity better than linear\nmodels. Experiments on large benchmark genomic datasets demonstrate that the\nproposed model improves accuracy and F1 score compared to existing models.", "AI": {"tldr": "Proposes an MLP with ReLU activation for predicting changepoint penalties, outperforming linear and tree-based models in accuracy and F1 score.", "motivation": "Existing methods for predicting changepoint penalties use simple models (linear or tree-based), limiting performance.", "method": "Uses a multilayer perceptron (MLP) with ReLU activation to predict penalties, offering continuous predictions and better non-linearity handling.", "result": "Experiments on genomic datasets show improved accuracy and F1 score over existing models.", "conclusion": "MLP-based penalty prediction enhances changepoint detection performance compared to simpler models."}}
{"id": "2410.13148", "pdf": "https://arxiv.org/pdf/2410.13148", "abs": "https://arxiv.org/abs/2410.13148", "authors": ["Felix J. Yu", "Nicholas Kamp", "Carlos A. Arg\u00fcelles"], "title": "Learning Efficient Representations of Neutrino Telescope Events", "categories": ["physics.data-an", "astro-ph.IM", "cs.LG", "hep-ex"], "comment": "12 pages, 6 figures", "summary": "Neutrino telescopes detect rare interactions of particles produced in some of\nthe most extreme environments in the Universe. This is accomplished by\ninstrumenting a cubic-kilometer volume of naturally occurring transparent\nmedium with light sensors. Given their substantial size and the high frequency\nof background interactions, these telescopes amass an enormous quantity of\nlarge variance, high-dimensional data. These attributes create substantial\nchallenges for analyzing and reconstructing interactions, particularly when\nutilizing machine learning (ML) techniques. In this paper, we present a novel\napproach, called om2vec, that employs transformer-based variational\nautoencoders to efficiently represent neutrino telescope events by learning\ncompact and descriptive latent representations. We demonstrate that these\nlatent representations offer enhanced flexibility and improved computational\nefficiency, thereby facilitating downstream tasks in data analysis.", "AI": {"tldr": "The paper introduces om2vec, a transformer-based variational autoencoder method, to efficiently represent neutrino telescope data for improved analysis.", "motivation": "Neutrino telescopes generate vast, complex data, posing challenges for analysis, especially with ML techniques.", "method": "The proposed om2vec uses transformer-based variational autoencoders to learn compact latent representations of neutrino events.", "result": "The latent representations enhance flexibility and computational efficiency for downstream data analysis tasks.", "conclusion": "om2vec offers a promising solution for handling high-dimensional neutrino telescope data effectively."}}
{"id": "2411.02150", "pdf": "https://arxiv.org/pdf/2411.02150", "abs": "https://arxiv.org/abs/2411.02150", "authors": ["Ahmad Halimi Razlighi", "Maximilian H. V. Tillmann", "Edgar Beck", "Carsten Bockelmann", "Armin Dekorsy"], "title": "Cooperative and Collaborative Multi-Task Semantic Communication for Distributed Sources", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "comment": "Accepted, IEEE International Conference on Communication (ICC 2025)", "summary": "In this paper, we explore a multi-task semantic communication (SemCom) system\nfor distributed sources, extending the existing focus on collaborative\nsingle-task execution. We build on the cooperative multi-task processing\nintroduced in [1], which divides the encoder into a common unit (CU) and\nmultiple specific units (SUs). While earlier studies in multi-task SemCom\nfocused on full observation settings, our research explores a more realistic\ncase where only distributed partial observations are available, such as in a\nproduction line monitored by multiple sensing nodes. To address this, we\npropose an SemCom system that supports multi-task processing through\ncooperation on the transmitter side via split structure and collaboration on\nthe receiver side. We have used an information-theoretic perspective with\nvariational approximations for our end-to-end data-driven approach. Simulation\nresults demonstrate that the proposed cooperative and collaborative multi-task\n(CCMT) SemCom system significantly improves task execution accuracy,\nparticularly in complex datasets, if the noise introduced from the\ncommunication channel is not limiting the task performance too much. Our\nfindings contribute to a more general SemCom framework capable of handling\ndistributed sources and multiple tasks simultaneously, advancing the\napplicability of SemCom systems in real-world scenarios.", "AI": {"tldr": "The paper proposes a cooperative and collaborative multi-task semantic communication (CCMT SemCom) system for distributed sources, improving task accuracy in realistic partial observation settings.", "motivation": "Extending single-task semantic communication to multi-task scenarios with distributed partial observations, such as in production lines with multiple sensors.", "method": "Uses a split encoder structure (common unit and specific units) and receiver-side collaboration, analyzed via information theory and variational approximations.", "result": "Simulations show improved task execution accuracy, especially in complex datasets, unless channel noise severely limits performance.", "conclusion": "The CCMT SemCom system advances real-world applicability by handling distributed sources and multiple tasks simultaneously."}}
{"id": "2501.04009", "pdf": "https://arxiv.org/pdf/2501.04009", "abs": "https://arxiv.org/abs/2501.04009", "authors": ["Mario Refoyo", "David Luengo"], "title": "Multi-SpaCE: Multi-Objective Subsequence-based Sparse Counterfactual Explanations for Multivariate Time Series Classification", "categories": ["cs.NE", "cs.LG", "stat.ML"], "comment": null, "summary": "Deep Learning systems excel in complex tasks but often lack transparency,\nlimiting their use in critical applications. Counterfactual explanations, a\ncore tool within eXplainable Artificial Intelligence (XAI), offer insights into\nmodel decisions by identifying minimal changes to an input to alter its\npredicted outcome. However, existing methods for time series data are limited\nby univariate assumptions, rigid constraints on modifications, or lack of\nvalidity guarantees. This paper introduces Multi-SpaCE, a multi-objective\ncounterfactual explanation method for multivariate time series. Using\nnon-dominated ranking genetic algorithm II (NSGA-II), Multi-SpaCE balances\nproximity, sparsity, plausibility, and contiguity. Unlike most methods, it\nensures perfect validity, supports multivariate data and provides a Pareto\nfront of solutions, enabling flexibility to different end-user needs.\nComprehensive experiments in diverse datasets demonstrate the ability of\nMulti-SpaCE to consistently achieve perfect validity and deliver superior\nperformance compared to existing methods.", "AI": {"tldr": "Multi-SpaCE introduces a multi-objective counterfactual explanation method for multivariate time series, ensuring validity and flexibility.", "motivation": "Deep Learning lacks transparency, limiting critical applications. Existing counterfactual methods for time series are constrained by univariate assumptions or lack validity.", "method": "Uses NSGA-II to balance proximity, sparsity, plausibility, and contiguity, ensuring perfect validity and supporting multivariate data.", "result": "Achieves perfect validity and outperforms existing methods in diverse datasets.", "conclusion": "Multi-SpaCE provides a robust, flexible solution for counterfactual explanations in multivariate time series."}}
{"id": "2501.04179", "pdf": "https://arxiv.org/pdf/2501.04179", "abs": "https://arxiv.org/abs/2501.04179", "authors": ["Ananth Raman", "Vinod Raman"], "title": "Generation from Noisy Examples", "categories": ["stat.ML", "cs.LG"], "comment": "15 pages. Accepted to ICML 2025", "summary": "We continue to study the learning-theoretic foundations of generation by\nextending the results from Kleinberg and Mullainathan [2024] and Li et al.\n[2024] to account for noisy example streams. In the noiseless setting of\nKleinberg and Mullainathan [2024] and Li et al. [2024], an adversary picks a\nhypothesis from a binary hypothesis class and provides a generator with a\nsequence of its positive examples. The goal of the generator is to eventually\noutput new, unseen positive examples. In the noisy setting, an adversary still\npicks a hypothesis and a sequence of its positive examples. But, before\npresenting the stream to the generator, the adversary inserts a finite number\nof negative examples. Unaware of which examples are noisy, the goal of the\ngenerator is to still eventually output new, unseen positive examples. In this\npaper, we provide necessary and sufficient conditions for when a binary\nhypothesis class can be noisily generatable. We provide such conditions with\nrespect to various constraints on the number of distinct examples that need to\nbe seen before perfect generation of positive examples. Interestingly, for\nfinite and countable classes we show that generatability is largely unaffected\nby the presence of a finite number of noisy examples.", "AI": {"tldr": "The paper extends prior work on learning-theoretic foundations of generation to noisy example streams, providing conditions for noisy generatability in binary hypothesis classes.", "motivation": "To understand how noisy example streams affect the generatability of hypotheses, building on noiseless settings studied earlier.", "method": "Extends noiseless generation frameworks to noisy settings, analyzing conditions for generatability with finite noisy examples.", "result": "For finite and countable classes, generatability remains largely unaffected by finite noise. Necessary and sufficient conditions for noisy generatability are provided.", "conclusion": "Noisy generatability is feasible under certain conditions, with finite noise having minimal impact on finite and countable hypothesis classes."}}
{"id": "2502.01583", "pdf": "https://arxiv.org/pdf/2502.01583", "abs": "https://arxiv.org/abs/2502.01583", "authors": ["Filip Kova\u010devi\u0107", "Yihan Zhang", "Marco Mondelli"], "title": "Spectral Estimators for Multi-Index Models: Precise Asymptotics and Optimal Weak Recovery", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.PR", "math.ST", "stat.TH"], "comment": "Accepted to COLT 2025", "summary": "Multi-index models provide a popular framework to investigate the\nlearnability of functions with low-dimensional structure and, also due to their\nconnections with neural networks, they have been object of recent intensive\nstudy. In this paper, we focus on recovering the subspace spanned by the\nsignals via spectral estimators -- a family of methods routinely used in\npractice, often as a warm-start for iterative algorithms. Our main technical\ncontribution is a precise asymptotic characterization of the performance of\nspectral methods, when sample size and input dimension grow proportionally and\nthe dimension $p$ of the space to recover is fixed. Specifically, we locate the\ntop-$p$ eigenvalues of the spectral matrix and establish the overlaps between\nthe corresponding eigenvectors (which give the spectral estimators) and a basis\nof the signal subspace. Our analysis unveils a phase transition phenomenon in\nwhich, as the sample complexity grows, eigenvalues escape from the bulk of the\nspectrum and, when that happens, eigenvectors recover directions of the desired\nsubspace. The precise characterization we put forward enables the optimization\nof the data preprocessing, thus allowing to identify the spectral estimator\nthat requires the minimal sample size for weak recovery.", "AI": {"tldr": "The paper analyzes spectral methods for recovering signal subspaces in multi-index models, revealing a phase transition in performance and optimizing preprocessing for minimal sample size.", "motivation": "To understand the learnability of functions with low-dimensional structure and improve spectral methods for subspace recovery in multi-index models.", "method": "Uses spectral estimators to recover signal subspaces, analyzing their asymptotic performance with fixed subspace dimension and proportional sample size and input dimension.", "result": "Identifies a phase transition where eigenvalues escape the bulk spectrum, enabling weak recovery of the subspace. Optimizes preprocessing for minimal sample size.", "conclusion": "Spectral methods can efficiently recover signal subspaces with optimized preprocessing, validated by precise asymptotic analysis."}}
{"id": "2502.05122", "pdf": "https://arxiv.org/pdf/2502.05122", "abs": "https://arxiv.org/abs/2502.05122", "authors": ["Johnny Xi", "Hugh Dance", "Peter Orbanz", "Benjamin Bloem-Reddy"], "title": "Distinguishing Cause from Effect with Causal Velocity Models", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "ICML 2025", "summary": "Bivariate structural causal models (SCM) are often used to infer causal\ndirection by examining their goodness-of-fit under restricted model classes. In\nthis paper, we describe a parametrization of bivariate SCMs in terms of a\ncausal velocity by viewing the cause variable as time in a dynamical system.\nThe velocity implicitly defines counterfactual curves via the solution of\ninitial value problems where the observation specifies the initial condition.\nUsing tools from measure transport, we obtain a unique correspondence between\nSCMs and the score function of the generated distribution via its causal\nvelocity. Based on this, we derive an objective function that directly\nregresses the velocity against the score function, the latter of which can be\nestimated non-parametrically from observational data. We use this to develop a\nmethod for bivariate causal discovery that extends beyond known model classes\nsuch as additive or location scale noise, and that requires no assumptions on\nthe noise distributions. When the score is estimated well, the objective is\nalso useful for detecting model non-identifiability and misspecification. We\npresent positive results in simulation and benchmark experiments where many\nexisting methods fail, and perform ablation studies to examine the method's\nsensitivity to accurate score estimation.", "AI": {"tldr": "The paper introduces a novel parametrization of bivariate SCMs using causal velocity, linking it to dynamical systems and measure transport for causal discovery without restrictive noise assumptions.", "motivation": "To extend causal discovery beyond known model classes (e.g., additive noise) and relax assumptions on noise distributions.", "method": "Parametrizes SCMs via causal velocity, connects it to score functions using measure transport, and derives an objective function for causal discovery.", "result": "Demonstrates success in simulations and benchmarks where other methods fail, and highlights utility for detecting non-identifiability/misspecification.", "conclusion": "The approach is effective for bivariate causal discovery, even in challenging scenarios, and relies on accurate score estimation."}}
{"id": "2502.06995", "pdf": "https://arxiv.org/pdf/2502.06995", "abs": "https://arxiv.org/abs/2502.06995", "authors": ["Luben M. C. Cabezas", "Vagner S. Santos", "Thiago R. Ramos", "Rafael Izbicki"], "title": "Epistemic Uncertainty in Conformal Scores: A Unified Approach", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Conformal prediction methods create prediction bands with distribution-free\nguarantees but do not explicitly capture epistemic uncertainty, which can lead\nto overconfident predictions in data-sparse regions. Although recent conformal\nscores have been developed to address this limitation, they are typically\ndesigned for specific tasks, such as regression or quantile regression.\nMoreover, they rely on particular modeling choices for epistemic uncertainty,\nrestricting their applicability. We introduce $\\texttt{EPICSCORE}$, a\nmodel-agnostic approach that enhances any conformal score by explicitly\nintegrating epistemic uncertainty. Leveraging Bayesian techniques such as\nGaussian Processes, Monte Carlo Dropout, or Bayesian Additive Regression Trees,\n$\\texttt{EPICSCORE}$ adaptively expands predictive intervals in regions with\nlimited data while maintaining compact intervals where data is abundant. As\nwith any conformal method, it preserves finite-sample marginal coverage.\nAdditionally, it also achieves asymptotic conditional coverage. Experiments\ndemonstrate its good performance compared to existing methods. Designed for\ncompatibility with any Bayesian model, but equipped with distribution-free\nguarantees, $\\texttt{EPICSCORE}$ provides a general-purpose framework for\nuncertainty quantification in prediction problems.", "AI": {"tldr": "EPICSCORE enhances conformal prediction by integrating epistemic uncertainty, providing adaptive prediction intervals with distribution-free guarantees.", "motivation": "Existing conformal prediction methods lack explicit handling of epistemic uncertainty, leading to overconfidence in data-sparse regions. EPICSCORE addresses this limitation.", "method": "EPICSCORE integrates Bayesian techniques (e.g., Gaussian Processes, Monte Carlo Dropout) to adaptively adjust prediction intervals based on data density, while maintaining conformal guarantees.", "result": "EPICSCORE achieves finite-sample marginal coverage and asymptotic conditional coverage, outperforming existing methods in experiments.", "conclusion": "EPICSCORE offers a model-agnostic, general-purpose framework for uncertainty quantification in prediction tasks."}}
{"id": "2502.09395", "pdf": "https://arxiv.org/pdf/2502.09395", "abs": "https://arxiv.org/abs/2502.09395", "authors": ["Jaime Maldonado", "Jonas Krumme", "Christoph Zetzsche", "Vanessa Didelez", "Kerstin Schill"], "title": "Robot Pouring: Identifying Causes of Spillage and Selecting Alternative Action Parameters Using Probabilistic Actual Causation", "categories": ["cs.RO", "cs.LG"], "comment": "20 pages, 13 figures", "summary": "In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a\nlarge variety of objects and goals. When confronted with an unexpected or\nunwanted outcome, we take corrective actions and try again until achieving the\ndesired result. The reasoning performed to identify a cause of the observed\noutcome and to select an appropriate corrective action is a crucial aspect of\nhuman reasoning for successful task execution. Central to this reasoning is the\nassumption that a factor is responsible for producing the observed outcome. In\nthis paper, we investigate the use of probabilistic actual causation to\ndetermine whether a factor is the cause of an observed undesired outcome.\nFurthermore, we show how the actual causation probabilities can be used to find\nalternative actions to change the outcome. We apply the probabilistic actual\ncausation analysis to a robot pouring task. When spillage occurs, the analysis\nindicates whether a task parameter is the cause and how it should be changed to\navoid spillage. The analysis requires a causal graph of the task and the\ncorresponding conditional probability distributions. To fulfill these\nrequirements, we perform a complete causal modeling procedure (i.e., task\nanalysis, definition of variables, determination of the causal graph structure,\nand estimation of conditional probability distributions) using data from a\nrealistic simulation of the robot pouring task, covering a large combinatorial\nspace of task parameters. Based on the results, we discuss the implications of\nthe variables' representation and how the alternative actions suggested by the\nactual causation analysis would compare to the alternative solutions proposed\nby a human observer. The practical use of the analysis of probabilistic actual\ncausation to select alternative action parameters is demonstrated.", "AI": {"tldr": "The paper explores probabilistic actual causation to identify causes of undesired outcomes in tasks and suggests corrective actions, demonstrated in a robot pouring task.", "motivation": "Human reasoning involves identifying causes of unexpected outcomes and taking corrective actions. The paper aims to formalize this using probabilistic actual causation.", "method": "Uses probabilistic actual causation analysis with causal graphs and conditional probability distributions, applied to a robot pouring task via simulation.", "result": "The analysis identifies causes of spillage and suggests alternative actions, comparing them to human-proposed solutions.", "conclusion": "Probabilistic actual causation is practical for selecting corrective actions, with implications for variable representation and human-like reasoning."}}
{"id": "2502.13961", "pdf": "https://arxiv.org/pdf/2502.13961", "abs": "https://arxiv.org/abs/2502.13961", "authors": ["Yatin Dandi", "Luca Pesce", "Lenka Zdeborov\u00e1", "Florent Krzakala"], "title": "The Computational Advantage of Depth: Learning High-Dimensional Hierarchical Functions with Gradient Descent", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Understanding the advantages of deep neural networks trained by gradient\ndescent (GD) compared to shallow models remains an open theoretical challenge.\nIn this paper, we introduce a class of target functions (single and multi-index\nGaussian hierarchical targets) that incorporate a hierarchy of latent subspace\ndimensionalities. This framework enables us to analytically study the learning\ndynamics and generalization performance of deep networks compared to shallow\nones in the high-dimensional limit. Specifically, our main theorem shows that\nfeature learning with GD successively reduces the effective dimensionality,\ntransforming a high-dimensional problem into a sequence of lower-dimensional\nones. This enables learning the target function with drastically less samples\nthan with shallow networks. While the results are proven in a controlled\ntraining setting, we also discuss more common training procedures and argue\nthat they learn through the same mechanisms.", "AI": {"tldr": "Deep networks trained by GD learn hierarchical targets more efficiently than shallow networks by reducing dimensionality progressively.", "motivation": "To understand why deep networks outperform shallow ones when trained by gradient descent.", "method": "Analytical study using Gaussian hierarchical targets to compare learning dynamics and generalization of deep vs. shallow networks.", "result": "Deep networks reduce dimensionality step-by-step, requiring fewer samples to learn the target function.", "conclusion": "Deep networks' hierarchical learning mechanism is key to their efficiency, even in common training settings."}}
{"id": "2503.13352", "pdf": "https://arxiv.org/pdf/2503.13352", "abs": "https://arxiv.org/abs/2503.13352", "authors": ["Ewan R. S. Wallace", "Nathan C. Frey", "Joshua A. Rackers"], "title": "Strain Problems got you in a Twist? Try StrainRelief: A Quantum-Accurate Tool for Ligand Strain Calculations", "categories": ["physics.chem-ph", "cs.LG"], "comment": null, "summary": "Ligand strain energy, the energy difference between the bound and unbound\nconformations of a ligand, is an important component of structure-based small\nmolecule drug design. A large majority of observed ligands in protein-small\nmolecule co-crystal structures bind in low-strain conformations, making strain\nenergy a useful filter for structure-based drug design. In this work we present\na tool for calculating ligand strain with a high accuracy. StrainRelief uses a\nMACE Neural Network Potential (NNP), trained on a large database of Density\nFunctional Theory (DFT) calculations to estimate ligand strain of neutral\nmolecules with quantum accuracy. We show that this tool estimates strain energy\ndifferences relative to DFT to within 1.4 kcal/mol, more accurately than\nalternative NNPs. These results highlight the utility of NNPs in drug\ndiscovery, and provide a useful tool for drug discovery teams.", "AI": {"tldr": "A tool called StrainRelief uses a MACE Neural Network Potential to accurately calculate ligand strain energy, aiding drug design.", "motivation": "Ligand strain energy is crucial in drug design, but existing methods lack accuracy. This work aims to provide a high-accuracy tool.", "method": "StrainRelief employs a MACE Neural Network Potential trained on DFT calculations to estimate ligand strain with quantum accuracy.", "result": "The tool achieves strain energy estimates within 1.4 kcal/mol of DFT, outperforming other NNPs.", "conclusion": "StrainRelief is a valuable tool for drug discovery, demonstrating the potential of NNPs in the field."}}
{"id": "2504.07996", "pdf": "https://arxiv.org/pdf/2504.07996", "abs": "https://arxiv.org/abs/2504.07996", "authors": ["Junlang Huang", "Hao Chen", "Li Luo", "Yong Cai", "Lexin Zhang", "Tianhao Ma", "Yitian Zhang", "Zhong Guan"], "title": "Fusing Global and Local: Transformer-CNN Synergy for Next-Gen Current Estimation", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "This paper presents a hybrid model combining Transformer and CNN for\npredicting the current waveform in signal lines. Unlike traditional approaches\nsuch as current source models, driver linear representations, waveform\nfunctional fitting, or equivalent load capacitance methods, our model does not\nrely on fixed simplified models of standard-cell drivers or RC loads. Instead,\nit replaces the complex Newton iteration process used in traditional SPICE\nsimulations, leveraging the powerful sequence modeling capabilities of the\nTransformer framework to directly predict current responses without iterative\nsolving steps. The hybrid architecture effectively integrates the global\nfeature-capturing ability of Transformers with the local feature extraction\nadvantages of CNNs, significantly improving the accuracy of current waveform\npredictions. Experimental results demonstrate that, compared to traditional\nSPICE simulations, the proposed algorithm achieves an error of only 0.0098.\nThese results highlight the algorithm's superior capabilities in predicting\nsignal line current waveforms, timing analysis, and power evaluation, making it\nsuitable for a wide range of technology nodes, from 40nm to 3nm.", "AI": {"tldr": "A hybrid Transformer-CNN model predicts signal line current waveforms more accurately than traditional methods, avoiding iterative SPICE simulations.", "motivation": "Traditional methods rely on simplified models or iterative processes, which limit accuracy and efficiency. This paper aims to improve waveform prediction.", "method": "Combines Transformer for sequence modeling and CNN for local feature extraction, eliminating the need for iterative solving.", "result": "Achieves an error of only 0.0098, outperforming SPICE simulations.", "conclusion": "The hybrid model is highly accurate and scalable across technology nodes (40nm to 3nm), useful for timing and power analysis."}}
{"id": "2504.17656", "pdf": "https://arxiv.org/pdf/2504.17656", "abs": "https://arxiv.org/abs/2504.17656", "authors": ["Ayush Jain", "Rampi Ramprasad"], "title": "polyGen: A Learning Framework for Atomic-level Polymer Structure Generation", "categories": ["cs.CE", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Synthetic polymeric materials underpin fundamental technologies in the\nenergy, electronics, consumer goods, and medical sectors, yet their development\nstill suffers from prolonged design timelines. Although polymer informatics\ntools have supported speedup, polymer simulation protocols continue to face\nsignificant challenges in the on-demand generation of realistic 3D atomic\nstructures that respect the conformational diversity of polymers. Generative\nalgorithms for 3D structures of inorganic crystals, bio-polymers, and small\nmolecules exist, but have not addressed synthetic polymers because of\nchallenges in representation and dataset constraints. In this work, we\nintroduce polyGen, the first generative model designed specifically for polymer\nstructures from minimal inputs such as the repeat unit chemistry alone. polyGen\ncombines graph-based encodings with a latent diffusion transformer using\npositional biased attention for realistic conformation generation. Given the\nlimited dataset of 3,855 DFT-optimized polymer structures, we incorporate joint\ntraining with small molecule data to enhance generation quality. We also\nestablish structure matching criteria to benchmark our approach on this novel\nproblem. polyGen overcomes the limitations of traditional crystal structure\nprediction methods for polymers, successfully generating realistic and diverse\nlinear and branched conformations, with promising performance even on\nchallenging large repeat units. As the first atomic-level proof-of-concept\ncapturing intrinsic polymer flexibility, it marks a new capability in material\nstructure generation.", "AI": {"tldr": "polyGen is a generative model for creating realistic 3D polymer structures from minimal inputs, overcoming dataset and representation challenges.", "motivation": "Current polymer simulation protocols struggle with generating diverse and realistic 3D atomic structures, hindering rapid material development.", "method": "polyGen uses graph-based encodings and a latent diffusion transformer with positional biased attention, trained on limited polymer and small molecule data.", "result": "The model successfully generates diverse and realistic polymer conformations, even for large repeat units, outperforming traditional methods.", "conclusion": "polyGen represents a breakthrough in polymer structure generation, offering a new tool for accelerated material design."}}
{"id": "2505.04255", "pdf": "https://arxiv.org/pdf/2505.04255", "abs": "https://arxiv.org/abs/2505.04255", "authors": ["Nay Klaimi", "Amira Bedoui", "Cl\u00e9ment Elvira", "Philippe Mary", "Luc Le Magoarou"], "title": "Model-based learning for joint channel estimationand hybrid MIMO precoding", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Hybrid precoding is a key ingredient of cost-effective massive multiple-input\nmultiple-output transceivers. However, setting jointly digital and analog\nprecoders to optimally serve multiple users is a difficult optimization\nproblem. Moreover, it relies heavily on precise knowledge of the channels,\nwhich is difficult to obtain, especially when considering realistic systems\ncomprising hardware impairments. In this paper, a joint channel estimation and\nhybrid precoding method is proposed, which consists in an end-to-end\narchitecture taking received pilots as inputs and outputting pre-coders. The\nresulting neural network is fully model-based, making it lightweight and\ninterpretable with very few learnable parameters. The channel estimation step\nis performed using the unfolded matching pursuit algorithm, accounting for\nimperfect knowledge of the antenna system, while the precoding step is done via\nunfolded projected gradient ascent. The great potential of the proposed method\nis empirically demonstrated on realistic synthetic channels.", "AI": {"tldr": "A lightweight, interpretable neural network method for joint channel estimation and hybrid precoding in massive MIMO systems, addressing hardware impairments.", "motivation": "Hybrid precoding in massive MIMO is complex and relies on precise channel knowledge, which is hard to obtain in realistic systems with hardware impairments.", "method": "End-to-end neural network architecture using unfolded matching pursuit for channel estimation and unfolded projected gradient ascent for precoding.", "result": "Demonstrated effectiveness on realistic synthetic channels.", "conclusion": "The proposed method offers a practical solution for joint channel estimation and hybrid precoding in impaired systems."}}
{"id": "2505.08698", "pdf": "https://arxiv.org/pdf/2505.08698", "abs": "https://arxiv.org/abs/2505.08698", "authors": ["Antonio \u00c1lvarez-L\u00f3pez", "Marcos Matabuena"], "title": "Continuous Temporal Learning of Probability Distributions via Neural ODEs with Applications in Continuous Glucose Monitoring Data", "categories": ["stat.ML", "cs.LG", "math.DS", "stat.AP", "stat.ME"], "comment": null, "summary": "Modeling the dynamics of probability distributions from time-dependent data\nsamples is a fundamental problem in many fields, including digital health. The\ngoal is to analyze how the distribution of a biomarker, such as glucose,\nchanges over time and how these changes may reflect the progression of chronic\ndiseases like diabetes. We introduce a probabilistic model based on a Gaussian\nmixture that captures the evolution of a continuous-time stochastic process.\nOur approach combines a non-parametric estimate of the distribution, obtained\nwith Maximum Mean Discrepancy (MMD), and a Neural Ordinary Differential\nEquation (Neural ODE) that governs the temporal evolution of the mixture\nweights. The model is highly interpretable, detects subtle distribution shifts,\nand remains computationally efficient. Simulation studies show that our method\nmatches or surpasses the estimation accuracy of state-of-the-art, less\ninterpretable techniques such as normalizing flows and non-parametric kernel\ndensity estimators. We further demonstrate its utility using data from a\ndigital clinical trial, revealing how interventions affect the time-dependent\ndistribution of glucose levels. The proposed method enables rigorous\ncomparisons between control and treatment groups from both mathematical and\nclinical perspectives, offering novel longitudinal characterizations that\nexisting approaches cannot achieve.", "AI": {"tldr": "A probabilistic model using Gaussian mixtures and Neural ODEs is introduced to analyze time-dependent biomarker distributions, outperforming state-of-the-art methods in accuracy and interpretability.", "motivation": "To track biomarker distribution changes (e.g., glucose) over time for chronic disease progression analysis, like diabetes.", "method": "Combines non-parametric MMD for distribution estimation with Neural ODEs for temporal evolution of mixture weights.", "result": "Outperforms state-of-the-art methods (e.g., normalizing flows) in accuracy, detects subtle shifts, and remains efficient.", "conclusion": "Enables rigorous comparisons in clinical trials, offering novel insights into biomarker dynamics."}}
{"id": "2505.17836", "pdf": "https://arxiv.org/pdf/2505.17836", "abs": "https://arxiv.org/abs/2505.17836", "authors": ["Anna Van Elst", "Igor Colin", "Stephan Cl\u00e9men\u00e7on"], "title": "Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": null, "summary": "This paper addresses the problem of robust estimation in gossip algorithms\nover arbitrary communication graphs. Gossip algorithms are fully decentralized,\nrelying only on local neighbor-to-neighbor communication, making them\nwell-suited for situations where communication is constrained. A fundamental\nchallenge in existing mean-based gossip algorithms is their vulnerability to\nmalicious or corrupted nodes. In this paper, we show that an outlier-robust\nmean can be computed by globally estimating a robust statistic. More\nspecifically, we propose a novel gossip algorithm for rank estimation, referred\nto as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated\nto trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed\ndescription of the proposed methods, a key contribution of our work is a\nprecise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank\nestimation and an $\\mathcal{O}((\\log t)/\\sqrt{t})$ rate for trimmed mean\nestimation, where by $t$ is meant the number of iterations. Moreover, we\nprovide a breakdown point analysis of \\textsc{GoTrim}. We empirically validate\nour theoretical results through experiments on diverse network topologies, data\ndistributions and contamination schemes.", "AI": {"tldr": "The paper introduces robust gossip algorithms, GoRank and GoTrim, for outlier-resistant mean estimation in decentralized networks, with proven convergence rates and empirical validation.", "motivation": "Existing gossip algorithms are vulnerable to malicious nodes, prompting the need for robust decentralized estimation methods.", "method": "Proposes GoRank for rank estimation and GoTrim for trimmed mean estimation, leveraging local neighbor communication.", "result": "Achieves O(1/t) convergence for rank estimation and O((log t)/\u221at) for trimmed mean estimation, with empirical validation.", "conclusion": "The proposed methods effectively address robustness in gossip algorithms, with theoretical and empirical support."}}
{"id": "2506.04354", "pdf": "https://arxiv.org/pdf/2506.04354", "abs": "https://arxiv.org/abs/2506.04354", "authors": ["Elmira Mirzabeigi", "Rezvan Salehi", "Kourosh Parand"], "title": "BridgeNet: A Hybrid, Physics-Informed Machine Learning Framework for Solving High-Dimensional Fokker-Planck Equations", "categories": ["physics.comp-ph", "cs.LG", "math-ph", "math.AP", "math.MP"], "comment": null, "summary": "BridgeNet is a novel hybrid framework that integrates convolutional neural\nnetworks with physics-informed neural networks to efficiently solve non-linear,\nhigh-dimensional Fokker-Planck equations (FPEs). Traditional PINNs, which\ntypically rely on fully connected architectures, often struggle to capture\ncomplex spatial hierarchies and enforce intricate boundary conditions. In\ncontrast, BridgeNet leverages adaptive CNN layers for effective local feature\nextraction and incorporates a dynamically weighted loss function that\nrigorously enforces physical constraints. Extensive numerical experiments\nacross various test cases demonstrate that BridgeNet not only achieves\nsignificantly lower error metrics and faster convergence compared to\nconventional PINN approaches but also maintains robust stability in\nhigh-dimensional settings. This work represents a substantial advancement in\ncomputational physics, offering a scalable and accurate solution methodology\nwith promising applications in fields ranging from financial mathematics to\ncomplex system dynamics.", "AI": {"tldr": "BridgeNet combines CNNs and PINNs to solve Fokker-Planck equations more efficiently than traditional PINNs, achieving lower errors and faster convergence.", "motivation": "Traditional PINNs struggle with complex spatial hierarchies and boundary conditions, prompting the need for a hybrid approach.", "method": "BridgeNet uses adaptive CNN layers for local feature extraction and a dynamically weighted loss function to enforce physical constraints.", "result": "BridgeNet outperforms conventional PINNs in error metrics, convergence speed, and stability in high-dimensional settings.", "conclusion": "BridgeNet advances computational physics with a scalable, accurate method applicable to fields like finance and system dynamics."}}
{"id": "2506.06072", "pdf": "https://arxiv.org/pdf/2506.06072", "abs": "https://arxiv.org/abs/2506.06072", "authors": ["Hongyi Zhou", "Weiran Liao", "Xi Huang", "Yucheng Tang", "Fabian Otto", "Xiaogang Jia", "Xinkai Jiang", "Simon Hilber", "Ge Li", "Qian Wang", "\u00d6mer Erdin\u00e7 Ya\u011fmurlu", "Nils Blank", "Moritz Reuss", "Rudolf Lioutikov"], "title": "BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We present the B-spline Encoded Action Sequence Tokenizer (BEAST), a novel\naction tokenizer that encodes action sequences into compact discrete or\ncontinuous tokens using B-splines. In contrast to existing action tokenizers\nbased on vector quantization or byte pair encoding, BEAST requires no separate\ntokenizer training and consistently produces tokens of uniform length, enabling\nfast action sequence generation via parallel decoding. Leveraging our B-spline\nformulation, BEAST inherently ensures generating smooth trajectories without\ndiscontinuities between adjacent segments. We extensively evaluate BEAST by\nintegrating it with three distinct model architectures: a Variational\nAutoencoder (VAE) with continuous tokens, a decoder-only Transformer with\ndiscrete tokens, and Florence-2, a pretrained Vision-Language Model with an\nencoder-decoder architecture, demonstrating BEAST's compatibility and\nscalability with large pretrained models. We evaluate BEAST across three\nestablished benchmarks consisting of 166 simulated tasks and on three distinct\nrobot settings with a total of 8 real-world tasks. Experimental results\ndemonstrate that BEAST (i) significantly reduces both training and inference\ncomputational costs, and (ii) consistently generates smooth, high-frequency\ncontrol signals suitable for continuous control tasks while (iii) reliably\nachieves competitive task success rates compared to state-of-the-art methods.", "AI": {"tldr": "BEAST is a novel action tokenizer using B-splines for encoding action sequences into compact tokens, enabling fast parallel decoding and smooth trajectory generation without separate tokenizer training.", "motivation": "Existing action tokenizers require separate training and produce non-uniform tokens, leading to inefficiencies and discontinuities in action sequences. BEAST addresses these limitations.", "method": "BEAST encodes action sequences into discrete or continuous tokens using B-splines, ensuring uniform token length and smooth trajectories. It integrates with VAE, Transformer, and Florence-2 models for evaluation.", "result": "BEAST reduces computational costs, generates smooth control signals, and achieves competitive task success rates across 166 simulated and 8 real-world tasks.", "conclusion": "BEAST is a scalable, efficient, and high-performing action tokenizer compatible with large pretrained models, outperforming state-of-the-art methods."}}
{"id": "2506.06221", "pdf": "https://arxiv.org/pdf/2506.06221", "abs": "https://arxiv.org/abs/2506.06221", "authors": ["Yan Shen", "Ruihai Wu", "Yubin Ke", "Xinyuan Song", "Zeyi Li", "Xiaoqi Li", "Hongwei Fan", "Haoran Lu", "Hao dong"], "title": "BiAssemble: Learning Collaborative Affordance for Bimanual Geometric Assembly", "categories": ["cs.RO", "cs.LG"], "comment": "ICML 2025", "summary": "Shape assembly, the process of combining parts into a complete whole, is a\ncrucial robotic skill with broad real-world applications. Among various\nassembly tasks, geometric assembly--where broken parts are reassembled into\ntheir original form (e.g., reconstructing a shattered bowl)--is particularly\nchallenging. This requires the robot to recognize geometric cues for grasping,\nassembly, and subsequent bimanual collaborative manipulation on varied\nfragments. In this paper, we exploit the geometric generalization of\npoint-level affordance, learning affordance aware of bimanual collaboration in\ngeometric assembly with long-horizon action sequences. To address the\nevaluation ambiguity caused by geometry diversity of broken parts, we introduce\na real-world benchmark featuring geometric variety and global reproducibility.\nExtensive experiments demonstrate the superiority of our approach over both\nprevious affordance-based and imitation-based methods. Project page:\nhttps://sites.google.com/view/biassembly/.", "AI": {"tldr": "The paper introduces a method for geometric assembly in robotics, focusing on bimanual collaboration and point-level affordance learning, validated by a real-world benchmark.", "motivation": "Geometric assembly is challenging due to the need for recognizing geometric cues and handling diverse fragments, motivating the development of a robust robotic skill.", "method": "The approach leverages point-level affordance learning for bimanual collaboration, addressing long-horizon action sequences and geometric diversity.", "result": "The method outperforms previous affordance-based and imitation-based techniques, as shown in extensive experiments.", "conclusion": "The proposed approach advances geometric assembly in robotics, with potential real-world applications."}}
{"id": "2506.07859", "pdf": "https://arxiv.org/pdf/2506.07859", "abs": "https://arxiv.org/abs/2506.07859", "authors": ["Amanuel Anteneh", "L\u00e9andre Brunel", "Carlos Gonz\u00e1lez-Arciniegas", "Olivier Pfister"], "title": "Deep reinforcement learning for near-deterministic preparation of cubic- and quartic-phase gates in photonic quantum computing", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Cubic-phase states are a sufficient resource for universal quantum computing\nover continuous variables. We present results from numerical experiments in\nwhich deep neural networks are trained via reinforcement learning to control a\nquantum optical circuit for generating cubic-phase states, with an average\nsuccess rate of 96%. The only non-Gaussian resource required is\nphoton-number-resolving measurements. We also show that the exact same\nresources enable the direct generation of a quartic-phase gate, with no need\nfor a cubic gate decomposition.", "AI": {"tldr": "Deep neural networks trained via reinforcement learning achieve 96% success in generating cubic-phase states for quantum computing, using photon-number-resolving measurements. The same setup also directly produces quartic-phase gates.", "motivation": "To enable universal quantum computing over continuous variables by efficiently generating non-Gaussian cubic-phase states.", "method": "Deep neural networks trained with reinforcement learning to control a quantum optical circuit, utilizing photon-number-resolving measurements.", "result": "Achieved a 96% success rate in generating cubic-phase states and demonstrated direct quartic-phase gate generation.", "conclusion": "The approach efficiently generates non-Gaussian states and gates, advancing continuous-variable quantum computing."}}
