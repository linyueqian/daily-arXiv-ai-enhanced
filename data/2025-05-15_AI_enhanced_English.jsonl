{"id": "2505.08828", "pdf": "https://arxiv.org/pdf/2505.08828", "abs": "https://arxiv.org/abs/2505.08828", "authors": ["Eduardo Araujo Oliveira", "Madhavi Mohoni", "Sonsoles L\u00f3pez-Pernas", "Mohammed Saqr"], "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "19 pages, 10 figures, 11 tables", "summary": "As human-AI collaboration becomes increasingly prevalent in educational\ncontexts, understanding and measuring the extent and nature of such\ninteractions pose significant challenges. This research investigates the use of\nauthorship verification (AV) techniques not as a punitive measure, but as a\nmeans to quantify AI assistance in academic writing, with a focus on promoting\ntransparency, interpretability, and student development. Building on prior\nwork, we structured our investigation into three stages: dataset selection and\nexpansion, AV method development, and systematic evaluation. Using three\ndatasets - including a public dataset (PAN-14) and two from University of\nMelbourne students from various courses - we expanded the data to include\nLLM-generated texts, totalling 1,889 documents and 540 authorship problems from\n506 students. We developed an adapted Feature Vector Difference AV methodology\nto construct robust academic writing profiles for students, designed to capture\nmeaningful, individual characteristics of their writing. The method's\neffectiveness was evaluated across multiple scenarios, including distinguishing\nbetween student-authored and LLM-generated texts and testing resilience against\nLLMs' attempts to mimic student writing styles. Results demonstrate the\nenhanced AV classifier's ability to identify stylometric discrepancies and\nmeasure human-AI collaboration at word and sentence levels while providing\neducators with a transparent tool to support academic integrity investigations.\nThis work advances AV technology, offering actionable insights into the\ndynamics of academic writing in an AI-driven era.", "AI": {"tldr": "The paper explores using authorship verification (AV) to measure AI assistance in academic writing, promoting transparency and student development. It develops an adapted AV method, tests it on expanded datasets, and demonstrates its effectiveness in distinguishing human-AI collaboration.", "motivation": "To address challenges in measuring human-AI collaboration in education, focusing on transparency, interpretability, and student growth rather than punitive measures.", "method": "Three-stage approach: dataset selection/expansion (including LLM-generated texts), AV method development (Feature Vector Difference), and systematic evaluation across scenarios.", "result": "The AV classifier effectively identifies stylometric discrepancies, measures human-AI collaboration, and aids educators in academic integrity investigations.", "conclusion": "The work advances AV technology, providing insights into AI-driven academic writing dynamics and supporting ethical AI use in education."}}
{"id": "2505.08891", "pdf": "https://arxiv.org/pdf/2505.08891", "abs": "https://arxiv.org/abs/2505.08891", "authors": ["Daeun Hwang", "Samuel Shields", "Alex Calderwood", "Shi Johnson-Bey", "Michael Mateas", "Noah Wardrip-Fruin", "Edward F. Melcer"], "title": "Clicking some of the silly options: Exploring Player Motivation in Static and Dynamic Educational Interactive Narratives", "categories": ["cs.CL"], "comment": "8 pages, 3 figures, 1 table, 1 appendix. Workshop paper, CHI 2025\n  Augmented Educators and AI", "summary": "Motivation is an important factor underlying successful learning. Previous\nresearch has demonstrated the positive effects that static interactive\nnarrative games can have on motivation. Concurrently, advances in AI have made\ndynamic and adaptive approaches to interactive narrative increasingly\naccessible. However, limited work has explored the impact that dynamic\nnarratives can have on learner motivation. In this paper, we compare two\nversions of Academical, a choice-based educational interactive narrative game\nabout research ethics. One version employs a traditional hand-authored\nbranching plot (i.e., static narrative) while the other dynamically sequences\nplots during play (i.e., dynamic narrative). Results highlight the importance\nof responsive content and a variety of choices for player engagement, while\nalso illustrating the challenge of balancing pedagogical goals with the dynamic\naspects of narrative. We also discuss design implications that arise from these\nfindings. Ultimately, this work provides initial steps to illuminate the\nemerging potential of AI-driven dynamic narrative in educational games.", "AI": {"tldr": "The paper compares static and dynamic narrative versions of an educational game, Academical, showing dynamic narratives enhance engagement but pose design challenges.", "motivation": "To explore the impact of dynamic narratives on learner motivation, leveraging AI advances for adaptive educational content.", "method": "Comparison of a static branching plot version and a dynamic plot-sequencing version of Academical, an educational game on research ethics.", "result": "Dynamic narratives improve engagement through responsive content and varied choices, though balancing pedagogy with narrative dynamics is challenging.", "conclusion": "The study highlights AI-driven dynamic narratives' potential in education, with design implications for future work."}}
{"id": "2505.08996", "pdf": "https://arxiv.org/pdf/2505.08996", "abs": "https://arxiv.org/abs/2505.08996", "authors": ["Adele E Goldberg", "Supantho Rakshit", "Jennifer Hu", "Kyle Mahowald"], "title": "A suite of LMs comprehend puzzle statements as well as humans", "categories": ["cs.CL"], "comment": null, "summary": "Recent claims suggest that large language models (LMs) underperform humans in\ncomprehending minimally complex English statements (Dentella et al., 2024).\nHere, we revisit those findings and argue that human performance was\noverestimated, while LLM abilities were underestimated. Using the same stimuli,\nwe report a preregistered study comparing human responses in two conditions:\none allowed rereading (replicating the original study), and one that restricted\nrereading (a more naturalistic comprehension test). Human accuracy dropped\nsignificantly when rereading was restricted (73%), falling below that of\nFalcon-180B-Chat (76%) and GPT-4 (81%). The newer GPT-o1 model achieves perfect\naccuracy. Results further show that both humans and models are\ndisproportionately challenged by queries involving potentially reciprocal\nactions (e.g., kissing), suggesting shared pragmatic sensitivities rather than\nmodel-specific deficits. Additional analyses using Llama-2-70B log\nprobabilities, a recoding of open-ended model responses, and grammaticality\nratings of other sentences reveal systematic underestimation of model\nperformance. We find that GPT-4o can align with either naive or expert\ngrammaticality judgments, depending on prompt framing. These findings\nunderscore the need for more careful experimental design and coding practices\nin LLM evaluation, and they challenge the assumption that current models are\ninherently weaker than humans at language comprehension.", "AI": {"tldr": "The paper revisits claims of LLMs underperforming humans in comprehension, showing human performance drops without rereading, while models like GPT-4 and Falcon-180B-Chat outperform humans. GPT-01 achieves perfect accuracy, and both humans and models struggle with reciprocal actions. The study highlights flaws in prior evaluations and suggests LLMs may not be inherently weaker than humans.", "motivation": "To challenge the assumption that LLMs are weaker than humans in language comprehension by re-evaluating human and model performance under more naturalistic conditions.", "method": "A preregistered study comparing human responses with and without rereading, using the same stimuli as prior work, and analyzing model performance (Falcon-180B-Chat, GPT-4, GPT-01) and human accuracy. Additional analyses included log probabilities, recoding responses, and grammaticality ratings.", "result": "Human accuracy dropped to 73% without rereading, below Falcon-180B-Chat (76%) and GPT-4 (81%). GPT-01 achieved perfect accuracy. Both humans and models struggled with reciprocal actions. GPT-4o aligned with naive or expert judgments based on prompts.", "conclusion": "The study reveals systematic underestimation of LLM performance and flaws in prior evaluations, challenging the notion that current models are inherently weaker than humans in comprehension."}}
{"id": "2505.09005", "pdf": "https://arxiv.org/pdf/2505.09005", "abs": "https://arxiv.org/abs/2505.09005", "authors": ["Nicole Cuneo", "Eleanor Graves", "Supantho Rakshit", "Adele E. Goldberg"], "title": "For GPT-4 as with Humans: Information Structure Predicts Acceptability of Long-Distance Dependencies", "categories": ["cs.CL"], "comment": null, "summary": "It remains debated how well any LM understands natural language or generates\nreliable metalinguistic judgments. Moreover, relatively little work has\ndemonstrated that LMs can represent and respect subtle relationships between\nform and function proposed by linguists. We here focus on a particular such\nrelationship established in recent work: English speakers' judgments about the\ninformation structure of canonical sentences predicts independently collected\nacceptability ratings on corresponding 'long distance dependency' [LDD]\nconstructions, across a wide array of base constructions and multiple types of\nLDDs. To determine whether any LM captures this relationship, we probe GPT-4 on\nthe same tasks used with humans and new extensions.Results reveal reliable\nmetalinguistic skill on the information structure and acceptability tasks,\nreplicating a striking interaction between the two, despite the zero-shot,\nexplicit nature of the tasks, and little to no chance of contamination [Studies\n1a, 1b]. Study 2 manipulates the information structure of base sentences and\nconfirms a causal relationship: increasing the prominence of a constituent in a\ncontext sentence increases the subsequent acceptability ratings on an LDD\nconstruction. The findings suggest a tight relationship between natural and\nGPT-4 generated English, and between information structure and syntax, which\nbegs for further exploration.", "AI": {"tldr": "GPT-4 demonstrates reliable metalinguistic skills in understanding information structure and acceptability in English, replicating human-like judgments and revealing a causal relationship between prominence and LDD acceptability.", "motivation": "To assess whether LMs like GPT-4 can capture subtle linguistic relationships, specifically the connection between information structure and acceptability in long-distance dependency constructions.", "method": "Probing GPT-4 on tasks involving information structure judgments and acceptability ratings, including zero-shot, explicit tasks and controlled manipulations of prominence.", "result": "GPT-4 replicated human-like interactions between information structure and acceptability, showing a causal effect of prominence on LDD acceptability.", "conclusion": "GPT-4's performance suggests a tight relationship between natural and model-generated English, highlighting the need for further exploration of LM linguistic capabilities."}}
{"id": "2505.08825", "pdf": "https://arxiv.org/pdf/2505.08825", "abs": "https://arxiv.org/abs/2505.08825", "authors": ["Pedro Antonio Alarcon Granadeno", "Theodore Chambers", "Jane Cleland-Huang"], "title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.AI"], "comment": "13 pages, 7 figures", "summary": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon\ngas leak (2015) demonstrate the urgent need for rapid and reliable plume\ntracing algorithms to protect public health and the environment. Traditional\nmethods, such as gradient-based or biologically inspired approaches, often fail\nin realistic, turbulent conditions. To address these challenges, we present a\nMulti-Agent Reinforcement Learning (MARL) algorithm designed for localizing\nmultiple airborne pollution sources using a swarm of small uncrewed aerial\nsystems (sUAS). Our method models the problem as a Partially Observable Markov\nGame (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific\nDouble Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical\naction-observation pairs, effectively approximating latent states. Unlike prior\nwork, we use a general-purpose simulation environment based on the Gaussian\nPlume Model (GPM), incorporating realistic elements such as a three-dimensional\nenvironment, sensor noise, multiple interacting agents, and multiple plume\nsources. The incorporation of action histories as part of the inputs further\nenhances the adaptability of our model in complex, partially observable\nenvironments. Extensive simulations show that our algorithm significantly\noutperforms conventional approaches. Specifically, our model allows agents to\nexplore only 1.29\\% of the environment to successfully locate pollution\nsources.", "AI": {"tldr": "A MARL algorithm using sUAS swarms for pollution source localization outperforms traditional methods by exploring only 1.29% of the environment.", "motivation": "Industrial disasters highlight the need for reliable plume tracing. Traditional methods fail in turbulent conditions.", "method": "Uses MARL with a POMG framework and LSTM-based ADDRQN, incorporating action histories and realistic simulations.", "result": "The algorithm locates pollution sources by exploring just 1.29% of the environment, outperforming conventional methods.", "conclusion": "The proposed MARL approach is effective for pollution source localization in complex, turbulent environments."}}
{"id": "2505.08896", "pdf": "https://arxiv.org/pdf/2505.08896", "abs": "https://arxiv.org/abs/2505.08896", "authors": ["Pankaj Kumar", "Aditya Mishra", "Pranamesh Chakraborty", "Subrahmanya Swamy Peruru"], "title": "Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Developing an autonomous vehicle control strategy for signalised\nintersections (SI) is one of the challenging tasks due to its inherently\ncomplex decision-making process. This study proposes a Deep Reinforcement\nLearning (DRL) based longitudinal vehicle control strategy at SI. A\ncomprehensive reward function has been formulated with a particular focus on\n(i) distance headway-based efficiency reward, (ii) decision-making criteria\nduring amber light, and (iii) asymmetric acceleration/ deceleration response,\nalong with the traditional safety and comfort criteria. This reward function\nhas been incorporated with two popular DRL algorithms, Deep Deterministic\nPolicy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the\ncontinuous action space of acceleration/deceleration. The proposed models have\nbeen trained on the combination of real-world leader vehicle (LV) trajectories\nand simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process.\nThe overall performance of the proposed models has been tested using Cumulative\nDistribution Function (CDF) plots and compared with the real-world trajectory\ndata. The results show that the RL models successfully maintain lower distance\nheadway (i.e., higher efficiency) and jerk compared to human-driven vehicles\nwithout compromising safety. Further, to assess the robustness of the proposed\nmodels, we evaluated the model performance on diverse safety-critical\nscenarios, in terms of car-following and traffic signal compliance. Both DDPG\nand SAC models successfully handled the critical scenarios, while the DDPG\nmodel showed smoother action profiles compared to the SAC model. Overall, the\nresults confirm that DRL-based longitudinal vehicle control strategy at SI can\nhelp to improve traffic safety, efficiency, and comfort.", "AI": {"tldr": "A Deep Reinforcement Learning (DRL) approach for autonomous vehicle control at signalised intersections improves efficiency, safety, and comfort by optimizing acceleration/deceleration using DDPG and SAC algorithms.", "motivation": "Developing autonomous vehicle control at signalised intersections is challenging due to complex decision-making, necessitating a robust and efficient strategy.", "method": "The study uses DRL (DDPG and SAC) with a tailored reward function focusing on efficiency, decision-making during amber lights, and asymmetric acceleration/deceleration. Training combines real-world and simulated trajectories.", "result": "RL models achieve lower distance headway and jerk than human drivers, maintaining safety. Both DDPG and SAC handle critical scenarios, with DDPG offering smoother actions.", "conclusion": "DRL-based control at signalised intersections enhances traffic safety, efficiency, and comfort, demonstrating the viability of autonomous solutions."}}
{"id": "2505.08990", "pdf": "https://arxiv.org/pdf/2505.08990", "abs": "https://arxiv.org/abs/2505.08990", "authors": ["Andrew C. Freeman"], "title": "Toward Accessible and Safe Live Streaming Using Distributed Content Filtering with MoQ", "categories": ["cs.MM", "cs.CV", "cs.DC", "cs.NI"], "comment": "Accepted to the ICME 2025 LIVES workshop", "summary": "Live video streaming is increasingly popular on social media platforms. With\nthe growth of live streaming comes an increased need for robust content\nmoderation to remove dangerous, illegal, or otherwise objectionable content.\nWhereas video on demand distribution enables offline content analysis, live\nstreaming imposes restrictions on latency for both analysis and distribution.\nIn this paper, we present extensions to the in-progress Media Over QUIC\nTransport protocol that enable real-time content moderation in one-to-many\nvideo live streams. Importantly, our solution removes only the video segments\nthat contain objectionable content, allowing playback resumption as soon as the\nstream conforms to content policies again. Content analysis tasks may be\ntransparently distributed to arbitrary client devices. We implement and\nevaluate our system in the context of light strobe removal for photosensitive\nviewers, finding that streaming clients experience an increased latency of only\none group-of-pictures duration.", "AI": {"tldr": "The paper proposes extensions to the Media Over QUIC Transport protocol for real-time content moderation in live video streams, removing only objectionable segments while minimizing latency.", "motivation": "The rise of live video streaming on social media necessitates robust, low-latency content moderation to filter dangerous or illegal content.", "method": "Extensions to the Media Over QUIC Transport protocol enable real-time moderation by distributing analysis tasks to client devices and removing only non-compliant video segments.", "result": "The system adds minimal latency (one group-of-pictures duration) and successfully resumes playback once content complies with policies.", "conclusion": "The proposed solution effectively balances real-time moderation with low-latency streaming, demonstrated in strobe removal for photosensitive viewers."}}
{"id": "2505.08792", "pdf": "https://arxiv.org/pdf/2505.08792", "abs": "https://arxiv.org/abs/2505.08792", "authors": ["Michelle Nashla Turcios", "Alicia E. Boyd", "Angela D. R. Smith", "Brittany Johnson"], "title": "A Preliminary Framework for Intersectionality in ML Pipelines", "categories": ["cs.LG", "cs.CY"], "comment": "Accepted for the 1st International Intersectionality and Software\n  Engineering Workshop, colocated with FSE 2025", "summary": "Machine learning (ML) has become a go-to solution for improving how we use,\nexperience, and interact with technology (and the world around us).\nUnfortunately, studies have repeatedly shown that machine learning technologies\nmay not provide adequate support for societal identities and experiences.\nIntersectionality is a sociological framework that provides a mechanism for\nexplicitly considering complex social identities, focusing on social justice\nand power. While the framework of intersectionality can support the development\nof technologies that acknowledge and support all members of society, it has\nbeen adopted and adapted in ways that are not always true to its foundations,\nthereby weakening its potential for impact. To support the appropriate adoption\nand use of intersectionality for more equitable technological outcomes, we\namplify the foundational intersectionality scholarship--Crenshaw, Combahee, and\nCollins (three C's), to create a socially relevant preliminary framework in\ndeveloping machine-learning solutions. We use this framework to evaluate and\nreport on the (mis)alignments of intersectionality application in machine\nlearning literature.", "AI": {"tldr": "The paper highlights the misuse of intersectionality in ML, proposes a framework based on foundational scholarship (Crenshaw, Combahee, Collins), and evaluates its application in ML literature.", "motivation": "Address the inadequate support of ML for societal identities and experiences, leveraging intersectionality for equitable tech outcomes.", "method": "Develop a framework based on foundational intersectionality scholarship to evaluate ML literature.", "result": "Identifies misalignments in how intersectionality is applied in ML.", "conclusion": "A proper adoption of intersectionality can lead to more equitable ML solutions."}}
{"id": "2505.09091", "pdf": "https://arxiv.org/pdf/2505.09091", "abs": "https://arxiv.org/abs/2505.09091", "authors": ["Zeeshan Ahmad", "Shudi Bao", "Meng Chen"], "title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "comment": null, "summary": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio.", "AI": {"tldr": "DPN-GAN introduces a novel GAN architecture with deformable periodic networks to improve audio generation quality by addressing mel-spectrogram limitations and mode collapse.", "motivation": "Existing GANs for audio generation rely on bandwidth-limited mel-spectrograms, leading to resolution constraints and mode collapse.", "method": "Proposes DPN-GAN with kernel-based periodic ReLU activation and deformable convolution for multi-resolution generation and enhanced discriminator.", "result": "DPN-GAN outperforms state-of-the-art models on speech and music tasks, showing robustness on noisy and out-of-distribution data.", "conclusion": "DPN-GAN advances audio generation by improving fidelity and adaptability, demonstrating superior performance across diverse datasets."}}
{"id": "2505.09439", "pdf": "https://arxiv.org/pdf/2505.09439", "abs": "https://arxiv.org/abs/2505.09439", "authors": ["Andrew Rouditchenko", "Saurabhchand Bhati", "Edson Araujo", "Samuel Thomas", "Hilde Kuehne", "Rogerio Feris", "James Glass"], "title": "Omni-R1: Do You Really Need Audio to Fine-Tune Your Audio LLM?", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "We propose Omni-R1 which fine-tunes a recent multi-modal LLM, Qwen2.5-Omni,\non an audio question answering dataset with the reinforcement learning method\nGRPO. This leads to new State-of-the-Art performance on the recent MMAU\nbenchmark. Omni-R1 achieves the highest accuracies on the sounds, music,\nspeech, and overall average categories, both on the Test-mini and Test-full\nsplits. To understand the performance improvement, we tested models both with\nand without audio and found that much of the performance improvement from GRPO\ncould be attributed to better text-based reasoning. We also made a surprising\ndiscovery that fine-tuning without audio on a text-only dataset was effective\nat improving the audio-based performance.", "AI": {"tldr": "Omni-R1 fine-tunes Qwen2.5-Omni with GRPO on an audio QA dataset, achieving SOTA on MMAU. Performance gains stem from improved text reasoning, and text-only fine-tuning boosts audio performance.", "motivation": "To enhance multi-modal LLM performance on audio QA tasks and explore the impact of reinforcement learning (GRPO) and text-based reasoning.", "method": "Fine-tuned Qwen2.5-Omni with GRPO on an audio QA dataset, tested with/without audio, and explored text-only fine-tuning.", "result": "Achieved SOTA on MMAU, highest accuracies in sound, music, speech, and overall. Text reasoning and text-only fine-tuning improved audio performance.", "conclusion": "GRPO and text-based reasoning significantly boost performance, and text-only fine-tuning unexpectedly enhances audio QA capabilities."}}
{"id": "2505.08798", "pdf": "https://arxiv.org/pdf/2505.08798", "abs": "https://arxiv.org/abs/2505.08798", "authors": ["Mobina Shrestha", "Bishwas Mandal", "Vishal Mandal", "Asis Shrestha"], "title": "In-Context Learning for Label-Efficient Cancer Image Classification in Oncology", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The application of AI in oncology has been limited by its reliance on large,\nannotated datasets and the need for retraining models for domain-specific\ndiagnostic tasks. Taking heed of these limitations, we investigated in-context\nlearning as a pragmatic alternative to model retraining by allowing models to\nadapt to new diagnostic tasks using only a few labeled examples at inference,\nwithout the need for retraining. Using four vision-language models\n(VLMs)-Paligemma, CLIP, ALIGN and GPT-4o, we evaluated the performance across\nthree oncology datasets: MHIST, PatchCamelyon and HAM10000. To the best of our\nknowledge, this is the first study to compare the performance of multiple VLMs\non different oncology classification tasks. Without any parameter updates, all\nmodels showed significant gains with few-shot prompting, with GPT-4o reaching\nan F1 score of 0.81 in binary classification and 0.60 in multi-class\nclassification settings. While these results remain below the ceiling of fully\nfine-tuned systems, they highlight the potential of ICL to approximate\ntask-specific behavior using only a handful of examples, reflecting how\nclinicians often reason from prior cases. Notably, open-source models like\nPaligemma and CLIP demonstrated competitive gains despite their smaller size,\nsuggesting feasibility for deployment in computing constrained clinical\nenvironments. Overall, these findings highlight the potential of ICL as a\npractical solution in oncology, particularly for rare cancers and\nresource-limited contexts where fine-tuning is infeasible and annotated data is\ndifficult to obtain.", "AI": {"tldr": "The paper explores in-context learning (ICL) as an alternative to retraining AI models for oncology tasks, showing competitive performance with few-shot prompting across multiple vision-language models.", "motivation": "To address the limitations of AI in oncology, such as reliance on large annotated datasets and the need for retraining, by leveraging ICL for adaptability with minimal labeled examples.", "method": "Evaluated four vision-language models (VLMs) on three oncology datasets using few-shot prompting without parameter updates.", "result": "GPT-4o achieved F1 scores of 0.81 (binary) and 0.60 (multi-class), while open-source models like Paligemma and CLIP showed competitive performance despite smaller size.", "conclusion": "ICL is a practical solution for oncology, especially in resource-limited settings, as it approximates task-specific behavior with minimal data."}}
{"id": "2505.09039", "pdf": "https://arxiv.org/pdf/2505.09039", "abs": "https://arxiv.org/abs/2505.09039", "authors": ["Jingfeng Chen", "Raghuveer Thirukovalluru", "Junlin Wang", "Kaiwei Luo", "Bhuwan Dhingra"], "title": "Atomic Consistency Preference Optimization for Long-Form Question Answering", "categories": ["cs.CL"], "comment": "16 pages, 2 figures", "summary": "Large Language Models (LLMs) frequently produce factoid hallucinations -\nplausible yet incorrect answers. A common mitigation strategy is model\nalignment, which improves factual accuracy by training on curated factual and\nnon-factual pairs. However, this approach often relies on a stronger model\n(e.g., GPT-4) or an external knowledge base to assess factual correctness,\nwhich may not always be accessible. To address this, we propose Atomic\nConsistency Preference Optimization (ACPO), a self-supervised preference-tuning\nmethod that enhances factual accuracy without external supervision. ACPO\nleverages atomic consistency signals, i.e., the agreement of individual facts\nacross multiple stochastic responses, to identify high- and low-quality data\npairs for model alignment. By eliminating the need for costly GPT calls, ACPO\nprovides a scalable and efficient approach to improving factoid\nquestion-answering. Despite being self-supervised, empirical results\ndemonstrate that ACPO outperforms FactAlign, a strong supervised alignment\nbaseline, by 1.95 points on the LongFact and BioGen datasets, highlighting its\neffectiveness in enhancing factual reliability without relying on external\nmodels or knowledge bases.", "AI": {"tldr": "ACPO is a self-supervised method to reduce factoid hallucinations in LLMs by leveraging atomic consistency signals, outperforming supervised baselines without external resources.", "motivation": "LLMs often generate plausible but incorrect answers (factoid hallucinations). Existing alignment methods rely on external models or knowledge bases, which may not be accessible.", "method": "ACPO uses atomic consistency signals (agreement of facts across stochastic responses) to identify high- and low-quality data pairs for self-supervised model alignment.", "result": "ACPO outperforms FactAlign by 1.95 points on LongFact and BioGen datasets, improving factual accuracy without external supervision.", "conclusion": "ACPO offers a scalable, efficient solution for enhancing factual reliability in LLMs without dependency on external models or knowledge bases."}}
{"id": "2505.09472", "pdf": "https://arxiv.org/pdf/2505.09472", "abs": "https://arxiv.org/abs/2505.09472", "authors": ["Mingkai Tang", "Lu Gan", "Kaichen Zhang"], "title": "Streaming Multi-agent Pathfinding", "categories": ["cs.MA", "cs.RO"], "comment": "to be published in IJCAI2025", "summary": "The task of the multi-agent pathfinding (MAPF) problem is to navigate a team\nof agents from their start point to the goal points. However, this setup is\nunsuitable in the assembly line scenario, which is periodic with a long working\nhour. To address this issue, the study formalizes the streaming MAPF (S-MAPF)\nproblem, which assumes that the agents in the same agent stream have a periodic\nstart time and share the same action sequence. The proposed solution, Agent\nStream Conflict-Based Search (ASCBS), is designed to tackle this problem by\nincorporating a cyclic vertex/edge constraint to handle conflicts.\nAdditionally, this work explores the potential usage of the disjoint splitting\nstrategy within ASCBS. Experimental results indicate that ASCBS surpasses\ntraditional MAPF solvers in terms of runtime for scenarios with prolonged\nworking hours.", "AI": {"tldr": "The paper introduces Streaming MAPF (S-MAPF) for periodic assembly line scenarios, proposing ASCBS, a solver that outperforms traditional MAPF methods in runtime for long-hour tasks.", "motivation": "Traditional MAPF is unsuitable for periodic, long-hour assembly line scenarios, necessitating a new approach.", "method": "The study formalizes S-MAPF and develops ASCBS, incorporating cyclic constraints and disjoint splitting to handle conflicts.", "result": "ASCBS outperforms traditional MAPF solvers in runtime for prolonged working hours.", "conclusion": "ASCBS is effective for periodic, long-duration MAPF tasks, offering a viable solution for assembly line scenarios."}}
{"id": "2505.08905", "pdf": "https://arxiv.org/pdf/2505.08905", "abs": "https://arxiv.org/abs/2505.08905", "authors": ["Michael Majurski", "Cynthia Matuszek"], "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users might ask them to generate in some form during their\ntraining. A plethora of evaluation benchmarks have been constructed to assess\nmodel quality, response appropriateness, and reasoning capabilities. However,\nthe human effort required for benchmark construction is limited and being\nrapidly outpaced by the size and scope of the models under evaluation.\nAdditionally, having humans build a benchmark for every possible domain of\ninterest is impractical. Therefore, we propose a methodology for automating the\nconstruction of fact-based synthetic data model evaluations grounded in\ndocument populations. This work leverages those very same LMs to evaluate\ndomain-specific knowledge automatically, using only grounding documents (e.g.,\na textbook) as input. This synthetic data benchmarking approach corresponds\nwell with human curated questions with a Spearman ranking correlation of 0.96\nand a benchmark evaluation Pearson accuracy correlation of 0.79. This novel\ntool supports generating both multiple choice and open-ended synthetic data\nquestions to gain diagnostic insight of LM capability. We apply this\nmethodology to evaluate model performance on a recent relevant arXiv preprint,\ndiscovering a surprisingly strong performance from Gemma3 models.", "AI": {"tldr": "The paper proposes automating the construction of fact-based synthetic benchmarks for evaluating language models (LMs) using grounding documents, reducing human effort and improving scalability.", "motivation": "Human effort in benchmark construction is limited and outpaced by LM advancements, making automated solutions necessary.", "method": "Uses LMs to generate domain-specific evaluation questions from grounding documents (e.g., textbooks), creating synthetic benchmarks.", "result": "The synthetic benchmarks correlate well with human-curated ones (Spearman 0.96, Pearson 0.79) and reveal strong performance of Gemma3 models.", "conclusion": "Automated synthetic benchmarking is a scalable and effective alternative to human-curated evaluations for assessing LM capabilities."}}
{"id": "2505.09558", "pdf": "https://arxiv.org/pdf/2505.09558", "abs": "https://arxiv.org/abs/2505.09558", "authors": ["Shengpeng Ji", "Tianle Liang", "Yangzhuo Li", "Jialong Zuo", "Minghui Fang", "Jinzheng He", "Yifu Chen", "Zhengqing Liu", "Ziyue Jiang", "Xize Cheng", "Siqi Zheng", "Jin Xu", "Junyang Lin", "Zhou Zhao"], "title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.MM", "cs.SD"], "comment": null, "summary": "End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered\nsignificant attention in the speech domain. However, the evaluation of spoken\ndialogue models' conversational performance has largely been overlooked. This\nis primarily due to the intelligent chatbots convey a wealth of non-textual\ninformation which cannot be easily measured using text-based language models\nlike ChatGPT. To address this gap, we propose WavReward, a reward feedback\nmodel based on audio language models that can evaluate both the IQ and EQ of\nspoken dialogue systems with speech input. Specifically, 1) based on audio\nlanguage models, WavReward incorporates the deep reasoning process and the\nnonlinear reward mechanism for post-training. By utilizing multi-sample\nfeedback via the reinforcement learning algorithm, we construct a specialized\nevaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a\npreference dataset used to train WavReward. ChatReward-30K includes both\ncomprehension and generation aspects of spoken dialogue models. These scenarios\nspan various tasks, such as text-based chats, nine acoustic attributes of\ninstruction chats, and implicit chats. WavReward outperforms previous\nstate-of-the-art evaluation models across multiple spoken dialogue scenarios,\nachieving a substantial improvement about Qwen2.5-Omni in objective accuracy\nfrom 55.1$\\%$ to 91.5$\\%$. In subjective A/B testing, WavReward also leads by a\nmargin of 83$\\%$. Comprehensive ablation studies confirm the necessity of each\ncomponent of WavReward. All data and code will be publicly at\nhttps://github.com/jishengpeng/WavReward after the paper is accepted.", "AI": {"tldr": "The paper introduces WavReward, an audio-based reward feedback model for evaluating spoken dialogue systems, outperforming existing methods in accuracy and subjective testing.", "motivation": "Existing evaluation methods for spoken dialogue models overlook non-textual information, prompting the need for an audio-based evaluation framework.", "method": "WavReward uses audio language models with deep reasoning and nonlinear reward mechanisms, trained via reinforcement learning on the ChatReward-30K dataset.", "result": "WavReward achieves 91.5% objective accuracy (vs. 55.1% for Qwen2.5-Omni) and 83% preference in subjective tests.", "conclusion": "WavReward effectively evaluates spoken dialogue systems, with ablation studies validating its components; data and code will be publicly released."}}
{"id": "2505.08793", "pdf": "https://arxiv.org/pdf/2505.08793", "abs": "https://arxiv.org/abs/2505.08793", "authors": ["Monirul Islam Pavel", "Siyi Hu", "Mahardhika Pratama", "Ryszard Kowalczyk"], "title": "Onboard Optimization and Learning: A Survey", "categories": ["cs.LG", "cs.AR"], "comment": "36 pages, 5 figures, 3 tables", "summary": "Onboard learning is a transformative approach in edge AI, enabling real-time\ndata processing, decision-making, and adaptive model training directly on\nresource-constrained devices without relying on centralized servers. This\nparadigm is crucial for applications demanding low latency, enhanced privacy,\nand energy efficiency. However, onboard learning faces challenges such as\nlimited computational resources, high inference costs, and security\nvulnerabilities. This survey explores a comprehensive range of methodologies\nthat address these challenges, focusing on techniques that optimize model\nefficiency, accelerate inference, and support collaborative learning across\ndistributed devices. Approaches for reducing model complexity, improving\ninference speed, and ensuring privacy-preserving computation are examined\nalongside emerging strategies that enhance scalability and adaptability in\ndynamic environments. By bridging advancements in hardware-software co-design,\nmodel compression, and decentralized learning, this survey provides insights\ninto the current state of onboard learning to enable robust, efficient, and\nsecure AI deployment at the edge.", "AI": {"tldr": "A survey on onboard learning in edge AI, addressing challenges like limited resources and security, and exploring methodologies for efficiency, speed, and privacy.", "motivation": "To enable real-time, low-latency, and privacy-preserving AI on resource-constrained edge devices.", "method": "Examines techniques like model optimization, inference acceleration, collaborative learning, and hardware-software co-design.", "result": "Identifies strategies for efficient, scalable, and secure AI deployment at the edge.", "conclusion": "Onboard learning is key for robust edge AI, with ongoing advancements in optimization and decentralization."}}
{"id": "2505.09304", "pdf": "https://arxiv.org/pdf/2505.09304", "abs": "https://arxiv.org/abs/2505.09304", "authors": ["Luciano Sebastian Martinez-Rau", "Quynh Nguyen Phuong Vu", "Yuxuan Zhang", "Bengt Oelmann", "Sebastian Bader"], "title": "Adaptive Noise Resilient Keyword Spotting Using One-Shot Learning", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Preprint submitted to the IEEE 11th World Forum on Internet of Things", "summary": "Keyword spotting (KWS) is a key component of smart devices, enabling\nefficient and intuitive audio interaction. However, standard KWS systems\ndeployed on embedded devices often suffer performance degradation under\nreal-world operating conditions. Resilient KWS systems address this issue by\nenabling dynamic adaptation, with applications such as adding or replacing\nkeywords, adjusting to specific users, and improving noise robustness. However,\ndeploying resilient, standalone KWS systems with low latency on\nresource-constrained devices remains challenging due to limited memory and\ncomputational resources. This study proposes a low computational approach for\ncontinuous noise adaptation of pretrained neural networks used for KWS\nclassification, requiring only 1-shot learning and one epoch. The proposed\nmethod was assessed using two pretrained models and three real-world noise\nsources at signal-to-noise ratios (SNRs) ranging from 24 to -3 dB. The adapted\nmodels consistently outperformed the pretrained models across all scenarios,\nespecially at SNR $\\leq$ 18 dB, achieving accuracy improvements of 4.9% to\n46.0%. These results highlight the efficacy of the proposed methodology while\nbeing lightweight enough for deployment on resource-constrained devices.", "AI": {"tldr": "A lightweight method for continuous noise adaptation in keyword spotting (KWS) systems improves performance under real-world conditions with minimal computational overhead.", "motivation": "Standard KWS systems degrade in real-world conditions; resilient systems are needed for dynamic adaptation but face deployment challenges on resource-constrained devices.", "method": "Proposes a low-computation approach for noise adaptation of pretrained KWS neural networks using 1-shot learning and one epoch.", "result": "Adapted models outperformed pretrained ones, especially at low SNRs (\u226418 dB), with accuracy improvements of 4.9% to 46.0%.", "conclusion": "The method is effective and lightweight, suitable for resource-constrained devices."}}
{"id": "2505.08977", "pdf": "https://arxiv.org/pdf/2505.08977", "abs": "https://arxiv.org/abs/2505.08977", "authors": ["Hossein Babaei", "Mel White", "Sina Alemohammad", "Richard G. Baraniuk"], "title": "SaFARi: State-Space Models for Frame-Agnostic Representation", "categories": ["cs.LG", "eess.AS", "eess.IV", "eess.SP"], "comment": "13 pages, 5 figures", "summary": "State-Space Models (SSMs) have re-emerged as a powerful tool for online\nfunction approximation, and as the backbone of machine learning models for\nlong-range dependent data. However, to date, only a few polynomial bases have\nbeen explored for this purpose, and the state-of-the-art implementations were\nbuilt upon the best of a few limited options. In this paper, we present a\ngeneralized method for building an SSM with any frame or basis, rather than\nbeing restricted to polynomials. This framework encompasses the approach known\nas HiPPO, but also permits an infinite diversity of other possible \"species\"\nwithin the SSM architecture. We dub this approach SaFARi: SSMs for\nFrame-Agnostic Representation.", "AI": {"tldr": "A generalized method for building State-Space Models (SSMs) with any frame or basis, extending beyond polynomials, is introduced.", "motivation": "Current SSMs are limited to a few polynomial bases, restricting their potential.", "method": "Proposes SaFARi, a framework for constructing SSMs with any frame or basis, not just polynomials.", "result": "Enables an infinite diversity of SSM architectures, expanding beyond HiPPO.", "conclusion": "SaFARi broadens the scope of SSMs, offering flexibility and new possibilities for long-range dependent data modeling."}}
{"id": "2505.08819", "pdf": "https://arxiv.org/pdf/2505.08819", "abs": "https://arxiv.org/abs/2505.08819", "authors": ["Asahi Miyazaki", "Tsuyoshi Okita"], "title": "Thoughts on Objectives of Sparse and Hierarchical Masked Image Model", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "9 pages, 11 figures", "summary": "Masked image modeling is one of the most poplular objectives of training.\nRecently, the SparK model has been proposed with superior performance among\nself-supervised learning models. This paper proposes a new mask pattern for\nthis SparK model, proposing it as the Mesh Mask-ed SparK model. We report the\neffect of the mask pattern used for image masking in pre-training on\nperformance.", "AI": {"tldr": "The paper introduces a new mask pattern, Mesh Mask, for the SparK model in self-supervised learning, analyzing its impact on performance.", "motivation": "To improve the performance of the SparK model by exploring the effect of different mask patterns in pre-training.", "method": "Proposes the Mesh Mask-ed SparK model, a new mask pattern for image masking during pre-training.", "result": "Reports the influence of the mask pattern on the model's performance.", "conclusion": "The Mesh Mask pattern enhances the SparK model's effectiveness in self-supervised learning."}}
{"id": "2505.09056", "pdf": "https://arxiv.org/pdf/2505.09056", "abs": "https://arxiv.org/abs/2505.09056", "authors": ["Brandon Smith", "Mohamed Reda Bouadjenek", "Tahsin Alamgir Kheya", "Phillip Dawson", "Sunil Aryal"], "title": "A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) represent a major step toward artificial general\nintelligence, significantly advancing our ability to interact with technology.\nWhile LLMs perform well on Natural Language Processing tasks -- such as\ntranslation, generation, code writing, and summarization -- questions remain\nabout their output similarity, variability, and ethical implications. For\ninstance, how similar are texts generated by the same model? How does this\ncompare across different models? And which models best uphold ethical\nstandards? To investigate, we used 5{,}000 prompts spanning diverse tasks like\ngeneration, explanation, and rewriting. This resulted in approximately 3\nmillion texts from 12 LLMs, including proprietary and open-source systems from\nOpenAI, Google, Microsoft, Meta, and Mistral. Key findings include: (1) outputs\nfrom the same LLM are more similar to each other than to human-written texts;\n(2) models like WizardLM-2-8x22b generate highly similar outputs, while GPT-4\nproduces more varied responses; (3) LLM writing styles differ significantly,\nwith Llama 3 and Mistral showing higher similarity, and GPT-4 standing out for\ndistinctiveness; (4) differences in vocabulary and tone underscore the\nlinguistic uniqueness of LLM-generated content; (5) some LLMs demonstrate\ngreater gender balance and reduced bias. These results offer new insights into\nthe behavior and diversity of LLM outputs, helping guide future development and\nethical evaluation.", "AI": {"tldr": "The paper investigates output similarity, variability, and ethical implications of 12 LLMs, revealing differences in style, similarity, and bias.", "motivation": "To understand how similar and varied LLM outputs are, and how they compare ethically across models.", "method": "Analyzed ~3M texts from 12 LLMs using 5,000 diverse prompts.", "result": "Same-model outputs are more similar than human texts; GPT-4 is more varied; some models show better ethical standards.", "conclusion": "Findings provide insights for LLM development and ethical evaluation."}}
{"id": "2505.08995", "pdf": "https://arxiv.org/pdf/2505.08995", "abs": "https://arxiv.org/abs/2505.08995", "authors": ["Ardian Selmonaj", "Oleg Szehr", "Giacomo Del Rio", "Alessandro Antonucci", "Adrian Schneider", "Michael R\u00fcegsegger"], "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1,\n  by Taylor & Francis", "summary": "This work presents a Hierarchical Multi-Agent Reinforcement Learning\nframework for analyzing simulated air combat scenarios involving heterogeneous\nagents. The objective is to identify effective Courses of Action that lead to\nmission success within preset simulations, thereby enabling the exploration of\nreal-world defense scenarios at low cost and in a safe-to-fail setting.\nApplying deep Reinforcement Learning in this context poses specific challenges,\nsuch as complex flight dynamics, the exponential size of the state and action\nspaces in multi-agent systems, and the capability to integrate real-time\ncontrol of individual units with look-ahead planning. To address these\nchallenges, the decision-making process is split into two levels of\nabstraction: low-level policies control individual units, while a high-level\ncommander policy issues macro commands aligned with the overall mission\ntargets. This hierarchical structure facilitates the training process by\nexploiting policy symmetries of individual agents and by separating control\nfrom command tasks. The low-level policies are trained for individual combat\ncontrol in a curriculum of increasing complexity. The high-level commander is\nthen trained on mission targets given pre-trained control policies. The\nempirical validation confirms the advantages of the proposed framework.", "AI": {"tldr": "A hierarchical multi-agent reinforcement learning framework is proposed for air combat simulations, addressing challenges like complex dynamics and large state-action spaces by splitting decision-making into low-level (unit control) and high-level (mission command) policies.", "motivation": "To explore real-world defense scenarios cost-effectively and safely by identifying effective courses of action in simulated air combat with heterogeneous agents.", "method": "Uses a two-level hierarchical approach: low-level policies for individual unit control and a high-level commander for mission-aligned macro commands. Training involves a curriculum for low-level policies and mission targets for the high-level commander.", "result": "Empirical validation confirms the framework's effectiveness in handling complex multi-agent air combat scenarios.", "conclusion": "The hierarchical structure successfully addresses challenges in multi-agent reinforcement learning for air combat, enabling efficient training and mission success."}}
{"id": "2505.08988", "pdf": "https://arxiv.org/pdf/2505.08988", "abs": "https://arxiv.org/abs/2505.08988", "authors": ["Montaser Mohammedalamen", "Michael Bowling"], "title": "Generalization in Monitored Markov Decision Processes (Mon-MDPs)", "categories": ["cs.AI"], "comment": "Under Review", "summary": "Reinforcement learning (RL) typically models the interaction between the\nagent and environment as a Markov decision process (MDP), where the rewards\nthat guide the agent's behavior are always observable. However, in many\nreal-world scenarios, rewards are not always observable, which can be modeled\nas a monitored Markov decision process (Mon-MDP). Prior work on Mon-MDPs have\nbeen limited to simple, tabular cases, restricting their applicability to\nreal-world problems. This work explores Mon-MDPs using function approximation\n(FA) and investigates the challenges involved. We show that combining function\napproximation with a learned reward model enables agents to generalize from\nmonitored states with observable rewards, to unmonitored environment states\nwith unobservable rewards. Therefore, we demonstrate that such generalization\nwith a reward model achieves near-optimal policies in environments formally\ndefined as unsolvable. However, we identify a critical limitation of such\nfunction approximation, where agents incorrectly extrapolate rewards due to\novergeneralization, resulting in undesirable behaviors. To mitigate\novergeneralization, we propose a cautious police optimization method leveraging\nreward uncertainty. This work serves as a step towards bridging this gap\nbetween Mon-MDP theory and real-world applications.", "AI": {"tldr": "This paper explores Monitored Markov Decision Processes (Mon-MDPs) with function approximation, addressing challenges in reward generalization and proposing a solution to mitigate overgeneralization.", "motivation": "Real-world scenarios often lack observable rewards, modeled as Mon-MDPs, but prior work is limited to simple cases. This work aims to bridge the gap between theory and practical applications.", "method": "The study combines function approximation with a learned reward model to generalize from monitored to unmonitored states, proposing cautious policy optimization to address overgeneralization.", "result": "The approach achieves near-optimal policies in unsolvable environments but identifies overgeneralization as a critical limitation.", "conclusion": "The work advances Mon-MDP theory towards real-world applicability, highlighting the need for cautious reward extrapolation."}}
{"id": "2402.00045", "pdf": "https://arxiv.org/pdf/2402.00045", "abs": "https://arxiv.org/abs/2402.00045", "authors": ["Li Lin", "Neeraj Gupta", "Yue Zhang", "Hainan Ren", "Chun-Hao Liu", "Feng Ding", "Xin Wang", "Xin Li", "Luisa Verdoliva", "Shu Hu"], "title": "Detecting Multimedia Generated by Large AI Models: A Survey", "categories": ["cs.MM", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid advancement of Large AI Models (LAIMs), particularly diffusion\nmodels and large language models, has marked a new era where AI-generated\nmultimedia is increasingly integrated into various aspects of daily life.\nAlthough beneficial in numerous fields, this content presents significant\nrisks, including potential misuse, societal disruptions, and ethical concerns.\nConsequently, detecting multimedia generated by LAIMs has become crucial, with\na marked rise in related research. Despite this, there remains a notable gap in\nsystematic surveys that focus specifically on detecting LAIM-generated\nmultimedia. Addressing this, we provide the first survey to comprehensively\ncover existing research on detecting multimedia (such as text, images, videos,\naudio, and multimodal content) created by LAIMs. Specifically, we introduce a\nnovel taxonomy for detection methods, categorized by media modality, and\naligned with two perspectives: pure detection (aiming to enhance detection\nperformance) and beyond detection (adding attributes like generalizability,\nrobustness, and interpretability to detectors). Additionally, we have presented\na brief overview of generation mechanisms, public datasets, online detection\ntools, and evaluation metrics to provide a valuable resource for researchers\nand practitioners in this field. Most importantly, we offer a focused analysis\nfrom a social media perspective to highlight their broader societal impact.\nFurthermore, we identify current challenges in detection and propose directions\nfor future research that address unexplored, ongoing, and emerging issues in\ndetecting multimedia generated by LAIMs. Our aim for this survey is to fill an\nacademic gap and contribute to global AI security efforts, helping to ensure\nthe integrity of information in the digital realm. The project link is\nhttps://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey.", "AI": {"tldr": "This paper presents the first comprehensive survey on detecting multimedia generated by Large AI Models (LAIMs), introducing a novel taxonomy for detection methods and addressing societal impacts and future research directions.", "motivation": "The rise of AI-generated multimedia poses risks like misuse and ethical concerns, yet lacks systematic surveys on detection methods, prompting this study.", "method": "The survey categorizes detection methods by media modality and perspectives (pure detection and beyond detection), while also reviewing generation mechanisms, datasets, tools, and metrics.", "result": "A novel taxonomy for detection methods is introduced, alongside insights into societal impacts and current challenges in detecting LAIM-generated content.", "conclusion": "The survey fills an academic gap, aids global AI security, and proposes future research directions to address emerging issues in LAIM-generated multimedia detection."}}
{"id": "2505.08795", "pdf": "https://arxiv.org/pdf/2505.08795", "abs": "https://arxiv.org/abs/2505.08795", "authors": ["Andres Anabalon", "Hugo Garces", "Julio Oliva", "Jose Cifuentes"], "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "7 pages, 3 figures", "summary": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric.", "AI": {"tldr": "A fast algorithm embeds hierarchical structures in 3D Minkowski spacetime, encoding data correlations in causal structure. Applied to WordNet, it perfectly embeds hierarchies, suggesting discrete data has a 3D geometric representation.", "motivation": "To explore whether hierarchical structures can be perfectly embedded in 3D Minkowski spacetime, leveraging causal relationships for data correlation.", "method": "Uses oriented token pairs (local hierarchical signals) without global symbolic structure, applied to WordNet for embedding hierarchies. Introduces causality-based retrieval.", "result": "Perfect embeddings of WordNet's mammal sub-tree and a maximal unambiguous subset (82,115 nouns) achieved. Hierarchies are codified in geometry, reproducing ground-truth.", "conclusion": "Hierarchical meaning is geometric, with deep connections to general relativity. Discrete data may universally have 3D geometric representations."}}
{"id": "2505.09325", "pdf": "https://arxiv.org/pdf/2505.09325", "abs": "https://arxiv.org/abs/2505.09325", "authors": ["Yicheng Gu", "Chaoren Wang", "Junan Zhang", "Xueyao Zhang", "Zihao Fang", "Haorui He", "Zhizheng Wu"], "title": "SingNet: Towards a Large-Scale, Diverse, and In-the-Wild Singing Voice Dataset", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "The lack of a publicly-available large-scale and diverse dataset has long\nbeen a significant bottleneck for singing voice applications like Singing Voice\nSynthesis (SVS) and Singing Voice Conversion (SVC). To tackle this problem, we\npresent SingNet, an extensive, diverse, and in-the-wild singing voice dataset.\nSpecifically, we propose a data processing pipeline to extract ready-to-use\ntraining data from sample packs and songs on the internet, forming 3000 hours\nof singing voices in various languages and styles. Furthermore, to facilitate\nthe use and demonstrate the effectiveness of SingNet, we pre-train and\nopen-source various state-of-the-art (SOTA) models on Wav2vec2, BigVGAN, and\nNSF-HiFiGAN based on our collected singing voice data. We also conduct\nbenchmark experiments on Automatic Lyric Transcription (ALT), Neural Vocoder,\nand Singing Voice Conversion (SVC). Audio demos are available at:\nhttps://singnet-dataset.github.io/.", "AI": {"tldr": "SingNet is a large-scale, diverse singing voice dataset addressing the bottleneck in singing voice applications like SVS and SVC. It includes 3000 hours of data, pre-trained SOTA models, and benchmark results.", "motivation": "The lack of a diverse, large-scale singing voice dataset hinders progress in applications like Singing Voice Synthesis and Conversion.", "method": "A data processing pipeline extracts training data from online sample packs and songs, forming 3000 hours of diverse singing voices. Pre-trained models on Wav2vec2, BigVGAN, and NSF-HiFiGAN are provided.", "result": "Benchmark experiments on ALT, Neural Vocoder, and SVC demonstrate the dataset's effectiveness.", "conclusion": "SingNet fills a critical gap in singing voice research, offering a valuable resource for future work."}}
{"id": "2505.08978", "pdf": "https://arxiv.org/pdf/2505.08978", "abs": "https://arxiv.org/abs/2505.08978", "authors": ["Luke Bauer", "Wenxuan Bao", "Malvika Jadhav", "Vincent Bindschaedler"], "title": "Inference Attacks for X-Vector Speaker Anonymization", "categories": ["cs.CR", "cs.SD", "eess.AS"], "comment": null, "summary": "We revisit the privacy-utility tradeoff of x-vector speaker anonymization.\nExisting approaches quantify privacy through training complex speaker\nverification or identification models that are later used as attacks. Instead,\nwe propose a novel inference attack for de-anonymization. Our attack is simple\nand ML-free yet we show experimentally that it outperforms existing approaches.", "AI": {"tldr": "The paper proposes a simple, ML-free inference attack for de-anonymization of x-vector speaker anonymization, outperforming existing complex methods.", "motivation": "Existing methods for quantifying privacy in speaker anonymization rely on complex ML models, which may not be optimal.", "method": "The authors introduce a novel, simple, and ML-free inference attack for de-anonymization.", "result": "Experiments show the proposed attack outperforms existing approaches.", "conclusion": "A simpler, ML-free method can effectively challenge privacy in speaker anonymization, suggesting a need to rethink current approaches."}}
{"id": "2505.08838", "pdf": "https://arxiv.org/pdf/2505.08838", "abs": "https://arxiv.org/abs/2505.08838", "authors": ["Peixuan Ge", "Tongkun Su", "Faqin Lv", "Baoliang Zhao", "Peng Zhang", "Chi Hong Wong", "Liang Yao", "Yu Sun", "Zenan Wang", "Pak Kin Wong", "Ying Hu"], "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Ultrasound (US) report generation is a challenging task due to the\nvariability of US images, operator dependence, and the need for standardized\ntext. Unlike X-ray and CT, US imaging lacks consistent datasets, making\nautomation difficult. In this study, we propose a unified framework for\nmulti-organ and multilingual US report generation, integrating fragment-based\nmultilingual training and leveraging the standardized nature of US reports. By\naligning modular text fragments with diverse imaging data and curating a\nbilingual English-Chinese dataset, the method achieves consistent and\nclinically accurate text generation across organ sites and languages.\nFine-tuning with selective unfreezing of the vision transformer (ViT) further\nimproves text-image alignment. Compared to the previous state-of-the-art KMVE\nmethod, our approach achieves relative gains of about 2\\% in BLEU scores,\napproximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly\nreducing errors such as missing or incorrect content. By unifying multi-organ\nand multi-language report generation into a single, scalable framework, this\nwork demonstrates strong potential for real-world clinical workflows.", "AI": {"tldr": "A unified framework for multi-organ and multilingual ultrasound report generation is proposed, improving accuracy and reducing errors compared to previous methods.", "motivation": "The variability of ultrasound images, operator dependence, and lack of standardized datasets make automated report generation challenging.", "method": "The framework integrates fragment-based multilingual training, aligns modular text fragments with imaging data, and uses a bilingual English-Chinese dataset. Fine-tuning with selective unfreezing of ViT improves text-image alignment.", "result": "Achieves relative gains of 2% in BLEU, 3% in ROUGE-L, and 15% in CIDEr, reducing errors like missing or incorrect content.", "conclusion": "The framework shows strong potential for real-world clinical workflows by unifying multi-organ and multi-language report generation."}}
{"id": "2505.09068", "pdf": "https://arxiv.org/pdf/2505.09068", "abs": "https://arxiv.org/abs/2505.09068", "authors": ["Jennifer Haase", "Paul H. P. Hanel", "Sebastian Pokutta"], "title": "S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "This paper introduces S-DAT (Synthetic-Divergent Association Task), a\nscalable, multilingual framework for automated assessment of divergent thinking\n(DT) -a core component of human creativity. Traditional creativity assessments\nare often labor-intensive, language-specific, and reliant on subjective human\nratings, limiting their scalability and cross-cultural applicability. In\ncontrast, S-DAT leverages large language models and advanced multilingual\nembeddings to compute semantic distance -- a language-agnostic proxy for DT. We\nevaluate S-DAT across eleven diverse languages, including English, Spanish,\nGerman, Russian, Hindi, and Japanese (Kanji, Hiragana, Katakana), demonstrating\nrobust and consistent scoring across linguistic contexts. Unlike prior DAT\napproaches, the S-DAT shows convergent validity with other DT measures and\ncorrect discriminant validity with convergent thinking. This cross-linguistic\nflexibility allows for more inclusive, global-scale creativity research,\naddressing key limitations of earlier approaches. S-DAT provides a powerful\ntool for fairer, more comprehensive evaluation of cognitive flexibility in\ndiverse populations and can be freely assessed online:\nhttps://sdat.iol.zib.de/.", "AI": {"tldr": "S-DAT is a scalable, multilingual framework for automated divergent thinking assessment, overcoming limitations of traditional methods by using language models and semantic distance.", "motivation": "Traditional creativity assessments are labor-intensive, language-specific, and subjective, hindering scalability and cross-cultural applicability.", "method": "S-DAT leverages large language models and multilingual embeddings to compute semantic distance as a proxy for divergent thinking.", "result": "Evaluated across 11 languages, S-DAT shows robust, consistent scoring, convergent validity with DT measures, and discriminant validity with convergent thinking.", "conclusion": "S-DAT enables inclusive, global-scale creativity research, offering a fairer, more comprehensive tool for cognitive flexibility evaluation."}}
{"id": "2505.09081", "pdf": "https://arxiv.org/pdf/2505.09081", "abs": "https://arxiv.org/abs/2505.09081", "authors": ["Gaurav Koley"], "title": "SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation", "categories": ["cs.SI", "cs.AI", "cs.MA"], "comment": null, "summary": "Contemporary approaches to agent-based modeling (ABM) of social systems have\ntraditionally emphasized rule-based behaviors, limiting their ability to\ncapture nuanced dynamics by moving beyond predefined rules and leveraging\ncontextual understanding from LMs of human social interaction. This paper\npresents SALM (Social Agent LM Framework), a novel approach for integrating\nlanguage models (LMs) into social network simulation that achieves\nunprecedented temporal stability in multi-agent scenarios. Our primary\ncontributions include: (1) a hierarchical prompting architecture enabling\nstable simulation beyond 4,000 timesteps while reducing token usage by 73%, (2)\nan attention-based memory system achieving 80% cache hit rates (95% CI [78%,\n82%]) with sub-linear memory growth of 9.5%, and (3) formal bounds on\npersonality stability. Through extensive validation against SNAP ego networks,\nwe demonstrate the first LLM-based framework capable of modeling long-term\nsocial phenomena while maintaining empirically validated behavioral fidelity.", "AI": {"tldr": "SALM integrates language models into social network simulations, achieving temporal stability and efficiency with hierarchical prompting, memory systems, and personality stability bounds.", "motivation": "Traditional agent-based modeling lacks nuanced dynamics due to rule-based limitations; SALM leverages LMs for contextual understanding in social interactions.", "method": "SALM uses hierarchical prompting for efficiency, an attention-based memory system, and formal personality stability bounds.", "result": "Achieves stable simulations beyond 4,000 timesteps, reduces token usage by 73%, and maintains high cache hit rates with minimal memory growth.", "conclusion": "SALM is the first LM-based framework for long-term social phenomena with validated behavioral fidelity."}}
{"id": "2505.09012", "pdf": "https://arxiv.org/pdf/2505.09012", "abs": "https://arxiv.org/abs/2505.09012", "authors": ["Bo Meng", "Chenghao Xu", "Yongli Zhu"], "title": "Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025", "summary": "Cascading failures in power grids can lead to grid collapse, causing severe\ndisruptions to social operations and economic activities. In certain cases,\nmulti-stage cascading failures can occur. However, existing\ncascading-failure-mitigation strategies are usually single-stage-based,\noverlooking the complexity of the multi-stage scenario. This paper treats the\nmulti-stage cascading failure problem as a reinforcement learning task and\ndevelops a simulation environment. The reinforcement learning agent is then\ntrained via the deterministic policy gradient algorithm to achieve continuous\nactions. Finally, the effectiveness of the proposed approach is validated on\nthe IEEE 14-bus and IEEE 118-bus systems.", "AI": {"tldr": "The paper addresses multi-stage cascading failures in power grids using reinforcement learning, validated on IEEE systems.", "motivation": "Existing mitigation strategies overlook multi-stage cascading failures, which can cause severe disruptions.", "method": "Treats the problem as a reinforcement learning task, using deterministic policy gradient for continuous actions.", "result": "Effectiveness is validated on IEEE 14-bus and 118-bus systems.", "conclusion": "The proposed approach successfully mitigates multi-stage cascading failures."}}
{"id": "2504.17938", "pdf": "https://arxiv.org/pdf/2504.17938", "abs": "https://arxiv.org/abs/2504.17938", "authors": ["Raza Ul Mustafa", "Sesha Dassanayake", "Noman Ashraf"], "title": "Machine Learning-Based Prediction of Quality Shifts on Video Streaming Over 5G", "categories": ["cs.MM", "cs.LG"], "comment": null, "summary": "The Quality of Experience (QoE) is the users satisfaction while streaming a\nvideo session over an over-the-top (OTT) platform like YouTube. QoE of YouTube\nreflects the smooth streaming session without any buffering and quality shift\nevents. One of the most important factors nowadays affecting QoE of YouTube is\nfrequent shifts from higher to lower resolutions and vice versa. These shifts\nensure a smooth streaming session; however, it might get a lower mean opinion\nscore. For instance, dropping from 1080p to 480p during a video can preserve\ncontinuity but might reduce the viewers enjoyment. Over time, OTT platforms are\nlooking for alternative ways to boost user experience instead of relying on\ntraditional Quality of Service (QoS) metrics such as bandwidth, latency, and\nthroughput. As a result, we look into the relationship between quality shifting\nin YouTube streaming sessions and the channel metrics RSRP, RSRQ, and SNR. Our\nfindings state that these channel metrics positively correlate with shifts.\nThus, in real-time, OTT can only rely on them to predict video streaming\nsessions into lower- and higher-resolution categories, thus providing more\nresources to improve user experience. Using traditional Machine Learning (ML)\nclassifiers, we achieved an accuracy of 77-percent, while using only RSRP,\nRSRQ, and SNR. In the era of 5G and beyond, where ultra-reliable, low-latency\nnetworks promise enhanced streaming capabilities, the proposed methodology can\nbe used to improve OTT services.", "AI": {"tldr": "The paper explores how channel metrics (RSRP, RSRQ, SNR) correlate with YouTube video quality shifts, proposing ML classifiers to predict shifts and improve QoE.", "motivation": "To enhance YouTube streaming QoE by reducing resolution shifts, moving beyond traditional QoS metrics.", "method": "Analyzed relationship between quality shifts and channel metrics; used ML classifiers for prediction.", "result": "Found positive correlation between channel metrics and shifts; achieved 77% accuracy in predicting shifts.", "conclusion": "Proposed method can improve OTT services, especially in 5G networks, by leveraging channel metrics for better QoE."}}
{"id": "2505.08803", "pdf": "https://arxiv.org/pdf/2505.08803", "abs": "https://arxiv.org/abs/2505.08803", "authors": ["Zizhao Hu", "Mohammad Rostami", "Jesse Thomason"], "title": "Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent research has highlighted the risk of generative model collapse, where\nperformance progressively degrades when continually trained on self-generated\ndata. However, existing exploration on model collapse is limited to single,\nunimodal models, limiting our understanding in more realistic scenarios, such\nas diverse multi-modal AI agents interacting autonomously through synthetic\ndata and continually evolving. We expand the synthetic data training and model\ncollapse study to multi-modal vision-language generative systems, such as\nvision-language models (VLMs) and text-to-image diffusion models, as well as\nrecursive generate-train loops with multiple models. We find that model\ncollapse, previously observed in single-modality generative models, exhibits\ndistinct characteristics in the multi-modal context, such as improved\nvision-language alignment and increased variance in VLM image-captioning task.\nAdditionally, we find that general approaches such as increased decoding\nbudgets, greater model diversity, and relabeling with frozen models can\neffectively mitigate model collapse. Our findings provide initial insights and\npractical guidelines for reducing the risk of model collapse in self-improving\nmulti-agent AI systems and curating robust multi-modal synthetic datasets.", "AI": {"tldr": "The paper explores model collapse in multi-modal generative systems, revealing distinct behaviors and mitigation strategies.", "motivation": "To understand and address model collapse in realistic multi-modal AI scenarios, beyond single-modality models.", "method": "Expands synthetic data training to multi-modal systems (VLMs, diffusion models) and recursive generate-train loops.", "result": "Model collapse in multi-modal systems shows unique traits (e.g., better vision-language alignment) and can be mitigated by methods like increased decoding budgets.", "conclusion": "Provides insights and guidelines for reducing model collapse in self-improving multi-agent AI systems and robust synthetic datasets."}}
{"id": "2505.09382", "pdf": "https://arxiv.org/pdf/2505.09382", "abs": "https://arxiv.org/abs/2505.09382", "authors": ["Zhengyan Sheng", "Jinghao He", "Liping Chen", "Kong Aik Lee", "Zhen-Hua Ling"], "title": "The Voice Timbre Attribute Detection 2025 Challenge Evaluation Plan", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Voice timbre refers to the unique quality or character of a person's voice\nthat distinguishes it from others as perceived by human hearing. The Voice\nTimbre Attribute Detection (VtaD) 2025 challenge focuses on explaining the\nvoice timbre attribute in a comparative manner. In this challenge, the human\nimpression of voice timbre is verbalized with a set of sensory descriptors,\nincluding bright, coarse, soft, magnetic, and so on. The timbre is explained\nfrom the comparison between two voices in their intensity within a specific\ndescriptor dimension. The VtaD 2025 challenge starts in May and culminates in a\nspecial proposal at the NCMMSC2025 conference in October 2025 in Zhenjiang,\nChina.", "AI": {"tldr": "The VtaD 2025 challenge aims to explain voice timbre attributes using sensory descriptors by comparing two voices, culminating in a proposal at NCMMSC2025.", "motivation": "To verbalize and compare human impressions of voice timbre using sensory descriptors like bright, coarse, soft, etc.", "method": "Comparative analysis of voice timbre intensity within specific descriptor dimensions.", "result": "A special proposal will be presented at NCMMSC2025 in Zhenjiang, China.", "conclusion": "The challenge advances understanding of voice timbre through structured comparison and sensory descriptors."}}
{"id": "2505.09615", "pdf": "https://arxiv.org/pdf/2505.09615", "abs": "https://arxiv.org/abs/2505.09615", "authors": ["Yung-Hsuan Lai", "Janek Ebbers", "Yu-Chiang Frank Wang", "Fran\u00e7ois Germain", "Michael Jeffrey Jones", "Moitreya Chatterjee"], "title": "UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing", "categories": ["cs.CV", "cs.SD", "eess.AS"], "comment": "CVPR 2025", "summary": "Audio-Visual Video Parsing (AVVP) entails the challenging task of localizing\nboth uni-modal events (i.e., those occurring exclusively in either the visual\nor acoustic modality of a video) and multi-modal events (i.e., those occurring\nin both modalities concurrently). Moreover, the prohibitive cost of annotating\ntraining data with the class labels of all these events, along with their start\nand end times, imposes constraints on the scalability of AVVP techniques unless\nthey can be trained in a weakly-supervised setting, where only\nmodality-agnostic, video-level labels are available in the training data. To\nthis end, recently proposed approaches seek to generate segment-level\npseudo-labels to better guide model training. However, the absence of\ninter-segment dependencies when generating these pseudo-labels and the general\nbias towards predicting labels that are absent in a segment limit their\nperformance. This work proposes a novel approach towards overcoming these\nweaknesses called Uncertainty-weighted Weakly-supervised Audio-visual Video\nParsing (UWAV). Additionally, our innovative approach factors in the\nuncertainty associated with these estimated pseudo-labels and incorporates a\nfeature mixup based training regularization for improved training. Empirical\nresults show that UWAV outperforms state-of-the-art methods for the AVVP task\non multiple metrics, across two different datasets, attesting to its\neffectiveness and generalizability.", "AI": {"tldr": "UWAV improves AVVP by addressing pseudo-label limitations with uncertainty weighting and feature mixup, outperforming state-of-the-art methods.", "motivation": "The high cost of detailed annotations for AVVP tasks and the limitations of weakly-supervised methods (e.g., lack of inter-segment dependencies and label bias) motivate the need for a better approach.", "method": "Proposes UWAV, which incorporates uncertainty-weighted pseudo-labels and feature mixup regularization to enhance training.", "result": "UWAV outperforms existing methods on AVVP tasks across multiple metrics and datasets.", "conclusion": "UWAV effectively addresses weaknesses in weakly-supervised AVVP, demonstrating superior performance and generalizability."}}
{"id": "2505.08843", "pdf": "https://arxiv.org/pdf/2505.08843", "abs": "https://arxiv.org/abs/2505.08843", "authors": ["Marco Corrias", "Giada Franceschi", "Michele Riva", "Alberto Tampieri", "Karin F\u00f6ttinger", "Ulrike Diebold", "Thomas Pock", "Cesare Franchini"], "title": "Total Variation-Based Image Decomposition and Denoising for Microscopy Images", "categories": ["eess.IV", "cond-mat.mtrl-sci", "cs.CV"], "comment": null, "summary": "Experimentally acquired microscopy images are unavoidably affected by the\npresence of noise and other unwanted signals, which degrade their quality and\nmight hide relevant features. With the recent increase in image acquisition\nrate, modern denoising and restoration solutions become necessary. This study\nfocuses on image decomposition and denoising of microscopy images through a\nworkflow based on total variation (TV), addressing images obtained from various\nmicroscopy techniques, including atomic force microscopy (AFM), scanning\ntunneling microscopy (STM), and scanning electron microscopy (SEM). Our\napproach consists in restoring an image by extracting its unwanted signal\ncomponents and subtracting them from the raw one, or by denoising it. We\nevaluate the performance of TV-$L^1$, Huber-ROF, and TGV-$L^1$ in achieving\nthis goal in distinct study cases. Huber-ROF proved to be the most flexible\none, while TGV-$L^1$ is the most suitable for denoising. Our results suggest a\nwider applicability of this method in microscopy, restricted not only to STM,\nAFM, and SEM images. The Python code used for this study is publicly available\nas part of AiSurf. It is designed to be integrated into experimental workflows\nfor image acquisition or can be used to denoise previously acquired images.", "AI": {"tldr": "The paper proposes a TV-based workflow for denoising and decomposing microscopy images, evaluating TV-L1, Huber-ROF, and TGV-L1 methods. Huber-ROF is most flexible, while TGV-L1 excels in denoising.", "motivation": "Microscopy images are degraded by noise, necessitating modern denoising solutions for high-speed acquisition.", "method": "The approach involves decomposing images to extract unwanted signals or denoising them using TV-based methods (TV-L1, Huber-ROF, TGV-L1).", "result": "Huber-ROF is the most flexible, and TGV-L1 is best for denoising. The method is applicable beyond STM, AFM, and SEM.", "conclusion": "The workflow is widely applicable in microscopy, with publicly available Python code (AiSurf) for integration into experimental workflows."}}
{"id": "2505.09082", "pdf": "https://arxiv.org/pdf/2505.09082", "abs": "https://arxiv.org/abs/2505.09082", "authors": ["Sophie Zhang", "Zhiming Lin"], "title": "CEC-Zero: Chinese Error Correction Solution Based on LLM", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) demonstrate exceptional\nChinese text processing capabilities, particularly in Chinese Spelling\nCorrection (CSC). While LLMs outperform traditional BERT-based models in\naccuracy and robustness, challenges persist in reliability and generalization.\nThis paper proposes CEC-Zero, a novel reinforcement learning (RL) framework\nenabling LLMs to self-correct through autonomous error strategy learning\nwithout external supervision. By integrating RL with LLMs' generative power,\nthe method eliminates dependency on annotated data or auxiliary models.\nExperiments reveal RL-enhanced LLMs achieve industry-viable accuracy and\nsuperior cross-domain generalization, offering a scalable solution for\nreliability optimization in Chinese NLP applications. This breakthrough\nfacilitates LLM deployment in practical Chinese text correction scenarios while\nestablishing a new paradigm for self-improving language models.", "AI": {"tldr": "CEC-Zero is a reinforcement learning framework for LLMs to self-correct Chinese text errors without supervision, improving accuracy and generalization.", "motivation": "Address reliability and generalization challenges in LLMs for Chinese Spelling Correction (CSC).", "method": "Proposes CEC-Zero, an RL framework integrating LLMs' generative power for autonomous error strategy learning without external supervision.", "result": "RL-enhanced LLMs achieve industry-viable accuracy and superior cross-domain generalization.", "conclusion": "CEC-Zero offers a scalable, reliable solution for Chinese NLP applications and sets a new paradigm for self-improving language models."}}
{"id": "2505.09396", "pdf": "https://arxiv.org/pdf/2505.09396", "abs": "https://arxiv.org/abs/2505.09396", "authors": ["Vince Trencsenyi", "Agnieszka Mensfelt", "Kostas Stathis"], "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The rapid rise of large language models (LLMs) has shifted artificial\nintelligence (AI) research toward agentic systems, motivating the use of weaker\nand more flexible notions of agency. However, this shift raises key questions\nabout the extent to which LLM-based agents replicate human strategic reasoning,\nparticularly in game-theoretic settings. In this context, we examine the role\nof agentic sophistication in shaping artificial reasoners' performance by\nevaluating three agent designs: a simple game-theoretic model, an unstructured\nLLM-as-agent model, and an LLM integrated into a traditional agentic framework.\nUsing guessing games as a testbed, we benchmarked these agents against human\nparticipants across general reasoning patterns and individual role-based\nobjectives. Furthermore, we introduced obfuscated game scenarios to assess\nagents' ability to generalise beyond training distributions. Our analysis,\ncovering over 2000 reasoning samples across 25 agent configurations, shows that\nhuman-inspired cognitive structures can enhance LLM agents' alignment with\nhuman strategic behaviour. Still, the relationship between agentic design\ncomplexity and human-likeness is non-linear, highlighting a critical dependence\non underlying LLM capabilities and suggesting limits to simple architectural\naugmentation.", "AI": {"tldr": "The paper explores how LLM-based agents compare to human strategic reasoning in game-theoretic settings, testing three agent designs and finding that human-inspired structures improve alignment, but complexity doesn't linearly correlate with human-likeness.", "motivation": "The rise of LLMs has shifted AI research toward agentic systems, raising questions about their ability to replicate human strategic reasoning, especially in game-theoretic contexts.", "method": "Three agent designs were evaluated: a simple game-theoretic model, an unstructured LLM-as-agent model, and an LLM integrated into a traditional agentic framework. Guessing games were used as a testbed, with obfuscated scenarios to assess generalization.", "result": "Human-inspired cognitive structures improved LLM agents' alignment with human strategic behavior, but the relationship between design complexity and human-likeness was non-linear, depending on LLM capabilities.", "conclusion": "While architectural enhancements can improve LLM agents' human-likeness, there are limits to simple augmentation, emphasizing the role of underlying LLM capabilities."}}
{"id": "2505.09024", "pdf": "https://arxiv.org/pdf/2505.09024", "abs": "https://arxiv.org/abs/2505.09024", "authors": ["Aaron Baughman", "Rahul Agarwal", "Eduardo Morales", "Gozde Akay"], "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, 3 tables", "summary": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment.", "AI": {"tldr": "Meta-prompting aligns LLM outputs with human expectations using agentic reinforcement learning, improving content quality for live events like the US Open 2024.", "motivation": "To solve the Theory of Mind (ToM) alignment problem by ensuring AI-generated text matches human mental expectations.", "method": "Uses an LLM as a Judge (LLMaaJ) to teach another LLM via in-context learning, optimizing text traits like factualness and novelty in a Hilbert vector space.", "result": "Achieved 53.8% alignment with human expectations, improving content quality and coverage of tennis action.", "conclusion": "The method successfully enhances AI-human collaboration in content creation, with applications in sports and entertainment."}}
{"id": "2412.01986", "pdf": "https://arxiv.org/pdf/2412.01986", "abs": "https://arxiv.org/abs/2412.01986", "authors": ["Armin Shafiee Sarvestani", "Sheyang Tang", "Zhou Wang"], "title": "HybridMQA: Exploring Geometry-Texture Interactions for Colored Mesh Quality Assessment", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Mesh quality assessment (MQA) models play a critical role in the design,\noptimization, and evaluation of mesh operation systems in a wide variety of\napplications. Current MQA models, whether model-based methods using\ntopology-aware features or projection-based approaches working on rendered 2D\nprojections, often fail to capture the intricate interactions between texture\nand 3D geometry. We introduce HybridMQA, a first-of-its-kind hybrid\nfull-reference colored MQA framework that integrates model-based and\nprojection-based approaches, capturing complex interactions between textural\ninformation and 3D structures for enriched quality representations. Our method\nemploys graph learning to extract detailed 3D representations, which are then\nprojected to 2D using a novel feature rendering process that precisely aligns\nthem with colored projections. This enables the exploration of geometry-texture\ninteractions via cross-attention, producing comprehensive mesh quality\nrepresentations. Extensive experiments demonstrate HybridMQA's superior\nperformance across diverse datasets, highlighting its ability to effectively\nleverage geometry-texture interactions for a thorough understanding of mesh\nquality. Our implementation will be made publicly available.", "AI": {"tldr": "HybridMQA is a hybrid full-reference colored mesh quality assessment framework combining model-based and projection-based methods to better capture texture-geometry interactions.", "motivation": "Current MQA models fail to adequately capture interactions between texture and 3D geometry, limiting their effectiveness.", "method": "HybridMQA integrates graph learning for 3D representations and a novel feature rendering process for 2D projections, using cross-attention to explore geometry-texture interactions.", "result": "Extensive experiments show HybridMQA outperforms existing methods by effectively leveraging geometry-texture interactions.", "conclusion": "HybridMQA provides a comprehensive solution for mesh quality assessment, with superior performance and public implementation."}}
{"id": "2505.08823", "pdf": "https://arxiv.org/pdf/2505.08823", "abs": "https://arxiv.org/abs/2505.08823", "authors": ["Cody Steinmetz", "Gavin Childress", "Aaron Herbst", "Gavin Jones", "Jasdeep Singh", "Eli Vang", "Keagan Weinstock"], "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical.", "AI": {"tldr": "The paper introduces a method to stably fine-tune full-precision LLMs into ternary (2-bit) models using RMS normalization and a gradual quantization schedule, achieving comparable accuracy without added complexity.", "motivation": "Large language models (LLMs) are costly to deploy due to their scale. While quantization reduces costs, it often degrades accuracy, especially in the ternary regime. The goal is to make ultra-low-bit inference practical without sacrificing performance.", "method": "The approach involves inserting RMS normalization before every linear projection and applying a gradual, layer-wise quantization schedule to fine-tune full-precision checkpoints into ternary LLMs.", "result": "The method matches or surpasses more complex knowledge-distillation pipelines on standard benchmarks, demonstrating that careful normalization can bridge the accuracy gap between ternary and full-precision models.", "conclusion": "Careful normalization and a gradual quantization schedule can make ternary LLMs practical, offering significant memory and computation savings without compromising accuracy."}}
{"id": "2503.11197", "pdf": "https://arxiv.org/pdf/2503.11197", "abs": "https://arxiv.org/abs/2503.11197", "authors": ["Gang Li", "Jizhong Liu", "Heinrich Dinkel", "Yadong Niu", "Junbo Zhang", "Jian Luan"], "title": "Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": null, "summary": "Recently, reinforcement learning (RL) has been shown to greatly enhance the\nreasoning capabilities of large language models (LLMs), and RL-based approaches\nhave been progressively applied to visual multimodal tasks. However, the audio\nmodality has largely been overlooked in these developments. Thus, we conduct a\nseries of RL explorations in audio understanding and reasoning, specifically\nfocusing on the audio question answering (AQA) task. We leverage the group\nrelative policy optimization (GRPO) algorithm to Qwen2-Audio-7B-Instruct, and\nour experiments demonstrated state-of-the-art performance on the MMAU Test-mini\nbenchmark, achieving an accuracy rate of 64.5%. The main findings in this\ntechnical report are as follows: 1) The GRPO algorithm can be effectively\napplied to large audio language models (LALMs), even when the model has only\n8.2B parameters; 2) With only 38k post-training samples, RL significantly\noutperforms supervised fine-tuning (SFT), indicating that RL-based approaches\ncan be effective without large datasets; 3) The explicit reasoning process has\nnot shown significant benefits for AQA tasks, and how to efficiently utilize\ndeep thinking remains an open question for further research; 4) LALMs still lag\nfar behind humans auditory-language reasoning, suggesting that the RL-based\napproaches warrant further exploration. Our project is available at\nhttps://github.com/xiaomi-research/r1-aqa and\nhttps://huggingface.co/mispeech/r1-aqa.", "AI": {"tldr": "RL enhances audio understanding in LLMs using GRPO, achieving 64.5% accuracy on MMAU Test-mini with minimal data.", "motivation": "Audio modality is overlooked in RL-based multimodal tasks, prompting exploration in audio question answering (AQA).", "method": "Applied GRPO algorithm to Qwen2-Audio-7B-Instruct for AQA, testing with 38k post-training samples.", "result": "Achieved state-of-the-art performance (64.5% accuracy), outperforming SFT with minimal data.", "conclusion": "RL is effective for LALMs, but further research is needed for deep reasoning and human-level performance."}}
{"id": "2505.08699", "pdf": "https://arxiv.org/pdf/2505.08699", "abs": "https://arxiv.org/abs/2505.08699", "authors": ["George Saon", "Avihu Dekel", "Alexander Brooks", "Tohru Nagano", "Abraham Daniels", "Aharon Satt", "Ashish Mittal", "Brian Kingsbury", "David Haws", "Edmilson Morais", "Gakuto Kurata", "Hagai Aronowitz", "Ibrahim Ibrahim", "Jeff Kuo", "Kate Soule", "Luis Lastras", "Masayuki Suzuki", "Ron Hoory", "Samuel Thomas", "Sashi Novitasari", "Takashi Fukuda", "Vishal Sunder", "Xiaodong Cui", "Zvi Kons"], "title": "Granite-speech: open-source speech-aware LLMs with strong English ASR capabilities", "categories": ["eess.AS"], "comment": "7 pages, 9 figures", "summary": "Granite-speech LLMs are compact and efficient speech language models\nspecifically designed for English ASR and automatic speech translation (AST).\nThe models were trained by modality aligning the 2B and 8B parameter variants\nof granite-3.3-instruct to speech on publicly available open-source corpora\ncontaining audio inputs and text targets consisting of either human transcripts\nfor ASR or automatically generated translations for AST. Comprehensive\nbenchmarking shows that on English ASR, which was our primary focus, they\noutperform several competitors' models that were trained on orders of magnitude\nmore proprietary data, and they keep pace on English-to-X AST for major\nEuropean languages, Japanese, and Chinese. The speech-specific components are:\na conformer acoustic encoder using block attention and self-conditioning\ntrained with connectionist temporal classification, a windowed\nquery-transformer speech modality adapter used to do temporal downsampling of\nthe acoustic embeddings and map them to the LLM text embedding space, and LoRA\nadapters to further fine-tune the text LLM. Granite-speech-3.3 operates in two\nmodes: in speech mode, it performs ASR and AST by activating the encoder,\nprojector, and LoRA adapters; in text mode, it calls the underlying\ngranite-3.3-instruct model directly (without LoRA), essentially preserving all\nthe text LLM capabilities and safety. Both models are freely available on\nHuggingFace (https://huggingface.co/ibm-granite/granite-speech-3.3-2b and\nhttps://huggingface.co/ibm-granite/granite-speech-3.3-8b) and can be used for\nboth research and commercial purposes under a permissive Apache 2.0 license.", "AI": {"tldr": "Granite-speech LLMs are efficient models for English ASR and AST, outperforming competitors with less data and supporting multiple languages.", "motivation": "To create compact, efficient speech language models for ASR and AST tasks, leveraging publicly available data.", "method": "Modality alignment of granite-3.3-instruct variants, using a conformer encoder, transformer adapter, and LoRA fine-tuning.", "result": "Outperforms competitors in English ASR and matches performance in AST for major languages.", "conclusion": "Granite-speech models are effective, freely available, and versatile for both speech and text tasks."}}
{"id": "2505.08845", "pdf": "https://arxiv.org/pdf/2505.08845", "abs": "https://arxiv.org/abs/2505.08845", "authors": ["Misgina Tsighe Hagos", "Antti Suutala", "Dmitrii Bychkov", "Hakan K\u00fcc\u00fckel", "Joar von Bahr", "Milda Poceviciute", "Johan Lundin", "Nina Linder", "Claes Lundstr\u00f6m"], "title": "Validation of Conformal Prediction in Cervical Atypia Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data.", "AI": {"tldr": "The paper evaluates conformal prediction for cervical cancer classification, highlighting its limitations in alignment with human expectations and proposing expert-annotation-based validation.", "motivation": "Deep learning models for cervical cancer screening lack reliable uncertainty measures, and conformal prediction, while promising, often misaligns with human expectations.", "method": "Three conformal prediction approaches are applied to three deep-learning models for cervical atypia classification, validated using expert annotations.", "result": "Coverage-based evaluations overestimate performance, and current methods produce prediction sets misaligned with human labels.", "conclusion": "Conformal prediction needs refinement to better align with human expectations and improve reliability in clinical settings."}}
{"id": "2505.09269", "pdf": "https://arxiv.org/pdf/2505.09269", "abs": "https://arxiv.org/abs/2505.09269", "authors": ["Ulrich Frank", "Pierre Maier"], "title": "How an unintended Side Effect of a Research Project led to Boosting the Power of UML", "categories": ["cs.CL"], "comment": null, "summary": "This paper describes the design, implementation and use of a new UML modeling\ntool that represents a significant advance over conventional tools. Among other\nthings, it allows the integration of class diagrams and object diagrams as well\nas the execution of objects. This not only enables new software architectures\ncharacterized by the integration of software with corresponding object models,\nbut is also ideal for use in teaching, as it provides students with a\nparticularly stimulating learning experience. A special feature of the project\nis that it has emerged from a long-standing international research project,\nwhich is aimed at a comprehensive multi-level architecture. The project is\ntherefore an example of how research can lead to valuable results that arise as\na side effect of other work.", "AI": {"tldr": "A new UML modeling tool integrates class and object diagrams, supports object execution, and enhances teaching and software architecture.", "motivation": "To advance conventional UML tools by enabling integration of diagrams and object execution, benefiting both software development and education.", "method": "Design and implementation of a UML tool with integrated class/object diagrams and object execution capabilities.", "result": "The tool supports new software architectures and improves learning experiences in teaching.", "conclusion": "The project demonstrates how research can yield valuable side results, exemplified by this innovative UML tool."}}
{"id": "2505.09511", "pdf": "https://arxiv.org/pdf/2505.09511", "abs": "https://arxiv.org/abs/2505.09511", "authors": ["Tianfu Wu", "Jiaqi Fu", "Wugang Meng", "Sungjin Cho", "Huanzhe Zhan", "Fumin Zhang"], "title": "Design of a Formation Control System to Assist Human Operators in Flying a Swarm of Robotic Blimps", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "Formation control is essential for swarm robotics, enabling coordinated\nbehavior in complex environments. In this paper, we introduce a novel formation\ncontrol system for an indoor blimp swarm using a specialized leader-follower\napproach enhanced with a dynamic leader-switching mechanism. This strategy\nallows any blimp to take on the leader role, distributing maneuvering demands\nacross the swarm and enhancing overall formation stability. Only the leader\nblimp is manually controlled by a human operator, while follower blimps use\nonboard monocular cameras and a laser altimeter for relative position and\naltitude estimation. A leader-switching scheme is proposed to assist the human\noperator to maintain stability of the swarm, especially when a sharp turn is\nperformed. Experimental results confirm that the leader-switching mechanism\neffectively maintains stable formations and adapts to dynamic indoor\nenvironments while assisting human operator.", "AI": {"tldr": "A leader-follower formation control system for indoor blimp swarms with dynamic leader-switching enhances stability and adaptability.", "motivation": "To improve swarm coordination and stability in complex indoor environments by distributing leadership roles dynamically.", "method": "Uses a leader-follower approach with dynamic leader-switching, manual control for the leader, and onboard sensors for followers.", "result": "The leader-switching mechanism maintains stable formations and adapts to dynamic environments, aiding human operators.", "conclusion": "The proposed system effectively enhances swarm stability and adaptability in indoor settings."}}
{"id": "2505.09029", "pdf": "https://arxiv.org/pdf/2505.09029", "abs": "https://arxiv.org/abs/2505.09029", "authors": ["Hazim Alzorgan", "Abolfazl Razi"], "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient\n(TD3), depend on basic noise-based exploration, which can result in less than\noptimal policy convergence. In this study, we introduce Monte Carlo Beam Search\n(MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts\nwith TD3 to improve exploration and action selection. MCBS produces several\ncandidate actions around the policy's output and assesses them through\nshort-horizon rollouts, enabling the agent to make better-informed choices. We\ntest MCBS across various continuous-control benchmarks, including\nHalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency\nand performance compared to standard TD3 and other baseline methods like SAC,\nPPO, and A2C. Our findings emphasize MCBS's capability to enhance policy\nlearning through structured look-ahead search while ensuring computational\nefficiency. Additionally, we offer a detailed analysis of crucial\nhyperparameters, such as beam width and rollout depth, and explore adaptive\nstrategies to optimize MCBS for complex control tasks. Our method shows a\nhigher convergence rate across different environments compared to TD3, SAC,\nPPO, and A2C. For instance, we achieved 90% of the maximum achievable reward\nwithin around 200 thousand timesteps compared to 400 thousand timesteps for the\nsecond-best method.", "AI": {"tldr": "MCBS combines beam search and Monte Carlo rollouts with TD3 to improve exploration and policy convergence, outperforming baselines like TD3, SAC, PPO, and A2C in continuous-control tasks.", "motivation": "Basic noise-based exploration in actor-critic methods like TD3 can lead to suboptimal policy convergence, prompting the need for better exploration strategies.", "method": "MCBS generates candidate actions around the policy's output and evaluates them via short-horizon rollouts, enhancing action selection.", "result": "MCBS shows improved sample efficiency and performance, achieving 90% of max reward in 200k timesteps vs. 400k for the next best method.", "conclusion": "MCBS enhances policy learning through structured look-ahead search while maintaining computational efficiency, with adaptive strategies for complex tasks."}}
{"id": "2505.08175", "pdf": "https://arxiv.org/pdf/2505.08175", "abs": "https://arxiv.org/abs/2505.08175", "authors": ["Zachary Novack", "Zach Evans", "Zack Zukowski", "Josiah Taylor", "CJ Carr", "Julian Parker", "Adnan Al-Sinan", "Gian Marco Iodice", "Julian McAuley", "Taylor Berg-Kirkpatrick", "Jordi Pons"], "title": "Fast Text-to-Audio Generation with Adversarial Post-Training", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": null, "summary": "Text-to-audio systems, while increasingly performant, are slow at inference\ntime, thus making their latency unpractical for many creative applications. We\npresent Adversarial Relativistic-Contrastive (ARC) post-training, the first\nadversarial acceleration algorithm for diffusion/flow models not based on\ndistillation. While past adversarial post-training methods have struggled to\ncompare against their expensive distillation counterparts, ARC post-training is\na simple procedure that (1) extends a recent relativistic adversarial\nformulation to diffusion/flow post-training and (2) combines it with a novel\ncontrastive discriminator objective to encourage better prompt adherence. We\npair ARC post-training with a number optimizations to Stable Audio Open and\nbuild a model capable of generating $\\approx$12s of 44.1kHz stereo audio in\n$\\approx$75ms on an H100, and $\\approx$7s on a mobile edge-device, the fastest\ntext-to-audio model to our knowledge.", "AI": {"tldr": "ARC post-training accelerates text-to-audio diffusion models without distillation, achieving ultra-fast inference times.", "motivation": "Current text-to-audio systems suffer from high latency, limiting their practicality for creative applications.", "method": "ARC post-training combines relativistic adversarial formulation with a contrastive discriminator objective to improve speed and prompt adherence.", "result": "The model generates 12s of 44.1kHz stereo audio in 75ms on an H100 and 7s on a mobile edge-device, setting a speed record.", "conclusion": "ARC post-training is a simple yet effective method for accelerating diffusion models, enabling real-time text-to-audio applications."}}
{"id": "2505.08827", "pdf": "https://arxiv.org/pdf/2505.08827", "abs": "https://arxiv.org/abs/2505.08827", "authors": ["Toby Simonds", "Kevin Lopez", "Akira Yoshiyama", "Dominique Garmier"], "title": "Self Rewarding Self Improving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We demonstrate that large language models can effectively self-improve\nthrough self-judging without requiring reference solutions, leveraging the\ninherent asymmetry between generating and verifying solutions. Our experiments\non Countdown puzzles and MIT Integration Bee problems show that models can\nprovide reliable reward signals without ground truth answers, enabling\nreinforcement learning in domains previously not possible. By implementing\nself-judging, we achieve significant performance gains maintaining alignment\nwith formal verification. When combined with synthetic question generation, we\nestablish a complete self-improvement loop where models generate practice\nproblems, solve them, and evaluate their own performance-achieving an 8%\nimprovement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on\nintegration tasks. Our findings demonstrate that LLM judges can provide\neffective reward signals for training models, unlocking many reinforcement\nlearning environments previously limited by the difficulty of creating\nprogrammatic rewards. This suggests a potential paradigm shift toward AI\nsystems that continuously improve through self-directed learning rather than\nhuman-guided training, potentially accelerating progress in domains with scarce\ntraining data or complex evaluation requirements.", "AI": {"tldr": "Large language models (LLMs) can self-improve by judging their own solutions without reference answers, achieving performance gains and enabling reinforcement learning in new domains.", "motivation": "To explore self-improvement in LLMs without relying on human-provided solutions or rewards, leveraging the asymmetry between generating and verifying solutions.", "method": "Models self-judge solutions on tasks like Countdown puzzles and MIT Integration Bee problems, using synthetic question generation and reinforcement learning.", "result": "An 8% improvement over baseline with Qwen 2.5 7B, surpassing GPT-4o on integration tasks, and enabling reinforcement learning in previously challenging domains.", "conclusion": "Self-judging LLMs can provide effective reward signals, enabling self-directed learning and potentially accelerating progress in data-scarce or complex domains."}}
{"id": "2504.05009", "pdf": "https://arxiv.org/pdf/2504.05009", "abs": "https://arxiv.org/abs/2504.05009", "authors": ["Huw Cheston", "Reuben Bance", "Peter M. C. Harrison"], "title": "Deconstructing Jazz Piano Style Using Machine Learning", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "comment": "Paper: 40 pages, 11 figures, 1 table; added information on training\n  time + computation cost, corrections to Table 1. Supplementary material: 33\n  pages, 48 figures, 6 tables; corrections to Table S.5", "summary": "Artistic style has been studied for centuries, and recent advances in machine\nlearning create new possibilities for understanding it computationally.\nHowever, ensuring that machine-learning models produce insights aligned with\nthe interests of practitioners and critics remains a significant challenge.\nHere, we focus on musical style, which benefits from a rich theoretical and\nmathematical analysis tradition. We train a variety of supervised-learning\nmodels to identify 20 iconic jazz musicians across a carefully curated dataset\nof 84 hours of recordings, and interpret their decision-making processes. Our\nmodels include a novel multi-input architecture that enables four musical\ndomains (melody, harmony, rhythm, and dynamics) to be analysed separately.\nThese models enable us to address fundamental questions in music theory and\nalso advance the state-of-the-art in music performer identification (94%\naccuracy across 20 classes). We release open-source implementations of our\nmodels and an accompanying web application for exploring musical styles.", "AI": {"tldr": "The paper explores computational analysis of musical style using machine learning, focusing on jazz musicians. It introduces a multi-input model for analyzing melody, harmony, rhythm, and dynamics, achieving 94% accuracy in performer identification.", "motivation": "To bridge the gap between machine-learning insights and the interests of music practitioners and critics by leveraging computational methods to study musical style.", "method": "Supervised-learning models, including a novel multi-input architecture, are trained on a curated dataset of 84 hours of jazz recordings to analyze four musical domains separately.", "result": "Achieves 94% accuracy in identifying 20 iconic jazz musicians and provides insights into music theory.", "conclusion": "The work advances performer identification and music theory understanding, with open-source models and a web app for style exploration."}}
{"id": "2505.09193", "pdf": "https://arxiv.org/pdf/2505.09193", "abs": "https://arxiv.org/abs/2505.09193", "authors": ["Wei Jiang", "Junru Li", "Kai Zhang", "Li Zhang"], "title": "BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression", "categories": ["eess.IV", "cs.CV"], "comment": "The first learned video codec that surpasses VTM 13.2 RA across all\n  standard test datasets. Code will be available at\n  https://github.com/JiangWeibeta/ECVC", "summary": "Recent forward prediction-based learned video compression (LVC) methods have\nachieved impressive results, even surpassing VVC reference software VTM under\nthe Low Delay B (LDB) configuration. In contrast, learned bidirectional video\ncompression (BVC) remains underexplored and still lags behind its forward-only\ncounterparts. This performance gap is mainly due to the limited ability to\nextract diverse and accurate contexts: most existing BVCs primarily exploit\ntemporal motion while neglecting non-local correlations across frames.\nMoreover, they lack the adaptability to dynamically suppress harmful contexts\narising from fast motion or occlusion. To tackle these challenges, we propose\nBiECVC, a BVC framework that incorporates diversified local and non-local\ncontext modeling along with adaptive context gating. For local context\nenhancement, BiECVC reuses high-quality features from lower layers and aligns\nthem using decoded motion vectors without introducing extra motion overhead.To\nmodel non-local dependencies efficiently, we adopt a linear attention mechanism\nthat balances performance and complexity. To further mitigate the impact of\ninaccurate context prediction, we introduce Bidirectional Context Gating,\ninspired by data-dependent decay in recent autoregressive language models, to\ndynamically filter contextual information based on conditional coding results.\nExtensive experiments demonstrate that BiECVC achieves state-of-the-art\nperformance, reducing the bit-rate by 13.4% and 15.7% compared to VTM 13.2\nunder the Random Access (RA) configuration with intra periods of 32 and 64,\nrespectively. To our knowledge, BiECVC is the first learned video codec to\nsurpass VTM 13.2 RA across all standard test datasets. Code will be available\nat https://github.com/JiangWeibeta/ECVC.", "AI": {"tldr": "BiECVC, a learned bidirectional video compression framework, outperforms VTM 13.2 by enhancing local and non-local context modeling and adaptive gating.", "motivation": "Existing bidirectional video compression (BVC) methods lag behind forward-only ones due to limited context extraction and adaptability.", "method": "BiECVC uses local feature reuse, linear attention for non-local dependencies, and bidirectional context gating for dynamic filtering.", "result": "BiECVC reduces bit-rate by 13.4% and 15.7% compared to VTM 13.2 under RA configuration.", "conclusion": "BiECVC is the first learned video codec to surpass VTM 13.2 RA, setting a new benchmark."}}
{"id": "2505.09286", "pdf": "https://arxiv.org/pdf/2505.09286", "abs": "https://arxiv.org/abs/2505.09286", "authors": ["Jiin Park", "Misuk Kim"], "title": "A Scalable Unsupervised Framework for multi-aspect labeling of Multilingual and Multi-Domain Review Data", "categories": ["cs.CL"], "comment": "36 pages, 3 figures", "summary": "Effectively analyzing online review data is essential across industries.\nHowever, many existing studies are limited to specific domains and languages or\ndepend on supervised learning approaches that require large-scale labeled\ndatasets. To address these limitations, we propose a multilingual, scalable,\nand unsupervised framework for cross-domain aspect detection. This framework is\ndesigned for multi-aspect labeling of multilingual and multi-domain review\ndata. In this study, we apply automatic labeling to Korean and English review\ndatasets spanning various domains and assess the quality of the generated\nlabels through extensive experiments. Aspect category candidates are first\nextracted through clustering, and each review is then represented as an\naspect-aware embedding vector using negative sampling. To evaluate the\nframework, we conduct multi-aspect labeling and fine-tune several pretrained\nlanguage models to measure the effectiveness of the automatically generated\nlabels. Results show that these models achieve high performance, demonstrating\nthat the labels are suitable for training. Furthermore, comparisons with\npublicly available large language models highlight the framework's superior\nconsistency and scalability when processing large-scale data. A human\nevaluation also confirms that the quality of the automatic labels is comparable\nto those created manually. This study demonstrates the potential of a robust\nmulti-aspect labeling approach that overcomes limitations of supervised methods\nand is adaptable to multilingual, multi-domain environments. Future research\nwill explore automatic review summarization and the integration of artificial\nintelligence agents to further improve the efficiency and depth of review\nanalysis.", "AI": {"tldr": "The paper proposes a multilingual, scalable, and unsupervised framework for cross-domain aspect detection in online reviews, achieving high performance with automatically generated labels.", "motivation": "Existing studies are limited by domain/language specificity and reliance on supervised learning, which requires large labeled datasets.", "method": "The framework uses clustering for aspect extraction and aspect-aware embedding vectors with negative sampling. Pretrained language models are fine-tuned to evaluate label quality.", "result": "The framework outperforms large language models in consistency and scalability, with human evaluation confirming label quality comparable to manual labels.", "conclusion": "The study demonstrates a robust, adaptable approach for multi-aspect labeling, with future work aimed at review summarization and AI integration."}}
{"id": "2505.09595", "pdf": "https://arxiv.org/pdf/2505.09595", "abs": "https://arxiv.org/abs/2505.09595", "authors": ["Abdullah Mushtaq", "Imran Taj", "Rafay Naeem", "Ibrahim Ghaznavi", "Junaid Qadir"], "title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": "Preprint. Submitted to the Journal of Artificial Intelligence\n  Research (JAIR) on April 29, 2025", "summary": "Large Language Models (LLMs) are predominantly trained and aligned in ways\nthat reinforce Western-centric epistemologies and socio-cultural norms, leading\nto cultural homogenization and limiting their ability to reflect global\ncivilizational plurality. Existing benchmarking frameworks fail to adequately\ncapture this bias, as they rely on rigid, closed-form assessments that overlook\nthe complexity of cultural inclusivity. To address this, we introduce\nWorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity\n(GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our\napproach is grounded in the Multiplex Worldview proposed by Senturk et al.,\nwhich distinguishes between Uniplex models, reinforcing cultural\nhomogenization, and Multiplex models, which integrate diverse perspectives.\nWorldView-Bench measures Cultural Polarization, the exclusion of alternative\nperspectives, through free-form generative evaluation rather than conventional\ncategorical benchmarks. We implement applied multiplexity through two\nintervention strategies: (1) Contextually-Implemented Multiplex LLMs, where\nsystem prompts embed multiplexity principles, and (2) Multi-Agent System\n(MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing\ndistinct cultural perspectives collaboratively generate responses. Our results\ndemonstrate a significant increase in Perspectives Distribution Score (PDS)\nentropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs,\nalongside a shift toward positive sentiment (67.7%) and enhanced cultural\nbalance. These findings highlight the potential of multiplex-aware AI\nevaluation in mitigating cultural bias in LLMs, paving the way for more\ninclusive and ethically aligned AI systems.", "AI": {"tldr": "WorldView-Bench is introduced to evaluate Global Cultural Inclusivity (GCI) in LLMs, addressing Western-centric biases through multiplexity principles and multi-agent systems, achieving significant improvements in cultural balance.", "motivation": "Current LLMs reinforce Western-centric norms, limiting global cultural plurality. Existing benchmarks fail to capture this bias, necessitating a new approach.", "method": "WorldView-Bench uses free-form generative evaluation and multiplexity principles, implemented via contextual prompts and multi-agent systems.", "result": "MAS-Implemented Multiplex LLMs increased Perspectives Distribution Score entropy from 13% to 94%, with improved sentiment (67.7%) and cultural balance.", "conclusion": "Multiplex-aware AI evaluation can mitigate cultural bias, promoting more inclusive and ethically aligned LLMs."}}
{"id": "2505.09031", "pdf": "https://arxiv.org/pdf/2505.09031", "abs": "https://arxiv.org/abs/2505.09031", "authors": ["Adarsh Kumar", "Hwiyoon Kim", "Jawahar Sai Nathani", "Neil Roy"], "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Hallucination, where large language models (LLMs) generate confident but\nincorrect or irrelevant information, remains a key limitation in their\napplication to complex, open-ended tasks. Chain-of-thought (CoT) prompting has\nemerged as a promising method for improving multistep reasoning by guiding\nmodels through intermediate steps. However, CoT alone does not fully address\nthe hallucination problem. In this work, we investigate how combining CoT with\nretrieval-augmented generation (RAG), as well as applying self-consistency and\nself-verification strategies, can reduce hallucinations and improve factual\naccuracy. By incorporating external knowledge sources during reasoning and\nenabling models to verify or revise their own outputs, we aim to generate more\naccurate and coherent responses. We present a comparative evaluation of\nbaseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification\ntechniques. Our results highlight the effectiveness of each method and identify\nthe most robust approach for minimizing hallucinations while preserving fluency\nand reasoning depth.", "AI": {"tldr": "Combining CoT with RAG and self-verification reduces LLM hallucinations, improving factual accuracy and coherence.", "motivation": "Addressing the hallucination problem in LLMs for complex tasks by enhancing CoT with retrieval and self-checking methods.", "method": "Evaluates CoT, CoT+RAG, self-consistency, and self-verification techniques to reduce hallucinations.", "result": "Identifies the most effective approach for minimizing hallucinations while maintaining reasoning quality.", "conclusion": "Combining CoT with RAG and self-verification is robust for reducing hallucinations in LLMs."}}
{"id": "2505.08829", "pdf": "https://arxiv.org/pdf/2505.08829", "abs": "https://arxiv.org/abs/2505.08829", "authors": ["David Kinney"], "title": "Aggregating Concepts of Fairness and Accuracy in Predictive Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al.", "AI": {"tldr": "The paper proposes using a linear combination of accuracy and fairness metrics to evaluate predictive algorithms, addressing trade-offs between these goals.", "motivation": "The rise of powerful AI predictive algorithms highlights the tension between accuracy and fairness, with no clear guidelines for balancing these goals or aggregating diverse metrics.", "method": "The paper argues for a linear combination of accuracy and fairness metrics, leveraging Harsanyi's preference aggregation theory, and applies this to the COMPAS dataset.", "result": "The approach provides a formal framework for evaluating predictive algorithms when both accuracy and fairness are valued.", "conclusion": "A linear combination of metrics offers a principled way to manage accuracy-fairness trade-offs, supported by theoretical and empirical analysis."}}
{"id": "2505.09323", "pdf": "https://arxiv.org/pdf/2505.09323", "abs": "https://arxiv.org/abs/2505.09323", "authors": ["Pengli Zhu", "Yingji Fu", "Nanguang Chen", "Anqi Qiu"], "title": "Q-space Guided Collaborative Attention Translation Network for Flexible Diffusion-Weighted Images Synthesis", "categories": ["eess.IV", "cs.CV"], "comment": "MICCAI 2025", "summary": "This study, we propose a novel Q-space Guided Collaborative Attention\nTranslation Networks (Q-CATN) for multi-shell, high-angular resolution DWI\n(MS-HARDI) synthesis from flexible q-space sampling, leveraging the commonly\nacquired structural MRI data. Q-CATN employs a collaborative attention\nmechanism to effectively extract complementary information from multiple\nmodalities and dynamically adjust its internal representations based on\nflexible q-space information, eliminating the need for fixed sampling schemes.\nAdditionally, we introduce a range of task-specific constraints to preserve\nanatomical fidelity in DWI, enabling Q-CATN to accurately learn the intrinsic\nrelationships between directional DWI signal distributions and q-space.\nExtensive experiments on the Human Connectome Project (HCP) dataset demonstrate\nthat Q-CATN outperforms existing methods, including 1D-qDL, 2D-qDL, MESC-SD,\nand QGAN, in estimating parameter maps and fiber tracts both quantitatively and\nqualitatively, while preserving fine-grained details. Notably, its ability to\naccommodate flexible q-space sampling highlights its potential as a promising\ntoolkit for clinical and research applications. Our code is available at\nhttps://github.com/Idea89560041/Q-CATN.", "AI": {"tldr": "Q-CATN is a novel network for synthesizing MS-HARDI DWI from flexible q-space sampling, using structural MRI data and collaborative attention. It outperforms existing methods in accuracy and detail preservation.", "motivation": "To address the limitations of fixed q-space sampling schemes in DWI synthesis and leverage structural MRI data for improved multi-modal information extraction.", "method": "Q-CATN uses a collaborative attention mechanism to dynamically adjust representations based on flexible q-space sampling and incorporates task-specific constraints for anatomical fidelity.", "result": "Q-CATN surpasses existing methods (1D-qDL, 2D-qDL, MESC-SD, QGAN) in estimating parameter maps and fiber tracts, preserving fine details.", "conclusion": "Q-CATN is a versatile tool for clinical and research applications, accommodating flexible q-space sampling effectively."}}
{"id": "2505.09316", "pdf": "https://arxiv.org/pdf/2505.09316", "abs": "https://arxiv.org/abs/2505.09316", "authors": ["Hongjin Qian", "Zheng Liu"], "title": "Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging", "categories": ["cs.CL", "cs.IR"], "comment": "16 pages", "summary": "Augmenting large language models (LLMs) with external retrieval has become a\nstandard method to address their inherent knowledge cutoff limitations.\nHowever, traditional retrieval-augmented generation methods employ static,\npre-inference retrieval strategies, making them inadequate for complex tasks\ninvolving ambiguous, multi-step, or evolving information needs. Recent advances\nin test-time scaling techniques have demonstrated significant potential in\nenabling LLMs to dynamically interact with external tools, motivating the shift\ntoward adaptive inference-time retrieval. Inspired by Information Foraging\nTheory (IFT), we propose InForage, a reinforcement learning framework that\nformalizes retrieval-augmented reasoning as a dynamic information-seeking\nprocess. Unlike existing approaches, InForage explicitly rewards intermediate\nretrieval quality, encouraging LLMs to iteratively gather and integrate\ninformation through adaptive search behaviors. To facilitate training, we\nconstruct a human-guided dataset capturing iterative search and reasoning\ntrajectories for complex, real-world web tasks. Extensive evaluations across\ngeneral question answering, multi-hop reasoning tasks, and a newly developed\nreal-time web QA dataset demonstrate InForage's superior performance over\nbaseline methods. These results highlight InForage's effectiveness in building\nrobust, adaptive, and efficient reasoning agents.", "AI": {"tldr": "InForage, a reinforcement learning framework, enhances LLMs by enabling adaptive retrieval during inference, outperforming traditional static methods in complex tasks.", "motivation": "Address limitations of static retrieval-augmented LLMs for complex, evolving tasks by leveraging dynamic, adaptive retrieval inspired by Information Foraging Theory.", "method": "Proposes InForage, a reinforcement learning framework that rewards intermediate retrieval quality, using a human-guided dataset for training.", "result": "Superior performance in general QA, multi-hop reasoning, and real-time web QA tasks compared to baseline methods.", "conclusion": "InForage effectively builds adaptive, efficient reasoning agents for complex information needs."}}
{"id": "2405.18044", "pdf": "https://arxiv.org/pdf/2405.18044", "abs": "https://arxiv.org/abs/2405.18044", "authors": ["Jiaqi Shao", "Tianjun Yuan", "Tao Lin", "Bing Luo"], "title": "Cognitive Insights and Stable Coalition Matching for Fostering Multi-Agent Cooperation", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Cognitive abilities, such as Theory of Mind (ToM), play a vital role in\nfacilitating cooperation in human social interactions. However, our study\nreveals that agents with higher ToM abilities may not necessarily exhibit\nbetter cooperative behavior compared to those with lower ToM abilities. To\naddress this challenge, we propose a novel matching coalition mechanism that\nleverages the strengths of agents with different ToM levels by explicitly\nconsidering belief alignment and specialized abilities when forming coalitions.\nOur proposed matching algorithm seeks to find stable coalitions that maximize\nthe potential for cooperative behavior and ensure long-term viability. By\nincorporating cognitive insights into the design of multi-agent systems, our\nwork demonstrates the potential of leveraging ToM to create more sophisticated\nand human-like coordination strategies that foster cooperation and improve\noverall system performance.", "AI": {"tldr": "Agents with higher Theory of Mind (ToM) don't always cooperate better. A new matching coalition mechanism aligns beliefs and abilities to improve cooperation.", "motivation": "To enhance cooperation in multi-agent systems by leveraging ToM despite its limitations.", "method": "Proposes a matching coalition mechanism considering belief alignment and specialized abilities.", "result": "Stable coalitions maximize cooperation and system performance.", "conclusion": "Incorporating ToM in multi-agent systems improves coordination and cooperation."}}
{"id": "2505.09114", "pdf": "https://arxiv.org/pdf/2505.09114", "abs": "https://arxiv.org/abs/2505.09114", "authors": ["Minh Hoang Nguyen", "Linh Le Pham Van", "Thommen George Karimpanal", "Sunil Gupta", "Hung Le"], "title": "Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Decision Transformers (DT) play a crucial role in modern reinforcement\nlearning, leveraging offline datasets to achieve impressive results across\nvarious domains. However, DT requires high-quality, comprehensive data to\nperform optimally. In real-world applications, the lack of training data and\nthe scarcity of optimal behaviours make training on offline datasets\nchallenging, as suboptimal data can hinder performance. To address this, we\npropose the Counterfactual Reasoning Decision Transformer (CRDT), a novel\nframework inspired by counterfactual reasoning. CRDT enhances DT ability to\nreason beyond known data by generating and utilizing counterfactual\nexperiences, enabling improved decision-making in unseen scenarios. Experiments\nacross Atari and D4RL benchmarks, including scenarios with limited data and\naltered dynamics, demonstrate that CRDT outperforms conventional DT approaches.\nAdditionally, reasoning counterfactually allows the DT agent to obtain\nstitching abilities, combining suboptimal trajectories, without architectural\nmodifications. These results highlight the potential of counterfactual\nreasoning to enhance reinforcement learning agents' performance and\ngeneralization capabilities.", "AI": {"tldr": "CRDT improves Decision Transformers by using counterfactual reasoning to handle suboptimal data and enhance decision-making in unseen scenarios.", "motivation": "Traditional Decision Transformers struggle with suboptimal or limited offline data, hindering performance. CRDT addresses this by leveraging counterfactual reasoning.", "method": "CRDT generates and uses counterfactual experiences to enhance reasoning and decision-making without architectural changes.", "result": "CRDT outperforms conventional DT in Atari and D4RL benchmarks, especially in limited-data and altered-dynamics scenarios, and enables trajectory stitching.", "conclusion": "Counterfactual reasoning significantly boosts DT performance and generalization, showcasing its potential in reinforcement learning."}}
{"id": "2505.08846", "pdf": "https://arxiv.org/pdf/2505.08846", "abs": "https://arxiv.org/abs/2505.08846", "authors": ["Felix Marti-Perez", "Brigt H\u00e5vardstun", "C\u00e8sar Ferri", "Carlos Monserrat", "Jan Arne Telle"], "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we introduce metrics to evaluate the use of simplified time\nseries in the context of interpretability of a TSC - a Time Series Classifier.\nSuch simplifications are important because time series data, in contrast to\ntext and image data, are not intuitively understandable to humans. These\nmetrics are related to the complexity of the simplifications - how many\nsegments they contain - and to their loyalty - how likely they are to maintain\nthe classification of the original time series. We employ these metrics to\nevaluate four distinct simplification algorithms, across several TSC algorithms\nand across datasets of varying characteristics, from seasonal or stationary to\nshort or long. Our findings suggest that using simplifications for\ninterpretability of TSC is much better than using the original time series,\nparticularly when the time series are seasonal, non-stationary and/or with low\nentropy.", "AI": {"tldr": "Metrics for evaluating simplified time series in TSC interpretability show better results than using original data, especially for seasonal, non-stationary, or low-entropy series.", "motivation": "Time series data are not intuitively understandable to humans, unlike text or images, necessitating simplifications for interpretability.", "method": "Introduced metrics for complexity and loyalty of simplifications, evaluated four algorithms across various TSC methods and datasets.", "result": "Simplifications outperform original time series for interpretability, particularly in seasonal, non-stationary, or low-entropy cases.", "conclusion": "Simplified time series enhance TSC interpretability, especially for complex datasets."}}
{"id": "2505.09334", "pdf": "https://arxiv.org/pdf/2505.09334", "abs": "https://arxiv.org/abs/2505.09334", "authors": ["Sadman Sakib Alif", "Nasim Anzum Promise", "Fiaz Al Abid", "Aniqua Nusrat Zereen"], "title": "DCSNet: A Lightweight Knowledge Distillation-Based Model with Explainable AI for Lung Cancer Diagnosis from Histopathological Images", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Lung cancer is a leading cause of cancer-related deaths globally, where early\ndetection and accurate diagnosis are critical for improving survival rates.\nWhile deep learning, particularly convolutional neural networks (CNNs), has\nrevolutionized medical image analysis by detecting subtle patterns indicative\nof early-stage lung cancer, its adoption faces challenges. These models are\noften computationally expensive and require significant resources, making them\nunsuitable for resource constrained environments. Additionally, their lack of\ntransparency hinders trust and broader adoption in sensitive fields like\nhealthcare. Knowledge distillation addresses these challenges by transferring\nknowledge from large, complex models (teachers) to smaller, lightweight models\n(students). We propose a knowledge distillation-based approach for lung cancer\ndetection, incorporating explainable AI (XAI) techniques to enhance model\ntransparency. Eight CNNs, including ResNet50, EfficientNetB0, EfficientNetB3,\nand VGG16, are evaluated as teacher models. We developed and trained a\nlightweight student model, Distilled Custom Student Network (DCSNet) using\nResNet50 as the teacher. This approach not only ensures high diagnostic\nperformance in resource-constrained settings but also addresses transparency\nconcerns, facilitating the adoption of AI-driven diagnostic tools in\nhealthcare.", "AI": {"tldr": "The paper proposes a knowledge distillation-based approach for lung cancer detection, using lightweight models and explainable AI to improve efficiency and transparency.", "motivation": "Early detection of lung cancer is critical, but deep learning models face challenges like high computational costs and lack of transparency, limiting their adoption in healthcare.", "method": "The study evaluates eight CNN teacher models (e.g., ResNet50, EfficientNetB0) and develops a lightweight student model (DCSNet) using knowledge distillation and explainable AI techniques.", "result": "The approach achieves high diagnostic performance while being suitable for resource-constrained environments and enhancing model transparency.", "conclusion": "The proposed method facilitates the adoption of AI-driven diagnostic tools in healthcare by balancing efficiency, accuracy, and transparency."}}
{"id": "2505.08800", "pdf": "https://arxiv.org/pdf/2505.08800", "abs": "https://arxiv.org/abs/2505.08800", "authors": ["Olivia Nocentini", "Marta Lagomarsino", "Gokhan Solak", "Younggeol Cho", "Qiyi Tong", "Marta Lorenzini", "Arash Ajoudani"], "title": "Graph-based Online Monitoring of Train Driver States via Facial and Skeletal Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Driver fatigue poses a significant challenge to railway safety, with\ntraditional systems like the dead-man switch offering limited and basic\nalertness checks. This study presents an online behavior-based monitoring\nsystem utilizing a customised Directed-Graph Neural Network (DGNN) to classify\ntrain driver's states into three categories: alert, not alert, and\npathological. To optimize input representations for the model, an ablation\nstudy was performed, comparing three feature configurations: skeletal-only,\nfacial-only, and a combination of both. Experimental results show that\ncombining facial and skeletal features yields the highest accuracy (80.88%) in\nthe three-class model, outperforming models using only facial or skeletal\nfeatures. Furthermore, this combination achieves over 99% accuracy in the\nbinary alertness classification. Additionally, we introduced a novel dataset\nthat, for the first time, incorporates simulated pathological conditions into\ntrain driver monitoring, broadening the scope for assessing risks related to\nfatigue and health. This work represents a step forward in enhancing railway\nsafety through advanced online monitoring using vision-based technologies.", "AI": {"tldr": "The paper introduces a DGNN-based online monitoring system for train driver fatigue, combining facial and skeletal features for improved accuracy, and presents a novel dataset including pathological conditions.", "motivation": "Addressing the limitations of traditional alertness checks in railway safety by developing a more advanced, behavior-based monitoring system.", "method": "Uses a Directed-Graph Neural Network (DGNN) to classify driver states (alert, not alert, pathological) and compares feature configurations (skeletal-only, facial-only, combined) through an ablation study.", "result": "Combined facial and skeletal features achieve 80.88% accuracy in three-class classification and over 99% in binary alertness classification. A novel dataset with simulated pathological conditions is introduced.", "conclusion": "The study advances railway safety by leveraging vision-based technologies for more accurate and comprehensive driver fatigue monitoring."}}
{"id": "2505.09338", "pdf": "https://arxiv.org/pdf/2505.09338", "abs": "https://arxiv.org/abs/2505.09338", "authors": ["Jingcheng Niu", "Xingdi Yuan", "Tong Wang", "Hamidreza Saghir", "Amir H. Abdi"], "title": "Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "We observe a novel phenomenon, contextual entrainment, across a wide range of\nlanguage models (LMs) and prompt settings, providing a new mechanistic\nperspective on how LMs become distracted by ``irrelevant'' contextual\ninformation in the input prompt. Specifically, LMs assign significantly higher\nlogits (or probabilities) to any tokens that have previously appeared in the\ncontext prompt, even for random tokens. This suggests that contextual\nentrainment is a mechanistic phenomenon, occurring independently of the\nrelevance or semantic relation of the tokens to the question or the rest of the\nsentence. We find statistically significant evidence that the magnitude of\ncontextual entrainment is influenced by semantic factors. Counterfactual\nprompts have a greater effect compared to factual ones, suggesting that while\ncontextual entrainment is a mechanistic phenomenon, it is modulated by semantic\nfactors.\n  We hypothesise that there is a circuit of attention heads -- the entrainment\nheads -- that corresponds to the contextual entrainment phenomenon. Using a\nnovel entrainment head discovery method based on differentiable masking, we\nidentify these heads across various settings. When we ``turn off'' these heads,\ni.e., set their outputs to zero, the effect of contextual entrainment is\nsignificantly attenuated, causing the model to generate output that capitulates\nto what it would produce if no distracting context were provided. Our discovery\nof contextual entrainment, along with our investigation into LM distraction via\nthe entrainment heads, marks a key step towards the mechanistic analysis and\nmitigation of the distraction problem.", "AI": {"tldr": "The paper introduces \"contextual entrainment,\" a phenomenon where language models (LMs) favor tokens from the input context, regardless of relevance. It identifies \"entrainment heads\" as the cause and shows how disabling them reduces distraction.", "motivation": "To understand and mitigate how LMs get distracted by irrelevant context, providing a mechanistic perspective.", "method": "Uses statistical analysis and a novel differentiable masking method to identify \"entrainment heads\" responsible for contextual entrainment. Tests counterfactual vs. factual prompts.", "result": "LMs disproportionately favor context tokens. Disabling entrainment heads reduces this effect, improving model focus.", "conclusion": "Contextual entrainment is a mechanistic but semantically modulated phenomenon. Identifying and mitigating it advances LM analysis and distraction reduction."}}
{"id": "2504.12777", "pdf": "https://arxiv.org/pdf/2504.12777", "abs": "https://arxiv.org/abs/2504.12777", "authors": ["James Rudd-Jones", "Mirco Musolesi", "Mar\u00eda P\u00e9rez-Ortiz"], "title": "Multi-Agent Reinforcement Learning Simulation for Environmental Policy Synthesis", "categories": ["cs.MA", "cs.AI"], "comment": "Published in AAMAS'25 Blue Sky Ideas Track", "summary": "Climate policy development faces significant challenges due to deep\nuncertainty, complex system dynamics, and competing stakeholder interests.\nClimate simulation methods, such as Earth System Models, have become valuable\ntools for policy exploration. However, their typical use is for evaluating\npotential polices, rather than directly synthesizing them. The problem can be\ninverted to optimize for policy pathways, but the traditional optimization\napproaches often struggle with non-linear dynamics, heterogeneous agents, and\ncomprehensive uncertainty quantification. We propose a framework for augmenting\nclimate simulations with Multi-Agent Reinforcement Learning (MARL) to address\nthese limitations. We identify key challenges at the interface between climate\nsimulations and the application of MARL in the context of policy synthesis,\nincluding reward definition, scalability with increasing agents and state\nspaces, uncertainty propagation across linked systems, and solution validation.\nAdditionally, we discuss challenges in making MARL-derived solutions\ninterpretable and useful for policy-makers. Our framework provides a foundation\nfor more sophisticated climate policy exploration while acknowledging important\nlimitations and areas for future research.", "AI": {"tldr": "The paper proposes using Multi-Agent Reinforcement Learning (MARL) to enhance climate policy synthesis, addressing challenges like non-linear dynamics and uncertainty quantification.", "motivation": "Climate policy development is hindered by uncertainty, complex dynamics, and stakeholder conflicts. Traditional methods like Earth System Models are limited to policy evaluation, not synthesis.", "method": "The framework integrates MARL with climate simulations to optimize policy pathways, tackling issues like reward definition, scalability, and uncertainty propagation.", "result": "The approach offers a foundation for advanced climate policy exploration but highlights limitations in interpretability and validation.", "conclusion": "MARL-augmented climate simulations can improve policy synthesis, though further research is needed to address interpretability and scalability challenges."}}
{"id": "2505.09289", "pdf": "https://arxiv.org/pdf/2505.09289", "abs": "https://arxiv.org/abs/2505.09289", "authors": ["Pedro M. P. Curvo", "Mara Dragomir", "Salvador Torpes", "Mohammadmahdi Rahimi"], "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "categories": ["cs.AI"], "comment": "11 Tables, 9 Figures", "summary": "This study evaluates and extends the findings made by Piatti et al., who\nintroduced GovSim, a simulation framework designed to assess the cooperative\ndecision-making capabilities of large language models (LLMs) in\nresource-sharing scenarios. By replicating key experiments, we validate claims\nregarding the performance of large models, such as GPT-4-turbo, compared to\nsmaller models. The impact of the universalization principle is also examined,\nwith results showing that large models can achieve sustainable cooperation,\nwith or without the principle, while smaller models fail without it. In\naddition, we provide multiple extensions to explore the applicability of the\nframework to new settings. We evaluate additional models, such as DeepSeek-V3\nand GPT-4o-mini, to test whether cooperative behavior generalizes across\ndifferent architectures and model sizes. Furthermore, we introduce new\nsettings: we create a heterogeneous multi-agent environment, study a scenario\nusing Japanese instructions, and explore an \"inverse environment\" where agents\nmust cooperate to mitigate harmful resource distributions. Our results confirm\nthat the benchmark can be applied to new models, scenarios, and languages,\noffering valuable insights into the adaptability of LLMs in complex cooperative\ntasks. Moreover, the experiment involving heterogeneous multi-agent systems\ndemonstrates that high-performing models can influence lower-performing ones to\nadopt similar behaviors. This finding has significant implications for other\nagent-based applications, potentially enabling more efficient use of\ncomputational resources and contributing to the development of more effective\ncooperative AI systems.", "AI": {"tldr": "The study validates and extends GovSim, a framework for assessing LLMs' cooperative decision-making, confirming large models like GPT-4-turbo outperform smaller ones. It explores new models, scenarios, and languages, showing adaptability and influence in heterogeneous systems.", "motivation": "To validate and expand on GovSim's findings, assessing LLMs' cooperative abilities and testing their adaptability in diverse settings.", "method": "Replicated key experiments, evaluated additional models (e.g., DeepSeek-V3, GPT-4o-mini), and introduced new scenarios (heterogeneous multi-agent systems, Japanese instructions, inverse environments).", "result": "Large models achieve sustainable cooperation regardless of the universalization principle, while smaller models fail without it. The framework adapts to new models, languages, and scenarios, with high-performing models influencing lower-performing ones.", "conclusion": "The study confirms GovSim's applicability to diverse cooperative tasks, highlighting the adaptability of LLMs and their potential for efficient cooperative AI systems."}}
{"id": "2505.08915", "pdf": "https://arxiv.org/pdf/2505.08915", "abs": "https://arxiv.org/abs/2505.08915", "authors": ["Jialin Mao", "Itay Griniasty", "Yan Sun", "Mark K. Transtrum", "James P. Sethna", "Pratik Chaudhari"], "title": "An Analytical Characterization of Sloppiness in Neural Networks: Insights from Linear Models", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech"], "comment": null, "summary": "Recent experiments have shown that training trajectories of multiple deep\nneural networks with different architectures, optimization algorithms,\nhyper-parameter settings, and regularization methods evolve on a remarkably\nlow-dimensional \"hyper-ribbon-like\" manifold in the space of probability\ndistributions. Inspired by the similarities in the training trajectories of\ndeep networks and linear networks, we analytically characterize this phenomenon\nfor the latter. We show, using tools in dynamical systems theory, that the\ngeometry of this low-dimensional manifold is controlled by (i) the decay rate\nof the eigenvalues of the input correlation matrix of the training data, (ii)\nthe relative scale of the ground-truth output to the weights at the beginning\nof training, and (iii) the number of steps of gradient descent. By analytically\ncomputing and bounding the contributions of these quantities, we characterize\nphase boundaries of the region where hyper-ribbons are to be expected. We also\nextend our analysis to kernel machines and linear models that are trained with\nstochastic gradient descent.", "AI": {"tldr": "The paper analyzes the low-dimensional \"hyper-ribbon-like\" manifold in deep neural network training trajectories, focusing on linear networks. It identifies key factors controlling this geometry and extends the analysis to kernel machines and SGD-trained linear models.", "motivation": "To understand the common low-dimensional manifold observed in training trajectories of diverse deep networks by analytically studying linear networks.", "method": "Uses dynamical systems theory to analyze the manifold's geometry, focusing on input correlation eigenvalues, initial weight-output scale, and gradient descent steps.", "result": "Characterizes phase boundaries for hyper-ribbon emergence and extends findings to kernel machines and SGD-trained linear models.", "conclusion": "The study provides theoretical insights into the low-dimensional training dynamics of neural networks, applicable to broader machine learning models."}}
{"id": "2505.09521", "pdf": "https://arxiv.org/pdf/2505.09521", "abs": "https://arxiv.org/abs/2505.09521", "authors": ["Dongyi He", "Shiyang Li", "Bin Jiang", "He Yan"], "title": "Spec2VolCAMU-Net: A Spectrogram-to-Volume Model for EEG-to-fMRI Reconstruction based on Multi-directional Time-Frequency Convolutional Attention Encoder and Vision-Mamba U-Net", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "High-resolution functional magnetic resonance imaging (fMRI) is essential for\nmapping human brain activity; however, it remains costly and logistically\nchallenging. If comparable volumes could be generated directly from widely\navailable scalp electroencephalography (EEG), advanced neuroimaging would\nbecome significantly more accessible. Existing EEG-to-fMRI generators rely on\nplain CNNs that fail to capture cross-channel time-frequency cues or on heavy\ntransformer/GAN decoders that strain memory and stability. We propose\nSpec2VolCAMU-Net, a lightweight spectrogram-to-volume generator that confronts\nthese issues via a Multi-directional Time-Frequency Convolutional Attention\nEncoder, stacking temporal, spectral and joint convolutions with\nself-attention, and a Vision-Mamba U-Net decoder whose linear-time state-space\nblocks enable efficient long-range spatial modelling. Trained end-to-end with a\nhybrid SSI-MSE loss, Spec2VolCAMU-Net achieves state-of-the-art fidelity on\nthree public benchmarks, recording SSIMs of 0.693 on NODDI, 0.725 on Oddball\nand 0.788 on CN-EPFL, representing improvements of 14.5%, 14.9%, and 16.9%\nrespectively over previous best SSIM scores. Furthermore, it achieves\ncompetitive PSNR scores, particularly excelling on the CN-EPFL dataset with a\n4.6% improvement over the previous best PSNR, thus striking a better balance in\nreconstruction quality. The proposed model is lightweight and efficient, making\nit suitable for real-time applications in clinical and research settings. The\ncode is available at https://github.com/hdy6438/Spec2VolCAMU-Net.", "AI": {"tldr": "A lightweight EEG-to-fMRI generator, Spec2VolCAMU-Net, improves reconstruction quality and efficiency using a novel encoder-decoder architecture.", "motivation": "High-resolution fMRI is costly and logistically challenging, while EEG is widely available. A reliable EEG-to-fMRI generator could democratize advanced neuroimaging.", "method": "Proposes Spec2VolCAMU-Net with a Multi-directional Time-Frequency Convolutional Attention Encoder and Vision-Mamba U-Net decoder, trained with a hybrid SSI-MSE loss.", "result": "Achieves state-of-the-art fidelity on three benchmarks (NODDI, Oddball, CN-EPFL) with SSIM improvements of 14.5%, 14.9%, and 16.9%, and competitive PSNR scores.", "conclusion": "The model is lightweight, efficient, and suitable for real-time applications, advancing EEG-to-fMRI reconstruction quality."}}
{"id": "2505.08801", "pdf": "https://arxiv.org/pdf/2505.08801", "abs": "https://arxiv.org/abs/2505.08801", "authors": ["Md. Sakib Hassan Chowdhury", "Md. Hafiz Ahamed", "Bishowjit Paul", "Sarafat Hussain Abhi", "Abu Bakar Siddique", "Md. Robius Sany"], "title": "OptiGait-LGBM: An Efficient Approach of Gait-based Person Re-identification in Non-Overlapping Regions", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "12 pages, 17 figures", "summary": "Gait recognition, known for its ability to identify individuals from a\ndistance, has gained significant attention in recent times due to its\nnon-intrusive verification. While video-based gait identification systems\nperform well on large public datasets, their performance drops when applied to\nreal-world, unconstrained gait data due to various factors. Among these,\nuncontrolled outdoor environments, non-overlapping camera views, varying\nillumination, and computational efficiency are core challenges in gait-based\nauthentication. Currently, no dataset addresses all these challenges\nsimultaneously. In this paper, we propose an OptiGait-LGBM model capable of\nrecognizing person re-identification under these constraints using a skeletal\nmodel approach, which helps mitigate inconsistencies in a person's appearance.\nThe model constructs a dataset from landmark positions, minimizing memory usage\nby using non-sequential data. A benchmark dataset, RUET-GAIT, is introduced to\nrepresent uncontrolled gait sequences in complex outdoor environments. The\nprocess involves extracting skeletal joint landmarks, generating numerical\ndatasets, and developing an OptiGait-LGBM gait classification model. Our aim is\nto address the aforementioned challenges with minimal computational cost\ncompared to existing methods. A comparative analysis with ensemble techniques\nsuch as Random Forest and CatBoost demonstrates that the proposed approach\noutperforms them in terms of accuracy, memory usage, and training time. This\nmethod provides a novel, low-cost, and memory-efficient video-based gait\nrecognition solution for real-world scenarios.", "AI": {"tldr": "Proposes OptiGait-LGBM, a skeletal model-based gait recognition method, addressing real-world challenges like uncontrolled environments and computational efficiency. Introduces RUET-GAIT dataset and outperforms existing methods.", "motivation": "Current gait recognition systems struggle with real-world, unconstrained data due to factors like varying illumination and non-overlapping camera views. No existing dataset tackles all these challenges.", "method": "Uses skeletal joint landmarks to create a numerical dataset, minimizing memory usage. Develops OptiGait-LGBM model for gait classification, focusing on efficiency.", "result": "Outperforms ensemble techniques (Random Forest, CatBoost) in accuracy, memory usage, and training time.", "conclusion": "OptiGait-LGBM offers a low-cost, memory-efficient solution for real-world gait recognition, validated by the RUET-GAIT dataset."}}
{"id": "2505.09388", "pdf": "https://arxiv.org/pdf/2505.09388", "abs": "https://arxiv.org/abs/2505.09388", "authors": ["An Yang", "Anfeng Li", "Baosong Yang", "Beichen Zhang", "Binyuan Hui", "Bo Zheng", "Bowen Yu", "Chang Gao", "Chengen Huang", "Chenxu Lv", "Chujie Zheng", "Dayiheng Liu", "Fan Zhou", "Fei Huang", "Feng Hu", "Hao Ge", "Haoran Wei", "Huan Lin", "Jialong Tang", "Jian Yang", "Jianhong Tu", "Jianwei Zhang", "Jianxin Yang", "Jiaxi Yang", "Jing Zhou", "Jingren Zhou", "Junyang Lin", "Kai Dang", "Keqin Bao", "Kexin Yang", "Le Yu", "Lianghao Deng", "Mei Li", "Mingfeng Xue", "Mingze Li", "Pei Zhang", "Peng Wang", "Qin Zhu", "Rui Men", "Ruize Gao", "Shixuan Liu", "Shuang Luo", "Tianhao Li", "Tianyi Tang", "Wenbiao Yin", "Xingzhang Ren", "Xinyu Wang", "Xinyu Zhang", "Xuancheng Ren", "Yang Fan", "Yang Su", "Yichang Zhang", "Yinger Zhang", "Yu Wan", "Yuqiong Liu", "Zekun Wang", "Zeyu Cui", "Zhenru Zhang", "Zhipeng Zhou", "Zihan Qiu"], "title": "Qwen3 Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we present Qwen3, the latest version of the Qwen model family.\nQwen3 comprises a series of large language models (LLMs) designed to advance\nperformance, efficiency, and multilingual capabilities. The Qwen3 series\nincludes models of both dense and Mixture-of-Expert (MoE) architectures, with\nparameter scales ranging from 0.6 to 235 billion. A key innovation in Qwen3 is\nthe integration of thinking mode (for complex, multi-step reasoning) and\nnon-thinking mode (for rapid, context-driven responses) into a unified\nframework. This eliminates the need to switch between different models--such as\nchat-optimized models (e.g., GPT-4o) and dedicated reasoning models (e.g.,\nQwQ-32B)--and enables dynamic mode switching based on user queries or chat\ntemplates. Meanwhile, Qwen3 introduces a thinking budget mechanism, allowing\nusers to allocate computational resources adaptively during inference, thereby\nbalancing latency and performance based on task complexity. Moreover, by\nleveraging the knowledge from the flagship models, we significantly reduce the\ncomputational resources required to build smaller-scale models, while ensuring\ntheir highly competitive performance. Empirical evaluations demonstrate that\nQwen3 achieves state-of-the-art results across diverse benchmarks, including\ntasks in code generation, mathematical reasoning, agent tasks, etc.,\ncompetitive against larger MoE models and proprietary models. Compared to its\npredecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119\nlanguages and dialects, enhancing global accessibility through improved\ncross-lingual understanding and generation capabilities. To facilitate\nreproducibility and community-driven research and development, all Qwen3 models\nare publicly accessible under Apache 2.0.", "AI": {"tldr": "Qwen3 is the latest version of the Qwen model family, featuring advanced performance, efficiency, and multilingual support. It integrates thinking and non-thinking modes, introduces a thinking budget mechanism, and reduces computational costs for smaller models. It outperforms benchmarks and expands multilingual support to 119 languages.", "motivation": "To enhance performance, efficiency, and multilingual capabilities in large language models while eliminating the need for model switching and optimizing resource allocation.", "method": "Qwen3 includes dense and MoE architectures, integrates thinking and non-thinking modes, and employs a thinking budget mechanism for adaptive resource allocation.", "result": "Achieves state-of-the-art results in benchmarks like code generation and mathematical reasoning, supports 119 languages, and reduces computational costs for smaller models.", "conclusion": "Qwen3 advances LLM capabilities with unified modes, efficient resource use, and broad multilingual support, making it accessible under Apache 2.0 for community-driven development."}}
{"id": "2503.14226", "pdf": "https://arxiv.org/pdf/2503.14226", "abs": "https://arxiv.org/abs/2503.14226", "authors": ["Huaifeng Zhang", "Ahmed Ali-Eldin"], "title": "The Hidden Bloat in Machine Learning Systems", "categories": ["cs.SE", "cs.MA"], "comment": null, "summary": "Software bloat refers to code and features that is not used by a software\nduring runtime. For Machine Learning (ML) systems, bloat is a major contributor\nto their technical debt leading to decreased performance and resource wastage.\nIn this work, we present, Negativa-ML, a novel tool to identify and remove\nbloat in ML frameworks by analyzing their shared libraries. Our approach\nincludes novel techniques to detect and locate unnecessary code within device\ncode - a key area overlooked by existing research, which focuses primarily on\nhost code. We evaluate Negativa-ML using four popular ML frameworks across ten\nworkloads over 300 shared libraries. The results demonstrate that the ML\nframeworks are highly bloated on both the device and host code side. On\naverage, Negativa-ML reduces the device code size in these frameworks by up to\n75% and the host code by up to 72%, resulting in total file size reductions of\nup to 55%. The device code is a primary source of bloat within ML frameworks.\nThrough debloating, we achieve reductions in peak host memory usage, peak GPU\nmemory usage, and execution time by up to 74.6%, 69.6%, and 44.6%,\nrespectively.", "AI": {"tldr": "Negativa-ML is a tool to detect and remove unused code (bloat) in ML frameworks, reducing code size and improving performance.", "motivation": "Software bloat in ML systems causes performance issues and resource wastage, especially in device code, which is often overlooked.", "method": "Negativa-ML analyzes shared libraries in ML frameworks, focusing on device code, to identify and remove unnecessary code.", "result": "The tool reduces device code size by up to 75%, host code by 72%, and improves memory usage and execution time significantly.", "conclusion": "Negativa-ML effectively addresses bloat in ML frameworks, enhancing efficiency and performance."}}
{"id": "2505.09341", "pdf": "https://arxiv.org/pdf/2505.09341", "abs": "https://arxiv.org/abs/2505.09341", "authors": ["Ev\u017een Wybitul"], "title": "Access Controls Will Solve the Dual-Use Dilemma", "categories": ["cs.AI"], "comment": null, "summary": "AI safety systems face a dual-use dilemma. Since the same request can be\neither harmless or harmful depending on who made it and why, if the system\nmakes decisions based solely on the request's content, it will refuse some\nlegitimate queries and let pass harmful ones. To address this, we propose a\nconceptual access control framework, based on verified user credentials (such\nas institutional affiliation) and classifiers that assign model outputs to risk\ncategories (such as advanced virology). The system permits responses only when\nthe user's verified credentials match the category's requirements. For\nimplementation of the model output classifiers, we introduce a theoretical\napproach utilizing small, gated expert modules integrated into the generator\nmodel, trained with gradient routing, that enable efficient risk detection\nwithout the capability gap problems of external monitors. While open questions\nremain about the verification mechanisms, risk categories, and the technical\nimplementation, our framework makes the first step toward enabling granular\ngovernance of AI capabilities: verified users gain access to specialized\nknowledge without arbitrary restrictions, while adversaries are blocked from\nit. This contextual approach reconciles model utility with robust safety,\naddressing the dual-use dilemma.", "AI": {"tldr": "A framework for AI safety uses verified credentials and risk categories to control access, balancing utility and safety.", "motivation": "Address the dual-use dilemma in AI safety, where requests can be harmless or harmful based on context.", "method": "Proposes a conceptual framework with verified user credentials and risk-based classifiers, using gated expert modules for efficient risk detection.", "result": "Enables granular governance: verified users access specialized knowledge, adversaries are blocked.", "conclusion": "Reconciles AI utility with robust safety, addressing the dual-use dilemma."}}
{"id": "2505.08940", "pdf": "https://arxiv.org/pdf/2505.08940", "abs": "https://arxiv.org/abs/2505.08940", "authors": ["Jeremie Blanchard", "Lisa Casino", "Jordan Gierschendorf"], "title": "NeurIPS 2024 Ariel Data Challenge: Characterisation of Exoplanetary Atmospheres Using a Data-Centric Approach", "categories": ["cs.LG", "astro-ph.IM"], "comment": "12 pages", "summary": "The characterization of exoplanetary atmospheres through spectral analysis is\na complex challenge. The NeurIPS 2024 Ariel Data Challenge, in collaboration\nwith the European Space Agency's (ESA) Ariel mission, provided an opportunity\nto explore machine learning techniques for extracting atmospheric compositions\nfrom simulated spectral data. In this work, we focus on a data-centric business\napproach, prioritizing generalization over competition-specific optimization.\nWe briefly outline multiple experimental axes, including feature extraction,\nsignal transformation, and heteroskedastic uncertainty modeling. Our\nexperiments demonstrate that uncertainty estimation plays a crucial role in the\nGaussian Log-Likelihood (GLL) score, impacting performance by several\npercentage points. Despite improving the GLL score by 11%, our results\nhighlight the inherent limitations of tabular modeling and feature engineering\nfor this task, as well as the constraints of a business-driven approach within\na Kaggle-style competition framework. Our findings emphasize the trade-offs\nbetween model simplicity, interpretability, and generalization in astrophysical\ndata analysis.", "AI": {"tldr": "The paper explores machine learning for exoplanetary atmospheric spectral analysis, emphasizing generalization and uncertainty estimation, but notes limitations of tabular modeling and business-driven approaches.", "motivation": "To address the challenge of characterizing exoplanetary atmospheres using spectral data, leveraging the NeurIPS 2024 Ariel Data Challenge and ESA's Ariel mission.", "method": "A data-centric approach focusing on feature extraction, signal transformation, and heteroskedastic uncertainty modeling, tested via Gaussian Log-Likelihood (GLL) scores.", "result": "Uncertainty estimation improved GLL scores by 11%, but tabular modeling and feature engineering showed inherent limitations.", "conclusion": "The study highlights trade-offs between simplicity, interpretability, and generalization in astrophysical data analysis, questioning the suitability of business-driven approaches for such tasks."}}
{"id": "2505.09565", "pdf": "https://arxiv.org/pdf/2505.09565", "abs": "https://arxiv.org/abs/2505.09565", "authors": ["Maik Dannecker", "Thomas Sanchez", "Meritxell Bach Cuadra", "\u00d6zg\u00fcn Turgut", "Anthony N. Price", "Lucilio Cordero-Grande", "Vanessa Kyriakopoulou", "Joseph V. Hajnal", "Daniel Rueckert"], "title": "Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using Implicit Neural Representations", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 pages, 6 figures", "summary": "High-resolution slice-to-volume reconstruction (SVR) from multiple\nmotion-corrupted low-resolution 2D slices constitutes a critical step in\nimage-based diagnostics of moving subjects, such as fetal brain Magnetic\nResonance Imaging (MRI). Existing solutions struggle with image artifacts and\nsevere subject motion or require slice pre-alignment to achieve satisfying\nreconstruction performance. We propose a novel SVR method to enable fast and\naccurate MRI reconstruction even in cases of severe image and motion\ncorruption. Our approach performs motion correction, outlier handling, and\nsuper-resolution reconstruction with all operations being entirely based on\nimplicit neural representations. The model can be initialized with\ntask-specific priors through fully self-supervised meta-learning on either\nsimulated or real-world data. In extensive experiments including over 480\nreconstructions of simulated and clinical MRI brain data from different\ncenters, we prove the utility of our method in cases of severe subject motion\nand image artifacts. Our results demonstrate improvements in reconstruction\nquality, especially in the presence of severe motion, compared to\nstate-of-the-art methods, and up to 50% reduction in reconstruction time.", "AI": {"tldr": "A novel SVR method using implicit neural representations improves MRI reconstruction quality and speed, especially for motion-corrupted data.", "motivation": "Existing SVR methods struggle with artifacts and motion, requiring pre-alignment. The goal is to enable fast, accurate reconstruction despite severe corruption.", "method": "Uses implicit neural representations for motion correction, outlier handling, and super-resolution. Initialized with task-specific priors via self-supervised meta-learning.", "result": "Outperforms state-of-the-art in reconstruction quality and reduces time by up to 50%, validated on 480 simulated and clinical MRI datasets.", "conclusion": "The proposed method effectively handles severe motion and artifacts, offering faster and more accurate MRI reconstruction."}}
{"id": "2505.08808", "pdf": "https://arxiv.org/pdf/2505.08808", "abs": "https://arxiv.org/abs/2505.08808", "authors": ["Anqing Jiang", "Jinhao Chai", "Yu Gao", "Yiru Wang", "Yuwen Heng", "Zhigang Sun", "Hao Sun", "Zezhong Zhao", "Li Sun", "Jian Zhou", "Lijuan Zhu", "Shugong Xu", "Hao Zhao"], "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in high-definition \\emph{HD} map construction have\ndemonstrated the effectiveness of dense representations, which heavily rely on\ncomputationally intensive bird's-eye view \\emph{BEV} features. While sparse\nrepresentations offer a more efficient alternative by avoiding dense BEV\nprocessing, existing methods often lag behind due to the lack of tailored\ndesigns. These limitations have hindered the competitiveness of sparse\nrepresentations in online HD map construction. In this work, we systematically\nrevisit and enhance sparse representation techniques, identifying key\narchitectural and algorithmic improvements that bridge the gap with--and\nultimately surpass--dense approaches. We introduce a dedicated network\narchitecture optimized for sparse map feature extraction, a sparse-dense\nsegmentation auxiliary task to better leverage geometric and semantic cues, and\na denoising module guided by physical priors to refine predictions. Through\nthese enhancements, our method achieves state-of-the-art performance on the\nnuScenes dataset, significantly advancing HD map construction and centerline\ndetection. Specifically, SparseMeXt-Tiny reaches a mean average precision\n\\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base\nattains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large\nachieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for\nsparse representations in HD map construction. These results underscore the\nuntapped potential of sparse methods, challenging the conventional reliance on\ndense representations and redefining efficiency-performance trade-offs in the\nfield.", "AI": {"tldr": "The paper enhances sparse representations for HD map construction, surpassing dense methods with a new network architecture, auxiliary tasks, and denoising, achieving state-of-the-art results on nuScenes.", "motivation": "Sparse representations lag behind dense ones in HD map construction due to lack of tailored designs, despite their efficiency. This work aims to bridge this gap.", "method": "Introduces a network optimized for sparse feature extraction, a sparse-dense segmentation task, and a denoising module with physical priors.", "result": "Achieves 55.5% to 68.9% mAP on nuScenes, with SparseMeXt-Large setting a new benchmark at 68.9% mAP and over 20 fps.", "conclusion": "Sparse methods have untapped potential, challenging dense representations and redefining efficiency-performance trade-offs in HD map construction."}}
{"id": "2505.09407", "pdf": "https://arxiv.org/pdf/2505.09407", "abs": "https://arxiv.org/abs/2505.09407", "authors": ["Subrit Dikshit", "Ritu Tiwari", "Priyank Jain"], "title": "Multilingual Machine Translation with Quantum Encoder Decoder Attention-based Convolutional Variational Circuits", "categories": ["cs.CL", "cs.AI", "cs.ET"], "comment": "12 pages, 12 figures", "summary": "Cloud-based multilingual translation services like Google Translate and\nMicrosoft Translator achieve state-of-the-art translation capabilities. These\nservices inherently use large multilingual language models such as GRU, LSTM,\nBERT, GPT, T5, or similar encoder-decoder architectures with attention\nmechanisms as the backbone. Also, new age natural language systems, for\ninstance ChatGPT and DeepSeek, have established huge potential in multiple\ntasks in natural language processing. At the same time, they also possess\noutstanding multilingual translation capabilities. However, these models use\nthe classical computing realm as a backend. QEDACVC (Quantum Encoder Decoder\nAttention-based Convolutional Variational Circuits) is an alternate solution\nthat explores the quantum computing realm instead of the classical computing\nrealm to study and demonstrate multilingual machine translation. QEDACVC\nintroduces the quantum encoder-decoder architecture that simulates and runs on\nquantum computing hardware via quantum convolution, quantum pooling, quantum\nvariational circuit, and quantum attention as software alterations. QEDACVC\nachieves an Accuracy of 82% when trained on the OPUS dataset for English,\nFrench, German, and Hindi corpora for multilingual translations.", "AI": {"tldr": "QEDACVC proposes a quantum computing-based approach for multilingual machine translation, achieving 82% accuracy on the OPUS dataset.", "motivation": "Existing translation services rely on classical computing; QEDACVC explores quantum computing for improved multilingual translation.", "method": "Uses quantum encoder-decoder architecture with quantum convolution, pooling, variational circuits, and attention mechanisms.", "result": "Achieves 82% accuracy on English, French, German, and Hindi translations.", "conclusion": "QEDACVC demonstrates the potential of quantum computing for multilingual machine translation."}}
{"id": "2505.07835", "pdf": "https://arxiv.org/pdf/2505.07835", "abs": "https://arxiv.org/abs/2505.07835", "authors": ["Alex C. Y. Wong", "Duncan McFarlane", "C. Ellarby", "M. Lee", "M. Kuok"], "title": "Intelligent Product 3.0: Decentralised AI Agents and Web3 Intelligence Standards", "categories": ["cs.NI", "cs.AI", "cs.MA", "I.2.11; C.3; C.2.4"], "comment": "18 pages, 1 Figure, 3 Tables; Corrected typo in Section 3.4 heading", "summary": "Twenty-five years ago, the specification of the Intelligent Product was\nestablished, envisaging real-time connectivity that not only enables products\nto gather accurate data about themselves but also allows them to assess and\ninfluence their own destiny. Early work by the Auto-ID project focused on\ncreating a single, open-standard repository for storing and retrieving product\ninformation, laying a foundation for scalable connectivity. A decade later, the\napproach was revisited in light of low-cost RFID systems that promised a\nlow-cost link between physical goods and networked information environments.\nSince then, advances in blockchain, Web3, and artificial intelligence have\nintroduced unprecedented levels of resilience, consensus, and autonomy. By\nleveraging decentralised identity, blockchain-based product information and\nhistory, and intelligent AI-to-AI collaboration, this paper examines these\ndevelopments and outlines a new specification for the Intelligent Product 3.0,\nillustrating how decentralised and AI-driven capabilities facilitate seamless\ninteraction between physical AI and everyday products.", "AI": {"tldr": "The paper revisits the Intelligent Product concept, updating it to Intelligent Product 3.0 with blockchain, Web3, and AI advancements for decentralized, autonomous interactions.", "motivation": "To modernize the Intelligent Product specification by integrating recent technologies like blockchain and AI, enabling decentralized, resilient, and autonomous product interactions.", "method": "Leverages decentralized identity, blockchain-based product information, and AI-to-AI collaboration to redefine the Intelligent Product framework.", "result": "Proposes Intelligent Product 3.0, showcasing how decentralized and AI-driven capabilities enhance product connectivity and autonomy.", "conclusion": "The updated specification enables seamless interaction between physical AI and everyday products, driven by modern tech advancements."}}
{"id": "2505.09412", "pdf": "https://arxiv.org/pdf/2505.09412", "abs": "https://arxiv.org/abs/2505.09412", "authors": ["Paul Kobialka", "Lina Gerlach", "Francesco Leofante", "Erika \u00c1brah\u00e1m", "Silvia Lizeth Tapia Tarifa", "Einar Broch Johnsen"], "title": "Counterfactual Strategies for Markov Decision Processes", "categories": ["cs.AI", "I.2.m"], "comment": null, "summary": "Counterfactuals are widely used in AI to explain how minimal changes to a\nmodel's input can lead to a different output. However, established methods for\ncomputing counterfactuals typically focus on one-step decision-making, and are\nnot directly applicable to sequential decision-making tasks. This paper fills\nthis gap by introducing counterfactual strategies for Markov Decision Processes\n(MDPs). During MDP execution, a strategy decides which of the enabled actions\n(with known probabilistic effects) to execute next. Given an initial strategy\nthat reaches an undesired outcome with a probability above some limit, we\nidentify minimal changes to the initial strategy to reduce that probability\nbelow the limit. We encode such counterfactual strategies as solutions to\nnon-linear optimization problems, and further extend our encoding to synthesize\ndiverse counterfactual strategies. We evaluate our approach on four real-world\ndatasets and demonstrate its practical viability in sophisticated sequential\ndecision-making tasks.", "AI": {"tldr": "The paper introduces counterfactual strategies for Markov Decision Processes (MDPs) to address sequential decision-making, focusing on minimal strategy changes to avoid undesired outcomes.", "motivation": "Existing counterfactual methods in AI are limited to one-step decision-making, leaving a gap for sequential tasks like MDPs.", "method": "The approach encodes counterfactual strategies as non-linear optimization problems and extends this to synthesize diverse strategies.", "result": "Evaluation on four real-world datasets confirms the method's practical viability for sequential decision-making.", "conclusion": "The paper successfully bridges the gap in counterfactual methods for MDPs, offering a viable solution for sequential tasks."}}
{"id": "2505.08941", "pdf": "https://arxiv.org/pdf/2505.08941", "abs": "https://arxiv.org/abs/2505.08941", "authors": ["Gavin Hull", "Alex Bihlo"], "title": "ForeCite: Adapting Pre-Trained Language Models to Predict Future Citation Rates of Academic Papers", "categories": ["cs.LG", "cs.CL"], "comment": "16 pages, 13 figures", "summary": "Predicting the future citation rates of academic papers is an important step\ntoward the automation of research evaluation and the acceleration of scientific\nprogress. We present $\\textbf{ForeCite}$, a simple but powerful framework to\nappend pre-trained causal language models with a linear head for average\nmonthly citation rate prediction. Adapting transformers for regression tasks,\nForeCite achieves a test correlation of $\\rho = 0.826$ on a curated dataset of\n900K+ biomedical papers published between 2000 and 2024, a 27-point improvement\nover the previous state-of-the-art. Comprehensive scaling-law analysis reveals\nconsistent gains across model sizes and data volumes, while temporal holdout\nexperiments confirm practical robustness. Gradient-based saliency heatmaps\nsuggest a potentially undue reliance on titles and abstract texts. These\nresults establish a new state-of-the-art in forecasting the long-term influence\nof academic research and lay the groundwork for the automated, high-fidelity\nevaluation of scientific contributions.", "AI": {"tldr": "ForeCite is a framework using pre-trained language models to predict future citation rates of academic papers, achieving a 27-point improvement over prior methods.", "motivation": "Automating research evaluation and accelerating scientific progress by predicting citation rates.", "method": "Appends pre-trained causal language models with a linear head for regression, tested on 900K+ biomedical papers.", "result": "Achieves a test correlation of \u03c1 = 0.826, with consistent gains across model sizes and data volumes.", "conclusion": "Sets a new state-of-the-art for forecasting research influence, enabling automated evaluation of scientific contributions."}}
{"id": "2505.08805", "pdf": "https://arxiv.org/pdf/2505.08805", "abs": "https://arxiv.org/abs/2505.08805", "authors": ["Anastasia Konik", "Laurent Desbat"], "title": "Range conditions on distributions and their possible application to geometric calibration in 2D parallel and fan-beam geometries", "categories": ["stat.AP", "eess.IV"], "comment": null, "summary": "In tomography, range conditions or data consistency conditions (DCCs) on\nfunctions have proven useful for geometric self-calibration, which involves\nidentifying geometric parameters of acquisition systems based only on acquired\nradiographic images. These self-calibration methods using range conditions on\nfunctions typically require non-truncated data. In this work, we derive range\nconditions on distributions and demonstrate their application in addressing\ndata truncation issues during the calibration process. We propose a novel\napproach based on range conditions on distributions, employing Dirac\ndistributions to model markers within the field-of-view of an X-ray system. Our\ncalibration methods are based on the local geometric information from\nnon-truncated projections of a marker set. By applying range conditions to\nprojections of sums of Dirac distributions, combined with specific calibration\nmarker sets, we derive analytical formulas that enable the identification of\ngeometric calibration parameters. We aim to present DCCs on distributions in\ntomography and explore the potential of DCCs on distributions as a possible\ntool in calibration. This approach represents one possible application,\ndemonstrating how DCCs on distributions can effectively address challenges such\nas data truncation and incomplete marker set information. We present results\nfor the 2D parallel geometry (Radon transform) and the 2D fan-beam geometry\nwith sources on a line.", "AI": {"tldr": "The paper introduces range conditions on distributions to address data truncation in tomography calibration, using Dirac distributions and marker sets for geometric parameter identification.", "motivation": "To overcome limitations of traditional range conditions on functions, which require non-truncated data, by leveraging distributions for more robust calibration.", "method": "Proposes using range conditions on distributions, specifically Dirac distributions, to model markers and derive analytical formulas for geometric calibration parameters.", "result": "Demonstrates successful application in 2D parallel and fan-beam geometries, addressing data truncation and incomplete marker information.", "conclusion": "Range conditions on distributions offer a promising tool for calibration, particularly in scenarios with truncated data or incomplete marker sets."}}
{"id": "2505.08811", "pdf": "https://arxiv.org/pdf/2505.08811", "abs": "https://arxiv.org/abs/2505.08811", "authors": ["Shijie Lian", "Ziyi Zhang", "Laurence Tianruo Yang and", "Mengyu Ren", "Debin Liu", "Hua Li"], "title": "TUGS: Physics-based Compact Representation of Underwater Scenes by Tensorized Gaussian", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Underwater 3D scene reconstruction is crucial for undewater robotic\nperception and navigation. However, the task is significantly challenged by the\ncomplex interplay between light propagation, water medium, and object surfaces,\nwith existing methods unable to model their interactions accurately.\nAdditionally, expensive training and rendering costs limit their practical\napplication in underwater robotic systems. Therefore, we propose Tensorized\nUnderwater Gaussian Splatting (TUGS), which can effectively solve the modeling\nchallenges of the complex interactions between object geometries and water\nmedia while achieving significant parameter reduction. TUGS employs lightweight\ntensorized higher-order Gaussians with a physics-based underwater Adaptive\nMedium Estimation (AME) module, enabling accurate simulation of both light\nattenuation and backscatter effects in underwater environments. Compared to\nother NeRF-based and GS-based methods designed for underwater, TUGS is able to\nrender high-quality underwater images with faster rendering speeds and less\nmemory usage. Extensive experiments on real-world underwater datasets have\ndemonstrated that TUGS can efficiently achieve superior reconstruction quality\nusing a limited number of parameters, making it particularly suitable for\nmemory-constrained underwater UAV applications", "AI": {"tldr": "TUGS is a method for underwater 3D scene reconstruction that addresses challenges like light propagation and water medium interactions, offering faster rendering and lower memory usage.", "motivation": "Existing methods struggle with modeling underwater light-object interactions and are computationally expensive, limiting practical use in robotic systems.", "method": "TUGS uses tensorized higher-order Gaussians and a physics-based Adaptive Medium Estimation module to simulate light attenuation and backscatter effects.", "result": "TUGS outperforms NeRF and GS-based methods in rendering quality, speed, and memory efficiency, validated on real-world datasets.", "conclusion": "TUGS is efficient and suitable for memory-constrained underwater UAV applications due to its superior reconstruction quality and reduced parameters."}}
{"id": "2505.09519", "pdf": "https://arxiv.org/pdf/2505.09519", "abs": "https://arxiv.org/abs/2505.09519", "authors": ["Zongqian Li", "Yixuan Su", "Nigel Collier"], "title": "PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning", "categories": ["cs.CL"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) methods have shown promise in adapting\nlarge language models, yet existing approaches exhibit counter-intuitive\nphenomena: integrating router into prompt tuning (PT) increases training\nefficiency yet does not improve performance universally; parameter reduction\nthrough matrix decomposition can improve performance in specific domains.\nMotivated by these observations and the modular nature of PT, we propose\nPT-MoE, a novel framework that integrates matrix decomposition with\nmixture-of-experts (MoE) routing for efficient PT. Results across 17 datasets\ndemonstrate that PT-MoE achieves state-of-the-art performance in both question\nanswering (QA) and mathematical problem solving tasks, improving F1 score by\n1.49 points over PT and 2.13 points over LoRA in QA tasks, while enhancing\nmathematical accuracy by 10.75 points over PT and 0.44 points over LoRA, all\nwhile using 25% fewer parameters than LoRA. Our analysis reveals that while PT\nmethods generally excel in QA tasks and LoRA-based methods in math datasets,\nthe integration of matrix decomposition and MoE in PT-MoE yields complementary\nbenefits: decomposition enables efficient parameter sharing across experts\nwhile MoE provides dynamic adaptation, collectively enabling PT-MoE to\ndemonstrate cross-task consistency and generalization abilities. These\nfindings, along with ablation studies on routing mechanisms and architectural\ncomponents, provide insights for future PEFT methods.", "AI": {"tldr": "PT-MoE integrates matrix decomposition and MoE routing for efficient prompt tuning, outperforming PT and LoRA in QA and math tasks with fewer parameters.", "motivation": "Addressing counter-intuitive phenomena in PEFT methods, such as router integration in PT not universally improving performance, and leveraging modular PT for better efficiency.", "method": "Proposes PT-MoE, combining matrix decomposition with MoE routing for efficient prompt tuning.", "result": "Achieves state-of-the-art performance in QA (1.49 F1 over PT) and math tasks (10.75 accuracy over PT), using 25% fewer parameters than LoRA.", "conclusion": "PT-MoE's integration of decomposition and MoE enables cross-task consistency and generalization, offering insights for future PEFT methods."}}
{"id": "2505.09518", "pdf": "https://arxiv.org/pdf/2505.09518", "abs": "https://arxiv.org/abs/2505.09518", "authors": ["Maris F. L. Galesloot", "Roman Andriushchenko", "Milan \u010ce\u0161ka", "Sebastian Junges", "Nils Jansen"], "title": "\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted for publication at IJCAI 2025", "summary": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs. We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments.", "AI": {"tldr": "The paper introduces HM-POMDPs for robust decision-making under uncertainty, combining formal verification and subgradient ascent to compute policies that generalize well and scale to large model sets.", "motivation": "Optimal POMDP policies may lack robustness against environmental perturbations. HM-POMDPs address this by considering multiple potential models, ensuring policies perform well across all.", "method": "Combines deductive formal verification (for worst-case POMDP identification) and subgradient ascent (for policy optimization).", "result": "Produces more robust policies that generalize better to unseen POMDPs and scales to over 100,000 environments.", "conclusion": "The approach effectively enhances robustness and scalability in HM-POMDPs, outperforming baselines."}}
{"id": "2505.08964", "pdf": "https://arxiv.org/pdf/2505.08964", "abs": "https://arxiv.org/abs/2505.08964", "authors": ["Majed Jaber", "Julien Michel", "Nicolas Boutry", "Pierre Parrend"], "title": "GPML: Graph Processing for Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in\ndynamic networks involves advanced cyber-threat detectors. The GPML (Graph\nProcessing for Machine Learning) library addresses this need by transforming\nraw network traffic traces into graph representations, enabling advanced\ninsights into network behaviors. The library provides tools to detect anomalies\nin interaction and community shifts in dynamic networks. GPML supports\ncommunity and spectral metrics extraction, enhancing both real-time detection\nand historical forensics analysis. This library supports modern cybersecurity\nchallenges with a robust, graph-based approach.", "AI": {"tldr": "GPML transforms network traffic into graphs for advanced anomaly detection and forensic analysis in dynamic networks.", "motivation": "Addressing the rise of complex cyber-threats in dynamic networks requiring advanced detection tools.", "method": "Uses graph representations of network traffic, supporting community and spectral metrics extraction.", "result": "Enables real-time anomaly detection and historical forensic analysis.", "conclusion": "GPML provides a robust, graph-based solution for modern cybersecurity challenges."}}
{"id": "2505.08882", "pdf": "https://arxiv.org/pdf/2505.08882", "abs": "https://arxiv.org/abs/2505.08882", "authors": ["Ali Almakhluk", "Uthman Baroudi", "Yasser El-Alfy"], "title": "Intelligent Road Anomaly Detection with Real-time Notification System for Enhanced Road Safety", "categories": ["cs.CV", "cs.SY", "eess.IV", "eess.SY"], "comment": null, "summary": "This study aims to improve transportation safety, especially traffic safety.\nRoad damage anomalies such as potholes and cracks have emerged as a significant\nand recurring cause for accidents. To tackle this problem and improve road\nsafety, a comprehensive system has been developed to detect potholes, cracks\n(e.g. alligator, transverse, longitudinal), classify their sizes, and transmit\nthis data to the cloud for appropriate action by authorities. The system also\nbroadcasts warning signals to nearby vehicles warning them if a severe anomaly\nis detected on the road. Moreover, the system can count road anomalies in\nreal-time. It is emulated through the utilization of Raspberry Pi, a camera\nmodule, deep learning model, laptop, and cloud service. Deploying this\ninnovative solution aims to proactively enhance road safety by notifying\nrelevant authorities and drivers about the presence of potholes and cracks to\ntake actions, thereby mitigating potential accidents arising from this\nprevalent road hazard leading to safer road conditions for the whole community.", "AI": {"tldr": "A system using Raspberry Pi, a camera, deep learning, and cloud services detects and classifies road damage (potholes, cracks) in real-time, alerts authorities and nearby vehicles, and aims to improve road safety.", "motivation": "Road damage anomalies like potholes and cracks are major causes of accidents, necessitating a proactive solution to enhance transportation safety.", "method": "The system employs Raspberry Pi, a camera module, deep learning models, and cloud services to detect, classify, and transmit road anomaly data, while also broadcasting warnings to nearby vehicles.", "result": "The system successfully detects and classifies road damage in real-time, enabling timely warnings and actions to mitigate accidents.", "conclusion": "This innovative solution proactively improves road safety by alerting authorities and drivers, reducing accidents caused by road hazards."}}
{"id": "2505.08814", "pdf": "https://arxiv.org/pdf/2505.08814", "abs": "https://arxiv.org/abs/2505.08814", "authors": ["Wenkai Li", "Xiaoqi Li", "Yingjie Mao", "Yishun Wang"], "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models.", "AI": {"tldr": "The paper investigates relationships between DNN depth, configuration, and four coverage metrics (primary functionality, boundary, hierarchy, structural) through empirical experiments on LeNet, VGG, and ResNet models. It also explores modified decision/condition coverage and dataset size, proposing future directions for DNN security testing.", "motivation": "The lack of empirical research on neural network coverage metrics and their relationships with model depth and configuration drives this study.", "method": "Empirical experiments using LeNet, VGG, and ResNet models (5-54 layers) to analyze coverage metrics and modified decision/condition coverage with dataset size.", "result": "Findings reveal patterns between model depth, configuration, and coverage metrics, along with insights into modified decision/condition coverage and dataset size.", "conclusion": "The study highlights the need for further research in DNN security testing, proposing three future directions to advance the field."}}
{"id": "2505.08842", "pdf": "https://arxiv.org/pdf/2505.08842", "abs": "https://arxiv.org/abs/2505.08842", "authors": ["Zekun Wu", "Seonglae Cho", "Umar Mohammed", "Cristian Munoz", "Kleyton Costa", "Xin Guan", "Theo King", "Ze Wang", "Emre Kazim", "Adriano Koshiyama"], "title": "LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Open-source AI libraries are foundational to modern AI systems but pose\nsignificant, underexamined risks across security, licensing, maintenance,\nsupply chain integrity, and regulatory compliance. We present LibVulnWatch, a\ngraph-based agentic assessment framework that performs deep, source-grounded\nevaluations of these libraries. Built on LangGraph, the system coordinates a\ndirected acyclic graph of specialized agents to extract, verify, and quantify\nrisk using evidence from trusted sources such as repositories, documentation,\nand vulnerability databases. LibVulnWatch generates reproducible,\ngovernance-aligned scores across five critical domains, publishing them to a\npublic leaderboard for longitudinal ecosystem monitoring. Applied to 20 widely\nused libraries, including ML frameworks, LLM inference engines, and agent\norchestration tools, our system covers up to 88% of OpenSSF Scorecard checks\nwhile uncovering up to 19 additional risks per library. These include critical\nRemote Code Execution (RCE) vulnerabilities, absent Software Bills of Materials\n(SBOMs), licensing constraints, undocumented telemetry, and widespread gaps in\nregulatory documentation and auditability. By translating high-level governance\nprinciples into practical, verifiable metrics, LibVulnWatch advances technical\nAI governance with a scalable, transparent mechanism for continuous supply\nchain risk assessment and informed library selection.", "AI": {"tldr": "LibVulnWatch is a graph-based framework for assessing risks in open-source AI libraries, covering security, licensing, and compliance, and revealing critical vulnerabilities and gaps.", "motivation": "Open-source AI libraries pose underexamined risks in security, licensing, and compliance, necessitating a systematic assessment tool.", "method": "LibVulnWatch uses a directed acyclic graph of specialized agents to extract, verify, and quantify risks from trusted sources like repositories and vulnerability databases.", "result": "Applied to 20 libraries, it covers 88% of OpenSSF Scorecard checks and uncovers up to 19 additional risks per library, including RCE vulnerabilities and missing SBOMs.", "conclusion": "LibVulnWatch provides scalable, transparent risk assessment for AI governance, aiding informed library selection and continuous monitoring."}}
{"id": "2505.09614", "pdf": "https://arxiv.org/pdf/2505.09614", "abs": "https://arxiv.org/abs/2505.09614", "authors": ["Anthony GX-Chen", "Dongyan Lin", "Mandana Samiei", "Doina Precup", "Blake A. Richards", "Rob Fergus", "Kenneth Marino"], "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning.", "AI": {"tldr": "LMs struggle with conjunctive causal relationships, showing a 'disjunctive bias' similar to humans. A test-time sampling method improves their causal reasoning.", "motivation": "To assess LMs' ability to explore and infer causal relationships, crucial for robust decision-making.", "method": "Using the 'Blicket Test' paradigm, LMs are evaluated on causal inference tasks. Performance is analyzed across models and prompting strategies.", "result": "LMs exhibit a disjunctive bias, struggling with conjunctive relationships. This mirrors human adult reasoning. A sampling method reduces this bias.", "conclusion": "LMs inherit human-like reasoning biases but can be improved with targeted methods, advancing their causal reasoning capabilities."}}
{"id": "2505.08982", "pdf": "https://arxiv.org/pdf/2505.08982", "abs": "https://arxiv.org/abs/2505.08982", "authors": ["Jiachen Qian", "Yang Zheng"], "title": "Model-free Online Learning for the Kalman Filter: Forgetting Factor and Logarithmic Regret", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "We consider the problem of online prediction for an unknown, non-explosive\nlinear stochastic system. With a known system model, the optimal predictor is\nthe celebrated Kalman filter. In the case of unknown systems, existing\napproaches based on recursive least squares and its variants may suffer from\ndegraded performance due to the highly imbalanced nature of the regression\nmodel. This imbalance can easily lead to overfitting and thus degrade\nprediction accuracy. We tackle this problem by injecting an inductive bias into\nthe regression model via {exponential forgetting}. While exponential forgetting\nis a common wisdom in online learning, it is typically used for re-weighting\ndata. In contrast, our approach focuses on balancing the regression model. This\nachieves a better trade-off between {regression} and {regularization errors},\nand simultaneously reduces the {accumulation error}. With new proof techniques,\nwe also provide a sharper logarithmic regret bound of $O(\\log^3 N)$, where $N$\nis the number of observations.", "AI": {"tldr": "The paper proposes an improved online prediction method for unknown linear stochastic systems using exponential forgetting to balance regression models, achieving better accuracy and a sharper regret bound.", "motivation": "Existing methods for unknown systems suffer from imbalanced regression models, leading to overfitting and degraded prediction accuracy.", "method": "The approach uses exponential forgetting to balance the regression model, improving the trade-off between regression and regularization errors.", "result": "The method reduces accumulation error and achieves a sharper logarithmic regret bound of O(log\u00b3 N).", "conclusion": "Exponential forgetting effectively balances the regression model, enhancing prediction accuracy and providing a tighter regret bound."}}
{"id": "2505.09197", "pdf": "https://arxiv.org/pdf/2505.09197", "abs": "https://arxiv.org/abs/2505.09197", "authors": ["Matthew D Blackledge", "Konstantinos Zormpas-Petridis", "Ricardo Donners", "Antonio Candito", "David J Collins", "Johann de Bono", "Chris Parker", "Dow-Mu Koh", "Nina Tunariu"], "title": "Generalizing imaging biomarker repeatability studies using Bayesian inference: Applications in detecting heterogeneous treatment response in whole-body diffusion-weighted MRI of metastatic prostate cancer", "categories": ["stat.AP", "eess.IV", "62P10 (Primary)", "I.4.7; I.4.9"], "comment": null, "summary": "The assessment of imaging biomarkers is critical for advancing precision\nmedicine and improving disease characterization. Despite the availability of\nmethods to derive disease heterogeneity metrics in imaging studies, a robust\nframework for evaluating measurement uncertainty remains underdeveloped. To\naddress this gap, we propose a novel Bayesian framework to assess the precision\nof disease heterogeneity measures in biomarker studies.\n  Our approach extends traditional methods for evaluating biomarker precision\nby providing greater flexibility in statistical assumptions and enabling the\nanalysis of biomarkers beyond univariate or multivariate normally-distributed\nvariables. Using Hamiltonian Monte Carlo sampling, the framework supports both,\nfor example, normally-distributed and Dirichlet-Multinomial distributed\nvariables, enabling the derivation of posterior distributions for biomarker\nparameters under diverse model assumptions. Designed to be broadly applicable\nacross various imaging modalities and biomarker types, the framework builds a\nfoundation for generalizing reproducible and objective biomarker evaluation.\n  To demonstrate utility, we apply the framework to whole-body\ndiffusion-weighted MRI (WBDWI) to assess heterogeneous therapeutic responses in\nmetastatic bone disease. Specifically, we analyze data from two patient studies\ninvestigating treatments for metastatic castrate-resistant prostate cancer\n(mCRPC). Our results reveal an approximately 70% response rate among individual\ntumors across both studies, objectively characterizing differential responses\nto systemic therapies and validating the clinical relevance of the proposed\nmethodology.\n  This Bayesian framework provides a powerful tool for advancing biomarker\nresearch across diverse imaging-based studies while offering valuable insights\ninto specific clinical applications, such as mCRPC treatment response.", "AI": {"tldr": "A Bayesian framework is proposed to evaluate the precision of disease heterogeneity measures in imaging biomarker studies, addressing gaps in uncertainty assessment.", "motivation": "The lack of a robust framework for evaluating measurement uncertainty in disease heterogeneity metrics motivates the development of this Bayesian approach.", "method": "The framework uses Hamiltonian Monte Carlo sampling to handle diverse statistical distributions (e.g., normal, Dirichlet-Multinomial) and derives posterior distributions for biomarker parameters.", "result": "Applied to WBDWI in metastatic bone disease, the method identified a 70% response rate in mCRPC tumors, validating its clinical utility.", "conclusion": "The Bayesian framework enhances biomarker research by providing reproducible, objective evaluation and insights into clinical applications like mCRPC treatment response."}}
{"id": "2505.08817", "pdf": "https://arxiv.org/pdf/2505.08817", "abs": "https://arxiv.org/abs/2505.08817", "authors": ["Camilo Carvajal Reyes", "Joaqu\u00edn Fontbona", "Felipe Tobar"], "title": "Towards SFW sampling for diffusion models via external conditioning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepcted at IJCNN 2025", "summary": "Score-based generative models (SBM), also known as diffusion models, are the\nde facto state of the art for image synthesis. Despite their unparalleled\nperformance, SBMs have recently been in the spotlight for being tricked into\ncreating not-safe-for-work (NSFW) content, such as violent images and\nnon-consensual nudity. Current approaches that prevent unsafe generation are\nbased on the models' own knowledge, and the majority of them require\nfine-tuning. This article explores the use of external sources for ensuring\nsafe outputs in SBMs. Our safe-for-work (SFW) sampler implements a Conditional\nTrajectory Correction step that guides the samples away from undesired regions\nin the ambient space using multimodal models as the source of conditioning.\nFurthermore, using Contrastive Language Image Pre-training (CLIP), our method\nadmits user-defined NSFW classes, which can vary in different settings. Our\nexperiments on the text-to-image SBM Stable Diffusion validate that the\nproposed SFW sampler effectively reduces the generation of explicit content\nwhile being competitive with other fine-tuning-based approaches, as assessed\nvia independent NSFW detectors. Moreover, we evaluate the impact of the SFW\nsampler on image quality and show that the proposed correction scheme comes at\na minor cost with negligible effect on samples not needing correction. Our\nstudy confirms the suitability of the SFW sampler towards aligned SBM models\nand the potential of using model-agnostic conditioning for the prevention of\nunwanted images.", "AI": {"tldr": "The paper proposes an external-conditioning method (SFW sampler) to prevent unsafe content generation in SBMs, using CLIP for user-defined NSFW classes, with minimal impact on image quality.", "motivation": "SBMs, while state-of-the-art for image synthesis, can generate unsafe content. Current prevention methods rely on model fine-tuning, prompting exploration of external conditioning for safer outputs.", "method": "The SFW sampler uses Conditional Trajectory Correction guided by multimodal models (e.g., CLIP) to steer samples away from NSFW regions, allowing user-defined NSFW classes.", "result": "Experiments on Stable Diffusion show the SFW sampler reduces explicit content effectively, competes with fine-tuning methods, and minimally affects image quality for non-NSFW samples.", "conclusion": "The SFW sampler demonstrates the potential of model-agnostic conditioning for aligning SBMs and preventing unwanted content, with negligible quality trade-offs."}}
{"id": "2505.08902", "pdf": "https://arxiv.org/pdf/2505.08902", "abs": "https://arxiv.org/abs/2505.08902", "authors": ["Lucas McCullum", "Pelagie Ami Agassi", "Leo Anthony Celi", "Daniel K. Ebner", "Chrystinne Oliveira Fernandes", "Rachel S. Hicklen", "Mkliwa Koumbia", "Lisa Soleymani Lehmann", "David Restrepo"], "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "Currently, a considerable research effort is devoted to comparing LLMs to a\ngroup of human experts, where the term \"expert\" is often ill-defined or\nvariable, at best, in a state of constantly updating LLM releases. Without\nproper safeguards in place, LLMs will threaten to cause harm to the established\nstructure of safe delivery of patient care which has been carefully developed\nthroughout history to keep the safety of the patient at the forefront. A key\ndriver of LLM innovation is founded on community research efforts which, if\ncontinuing to operate under \"humans versus LLMs\" principles, will expedite this\ntrend. Therefore, research efforts moving forward must focus on effectively\ncharacterizing the safe use of LLMs in clinical settings that persist across\nthe rapid development of novel LLM models. In this communication, we\ndemonstrate that rather than comparing LLMs to humans, there is a need to\ndevelop strategies enabling efficient work of humans with LLMs in an almost\nsymbiotic manner.", "AI": {"tldr": "The paper argues against comparing LLMs to human experts and emphasizes the need for strategies to integrate LLMs safely into clinical settings, focusing on human-LLM collaboration.", "motivation": "The motivation is to address the potential harm of LLMs in healthcare due to ill-defined comparisons with human experts and rapid model updates, advocating for safer integration.", "method": "The paper proposes shifting research focus from human-versus-LLM comparisons to developing strategies for symbiotic human-LLM collaboration in clinical settings.", "result": "The result highlights the urgency of characterizing safe LLM use in healthcare to prevent disruption of patient care structures.", "conclusion": "The conclusion calls for prioritizing research on human-LLM collaboration to ensure safe and effective integration in clinical environments."}}
{"id": "2412.15404", "pdf": "https://arxiv.org/pdf/2412.15404", "abs": "https://arxiv.org/abs/2412.15404", "authors": ["Ahmet Yasin Aytar", "Kemal Kilic", "Kamer Kaya"], "title": "A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "In the rapidly evolving field of data science, efficiently navigating the\nexpansive body of academic literature is crucial for informed decision-making\nand innovation. This paper presents an enhanced Retrieval-Augmented Generation\n(RAG) application, an artificial intelligence (AI)-based system designed to\nassist data scientists in accessing precise and contextually relevant academic\nresources. The AI-powered application integrates advanced techniques, including\nthe GeneRation Of BIbliographic Data (GROBID) technique for extracting\nbibliographic information, fine-tuned embedding models, semantic chunking, and\nan abstract-first retrieval method, to significantly improve the relevance and\naccuracy of the retrieved information. This implementation of AI specifically\naddresses the challenge of academic literature navigation. A comprehensive\nevaluation using the Retrieval-Augmented Generation Assessment System (RAGAS)\nframework demonstrates substantial improvements in key metrics, particularly\nContext Relevance, underscoring the system's effectiveness in reducing\ninformation overload and enhancing decision-making processes. Our findings\nhighlight the potential of this enhanced Retrieval-Augmented Generation system\nto transform academic exploration within data science, ultimately advancing the\nworkflow of research and innovation in the field.", "AI": {"tldr": "An AI-enhanced Retrieval-Augmented Generation (RAG) system improves academic literature navigation for data scientists by integrating advanced techniques like GROBID, fine-tuned embeddings, and semantic chunking, showing significant improvements in relevance and accuracy.", "motivation": "Addressing the challenge of efficiently navigating the vast academic literature in data science to support informed decision-making and innovation.", "method": "The system combines GROBID for bibliographic extraction, fine-tuned embedding models, semantic chunking, and abstract-first retrieval to enhance information retrieval.", "result": "Evaluation using the RAGAS framework shows notable improvements in Context Relevance, reducing information overload and aiding decision-making.", "conclusion": "The enhanced RAG system has the potential to transform academic exploration in data science, advancing research and innovation workflows."}}
{"id": "2505.09003", "pdf": "https://arxiv.org/pdf/2505.09003", "abs": "https://arxiv.org/abs/2505.09003", "authors": ["Zeki Doruk Erden", "Donia Gasmi", "Boi Faltings"], "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition", "categories": ["cs.LG", "cs.AI"], "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS)\n  workshop at AAMAS 2025", "summary": "Continual learning for reinforcement learning agents remains a significant\nchallenge, particularly in preserving and leveraging existing information\nwithout an external signal to indicate changes in tasks or environments. In\nthis study, we explore the effectiveness of autoencoders in detecting new tasks\nand matching observed environments to previously encountered ones. Our approach\nintegrates policy optimization with familiarity autoencoders within an\nend-to-end continual learning system. This system can recognize and learn new\ntasks or environments while preserving knowledge from earlier experiences and\ncan selectively retrieve relevant knowledge when re-encountering a known\nenvironment. Initial results demonstrate successful continual learning without\nexternal signals to indicate task changes or reencounters, showing promise for\nthis methodology.", "AI": {"tldr": "The paper explores using autoencoders for continual learning in reinforcement learning, enabling task recognition and knowledge retention without external signals.", "motivation": "Addressing the challenge of continual learning in reinforcement learning, particularly in preserving and leveraging existing information without external task-change signals.", "method": "Integrates policy optimization with familiarity autoencoders in an end-to-end system to detect new tasks and match environments to prior ones.", "result": "Initial results show successful continual learning without external signals, with the system recognizing and learning new tasks while retaining past knowledge.", "conclusion": "The approach shows promise for continual learning in reinforcement learning by autonomously managing task recognition and knowledge retrieval."}}
{"id": "2505.09324", "pdf": "https://arxiv.org/pdf/2505.09324", "abs": "https://arxiv.org/abs/2505.09324", "authors": ["Lakshya Gupta", "Imran N. Junejo"], "title": "Neural Video Compression using 2D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "9 pages, 8 figures", "summary": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space.", "AI": {"tldr": "The paper proposes a neural video codec using 2D Gaussian Splatting for real-time applications, improving encoding speed by 88%.", "motivation": "Traditional video codecs lack adaptability and efficiency, while neural video codecs (NVC) offer better performance but face computational challenges in real-time applications.", "method": "A region-of-interest (ROI) based neural video compression model using 2D Gaussian Splatting, with content-aware initialization and inter-frame redundancy reduction.", "result": "The proposed method speeds up encoding time by 88% compared to previous Gaussian splatting-based image codecs.", "conclusion": "The work demonstrates the feasibility of using Gaussian splatting for neural video codecs, offering potential for real-time applications like video conferencing."}}
{"id": "2505.08833", "pdf": "https://arxiv.org/pdf/2505.08833", "abs": "https://arxiv.org/abs/2505.08833", "authors": ["Qingyi Wang", "Yuebing Liang", "Yunhan Zheng", "Kaiyuan Xu", "Jinhua Zhao", "Shenhao Wang"], "title": "Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Generative AI offers new opportunities for automating urban planning by\ncreating site-specific urban layouts and enabling flexible design exploration.\nHowever, existing approaches often struggle to produce realistic and practical\ndesigns at scale. Therefore, we adapt a state-of-the-art Stable Diffusion\nmodel, extended with ControlNet, to generate high-fidelity satellite imagery\nconditioned on land use descriptions, infrastructure, and natural environments.\nTo overcome data availability limitations, we spatially link satellite imagery\nwith structured land use and constraint information from OpenStreetMap. Using\ndata from three major U.S. cities, we demonstrate that the proposed diffusion\nmodel generates realistic and diverse urban landscapes by varying land-use\nconfigurations, road networks, and water bodies, facilitating cross-city\nlearning and design diversity. We also systematically evaluate the impacts of\nvarying language prompts and control imagery on the quality of satellite\nimagery generation. Our model achieves high FID and KID scores and demonstrates\nrobustness across diverse urban contexts. Qualitative assessments from urban\nplanners and the general public show that generated images align closely with\ndesign descriptions and constraints, and are often preferred over real images.\nThis work establishes a benchmark for controlled urban imagery generation and\nhighlights the potential of generative AI as a tool for enhancing planning\nworkflows and public engagement.", "AI": {"tldr": "The paper adapts Stable Diffusion with ControlNet to generate realistic urban layouts from land-use descriptions, overcoming data limitations by linking satellite imagery with OpenStreetMap data. It demonstrates high-quality, diverse urban designs and evaluates prompt impacts, achieving strong performance metrics and positive qualitative feedback.", "motivation": "To address the challenge of producing realistic and practical urban designs at scale using generative AI, leveraging existing data and models.", "method": "Adapts Stable Diffusion with ControlNet, using satellite imagery linked to OpenStreetMap data for land-use and constraints. Evaluates language prompts and control imagery impacts.", "result": "Generates high-fidelity, diverse urban landscapes with strong FID and KID scores. Qualitative feedback shows preference over real images.", "conclusion": "Establishes a benchmark for controlled urban imagery generation, showcasing generative AI's potential in urban planning workflows and public engagement."}}
{"id": "2505.08910", "pdf": "https://arxiv.org/pdf/2505.08910", "abs": "https://arxiv.org/abs/2505.08910", "authors": ["Nahid Alam", "Karthik Reddy Kanjula", "Surya Guthikonda", "Timothy Chung", "Bala Krishna S Vegesna", "Abhipsha Das", "Anthony Susevski", "Ryan Sze-Yin Chan", "S M Iftekhar Uddin", "Shayekh Bin Islam", "Roshan Santhosh", "Snegha A", "Drishti Sharma", "Chen Liu", "Isha Chaturvedi", "Genta Indra Winata", "Ashvanth. S", "Snehanshu Mukherjee", "Alham Fikri Aji"], "title": "Behind Maya: Building a Multilingual Vision Language Model", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted at VLM4ALL CVPR 2025 Workshop", "summary": "In recent times, we have seen a rapid development of large Vision-Language\nModels (VLMs). They have shown impressive results on academic benchmarks,\nprimarily in widely spoken languages but lack performance on low-resource\nlanguages and varied cultural contexts. To address these limitations, we\nintroduce Maya, an open-source Multilingual VLM. Our contributions are: 1) a\nmultilingual image-text pretraining dataset in eight languages, based on the\nLLaVA pretraining dataset; and 2) a multilingual image-text model supporting\nthese languages, enhancing cultural and linguistic comprehension in\nvision-language tasks. Code available at https://github.com/nahidalam/maya.", "AI": {"tldr": "Maya is an open-source Multilingual Vision-Language Model (VLM) addressing performance gaps in low-resource languages and cultural contexts by introducing a multilingual dataset and model.", "motivation": "Existing VLMs excel in widely spoken languages but underperform in low-resource languages and diverse cultural settings.", "method": "Developed Maya, a multilingual VLM, using a pretraining dataset in eight languages based on LLaVA.", "result": "Enhanced cultural and linguistic comprehension in vision-language tasks for the supported languages.", "conclusion": "Maya bridges the gap in multilingual and culturally diverse vision-language understanding, with open-source availability."}}
{"id": "2505.08807", "pdf": "https://arxiv.org/pdf/2505.08807", "abs": "https://arxiv.org/abs/2505.08807", "authors": ["Yuntao Wang", "Yanghe Pan", "Shaolong Guo", "Zhou Su"], "title": "Security of Internet of Agents: Attacks and Countermeasures", "categories": ["cs.CR", "cs.AI"], "comment": "11 pages, 5 figures, 3 tables, submitted to IEEE OJCS", "summary": "With the rise of large language and vision-language models, AI agents have\nevolved into autonomous, interactive systems capable of perception, reasoning,\nand decision-making. As they proliferate across virtual and physical domains,\nthe Internet of Agents (IoA) has emerged as a key infrastructure for enabling\nscalable and secure coordination among heterogeneous agents. This survey offers\na comprehensive examination of the security and privacy landscape in IoA\nsystems. We begin by outlining the IoA architecture and its distinct\nvulnerabilities compared to traditional networks, focusing on four critical\naspects: identity authentication threats, cross-agent trust issues, embodied\nsecurity, and privacy risks. We then review existing and emerging defense\nmechanisms and highlight persistent challenges. Finally, we identify open\nresearch directions to advance the development of resilient and\nprivacy-preserving IoA ecosystems.", "AI": {"tldr": "A survey on security and privacy in the Internet of Agents (IoA), covering vulnerabilities, defense mechanisms, and open research directions.", "motivation": "The rise of autonomous AI agents necessitates a secure and privacy-preserving IoA infrastructure.", "method": "Examines IoA architecture, vulnerabilities (e.g., identity threats, trust issues), and defense mechanisms.", "result": "Identifies persistent challenges and gaps in current IoA security and privacy solutions.", "conclusion": "Highlights the need for further research to build resilient and privacy-preserving IoA ecosystems."}}
{"id": "2505.09011", "pdf": "https://arxiv.org/pdf/2505.09011", "abs": "https://arxiv.org/abs/2505.09011", "authors": ["Antonio Candito", "Matthew D Blackledge", "Richard Holbrey", "Nuria Porta", "Ana Ribeiro", "Fabio Zugni", "Luca D'Erme", "Francesca Castagnoli", "Alina Dragan", "Ricardo Donners", "Christina Messiou", "Nina Tunariu", "Dow-Mu Koh"], "title": "Signal-based AI-driven software solution for automated quantification of metastatic bone disease and treatment response assessment using Whole-Body Diffusion-Weighted MRI (WB-DWI) biomarkers in Advanced Prostate Cancer", "categories": ["cs.LG"], "comment": null, "summary": "We developed an AI-driven software solution to quantify metastatic bone\ndisease from WB-DWI scans. Core technologies include: (i) a weakly-supervised\nResidual U-Net model generating a skeleton probability map to isolate bone;\n(ii) a statistical framework for WB-DWI intensity normalisation, obtaining a\nsignal-normalised b=900s/mm^2 (b900) image; and (iii) a shallow convolutional\nneural network that processes outputs from (i) and (ii) to generate a mask of\nsuspected bone lesions, characterised by higher b900 signal intensity due to\nrestricted water diffusion. This mask is applied to the gADC map to extract TDV\nand gADC statistics. We tested the tool using expert-defined metastatic bone\ndisease delineations on 66 datasets, assessed repeatability of imaging\nbiomarkers (N=10), and compared software-based response assessment with a\nconstruct reference standard based on clinical, laboratory and imaging\nassessments (N=118). Dice score between manual and automated delineations was\n0.6 for lesions within pelvis and spine, with an average surface distance of\n2mm. Relative differences for log-transformed TDV (log-TDV) and median gADC\nwere below 9% and 5%, respectively. Repeatability analysis showed coefficients\nof variation of 4.57% for log-TDV and 3.54% for median gADC, with intraclass\ncorrelation coefficients above 0.9. The software achieved 80.5% accuracy, 84.3%\nsensitivity, and 85.7% specificity in assessing response to treatment compared\nto the construct reference standard. Computation time generating a mask\naveraged 90 seconds per scan. Our software enables reproducible TDV and gADC\nquantification from WB-DWI scans for monitoring metastatic bone disease\nresponse, thus providing potentially useful measurements for clinical\ndecision-making in APC patients.", "AI": {"tldr": "An AI-driven tool for quantifying metastatic bone disease from WB-DWI scans using a combination of deep learning models and statistical methods, achieving high accuracy and reproducibility.", "motivation": "To provide a reproducible and efficient method for quantifying metastatic bone disease from WB-DWI scans, aiding clinical decision-making for APC patients.", "method": "Combines a weakly-supervised Residual U-Net for bone isolation, a statistical framework for intensity normalization, and a shallow CNN for lesion detection, followed by biomarker extraction.", "result": "Achieved 0.6 Dice score, <9% and <5% differences for log-TDV and median gADC, and 80.5% accuracy in treatment response assessment.", "conclusion": "The software offers reliable and fast quantification of metastatic bone disease, supporting clinical monitoring and decision-making."}}
{"id": "2505.09433", "pdf": "https://arxiv.org/pdf/2505.09433", "abs": "https://arxiv.org/abs/2505.09433", "authors": ["Jiahao Zhu", "Kang You", "Dandan Ding", "Zhan Ma"], "title": "Efficient LiDAR Reflectance Compression via Scanning Serialization", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Reflectance attributes in LiDAR point clouds provide essential information\nfor downstream tasks but remain underexplored in neural compression methods. To\naddress this, we introduce SerLiC, a serialization-based neural compression\nframework to fully exploit the intrinsic characteristics of LiDAR reflectance.\nSerLiC first transforms 3D LiDAR point clouds into 1D sequences via scan-order\nserialization, offering a device-centric perspective for reflectance analysis.\nEach point is then tokenized into a contextual representation comprising its\nsensor scanning index, radial distance, and prior reflectance, for effective\ndependencies exploration. For efficient sequential modeling, Mamba is\nincorporated with a dual parallelization scheme, enabling simultaneous\nautoregressive dependency capture and fast processing. Extensive experiments\ndemonstrate that SerLiC attains over 2x volume reduction against the original\nreflectance data, outperforming the state-of-the-art method by up to 22%\nreduction of compressed bits while using only 2% of its parameters. Moreover, a\nlightweight version of SerLiC achieves > 10 fps (frames per second) with just\n111K parameters, which is attractive for real-world applications.", "AI": {"tldr": "SerLiC is a neural compression framework for LiDAR reflectance data, using serialization and Mamba for efficient modeling, achieving significant compression and speed.", "motivation": "LiDAR reflectance attributes are underexplored in neural compression, despite their importance for downstream tasks.", "method": "SerLiC serializes LiDAR point clouds into 1D sequences, tokenizes points with contextual representations, and uses Mamba for sequential modeling.", "result": "SerLiC achieves over 2x volume reduction, outperforms state-of-the-art by 22% in compressed bits, and offers a lightweight version with >10 fps.", "conclusion": "SerLiC effectively compresses LiDAR reflectance data with high efficiency, making it suitable for real-world applications."}}
{"id": "2505.08834", "pdf": "https://arxiv.org/pdf/2505.08834", "abs": "https://arxiv.org/abs/2505.08834", "authors": ["Muhammad Junaid Asif"], "title": "Crowd Scene Analysis using Deep Learning Techniques", "categories": ["cs.CV", "cs.AI"], "comment": "MS Graduate Research Thesis", "summary": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches", "AI": {"tldr": "The paper addresses challenges in crowd scene analysis, proposing self-supervised training for crowd counting and a spatiotemporal model for anomaly detection, achieving state-of-the-art results.", "motivation": "To tackle data-hungry deep learning models in crowd counting and improve anomaly detection in complex scenes.", "method": "1. Self-supervised training with Multi-Column CNN for crowd counting. 2. Spatiotemporal model (VGG19 + LSTM) with dense residual blocks for anomaly detection.", "result": "Evaluated on ShanghaiTech, UCF-QNRF (MAE, MSE), Hockey Fight, and SCVD datasets, outperforming existing methods.", "conclusion": "The proposed models effectively address challenges in crowd counting and anomaly detection, demonstrating superior performance."}}
{"id": "2505.08971", "pdf": "https://arxiv.org/pdf/2505.08971", "abs": "https://arxiv.org/abs/2505.08971", "authors": ["Yangyi Chen", "Hao Peng", "Tong Zhang", "Heng Ji"], "title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "The code will be available at https://github.com/Yangyi-Chen/PRIOR", "summary": "In standard large vision-language models (LVLMs) pre-training, the model\ntypically maximizes the joint probability of the caption conditioned on the\nimage via next-token prediction (NTP); however, since only a small subset of\ncaption tokens directly relates to the visual content, this naive NTP\nunintentionally fits the model to noise and increases the risk of\nhallucination. We present PRIOR, a simple vision-language pre-training approach\nthat addresses this issue by prioritizing image-related tokens through\ndifferential weighting in the NTP loss, drawing from the importance sampling\nframework. PRIOR introduces a reference model-a text-only large language model\n(LLM) trained on the captions without image inputs, to weight each token based\non its probability for LVLMs training. Intuitively, tokens that are directly\nrelated to the visual inputs are harder to predict without the image and thus\nreceive lower probabilities from the text-only reference LLM. During training,\nwe implement a token-specific re-weighting term based on the importance scores\nto adjust each token's loss. We implement PRIOR in two distinct settings: LVLMs\nwith visual encoders and LVLMs without visual encoders. We observe 19% and 8%\naverage relative improvement, respectively, on several vision-language\nbenchmarks compared to NTP. In addition, PRIOR exhibits superior scaling\nproperties, as demonstrated by significantly higher scaling coefficients,\nindicating greater potential for performance gains compared to NTP given\nincreasing compute and data.", "AI": {"tldr": "PRIOR improves vision-language pre-training by prioritizing image-related tokens in next-token prediction, reducing noise and hallucination risks.", "motivation": "Standard NTP in LVLMs fits noise due to unrelated caption tokens, increasing hallucination risks.", "method": "PRIOR uses a text-only LLM to weight tokens, adjusting loss based on visual relevance.", "result": "19% and 8% relative improvements in benchmarks for LVLMs with and without visual encoders, respectively.", "conclusion": "PRIOR outperforms NTP, shows better scaling, and reduces hallucination risks."}}
{"id": "2505.08809", "pdf": "https://arxiv.org/pdf/2505.08809", "abs": "https://arxiv.org/abs/2505.08809", "authors": ["Shixi Qin", "Zhiyong Yang", "Shilong Bao", "Shi Wang", "Qianqian Xu", "Qingming Huang"], "title": "MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schr\u00f6dinger Bridges", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper focuses on implanting multiple heterogeneous backdoor triggers in\nbridge-based diffusion models designed for complex and arbitrary input\ndistributions. Existing backdoor formulations mainly address single-attack\nscenarios and are limited to Gaussian noise input models. To fill this gap, we\npropose MixBridge, a novel diffusion Schr\\\"odinger bridge (DSB) framework to\ncater to arbitrary input distributions (taking I2I tasks as special cases).\nBeyond this trait, we demonstrate that backdoor triggers can be injected into\nMixBridge by directly training with poisoned image pairs. This eliminates the\nneed for the cumbersome modifications to stochastic differential equations\nrequired in previous studies, providing a flexible tool to study backdoor\nbehavior for bridge models. However, a key question arises: can a single DSB\nmodel train multiple backdoor triggers? Unfortunately, our theory shows that\nwhen attempting this, the model ends up following the geometric mean of benign\nand backdoored distributions, leading to performance conflict across backdoor\ntasks. To overcome this, we propose a Divide-and-Merge strategy to mix\ndifferent bridges, where models are independently pre-trained for each specific\nobjective (Divide) and then integrated into a unified model (Merge). In\naddition, a Weight Reallocation Scheme (WRS) is also designed to enhance the\nstealthiness of MixBridge. Empirical studies across diverse generation tasks\nspeak to the efficacy of MixBridge.", "AI": {"tldr": "MixBridge is a diffusion Schr\u00f6dinger bridge framework for arbitrary input distributions, enabling multiple backdoor triggers without modifying stochastic differential equations. A Divide-and-Merge strategy resolves performance conflicts.", "motivation": "Existing backdoor methods are limited to single-attack scenarios and Gaussian noise inputs. MixBridge addresses these limitations for complex distributions.", "method": "Proposes MixBridge, a DSB framework, and a Divide-and-Merge strategy with Weight Reallocation Scheme (WRS) to handle multiple backdoor triggers.", "result": "MixBridge successfully injects multiple backdoor triggers and resolves conflicts via Divide-and-Merge, enhancing stealthiness with WRS.", "conclusion": "MixBridge offers a flexible and effective solution for studying backdoor behavior in bridge models, validated by diverse generation tasks."}}
{"id": "2505.09017", "pdf": "https://arxiv.org/pdf/2505.09017", "abs": "https://arxiv.org/abs/2505.09017", "authors": ["Bizhan Alipour Pijan", "Serdar Bozdag"], "title": "DyGSSM: Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Most of the dynamic graph representation learning methods involve dividing a\ndynamic graph into discrete snapshots to capture the evolving behavior of nodes\nover time. Existing methods primarily capture only local or global structures\nof each node within a snapshot using message-passing and random walk-based\nmethods. Then, they utilize sequence-based models (e.g., transformers) to\nencode the temporal evolution of node embeddings, and meta-learning techniques\nto update the model parameters. However, these approaches have two limitations.\nFirst, they neglect the extraction of global and local information\nsimultaneously in each snapshot. Second, they fail to consider the model's\nperformance in the current snapshot during parameter updates, resulting in a\nlack of temporal dependency management. Recently, HiPPO (High-order Polynomial\nProjection Operators) algorithm has gained attention for their ability to\noptimize and preserve sequence history in State Space Model (SSM). To address\nthe aforementioned limitations in dynamic graph representation learning, we\npropose a novel method called Multi-view Dynamic Graph Embeddings with State\nSpace Model Gradient Update (DyGSSM). Our approach combines Graph Convolution\nNetworks (GCN) for local feature extraction and random walk with Gated\nRecurrent Unit (GRU) for global feature extraction in each snapshot. We then\nintegrate the local and global features using a cross-attention mechanism.\nAdditionally, we incorporate an SSM based on HiPPO algorithm to account for\nlong-term dependencies when updating model parameters, ensuring that model\nperformance in each snapshot informs subsequent updates. Experiments on five\npublic datasets show that our method outperforms existing baseline and\nstate-of-the-art (SOTA) methods in 17 out of 20 cases.", "AI": {"tldr": "The paper proposes DyGSSM, a method combining GCN and GRU for dynamic graph representation learning, using HiPPO-based SSM for temporal dependency management, outperforming existing methods.", "motivation": "Existing methods fail to simultaneously capture global and local structures in dynamic graphs and lack effective temporal dependency management during parameter updates.", "method": "DyGSSM integrates GCN for local features and GRU for global features per snapshot, using cross-attention and HiPPO-based SSM for temporal updates.", "result": "Outperforms baselines in 17/20 cases across five datasets.", "conclusion": "DyGSSM effectively addresses limitations in dynamic graph representation learning by combining multi-view features and HiPPO-based SSM."}}
{"id": "2505.09529", "pdf": "https://arxiv.org/pdf/2505.09529", "abs": "https://arxiv.org/abs/2505.09529", "authors": ["Mohamed Moustafa", "Joseph Lemley", "Peter Corcoran"], "title": "Contactless Cardiac Pulse Monitoring Using Event Cameras", "categories": ["cs.CV", "cs.ET", "cs.LG", "eess.IV"], "comment": "This paper is a preprint of a paper submitted to IEEE Access and is\n  currently under review", "summary": "Time event cameras are a novel technology for recording scene information at\nextremely low latency and with low power consumption. Event cameras output a\nstream of events that encapsulate pixel-level light intensity changes within\nthe scene, capturing information with a higher dynamic range and temporal\nresolution than traditional cameras. This study investigates the contact-free\nreconstruction of an individual's cardiac pulse signal from time event\nrecording of their face using a supervised convolutional neural network (CNN)\nmodel. An end-to-end model is trained to extract the cardiac signal from a\ntwo-dimensional representation of the event stream, with model performance\nevaluated based on the accuracy of the calculated heart rate. The experimental\nresults confirm that physiological cardiac information in the facial region is\neffectively preserved within the event stream, showcasing the potential of this\nnovel sensor for remote heart rate monitoring. The model trained on event\nframes achieves a root mean square error (RMSE) of 3.32 beats per minute (bpm)\ncompared to the RMSE of 2.92 bpm achieved by the baseline model trained on\nstandard camera frames. Furthermore, models trained on event frames generated\nat 60 and 120 FPS outperformed the 30 FPS standard camera results, achieving an\nRMSE of 2.54 and 2.13 bpm, respectively.", "AI": {"tldr": "Event cameras capture facial data to reconstruct cardiac pulse signals using a CNN, achieving competitive heart rate accuracy compared to standard cameras.", "motivation": "To explore the potential of event cameras for low-latency, high-dynamic-range remote heart rate monitoring.", "method": "A supervised CNN model processes 2D event stream representations to extract cardiac signals, evaluated by heart rate accuracy.", "result": "Event cameras preserve cardiac info effectively, with RMSEs of 3.32 bpm (event frames) and outperforming standard cameras at higher FPS (2.54/2.13 bpm at 60/120 FPS).", "conclusion": "Event cameras show promise for remote heart rate monitoring, offering advantages in dynamic range and temporal resolution."}}
{"id": "2505.08854", "pdf": "https://arxiv.org/pdf/2505.08854", "abs": "https://arxiv.org/abs/2505.08854", "authors": ["Yuping Wang", "Shuo Xing", "Cui Can", "Renjie Li", "Hongyuan Hua", "Kexin Tian", "Zhaobin Mo", "Xiangbo Gao", "Keshu Wu", "Sulong Zhou", "Hengxu You", "Juntong Peng", "Junge Zhang", "Zehao Wang", "Rui Song", "Mingxuan Yan", "Walter Zimmer", "Xingcheng Zhou", "Peiran Li", "Zhaohan Lu", "Chia-Ju Chen", "Yue Huang", "Ryan A. Rossi", "Lichao Sun", "Hongkai Yu", "Zhiwen Fan", "Frank Hao Yang", "Yuhao Kang", "Ross Greer", "Chenxi Liu", "Eun Hak Lee", "Xuan Di", "Xinyue Ye", "Liu Ren", "Alois Knoll", "Xiaopeng Li", "Shuiwang Ji", "Masayoshi Tomizuka", "Marco Pavone", "Tianbao Yang", "Jing Du", "Ming-Hsuan Yang", "Hua Wei", "Ziran Wang", "Yang Zhou", "Jiachen Li", "Zhengzhong Tu"], "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) constitutes a transformative\ntechnological wave that reconfigures industries through its unparalleled\ncapabilities for content creation, reasoning, planning, and multimodal\nunderstanding. This revolutionary force offers the most promising path yet\ntoward solving one of engineering's grandest challenges: achieving reliable,\nfully autonomous driving, particularly the pursuit of Level 5 autonomy. This\nsurvey delivers a comprehensive and critical synthesis of the emerging role of\nGenAI across the autonomous driving stack. We begin by distilling the\nprinciples and trade-offs of modern generative modeling, encompassing VAEs,\nGANs, Diffusion Models, and Large Language Models (LLMs). We then map their\nfrontier applications in image, LiDAR, trajectory, occupancy, video generation\nas well as LLM-guided reasoning and decision making. We categorize practical\napplications, such as synthetic data workflows, end-to-end driving strategies,\nhigh-fidelity digital twin systems, smart transportation networks, and\ncross-domain transfer to embodied AI. We identify key obstacles and\npossibilities such as comprehensive generalization across rare cases,\nevaluation and safety checks, budget-limited implementation, regulatory\ncompliance, ethical concerns, and environmental effects, while proposing\nresearch plans across theoretical assurances, trust metrics, transport\nintegration, and socio-technical influence. By unifying these threads, the\nsurvey provides a forward-looking reference for researchers, engineers, and\npolicymakers navigating the convergence of generative AI and advanced\nautonomous mobility. An actively maintained repository of cited works is\navailable at https://github.com/taco-group/GenAI4AD.", "AI": {"tldr": "The survey explores GenAI's role in autonomous driving, covering generative models, applications, challenges, and future research directions.", "motivation": "To address the challenge of achieving Level 5 autonomous driving by leveraging GenAI's capabilities in content creation and reasoning.", "method": "The paper synthesizes principles of generative models (VAEs, GANs, Diffusion Models, LLMs) and their applications in autonomous driving, including synthetic data, decision-making, and digital twins.", "result": "Identifies practical applications, challenges (e.g., generalization, safety, ethics), and proposes research plans for theoretical assurances and socio-technical impact.", "conclusion": "The survey serves as a forward-looking guide for researchers, engineers, and policymakers on GenAI's integration into autonomous mobility."}}
{"id": "2505.09083", "pdf": "https://arxiv.org/pdf/2505.09083", "abs": "https://arxiv.org/abs/2505.09083", "authors": ["Dominic Zaun Eu Jones"], "title": "Ornithologist: Towards Trustworthy \"Reasoning\" about Central Bank Communications", "categories": ["econ.GN", "cs.CL", "q-fin.EC", "J.4; I.2.7"], "comment": "16 pages, 6 figures", "summary": "I develop Ornithologist, a weakly-supervised textual classification system\nand measure the hawkishness and dovishness of central bank text. Ornithologist\nuses ``taxonomy-guided reasoning'', guiding a large language model with\nhuman-authored decision trees. This increases the transparency and\nexplainability of the system and makes it accessible to non-experts. It also\nreduces hallucination risk. Since it requires less supervision than traditional\nclassification systems, it can more easily be applied to other problems or\nsources of text (e.g. news) without much modification. Ornithologist\nmeasurements of hawkishness and dovishness of RBA communication carry\ninformation about the future of the cash rate path and of market expectations.", "AI": {"tldr": "Ornithologist is a weakly-supervised textual classification system that measures central bank text hawkishness/dovishness using taxonomy-guided reasoning with large language models, improving transparency and reducing hallucination risks.", "motivation": "To create a transparent, explainable, and adaptable system for classifying central bank text (e.g., hawkishness/dovishness) with minimal supervision.", "method": "Uses taxonomy-guided reasoning, combining human-authored decision trees with large language models for classification.", "result": "Ornithologist's measurements of RBA communication predict future cash rate paths and market expectations.", "conclusion": "The system is effective, adaptable, and reduces risks, making it useful for non-experts and other text sources."}}
{"id": "2505.08810", "pdf": "https://arxiv.org/pdf/2505.08810", "abs": "https://arxiv.org/abs/2505.08810", "authors": ["Bappa Muktar", "Vincent Fono", "Adama Nouboukpo"], "title": "Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Vehicular Ad Hoc Networks (VANETs) play a key role in Intelligent\nTransportation Systems (ITS), particularly in enabling real-time communication\nfor emergency vehicles. However, Distributed Denial of Service (DDoS) attacks,\nwhich interfere with safety-critical communication channels, can severely\nimpair their reliability. This study introduces a robust and scalable framework\nto detect DDoS attacks in highway-based VANET environments. A synthetic dataset\nwas constructed using Network Simulator 3 (NS-3) in conjunction with the\nSimulation of Urban Mobility (SUMO) and further enriched with real-world\nmobility traces from Germany's A81 highway, extracted via OpenStreetMap (OSM).\nThree traffic categories were simulated: DDoS, VoIP, and TCP-based video\nstreaming (VideoTCP). The data preprocessing pipeline included normalization,\nsignal-to-noise ratio (SNR) feature engineering, missing value imputation, and\nclass balancing using the Synthetic Minority Over-sampling Technique (SMOTE).\nFeature importance was assessed using SHapley Additive exPlanations (SHAP).\nEleven classifiers were benchmarked, among them XGBoost (XGB), CatBoost (CB),\nAdaBoost (AB), GradientBoosting (GB), and an Artificial Neural Network (ANN).\nXGB and CB achieved the best performance, each attaining an F1-score of 96%.\nThese results highlight the robustness of the proposed framework and its\npotential for real-time deployment in VANETs to secure critical emergency\ncommunications.", "AI": {"tldr": "A framework for detecting DDoS attacks in VANETs, using synthetic data and achieving high accuracy with XGBoost and CatBoost.", "motivation": "DDoS attacks disrupt safety-critical communication in VANETs, necessitating a reliable detection method.", "method": "Used NS-3 and SUMO for simulation, enriched with real-world data, and employed preprocessing and multiple classifiers.", "result": "XGBoost and CatBoost achieved 96% F1-score, demonstrating robust performance.", "conclusion": "The framework is effective for real-time DDoS detection in VANETs, enhancing emergency communication security."}}
{"id": "2505.09022", "pdf": "https://arxiv.org/pdf/2505.09022", "abs": "https://arxiv.org/abs/2505.09022", "authors": ["Annan Yu", "N. Benjamin Erichson"], "title": "Block-Biased Mamba for Long-Range Sequence Processing", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Mamba extends earlier state space models (SSMs) by introducing\ninput-dependent dynamics, and has demonstrated strong empirical performance\nacross a range of domains, including language modeling, computer vision, and\nfoundation models. However, a surprising weakness remains: despite being built\non architectures designed for long-range dependencies, Mamba performs poorly on\nlong-range sequential tasks. Understanding and addressing this gap is important\nfor improving Mamba's universality and versatility. In this work, we analyze\nMamba's limitations through three perspectives: expressiveness, inductive bias,\nand training stability. Our theoretical results show how Mamba falls short in\neach of these aspects compared to earlier SSMs such as S4D. To address these\nissues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6\nunit that combines block-wise selective dynamics with a channel-specific bias.\nWe prove that these changes equip the model with a better-suited inductive bias\nand improve its expressiveness and stability. Empirically,\n$\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks\nwhile maintaining Mamba's performance on language modeling benchmarks.", "AI": {"tldr": "Mamba, an improved state space model (SSM), struggles with long-range tasks despite its design. The paper analyzes its limitations and proposes $\text{B}_2\text{S}_6$ to enhance performance.", "motivation": "Mamba's poor performance on long-range tasks contradicts its design for long-range dependencies, prompting a need for improvement.", "method": "The paper analyzes Mamba's limitations in expressiveness, inductive bias, and training stability, then introduces $\text{B}_2\text{S}_6$, a modified S6 unit with block-wise selective dynamics and channel-specific bias.", "result": "$\text{B}_2\text{S}_6$ outperforms S4 and S4D on Long-Range Arena tasks while maintaining Mamba's language modeling performance.", "conclusion": "The proposed $\text{B}_2\text{S}_6$ addresses Mamba's weaknesses, improving its universality and versatility."}}
{"id": "2306.14725", "pdf": "https://arxiv.org/pdf/2306.14725", "abs": "https://arxiv.org/abs/2306.14725", "authors": ["Matthias Schwab", "Mathias Pamminger", "Christian Kremser", "Daniel Obmann", "Markus Haltmeier", "Agnes Mayr"], "title": "Error correcting 2D-3D cascaded network for myocardial infarct scar segmentation on late gadolinium enhancement cardiac magnetic resonance images", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) imaging is\nconsidered the in vivo reference standard for assessing infarct size (IS) and\nmicrovascular obstruction (MVO) in ST-elevation myocardial infarction (STEMI)\npatients. However, the exact quantification of those markers of myocardial\ninfarct severity remains challenging and very time-consuming. As LGE\ndistribution patterns can be quite complex and hard to delineate from the blood\npool or epicardial fat, automatic segmentation of LGE CMR images is\nchallenging. In this work, we propose a cascaded framework of two-dimensional\nand three-dimensional convolutional neural networks (CNNs) which enables to\ncalculate the extent of myocardial infarction in a fully automated way. By\nartificially generating segmentation errors which are characteristic for 2D\nCNNs during training of the cascaded framework we are enforcing the detection\nand correction of 2D segmentation errors and hence improve the segmentation\naccuracy of the entire method. The proposed method was trained and evaluated on\ntwo publicly available datasets. We perform comparative experiments where we\nshow that our framework outperforms state-of-the-art reference methods in\nsegmentation of myocardial infarction. Furthermore, in extensive ablation\nstudies we show the advantages that come with the proposed error correcting\ncascaded method. The code of this project is publicly available at\nhttps://github.com/matthi99/EcorC.git", "AI": {"tldr": "A cascaded CNN framework automates LGE CMR image segmentation for infarct size and microvascular obstruction, outperforming state-of-the-art methods.", "motivation": "Accurate and efficient quantification of myocardial infarction markers in LGE CMR images is challenging due to complex patterns and manual delineation requirements.", "method": "Proposes a cascaded 2D and 3D CNN framework, training with artificial segmentation errors to improve accuracy.", "result": "Outperforms existing methods in segmentation accuracy, validated on public datasets.", "conclusion": "The framework offers a robust, automated solution for myocardial infarction segmentation, with publicly available code."}}
{"id": "2505.08886", "pdf": "https://arxiv.org/pdf/2505.08886", "abs": "https://arxiv.org/abs/2505.08886", "authors": ["Hamideh Khaleghpour", "Brett McKinney"], "title": "Optimizing Neuro-Fuzzy and Colonial Competition Algorithms for Skin Cancer Diagnosis in Dermatoscopic Images", "categories": ["cs.CV", "cs.LG"], "comment": "7 pages, 10 figures. Accepted at the 2nd Asia Pacific Computer\n  Systems Conference (APCS 2024), March 15-17, 2024", "summary": "The rising incidence of skin cancer, coupled with limited public awareness\nand a shortfall in clinical expertise, underscores an urgent need for advanced\ndiagnostic aids. Artificial Intelligence (AI) has emerged as a promising tool\nin this domain, particularly for distinguishing malignant from benign skin\nlesions. Leveraging publicly available datasets of skin lesions, researchers\nhave been developing AI-based diagnostic solutions. However, the integration of\nsuch computer systems in clinical settings is still nascent. This study aims to\nbridge this gap by employing a fusion of image processing techniques and\nmachine learning algorithms, specifically neuro-fuzzy and colonial competition\napproaches. Applied to dermoscopic images from the ISIC database, our method\nachieved a notable accuracy of 94% on a dataset of 560 images. These results\nunderscore the potential of our approach in aiding clinicians in the early\ndetection of melanoma, thereby contributing significantly to skin cancer\ndiagnostics.", "AI": {"tldr": "AI-based diagnostic tool using neuro-fuzzy and colonial competition methods achieves 94% accuracy in distinguishing malignant skin lesions.", "motivation": "Addressing the urgent need for advanced diagnostic aids due to rising skin cancer cases and limited clinical expertise.", "method": "Combines image processing with machine learning (neuro-fuzzy and colonial competition) on dermoscopic images from the ISIC database.", "result": "Achieved 94% accuracy on a dataset of 560 images.", "conclusion": "Demonstrates potential for early melanoma detection, enhancing skin cancer diagnostics."}}
{"id": "2505.09246", "pdf": "https://arxiv.org/pdf/2505.09246", "abs": "https://arxiv.org/abs/2505.09246", "authors": ["Derian Boer", "Stephen Roth", "Stefan Kramer"], "title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "In many real-world settings, machine learning models and interactive systems\nhave access to both structured knowledge, e.g., knowledge graphs or tables, and\nunstructured content, e.g., natural language documents. However, most rely on\neither. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking\nunstructured content to nodes within structured data, thereby enabling new\nstrategies for knowledge access and use. In this work, we present\nFocusedRetriever, a modular SKB-based framework for multi-hop question\nanswering. It integrates components (VSS-based entity search, LLM-based\ngeneration of Cypher queries and pairwise re-ranking) in a way that enables it\nto outperform state-of-the-art methods across all three STaRK benchmark test\nsets, covering diverse domains and multiple performance metrics. The average\nfirst-hit rate exceeds that of the second-best method by 25.7%.\nFocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to\nextract relational facts and entity attributes from unstructured text, (2) node\nset joins to filter answer candidates based on these extracted triplets and\nconstraints, (3) vector similarity search to retrieve and rank relevant\nunstructured content, and (4) the contextual capabilities of LLMs to finally\nrank the top-k answers. For generality, we only incorporate base LLMs in\nFocusedRetriever in our evaluation. However, our analysis of intermediate\nresults highlights several opportunities for further upgrades including\nfinetuning. The source code is publicly available at\nhttps://github.com/kramerlab/FocusedRetriever .", "AI": {"tldr": "FocusedRetriever is a modular SKB-based framework for multi-hop QA, outperforming state-of-the-art methods by 25.7% on STaRK benchmarks. It integrates LLMs, VSS, and re-ranking to leverage both structured and unstructured data.", "motivation": "Bridging the gap between structured knowledge (e.g., knowledge graphs) and unstructured content (e.g., natural language) to enhance knowledge access and use in machine learning models.", "method": "Combines LLMs for relational fact extraction, node set joins for filtering, vector similarity search for ranking, and LLMs for final answer ranking.", "result": "Achieves a 25.7% higher first-hit rate than the second-best method across diverse domains in the STaRK benchmark.", "conclusion": "FocusedRetriever demonstrates the effectiveness of integrating structured and unstructured data, with potential for further improvements via finetuning."}}
{"id": "2505.08818", "pdf": "https://arxiv.org/pdf/2505.08818", "abs": "https://arxiv.org/abs/2505.08818", "authors": ["Amara Tariq", "Rimita Lahiri", "Charles Kahn", "Imon Banerjee"], "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "15 pages, 2, tables, 3 figures", "summary": "The intricate and multifaceted nature of vision language model (VLM)\ndevelopment, adaptation, and application necessitates the establishment of\nclear and standardized reporting protocols, particularly within the high-stakes\ncontext of healthcare. Defining these reporting standards is inherently\nchallenging due to the diverse nature of studies involving VLMs, which vary\nsignificantly from the development of all new VLMs or finetuning for domain\nalignment to off-the-shelf use of VLM for targeted diagnosis and prediction\ntasks. In this position paper, we argue that traditional machine learning\nreporting standards and evaluation guidelines must be restructured to\naccommodate multiphase VLM studies; it also has to be organized for intuitive\nunderstanding of developers while maintaining rigorous standards for\nreproducibility. To facilitate community adoption, we propose a categorization\nframework for VLM studies and outline corresponding reporting standards that\ncomprehensively address performance evaluation, data reporting protocols, and\nrecommendations for manuscript composition. These guidelines are organized\naccording to the proposed categorization scheme. Lastly, we present a checklist\nthat consolidates reporting standards, offering a standardized tool to ensure\nconsistency and quality in the publication of VLM-related research.", "AI": {"tldr": "The paper advocates for standardized reporting protocols in vision language model (VLM) research, especially in healthcare, proposing a categorization framework and checklist to ensure consistency and reproducibility.", "motivation": "The diverse and high-stakes nature of VLM studies in healthcare necessitates clear reporting standards to address variability in development, adaptation, and application.", "method": "The authors propose a categorization framework for VLM studies and outline reporting standards covering performance evaluation, data reporting, and manuscript composition.", "result": "A checklist is presented to standardize reporting, ensuring consistency and quality in VLM-related research publications.", "conclusion": "Restructuring traditional ML reporting standards for VLMs is essential for intuitive understanding and reproducibility, with the proposed framework facilitating community adoption."}}
{"id": "2505.09063", "pdf": "https://arxiv.org/pdf/2505.09063", "abs": "https://arxiv.org/abs/2505.09063", "authors": ["Khalid Rafiq", "Wenjing Liao", "Aditya G. Nair"], "title": "Single-shot prediction of parametric partial differential equations", "categories": ["cs.LG", "cs.NA", "math.NA", "68T07"], "comment": "35 pages, 17 figures", "summary": "We introduce Flexi-VAE, a data-driven framework for efficient single-shot\nforecasting of nonlinear parametric partial differential equations (PDEs),\neliminating the need for iterative time-stepping while maintaining high\naccuracy and stability. Flexi-VAE incorporates a neural propagator that\nadvances latent representations forward in time, aligning latent evolution with\nphysical state reconstruction in a variational autoencoder setting. We evaluate\ntwo propagation strategies, the Direct Concatenation Propagator (DCP) and the\nPositional Encoding Propagator (PEP), and demonstrate, through\nrepresentation-theoretic analysis, that DCP offers superior long-term\ngeneralization by fostering disentangled and physically meaningful latent\nspaces. Geometric diagnostics, including Jacobian spectral analysis, reveal\nthat propagated latent states reside in regions of lower decoder sensitivity\nand more stable local geometry than those derived via direct encoding,\nenhancing robustness for long-horizon predictions. We validate Flexi-VAE on\ncanonical PDE benchmarks, the 1D viscous Burgers equation and the 2D\nadvection-diffusion equation, achieving accurate forecasts across wide\nparametric ranges. The model delivers over 50x CPU and 90x GPU speedups\ncompared to autoencoder-LSTM baselines for large temporal shifts. These results\nposition Flexi-VAE as a scalable and interpretable surrogate modeling tool for\naccelerating high-fidelity simulations in computational fluid dynamics (CFD)\nand other parametric PDE-driven applications, with extensibility to\nhigher-dimensional and more complex systems.", "AI": {"tldr": "Flexi-VAE is a framework for efficient single-shot forecasting of nonlinear PDEs, avoiding iterative time-stepping while ensuring accuracy. It uses neural propagators in a VAE setting, with DCP outperforming PEP for long-term predictions. Validated on PDE benchmarks, it shows significant speedups and robustness.", "motivation": "To overcome the inefficiency of iterative time-stepping in PDE forecasting and provide a scalable, interpretable surrogate model for high-fidelity simulations.", "method": "Flexi-VAE employs a neural propagator in a VAE framework, comparing DCP and PEP strategies. It uses geometric diagnostics like Jacobian spectral analysis to ensure stable latent spaces.", "result": "Achieves accurate forecasts for 1D and 2D PDEs, with 50x CPU and 90x GPU speedups over baselines. DCP enhances long-term generalization.", "conclusion": "Flexi-VAE is a scalable, interpretable tool for accelerating PDE-driven simulations, with potential for higher-dimensional applications."}}
{"id": "2403.02043", "pdf": "https://arxiv.org/pdf/2403.02043", "abs": "https://arxiv.org/abs/2403.02043", "authors": ["Rui Louren\u00e7o", "Lucas Thomaz", "Eduardo A. B. Silva", "Sergio M. M. Faria"], "title": "Iterative Occlusion-Aware Light Field Depth Estimation using 4D Geometrical Cues", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Light field cameras and multi-camera arrays have emerged as promising\nsolutions for accurately estimating depth by passively capturing light\ninformation. This is possible because the 3D information of a scene is embedded\nin the 4D light field geometry. Commonly, depth estimation methods extract this\ninformation relying on gradient information, heuristic-based optimisation\nmodels, or learning-based approaches. This paper focuses mainly on explicitly\nunderstanding and exploiting 4D geometrical cues for light field depth\nestimation. Thus, a novel method is proposed, based on a non-learning-based\noptimisation approach for depth estimation that explicitly considers surface\nnormal accuracy and occlusion regions by utilising a fully explainable 4D\ngeometric model of the light field. The 4D model performs depth/disparity\nestimation by determining the orientations and analysing the intersections of\nkey 2D planes in 4D space, which are the images of 3D-space points in the 4D\nlight field. Experimental results show that the proposed method outperforms\nboth learning-based and non-learning-based state-of-the-art methods in terms of\nsurface normal angle accuracy, achieving a Median Angle Error on planar\nsurfaces, on average, 26.3$\\%$ lower than the state-of-the-art, and still being\ncompetitive with state-of-the-art methods in terms of MSE ${\\times}$ 100 and\nBadpix 0.07.", "AI": {"tldr": "A non-learning-based optimization method for light field depth estimation, leveraging 4D geometric cues, outperforms state-of-the-art in surface normal accuracy.", "motivation": "To improve depth estimation by explicitly using 4D geometric cues in light fields, addressing occlusion and surface normal accuracy.", "method": "A non-learning-based optimization approach using a 4D geometric model to analyze intersections of 2D planes in 4D space.", "result": "Achieves 26.3% lower Median Angle Error than state-of-the-art and competitive MSE and Badpix scores.", "conclusion": "The method effectively exploits 4D geometry for accurate depth estimation, surpassing learning and non-learning benchmarks."}}
{"id": "2505.08909", "pdf": "https://arxiv.org/pdf/2505.08909", "abs": "https://arxiv.org/abs/2505.08909", "authors": ["Deliang Wei", "Peng Chen", "Haobo Xu", "Jiale Yao", "Fang Li", "Tieyong Zeng"], "title": "Learning Cocoercive Conservative Denoisers via Helmholtz Decomposition for Poisson Inverse Problems", "categories": ["cs.CV", "cs.LG", "math.FA", "math.OC", "94A08, 47H10, 47J26, 46N10, 47N10"], "comment": "31 pages", "summary": "Plug-and-play (PnP) methods with deep denoisers have shown impressive results\nin imaging problems. They typically require strong convexity or smoothness of\nthe fidelity term and a (residual) non-expansive denoiser for convergence.\nThese assumptions, however, are violated in Poisson inverse problems, and\nnon-expansiveness can hinder denoising performance. To address these\nchallenges, we propose a cocoercive conservative (CoCo) denoiser, which may be\n(residual) expansive, leading to improved denoising. By leveraging the\ngeneralized Helmholtz decomposition, we introduce a novel training strategy\nthat combines Hamiltonian regularization to promote conservativeness and\nspectral regularization to ensure cocoerciveness. We prove that CoCo denoiser\nis a proximal operator of a weakly convex function, enabling a restoration\nmodel with an implicit weakly convex prior. The global convergence of PnP\nmethods to a stationary point of this restoration model is established.\nExtensive experimental results demonstrate that our approach outperforms\nclosely related methods in both visual quality and quantitative metrics.", "AI": {"tldr": "The paper introduces a cocoercive conservative (CoCo) denoiser to address limitations of PnP methods in Poisson inverse problems, improving denoising performance and ensuring convergence.", "motivation": "Existing PnP methods require restrictive assumptions (strong convexity/smoothness and non-expansive denoisers) that fail in Poisson inverse problems and limit denoising performance.", "method": "Proposes CoCo denoiser, trained with Hamiltonian and spectral regularization, ensuring it acts as a proximal operator of a weakly convex function.", "result": "CoCo denoiser enables a restoration model with implicit weakly convex prior, with global convergence proven. Experiments show superior performance.", "conclusion": "The CoCo denoiser overcomes prior limitations, offering improved denoising and convergence in PnP methods for Poisson inverse problems."}}
{"id": "2505.09436", "pdf": "https://arxiv.org/pdf/2505.09436", "abs": "https://arxiv.org/abs/2505.09436", "authors": ["Raghav Garg", "Kapil Sharma", "Karan Gupta"], "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques.", "AI": {"tldr": "CXMArena is a synthetic benchmark for evaluating LLMs in CXM, addressing data scarcity and realism gaps in current benchmarks.", "motivation": "Existing benchmarks lack realism and fail to address operational CXM tasks, hindering LLM evaluation in contact centers.", "method": "Developed a scalable LLM-powered pipeline to simulate CXM entities, including knowledge articles and conversations, with controlled noise and validation.", "result": "CXMArena benchmarks show low accuracy (68%) and F1 scores (0.3) for state-of-the-art models, highlighting challenges.", "conclusion": "CXMArena fills a critical gap in CXM evaluation, revealing the need for advanced solutions beyond conventional methods."}}
{"id": "2505.08821", "pdf": "https://arxiv.org/pdf/2505.08821", "abs": "https://arxiv.org/abs/2505.08821", "authors": ["Meryem Altin Karagoz", "Marc D. Breton", "Anas El Fathi"], "title": "A Comparative Study of Transformer-Based Models for Multi-Horizon Blood Glucose Prediction", "categories": ["q-bio.QM", "cs.AI", "stat.AP"], "comment": "7 pages, 2 figures, 1 table, 1st IFAC Workshop on Engineering\n  Diabetes Technologies (EDT 2025)", "summary": "Accurate blood glucose prediction can enable novel interventions for type 1\ndiabetes treatment, including personalized insulin and dietary adjustments.\nAlthough recent advances in transformer-based architectures have demonstrated\nthe power of attention mechanisms in complex multivariate time series\nprediction, their potential for blood glucose (BG) prediction remains\nunderexplored. We present a comparative analysis of transformer models for\nmulti-horizon BG prediction, examining forecasts up to 4 hours and input\nhistory up to 1 week. The publicly available DCLP3 dataset (n=112) was split\n(80%-10%-10%) for training, validation, and testing, and the OhioT1DM dataset\n(n=12) served as an external test set. We trained networks with point-wise,\npatch-wise, series-wise, and hybrid embeddings, using CGM, insulin, and meal\ndata. For short-term blood glucose prediction, Crossformer, a patch-wise\ntransformer architecture, achieved a superior 30-minute prediction of RMSE\n(15.6 mg / dL on OhioT1DM). For longer-term predictions (1h, 2h, and 4h),\nPatchTST, another path-wise transformer, prevailed with the lowest RMSE (24.6\nmg/dL, 36.1 mg/dL, and 46.5 mg/dL on OhioT1DM). In general, models that used\ntokenization through patches demonstrated improved accuracy with larger input\nsizes, with the best results obtained with a one-week history. These findings\nhighlight the promise of transformer-based architectures for BG prediction by\ncapturing and leveraging seasonal patterns in multivariate time-series data to\nimprove accuracy.", "AI": {"tldr": "Transformer models, especially Crossformer and PatchTST, outperform in blood glucose prediction, with patch-wise tokenization improving accuracy for longer input histories.", "motivation": "Accurate blood glucose prediction can enhance type 1 diabetes treatment through personalized insulin and dietary adjustments, but transformer models' potential for this task is underexplored.", "method": "Comparative analysis of transformer models (Crossformer, PatchTST) for multi-horizon BG prediction using CGM, insulin, and meal data, tested on DCLP3 and OhioT1DM datasets.", "result": "Crossformer excelled in 30-minute predictions (RMSE 15.6 mg/dL), while PatchTST led in longer-term predictions (1h-4h, RMSE 24.6-46.5 mg/dL). Patch-wise tokenization improved accuracy with larger input sizes.", "conclusion": "Transformer-based architectures, particularly with patch-wise tokenization, show promise for BG prediction by capturing seasonal patterns in time-series data."}}
{"id": "2505.09076", "pdf": "https://arxiv.org/pdf/2505.09076", "abs": "https://arxiv.org/abs/2505.09076", "authors": ["Berkay Guler", "Hamid Jafarkhani"], "title": "AdaFortiTran: An Adaptive Transformer Model for Robust OFDM Channel Estimation", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Deep learning models for channel estimation in Orthogonal Frequency Division\nMultiplexing (OFDM) systems often suffer from performance degradation under\nfast-fading channels and low-SNR scenarios. To address these limitations, we\nintroduce the Adaptive Fortified Transformer (AdaFortiTran), a novel model\nspecifically designed to enhance channel estimation in challenging\nenvironments. Our approach employs convolutional layers that exploit locality\nbias to capture strong correlations between neighboring channel elements,\ncombined with a transformer encoder that applies the global Attention mechanism\nto channel patches. This approach effectively models both long-range\ndependencies and spectro-temporal interactions within single OFDM frames. We\nfurther augment the model's adaptability by integrating nonlinear\nrepresentations of available channel statistics SNR, delay spread, and Doppler\nshift as priors. A residual connection is employed to merge global features\nfrom the transformer with local features from early convolutional processing,\nfollowed by final convolutional layers to refine the hierarchical channel\nrepresentation. Despite its compact architecture, AdaFortiTran achieves up to 6\ndB reduction in mean squared error (MSE) compared to state-of-the-art models.\nTested across a wide range of Doppler shifts (200-1000 Hz), SNRs (0 to 25 dB),\nand delay spreads (50-300 ns), it demonstrates superior robustness in\nhigh-mobility environments.", "AI": {"tldr": "AdaFortiTran improves OFDM channel estimation in fast-fading and low-SNR conditions using a hybrid CNN-transformer model with adaptive priors, achieving a 6 dB MSE reduction.", "motivation": "Address performance degradation of deep learning models in fast-fading and low-SNR scenarios for OFDM systems.", "method": "Combines convolutional layers for local correlations and a transformer encoder for global attention, integrating SNR, delay spread, and Doppler shift as priors. Uses residual connections and final convolutional layers for refinement.", "result": "Achieves up to 6 dB MSE reduction and superior robustness across varying Doppler shifts, SNRs, and delay spreads.", "conclusion": "AdaFortiTran is a compact, effective solution for challenging channel estimation environments."}}
{"id": "2404.06080", "pdf": "https://arxiv.org/pdf/2404.06080", "abs": "https://arxiv.org/abs/2404.06080", "authors": ["Ching-Kai Lin", "Di-Chun Wei", "Yun-Chien Cheng"], "title": "Using Few-Shot Learning to Classify Primary Lung Cancer and Other Malignancy with Lung Metastasis in Cytological Imaging via Endobronchial Ultrasound Procedures", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "This study presents a computer-aided diagnosis (CAD) system to assist early\ndetection of lung metastases during endobronchial ultrasound (EBUS) procedures,\nsignificantly reducing follow-up time and enabling timely treatment. Due to\nlimited cytology images and morphological similarities among cells, classifying\nlung metastases is challenging, and existing research rarely targets this issue\ndirectly.To overcome data scarcity and improve classification, the authors\npropose a few-shot learning model using a hybrid pretrained backbone with\nfine-grained classification and contrastive learning. Parameter-efficient\nfine-tuning on augmented support sets enhances generalization and\ntransferability. The model achieved 49.59% accuracy, outperforming existing\nmethods. With 20 image samples, accuracy improved to 55.48%, showing strong\npotential for identifying rare or novel cancer types in low-data clinical\nenvironments.", "AI": {"tldr": "A few-shot learning model for lung metastasis detection in EBUS procedures, achieving 49.59% accuracy, improving to 55.48% with 20 samples.", "motivation": "Early detection of lung metastases is challenging due to limited cytology images and cell similarities. Existing research lacks direct solutions.", "method": "Proposes a few-shot learning model with hybrid pretrained backbone, fine-grained classification, and contrastive learning. Uses parameter-efficient fine-tuning on augmented support sets.", "result": "Achieved 49.59% accuracy, rising to 55.48% with 20 samples, outperforming existing methods.", "conclusion": "The model shows strong potential for rare cancer detection in low-data clinical settings."}}
{"id": "2505.08961", "pdf": "https://arxiv.org/pdf/2505.08961", "abs": "https://arxiv.org/abs/2505.08961", "authors": ["Yancheng Wang", "Nebojsa Jojic", "Yingzhen Yang"], "title": "Differentiable Channel Selection in Self-Attention For Person Re-Identification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this paper, we propose a novel attention module termed the Differentiable\nChannel Selection Attention module, or the DCS-Attention module. In contrast\nwith conventional self-attention, the DCS-Attention module features selection\nof informative channels in the computation of the attention weights. The\nselection of the feature channels is performed in a differentiable manner,\nenabling seamless integration with DNN training. Our DCS-Attention is\ncompatible with either fixed neural network backbones or learnable backbones\nwith Differentiable Neural Architecture Search (DNAS), leading to DCS with\nFixed Backbone (DCS-FB) and DCS-DNAS, respectively. Importantly, our\nDCS-Attention is motivated by the principle of Information Bottleneck (IB), and\na novel variational upper bound for the IB loss, which can be optimized by SGD,\nis derived and incorporated into the training loss of the networks with the\nDCS-Attention modules. In this manner, a neural network with DCS-Attention\nmodules is capable of selecting the most informative channels for feature\nextraction so that it enjoys state-of-the-art performance for the Re-ID task.\nExtensive experiments on multiple person Re-ID benchmarks using both DCS-FB and\nDCS-DNAS show that DCS-Attention significantly enhances the prediction accuracy\nof DNNs for person Re-ID, which demonstrates the effectiveness of DCS-Attention\nin learning discriminative features critical to identifying person identities.\nThe code of our work is available at\nhttps://github.com/Statistical-Deep-Learning/DCS-Attention.", "AI": {"tldr": "The paper introduces the DCS-Attention module, a novel attention mechanism that selects informative channels for feature extraction, improving performance in person Re-ID tasks.", "motivation": "The work is motivated by the Information Bottleneck principle, aiming to enhance feature discriminability in neural networks.", "method": "The DCS-Attention module selects channels differentially, integrates with fixed or learnable backbones (DCS-FB/DCS-DNAS), and optimizes a variational IB loss.", "result": "Experiments show DCS-Attention significantly boosts accuracy in person Re-ID benchmarks.", "conclusion": "DCS-Attention effectively learns discriminative features, achieving state-of-the-art performance in Re-ID tasks."}}
{"id": "2505.09610", "pdf": "https://arxiv.org/pdf/2505.09610", "abs": "https://arxiv.org/abs/2505.09610", "authors": ["Nicolas Dupuis", "Ravi Nair", "Shyam Ramji", "Sean McClintock", "Nishant Chauhan", "Priyanka Nagpal", "Bart Blaner", "Ken Valk", "Leon Stok", "Ruchir Puri"], "title": "Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The use of Large Language Models (LLMs) in hardware design has taken off in\nrecent years, principally through its incorporation in tools that increase chip\ndesigner productivity. There has been considerable discussion about the use of\nLLMs in RTL specifications of chip designs, for which the two most popular\nlanguages are Verilog and VHDL. LLMs and their use in Verilog design has\nreceived significant attention due to the higher popularity of the language,\nbut little attention so far has been given to VHDL despite its continued\npopularity in the industry. There has also been little discussion about the\nunique needs of organizations that engage in high-performance processor design,\nand techniques to deploy AI solutions in these settings. In this paper, we\ndescribe our journey in developing a Large Language Model (LLM) specifically\nfor the purpose of explaining VHDL code, a task that has particular importance\nin an organization with decades of experience and assets in high-performance\nprocessor design. We show how we developed test sets specific to our needs and\nused them for evaluating models as we performed extended pretraining (EPT) of a\nbase LLM. Expert evaluation of the code explanations produced by the EPT model\nincreased to 69% compared to a base model rating of 43%. We further show how we\ndeveloped an LLM-as-a-judge to gauge models similar to expert evaluators. This\nled us to deriving and evaluating a host of new models, including an\ninstruction-tuned version of the EPT model with an expected expert evaluator\nrating of 71%. Our experiments also indicate that with the potential use of\nnewer base models, this rating can be pushed to 85% and beyond. We conclude\nwith a discussion on further improving the quality of hardware design LLMs\nusing exciting new developments in the Generative AI world.", "AI": {"tldr": "The paper explores developing an LLM for explaining VHDL code in high-performance processor design, achieving improved expert evaluation ratings through extended pretraining and instruction tuning.", "motivation": "Addressing the lack of attention to VHDL in LLM applications and the unique needs of high-performance processor design organizations.", "method": "Extended pretraining (EPT) of a base LLM, development of specific test sets, and expert evaluation. An LLM-as-a-judge was also created to evaluate models.", "result": "Expert evaluation ratings improved from 43% (base model) to 69% (EPT model) and 71% (instruction-tuned EPT model). Potential for 85%+ with newer base models.", "conclusion": "Further improvements in hardware design LLMs are possible with advancements in Generative AI."}}
{"id": "2505.08830", "pdf": "https://arxiv.org/pdf/2505.08830", "abs": "https://arxiv.org/abs/2505.08830", "authors": ["Wenhao Jiang", "Yuchuan Luo", "Guilin Deng", "Silong Chen", "Xu Yang", "Shihong Wu", "Xinwen Gao", "Lin Liu", "Shaojing Fu"], "title": "Federated Large Language Models: Feasibility, Robustness, Security and Future Directions", "categories": ["cs.CR", "cs.AI"], "comment": "35 pages", "summary": "The integration of Large Language Models (LLMs) and Federated Learning (FL)\npresents a promising solution for joint training on distributed data while\npreserving privacy and addressing data silo issues. However, this emerging\nfield, known as Federated Large Language Models (FLLM), faces significant\nchallenges, including communication and computation overheads, heterogeneity,\nprivacy and security concerns. Current research has primarily focused on the\nfeasibility of FLLM, but future trends are expected to emphasize enhancing\nsystem robustness and security. This paper provides a comprehensive review of\nthe latest advancements in FLLM, examining challenges from four critical\nperspectives: feasibility, robustness, security, and future directions. We\npresent an exhaustive survey of existing studies on FLLM feasibility, introduce\nmethods to enhance robustness in the face of resource, data, and task\nheterogeneity, and analyze novel risks associated with this integration,\nincluding privacy threats and security challenges. We also review the latest\ndevelopments in defense mechanisms and explore promising future research\ndirections, such as few-shot learning, machine unlearning, and IP protection.\nThis survey highlights the pressing need for further research to enhance system\nrobustness and security while addressing the unique challenges posed by the\nintegration of FL and LLM.", "AI": {"tldr": "The paper reviews Federated Large Language Models (FLLM), addressing challenges like overheads, heterogeneity, and security, while highlighting future research directions.", "motivation": "To explore the integration of LLMs and FL for privacy-preserving distributed training, identifying challenges and future trends.", "method": "Comprehensive review of FLLM advancements, focusing on feasibility, robustness, security, and future directions.", "result": "Identifies key challenges and reviews defense mechanisms, emphasizing the need for enhanced robustness and security.", "conclusion": "Further research is needed to address FLLM's unique challenges, with future trends focusing on robustness and security."}}
{"id": "2505.09085", "pdf": "https://arxiv.org/pdf/2505.09085", "abs": "https://arxiv.org/abs/2505.09085", "authors": ["Jiaxuan Chen", "Yu Qi", "Yueming Wang", "Gang Pan"], "title": "Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in deep neural networks (DNNs), particularly large-scale\nlanguage models, have demonstrated remarkable capabilities in image and natural\nlanguage understanding. Although scaling up model parameters with increasing\nvolume of training data has progressively improved DNN capabilities, achieving\ncomplex cognitive abilities - such as understanding abstract concepts,\nreasoning, and adapting to novel scenarios, which are intrinsic to human\ncognition - remains a major challenge. In this study, we show that\nbrain-in-the-loop supervised learning, utilizing a small set of brain signals,\ncan effectively transfer human conceptual structures to DNNs, significantly\nenhancing their comprehension of abstract and even unseen concepts.\nExperimental results further indicate that the enhanced cognitive capabilities\nlead to substantial performance gains in challenging tasks, including\nfew-shot/zero-shot learning and out-of-distribution recognition, while also\nyielding highly interpretable concept representations. These findings highlight\nthat human-in-the-loop supervision can effectively augment the complex\ncognitive abilities of large models, offering a promising pathway toward\ndeveloping more human-like cognitive abilities in artificial systems.", "AI": {"tldr": "Brain-in-the-loop supervised learning enhances DNNs' cognitive abilities using human brain signals, improving performance in complex tasks like few-shot learning.", "motivation": "Despite DNN advancements, achieving human-like cognitive abilities (e.g., abstract reasoning) remains challenging. This study explores using brain signals to bridge this gap.", "method": "Utilizes brain-in-the-loop supervised learning with human brain signals to transfer conceptual structures to DNNs.", "result": "Enhanced DNN comprehension of abstract concepts, improved performance in few-shot/zero-shot learning, and interpretable representations.", "conclusion": "Human-in-the-loop supervision can augment DNNs' cognitive abilities, advancing toward human-like AI systems."}}
{"id": "2409.13498", "pdf": "https://arxiv.org/pdf/2409.13498", "abs": "https://arxiv.org/abs/2409.13498", "authors": ["Savvas Sifnaios", "George Arvanitakis", "Fotios K. Konstantinidis", "Georgios Tsimiklis", "Angelos Amditis", "Panayiotis Frangos"], "title": "A Deep Learning Approach for Pixel-level Material Classification via Hyperspectral Imaging", "categories": ["eess.IV", "cs.AI", "cs.CV", "I.5; I.2.10"], "comment": "13 pages, 15 figures, 6 equations", "summary": "Recent advancements in computer vision, particularly in detection,\nsegmentation, and classification, have significantly impacted various domains.\nHowever, these advancements are tied to RGB-based systems, which are\ninsufficient for applications in industries like waste sorting,\npharmaceuticals, and defense, where advanced object characterization beyond\nshape or color is necessary. Hyperspectral (HS) imaging, capturing both\nspectral and spatial information, addresses these limitations and offers\nadvantages over conventional technologies such as X-ray fluorescence and Raman\nspectroscopy, particularly in terms of speed, cost, and safety.\n  This study evaluates the potential of combining HS imaging with deep learning\nfor material characterization. The research involves: i) designing an\nexperimental setup with HS camera, conveyor, and controlled lighting; ii)\ngenerating a multi-object dataset of various plastics (HDPE, PET, PP, PS) with\nsemi-automated mask generation and Raman spectroscopy-based labeling; and iii)\ndeveloping a deep learning model trained on HS images for pixel-level material\nclassification. The model achieved 99.94\\% classification accuracy,\ndemonstrating robustness in color, size, and shape invariance, and effectively\nhandling material overlap. Limitations, such as challenges with black objects,\nare also discussed. Extending computer vision beyond RGB to HS imaging proves\nfeasible, overcoming major limitations of traditional methods and showing\nstrong potential for future applications.", "AI": {"tldr": "Combining hyperspectral imaging with deep learning achieves high accuracy in material classification, overcoming RGB limitations.", "motivation": "RGB-based systems lack advanced object characterization needed in industries like waste sorting and pharmaceuticals. Hyperspectral imaging offers better spectral and spatial data.", "method": "Designed an experimental setup with HS camera, generated a multi-object dataset, and developed a deep learning model for pixel-level material classification.", "result": "Achieved 99.94% classification accuracy, robust to color, size, and shape variations, and handled material overlap well.", "conclusion": "Hyperspectral imaging with deep learning is feasible and outperforms traditional methods, with strong potential for future applications."}}
{"id": "2505.08999", "pdf": "https://arxiv.org/pdf/2505.08999", "abs": "https://arxiv.org/abs/2505.08999", "authors": ["Wei-Long Tian", "Peng Gao", "Xiao Liu", "Long Xu", "Hamido Fujita", "Hanan Aljuai", "Mao-Li Wang"], "title": "Towards Adaptive Meta-Gradient Adversarial Examples for Visual Tracking", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, visual tracking methods based on convolutional neural\nnetworks and Transformers have achieved remarkable performance and have been\nsuccessfully applied in fields such as autonomous driving. However, the\nnumerous security issues exposed by deep learning models have gradually\naffected the reliable application of visual tracking methods in real-world\nscenarios. Therefore, how to reveal the security vulnerabilities of existing\nvisual trackers through effective adversarial attacks has become a critical\nproblem that needs to be addressed. To this end, we propose an adaptive\nmeta-gradient adversarial attack (AMGA) method for visual tracking. This method\nintegrates multi-model ensembles and meta-learning strategies, combining\nmomentum mechanisms and Gaussian smoothing, which can significantly enhance the\ntransferability and attack effectiveness of adversarial examples. AMGA randomly\nselects models from a large model repository, constructs diverse tracking\nscenarios, and iteratively performs both white- and black-box adversarial\nattacks in each scenario, optimizing the gradient directions of each model.\nThis paradigm minimizes the gap between white- and black-box adversarial\nattacks, thus achieving excellent attack performance in black-box scenarios.\nExtensive experimental results on large-scale datasets such as OTB2015, LaSOT,\nand GOT-10k demonstrate that AMGA significantly improves the attack\nperformance, transferability, and deception of adversarial examples. Codes and\ndata are available at https://github.com/pgao-lab/AMGA.", "AI": {"tldr": "Proposes AMGA, an adaptive meta-gradient adversarial attack method for visual tracking, enhancing attack transferability and effectiveness by integrating multi-model ensembles, meta-learning, momentum mechanisms, and Gaussian smoothing.", "motivation": "Address security vulnerabilities in deep learning-based visual trackers by developing effective adversarial attacks to reveal weaknesses.", "method": "Combines multi-model ensembles, meta-learning, momentum mechanisms, and Gaussian smoothing to optimize adversarial examples. Performs iterative white- and black-box attacks in diverse scenarios.", "result": "AMGA significantly improves attack performance, transferability, and deception on datasets like OTB2015, LaSOT, and GOT-10k.", "conclusion": "AMGA effectively bridges the gap between white- and black-box attacks, demonstrating superior performance in adversarial scenarios."}}
{"id": "2402.01383", "pdf": "https://arxiv.org/pdf/2402.01383", "abs": "https://arxiv.org/abs/2402.01383", "authors": ["Mingqi Gao", "Xinyu Hu", "Jie Ruan", "Xiao Pu", "Xiaojun Wan"], "title": "LLM-based NLG Evaluation: Current Status and Challenges", "categories": ["cs.CL"], "comment": null, "summary": "Evaluating natural language generation (NLG) is a vital but challenging\nproblem in natural language processing. Traditional evaluation metrics mainly\ncapturing content (e.g. n-gram) overlap between system outputs and references\nare far from satisfactory, and large language models (LLMs) such as ChatGPT\nhave demonstrated great potential in NLG evaluation in recent years. Various\nautomatic evaluation methods based on LLMs have been proposed, including\nmetrics derived from LLMs, prompting LLMs, fine-tuning LLMs, and human-LLM\ncollaborative evaluation. In this survey, we first give a taxonomy of LLM-based\nNLG evaluation methods, and discuss their pros and cons, respectively. Lastly,\nwe discuss several open problems in this area and point out future research\ndirections.", "AI": {"tldr": "A survey on LLM-based NLG evaluation methods, discussing their taxonomy, pros, cons, and future research directions.", "motivation": "Traditional NLG evaluation metrics (e.g., n-gram overlap) are inadequate, and LLMs like ChatGPT show promise for improving evaluation.", "method": "Taxonomy of LLM-based NLG evaluation methods: metrics from LLMs, prompting, fine-tuning, and human-LLM collaboration.", "result": "LLMs offer diverse evaluation approaches but have trade-offs in effectiveness and practicality.", "conclusion": "Open problems remain; future research should address these to advance LLM-based NLG evaluation."}}
{"id": "2505.08835", "pdf": "https://arxiv.org/pdf/2505.08835", "abs": "https://arxiv.org/abs/2505.08835", "authors": ["Hyunsik Na", "Wonho Lee", "Seungdeok Roh", "Sohee Park", "Daeseon Choi"], "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "The advent of convenient and efficient fully unmanned stores equipped with\nartificial intelligence-based automated checkout systems marks a new era in\nretail. However, these systems have inherent artificial intelligence security\nvulnerabilities, which are exploited via adversarial patch attacks,\nparticularly in physical environments. This study demonstrated that adversarial\npatches can severely disrupt object detection models used in unmanned stores,\nleading to issues such as theft, inventory discrepancies, and interference. We\ninvestigated three types of adversarial patch attacks -- Hiding, Creating, and\nAltering attacks -- and highlighted their effectiveness. We also introduce the\nnovel color histogram similarity loss function by leveraging attacker knowledge\nof the color information of a target class object. Besides the traditional\nconfusion-matrix-based attack success rate, we introduce a new\nbounding-boxes-based metric to analyze the practical impact of these attacks.\nStarting with attacks on object detection models trained on snack and fruit\ndatasets in a digital environment, we evaluated the effectiveness of\nadversarial patches in a physical testbed that mimicked a real unmanned store\nwith RGB cameras and realistic conditions. Furthermore, we assessed the\nrobustness of these attacks in black-box scenarios, demonstrating that shadow\nattacks can enhance success rates of attacks even without direct access to\nmodel parameters. Our study underscores the necessity for robust defense\nstrategies to protect unmanned stores from adversarial threats. Highlighting\nthe limitations of the current defense mechanisms in real-time detection\nsystems and discussing various proactive measures, we provide insights into\nimproving the robustness of object detection models and fortifying unmanned\nretail environments against these attacks.", "AI": {"tldr": "The study explores adversarial patch attacks on AI-based checkout systems in unmanned stores, demonstrating their effectiveness and proposing new metrics and defense strategies.", "motivation": "To address security vulnerabilities in AI-based automated checkout systems in unmanned stores, particularly adversarial patch attacks that disrupt object detection models.", "method": "Investigated three adversarial patch attacks (Hiding, Creating, Altering) and introduced a new color histogram similarity loss function. Evaluated attacks in digital and physical environments, including black-box scenarios.", "result": "Adversarial patches significantly disrupt object detection, causing theft and inventory issues. Shadow attacks enhance success rates even without model access.", "conclusion": "The study highlights the need for robust defense strategies to protect unmanned stores from adversarial threats and improve model robustness."}}
{"id": "2505.09089", "pdf": "https://arxiv.org/pdf/2505.09089", "abs": "https://arxiv.org/abs/2505.09089", "authors": ["Philipp Hess", "Maximilian Gelbrecht", "Christof Sch\u00f6tz", "Michael Aich", "Yu Huang", "Shangshang Yang", "Niklas Boers"], "title": "Generating time-consistent dynamics with discriminator-guided image diffusion models", "categories": ["cs.LG"], "comment": null, "summary": "Realistic temporal dynamics are crucial for many video generation, processing\nand modelling applications, e.g. in computational fluid dynamics, weather\nprediction, or long-term climate simulations. Video diffusion models (VDMs) are\nthe current state-of-the-art method for generating highly realistic dynamics.\nHowever, training VDMs from scratch can be challenging and requires large\ncomputational resources, limiting their wider application. Here, we propose a\ntime-consistency discriminator that enables pretrained image diffusion models\nto generate realistic spatiotemporal dynamics. The discriminator guides the\nsampling inference process and does not require extensions or finetuning of the\nimage diffusion model. We compare our approach against a VDM trained from\nscratch on an idealized turbulence simulation and a real-world global\nprecipitation dataset. Our approach performs equally well in terms of temporal\nconsistency, shows improved uncertainty calibration and lower biases compared\nto the VDM, and achieves stable centennial-scale climate simulations at daily\ntime steps.", "AI": {"tldr": "A time-consistency discriminator is proposed to adapt pretrained image diffusion models for realistic spatiotemporal video generation, matching VDMs in performance while reducing computational costs.", "motivation": "Training video diffusion models (VDMs) from scratch is resource-intensive, limiting their broader use. This work aims to leverage existing image diffusion models for video generation.", "method": "Introduces a time-consistency discriminator to guide sampling in pretrained image diffusion models, avoiding model extensions or finetuning.", "result": "Matches VDMs in temporal consistency, improves uncertainty calibration, reduces biases, and enables stable long-term climate simulations.", "conclusion": "The proposed discriminator efficiently adapts image diffusion models for video tasks, offering a practical alternative to VDMs."}}
{"id": "2409.18872", "pdf": "https://arxiv.org/pdf/2409.18872", "abs": "https://arxiv.org/abs/2409.18872", "authors": ["Richard Osuala", "Smriti Joshi", "Apostolia Tsirikoglou", "Lidia Garrucho", "Walter H. L. Pinaya", "Daniel M. Lang", "Julia A. Schnabel", "Oliver Diaz", "Karim Lekadir"], "title": "Simulating Dynamic Tumor Contrast Enhancement in Breast MRI using Conditional Generative Adversarial Networks", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper presents a method for virtual contrast enhancement in breast MRI,\noffering a promising non-invasive alternative to traditional contrast\nagent-based DCE-MRI acquisition. Using a conditional generative adversarial\nnetwork, we predict DCE-MRI images, including jointly-generated sequences of\nmultiple corresponding DCE-MRI timepoints, from non-contrast-enhanced MRIs,\nenabling tumor localization and characterization without the associated health\nrisks. Furthermore, we qualitatively and quantitatively evaluate the synthetic\nDCE-MRI images, proposing a multi-metric Scaled Aggregate Measure (SAMe),\nassessing their utility in a tumor segmentation downstream task, and conclude\nwith an analysis of the temporal patterns in multi-sequence DCE-MRI generation.\nOur approach demonstrates promising results in generating realistic and useful\nDCE-MRI sequences, highlighting the potential of virtual contrast enhancement\nfor improving breast cancer diagnosis and treatment, particularly for patients\nwhere contrast agent administration is contraindicated.", "AI": {"tldr": "A method for virtual contrast enhancement in breast MRI using a generative adversarial network to predict DCE-MRI images from non-contrast MRIs, evaluated for tumor segmentation and temporal patterns.", "motivation": "To provide a non-invasive alternative to traditional contrast agent-based DCE-MRI, reducing health risks for patients with contraindications.", "method": "Uses a conditional generative adversarial network to predict DCE-MRI sequences from non-contrast MRIs, evaluated with a multi-metric Scaled Aggregate Measure (SAMe).", "result": "Demonstrates promising results in generating realistic DCE-MRI sequences, useful for tumor localization and characterization.", "conclusion": "Highlights the potential of virtual contrast enhancement for improving breast cancer diagnosis, especially for patients who cannot tolerate contrast agents."}}
{"id": "2505.09018", "pdf": "https://arxiv.org/pdf/2505.09018", "abs": "https://arxiv.org/abs/2505.09018", "authors": ["Adarsh Kumar"], "title": "Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Effective dietary monitoring is critical for managing Type 2 diabetes, yet\naccurately estimating caloric intake remains a major challenge. While\ncontinuous glucose monitors (CGMs) offer valuable physiological data, they\noften fall short in capturing the full nutritional profile of meals due to\ninter-individual and meal-specific variability. In this work, we introduce a\nmultimodal deep learning framework that jointly leverages CGM time-series data,\nDemographic/Microbiome, and pre-meal food images to enhance caloric estimation.\nOur model utilizes attention based encoding and a convolutional feature\nextraction for meal imagery, multi-layer perceptrons for CGM and Microbiome\ndata followed by a late fusion strategy for joint reasoning. We evaluate our\napproach on a curated dataset of over 40 participants, incorporating\nsynchronized CGM, Demographic and Microbiome data and meal photographs with\nstandardized caloric labels. Our model achieves a Root Mean Squared Relative\nError (RMSRE) of 0.2544, outperforming the baselines models by over 50%. These\nfindings demonstrate the potential of multimodal sensing to improve automated\ndietary assessment tools for chronic disease management.", "AI": {"tldr": "A multimodal deep learning framework improves caloric intake estimation for Type 2 diabetes management by combining CGM data, demographic/microbiome info, and meal images, outperforming baselines by 50%.", "motivation": "Accurate caloric intake estimation is challenging for diabetes management, and existing tools like CGMs lack full nutritional profiling.", "method": "Uses attention-based encoding for meal images, MLPs for CGM/microbiome data, and late fusion for joint reasoning.", "result": "Achieves RMSRE of 0.2544, outperforming baselines by over 50%.", "conclusion": "Multimodal sensing enhances dietary assessment tools for chronic disease management."}}
{"id": "2404.03080", "pdf": "https://arxiv.org/pdf/2404.03080", "abs": "https://arxiv.org/abs/2404.03080", "authors": ["Yanpeng Ye", "Jie Ren", "Shaozhou Wang", "Yuwei Wan", "Imran Razzak", "Bram Hoex", "Haofen Wang", "Tong Xie", "Wenjie Zhang"], "title": "Construction and Application of Materials Knowledge Graph in Multidisciplinary Materials Science via Large Language Model", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages, 7 figures, 3 tables; Accepted by 38th Conference on Neural\n  Information Processing Systems (NeurIPS 2024)", "summary": "Knowledge in materials science is widely dispersed across extensive\nscientific literature, posing significant challenges to the efficient discovery\nand integration of new materials. Traditional methods, often reliant on costly\nand time-consuming experimental approaches, further complicate rapid\ninnovation. Addressing these challenges, the integration of artificial\nintelligence with materials science has opened avenues for accelerating the\ndiscovery process, though it also demands precise annotation, data extraction,\nand traceability of information. To tackle these issues, this article\nintroduces the Materials Knowledge Graph (MKG), which utilizes advanced natural\nlanguage processing techniques integrated with large language models to extract\nand systematically organize a decade's worth of high-quality research into\nstructured triples, contains 162,605 nodes and 731,772 edges. MKG categorizes\ninformation into comprehensive labels such as Name, Formula, and Application,\nstructured around a meticulously designed ontology, thus enhancing data\nusability and integration. By implementing network-based algorithms, MKG not\nonly facilitates efficient link prediction but also significantly reduces\nreliance on traditional experimental methods. This structured approach not only\nstreamlines materials research but also lays the groundwork for more\nsophisticated science knowledge graphs.", "AI": {"tldr": "The paper introduces the Materials Knowledge Graph (MKG), leveraging AI and NLP to organize materials science literature into structured data, reducing reliance on traditional experimental methods.", "motivation": "The dispersed nature of materials science knowledge and inefficiencies in traditional methods hinder rapid innovation. AI integration offers a solution but requires precise data handling.", "method": "MKG uses NLP and large language models to extract and organize research into structured triples (162,605 nodes, 731,772 edges) with a designed ontology.", "result": "MKG enhances data usability, enables efficient link prediction, and reduces dependency on costly experimental approaches.", "conclusion": "MKG streamlines materials research and paves the way for advanced science knowledge graphs."}}
{"id": "2505.08841", "pdf": "https://arxiv.org/pdf/2505.08841", "abs": "https://arxiv.org/abs/2505.08841", "authors": ["Andrea Cremaschi", "Dae-Jin Lee", "Manuele Leonelli"], "title": "Will AI Take My Job? Evolving Perceptions of Automation and Labor Risk in Latin America", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As artificial intelligence and robotics increasingly reshape the global labor\nmarket, understanding public perceptions of these technologies becomes\ncritical. We examine how these perceptions have evolved across Latin America,\nusing survey data from the 2017, 2018, 2020, and 2023 waves of the\nLatinobar\\'ometro. Drawing on responses from over 48,000 individuals across 16\ncountries, we analyze fear of job loss due to artificial intelligence and\nrobotics. Using statistical modeling and latent class analysis, we identify key\nstructural and ideological predictors of concern, with education level and\npolitical orientation emerging as the most consistent drivers. Our findings\nreveal substantial temporal and cross-country variation, with a notable peak in\nfear during 2018 and distinct attitudinal profiles emerging from latent\nsegmentation. These results offer new insights into the social and structural\ndimensions of AI anxiety in emerging economies and contribute to a broader\nunderstanding of public attitudes toward automation beyond the Global North.", "AI": {"tldr": "The paper analyzes public perceptions of AI and robotics in Latin America, identifying education and political orientation as key predictors of job loss fear, with notable variations over time and across countries.", "motivation": "To understand how public perceptions of AI and robotics evolve in Latin America, given their impact on the labor market, and to explore the social and structural factors driving these perceptions.", "method": "Uses survey data from Latinobar\u00f3metro (2017-2023) with over 48,000 respondents across 16 countries, employing statistical modeling and latent class analysis.", "result": "Reveals significant temporal and cross-country variation in fear of job loss, peaking in 2018, with education and political orientation as consistent predictors. Latent segmentation identifies distinct attitudinal profiles.", "conclusion": "Provides insights into AI anxiety in emerging economies, highlighting the role of social and structural factors, and expands understanding of automation attitudes beyond the Global North."}}
{"id": "2505.09106", "pdf": "https://arxiv.org/pdf/2505.09106", "abs": "https://arxiv.org/abs/2505.09106", "authors": ["Ya Liu", "Kai Yang", "Yu Zhu", "Keying Yang", "Haibo Zhao"], "title": "Argus: Federated Non-convex Bilevel Learning over 6G Space-Air-Ground Integrated Network", "categories": ["cs.LG", "68T07", "I.2"], "comment": "17 pages, 11 figures", "summary": "The space-air-ground integrated network (SAGIN) has recently emerged as a\ncore element in the 6G networks. However, traditional centralized and\nsynchronous optimization algorithms are unsuitable for SAGIN due to\ninfrastructureless and time-varying environments. This paper aims to develop a\nnovel Asynchronous algorithm a.k.a. Argus for tackling non-convex and\nnon-smooth decentralized federated bilevel learning over SAGIN. The proposed\nalgorithm allows networked agents (e.g. autonomous aerial vehicles) to tackle\nbilevel learning problems in time-varying networks asynchronously, thereby\naverting stragglers from impeding the overall training speed. We provide a\ntheoretical analysis of the iteration complexity, communication complexity, and\ncomputational complexity of Argus. Its effectiveness is further demonstrated\nthrough numerical experiments.", "AI": {"tldr": "The paper introduces Argus, an asynchronous algorithm for decentralized federated bilevel learning in SAGIN, addressing non-convex and non-smooth problems in time-varying networks.", "motivation": "Traditional centralized and synchronous methods are unsuitable for SAGIN due to its infrastructureless and dynamic nature, necessitating a novel asynchronous approach.", "method": "The proposed Argus algorithm enables networked agents (e.g., aerial vehicles) to perform asynchronous bilevel learning in time-varying networks, avoiding delays from stragglers.", "result": "Theoretical analysis covers iteration, communication, and computational complexities, with numerical experiments validating Argus's effectiveness.", "conclusion": "Argus successfully addresses the challenges of decentralized federated bilevel learning in SAGIN, offering a robust solution for dynamic environments."}}
{"id": "2504.21227", "pdf": "https://arxiv.org/pdf/2504.21227", "abs": "https://arxiv.org/abs/2504.21227", "authors": ["Omid Halimi Milani", "Amanda Nikho", "Lauren Mills", "Marouane Tliba", "Ahmet Enis Cetin", "Mohammed H. Elnagar"], "title": "Gradient Attention Map Based Verification of Deep Convolutional Neural Networks with Application to X-ray Image Datasets", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "13 pages, 7 figures, accepted at IEEE VLSI Test Symposium (VTS) 2025", "summary": "Deep learning models have great potential in medical imaging, including\northodontics and skeletal maturity assessment. However, applying a model to\ndata different from its training set can lead to unreliable predictions that\nmay impact patient care. To address this, we propose a comprehensive\nverification framework that evaluates model suitability through multiple\ncomplementary strategies. First, we introduce a Gradient Attention Map\n(GAM)-based approach that analyzes attention patterns using Grad-CAM and\ncompares them via similarity metrics such as IoU, Dice Similarity, SSIM, Cosine\nSimilarity, Pearson Correlation, KL Divergence, and Wasserstein Distance.\nSecond, we extend verification to early convolutional feature maps, capturing\nstructural mis-alignments missed by attention alone. Finally, we incorporate an\nadditional garbage class into the classification model to explicitly reject\nout-of-distribution inputs. Experimental results demonstrate that these\ncombined methods effectively identify unsuitable models and inputs, promoting\nsafer and more reliable deployment of deep learning in medical imaging.", "AI": {"tldr": "A framework for verifying deep learning models in medical imaging ensures reliability by analyzing attention patterns, feature maps, and rejecting out-of-distribution inputs.", "motivation": "Deep learning models in medical imaging can produce unreliable predictions when applied to data different from their training sets, risking patient care.", "method": "The framework uses Gradient Attention Maps (GAM) to analyze attention patterns, extends verification to early convolutional feature maps, and adds a garbage class to reject out-of-distribution inputs.", "result": "The combined methods effectively identify unsuitable models and inputs, enhancing reliability.", "conclusion": "The proposed framework promotes safer and more reliable deployment of deep learning in medical imaging."}}
{"id": "2505.09073", "pdf": "https://arxiv.org/pdf/2505.09073", "abs": "https://arxiv.org/abs/2505.09073", "authors": ["J. Brennan Peace", "Shuowen Hu", "Benjamin S. Riggan"], "title": "2D-3D Attention and Entropy for Pose Robust 2D Facial Recognition", "categories": ["cs.CV"], "comment": "To appear at the IEEE International Conference on Automatic Face and\n  Gesture 2025 (FG2025)", "summary": "Despite recent advances in facial recognition, there remains a fundamental\nissue concerning degradations in performance due to substantial perspective\n(pose) differences between enrollment and query (probe) imagery. Therefore, we\npropose a novel domain adaptive framework to facilitate improved performances\nacross large discrepancies in pose by enabling image-based (2D) representations\nto infer properties of inherently pose invariant point cloud (3D)\nrepresentations. Specifically, our proposed framework achieves better pose\ninvariance by using (1) a shared (joint) attention mapping to emphasize common\npatterns that are most correlated between 2D facial images and 3D facial data\nand (2) a joint entropy regularizing loss to promote better\nconsistency$\\unicode{x2014}$enhancing correlations among the intersecting 2D\nand 3D representations$\\unicode{x2014}$by leveraging both attention maps. This\nframework is evaluated on FaceScape and ARL-VTF datasets, where it outperforms\ncompetitive methods by achieving profile (90$\\unicode{x00b0}$$\\unicode{x002b}$)\nTAR @ 1$\\unicode{x0025}$ FAR improvements of at least 7.1$\\unicode{x0025}$ and\n1.57$\\unicode{x0025}$, respectively.", "AI": {"tldr": "A novel domain adaptive framework improves facial recognition performance across large pose discrepancies by aligning 2D and 3D representations using shared attention and joint entropy regularization.", "motivation": "Address performance degradation in facial recognition due to pose differences between enrollment and query images.", "method": "Proposes a framework with shared attention mapping and joint entropy regularization to align 2D and 3D facial representations.", "result": "Outperforms competitive methods on FaceScape and ARL-VTF datasets, with significant improvements in profile recognition accuracy.", "conclusion": "The framework effectively enhances pose invariance in facial recognition, demonstrating superior performance on benchmark datasets."}}
{"id": "2410.04526", "pdf": "https://arxiv.org/pdf/2410.04526", "abs": "https://arxiv.org/abs/2410.04526", "authors": ["Siqiao Xue", "Xiaojing Li", "Fan Zhou", "Qingyang Dai", "Zhixuan Chu", "Hongyuan Mei"], "title": "FAMMA: A Benchmark for Financial Domain Multilingual Multimodal Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this paper, we introduce FAMMA, an open-source benchmark for\n\\underline{f}in\\underline{a}ncial \\underline{m}ultilingual\n\\underline{m}ultimodal question \\underline{a}nswering (QA). Our benchmark aims\nto evaluate the abilities of large language models (LLMs) in answering complex\nreasoning questions that require advanced financial knowledge. The benchmark\nhas two versions: FAMMA-Basic consists of 1,945 questions extracted from\nuniversity textbooks and exams, along with human-annotated answers and\nrationales; FAMMA-LivePro consists of 103 novel questions created by human\ndomain experts, with answers and rationales held out from the public for a\ncontamination-free evaluation. These questions cover advanced knowledge of 8\nmajor subfields in finance (e.g., corporate finance, derivatives, and portfolio\nmanagement). Some are in Chinese or French, while a majority of them are in\nEnglish. Each question has some non-text data such as charts, diagrams, or\ntables. Our experiments reveal that FAMMA poses a significant challenge on\nLLMs, including reasoning models such as GPT-o1 and DeepSeek-R1. Additionally,\nwe curated 1,270 reasoning trajectories of DeepSeek-R1 on the FAMMA-Basic data,\nand fine-tuned a series of open-source Qwen models using this reasoning data.\nWe found that training a model on these reasoning trajectories can\nsignificantly improve its performance on FAMMA-LivePro. We released our\nleaderboard, data, code, and trained models at\nhttps://famma-bench.github.io/famma/.", "AI": {"tldr": "FAMMA is an open-source benchmark for financial multilingual multimodal QA, challenging LLMs with complex reasoning questions. It includes two versions (Basic and LivePro) and shows that training on reasoning trajectories improves performance.", "motivation": "To evaluate LLMs' abilities in answering complex financial questions requiring advanced knowledge and multilingual, multimodal understanding.", "method": "Created FAMMA-Basic (1,945 questions from textbooks/exams) and FAMMA-LivePro (103 expert-created questions). Experiments tested LLMs like GPT-o1 and DeepSeek-R1, and fine-tuned Qwen models using reasoning trajectories.", "result": "FAMMA poses a significant challenge to LLMs. Training on reasoning trajectories improved performance on FAMMA-LivePro.", "conclusion": "FAMMA is a valuable benchmark for evaluating and improving LLMs in financial multilingual multimodal QA, with released resources for further research."}}
{"id": "2505.08844", "pdf": "https://arxiv.org/pdf/2505.08844", "abs": "https://arxiv.org/abs/2505.08844", "authors": ["Jiawen Chen", "Jianghao Zhang", "Huaxiu Yao", "Yun Li"], "title": "CellTypeAgent: Trustworthy cell type annotation with Large Language Models", "categories": ["q-bio.GN", "cs.AI", "68T20", "I.2.1"], "comment": null, "summary": "Cell type annotation is a critical yet laborious step in single-cell RNA\nsequencing analysis. We present a trustworthy large language model (LLM)-agent,\nCellTypeAgent, which integrates LLMs with verification from relevant databases.\nCellTypeAgent achieves higher accuracy than existing methods while mitigating\nhallucinations. We evaluated CellTypeAgent across nine real datasets involving\n303 cell types from 36 tissues. This combined approach holds promise for more\nefficient and reliable cell type annotation.", "AI": {"tldr": "CellTypeAgent, a trustworthy LLM-agent, improves cell type annotation accuracy by integrating LLMs with database verification, outperforming existing methods.", "motivation": "Cell type annotation is laborious in single-cell RNA sequencing analysis, necessitating a more efficient and reliable solution.", "method": "CellTypeAgent combines large language models (LLMs) with database verification to mitigate hallucinations and enhance accuracy.", "result": "Evaluated on nine datasets (303 cell types, 36 tissues), CellTypeAgent outperforms existing methods.", "conclusion": "The combined approach of LLMs and verification promises more efficient and reliable cell type annotation."}}
{"id": "2505.09113", "pdf": "https://arxiv.org/pdf/2505.09113", "abs": "https://arxiv.org/abs/2505.09113", "authors": ["Yingrong Wang", "Anpeng Wu", "Baohong Li", "Ziyang Xiao", "Ruoxuan Xiong", "Qing Han", "Kun Kuang"], "title": "Sequential Treatment Effect Estimation with Unmeasured Confounders", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "This paper studies the cumulative causal effects of sequential treatments in\nthe presence of unmeasured confounders. It is a critical issue in sequential\ndecision-making scenarios where treatment decisions and outcomes dynamically\nevolve over time. Advanced causal methods apply transformer as a backbone to\nmodel such time sequences, which shows superiority in capturing long time\ndependence and periodic patterns via attention mechanism. However, even they\ncontrol the observed confounding, these estimators still suffer from unmeasured\nconfounders, which influence both treatment assignments and outcomes. How to\nadjust the latent confounding bias in sequential treatment effect estimation\nremains an open challenge. Therefore, we propose a novel Decomposing Sequential\nInstrumental Variable framework for CounterFactual Regression (DSIV-CFR),\nrelying on a common negative control assumption. Specifically, an instrumental\nvariable (IV) is a special negative control exposure, while the previous\noutcome serves as a negative control outcome. This allows us to recover the IVs\nlatent in observation variables and estimate sequential treatment effects via a\ngeneralized moment condition. We conducted experiments on 4 datasets and\nachieved significant performance in one- and multi-step prediction, supported\nby which we can identify optimal treatments for dynamic systems.", "AI": {"tldr": "The paper proposes a novel framework (DSIV-CFR) to address unmeasured confounders in sequential treatment effects using instrumental variables and negative controls, achieving strong performance in dynamic systems.", "motivation": "The challenge of unmeasured confounders in sequential decision-making, which biases treatment effect estimation despite advanced causal methods like transformers.", "method": "Introduces DSIV-CFR, leveraging instrumental variables (IVs) and negative controls (previous outcomes) to adjust for latent confounding via a generalized moment condition.", "result": "Experiments on 4 datasets show significant performance in one- and multi-step prediction, enabling optimal treatment identification.", "conclusion": "DSIV-CFR effectively addresses unmeasured confounding in sequential treatments, offering a robust solution for dynamic systems."}}
{"id": "2505.01742", "pdf": "https://arxiv.org/pdf/2505.01742", "abs": "https://arxiv.org/abs/2505.01742", "authors": ["Yu Mao", "Jingzong Li", "Jun Wang", "Hong Xu", "Tei-Wei Kuo", "Nan Guan", "Chun Jason Xue"], "title": "Easz: An Agile Transformer-based Image Compression Framework for Resource-constrained IoTs", "categories": ["eess.IV", "cs.LG"], "comment": null, "summary": "Neural image compression, necessary in various machine-to-machine\ncommunication scenarios, suffers from its heavy encode-decode structures and\ninflexibility in switching between different compression levels. Consequently,\nit raises significant challenges in applying the neural image compression to\nedge devices that are developed for powerful servers with high computational\nand storage capacities. We take a step to solve the challenges by proposing a\nnew transformer-based edge-compute-free image coding framework called Easz.\nEasz shifts the computational overhead to the server, and hence avoids the\nheavy encoding and model switching overhead on the edge. Easz utilizes a\npatch-erase algorithm to selectively remove image contents using a conditional\nuniform-based sampler. The erased pixels are reconstructed on the receiver side\nthrough a transformer-based framework. To further reduce the computational\noverhead on the receiver, we then introduce a lightweight transformer-based\nreconstruction structure to reduce the reconstruction load on the receiver\nside. Extensive evaluations conducted on a real-world testbed demonstrate\nmultiple advantages of Easz over existing compression approaches, in terms of\nadaptability to different compression levels, computational efficiency, and\nimage reconstruction quality.", "AI": {"tldr": "Easz is a transformer-based edge-compute-free image coding framework that shifts computational overhead to servers, improving adaptability, efficiency, and reconstruction quality for edge devices.", "motivation": "Neural image compression faces challenges in edge devices due to heavy encode-decode structures and inflexibility in switching compression levels.", "method": "Easz uses a patch-erase algorithm and conditional uniform-based sampler to remove image contents, with a transformer-based framework for reconstruction. A lightweight transformer reduces receiver-side load.", "result": "Easz outperforms existing methods in adaptability, computational efficiency, and image reconstruction quality.", "conclusion": "Easz effectively addresses edge device limitations by offloading computation to servers, offering a practical solution for neural image compression."}}
{"id": "2505.09092", "pdf": "https://arxiv.org/pdf/2505.09092", "abs": "https://arxiv.org/abs/2505.09092", "authors": ["Yuhang Wang", "Abdulaziz Alhuraish", "Shengming Yuan", "Hao Zhou"], "title": "OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Lane Keeping Assist (LKA) is widely adopted in modern vehicles, yet its\nreal-world performance remains underexplored due to proprietary systems and\nlimited data access. This paper presents OpenLKA, the first open, large-scale\ndataset for LKA evaluation and improvement. It includes 400 hours of driving\ndata from 50+ production vehicle models, collected through extensive road\ntesting in Tampa, Florida and global contributions from the Comma.ai driving\ncommunity. The dataset spans a wide range of challenging scenarios, including\ncomplex road geometries, degraded lane markings, adverse weather, lighting\nconditions and surrounding traffic. The dataset is multimodal, comprising: i)\nfull CAN bus streams, decoded using custom reverse-engineered DBC files to\nextract key LKA events (e.g., system disengagements, lane detection failures);\nii) synchronized high-resolution dash-cam video; iii) real-time outputs from\nOpenpilot, providing accurate estimates of road curvature and lane positioning;\niv) enhanced scene annotations generated by Vision Language Models, describing\nlane visibility, pavement quality, weather, lighting, and traffic conditions.\nBy integrating vehicle-internal signals with high-fidelity perception and rich\nsemantic context, OpenLKA provides a comprehensive platform for benchmarking\nthe real-world performance of production LKA systems, identifying\nsafety-critical operational scenarios, and assessing the readiness of current\nroad infrastructure for autonomous driving. The dataset is publicly available\nat: https://github.com/OpenLKA/OpenLKA.", "AI": {"tldr": "OpenLKA is the first open, large-scale dataset for evaluating and improving Lane Keeping Assist (LKA) systems, featuring 400 hours of driving data from 50+ vehicle models, multimodal inputs, and rich annotations.", "motivation": "The real-world performance of LKA systems is underexplored due to proprietary systems and limited data access. OpenLKA aims to address this gap.", "method": "The dataset includes CAN bus streams, dash-cam video, Openpilot outputs, and scene annotations, collected from road testing and community contributions.", "result": "OpenLKA provides a comprehensive platform for benchmarking LKA performance, identifying safety-critical scenarios, and assessing road infrastructure readiness.", "conclusion": "OpenLKA is publicly available, offering a valuable resource for advancing LKA research and autonomous driving readiness."}}
{"id": "2411.09116", "pdf": "https://arxiv.org/pdf/2411.09116", "abs": "https://arxiv.org/abs/2411.09116", "authors": ["Yidan Zhang", "Yu Wan", "Boyi Deng", "Baosong Yang", "Haoran Wei", "Fei Huang", "Bowen Yu", "Junyang Lin", "Fei Huang", "Jingren Zhou"], "title": "P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) showcase varied\nmultilingual capabilities across tasks like translation, code generation, and\nreasoning. Previous assessments often limited their scope to fundamental\nnatural language processing (NLP) or isolated capability-specific tasks. To\nalleviate this drawback, we aim to present a comprehensive multilingual\nmultitask benchmark. First, we introduce P-MMEval, a large-scale benchmark\ncovering effective fundamental and capability-specialized datasets.\nFurthermore, P-MMEval delivers consistent language coverage across various\ndatasets and provides parallel samples. Finally, we conduct extensive\nexperiments on representative multilingual model series to compare performances\nacross models and tasks, explore the relationship between multilingual\nperformances and factors such as tasks, model sizes, languages, and prompts,\nand examine the effectiveness of knowledge transfer from English to other\nlanguages. The resulting insights are intended to offer valuable guidance for\nfuture research. The dataset is available at\nhttps://huggingface.co/datasets/Qwen/P-MMEval.", "AI": {"tldr": "The paper introduces P-MMEval, a comprehensive multilingual multitask benchmark to evaluate LLMs beyond traditional NLP tasks, offering insights into performance across models, tasks, and languages.", "motivation": "To address the limited scope of previous LLM assessments by creating a benchmark that covers diverse multilingual tasks and provides consistent language coverage.", "method": "Developed P-MMEval, a large-scale benchmark with fundamental and specialized datasets, parallel samples, and extensive experiments on multilingual models.", "result": "Evaluated model performances across tasks, languages, and factors like model size and prompts, and examined English-to-other-language knowledge transfer.", "conclusion": "P-MMEval provides valuable insights for future research, with the dataset publicly available for further exploration."}}
{"id": "2505.08847", "pdf": "https://arxiv.org/pdf/2505.08847", "abs": "https://arxiv.org/abs/2505.08847", "authors": ["Fatima Ezzeddine", "Rinad Akel", "Ihab Sbeity", "Silvia Giordano", "Marc Langheinrich", "Omran Ayoub"], "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Machine Learning as a Service (MLaaS) has gained important attraction as a\nmeans for deploying powerful predictive models, offering ease of use that\nenables organizations to leverage advanced analytics without substantial\ninvestments in specialized infrastructure or expertise. However, MLaaS\nplatforms must be safeguarded against security and privacy attacks, such as\nmodel extraction (MEA) attacks. The increasing integration of explainable AI\n(XAI) within MLaaS has introduced an additional privacy challenge, as attackers\ncan exploit model explanations particularly counterfactual explanations (CFs)\nto facilitate MEA. In this paper, we investigate the trade offs among model\nperformance, privacy, and explainability when employing Differential Privacy\n(DP), a promising technique for mitigating CF facilitated MEA. We evaluate two\ndistinct DP strategies: implemented during the classification model training\nand at the explainer during CF generation.", "AI": {"tldr": "The paper explores the trade-offs between model performance, privacy, and explainability in MLaaS when using Differential Privacy (DP) to counter model extraction attacks (MEA) exploiting counterfactual explanations (CFs).", "motivation": "MLaaS platforms face security and privacy risks, especially from MEA attacks exploiting XAI tools like CFs. DP is a potential solution, but its impact on performance and explainability needs evaluation.", "method": "Two DP strategies are tested: one applied during model training and another during CF generation.", "result": "The study assesses how DP affects model performance, privacy, and explainability in MLaaS.", "conclusion": "The findings highlight the trade-offs and effectiveness of DP strategies in mitigating CF-facilitated MEA while maintaining model utility and explainability."}}
{"id": "2505.09131", "pdf": "https://arxiv.org/pdf/2505.09131", "abs": "https://arxiv.org/abs/2505.09131", "authors": ["Kunwoong Kim", "Jihu Lee", "Sangchul Park", "Yongdai Kim"], "title": "Fair Clustering via Alignment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025. This is the version submitted for review and\n  will be replaced by the camera-ready version soon", "summary": "Algorithmic fairness in clustering aims to balance the proportions of\ninstances assigned to each cluster with respect to a given sensitive attribute.\nWhile recently developed fair clustering algorithms optimize clustering\nobjectives under specific fairness constraints, their inherent complexity or\napproximation often results in suboptimal clustering utility or numerical\ninstability in practice. To resolve these limitations, we propose a new fair\nclustering algorithm based on a novel decomposition of the fair K-means\nclustering objective function. The proposed algorithm, called Fair Clustering\nvia Alignment (FCA), operates by alternately (i) finding a joint probability\ndistribution to align the data from different protected groups, and (ii)\noptimizing cluster centers in the aligned space. A key advantage of FCA is that\nit theoretically guarantees approximately optimal clustering utility for any\ngiven fairness level without complex constraints, thereby enabling high-utility\nfair clustering in practice. Experiments show that FCA outperforms existing\nmethods by (i) attaining a superior trade-off between fairness level and\nclustering utility, and (ii) achieving near-perfect fairness without numerical\ninstability.", "AI": {"tldr": "A new fair clustering algorithm, FCA, balances fairness and utility by aligning data from protected groups and optimizing cluster centers, outperforming existing methods.", "motivation": "Existing fair clustering algorithms suffer from suboptimal utility or instability due to complexity or approximations.", "method": "FCA decomposes the fair K-means objective, alternately aligning data from protected groups and optimizing cluster centers in the aligned space.", "result": "FCA achieves superior fairness-utility trade-off and near-perfect fairness without instability.", "conclusion": "FCA provides a practical, high-utility solution for fair clustering with theoretical guarantees."}}
{"id": "2307.09714", "pdf": "https://arxiv.org/pdf/2307.09714", "abs": "https://arxiv.org/abs/2307.09714", "authors": ["Minyu Fan", "Kun Liu", "Jie Zhu", "Yu Cao", "Sha Wang"], "title": "Flexible single multimode fiber imaging using white LED", "categories": ["physics.optics", "eess.IV"], "comment": null, "summary": "Multimode fiber (MMF) has been proven to have good potential in imaging and\noptical communication because of its advantages of small diameter and large\nmode numbers. However, due to the mode coupling and modal dispersion, it is\nvery sensitive to environmental changes. Minor changes in the fiber shape can\nlead to difficulties in information reconstruction. Here, white LED and\ncascaded Unet are used to achieve MMF imaging to eliminate the effect of fiber\nperturbations. The output speckle patterns in three different color channels of\nthe CCD camera produced by transferring images through the MMF are concatenated\nand inputted into the cascaded Unet using channel stitching technology to\nimprove the reconstruction effects. The average Pearson correlation coefficient\n(PCC) of the reconstructed images from the Fashion-MINIST dataset is 0.83. In\norder to check the flexibility of such a system, perturbation tests on the\nimage reconstruction capability by changing the fiber shapes are conducted. The\nexperimental results show that the MMF imaging system has good robustness\nproperties, i. e. the average PCC remains 0.83 even after completely changing\nthe shape of the MMF. This research potentially provides a flexible approach\nfor the practical application of MMF imaging.", "AI": {"tldr": "Using white LED and cascaded Unet, the paper achieves robust MMF imaging despite fiber perturbations, maintaining a high PCC of 0.83.", "motivation": "MMF's sensitivity to environmental changes complicates information reconstruction, prompting a need for robust imaging solutions.", "method": "White LED and cascaded Unet with channel stitching technology are used to process speckle patterns from MMF for image reconstruction.", "result": "Achieves an average PCC of 0.83 for reconstructed images, even after fiber shape changes, demonstrating robustness.", "conclusion": "The method offers a flexible and practical approach for MMF imaging applications."}}
{"id": "2505.09118", "pdf": "https://arxiv.org/pdf/2505.09118", "abs": "https://arxiv.org/abs/2505.09118", "authors": ["Dayong Liang", "Changmeng Zheng", "Zhiyuan Wen", "Yi Cai", "Xiao-Yong Wei", "Qing Li"], "title": "Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Traditional scene graphs primarily focus on spatial relationships, limiting\nvision-language models' (VLMs) ability to reason about complex interactions in\nvisual scenes. This paper addresses two key challenges: (1) conventional\ndetection-to-construction methods produce unfocused, contextually irrelevant\nrelationship sets, and (2) existing approaches fail to form persistent memories\nfor generalizing interaction reasoning to new scenes. We propose\nInteraction-augmented Scene Graph Reasoning (ISGR), a framework that enhances\nVLMs' interactional reasoning through three complementary components. First,\nour dual-stream graph constructor combines SAM-powered spatial relation\nextraction with interaction-aware captioning to generate functionally salient\nscene graphs with spatial grounding. Second, we employ targeted interaction\nqueries to activate VLMs' latent knowledge of object functionalities,\nconverting passive recognition into active reasoning about how objects work\ntogether. Finally, we introduce a lone-term memory reinforcement learning\nstrategy with a specialized interaction-focused reward function that transforms\ntransient patterns into long-term reasoning heuristics. Extensive experiments\ndemonstrate that our approach significantly outperforms baseline methods on\ninteraction-heavy reasoning benchmarks, with particularly strong improvements\non complex scene understanding tasks. The source code can be accessed at\nhttps://github.com/open_upon_acceptance.", "AI": {"tldr": "The paper introduces ISGR, a framework to enhance VLMs' interaction reasoning by combining spatial and functional scene graphs, active reasoning, and long-term memory reinforcement.", "motivation": "Traditional scene graphs lack interaction reasoning, limiting VLMs' ability to understand complex visual scenes.", "method": "ISGR uses dual-stream graph construction, interaction queries, and long-term memory reinforcement learning.", "result": "ISGR outperforms baselines on interaction-heavy benchmarks, especially in complex scene understanding.", "conclusion": "ISGR effectively improves VLMs' interaction reasoning, offering a robust solution for complex scene understanding."}}
{"id": "2502.09650", "pdf": "https://arxiv.org/pdf/2502.09650", "abs": "https://arxiv.org/abs/2502.09650", "authors": ["Chengqian Gao", "Haonan Li", "Liu Liu", "Zeke Xie", "Peilin Zhao", "Zhiqiang Xu"], "title": "Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ICML 2025", "summary": "The alignment of large language models (LLMs) often assumes that using more\nclean data yields better outcomes, overlooking the match between model capacity\nand example difficulty. Challenging this, we propose a new principle:\nPreference data vary in difficulty, and overly difficult examples hinder\nalignment, by exceeding the model's capacity. Through systematic\nexperimentation, we validate this principle with three key findings: (1)\npreference examples vary in difficulty, as evidenced by consistent learning\norders across alignment runs; (2) overly difficult examples significantly\ndegrade performance across four LLMs and two datasets; and (3) the capacity of\na model dictates its threshold for handling difficult examples, underscoring a\ncritical relationship between data selection and model capacity. Building on\nthis principle, we introduce Selective DPO, which filters out overly difficult\nexamples. This simple adjustment improves alignment performance by 9-16% in win\nrates on the AlpacaEval 2 benchmark compared to the DPO baseline, suppressing a\nseries of DPO variants with different algorithmic adjustments. Together, these\nresults illuminate the importance of aligning data difficulty with model\ncapacity, offering a transformative perspective for improving alignment\nstrategies in LLMs. Code is available at\nhttps://github.com/glorgao/SelectiveDPO.", "AI": {"tldr": "The paper challenges the assumption that more clean data always improves LLM alignment, proposing that overly difficult examples hinder performance. Selective DPO, filtering such examples, boosts alignment by 9-16%.", "motivation": "To address the overlooked mismatch between model capacity and example difficulty in LLM alignment, which can degrade performance.", "method": "Introduces Selective DPO, which filters overly difficult examples based on model capacity, validated through systematic experiments.", "result": "Shows that overly difficult examples degrade performance, and Selective DPO improves alignment by 9-16% in win rates.", "conclusion": "Aligning data difficulty with model capacity is crucial for effective LLM alignment, offering a transformative strategy."}}
{"id": "2505.08849", "pdf": "https://arxiv.org/pdf/2505.08849", "abs": "https://arxiv.org/abs/2505.08849", "authors": ["Keyu Chen", "Hao Tang", "Qinglin Liu", "Yizhao Xu"], "title": "Improved Algorithms for Differentially Private Language Model Alignment", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Language model alignment is crucial for ensuring that large language models\n(LLMs) align with human preferences, yet it often involves sensitive user data,\nraising significant privacy concerns. While prior work has integrated\ndifferential privacy (DP) with alignment techniques, their performance remains\nlimited. In this paper, we propose novel algorithms for privacy-preserving\nalignment and rigorously analyze their effectiveness across varying privacy\nbudgets and models. Our framework can be deployed on two celebrated alignment\ntechniques, namely direct preference optimization (DPO) and reinforcement\nlearning from human feedback (RLHF). Through systematic experiments on\nlarge-scale language models, we demonstrate that our approach achieves\nstate-of-the-art performance. Notably, one of our algorithms, DP-AdamW,\ncombined with DPO, surpasses existing methods, improving alignment quality by\nup to 15% under moderate privacy budgets ({\\epsilon}=2-5). We further\ninvestigate the interplay between privacy guarantees, alignment efficacy, and\ncomputational demands, providing practical guidelines for optimizing these\ntrade-offs.", "AI": {"tldr": "Novel privacy-preserving algorithms for language model alignment outperform existing methods, improving alignment quality by up to 15% under moderate privacy budgets.", "motivation": "Addressing privacy concerns in language model alignment while maintaining performance.", "method": "Proposed algorithms (e.g., DP-AdamW) integrated with DPO and RLHF, analyzed across privacy budgets and models.", "result": "Achieves state-of-the-art performance; DP-AdamW with DPO improves alignment by 15% (\u03b5=2-5).", "conclusion": "Provides practical guidelines for balancing privacy, alignment efficacy, and computational costs."}}
{"id": "2505.09134", "pdf": "https://arxiv.org/pdf/2505.09134", "abs": "https://arxiv.org/abs/2505.09134", "authors": ["Daniel Huang"], "title": "Scaling Gaussian Process Regression with Full Derivative Observations", "categories": ["cs.LG", "stat.ML"], "comment": "12 pages", "summary": "We present a scalable Gaussian Process (GP) method that can fit and predict\nfull derivative observations called DSoftKI. It extends SoftKI, a method that\napproximates a kernel via softmax interpolation from learned interpolation\npoint locations, to the setting with derivatives. DSoftKI enhances SoftKI's\ninterpolation scheme to incorporate the directional orientation of\ninterpolation points relative to the data. This enables the construction of a\nscalable approximate kernel, including its first and second-order derivatives,\nthrough interpolation. We evaluate DSoftKI on a synthetic function benchmark\nand high-dimensional molecular force field prediction (100-1000 dimensions),\ndemonstrating that DSoftKI is accurate and can scale to larger datasets with\nfull derivative observations than previously possible.", "AI": {"tldr": "DSoftKI extends SoftKI to handle derivative observations, improving scalability and accuracy for high-dimensional tasks like molecular force field prediction.", "motivation": "To address the challenge of scaling Gaussian Processes (GPs) for datasets with full derivative observations, especially in high-dimensional settings.", "method": "Extends SoftKI's softmax interpolation to incorporate directional orientation of interpolation points, enabling scalable kernel approximation with derivatives.", "result": "DSoftKI shows accuracy and scalability on synthetic benchmarks and high-dimensional molecular force field prediction (100-1000 dimensions).", "conclusion": "DSoftKI advances GP methods by efficiently handling derivative observations, enabling larger-scale applications."}}
{"id": "2503.07316", "pdf": "https://arxiv.org/pdf/2503.07316", "abs": "https://arxiv.org/abs/2503.07316", "authors": ["Zacharie Idriss", "Raghu Raj"], "title": "Data-Driven Calibration Technique for Quantitative Radar Imaging", "categories": ["eess.SP", "eess.IV"], "comment": "6 pages 7 figures For 2025 IEEE CISA", "summary": "Quantitative inversion algorithms allow for the reconstruction of electrical\nproperties (such as permittivity, and conductivity) for every point in a scene.\nHowever, they are challenging to use on measured datasets due to the need to\nknow the incident wave field in the scene. In general, this is unknown due to\nfactors such as antenna characteristics, path loss, waveform factors, etc. In\nthis paper, we introduce a scalar calibration factor to account for these\nfactors. To solve for the calibration factor, we augment the inversion\nprocedure by including the forward problem, which we solve by training a simple\nfeed-forward fully connected neural network to learn a mapping between the\nunderlying permittivity distribution and the scattered field at the radar. We\nthen minimize the mismatch between the measured and simulated fields to\noptimize the scalar calibration factor for each transmitter. We use the Fresnel\nInstitute dataset to test our algorithm.", "AI": {"tldr": "The paper introduces a scalar calibration factor to address unknown incident wave fields in quantitative inversion algorithms, using a neural network to solve the forward problem and optimize the factor.", "motivation": "Quantitative inversion algorithms struggle with unknown incident wave fields due to factors like antenna characteristics and path loss, necessitating a calibration solution.", "method": "A scalar calibration factor is introduced, and a feed-forward neural network is trained to map permittivity distribution to scattered fields. The mismatch between measured and simulated fields is minimized to optimize the factor.", "result": "The algorithm is tested on the Fresnel Institute dataset, demonstrating its effectiveness in handling unknown incident wave fields.", "conclusion": "The proposed method successfully addresses the challenge of unknown incident wave fields in quantitative inversion, enhancing reconstruction accuracy."}}
{"id": "2505.09123", "pdf": "https://arxiv.org/pdf/2505.09123", "abs": "https://arxiv.org/abs/2505.09123", "authors": ["Guoying Liang", "Su Yang"], "title": "Promoting SAM for Camouflaged Object Detection via Selective Key Point-based Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Big model has emerged as a new research paradigm that can be applied to\nvarious down-stream tasks with only minor effort for domain adaption.\nCorrespondingly, this study tackles Camouflaged Object Detection (COD)\nleveraging the Segment Anything Model (SAM). The previous studies declared that\nSAM is not workable for COD but this study reveals that SAM works if promoted\nproperly, for which we devise a new framework to render point promotions:\nFirst, we develop the Promotion Point Targeting Network (PPT-net) to leverage\nmulti-scale features in predicting the probabilities of camouflaged objects'\npresences at given candidate points over the image. Then, we develop a key\npoint selection (KPS) algorithm to deploy both positive and negative point\npromotions contrastively to SAM to guide the segmentation. It is the first work\nto facilitate big model for COD and achieves plausible results experimentally\nover the existing methods on 3 data sets under 6 metrics. This study\ndemonstrates an off-the-shelf methodology for COD by leveraging SAM, which\ngains advantage over designing professional models from scratch, not only in\nperformance, but also in turning the problem to a less challenging task, that\nis, seeking informative but not exactly precise promotions.", "AI": {"tldr": "The study introduces a framework to adapt the Segment Anything Model (SAM) for Camouflaged Object Detection (COD), achieving competitive results by using point promotions and a novel key point selection algorithm.", "motivation": "To leverage big models like SAM for COD, overcoming previous claims that SAM is unsuitable for this task.", "method": "Developed the Promotion Point Targeting Network (PPT-net) for multi-scale feature prediction and a Key Point Selection (KPS) algorithm for contrastive point promotions.", "result": "Achieved plausible results on 3 datasets under 6 metrics, outperforming existing methods.", "conclusion": "Demonstrates an effective off-the-shelf approach for COD using SAM, offering advantages in performance and reducing task complexity."}}
{"id": "2502.10725", "pdf": "https://arxiv.org/pdf/2502.10725", "abs": "https://arxiv.org/abs/2502.10725", "authors": ["Fei Yang"], "title": "PropNet: a White-Box and Human-Like Network for Sentence Representation", "categories": ["cs.CL", "cs.AI"], "comment": "Clarified some ambiguities in the previous version", "summary": "Transformer-based embedding methods have dominated the field of sentence\nrepresentation in recent years. Although they have achieved remarkable\nperformance on NLP missions, such as semantic textual similarity (STS) tasks,\ntheir black-box nature and large-data-driven training style have raised\nconcerns, including issues related to bias, trust, and safety. Many efforts\nhave been made to improve the interpretability of embedding models, but these\nproblems have not been fundamentally resolved. To achieve inherent\ninterpretability, we propose a purely white-box and human-like sentence\nrepresentation network, PropNet. Inspired by findings from cognitive science,\nPropNet constructs a hierarchical network based on the propositions contained\nin a sentence. While experiments indicate that PropNet has a significant gap\ncompared to state-of-the-art (SOTA) embedding models in STS tasks, case studies\nreveal substantial room for improvement. Additionally, PropNet enables us to\nanalyze and understand the human cognitive processes underlying STS benchmarks.", "AI": {"tldr": "PropNet is a white-box, human-like sentence representation network inspired by cognitive science, addressing interpretability gaps in Transformer-based models, though it lags in performance on STS tasks.", "motivation": "To address the black-box nature and interpretability issues of Transformer-based sentence embedding models, which raise concerns about bias, trust, and safety.", "method": "Proposes PropNet, a hierarchical network based on propositions in sentences, inspired by cognitive science.", "result": "PropNet shows a performance gap compared to SOTA models in STS tasks but offers interpretability and insights into human cognitive processes.", "conclusion": "PropNet provides a foundation for inherently interpretable sentence representation, with potential for future improvements."}}
{"id": "2505.08878", "pdf": "https://arxiv.org/pdf/2505.08878", "abs": "https://arxiv.org/abs/2505.08878", "authors": ["Dor Tsur", "Carol Xuan Long", "Claudio Mayrink Verdun", "Hsiang Hsu", "Haim Permuter", "Flavio P. Calmon"], "title": "Optimized Couplings for Watermarking Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted at ISIT25", "summary": "Large-language models (LLMs) are now able to produce text that is, in many\ncases, seemingly indistinguishable from human-generated content. This has\nfueled the development of watermarks that imprint a ``signal'' in LLM-generated\ntext with minimal perturbation of an LLM's output. This paper provides an\nanalysis of text watermarking in a one-shot setting. Through the lens of\nhypothesis testing with side information, we formulate and analyze the\nfundamental trade-off between watermark detection power and distortion in\ngenerated textual quality. We argue that a key component in watermark design is\ngenerating a coupling between the side information shared with the watermark\ndetector and a random partition of the LLM vocabulary. Our analysis identifies\nthe optimal coupling and randomization strategy under the worst-case LLM\nnext-token distribution that satisfies a min-entropy constraint. We provide a\nclosed-form expression of the resulting detection rate under the proposed\nscheme and quantify the cost in a max-min sense. Finally, we provide an array\nof numerical results, comparing the proposed scheme with the theoretical\noptimum and existing schemes, in both synthetic data and LLM watermarking. Our\ncode is available at https://github.com/Carol-Long/CC_Watermark", "AI": {"tldr": "The paper analyzes text watermarking for LLMs, focusing on the trade-off between detection power and output quality, proposing an optimal coupling strategy and comparing it with existing methods.", "motivation": "To address the challenge of distinguishing LLM-generated text from human content by developing effective watermarking techniques with minimal distortion.", "method": "Formulates watermarking as hypothesis testing with side information, identifies optimal coupling and randomization strategies under constraints, and provides theoretical and numerical analysis.", "result": "Derives a closed-form expression for detection rate, quantifies costs, and compares the proposed scheme with theoretical and existing methods.", "conclusion": "The proposed watermarking scheme achieves optimal performance under constraints, validated by theoretical and empirical results."}}
{"id": "2505.09160", "pdf": "https://arxiv.org/pdf/2505.09160", "abs": "https://arxiv.org/abs/2505.09160", "authors": ["Berkay Guler", "Giovanni Geraci", "Hamid Jafarkhani"], "title": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Current applications of self-supervised learning to wireless channel\nrepresentation often borrow paradigms developed for text and image processing,\nwithout fully addressing the unique characteristics and constraints of wireless\ncommunications. Aiming to fill this gap, we first propose WiMAE (Wireless\nMasked Autoencoder), a transformer-based encoder-decoder foundation model\npretrained on a realistic open-source multi-antenna wireless channel dataset.\nBuilding upon this foundation, we develop ContraWiMAE, which enhances WiMAE by\nincorporating a contrastive learning objective alongside the reconstruction\ntask in a unified multi-task framework. By warm-starting from pretrained WiMAE\nweights and generating positive pairs via noise injection, the contrastive\ncomponent enables the model to capture both structural and discriminative\nfeatures, enhancing representation quality beyond what reconstruction alone can\nachieve. Through extensive evaluation on unseen scenarios, we demonstrate the\neffectiveness of both approaches across multiple downstream tasks, with\nContraWiMAE showing further improvements in linear separability and\nadaptability in diverse wireless environments. Comparative evaluations against\na state-of-the-art wireless channel foundation model confirm the superior\nperformance and data efficiency of our models, highlighting their potential as\npowerful baselines for future research in self-supervised wireless channel\nrepresentation learning.", "AI": {"tldr": "The paper introduces WiMAE and ContraWiMAE, transformer-based models for self-supervised wireless channel representation, outperforming existing methods in adaptability and performance.", "motivation": "Existing self-supervised learning methods for wireless channels borrow from text/image paradigms, neglecting unique wireless constraints. This work addresses the gap.", "method": "WiMAE is a transformer-based encoder-decoder pretrained on multi-antenna data. ContraWiMAE adds contrastive learning to WiMAE via noise injection and multi-task training.", "result": "Both models excel in unseen scenarios, with ContraWiMAE improving linear separability and adaptability. They outperform state-of-the-art models in performance and data efficiency.", "conclusion": "WiMAE and ContraWiMAE set strong baselines for future self-supervised wireless channel representation research."}}
{"id": "2505.07890", "pdf": "https://arxiv.org/pdf/2505.07890", "abs": "https://arxiv.org/abs/2505.07890", "authors": ["Kutay Ert\u00fcrk", "Furkan Alt\u0131n\u0131\u015f\u0131k", "\u0130rem Sar\u0131alt\u0131n", "\u00d6mer Nezih Gerek"], "title": "TSLFormer: A Lightweight Transformer Model for Turkish Sign Language Recognition Using Skeletal Landmarks", "categories": ["cs.CL", "eess.IV"], "comment": null, "summary": "This study presents TSLFormer, a light and robust word-level Turkish Sign\nLanguage (TSL) recognition model that treats sign gestures as ordered,\nstring-like language. Instead of using raw RGB or depth videos, our method only\nworks with 3D joint positions - articulation points - extracted using Google's\nMediapipe library, which focuses on the hand and torso skeletal locations. This\ncreates efficient input dimensionality reduction while preserving important\nsemantic gesture information.\n  Our approach revisits sign language recognition as sequence-to-sequence\ntranslation, inspired by the linguistic nature of sign languages and the\nsuccess of transformers in natural language processing. Since TSLFormer uses\nthe self-attention mechanism, it effectively captures temporal co-occurrence\nwithin gesture sequences and highlights meaningful motion patterns as words\nunfold.\n  Evaluated on the AUTSL dataset with over 36,000 samples and 227 different\nwords, TSLFormer achieves competitive performance with minimal computational\ncost. These results show that joint-based input is sufficient for enabling\nreal-time, mobile, and assistive communication systems for hearing-impaired\nindividuals.", "AI": {"tldr": "TSLFormer is a lightweight Turkish Sign Language recognition model using 3D joint positions for efficient, real-time sign translation.", "motivation": "To address the need for efficient and robust sign language recognition by treating gestures as ordered sequences, leveraging linguistic similarities.", "method": "Uses 3D joint positions from Mediapipe, models sign language as sequence-to-sequence translation with transformers.", "result": "Achieves competitive performance on AUTSL dataset (36k samples, 227 words) with minimal computational cost.", "conclusion": "Joint-based input enables real-time, mobile assistive systems for hearing-impaired users."}}
{"id": "2505.09129", "pdf": "https://arxiv.org/pdf/2505.09129", "abs": "https://arxiv.org/abs/2505.09129", "authors": ["Wei Meng"], "title": "WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes", "categories": ["cs.CV", "cs.AI", "es: 68T10, 68T05, 62H35, 68U10", "I.4.9; I.5.1; I.2.10"], "comment": "17 pages, 3 figures, 3 tables. The paper proposes a lightweight\n  weakly-supervised color intelligence model for tactical video anomaly\n  detection, tested on anonymized African surveillance data", "summary": "The deployment of traditional deep learning models in high-risk security\ntasks in an unlabeled, data-non-exploitable video intelligence environment\nfaces significant challenges. In this paper, we propose a lightweight anomaly\ndetection framework based on color features for surveillance video clips in a\nhigh sensitivity tactical mission, aiming to quickly identify and interpret\npotential threat events under resource-constrained and data-sensitive\nconditions. The method fuses unsupervised KMeans clustering with RGB channel\nhistogram modeling to achieve composite detection of structural anomalies and\ncolor mutation signals in key frames. The experiment takes an operation\nsurveillance video occurring in an African country as a research sample, and\nsuccessfully identifies multiple highly anomalous frames related to high-energy\nlight sources, target presence, and reflective interference under the condition\nof no access to the original data. The results show that this method can be\neffectively used for tactical assassination warning, suspicious object\nscreening and environmental drastic change monitoring with strong deployability\nand tactical interpretation value. The study emphasizes the importance of color\nfeatures as low semantic battlefield signal carriers, and its battlefield\nintelligent perception capability will be further extended by combining graph\nneural networks and temporal modeling in the future.", "AI": {"tldr": "A lightweight anomaly detection framework using color features for surveillance videos in high-risk tactical missions, achieving effective threat identification under resource constraints.", "motivation": "Challenges in deploying traditional deep learning models in unlabeled, data-sensitive video intelligence environments for high-risk security tasks.", "method": "Fuses unsupervised KMeans clustering with RGB channel histogram modeling to detect structural anomalies and color mutations in key frames.", "result": "Successfully identifies anomalous frames (e.g., high-energy light sources, target presence) in an African surveillance video without original data access.", "conclusion": "The method is deployable and valuable for tactical applications; future work includes integrating graph neural networks and temporal modeling."}}
{"id": "2503.10652", "pdf": "https://arxiv.org/pdf/2503.10652", "abs": "https://arxiv.org/abs/2503.10652", "authors": ["Han Wang", "Jacek Pawlak", "Aruna Sivakumar"], "title": "Simulating and Analysing Human Survey Responses with Large Language Models: A Case Study in Energy Stated Preference", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Survey research plays a crucial role in studies by capturing consumer\npreferences and informing policy decisions. Stated preference (SP) surveys help\nresearchers understand how individuals make trade-offs in hypothetical,\npotentially futuristic, scenarios. However, traditional methods are costly,\ntime-consuming, and affected by respondent fatigue and ethical constraints.\nLarge language models (LLMs) have shown remarkable capabilities in generating\nhuman-like responses, prompting interest in their use in survey research. This\nstudy investigates LLMs for simulating consumer choices in energy-related SP\nsurveys and explores their integration into data collection and analysis\nworkflows. Test scenarios were designed to assess the simulation performance of\nseveral LLMs (LLaMA 3.1, Mistral, GPT-3.5, DeepSeek-R1) at individual and\naggregated levels, considering prompt design, in-context learning (ICL),\nchain-of-thought (CoT) reasoning, model types, integration with traditional\nchoice models, and potential biases. While LLMs achieve accuracy above random\nguessing, performance remains insufficient for practical simulation use.\nCloud-based LLMs do not consistently outperform smaller local models.\nDeepSeek-R1 achieves the highest average accuracy (77%) and outperforms\nnon-reasoning LLMs in accuracy, factor identification, and choice distribution\nalignment. Previous SP choices are the most effective input; longer prompts\nwith more factors reduce accuracy. Mixed logit models can support LLM prompt\nrefinement. Reasoning LLMs show potential in data analysis by indicating factor\nsignificance, offering a qualitative complement to statistical models. Despite\nlimitations, pre-trained LLMs offer scalability and require minimal historical\ndata. Future work should refine prompts, further explore CoT reasoning, and\ninvestigate fine-tuning techniques.", "AI": {"tldr": "The study explores using LLMs to simulate consumer choices in energy-related SP surveys, finding limited practical accuracy but potential for scalability and qualitative insights.", "motivation": "Traditional SP survey methods are costly and time-consuming, prompting interest in LLMs for simulating consumer choices efficiently.", "method": "Test scenarios assessed LLMs (LLaMA 3.1, Mistral, GPT-3.5, DeepSeek-R1) for simulation performance, focusing on prompt design, reasoning methods, and integration with choice models.", "result": "LLMs achieve above-random accuracy (DeepSeek-R1 highest at 77%) but remain insufficient for practical use. Reasoning LLMs show qualitative potential in data analysis.", "conclusion": "Pre-trained LLMs offer scalability but need refinement. Future work should focus on prompt design, reasoning, and fine-tuning."}}
{"id": "2505.08894", "pdf": "https://arxiv.org/pdf/2505.08894", "abs": "https://arxiv.org/abs/2505.08894", "authors": ["Hiba Eltigani", "Rukhshan Haroon", "Asli Kocak", "Abdullah Bin Faisal", "Noah Martin", "Fahad Dogar"], "title": "WaLLM -- Insights from an LLM-Powered Chatbot deployment via WhatsApp", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Recent advances in generative AI, such as ChatGPT, have transformed access to\ninformation in education, knowledge-seeking, and everyday decision-making.\nHowever, in many developing regions, access remains a challenge due to the\npersistent digital divide. To help bridge this gap, we developed WaLLM - a\ncustom AI chatbot over WhatsApp, a widely used communication platform in\ndeveloping regions. Beyond answering queries, WaLLM offers several features to\nenhance user engagement: a daily top question, suggested follow-up questions,\ntrending and recent queries, and a leaderboard-based reward system. Our service\nhas been operational for over 6 months, amassing over 14.7K queries from\napproximately 100 users. In this paper, we present WaLLM's design and a\nsystematic analysis of logs to understand user interactions. Our results show\nthat 55% of user queries seek factual information. \"Health and well-being\" was\nthe most popular topic (28%), including queries about nutrition and disease,\nsuggesting users view WaLLM as a reliable source. Two-thirds of users' activity\noccurred within 24 hours of the daily top question. Users who accessed the\n\"Leaderboard\" interacted with WaLLM 3x as those who did not. We conclude by\ndiscussing implications for culture-based customization, user interface design,\nand appropriate calibration of users' trust in AI systems for developing\nregions.", "AI": {"tldr": "WaLLM, a WhatsApp-based AI chatbot, addresses the digital divide in developing regions by providing accessible information and engagement features like daily questions and leaderboards.", "motivation": "To bridge the digital divide in developing regions by leveraging WhatsApp for AI-driven information access.", "method": "Developed WaLLM, a custom AI chatbot on WhatsApp, with features like daily questions, follow-ups, trending queries, and a reward system. Analyzed 6 months of user interaction logs.", "result": "55% of queries sought factual info; health was the top topic (28%). Leaderboard users interacted 3x more. Most activity occurred within 24h of daily questions.", "conclusion": "Highlights the need for culture-based customization, UI design, and trust calibration in AI systems for developing regions."}}
{"id": "2505.09174", "pdf": "https://arxiv.org/pdf/2505.09174", "abs": "https://arxiv.org/abs/2505.09174", "authors": ["Xinyu You", "Xiang Liu", "Chuan-Shen Hu", "Kelin Xia", "Tze Chien Sum"], "title": "Quotient Complex Transformer (QCformer) for Perovskite Data Analysis", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": null, "summary": "The discovery of novel functional materials is crucial in addressing the\nchallenges of sustainable energy generation and climate change. Hybrid\norganic-inorganic perovskites (HOIPs) have gained attention for their\nexceptional optoelectronic properties in photovoltaics. Recently, geometric\ndeep learning, particularly graph neural networks (GNNs), has shown strong\npotential in predicting material properties and guiding material design.\nHowever, traditional GNNs often struggle to capture the periodic structures and\nhigher-order interactions prevalent in such systems. To address these\nlimitations, we propose a novel representation based on quotient complexes\n(QCs) and introduce the Quotient Complex Transformer (QCformer) for material\nproperty prediction. A material structure is modeled as a quotient complex,\nwhich encodes both pairwise and many-body interactions via simplices of varying\ndimensions and captures material periodicity through a quotient operation. Our\nmodel leverages higher-order features defined on simplices and processes them\nusing a simplex-based Transformer module. We pretrain QCformer on benchmark\ndatasets such as the Materials Project and JARVIS, and fine-tune it on HOIP\ndatasets. The results show that QCformer outperforms state-of-the-art models in\nHOIP property prediction, demonstrating its effectiveness. The quotient complex\nrepresentation and QCformer model together contribute a powerful new tool for\npredictive modeling of perovskite materials.", "AI": {"tldr": "A novel method, QCformer, using quotient complexes and graph neural networks, improves prediction of hybrid perovskite properties.", "motivation": "Addressing the limitations of traditional GNNs in capturing periodic structures and higher-order interactions in materials like HOIPs.", "method": "Proposes a quotient complex representation and QCformer, a simplex-based Transformer, for material property prediction.", "result": "QCformer outperforms state-of-the-art models in predicting HOIP properties.", "conclusion": "QCformer and quotient complex representation offer a powerful tool for predictive modeling of perovskite materials."}}
{"id": "2505.09139", "pdf": "https://arxiv.org/pdf/2505.09139", "abs": "https://arxiv.org/abs/2505.09139", "authors": ["Lucas Choi", "Ross Greer"], "title": "Beyond General Prompts: Automated Prompt Refinement using Contrastive Class Alignment Scores for Disambiguating Objects in Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) offer flexible object detection through natural\nlanguage prompts but suffer from performance variability depending on prompt\nphrasing. In this paper, we introduce a method for automated prompt refinement\nusing a novel metric called the Contrastive Class Alignment Score (CCAS), which\nranks prompts based on their semantic alignment with a target object class\nwhile penalizing similarity to confounding classes. Our method generates\ndiverse prompt candidates via a large language model and filters them through\nCCAS, computed using prompt embeddings from a sentence transformer. We evaluate\nour approach on challenging object categories, demonstrating that our automatic\nselection of high-precision prompts improves object detection accuracy without\nthe need for additional model training or labeled data. This scalable and\nmodel-agnostic pipeline offers a principled alternative to manual prompt\nengineering for VLM-based detection systems.", "AI": {"tldr": "Automated prompt refinement for VLMs using CCAS improves object detection accuracy without extra training or labeled data.", "motivation": "Address performance variability in VLMs due to prompt phrasing by automating prompt refinement.", "method": "Generate diverse prompts via a large language model, filter them using CCAS (Contrastive Class Alignment Score) based on semantic alignment.", "result": "Improves object detection accuracy for challenging categories by selecting high-precision prompts.", "conclusion": "Offers a scalable, model-agnostic alternative to manual prompt engineering for VLMs."}}
{"id": "2503.17599", "pdf": "https://arxiv.org/pdf/2503.17599", "abs": "https://arxiv.org/abs/2503.17599", "authors": ["Zheqing Li", "Yiying Yang", "Jiping Lang", "Wenhao Jiang", "Yuhang Zhao", "Shuang Li", "Dingqian Wang", "Zhu Lin", "Xuanna Li", "Yuze Tang", "Jiexian Qiu", "Xiaolin Lu", "Hongji Yu", "Shuang Chen", "Yuhua Bi", "Xiaofei Zeng", "Yixian Chen", "Junrong Chen", "Lin Yao"], "title": "Evaluating Clinical Competencies of Large Language Models with a General Practice Benchmark", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated considerable potential in\ngeneral practice. However, existing benchmarks and evaluation frameworks\nprimarily depend on exam-style or simplified question-answer formats, lacking a\ncompetency-based structure aligned with the real-world clinical\nresponsibilities encountered in general practice. Consequently, the extent to\nwhich LLMs can reliably fulfill the duties of general practitioners (GPs)\nremains uncertain. In this work, we propose a novel evaluation framework to\nassess the capability of LLMs to function as GPs. Based on this framework, we\nintroduce a general practice benchmark (GPBench), whose data are meticulously\nannotated by domain experts in accordance with routine clinical practice\nstandards. We evaluate ten state-of-the-art LLMs and analyze their\ncompetencies. Our findings indicate that current LLMs are not yet ready for\ndeployment in such settings without human oversight, and further optimization\nspecifically tailored to the daily responsibilities of GPs is essential.", "AI": {"tldr": "The paper proposes GPBench, a novel evaluation framework to assess LLMs' capability as general practitioners, finding current models inadequate without human oversight.", "motivation": "Existing benchmarks lack real-world clinical alignment, leaving LLMs' GP competency uncertain.", "method": "Introduces GPBench, a benchmark with expert-annotated data, and evaluates ten LLMs.", "result": "Current LLMs are not ready for GP deployment without human oversight.", "conclusion": "Further optimization tailored to GP responsibilities is needed."}}
{"id": "2505.08904", "pdf": "https://arxiv.org/pdf/2505.08904", "abs": "https://arxiv.org/abs/2505.08904", "authors": ["Varun Nagaraj Rao", "Samantha Dalal", "Andrew Schwartz", "Amna Liaqat", "Dana Calacci", "Andr\u00e9s Monroy-Hern\u00e1ndez"], "title": "FareShare: A Tool for Labor Organizers to Estimate Lost Wages and Contest Arbitrary AI and Algorithmic Deactivations", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC"], "comment": null, "summary": "What happens when a rideshare driver is suddenly locked out of the platform\nconnecting them to riders, wages, and daily work? Deactivation-the abrupt\nremoval of gig workers' platform access-typically occurs through arbitrary AI\nand algorithmic decisions with little explanation or recourse. This represents\none of the most severe forms of algorithmic control and often devastates\nworkers' financial stability. Recent U.S. state policies now mandate appeals\nprocesses and recovering compensation during the period of wrongful\ndeactivation based on past earnings. Yet, labor organizers still lack effective\ntools to support these complex, error-prone workflows. We designed FareShare, a\ncomputational tool automating lost wage estimation for deactivated drivers,\nthrough a 6 month partnership with the State of Washington's largest rideshare\nlabor union. Over the following 3 months, our field deployment of FareShare\nregistered 178 account signups. We observed that the tool could reduce lost\nwage calculation time by over 95%, eliminate manual data entry errors, and\nenable legal teams to generate arbitration-ready reports more efficiently.\nBeyond these gains, the deployment also surfaced important socio-technical\nchallenges around trust, consent, and tool adoption in high-stakes labor\ncontexts.", "AI": {"tldr": "FareShare automates lost wage estimation for deactivated rideshare drivers, reducing calculation time by 95% and improving legal workflows, but faces socio-technical challenges.", "motivation": "Deactivation of gig workers via AI lacks transparency and harms financial stability, with recent policies mandating appeals but lacking effective tools.", "method": "Developed FareShare in partnership with a rideshare union, automating wage estimation and deploying it for 178 drivers.", "result": "Reduced wage calculation time by 95%, eliminated manual errors, and improved legal report generation.", "conclusion": "FareShare is effective but highlights trust and adoption challenges in labor contexts."}}
{"id": "2505.09175", "pdf": "https://arxiv.org/pdf/2505.09175", "abs": "https://arxiv.org/abs/2505.09175", "authors": ["Mohammad Ganjirad", "Mahmoud Reza Delavar", "Hossein Bagheri", "Mohammad Mehdi Azizi"], "title": "Optimizing Urban Critical Green Space Development Using Machine Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This paper presents a novel framework for prioritizing urban green space\ndevelopment in Tehran using diverse socio-economic, environmental, and\nsensitivity indices. The indices were derived from various sources including\nGoogle Earth Engine, air pollution measurements, municipal reports and the\nWeather Research & Forecasting (WRF) model. The WRF model was used to estimate\nthe air temperature at a 1 km resolution due to insufficient meteorological\nstations, yielding RMSE and MAE values of 0.96{\\deg}C and 0.92{\\deg}C,\nrespectively. After data preparation, several machine learning models were used\nfor binary vegetation cover classification including XGBoost, LightGBM, Random\nForest (RF) and Extra Trees. RF achieved the highest performance, exceeding 94%\nin Overall Accuracy, Recall, and F1-score. Then, the probability of areas\nlacking vegetation cover was assessed using socio-economic, environmental and\nsensitivity indices. This resulted in the RF generating an urban green space\ndevelopment prioritization map. Feature Importance Analysis revealed that the\nmost significant indices were nightly land surface temperature (LST) and\nsensitive population. Finally, the framework performance was validated through\nmicroclimate simulation to assess the critical areas after and before the green\nspace development by green roofs. The simulation demonstrated reducing air\ntemperature by up to 0.67{\\deg}C after utilizing the green roof technology in\ncritical areas. As a result, this framework provides a valuable tool for urban\nplanners to develop green spaces.", "AI": {"tldr": "A framework for prioritizing urban green space development in Tehran using socio-economic, environmental, and sensitivity indices, validated by microclimate simulation.", "motivation": "To address insufficient green spaces in Tehran by leveraging diverse data sources and machine learning for effective prioritization.", "method": "Used Google Earth Engine, WRF model, and machine learning (XGBoost, LightGBM, RF, Extra Trees) for vegetation classification and prioritization. RF performed best (94% accuracy).", "result": "RF-generated prioritization map identified critical areas. Green roofs reduced air temperature by 0.67\u00b0C in these areas.", "conclusion": "The framework aids urban planners in developing green spaces effectively, validated by temperature reduction."}}
{"id": "2505.09140", "pdf": "https://arxiv.org/pdf/2505.09140", "abs": "https://arxiv.org/abs/2505.09140", "authors": ["Zechao Guan", "Feng Yan", "Shuai Du", "Lin Ma", "Qingshan Liu"], "title": "TopoDiT-3D: Topology-Aware Diffusion Transformer with Bottleneck Structure for 3D Point Cloud Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in Diffusion Transformer (DiT) models have significantly\nimproved 3D point cloud generation. However, existing methods primarily focus\non local feature extraction while overlooking global topological information,\nsuch as voids, which are crucial for maintaining shape consistency and\ncapturing complex geometries. To address this limitation, we propose\nTopoDiT-3D, a Topology-Aware Diffusion Transformer with a bottleneck structure\nfor 3D point cloud generation. Specifically, we design the bottleneck structure\nutilizing Perceiver Resampler, which not only offers a mode to integrate\ntopological information extracted through persistent homology into feature\nlearning, but also adaptively filters out redundant local features to improve\ntraining efficiency. Experimental results demonstrate that TopoDiT-3D\noutperforms state-of-the-art models in visual quality, diversity, and training\nefficiency. Furthermore, TopoDiT-3D demonstrates the importance of rich\ntopological information for 3D point cloud generation and its synergy with\nconventional local feature learning. Videos and code are available at\nhttps://github.com/Zechao-Guan/TopoDiT-3D.", "AI": {"tldr": "TopoDiT-3D, a topology-aware diffusion transformer, improves 3D point cloud generation by integrating global topological information and filtering redundant local features.", "motivation": "Existing methods overlook global topological information like voids, which are crucial for shape consistency and complex geometries.", "method": "Proposes TopoDiT-3D with a bottleneck structure using Perceiver Resampler to integrate topological information and filter redundant local features.", "result": "Outperforms state-of-the-art models in visual quality, diversity, and training efficiency.", "conclusion": "Highlights the importance of topological information and its synergy with local feature learning in 3D point cloud generation."}}
{"id": "2503.21696", "pdf": "https://arxiv.org/pdf/2503.21696", "abs": "https://arxiv.org/abs/2503.21696", "authors": ["Wenqi Zhang", "Mengna Wang", "Gangao Liu", "Xu Huixin", "Yiwei Jiang", "Yongliang Shen", "Guiyang Hou", "Zhe Zheng", "Hang Zhang", "Xin Li", "Weiming Lu", "Peng Li", "Yueting Zhuang"], "title": "Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks", "categories": ["cs.CL", "cs.CV"], "comment": "Code: https://github.com/zwq2018/embodied_reasoner Dataset:\n  https://huggingface.co/datasets/zwq2018/embodied_reasoner", "summary": "Recent advances in deep thinking models have demonstrated remarkable\nreasoning capabilities on mathematical and coding tasks. However, their\neffectiveness in embodied domains which require continuous interaction with\nenvironments through image action interleaved trajectories remains largely\n-unexplored. We present Embodied Reasoner, a model that extends o1 style\nreasoning to interactive embodied search tasks. Unlike mathematical reasoning\nthat relies primarily on logical deduction, embodied scenarios demand spatial\nunderstanding, temporal reasoning, and ongoing self-reflection based on\ninteraction history. To address these challenges, we synthesize 9.3k coherent\nObservation-Thought-Action trajectories containing 64k interactive images and\n90k diverse thinking processes (analysis, spatial reasoning, reflection,\nplanning, and verification). We develop a three-stage training pipeline that\nprogressively enhances the model's capabilities through imitation learning,\nself-exploration via rejection sampling, and self-correction through reflection\ntuning. The evaluation shows that our model significantly outperforms those\nadvanced visual reasoning models, e.g., it exceeds OpenAI o1, o3-mini, and\nClaude-3.7 by +9\\%, 24\\%, and +13\\%. Analysis reveals our model exhibits fewer\nrepeated searches and logical inconsistencies, with particular advantages in\ncomplex long-horizon tasks. Real-world environments also show our superiority\nwhile exhibiting fewer repeated searches and logical inconsistency cases.", "AI": {"tldr": "The paper introduces Embodied Reasoner, a model for interactive embodied tasks, outperforming advanced visual reasoning models like OpenAI o1 and Claude-3.7.", "motivation": "Existing deep thinking models excel in mathematical and coding tasks but lack exploration in embodied domains requiring continuous interaction.", "method": "The model uses a three-stage training pipeline: imitation learning, self-exploration, and self-correction, trained on 9.3k Observation-Thought-Action trajectories.", "result": "The model outperforms OpenAI o1, o3-mini, and Claude-3.7 by +9%, 24%, and +13%, with fewer repeated searches and logical inconsistencies.", "conclusion": "Embodied Reasoner excels in complex long-horizon tasks and real-world environments, demonstrating superior reasoning and interaction capabilities."}}
{"id": "2505.08916", "pdf": "https://arxiv.org/pdf/2505.08916", "abs": "https://arxiv.org/abs/2505.08916", "authors": ["Chan Le Duc", "Ludovic Brieulle"], "title": "A New Tractable Description Logic under Categorical Semantics", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "Biomedical ontologies contain numerous concept or role names involving\nnegative knowledge such as lacks_part, absence_of. Such a representation with\nlabels rather than logical constructors would not allow a reasoner to interpret\nlacks_part as a kind of negation of has_part. It is known that adding negation\nto the tractable Description Logic (DL) EL allowing for conjunction,\nexistential restriction and concept inclusion makes it intractable since the\nobtained logic includes implicitly disjunction and universal restriction which\ninteract with other constructors. In this paper, we propose a new extension of\nEL with a weakened negation allowing to represent negative knowledge while\nretaining tractability. To this end, we introduce categorical semantics of all\nlogical constructors of the DL SH including EL with disjunction, negation,\nuniversal restriction, role inclusion and transitive roles. The categorical\nsemantics of a logical constructor is usually described as a set of categorical\nproperties referring to several objects without using set membership. To\nrestore tractability, we have to weaken semantics of disjunction and universal\nrestriction by identifying \\emph{independent} categorical properties that are\nresponsible for intractability, and dropping them from the set of categorical\nproperties. We show that the logic resulting from weakening semantics is more\nexpressive than EL with the bottom concept, transitive roles and role\ninclusion.", "AI": {"tldr": "The paper proposes a tractable extension of the Description Logic EL with weakened negation to represent negative knowledge without losing computational efficiency.", "motivation": "Biomedical ontologies often use labels for negative knowledge (e.g., lacks_part) instead of logical constructors, which prevents reasoning. Adding full negation to EL makes it intractable, so a weaker form is needed.", "method": "Introduces categorical semantics for DL SH constructors, identifies properties causing intractability, and weakens them to retain tractability.", "result": "The resulting logic is more expressive than EL with bottom concept, transitive roles, and role inclusion, while remaining tractable.", "conclusion": "The proposed weakened negation in EL successfully balances expressivity and tractability for representing negative knowledge."}}
{"id": "2505.09214", "pdf": "https://arxiv.org/pdf/2505.09214", "abs": "https://arxiv.org/abs/2505.09214", "authors": ["Zhonghao Lyu", "Ming Xiao", "Jie Xu", "Mikael Skoglund", "Marco Di Renzo"], "title": "The Larger the Merrier? Efficient Large AI Model Inference in Wireless Edge Networks", "categories": ["cs.LG"], "comment": null, "summary": "The growing demand for large artificial intelligence model (LAIM) services is\ndriving a paradigm shift from traditional cloud-based inference to edge-based\ninference for low-latency, privacy-preserving applications. In particular,\nedge-device co-inference, which partitions LAIMs between edge devices and\nservers, has emerged as a promising strategy for resource-efficient LAIM\nexecution in wireless networks. In this paper, we investigate a pruning-aware\nLAIM co-inference scheme, where a pre-trained LAIM is pruned and partitioned\ninto on-device and on-server sub-models for deployment. For analysis, we first\nprove that the LAIM output distortion is upper bounded by its parameter\ndistortion. Then, we derive a lower bound on parameter distortion via\nrate-distortion theory, analytically capturing the relationship between pruning\nratio and co-inference performance. Next, based on the analytical results, we\nformulate an LAIM co-inference distortion bound minimization problem by jointly\noptimizing the pruning ratio, transmit power, and computation frequency under\nsystem latency, energy, and available resource constraints. Moreover, we\npropose an efficient algorithm to tackle the considered highly non-convex\nproblem. Finally, extensive simulations demonstrate the effectiveness of the\nproposed design. In particular, model parameter distortion is shown to provide\na reliable bound on output distortion. Also, the proposed joint pruning ratio\nand resource management design achieves superior performance in balancing\ntrade-offs among inference performance, system latency, and energy consumption\ncompared with benchmark schemes, such as fully on-device and on-server\ninference. Moreover, the split point is shown to play a critical role in system\nperformance optimization under heterogeneous and resource-limited edge\nenvironments.", "AI": {"tldr": "The paper proposes a pruning-aware co-inference scheme for large AI models (LAIMs) between edge devices and servers, optimizing pruning ratio, power, and computation to minimize distortion while meeting latency and energy constraints.", "motivation": "The shift to edge-based inference for low-latency, privacy-preserving AI services drives the need for resource-efficient LAIM execution in wireless networks.", "method": "The scheme prunes and partitions LAIMs into on-device and on-server sub-models, analyzes distortion bounds, and formulates a joint optimization problem for pruning ratio, power, and computation. An efficient algorithm solves the non-convex problem.", "result": "Simulations show the proposed design effectively bounds output distortion, balances performance-latency-energy trade-offs, and outperforms benchmark schemes like fully on-device or on-server inference.", "conclusion": "The split point and joint optimization of pruning and resources are critical for optimizing LAIM co-inference in resource-limited edge environments."}}
{"id": "2505.09155", "pdf": "https://arxiv.org/pdf/2505.09155", "abs": "https://arxiv.org/abs/2505.09155", "authors": ["Yichen Shi", "Zhuofu Tao", "Yuhao Gao", "Li Huang", "Hongyang Wang", "Zhiping Yu", "Ting-Jung Lin", "Lei He"], "title": "AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection", "categories": ["cs.CV"], "comment": "accepted by LAD25", "summary": "Current multimodal large language models (MLLMs) struggle to understand\ncircuit schematics due to their limited recognition capabilities. This could be\nattributed to the lack of high-quality schematic-netlist training data.\nExisting work such as AMSnet applies schematic parsing to generate netlists.\nHowever, these methods rely on hard-coded heuristics and are difficult to apply\nto complex or noisy schematics in this paper. We therefore propose a novel net\ndetection mechanism based on segmentation with high robustness. The proposed\nmethod also recovers positional information, allowing digital reconstruction of\nschematics. We then expand AMSnet dataset with schematic images from various\nsources and create AMSnet 2.0. AMSnet 2.0 contains 2,686 circuits with\nschematic images, Spectre-formatted netlists, OpenAccess digital schematics,\nand positional information for circuit components and nets, whereas AMSnet only\nincludes 792 circuits with SPICE netlists but no digital schematics.", "AI": {"tldr": "A novel net detection method for MLLMs improves schematic understanding by segmenting and recovering positional data, expanding the AMSnet dataset to AMSnet 2.0 with richer annotations.", "motivation": "Current MLLMs struggle with circuit schematics due to limited recognition and lack of high-quality training data. Existing methods like AMSnet rely on rigid heuristics and fail with complex/noisy schematics.", "method": "Proposes a segmentation-based net detection mechanism for robustness and positional data recovery, enabling digital schematic reconstruction. Expands AMSnet to AMSnet 2.0 with diverse data.", "result": "AMSnet 2.0 includes 2,686 circuits with schematic images, netlists, digital schematics, and positional info, a significant upgrade from AMSnet's 792 circuits with only SPICE netlists.", "conclusion": "The new method enhances MLLM capabilities for schematic understanding, supported by a more comprehensive dataset (AMSnet 2.0)."}}
{"id": "2503.21813", "pdf": "https://arxiv.org/pdf/2503.21813", "abs": "https://arxiv.org/abs/2503.21813", "authors": ["Zhangcheng Qiang", "Kerry Taylor", "Weiqing Wang", "Jing Jiang"], "title": "OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching", "categories": ["cs.CL", "cs.IR"], "comment": "14 pages, 4 figures, 4 tables, 2 prompt templates", "summary": "Hallucinations are often inevitable in downstream tasks using large language\nmodels (LLMs). To tackle the substantial challenge of addressing hallucinations\nfor LLM-based ontology matching (OM) systems, we introduce a new benchmark\ndataset OAEI-LLM-T. The dataset evolves from seven TBox datasets in the\nOntology Alignment Evaluation Initiative (OAEI), capturing hallucinations of\nten different LLMs performing OM tasks. These OM-specific hallucinations are\norganised into two primary categories and six sub-categories. We showcase the\nusefulness of the dataset in constructing an LLM leaderboard for OM tasks and\nfor fine-tuning LLMs used in OM tasks.", "AI": {"tldr": "A new benchmark dataset, OAEI-LLM-T, is introduced to address hallucinations in LLM-based ontology matching, categorizing them into two main types and six subcategories for evaluation and fine-tuning.", "motivation": "Hallucinations in LLMs pose challenges for ontology matching tasks, necessitating a dedicated dataset to study and mitigate them.", "method": "The dataset is derived from seven TBox datasets in OAEI, capturing hallucinations from ten LLMs, and categorizing them systematically.", "result": "The dataset enables the creation of an LLM leaderboard for OM tasks and supports fine-tuning LLMs to reduce hallucinations.", "conclusion": "OAEI-LLM-T provides a valuable resource for improving LLM performance in ontology matching by addressing hallucination issues."}}
{"id": "2505.08918", "pdf": "https://arxiv.org/pdf/2505.08918", "abs": "https://arxiv.org/abs/2505.08918", "authors": ["Marina Popova", "Iaroslav Chelombitko", "Aleksey Komissarov"], "title": "When repeats drive the vocabulary: a Byte-Pair Encoding analysis of T2T primate genomes", "categories": ["q-bio.GN", "cs.AI"], "comment": "ICLR 2025 Workshop on Machine Learning for Genomics Explorations", "summary": "The emergence of telomere-to-telomere (T2T) genome assemblies has opened new\navenues for comparative genomics, yet effective tokenization strategies for\ngenomic sequences remain underexplored. In this pilot study, we apply Byte Pair\nEncoding (BPE) to nine T2T primate genomes including three human assemblies by\ntraining independent BPE tokenizers with a fixed vocabulary of 512,000 tokens\nusing our custom tool, dnaBPE. Our analysis reveals that only 11,569 tokens are\nshared across all assemblies, while nearly 991,854 tokens are unique to a\nsingle genome, indicating a rapid decline in shared vocabulary with increasing\nassembly comparisons. Moreover, phylogenetic trees derived from token overlap\nfailed to recapitulate established primate relationships, a discrepancy\nattributed to the disproportionate influence of species-specific high-copy\nrepetitive elements. These findings underscore the dual nature of BPE\ntokenization: while it effectively compresses repetitive sequences, its\nsensitivity to high-copy elements limits its utility as a universal tool for\ncomparative genomics. We discuss potential hybrid strategies and repeat-masking\napproaches to refine genomic tokenization, emphasizing the need for\ndomain-specific adaptations in the development of large-scale genomic language\nmodels. The dnaBPE tool used in this study is open-source and available at\nhttps://github.com/aglabx/dnaBPE.", "AI": {"tldr": "The study explores Byte Pair Encoding (BPE) for tokenizing T2T primate genomes, revealing limited shared vocabulary and challenges in phylogenetic accuracy due to repetitive elements.", "motivation": "To address the underexplored area of effective tokenization strategies for genomic sequences, particularly in the context of T2T assemblies.", "method": "Applied BPE to nine T2T primate genomes using a custom tool, dnaBPE, with a fixed vocabulary of 512,000 tokens.", "result": "Found only 11,569 shared tokens across assemblies, with 991,854 unique tokens, and phylogenetic trees from token overlap did not match known primate relationships.", "conclusion": "BPE's compression of repetitive sequences is effective but limited for comparative genomics; hybrid strategies and repeat-masking are suggested for improvement."}}
{"id": "2505.09218", "pdf": "https://arxiv.org/pdf/2505.09218", "abs": "https://arxiv.org/abs/2505.09218", "authors": ["Alexander Tyurin", "Danil Sivtsov"], "title": "Birch SGD: A Tree Graph Framework for Local and Asynchronous SGD Methods", "categories": ["cs.LG", "cs.DC", "math.OC"], "comment": null, "summary": "We propose a new unifying framework, Birch SGD, for analyzing and designing\ndistributed SGD methods. The central idea is to represent each method as a\nweighted directed tree, referred to as a computation tree. Leveraging this\nrepresentation, we introduce a general theoretical result that reduces\nconvergence analysis to studying the geometry of these trees. This perspective\nyields a purely graph-based interpretation of optimization dynamics, offering a\nnew and intuitive foundation for method development. Using Birch SGD, we design\neight new methods and analyze them alongside previously known ones, with at\nleast six of the new methods shown to have optimal computational time\ncomplexity. Our research leads to two key insights: (i) all methods share the\nsame \"iteration rate\" of $O\\left(\\frac{(R + 1) L \\Delta}{\\varepsilon} +\n\\frac{\\sigma^2 L \\Delta}{\\varepsilon^2}\\right)$, where $R$ the maximum \"tree\ndistance\" along the main branch of a tree; and (ii) different methods exhibit\ndifferent trade-offs-for example, some update iterates more frequently,\nimproving practical performance, while others are more communication-efficient\nor focus on other aspects. Birch SGD serves as a unifying framework for\nnavigating these trade-offs. We believe these results provide a unified\nfoundation for understanding, analyzing, and designing efficient asynchronous\nand parallel optimization methods.", "AI": {"tldr": "Birch SGD is a framework for analyzing distributed SGD methods using computation trees, unifying convergence analysis and method design. It introduces eight new methods, some with optimal complexity, and reveals trade-offs in performance and efficiency.", "motivation": "To provide a unified framework for analyzing and designing distributed SGD methods, simplifying convergence analysis and method development.", "method": "Represent SGD methods as weighted directed trees (computation trees) and analyze their geometry to derive convergence properties.", "result": "Eight new methods designed, some with optimal complexity; insights on trade-offs between iteration rate, communication efficiency, and practical performance.", "conclusion": "Birch SGD unifies understanding and design of distributed SGD methods, offering a foundation for efficient asynchronous and parallel optimization."}}
{"id": "2505.09168", "pdf": "https://arxiv.org/pdf/2505.09168", "abs": "https://arxiv.org/abs/2505.09168", "authors": ["Jianlin Sun", "Xiaolin Fang", "Juwei Guan", "Dongdong Gui", "Teqi Wang", "Tongxin Zhu"], "title": "DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The core challenge in Camouflage Object Detection (COD) lies in the\nindistinguishable similarity between targets and backgrounds in terms of color,\ntexture, and shape. This causes existing methods to either lose edge details\n(such as hair-like fine structures) due to over-reliance on global semantic\ninformation or be disturbed by similar backgrounds (such as vegetation\npatterns) when relying solely on local features. We propose DRRNet, a\nfour-stage architecture characterized by a \"context-detail-fusion-refinement\"\npipeline to address these issues. Specifically, we introduce an Omni-Context\nFeature Extraction Module to capture global camouflage patterns and a Local\nDetail Extraction Module to supplement microstructural information for the\nfull-scene context module. We then design a module for forming dual\nrepresentations of scene understanding and structural awareness, which fuses\npanoramic features and local features across various scales. In the decoder, we\nalso introduce a reverse refinement module that leverages spatial edge priors\nand frequency-domain noise suppression to perform a two-stage inverse\nrefinement of the output. By applying two successive rounds of inverse\nrefinement, the model effectively suppresses background interference and\nenhances the continuity of object boundaries. Experimental results demonstrate\nthat DRRNet significantly outperforms state-of-the-art methods on benchmark\ndatasets. Our code is available at https://github.com/jerrySunning/DRRNet.", "AI": {"tldr": "DRRNet introduces a four-stage architecture for Camouflage Object Detection, combining global and local features with a refinement pipeline to improve edge details and reduce background interference.", "motivation": "Existing COD methods struggle with indistinct target-background similarities, losing edge details or being misled by similar backgrounds.", "method": "DRRNet uses a four-stage pipeline: Omni-Context Feature Extraction, Local Detail Extraction, dual-representation fusion, and reverse refinement.", "result": "DRRNet outperforms state-of-the-art methods on benchmark datasets by enhancing boundary continuity and suppressing noise.", "conclusion": "DRRNet effectively addresses COD challenges by integrating global and local features with innovative refinement techniques."}}
{"id": "2503.24293", "pdf": "https://arxiv.org/pdf/2503.24293", "abs": "https://arxiv.org/abs/2503.24293", "authors": ["Hayley Ross", "Kathryn Davidson", "Najoung Kim"], "title": "Is analogy enough to draw novel adjective-noun inferences?", "categories": ["cs.CL"], "comment": "9 pages (17 pages with appendix). Accepted to SCiL 2025", "summary": "Recent work (Ross et al., 2025, 2024) has argued that the ability of humans\nand LLMs respectively to generalize to novel adjective-noun combinations shows\nthat they each have access to a compositional mechanism to determine the\nphrase's meaning and derive inferences. We study whether these inferences can\ninstead be derived by analogy to known inferences, without need for\ncomposition. We investigate this by (1) building a model of analogical\nreasoning using similarity over lexical items, and (2) asking human\nparticipants to reason by analogy. While we find that this strategy works well\nfor a large proportion of the dataset of Ross et al. (2025), there are novel\ncombinations for which both humans and LLMs derive convergent inferences but\nwhich are not well handled by analogy. We thus conclude that the mechanism\nhumans and LLMs use to generalize in these cases cannot be fully reduced to\nanalogy, and likely involves composition.", "AI": {"tldr": "The paper explores whether analogical reasoning, rather than composition, can explain how humans and LLMs generalize to novel adjective-noun combinations. While analogy works for many cases, some require composition.", "motivation": "To determine if generalization in humans and LLMs for novel adjective-noun combinations relies on analogy or composition.", "method": "(1) Build a model of analogical reasoning using lexical similarity. (2) Conduct human experiments on analogical reasoning.", "result": "Analogy works for many cases, but some novel combinations require composition, as both humans and LLMs show convergent inferences not explainable by analogy.", "conclusion": "Generalization in humans and LLMs cannot be fully reduced to analogy; composition is likely involved."}}
{"id": "2505.08919", "pdf": "https://arxiv.org/pdf/2505.08919", "abs": "https://arxiv.org/abs/2505.08919", "authors": ["Kangxian Xie", "Yufei Zhu", "Kaiming Kuang", "Li Zhang", "Hongwei Bran Li", "Mingchen Gao", "Jiancheng Yang"], "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "In revision process", "summary": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in\nsegmentectomy and surgical treatment planning for lung cancer. Due to the\nresolution requirement of the target reconstruction, conventional deep\nlearning-based methods often suffer from computational resource constraints or\nlimited granularity. Conversely, implicit modeling is favored due to its\ncomputational efficiency and continuous representation at any resolution. We\npropose a neural implicit function-based method to learn a 3D surface to\nachieve anatomy-aware, precise pulmonary segment reconstruction, represented as\na shape by deforming a learnable template. Additionally, we introduce two\nclinically relevant evaluation metrics to assess the reconstruction\ncomprehensively. Further, due to the absence of publicly available shape\ndatasets to benchmark reconstruction algorithms, we developed a shape dataset\nnamed Lung3D, including the 3D models of 800 labeled pulmonary segments and the\ncorresponding airways, arteries, veins, and intersegmental veins. We\ndemonstrate that the proposed approach outperforms existing methods, providing\na new perspective for pulmonary segment reconstruction. Code and data will be\navailable at https://github.com/M3DV/ImPulSe.", "AI": {"tldr": "A neural implicit function-based method for high-quality 3D pulmonary segment reconstruction, outperforming existing methods with clinically relevant metrics and a new dataset, Lung3D.", "motivation": "High-quality 3D reconstruction of pulmonary segments is crucial for lung cancer surgery, but current methods face computational or granularity limitations.", "method": "Uses neural implicit functions to deform a learnable template for precise, anatomy-aware reconstruction, with new evaluation metrics.", "result": "Outperforms existing methods; introduces Lung3D dataset with 800 labeled pulmonary segments.", "conclusion": "Proposes a superior approach for pulmonary segment reconstruction, with publicly available code and data."}}
{"id": "2505.09239", "pdf": "https://arxiv.org/pdf/2505.09239", "abs": "https://arxiv.org/abs/2505.09239", "authors": ["Faruk Alpay"], "title": "Stable and Convexified Information Bottleneck Optimization via Symbolic Continuation and Entropy-Regularized Trajectories", "categories": ["cs.LG", "68T05, 90C25, 94A15", "I.2.6; G.1.6; H.1.1"], "comment": "23 pages, 11 figures, includes analytical proofs, sensitivity\n  analysis (95% CI), and JAX-based open-source implementation available at:\n  https://github.com/farukalpay/information-bottleneck-beta-optimization", "summary": "The Information Bottleneck (IB) method frequently suffers from unstable\noptimization, characterized by abrupt representation shifts near critical\npoints of the IB trade-off parameter, beta. In this paper, I introduce a novel\napproach to achieve stable and convex IB optimization through symbolic\ncontinuation and entropy-regularized trajectories. I analytically prove\nconvexity and uniqueness of the IB solution path when an entropy regularization\nterm is included, and demonstrate how this stabilizes representation learning\nacross a wide range of \\b{eta} values. Additionally, I provide extensive\nsensitivity analyses around critical points (beta) with statistically robust\nuncertainty quantification (95% confidence intervals). The open-source\nimplementation, experimental results, and reproducibility framework included in\nthis work offer a clear path for practical deployment and future extension of\nmy proposed method.", "AI": {"tldr": "The paper introduces a stable and convex optimization method for the Information Bottleneck (IB) problem using entropy regularization, ensuring smooth representation learning across beta values.", "motivation": "The IB method often suffers from unstable optimization and abrupt shifts near critical beta points, which this work aims to address.", "method": "The proposed approach uses symbolic continuation and entropy-regularized trajectories to achieve convexity and uniqueness in the IB solution path.", "result": "The method stabilizes representation learning, with proven convexity and uniqueness, and includes sensitivity analyses with robust uncertainty quantification.", "conclusion": "The work provides a practical, open-source framework for stable IB optimization, ready for deployment and future extensions."}}
{"id": "2505.09178", "pdf": "https://arxiv.org/pdf/2505.09178", "abs": "https://arxiv.org/abs/2505.09178", "authors": ["Yitao Zhu", "Yuan Yin", "Zhenrong Shen", "Zihao Zhao", "Haiyu Song", "Sheng Wang", "Dinggang Shen", "Qian Wang"], "title": "UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System", "categories": ["cs.CV"], "comment": "14 pages", "summary": "The growing complexity and scale of visual model pre-training have made\ndeveloping and deploying multi-task computer-aided diagnosis (CAD) systems\nincreasingly challenging and resource-intensive. Furthermore, the medical\nimaging community lacks an open-source CAD platform to enable the rapid\ncreation of efficient and extendable diagnostic models. To address these\nissues, we propose UniCAD, a unified architecture that leverages the robust\ncapabilities of pre-trained vision foundation models to seamlessly handle both\n2D and 3D medical images while requiring only minimal task-specific parameters.\nUniCAD introduces two key innovations: (1) Efficiency: A low-rank adaptation\nstrategy is employed to adapt a pre-trained visual model to the medical image\ndomain, achieving performance on par with fully fine-tuned counterparts while\nintroducing only 0.17% trainable parameters. (2) Plug-and-Play: A modular\narchitecture that combines a frozen foundation model with multiple\nplug-and-play experts, enabling diverse tasks and seamless functionality\nexpansion. Building on this unified CAD architecture, we establish an\nopen-source platform where researchers can share and access lightweight CAD\nexperts, fostering a more equitable and efficient research ecosystem.\nComprehensive experiments across 12 diverse medical datasets demonstrate that\nUniCAD consistently outperforms existing methods in both accuracy and\ndeployment efficiency. The source code and project page are available at\nhttps://mii-laboratory.github.io/UniCAD/.", "AI": {"tldr": "UniCAD is a unified, efficient, and modular architecture for multi-task medical image diagnosis, leveraging pre-trained vision models with minimal task-specific parameters.", "motivation": "Addressing the lack of an open-source CAD platform and the resource-intensive nature of developing multi-task diagnostic systems.", "method": "Uses low-rank adaptation for efficiency and a modular plug-and-play design with frozen foundation models and task-specific experts.", "result": "Outperforms existing methods in accuracy and deployment efficiency across 12 diverse medical datasets.", "conclusion": "UniCAD provides an open-source platform for equitable and efficient research in medical image diagnosis."}}
{"id": "2504.04717", "pdf": "https://arxiv.org/pdf/2504.04717", "abs": "https://arxiv.org/abs/2504.04717", "authors": ["Yubo Li", "Xiaobin Shen", "Xinyu Yao", "Xueying Ding", "Yidi Miao", "Ramayya Krishnan", "Rema Padman"], "title": "Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have revolutionized their\nability to handle single-turn tasks, yet real-world applications demand\nsophisticated multi-turn interactions. This survey provides a comprehensive\nreview of recent advancements in evaluating and enhancing multi-turn\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\nfollowing in diverse domains such as math and coding to complex conversational\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\nsettings, we systematically examine the challenges of maintaining context,\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\norganizes current benchmarks and datasets into coherent categories that reflect\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\nreview a range of enhancement methodologies under multi-turn settings,\nincluding model-centric strategies (contextual learning, supervised\nfine-tuning, reinforcement learning, and new architectures), external\nintegration approaches (memory-augmented, retrieval-based methods, and\nknowledge graph), and agent-based techniques for collaborative interactions.\nFinally, we discuss open challenges and propose future directions for research\nto further advance the robustness and effectiveness of multi-turn interactions\nin LLMs. Related resources and papers are available at\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.", "AI": {"tldr": "A survey on evaluating and enhancing multi-turn interactions in LLMs, covering benchmarks, methodologies, and future directions.", "motivation": "Real-world applications require sophisticated multi-turn interactions, but current LLMs excel mainly in single-turn tasks.", "method": "Systematic review of benchmarks, datasets, and enhancement methods (model-centric, external integration, agent-based).", "result": "Organized current benchmarks and reviewed methodologies to improve multi-turn interactions in LLMs.", "conclusion": "Identifies open challenges and proposes future research directions for robust multi-turn LLM interactions."}}
{"id": "2505.08939", "pdf": "https://arxiv.org/pdf/2505.08939", "abs": "https://arxiv.org/abs/2505.08939", "authors": ["Suchismita Naik", "Prakash Shukla", "Ike Obi", "Jessica Backus", "Nancy Rasche", "Paul Parsons"], "title": "Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work", "categories": ["cs.HC", "cs.AI"], "comment": "5 pages, 2 Tables, In Creativity and Cognition 2025, June 23--25,\n  2025, Virtual, United Kingdom", "summary": "As generative AI tools become integrated into design workflows, students\nincreasingly engage with these tools not just as aids, but as collaborators.\nThis study analyzes reflections from 33 student teams in an HCI design course\nto examine the kinds of judgments students make when using AI tools. We found\nboth established forms of design judgment (e.g., instrumental, appreciative,\nquality) and emergent types: agency-distribution judgment and reliability\njudgment. These new forms capture how students negotiate creative\nresponsibility with AI and assess the trustworthiness of its outputs. Our\nfindings suggest that generative AI introduces new layers of complexity into\ndesign reasoning, prompting students to reflect not only on what AI produces,\nbut also on how and when to rely on it. By foregrounding these judgments, we\noffer a conceptual lens for understanding how students engage in co-creative\nsensemaking with AI in design contexts.", "AI": {"tldr": "The study explores how students in an HCI design course use generative AI as collaborators, identifying new forms of design judgment like agency-distribution and reliability judgments.", "motivation": "To understand how students integrate generative AI into design workflows and the judgments they make when collaborating with AI.", "method": "Analysis of reflections from 33 student teams in an HCI design course.", "result": "Identified established and emergent design judgments, highlighting how students negotiate creative responsibility and assess AI's trustworthiness.", "conclusion": "Generative AI adds complexity to design reasoning, requiring students to reflect on AI's role and reliability, offering a new lens for co-creative sensemaking."}}
{"id": "2505.09284", "pdf": "https://arxiv.org/pdf/2505.09284", "abs": "https://arxiv.org/abs/2505.09284", "authors": ["Panqi Chen", "Yifan Sun", "Lei Cheng", "Yang Yang", "Weichang Li", "Yang Liu", "Weiqing Liu", "Jiang Bian", "Shikai Fang"], "title": "Generating Full-field Evolution of Physical Dynamics from Irregular Sparse Observations", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Modeling and reconstructing multidimensional physical dynamics from sparse\nand off-grid observations presents a fundamental challenge in scientific\nresearch. Recently, diffusion-based generative modeling shows promising\npotential for physical simulation. However, current approaches typically\noperate on on-grid data with preset spatiotemporal resolution, but struggle\nwith the sparsely observed and continuous nature of real-world physical\ndynamics. To fill the gaps, we present SDIFT, Sequential DIffusion in\nFunctional Tucker space, a novel framework that generates full-field evolution\nof physical dynamics from irregular sparse observations. SDIFT leverages the\nfunctional Tucker model as the latent space representer with proven universal\napproximation property, and represents observations as latent functions and\nTucker core sequences. We then construct a sequential diffusion model with\ntemporally augmented UNet in the functional Tucker space, denoising noise drawn\nfrom a Gaussian process to generate the sequence of core tensors.\n  At the posterior sampling stage, we propose a Message-Passing Posterior\nSampling mechanism, enabling conditional generation of the entire sequence\nguided by observations at limited time steps. We validate SDIFT on three\nphysical systems spanning astronomical (supernova explosions, light-year\nscale), environmental (ocean sound speed fields, kilometer scale), and\nmolecular (organic liquid, millimeter scale) domains, demonstrating significant\nimprovements in both reconstruction accuracy and computational efficiency\ncompared to state-of-the-art approaches.", "AI": {"tldr": "SDIFT is a novel framework using sequential diffusion in functional Tucker space to model and reconstruct multidimensional physical dynamics from sparse, off-grid observations, outperforming existing methods in accuracy and efficiency.", "motivation": "The challenge lies in reconstructing physical dynamics from sparse, irregular observations, which current diffusion-based methods struggle with due to their reliance on on-grid data.", "method": "SDIFT employs a functional Tucker model for latent space representation and a sequential diffusion model with a temporally augmented UNet to denoise Gaussian process noise, generating core tensor sequences.", "result": "Validated on astronomical, environmental, and molecular systems, SDIFT shows superior reconstruction accuracy and computational efficiency.", "conclusion": "SDIFT effectively addresses the limitations of current methods, offering a robust solution for modeling physical dynamics from sparse observations."}}
{"id": "2505.09188", "pdf": "https://arxiv.org/pdf/2505.09188", "abs": "https://arxiv.org/abs/2505.09188", "authors": ["Minjun Kim", "Jaehyeon Choi", "Jongkeun Lee", "Wonjin Cho", "U Kang"], "title": "Zero-shot Quantization: A Comprehensive Survey", "categories": ["cs.CV"], "comment": "IJCAI 2025 Survey Track", "summary": "Network quantization has proven to be a powerful approach to reduce the\nmemory and computational demands of deep learning models for deployment on\nresource-constrained devices. However, traditional quantization methods often\nrely on access to training data, which is impractical in many real-world\nscenarios due to privacy, security, or regulatory constraints. Zero-shot\nQuantization (ZSQ) emerges as a promising solution, achieving quantization\nwithout requiring any real data. In this paper, we provide a comprehensive\noverview of ZSQ methods and their recent advancements. First, we provide a\nformal definition of the ZSQ problem and highlight the key challenges. Then, we\ncategorize the existing ZSQ methods into classes based on data generation\nstrategies, and analyze their motivations, core ideas, and key takeaways.\nLastly, we suggest future research directions to address the remaining\nlimitations and advance the field of ZSQ. To the best of our knowledge, this\npaper is the first in-depth survey on ZSQ.", "AI": {"tldr": "This paper surveys Zero-shot Quantization (ZSQ), a method for reducing deep learning model size without real data, categorizing existing approaches and suggesting future directions.", "motivation": "Traditional quantization requires training data, which is often unavailable due to privacy or regulatory constraints. ZSQ addresses this by enabling quantization without real data.", "method": "The paper categorizes ZSQ methods based on data generation strategies, analyzing their motivations and core ideas.", "result": "A comprehensive overview of ZSQ methods is provided, highlighting challenges and recent advancements.", "conclusion": "The paper identifies future research directions to improve ZSQ, marking the first in-depth survey on the topic."}}
{"id": "2505.00949", "pdf": "https://arxiv.org/pdf/2505.00949", "abs": "https://arxiv.org/abs/2505.00949", "authors": ["Akhiad Bercovich", "Itay Levy", "Izik Golan", "Mohammad Dabbah", "Ran El-Yaniv", "Omri Puny", "Ido Galil", "Zach Moshe", "Tomer Ronen", "Najeeb Nabwani", "Ido Shahaf", "Oren Tropp", "Ehud Karpas", "Ran Zilberstein", "Jiaqi Zeng", "Soumye Singhal", "Alexander Bukharin", "Yian Zhang", "Tugrul Konuk", "Gerald Shen", "Ameya Sunil Mahabaleshwarkar", "Bilal Kartal", "Yoshi Suhara", "Olivier Delalleau", "Zijia Chen", "Zhilin Wang", "David Mosallanezhad", "Adi Renduchintala", "Haifeng Qian", "Dima Rekesh", "Fei Jia", "Somshubra Majumdar", "Vahid Noroozi", "Wasi Uddin Ahmad", "Sean Narenthiran", "Aleksander Ficek", "Mehrzad Samadi", "Jocelyn Huang", "Siddhartha Jain", "Igor Gitman", "Ivan Moshkov", "Wei Du", "Shubham Toshniwal", "George Armstrong", "Branislav Kisacanin", "Matvei Novikov", "Daria Gitman", "Evelina Bakhturina", "Jane Polak Scowcroft", "John Kamalu", "Dan Su", "Kezhi Kong", "Markus Kliegl", "Rabeeh Karimi", "Ying Lin", "Sanjeev Satheesh", "Jupinder Parmar", "Pritam Gundecha", "Brandon Norick", "Joseph Jennings", "Shrimai Prabhumoye", "Syeda Nahida Akter", "Mostofa Patwary", "Abhinav Khattar", "Deepak Narayanan", "Roger Waleffe", "Jimmy Zhang", "Bor-Yiing Su", "Guyue Huang", "Terry Kong", "Parth Chadha", "Sahil Jain", "Christine Harvey", "Elad Segal", "Jining Huang", "Sergey Kashirsky", "Robert McQueen", "Izzy Putterman", "George Lam", "Arun Venkatesan", "Sherry Wu", "Vinh Nguyen", "Manoj Kilaru", "Andrew Wang", "Anna Warno", "Abhilash Somasamudramath", "Sandip Bhaskar", "Maka Dong", "Nave Assaf", "Shahar Mor", "Omer Ullman Argov", "Scot Junkin", "Oleksandr Romanenko", "Pedro Larroy", "Monika Katariya", "Marco Rovinelli", "Viji Balas", "Nicholas Edelman", "Anahita Bhiwandiwalla", "Muthu Subramaniam", "Smita Ithape", "Karthik Ramamoorthy", "Yuting Wu", "Suguna Varshini Velury", "Omri Almog", "Joyjit Daw", "Denys Fridman", "Erick Galinkin", "Michael Evans", "Shaona Ghosh", "Katherine Luna", "Leon Derczynski", "Nikki Pope", "Eileen Long", "Seth Schneider", "Guillermo Siman", "Tomasz Grzegorzek", "Pablo Ribalta", "Monika Katariya", "Chris Alexiuk", "Joey Conway", "Trisha Saar", "Ann Guan", "Krzysztof Pawelec", "Shyamala Prayaga", "Oleksii Kuchaiev", "Boris Ginsburg", "Oluwatobi Olabiyi", "Kari Briski", "Jonathan Cohen", "Bryan Catanzaro", "Jonah Alben", "Yonatan Geifman", "Eric Chung"], "title": "Llama-Nemotron: Efficient Reasoning Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce the Llama-Nemotron series of models, an open family of\nheterogeneous reasoning models that deliver exceptional reasoning capabilities,\ninference efficiency, and an open license for enterprise use. The family comes\nin three sizes -- Nano (8B), Super (49B), and Ultra (253B) -- and performs\ncompetitively with state-of-the-art reasoning models such as DeepSeek-R1 while\noffering superior inference throughput and memory efficiency. In this report,\nwe discuss the training procedure for these models, which entails using neural\narchitecture search from Llama 3 models for accelerated inference, knowledge\ndistillation, and continued pretraining, followed by a reasoning-focused\npost-training stage consisting of two main parts: supervised fine-tuning and\nlarge scale reinforcement learning. Llama-Nemotron models are the first\nopen-source models to support a dynamic reasoning toggle, allowing users to\nswitch between standard chat and reasoning modes during inference. To further\nsupport open research and facilitate model development, we provide the\nfollowing resources: 1. We release the Llama-Nemotron reasoning models --\nLN-Nano, LN-Super, and LN-Ultra -- under the commercially permissive NVIDIA\nOpen Model License Agreement. 2. We release the complete post-training dataset:\nLlama-Nemotron-Post-Training-Dataset. 3. We also release our training\ncodebases: NeMo, NeMo-Aligner, and Megatron-LM.", "AI": {"tldr": "The Llama-Nemotron series offers open-source, heterogeneous reasoning models with competitive performance, superior efficiency, and a dynamic reasoning toggle. Three sizes are available, trained using neural architecture search, knowledge distillation, and reinforcement learning.", "motivation": "To provide high-performance, efficient reasoning models with open licensing for enterprise use and support open research.", "method": "Training involves neural architecture search, knowledge distillation, continued pretraining, and a reasoning-focused post-training stage (supervised fine-tuning and large-scale reinforcement learning).", "result": "Models (Nano, Super, Ultra) perform competitively with state-of-the-art models while offering better throughput and memory efficiency.", "conclusion": "Llama-Nemotron models advance open-source reasoning capabilities with practical features and released resources for community development."}}
{"id": "2505.09021", "pdf": "https://arxiv.org/pdf/2505.09021", "abs": "https://arxiv.org/abs/2505.09021", "authors": ["Maria Dhakal", "Chia-Yi Su", "Robert Wallace", "Chris Fakhimi", "Aakash Bansal", "Toby Li", "Yu Huang", "Collin McMillan"], "title": "AI-Mediated Code Comment Improvement", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "This paper describes an approach to improve code comments along different\nquality axes by rewriting those comments with customized Artificial\nIntelligence (AI)-based tools. We conduct an empirical study followed by\ngrounded theory qualitative analysis to determine the quality axes to improve.\nThen we propose a procedure using a Large Language Model (LLM) to rewrite\nexisting code comments along the quality axes. We implement our procedure using\nGPT-4o, then distil the results into a smaller model capable of being run\nin-house, so users can maintain data custody. We evaluate both our approach\nusing GPT-4o and the distilled model versions. We show in an evaluation how our\nprocedure improves code comments along the quality axes. We release all data\nand source code in an online repository for reproducibility.", "AI": {"tldr": "The paper proposes an AI-based approach to improve code comments by rewriting them using LLMs like GPT-4o, followed by distilling the model for in-house use, and evaluates its effectiveness.", "motivation": "To enhance code comment quality along identified axes using AI tools while ensuring data custody.", "method": "Empirical study and grounded theory to define quality axes, followed by LLM-based comment rewriting and model distillation.", "result": "The approach improves code comments along the quality axes, with both GPT-4o and distilled models showing effectiveness.", "conclusion": "The method successfully enhances code comment quality and is made reproducible via released data and source code."}}
{"id": "2505.09287", "pdf": "https://arxiv.org/pdf/2505.09287", "abs": "https://arxiv.org/abs/2505.09287", "authors": ["Shunsuke Yoneda", "Valdemar \u0160v\u00e1bensk\u00fd", "Gen Li", "Daisuke Deguchi", "Atsushi Shimada"], "title": "Ranking-Based At-Risk Student Prediction Using Federated Learning and Differential Features", "categories": ["cs.LG", "cs.CY", "I.2; I.6; K.3"], "comment": "To appear in the Proceedings of the 18th Educational Data Mining\n  Conference (EDM 2025)", "summary": "Digital textbooks are widely used in various educational contexts, such as\nuniversity courses and online lectures. Such textbooks yield learning log data\nthat have been used in numerous educational data mining (EDM) studies for\nstudent behavior analysis and performance prediction. However, these studies\nhave faced challenges in integrating confidential data, such as academic\nrecords and learning logs, across schools due to privacy concerns.\nConsequently, analyses are often conducted with data limited to a single\nschool, which makes developing high-performing and generalizable models\ndifficult. This study proposes a method that combines federated learning and\ndifferential features to address these issues. Federated learning enables model\ntraining without centralizing data, thereby preserving student privacy.\nDifferential features, which utilize relative values instead of absolute\nvalues, enhance model performance and generalizability. To evaluate the\nproposed method, a model for predicting at-risk students was trained using data\nfrom 1,136 students across 12 courses conducted over 4 years, and validated on\nhold-out test data from 5 other courses. Experimental results demonstrated that\nthe proposed method addresses privacy concerns while achieving performance\ncomparable to that of models trained via centralized learning in terms of Top-n\nprecision, nDCG, and PR-AUC. Furthermore, using differential features improved\nprediction performance across all evaluation datasets compared to\nnon-differential approaches. The trained models were also applicable for early\nprediction, achieving high performance in detecting at-risk students in earlier\nstages of the semester within the validation datasets.", "AI": {"tldr": "The paper proposes a federated learning method with differential features to address privacy concerns in analyzing digital textbook logs across schools, achieving comparable performance to centralized models.", "motivation": "Privacy concerns limit the integration of confidential student data across schools, hindering the development of generalizable models for behavior analysis and performance prediction.", "method": "Combines federated learning (to avoid centralizing data) and differential features (using relative values) to train models for predicting at-risk students.", "result": "The method matched centralized learning in performance metrics (Top-n precision, nDCG, PR-AUC) and improved prediction with differential features. Early detection of at-risk students was also successful.", "conclusion": "The proposed method effectively balances privacy and performance, enhancing generalizability and early prediction in educational data mining."}}
{"id": "2505.09196", "pdf": "https://arxiv.org/pdf/2505.09196", "abs": "https://arxiv.org/abs/2505.09196", "authors": ["Tong Li", "Lizhi Wang", "Hansen Feng", "Lin Zhu", "Hua Huang"], "title": "PDE: Gene Effect Inspired Parameter Dynamic Evolution for Low-light Image Enhancement", "categories": ["cs.CV"], "comment": "11 pages, 9 tables, 9 figures", "summary": "Low-light image enhancement (LLIE) is a fundamental task in computational\nphotography, aiming to improve illumination, reduce noise, and enhance image\nquality. While recent advancements focus on designing increasingly complex\nneural network models, we observe a peculiar phenomenon: resetting certain\nparameters to random values unexpectedly improves enhancement performance for\nsome images. Drawing inspiration from biological genes, we term this phenomenon\nthe gene effect. The gene effect limits enhancement performance, as even random\nparameters can sometimes outperform learned ones, preventing models from fully\nutilizing their capacity. In this paper, we investigate the reason and propose\na solution. Based on our observations, we attribute the gene effect to static\nparameters, analogous to how fixed genetic configurations become maladaptive\nwhen environments change. Inspired by biological evolution, where adaptation to\nnew environments relies on gene mutation and recombination, we propose\nparameter dynamic evolution (PDE) to adapt to different images and mitigate the\ngene effect. PDE employs a parameter orthogonal generation technique and the\ncorresponding generated parameters to simulate gene recombination and gene\nmutation, separately. Experiments validate the effectiveness of our techniques.\nThe code will be released to the public.", "AI": {"tldr": "The paper introduces the 'gene effect' in low-light image enhancement (LLIE), where random parameters sometimes outperform learned ones, limiting model performance. The authors propose Parameter Dynamic Evolution (PDE) to mitigate this effect by simulating biological gene mutation and recombination.", "motivation": "The 'gene effect' hinders LLIE performance, as static parameters can become maladaptive. The study aims to address this by drawing inspiration from biological evolution.", "method": "Proposes Parameter Dynamic Evolution (PDE), using parameter orthogonal generation to simulate gene recombination and mutation, adapting parameters dynamically for different images.", "result": "Experiments confirm PDE's effectiveness in mitigating the gene effect and improving LLIE performance.", "conclusion": "PDE successfully addresses the gene effect, enhancing LLIE by dynamically evolving parameters, with code to be publicly released."}}
{"id": "2505.05084", "pdf": "https://arxiv.org/pdf/2505.05084", "abs": "https://arxiv.org/abs/2505.05084", "authors": ["Xiaowei Zhu", "Yubing Ren", "Yanan Cao", "Xixun Lin", "Fang Fang", "Yangxi Li"], "title": "Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction", "categories": ["cs.CL"], "comment": null, "summary": "The rapid advancement of large language models has raised significant\nconcerns regarding their potential misuse by malicious actors. As a result,\ndeveloping effective detectors to mitigate these risks has become a critical\npriority. However, most existing detection methods focus excessively on\ndetection accuracy, often neglecting the societal risks posed by high false\npositive rates (FPRs). This paper addresses this issue by leveraging Conformal\nPrediction (CP), which effectively constrains the upper bound of FPRs. While\ndirectly applying CP constrains FPRs, it also leads to a significant reduction\nin detection performance. To overcome this trade-off, this paper proposes a\nZero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal\nPrediction (MCP), which both enforces the FPR constraint and improves detection\nperformance. This paper also introduces RealDet, a high-quality dataset that\nspans a wide range of domains, ensuring realistic calibration and enabling\nsuperior detection performance when combined with MCP. Empirical evaluations\ndemonstrate that MCP effectively constrains FPRs, significantly enhances\ndetection performance, and increases robustness against adversarial attacks\nacross multiple detectors and datasets.", "AI": {"tldr": "The paper proposes a Zero-Shot Machine-Generated Text Detection Framework using Multiscaled Conformal Prediction (MCP) to balance FPR constraints and detection performance, validated by the RealDet dataset.", "motivation": "Addressing societal risks from high false positive rates (FPRs) in existing detection methods for large language models.", "method": "Leverages Conformal Prediction (CP) and introduces MCP to enforce FPR constraints while improving detection. Uses the RealDet dataset for realistic calibration.", "result": "MCP effectively constrains FPRs, enhances detection performance, and increases robustness against adversarial attacks.", "conclusion": "MCP offers a balanced solution for mitigating misuse risks of large language models by improving detection without compromising FPR constraints."}}
{"id": "2505.09027", "pdf": "https://arxiv.org/pdf/2505.09027", "abs": "https://arxiv.org/abs/2505.09027", "authors": ["Yi Cui"], "title": "Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2409.05177", "summary": "We introduce WebApp1K, a novel benchmark for evaluating large language models\n(LLMs) in test-driven development (TDD) tasks, where test cases serve as both\nprompt and verification for code generation. Unlike traditional approaches\nrelying on natural language prompts, our benchmark emphasizes the ability of\nLLMs to interpret and implement functionality directly from test cases,\nreflecting real-world software development practices. Comprising 1000 diverse\nchallenges across 20 application domains, the benchmark evaluates LLMs on their\nability to generate compact, functional code under the constraints of context\nlength and multi-feature complexity. Our findings highlight instruction\nfollowing and in-context learning as critical capabilities for TDD success,\nsurpassing the importance of general coding proficiency or pretraining\nknowledge. Through comprehensive evaluation of 19 frontier models, we reveal\nperformance bottlenecks, such as instruction loss in long prompts, and provide\na detailed error analysis spanning multiple root causes. This work underscores\nthe practical value of TDD-specific benchmarks and lays the foundation for\nadvancing LLM capabilities in rigorous, application-driven coding scenarios.", "AI": {"tldr": "WebApp1K is a benchmark for evaluating LLMs in test-driven development (TDD) tasks, using test cases as prompts and verification. It assesses LLMs' ability to generate functional code from test cases across 1000 diverse challenges. Key findings emphasize instruction following and in-context learning as crucial for TDD success.", "motivation": "To address the gap in evaluating LLMs for real-world TDD tasks, where test cases guide code generation, reflecting actual software development practices.", "method": "The benchmark includes 1000 challenges across 20 domains, testing LLMs on compact, functional code generation under constraints like context length and multi-feature complexity.", "result": "Evaluation of 19 models revealed performance bottlenecks (e.g., instruction loss in long prompts) and highlighted instruction following and in-context learning as critical for TDD success.", "conclusion": "WebApp1K demonstrates the value of TDD-specific benchmarks and sets a foundation for improving LLMs in rigorous, application-driven coding tasks."}}
{"id": "2505.09294", "pdf": "https://arxiv.org/pdf/2505.09294", "abs": "https://arxiv.org/abs/2505.09294", "authors": ["Fan Xu", "Wuyang Chen", "Wei Gao"], "title": "On the Learning with Augmented Class via Forests", "categories": ["cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Decision trees and forests have achieved successes in various real\napplications, most working with all testing classes known in training data. In\nthis work, we focus on learning with augmented class via forests, where an\naugmented class may appear in testing data yet not in training data. We\nincorporate information of augmented class into trees' splitting, i.e., a new\nsplitting criterion, called augmented Gini impurity, is introduced to exploit\nsome unlabeled data from testing distribution. We then develop the approach\nnamed Learning with Augmented Class via Forests (LACForest), which constructs\nshallow forests based on the augmented Gini impurity and then splits forests\nwith pseudo-labeled augmented instances for better performance. We also develop\ndeep neural forests with a novel optimization objective based on our augmented\nGini impurity, so as to utilize the representation power of neural networks for\nforests. Theoretically, we present the convergence analysis for augmented Gini\nimpurity, and finally conduct experiments to verify the effectiveness of our\napproaches. The code is available at https://github.com/nju-xuf/LACForest/.", "AI": {"tldr": "The paper introduces LACForest, a method for learning with augmented classes in forests, using a new splitting criterion called augmented Gini impurity. It combines shallow forests and deep neural forests for improved performance.", "motivation": "Address the challenge of augmented classes appearing in testing data but not in training data, enhancing decision tree and forest methods.", "method": "Develops LACForest with augmented Gini impurity for splitting, uses pseudo-labeled augmented instances, and integrates deep neural forests with a novel optimization objective.", "result": "Theoretical convergence analysis and experiments confirm the effectiveness of LACForest.", "conclusion": "LACForest successfully handles augmented classes and improves performance, with code publicly available."}}
{"id": "2505.09251", "pdf": "https://arxiv.org/pdf/2505.09251", "abs": "https://arxiv.org/abs/2505.09251", "authors": ["Vineetha Joy", "Aditya Anand", "Nidhi", "Anshuman Kumar", "Amit Sethi", "Hema Singh"], "title": "A Surrogate Model for the Forward Design of Multi-layered Metasurface-based Radar Absorbing Structures", "categories": ["cs.CV"], "comment": null, "summary": "Metasurface-based radar absorbing structures (RAS) are highly preferred for\napplications like stealth technology, electromagnetic (EM) shielding, etc. due\nto their capability to achieve frequency selective absorption characteristics\nwith minimal thickness and reduced weight penalty. However, the conventional\napproach for the EM design and optimization of these structures relies on\nforward simulations, using full wave simulation tools, to predict the\nelectromagnetic (EM) response of candidate meta atoms. This process is\ncomputationally intensive, extremely time consuming and requires exploration of\nlarge design spaces. To overcome this challenge, we propose a surrogate model\nthat significantly accelerates the prediction of EM responses of multi-layered\nmetasurface-based RAS. A convolutional neural network (CNN) based architecture\nwith Huber loss function has been employed to estimate the reflection\ncharacteristics of the RAS model. The proposed model achieved a cosine\nsimilarity of 99.9% and a mean square error of 0.001 within 1000 epochs of\ntraining. The efficiency of the model has been established via full wave\nsimulations as well as experiment where it demonstrated significant reduction\nin computational time while maintaining high predictive accuracy.", "AI": {"tldr": "A CNN-based surrogate model accelerates EM response prediction for metasurface-based RAS, achieving high accuracy and reduced computational time.", "motivation": "Overcome the computational intensity and time consumption of conventional EM design methods for metasurface-based RAS.", "method": "Uses a CNN with Huber loss function to predict reflection characteristics of RAS.", "result": "Achieved 99.9% cosine similarity and 0.001 MSE, with significant computational time reduction.", "conclusion": "The surrogate model is efficient and accurate, suitable for practical applications in RAS design."}}
{"id": "2505.08037", "pdf": "https://arxiv.org/pdf/2505.08037", "abs": "https://arxiv.org/abs/2505.08037", "authors": ["Yutong Liu", "Feng Xiao", "Ziyue Zhang", "Yongbin Yu", "Cheng Huang", "Fan Gao", "Xiangxiang Wang", "Ma-bao Ban", "Manping Fan", "Thupten Tsering", "Cheng Huang", "Gadeng Luosang", "Renzeng Duojie", "Nyima Tashi"], "title": "TiSpell: A Semi-Masked Methodology for Tibetan Spelling Correction covering Multi-Level Error with Data Augmentation", "categories": ["cs.CL", "cs.LG"], "comment": "14 pages, 7 figures", "summary": "Multi-level Tibetan spelling correction addresses errors at both the\ncharacter and syllable levels within a unified model. Existing methods focus\nmainly on single-level correction and lack effective integration of both\nlevels. Moreover, there are no open-source datasets or augmentation methods\ntailored for this task in Tibetan. To tackle this, we propose a data\naugmentation approach using unlabeled text to generate multi-level corruptions,\nand introduce TiSpell, a semi-masked model capable of correcting both\ncharacter- and syllable-level errors. Although syllable-level correction is\nmore challenging due to its reliance on global context, our semi-masked\nstrategy simplifies this process. We synthesize nine types of corruptions on\nclean sentences to create a robust training set. Experiments on both simulated\nand real-world data demonstrate that TiSpell, trained on our dataset,\noutperforms baseline models and matches the performance of state-of-the-art\napproaches, confirming its effectiveness.", "AI": {"tldr": "TiSpell is a semi-masked model for multi-level Tibetan spelling correction, outperforming baselines by leveraging data augmentation and a unified approach for character- and syllable-level errors.", "motivation": "Existing methods lack integration for multi-level correction and lack tailored datasets for Tibetan spelling errors.", "method": "Proposes data augmentation with unlabeled text and introduces TiSpell, a semi-masked model for correcting both character- and syllable-level errors.", "result": "TiSpell outperforms baselines and matches state-of-the-art performance on simulated and real-world data.", "conclusion": "TiSpell is effective for multi-level Tibetan spelling correction, addressing gaps in existing methods."}}
{"id": "2505.09040", "pdf": "https://arxiv.org/pdf/2505.09040", "abs": "https://arxiv.org/abs/2505.09040", "authors": ["Owen Kwon", "Abraham George", "Alison Bartsch", "Amir Barati Farimani"], "title": "RT-cache: Efficient Robot Trajectory Retrieval System", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "9 pages, 5 figures. Submitted to an IEEE robotics conference", "summary": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation.", "AI": {"tldr": "RT-cache accelerates robot inference by retrieving and reusing past successful trajectories, reducing latency and improving task success.", "motivation": "High per-step inference costs in Vision-Language-Action (VLA) models cause significant latency, prompting the need for a faster, data-driven solution.", "method": "RT-cache uses a large-scale memory of past trajectories, integrating a Memory Builder and Trajectory Retrieval for efficient retrieval and replay of motion snippets.", "result": "Experiments show RT-cache completes tasks faster and more successfully than baselines without retrieval.", "conclusion": "RT-cache offers a practical, data-driven approach for real-time robot manipulation by leveraging past experiences."}}
{"id": "2505.09308", "pdf": "https://arxiv.org/pdf/2505.09308", "abs": "https://arxiv.org/abs/2505.09308", "authors": ["George Andriopoulos", "Soyuj Jung Basnet", "Juan Guevara", "Li Guo", "Keith Ross"], "title": "Neural Multivariate Regression: Qualitative Insights from the Unconstrained Feature Model", "categories": ["cs.LG"], "comment": "31 pages, 8 figures", "summary": "The Unconstrained Feature Model (UFM) is a mathematical framework that\nenables closed-form approximations for minimal training loss and related\nperformance measures in deep neural networks (DNNs). This paper leverages the\nUFM to provide qualitative insights into neural multivariate regression, a\ncritical task in imitation learning, robotics, and reinforcement learning.\nSpecifically, we address two key questions: (1) How do multi-task models\ncompare to multiple single-task models in terms of training performance? (2)\nCan whitening and normalizing regression targets improve training performance?\nThe UFM theory predicts that multi-task models achieve strictly smaller\ntraining MSE than multiple single-task models when the same or stronger\nregularization is applied to the latter, and our empirical results confirm\nthese findings. Regarding whitening and normalizing regression targets, the UFM\ntheory predicts that they reduce training MSE when the average variance across\nthe target dimensions is less than one, and our empirical results once again\nconfirm these findings. These findings highlight the UFM as a powerful\nframework for deriving actionable insights into DNN design and data\npre-processing strategies.", "AI": {"tldr": "The Unconstrained Feature Model (UFM) provides closed-form approximations for DNN performance, showing multi-task models outperform single-task ones under certain conditions, and whitening/normalizing targets reduces MSE when average variance is <1.", "motivation": "To understand and improve neural multivariate regression in DNNs, particularly for imitation learning, robotics, and reinforcement learning.", "method": "Leverages UFM to analyze multi-task vs. single-task models and the impact of whitening/normalizing regression targets.", "result": "Multi-task models achieve lower training MSE than single-task models with comparable regularization; whitening/normalizing reduces MSE when target variance is <1.", "conclusion": "UFM is a valuable tool for guiding DNN design and data pre-processing strategies."}}
{"id": "2505.09252", "pdf": "https://arxiv.org/pdf/2505.09252", "abs": "https://arxiv.org/abs/2505.09252", "authors": ["Yinuo Wang", "Yue Zeng", "Kai Chen", "Cai Meng", "Chao Pan", "Zhouping Tang"], "title": "Zero-Shot Multi-modal Large Language Model v.s. Supervised Deep Learning: A Comparative Study on CT-Based Intracranial Hemorrhage Subtyping", "categories": ["cs.CV"], "comment": null, "summary": "Introduction: Timely identification of intracranial hemorrhage (ICH) subtypes\non non-contrast computed tomography is critical for prognosis prediction and\ntherapeutic decision-making, yet remains challenging due to low contrast and\nblurring boundaries. This study evaluates the performance of zero-shot\nmulti-modal large language models (MLLMs) compared to traditional deep learning\nmethods in ICH binary classification and subtyping. Methods: We utilized a\ndataset provided by RSNA, comprising 192 NCCT volumes. The study compares\nvarious MLLMs, including GPT-4o, Gemini 2.0 Flash, and Claude 3.5 Sonnet V2,\nwith conventional deep learning models, including ResNet50 and Vision\nTransformer. Carefully crafted prompts were used to guide MLLMs in tasks such\nas ICH presence, subtype classification, localization, and volume estimation.\nResults: The results indicate that in the ICH binary classification task,\ntraditional deep learning models outperform MLLMs comprehensively. For subtype\nclassification, MLLMs also exhibit inferior performance compared to traditional\ndeep learning models, with Gemini 2.0 Flash achieving an macro-averaged\nprecision of 0.41 and a macro-averaged F1 score of 0.31. Conclusion: While\nMLLMs excel in interactive capabilities, their overall accuracy in ICH\nsubtyping is inferior to deep networks. However, MLLMs enhance interpretability\nthrough language interactions, indicating potential in medical imaging\nanalysis. Future efforts will focus on model refinement and developing more\nprecise MLLMs to improve performance in three-dimensional medical image\nprocessing.", "AI": {"tldr": "Zero-shot MLLMs underperform traditional deep learning models in ICH binary classification and subtyping, but offer better interpretability.", "motivation": "To evaluate the performance of zero-shot MLLMs vs. traditional deep learning in ICH classification and subtyping due to challenges like low contrast and blurring boundaries.", "method": "Compared MLLMs (GPT-4o, Gemini 2.0 Flash, Claude 3.5 Sonnet V2) with deep learning models (ResNet50, Vision Transformer) using RSNA dataset of 192 NCCT volumes. Tasks included ICH presence, subtype classification, localization, and volume estimation.", "result": "Traditional deep learning models outperformed MLLMs in binary classification and subtyping. Gemini 2.0 Flash scored poorly (macro-averaged precision: 0.41, F1: 0.31).", "conclusion": "MLLMs lag in accuracy but improve interpretability. Future work aims to refine MLLMs for 3D medical image processing."}}
{"id": "2505.08167", "pdf": "https://arxiv.org/pdf/2505.08167", "abs": "https://arxiv.org/abs/2505.08167", "authors": ["Ruilin Liu", "Zhixiao Zhao", "Jieqiong Li", "Chang Liu", "Dongbo Wang"], "title": "Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 5 figures", "summary": "The rapid development of large language models (LLMs) has provided\nsignificant support and opportunities for the advancement of domain-specific\nLLMs. However, fine-tuning these large models using Intangible Cultural\nHeritage (ICH) data inevitably faces challenges such as bias, incorrect\nknowledge inheritance, and catastrophic forgetting. To address these issues, we\npropose a novel training method that integrates a bidirectional chains of\nthought and a reward mechanism. This method is built upon ICH-Qwen, a large\nlanguage model specifically designed for the field of intangible cultural\nheritage. The proposed method enables the model to not only perform forward\nreasoning but also enhances the accuracy of the generated answers by utilizing\nreverse questioning and reverse reasoning to activate the model's latent\nknowledge. Additionally, a reward mechanism is introduced during training to\noptimize the decision-making process. This mechanism improves the quality of\nthe model's outputs through structural and content evaluations with different\nweighting schemes. We conduct comparative experiments on ICH-Qwen, with results\ndemonstrating that our method outperforms 0-shot, step-by-step reasoning,\nknowledge distillation, and question augmentation methods in terms of accuracy,\nBleu-4, and Rouge-L scores on the question-answering task. Furthermore, the\npaper highlights the effectiveness of combining the bidirectional chains of\nthought and reward mechanism through ablation experiments. In addition, a\nseries of generalizability experiments are conducted, with results showing that\nthe proposed method yields improvements on various domain-specific datasets and\nadvanced models in areas such as Finance, Wikidata, and StrategyQA. This\ndemonstrates that the method is adaptable to multiple domains and provides a\nvaluable approach for model training in future applications across diverse\nfields.", "AI": {"tldr": "A novel training method combining bidirectional chains of thought and a reward mechanism improves domain-specific LLMs, addressing bias and knowledge issues in ICH data.", "motivation": "Challenges like bias, incorrect knowledge inheritance, and catastrophic forgetting in fine-tuning LLMs with ICH data necessitate a robust training approach.", "method": "Proposes bidirectional chains of thought (forward and reverse reasoning) and a reward mechanism for optimizing decision-making and output quality.", "result": "Outperforms baseline methods (0-shot, step-by-step reasoning, etc.) in accuracy, Bleu-4, and Rouge-L scores, and shows generalizability across domains.", "conclusion": "The method is adaptable and effective for diverse domains, offering a promising approach for future LLM training."}}
{"id": "2505.09062", "pdf": "https://arxiv.org/pdf/2505.09062", "abs": "https://arxiv.org/abs/2505.09062", "authors": ["Junda Zhao", "Yuliang Song", "Eldan Cohen"], "title": "Variational Prefix Tuning for Diverse and Accurate Code Summarization Using Pre-trained Language Models", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.7"], "comment": "Accepted by the Journal of Systems and Software", "summary": "Recent advancements in source code summarization have leveraged\ntransformer-based pre-trained models, including Large Language Models of Code\n(LLMCs), to automate and improve the generation of code summaries. However,\nexisting methods often focus on generating a single high-quality summary for a\ngiven source code, neglecting scenarios where the generated summary might be\ninadequate and alternative options are needed. In this paper, we introduce\nVariational Prefix Tuning (VPT), a novel approach that enhances pre-trained\nmodels' ability to generate diverse yet accurate sets of summaries, allowing\nthe user to choose the most suitable one for the given source code. Our method\nintegrates a Conditional Variational Autoencoder (CVAE) framework as a modular\ncomponent into pre-trained models, enabling us to model the distribution of\nobserved target summaries and sample continuous embeddings to be used as\nprefixes to steer the generation of diverse outputs during decoding.\nImportantly, we construct our method in a parameter-efficient manner,\neliminating the need for expensive model retraining, especially when using\nLLMCs. Furthermore, we employ a bi-criteria reranking method to select a subset\nof generated summaries, optimizing both the diversity and the accuracy of the\noptions presented to users. We present extensive experimental evaluations using\nwidely used datasets and current state-of-the-art pre-trained code\nsummarization models to demonstrate the effectiveness of our approach and its\nadaptability across models.", "AI": {"tldr": "The paper introduces Variational Prefix Tuning (VPT), a method to generate diverse and accurate code summaries using pre-trained models, addressing the limitation of single-summary approaches.", "motivation": "Existing methods generate only one summary per code snippet, which may be inadequate, lacking diversity for user choice.", "method": "VPT integrates a Conditional Variational Autoencoder (CVAE) into pre-trained models to sample diverse summaries efficiently, without retraining. A bi-criteria reranking optimizes diversity and accuracy.", "result": "Experiments show VPT's effectiveness and adaptability across models, providing diverse and accurate summary options.", "conclusion": "VPT enhances pre-trained models for diverse summary generation, offering practical and efficient solutions for code summarization."}}
{"id": "2505.09331", "pdf": "https://arxiv.org/pdf/2505.09331", "abs": "https://arxiv.org/abs/2505.09331", "authors": ["Cunlai Pu", "Fangrui Wu", "Rajput Ramiz Sharafat", "Guangzhao Dai", "Xiangbo Shu"], "title": "MUST: Multi-Scale Structural-Temporal Link Prediction Model for UAV Ad Hoc Networks", "categories": ["cs.LG"], "comment": null, "summary": "Link prediction in unmanned aerial vehicle (UAV) ad hoc networks (UANETs)\naims to predict the potential formation of future links between UAVs. In\nadversarial environments where the route information of UAVs is unavailable,\npredicting future links must rely solely on the observed historical topological\ninformation of UANETs. However, the highly dynamic and sparse nature of UANET\ntopologies presents substantial challenges in effectively capturing meaningful\nstructural and temporal patterns for accurate link prediction. Most existing\nlink prediction methods focus on temporal dynamics at a single structural scale\nwhile neglecting the effects of sparsity, resulting in insufficient information\ncapture and limited applicability to UANETs. In this paper, we propose a\nmulti-scale structural-temporal link prediction model (MUST) for UANETs.\nSpecifically, we first employ graph attention networks (GATs) to capture\nstructural features at multiple levels, including the individual UAV level, the\nUAV community level, and the overall network level. Then, we use long\nshort-term memory (LSTM) networks to learn the temporal dynamics of these\nmulti-scale structural features. Additionally, we address the impact of\nsparsity by introducing a sophisticated loss function during model\noptimization. We validate the performance of MUST using several UANET datasets\ngenerated through simulations. Extensive experimental results demonstrate that\nMUST achieves state-of-the-art link prediction performance in highly dynamic\nand sparse UANETs.", "AI": {"tldr": "Proposes MUST, a multi-scale structural-temporal model for link prediction in UAV networks, addressing sparsity and dynamics with GATs and LSTMs.", "motivation": "Link prediction in UAV networks is challenging due to dynamic, sparse topologies and lack of route info, requiring methods beyond single-scale temporal dynamics.", "method": "Uses GATs for multi-scale structural features (individual, community, network levels) and LSTMs for temporal dynamics, with a specialized loss function for sparsity.", "result": "MUST outperforms existing methods in highly dynamic, sparse UAV networks, validated by simulation datasets.", "conclusion": "MUST effectively captures structural-temporal patterns and addresses sparsity, achieving state-of-the-art link prediction in UAV networks."}}
{"id": "2505.09256", "pdf": "https://arxiv.org/pdf/2505.09256", "abs": "https://arxiv.org/abs/2505.09256", "authors": ["Jaemin Jung", "Youngjoon Jang", "Joon Son Chung"], "title": "Test-Time Augmentation for Pose-invariant Face Recognition", "categories": ["cs.CV"], "comment": null, "summary": "The goal of this paper is to enhance face recognition performance by\naugmenting head poses during the testing phase. Existing methods often rely on\ntraining on frontalised images or learning pose-invariant representations, yet\nboth approaches typically require re-training and testing for each dataset,\ninvolving a substantial amount of effort. In contrast, this study proposes\nPose-TTA, a novel approach that aligns faces at inference time without\nadditional training. To achieve this, we employ a portrait animator that\ntransfers the source image identity into the pose of a driving image. Instead\nof frontalising a side-profile face -- which can introduce distortion --\nPose-TTA generates matching side-profile images for comparison, thereby\nreducing identity information loss. Furthermore, we propose a weighted feature\naggregation strategy to address any distortions or biases arising from the\nsynthetic data, thus enhancing the reliability of the augmented images.\nExtensive experiments on diverse datasets and with various pre-trained face\nrecognition models demonstrate that Pose-TTA consistently improves inference\nperformance. Moreover, our method is straightforward to integrate into existing\nface recognition pipelines, as it requires no retraining or fine-tuning of the\nunderlying recognition models.", "AI": {"tldr": "Pose-TTA enhances face recognition by aligning faces at inference time without retraining, using a portrait animator and weighted feature aggregation to reduce distortion and improve performance.", "motivation": "Existing face recognition methods require retraining for each dataset, which is effort-intensive. This paper aims to improve performance without additional training.", "method": "Proposes Pose-TTA, which aligns faces at inference time using a portrait animator and weighted feature aggregation to handle synthetic data distortions.", "result": "Pose-TTA consistently improves inference performance across diverse datasets and pre-trained models, with no need for retraining.", "conclusion": "Pose-TTA is an effective, easy-to-integrate solution for enhancing face recognition without retraining, addressing pose-related challenges."}}
{"id": "2505.08435", "pdf": "https://arxiv.org/pdf/2505.08435", "abs": "https://arxiv.org/abs/2505.08435", "authors": ["Mehran Sarmadi", "Morteza Alikhani", "Erfan Zinvandi", "Zahra Pourbahman"], "title": "Hakim: Farsi Text Embedding Model", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advancements in text embedding have significantly improved natural\nlanguage understanding across many languages, yet Persian remains notably\nunderrepresented in large-scale embedding research. In this paper, we present\nHakim, a novel state-of-the-art Persian text embedding model that achieves a\n8.5% performance improvement over existing approaches on the FaMTEB benchmark,\noutperforming all previously developed Persian language models. As part of this\nwork, we introduce three new datasets - Corpesia, Pairsia-sup, and\nPairsia-unsup - to support supervised and unsupervised training scenarios.\nAdditionally, Hakim is designed for applications in chatbots and\nretrieval-augmented generation (RAG) systems, particularly addressing retrieval\ntasks that require incorporating message history within these systems. We also\npropose a new baseline model built on the BERT architecture. Our language model\nconsistently achieves higher accuracy across various Persian NLP tasks, while\nthe RetroMAE-based model proves particularly effective for textual information\nretrieval applications. Together, these contributions establish a new\nfoundation for advancing Persian language understanding.", "AI": {"tldr": "Hakim, a new Persian text embedding model, outperforms existing methods by 8.5% on FaMTEB, introduces new datasets, and supports chatbot and RAG applications.", "motivation": "Persian is underrepresented in text embedding research, prompting the development of Hakim to address this gap.", "method": "Hakim leverages a BERT-based baseline and RetroMAE for retrieval tasks, supported by three new datasets (Corpesia, Pairsia-sup, Pairsia-unsup).", "result": "Hakim achieves state-of-the-art performance on Persian NLP tasks and excels in retrieval applications.", "conclusion": "Hakim advances Persian language understanding and sets a new benchmark for future research."}}
{"id": "2505.09108", "pdf": "https://arxiv.org/pdf/2505.09108", "abs": "https://arxiv.org/abs/2505.09108", "authors": ["Fernando Cladera", "Zachary Ravichandran", "Jason Hughes", "Varun Murali", "Carlos Nieto-Granda", "M. Ani Hsieh", "George J. Pappas", "Camillo J. Taylor", "Vijay Kumar"], "title": "Air-Ground Collaboration for Language-Specified Missions in Unknown Environments", "categories": ["cs.RO", "cs.AI"], "comment": "19 pages, 24 figures, 7 tables. Submitted to T-FR", "summary": "As autonomous robotic systems become increasingly mature, users will want to\nspecify missions at the level of intent rather than in low-level detail.\nLanguage is an expressive and intuitive medium for such mission specification.\nHowever, realizing language-guided robotic teams requires overcoming\nsignificant technical hurdles. Interpreting and realizing language-specified\nmissions requires advanced semantic reasoning. Successful heterogeneous robots\nmust effectively coordinate actions and share information across varying\nviewpoints. Additionally, communication between robots is typically\nintermittent, necessitating robust strategies that leverage communication\nopportunities to maintain coordination and achieve mission objectives. In this\nwork, we present a first-of-its-kind system where an unmanned aerial vehicle\n(UAV) and an unmanned ground vehicle (UGV) are able to collaboratively\naccomplish missions specified in natural language while reacting to changes in\nspecification on the fly. We leverage a Large Language Model (LLM)-enabled\nplanner to reason over semantic-metric maps that are built online and\nopportunistically shared between an aerial and a ground robot. We consider\ntask-driven navigation in urban and rural areas. Our system must infer\nmission-relevant semantics and actively acquire information via semantic\nmapping. In both ground and air-ground teaming experiments, we demonstrate our\nsystem on seven different natural-language specifications at up to\nkilometer-scale navigation.", "AI": {"tldr": "A system enables UAV and UGV to collaboratively execute natural-language missions using LLM-enabled planning and semantic-metric maps, tested in urban/rural navigation.", "motivation": "To allow users to specify robotic missions via natural language, overcoming challenges like semantic reasoning, coordination, and intermittent communication.", "method": "Uses LLM-enabled planner with online semantic-metric maps shared between UAV and UGV for task-driven navigation.", "result": "Demonstrated successful execution of seven natural-language missions at kilometer-scale in ground and air-ground experiments.", "conclusion": "The system effectively bridges language-based mission specification with robotic execution, enabling dynamic collaboration."}}
{"id": "2505.09344", "pdf": "https://arxiv.org/pdf/2505.09344", "abs": "https://arxiv.org/abs/2505.09344", "authors": ["Gabriel Cort\u00eas", "Nuno Louren\u00e7o", "Paolo Romano", "Penousal Machado"], "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces.", "AI": {"tldr": "GreenFactory is an ensemble of zero-cost proxies using a random forest regressor to predict model test accuracy, outperforming traditional methods in Neural Architecture Search.", "motivation": "Traditional performance evaluation in Neural Architecture Search is resource-intensive, and existing zero-cost proxies lack generalization and accuracy prediction.", "method": "Proposes GreenFactory, an ensemble of zero-cost proxies combined via a random forest regressor to directly predict test accuracy.", "result": "Achieves high Kendall correlations (e.g., 0.907-0.945) on NATS-Bench datasets, demonstrating robust performance prediction.", "conclusion": "GreenFactory reliably predicts model accuracy, addressing limitations of existing proxies and improving efficiency in architecture search."}}
{"id": "2505.09263", "pdf": "https://arxiv.org/pdf/2505.09263", "abs": "https://arxiv.org/abs/2505.09263", "authors": ["Guan Gui", "Bin-Bin Gao", "Jun Liu", "Chengjie Wang", "Yunsheng Wu"], "title": "Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Anomaly detection is a practical and challenging task due to the scarcity of\nanomaly samples in industrial inspection. Some existing anomaly detection\nmethods address this issue by synthesizing anomalies with noise or external\ndata. However, there is always a large semantic gap between synthetic and\nreal-world anomalies, resulting in weak performance in anomaly detection. To\nsolve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen)\nmethod, which guides the diffusion model to generate realistic and diverse\nanomalies with only a few real anomalies, thereby benefiting training anomaly\ndetection models. Specifically, our work is divided into three stages. In the\nfirst stage, we learn the anomaly distribution based on a few given real\nanomalies and inject the learned knowledge into an embedding. In the second\nstage, we use the embedding and given bounding boxes to guide the diffusion\nmodel to generate realistic and diverse anomalies on specific objects (or\ntextures). In the final stage, we propose a weakly-supervised anomaly detection\nmethod to train a more powerful model with generated anomalies. Our method\nbuilds upon DRAEM and DesTSeg as the foundation model and conducts experiments\non the commonly used industrial anomaly detection dataset, MVTec. The\nexperiments demonstrate that our generated anomalies effectively improve the\nmodel performance of both anomaly classification and segmentation tasks\nsimultaneously, \\eg, DRAEM and DseTSeg achieved a 5.8\\% and 1.5\\% improvement\nin AU-PR metric on segmentation task, respectively. The code and generated\nanomalous data are available at https://github.com/gaobb/AnoGen.", "AI": {"tldr": "Proposes AnoGen, a few-shot anomaly-driven generation method using diffusion models to create realistic anomalies, improving anomaly detection performance.", "motivation": "Addresses the semantic gap between synthetic and real-world anomalies by generating realistic anomalies from few samples.", "method": "Three-stage approach: learning anomaly distribution, guiding diffusion models to generate anomalies, and training anomaly detection models with generated data.", "result": "Improves AU-PR metrics by 5.8% and 1.5% for DRAEM and DesTSeg on segmentation tasks.", "conclusion": "AnoGen effectively enhances anomaly detection performance by generating diverse and realistic anomalies."}}
{"id": "2411.03343", "pdf": "https://arxiv.org/pdf/2411.03343", "abs": "https://arxiv.org/abs/2411.03343", "authors": ["Nathalie Kirch", "Constantin Weisser", "Severin Field", "Helen Yannakoudakis", "Stephen Casper"], "title": "What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Jailbreaks have been a central focus of research regarding the safety and\nreliability of large language models (LLMs), yet the mechanisms underlying\nthese attacks remain poorly understood. While previous studies have\npredominantly relied on linear methods to detect jailbreak attempts and model\nrefusals, we take a different approach by examining both linear and non-linear\nfeatures in prompts that lead to successful jailbreaks. First, we introduce a\nnovel dataset comprising 10,800 jailbreak attempts spanning 35 diverse attack\nmethods. Leveraging this dataset, we train probes to classify successful from\nunsuccessful jailbreaks using the latent representations corresponding to\nprompt tokens. Notably, we find that even when probes achieve high accuracy in\npredicting the success of jailbreaks, their performance often fails to\ngeneralize to unseen attack methods. This reveals that different jailbreaking\nstrategies exploit different non-linear, non-universal features. Next, we\ndemonstrate that non-linear probes provide a powerful tool for steering model\nbehavior. Specifically, we use these probes to guide targeted latent space\nperturbations, enabling us to effectively modulate the model's robustness\nagainst jailbreaks. Overall, our findings challenge the assumption that\njailbreaks can be fully understood through linear or simple universal prompt\nfeatures alone, highlighting the importance of a nuanced understanding of the\nmechanisms behind LLM vulnerabilities.", "AI": {"tldr": "The paper investigates jailbreak mechanisms in LLMs, using linear and non-linear features to classify successful attacks. It introduces a dataset of 10,800 attempts and finds that probes struggle to generalize across attack methods, revealing diverse non-linear features. Non-linear probes are shown to modulate model robustness.", "motivation": "To better understand the poorly understood mechanisms of jailbreaks in LLMs, moving beyond linear methods to explore non-linear features.", "method": "Introduces a dataset of 10,800 jailbreak attempts, trains probes using latent representations, and tests generalization. Uses non-linear probes for targeted latent space perturbations.", "result": "Probes achieve high accuracy but fail to generalize across attack methods, indicating diverse non-linear features. Non-linear probes effectively modulate model robustness.", "conclusion": "Jailbreaks cannot be fully understood with linear or universal features alone; nuanced understanding of LLM vulnerabilities is crucial."}}
{"id": "2505.09115", "pdf": "https://arxiv.org/pdf/2505.09115", "abs": "https://arxiv.org/abs/2505.09115", "authors": ["Yu Lun Hsu", "Yun-Rung Chou", "Chiao-Ju Chang", "Yu-Cheng Chang", "Zer-Wei Lee", "Rokas Gipi\u0161kis", "Rachel Li", "Chih-Yuan Shih", "Jen-Kuei Peng", "Hsien-Liang Huang", "Jaw-Shiun Tsai", "Mike Y. Chen"], "title": "PreCare: Designing AI Assistants for Advance Care Planning (ACP) to Enhance Personal Value Exploration, Patient Knowledge, and Decisional Confidence", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Advance Care Planning (ACP) allows individuals to specify their preferred\nend-of-life life-sustaining treatments before they become incapacitated by\ninjury or terminal illness (e.g., coma, cancer, dementia). While online ACP\noffers high accessibility, it lacks key benefits of clinical consultations,\nincluding personalized value exploration, immediate clarification of decision\nconsequences. To bridge this gap, we conducted two formative studies: 1)\nshadowed and interviewed 3 ACP teams consisting of physicians, nurses, and\nsocial workers (18 patients total), and 2) interviewed 14 users of ACP\nwebsites. Building on these insights, we designed PreCare in collaboration with\n6 ACP professionals. PreCare is a website with 3 AI-driven assistants designed\nto guide users through exploring personal values, gaining ACP knowledge, and\nsupporting informed decision-making. A usability study (n=12) showed that\nPreCare achieved a System Usability Scale (SUS) rating of excellent. A\ncomparative evaluation (n=12) showed that PreCare's AI assistants significantly\nimproved exploration of personal values, knowledge, and decisional confidence,\nand was preferred by 92% of participants.", "AI": {"tldr": "PreCare, an AI-driven website, bridges the gap in online Advance Care Planning (ACP) by offering personalized guidance, improving user knowledge, and decisional confidence, with high usability and preference rates.", "motivation": "Online ACP lacks personalized clinical benefits like value exploration and decision clarification. The study aims to enhance online ACP with AI-driven tools.", "method": "Conducted formative studies with ACP teams and website users, then designed PreCare with AI assistants. Evaluated usability and effectiveness via user studies.", "result": "PreCare achieved excellent usability (SUS) and significantly improved value exploration, knowledge, and decisional confidence, preferred by 92% of participants.", "conclusion": "AI-driven PreCare effectively enhances online ACP, offering a viable alternative to clinical consultations with high user satisfaction."}}
{"id": "2505.09354", "pdf": "https://arxiv.org/pdf/2505.09354", "abs": "https://arxiv.org/abs/2505.09354", "authors": ["Guangtai Wang", "Chi-Man Vong", "Jintao Huang"], "title": "Exploiting the Potential Supervision Information of Clean Samples in Partial Label Learning", "categories": ["cs.LG"], "comment": null, "summary": "Diminishing the impact of false-positive labels is critical for conducting\ndisambiguation in partial label learning. However, the existing disambiguation\nstrategies mainly focus on exploiting the characteristics of individual partial\nlabel instances while neglecting the strong supervision information of clean\nsamples randomly lying in the datasets. In this work, we show that clean\nsamples can be collected to offer guidance and enhance the confidence of the\nmost possible candidates. Motivated by the manner of the differentiable count\nloss strat- egy and the K-Nearest-Neighbor algorithm, we proposed a new\ncalibration strategy called CleanSE. Specifically, we attribute the most\nreliable candidates with higher significance under the assumption that for each\nclean sample, if its label is one of the candidates of its nearest neighbor in\nthe representation space, it is more likely to be the ground truth of its\nneighbor. Moreover, clean samples offer help in characterizing the sample\ndistributions by restricting the label counts of each label to a specific\ninterval. Extensive experiments on 3 synthetic benchmarks and 5 real-world PLL\ndatasets showed this calibration strategy can be applied to most of the\nstate-of-the-art PLL methods as well as enhance their performance.", "AI": {"tldr": "The paper introduces CleanSE, a calibration strategy for partial label learning that leverages clean samples to improve disambiguation by enhancing candidate confidence and characterizing sample distributions.", "motivation": "Existing disambiguation strategies in partial label learning neglect the supervision information from clean samples, which can guide and boost confidence in candidate labels.", "method": "CleanSE combines differentiable count loss and K-Nearest-Neighbor to attribute higher significance to reliable candidates and uses clean samples to restrict label counts, improving sample distribution characterization.", "result": "Experiments on synthetic and real-world datasets demonstrate CleanSE's applicability to state-of-the-art PLL methods and its performance enhancement.", "conclusion": "CleanSE effectively utilizes clean samples to improve disambiguation in partial label learning, enhancing the performance of existing methods."}}
{"id": "2505.09264", "pdf": "https://arxiv.org/pdf/2505.09264", "abs": "https://arxiv.org/abs/2505.09264", "authors": ["Bin-Bin Gao"], "title": "Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Unsupervised reconstruction networks using self-attention transformers have\nachieved state-of-the-art performance for multi-class (unified) anomaly\ndetection with a single model. However, these self-attention reconstruction\nmodels primarily operate on target features, which may result in perfect\nreconstruction for both normal and anomaly features due to high consistency\nwith context, leading to failure in detecting anomalies. Additionally, these\nmodels often produce inaccurate anomaly segmentation due to performing\nreconstruction in a low spatial resolution latent space. To enable\nreconstruction models enjoying high efficiency while enhancing their\ngeneralization for unified anomaly detection, we propose a simple yet effective\nmethod that reconstructs normal features and restores anomaly features with\njust One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP\nallows for the first time to reconstruct or restore anomalies with just one\nnormal image prompt, effectively boosting unified anomaly detection\nperformance. Furthermore, we propose a supervised refiner that regresses\nreconstruction errors by using both real normal and synthesized anomalous\nimages, which significantly improves pixel-level anomaly segmentation. OneNIP\noutperforms previous methods on three industry anomaly detection benchmarks:\nMVTec, BTAD, and VisA. The code and pre-trained models are available at\nhttps://github.com/gaobb/OneNIP.", "AI": {"tldr": "OneNIP proposes a method using one normal image prompt to reconstruct normal features and restore anomalies, improving unified anomaly detection and segmentation.", "motivation": "Self-attention reconstruction models struggle with detecting anomalies due to perfect reconstruction of both normal and anomaly features and low-resolution latent space issues.", "method": "OneNIP uses one normal image prompt for reconstruction and restoration, along with a supervised refiner for better anomaly segmentation.", "result": "OneNIP outperforms previous methods on MVTec, BTAD, and VisA benchmarks.", "conclusion": "OneNIP is a simple yet effective solution for enhancing anomaly detection and segmentation performance."}}
{"id": "2502.04405", "pdf": "https://arxiv.org/pdf/2502.04405", "abs": "https://arxiv.org/abs/2502.04405", "authors": ["Long Chen", "Xiaotian Song", "Andy Song", "BaDong Chen", "Jiancheng Lv", "Yanan Sun"], "title": "FAS: Fast ANN-SNN Conversion for Spiking Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Spiking Large Language Models have been shown as a good alternative to LLMs\nin various scenarios. Existing methods for creating Spiking LLMs, i.e., direct\ntraining and ANN-SNN conversion, often suffer from performance degradation and\nrelatively high computational costs. To address these issues, we propose a\nnovel Fast ANN-SNN conversion strategy (FAS) that transforms LLMs into spiking\nLLMs in two stages. The first stage employs a full-parameter fine-tuning of\npre-trained models, so it does not need any direct training from scratch. The\nsecond stage introduces a coarse-to-fine calibration method to reduce\nconversion errors and improve accuracy. Experiments on both language and\nvision-language tasks across four different scales of LLMs demonstrate that FAS\ncan achieve state-of-the-art performance yet with significantly reduced\ninference latency and computational costs. Notably, FAS only takes eight\ntimesteps to achieve an accuracy of 3\\% higher than that of the OPT-7B model,\nwhile reducing energy consumption by 96.63\\%. The source code is available at\nhttps://github.com/lc783/FAS", "AI": {"tldr": "FAS introduces a fast ANN-SNN conversion strategy for Spiking LLMs, improving accuracy and reducing computational costs.", "motivation": "Existing methods for Spiking LLMs suffer from performance degradation and high computational costs.", "method": "FAS uses a two-stage approach: full-parameter fine-tuning and coarse-to-fine calibration.", "result": "FAS achieves higher accuracy with reduced latency and energy consumption, outperforming OPT-7B.", "conclusion": "FAS is an efficient and high-performing method for converting LLMs to Spiking LLMs."}}
{"id": "2505.09142", "pdf": "https://arxiv.org/pdf/2505.09142", "abs": "https://arxiv.org/abs/2505.09142", "authors": ["Seungbeom Choi", "Jeonghoe Goo", "Eunjoo Jeon", "Mingyu Yang", "Minsung Jang"], "title": "ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "13 pages, 5 figures. Cloud-native LLM scheduling system with\n  latency-aware inference optimization", "summary": "We propose ELIS, a serving system for Large Language Models (LLMs) featuring\nan Iterative Shortest Remaining Time First (ISRTF) scheduler designed to\nefficiently manage inference tasks with the shortest remaining tokens. Current\nLLM serving systems often employ a first-come-first-served scheduling strategy,\nwhich can lead to the \"head-of-line blocking\" problem. To overcome this\nlimitation, it is necessary to predict LLM inference times and apply a shortest\njob first scheduling strategy. However, due to the auto-regressive nature of\nLLMs, predicting the inference latency is challenging. ELIS addresses this\nchallenge by training a response length predictor for LLMs using the BGE model,\nan encoder-based state-of-the-art model. Additionally, we have devised the\nISRTF scheduling strategy, an optimization of shortest remaining time first\ntailored to existing LLM iteration batching. To evaluate our work in an\nindustrial setting, we simulate streams of requests based on our study of\nreal-world user LLM serving trace records. Furthermore, we implemented ELIS as\na cloud-native scheduler system on Kubernetes to evaluate its performance in\nproduction environments. Our experimental results demonstrate that ISRTF\nreduces the average job completion time by up to 19.6%.", "AI": {"tldr": "ELIS is a serving system for LLMs with an ISRTF scheduler to manage tasks efficiently by prioritizing those with the shortest remaining tokens, reducing job completion time by up to 19.6%.", "motivation": "Current LLM serving systems use first-come-first-served scheduling, causing head-of-line blocking. Predicting LLM inference times is hard due to their auto-regressive nature.", "method": "ELIS trains a response length predictor using the BGE model and introduces the ISRTF scheduler, optimized for LLM iteration batching. It's implemented on Kubernetes for real-world testing.", "result": "ISRTF reduces average job completion time by up to 19.6%.", "conclusion": "ELIS effectively addresses scheduling inefficiencies in LLM serving, improving performance in production environments."}}
{"id": "2505.09361", "pdf": "https://arxiv.org/pdf/2505.09361", "abs": "https://arxiv.org/abs/2505.09361", "authors": ["Samir Moustafa", "Nils M. Kriege", "Wilfried N. Gansterer"], "title": "Efficient Mixed Precision Quantization in Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have become essential for handling large-scale\ngraph applications. However, the computational demands of GNNs necessitate the\ndevelopment of efficient methods to accelerate inference. Mixed precision\nquantization emerges as a promising solution to enhance the efficiency of GNN\narchitectures without compromising prediction performance. Compared to\nconventional deep learning architectures, GNN layers contain a wider set of\ncomponents that can be quantized, including message passing functions,\naggregation functions, update functions, the inputs, learnable parameters, and\noutputs of these functions. In this paper, we introduce a theorem for efficient\nquantized message passing to aggregate integer messages. It guarantees\nnumerical equality of the aggregated messages using integer values with respect\nto those obtained with full (FP32) precision. Based on this theorem, we\nintroduce the Mixed Precision Quantization for GNN (MixQ-GNN) framework, which\nflexibly selects effective integer bit-widths for all components within GNN\nlayers. Our approach systematically navigates the wide set of possible\nbit-width combinations, addressing the challenge of optimizing efficiency while\naiming at maintaining comparable prediction performance. MixQ-GNN integrates\nwith existing GNN quantization methods, utilizing their graph structure\nadvantages to achieve higher prediction performance. On average, MixQ-GNN\nachieved reductions in bit operations of 5.5x for node classification and 5.1x\nfor graph classification compared to architectures represented in FP32\nprecision.", "AI": {"tldr": "MixQ-GNN introduces mixed precision quantization for GNNs, ensuring efficient inference without performance loss, achieving 5.5x and 5.1x reductions in bit operations for node and graph classification.", "motivation": "The computational demands of GNNs require efficient methods to accelerate inference while maintaining performance.", "method": "MixQ-GNN uses a theorem for quantized message passing and flexibly selects integer bit-widths for GNN components.", "result": "Achieves 5.5x and 5.1x reductions in bit operations for node and graph classification compared to FP32.", "conclusion": "MixQ-GNN effectively balances efficiency and performance in GNN inference through mixed precision quantization."}}
{"id": "2505.09265", "pdf": "https://arxiv.org/pdf/2505.09265", "abs": "https://arxiv.org/abs/2505.09265", "authors": ["Bin-Bin Gao"], "title": "MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by NeurIPS 2024", "summary": "Zero- and few-shot visual anomaly segmentation relies on powerful\nvision-language models that detect unseen anomalies using manually designed\ntextual prompts. However, visual representations are inherently independent of\nlanguage. In this paper, we explore the potential of a pure visual foundation\nmodel as an alternative to widely used vision-language models for universal\nvisual anomaly segmentation. We present a novel paradigm that unifies anomaly\nsegmentation into change segmentation. This paradigm enables us to leverage\nlarge-scale synthetic image pairs, featuring object-level and local region\nchanges, derived from existing image datasets, which are independent of target\nanomaly datasets. We propose a one-prompt Meta-learning framework for Universal\nAnomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and\nthen generalizes well to segment any novel or unseen visual anomalies in the\nreal world. To handle geometrical variations between prompt and query images,\nwe propose a soft feature alignment module that bridges paired-image change\nperception and single-image semantic segmentation. This is the first work to\nachieve universal anomaly segmentation using a pure vision model without\nrelying on special anomaly detection datasets and pre-trained visual-language\nmodels. Our method effectively and efficiently segments any anomalies with only\none normal image prompt and enjoys training-free without guidance from\nlanguage. Our MetaUAS significantly outperforms previous zero-shot, few-shot,\nand even full-shot anomaly segmentation methods. The code and pre-trained\nmodels are available at https://github.com/gaobb/MetaUAS.", "AI": {"tldr": "MetaUAS introduces a pure visual foundation model for universal anomaly segmentation, unifying it with change segmentation and leveraging synthetic data, outperforming existing methods.", "motivation": "Current methods rely on vision-language models, but visual representations are independent of language, prompting exploration of a pure visual alternative.", "method": "Proposes MetaUAS, a one-prompt meta-learning framework trained on synthetic image pairs, with a soft feature alignment module for handling geometrical variations.", "result": "MetaUAS outperforms zero-shot, few-shot, and full-shot anomaly segmentation methods without relying on language or special datasets.", "conclusion": "MetaUAS achieves universal anomaly segmentation efficiently with one normal image prompt, training-free, and language-independent."}}
{"id": "2502.15507", "pdf": "https://arxiv.org/pdf/2502.15507", "abs": "https://arxiv.org/abs/2502.15507", "authors": ["Shashank Kirtania"], "title": "Activation Steering in Neural Theorem Provers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "incorrect explanation for a concept, need to revise and update!", "summary": "Large Language Models (LLMs) have shown promise in proving formal theorems\nusing proof assistants like Lean. However, current state of the art language\nmodels struggles to predict next step in proofs leading practitioners to use\ndifferent sampling techniques to improve LLMs capabilities. We observe that the\nLLM is capable of predicting the correct tactic; however, it faces challenges\nin ranking it appropriately within the set of candidate tactics, affecting the\noverall selection process. To overcome this hurdle, we use activation steering\nto guide LLMs responses to improve the generations at the time of inference.\nOur results suggest that activation steering offers a promising lightweight\nalternative to specialized fine-tuning for enhancing theorem proving\ncapabilities in LLMs, particularly valuable in resource-constrained\nenvironments.", "AI": {"tldr": "Activation steering improves LLMs' theorem proving by guiding tactic selection, offering a lightweight alternative to fine-tuning.", "motivation": "LLMs struggle with ranking correct tactics in proof assistants, hindering their theorem-proving effectiveness.", "method": "Use activation steering to guide LLM responses during inference for better tactic selection.", "result": "Activation steering enhances LLMs' theorem-proving capabilities without extensive fine-tuning.", "conclusion": "Activation steering is a promising, resource-efficient method for improving LLMs in theorem proving."}}
{"id": "2505.09166", "pdf": "https://arxiv.org/pdf/2505.09166", "abs": "https://arxiv.org/abs/2505.09166", "authors": ["Hannu Simonen", "Atte Kiviniemi", "Jonas Oppenlaender"], "title": "An Initial Exploration of Default Images in Text-to-Image Generation", "categories": ["cs.HC", "cs.AI", "H.5.m; I.2.m"], "comment": "16 pages, 6 figures", "summary": "In the creative practice of text-to-image generation (TTI), images are\ngenerated from text prompts. However, TTI models are trained to always yield an\noutput, even if the prompt contains unknown terms. In this case, the model may\ngenerate what we call \"default images\": images that closely resemble each other\nacross many unrelated prompts. We argue studying default images is valuable for\ndesigning better solutions for TTI and prompt engineering. In this paper, we\nprovide the first investigation into default images on Midjourney, a popular\nimage generator. We describe our systematic approach to create input prompts\ntriggering default images, and present the results of our initial experiments\nand several small-scale ablation studies. We also report on a survey study\ninvestigating how default images affect user satisfaction. Our work lays the\nfoundation for understanding default images in TTI and highlights challenges\nand future research directions.", "AI": {"tldr": "The paper investigates 'default images' in text-to-image generation (TTI), where models produce similar outputs for unrelated prompts. It focuses on Midjourney, offering methods to trigger these images and analyzing their impact on user satisfaction.", "motivation": "Understanding default images is crucial for improving TTI models and prompt engineering, as these images reveal limitations in model behavior.", "method": "The study uses systematic prompt creation to trigger default images, conducts experiments, ablation studies, and a user survey.", "result": "Findings highlight the prevalence of default images and their negative impact on user satisfaction.", "conclusion": "The work establishes a foundation for future research on default images in TTI, identifying key challenges and directions."}}
{"id": "2505.09366", "pdf": "https://arxiv.org/pdf/2505.09366", "abs": "https://arxiv.org/abs/2505.09366", "authors": ["SeyedMojtaba Mohasel", "Alireza Afzal Aghaei", "Corey Pew"], "title": "Personalized Control for Lower Limb Prosthesis Using Kolmogorov-Arnold Networks", "categories": ["cs.LG"], "comment": null, "summary": "Objective: This paper investigates the potential of learnable activation\nfunctions in Kolmogorov-Arnold Networks (KANs) for personalized control in a\nlower-limb prosthesis. In addition, user-specific vs. pooled training data is\nevaluated to improve machine learning (ML) and Deep Learning (DL) performance\nfor turn intent prediction.\n  Method: Inertial measurement unit (IMU) data from the shank were collected\nfrom five individuals with lower-limb amputation performing turning tasks in a\nlaboratory setting. Ability to classify an upcoming turn was evaluated for\nMultilayer Perceptron (MLP), Kolmogorov-Arnold Network (KAN), convolutional\nneural network (CNN), and fractional Kolmogorov-Arnold Networks (FKAN). The\ncomparison of MLP and KAN (for ML models) and FKAN and CNN (for DL models)\nassessed the effectiveness of learnable activation functions. Models were\ntrained separately on user-specific and pooled data to evaluate the impact of\ntraining data on their performance.\n  Results: Learnable activation functions in KAN and FKAN did not yield\nsignificant improvement compared to MLP and CNN, respectively. Training on\nuser-specific data yielded superior results compared to pooled data for ML\nmodels ($p < 0.05$). In contrast, no significant difference was observed\nbetween user-specific and pooled training for DL models.\n  Significance: These findings suggest that learnable activation functions may\ndemonstrate distinct advantages in datasets involving more complex tasks and\nlarger volumes. In addition, pooled training showed comparable performance to\nuser-specific training in DL models, indicating that model training for\nprosthesis control can utilize data from multiple participants.", "AI": {"tldr": "The paper explores learnable activation functions in KANs for personalized lower-limb prosthesis control, comparing user-specific vs. pooled training data for turn intent prediction. Results show no significant improvement with learnable activation functions, but user-specific data outperformed pooled data for ML models.", "motivation": "To enhance personalized control in lower-limb prostheses by evaluating learnable activation functions in KANs and the impact of training data (user-specific vs. pooled) on ML/DL performance.", "method": "IMU data from amputees performing turns was used to train MLP, KAN, CNN, and FKAN models. Learnable activation functions in KAN/FKAN were compared to MLP/CNN, and training data impact was assessed.", "result": "Learnable activation functions didn't improve performance significantly. User-specific data outperformed pooled data for ML models, but no difference was seen in DL models.", "conclusion": "Learnable activation functions may benefit more complex tasks. Pooled training is viable for DL models in prosthesis control, reducing reliance on user-specific data."}}
{"id": "2505.09274", "pdf": "https://arxiv.org/pdf/2505.09274", "abs": "https://arxiv.org/abs/2505.09274", "authors": ["Fares Bougourzi", "Abdenour Hadid"], "title": "Recent Advances in Medical Imaging Segmentation: A Survey", "categories": ["cs.CV"], "comment": null, "summary": "Medical imaging is a cornerstone of modern healthcare, driving advancements\nin diagnosis, treatment planning, and patient care. Among its various tasks,\nsegmentation remains one of the most challenging problem due to factors such as\ndata accessibility, annotation complexity, structural variability, variation in\nmedical imaging modalities, and privacy constraints. Despite recent progress,\nachieving robust generalization and domain adaptation remains a significant\nhurdle, particularly given the resource-intensive nature of some proposed\nmodels and their reliance on domain expertise. This survey explores\ncutting-edge advancements in medical image segmentation, focusing on\nmethodologies such as Generative AI, Few-Shot Learning, Foundation Models, and\nUniversal Models. These approaches offer promising solutions to longstanding\nchallenges. We provide a comprehensive overview of the theoretical foundations,\nstate-of-the-art techniques, and recent applications of these methods. Finally,\nwe discuss inherent limitations, unresolved issues, and future research\ndirections aimed at enhancing the practicality and accessibility of\nsegmentation models in medical imaging. We are maintaining a\n\\href{https://github.com/faresbougourzi/Awesome-DL-for-Medical-Imaging-Segmentation}{GitHub\nRepository} to continue tracking and updating innovations in this field.", "AI": {"tldr": "A survey on advancements in medical image segmentation, focusing on Generative AI, Few-Shot Learning, Foundation Models, and Universal Models, addressing challenges like generalization and domain adaptation.", "motivation": "Medical image segmentation is critical but faces challenges like data accessibility, annotation complexity, and domain variability. Robust solutions are needed to improve healthcare applications.", "method": "The paper reviews methodologies such as Generative AI, Few-Shot Learning, Foundation Models, and Universal Models, providing theoretical foundations and state-of-the-art techniques.", "result": "The survey highlights promising solutions to segmentation challenges but notes limitations and unresolved issues.", "conclusion": "Future research should focus on enhancing practicality and accessibility of segmentation models, with ongoing updates tracked via a GitHub repository."}}
{"id": "2502.15823", "pdf": "https://arxiv.org/pdf/2502.15823", "abs": "https://arxiv.org/abs/2502.15823", "authors": ["Wenyue Hua", "Tyler Wong", "Sun Fei", "Liangming Pan", "Adam Jardine", "William Yang Wang"], "title": "InductionBench: LLMs Fail in the Simplest Complexity Class", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.FL"], "comment": "25 pages, 10 figures, more details including examples and prompts are\n  added", "summary": "Large language models (LLMs) have shown remarkable improvements in reasoning\nand many existing benchmarks have been addressed by models such as o1 and o3\neither fully or partially. However, a majority of these benchmarks emphasize\ndeductive reasoning, including mathematical and coding tasks in which rules\nsuch as mathematical axioms or programming syntax are clearly defined, based on\nwhich LLMs can plan and apply these rules to arrive at a solution. In contrast,\ninductive reasoning, where one infers the underlying rules from observed data,\nremains less explored. Such inductive processes lie at the heart of scientific\ndiscovery, as they enable researchers to extract general principles from\nempirical observations. To assess whether LLMs possess this capacity, we\nintroduce InductionBench, a new benchmark designed to evaluate the inductive\nreasoning ability of LLMs. Our experimental findings reveal that even the most\nadvanced models available struggle to master the simplest complexity classes\nwithin the subregular hierarchy of functions, highlighting a notable deficiency\nin current LLMs' inductive reasoning capabilities. Coda and data are available\nhttps://github.com/Wenyueh/inductive_reasoning_benchmark.", "AI": {"tldr": "The paper introduces InductionBench, a benchmark to evaluate LLMs' inductive reasoning, finding current models struggle with basic tasks.", "motivation": "Existing benchmarks focus on deductive reasoning, leaving inductive reasoning, crucial for scientific discovery, underexplored.", "method": "Developed InductionBench to test LLMs' ability to infer rules from data.", "result": "Advanced LLMs perform poorly on simple inductive tasks.", "conclusion": "Current LLMs lack strong inductive reasoning capabilities, highlighting a gap for future research."}}
{"id": "2505.09203", "pdf": "https://arxiv.org/pdf/2505.09203", "abs": "https://arxiv.org/abs/2505.09203", "authors": ["Xiao-Qi Han", "Peng-Jie Guo", "Ze-Feng Gao", "Hao Sun", "Zhong-Yi Lu"], "title": "InvDesFlow-AL: Active Learning-based Workflow for Inverse Design of Functional Materials", "categories": ["cond-mat.mtrl-sci", "cond-mat.supr-con", "cs.AI", "cs.LG"], "comment": "29 pages, 11 figures", "summary": "Developing inverse design methods for functional materials with specific\nproperties is critical to advancing fields like renewable energy, catalysis,\nenergy storage, and carbon capture. Generative models based on diffusion\nprinciples can directly produce new materials that meet performance\nconstraints, thereby significantly accelerating the material design process.\nHowever, existing methods for generating and predicting crystal structures\noften remain limited by low success rates. In this work, we propose a novel\ninverse material design generative framework called InvDesFlow-AL, which is\nbased on active learning strategies. This framework can iteratively optimize\nthe material generation process to gradually guide it towards desired\nperformance characteristics. In terms of crystal structure prediction, the\nInvDesFlow-AL model achieves an RMSE of 0.0423 {\\AA}, representing an 32.96%\nimprovement in performance compared to exsisting generative models.\nAdditionally, InvDesFlow-AL has been successfully validated in the design of\nlow-formation-energy and low-Ehull materials. It can systematically generate\nmaterials with progressively lower formation energies while continuously\nexpanding the exploration across diverse chemical spaces. These results fully\ndemonstrate the effectiveness of the proposed active learning-driven generative\nmodel in accelerating material discovery and inverse design. To further prove\nthe effectiveness of this method, we took the search for BCS superconductors\nunder ambient pressure as an example explored by InvDesFlow-AL. As a result, we\nsuccessfully identified Li\\(_2\\)AuH\\(_6\\) as a conventional BCS superconductor\nwith an ultra-high transition temperature of 140 K. This discovery provides\nstrong empirical support for the application of inverse design in materials\nscience.", "AI": {"tldr": "A novel inverse material design framework, InvDesFlow-AL, uses active learning to optimize material generation, achieving a 32.96% performance improvement in crystal structure prediction and successfully identifying a high-temperature BCS superconductor.", "motivation": "The need for efficient inverse design methods to accelerate the discovery of functional materials for applications like renewable energy and catalysis.", "method": "Proposes InvDesFlow-AL, an active learning-driven generative framework for iterative optimization of material generation towards desired properties.", "result": "Achieves an RMSE of 0.0423 \u00c5 in crystal structure prediction and identifies Li\u2082AuH\u2086 as a BCS superconductor with a 140 K transition temperature.", "conclusion": "InvDesFlow-AL effectively accelerates material discovery and demonstrates the potential of inverse design in materials science."}}
{"id": "2505.09427", "pdf": "https://arxiv.org/pdf/2505.09427", "abs": "https://arxiv.org/abs/2505.09427", "authors": ["Achref Doula", "Max M\u00fchl\u00e4user", "Alejandro Sanchez Guinea"], "title": "SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Large Language Models (LLMs) show growing promise in autonomous driving by\nreasoning over complex traffic scenarios to generate path plans. However, their\ntendencies toward overconfidence, and hallucinations raise critical safety\nconcerns. We introduce SafePath, a modular framework that augments LLM-based\npath planning with formal safety guarantees using conformal prediction.\nSafePath operates in three stages. In the first stage, we use an LLM that\ngenerates a set of diverse candidate paths, exploring possible trajectories\nbased on agent behaviors and environmental cues. In the second stage, SafePath\nfilters out high-risk trajectories while guaranteeing that at least one safe\noption is included with a user-defined probability, through a multiple-choice\nquestion-answering formulation that integrates conformal prediction. In the\nfinal stage, our approach selects the path with the lowest expected collision\nrisk when uncertainty is low or delegates control to a human when uncertainty\nis high. We theoretically prove that SafePath guarantees a safe trajectory with\na user-defined probability, and we show how its human delegation rate can be\ntuned to balance autonomy and safety. Extensive experiments on nuScenes and\nHighway-env show that SafePath reduces planning uncertainty by 77\\% and\ncollision rates by up to 70\\%, demonstrating effectiveness in making LLM-driven\npath planning more safer.", "AI": {"tldr": "SafePath is a modular framework that enhances LLM-based path planning in autonomous driving by integrating conformal prediction for safety guarantees, reducing uncertainty and collision rates.", "motivation": "LLMs in autonomous driving can be overconfident or hallucinate, posing safety risks. SafePath addresses this by ensuring safety guarantees.", "method": "SafePath operates in three stages: generating diverse candidate paths, filtering high-risk trajectories with conformal prediction, and selecting the safest path or delegating to humans.", "result": "SafePath reduces planning uncertainty by 77% and collision rates by up to 70%, proving its effectiveness.", "conclusion": "SafePath successfully balances autonomy and safety in LLM-driven path planning, with tunable human delegation for uncertainty."}}
{"id": "2505.09306", "pdf": "https://arxiv.org/pdf/2505.09306", "abs": "https://arxiv.org/abs/2505.09306", "authors": ["Thijs L van der Plas", "Stephen Law", "Michael JO Pocock"], "title": "Predicting butterfly species presence from satellite imagery using soft contrastive regularisation", "categories": ["cs.CV", "cs.LG"], "comment": "To be published in the 2025 CVPR FGVC12 workshop", "summary": "The growing demand for scalable biodiversity monitoring methods has fuelled\ninterest in remote sensing data, due to its widespread availability and\nextensive coverage. Traditionally, the application of remote sensing to\nbiodiversity research has focused on mapping and monitoring habitats, but with\nincreasing availability of large-scale citizen-science wildlife observation\ndata, recent methods have started to explore predicting multi-species presence\ndirectly from satellite images. This paper presents a new data set for\npredicting butterfly species presence from satellite data in the United\nKingdom. We experimentally optimise a Resnet-based model to predict\nmulti-species presence from 4-band satellite images, and find that this model\nespecially outperforms the mean rate baseline for locations with high species\nbiodiversity. To improve performance, we develop a soft, supervised contrastive\nregularisation loss that is tailored to probabilistic labels (such as\nspecies-presence data), and demonstrate that this improves prediction accuracy.\nIn summary, our new data set and contrastive regularisation method contribute\nto the open challenge of accurately predicting species biodiversity from remote\nsensing data, which is key for efficient biodiversity monitoring.", "AI": {"tldr": "A new dataset and contrastive regularization method are introduced to predict butterfly species presence from satellite images, improving biodiversity monitoring accuracy.", "motivation": "The demand for scalable biodiversity monitoring methods drives the use of remote sensing data, especially with the availability of citizen-science wildlife data.", "method": "A Resnet-based model is optimized to predict multi-species presence from 4-band satellite images, enhanced by a soft, supervised contrastive regularization loss.", "result": "The model outperforms baselines in high-biodiversity areas, and the contrastive regularization improves prediction accuracy.", "conclusion": "The dataset and method advance the challenge of predicting species biodiversity from remote sensing, aiding efficient monitoring."}}
{"id": "2502.16560", "pdf": "https://arxiv.org/pdf/2502.16560", "abs": "https://arxiv.org/abs/2502.16560", "authors": ["Rui Xing", "Boyang Sun", "Kun Zhang", "Preslav Nakov", "Timothy Baldwin", "Jey Han Lau"], "title": "An Analytical Emotion Framework of Rumour Threads on Social Media", "categories": ["cs.AI", "cs.CL", "cs.SI"], "comment": "Accepted to ICWSM 2025 MisD Workshop", "summary": "Rumours in online social media pose significant risks to modern society,\nmotivating the need for better understanding of how they develop. We focus\nspecifically on the interface between emotion and rumours in threaded\ndiscourses, building on the surprisingly sparse literature on the topic which\nhas largely focused on single aspect of emotions within the original rumour\nposts themselves, and largely overlooked the comparative differences between\nrumours and non-rumours. In this work, we take one step further to provide a\ncomprehensive analytical emotion framework with multi-aspect emotion detection,\ncontrasting rumour and non-rumour threads and provide both correlation and\ncausal analysis of emotions. We applied our framework on existing widely-used\nrumour datasets to further understand the emotion dynamics in online social\nmedia threads. Our framework reveals that rumours trigger more negative\nemotions (e.g., anger, fear, pessimism), while non-rumours evoke more positive\nones. Emotions are contagious, rumours spread negativity, non-rumours spread\npositivity. Causal analysis shows surprise bridges rumours and other emotions;\npessimism comes from sadness and fear, while optimism arises from joy and love.", "AI": {"tldr": "The paper analyzes the role of emotions in rumor vs. non-rumor threads in social media, revealing that rumors trigger more negative emotions and spread negativity, while non-rumors evoke positivity.", "motivation": "To understand the emotional dynamics in rumor development, addressing gaps in literature that overlook comparative differences between rumors and non-rumors.", "method": "A comprehensive analytical emotion framework with multi-aspect emotion detection, applied to existing rumor datasets for correlation and causal analysis.", "result": "Rumors trigger negative emotions (anger, fear, pessimism), while non-rumors evoke positive ones. Emotions are contagious, with surprise bridging rumors and other emotions.", "conclusion": "Emotions play a key role in rumor spread, with negativity linked to rumors and positivity to non-rumors, offering insights for better rumor management."}}
{"id": "2505.09208", "pdf": "https://arxiv.org/pdf/2505.09208", "abs": "https://arxiv.org/abs/2505.09208", "authors": ["Lei Fan", "Kunyang Deng", "Fangxue Liu"], "title": "Educational impacts of generative artificial intelligence on learning and performance of engineering students in China", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "With the rapid advancement of generative artificial intelligence(AI), its\npotential applications in higher education have attracted significant\nattention. This study investigated how 148 students from diverse engineering\ndisciplines and regions across China used generative AI, focusing on its impact\non their learning experience and the opportunities and challenges it poses in\nengineering education. Based on the surveyed data, we explored four key areas:\nthe frequency and application scenarios of AI use among engineering students,\nits impact on students' learning and performance, commonly encountered\nchallenges in using generative AI, and future prospects for its adoption in\nengineering education. The results showed that more than half of the\nparticipants reported a positive impact of generative AI on their learning\nefficiency, initiative, and creativity, with nearly half believing it also\nenhanced their independent thinking. However, despite acknowledging improved\nstudy efficiency, many felt their actual academic performance remained largely\nunchanged and expressed concerns about the accuracy and domain-specific\nreliability of generative AI. Our findings provide a first-hand insight into\nthe current benefits and challenges generative AI brings to students,\nparticularly Chinese engineering students, while offering several\nrecommendations, especially from the students' perspective, for effectively\nintegrating generative AI into engineering education.", "AI": {"tldr": "Generative AI positively impacts learning efficiency and creativity among Chinese engineering students, though concerns about accuracy and academic performance persist.", "motivation": "To explore the impact of generative AI on engineering students' learning experiences and identify opportunities and challenges in its adoption.", "method": "Surveyed 148 engineering students across China, analyzing AI usage frequency, learning impact, challenges, and future prospects.", "result": "Over half reported improved learning efficiency and creativity, but concerns about accuracy and unchanged academic performance were noted.", "conclusion": "Generative AI offers benefits but requires careful integration into engineering education, addressing reliability and performance concerns."}}
{"id": "2505.09432", "pdf": "https://arxiv.org/pdf/2505.09432", "abs": "https://arxiv.org/abs/2505.09432", "authors": ["Yuzhou Cao", "Han Bao", "Lei Feng", "Bo An"], "title": "Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenche-Young Losses", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Surrogate regret bounds bridge the gap between the convergence rates of\nsurrogate and target losses, with linear bounds favorable for their lossless\nregret transfer. While convex smooth surrogate losses are appealing in\nparticular due to the efficient estimation and optimization, the existence of a\ntrade-off between the smoothness and linear regret bound has been believed in\nthe community. That being said, the better optimization and estimation\nproperties of convex smooth surrogate losses may inevitably deteriorate after\nundergoing the regret transfer onto a target loss. We overcome this dilemma for\narbitrary discrete target losses by constructing a convex smooth surrogate\nloss, which entails a linear surrogate regret bound composed with a tailored\nprediction link. The construction is based on Fenchel-Young losses generated by\nthe convolutional negentropy, which are equivalent to the infimal convolution\nof a generalized negentropy and the target Bayes risk. Consequently, the\ninfimal convolution enables us to derive a smooth loss while maintaining the\nsurrogate regret bound linear. We additionally benefit from the infimal\nconvolution to have a consistent estimator of the underlying class probability.\nOur results are overall a novel demonstration of how convex analysis penetrates\ninto optimization and statistical efficiency in risk minimization.", "AI": {"tldr": "The paper addresses the trade-off between smoothness and linear regret bounds in surrogate losses, proposing a method to construct convex smooth surrogates with linear regret bounds for discrete target losses.", "motivation": "The community believes in a trade-off between smoothness and linear regret bounds in surrogate losses, which may degrade optimization and estimation properties. The paper aims to overcome this dilemma.", "method": "The authors construct convex smooth surrogate losses using Fenchel-Young losses based on convolutional negentropy, equivalent to infimal convolution of generalized negentropy and target Bayes risk.", "result": "The method maintains a linear surrogate regret bound while ensuring smoothness and provides a consistent estimator of class probability.", "conclusion": "The work demonstrates how convex analysis can enhance optimization and statistical efficiency in risk minimization."}}
{"id": "2505.09329", "pdf": "https://arxiv.org/pdf/2505.09329", "abs": "https://arxiv.org/abs/2505.09329", "authors": ["Jiarun Liu", "Hong-Yu Zhou", "Weijian Huang", "Hao Yang", "Dongning Song", "Tao Tan", "Yong Liang", "Shanshan Wang"], "title": "BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "Scaling up model and data size have demonstrated impressive performance\nimprovement over a wide range of tasks. Despite extensive studies on scaling\nbehaviors for general-purpose tasks, medical images exhibit substantial\ndifferences from natural data. It remains unclear the key factors in developing\nmedical vision foundation models at scale due to the absence of an extensive\nunderstanding of scaling behavior in the medical domain. In this paper, we\nexplored the scaling behavior across model sizes, training algorithms, data\nsizes, and imaging modalities in developing scalable medical vision foundation\nmodels by self-supervised learning. To support scalable pretraining, we\nintroduce BioVFM-21M, a large-scale biomedical image dataset encompassing a\nwide range of biomedical image modalities and anatomies. We observed that\nscaling up does provide benefits but varies across tasks. Additional analysis\nreveals several factors correlated with scaling benefits. Finally, we propose\nBioVFM, a large-scale medical vision foundation model pretrained on 21 million\nbiomedical images, which outperforms the previous state-of-the-art foundation\nmodels across 12 medical benchmarks. Our results highlight that while scaling\nup is beneficial for pursuing better performance, task characteristics, data\ndiversity, pretraining methods, and computational efficiency remain critical\nconsiderations for developing scalable medical foundation models.", "AI": {"tldr": "The paper explores scaling behaviors in medical vision foundation models, introducing BioVFM-21M, a large-scale dataset, and BioVFM, a model outperforming benchmarks.", "motivation": "Understanding scaling behaviors in medical imaging, which differs from natural data, to develop effective foundation models.", "method": "Self-supervised learning with scaling across model sizes, training algorithms, data sizes, and imaging modalities.", "result": "Scaling benefits vary by task; BioVFM outperforms state-of-the-art models on 12 medical benchmarks.", "conclusion": "Scaling improves performance, but task characteristics, data diversity, pretraining methods, and efficiency are crucial."}}
{"id": "2505.09262", "pdf": "https://arxiv.org/pdf/2505.09262", "abs": "https://arxiv.org/abs/2505.09262", "authors": ["Hongxin Xiang", "Ke Li", "Mingquan Liu", "Zhixiang Cheng", "Bin Yao", "Wenjie Du", "Jun Xia", "Li Zeng", "Xin Jin", "Xiangxiang Zeng"], "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling", "categories": ["physics.chem-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science.", "AI": {"tldr": "EDBench introduces a large-scale dataset for electron density (ED) to enhance machine learning force fields (MLFFs), enabling efficient and accurate ED calculations beyond traditional DFT methods.", "motivation": "Existing MLFFs overlook electron density (ED), a critical factor for accurate molecular force fields, due to the lack of large-scale ED data.", "method": "EDBench provides 3.3 million molecules with accurate ED data, derived from PCQM4Mv2, and introduces benchmark tasks for prediction, retrieval, and generation.", "result": "State-of-the-art methods achieve high accuracy in ED tasks, and learning-based approaches reduce computational costs significantly compared to DFT.", "conclusion": "EDBench supports ED-driven research in drug discovery and materials science, offering a foundation for future MLFF advancements."}}
{"id": "2505.09458", "pdf": "https://arxiv.org/pdf/2505.09458", "abs": "https://arxiv.org/abs/2505.09458", "authors": ["Jad Mounayer", "Alicia Tierz", "Jerome Tomezyk", "Chady Ghnatios", "Francisco Chinesta"], "title": "Variational Rank Reduction Autoencoder", "categories": ["cs.LG"], "comment": null, "summary": "Deterministic Rank Reduction Autoencoders (RRAEs) enforce by construction a\nregularization on the latent space by applying a truncated SVD. While this\nregularization makes Autoencoders more powerful, using them for generative\npurposes is counter-intuitive due to their deterministic nature. On the other\nhand, Variational Autoencoders (VAEs) are well known for their generative\nabilities by learning a probabilistic latent space. In this paper, we present\nVariational Rank Reduction Autoencoders (VRRAEs), a model that leverages the\nadvantages of both RRAEs and VAEs. Our claims and results show that when\ncarefully sampling the latent space of RRAEs and further regularizing with the\nKullback-Leibler (KL) divergence (similarly to VAEs), VRRAEs outperform RRAEs\nand VAEs. Additionally, we show that the regularization induced by the SVD not\nonly makes VRRAEs better generators than VAEs, but also reduces the possibility\nof posterior collapse. Our results include a synthetic dataset of a small size\nthat showcases the robustness of VRRAEs against collapse, and three real-world\ndatasets; the MNIST, CelebA, and CIFAR-10, over which VRRAEs are shown to\noutperform both VAEs and RRAEs on many random generation and interpolation\ntasks based on the FID score.", "AI": {"tldr": "VRRAEs combine RRAEs' deterministic regularization with VAEs' probabilistic generative abilities, outperforming both in generation tasks and reducing posterior collapse.", "motivation": "To merge the strengths of RRAEs (deterministic regularization via SVD) and VAEs (probabilistic generative abilities) for improved performance.", "method": "VRRAEs sample RRAEs' latent space and regularize with KL divergence, leveraging SVD-induced regularization.", "result": "VRRAEs outperform RRAEs and VAEs in generation tasks (MNIST, CelebA, CIFAR-10) and resist posterior collapse.", "conclusion": "VRRAEs effectively combine deterministic and probabilistic approaches, enhancing generative performance and robustness."}}
{"id": "2505.09336", "pdf": "https://arxiv.org/pdf/2505.09336", "abs": "https://arxiv.org/abs/2505.09336", "authors": ["Muzammil Behzad"], "title": "Unsupervised Multiview Contrastive Language-Image Joint Learning with Pseudo-Labeled Prompts Via Vision-Language Model for 3D/4D Facial Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce MultiviewVLM, a vision-language model designed\nfor unsupervised contrastive multiview representation learning of facial\nemotions from 3D/4D data. Our architecture integrates pseudo-labels derived\nfrom generated textual prompts to guide implicit alignment of emotional\nsemantics. To capture shared information across multi-views, we propose a joint\nembedding space that aligns multiview representations without requiring\nexplicit supervision. We further enhance the discriminability of our model\nthrough a novel multiview contrastive learning strategy that leverages stable\npositive-negative pair sampling. A gradient-friendly loss function is\nintroduced to promote smoother and more stable convergence, and the model is\noptimized for distributed training to ensure scalability. Extensive experiments\ndemonstrate that MultiviewVLM outperforms existing state-of-the-art methods and\ncan be easily adapted to various real-world applications with minimal\nmodifications.", "AI": {"tldr": "MultiviewVLM is a vision-language model for unsupervised contrastive learning of facial emotions from 3D/4D data, using pseudo-labels and a joint embedding space to align multiview representations. It outperforms state-of-the-art methods.", "motivation": "The paper aims to improve unsupervised representation learning for facial emotions by leveraging multiview data and aligning emotional semantics without explicit supervision.", "method": "The model integrates pseudo-labels from textual prompts, uses a joint embedding space for multiview alignment, and employs a novel contrastive learning strategy with stable pair sampling. A gradient-friendly loss function and distributed training optimization are also introduced.", "result": "MultiviewVLM outperforms existing state-of-the-art methods and is adaptable to real-world applications with minimal modifications.", "conclusion": "The proposed MultiviewVLM effectively learns facial emotion representations from multiview data, demonstrating superior performance and scalability."}}
{"id": "2505.09295", "pdf": "https://arxiv.org/pdf/2505.09295", "abs": "https://arxiv.org/abs/2505.09295", "authors": ["Qiming Wu", "Siqi Li", "Doudou Zhou", "Nan Liu"], "title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring fairness is critical when applying artificial intelligence to\nhigh-stakes domains such as healthcare, where predictive models trained on\nimbalanced and demographically skewed data risk exacerbating existing\ndisparities. Federated learning (FL) enables privacy-preserving collaboration\nacross institutions, but remains vulnerable to both algorithmic bias and\nsubgroup imbalance - particularly when multiple sensitive attributes intersect.\nWe propose FedIDA (Fed erated Learning for Imbalance and D isparity A\nwareness), a framework-agnostic method that combines fairness-aware\nregularization with group-conditional oversampling. FedIDA supports multiple\nsensitive attributes and heterogeneous data distributions without altering the\nconvergence behavior of the underlying FL algorithm. We provide theoretical\nanalysis establishing fairness improvement bounds using Lipschitz continuity\nand concentration inequalities, and show that FedIDA reduces the variance of\nfairness metrics across test sets. Empirical results on both benchmark and\nreal-world clinical datasets confirm that FedIDA consistently improves fairness\nwhile maintaining competitive predictive performance, demonstrating its\neffectiveness for equitable and privacy-preserving modeling in healthcare. The\nsource code is available on GitHub.", "AI": {"tldr": "FedIDA is a federated learning method addressing fairness and imbalance in healthcare AI, combining regularization and oversampling without disrupting FL convergence.", "motivation": "Fairness in AI is crucial for healthcare due to risks of bias from imbalanced and skewed data, especially in federated learning settings.", "method": "FedIDA integrates fairness-aware regularization and group-conditional oversampling, supporting multiple sensitive attributes and heterogeneous data.", "result": "Theoretical and empirical results show FedIDA improves fairness metrics and maintains predictive performance.", "conclusion": "FedIDA effectively enhances fairness in privacy-preserving healthcare AI, with code available for implementation."}}
{"id": "2505.09486", "pdf": "https://arxiv.org/pdf/2505.09486", "abs": "https://arxiv.org/abs/2505.09486", "authors": ["Seyed Roozbeh Razavi Rohani", "Khashayar Khajavi", "Wesley Chung", "Mo Chen", "Sharan Vaswani"], "title": "Preserving Plasticity in Continual Learning with Adaptive Linearity Injection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in 4th Conference on Lifelong Learning Agents (CoLLAs), 2025", "summary": "Loss of plasticity in deep neural networks is the gradual reduction in a\nmodel's capacity to incrementally learn and has been identified as a key\nobstacle to learning in non-stationary problem settings. Recent work has shown\nthat deep linear networks tend to be resilient towards loss of plasticity.\nMotivated by this observation, we propose Adaptive Linearization (AdaLin), a\ngeneral approach that dynamically adapts each neuron's activation function to\nmitigate plasticity loss. Unlike prior methods that rely on regularization or\nperiodic resets, AdaLin equips every neuron with a learnable parameter and a\ngating mechanism that injects linearity into the activation function based on\nits gradient flow. This adaptive modulation ensures sufficient gradient signal\nand sustains continual learning without introducing additional hyperparameters\nor requiring explicit task boundaries. When used with conventional activation\nfunctions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can\nsignificantly improve performance on standard benchmarks, including Random\nLabel and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split\nCIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such\nas class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in\nmitigating plasticity loss in off-policy reinforcement learning agents. We\nperform a systematic set of ablations that show that neuron-level adaptation is\ncrucial for good performance and analyze a number of metrics in the network\nthat might be correlated to loss of plasticity.", "AI": {"tldr": "AdaLin dynamically adapts neuron activation functions to mitigate plasticity loss in deep neural networks, improving performance on benchmarks without extra hyperparameters.", "motivation": "Loss of plasticity hinders continual learning in non-stationary settings; deep linear networks show resilience, inspiring AdaLin.", "method": "AdaLin uses learnable parameters and gating to inject linearity into activation functions based on gradient flow.", "result": "AdaLin improves performance on benchmarks like MNIST, CIFAR-10, and CIFAR-100, and aids in reinforcement learning.", "conclusion": "Neuron-level adaptation is key to mitigating plasticity loss, as shown by AdaLin's success across tasks."}}
{"id": "2505.09358", "pdf": "https://arxiv.org/pdf/2505.09358", "abs": "https://arxiv.org/abs/2505.09358", "authors": ["Bingxin Ke", "Kevin Qu", "Tianfu Wang", "Nando Metzger", "Shengyu Huang", "Bo Li", "Anton Obukhov", "Konrad Schindler"], "title": "Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis", "categories": ["cs.CV", "cs.LG"], "comment": "Journal extension of our CVPR 2024 paper, featuring new tasks,\n  improved efficiency, high-resolution capabilities, and enhanced accessibility", "summary": "The success of deep learning in computer vision over the past decade has\nhinged on large labeled datasets and strong pretrained models. In data-scarce\nsettings, the quality of these pretrained models becomes crucial for effective\ntransfer learning. Image classification and self-supervised learning have\ntraditionally been the primary methods for pretraining CNNs and\ntransformer-based architectures. Recently, the rise of text-to-image generative\nmodels, particularly those using denoising diffusion in a latent space, has\nintroduced a new class of foundational models trained on massive, captioned\nimage datasets. These models' ability to generate realistic images of unseen\ncontent suggests they possess a deep understanding of the visual world. In this\nwork, we present Marigold, a family of conditional generative models and a\nfine-tuning protocol that extracts the knowledge from pretrained latent\ndiffusion models like Stable Diffusion and adapts them for dense image analysis\ntasks, including monocular depth estimation, surface normals prediction, and\nintrinsic decomposition. Marigold requires minimal modification of the\npre-trained latent diffusion model's architecture, trains with small synthetic\ndatasets on a single GPU over a few days, and demonstrates state-of-the-art\nzero-shot generalization. Project page:\nhttps://marigoldcomputervision.github.io", "AI": {"tldr": "Marigold leverages pretrained latent diffusion models (e.g., Stable Diffusion) for dense image analysis tasks like depth estimation, achieving state-of-the-art zero-shot generalization with minimal architecture changes and small synthetic datasets.", "motivation": "Traditional pretraining relies on labeled datasets or self-supervised learning, but text-to-image generative models offer a new, rich source of visual knowledge. Marigold aims to harness this for dense image tasks.", "method": "Marigold fine-tunes pretrained latent diffusion models with a small synthetic dataset, requiring minimal architectural changes and training on a single GPU.", "result": "The model achieves state-of-the-art zero-shot generalization on tasks like monocular depth estimation and surface normals prediction.", "conclusion": "Marigold demonstrates the potential of adapting generative models for dense image analysis, offering efficient and effective transfer learning."}}
{"id": "2505.09342", "pdf": "https://arxiv.org/pdf/2505.09342", "abs": "https://arxiv.org/abs/2505.09342", "authors": ["Mostafa Jafari", "Alireza Shameli-Sendi"], "title": "Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems", "categories": ["cs.CR", "cs.AI", "cs.LG", "68", "I.2.1"], "comment": "Submitted to IEEE Transactions on Information Forensics and Security\n  (T-IFS), 13 pages, 4 figures", "summary": "Machine learning is a key tool for Android malware detection, effectively\nidentifying malicious patterns in apps. However, ML-based detectors are\nvulnerable to evasion attacks, where small, crafted changes bypass detection.\nDespite progress in adversarial defenses, the lack of comprehensive evaluation\nframeworks in binary-constrained domains limits understanding of their\nrobustness. We introduce two key contributions. First, Prioritized Binary\nRounding, a technique to convert continuous perturbations into binary feature\nspaces while preserving high attack success and low perturbation size. Second,\nthe sigma-binary attack, a novel adversarial method for binary domains,\ndesigned to achieve attack goals with minimal feature changes. Experiments on\nthe Malscan dataset show that sigma-binary outperforms existing attacks and\nexposes key vulnerabilities in state-of-the-art defenses. Defenses equipped\nwith adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant\nbrittleness, with attack success rates exceeding 90% using fewer than 10\nfeature modifications and reaching 100% with just 20. Adversarially trained\ndefenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small\nbudgets but remains vulnerable to unrestricted perturbations, with attack\nsuccess rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates\nstrong robustness against state-of-the-art gradient-based adversarial attacks\nby maintaining an attack success rate below 16.55%, the sigma-binary attack\nsignificantly outperforms these methods, achieving a 94.56% success rate under\nunrestricted perturbations. These findings highlight the critical need for\nprecise method like sigma-binary to expose hidden vulnerabilities in existing\ndefenses and support the development of more resilient malware detection\nsystems.", "AI": {"tldr": "The paper introduces Prioritized Binary Rounding and the sigma-binary attack to improve adversarial robustness in binary-constrained ML-based Android malware detection. The sigma-binary attack outperforms existing methods, exposing vulnerabilities in state-of-the-art defenses.", "motivation": "ML-based Android malware detectors are vulnerable to evasion attacks, and existing defenses lack comprehensive evaluation in binary domains.", "method": "Proposes Prioritized Binary Rounding for converting continuous perturbations into binary spaces and the sigma-binary attack for adversarial evasion in binary domains.", "result": "Sigma-binary achieves high attack success rates (up to 94.56%) with minimal feature changes, outperforming existing defenses.", "conclusion": "The findings emphasize the need for precise adversarial methods like sigma-binary to improve robustness in malware detection systems."}}
{"id": "2505.09500", "pdf": "https://arxiv.org/pdf/2505.09500", "abs": "https://arxiv.org/abs/2505.09500", "authors": ["Timothy Qian", "Vinith Suriyakumar", "Ashia Wilson", "Dylan Hadfield-Menell"], "title": "Layered Unlearning for Adversarial Relearning", "categories": ["cs.LG"], "comment": "37 pages, 8 figures", "summary": "Our goal is to understand how post-training methods, such as fine-tuning,\nalignment, and unlearning, modify language model behavior and representations.\nWe are particularly interested in the brittle nature of these modifications\nthat makes them easy to bypass through prompt engineering or relearning. Recent\nresults suggest that post-training induces shallow context-dependent\n``circuits'' that suppress specific response patterns. This could be one\nexplanation for the brittleness of post-training. To test this hypothesis, we\ndesign an unlearning algorithm, Layered Unlearning (LU), that creates distinct\ninhibitory mechanisms for a growing subset of the data. By unlearning the first\n$i$ folds while retaining the remaining $k - i$ at the $i$th of $k$ stages, LU\nlimits the ability of relearning on a subset of data to recover the full\ndataset. We evaluate LU through a combination of synthetic and large language\nmodel (LLM) experiments. We find that LU improves robustness to adversarial\nrelearning for several different unlearning methods. Our results contribute to\nthe state-of-the-art of machine unlearning and provide insight into the effect\nof post-training updates.", "AI": {"tldr": "The paper investigates the brittleness of post-training methods in language models and proposes Layered Unlearning (LU) to improve robustness against adversarial relearning.", "motivation": "To understand how post-training methods modify model behavior and why these modifications are brittle, often bypassed by prompt engineering or relearning.", "method": "Designs an unlearning algorithm, Layered Unlearning (LU), which incrementally unlearns subsets of data to limit relearning recovery. Evaluated using synthetic and LLM experiments.", "result": "LU enhances robustness to adversarial relearning across various unlearning methods.", "conclusion": "LU advances machine unlearning techniques and sheds light on the impact of post-training updates."}}
{"id": "2505.09368", "pdf": "https://arxiv.org/pdf/2505.09368", "abs": "https://arxiv.org/abs/2505.09368", "authors": ["Jenny Schmalfuss", "Victor Oei", "Lukas Mehl", "Madlen Bartsch", "Shashank Agnihotri", "Margret Keuper", "Andr\u00e9s Bruhn"], "title": "RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Standard benchmarks for optical flow, scene flow, and stereo vision\nalgorithms generally focus on model accuracy rather than robustness to image\ncorruptions like noise or rain. Hence, the resilience of models to such\nreal-world perturbations is largely unquantified. To address this, we present\nRobustSpring, a comprehensive dataset and benchmark for evaluating robustness\nto image corruptions for optical flow, scene flow, and stereo models.\nRobustSpring applies 20 different image corruptions, including noise, blur,\ncolor changes, quality degradations, and weather distortions, in a time-,\nstereo-, and depth-consistent manner to the high-resolution Spring dataset,\ncreating a suite of 20,000 corrupted images that reflect challenging\nconditions. RobustSpring enables comparisons of model robustness via a new\ncorruption robustness metric. Integration with the Spring benchmark enables\npublic two-axis evaluations of both accuracy and robustness. We benchmark a\ncurated selection of initial models, observing that accurate models are not\nnecessarily robust and that robustness varies widely by corruption type.\nRobustSpring is a new computer vision benchmark that treats robustness as a\nfirst-class citizen to foster models that combine accuracy with resilience. It\nwill be available at https://spring-benchmark.org.", "AI": {"tldr": "RobustSpring introduces a dataset and benchmark to evaluate model robustness to image corruptions for optical flow, scene flow, and stereo vision, addressing the lack of focus on real-world perturbations in existing benchmarks.", "motivation": "Existing benchmarks prioritize accuracy over robustness to real-world image corruptions, leaving model resilience unquantified.", "method": "RobustSpring applies 20 diverse image corruptions to the Spring dataset, generating 20,000 corrupted images, and introduces a new corruption robustness metric.", "result": "Initial benchmarks show that accurate models are not necessarily robust, and robustness varies by corruption type.", "conclusion": "RobustSpring promotes robustness as a key metric, aiming to foster models that balance accuracy with resilience."}}
{"id": "2505.09343", "pdf": "https://arxiv.org/pdf/2505.09343", "abs": "https://arxiv.org/abs/2505.09343", "authors": ["Chenggang Zhao", "Chengqi Deng", "Chong Ruan", "Damai Dai", "Huazuo Gao", "Jiashi Li", "Liyue Zhang", "Panpan Huang", "Shangyan Zhou", "Shirong Ma", "Wenfeng Liang", "Ying He", "Yuqing Wang", "Yuxuan Liu", "Y. X. Wei"], "title": "Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures", "categories": ["cs.DC", "cs.AI", "cs.AR"], "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive version will appear as\n  part of the Industry Track in Proceedings of the 52nd Annual International\n  Symposium on Computer Architecture (ISCA '25)", "summary": "The rapid scaling of large language models (LLMs) has unveiled critical\nlimitations in current hardware architectures, including constraints in memory\ncapacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3,\ntrained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model\nco-design can effectively address these challenges, enabling cost-efficient\ntraining and inference at scale. This paper presents an in-depth analysis of\nthe DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting\nkey innovations such as Multi-head Latent Attention (MLA) for enhanced memory\nefficiency, Mixture of Experts (MoE) architectures for optimized\ncomputation-communication trade-offs, FP8 mixed-precision training to unlock\nthe full potential of hardware capabilities, and a Multi-Plane Network Topology\nto minimize cluster-level network overhead. Building on the hardware\nbottlenecks encountered during DeepSeek-V3's development, we engage in a\nbroader discussion with academic and industry peers on potential future\nhardware directions, including precise low-precision computation units,\nscale-up and scale-out convergence, and innovations in low-latency\ncommunication fabrics. These insights underscore the critical role of hardware\nand model co-design in meeting the escalating demands of AI workloads, offering\na practical blueprint for innovation in next-generation AI systems.", "AI": {"tldr": "DeepSeek-V3 addresses hardware limitations in LLMs through co-design, featuring innovations like MLA, MoE, FP8 training, and Multi-Plane Network Topology, while discussing future hardware directions.", "motivation": "Current hardware architectures struggle with memory, computation, and bandwidth constraints for scaling LLMs, necessitating hardware-aware model co-design.", "method": "DeepSeek-V3 employs Multi-head Latent Attention, Mixture of Experts, FP8 mixed-precision training, and Multi-Plane Network Topology for efficient training and inference.", "result": "The approach enables cost-efficient scaling of LLMs, addressing key hardware bottlenecks and improving performance.", "conclusion": "Hardware and model co-design is crucial for next-gen AI systems, with future directions including low-precision computation and improved communication fabrics."}}
{"id": "2505.09503", "pdf": "https://arxiv.org/pdf/2505.09503", "abs": "https://arxiv.org/abs/2505.09503", "authors": ["Patrik Kenfack", "Samira Ebrahimi Kaho", "Ulrich A\u00efvodji"], "title": "Towards Fair In-Context Learning with Tabular Foundation Models", "categories": ["cs.LG"], "comment": "24 pages, 10 figures, 4 tables", "summary": "Tabular foundational models have exhibited strong in-context learning (ICL)\ncapabilities on structured data, allowing them to make accurate predictions on\ntest sets without parameter updates, using training examples as context. This\nemerging approach positions itself as a competitive alternative to traditional\ngradient-boosted tree methods. However, while biases in conventional machine\nlearning models are well documented, it remains unclear how these biases\nmanifest in tabular ICL. The paper investigates the fairness implications of\ntabular ICL and explores three preprocessing strategies--correlation removal,\ngroup-balanced demonstration selection, and uncertainty-based demonstration\nselection--to address bias. Comprehensive experiments indicate that\nuncertainty-based demonstration selection consistently enhances group fairness\nof in-context predictions. The source code for reproducing the results of this\nwork can be found at https://github.com/patrikken/Fair-TabICL.", "AI": {"tldr": "The paper explores fairness in tabular in-context learning (ICL), proposing preprocessing strategies to mitigate bias, with uncertainty-based demonstration selection proving most effective.", "motivation": "To understand and address biases in tabular ICL, positioning it as a fair alternative to traditional methods.", "method": "Investigates three preprocessing strategies: correlation removal, group-balanced demonstration selection, and uncertainty-based demonstration selection.", "result": "Uncertainty-based demonstration selection consistently improves group fairness in predictions.", "conclusion": "Tabular ICL can be made fairer with preprocessing, particularly uncertainty-based demonstration selection, enhancing its viability as a competitive method."}}
{"id": "2505.09372", "pdf": "https://arxiv.org/pdf/2505.09372", "abs": "https://arxiv.org/abs/2505.09372", "authors": ["Siyuan Yan", "Xieji Li", "Ming Hu", "Yiwen Jiang", "Zhen Yu", "Zongyuan Ge"], "title": "MAKE: Multi-Aspect Knowledge-Enhanced Vision-Language Pretraining for Zero-shot Dermatological Assessment", "categories": ["cs.CV"], "comment": "MICCAI2025 early acceptance; First two authors contribute equally", "summary": "Dermatological diagnosis represents a complex multimodal challenge that\nrequires integrating visual features with specialized clinical knowledge. While\nvision-language pretraining (VLP) has advanced medical AI, its effectiveness in\ndermatology is limited by text length constraints and the lack of structured\ntexts. In this paper, we introduce MAKE, a Multi-Aspect Knowledge-Enhanced\nvision-language pretraining framework for zero-shot dermatological tasks.\nRecognizing that comprehensive dermatological descriptions require multiple\nknowledge aspects that exceed standard text constraints, our framework\nintroduces: (1) a multi-aspect contrastive learning strategy that decomposes\nclinical narratives into knowledge-enhanced sub-texts through large language\nmodels, (2) a fine-grained alignment mechanism that connects subcaptions with\ndiagnostically relevant image features, and (3) a diagnosis-guided weighting\nscheme that adaptively prioritizes different sub-captions based on clinical\nsignificance prior. Through pretraining on 403,563 dermatological image-text\npairs collected from education resources, MAKE significantly outperforms\nstate-of-the-art VLP models on eight datasets across zero-shot skin disease\nclassification, concept annotation, and cross-modal retrieval tasks. Our code\nwill be made publicly available at https: //github.com/SiyuanYan1/MAKE.", "AI": {"tldr": "MAKE is a Multi-Aspect Knowledge-Enhanced VLP framework for dermatology, improving zero-shot tasks by decomposing clinical narratives and aligning sub-texts with image features.", "motivation": "Existing VLP models struggle with dermatology due to text length constraints and lack of structured texts, limiting their effectiveness.", "method": "MAKE uses multi-aspect contrastive learning, fine-grained alignment, and diagnosis-guided weighting to enhance zero-shot dermatological tasks.", "result": "MAKE outperforms state-of-the-art VLP models on eight datasets for skin disease classification, concept annotation, and cross-modal retrieval.", "conclusion": "MAKE advances dermatological AI by addressing text limitations and improving multimodal integration, with code made publicly available."}}
{"id": "2505.09371", "pdf": "https://arxiv.org/pdf/2505.09371", "abs": "https://arxiv.org/abs/2505.09371", "authors": ["Akash Kundu", "Stefano Mangini"], "title": "TensorRL-QAS: Reinforcement learning with tensor networks for scalable quantum architecture search", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG"], "comment": "The code will be available soon! Comments are welcomed!", "summary": "Variational quantum algorithms hold the promise to address meaningful quantum\nproblems already on noisy intermediate-scale quantum hardware, but they face\nthe challenge of designing quantum circuits that both solve the target problem\nand comply with device limitations. Quantum architecture search (QAS) automates\nthis design process, with reinforcement learning (RL) emerging as a promising\napproach. Yet, RL-based QAS methods encounter significant scalability issues,\nas computational and training costs grow rapidly with the number of qubits,\ncircuit depth, and noise, severely impacting performance. To address these\nchallenges, we introduce $\\textit{TensorRL-QAS}$, a scalable framework that\ncombines tensor network (TN) methods with RL for designing quantum circuits. By\nwarm-starting the architecture search with a matrix product state approximation\nof the target solution, TensorRL-QAS effectively narrows the search space to\nphysically meaningful circuits, accelerating convergence to the desired\nsolution. Tested on several quantum chemistry problems of up to 12-qubit,\nTensorRL-QAS achieves up to a 10-fold reduction in CNOT count and circuit depth\ncompared to baseline methods, while maintaining or surpassing chemical\naccuracy. It reduces function evaluations by up to 100-fold, accelerates\ntraining episodes by up to $98\\%$, and achieves up to $50\\%$ success\nprobability for 10-qubit systems-far exceeding the $<1\\%$ rates of baseline\napproaches. Robustness and versatility are demonstrated both in the noiseless\nand noisy scenarios, where we report a simulation of up to 8-qubit. These\nadvancements establish TensorRL-QAS as a promising candidate for a scalable and\nefficient quantum circuit discovery protocol on near-term quantum hardware.", "AI": {"tldr": "TensorRL-QAS combines tensor networks and reinforcement learning to design scalable quantum circuits, reducing costs and improving performance.", "motivation": "Address scalability issues in RL-based quantum architecture search for noisy intermediate-scale quantum hardware.", "method": "Uses tensor networks to warm-start RL, narrowing the search space to meaningful circuits.", "result": "Achieves up to 10-fold reduction in CNOT count and depth, 100-fold fewer evaluations, and 50% success probability for 10-qubit systems.", "conclusion": "TensorRL-QAS is scalable and efficient for near-term quantum hardware."}}
{"id": "2505.09572", "pdf": "https://arxiv.org/pdf/2505.09572", "abs": "https://arxiv.org/abs/2505.09572", "authors": ["Julian Kranz", "Davide Gallon", "Steffen Dereich", "Arnulf Jentzen"], "title": "SAD Neural Networks: Divergent Gradient Flows and Asymptotic Optimality via o-minimal Structures", "categories": ["cs.LG", "math.LO", "math.OC", "stat.ML", "Primary 68T05, Secondary 68T07, 26B40, 03C64, 03C98"], "comment": "27 pages, 4 figures", "summary": "We study gradient flows for loss landscapes of fully connected feed forward\nneural networks with commonly used continuously differentiable activation\nfunctions such as the logistic, hyperbolic tangent, softplus or GELU function.\nWe prove that the gradient flow either converges to a critical point or\ndiverges to infinity while the loss converges to an asymptotic critical value.\nMoreover, we prove the existence of a threshold $\\varepsilon>0$ such that the\nloss value of any gradient flow initialized at most $\\varepsilon$ above the\noptimal level converges to it. For polynomial target functions and sufficiently\nbig architecture and data set, we prove that the optimal loss value is zero and\ncan only be realized asymptotically. From this setting, we deduce our main\nresult that any gradient flow with sufficiently good initialization diverges to\ninfinity. Our proof heavily relies on the geometry of o-minimal structures. We\nconfirm these theoretical findings with numerical experiments and extend our\ninvestigation to real-world scenarios, where we observe an analogous behavior.", "AI": {"tldr": "The paper analyzes gradient flows in fully connected neural networks with common activation functions, proving convergence or divergence behavior and identifying thresholds for loss convergence.", "motivation": "To understand the behavior of gradient flows in neural networks and their convergence properties under various conditions.", "method": "Theoretical analysis using o-minimal structures and numerical experiments to validate findings.", "result": "Gradient flows either converge to critical points or diverge to infinity, with loss converging to an asymptotic value. A threshold exists for initialization ensuring convergence to optimal loss.", "conclusion": "Gradient flows with good initialization diverge to infinity, and theoretical results align with numerical and real-world observations."}}
{"id": "2505.09379", "pdf": "https://arxiv.org/pdf/2505.09379", "abs": "https://arxiv.org/abs/2505.09379", "authors": ["Ali Rida Sahili", "Najett Neji", "Hedi Tabia"], "title": "Text-driven Motion Generation: Overview, Challenges and Directions", "categories": ["cs.CV"], "comment": "17 pages, 5 tables", "summary": "Text-driven motion generation offers a powerful and intuitive way to create\nhuman movements directly from natural language. By removing the need for\npredefined motion inputs, it provides a flexible and accessible approach to\ncontrolling animated characters. This makes it especially useful in areas like\nvirtual reality, gaming, human-computer interaction, and robotics. In this\nreview, we first revisit the traditional perspective on motion synthesis, where\nmodels focused on predicting future poses from observed initial sequences,\noften conditioned on action labels. We then provide a comprehensive and\nstructured survey of modern text-to-motion generation approaches, categorizing\nthem from two complementary perspectives: (i) architectural, dividing methods\ninto VAE-based, diffusion-based, and hybrid models; and (ii) motion\nrepresentation, distinguishing between discrete and continuous motion\ngeneration strategies. In addition, we explore the most widely used datasets,\nevaluation methods, and recent benchmarks that have shaped progress in this\narea. With this survey, we aim to capture where the field currently stands,\nbring attention to its key challenges and limitations, and highlight promising\ndirections for future exploration. We hope this work offers a valuable starting\npoint for researchers and practitioners working to push the boundaries of\nlanguage-driven human motion synthesis.", "AI": {"tldr": "A survey on text-driven motion generation, covering traditional and modern approaches, datasets, evaluation methods, and future directions.", "motivation": "To provide a flexible and intuitive way to generate human movements from natural language, benefiting fields like VR, gaming, and robotics.", "method": "Categorizes modern text-to-motion methods architecturally (VAE-based, diffusion-based, hybrid) and by motion representation (discrete vs. continuous).", "result": "Summarizes current progress, datasets, benchmarks, and identifies key challenges and limitations.", "conclusion": "Highlights promising future directions and serves as a resource for advancing language-driven motion synthesis."}}
{"id": "2505.09380", "pdf": "https://arxiv.org/pdf/2505.09380", "abs": "https://arxiv.org/abs/2505.09380", "authors": ["Qinghui Liu", "Jon Nesvold", "Hanna Raaum", "Elakkyen Murugesu", "Martin R\u00f8vang", "Bradley J Maclntosh", "Atle Bj\u00f8rnerud", "Karoline Skogen"], "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "19 pages, 11 figures, on submission to BMC Methods", "summary": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback.", "AI": {"tldr": "NeoMedSys, a radiology software platform, improved the performance of VIOLA-AI for intracranial hemorrhage detection through iterative refinements in real-world clinical settings.", "motivation": "To address challenges in deploying AI tools in radiology by enabling efficient deployment and refinement of AI models like VIOLA-AI.", "method": "NeoMedSys integrated tools for AI model deployment, testing, and optimization with a web-based medical image viewer and annotation system. It was tested in clinical settings for TBI and stroke cases, with performance metrics tracked.", "result": "VIOLA-AI showed significant improvements: sensitivity rose to 90.3% (from 79.2%), specificity to 89.3% (from 80.7%), and AUC to 0.949 (from 0.873).", "conclusion": "NeoMedSys effectively enhances AI model performance through iterative refinements and real-time feedback, demonstrating its feasibility in clinical radiology."}}
{"id": "2505.09586", "pdf": "https://arxiv.org/pdf/2505.09586", "abs": "https://arxiv.org/abs/2505.09586", "authors": ["Yipeng Zhang", "Longlong Li", "Kelin Xia"], "title": "Rhomboid Tiling for Geometric Graph Deep Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have proven effective for learning from\ngraph-structured data through their neighborhood-based message passing\nframework. Many hierarchical graph clustering pooling methods modify this\nframework by introducing clustering-based strategies, enabling the construction\nof more expressive and powerful models. However, all of these message passing\nframework heavily rely on the connectivity structure of graphs, limiting their\nability to capture the rich geometric features inherent in geometric graphs. To\naddress this, we propose Rhomboid Tiling (RT) clustering, a novel clustering\nmethod based on the rhomboid tiling structure, which performs clustering by\nleveraging the complex geometric information of the data and effectively\nextracts its higher-order geometric structures. Moreover, we design RTPool, a\nhierarchical graph clustering pooling model based on RT clustering for graph\nclassification tasks. The proposed model demonstrates superior performance,\noutperforming 21 state-of-the-art competitors on all the 7 benchmark datasets.", "AI": {"tldr": "The paper introduces Rhomboid Tiling (RT) clustering and RTPool, a hierarchical graph clustering pooling model, to enhance GNNs by leveraging geometric information, outperforming 21 competitors on 7 datasets.", "motivation": "Existing GNN pooling methods rely on graph connectivity, missing rich geometric features in geometric graphs. RT clustering addresses this gap.", "method": "Proposes RT clustering for geometric feature extraction and RTPool, a hierarchical pooling model for graph classification.", "result": "RTPool outperforms 21 state-of-the-art methods across 7 benchmark datasets.", "conclusion": "RT clustering and RTPool effectively capture geometric structures, enhancing GNN performance for graph classification."}}
{"id": "2505.09385", "pdf": "https://arxiv.org/pdf/2505.09385", "abs": "https://arxiv.org/abs/2505.09385", "authors": ["Xiaoyang Yu", "Xiaoming Wu", "Xin Wang", "Dongrun Li", "Ming Yang", "Peng Cheng"], "title": "FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Federated semantic segmentation enables pixel-level classification in images\nthrough collaborative learning while maintaining data privacy. However,\nexisting research commonly overlooks the fine-grained class relationships\nwithin the semantic space when addressing heterogeneous problems, particularly\ndomain shift. This oversight results in ambiguities between class\nrepresentation. To overcome this challenge, we propose a novel federated\nsegmentation framework that strikes class consistency, termed FedSaaS.\nSpecifically, we introduce class exemplars as a criterion for both local- and\nglobal-level class representations. On the server side, the uploaded class\nexemplars are leveraged to model class prototypes, which supervise global\nbranch of clients, ensuring alignment with global-level representation. On the\nclient side, we incorporate an adversarial mechanism to harmonize contributions\nof global and local branches, leading to consistent output. Moreover,\nmultilevel contrastive losses are employed on both sides to enforce consistency\nbetween two-level representations in the same semantic space. Extensive\nexperiments on several driving scene segmentation datasets demonstrate that our\nframework outperforms state-of-the-art methods, significantly improving average\nsegmentation accuracy and effectively addressing the class-consistency\nrepresentation problem.", "AI": {"tldr": "FedSaaS improves federated semantic segmentation by addressing class-consistency issues through class exemplars and adversarial mechanisms, outperforming existing methods.", "motivation": "Existing federated semantic segmentation methods neglect fine-grained class relationships, causing ambiguities in class representation, especially under domain shift.", "method": "Proposes FedSaaS, using class exemplars for local and global class representation, adversarial mechanisms for harmonization, and multilevel contrastive losses for consistency.", "result": "Outperforms state-of-the-art methods, significantly improving segmentation accuracy and resolving class-consistency issues.", "conclusion": "FedSaaS effectively addresses class-consistency in federated semantic segmentation, enhancing performance and representation alignment."}}
{"id": "2505.09393", "pdf": "https://arxiv.org/pdf/2505.09393", "abs": "https://arxiv.org/abs/2505.09393", "authors": ["Huakun Liu", "Hiroki Ota", "Xin Wei", "Yutaro Hirao", "Monica Perusquia-Hernandez", "Hideaki Uchiyama", "Kiyoshi Kiyokawa"], "title": "UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Sparse wearable inertial measurement units (IMUs) have gained popularity for\nestimating 3D human motion. However, challenges such as pose ambiguity, data\ndrift, and limited adaptability to diverse bodies persist. To address these\nissues, we propose UMotion, an uncertainty-driven, online fusing-all state\nestimation framework for 3D human shape and pose estimation, supported by six\nintegrated, body-worn ultra-wideband (UWB) distance sensors with IMUs. UWB\nsensors measure inter-node distances to infer spatial relationships, aiding in\nresolving pose ambiguities and body shape variations when combined with\nanthropometric data. Unfortunately, IMUs are prone to drift, and UWB sensors\nare affected by body occlusions. Consequently, we develop a tightly coupled\nUnscented Kalman Filter (UKF) framework that fuses uncertainties from sensor\ndata and estimated human motion based on individual body shape. The UKF\niteratively refines IMU and UWB measurements by aligning them with uncertain\nhuman motion constraints in real-time, producing optimal estimates for each.\nExperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of UMotion in stabilizing sensor data and the improvement over\nstate of the art in pose accuracy.", "AI": {"tldr": "UMotion is a framework using IMUs and UWB sensors for 3D human motion estimation, addressing pose ambiguity and drift with a UKF-based fusion method.", "motivation": "Existing methods using sparse wearable IMUs face challenges like pose ambiguity, data drift, and limited adaptability to diverse body shapes.", "method": "UMotion integrates IMUs and UWB sensors, using a UKF framework to fuse uncertainties and refine measurements in real-time.", "result": "Experiments show UMotion stabilizes sensor data and improves pose accuracy over state-of-the-art methods.", "conclusion": "UMotion effectively addresses key challenges in 3D human motion estimation with wearable sensors."}}
{"id": "2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "title": "Online Isolation Forest", "categories": ["cs.LG"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection.", "AI": {"tldr": "Online-iForest is a streaming anomaly detection method that outperforms existing online and offline techniques in efficiency, making it ideal for real-time applications like cybersecurity.", "motivation": "Existing anomaly detection methods are impractical for streaming data due to memory constraints and reliance on retraining.", "method": "Proposes Online-iForest, designed for streaming conditions to track evolving data processes without retraining.", "result": "Matches online alternatives and rivals offline methods, excelling in efficiency for fast anomaly detection.", "conclusion": "Online-iForest is a highly efficient solution for real-time anomaly detection in critical applications."}}
{"id": "2505.09406", "pdf": "https://arxiv.org/pdf/2505.09406", "abs": "https://arxiv.org/abs/2505.09406", "authors": ["Yue Wen", "Liang Song", "Yijia Liu", "Siting Zhu", "Yanzi Miao", "Lijun Han", "Hesheng Wang"], "title": "FreeDriveRF: Monocular RGB Dynamic NeRF without Poses for Autonomous Driving via Point-Level Dynamic-Static Decoupling", "categories": ["cs.CV"], "comment": "7 pages, 9 figures, accepted by ICRA2025", "summary": "Dynamic scene reconstruction for autonomous driving enables vehicles to\nperceive and interpret complex scene changes more precisely. Dynamic Neural\nRadiance Fields (NeRFs) have recently shown promising capability in scene\nmodeling. However, many existing methods rely heavily on accurate poses inputs\nand multi-sensor data, leading to increased system complexity. To address this,\nwe propose FreeDriveRF, which reconstructs dynamic driving scenes using only\nsequential RGB images without requiring poses inputs. We innovatively decouple\ndynamic and static parts at the early sampling level using semantic\nsupervision, mitigating image blurring and artifacts. To overcome the\nchallenges posed by object motion and occlusion in monocular camera, we\nintroduce a warped ray-guided dynamic object rendering consistency loss,\nutilizing optical flow to better constrain the dynamic modeling process.\nAdditionally, we incorporate estimated dynamic flow to constrain the pose\noptimization process, improving the stability and accuracy of unbounded scene\nreconstruction. Extensive experiments conducted on the KITTI and Waymo datasets\ndemonstrate the superior performance of our method in dynamic scene modeling\nfor autonomous driving.", "AI": {"tldr": "FreeDriveRF reconstructs dynamic driving scenes using only sequential RGB images, eliminating the need for pose inputs, and improves dynamic modeling with semantic supervision and optical flow constraints.", "motivation": "Existing methods for dynamic scene reconstruction in autonomous driving rely on accurate poses and multi-sensor data, increasing system complexity. FreeDriveRF aims to simplify this by using only RGB images.", "method": "The method decouples dynamic and static parts early using semantic supervision and introduces a warped ray-guided dynamic object rendering consistency loss with optical flow. It also uses estimated dynamic flow for pose optimization.", "result": "Experiments on KITTI and Waymo datasets show superior performance in dynamic scene modeling.", "conclusion": "FreeDriveRF effectively reconstructs dynamic scenes without pose inputs, addressing challenges like motion and occlusion, and outperforms existing methods."}}
{"id": "2505.09395", "pdf": "https://arxiv.org/pdf/2505.09395", "abs": "https://arxiv.org/abs/2505.09395", "authors": ["Chen-Yu Liu", "Kuan-Cheng Chen", "Yi-Chien Chen", "Samuel Yen-Chi Chen", "Wei-Hao Huang", "Wei-Jia Huang", "Yen-Jui Chang"], "title": "Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Typhoon trajectory forecasting is essential for disaster preparedness but\nremains computationally demanding due to the complexity of atmospheric dynamics\nand the resource requirements of deep learning models. Quantum-Train (QT), a\nhybrid quantum-classical framework that leverages quantum neural networks\n(QNNs) to generate trainable parameters exclusively during training,\neliminating the need for quantum hardware at inference time. Building on QT's\nsuccess across multiple domains, including image classification, reinforcement\nlearning, flood prediction, and large language model (LLM) fine-tuning, we\nintroduce Quantum Parameter Adaptation (QPA) for efficient typhoon forecasting\nmodel learning. Integrated with an Attention-based Multi-ConvGRU model, QPA\nenables parameter-efficient training while maintaining predictive accuracy.\nThis work represents the first application of quantum machine learning (QML) to\nlarge-scale typhoon trajectory prediction, offering a scalable and\nenergy-efficient approach to climate modeling. Our results demonstrate that QPA\nsignificantly reduces the number of trainable parameters while preserving\nperformance, making high-performance forecasting more accessible and\nsustainable through hybrid quantum-classical learning.", "AI": {"tldr": "QT introduces Quantum Parameter Adaptation (QPA) for efficient typhoon trajectory forecasting, reducing trainable parameters while maintaining accuracy.", "motivation": "Typhoon trajectory forecasting is computationally demanding; QT aims to provide a scalable, energy-efficient solution using quantum-classical hybrid learning.", "method": "QT leverages quantum neural networks (QNNs) for parameter generation during training, integrated with an Attention-based Multi-ConvGRU model for typhoon forecasting.", "result": "QPA significantly reduces trainable parameters without compromising predictive accuracy, making forecasting more accessible.", "conclusion": "QT's QPA offers a scalable, sustainable approach to typhoon trajectory prediction, advancing quantum machine learning in climate modeling."}}
{"id": "2505.09602", "pdf": "https://arxiv.org/pdf/2505.09602", "abs": "https://arxiv.org/abs/2505.09602", "authors": ["David Khachaturov", "Robert Mullins"], "title": "Adversarial Suffix Filtering: a Defense Pipeline for LLMs", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly embedded in autonomous systems\nand public-facing environments, yet they remain susceptible to jailbreak\nvulnerabilities that may undermine their security and trustworthiness.\nAdversarial suffixes are considered to be the current state-of-the-art\njailbreak, consistently outperforming simpler methods and frequently succeeding\neven in black-box settings. Existing defenses rely on access to the internal\narchitecture of models limiting diverse deployment, increase memory and\ncomputation footprints dramatically, or can be bypassed with simple prompt\nengineering methods. We introduce $\\textbf{Adversarial Suffix Filtering}$\n(ASF), a lightweight novel model-agnostic defensive pipeline designed to\nprotect LLMs against adversarial suffix attacks. ASF functions as an input\npreprocessor and sanitizer that detects and filters adversarially crafted\nsuffixes in prompts, effectively neutralizing malicious injections. We\ndemonstrate that ASF provides comprehensive defense capabilities across both\nblack-box and white-box attack settings, reducing the attack efficacy of\nstate-of-the-art adversarial suffix generation methods to below 4%, while only\nminimally affecting the target model's capabilities in non-adversarial\nscenarios.", "AI": {"tldr": "ASF is a lightweight, model-agnostic defense against adversarial suffix attacks on LLMs, reducing attack efficacy to below 4% without compromising normal performance.", "motivation": "LLMs are vulnerable to jailbreak attacks like adversarial suffixes, and existing defenses are limited or ineffective.", "method": "Introduces Adversarial Suffix Filtering (ASF), a pipeline to detect and filter adversarial suffixes in prompts.", "result": "ASF reduces attack efficacy to below 4% in both black-box and white-box settings, with minimal impact on normal model performance.", "conclusion": "ASF is an effective, lightweight solution for protecting LLMs against adversarial suffix attacks."}}
{"id": "2505.09413", "pdf": "https://arxiv.org/pdf/2505.09413", "abs": "https://arxiv.org/abs/2505.09413", "authors": ["Ma Changfeng", "Bi Ran", "Guo Jie", "Wang Chongjun", "Guo Yanwen"], "title": "Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians", "categories": ["cs.CV"], "comment": "CVPR 2025 Accepted", "summary": "Current learning-based methods predict NeRF or 3D Gaussians from point clouds\nto achieve photo-realistic rendering but still depend on categorical priors,\ndense point clouds, or additional refinements. Hence, we introduce a novel\npoint cloud rendering method by predicting 2D Gaussians from point clouds. Our\nmethod incorporates two identical modules with an entire-patch architecture\nenabling the network to be generalized to multiple datasets. The module\nnormalizes and initializes the Gaussians utilizing the point cloud information\nincluding normals, colors and distances. Then, splitting decoders are employed\nto refine the initial Gaussians by duplicating them and predicting more\naccurate results, making our methodology effectively accommodate sparse point\nclouds as well. Once trained, our approach exhibits direct generalization to\npoint clouds across different categories. The predicted Gaussians are employed\ndirectly for rendering without additional refinement on the rendered images,\nretaining the benefits of 2D Gaussians. We conduct extensive experiments on\nvarious datasets, and the results demonstrate the superiority and\ngeneralization of our method, which achieves SOTA performance. The code is\navailable at\nhttps://github.com/murcherful/GauPCRender}{https://github.com/murcherful/GauPCRender.", "AI": {"tldr": "A novel point cloud rendering method predicts 2D Gaussians from point clouds, eliminating the need for categorical priors or dense inputs, and achieves SOTA performance with direct generalization across datasets.", "motivation": "Current methods rely on categorical priors, dense point clouds, or refinements, limiting flexibility and generalization.", "method": "Uses two identical modules with an entire-patch architecture to normalize and initialize Gaussians, then refines them with splitting decoders for sparse inputs.", "result": "Achieves state-of-the-art performance and generalization across datasets without additional refinement.", "conclusion": "The method effectively renders sparse point clouds using 2D Gaussians, offering superior performance and generalization."}}
{"id": "2505.09435", "pdf": "https://arxiv.org/pdf/2505.09435", "abs": "https://arxiv.org/abs/2505.09435", "authors": ["Yili He", "Yan Zhu", "Peiyao Fu", "Ruijie Yang", "Tianyi Chen", "Zhihua Wang", "Quanlin Li", "Pinghong Zhou", "Xian Yang", "Shuo Wang"], "title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records", "categories": ["cs.CV", "cs.AI"], "comment": "Early accepted to MICCAI 2025", "summary": "Pre-training on image-text colonoscopy records offers substantial potential\nfor improving endoscopic image analysis, but faces challenges including\nnon-informative background images, complex medical terminology, and ambiguous\nmulti-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised\nframework that enhances Contrastive Language-Image Pre-training (CLIP) for this\ndomain. Endo-CLIP's three-stage framework--cleansing, attunement, and\nunification--addresses these challenges by (1) removing background frames, (2)\nleveraging large language models to extract clinical attributes for\nfine-grained contrastive learning, and (3) employing patient-level\ncross-attention to resolve multi-polyp ambiguities. Extensive experiments\ndemonstrate that Endo-CLIP significantly outperforms state-of-the-art\npre-training methods in zero-shot and few-shot polyp detection and\nclassification, paving the way for more accurate and clinically relevant\nendoscopic analysis.", "AI": {"tldr": "Endo-CLIP is a self-supervised framework enhancing CLIP for endoscopic image analysis, addressing challenges like non-informative backgrounds and complex terminology, and outperforms state-of-the-art methods in polyp detection and classification.", "motivation": "Improving endoscopic image analysis by overcoming challenges like non-informative backgrounds, complex terminology, and ambiguous multi-lesion descriptions.", "method": "Three-stage framework: cleansing (removing background frames), attunement (using large language models for fine-grained contrastive learning), and unification (patient-level cross-attention for multi-polyp ambiguities).", "result": "Significantly outperforms state-of-the-art pre-training methods in zero-shot and few-shot polyp detection and classification.", "conclusion": "Endo-CLIP enables more accurate and clinically relevant endoscopic analysis."}}
{"id": "2505.07363", "pdf": "https://arxiv.org/pdf/2505.07363", "abs": "https://arxiv.org/abs/2505.07363", "authors": ["Serge Massar"], "title": "Equilibrium Propagation for Learning in Lagrangian Dynamical Systems", "categories": ["nlin.CD", "cs.LG", "physics.data-an"], "comment": "8 pages, 1 figure", "summary": "We propose a method for training dynamical systems governed by Lagrangian\nmechanics using Equilibrium Propagation. Our approach extends Equilibrium\nPropagation -- initially developed for energy-based models -- to dynamical\ntrajectories by leveraging the principle of action extremization. Training is\nachieved by gently nudging trajectories toward desired targets and measuring\nhow the variables conjugate to the parameters to be trained respond. This\nmethod is particularly suited to systems with periodic boundary conditions or\nfixed initial and final states, enabling efficient parameter updates without\nrequiring explicit backpropagation through time. In the case of periodic\nboundary conditions, this approach yields the semiclassical limit of Quantum\nEquilibrium Propagation. Applications to systems with dissipation are also\ndiscussed.", "AI": {"tldr": "A method for training dynamical systems using Equilibrium Propagation, extending it to Lagrangian mechanics by action extremization, suitable for periodic or fixed boundary conditions.", "motivation": "To enable efficient training of dynamical systems without explicit backpropagation through time, leveraging Lagrangian mechanics and Equilibrium Propagation.", "method": "Extends Equilibrium Propagation to dynamical trajectories via action extremization, nudging trajectories toward targets and measuring conjugate variables for parameter updates.", "result": "Efficient parameter updates for systems with periodic or fixed boundary conditions, with applications to dissipative systems and connections to semiclassical Quantum Equilibrium Propagation.", "conclusion": "The method offers a practical alternative for training dynamical systems, especially those with specific boundary conditions, avoiding computational costs of backpropagation through time."}}
{"id": "2505.09415", "pdf": "https://arxiv.org/pdf/2505.09415", "abs": "https://arxiv.org/abs/2505.09415", "authors": ["Hongyang Wang", "Yichen Shi", "Zhuofu Tao", "Yuhao Gao", "Liepiao Zhang", "Xun Lin", "Jun Feng", "Xiaochen Yuan", "Zitong Yu", "Xiaochun Cao"], "title": "FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Face anti-spoofing (FAS) is crucial for protecting facial recognition systems\nfrom presentation attacks. Previous methods approached this task as a\nclassification problem, lacking interpretability and reasoning behind the\npredicted results. Recently, multimodal large language models (MLLMs) have\nshown strong capabilities in perception, reasoning, and decision-making in\nvisual tasks. However, there is currently no universal and comprehensive MLLM\nand dataset specifically designed for FAS task. To address this gap, we propose\nFaceShield, a MLLM for FAS, along with the corresponding pre-training and\nsupervised fine-tuning (SFT) datasets, FaceShield-pre10K and FaceShield-sft45K.\nFaceShield is capable of determining the authenticity of faces, identifying\ntypes of spoofing attacks, providing reasoning for its judgments, and detecting\nattack areas. Specifically, we employ spoof-aware vision perception (SAVP) that\nincorporates both the original image and auxiliary information based on prior\nknowledge. We then use an prompt-guided vision token masking (PVTM) strategy to\nrandom mask vision tokens, thereby improving the model's generalization\nability. We conducted extensive experiments on three benchmark datasets,\ndemonstrating that FaceShield significantly outperforms previous deep learning\nmodels and general MLLMs on four FAS tasks, i.e., coarse-grained\nclassification, fine-grained classification, reasoning, and attack\nlocalization. Our instruction datasets, protocols, and codes will be released\nsoon.", "AI": {"tldr": "FaceShield is a multimodal large language model (MLLM) for face anti-spoofing (FAS), offering interpretability, reasoning, and attack detection, outperforming previous methods.", "motivation": "Existing FAS methods lack interpretability and reasoning. MLLMs show promise but lack FAS-specific models and datasets.", "method": "Proposes FaceShield with spoof-aware vision perception (SAVP) and prompt-guided vision token masking (PVTM) for generalization.", "result": "FaceShield outperforms deep learning models and general MLLMs on four FAS tasks.", "conclusion": "FaceShield advances FAS with interpretability, reasoning, and attack detection, supported by new datasets and methods."}}
{"id": "2505.09438", "pdf": "https://arxiv.org/pdf/2505.09438", "abs": "https://arxiv.org/abs/2505.09438", "authors": ["Paul Tschisgale", "Holger Maus", "Fabian Kieser", "Ben Kroehs", "Stefan Petersen", "Peter Wulff"], "title": "Evaluating GPT- and Reasoning-based Large Language Models on Physics Olympiad Problems: Surpassing Human Performance and Implications for Educational Assessment", "categories": ["physics.ed-ph", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are now widely accessible, reaching learners at\nall educational levels. This development has raised concerns that their use may\ncircumvent essential learning processes and compromise the integrity of\nestablished assessment formats. In physics education, where problem solving\nplays a central role in instruction and assessment, it is therefore essential\nto understand the physics-specific problem-solving capabilities of LLMs. Such\nunderstanding is key to informing responsible and pedagogically sound\napproaches to integrating LLMs into instruction and assessment. This study\ntherefore compares the problem-solving performance of a general-purpose LLM\n(GPT-4o, using varying prompting techniques) and a reasoning-optimized model\n(o1-preview) with that of participants of the German Physics Olympiad, based on\na set of well-defined Olympiad problems. In addition to evaluating the\ncorrectness of the generated solutions, the study analyzes characteristic\nstrengths and limitations of LLM-generated solutions. The findings of this\nstudy indicate that both tested LLMs (GPT-4o and o1-preview) demonstrate\nadvanced problem-solving capabilities on Olympiad-type physics problems, on\naverage outperforming the human participants. Prompting techniques had little\neffect on GPT-4o's performance, while o1-preview almost consistently\noutperformed both GPT-4o and the human benchmark. Based on these findings, the\nstudy discusses implications for the design of summative and formative\nassessment in physics education, including how to uphold assessment integrity\nand support students in critically engaging with LLMs.", "AI": {"tldr": "The study compares LLMs (GPT-4o and o1-preview) with human participants in solving physics Olympiad problems, finding LLMs outperform humans. It discusses implications for physics education and assessment integrity.", "motivation": "To understand LLMs' physics problem-solving capabilities and inform responsible integration into education and assessment.", "method": "Comparison of LLMs (GPT-4o with varying prompts and o1-preview) against German Physics Olympiad participants using Olympiad problems.", "result": "LLMs, especially o1-preview, outperformed humans. Prompting had little effect on GPT-4o.", "conclusion": "The study highlights the need to redesign physics assessments to uphold integrity and guide students in using LLMs critically."}}
{"id": "2505.08804", "pdf": "https://arxiv.org/pdf/2505.08804", "abs": "https://arxiv.org/abs/2505.08804", "authors": ["Longtian Wang", "Xiaofei Xie", "Tianlin Li", "Yuhan Zhi", "Chao Shen"], "title": "TokenProber: Jailbreaking Text-to-image Models via Fine-grained Word Impact Analysis", "categories": ["cs.CR", "cs.LG"], "comment": "13 pages, 5 figures", "summary": "Text-to-image (T2I) models have significantly advanced in producing\nhigh-quality images. However, such models have the ability to generate images\ncontaining not-safe-for-work (NSFW) content, such as pornography, violence,\npolitical content, and discrimination. To mitigate the risk of generating NSFW\ncontent, refusal mechanisms, i.e., safety checkers, have been developed to\ncheck potential NSFW content. Adversarial prompting techniques have been\ndeveloped to evaluate the robustness of the refusal mechanisms. The key\nchallenge remains to subtly modify the prompt in a way that preserves its\nsensitive nature while bypassing the refusal mechanisms. In this paper, we\nintroduce TokenProber, a method designed for sensitivity-aware differential\ntesting, aimed at evaluating the robustness of the refusal mechanisms in T2I\nmodels by generating adversarial prompts. Our approach is based on the key\nobservation that adversarial prompts often succeed by exploiting discrepancies\nin how T2I models and safety checkers interpret sensitive content. Thus, we\nconduct a fine-grained analysis of the impact of specific words within prompts,\ndistinguishing between dirty words that are essential for NSFW content\ngeneration and discrepant words that highlight the different sensitivity\nassessments between T2I models and safety checkers. Through the\nsensitivity-aware mutation, TokenProber generates adversarial prompts, striking\na balance between maintaining NSFW content generation and evading detection.\nOur evaluation of TokenProber against 5 safety checkers on 3 popular T2I\nmodels, using 324 NSFW prompts, demonstrates its superior effectiveness in\nbypassing safety filters compared to existing methods (e.g., 54%+ increase on\naverage), highlighting TokenProber's ability to uncover robustness issues in\nthe existing refusal mechanisms.", "AI": {"tldr": "TokenProber is a method for testing the robustness of safety checkers in T2I models by generating adversarial prompts that bypass filters while maintaining NSFW content.", "motivation": "To address the challenge of evaluating and improving the robustness of refusal mechanisms in T2I models against adversarial prompts.", "method": "TokenProber uses sensitivity-aware differential testing, analyzing the impact of specific words (dirty vs. discrepant) to generate adversarial prompts.", "result": "TokenProber outperforms existing methods, achieving a 54%+ increase in bypassing safety filters across 5 checkers and 3 T2I models.", "conclusion": "TokenProber effectively uncovers robustness issues in refusal mechanisms, highlighting the need for improved safety measures in T2I models."}}
{"id": "2505.09422", "pdf": "https://arxiv.org/pdf/2505.09422", "abs": "https://arxiv.org/abs/2505.09422", "authors": ["Xiangyuan Peng", "Yu Wang", "Miao Tang", "Bierzynski Kay", "Lorenzo Servadei", "Robert Wille"], "title": "MoRAL: Motion-aware Multi-Frame 4D Radar and LiDAR Fusion for Robust 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Reliable autonomous driving systems require accurate detection of traffic\nparticipants. To this end, multi-modal fusion has emerged as an effective\nstrategy. In particular, 4D radar and LiDAR fusion methods based on multi-frame\nradar point clouds have demonstrated the effectiveness in bridging the point\ndensity gap. However, they often neglect radar point clouds' inter-frame\nmisalignment caused by object movement during accumulation and do not fully\nexploit the object dynamic information from 4D radar. In this paper, we propose\nMoRAL, a motion-aware multi-frame 4D radar and LiDAR fusion framework for\nrobust 3D object detection. First, a Motion-aware Radar Encoder (MRE) is\ndesigned to compensate for inter-frame radar misalignment from moving objects.\nLater, a Motion Attention Gated Fusion (MAGF) module integrate radar motion\nfeatures to guide LiDAR features to focus on dynamic foreground objects.\nExtensive evaluations on the View-of-Delft (VoD) dataset demonstrate that MoRAL\noutperforms existing methods, achieving the highest mAP of 73.30% in the entire\narea and 88.68% in the driving corridor. Notably, our method also achieves the\nbest AP of 69.67% for pedestrians in the entire area and 96.25% for cyclists in\nthe driving corridor.", "AI": {"tldr": "MoRAL is a motion-aware fusion framework for 4D radar and LiDAR, improving 3D object detection by addressing radar misalignment and leveraging object dynamics.", "motivation": "Current multi-modal fusion methods neglect radar misalignment and underutilize dynamic information from 4D radar, limiting detection accuracy.", "method": "Proposes MoRAL with a Motion-aware Radar Encoder (MRE) to correct misalignment and a Motion Attention Gated Fusion (MAGF) module to integrate radar motion features with LiDAR.", "result": "Achieves 73.30% mAP overall and 88.68% in driving corridors, with top performance for pedestrians (69.67%) and cyclists (96.25%).", "conclusion": "MoRAL enhances 3D object detection by effectively addressing radar misalignment and leveraging motion data, outperforming existing methods."}}
{"id": "2505.09456", "pdf": "https://arxiv.org/pdf/2505.09456", "abs": "https://arxiv.org/abs/2505.09456", "authors": ["Josep Lumbreras", "Ruo Cheng Huang", "Yanglin Hu", "Mile Gu", "Marco Tomamichel"], "title": "Quantum state-agnostic work extraction (almost) without dissipation", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "5 pages+14 pages, 2 figures", "summary": "We investigate work extraction protocols designed to transfer the maximum\npossible energy to a battery using sequential access to $N$ copies of an\nunknown pure qubit state. The core challenge is designing interactions to\noptimally balance two competing goals: charging of the battery optimally using\nthe qubit in hand, and acquiring more information by qubit to improve energy\nharvesting in subsequent rounds. Here, we leverage exploration-exploitation\ntrade-off in reinforcement learning to develop adaptive strategies achieving\nenergy dissipation that scales only poly-logarithmically in $N$. This\nrepresents an exponential improvement over current protocols based on full\nstate tomography.", "AI": {"tldr": "The paper explores work extraction protocols for maximizing energy transfer to a battery using sequential access to unknown pure qubit states, achieving poly-logarithmic scaling in energy dissipation via adaptive reinforcement learning strategies.", "motivation": "The challenge lies in balancing optimal battery charging with acquiring information for future energy harvesting, addressing limitations of current tomography-based protocols.", "method": "The study employs reinforcement learning to develop adaptive strategies, leveraging the exploration-exploitation trade-off.", "result": "The proposed method achieves poly-logarithmic scaling in energy dissipation, an exponential improvement over full state tomography protocols.", "conclusion": "The adaptive reinforcement learning approach significantly enhances energy harvesting efficiency for sequential qubit state access."}}
{"id": "2505.08816", "pdf": "https://arxiv.org/pdf/2505.08816", "abs": "https://arxiv.org/abs/2505.08816", "authors": ["Ippokratis Koukoulis", "Ilias Syrigos", "Thanasis Korakis"], "title": "Self-Supervised Transformer-based Contrastive Learning for Intrusion Detection Systems", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted at IFIP Networking 2025. Code available at\n  https://github.com/koukipp/contrastive_transformers_ids", "summary": "As the digital landscape becomes more interconnected, the frequency and\nseverity of zero-day attacks, have significantly increased, leading to an\nurgent need for innovative Intrusion Detection Systems (IDS). Machine\nLearning-based IDS that learn from the network traffic characteristics and can\ndiscern attack patterns from benign traffic offer an advanced solution to\ntraditional signature-based IDS. However, they heavily rely on labeled\ndatasets, and their ability to generalize when encountering unseen traffic\npatterns remains a challenge. This paper proposes a novel self-supervised\ncontrastive learning approach based on transformer encoders, specifically\ntailored for generalizable intrusion detection on raw packet sequences. Our\nproposed learning scheme employs a packet-level data augmentation strategy\ncombined with a transformer-based architecture to extract and generate\nmeaningful representations of traffic flows. Unlike traditional methods reliant\non handcrafted statistical features (NetFlow), our approach automatically\nlearns comprehensive packet sequence representations, significantly enhancing\nperformance in anomaly identification tasks and supervised learning for\nintrusion detection. Our transformer-based framework exhibits better\nperformance in comparison to existing NetFlow self-supervised methods.\nSpecifically, we achieve up to a 3% higher AUC in anomaly detection for\nintra-dataset evaluation and up to 20% higher AUC scores in inter-dataset\nevaluation. Moreover, our model provides a strong baseline for supervised\nintrusion detection with limited labeled data, exhibiting an improvement over\nself-supervised NetFlow models of up to 1.5% AUC when pretrained and evaluated\non the same dataset. Additionally, we show the adaptability of our pretrained\nmodel when fine-tuned across different datasets, demonstrating strong\nperformance even when lacking benign data from the target domain.", "AI": {"tldr": "The paper proposes a self-supervised contrastive learning approach using transformer encoders for generalizable intrusion detection, outperforming traditional methods in anomaly detection and supervised learning tasks.", "motivation": "The increasing frequency and severity of zero-day attacks necessitate advanced IDS solutions beyond traditional signature-based systems. Machine Learning-based IDS face challenges with labeled datasets and generalization.", "method": "A novel self-supervised contrastive learning approach with packet-level data augmentation and transformer-based architecture to learn comprehensive packet sequence representations.", "result": "Achieves up to 3% higher AUC in intra-dataset and 20% higher AUC in inter-dataset anomaly detection, with improved supervised learning performance (1.5% AUC gain).", "conclusion": "The transformer-based framework offers superior performance and adaptability, even with limited labeled data or lacking benign data in target domains."}}
{"id": "2505.09450", "pdf": "https://arxiv.org/pdf/2505.09450", "abs": "https://arxiv.org/abs/2505.09450", "authors": ["Yuelin Zhang", "Qingpeng Ding", "Long Lei", "Yongxuan Feng", "Raymond Shing-Yan Tang", "Shing Shin Cheng"], "title": "MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy", "categories": ["cs.CV"], "comment": "Early Accepted by MICCAI 2025", "summary": "Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally\ninvasive diagnostic procedure. However, an aspiration needle tracker addressing\nrapid reciprocating motion is still missing. MrTrack, an aspiration needle\ntracker with a mamba-based register mechanism, is proposed. MrTrack leverages a\nMamba-based register extractor to sequentially distill global context from each\nhistorical search map, storing these temporal cues in a register bank. The\nMamba-based register retriever then retrieves temporal prompts from the\nregister bank to provide external cues when current vision features are\ntemporarily unusable due to rapid reciprocating motion and imaging degradation.\nA self-supervised register diversify loss is proposed to encourage feature\ndiversity and dimension independence within the learned register, mitigating\nfeature collapse. Comprehensive experiments conducted on both motorized and\nmanual aspiration datasets demonstrate that MrTrack not only outperforms\nstate-of-the-art trackers in accuracy and robustness but also achieves superior\ninference efficiency.", "AI": {"tldr": "MrTrack is a Mamba-based aspiration needle tracker for ultrasound-guided FNA biopsies, addressing rapid motion challenges with temporal context storage and retrieval, outperforming state-of-the-art methods.", "motivation": "Current ultrasound-guided FNA biopsies lack a needle tracker for rapid reciprocating motion, necessitating a robust solution like MrTrack.", "method": "MrTrack uses a Mamba-based register mechanism to distill global context from historical search maps and retrieves temporal prompts for degraded vision features. A self-supervised loss ensures feature diversity.", "result": "MrTrack outperforms state-of-the-art trackers in accuracy, robustness, and inference efficiency on motorized and manual aspiration datasets.", "conclusion": "MrTrack effectively addresses rapid motion challenges in FNA biopsies, offering superior performance and efficiency."}}
{"id": "2505.09466", "pdf": "https://arxiv.org/pdf/2505.09466", "abs": "https://arxiv.org/abs/2505.09466", "authors": ["Xi Chen", "Shiyang Zhou", "Muqi Huang", "Jiaxu Feng", "Yun Xiong", "Kun Zhou", "Biao Yang", "Yuhui Zhang", "Huishuai Bao", "Sijia Peng", "Chuan Li", "Feng Shi"], "title": "A 2D Semantic-Aware Position Encoding for Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 4 figures, 3 tables", "summary": "Vision transformers have demonstrated significant advantages in computer\nvision tasks due to their ability to capture long-range dependencies and\ncontextual relationships through self-attention. However, existing position\nencoding techniques, which are largely borrowed from natural language\nprocessing, fail to effectively capture semantic-aware positional relationships\nbetween image patches. Traditional approaches like absolute position encoding\nand relative position encoding primarily focus on 1D linear position\nrelationship, often neglecting the semantic similarity between distant yet\ncontextually related patches. These limitations hinder model generalization,\ntranslation equivariance, and the ability to effectively handle repetitive or\nstructured patterns in images. In this paper, we propose 2-Dimensional\nSemantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding\nmethod with semantic awareness that dynamically adapts position representations\nby leveraging local content instead of fixed linear position relationship or\nspatial coordinates. Our method enhances the model's ability to generalize\nacross varying image resolutions and scales, improves translation equivariance,\nand better aggregates features for visually similar but spatially distant\npatches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the\ngap between position encoding and perceptual similarity, thereby improving\nperformance on computer vision tasks.", "AI": {"tldr": "The paper introduces $\text{SaPE}^2$, a semantic-aware position encoding method for vision transformers, addressing limitations of traditional 1D position encodings in capturing image patch relationships.", "motivation": "Existing position encoding methods, borrowed from NLP, fail to capture semantic relationships between image patches, hindering model generalization and equivariance.", "method": "Proposes $\text{SaPE}^2$, a 2D semantic-aware position encoding that dynamically adapts position representations based on local content.", "result": "Enhances generalization across resolutions, improves translation equivariance, and better aggregates features for similar but distant patches.", "conclusion": "$\text{SaPE}^2$ bridges the gap between position encoding and perceptual similarity, boosting performance in computer vision tasks."}}
{"id": "2505.08822", "pdf": "https://arxiv.org/pdf/2505.08822", "abs": "https://arxiv.org/abs/2505.08822", "authors": ["Yuhao Wang", "Kailai Wang", "Songhua Hu", "Yunpeng", "Zhang", "Gino Lim", "Pengyu Zhu"], "title": "The Geography of Transportation Cybersecurity: Visitor Flows, Industry Clusters, and Spatial Dynamics", "categories": ["cs.CY", "cs.LG", "physics.soc-ph"], "comment": null, "summary": "The rapid evolution of the transportation cybersecurity ecosystem,\nencompassing cybersecurity, automotive, and transportation and logistics\nsectors, will lead to the formation of distinct spatial clusters and visitor\nflow patterns across the US. This study examines the spatiotemporal dynamics of\nvisitor flows, analyzing how socioeconomic factors shape industry clustering\nand workforce distribution within these evolving sectors. To model and predict\nvisitor flow patterns, we develop a BiTransGCN framework, integrating an\nattention-based Transformer architecture with a Graph Convolutional Network\nbackbone. By integrating AI-enabled forecasting techniques with spatial\nanalysis, this study improves our ability to track, interpret, and anticipate\nchanges in industry clustering and mobility trends, thereby supporting\nstrategic planning for a secure and resilient transportation network. It offers\na data-driven foundation for economic planning, workforce development, and\ntargeted investments in the transportation cybersecurity ecosystem.", "AI": {"tldr": "The paper explores spatiotemporal visitor flow patterns in the US transportation cybersecurity ecosystem using a BiTransGCN framework, combining AI and spatial analysis for improved industry clustering and mobility trend predictions.", "motivation": "To understand how socioeconomic factors influence industry clustering and workforce distribution in the evolving transportation cybersecurity ecosystem.", "method": "Develops a BiTransGCN framework, integrating attention-based Transformer architecture with Graph Convolutional Network for modeling and predicting visitor flows.", "result": "Enhances tracking, interpretation, and anticipation of industry clustering and mobility trends, aiding strategic planning for a secure transportation network.", "conclusion": "Provides a data-driven approach for economic planning, workforce development, and targeted investments in the transportation cybersecurity ecosystem."}}
{"id": "2505.09455", "pdf": "https://arxiv.org/pdf/2505.09455", "abs": "https://arxiv.org/abs/2505.09455", "authors": ["Jeremie Ochin", "Raphael Chekroun", "Bogdan Stanciulescu", "Sotiris Manitsaris"], "title": "Beyond Pixels: Leveraging the Language of Soccer to Improve Spatio-Temporal Action Detection in Broadcast Videos", "categories": ["cs.CV"], "comment": "12 pages, submitted to Advanced Concepts for Intelligent Vision\n  Systems 2025", "summary": "State-of-the-art spatio-temporal action detection (STAD) methods show\npromising results for extracting soccer events from broadcast videos. However,\nwhen operated in the high-recall, low-precision regime required for exhaustive\nevent coverage in soccer analytics, their lack of contextual understanding\nbecomes apparent: many false positives could be resolved by considering a\nbroader sequence of actions and game-state information. In this work, we\naddress this limitation by reasoning at the game level and improving STAD\nthrough the addition of a denoising sequence transduction task. Sequences of\nnoisy, context-free player-centric predictions are processed alongside clean\ngame state information using a Transformer-based encoder-decoder model. By\nmodeling extended temporal context and reasoning jointly over team-level\ndynamics, our method leverages the \"language of soccer\" - its tactical\nregularities and inter-player dependencies - to generate \"denoised\" sequences\nof actions. This approach improves both precision and recall in low-confidence\nregimes, enabling more reliable event extraction from broadcast video and\ncomplementing existing pixel-based methods.", "AI": {"tldr": "The paper proposes a Transformer-based method to improve spatio-temporal action detection (STAD) in soccer by incorporating game-level context and denoising sequences, enhancing precision and recall.", "motivation": "Current STAD methods lack contextual understanding, leading to false positives in high-recall, low-precision regimes for soccer analytics.", "method": "Uses a Transformer-based encoder-decoder model to process noisy player-centric predictions alongside game state info, leveraging temporal context and team dynamics.", "result": "Improves precision and recall in low-confidence regimes, enabling more reliable event extraction from broadcast video.", "conclusion": "The approach effectively leverages soccer's tactical regularities to enhance STAD, complementing existing pixel-based methods."}}
{"id": "2505.09477", "pdf": "https://arxiv.org/pdf/2505.09477", "abs": "https://arxiv.org/abs/2505.09477", "authors": ["Zachary Ravichandran", "Fernando Cladera", "Jason Hughes", "Varun Murali", "M. Ani Hsieh", "George J. Pappas", "Camillo J. Taylor", "Vijay Kumar"], "title": "Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted to the IEEE ICRA Workshop on Field Robotics 2025", "summary": "The integration of foundation models (FMs) into robotics has enabled robots\nto understand natural language and reason about the semantics in their\nenvironments. However, existing FM-enabled robots primary operate in\nclosed-world settings, where the robot is given a full prior map or has a full\nview of its workspace. This paper addresses the deployment of FM-enabled robots\nin the field, where missions often require a robot to operate in large-scale\nand unstructured environments. To effectively accomplish these missions, robots\nmust actively explore their environments, navigate obstacle-cluttered terrain,\nhandle unexpected sensor inputs, and operate with compute constraints. We\ndiscuss recent deployments of SPINE, our LLM-enabled autonomy framework, in\nfield robotic settings. To the best of our knowledge, we present the first\ndemonstration of large-scale LLM-enabled robot planning in unstructured\nenvironments with several kilometers of missions. SPINE is agnostic to a\nparticular LLM, which allows us to distill small language models capable of\nrunning onboard size, weight and power (SWaP) limited platforms. Via\npreliminary model distillation work, we then present the first language-driven\nUAV planner using on-device language models. We conclude our paper by proposing\nseveral promising directions for future research.", "AI": {"tldr": "The paper discusses deploying foundation model (FM)-enabled robots in unstructured, large-scale environments, introducing SPINE, an LLM-based framework for autonomous field robotics.", "motivation": "Existing FM-enabled robots operate in closed-world settings, but real-world missions require adaptability in unstructured environments with compute constraints.", "method": "The paper presents SPINE, an LLM-enabled autonomy framework, and demonstrates its use in large-scale, unstructured environments, including UAV planning with distilled small language models.", "result": "SPINE successfully enables robots to operate in unstructured environments over several kilometers, with the first demonstration of on-device language-driven UAV planning.", "conclusion": "The paper highlights the potential of SPINE for field robotics and proposes future research directions for improving LLM-enabled autonomy."}}
{"id": "2505.08837", "pdf": "https://arxiv.org/pdf/2505.08837", "abs": "https://arxiv.org/abs/2505.08837", "authors": ["Muhammad Saqib", "Dipkumar Mehta", "Fnu Yashu", "Shubham Malhotra"], "title": "Adaptive Security Policy Management in Cloud Environments Using Reinforcement Learning", "categories": ["cs.CR", "cs.CV", "cs.DC", "cs.LG", "cs.NI"], "comment": "10 pages, 6 figures, 1 table", "summary": "The security of cloud environments, such as Amazon Web Services (AWS), is\ncomplex and dynamic. Static security policies have become inadequate as threats\nevolve and cloud resources exhibit elasticity [1]. This paper addresses the\nlimitations of static policies by proposing a security policy management\nframework that uses reinforcement learning (RL) to adapt dynamically.\nSpecifically, we employ deep reinforcement learning algorithms, including deep\nQ Networks and proximal policy optimization, enabling the learning and\ncontinuous adjustment of controls such as firewall rules and Identity and\nAccess Management (IAM) policies. The proposed RL based solution leverages\ncloud telemetry data (AWS Cloud Trail logs, network traffic data, threat\nintelligence feeds) to continuously refine security policies, maximizing threat\nmitigation, and compliance while minimizing resource impact. Experimental\nresults demonstrate that our adaptive RL based framework significantly\noutperforms static policies, achieving higher intrusion detection rates (92%\ncompared to 82% for static policies) and substantially reducing incident\ndetection and response times by 58%. In addition, it maintains high conformity\nwith security requirements and efficient resource usage. These findings\nvalidate the effectiveness of adaptive reinforcement learning approaches in\nimproving cloud security policy management.", "AI": {"tldr": "The paper proposes a reinforcement learning (RL) framework for dynamic security policy management in cloud environments, outperforming static policies in threat detection and response.", "motivation": "Static security policies are inadequate for evolving threats and elastic cloud resources, necessitating adaptive solutions.", "method": "Uses deep RL algorithms (deep Q Networks, proximal policy optimization) to dynamically adjust firewall rules and IAM policies based on cloud telemetry data.", "result": "Achieves 92% intrusion detection (vs. 82% for static policies) and reduces response times by 58%, while maintaining compliance and resource efficiency.", "conclusion": "Reinforcement learning is effective for adaptive cloud security policy management, improving threat mitigation and operational efficiency."}}
{"id": "2505.09484", "pdf": "https://arxiv.org/pdf/2505.09484", "abs": "https://arxiv.org/abs/2505.09484", "authors": ["Yingjie Ma", "Xun Lin", "Zitong Yu", "Xin Liu", "Xiaochen Yuan", "Weicheng Xie", "Linlin Shen"], "title": "Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing", "categories": ["cs.CV"], "comment": null, "summary": "Face Anti-Spoofing (FAS) is essential for the security of facial recognition\nsystems in diverse scenarios such as payment processing and surveillance.\nCurrent multimodal FAS methods often struggle with effective generalization,\nmainly due to modality-specific biases and domain shifts. To address these\nchallenges, we introduce the \\textbf{M}ulti\\textbf{m}odal \\textbf{D}enoising\nand \\textbf{A}lignment (\\textbf{MMDA}) framework. By leveraging the zero-shot\ngeneralization capability of CLIP, the MMDA framework effectively suppresses\nnoise in multimodal data through denoising and alignment mechanisms, thereby\nsignificantly enhancing the generalization performance of cross-modal\nalignment. The \\textbf{M}odality-\\textbf{D}omain Joint \\textbf{D}ifferential\n\\textbf{A}ttention (\\textbf{MD2A}) module in MMDA concurrently mitigates the\nimpacts of domain and modality noise by refining the attention mechanism based\non extracted common noise features. Furthermore, the \\textbf{R}epresentation\n\\textbf{S}pace \\textbf{S}oft (\\textbf{RS2}) Alignment strategy utilizes the\npre-trained CLIP model to align multi-domain multimodal data into a generalized\nrepresentation space in a flexible manner, preserving intricate representations\nand enhancing the model's adaptability to various unseen conditions. We also\ndesign a \\textbf{U}-shaped \\textbf{D}ual \\textbf{S}pace \\textbf{A}daptation\n(\\textbf{U-DSA}) module to enhance the adaptability of representations while\nmaintaining generalization performance. These improvements not only enhance the\nframework's generalization capabilities but also boost its ability to represent\ncomplex representations. Our experimental results on four benchmark datasets\nunder different evaluation protocols demonstrate that the MMDA framework\noutperforms existing state-of-the-art methods in terms of cross-domain\ngeneralization and multimodal detection accuracy. The code will be released\nsoon.", "AI": {"tldr": "The paper introduces the MMDA framework for Face Anti-Spoofing (FAS), addressing generalization issues in multimodal methods through denoising, alignment, and attention mechanisms, outperforming state-of-the-art methods.", "motivation": "Current multimodal FAS methods face challenges like modality-specific biases and domain shifts, limiting generalization. The goal is to improve cross-modal alignment and noise suppression.", "method": "The MMDA framework uses CLIP for zero-shot generalization, MD2A for noise mitigation, RS2 for flexible alignment, and U-DSA for representation adaptability.", "result": "Experiments on four datasets show MMDA outperforms existing methods in cross-domain generalization and multimodal detection accuracy.", "conclusion": "MMDA enhances FAS generalization and representation capabilities, with promising results and future code release."}}
{"id": "2505.09498", "pdf": "https://arxiv.org/pdf/2505.09498", "abs": "https://arxiv.org/abs/2505.09498", "authors": ["Bo Zhang", "Shuo Li", "Runhe Tian", "Yang Yang", "Jixin Tang", "Jinhao Zhou", "Lin Ma"], "title": "Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 7 figures", "summary": "In this paper, we introduce Flash-VL 2B, a novel approach to optimizing\nVision-Language Models (VLMs) for real-time applications, targeting ultra-low\nlatency and high throughput without sacrificing accuracy. Leveraging advanced\narchitectural enhancements and efficient computational strategies, Flash-VL 2B\nis designed to maximize throughput by reducing processing time while\nmaintaining competitive performance across multiple vision-language benchmarks.\nOur approach includes tailored architectural choices, token compression\nmechanisms, data curation, training schemes, and a novel image processing\ntechnique called implicit semantic stitching that effectively balances\ncomputational load and model performance. Through extensive evaluations on 11\nstandard VLM benchmarks, we demonstrate that Flash-VL 2B achieves\nstate-of-the-art results in both speed and accuracy, making it a promising\nsolution for deployment in resource-constrained environments and large-scale\nreal-time applications.", "AI": {"tldr": "Flash-VL 2B optimizes Vision-Language Models for real-time use, achieving high speed and accuracy through architectural and computational enhancements.", "motivation": "To enable real-time applications of VLMs with ultra-low latency and high throughput without compromising accuracy.", "method": "Uses architectural enhancements, token compression, data curation, training schemes, and implicit semantic stitching for efficient processing.", "result": "Achieves state-of-the-art speed and accuracy on 11 VLM benchmarks.", "conclusion": "Flash-VL 2B is a viable solution for resource-constrained and large-scale real-time applications."}}
{"id": "2505.08899", "pdf": "https://arxiv.org/pdf/2505.08899", "abs": "https://arxiv.org/abs/2505.08899", "authors": ["Andrew Mullhaupt", "Cheng Peng"], "title": "Bounding Neyman-Pearson Region with $f$-Divergences", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "The Neyman-Pearson region of a simple binary hypothesis testing is the set of\npoints whose coordinates represent the false positive rate and false negative\nrate of some test. The lower boundary of this region is given by the\nNeyman-Pearson lemma, and is up to a coordinate change, equivalent to the\noptimal ROC curve. We establish a novel lower bound for the boundary in terms\nof any $f$-divergence. Since the bound generated by hockey-stick\n$f$-divergences characterizes the Neyman-Pearson boundary, this bound is best\npossible. In the case of KL divergence, this bound improves Pinsker's\ninequality. Furthermore, we obtain a closed-form refined upper bound for the\nNeyman-Pearson boundary in terms of the Chernoff $\\alpha$-coefficient. Finally,\nwe present methods for constructing pairs of distributions that can\napproximately or exactly realize any given Neyman-Pearson boundary.", "AI": {"tldr": "The paper establishes a novel lower bound for the Neyman-Pearson boundary in terms of any $f$-divergence, improves Pinsker's inequality for KL divergence, and provides methods to construct distributions realizing given boundaries.", "motivation": "To better understand and characterize the Neyman-Pearson boundary in hypothesis testing, particularly through $f$-divergences and Chernoff coefficients.", "method": "The authors derive bounds for the Neyman-Pearson boundary using $f$-divergences, refine Pinsker's inequality, and develop methods to construct distributions that match given boundaries.", "result": "A best-possible lower bound for the boundary is established, Pinsker's inequality is improved, and a closed-form upper bound is derived. Construction methods for distributions are also presented.", "conclusion": "The work provides new insights and tools for analyzing the Neyman-Pearson boundary, with practical implications for hypothesis testing and distribution construction."}}
{"id": "2505.09528", "pdf": "https://arxiv.org/pdf/2505.09528", "abs": "https://arxiv.org/abs/2505.09528", "authors": ["Jeffrey Wen", "Rizwan Ahmad", "Philip Schniter"], "title": "Conformal Bounds on Full-Reference Image Quality for Imaging Inverse Problems", "categories": ["cs.CV"], "comment": null, "summary": "In imaging inverse problems, we would like to know how close the recovered\nimage is to the true image in terms of full-reference image quality (FRIQ)\nmetrics like PSNR, SSIM, LPIPS, etc. This is especially important in\nsafety-critical applications like medical imaging, where knowing that, say, the\nSSIM was poor could potentially avoid a costly misdiagnosis. But since we don't\nknow the true image, computing FRIQ is non-trivial. In this work, we combine\nconformal prediction with approximate posterior sampling to construct bounds on\nFRIQ that are guaranteed to hold up to a user-specified error probability. We\ndemonstrate our approach on image denoising and accelerated magnetic resonance\nimaging (MRI) problems. Code is available at\nhttps://github.com/jwen307/quality_uq.", "AI": {"tldr": "The paper proposes a method to bound full-reference image quality (FRIQ) metrics without knowing the true image, using conformal prediction and approximate posterior sampling, validated on denoising and MRI tasks.", "motivation": "In safety-critical applications like medical imaging, knowing the quality of recovered images is crucial to avoid misdiagnoses, but FRIQ metrics cannot be directly computed without the true image.", "method": "Combines conformal prediction with approximate posterior sampling to construct guaranteed bounds on FRIQ metrics.", "result": "Demonstrated effectiveness on image denoising and accelerated MRI, with code publicly available.", "conclusion": "The approach provides reliable bounds on FRIQ metrics, aiding quality assessment in imaging inverse problems."}}
{"id": "2505.09561", "pdf": "https://arxiv.org/pdf/2505.09561", "abs": "https://arxiv.org/abs/2505.09561", "authors": ["Marcel Torne", "Andy Tang", "Yuejiang Liu", "Chelsea Finn"], "title": "Learning Long-Context Diffusion Policies via Past-Token Prediction", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Videos are available at https://long-context-dp.github.io", "summary": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x.", "AI": {"tldr": "The paper proposes Past-Token Prediction (PTP) to improve long-context policy learning in robotics by predicting past actions alongside future ones, enhancing temporal modeling and reducing training overhead.", "motivation": "Learning long-context policies from demonstrations is challenging due to memory demands and performance degradation from spurious correlations. Existing methods truncate context, losing critical historical information.", "method": "Introduces PTP, an auxiliary task predicting past action tokens, and a multistage training strategy: pre-training visual encoders with short contexts and fine-tuning with long-context embeddings. Also extends PTP to a self-verification mechanism during inference.", "result": "Improves long-context diffusion policy performance by 3x and accelerates training by over 10x across real-world and simulated tasks.", "conclusion": "PTP effectively addresses the challenge of retaining past information in long-context policies, offering significant performance and efficiency gains."}}
{"id": "2505.08908", "pdf": "https://arxiv.org/pdf/2505.08908", "abs": "https://arxiv.org/abs/2505.08908", "authors": ["Benedikt Koch", "Kosuke Imai"], "title": "Statistical Decision Theory with Counterfactual Loss", "categories": ["math.ST", "cs.LG", "econ.TH", "stat.TH"], "comment": null, "summary": "Classical statistical decision theory evaluates treatment choices based\nsolely on observed outcomes. However, by ignoring counterfactual outcomes, it\ncannot assess the quality of decisions relative to feasible alternatives. For\nexample, the quality of a physician's decision may depend not only on patient\nsurvival, but also on whether a less invasive treatment could have produced a\nsimilar result. To address this limitation, we extend standard decision theory\nto incorporate counterfactual losses--criteria that evaluate decisions using\nall potential outcomes. The central challenge in this generalization is\nidentification: because only one potential outcome is observed for each unit,\nthe associated risk under a counterfactual loss is generally not identifiable.\nWe show that under the assumption of strong ignorability, a counterfactual risk\nis identifiable if and only if the counterfactual loss function is additive in\nthe potential outcomes. Moreover, we demonstrate that additive counterfactual\nlosses can yield treatment recommendations that differ from those based on\nstandard loss functions, provided that the decision problem involves more than\ntwo treatment options.", "AI": {"tldr": "The paper extends classical decision theory by incorporating counterfactual outcomes to evaluate treatment choices, addressing limitations of traditional methods that ignore feasible alternatives.", "motivation": "Traditional decision theory fails to assess decision quality relative to feasible alternatives, such as less invasive treatments, by ignoring counterfactual outcomes.", "method": "The authors generalize standard decision theory to include counterfactual losses, focusing on identifiability under strong ignorability and additive loss functions.", "result": "Counterfactual risk is identifiable only if the loss function is additive in potential outcomes, leading to different treatment recommendations for problems with more than two options.", "conclusion": "Incorporating additive counterfactual losses can improve decision-making by considering all potential outcomes, especially in complex scenarios with multiple treatment choices."}}
{"id": "2505.09562", "pdf": "https://arxiv.org/pdf/2505.09562", "abs": "https://arxiv.org/abs/2505.09562", "authors": ["Nicola Marinello", "Simen Cassiman", "Jonas Heylen", "Marc Proesmans", "Luc Van Gool"], "title": "Camera-Only 3D Panoptic Scene Completion for Autonomous Driving through Differentiable Object Shapes", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025 Workshop on Autonomous Driving", "summary": "Autonomous vehicles need a complete map of their surroundings to plan and\nact. This has sparked research into the tasks of 3D occupancy prediction, 3D\nscene completion, and 3D panoptic scene completion, which predict a dense map\nof the ego vehicle's surroundings as a voxel grid. Scene completion extends\noccupancy prediction by predicting occluded regions of the voxel grid, and\npanoptic scene completion further extends this task by also distinguishing\nobject instances within the same class; both aspects are crucial for path\nplanning and decision-making. However, 3D panoptic scene completion is\ncurrently underexplored. This work introduces a novel framework for 3D panoptic\nscene completion that extends existing 3D semantic scene completion models. We\npropose an Object Module and Panoptic Module that can easily be integrated with\n3D occupancy and scene completion methods presented in the literature. Our\napproach leverages the available annotations in occupancy benchmarks, allowing\nindividual object shapes to be learned as a differentiable problem. The code is\navailable at https://github.com/nicolamarinello/OffsetOcc .", "AI": {"tldr": "A novel framework for 3D panoptic scene completion is introduced, extending existing 3D semantic scene completion models with Object and Panoptic Modules.", "motivation": "Autonomous vehicles require dense 3D maps for planning, but current 3D panoptic scene completion is underexplored.", "method": "Proposes Object and Panoptic Modules integrated with existing 3D occupancy and scene completion methods, leveraging occupancy benchmarks for learning object shapes.", "result": "The framework enables differentiable learning of individual object shapes, enhancing 3D panoptic scene completion.", "conclusion": "The approach advances 3D panoptic scene completion, crucial for autonomous vehicle decision-making."}}
{"id": "2505.09568", "pdf": "https://arxiv.org/pdf/2505.09568", "abs": "https://arxiv.org/abs/2505.09568", "authors": ["Jiuhai Chen", "Zhiyang Xu", "Xichen Pan", "Yushi Hu", "Can Qin", "Tom Goldstein", "Lifu Huang", "Tianyi Zhou", "Saining Xie", "Silvio Savarese", "Le Xue", "Caiming Xiong", "Ran Xu"], "title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unifying image understanding and generation has gained growing attention in\nrecent research on multimodal models. Although design choices for image\nunderstanding have been extensively studied, the optimal model architecture and\ntraining recipe for a unified framework with image generation remain\nunderexplored. Motivated by the strong potential of autoregressive and\ndiffusion models for high-quality generation and scalability, we conduct a\ncomprehensive study of their use in unified multimodal settings, with emphasis\non image representations, modeling objectives, and training strategies.\nGrounded in these investigations, we introduce a novel approach that employs a\ndiffusion transformer to generate semantically rich CLIP image features, in\ncontrast to conventional VAE-based representations. This design yields both\nhigher training efficiency and improved generative quality. Furthermore, we\ndemonstrate that a sequential pretraining strategy for unified models-first\ntraining on image understanding and subsequently on image generation-offers\npractical advantages by preserving image understanding capability while\ndeveloping strong image generation ability. Finally, we carefully curate a\nhigh-quality instruction-tuning dataset BLIP3o-60k for image generation by\nprompting GPT-4o with a diverse set of captions covering various scenes,\nobjects, human gestures, and more. Building on our innovative model design,\ntraining recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art\nunified multimodal models. BLIP3-o achieves superior performance across most of\nthe popular benchmarks spanning both image understanding and generation tasks.\nTo facilitate future research, we fully open-source our models, including code,\nmodel weights, training scripts, and pretraining and instruction tuning\ndatasets.", "AI": {"tldr": "The paper introduces BLIP3-o, a unified multimodal model combining image understanding and generation using a diffusion transformer and sequential pretraining. It outperforms benchmarks and is open-sourced.", "motivation": "To explore optimal architectures and training strategies for unifying image understanding and generation, leveraging autoregressive and diffusion models.", "method": "Uses a diffusion transformer for CLIP image features, sequential pretraining (understanding first, then generation), and a curated dataset (BLIP3o-60k) for instruction tuning.", "result": "BLIP3-o achieves state-of-the-art performance in both image understanding and generation tasks.", "conclusion": "The proposed approach is effective, scalable, and open-sourced to advance future research in unified multimodal models."}}
{"id": "2505.08986", "pdf": "https://arxiv.org/pdf/2505.08986", "abs": "https://arxiv.org/abs/2505.08986", "authors": ["Amirreza Davar", "Zhengtong Xu", "Siavash Mahmoudi", "Pouya Sohrabipour", "Chaitanya Pallerla", "Yu She", "Wan Shou", "Philip Crandall", "Dongyi Wang"], "title": "ChicGrasp: Imitation-Learning based Customized Dual-Jaw Gripper Control for Delicate, Irregular Bio-products Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": "Submitted for journal review", "summary": "Automated poultry processing lines still rely on humans to lift slippery,\neasily bruised carcasses onto a shackle conveyor. Deformability, anatomical\nvariance, and strict hygiene rules make conventional suction and scripted\nmotions unreliable. We present ChicGrasp, an end--to--end hardware--software\nco-design for this task. An independently actuated dual-jaw pneumatic gripper\nclamps both chicken legs, while a conditional diffusion-policy controller,\ntrained from only 50 multi--view teleoperation demonstrations (RGB +\nproprioception), plans 5 DoF end--effector motion, which includes jaw commands\nin one shot. On individually presented raw broiler carcasses, our system\nachieves a 40.6\\% grasp--and--lift success rate and completes the pick to\nshackle cycle in 38 s, whereas state--of--the--art implicit behaviour cloning\n(IBC) and LSTM-GMM baselines fail entirely. All CAD, code, and datasets will be\nopen-source. ChicGrasp shows that imitation learning can bridge the gap between\nrigid hardware and variable bio--products, offering a reproducible benchmark\nand a public dataset for researchers in agricultural engineering and robot\nlearning.", "AI": {"tldr": "ChicGrasp is a hardware-software co-design for automating poultry processing, using a dual-jaw gripper and a diffusion-policy controller trained from 50 demonstrations. It achieves a 40.6% success rate, outperforming baselines.", "motivation": "Current poultry processing relies on humans due to challenges like deformability and hygiene, which conventional methods can't address.", "method": "Uses an actuated dual-jaw gripper and a conditional diffusion-policy controller trained from multi-view teleoperation demonstrations.", "result": "Achieves 40.6% grasp-and-lift success rate and completes the cycle in 38s, outperforming IBC and LSTM-GMM baselines.", "conclusion": "ChicGrasp demonstrates imitation learning's potential for handling bio-products, providing a benchmark and dataset for future research."}}
{"id": "2505.09564", "pdf": "https://arxiv.org/pdf/2505.09564", "abs": "https://arxiv.org/abs/2505.09564", "authors": ["Anne-Marie Rickmann", "Stephanie L. Thorn", "Shawn S. Ahn", "Supum Lee", "Selen Uman", "Taras Lysyy", "Rachel Burns", "Nicole Guerrera", "Francis G. Spinale", "Jason A. Burdick", "Albert J. Sinusas", "James S. Duncan"], "title": "Using Foundation Models as Pseudo-Label Generators for Pre-Clinical 4D Cardiac CT Segmentation", "categories": ["cs.CV"], "comment": "accepted at FIMH 2025", "summary": "Cardiac image segmentation is an important step in many cardiac image\nanalysis and modeling tasks such as motion tracking or simulations of cardiac\nmechanics. While deep learning has greatly advanced segmentation in clinical\nsettings, there is limited work on pre-clinical imaging, notably in porcine\nmodels, which are often used due to their anatomical and physiological\nsimilarity to humans. However, differences between species create a domain\nshift that complicates direct model transfer from human to pig data.\n  Recently, foundation models trained on large human datasets have shown\npromise for robust medical image segmentation; yet their applicability to\nporcine data remains largely unexplored. In this work, we investigate whether\nfoundation models can generate sufficiently accurate pseudo-labels for pig\ncardiac CT and propose a simple self-training approach to iteratively refine\nthese labels. Our method requires no manually annotated pig data, relying\ninstead on iterative updates to improve segmentation quality. We demonstrate\nthat this self-training process not only enhances segmentation accuracy but\nalso smooths out temporal inconsistencies across consecutive frames. Although\nour results are encouraging, there remains room for improvement, for example by\nincorporating more sophisticated self-training strategies and by exploring\nadditional foundation models and other cardiac imaging technologies.", "AI": {"tldr": "The paper explores using foundation models for cardiac CT segmentation in porcine models via self-training, improving accuracy without manual annotations.", "motivation": "Pre-clinical cardiac imaging, especially in porcine models, lacks robust segmentation methods due to domain shifts from human data.", "method": "A self-training approach iteratively refines pseudo-labels from foundation models, requiring no manual pig annotations.", "result": "Self-training enhances segmentation accuracy and temporal consistency in porcine cardiac CT.", "conclusion": "While promising, further improvements could involve advanced self-training strategies and exploring other foundation models or imaging technologies."}}
{"id": "2505.09576", "pdf": "https://arxiv.org/pdf/2505.09576", "abs": "https://arxiv.org/abs/2505.09576", "authors": ["Shannon Lodoen", "Alexi Orchard"], "title": "Ethics and Persuasion in Reinforcement Learning from Human Feedback: A Procedural Rhetorical Approach", "categories": ["cs.CY", "cs.AI"], "comment": "10 pages, 1 figure, Accepted version", "summary": "Since 2022, versions of generative AI chatbots such as ChatGPT and Claude\nhave been trained using a specialized technique called Reinforcement Learning\nfrom Human Feedback (RLHF) to fine-tune language model output using feedback\nfrom human annotators. As a result, the integration of RLHF has greatly\nenhanced the outputs of these large language models (LLMs) and made the\ninteractions and responses appear more \"human-like\" than those of previous\nversions using only supervised learning. The increasing convergence of human\nand machine-written text has potentially severe ethical, sociotechnical, and\npedagogical implications relating to transparency, trust, bias, and\ninterpersonal relations. To highlight these implications, this paper presents a\nrhetorical analysis of some of the central procedures and processes currently\nbeing reshaped by RLHF-enhanced generative AI chatbots: upholding language\nconventions, information seeking practices, and expectations for social\nrelationships. Rhetorical investigations of generative AI and LLMs have, to\nthis point, focused largely on the persuasiveness of the content generated.\nUsing Ian Bogost's concept of procedural rhetoric, this paper shifts the site\nof rhetorical investigation from content analysis to the underlying mechanisms\nof persuasion built into RLHF-enhanced LLMs. In doing so, this theoretical\ninvestigation opens a new direction for further inquiry in AI ethics that\nconsiders how procedures rerouted through AI-driven technologies might\nreinforce hegemonic language use, perpetuate biases, decontextualize learning,\nand encroach upon human relationships. It will therefore be of interest to\neducators, researchers, scholars, and the growing number of users of generative\nAI chatbots.", "AI": {"tldr": "The paper explores how RLHF enhances AI chatbots, making them more human-like, and examines ethical and sociotechnical implications like bias and transparency.", "motivation": "To analyze the ethical and pedagogical impacts of RLHF-enhanced AI chatbots on language, information seeking, and social relationships.", "method": "Uses rhetorical analysis, particularly procedural rhetoric, to shift focus from content to the persuasive mechanisms in RLHF.", "result": "Highlights how RLHF may reinforce biases, decontextualize learning, and affect human relationships.", "conclusion": "Calls for further inquiry into AI ethics, focusing on procedural impacts, and appeals to educators, researchers, and users."}}
{"id": "2505.09004", "pdf": "https://arxiv.org/pdf/2505.09004", "abs": "https://arxiv.org/abs/2505.09004", "authors": ["Monica Welfert", "Nathan Stromberg", "Mario Diaz", "Lalitha Sankar"], "title": "Lower Bounds on the MMSE of Adversarially Inferring Sensitive Features", "categories": ["stat.ML", "cs.LG"], "comment": "submitted to IEEE Transactions on Information Theory", "summary": "We propose an adversarial evaluation framework for sensitive feature\ninference based on minimum mean-squared error (MMSE) estimation with a finite\nsample size and linear predictive models. Our approach establishes theoretical\nlower bounds on the true MMSE of inferring sensitive features from noisy\nobservations of other correlated features. These bounds are expressed in terms\nof the empirical MMSE under a restricted hypothesis class and a non-negative\nerror term. The error term captures both the estimation error due to finite\nnumber of samples and the approximation error from using a restricted\nhypothesis class. For linear predictive models, we derive closed-form bounds,\nwhich are order optimal in terms of the noise variance, on the approximation\nerror for several classes of relationships between the sensitive and\nnon-sensitive features, including linear mappings, binary symmetric channels,\nand class-conditional multi-variate Gaussian distributions. We also present a\nnew lower bound that relies on the MSE computed on a hold-out validation\ndataset of the MMSE estimator learned on finite-samples and a restricted\nhypothesis class. Through empirical evaluation, we demonstrate that our\nframework serves as an effective tool for MMSE-based adversarial evaluation of\nsensitive feature inference that balances theoretical guarantees with practical\nefficiency.", "AI": {"tldr": "Proposes an adversarial evaluation framework for sensitive feature inference using MMSE estimation, providing theoretical lower bounds and empirical validation.", "motivation": "To address the challenge of inferring sensitive features from noisy observations while ensuring theoretical guarantees and practical efficiency.", "method": "Uses MMSE estimation with finite sample size and linear predictive models, deriving closed-form bounds for various feature relationships.", "result": "Establishes order-optimal bounds on approximation error and introduces a new lower bound using validation data.", "conclusion": "The framework effectively balances theoretical rigor with practical utility for adversarial evaluation of sensitive feature inference."}}
{"id": "2505.09571", "pdf": "https://arxiv.org/pdf/2505.09571", "abs": "https://arxiv.org/abs/2505.09571", "authors": ["Guillermo Gomez-Trenado", "Pablo Mesejo", "Oscar Cord\u00f3n", "St\u00e9phane Lathuili\u00e8re"], "title": "Don't Forget your Inverse DDIM for Image Editing", "categories": ["cs.CV", "I.2.10; I.5.0"], "comment": "12 pages, 12 figures, code available at\n  https://guillermogotre.github.io/sage/", "summary": "The field of text-to-image generation has undergone significant advancements\nwith the introduction of diffusion models. Nevertheless, the challenge of\nediting real images persists, as most methods are either computationally\nintensive or produce poor reconstructions. This paper introduces SAGE\n(Self-Attention Guidance for image Editing) - a novel technique leveraging\npre-trained diffusion models for image editing. SAGE builds upon the DDIM\nalgorithm and incorporates a novel guidance mechanism utilizing the\nself-attention layers of the diffusion U-Net. This mechanism computes a\nreconstruction objective based on attention maps generated during the inverse\nDDIM process, enabling efficient reconstruction of unedited regions without the\nneed to precisely reconstruct the entire input image. Thus, SAGE directly\naddresses the key challenges in image editing. The superiority of SAGE over\nother methods is demonstrated through quantitative and qualitative evaluations\nand confirmed by a statistically validated comprehensive user study, in which\nall 47 surveyed users preferred SAGE over competing methods. Additionally, SAGE\nranks as the top-performing method in seven out of 10 quantitative analyses and\nsecures second and third places in the remaining three.", "AI": {"tldr": "SAGE introduces a novel image editing technique using pre-trained diffusion models, outperforming existing methods in efficiency and quality.", "motivation": "Addressing the challenges of computationally intensive or poor-quality image editing in text-to-image generation.", "method": "Leverages DDIM algorithm with a self-attention guidance mechanism for efficient reconstruction of unedited regions.", "result": "Outperforms competitors in user studies and quantitative analyses, ranking top in 7 out of 10 evaluations.", "conclusion": "SAGE effectively tackles key image editing challenges, offering superior performance and user preference."}}
{"id": "2505.09591", "pdf": "https://arxiv.org/pdf/2505.09591", "abs": "https://arxiv.org/abs/2505.09591", "authors": ["Tobias Jan Wieczorek", "Nathalie Daun", "Mohammad Emtiyaz Khan", "Marcus Rohrbach"], "title": "Variational Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 16 figures, under review at ICCV 2025", "summary": "Despite remarkable progress in multimodal models for Visual Question\nAnswering (VQA), there remain major reliability concerns because the models can\noften be overconfident and miscalibrated, especially in out-of-distribution\n(OOD) settings. Plenty has been done to address such issues for unimodal\nmodels, but little work exists for multimodal cases. Here, we address\nunreliability in multimodal models by proposing a Variational VQA approach.\nSpecifically, instead of fine-tuning vision-language models by using AdamW, we\nemploy a recently proposed variational algorithm called IVON, which yields a\nposterior distribution over model parameters. Through extensive experiments, we\nshow that our approach improves calibration and abstentions without sacrificing\nthe accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce\nExpected Calibration Error by more than 50% compared to the AdamW baseline and\nraise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of\ndistribution shifts, the performance gain is even higher, achieving 8% Coverage\n(@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we\npresent variational learning as a viable option to enhance the reliability of\nmultimodal models.", "AI": {"tldr": "A Variational VQA approach improves calibration and reliability in multimodal models, especially under OOD settings, outperforming AdamW fine-tuning.", "motivation": "Addressing reliability concerns in multimodal VQA models, particularly their overconfidence and miscalibration in OOD scenarios.", "method": "Proposes using IVON, a variational algorithm, to fine-tune vision-language models, yielding a posterior distribution over parameters.", "result": "Reduces Expected Calibration Error by over 50%, increases Coverage by 4% vs. SOTA, and achieves 8% improvement in OOD settings.", "conclusion": "Variational learning enhances the reliability of multimodal models, offering better calibration and performance under distribution shifts."}}
{"id": "2505.09026", "pdf": "https://arxiv.org/pdf/2505.09026", "abs": "https://arxiv.org/abs/2505.09026", "authors": ["Domniki Ladopoulou", "Dat Minh Hong", "Petros Dellaportas"], "title": "Probabilistic Wind Power Forecasting via Non-Stationary Gaussian Processes", "categories": ["stat.AP", "cs.LG", "stat.ML"], "comment": "11 pages, 3 figures, 2 tables", "summary": "Accurate probabilistic forecasting of wind power is essential for maintaining\ngrid stability and enabling efficient integration of renewable energy sources.\nGaussian Process (GP) models offer a principled framework for quantifying\nuncertainty; however, conventional approaches rely on stationary kernels, which\nare inadequate for modeling the inherently non-stationary nature of wind speed\nand power output. We propose a non-stationary GP framework that incorporates\nthe generalized spectral mixture (GSM) kernel, enabling the model to capture\ntime-varying patterns and heteroscedastic behaviors in wind speed and wind\npower data. We evaluate the performance of the proposed model on real-world\nSCADA data across short\\mbox{-,} medium-, and long-term forecasting horizons.\nCompared to standard radial basis function and spectral mixture kernels, the\nGSM-based model outperforms, particularly in short-term forecasts. These\nresults highlight the necessity of modeling non-stationarity in wind power\nforecasting and demonstrate the practical value of non-stationary GP models in\noperational settings.", "AI": {"tldr": "A non-stationary Gaussian Process (GP) framework with a generalized spectral mixture (GSM) kernel improves wind power forecasting by capturing time-varying patterns and heteroscedastic behaviors, outperforming traditional stationary kernels.", "motivation": "Accurate wind power forecasting is crucial for grid stability and renewable energy integration, but conventional stationary GP models fail to address the non-stationary nature of wind data.", "method": "The proposed non-stationary GP framework uses the GSM kernel to model time-varying and heteroscedastic behaviors in wind speed and power data.", "result": "The GSM-based model outperforms standard radial basis function and spectral mixture kernels, especially in short-term forecasts, as validated by real-world SCADA data.", "conclusion": "Non-stationary GP models are essential for accurate wind power forecasting and offer practical benefits in operational settings."}}
{"id": "2505.09608", "pdf": "https://arxiv.org/pdf/2505.09608", "abs": "https://arxiv.org/abs/2505.09608", "authors": ["Nadav Magar", "Amir Hertz", "Eric Tabellion", "Yael Pritch", "Alex Rav-Acha", "Ariel Shamir", "Yedid Hoshen"], "title": "LightLab: Controlling Light Sources in Images with Diffusion Models", "categories": ["cs.CV", "cs.GR"], "comment": "Project Page: https://nadmag.github.io/LightLab/", "summary": "We present a simple, yet effective diffusion-based method for fine-grained,\nparametric control over light sources in an image. Existing relighting methods\neither rely on multiple input views to perform inverse rendering at inference\ntime, or fail to provide explicit control over light changes. Our method\nfine-tunes a diffusion model on a small set of real raw photograph pairs,\nsupplemented by synthetically rendered images at scale, to elicit its\nphotorealistic prior for relighting. We leverage the linearity of light to\nsynthesize image pairs depicting controlled light changes of either a target\nlight source or ambient illumination. Using this data and an appropriate\nfine-tuning scheme, we train a model for precise illumination changes with\nexplicit control over light intensity and color. Lastly, we show how our method\ncan achieve compelling light editing results, and outperforms existing methods\nbased on user preference.", "AI": {"tldr": "A diffusion-based method for fine-grained control over light sources in images, outperforming existing relighting techniques.", "motivation": "Existing relighting methods lack explicit control over light changes or require multiple input views.", "method": "Fine-tunes a diffusion model on real and synthetic image pairs, leveraging light linearity for controlled changes.", "result": "Achieves precise illumination control and outperforms existing methods in user preference.", "conclusion": "The method provides effective, photorealistic light editing with explicit control."}}
{"id": "2505.09598", "pdf": "https://arxiv.org/pdf/2505.09598", "abs": "https://arxiv.org/abs/2505.09598", "authors": ["Nidhal Jegham", "Marwen Abdelatti", "Lassad Elmoubarki", "Abdeltawab Hendawi"], "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) spread across industries, understanding their\nenvironmental footprint at the inference level is no longer optional; it is\nessential. However, most existing studies exclude proprietary models, overlook\ninfrastructural variability and overhead, or focus solely on training, even as\ninference increasingly dominates AI's environmental impact. To bridge this gap,\nthis paper introduces a novel infrastructure-aware benchmarking framework for\nquantifying the environmental footprint of LLM inference across 30\nstate-of-the-art models as deployed in commercial data centers. Our framework\ncombines public API performance data with region-specific environmental\nmultipliers and statistical inference of hardware configurations. We\nadditionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank\nmodels by performance relative to environmental cost. Our results show that o3\nand DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33\nWh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and\nthat Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short\nGPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results\nin substantial annual environmental impacts. These include electricity use\ncomparable to 35,000 U.S. homes, freshwater evaporation matching the annual\ndrinking needs of 1.2 million people, and carbon emissions requiring a\nChicago-sized forest to offset. These findings illustrate a growing paradox:\nalthough individual queries are efficient, their global scale drives\ndisproportionate resource consumption. Our study provides a standardized,\nempirically grounded methodology for benchmarking the sustainability of LLM\ndeployments, laying a foundation for future environmental accountability in AI\ndevelopment and sustainability standards.", "AI": {"tldr": "The paper introduces a framework to measure the environmental impact of LLM inference, revealing significant energy and resource costs at scale, and identifies eco-efficient models.", "motivation": "Understanding the environmental footprint of LLM inference is crucial as it dominates AI's impact, yet prior studies overlook proprietary models and infrastructure variability.", "method": "A novel benchmarking framework combines API data, region-specific environmental multipliers, hardware inference, and cross-efficiency DEA to rank models by eco-efficiency.", "result": "O3 and DeepSeek-R1 are the most energy-intensive, while Claude-3.7 Sonnet is the most eco-efficient. Scaling GPT-4o queries reveals substantial annual environmental impacts.", "conclusion": "The study provides a standardized method for assessing LLM sustainability, highlighting the paradox of efficient individual queries versus global resource consumption."}}
{"id": "2505.09075", "pdf": "https://arxiv.org/pdf/2505.09075", "abs": "https://arxiv.org/abs/2505.09075", "authors": ["Carlos Misael Madrid Padilla", "Oscar Hernan Madrid Padilla", "Sabyasachi Chatterjee"], "title": "Risk Bounds For Distributional Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This work examines risk bounds for nonparametric distributional regression\nestimators. For convex-constrained distributional regression, general upper\nbounds are established for the continuous ranked probability score (CRPS) and\nthe worst-case mean squared error (MSE) across the domain. These theoretical\nresults are applied to isotonic and trend filtering distributional regression,\nyielding convergence rates consistent with those for mean estimation.\nFurthermore, a general upper bound is derived for distributional regression\nunder non-convex constraints, with a specific application to neural\nnetwork-based estimators. Comprehensive experiments on both simulated and real\ndata validate the theoretical contributions, demonstrating their practical\neffectiveness.", "AI": {"tldr": "The paper establishes risk bounds for nonparametric distributional regression, covering convex and non-convex constraints, with applications to isotonic, trend filtering, and neural network estimators, validated by experiments.", "motivation": "To provide theoretical guarantees for nonparametric distributional regression estimators, addressing both convex and non-convex constraints.", "method": "Derives upper bounds for CRPS and worst-case MSE, applying them to isotonic, trend filtering, and neural network-based regression.", "result": "Convergence rates consistent with mean estimation are achieved, and theoretical bounds are validated through experiments.", "conclusion": "The work offers practical and theoretical insights into distributional regression, demonstrating effectiveness across various estimators."}}
{"id": "2110.15907", "pdf": "https://arxiv.org/pdf/2110.15907", "abs": "https://arxiv.org/abs/2110.15907", "authors": ["Montaser Mohammedalamen", "Dustin Morrill", "Alexander Sieusahai", "Yash Satsangi", "Michael Bowling"], "title": "Learning to Be Cautious", "categories": ["cs.AI", "cs.LG"], "comment": "Under Review", "summary": "A key challenge in the field of reinforcement learning is to develop agents\nthat behave cautiously in novel situations. It is generally impossible to\nanticipate all situations that an autonomous system may face or what behavior\nwould best avoid bad outcomes. An agent that can learn to be cautious would\novercome this challenge by discovering for itself when and how to behave\ncautiously. In contrast, current approaches typically embed task-specific\nsafety information or explicit cautious behaviors into the system, which is\nerror-prone and imposes extra burdens on practitioners. In this paper, we\npresent both a sequence of tasks where cautious behavior becomes increasingly\nnon-obvious, as well as an algorithm to demonstrate that it is possible for a\nsystem to learn to be cautious. The essential features of our algorithm are\nthat it characterizes reward function uncertainty without task-specific safety\ninformation and uses this uncertainty to construct a robust policy.\nSpecifically, we construct robust policies with a k-of-N counterfactual regret\nminimization (CFR) subroutine given learned reward function uncertainty\nrepresented by a neural network ensemble. These policies exhibit caution in\neach of our tasks without any task-specific safety tuning.", "AI": {"tldr": "The paper introduces an algorithm for reinforcement learning agents to autonomously learn cautious behavior in novel situations, avoiding the need for task-specific safety tuning.", "motivation": "Current methods require embedding task-specific safety information, which is error-prone and burdensome. The goal is to develop agents that learn cautious behavior independently.", "method": "The algorithm characterizes reward function uncertainty using a neural network ensemble and constructs robust policies via k-of-N counterfactual regret minimization (CFR).", "result": "The system successfully learns cautious behavior in increasingly non-obvious tasks without task-specific safety tuning.", "conclusion": "The approach demonstrates that autonomous learning of cautious behavior is feasible, offering a scalable and generalizable solution."}}
{"id": "2505.09087", "pdf": "https://arxiv.org/pdf/2505.09087", "abs": "https://arxiv.org/abs/2505.09087", "authors": ["He Wang", "Yikun Zhang", "Jie Chen", "Jian Zhan", "Yaoqi Zhou"], "title": "A Comparative Review of RNA Language Models", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Given usefulness of protein language models (LMs) in structure and functional\ninference, RNA LMs have received increased attentions in the last few years.\nHowever, these RNA models are often not compared against the same standard.\nHere, we divided RNA LMs into three classes (pretrained on multiple RNA types\n(especially noncoding RNAs), specific-purpose RNAs, and LMs that unify RNA with\nDNA or proteins or both) and compared 13 RNA LMs along with 3 DNA and 1 protein\nLMs as controls in zero-shot prediction of RNA secondary structure and\nfunctional classification. Results shows that the models doing well on\nsecondary structure prediction often perform worse in function classification\nor vice versa, suggesting that more balanced unsupervised training is needed.", "AI": {"tldr": "RNA language models (LMs) are compared for secondary structure and function prediction, revealing performance trade-offs.", "motivation": "To standardize evaluation of RNA LMs and assess their performance in structure and function prediction.", "method": "Classified 13 RNA LMs into three categories and compared them with DNA/protein LMs in zero-shot tasks.", "result": "Models excelling in structure prediction often underperform in function classification, and vice versa.", "conclusion": "Balanced unsupervised training is needed to improve RNA LMs for both tasks."}}
{"id": "2505.08889", "pdf": "https://arxiv.org/pdf/2505.08889", "abs": "https://arxiv.org/abs/2505.08889", "authors": ["Linjie Lyu", "Valentin Deschaintre", "Yannick Hold-Geoffroy", "Milo\u0161 Ha\u0161an", "Jae Shin Yoon", "Thomas Leimk\u00fchler", "Christian Theobalt", "Iliyan Georgiev"], "title": "IntrinsicEdit: Precise generative image manipulation in intrinsic space", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025 Journal track", "summary": "Generative diffusion models have advanced image editing with high-quality\nresults and intuitive interfaces such as prompts and semantic drawing. However,\nthese interfaces lack precise control, and the associated methods typically\nspecialize on a single editing task. We introduce a versatile, generative\nworkflow that operates in an intrinsic-image latent space, enabling semantic,\nlocal manipulation with pixel precision for a range of editing operations.\nBuilding atop the RGB-X diffusion framework, we address key challenges of\nidentity preservation and intrinsic-channel entanglement. By incorporating\nexact diffusion inversion and disentangled channel manipulation, we enable\nprecise, efficient editing with automatic resolution of global illumination\neffects -- all without additional data collection or model fine-tuning. We\ndemonstrate state-of-the-art performance across a variety of tasks on complex\nimages, including color and texture adjustments, object insertion and removal,\nglobal relighting, and their combinations.", "AI": {"tldr": "A versatile generative workflow in intrinsic-image latent space enables precise, semantic image editing without additional data or fine-tuning.", "motivation": "Current diffusion models lack precise control and specialize in single tasks, limiting their versatility in image editing.", "method": "Uses RGB-X diffusion framework with exact diffusion inversion and disentangled channel manipulation for pixel-precise editing.", "result": "Achieves state-of-the-art performance in tasks like color/texture adjustments, object insertion/removal, and global relighting.", "conclusion": "The method provides a flexible, high-quality solution for diverse image editing tasks with minimal overhead."}}
{"id": "2306.09138", "pdf": "https://arxiv.org/pdf/2306.09138", "abs": "https://arxiv.org/abs/2306.09138", "authors": ["Riccardo Zese", "Evelina Lamma", "Fabrizio Riguzzi"], "title": "Exploiting Uncertainty for Querying Inconsistent Description Logics Knowledge Bases", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "The necessity to manage inconsistency in Description Logics Knowledge Bases\n(KBs) has come to the fore with the increasing importance gained by the\nSemantic Web, where information comes from different sources that constantly\nchange their content and may contain contradictory descriptions when considered\neither alone or together. Classical reasoning algorithms do not handle\ninconsistent KBs, forcing the debugging of the KB in order to remove the\ninconsistency. In this paper, we exploit an existing probabilistic semantics\ncalled DISPONTE to overcome this problem and allow queries also in case of\ninconsistent KBs. We implemented our approach in the reasoners TRILL and BUNDLE\nand empirically tested the validity of our proposal. Moreover, we formally\ncompare the presented approach to that of the repair semantics, one of the most\nestablished semantics when considering DL reasoning tasks.", "AI": {"tldr": "The paper addresses inconsistency in Description Logics Knowledge Bases (KBs) by using the probabilistic semantics DISPONTE, enabling queries even with inconsistent KBs. It compares this approach to repair semantics.", "motivation": "Inconsistency in KBs arises from diverse, dynamic Semantic Web sources, and classical reasoning fails to handle it.", "method": "Uses DISPONTE probabilistic semantics, implemented in TRILL and BUNDLE reasoners, and compares it to repair semantics.", "result": "Empirical tests validate the approach, showing it works with inconsistent KBs.", "conclusion": "DISPONTE offers a viable alternative to classical debugging, allowing reasoning with inconsistent KBs."}}
{"id": "2505.09098", "pdf": "https://arxiv.org/pdf/2505.09098", "abs": "https://arxiv.org/abs/2505.09098", "authors": ["Yan Hao Ling", "Zhouhao Yang", "Jonathan Scarlett"], "title": "Statistical Mean Estimation with Coded Relayed Observations", "categories": ["cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "comment": null, "summary": "We consider a problem of statistical mean estimation in which the samples are\nnot observed directly, but are instead observed by a relay (``teacher'') that\ntransmits information through a memoryless channel to the decoder\n(``student''), who then produces the final estimate. We consider the minimax\nestimation error in the large deviations regime, and establish achievable error\nexponents that are tight in broad regimes of the estimation accuracy and\nchannel quality. In contrast, two natural baseline methods are shown to yield\nstrictly suboptimal error exponents. We initially focus on Bernoulli sources\nand binary symmetric channels, and then generalize to sub-Gaussian and\nheavy-tailed settings along with arbitrary discrete memoryless channels.", "AI": {"tldr": "The paper studies statistical mean estimation where samples are relayed through a noisy channel, establishing tight error exponents and showing suboptimality of baseline methods.", "motivation": "To address the challenge of mean estimation when samples are indirectly observed via a noisy channel, aiming to optimize estimation accuracy.", "method": "Analyzes minimax estimation error in large deviations regime, focusing on Bernoulli sources and binary symmetric channels, then generalizing to sub-Gaussian, heavy-tailed, and arbitrary discrete memoryless channels.", "result": "Achieves tight error exponents in broad regimes, demonstrating suboptimality of two baseline methods.", "conclusion": "The proposed approach outperforms baseline methods, providing optimal error exponents for mean estimation under noisy channel conditions."}}
{"id": "2505.08932", "pdf": "https://arxiv.org/pdf/2505.08932", "abs": "https://arxiv.org/abs/2505.08932", "authors": ["Mohammad Wasil", "Ahmad Drak", "Brennan Penfold", "Ludovico Scarton", "Maximilian Johenneken", "Alexander Asteroth", "Sebastian Houben"], "title": "Parameter-Efficient Fine-Tuning of Vision Foundation Model for Forest Floor Segmentation from UAV Imagery", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to the Novel Approaches for Precision Agriculture and\n  Forestry with Autonomous Robots IEEE ICRA Workshop - 2025", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used for reforestation and\nforest monitoring, including seed dispersal in hard-to-reach terrains. However,\na detailed understanding of the forest floor remains a challenge due to high\nnatural variability, quickly changing environmental parameters, and ambiguous\nannotations due to unclear definitions. To address this issue, we adapt the\nSegment Anything Model (SAM), a vision foundation model with strong\ngeneralization capabilities, to segment forest floor objects such as tree\nstumps, vegetation, and woody debris. To this end, we employ\nparameter-efficient fine-tuning (PEFT) to fine-tune a small subset of\nadditional model parameters while keeping the original weights fixed. We adjust\nSAM's mask decoder to generate masks corresponding to our dataset categories,\nallowing for automatic segmentation without manual prompting. Our results show\nthat the adapter-based PEFT method achieves the highest mean intersection over\nunion (mIoU), while Low-rank Adaptation (LoRA), with fewer parameters, offers a\nlightweight alternative for resource-constrained UAV platforms.", "AI": {"tldr": "The paper adapts the Segment Anything Model (SAM) for forest floor segmentation using parameter-efficient fine-tuning (PEFT), achieving high accuracy with methods like adapter-based PEFT and LoRA.", "motivation": "Challenges in forest floor understanding due to variability, changing conditions, and unclear annotations motivate the use of SAM for automated segmentation.", "method": "SAM is fine-tuned using PEFT, adjusting the mask decoder for forest floor objects without manual prompting, comparing adapter-based PEFT and LoRA.", "result": "Adapter-based PEFT achieves the highest mIoU, while LoRA provides a lightweight alternative for UAVs.", "conclusion": "The adapted SAM with PEFT effectively segments forest floor objects, offering scalable solutions for UAV-based reforestation and monitoring."}}
{"id": "2411.04867", "pdf": "https://arxiv.org/pdf/2411.04867", "abs": "https://arxiv.org/abs/2411.04867", "authors": ["Satchit Chatterji", "Erman Acar"], "title": "Think Smart, Act SMARL! Analyzing Probabilistic Logic Shields for Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": "21 pages, 16 figures, Earlier title: \"Analyzing Probabilistic Logic\n  Driven Safety in Multi-Agent Reinforcement Learning\" (changed for specificity\n  and clarity)", "summary": "Safe reinforcement learning (RL) is crucial for real-world applications, and\nmulti-agent interactions introduce additional safety challenges. While\nProbabilistic Logic Shields (PLS) has been a powerful proposal to enforce\nsafety in single-agent RL, their generalizability to multi-agent settings\nremains unexplored. In this paper, we address this gap by conducting extensive\nanalyses of PLS within decentralized, multi-agent environments, and in doing\nso, propose Shielded Multi-Agent Reinforcement Learning (SMARL) as a general\nframework for steering MARL towards norm-compliant outcomes. Our key\ncontributions are: (1) a novel Probabilistic Logic Temporal Difference (PLTD)\nupdate for shielded, independent Q-learning, which incorporates probabilistic\nconstraints directly into the value update process; (2) a probabilistic logic\npolicy gradient method for shielded PPO with formal safety guarantees for MARL;\nand (3) comprehensive evaluation across symmetric and asymmetrically shielded\n$n$-player game-theoretic benchmarks, demonstrating fewer constraint violations\nand significantly better cooperation under normative constraints. These results\nposition SMARL as an effective mechanism for equilibrium selection, paving the\nway toward safer, socially aligned multi-agent systems.", "AI": {"tldr": "The paper introduces Shielded Multi-Agent Reinforcement Learning (SMARL), extending Probabilistic Logic Shields (PLS) to multi-agent settings for safer, norm-compliant outcomes.", "motivation": "Addressing the unexplored generalizability of PLS to multi-agent RL, aiming to enhance safety and cooperation in decentralized environments.", "method": "Proposes SMARL with (1) Probabilistic Logic Temporal Difference (PLTD) for Q-learning, (2) a shielded PPO method with safety guarantees, and (3) evaluation in game-theoretic benchmarks.", "result": "Demonstrates fewer constraint violations and improved cooperation under normative constraints.", "conclusion": "SMARL is effective for equilibrium selection, advancing safer, socially aligned multi-agent systems."}}
{"id": "2505.09099", "pdf": "https://arxiv.org/pdf/2505.09099", "abs": "https://arxiv.org/abs/2505.09099", "authors": ["Shirui Lyu", "Vittorio Caggiano", "Matteo Leonetti", "Dario Farina", "Letizia Gionfrida"], "title": "Imitation Learning for Adaptive Control of a Virtual Soft Exoglove", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "The use of wearable robots has been widely adopted in rehabilitation training\nfor patients with hand motor impairments. However, the uniqueness of patients'\nmuscle loss is often overlooked. Leveraging reinforcement learning and a\nbiologically accurate musculoskeletal model in simulation, we propose a\ncustomized wearable robotic controller that is able to address specific muscle\ndeficits and to provide compensation for hand-object manipulation tasks. Video\ndata of a same subject performing human grasping tasks is used to train a\nmanipulation model through learning from demonstration. This manipulation model\nis subsequently fine-tuned to perform object-specific interaction tasks. The\nmuscle forces in the musculoskeletal manipulation model are then weakened to\nsimulate neurological motor impairments, which are later compensated by the\nactuation of a virtual wearable robotics glove. Results shows that integrating\nthe virtual wearable robotic glove provides shared assistance to support the\nhand manipulator with weakened muscle forces. The learned exoglove controller\nachieved an average of 90.5\\% of the original manipulation proficiency.", "AI": {"tldr": "A reinforcement learning-based wearable robotic controller is proposed to address specific muscle deficits in hand rehabilitation, achieving 90.5% of original manipulation proficiency.", "motivation": "Current wearable robots for hand rehabilitation overlook patients' unique muscle loss, necessitating a customized solution.", "method": "Uses reinforcement learning and a musculoskeletal model in simulation, trained with video data of human grasping tasks, then fine-tuned for object-specific tasks. Muscle forces are weakened to simulate impairments and compensated by a virtual robotic glove.", "result": "The virtual robotic glove provided shared assistance, achieving 90.5% of the original manipulation proficiency.", "conclusion": "The proposed customized controller effectively compensates for muscle deficits in hand rehabilitation, demonstrating high proficiency."}}
{"id": "2505.08949", "pdf": "https://arxiv.org/pdf/2505.08949", "abs": "https://arxiv.org/abs/2505.08949", "authors": ["Kateryna Zorina", "David Kovar", "Mederic Fourmy", "Florent Lamiraux", "Nicolas Mansard", "Justin Carpentier", "Josef Sivic", "Vladimir Petrik"], "title": "Multi-step manipulation task and motion planning guided by video demonstration", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY"], "comment": null, "summary": "This work aims to leverage instructional video to solve complex multi-step\ntask-and-motion planning tasks in robotics. Towards this goal, we propose an\nextension of the well-established Rapidly-Exploring Random Tree (RRT) planner,\nwhich simultaneously grows multiple trees around grasp and release states\nextracted from the guiding video. Our key novelty lies in combining contact\nstates and 3D object poses extracted from the guiding video with a traditional\nplanning algorithm that allows us to solve tasks with sequential dependencies,\nfor example, if an object needs to be placed at a specific location to be\ngrasped later. We also investigate the generalization capabilities of our\napproach to go beyond the scene depicted in the instructional video. To\ndemonstrate the benefits of the proposed video-guided planning approach, we\ndesign a new benchmark with three challenging tasks: (I) 3D re-arrangement of\nmultiple objects between a table and a shelf, (ii) multi-step transfer of an\nobject through a tunnel, and (iii) transferring objects using a tray similar to\na waiter transfers dishes. We demonstrate the effectiveness of our planning\nalgorithm on several robots, including the Franka Emika Panda and the KUKA KMR\niiwa. For a seamless transfer of the obtained plans to the real robot, we\ndevelop a trajectory refinement approach formulated as an optimal control\nproblem (OCP).", "AI": {"tldr": "The paper proposes a video-guided RRT planner for multi-step robotic tasks, combining video-extracted data with traditional planning to handle sequential dependencies. It tests generalization and demonstrates effectiveness on real robots.", "motivation": "To solve complex multi-step robotic tasks using instructional videos, addressing sequential dependencies and generalization beyond the video scene.", "method": "Extends RRT by growing trees around video-extracted grasp/release states, combining contact states and 3D poses with planning. Tests on three tasks and refines trajectories via optimal control.", "result": "Effective planning on robots like Franka Emika Panda and KUKA KMR iiwa, with successful generalization beyond the video.", "conclusion": "The video-guided RRT planner is effective for multi-step tasks, with potential for real-world robotic applications."}}
{"id": "2411.11681", "pdf": "https://arxiv.org/pdf/2411.11681", "abs": "https://arxiv.org/abs/2411.11681", "authors": ["Jiawei Li", "Xinyue Liang", "Junlong Zhang", "Yizhe Yang", "Chong Feng", "Yang Gao"], "title": "PSPO*: An Effective Process-supervised Policy Optimization for Reasoning Alignment", "categories": ["cs.AI", "cs.LG"], "comment": "Our code can be found at https://github.com/DIRECT-BIT/PSPO", "summary": "Process supervision enhances the performance of large language models in\nreasoning tasks by providing feedback at each step of chain-of-thought\nreasoning. However, due to the lack of effective process supervision methods,\neven advanced large language models are prone to logical errors and redundant\nreasoning. We claim that the effectiveness of process supervision significantly\ndepends on both the accuracy and the length of reasoning chains. Moreover, we\nidentify that these factors exhibit a nonlinear relationship with the overall\nreward score of the reasoning process. Inspired by these insights, we propose a\nnovel process supervision paradigm, PSPO*, which systematically outlines the\nworkflow from reward model training to policy optimization, and highlights the\nimportance of nonlinear rewards in process supervision. Based on PSPO*, we\ndevelop the PSPO-WRS, which considers the number of reasoning steps in\ndetermining reward scores and utilizes an adjusted Weibull distribution for\nnonlinear reward shaping. Experimental results on six mathematical reasoning\ndatasets demonstrate that PSPO-WRS consistently outperforms current mainstream\nmodels.", "AI": {"tldr": "PSPO-WRS, a novel process supervision method, improves reasoning in large language models by using nonlinear rewards and adjusted Weibull distribution, outperforming existing models.", "motivation": "Current process supervision methods are ineffective, leading to logical errors and redundant reasoning in large language models.", "method": "Proposes PSPO*, a paradigm for reward model training and policy optimization, and PSPO-WRS, which uses nonlinear rewards and Weibull distribution for reward shaping.", "result": "PSPO-WRS outperforms mainstream models on six mathematical reasoning datasets.", "conclusion": "Effective process supervision requires nonlinear rewards and consideration of reasoning chain length, as demonstrated by PSPO-WRS."}}
{"id": "2505.09110", "pdf": "https://arxiv.org/pdf/2505.09110", "abs": "https://arxiv.org/abs/2505.09110", "authors": ["Zhihao Dou", "Jiaqi Wang", "Wei Sun", "Zhuqing Liu", "Minghong Fang"], "title": "Toward Malicious Clients Detection in Federated Learning", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "To appear in ACM ASIACCS 2025", "summary": "Federated learning (FL) enables multiple clients to collaboratively train a\nglobal machine learning model without sharing their raw data. However, the\ndecentralized nature of FL introduces vulnerabilities, particularly to\npoisoning attacks, where malicious clients manipulate their local models to\ndisrupt the training process. While Byzantine-robust aggregation rules have\nbeen developed to mitigate such attacks, they remain inadequate against more\nadvanced threats. In response, recent advancements have focused on FL detection\ntechniques to identify potentially malicious participants. Unfortunately, these\nmethods often misclassify numerous benign clients as threats or rely on\nunrealistic assumptions about the server's capabilities. In this paper, we\npropose a novel algorithm, SafeFL, specifically designed to accurately identify\nmalicious clients in FL. The SafeFL approach involves the server collecting a\nseries of global models to generate a synthetic dataset, which is then used to\ndistinguish between malicious and benign models based on their behavior.\nExtensive testing demonstrates that SafeFL outperforms existing methods,\noffering superior efficiency and accuracy in detecting malicious clients.", "AI": {"tldr": "SafeFL is a novel algorithm for accurately identifying malicious clients in federated learning, outperforming existing methods in efficiency and accuracy.", "motivation": "Federated learning is vulnerable to poisoning attacks, and current detection methods are either inaccurate or rely on unrealistic assumptions.", "method": "SafeFL collects global models to create a synthetic dataset, then distinguishes malicious from benign models based on behavior.", "result": "SafeFL outperforms existing methods in detecting malicious clients.", "conclusion": "SafeFL provides a robust solution for identifying malicious participants in federated learning."}}
{"id": "2505.08998", "pdf": "https://arxiv.org/pdf/2505.08998", "abs": "https://arxiv.org/abs/2505.08998", "authors": ["Liwen Wu", "Sai Bi", "Zexiang Xu", "Hao Tan", "Kai Zhang", "Fujun Luan", "Haolin Lu", "Ravi Ramamoorthi"], "title": "Neural BRDF Importance Sampling by Reparameterization", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Neural bidirectional reflectance distribution functions (BRDFs) have emerged\nas popular material representations for enhancing realism in physically-based\nrendering. Yet their importance sampling remains a significant challenge. In\nthis paper, we introduce a reparameterization-based formulation of neural BRDF\nimportance sampling that seamlessly integrates into the standard rendering\npipeline with precise generation of BRDF samples. The reparameterization-based\nformulation transfers the distribution learning task to a problem of\nidentifying BRDF integral substitutions. In contrast to previous methods that\nrely on invertible networks and multi-step inference to reconstruct BRDF\ndistributions, our model removes these constraints, which offers greater\nflexibility and efficiency. Our variance and performance analysis demonstrates\nthat our reparameterization method achieves the best variance reduction in\nneural BRDF renderings while maintaining high inference speeds compared to\nexisting baselines.", "AI": {"tldr": "A reparameterization-based method for neural BRDF importance sampling improves efficiency and flexibility in rendering.", "motivation": "Neural BRDFs enhance realism in rendering, but importance sampling remains challenging.", "method": "Reparameterization transfers distribution learning to BRDF integral substitutions, avoiding invertible networks and multi-step inference.", "result": "Achieves best variance reduction in neural BRDF renderings with high inference speeds.", "conclusion": "The method offers a flexible and efficient solution for neural BRDF importance sampling."}}
{"id": "2501.05765", "pdf": "https://arxiv.org/pdf/2501.05765", "abs": "https://arxiv.org/abs/2501.05765", "authors": ["Priya T. V.", "Shrisha Rao"], "title": "Deontic Temporal Logic for Formal Verification of AI Ethics", "categories": ["cs.AI", "cs.LO", "I.2.m; F.4.1"], "comment": null, "summary": "Ensuring ethical behavior in Artificial Intelligence (AI) systems amidst\ntheir increasing ubiquity and influence is a major concern the world over. The\nuse of formal methods in AI ethics is a possible crucial approach for\nspecifying and verifying the ethical behavior of AI systems. This paper\nproposes a formalization based on deontic logic to define and evaluate the\nethical behavior of AI systems, focusing on system-level specifications,\ncontributing to this important goal. It introduces axioms and theorems to\ncapture ethical requirements related to fairness and explainability. The\nformalization incorporates temporal operators to reason about the ethical\nbehavior of AI systems over time. The authors evaluate the effectiveness of\nthis formalization by assessing the ethics of the real-world COMPAS and loan\nprediction AI systems. Various ethical properties of the COMPAS and loan\nprediction systems are encoded using deontic logical formulas, allowing the use\nof an automated theorem prover to verify whether these systems satisfy the\ndefined properties. The formal verification reveals that both systems fail to\nfulfill certain key ethical properties related to fairness and\nnon-discrimination, demonstrating the effectiveness of the proposed\nformalization in identifying potential ethical issues in real-world AI\napplications.", "AI": {"tldr": "The paper proposes a deontic logic-based formalization to define and verify ethical behavior in AI systems, focusing on fairness and explainability. It tests this on COMPAS and loan prediction systems, revealing ethical shortcomings.", "motivation": "Addressing the need for ethical AI behavior, the paper explores formal methods to specify and verify ethical compliance in AI systems.", "method": "Uses deontic logic with temporal operators to formalize ethical requirements, applying automated theorem proving to real-world AI systems (COMPAS and loan prediction).", "result": "Formal verification shows both systems fail key ethical properties, highlighting the method's effectiveness in identifying ethical issues.", "conclusion": "The proposed formalization is effective for evaluating AI ethics, revealing real-world systems' ethical shortcomings."}}
{"id": "2505.09161", "pdf": "https://arxiv.org/pdf/2505.09161", "abs": "https://arxiv.org/abs/2505.09161", "authors": ["Yu Xin", "Peng Liu", "Zhuohang Xie", "Wenhui Mi", "Pengyue Gao", "Hong Jian Zhao", "Jian Lv", "Yanchao Wang", "Yanming Ma"], "title": "Bridging Theory and Experiment in Materials Discovery: Machine-Learning-Assisted Prediction of Synthesizable Structures", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Even though thermodynamic energy-based crystal structure prediction (CSP) has\nrevolutionized materials discovery, the energy-driven CSP approaches often\nstruggle to identify experimentally realizable metastable materials synthesized\nthrough kinetically controlled pathways, creating a critical gap between\ntheoretical predictions and experimental synthesis. Here, we propose a\nsynthesizability-driven CSP framework that integrates symmetry-guided structure\nderivation with a Wyckoff encode-based machine-learning model, allowing for the\nefficient localization of subspaces likely to yield highly synthesizable\nstructures. Within the identified promising subspaces, a structure-based\nsynthesizability evaluation model, fine-tuned using recently synthesized\nstructures to enhance predictive accuracy, is employed in conjunction with ab\ninitio calculations to systematically identify synthesizable candidates. The\nframework successfully reproduces 13 experimentally known XSe (X = Sc, Ti, Mn,\nFe, Ni, Cu, Zn) structures, demonstrating its effectiveness in predicting\nsynthesizable structures. Notably, 92,310 structures are filtered from the\n554,054 candidates predicted by GNoME, exhibiting great potential for promising\nsynthesizability. Additionally, eight thermodynamically favorable Hf-X-O (X =\nTi, V, and Mn) structures have been identified, among which three HfV$_2$O$_7$\ncandidates exhibit high synthesizability, presenting viable candidates for\nexperimental realization and potentially associated with experimentally\nobserved temperature-induced phase transitions. This work establishes a\ndata-driven paradigm for machine-learning-assisted inorganic materials\nsynthesis, highlighting its potential to bridge the gap between computational\npredictions and experimental realization while unlocking new opportunities for\nthe targeted discovery of novel functional materials.", "AI": {"tldr": "A synthesizability-driven crystal structure prediction (CSP) framework combines symmetry-guided derivation and machine learning to identify highly synthesizable materials, bridging the gap between theory and experiment.", "motivation": "Traditional energy-driven CSP struggles to predict metastable materials synthesized via kinetic pathways, creating a disconnect between predictions and experimental synthesis.", "method": "The framework integrates symmetry-guided structure derivation with a Wyckoff encode-based ML model to locate promising subspaces. A synthesizability evaluation model, fine-tuned with experimental data, is used alongside ab initio calculations.", "result": "The method successfully predicts 13 known XSe structures and filters 92,310 synthesizable candidates from 554,054. It also identifies eight Hf-X-O structures, with three HfV$_2$O$_7$ candidates showing high synthesizability.", "conclusion": "This data-driven approach bridges computational predictions and experimental synthesis, enabling targeted discovery of functional materials."}}
{"id": "2505.09109", "pdf": "https://arxiv.org/pdf/2505.09109", "abs": "https://arxiv.org/abs/2505.09109", "authors": ["Yuxing Chen", "Bowen Xiao", "He Wang"], "title": "FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Due to the deformability of garments, generating a large amount of\nhigh-quality data for robotic garment manipulation tasks is highly challenging.\nIn this paper, we present a synthetic garment dataset that can be used for\nrobotic garment folding. We begin by constructing geometric garment templates\nbased on keypoints and applying generative models to generate realistic texture\npatterns. Leveraging these keypoint annotations, we generate folding\ndemonstrations in simulation and train folding policies via closed-loop\nimitation learning. To improve robustness, we propose KG-DAgger, which uses a\nkeypoint-based strategy to generate demonstration data for recovering from\nfailures. KG-DAgger significantly improves the model performance, boosting the\nreal-world success rate by 25\\%. After training with 15K trajectories (about 2M\nimage-action pairs), the model achieves a 75\\% success rate in the real world.\nExperiments in both simulation and real-world settings validate the\neffectiveness of our proposed framework.", "AI": {"tldr": "A synthetic garment dataset for robotic folding is created using geometric templates and generative models. KG-DAgger improves robustness, boosting real-world success by 25% to 75%.", "motivation": "Generating high-quality data for robotic garment manipulation is challenging due to garment deformability.", "method": "Construct geometric garment templates, apply generative models for textures, and use KG-DAgger for robust imitation learning.", "result": "75% success rate in real-world folding after training with 15K trajectories (2M image-action pairs).", "conclusion": "The framework is effective for robotic garment folding, validated in simulation and real-world experiments."}}
{"id": "2503.16371", "pdf": "https://arxiv.org/pdf/2503.16371", "abs": "https://arxiv.org/abs/2503.16371", "authors": ["Minori Narita", "Ryo Kuroiwa", "J. Christopher Beck"], "title": "Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming", "categories": ["cs.AI", "cs.LG"], "comment": "24 pages, 4 figures, to be published in CPAIOR 2025\n  (https://sites.google.com/view/cpaior2025)", "summary": "Domain-Independent Dynamic Programming (DIDP) is a state-space search\nparadigm based on dynamic programming for combinatorial optimization. In its\ncurrent implementation, DIDP guides the search using user-defined dual bounds.\nReinforcement learning (RL) is increasingly being applied to combinatorial\noptimization problems and shares several key structures with DP, being\nrepresented by the Bellman equation and state-based transition systems. We\npropose using reinforcement learning to obtain a heuristic function to guide\nthe search in DIDP. We develop two RL-based guidance approaches: value-based\nguidance using Deep Q-Networks and policy-based guidance using Proximal Policy\nOptimization. Our experiments indicate that RL-based guidance significantly\noutperforms standard DIDP and problem-specific greedy heuristics with the same\nnumber of node expansions. Further, despite longer node evaluation times, RL\nguidance achieves better run-time performance than standard DIDP on three of\nfour benchmark domains.", "AI": {"tldr": "Using RL to guide DIDP improves performance over standard DIDP and greedy heuristics.", "motivation": "Combine RL's heuristic learning with DIDP's dynamic programming for better combinatorial optimization.", "method": "Developed value-based (DQN) and policy-based (PPO) RL approaches to guide DIDP search.", "result": "RL guidance outperforms standard DIDP and greedy heuristics in node expansions and runtime.", "conclusion": "RL-based guidance enhances DIDP, proving effective in most benchmark domains."}}
{"id": "2505.09167", "pdf": "https://arxiv.org/pdf/2505.09167", "abs": "https://arxiv.org/abs/2505.09167", "authors": ["Amit Daniely", "Idan Mehalel", "Elchanan Mossel"], "title": "Online Learning of Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study online learning of feedforward neural networks with the sign\nactivation function that implement functions from the unit ball in\n$\\mathbb{R}^d$ to a finite label set $\\{1, \\ldots, Y\\}$.\n  First, we characterize a margin condition that is sufficient and in some\ncases necessary for online learnability of a neural network: Every neuron in\nthe first hidden layer classifies all instances with some margin $\\gamma$\nbounded away from zero. Quantitatively, we prove that for any net, the optimal\nmistake bound is at most approximately $\\mathtt{TS}(d,\\gamma)$, which is the\n$(d,\\gamma)$-totally-separable-packing number, a more restricted variation of\nthe standard $(d,\\gamma)$-packing number. We complement this result by\nconstructing a net on which any learner makes $\\mathtt{TS}(d,\\gamma)$ many\nmistakes. We also give a quantitative lower bound of approximately\n$\\mathtt{TS}(d,\\gamma) \\geq \\max\\{1/(\\gamma \\sqrt{d})^d, d\\}$ when $\\gamma \\geq\n1/2$, implying that for some nets and input sequences every learner will err\nfor $\\exp(d)$ many times, and that a dimension-free mistake bound is almost\nalways impossible.\n  To remedy this inevitable dependence on $d$, it is natural to seek additional\nnatural restrictions to be placed on the network, so that the dependence on $d$\nis removed. We study two such restrictions. The first is the multi-index model,\nin which the function computed by the net depends only on $k \\ll d$ orthonormal\ndirections. We prove a mistake bound of approximately $(1.5/\\gamma)^{k + 2}$ in\nthis model. The second is the extended margin assumption. In this setting, we\nassume that all neurons (in all layers) in the network classify every ingoing\ninput from previous layer with margin $\\gamma$ bounded away from zero. In this\nmodel, we prove a mistake bound of approximately $(\\log Y)/ \\gamma^{O(L)}$,\nwhere L is the depth of the network.", "AI": {"tldr": "The paper studies online learning of feedforward neural networks with sign activation, focusing on margin conditions for learnability and deriving mistake bounds. It also explores restrictions like the multi-index model and extended margin assumption to reduce dimensionality dependence.", "motivation": "To understand the conditions under which neural networks with sign activation can be learned online, and to derive quantitative bounds on mistakes made during learning.", "method": "Characterizes a margin condition for learnability, proves optimal mistake bounds using the totally-separable-packing number, and explores additional restrictions (multi-index model and extended margin assumption) to mitigate dimensionality dependence.", "result": "For general nets, the mistake bound is approximately TS(d,\u03b3). Under the multi-index model, it's (1.5/\u03b3)^(k+2), and under the extended margin assumption, it's (log Y)/\u03b3^O(L).", "conclusion": "Margin conditions are crucial for online learnability, and additional restrictions can help reduce the dependence on input dimensionality."}}
{"id": "2505.09315", "pdf": "https://arxiv.org/pdf/2505.09315", "abs": "https://arxiv.org/abs/2505.09315", "authors": ["Xuefeng Jiang", "Yuan Ma", "Pengxiang Li", "Leimeng Xu", "Xin Wen", "Kun Zhan", "Zhongpu Xia", "Peng Jia", "XianPeng Lang", "Sheng Sun"], "title": "TransDiffuser: End-to-end Trajectory Generation with Decorrelated Multi-modal Representation for Autonomous Driving", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Under review", "summary": "In recent years, diffusion model has shown its potential across diverse\ndomains from vision generation to language modeling. Transferring its\ncapabilities to modern autonomous driving systems has also emerged as a\npromising direction.In this work, we propose TransDiffuser, an encoder-decoder\nbased generative trajectory planning model for end-to-end autonomous driving.\nThe encoded scene information serves as the multi-modal conditional input of\nthe denoising decoder. To tackle the mode collapse dilemma in generating\nhigh-quality diverse trajectories, we introduce a simple yet effective\nmulti-modal representation decorrelation optimization mechanism during the\ntraining process.TransDiffuser achieves PDMS of 94.85 on the NAVSIM benchmark,\nsurpassing previous state-of-the-art methods without any anchor-based prior\ntrajectories.", "AI": {"tldr": "TransDiffuser is a diffusion-based generative trajectory planning model for autonomous driving, outperforming state-of-the-art methods with a PDMS of 94.85 on NAVSIM.", "motivation": "To leverage diffusion models' potential for diverse trajectory planning in autonomous driving, addressing mode collapse.", "method": "Uses an encoder-decoder architecture with multi-modal conditional input and introduces a decorrelation optimization mechanism for diverse trajectory generation.", "result": "Achieves PDMS of 94.85 on NAVSIM, surpassing prior methods without anchor-based trajectories.", "conclusion": "TransDiffuser demonstrates the effectiveness of diffusion models in autonomous driving trajectory planning."}}
{"id": "2503.18938", "pdf": "https://arxiv.org/pdf/2503.18938", "abs": "https://arxiv.org/abs/2503.18938", "authors": ["Shenyuan Gao", "Siyuan Zhou", "Yilun Du", "Jun Zhang", "Chuang Gan"], "title": "AdaWorld: Learning Adaptable World Models with Latent Actions", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "comment": "ICML 2025. Project page: https://adaptable-world-model.github.io/,\n  code: https://github.com/Little-Podi/AdaWorld, model:\n  https://huggingface.co/Little-Podi/AdaWorld", "summary": "World models aim to learn action-controlled future prediction and have proven\nessential for the development of intelligent agents. However, most existing\nworld models rely heavily on substantial action-labeled data and costly\ntraining, making it challenging to adapt to novel environments with\nheterogeneous actions through limited interactions. This limitation can hinder\ntheir applicability across broader domains. To overcome this limitation, we\npropose AdaWorld, an innovative world model learning approach that enables\nefficient adaptation. The key idea is to incorporate action information during\nthe pretraining of world models. This is achieved by extracting latent actions\nfrom videos in a self-supervised manner, capturing the most critical\ntransitions between frames. We then develop an autoregressive world model that\nconditions on these latent actions. This learning paradigm enables highly\nadaptable world models, facilitating efficient transfer and learning of new\nactions even with limited interactions and finetuning. Our comprehensive\nexperiments across multiple environments demonstrate that AdaWorld achieves\nsuperior performance in both simulation quality and visual planning.", "AI": {"tldr": "AdaWorld is a world model learning approach that uses self-supervised latent actions for efficient adaptation to novel environments with limited data.", "motivation": "Existing world models require extensive action-labeled data and costly training, limiting adaptability to new environments.", "method": "AdaWorld extracts latent actions from videos self-supervisedly and conditions an autoregressive world model on these actions.", "result": "AdaWorld outperforms in simulation quality and visual planning across multiple environments.", "conclusion": "AdaWorld enables efficient adaptation and transfer of world models with limited interactions."}}
{"id": "2505.09229", "pdf": "https://arxiv.org/pdf/2505.09229", "abs": "https://arxiv.org/abs/2505.09229", "authors": ["Brian Britos", "Mathias Bourel"], "title": "Optimal Transport-Based Domain Adaptation for Rotated Linear Regression", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "Optimal Transport (OT) has proven effective for domain adaptation (DA) by\naligning distributions across domains with differing statistical properties.\nBuilding on the approach of Courty et al. (2016), who mapped source data to the\ntarget domain for improved model transfer, we focus on a supervised DA problem\ninvolving linear regression models under rotational shifts. This ongoing work\nconsiders cases where source and target domains are related by a\nrotation-common in applications like sensor calibration or image orientation.\nWe show that in $\\mathbb{R}^2$ , when using a p-norm cost with $p $\\ge$ 2$, the\noptimal transport map recovers the underlying rotation. Based on this, we\npropose an algorithm that combines K-means clustering, OT, and singular value\ndecomposition (SVD) to estimate the rotation angle and adapt the regression\nmodel. This method is particularly effective when the target domain is sparsely\nsampled, leveraging abundant source data for improved generalization. Our\ncontributions offer both theoretical and practical insights into OT-based model\nadaptation under geometric transformations.", "AI": {"tldr": "The paper explores using Optimal Transport (OT) for domain adaptation under rotational shifts, proposing an algorithm combining K-means, OT, and SVD to recover rotation angles and adapt regression models.", "motivation": "Addressing domain adaptation challenges where source and target domains differ by rotational shifts, common in applications like sensor calibration or image orientation.", "method": "Proposes an algorithm integrating K-means clustering, OT, and SVD to estimate rotation angles and adapt linear regression models, especially effective for sparsely sampled target domains.", "result": "Demonstrates that OT with a p-norm cost (p \u2265 2) in \u211d\u00b2 recovers underlying rotations, enabling effective model adaptation.", "conclusion": "The approach provides theoretical and practical insights into OT-based model adaptation under geometric transformations, enhancing generalization."}}
{"id": "2505.09356", "pdf": "https://arxiv.org/pdf/2505.09356", "abs": "https://arxiv.org/abs/2505.09356", "authors": ["Srinivas Ravuri", "Yuan Xu", "Martin Ludwig Zehetner", "Ketan Motlag", "Sahin Albayrak"], "title": "APR-Transformer: Initial Pose Estimation for Localization in Complex Environments through Absolute Pose Regression", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages with 6 figures", "summary": "Precise initialization plays a critical role in the performance of\nlocalization algorithms, especially in the context of robotics, autonomous\ndriving, and computer vision. Poor localization accuracy is often a consequence\nof inaccurate initial poses, particularly noticeable in GNSS-denied\nenvironments where GPS signals are primarily relied upon for initialization.\nRecent advances in leveraging deep neural networks for pose regression have led\nto significant improvements in both accuracy and robustness, especially in\nestimating complex spatial relationships and orientations. In this paper, we\nintroduce APR-Transformer, a model architecture inspired by state-of-the-art\nmethods, which predicts absolute pose (3D position and 3D orientation) using\neither image or LiDAR data. We demonstrate that our proposed method achieves\nstate-of-the-art performance on established benchmark datasets such as the\nRadar Oxford Robot-Car and DeepLoc datasets. Furthermore, we extend our\nexperiments to include our custom complex APR-BeIntelli dataset. Additionally,\nwe validate the reliability of our approach in GNSS-denied environments by\ndeploying the model in real-time on an autonomous test vehicle. This showcases\nthe practical feasibility and effectiveness of our approach. The source code is\navailable at:https://github.com/GT-ARC/APR-Transformer.", "AI": {"tldr": "APR-Transformer, a deep neural network model, improves localization accuracy by predicting absolute pose from image or LiDAR data, achieving state-of-the-art results on benchmarks and real-world GNSS-denied environments.", "motivation": "Poor localization accuracy due to inaccurate initial poses, especially in GNSS-denied environments, drives the need for robust pose estimation methods.", "method": "APR-Transformer, inspired by state-of-the-art methods, predicts 3D position and orientation using image or LiDAR data.", "result": "Achieves top performance on Radar Oxford Robot-Car, DeepLoc, and custom APR-BeIntelli datasets, validated in real-time autonomous vehicle tests.", "conclusion": "APR-Transformer is effective and feasible for precise localization, particularly in GNSS-denied scenarios."}}
{"id": "2503.21620", "pdf": "https://arxiv.org/pdf/2503.21620", "abs": "https://arxiv.org/abs/2503.21620", "authors": ["Zhengxi Lu", "Yuxiang Chai", "Yaxuan Guo", "Xi Yin", "Liang Liu", "Hao Wang", "Han Xiao", "Shuai Ren", "Guanjing Xiong", "Hongsheng Li"], "title": "UI-R1: Enhancing Efficient Action Prediction of GUI Agents by Reinforcement Learning", "categories": ["cs.AI"], "comment": "Updated UI-R1-E-3B", "summary": "The recent DeepSeek-R1 has showcased the emergence of reasoning capabilities\nin LLMs through reinforcement learning (RL) with rule-based rewards. Despite\nits success in language models, its application in multi-modal domains,\nparticularly in graphic user interface (GUI) agent tasks, remains\nunder-explored. To address this issue, we propose UI-R1, the first framework to\nexplore how rule-based RL can enhance the reasoning capabilities of multimodal\nlarge language models (MLLMs) for GUI action prediction tasks. Specifically,\nUI-R1 introduces a novel rule-based action reward, enabling model optimization\nvia policy-based algorithms such as Group Relative Policy Optimization (GRPO).\nFor efficient training, we curate a small yet high-quality dataset of 136\nchallenging tasks, encompassing five common action types on mobile devices.\nExperimental results demonstrate that our proposed UI-R1-3B achieves\nsignificant improvements over the base model (i.e. Qwen2.5-VL-3B) on both\nin-domain (ID) and out-of-domain (OOD) tasks, with average accuracy gains of\n22.1% on ScreenSpot, 6.0% on ScreenSpot-Pro, and 12.7% on ANDROIDCONTROL.\nFurthermore, UI-R1-3B delivers competitive performance compared to larger\nmodels (e.g., OS-Atlas-7B) trained via supervised fine-tuning (SFT) on 76K\nsamples. We additionally develop an optimized version, UI-R1-E-3B, which\nsignificantly improves both grounding efficiency and accuracy. These results\nunderscore the potential of rule-based reinforcement learning to advance GUI\nunderstanding and control, paving the way for future research in this domain.\nCode website: https://github.com/lll6gg/UI-R1.", "AI": {"tldr": "UI-R1 is a framework using rule-based RL to enhance MLLMs for GUI tasks, showing significant accuracy improvements over base models and competitive performance against larger models.", "motivation": "The under-explored application of rule-based RL in multi-modal domains, especially GUI agent tasks, motivates the development of UI-R1.", "method": "UI-R1 employs rule-based action rewards and policy-based algorithms like GRPO, trained on a curated dataset of 136 challenging tasks.", "result": "UI-R1-3B outperforms the base model with 22.1%, 6.0%, and 12.7% accuracy gains on benchmarks and competes with larger models.", "conclusion": "Rule-based RL holds promise for advancing GUI understanding, with UI-R1 paving the way for future research in this domain."}}
{"id": "2505.09266", "pdf": "https://arxiv.org/pdf/2505.09266", "abs": "https://arxiv.org/abs/2505.09266", "authors": ["Lirand\u00eb Pira", "Airin Antony", "Nayanthara Prathap", "Daniel Peace", "Jacquiline Romero"], "title": "Enhanced Photonic Chip Design via Interpretable Machine Learning Techniques", "categories": ["physics.optics", "cs.LG", "quant-ph"], "comment": null, "summary": "Photonic chip design has seen significant advancements with the adoption of\ninverse design methodologies, offering flexibility and efficiency in optimizing\ndevice performance. However, the black-box nature of the optimization\napproaches, such as those used in inverse design in order to minimize a loss\nfunction or maximize coupling efficiency, poses challenges in understanding the\noutputs. This challenge is prevalent in machine learning-based optimization\nmethods, which can suffer from the same lack of transparency. To this end,\ninterpretability techniques address the opacity of optimization models. In this\nwork, we apply interpretability techniques from machine learning, with the aim\nof gaining understanding of inverse design optimization used in designing\nphotonic components, specifically two-mode multiplexers. We base our\nmethodology on the widespread interpretability technique known as local\ninterpretable model-agnostic explanations, or LIME. As a result, LIME-informed\ninsights point us to more effective initial conditions, directly improving\ndevice performance. This demonstrates that interpretability methods can do more\nthan explain models -- they can actively guide and enhance the inverse-designed\nphotonic components. Our results demonstrate the ability of interpretable\ntechniques to reveal underlying patterns in the inverse design process, leading\nto the development of better-performing components.", "AI": {"tldr": "The paper applies interpretability techniques (LIME) to inverse design in photonic chip optimization, improving device performance by revealing underlying patterns.", "motivation": "The black-box nature of inverse design and machine learning optimization lacks transparency, hindering understanding and improvement of photonic components.", "method": "Uses LIME (local interpretable model-agnostic explanations) to analyze and interpret inverse design optimization for two-mode multiplexers.", "result": "LIME-informed insights improve initial conditions, enhancing device performance and revealing optimization patterns.", "conclusion": "Interpretability methods like LIME can actively guide and improve inverse-designed photonic components, beyond just explaining models."}}
{"id": "2207.14425", "pdf": "https://arxiv.org/pdf/2207.14425", "abs": "https://arxiv.org/abs/2207.14425", "authors": ["Hao Wang", "Wenhao Shen", "Guosheng Lin", "Steven C. H. Hoi", "Chunyan Miao"], "title": "3D Cartoon Face Generation with Controllable Expressions from a Single GAN Image", "categories": ["cs.CV"], "comment": "IJCNN 2025. Code:\n  https://github.com/hwang1996/3D-Cartoon-Face-Generation", "summary": "In this paper, we investigate an open research task of generating 3D cartoon\nface shapes from single 2D GAN generated human faces and without 3D\nsupervision, where we can also manipulate the facial expressions of the 3D\nshapes. To this end, we discover the semantic meanings of StyleGAN latent\nspace, such that we are able to produce face images of various expressions,\nposes, and lighting conditions by controlling the latent codes. Specifically,\nwe first finetune the pretrained StyleGAN face model on the cartoon datasets.\nBy feeding the same latent codes to face and cartoon generation models, we aim\nto realize the translation from 2D human face images to cartoon styled avatars.\nWe then discover semantic directions of the GAN latent space, in an attempt to\nchange the facial expressions while preserving the original identity. As we do\nnot have any 3D annotations for cartoon faces, we manipulate the latent codes\nto generate images with different poses and lighting conditions, such that we\ncan reconstruct the 3D cartoon face shapes. We validate the efficacy of our\nmethod on three cartoon datasets qualitatively and quantitatively.", "AI": {"tldr": "The paper explores generating 3D cartoon faces from 2D GAN-generated human faces without 3D supervision, using StyleGAN's latent space for expression and pose manipulation.", "motivation": "To bridge the gap between 2D human faces and 3D cartoon avatars without requiring 3D annotations.", "method": "Fine-tunes StyleGAN on cartoon datasets, manipulates latent codes for expressions and poses, and reconstructs 3D shapes from varied 2D images.", "result": "Validated on three cartoon datasets, showing effective translation and manipulation.", "conclusion": "The approach successfully generates and manipulates 3D cartoon faces without 3D supervision."}}
{"id": "2505.02306", "pdf": "https://arxiv.org/pdf/2505.02306", "abs": "https://arxiv.org/abs/2505.02306", "authors": ["Junfeng Jiao", "Jihyung Park", "Yiming Xu", "Kristen Sussman", "Lucy Atkinson"], "title": "SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance", "categories": ["cs.AI"], "comment": null, "summary": "Despite the abundance of public safety documents and emergency protocols,\nmost individuals remain ill-equipped to interpret and act on such information\nduring crises. Traditional emergency decision support systems (EDSS) are\ndesigned for professionals and rely heavily on static documents like PDFs or\nSOPs, which are difficult for non-experts to navigate under stress. This gap\nbetween institutional knowledge and public accessibility poses a critical\nbarrier to effective emergency preparedness and response. We introduce\nSafeMate, a retrieval-augmented AI assistant that delivers accurate,\ncontext-aware guidance to general users in both preparedness and active\nemergency scenarios. Built on the Model Context Protocol (MCP), SafeMate\ndynamically routes user queries to tools for document retrieval, checklist\ngeneration, and structured summarization. It uses FAISS with cosine similarity\nto identify relevant content from trusted sources.", "AI": {"tldr": "SafeMate is an AI assistant designed to bridge the gap between institutional emergency knowledge and public accessibility, providing context-aware guidance during crises.", "motivation": "Traditional emergency decision support systems are not user-friendly for non-experts, creating a barrier in emergency preparedness and response.", "method": "SafeMate uses the Model Context Protocol (MCP) and FAISS with cosine similarity for dynamic document retrieval, checklist generation, and summarization.", "result": "The system delivers accurate, context-aware guidance to general users in emergency scenarios.", "conclusion": "SafeMate improves public accessibility to emergency protocols, enhancing preparedness and response."}}
{"id": "2505.09313", "pdf": "https://arxiv.org/pdf/2505.09313", "abs": "https://arxiv.org/abs/2505.09313", "authors": ["Qiangqiang Liu", "Qian Huang", "Frank Fan", "Haishan Wu", "Xueyan Tang"], "title": "Detecting Sybil Addresses in Blockchain Airdrops: A Subgraph-based Feature Propagation and Fusion Approach", "categories": ["cs.CR", "cs.LG"], "comment": "IEEE International Conference on Blockchain and Cryptocurrency(Proc.\n  IEEE ICBC 2025)", "summary": "Sybil attacks pose a significant security threat to blockchain ecosystems,\nparticularly in token airdrop events. This paper proposes a novel sybil address\nidentification method based on subgraph feature extraction lightGBM. The method\nfirst constructs a two-layer deep transaction subgraph for each address, then\nextracts key event operation features according to the lifecycle of sybil\naddresses, including the time of first transaction, first gas acquisition,\nparticipation in airdrop activities, and last transaction. These temporal\nfeatures effectively capture the consistency of sybil address behavior\noperations. Additionally, the method extracts amount and network structure\nfeatures, comprehensively describing address behavior patterns and network\ntopology through feature propagation and fusion. Experiments conducted on a\ndataset containing 193,701 addresses (including 23,240 sybil addresses) show\nthat this method outperforms existing approaches in terms of precision, recall,\nF1 score, and AUC, with all metrics exceeding 0.9. The methods and results of\nthis study can be further applied to broader blockchain security areas such as\ntransaction manipulation identification and token liquidity risk assessment,\ncontributing to the construction of a more secure and fair blockchain\necosystem.", "AI": {"tldr": "A novel method using subgraph feature extraction and lightGBM identifies sybil addresses in blockchain airdrops with high accuracy (metrics >0.9).", "motivation": "Sybil attacks threaten blockchain security, especially in token airdrops, necessitating effective detection methods.", "method": "Constructs two-layer transaction subgraphs, extracts temporal, amount, and network structure features, and uses lightGBM for classification.", "result": "Outperforms existing methods with precision, recall, F1, and AUC all exceeding 0.9 on a dataset of 193,701 addresses.", "conclusion": "The method enhances blockchain security and can be applied to other areas like transaction manipulation and liquidity risk."}}
{"id": "2209.14946", "pdf": "https://arxiv.org/pdf/2209.14946", "abs": "https://arxiv.org/abs/2209.14946", "authors": ["Qinglai Wei", "Beiming Yuan", "Diancheng Chen"], "title": "EiHi Net: Out-of-Distribution Generalization Paradigm", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper develops a new EiHi net to solve the out-of-distribution (OoD)\ngeneralization problem in deep learning. EiHi net is a model learning paradigm\nthat can be blessed on any visual backbone. This paradigm can change the\nprevious learning method of the deep model, namely find out correlations\nbetween inductive sample features and corresponding categories, which suffers\nfrom pseudo correlations between indecisive features and labels. We fuse SimCLR\nand VIC-Reg via explicitly and dynamically establishing the original - positive\n- negative sample pair as a minimal learning element, the deep model\niteratively establishes a relationship close to the causal one between features\nand labels, while suppressing pseudo correlations. To further validate the\nproposed model, and strengthen the established causal relationships, we develop\na human-in-the-loop strategy, with few guidance samples, to prune the\nrepresentation space directly. Finally, it is shown that the developed EiHi net\nmakes significant improvements in the most difficult and typical OoD dataset\nNico, compared with the current SOTA results, without any domain ($e.g.$\nbackground, irrelevant features) information.", "AI": {"tldr": "EiHi net improves OoD generalization in deep learning by dynamically establishing causal feature-label relationships and suppressing pseudo correlations, validated on the Nico dataset.", "motivation": "Address the OoD generalization problem in deep learning by avoiding pseudo correlations between indecisive features and labels.", "method": "Fuses SimCLR and VIC-Reg to dynamically establish causal relationships between features and labels, and employs a human-in-the-loop strategy to prune the representation space.", "result": "Significant improvements on the Nico dataset without relying on domain information, outperforming SOTA methods.", "conclusion": "EiHi net effectively enhances OoD generalization by focusing on causal relationships and suppressing pseudo correlations."}}
{"id": "2505.06977", "pdf": "https://arxiv.org/pdf/2505.06977", "abs": "https://arxiv.org/abs/2505.06977", "authors": ["Wenju Sun", "Qingyong Li", "Yangli-ao Geng", "Boyang Li"], "title": "CAT Merging: A Training-Free Approach for Resolving Conflicts in Model Merging", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multi-task model merging offers a promising paradigm for integrating multiple\nexpert models into a unified model without additional training. Existing\nstate-of-the-art techniques, such as Task Arithmetic and its variants, merge\nmodels by accumulating task vectors -- the parameter differences between\npretrained and finetuned models. However, task vector accumulation is often\nhindered by knowledge conflicts, leading to performance degradation. To address\nthis challenge, we propose Conflict-Aware Task Merging (CAT Merging), a novel\ntraining-free framework that selectively trims conflict-prone components from\nthe task vectors. CAT Merging introduces several parameter-specific strategies,\nincluding projection for linear weights and masking for scaling and shifting\nparameters in normalization layers. Extensive experiments on vision, language,\nand vision-language tasks demonstrate that CAT Merging effectively suppresses\nknowledge conflicts, achieving average accuracy improvements of up to 2.5%\n(ViT-B/32) and 2.0% (ViT-L/14) over state-of-the-art methods.", "AI": {"tldr": "CAT Merging is a training-free framework that trims conflict-prone components in task vectors to improve multi-task model merging.", "motivation": "Existing methods like Task Arithmetic suffer from knowledge conflicts during model merging, causing performance degradation.", "method": "CAT Merging selectively trims conflict-prone components using strategies like projection for linear weights and masking for normalization layers.", "result": "Achieves average accuracy improvements of 2.5% (ViT-B/32) and 2.0% (ViT-L/14) over state-of-the-art methods.", "conclusion": "CAT Merging effectively suppresses knowledge conflicts, enhancing multi-task model merging performance."}}
{"id": "2505.09326", "pdf": "https://arxiv.org/pdf/2505.09326", "abs": "https://arxiv.org/abs/2505.09326", "authors": ["Vincent Abbott", "Kotaro Kamiya", "Gerard Glowacki", "Yu Atsumi", "Gioele Zardini", "Yoshihiro Maruyama"], "title": "Accelerating Machine Learning Systems via Category Theory: Applications to Spherical Attention for Gene Regulatory Networks", "categories": ["math.CT", "cs.LG", "q-bio.MN"], "comment": null, "summary": "How do we enable artificial intelligence models to improve themselves? This\nis central to exponentially improving generalized artificial intelligence\nmodels, which can improve their own architecture to handle new problem domains\nin an efficient manner that leverages the latest hardware. However, current\nautomated compilation methods are poor, and efficient algorithms require years\nof human development. In this paper, we use neural circuit diagrams, based in\ncategory theory, to prove a general theorem related to deep learning\nalgorithms, guide the development of a novel attention algorithm catered to the\ndomain of gene regulatory networks, and produce a corresponding efficient\nkernel. The algorithm we propose, spherical attention, shows that neural\ncircuit diagrams enable a principled and systematic method for reasoning about\ndeep learning architectures and providing high-performance code. By replacing\nSoftMax with an $L^2$ norm as suggested by diagrams, it overcomes the special\nfunction unit bottleneck of standard attention while retaining the streaming\nproperty essential to high-performance. Our diagrammatically derived\n\\textit{FlashSign} kernel achieves comparable performance to the\nstate-of-the-art, fine-tuned FlashAttention algorithm on an A100, and\n$3.6\\times$ the performance of PyTorch. Overall, this investigation shows\nneural circuit diagrams' suitability as a high-level framework for the\nautomated development of efficient, novel artificial intelligence\narchitectures.", "AI": {"tldr": "The paper introduces neural circuit diagrams for improving AI models, proposing a novel attention algorithm (spherical attention) and an efficient kernel (FlashSign), achieving performance comparable to state-of-the-art methods.", "motivation": "To enable AI models to self-improve and overcome limitations of current automated compilation methods, leveraging neural circuit diagrams for systematic architecture development.", "method": "Uses neural circuit diagrams based on category theory to derive a novel attention algorithm (spherical attention) and an efficient kernel (FlashSign), replacing SoftMax with an $L^2$ norm.", "result": "Spherical attention overcomes bottlenecks of standard attention, and FlashSign matches FlashAttention's performance on an A100 while outperforming PyTorch by 3.6x.", "conclusion": "Neural circuit diagrams are a promising high-level framework for automated, efficient AI architecture development."}}
{"id": "2401.07378", "pdf": "https://arxiv.org/pdf/2401.07378", "abs": "https://arxiv.org/abs/2401.07378", "authors": ["Guangyu Meng", "Ruyu Zhou", "Liu Liu", "Peixian Liang", "Fang Liu", "Danny Chen", "Michael Niemier", "X. Sharon Hu"], "title": "Efficient approximation of Earth Mover's Distance Based on Nearest Neighbor Search", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Earth Mover's Distance (EMD) is an important similarity measure between two\ndistributions, used in computer vision and many other application domains.\nHowever, its exact calculation is computationally and memory intensive, which\nhinders its scalability and applicability for large-scale problems. Various\napproximate EMD algorithms have been proposed to reduce computational costs,\nbut they suffer lower accuracy and may require additional memory usage or\nmanual parameter tuning. In this paper, we present a novel approach, NNS-EMD,\nto approximate EMD using Nearest Neighbor Search (NNS), in order to achieve\nhigh accuracy, low time complexity, and high memory efficiency. The NNS\noperation reduces the number of data points compared in each NNS iteration and\noffers opportunities for parallel processing. We further accelerate NNS-EMD via\nvectorization on GPU, which is especially beneficial for large datasets. We\ncompare NNS-EMD with both the exact EMD and state-of-the-art approximate EMD\nalgorithms on image classification and retrieval tasks. We also apply NNS-EMD\nto calculate transport mapping and realize color transfer between images.\nNNS-EMD can be 44x to 135x faster than the exact EMD implementation, and\nachieves superior accuracy, speedup, and memory efficiency over existing\napproximate EMD methods.", "AI": {"tldr": "NNS-EMD is a novel method using Nearest Neighbor Search to approximate Earth Mover's Distance, offering high accuracy, low time complexity, and memory efficiency, with GPU acceleration for large datasets.", "motivation": "Exact EMD is computationally intensive, hindering scalability, while existing approximate methods sacrifice accuracy or require tuning.", "method": "NNS-EMD leverages Nearest Neighbor Search to reduce comparisons and enable parallel processing, with GPU vectorization for speed.", "result": "NNS-EMD is 44x-135x faster than exact EMD, outperforming other approximate methods in accuracy, speed, and memory efficiency.", "conclusion": "NNS-EMD is a scalable, efficient, and accurate alternative to exact and approximate EMD methods, validated in image tasks."}}
{"id": "2505.07089", "pdf": "https://arxiv.org/pdf/2505.07089", "abs": "https://arxiv.org/abs/2505.07089", "authors": ["Hanzheng Dai", "Yuanliang Li", "Zhibo Zhang", "Jun Yan"], "title": "RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Automated penetration testing (AutoPT) powered by large language models\n(LLMs) has gained attention for its ability to automate ethical hacking\nprocesses and identify vulnerabilities in target systems by leveraging the\nintrinsic knowledge of LLMs. However, existing LLM-based AutoPT frameworks\noften underperform compared to human experts in challenging tasks for several\nreasons: the imbalanced knowledge used in LLM training, short-sighted planning\nin the planning process, and hallucinations during command generation. In\naddition, the penetration testing (PT) process, with its trial-and-error\nnature, is limited by existing frameworks that lack mechanisms to learn from\nprevious failed operations, restricting adaptive improvement of PT strategies.\nTo address these limitations, we propose a knowledge-informed self-reflective\nPT framework powered by LLMs, called RefPentester, which is an AutoPT framework\ndesigned to assist human operators in identifying the current stage of the PT\nprocess, selecting appropriate tactic and technique for the stage, choosing\nsuggested action, providing step-by-step operational guidance, and learning\nfrom previous failed operations. We also modeled the PT process as a\nseven-state Stage Machine to integrate the proposed framework effectively. The\nevaluation shows that RefPentester can successfully reveal credentials on Hack\nThe Box's Sau machine, outperforming the baseline GPT-4o model by 16.7%. Across\nPT stages, RefPentester also demonstrates superior success rates on PT stage\ntransitions.", "AI": {"tldr": "RefPentester, a knowledge-informed self-reflective AutoPT framework, outperforms baseline GPT-4o by 16.7% in identifying vulnerabilities, addressing limitations like imbalanced knowledge and lack of learning from failures.", "motivation": "Existing LLM-based AutoPT frameworks underperform due to imbalanced knowledge, short-sighted planning, and hallucinations, and lack mechanisms to learn from failures.", "method": "Proposes RefPentester, a framework integrating a seven-state Stage Machine to guide PT stages, select tactics, and learn from failures.", "result": "RefPentester outperforms GPT-4o by 16.7% in revealing credentials and shows superior success rates in PT stage transitions.", "conclusion": "RefPentester effectively addresses AutoPT limitations, enhancing performance and adaptability in penetration testing."}}
{"id": "2505.09364", "pdf": "https://arxiv.org/pdf/2505.09364", "abs": "https://arxiv.org/abs/2505.09364", "authors": ["Michael Benigni", "Maurizio Ferrari Dacrema", "Dietmar Jannach"], "title": "Diffusion Recommender Models and the Illusion of Progress: A Concerning Study of Reproducibility and a Conceptual Mismatch", "categories": ["cs.IR", "cs.LG", "cs.NE"], "comment": null, "summary": "Countless new machine learning models are published every year and are\nreported to significantly advance the state-of-the-art in \\emph{top-n}\nrecommendation. However, earlier reproducibility studies indicate that progress\nin this area may be quite limited. Specifically, various widespread\nmethodological issues, e.g., comparisons with untuned baseline models, have led\nto an \\emph{illusion of progress}. In this work, our goal is to examine whether\nthese problems persist in today's research. To this end, we aim to reproduce\nthe latest advancements reported from applying modern Denoising Diffusion\nProbabilistic Models to recommender systems, focusing on four models published\nat the top-ranked SIGIR conference in 2023 and 2024. Our findings are\nconcerning, revealing persistent methodological problems. Alarmingly, through\nexperiments, we find that the latest recommendation techniques based on\ndiffusion models, despite their computational complexity and substantial carbon\nfootprint, are consistently outperformed by simpler existing models.\nFurthermore, we identify key mismatches between the characteristics of\ndiffusion models and those of the traditional \\emph{top-n} recommendation task,\nraising doubts about their suitability for recommendation. We also note that,\nin the papers we analyze, the generative capabilities of these models are\nconstrained to a minimum. Overall, our results and continued methodological\nissues call for greater scientific rigor and a disruptive change in the\nresearch and publication culture in this area.", "AI": {"tldr": "The paper critiques the reproducibility and methodological flaws in recent top-n recommendation research, particularly with diffusion models, finding they underperform simpler methods and questioning their suitability.", "motivation": "To assess whether persistent methodological issues in machine learning research, such as untuned baselines, still plague recent advancements in recommender systems, specifically diffusion models.", "method": "Reproduces four recent SIGIR-published diffusion-based recommendation models, comparing them to simpler alternatives and evaluating their methodological rigor.", "result": "Finds diffusion models are consistently outperformed by simpler methods, have high computational costs, and are poorly suited for top-n recommendation tasks.", "conclusion": "Calls for improved scientific rigor and a shift in research culture to address ongoing methodological problems in the field."}}
{"id": "2403.03370", "pdf": "https://arxiv.org/pdf/2403.03370", "abs": "https://arxiv.org/abs/2403.03370", "authors": ["Changan Chen", "Rui Wang", "Christoph Vogel", "Marc Pollefeys"], "title": "F$^3$Loc: Fusion and Filtering for Floorplan Localization", "categories": ["cs.CV", "cs.RO"], "comment": "10 pages, 11 figure, accepted to CVPR 2024 (fixed typo eq.8: s_x,s_y,\n  s_phi -> x, y, phi)", "summary": "In this paper we propose an efficient data-driven solution to\nself-localization within a floorplan. Floorplan data is readily available,\nlong-term persistent and inherently robust to changes in the visual appearance.\nOur method does not require retraining per map and location or demand a large\ndatabase of images of the area of interest. We propose a novel probabilistic\nmodel consisting of an observation and a novel temporal filtering module.\nOperating internally with an efficient ray-based representation, the\nobservation module consists of a single and a multiview module to predict\nhorizontal depth from images and fuses their results to benefit from advantages\noffered by either methodology. Our method operates on conventional consumer\nhardware and overcomes a common limitation of competing methods that often\ndemand upright images. Our full system meets real-time requirements, while\noutperforming the state-of-the-art by a significant margin.", "AI": {"tldr": "An efficient data-driven method for self-localization in floorplans, using a probabilistic model with observation and temporal filtering modules, outperforming state-of-the-art without requiring retraining or large image databases.", "motivation": "To address the need for robust, efficient self-localization in floorplans without relying on retraining or extensive image databases.", "method": "A probabilistic model with observation (single/multiview modules for depth prediction) and temporal filtering modules, using ray-based representation.", "result": "Operates in real-time on consumer hardware, outperforms state-of-the-art, and works without upright images.", "conclusion": "The proposed method is efficient, robust, and superior to existing solutions for floorplan-based self-localization."}}
{"id": "2505.07773", "pdf": "https://arxiv.org/pdf/2505.07773", "abs": "https://arxiv.org/abs/2505.07773", "authors": ["Xinji Mai", "Haotian Xu", "Xing W", "Weinong Wang", "Yingying Zhang", "Wenqiang Zhang"], "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks\nrequiring precise, verifiable computation. While Reinforcement Learning (RL)\nfrom outcome-based rewards enhances text-based reasoning, understanding how\nagents autonomously learn to leverage external tools like code execution\nremains crucial. We investigate RL from outcome-based rewards for\nTool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously\ngenerate and execute Python code for mathematical problems without supervised\ntool-use examples. Our central contribution is we demonstrate that as RL\ntraining progresses, key metrics scale predictably. Specifically, we observe\nstrong positive correlations where increased training steps lead to increases\nin the spontaneous code execution frequency, the average response length, and,\ncritically, the final task accuracy. This suggests a quantifiable relationship\nbetween computational effort invested in training and the emergence of\neffective, tool-augmented reasoning strategies. We implement a robust framework\nfeaturing a decoupled code execution environment and validate our findings\nacross standard RL algorithms and frameworks. Experiments show ZeroTIR\nsignificantly surpasses non-tool ZeroRL baselines on challenging math\nbenchmarks. Our findings provide a foundational understanding of how autonomous\ntool use is acquired and scales within Agent RL, offering a reproducible\nbenchmark for future studies. Code is released at\n\\href{https://github.com/yyht/openrlhf_async_pipline}{https://github.com/yyht/openrlhf\\_async\\_pipline}.", "AI": {"tldr": "ZeroTIR trains LLMs with RL to autonomously generate and execute Python code for math tasks, showing predictable scaling in performance metrics like accuracy and code execution frequency.", "motivation": "LLMs struggle with precise mathematical reasoning, and understanding how RL can enable autonomous tool use (like code execution) is crucial.", "method": "ZeroTIR uses RL from outcome-based rewards to train LLMs to generate and execute Python code without supervised examples. A decoupled code execution environment is implemented.", "result": "Increased training steps correlate with higher code execution frequency, longer responses, and improved task accuracy. ZeroTIR outperforms non-tool baselines on math benchmarks.", "conclusion": "ZeroTIR demonstrates a quantifiable relationship between RL training and tool-augmented reasoning, providing a benchmark for future studies."}}
{"id": "2505.09365", "pdf": "https://arxiv.org/pdf/2505.09365", "abs": "https://arxiv.org/abs/2505.09365", "authors": ["H. T. R\u00fcdisser", "G. Nguyen", "J. Le Lou\u00ebdec", "C. M\u00f6stl"], "title": "ARCANE -- Early Detection of Interplanetary Coronal Mass Ejections", "categories": ["physics.space-ph", "astro-ph.IM", "astro-ph.SR", "cs.LG"], "comment": "25 pages, 9 figures, 1 table, submitted to AGU Space Weather on 14th\n  May 2025", "summary": "Interplanetary coronal mass ejections (ICMEs) are major drivers of space\nweather disturbances, posing risks to both technological infrastructure and\nhuman activities. Automatic detection of ICMEs in solar wind in situ data is\nessential for early warning systems. While several methods have been proposed\nto identify these structures in time series data, robust real-time detection\nremains a significant challenge. In this work, we present ARCANE - the first\nframework explicitly designed for early ICME detection in streaming solar wind\ndata under realistic operational constraints, enabling event identification\nwithout requiring observation of the full structure. Our approach evaluates the\nstrengths and limitations of detection models by comparing a machine\nlearning-based method to a threshold-based baseline. The ResUNet++ model,\npreviously validated on science data, significantly outperforms the baseline,\nparticularly in detecting high-impact events, while retaining solid performance\non lower-impact cases. Notably, we find that using real-time solar wind (RTSW)\ndata instead of high-resolution science data leads to only minimal performance\ndegradation. Despite the challenges of operational settings, our detection\npipeline achieves an F1 score of 0.53, with an average detection delay of 21.5%\nof the event's duration while only seeing a minimal amount of data. As more\ndata becomes available, the performance increases significantly. These results\nmark a substantial step forward in automated space weather monitoring and lay\nthe groundwork for enhanced real-time forecasting capabilities.", "AI": {"tldr": "ARCANE is a framework for early detection of ICMEs in streaming solar wind data, outperforming baselines with minimal performance loss in real-time settings.", "motivation": "ICMEs pose risks to space weather; robust real-time detection is needed for early warnings.", "method": "Compares machine learning (ResUNet++) to a threshold-based baseline for ICME detection in streaming data.", "result": "ResUNet++ outperforms baseline, achieving F1 score of 0.53 with minimal delay and data.", "conclusion": "ARCANE advances automated space weather monitoring, enabling better real-time forecasting."}}
{"id": "2407.19708", "pdf": "https://arxiv.org/pdf/2407.19708", "abs": "https://arxiv.org/abs/2407.19708", "authors": ["Ezequiel Perez-Zarate", "Oscar Ramos-Soto", "Chunxiao Liu", "Diego Oliva", "Marco Perez-Cisneros"], "title": "ALEN: A Dual-Approach for Uniform and Non-Uniform Low-Light Image Enhancement", "categories": ["cs.CV"], "comment": "Minor updates and corrections", "summary": "Low-light image enhancement is an important task in computer vision,\nessential for improving the visibility and quality of images captured in\nnon-optimal lighting conditions. Inadequate illumination can lead to\nsignificant information loss and poor image quality, impacting various\napplications such as surveillance. photography, or even autonomous driving. In\nthis regard, automated methods have been developed to automatically adjust\nillumination in the image for a better visual perception. Current enhancement\ntechniques often use specific datasets to enhance low-light images, but still\npresent challenges when adapting to diverse real-world conditions, where\nillumination degradation may be localized to specific regions. To address this\nchallenge, the Adaptive Light Enhancement Network (ALEN) is introduced, whose\nmain approach is the use of a classification mechanism to determine whether\nlocal or global illumination enhancement is required. Subsequently, estimator\nnetworks adjust illumination based on this classification and simultaneously\nenhance color fidelity. ALEN integrates the Light Classification Network\n(LCNet) for illuminance categorization, complemented by the Single-Channel\nNetwork (SCNet), and Multi-Channel Network (MCNet) for precise estimation of\nillumination and color, respectively. Extensive experiments on publicly\navailable datasets for low-light conditions were carried out to underscore\nALEN's robust generalization capabilities, demonstrating superior performance\nin both quantitative metrics and qualitative assessments when compared to\nrecent state-of-the-art methods. The ALEN not only enhances image quality in\nterms of visual perception but also represents an advancement in high-level\nvision tasks, such as semantic segmentation, as presented in this work. The\ncode of this method is available at https://github.com/xingyumex/ALEN", "AI": {"tldr": "ALEN introduces an adaptive network for low-light image enhancement, using classification to decide between local or global illumination adjustment, outperforming state-of-the-art methods.", "motivation": "Low-light conditions degrade image quality, impacting applications like surveillance and autonomous driving. Current methods struggle with diverse real-world scenarios.", "method": "ALEN uses LCNet for illuminance classification, SCNet for illumination estimation, and MCNet for color enhancement.", "result": "ALEN shows superior performance in quantitative and qualitative assessments on public datasets.", "conclusion": "ALEN advances low-light enhancement and benefits high-level vision tasks like semantic segmentation."}}
{"id": "2404.11269", "pdf": "https://arxiv.org/pdf/2404.11269", "abs": "https://arxiv.org/abs/2404.11269", "authors": ["Zahra Zamanzadeh Darban", "Yiyuan Yang", "Geoffrey I. Webb", "Charu C. Aggarwal", "Qingsong Wen", "Shirui Pan", "Mahsa Salehi"], "title": "DACAD: Domain Adaptation Contrastive Learning for Anomaly Detection in Multivariate Time Series", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 3 figures, 6 tables", "summary": "In time series anomaly detection (TSAD), the scarcity of labeled data poses a\nchallenge to the development of accurate models. Unsupervised domain adaptation\n(UDA) offers a solution by leveraging labeled data from a related domain to\ndetect anomalies in an unlabeled target domain. However, existing UDA methods\nassume consistent anomalous classes across domains. To address this limitation,\nwe propose a novel Domain Adaptation Contrastive learning model for Anomaly\nDetection in multivariate time series (DACAD), combining UDA with contrastive\nlearning. DACAD utilizes an anomaly injection mechanism that enhances\ngeneralization across unseen anomalous classes, improving adaptability and\nrobustness. Additionally, our model employs supervised contrastive loss for the\nsource domain and self-supervised contrastive triplet loss for the target\ndomain, ensuring comprehensive feature representation learning and\ndomain-invariant feature extraction. Finally, an effective Center-based Entropy\nClassifier (CEC) accurately learns normal boundaries in the source domain.\nExtensive evaluations on multiple real-world datasets and a synthetic dataset\nhighlight DACAD's superior performance in transferring knowledge across domains\nand mitigating the challenge of limited labeled data in TSAD.", "AI": {"tldr": "DACAD combines unsupervised domain adaptation with contrastive learning for time series anomaly detection, addressing inconsistent anomalous classes and improving adaptability.", "motivation": "The scarcity of labeled data in TSAD and the assumption of consistent anomalous classes in existing UDA methods limit their effectiveness.", "method": "DACAD uses anomaly injection, supervised contrastive loss for the source domain, self-supervised contrastive triplet loss for the target domain, and a Center-based Entropy Classifier (CEC).", "result": "DACAD outperforms existing methods in transferring knowledge across domains and handling limited labeled data.", "conclusion": "DACAD is a robust solution for TSAD, enhancing generalization and adaptability across domains with inconsistent anomalous classes."}}
{"id": "2505.09425", "pdf": "https://arxiv.org/pdf/2505.09425", "abs": "https://arxiv.org/abs/2505.09425", "authors": ["Sarah Leyder", "Jakob Raymaekers", "Peter J. Rousseeuw", "Tom Van Deuren", "Tim Verdonck"], "title": "Independent Component Analysis by Robust Distance Correlation", "categories": ["stat.CO", "cs.LG"], "comment": null, "summary": "Independent component analysis (ICA) is a powerful tool for decomposing a\nmultivariate signal or distribution into fully independent sources, not just\nuncorrelated ones. Unfortunately, most approaches to ICA are not robust against\noutliers. Here we propose a robust ICA method called RICA, which estimates the\ncomponents by minimizing a robust measure of dependence between multivariate\nrandom variables. The dependence measure used is the distance correlation\n(dCor). In order to make it more robust we first apply a new transformation\ncalled the bowl transform, which is bounded, one-to-one, continuous, and maps\nfar outliers to points close to the origin. This preserves the crucial property\nthat a zero dCor implies independence. RICA estimates the independent sources\nsequentially, by looking for the component that has the smallest dCor with the\nremainder. RICA is strongly consistent and has the usual parametric rate of\nconvergence. Its robustness is investigated by a simulation study, in which it\ngenerally outperforms its competitors. The method is illustrated on three\napplications, including the well-known cocktail party problem.", "AI": {"tldr": "RICA is a robust ICA method using distance correlation and a bowl transform to handle outliers, outperforming competitors in simulations and applications.", "motivation": "Standard ICA methods lack robustness against outliers, limiting their practical utility.", "method": "RICA minimizes a robust dependence measure (distance correlation) after applying a bowl transform to handle outliers. It estimates components sequentially.", "result": "RICA is strongly consistent, converges at a parametric rate, and outperforms competitors in robustness simulations.", "conclusion": "RICA is a robust and effective ICA method, demonstrated in simulations and real-world applications like the cocktail party problem."}}
{"id": "2408.17297", "pdf": "https://arxiv.org/pdf/2408.17297", "abs": "https://arxiv.org/abs/2408.17297", "authors": ["Boris Meden", "Asma Brazi", "Fabrice Mayran de Chamisso", "Steve Bourgeois", "Vincent Lepetit"], "title": "BOP-Distrib: Revisiting 6D Pose Estimation Benchmarks for Better Evaluation under Visual Ambiguities", "categories": ["cs.CV"], "comment": null, "summary": "6D pose estimation aims at determining the object pose that best explains the\ncamera observation. The unique solution for non-ambiguous objects can turn into\na multi-modal pose distribution for symmetrical objects or when occlusions of\nsymmetry-breaking elements happen, depending on the viewpoint. Currently, 6D\npose estimation methods are benchmarked on datasets that consider, for their\nground truth annotations, visual ambiguities as only related to global object\nsymmetries, whereas they should be defined per-image to account for the camera\nviewpoint. We thus first propose an automatic method to re-annotate those\ndatasets with a 6D pose distribution specific to each image, taking into\naccount the object surface visibility in the image to correctly determine the\nvisual ambiguities. Second, given this improved ground truth, we re-evaluate\nthe state-of-the-art single pose methods and show that this greatly modifies\nthe ranking of these methods. Third, as some recent works focus on estimating\nthe complete set of solutions, we derive a precision/recall formulation to\nevaluate them against our image-wise distribution ground truth, making it the\nfirst benchmark for pose distribution methods on real images.", "AI": {"tldr": "The paper addresses the need for per-image 6D pose annotations to account for visual ambiguities in pose estimation, proposes an automatic re-annotation method, re-evaluates state-of-the-art methods, and introduces a benchmark for pose distribution methods.", "motivation": "Current 6D pose estimation benchmarks overlook per-image visual ambiguities caused by object symmetries or occlusions, leading to inaccurate evaluations.", "method": "An automatic method is proposed to re-annotate datasets with image-specific 6D pose distributions, considering object surface visibility. State-of-the-art methods are re-evaluated, and a precision/recall benchmark for pose distribution methods is introduced.", "result": "Re-annotation improves ground truth accuracy, altering the ranking of existing methods. The new benchmark enables evaluation of pose distribution methods.", "conclusion": "The work highlights the importance of per-image pose annotations and provides tools for better evaluation of 6D pose estimation methods."}}
{"id": "2406.16696", "pdf": "https://arxiv.org/pdf/2406.16696", "abs": "https://arxiv.org/abs/2406.16696", "authors": ["Gilad Abiri"], "title": "Public Constitutional AI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "We are increasingly subjected to the power of AI authorities. As AI decisions\nbecome inescapable, entering domains such as healthcare, education, and law, we\nmust confront a vital question: how can we ensure AI systems have the\nlegitimacy necessary for effective governance? This essay argues that to secure\nAI legitimacy, we need methods that engage the public in designing and\nconstraining AI systems, ensuring these technologies reflect the community's\nshared values. Constitutional AI, proposed by Anthropic, represents a step\ntowards this goal, offering a model for democratic control of AI. However,\nwhile Constitutional AI's commitment to hardcoding explicit principles into AI\nmodels enhances transparency and accountability, it falls short in two crucial\naspects: addressing the opacity of individual AI decisions and fostering\ngenuine democratic legitimacy. To overcome these limitations, this essay\nproposes \"Public Constitutional AI.\" This approach envisions a participatory\nprocess where diverse stakeholders, including ordinary citizens, deliberate on\nthe principles guiding AI development. The resulting \"AI Constitution\" would\ncarry the legitimacy of popular authorship, grounding AI governance in the\npublic will. Furthermore, the essay proposes \"AI Courts\" to develop \"AI case\nlaw,\" providing concrete examples for operationalizing constitutional\nprinciples in AI training. This evolving combination of constitutional\nprinciples and case law aims to make AI governance more responsive to public\nvalues. By grounding AI governance in deliberative democratic processes, Public\nConstitutional AI offers a path to imbue automated authorities with genuine\ndemocratic legitimacy, addressing the unique challenges posed by increasingly\npowerful AI systems while ensuring their alignment with the public interest.", "AI": {"tldr": "The paper proposes 'Public Constitutional AI' to enhance AI legitimacy through public participation and 'AI Courts' for case law, addressing gaps in current methods like Constitutional AI.", "motivation": "The rise of AI in critical domains necessitates ensuring its governance reflects public values and legitimacy.", "method": "Introduces 'Public Constitutional AI' involving public deliberation for AI principles and 'AI Courts' to create case law.", "result": "Aims to make AI governance more democratic and aligned with public values.", "conclusion": "Public Constitutional AI offers a democratic approach to legitimize AI governance, ensuring alignment with public interest."}}
{"id": "2505.09430", "pdf": "https://arxiv.org/pdf/2505.09430", "abs": "https://arxiv.org/abs/2505.09430", "authors": ["Yutong Hu", "Pinhao Song", "Kehan Wen", "Renaud Detry"], "title": "Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We present a method for training multi-task vision-language robotic diffusion\npolicies that reduces training time and memory usage by an order of magnitude.\nThis improvement arises from a previously underexplored distinction between\naction diffusion and the image diffusion techniques that inspired it: image\ngeneration targets are high-dimensional, while robot actions lie in a much\nlower-dimensional space. Meanwhile, the vision-language conditions for action\ngeneration remain high-dimensional. Our approach, Mini-Diffuser, exploits this\nasymmetry by introducing Level-2 minibatching, which pairs multiple noised\naction samples with each vision-language condition, instead of the conventional\none-to-one sampling strategy. To support this batching scheme, we introduce\narchitectural adaptations to the diffusion transformer that prevent information\nleakage across samples while maintaining full conditioning access. In RLBench\nsimulations, Mini-Diffuser achieves 95\\% of the performance of state-of-the-art\nmulti-task diffusion policies, while using only 5\\% of the training time and\n7\\% of the memory. Real-world experiments further validate that Mini-Diffuser\npreserves the key strengths of diffusion-based policies, including the ability\nto model multimodal action distributions and produce behavior conditioned on\ndiverse perceptual inputs. Code available at\ngithub.com/utomm/mini-diffuse-actor.", "AI": {"tldr": "Mini-Diffuser reduces training time and memory usage for multi-task vision-language robotic diffusion policies by exploiting the asymmetry between high-dimensional vision-language conditions and low-dimensional robot actions.", "motivation": "The motivation is to address the inefficiency in training multi-task diffusion policies, which traditionally require high computational resources due to the high-dimensional nature of image diffusion techniques.", "method": "The method introduces Level-2 minibatching, pairing multiple noised action samples with each vision-language condition, and includes architectural adaptations to prevent information leakage.", "result": "Mini-Diffuser achieves 95% of the performance of state-of-the-art policies while using only 5% of training time and 7% of memory in RLBench simulations. Real-world experiments confirm its effectiveness.", "conclusion": "Mini-Diffuser successfully balances efficiency and performance, preserving the strengths of diffusion-based policies while significantly reducing resource requirements."}}
{"id": "2409.02562", "pdf": "https://arxiv.org/pdf/2409.02562", "abs": "https://arxiv.org/abs/2409.02562", "authors": ["Paul Johannes Claasen", "Johan Pieter de Villiers"], "title": "One Homography is All You Need: IMM-based Joint Homography and Multiple Object State Estimation", "categories": ["cs.CV"], "comment": "Preprint submitted to Expert Systems with Applications", "summary": "A novel online MOT algorithm, IMM Joint Homography State Estimation\n(IMM-JHSE), is proposed. IMM-JHSE uses an initial homography estimate as the\nonly additional 3D information, whereas other 3D MOT methods use regular 3D\nmeasurements. By jointly modelling the homography matrix and its dynamics as\npart of track state vectors, IMM-JHSE removes the explicit influence of camera\nmotion compensation techniques on predicted track position states, which was\nprevalent in previous approaches. Expanding upon this, static and dynamic\ncamera motion models are combined using an IMM filter. A simple bounding box\nmotion model is used to predict bounding box positions to incorporate image\nplane information. In addition to applying an IMM to camera motion, a\nnon-standard IMM approach is applied where bounding-box-based BIoU scores are\nmixed with ground-plane-based Mahalanobis distances in an IMM-like fashion to\nperform association only, making IMM-JHSE robust to motion away from the ground\nplane. Finally, IMM-JHSE makes use of dynamic process and measurement noise\nestimation techniques. IMM-JHSE improves upon related techniques, including\nUCMCTrack, OC-SORT, C-BIoU and ByteTrack on the DanceTrack and KITTI-car\ndatasets, increasing HOTA by 2.64 and 2.11, respectively, while offering\ncompetitive performance on the MOT17, MOT20 and KITTI-pedestrian datasets.\nUsing publicly available detections, IMM-JHSE outperforms almost all other 2D\nMOT methods and is outperformed only by 3D MOT methods -- some of which are\noffline -- on the KITTI-car dataset. Compared to tracking-by-attention methods,\nIMM-JHSE shows remarkably similar performance on the DanceTrack dataset and\noutperforms them on the MOT17 dataset. The code is publicly available:\nhttps://github.com/Paulkie99/imm-jhse.", "AI": {"tldr": "IMM-JHSE is a novel online MOT algorithm that improves tracking by jointly modeling homography and dynamics, outperforming other methods on several datasets.", "motivation": "To enhance multi-object tracking (MOT) by reducing reliance on explicit camera motion compensation and improving robustness to motion away from the ground plane.", "method": "Uses IMM filter for camera motion, combines static/dynamic models, and employs dynamic noise estimation. Association is done via mixed BIoU scores and Mahalanobis distances.", "result": "Outperforms UCMCTrack, OC-SORT, C-BIoU, and ByteTrack on DanceTrack and KITTI-car datasets (HOTA increases by 2.64 and 2.11). Competitive on MOT17, MOT20, and KITTI-pedestrian.", "conclusion": "IMM-JHSE is a robust and efficient MOT method, excelling in 2D tracking and showing promise against 3D methods."}}
{"id": "2408.09106", "pdf": "https://arxiv.org/pdf/2408.09106", "abs": "https://arxiv.org/abs/2408.09106", "authors": ["Kun Li", "Xiantao Cai", "Jia Wu", "Shirui Pan", "Huiting Xu", "Bo Du", "Wenbin Hu"], "title": "Fragment-Masked Diffusion for Molecular Optimization", "categories": ["q-bio.BM", "cs.AI"], "comment": "12 pages, 9 figures, 4 tables", "summary": "Molecular optimization is a crucial aspect of drug discovery, aimed at\nrefining molecular structures to enhance drug efficacy and minimize side\neffects, ultimately accelerating the overall drug development process. Many\nmolecular optimization methods have been proposed, significantly advancing drug\ndiscovery. These methods primarily on understanding the specific drug target\nstructures or their hypothesized roles in combating diseases. However,\nchallenges such as a limited number of available targets and a difficulty\ncapturing clear structures hinder innovative drug development. In contrast,\nphenotypic drug discovery (PDD) does not depend on clear target structures and\ncan identify hits with novel and unbiased polypharmacology signatures. As a\nresult, PDD-based molecular optimization can reduce potential safety risks\nwhile optimizing phenotypic activity, thereby increasing the likelihood of\nclinical success. Therefore, we propose a fragment-masked molecular\noptimization method based on PDD (FMOP). FMOP employs a regression-free\ndiffusion model to conditionally optimize the molecular masked regions,\neffectively generating new molecules with similar scaffolds. On the large-scale\ndrug response dataset GDSCv2, we optimize the potential molecules across all\n985 cell lines. The overall experiments demonstrate that the in-silico\noptimization success rate reaches 95.4\\%, with an average efficacy increase of\n7.5\\%. Additionally, we conduct extensive ablation and visualization\nexperiments, confirming that FMOP is an effective and robust molecular\noptimization method. The code is available at:\nhttps://anonymous.4open.science/r/FMOP-98C2.", "AI": {"tldr": "FMOP is a fragment-masked molecular optimization method based on phenotypic drug discovery, achieving a 95.4% success rate and 7.5% efficacy increase.", "motivation": "Overcoming limitations of target-dependent methods in drug discovery by leveraging phenotypic drug discovery for unbiased optimization.", "method": "Uses a regression-free diffusion model to conditionally optimize masked molecular regions, generating new molecules with similar scaffolds.", "result": "95.4% in-silico optimization success rate and 7.5% average efficacy increase on GDSCv2 dataset.", "conclusion": "FMOP is an effective and robust molecular optimization method, validated by experiments and visualizations."}}
{"id": "2505.09471", "pdf": "https://arxiv.org/pdf/2505.09471", "abs": "https://arxiv.org/abs/2505.09471", "authors": ["Xiaoyu Hu", "Gengyu Xue", "Zhenhua Lin", "Yi Yu"], "title": "Fairness-aware Bayes optimal functional classification", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "Algorithmic fairness has become a central topic in machine learning, and\nmitigating disparities across different subpopulations has emerged as a rapidly\ngrowing research area. In this paper, we systematically study the\nclassification of functional data under fairness constraints, ensuring the\ndisparity level of the classifier is controlled below a pre-specified\nthreshold. We propose a unified framework for fairness-aware functional\nclassification, tackling an infinite-dimensional functional space, addressing\nkey challenges from the absence of density ratios and intractability of\nposterior probabilities, and discussing unique phenomena in functional\nclassification. We further design a post-processing algorithm, Fair Functional\nLinear Discriminant Analysis classifier (Fair-FLDA), which targets at\nhomoscedastic Gaussian processes and achieves fairness via group-wise\nthresholding. Under weak structural assumptions on eigenspace, theoretical\nguarantees on fairness and excess risk controls are established. As a\nbyproduct, our results cover the excess risk control of the standard FLDA as a\nspecial case, which, to the best of our knowledge, is first time seen. Our\ntheoretical findings are complemented by extensive numerical experiments on\nsynthetic and real datasets, highlighting the practicality of our designed\nalgorithm.", "AI": {"tldr": "The paper introduces a fairness-aware framework for functional data classification, proposing Fair-FLDA to control disparities and ensure theoretical guarantees on fairness and risk.", "motivation": "Addressing algorithmic fairness in machine learning, especially for functional data, where disparities across subpopulations must be mitigated.", "method": "Proposes Fair-FLDA, a post-processing algorithm for functional classification under fairness constraints, using group-wise thresholding for homoscedastic Gaussian processes.", "result": "Theoretical guarantees on fairness and excess risk control are established, with empirical validation on synthetic and real datasets.", "conclusion": "Fair-FLDA effectively balances fairness and performance in functional classification, with broader implications for standard FLDA."}}
{"id": "2409.18769", "pdf": "https://arxiv.org/pdf/2409.18769", "abs": "https://arxiv.org/abs/2409.18769", "authors": ["George R. Nahass", "Sasha Hubschman", "Jeffrey C. Peterson", "Ghasem Yazdanpanah", "Nicholas Tomaras", "Madison Cheung", "Alex Palacios", "Kevin Heinze", "Chad A. Purnell", "Pete Setabutr", "Ann Q. Tran", "Darvin Yi"], "title": "State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features", "categories": ["cs.CV", "cs.AI"], "comment": "25 pages, 12 figures, 16 tables", "summary": "Periorbital distances are critical markers for diagnosing and monitoring a\nrange of oculoplastic and craniofacial conditions. Manual measurement, however,\nis subjective and prone to intergrader variability. Automated methods have been\ndeveloped but remain limited by standardized imaging requirements, small\ndatasets, and a narrow focus on individual measurements. We developed a\nsegmentation pipeline trained on a domain-specific dataset of healthy eyes and\ncompared its performance against the Segment Anything Model (SAM) and the prior\nbenchmark, PeriorbitAI. Segmentation accuracy was evaluated across multiple\ndisease classes and imaging conditions. We further investigated the use of\npredicted periorbital distances as features for disease classification under\nin-distribution (ID) and out-of-distribution (OOD) settings, comparing shallow\nclassifiers, CNNs, and fusion models. Our segmentation model achieved\nstate-of-the-art accuracy across all datasets, with error rates within\nintergrader variability and superior performance relative to SAM and\nPeriorbitAI. In classification tasks, models trained on periorbital distances\nmatched CNN performance on ID data (77--78\\% accuracy) and substantially\noutperformed CNNs under OOD conditions (63--68\\% accuracy vs. 14\\%). Fusion\nmodels achieved the highest ID accuracy (80\\%) but were sensitive to degraded\nCNN features under OOD shifts. Segmentation-derived periorbital distances\nprovide robust, explainable features for disease classification and generalize\nbetter under domain shift than CNN image classifiers. These results establish a\nnew benchmark for periorbital distance prediction and highlight the potential\nof anatomy-based AI pipelines for real-world deployment in oculoplastic and\ncraniofacial care.", "AI": {"tldr": "An automated segmentation pipeline for periorbital distances outperforms manual and existing automated methods, achieving state-of-the-art accuracy and robustness in disease classification under varied conditions.", "motivation": "Manual measurement of periorbital distances is subjective and prone to variability, while existing automated methods are limited by strict imaging requirements and small datasets.", "method": "Developed a segmentation pipeline trained on a domain-specific dataset, compared it with Segment Anything Model (SAM) and PeriorbitAI, and evaluated segmentation accuracy and classification performance using periorbital distances as features.", "result": "The segmentation model achieved state-of-the-art accuracy, with error rates within intergrader variability. Classification models using periorbital distances matched or outperformed CNNs, especially under out-of-distribution conditions.", "conclusion": "Segmentation-derived periorbital distances provide robust, explainable features for disease classification, generalizing better under domain shifts than CNN-based methods, and set a new benchmark for real-world deployment."}}
{"id": "2410.02847", "pdf": "https://arxiv.org/pdf/2410.02847", "abs": "https://arxiv.org/abs/2410.02847", "authors": ["Tiexin Qin", "Mengxu Zhu", "Chunyang Li", "Terry Lyons", "Hong Yan", "Haoliang Li"], "title": "Deep Signature: Characterization of Large-Scale Molecular Dynamics", "categories": ["q-bio.QM", "cs.AI"], "comment": "ICLR 2025", "summary": "Understanding protein dynamics are essential for deciphering protein\nfunctional mechanisms and developing molecular therapies. However, the complex\nhigh-dimensional dynamics and interatomic interactions of biological processes\npose significant challenge for existing computational techniques. In this\npaper, we approach this problem for the first time by introducing Deep\nSignature, a novel computationally tractable framework that characterizes\ncomplex dynamics and interatomic interactions based on their evolving\ntrajectories. Specifically, our approach incorporates soft spectral clustering\nthat locally aggregates cooperative dynamics to reduce the size of the system,\nas well as signature transform that collects iterated integrals to provide a\nglobal characterization of the non-smooth interactive dynamics. Theoretical\nanalysis demonstrates that Deep Signature exhibits several desirable\nproperties, including invariance to translation, near invariance to rotation,\nequivariance to permutation of atomic coordinates, and invariance under time\nreparameterization. Furthermore, experimental results on three benchmarks of\nbiological processes verify that our approach can achieve superior performance\ncompared to baseline methods.", "AI": {"tldr": "Deep Signature is a novel framework for analyzing protein dynamics, combining soft spectral clustering and signature transforms to handle high-dimensional data, achieving superior performance over baselines.", "motivation": "Understanding protein dynamics is crucial for functional insights and therapies, but existing methods struggle with complexity.", "method": "Uses soft spectral clustering for local dynamics aggregation and signature transforms for global characterization of interactions.", "result": "Theoretical properties include invariance to transformations, and experiments show better performance than baselines.", "conclusion": "Deep Signature effectively addresses challenges in protein dynamics analysis with promising results."}}
{"id": "2505.09496", "pdf": "https://arxiv.org/pdf/2505.09496", "abs": "https://arxiv.org/abs/2505.09496", "authors": ["Rui Miao", "Babak Shahbaba", "Annie Qu"], "title": "Reinforcement Learning for Individual Optimal Policy from Heterogeneous Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) aims to find optimal policies in dynamic\nenvironments in order to maximize the expected total rewards by leveraging\npre-collected data. Learning from heterogeneous data is one of the fundamental\nchallenges in offline RL. Traditional methods focus on learning an optimal\npolicy for all individuals with pre-collected data from a single episode or\nhomogeneous batch episodes, and thus, may result in a suboptimal policy for a\nheterogeneous population. In this paper, we propose an individualized offline\npolicy optimization framework for heterogeneous time-stationary Markov decision\nprocesses (MDPs). The proposed heterogeneous model with individual latent\nvariables enables us to efficiently estimate the individual Q-functions, and\nour Penalized Pessimistic Personalized Policy Learning (P4L) algorithm\nguarantees a fast rate on the average regret under a weak partial coverage\nassumption on behavior policies. In addition, our simulation studies and a real\ndata application demonstrate the superior numerical performance of the proposed\nmethod compared with existing methods.", "AI": {"tldr": "The paper introduces an individualized offline RL framework for heterogeneous MDPs, proposing the P4L algorithm to optimize policies for diverse populations, outperforming traditional methods.", "motivation": "Traditional offline RL methods often yield suboptimal policies for heterogeneous populations due to reliance on homogeneous data. This work addresses the challenge of learning from heterogeneous data.", "method": "The authors propose a heterogeneous model with individual latent variables and the P4L algorithm, which estimates individual Q-functions and ensures fast regret rates under weak coverage assumptions.", "result": "Simulations and real-data applications show the proposed method outperforms existing approaches in numerical performance.", "conclusion": "The P4L algorithm effectively addresses heterogeneity in offline RL, offering superior performance and theoretical guarantees."}}
{"id": "2410.07795", "pdf": "https://arxiv.org/pdf/2410.07795", "abs": "https://arxiv.org/abs/2410.07795", "authors": ["Cuong Le", "Viktor Johansson", "Manon Kok", "Bastian Wandt"], "title": "Optimal-state Dynamics Estimation for Physics-based Human Motion Capture from Videos", "categories": ["cs.CV"], "comment": "17 pages, 7 figure, NeurIPS 2024", "summary": "Human motion capture from monocular videos has made significant progress in\nrecent years. However, modern approaches often produce temporal artifacts, e.g.\nin form of jittery motion and struggle to achieve smooth and physically\nplausible motions. Explicitly integrating physics, in form of internal forces\nand exterior torques, helps alleviating these artifacts. Current\nstate-of-the-art approaches make use of an automatic PD controller to predict\ntorques and reaction forces in order to re-simulate the input kinematics, i.e.\nthe joint angles of a predefined skeleton. However, due to imperfect physical\nmodels, these methods often require simplifying assumptions and extensive\npreprocessing of the input kinematics to achieve good performance. To this end,\nwe propose a novel method to selectively incorporate the physics models with\nthe kinematics observations in an online setting, inspired by a neural\nKalman-filtering approach. We develop a control loop as a meta-PD controller to\npredict internal joint torques and external reaction forces, followed by a\nphysics-based motion simulation. A recurrent neural network is introduced to\nrealize a Kalman filter that attentively balances the kinematics input and\nsimulated motion, resulting in an optimal-state dynamics prediction. We show\nthat this filtering step is crucial to provide an online supervision that helps\nbalancing the shortcoming of the respective input motions, thus being important\nfor not only capturing accurate global motion trajectories but also producing\nphysically plausible human poses. The proposed approach excels in the\nphysics-based human pose estimation task and demonstrates the physical\nplausibility of the predictive dynamics, compared to state of the art. The code\nis available on https://github.com/cuongle1206/OSDCap", "AI": {"tldr": "A novel method integrates physics models with kinematics observations using a neural Kalman-filtering approach to improve human motion capture from monocular videos, addressing temporal artifacts and enhancing physical plausibility.", "motivation": "Modern motion capture methods often produce temporal artifacts like jittery motion and struggle with smooth, physically plausible results. Current approaches rely on imperfect physical models and require extensive preprocessing.", "method": "The proposed method uses a meta-PD controller to predict joint torques and reaction forces, followed by physics-based motion simulation. A recurrent neural network implements a Kalman filter to balance kinematics input and simulated motion.", "result": "The approach outperforms state-of-the-art methods in physics-based human pose estimation, producing accurate global motion trajectories and physically plausible poses.", "conclusion": "The neural Kalman-filtering method effectively balances kinematics and physics, improving motion capture quality and physical plausibility."}}
{"id": "2411.06542", "pdf": "https://arxiv.org/pdf/2411.06542", "abs": "https://arxiv.org/abs/2411.06542", "authors": ["Yuki Shirai", "Tong Zhao", "H. J. Terry Suh", "Huaijiang Zhu", "Xinpei Ni", "Jiuguang Wang", "Max Simchowitz", "Tao Pang"], "title": "Is Linear Feedback on Smoothed Dynamics Sufficient for Stabilizing Contact-Rich Plans?", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "ICRA2025", "summary": "Designing planners and controllers for contact-rich manipulation is extremely\nchallenging as contact violates the smoothness conditions that many\ngradient-based controller synthesis tools assume. Contact smoothing\napproximates a non-smooth system with a smooth one, allowing one to use these\nsynthesis tools more effectively. However, applying classical control synthesis\nmethods to smoothed contact dynamics remains relatively under-explored. This\npaper analyzes the efficacy of linear controller synthesis using differential\nsimulators based on contact smoothing. We introduce natural baselines for\nleveraging contact smoothing to compute (a) open-loop plans robust to uncertain\nconditions and/or dynamics, and (b) feedback gains to stabilize around\nopen-loop plans. Using robotic bimanual whole-body manipulation as a testbed,\nwe perform extensive empirical experiments on over 300 trajectories and analyze\nwhy LQR seems insufficient for stabilizing contact-rich plans. The video\nsummarizing this paper and hardware experiments is found here:\nhttps://youtu.be/HLaKi6qbwQg?si=_zCAmBBD6rGSitm9.", "AI": {"tldr": "The paper explores linear controller synthesis using contact smoothing for contact-rich manipulation, testing its effectiveness with empirical experiments.", "motivation": "Contact-rich manipulation is challenging due to non-smooth dynamics, and classical control synthesis methods for smoothed contact dynamics are under-explored.", "method": "The study uses differential simulators with contact smoothing to compute open-loop plans and feedback gains, tested on bimanual whole-body manipulation.", "result": "Empirical experiments on 300+ trajectories show LQR's insufficiency for stabilizing contact-rich plans.", "conclusion": "Contact smoothing aids control synthesis, but LQR alone may not suffice for contact-rich scenarios."}}
{"id": "2505.09506", "pdf": "https://arxiv.org/pdf/2505.09506", "abs": "https://arxiv.org/abs/2505.09506", "authors": ["Mar\u00eda Alejandra Hern\u00e1ndez", "Oscar Rodriguez", "Dae-Jin Lee"], "title": "Deep-SITAR: A SITAR-Based Deep Learning Framework for Growth Curve Modeling via Autoencoders", "categories": ["stat.ML", "cs.LG", "F.2.2; I.2.7"], "comment": "Pre-print", "summary": "Several approaches have been developed to capture the complexity and\nnonlinearity of human growth. One widely used is the Super Imposition by\nTranslation and Rotation (SITAR) model, which has become popular in studies of\nadolescent growth. SITAR is a shape-invariant mixed-effects model that\nrepresents the shared growth pattern of a population using a natural cubic\nspline mean curve while incorporating three subject-specific random effects --\ntiming, size, and growth intensity -- to account for variations among\nindividuals. In this work, we introduce a supervised deep learning framework\nbased on an autoencoder architecture that integrates a deep neural network\n(neural network) with a B-spline model to estimate the SITAR model. In this\napproach, the encoder estimates the random effects for each individual, while\nthe decoder performs a fitting based on B-splines similar to the classic SITAR\nmodel. We refer to this method as the Deep-SITAR model. This innovative\napproach enables the prediction of the random effects of new individuals\nentering a population without requiring a full model re-estimation. As a\nresult, Deep-SITAR offers a powerful approach to predicting growth\ntrajectories, combining the flexibility and efficiency of deep learning with\nthe interpretability of traditional mixed-effects models.", "AI": {"tldr": "Deep-SITAR combines deep learning with B-splines to predict human growth trajectories, improving efficiency and interpretability over the classic SITAR model.", "motivation": "To enhance the SITAR model by integrating deep learning for better prediction of individual growth variations without full re-estimation.", "method": "Uses an autoencoder with a neural network (encoder) and B-spline model (decoder) to estimate SITAR's random effects.", "result": "Deep-SITAR efficiently predicts growth trajectories for new individuals without re-estimating the entire model.", "conclusion": "Deep-SITAR merges deep learning's flexibility with traditional mixed-effects models' interpretability for growth analysis."}}
{"id": "2410.23854", "pdf": "https://arxiv.org/pdf/2410.23854", "abs": "https://arxiv.org/abs/2410.23854", "authors": ["Chenyu Li", "Minghui Zhang", "Chuyan Zhang", "Yun Gu"], "title": "Reflecting Topology Consistency and Abnormality via Learnable Attentions for Airway Labeling", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Accurate airway anatomical labeling is crucial for clinicians to identify and\nnavigate complex bronchial structures during bronchoscopy. Automatic airway\nanatomical labeling is challenging due to significant individual variability\nand anatomical variations. Previous methods are prone to generate inconsistent\npredictions, which is harmful for preoperative planning and intraoperative\nnavigation. This paper aims to address these challenges by proposing a novel\nmethod that enhances topological consistency and improves the detection of\nabnormal airway branches. We propose a novel approach incorporating two\nmodules: the Soft Subtree Consistency (SSC) and the Abnormal Branch Saliency\n(ABS). The SSC module constructs a soft subtree to capture clinically relevant\ntopological relationships, allowing for flexible feature aggregation within and\nacross subtrees. The ABS module facilitates the interaction between node\nfeatures and prototypes to distinguish abnormal branches, preventing the\nerroneous aggregation of features between normal and abnormal nodes. Evaluated\non a challenging dataset characterized by severe airway distortion and atrophy,\nour method achieves superior performance compared to state-of-the-art\napproaches. Specifically, it attains a 91.4% accuracy at the segmental level\nand an 83.7% accuracy at the subsegmental level, representing a 1.4% increase\nin subsegmental accuracy and a 3.1% increase in topological consistency.\nNotably, the method demonstrates reliable performance in cases with\ndisease-induced airway deformities, ensuring consistent and accurate labeling.", "AI": {"tldr": "A novel method for automatic airway anatomical labeling improves accuracy and consistency by incorporating Soft Subtree Consistency (SSC) and Abnormal Branch Saliency (ABS) modules, outperforming existing methods.", "motivation": "Accurate airway labeling is vital for bronchoscopy but challenging due to anatomical variability. Inconsistent predictions from prior methods hinder clinical use.", "method": "Proposes SSC for flexible topological feature aggregation and ABS to distinguish abnormal branches, preventing feature mixing.", "result": "Achieves 91.4% segmental and 83.7% subsegmental accuracy, with improved topological consistency and reliability in deformed airways.", "conclusion": "The method enhances labeling accuracy and consistency, especially in challenging cases, benefiting clinical applications."}}
{"id": "2411.17058", "pdf": "https://arxiv.org/pdf/2411.17058", "abs": "https://arxiv.org/abs/2411.17058", "authors": ["Tingmin Wu", "Shuiqiao Yang", "Shigang Liu", "David Nguyen", "Seung Jang", "Alsharif Abuadbba"], "title": "ThreatModeling-LLM: Automating Threat Modeling using Large Language Models for Banking System", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Threat modeling is a crucial component of cybersecurity, particularly for\nindustries such as banking, where the security of financial data is paramount.\nTraditional threat modeling approaches require expert intervention and manual\neffort, often leading to inefficiencies and human error. The advent of Large\nLanguage Models (LLMs) offers a promising avenue for automating these\nprocesses, enhancing both efficiency and efficacy. However, this transition is\nnot straightforward due to three main challenges: (1) the lack of publicly\navailable, domain-specific datasets, (2) the need for tailored models to handle\ncomplex banking system architectures, and (3) the requirement for real-time,\nadaptive mitigation strategies that align with compliance standards like NIST\n800-53. In this paper, we introduce ThreatModeling-LLM, a novel and adaptable\nframework that automates threat modeling for banking systems using LLMs.\nThreatModeling-LLM operates in three stages: 1) dataset creation, 2) prompt\nengineering and 3) model fine-tuning. We first generate a benchmark dataset\nusing Microsoft Threat Modeling Tool (TMT). Then, we apply Chain of Thought\n(CoT) and Optimization by PROmpting (OPRO) on the pre-trained LLMs to optimize\nthe initial prompt. Lastly, we fine-tune the LLM using Low-Rank Adaptation\n(LoRA) based on the benchmark dataset and the optimized prompt to improve the\nthreat identification and mitigation generation capabilities of pre-trained\nLLMs.", "AI": {"tldr": "ThreatModeling-LLM automates threat modeling for banking systems using LLMs, addressing dataset, model, and real-time strategy challenges.", "motivation": "Traditional threat modeling is inefficient and error-prone; LLMs offer automation potential but face domain-specific challenges.", "method": "Three-stage framework: dataset creation (using TMT), prompt engineering (CoT and OPRO), and model fine-tuning (LoRA).", "result": "Improved threat identification and mitigation generation capabilities in LLMs for banking systems.", "conclusion": "ThreatModeling-LLM provides an efficient, adaptable solution for automating threat modeling in banking."}}
{"id": "2505.09516", "pdf": "https://arxiv.org/pdf/2505.09516", "abs": "https://arxiv.org/abs/2505.09516", "authors": ["Siyi Wang", "Alexandre Leblanc", "Paul D. McNicholas"], "title": "Depth-Based Local Center Clustering: A Framework for Handling Different Clustering Scenarios", "categories": ["stat.ME", "cs.LG", "stat.AP"], "comment": null, "summary": "Cluster analysis, or clustering, plays a crucial role across numerous\nscientific and engineering domains. Despite the wealth of clustering methods\nproposed over the past decades, each method is typically designed for specific\nscenarios and presents certain limitations in practical applications. In this\npaper, we propose depth-based local center clustering (DLCC). This novel method\nmakes use of data depth, which is known to produce a center-outward ordering of\nsample points in a multivariate space. However, data depth typically fails to\ncapture the multimodal characteristics of {data}, something of the utmost\nimportance in the context of clustering. To overcome this, DLCC makes use of a\nlocal version of data depth that is based on subsets of {data}. From this,\nlocal centers can be identified as well as clusters of varying shapes.\nFurthermore, we propose a new internal metric based on density-based clustering\nto evaluate clustering performance on {non-convex clusters}. Overall, DLCC is a\nflexible clustering approach that seems to overcome some limitations of\ntraditional clustering methods, thereby enhancing data analysis capabilities\nacross a wide range of application scenarios.", "AI": {"tldr": "DLCC is a novel clustering method using local data depth to handle multimodal data and non-convex clusters, outperforming traditional methods.", "motivation": "Existing clustering methods are scenario-specific and limited; DLCC aims to address these gaps by leveraging local data depth.", "method": "DLCC uses local data depth on subsets of data to identify local centers and clusters of varying shapes, with a new density-based metric for evaluation.", "result": "DLCC effectively handles multimodal and non-convex clusters, offering flexibility and improved performance over traditional methods.", "conclusion": "DLCC enhances clustering capabilities, overcoming limitations of traditional methods for diverse applications."}}
{"id": "2412.05888", "pdf": "https://arxiv.org/pdf/2412.05888", "abs": "https://arxiv.org/abs/2412.05888", "authors": ["Donghang Lyu", "Ruochen Gao", "Marius Staring"], "title": "MCP-MedSAM: A Powerful Lightweight Medical Segment Anything Model Trained with a Single GPU in Just One Day", "categories": ["cs.CV"], "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA)", "summary": "Medical image segmentation involves partitioning medical images into\nmeaningful regions, with a focus on identifying anatomical structures and\nlesions. It has broad applications in healthcare, and deep learning methods\nhave enabled significant advancements in automating this process. Recently, the\nintroduction of the Segmentation Anything Model (SAM), the first foundation\nmodel for segmentation task, has prompted researchers to adapt it for the\nmedical domain to improve performance across various tasks. However, SAM's\nlarge model size and high GPU requirements hinder its scalability and\ndevelopment in the medical domain. In this work, we propose MCP-MedSAM, a\npowerful and lightweight medical SAM model designed to be trainable on a single\nA100 GPU with 40GB of memory within one day while delivering superior\nsegmentation performance. Recognizing the significant internal differences\nbetween modalities and the need for direct segmentation target information\nwithin bounding boxes, we introduce two kinds of prompts: the modality prompt\nand the content prompt. After passing through the prompt encoder, their\nembedding representations can further improve the segmentation performance by\nincorporating more relevant information without adding significant training\noverhead. Additionally, we adopt an effective modality-based data sampling\nstrategy to address data imbalance between modalities, ensuring more balanced\nperformance across all modalities. Our method was trained and evaluated using a\nlarge-scale challenge dataset, compared to top-ranking methods on the challenge\nleaderboard, MCP-MedSAM achieved superior performance while requiring only one\nday of training on a single GPU. The code is publicly available at\n\\textcolor{blue}{https://github.com/dong845/MCP-MedSAM}.}", "AI": {"tldr": "MCP-MedSAM is a lightweight medical image segmentation model based on SAM, designed for efficient training on a single GPU while improving performance through modality and content prompts.", "motivation": "SAM's large size and high GPU requirements limit its scalability in medical applications. MCP-MedSAM addresses this by offering a lightweight, efficient alternative.", "method": "Introduces modality and content prompts to enhance segmentation, uses a modality-based data sampling strategy, and trains on a single A100 GPU in one day.", "result": "Achieves superior performance compared to top-ranking methods on a challenge dataset, with efficient training.", "conclusion": "MCP-MedSAM is a scalable, high-performance solution for medical image segmentation, balancing efficiency and accuracy."}}
{"id": "2501.02982", "pdf": "https://arxiv.org/pdf/2501.02982", "abs": "https://arxiv.org/abs/2501.02982", "authors": ["Ziyan Qin", "Jigen Peng", "Shigang Yue", "Qinbing Fu"], "title": "A Bio-Inspired Research Paradigm of Collision Perception Neurons Enabling Neuro-Robotic Integration: The LGMD Case", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "comment": "35 pages, 6 figures", "summary": "Compared to human vision, locust visual systems excel at rapid and precise\ncollision detection, despite relying on only hundreds of thousands of neurons\norganized through a few neuropils. This efficiency makes them an attractive\nmodel system for developing artificial collision-detecting systems.\nSpecifically, researchers have identified collision-selective neurons in the\nlocust's optic lobe, called lobula giant movement detectors (LGMDs), which\nrespond specifically to approaching objects. Research upon LGMD neurons began\nin the early 1970s. Initially, due to their large size, these neurons were\nidentified as motion detectors, but their role as looming detectors was\nrecognized over time. Since then, progress in neuroscience, computational\nmodeling of LGMD's visual neural circuits, and LGMD-based robotics have\nadvanced in tandem, each field supporting and driving the others. Today, with a\ndeeper understanding of LGMD neurons, LGMD-based models have significantly\nimproved collision-free navigation in mobile robots including ground and aerial\nrobots. This review highlights recent developments in LGMD research from the\nperspectives of neuroscience, computational modeling, and robotics. It\nemphasizes a biologically plausible research paradigm, where insights from\nneuroscience inform real-world applications, which would in turn validate and\nadvance neuroscience. With strong support from extensive research and growing\napplication demand, this paradigm has reached a mature stage and demonstrates\nversatility across different areas of neuroscience research, thereby enhancing\nour understanding of the interconnections between neuroscience, computational\nmodeling, and robotics. Furthermore, this paradigm would shed light upon the\nmodeling and robotic research into other motion-sensitive neurons or neural\ncircuits.", "AI": {"tldr": "The paper reviews locust LGMD neurons for collision detection, highlighting their role in neuroscience, computational modeling, and robotics, and their impact on improving robot navigation.", "motivation": "Locusts' efficient collision detection with minimal neurons makes them a model for artificial systems, inspiring research into LGMD neurons for robotics and neuroscience.", "method": "Research combines neuroscience insights, computational modeling of LGMD circuits, and robotics applications to advance collision detection.", "result": "LGMD-based models have enhanced collision-free navigation in robots, validating the interdisciplinary approach.", "conclusion": "The LGMD research paradigm bridges neuroscience and robotics, offering a versatile model for studying other neural circuits."}}
{"id": "2505.09546", "pdf": "https://arxiv.org/pdf/2505.09546", "abs": "https://arxiv.org/abs/2505.09546", "authors": ["Yujin Kim", "Nathaniel Chin", "Arnav Vasudev", "Sanjiban Choudhury"], "title": "Distilling Realizable Students from Unrealizable Teachers", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We study policy distillation under privileged information, where a student\npolicy with only partial observations must learn from a teacher with full-state\naccess. A key challenge is information asymmetry: the student cannot directly\naccess the teacher's state space, leading to distributional shifts and policy\ndegradation. Existing approaches either modify the teacher to produce\nrealizable but sub-optimal demonstrations or rely on the student to explore\nmissing information independently, both of which are inefficient. Our key\ninsight is that the student should strategically interact with the teacher\n--querying only when necessary and resetting from recovery states --to stay on\na recoverable path within its own observation space. We introduce two methods:\n(i) an imitation learning approach that adaptively determines when the student\nshould query the teacher for corrections, and (ii) a reinforcement learning\napproach that selects where to initialize training for efficient exploration.\nWe validate our methods in both simulated and real-world robotic tasks,\ndemonstrating significant improvements over standard teacher-student baselines\nin training efficiency and final performance. The project website is available\nat : https://portal-cornell.github.io/CritiQ_ReTRy/", "AI": {"tldr": "Policy distillation under privileged information, where a student learns from a teacher with full-state access, is improved by strategic interaction and adaptive querying.", "motivation": "Addressing information asymmetry and inefficiency in existing methods for policy distillation.", "method": "Two approaches: (i) imitation learning with adaptive teacher queries, and (ii) reinforcement learning for efficient exploration initialization.", "result": "Validated in simulated and real-world tasks, showing improved training efficiency and performance over baselines.", "conclusion": "Strategic interaction and adaptive querying enhance policy distillation under privileged information."}}
{"id": "2502.07409", "pdf": "https://arxiv.org/pdf/2502.07409", "abs": "https://arxiv.org/abs/2502.07409", "authors": ["Anh-Tien Nguyen", "Duy Minh Ho Nguyen", "Nghiem Tuong Diep", "Trung Quoc Nguyen", "Nhat Ho", "Jacqueline Michelle Metsch", "Miriam Cindy Maurer", "Daniel Sonntag", "Hanibal Bohnenberger", "Anne-Christin Hauschild"], "title": "MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Whole slide pathology image classification presents challenges due to\ngigapixel image sizes and limited annotation labels, hindering model\ngeneralization. This paper introduces a prompt learning method to adapt large\nvision-language models for few-shot pathology classification. We first extend\nthe Prov-GigaPath vision foundation model, pre-trained on 1.3 billion pathology\nimage tiles, into a vision-language model by adding adaptors and aligning it\nwith medical text encoders via contrastive learning on 923K image-text pairs.\nThe model is then used to extract visual features and text embeddings from\nfew-shot annotations and fine-tunes with learnable prompt embeddings. Unlike\nprior methods that combine prompts with frozen features using prefix embeddings\nor self-attention, we propose multi-granular attention that compares\ninteractions between learnable prompts with individual image patches and groups\nof them. This approach improves the model's ability to capture both\nfine-grained details and broader context, enhancing its recognition of complex\npatterns across sub-regions. To further improve accuracy, we leverage\n(unbalanced) optimal transport-based visual-text distance to secure model\nrobustness by mitigating perturbations that might occur during the data\naugmentation process. Empirical experiments on lung, kidney, and breast\npathology modalities validate the effectiveness of our approach; thereby, we\nsurpass several of the latest competitors and consistently improve performance\nacross diverse architectures, including CLIP, PLIP, and Prov-GigaPath\nintegrated PLIP. We release our implementations and pre-trained models at this\nMGPATH.", "AI": {"tldr": "The paper introduces a prompt learning method for few-shot pathology image classification, leveraging a vision-language model with multi-granular attention and optimal transport-based distance to improve accuracy and robustness.", "motivation": "Challenges in whole slide pathology image classification due to gigapixel sizes and limited annotations hinder model generalization.", "method": "Extends Prov-GigaPath into a vision-language model, aligns it with medical text encoders, and uses multi-granular attention and optimal transport-based distance for robustness.", "result": "Outperforms competitors on lung, kidney, and breast pathology datasets, improving performance across architectures like CLIP, PLIP, and Prov-GigaPath integrated PLIP.", "conclusion": "The proposed method effectively addresses few-shot pathology classification challenges, enhancing model generalization and robustness."}}
{"id": "2501.12222", "pdf": "https://arxiv.org/pdf/2501.12222", "abs": "https://arxiv.org/abs/2501.12222", "authors": ["Zhenfeng Ouyang", "Bo-Wen Yao", "Xiao-Qi Han", "Peng-Jie Guo", "Ze-Feng Gao", "Zhong-Yi Lu"], "title": "High-temperature superconductivity in Li$_2$AuH$_6$ mediated by strong electron-phonon coupling under ambient pressure", "categories": ["cond-mat.supr-con", "cond-mat.mtrl-sci", "cs.AI", "physics.comp-ph"], "comment": "6 pages; 4 figures", "summary": "We used our developed AI search engine~(InvDesFlow) to perform extensive\ninvestigations regarding ambient stable superconducting hydrides. A cubic\nstructure Li$_2$AuH$_6$ with Au-H octahedral motifs is identified to be a\ncandidate. After performing thermodynamical analysis, we provide a feasible\nroute to experimentally synthesize this material via the known LiAu and LiH\ncompounds under ambient pressure. The further first-principles calculations\nsuggest that Li$_2$AuH$_6$ shows a high superconducting transition temperature\n($T_c$) $\\sim$ 140 K under ambient pressure. The H-1$s$ electrons strongly\ncouple with phonon modes of vibrations of Au-H octahedrons as well as\nvibrations of Li atoms, where the latter is not taken seriously in other\npreviously similar cases. Hence, different from previous claims of searching\nmetallic covalent bonds to find high-$T_c$ superconductors, we emphasize here\nthe importance of those phonon modes with strong electron-phonon coupling\n(EPC). And we suggest that one can intercalate atoms into binary or ternary\nhydrides to introduce more potential phonon modes with strong EPC, which is an\neffective approach to find high-$T_c$ superconductors within multicomponent\ncompounds.", "AI": {"tldr": "The paper identifies Li$_2$AuH$_6$ as a high-T$_c$ superconductor (140 K) under ambient pressure, emphasizing strong electron-phonon coupling (EPC) from Au-H and Li vibrations. It suggests intercalating atoms into hydrides to enhance EPC for discovering high-T$_c$ superconductors.", "motivation": "To discover ambient-stable superconducting hydrides with high transition temperatures (T$_c$) by focusing on strong electron-phonon coupling (EPC) mechanisms.", "method": "Used the AI search engine InvDesFlow to identify Li$_2$AuH$_6$, performed thermodynamical analysis, and first-principles calculations to evaluate its superconducting properties.", "result": "Li$_2$AuH$_6$ exhibits a high T$_c$ of 140 K under ambient pressure, driven by strong EPC from Au-H octahedrons and Li vibrations.", "conclusion": "Intercalating atoms into hydrides to introduce more phonon modes with strong EPC is a promising strategy for discovering high-T$_c$ superconductors in multicomponent compounds."}}
{"id": "2505.09552", "pdf": "https://arxiv.org/pdf/2505.09552", "abs": "https://arxiv.org/abs/2505.09552", "authors": ["Pascal K\u00fcndig", "Fabio Sigrist"], "title": "Scalable Computations for Generalized Mixed Effects Models with Crossed Random Effects Using Krylov Subspace Methods", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Mixed effects models are widely used for modeling data with hierarchically\ngrouped structures and high-cardinality categorical predictor variables.\nHowever, for high-dimensional crossed random effects, current standard\ncomputations relying on Cholesky decompositions can become prohibitively slow.\nIn this work, we present novel Krylov subspace-based methods that address\nseveral existing computational bottlenecks. Among other things, we\ntheoretically analyze and empirically evaluate various preconditioners for the\nconjugate gradient and stochastic Lanczos quadrature methods, derive new\nconvergence results, and develop computationally efficient methods for\ncalculating predictive variances. Extensive experiments using simulated and\nreal-world data sets show that our proposed methods scale much better than\nCholesky-based computations, for instance, achieving a runtime reduction of\napproximately two orders of magnitudes for both estimation and prediction.\nMoreover, our software implementation is up to 10'000 times faster and more\nstable than state-of-the-art implementations such as lme4 and glmmTMB when\nusing default settings. Our methods are implemented in the free C++ software\nlibrary GPBoost with high-level Python and R packages.", "AI": {"tldr": "Novel Krylov subspace-based methods improve computational efficiency for mixed effects models with high-dimensional crossed random effects, outperforming Cholesky-based methods by orders of magnitude.", "motivation": "Address computational bottlenecks in mixed effects models for high-dimensional crossed random effects, where Cholesky decompositions are too slow.", "method": "Propose Krylov subspace-based methods, analyze preconditioners for conjugate gradient and stochastic Lanczos quadrature, and develop efficient predictive variance calculations.", "result": "Achieves runtime reductions of ~100x, with software implementation up to 10,000x faster and more stable than lme4 and glmmTMB.", "conclusion": "The methods significantly enhance scalability and efficiency, implemented in GPBoost for practical use."}}
{"id": "2502.15250", "pdf": "https://arxiv.org/pdf/2502.15250", "abs": "https://arxiv.org/abs/2502.15250", "authors": ["Yishuo Wang", "Feng Zhou", "Qicheng Meng", "Muping Zhou", "Zhijun Hu", "Chengqing Zhang", "Tianhao Zhao"], "title": "An ocean front detection and tracking algorithm", "categories": ["cs.CV"], "comment": null, "summary": "Existing ocean front detection methods--including histogram-based variance\nanalysis, Lyapunov exponent, gradient thresholding, and machine\nlearning--suffer from critical limitations: discontinuous outputs,\nover-detection, reliance on single-threshold decisions, and lack of open-source\nimplementations. To address these challenges, this paper proposes the Bayesian\nFront Detection and Tracking framework with Metric Space Analysis (BFDT-MSA).\nThe framework introduces three innovations: (1) a Bayesian decision mechanism\nthat integrates gradient priors and field operators to eliminate manual\nthreshold sensitivity; (2) morphological refinement algorithms for merging\nfragmented fronts, deleting spurious rings, and thinning frontal zones to\npixel-level accuracy; and (3) a novel metric space definition for temporal\nfront tracking, enabling systematic analysis of front evolution. Validated on\nglobal SST data (2022--2024), BFDT-MSA reduces over-detection by $73\\%$\ncompared to histogram-based methods while achieving superior intensity\n($0.16^\\circ$C/km), continuity, and spatiotemporal coherence. The open-source\nrelease bridges a critical gap in reproducible oceanographic research.", "AI": {"tldr": "The paper proposes BFDT-MSA, a Bayesian framework for ocean front detection, addressing limitations like discontinuous outputs and over-detection with innovations like Bayesian decision mechanisms and morphological refinement.", "motivation": "Existing methods for ocean front detection have flaws like discontinuous outputs and reliance on single-threshold decisions, prompting the need for a more robust solution.", "method": "BFDT-MSA integrates Bayesian decision mechanisms, morphological refinement algorithms, and metric space analysis for temporal front tracking.", "result": "Validated on global SST data, BFDT-MSA reduces over-detection by 73% and improves intensity, continuity, and coherence.", "conclusion": "The framework offers a reproducible, open-source solution for ocean front detection, advancing oceanographic research."}}
{"id": "2502.01391", "pdf": "https://arxiv.org/pdf/2502.01391", "abs": "https://arxiv.org/abs/2502.01391", "authors": ["Fotis I. Giasemis", "Alexandros Sopasakis"], "title": "Learning Traffic Anomalies from Generative Models on Real-Time Observations", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Accurate detection of traffic anomalies is crucial for effective urban\ntraffic management and congestion mitigation. We use the Spatiotemporal\nGenerative Adversarial Network (STGAN) framework combining Graph Neural\nNetworks and Long Short-Term Memory networks to capture complex spatial and\ntemporal dependencies in traffic data. We apply STGAN to real-time,\nminute-by-minute observations from 42 traffic cameras across Gothenburg,\nSweden, collected over several months in 2020. The images are processed to\ncompute a flow metric representing vehicle density, which serves as input for\nthe model. Training is conducted on data from April to November 2020, and\nvalidation is performed on a separate dataset from November 14 to 23, 2020. Our\nresults demonstrate that the model effectively detects traffic anomalies with\nhigh precision and low false positive rates. The detected anomalies include\ncamera signal interruptions, visual artifacts, and extreme weather conditions\naffecting traffic flow.", "AI": {"tldr": "STGAN framework detects traffic anomalies with high precision using spatiotemporal data from Gothenburg traffic cameras.", "motivation": "Accurate traffic anomaly detection is vital for urban traffic management and congestion reduction.", "method": "Combines Graph Neural Networks and LSTM in STGAN to analyze spatial and temporal traffic data from 42 cameras.", "result": "High precision and low false positives in detecting anomalies like signal interruptions and weather effects.", "conclusion": "STGAN effectively identifies traffic anomalies, aiding urban traffic management."}}
{"id": "2505.09603", "pdf": "https://arxiv.org/pdf/2505.09603", "abs": "https://arxiv.org/abs/2505.09603", "authors": ["Shivin Dass", "Alaa Khaddaj", "Logan Engstrom", "Aleksander Madry", "Andrew Ilyas", "Roberto Mart\u00edn-Mart\u00edn"], "title": "DataMIL: Selecting Data for Robot Imitation Learning with Datamodels", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Recently, the robotics community has amassed ever larger and more diverse\ndatasets to train generalist robot policies. However, while these policies\nachieve strong mean performance across a variety of tasks, they often\nunderperform on individual, specialized tasks and require further tuning on\nnewly acquired task-specific data. Combining task-specific data with carefully\ncurated subsets of large prior datasets via co-training can produce better\nspecialized policies, but selecting data naively may actually harm downstream\nperformance. To address this, we introduce DataMIL, a policy-driven data\nselection framework built on the datamodels paradigm that reasons about data\nselection in an end-to-end manner, using the policy itself to identify which\ndata points will most improve performance. Unlike standard practices that\nfilter data using human notions of quality (e.g., based on semantic or visual\nsimilarity), DataMIL directly optimizes data selection for task success,\nallowing us to select data that enhance the policy while dropping data that\ndegrade it. To avoid performing expensive rollouts in the environment during\nselection, we use a novel surrogate loss function on task-specific data,\nallowing us to use DataMIL in the real world without degrading performance. We\nvalidate our approach on a suite of more than 60 simulation and real-world\nmanipulation tasks - most notably showing successful data selection from the\nOpen X-Embodiment datasets-demonstrating consistent gains in success rates and\nsuperior performance over multiple baselines. Our results underscore the\nimportance of end-to-end, performance-aware data selection for unlocking the\npotential of large prior datasets in robotics. More information at\nhttps://robin-lab.cs.utexas.edu/datamodels4imitation/", "AI": {"tldr": "DataMIL is a policy-driven framework for selecting data to improve specialized robot policies by optimizing for task success, outperforming baselines on 60+ tasks.", "motivation": "Large datasets train generalist robot policies, but they often underperform on specialized tasks. Combining task-specific data with curated subsets of prior datasets can help, but naive selection may harm performance.", "method": "DataMIL uses a policy-driven approach with a surrogate loss function to select data that enhances performance, avoiding expensive rollouts.", "result": "Validated on 60+ tasks, DataMIL consistently improves success rates and outperforms baselines, especially with Open X-Embodiment datasets.", "conclusion": "End-to-end, performance-aware data selection is crucial for leveraging large datasets in robotics effectively."}}
{"id": "2503.21776", "pdf": "https://arxiv.org/pdf/2503.21776", "abs": "https://arxiv.org/abs/2503.21776", "authors": ["Kaituo Feng", "Kaixiong Gong", "Bohao Li", "Zonghao Guo", "Yibing Wang", "Tianshuo Peng", "Junfei Wu", "Xiaoying Zhang", "Benyou Wang", "Xiangyu Yue"], "title": "Video-R1: Reinforcing Video Reasoning in MLLMs", "categories": ["cs.CV"], "comment": "Project page: https://github.com/tulerfeng/Video-R1", "summary": "Inspired by DeepSeek-R1's success in eliciting reasoning abilities through\nrule-based reinforcement learning (RL), we introduce Video-R1 as the first\nattempt to systematically explore the R1 paradigm for incentivizing video\nreasoning within multimodal large language models (MLLMs). However, directly\napplying RL training with the GRPO algorithm to video reasoning presents two\nprimary challenges: (i) a lack of temporal modeling for video reasoning, and\n(ii) the scarcity of high-quality video-reasoning data. To address these\nissues, we first propose the T-GRPO algorithm, which encourages models to\nutilize temporal information in videos for reasoning. Additionally, instead of\nrelying solely on video data, we incorporate high-quality image-reasoning data\ninto the training process. We have constructed two datasets: Video-R1-CoT-165k\nfor SFT cold start and Video-R1-260k for RL training, both comprising image and\nvideo data. Experimental results demonstrate that Video-R1 achieves significant\nimprovements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as\nwell as on general video benchmarks including MVBench and TempCompass, etc.\nNotably, Video-R1-7B attains a 37.1% accuracy on video spatial reasoning\nbenchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All\ncode, models, and data are released in: https://github.com/tulerfeng/Video-R1.", "AI": {"tldr": "Video-R1 introduces a rule-based RL approach for video reasoning in MLLMs, addressing temporal modeling and data scarcity with T-GRPO and hybrid datasets, achieving superior performance over GPT-4o.", "motivation": "To extend the R1 paradigm for video reasoning in MLLMs, overcoming challenges like temporal modeling and data scarcity.", "method": "Proposes T-GRPO for temporal modeling and uses hybrid image-video datasets (Video-R1-CoT-165k and Video-R1-260k) for training.", "result": "Significant improvements on benchmarks like VideoMMMU and VSI-Bench, with Video-R1-7B outperforming GPT-4o (37.1% accuracy on VSI-bench).", "conclusion": "Video-R1 successfully adapts RL for video reasoning, demonstrating state-of-the-art performance and releasing all resources openly."}}
{"id": "2502.18760", "pdf": "https://arxiv.org/pdf/2502.18760", "abs": "https://arxiv.org/abs/2502.18760", "authors": ["Akhil Nagariya", "Dimitar Filev", "Srikanth Saripalli", "Gaurav Pandey"], "title": "Learning Autonomy: Off-Road Navigation Enhanced by Human Input", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "In the area of autonomous driving, navigating off-road terrains presents a\nunique set of challenges, from unpredictable surfaces like grass and dirt to\nunexpected obstacles such as bushes and puddles. In this work, we present a\nnovel learning-based local planner that addresses these challenges by directly\ncapturing human driving nuances from real-world demonstrations using only a\nmonocular camera. The key features of our planner are its ability to navigate\nin challenging off-road environments with various terrain types and its fast\nlearning capabilities. By utilizing minimal human demonstration data (5-10\nmins), it quickly learns to navigate in a wide array of off-road conditions.\nThe local planner significantly reduces the real world data required to learn\nhuman driving preferences. This allows the planner to apply learned behaviors\nto real-world scenarios without the need for manual fine-tuning, demonstrating\nquick adjustment and adaptability in off-road autonomous driving technology.", "AI": {"tldr": "A learning-based local planner for off-road autonomous driving uses minimal human demonstrations (5-10 mins) to quickly adapt to diverse terrains, reducing data needs and manual tuning.", "motivation": "Navigating off-road terrains is challenging due to unpredictable surfaces and obstacles, requiring adaptable solutions.", "method": "The planner captures human driving nuances from real-world monocular camera demonstrations, enabling fast learning.", "result": "It successfully navigates various off-road conditions with minimal data and no manual fine-tuning.", "conclusion": "The planner demonstrates adaptability and efficiency in off-road autonomous driving, reducing reliance on extensive data."}}
{"id": "2505.09612", "pdf": "https://arxiv.org/pdf/2505.09612", "abs": "https://arxiv.org/abs/2505.09612", "authors": ["Tathagata Sadhukhan", "Manit Paul", "Raaz Dwivedi"], "title": "Adaptively-weighted Nearest Neighbors for Matrix Completion", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "25 pages, 6 figures", "summary": "In this technical note, we introduce and analyze AWNN: an adaptively weighted\nnearest neighbor method for performing matrix completion. Nearest neighbor (NN)\nmethods are widely used in missing data problems across multiple disciplines\nsuch as in recommender systems and for performing counterfactual inference in\npanel data settings. Prior works have shown that in addition to being very\nintuitive and easy to implement, NN methods enjoy nice theoretical guarantees.\nHowever, the performance of majority of the NN methods rely on the appropriate\nchoice of the radii and the weights assigned to each member in the nearest\nneighbor set and despite several works on nearest neighbor methods in the past\ntwo decades, there does not exist a systematic approach of choosing the radii\nand the weights without relying on methods like cross-validation. AWNN\naddresses this challenge by judiciously balancing the bias variance trade off\ninherent in weighted nearest-neighbor regression. We provide theoretical\nguarantees for the proposed method under minimal assumptions and support the\ntheory via synthetic experiments.", "AI": {"tldr": "AWNN is an adaptively weighted nearest neighbor method for matrix completion, addressing the challenge of choosing radii and weights systematically without cross-validation.", "motivation": "Existing NN methods lack a systematic approach for selecting radii and weights, relying on cross-validation. AWNN aims to solve this by balancing bias-variance trade-offs.", "method": "AWNN introduces adaptive weighting for nearest neighbors, balancing bias and variance in regression. Theoretical guarantees are provided under minimal assumptions.", "result": "The method is supported by synthetic experiments, demonstrating its effectiveness in matrix completion tasks.", "conclusion": "AWNN offers a systematic and theoretically grounded solution for improving nearest neighbor methods in matrix completion."}}
{"id": "2504.14988", "pdf": "https://arxiv.org/pdf/2504.14988", "abs": "https://arxiv.org/abs/2504.14988", "authors": ["Hong-Tao Yu", "Xiu-Shen Wei", "Yuxin Peng", "Serge Belongie"], "title": "Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A Comprehensive Evaluation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated\nremarkable multimodal perception capabilities, garnering significant attention.\nWhile numerous evaluation studies have emerged, assessing LVLMs both\nholistically and on specialized tasks, fine-grained image tasks-fundamental to\ncomputer vision-remain largely unexplored. To fill this gap, we introduce a\ncomprehensive fine-grained evaluation benchmark, i.e., FG-BMK, comprising 1.01\nmillion questions and 0.33 million images. Our evaluation systematically\nexamines LVLMs from both human-oriented and machine-oriented perspectives,\nfocusing on their semantic recognition and fine-grained feature representation\ncapabilities. Through extensive experiments on twelve representative\nLVLMs/VLMs, we uncover key findings regarding the influence of training\nparadigms, modality alignment, perturbation susceptibility, and fine-grained\ncategory reasoning on task performance. This work provides critical insights\ninto the limitations of current LVLMs and offers guidance for future data\nconstruction and model design in the development of more advanced LVLMs. Our\ncode is open-source and available at https://github.com/SEU-VIPGroup/FG-BMK.", "AI": {"tldr": "The paper introduces FG-BMK, a fine-grained evaluation benchmark for Large Vision-Language Models (LVLMs), addressing gaps in assessing their performance on detailed image tasks.", "motivation": "Existing evaluations of LVLMs lack focus on fine-grained image tasks, which are fundamental to computer vision.", "method": "The authors create FG-BMK, a benchmark with 1.01M questions and 0.33M images, and evaluate 12 LVLMs/VLMs on semantic recognition and fine-grained feature representation.", "result": "Key findings include insights into training paradigms, modality alignment, perturbation susceptibility, and fine-grained reasoning.", "conclusion": "The study highlights LVLM limitations and provides guidance for future data and model improvements, with open-source code available."}}
{"id": "2503.10984", "pdf": "https://arxiv.org/pdf/2503.10984", "abs": "https://arxiv.org/abs/2503.10984", "authors": ["Hanti Lin"], "title": "The Problem of the Priors, or Posteriors?", "categories": ["stat.OT", "cs.AI", "math.PR"], "comment": null, "summary": "The problem of the priors is well known: it concerns the challenge of\nidentifying norms that govern one's prior credences. I argue that a key to\naddressing this problem lies in considering what I call the problem of the\nposteriors -- the challenge of identifying norms that directly govern one's\nposterior credences, which backward induce some norms on the priors via the\ndiachronic requirement of conditionalization. This forward-looking approach can\nbe summarized as: Think ahead, work backward. Although this idea can be traced\nto Freedman (1963), Carnap (1963), and Shimony (1970), I believe that it has\nnot received enough attention. In this paper, I initiate a systematic defense\nof forward-looking Bayesianism, addressing potential objections from more\ntraditional views (both subjectivist and objectivist). I also develop a\nspecific approach to forward-looking Bayesianism -- one that values the\nconvergence of posterior credences to the truth, and treats it as a fundamental\nrather than derived norm. This approach, called {\\em convergentist\nBayesianism}, is argued to be crucial for a Bayesian foundation of Ockham's\nrazor in statistics and machine learning.", "AI": {"tldr": "The paper proposes a forward-looking approach to Bayesianism, focusing on posterior credences to induce norms on priors, and introduces convergentist Bayesianism as a key norm for truth convergence.", "motivation": "Address the problem of priors by shifting focus to posterior credences, leveraging conditionalization to backward induce norms on priors.", "method": "Systematic defense of forward-looking Bayesianism, addressing objections from traditional views, and developing convergentist Bayesianism.", "result": "Convergentist Bayesianism is presented as a fundamental norm for truth convergence, supporting Ockham's razor in statistics and machine learning.", "conclusion": "Forward-looking Bayesianism, especially convergentist Bayesianism, offers a robust framework for norm derivation and foundational support for Ockham's razor."}}
{"id": "2405.13806", "pdf": "https://arxiv.org/pdf/2405.13806", "abs": "https://arxiv.org/abs/2405.13806", "authors": ["Nian Liu", "Xiaoxin He", "Thomas Laurent", "Francesco Di Giovanni", "Michael M. Bronstein", "Xavier Bresson"], "title": "A General Graph Spectral Wavelet Convolution via Chebyshev Order Decomposition", "categories": ["cs.LG"], "comment": "This paper is accepted by ICML 2025", "summary": "Spectral graph convolution, an important tool of data filtering on graphs,\nrelies on two essential decisions: selecting spectral bases for signal\ntransformation and parameterizing the kernel for frequency analysis. While\nrecent techniques mainly focus on standard Fourier transform and vector-valued\nspectral functions, they fall short in flexibility to model signal\ndistributions over large spatial ranges, and capacity of spectral function. In\nthis paper, we present a novel wavelet-based graph convolution network, namely\nWaveGC, which integrates multi-resolution spectral bases and a matrix-valued\nfilter kernel. Theoretically, we establish that WaveGC can effectively capture\nand decouple short-range and long-range information, providing superior\nfiltering flexibility, surpassing existing graph wavelet neural networks. To\ninstantiate WaveGC, we introduce a novel technique for learning general graph\nwavelets by separately combining odd and even terms of Chebyshev polynomials.\nThis approach strictly satisfies wavelet admissibility criteria. Our numerical\nexperiments showcase the consistent improvements in both short-range and\nlong-range tasks. This underscores the effectiveness of the proposed model in\nhandling different scenarios. Our code is available at\nhttps://github.com/liun-online/WaveGC.", "AI": {"tldr": "WaveGC, a wavelet-based graph convolution network, improves spectral graph convolution by integrating multi-resolution bases and a matrix-valued kernel, outperforming existing methods in flexibility and performance.", "motivation": "Existing spectral graph convolution methods lack flexibility for large spatial ranges and spectral function capacity, limiting their effectiveness.", "method": "WaveGC combines multi-resolution spectral bases and a matrix-valued filter kernel, using Chebyshev polynomials to learn general graph wavelets while satisfying admissibility criteria.", "result": "Numerical experiments show WaveGC consistently improves performance in both short-range and long-range tasks.", "conclusion": "WaveGC offers superior filtering flexibility and effectiveness, making it a robust solution for diverse graph signal processing scenarios."}}
{"id": "2505.02126", "pdf": "https://arxiv.org/pdf/2505.02126", "abs": "https://arxiv.org/abs/2505.02126", "authors": ["Zhihao Tang", "Shenghao Yang", "Hongtao Zhang", "Mingbo Zhao"], "title": "GarmentGS: Point-Cloud Guided Gaussian Splatting for High-Fidelity Non-Watertight 3D Garment Reconstruction", "categories": ["cs.CV"], "comment": "Accepted by ICMR 2025", "summary": "Traditional 3D garment creation requires extensive manual operations,\nresulting in time and labor costs. Recently, 3D Gaussian Splatting has achieved\nbreakthrough progress in 3D scene reconstruction and rendering, attracting\nwidespread attention and opening new pathways for 3D garment reconstruction.\nHowever, due to the unstructured and irregular nature of Gaussian primitives,\nit is difficult to reconstruct high-fidelity, non-watertight 3D garments. In\nthis paper, we present GarmentGS, a dense point cloud-guided method that can\nreconstruct high-fidelity garment surfaces with high geometric accuracy and\ngenerate non-watertight, single-layer meshes. Our method introduces a fast\ndense point cloud reconstruction module that can complete garment point cloud\nreconstruction in 10 minutes, compared to traditional methods that require\nseveral hours. Furthermore, we use dense point clouds to guide the movement,\nflattening, and rotation of Gaussian primitives, enabling better distribution\non the garment surface to achieve superior rendering effects and geometric\naccuracy. Through numerical and visual comparisons, our method achieves fast\ntraining and real-time rendering while maintaining competitive quality.", "AI": {"tldr": "GarmentGS uses dense point clouds to guide 3D Gaussian Splatting for fast, high-fidelity garment reconstruction, outperforming traditional methods in speed and quality.", "motivation": "Traditional 3D garment creation is time-consuming and labor-intensive. Gaussian Splatting offers potential but struggles with unstructured primitives for garment reconstruction.", "method": "Introduces GarmentGS, leveraging dense point clouds to guide Gaussian primitives for accurate, non-watertight garment reconstruction and fast point cloud generation.", "result": "Achieves garment reconstruction in 10 minutes (vs. hours), with high geometric accuracy and superior rendering.", "conclusion": "GarmentGS enables fast, high-quality garment reconstruction with real-time rendering, advancing 3D garment modeling."}}
{"id": "2504.10612", "pdf": "https://arxiv.org/pdf/2504.10612", "abs": "https://arxiv.org/abs/2504.10612", "authors": ["Michal Balcerak", "Tamaz Amiranashvili", "Antonio Terpin", "Suprosanna Shit", "Sebastian Kaltenbach", "Petros Koumoutsakos", "Bjoern Menze"], "title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The most widely used generative models map noise and data distributions by\nmatching flows or scores. However, they struggle to incorporate partial\nobservations and additional priors--something energy-based models (EBMs) handle\nelegantly by simply adding corresponding scalar energy terms. We address this\nissue by proposing Energy Matching, a framework that endows flow-based\napproaches with the flexibility of EBMs. Far from the data manifold, samples\nmove along curl-free, optimal transport paths from noise to data. As they\napproach the data manifold, an entropic energy term guides the system into a\nBoltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in\nterms of fidelity, while retaining simulation-free training of transport-based\napproaches away from the data manifold. Furthermore, we leverage the method's\nflexibility to introduce an interaction energy that supports diverse mode\nexploration, which we demonstrate in a controlled protein-generation setting.\nOur approach focuses on learning a scalar potential energy--without\ntime-conditioning, auxiliary generators, or additional networks--which marks a\nsignificant departure from recent EBM methods. We believe that this simplified\nframework significantly advances EBMs capabilities and paves the way for their\nwider adoption in generative modeling across diverse domains.", "AI": {"tldr": "Energy Matching combines flow-based models with EBM flexibility, improving generation fidelity and regularization for inverse problems.", "motivation": "Address limitations of generative models in handling partial observations and priors, leveraging EBM strengths.", "method": "Proposes Energy Matching, using a scalar field to guide samples from noise to data, incorporating entropic energy for Boltzmann equilibrium.", "result": "Outperforms EBMs on CIFAR-10 and ImageNet, supports diverse mode exploration in protein generation.", "conclusion": "Simplifies EBM framework, advancing generative modeling capabilities for broader adoption."}}
{"id": "2406.13041", "pdf": "https://arxiv.org/pdf/2406.13041", "abs": "https://arxiv.org/abs/2406.13041", "authors": ["Haoyuan Cai", "Sulaiman A. Alghunaim", "Ali H. Sayed"], "title": "Accelerated Stochastic Min-Max Optimization Based on Bias-corrected Momentum", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Lower-bound analyses for nonconvex strongly-concave minimax optimization\nproblems have shown that stochastic first-order algorithms require at least\n$\\mathcal{O}(\\varepsilon^{-4})$ oracle complexity to find an\n$\\varepsilon$-stationary point. Some works indicate that this complexity can be\nimproved to $\\mathcal{O}(\\varepsilon^{-3})$ when the loss gradient is Lipschitz\ncontinuous. The question of achieving enhanced convergence rates under distinct\nconditions, remains unresolved. In this work, we address this question for\noptimization problems that are nonconvex in the minimization variable and\nstrongly concave or Polyak-Lojasiewicz (PL) in the maximization variable. We\nintroduce novel bias-corrected momentum algorithms utilizing efficient\nHessian-vector products. We establish convergence conditions and demonstrate a\nlower iteration complexity of $\\mathcal{O}(\\varepsilon^{-3})$ for the proposed\nalgorithms. The effectiveness of the method is validated through applications\nto robust logistic regression using real-world datasets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.06512", "pdf": "https://arxiv.org/pdf/2505.06512", "abs": "https://arxiv.org/abs/2505.06512", "authors": ["Hang Wang", "Zhi-Qi Cheng", "Chenhao Lin", "Chao Shen", "Lei Zhang"], "title": "HCMA: Hierarchical Cross-model Alignment for Grounded Text-to-Image Generation", "categories": ["cs.CV"], "comment": "10 pages, 4 figures", "summary": "Text-to-image synthesis has progressed to the point where models can generate\nvisually compelling images from natural language prompts. Yet, existing methods\noften fail to reconcile high-level semantic fidelity with explicit spatial\ncontrol, particularly in scenes involving multiple objects, nuanced relations,\nor complex layouts. To bridge this gap, we propose a Hierarchical Cross-Modal\nAlignment (HCMA) framework for grounded text-to-image generation. HCMA\nintegrates two alignment modules into each diffusion sampling step: a global\nmodule that continuously aligns latent representations with textual\ndescriptions to ensure scene-level coherence, and a local module that employs\nbounding-box layouts to anchor objects at specified locations, enabling\nfine-grained spatial control. Extensive experiments on the MS-COCO 2014\nvalidation set show that HCMA surpasses state-of-the-art baselines, achieving a\n0.69 improvement in Frechet Inception Distance (FID) and a 0.0295 gain in CLIP\nScore. These results demonstrate HCMA's effectiveness in faithfully capturing\nintricate textual semantics while adhering to user-defined spatial constraints,\noffering a robust solution for semantically grounded image generation.Our code\nis available at https://github.com/hwang-cs-ime/HCMA", "AI": {"tldr": "HCMA improves text-to-image synthesis by combining global and local alignment for better semantic fidelity and spatial control.", "motivation": "Existing methods lack spatial control and semantic fidelity in complex scenes.", "method": "HCMA integrates global (scene-level) and local (object-level) alignment modules into diffusion sampling.", "result": "HCMA outperforms baselines, improving FID by 0.69 and CLIP Score by 0.0295.", "conclusion": "HCMA effectively balances semantic accuracy and spatial control for grounded image generation."}}
{"id": "2504.16472", "pdf": "https://arxiv.org/pdf/2504.16472", "abs": "https://arxiv.org/abs/2504.16472", "authors": ["Mark Harman", "Peter O'Hearn", "Shubho Sengupta"], "title": "Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges", "categories": ["cs.SE", "cs.AI"], "comment": "To Appear as keynote paper at FSE 2025", "summary": "Despite decades of research and practice in automated software testing,\nseveral fundamental concepts remain ill-defined and under-explored, yet offer\nenormous potential real-world impact. We show that these concepts raise\nexciting new challenges in the context of Large Language Models for software\ntest generation. More specifically, we formally define and investigate the\nproperties of hardening and catching tests. A hardening test is one that seeks\nto protect against future regressions, while a catching test is one that\ncatches such a regression or a fault in new functionality introduced by a code\nchange. Hardening tests can be generated at any time and may become catching\ntests when a future regression is caught. We also define and motivate the\nCatching 'Just-in-Time' (JiTTest) Challenge, in which tests are generated\n'just-in-time' to catch new faults before they land into production. We show\nthat any solution to Catching JiTTest generation can also be repurposed to\ncatch latent faults in legacy code. We enumerate possible outcomes for\nhardening and catching tests and JiTTests, and discuss open research problems,\ndeployment options, and initial results from our work on automated LLM-based\nhardening at Meta. This paper was written to accompany the keynote by the\nauthors at the ACM International Conference on the Foundations of Software\nEngineering (FSE) 2025. Author order is alphabetical. The corresponding author\nis Mark Harman.", "AI": {"tldr": "The paper explores hardening and catching tests in software testing, introduces the Catching 'Just-in-Time' (JiTTest) Challenge, and discusses LLM-based solutions for automated test generation.", "motivation": "To address ill-defined fundamental concepts in automated software testing and leverage Large Language Models (LLMs) for impactful test generation.", "method": "Formally defines hardening and catching tests, proposes the JiTTest Challenge, and explores LLM-based solutions for automated test generation.", "result": "Initial results from LLM-based hardening at Meta and potential outcomes for hardening, catching tests, and JiTTests.", "conclusion": "The paper highlights open research problems, deployment options, and the potential of LLMs in software testing, aiming to catch faults before production."}}
{"id": "2408.10368", "pdf": "https://arxiv.org/pdf/2408.10368", "abs": "https://arxiv.org/abs/2408.10368", "authors": ["Yuntao Wu", "Jiayuan Guo", "Goutham Gopalakrishna", "Zissis Poulos"], "title": "Deep-MacroFin: Informed Equilibrium Neural Network for Continuous Time Economic Models", "categories": ["cs.LG", "cs.CE", "q-fin.CP", "I.0; J.4"], "comment": "30 pages, 13 figures", "summary": "In this paper, we present Deep-MacroFin, a comprehensive framework designed\nto solve partial differential equations, with a particular focus on models in\ncontinuous time economics. This framework leverages deep learning\nmethodologies, including Multi-Layer Perceptrons and the newly developed\nKolmogorov-Arnold Networks. It is optimized using economic information\nencapsulated by Hamilton-Jacobi-Bellman (HJB) equations and coupled algebraic\nequations. The application of neural networks holds the promise of accurately\nresolving high-dimensional problems with fewer computational demands and\nlimitations compared to other numerical methods. This framework can be readily\nadapted for systems of partial differential equations in high dimensions.\nImportantly, it offers a more efficient (5$\\times$ less CUDA memory and\n40$\\times$ fewer FLOPs in 100D problems) and user-friendly implementation than\nexisting libraries. We also incorporate a time-stepping scheme to enhance\ntraining stability for nonlinear HJB equations, enabling the solution of 50D\neconomic models.", "AI": {"tldr": "Deep-MacroFin is a deep learning framework for solving high-dimensional PDEs in economics, offering efficiency and ease of use.", "motivation": "Addressing computational challenges in solving high-dimensional PDEs in continuous-time economics.", "method": "Uses Multi-Layer Perceptrons and Kolmogorov-Arnold Networks, optimized with HJB equations and algebraic constraints.", "result": "Achieves 5\u00d7 less memory and 40\u00d7 fewer FLOPs in 100D problems, and solves 50D economic models.", "conclusion": "Deep-MacroFin provides an efficient, scalable solution for high-dimensional PDEs in economics."}}
{"id": "2505.08233", "pdf": "https://arxiv.org/pdf/2505.08233", "abs": "https://arxiv.org/abs/2505.08233", "authors": ["Santhoshkumar Peddi", "Soham Bandyopadhyay", "Debasis Samanta"], "title": "G-MSGINet: A Grouped Multi-Scale Graph-Involution Network for Contactless Fingerprint Recognition", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents G-MSGINet, a unified and efficient framework for robust\ncontactless fingerprint recognition that jointly performs minutiae localization\nand identity embedding directly from raw input images. Existing approaches rely\non multi-branch architectures, orientation labels, or complex preprocessing\nsteps, which limit scalability and generalization across real-world acquisition\nscenarios. In contrast, the proposed architecture introduces the GMSGI layer, a\nnovel computational module that integrates grouped pixel-level involution,\ndynamic multi-scale kernel generation, and graph-based relational modelling\ninto a single processing unit. Stacked GMSGI layers progressively refine both\nlocal minutiae-sensitive features and global topological representations\nthrough end-to-end optimization. The architecture eliminates explicit\norientation supervision and adapts graph connectivity directly from learned\nkernel descriptors, thereby capturing meaningful structural relationships among\nfingerprint regions without fixed heuristics. Extensive experiments on three\nbenchmark datasets, namely PolyU, CFPose, and Benchmark 2D/3D, demonstrate that\nG-MSGINet consistently achieves minutiae F1-scores in the range of\n$0.83\\pm0.02$ and Rank-1 identification accuracies between 97.0% and 99.1%,\nwhile maintaining an Equal Error Rate (EER) as low as 0.5%. These results\ncorrespond to improvements of up to 4.8% in F1-score and 1.4% in Rank-1\naccuracy when compared to prior methods, using only 0.38 million parameters and\n6.63 giga floating-point operations, which represents up to ten times fewer\nparameters than competitive baselines. This highlights the scalability and\neffectiveness of G-MSGINet in real-world contactless biometric recognition\nscenarios.", "AI": {"tldr": "G-MSGINet is a unified framework for contactless fingerprint recognition, combining minutiae localization and identity embedding without complex preprocessing. It outperforms existing methods with fewer parameters.", "motivation": "Existing fingerprint recognition methods rely on multi-branch architectures or complex preprocessing, limiting scalability and generalization. G-MSGINet aims to address these limitations.", "method": "The framework uses GMSGI layers, integrating pixel-level involution, multi-scale kernel generation, and graph-based relational modeling. It refines features end-to-end without orientation supervision.", "result": "G-MSGINet achieves F1-scores of 0.83\u00b10.02, Rank-1 accuracies of 97.0%-99.1%, and an EER of 0.5%, outperforming prior methods with fewer parameters.", "conclusion": "G-MSGINet is scalable and effective for real-world contactless fingerprint recognition, offering superior performance with reduced computational costs."}}
{"id": "2504.20412", "pdf": "https://arxiv.org/pdf/2504.20412", "abs": "https://arxiv.org/abs/2504.20412", "authors": ["Alex Mathai", "Chenxi Huang", "Suwei Ma", "Jihwan Kim", "Hailie Mitchell", "Aleksandr Nogikh", "Petros Maniatis", "Franjo Ivan\u010di\u0107", "Junfeng Yang", "Baishakhi Ray"], "title": "CrashFixer: A crash resolution agent for the Linux kernel", "categories": ["cs.SE", "cs.AI", "cs.OS"], "comment": null, "summary": "Code large language models (LLMs) have shown impressive capabilities on a\nmultitude of software engineering tasks. In particular, they have demonstrated\nremarkable utility in the task of code repair. However, common benchmarks used\nto evaluate the performance of code LLMs are often limited to small-scale\nsettings. In this work, we build upon kGym, which shares a benchmark for\nsystem-level Linux kernel bugs and a platform to run experiments on the Linux\nkernel.\n  This paper introduces CrashFixer, the first LLM-based software repair agent\nthat is applicable to Linux kernel bugs. Inspired by the typical workflow of a\nkernel developer, we identify the key capabilities an expert developer\nleverages to resolve a kernel crash. Using this as our guide, we revisit the\nkGym platform and identify key system improvements needed to practically run\nLLM-based agents at the scale of the Linux kernel (50K files and 20M lines of\ncode). We implement these changes by extending kGym to create an improved\nplatform - called kGymSuite, which will be open-sourced. Finally, the paper\npresents an evaluation of various repair strategies for such complex kernel\nbugs and showcases the value of explicitly generating a hypothesis before\nattempting to fix bugs in complex systems such as the Linux kernel. We also\nevaluated CrashFixer's capabilities on still open bugs, and found at least two\npatch suggestions considered plausible to resolve the reported bug.", "AI": {"tldr": "CrashFixer is the first LLM-based software repair agent for Linux kernel bugs, built on kGymSuite, an improved platform for large-scale code repair. It mimics expert developer workflows and shows promising results, including plausible patches for open bugs.", "motivation": "Existing benchmarks for code LLMs are limited to small-scale settings, leaving a gap for evaluating their performance on complex systems like the Linux kernel.", "method": "The paper extends kGym to create kGymSuite, enabling LLM-based repair agents to operate at the Linux kernel scale. CrashFixer mimics expert developer workflows, including hypothesis generation before bug fixing.", "result": "CrashFixer demonstrated practical utility, generating plausible patches for open Linux kernel bugs.", "conclusion": "LLM-based agents like CrashFixer can effectively address complex system bugs, with hypothesis generation proving valuable in the repair process."}}
{"id": "2409.17632", "pdf": "https://arxiv.org/pdf/2409.17632", "abs": "https://arxiv.org/abs/2409.17632", "authors": ["Eike Cramer"], "title": "Least Squares and Marginal Log-Likelihood Model Predictive Control using Normalizing Flows", "categories": ["cs.LG"], "comment": "16 pages, 7 Figures, 10 Tables", "summary": "Real-world (bio)chemical processes often exhibit stochastic dynamics with\nnon-trivial correlations and state-dependent fluctuations. Model predictive\ncontrol (MPC) often must consider these fluctuations to achieve reliable\nperformance. However, most process models simply add stationary noise terms to\na deterministic prediction. This work proposes using conditional normalizing\nflows as discrete-time models to learn stochastic dynamics. Normalizing flows\nlearn the probability density function (PDF) of the states explicitly, given\nprior states and control inputs. In addition to standard least squares (LSQ)\nobjectives, this work derives a marginal log-likelihood (MLL) objective based\non the explicit PDF and Markov chain simulations. In a reactor study, the\nnormalizing flow MPC reduces the setpoint error in open and closed-loop cases\nto half that of a nominal controller. Furthermore, the chance constraints lead\nto fewer constraint violations than the nominal controller. The MLL objective\nyields slightly more stable results than the LSQ, particularly for small\nscenario sets.", "AI": {"tldr": "The paper proposes using conditional normalizing flows for stochastic dynamics modeling in MPC, reducing setpoint error and constraint violations compared to nominal controllers.", "motivation": "Real-world biochemical processes exhibit stochastic dynamics with correlations and state-dependent fluctuations, which traditional MPC models often oversimplify.", "method": "Conditional normalizing flows are used to learn stochastic dynamics, with objectives including least squares and marginal log-likelihood based on explicit PDFs and Markov chain simulations.", "result": "In a reactor study, the proposed method halves setpoint error and reduces constraint violations compared to nominal controllers, with MLL offering more stability for small scenario sets.", "conclusion": "Conditional normalizing flows improve MPC performance by better capturing stochastic dynamics, with MLL objectives enhancing stability in limited scenarios."}}
{"id": "2505.08527", "pdf": "https://arxiv.org/pdf/2505.08527", "abs": "https://arxiv.org/abs/2505.08527", "authors": ["Zheang Huai", "Hui Tang", "Yi Li", "Zhuangzhuang Chen", "Xiaomeng Li"], "title": "Leveraging Segment Anything Model for Source-Free Domain Adaptation via Dual Feature Guided Auto-Prompting", "categories": ["cs.CV"], "comment": null, "summary": "Source-free domain adaptation (SFDA) for segmentation aims at adapting a\nmodel trained in the source domain to perform well in the target domain with\nonly the source model and unlabeled target data.Inspired by the recent success\nof Segment Anything Model (SAM) which exhibits the generality of segmenting\nimages of various modalities and in different domains given human-annotated\nprompts like bounding boxes or points, we for the first time explore the\npotentials of Segment Anything Model for SFDA via automatedly finding an\naccurate bounding box prompt. We find that the bounding boxes directly\ngenerated with existing SFDA approaches are defective due to the domain gap.To\ntackle this issue, we propose a novel Dual Feature Guided (DFG) auto-prompting\napproach to search for the box prompt. Specifically, the source model is first\ntrained in a feature aggregation phase, which not only preliminarily adapts the\nsource model to the target domain but also builds a feature distribution\nwell-prepared for box prompt search. In the second phase, based on two feature\ndistribution observations, we gradually expand the box prompt with the guidance\nof the target model feature and the SAM feature to handle the class-wise\nclustered target features and the class-wise dispersed target features,\nrespectively. To remove the potentially enlarged false positive regions caused\nby the over-confident prediction of the target model, the refined pseudo-labels\nproduced by SAM are further postprocessed based on connectivity analysis.\nExperiments on 3D and 2D datasets indicate that our approach yields superior\nperformance compared to conventional methods. Code is available at\nhttps://github.com/xmed-lab/DFG.", "AI": {"tldr": "The paper introduces a Dual Feature Guided (DFG) auto-prompting approach for source-free domain adaptation (SFDA) in segmentation, leveraging the Segment Anything Model (SAM) to generate accurate bounding box prompts and outperforming conventional methods.", "motivation": "The motivation is to adapt a segmentation model trained in a source domain to a target domain without labeled target data, addressing the challenge of defective bounding boxes generated by existing SFDA methods due to domain gaps.", "method": "The method involves a two-phase approach: (1) training the source model in a feature aggregation phase to adapt it to the target domain and prepare for box prompt search, and (2) using DFG to expand the box prompt guided by target model and SAM features, followed by pseudo-label refinement based on connectivity analysis.", "result": "Experiments on 3D and 2D datasets show superior performance compared to conventional SFDA methods.", "conclusion": "The DFG auto-prompting approach effectively addresses the domain gap issue in SFDA for segmentation, leveraging SAM to improve accuracy and outperforming existing methods."}}
{"id": "2505.00887", "pdf": "https://arxiv.org/pdf/2505.00887", "abs": "https://arxiv.org/abs/2505.00887", "authors": ["Xi Chen", "Yateng Tang", "Jiarong Xu", "Jiawei Zhang", "Siwei Zhang", "Sijia Peng", "Xuehao Zheng", "Yun Xiong"], "title": "Rethinking Time Encoding via Learnable Transformation Functions", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 19 figures, 10 tables", "summary": "Effectively modeling time information and incorporating it into applications\nor models involving chronologically occurring events is crucial. Real-world\nscenarios often involve diverse and complex time patterns, which pose\nsignificant challenges for time encoding methods. While previous methods focus\non capturing time patterns, many rely on specific inductive biases, such as\nusing trigonometric functions to model periodicity. This narrow focus on\nsingle-pattern modeling makes them less effective in handling the diversity and\ncomplexities of real-world time patterns. In this paper, we investigate to\nimprove the existing commonly used time encoding methods and introduce\nLearnable Transformation-based Generalized Time Encoding (LeTE). We propose\nusing deep function learning techniques to parameterize non-linear\ntransformations in time encoding, making them learnable and capable of modeling\ngeneralized time patterns, including diverse and complex temporal dynamics. By\nenabling learnable transformations, LeTE encompasses previous methods as\nspecific cases and allows seamless integration into a wide range of tasks.\nThrough extensive experiments across diverse domains, we demonstrate the\nversatility and effectiveness of LeTE.", "AI": {"tldr": "The paper introduces LeTE, a learnable time encoding method using deep function learning to handle diverse and complex time patterns, outperforming previous methods.", "motivation": "Existing time encoding methods are limited by narrow inductive biases, making them ineffective for real-world diverse and complex time patterns.", "method": "Proposes Learnable Transformation-based Generalized Time Encoding (LeTE) using deep function learning to parameterize non-linear transformations.", "result": "LeTE outperforms previous methods, demonstrating versatility and effectiveness across diverse domains.", "conclusion": "LeTE generalizes previous methods and is adaptable for various tasks, addressing the limitations of existing time encoding approaches."}}
{"id": "2410.02247", "pdf": "https://arxiv.org/pdf/2410.02247", "abs": "https://arxiv.org/abs/2410.02247", "authors": ["Xinhao Yao", "Hongjin Qian", "Xiaolin Hu", "Gengze Xu", "Wei Liu", "Jian Luan", "Bin Wang", "Yong Liu"], "title": "Theoretical Insights into Fine-Tuning Attention Mechanism: Generalization and Optimization", "categories": ["cs.LG"], "comment": "IJCAI 2025", "summary": "Large Language Models (LLMs), built on Transformer architectures, exhibit\nremarkable generalization across a wide range of tasks. However, fine-tuning\nthese models for specific tasks remains resource-intensive due to their\nextensive parameterization. In this paper, we explore two remarkable phenomena\nrelated to the attention mechanism during the fine-tuning of LLMs (where\n$\\mathbf{W}_q$, $\\mathbf{W}_k$, and $\\mathbf{W}_v$ denote the weights of the\nquery, key, and value layers, respectively). The first phenomenon, termed\n\"Unequal Importance of Attention Matrices\", highlights the impact of\nfine-tuning different weight matrices. It shows that optimizing the\n$\\mathbf{W}_v$ matrix yields significantly better performance than optimizing\nthe $\\mathbf{W}_k$ matrix. Fine-tuning only the $\\mathbf{W}_q$ and\n$\\mathbf{W}_v$ matrices is computationally efficient while delivering results\ncomparable to, or even better than fine-tuning all three matrices\n($\\mathbf{W}_q$, $\\mathbf{W}_k$, and $\\mathbf{W}_v$). The second\nphenomenon,\"Attention Matrices with Customized Learning Rate Lead to Better\nConvergence\", emphasizes the importance of assigning distinct learning rates to\nthese matrices. Specifically, a higher learning rate for the $\\mathbf{W}_v$\nmatrix compared to $\\mathbf{W}_q$ and $\\mathbf{W}_k$ accelerates convergence\nand improves performance. Building on these insights, we propose a new strategy\nthat improves fine-tuning efficiency in terms of both storage and time.\nExperimental results on benchmark datasets validate the effectiveness of this\napproach, supporting our theoretical findings. Our analysis lays the\ntheoretical groundwork for configuring and improving algorithms in LLMs\nfine-tuning.", "AI": {"tldr": "The paper explores efficient fine-tuning of LLMs by focusing on optimizing specific attention matrices (W_v, W_q) and using customized learning rates, achieving comparable or better performance with reduced computational costs.", "motivation": "Fine-tuning LLMs is resource-intensive due to their large parameter size. The study aims to identify efficient fine-tuning strategies by analyzing the impact of optimizing specific attention matrices and learning rates.", "method": "The study investigates two phenomena: (1) Unequal importance of attention matrices (W_v, W_q, W_k) and (2) Customized learning rates for these matrices. A new fine-tuning strategy is proposed based on these insights.", "result": "Optimizing W_v and W_q is more effective than W_k, and using higher learning rates for W_v improves convergence and performance. The proposed strategy reduces storage and time costs while maintaining performance.", "conclusion": "The findings provide a theoretical foundation for efficient LLM fine-tuning, demonstrating that selective optimization and tailored learning rates enhance performance and reduce resource usage."}}
{"id": "2505.08537", "pdf": "https://arxiv.org/pdf/2505.08537", "abs": "https://arxiv.org/abs/2505.08537", "authors": ["Mohamed Lamine Mekhalfi", "Paul Chippendale", "Fabio Poiesi", "Samuele Bonecher", "Gilberto Osler", "Nicola Zancanella"], "title": "The RaspGrade Dataset: Towards Automatic Raspberry Ripeness Grading with Deep Learning", "categories": ["cs.CV"], "comment": null, "summary": "This research investigates the application of computer vision for rapid,\naccurate, and non-invasive food quality assessment, focusing on the novel\nchallenge of real-time raspberry grading into five distinct classes within an\nindustrial environment as the fruits move along a conveyor belt. To address\nthis, a dedicated dataset of raspberries, namely RaspGrade, was acquired and\nmeticulously annotated. Instance segmentation experiments revealed that\naccurate fruit-level masks can be obtained; however, the classification of\ncertain raspberry grades presents challenges due to color similarities and\nocclusion, while others are more readily distinguishable based on color. The\nacquired and annotated RaspGrade dataset is accessible on Hugging Face at:\nhttps://huggingface.co/datasets/FBK-TeV/RaspGrade.", "AI": {"tldr": "The paper explores using computer vision for real-time raspberry grading, introducing the RaspGrade dataset, and highlights challenges in classification due to color similarities and occlusion.", "motivation": "To enable rapid, accurate, and non-invasive food quality assessment in industrial settings, specifically for raspberry grading.", "method": "Utilized instance segmentation on the RaspGrade dataset to classify raspberries into five grades, addressing challenges like color similarities and occlusion.", "result": "Accurate fruit-level masks were achieved, but classification of some grades was difficult due to color similarities and occlusion.", "conclusion": "The RaspGrade dataset is publicly available, and while some grading challenges persist, the method shows promise for industrial food quality assessment."}}
{"id": "2505.01618", "pdf": "https://arxiv.org/pdf/2505.01618", "abs": "https://arxiv.org/abs/2505.01618", "authors": ["Nolan Dey", "Bin Claire Zhang", "Lorenzo Noci", "Mufan Li", "Blake Bordelon", "Shane Bergsma", "Cengiz Pehlevan", "Boris Hanin", "Joel Hestness"], "title": "Don't be lazy: CompleteP enables compute-efficient deep transformers", "categories": ["cs.LG", "cs.AI"], "comment": "10 main pages, 16 appendix pages, 13 figures", "summary": "We study compute efficiency of LLM training when using different\nparameterizations, i.e., rules for adjusting model and optimizer\nhyperparameters (HPs) as model size changes. Some parameterizations fail to\ntransfer optimal base HPs (such as learning rate) across changes in model\ndepth, requiring practitioners to either re-tune these HPs as they scale up\n(expensive), or accept sub-optimal training when re-tuning is prohibitive. Even\nwhen they achieve HP transfer, we develop theory to show parameterizations may\nstill exist in the lazy learning regime where layers learn only features close\nto their linearization, preventing effective use of depth and nonlinearity.\nFinally, we identify and adopt the parameterization we call CompleteP that\nachieves both depth-wise HP transfer and non-lazy learning in all layers.\nCompleteP enables a wider range of model width/depth ratios to remain\ncompute-efficient, unlocking shapes better suited for different hardware\nsettings and operational contexts. Moreover, CompleteP enables 12-34% compute\nefficiency improvements over the prior state-of-the-art.", "AI": {"tldr": "The paper introduces CompleteP, a parameterization method for LLM training that ensures hyperparameter transfer across model sizes and avoids lazy learning, improving compute efficiency by 12-34%.", "motivation": "Current parameterizations often fail to transfer optimal hyperparameters across model sizes, leading to expensive re-tuning or sub-optimal training. Some also restrict learning to linearized features, limiting depth and nonlinearity.", "method": "The study analyzes different parameterizations, develops theory on lazy learning, and identifies CompleteP, which ensures hyperparameter transfer and non-lazy learning.", "result": "CompleteP allows flexible model shapes for hardware and operational needs, achieving 12-34% better compute efficiency than prior methods.", "conclusion": "CompleteP is a superior parameterization for LLM training, enabling efficient scaling and better use of model depth and nonlinearity."}}
{"id": "2410.08007", "pdf": "https://arxiv.org/pdf/2410.08007", "abs": "https://arxiv.org/abs/2410.08007", "authors": ["Giovanni De Toni", "Stefano Teso", "Bruno Lepri", "Andrea Passerini"], "title": "Time Can Invalidate Algorithmic Recourse", "categories": ["cs.LG", "cs.CY"], "comment": "This is a preprint of a paper accepted at FAccT 2025. The content is\n  identical to the published version, apart from minor cosmetic changes", "summary": "Algorithmic Recourse (AR) aims to provide users with actionable steps to\noverturn unfavourable decisions made by machine learning predictors. However,\nthese actions often take time to implement (e.g., getting a degree can take\nyears), and their effects may vary as the world evolves. Thus, it is natural to\nask for recourse that remains valid in a dynamic environment. In this paper, we\nstudy the robustness of algorithmic recourse over time by casting the problem\nthrough the lens of causality. We demonstrate theoretically and empirically\nthat (even robust) causal AR methods can fail over time, except in the --\nunlikely -- case that the world is stationary. Even more critically, unless the\nworld is fully deterministic, counterfactual AR cannot be solved optimally. To\naccount for this, we propose a simple yet effective algorithm for temporal AR\nthat explicitly accounts for time under the assumption of having access to an\nestimator approximating the stochastic process. Our simulations on synthetic\nand realistic datasets show how considering time produces more resilient\nsolutions to potential trends in the data distribution.", "AI": {"tldr": "The paper explores the robustness of algorithmic recourse (AR) over time, highlighting its limitations in dynamic environments and proposing a temporal AR solution.", "motivation": "AR provides actionable steps to reverse unfavorable ML decisions, but its validity diminishes over time due to environmental changes. The study aims to address this temporal fragility.", "method": "The problem is framed causally, analyzing AR robustness theoretically and empirically. A temporal AR algorithm is proposed, assuming access to a stochastic process estimator.", "result": "Causal AR methods fail over time unless the world is stationary. Counterfactual AR cannot be optimally solved unless the world is deterministic. The proposed temporal AR shows resilience in simulations.", "conclusion": "Temporal AR, accounting for time and stochastic processes, offers more robust solutions in dynamic environments compared to traditional AR methods."}}
{"id": "2505.08568", "pdf": "https://arxiv.org/pdf/2505.08568", "abs": "https://arxiv.org/abs/2505.08568", "authors": ["Xiao Ni", "Carsten Kuehnel", "Xiaoyi Jiang"], "title": "Thermal Detection of People with Mobility Restrictions for Barrier Reduction at Traffic Lights Controlled Intersections", "categories": ["cs.CV"], "comment": null, "summary": "Rapid advances in deep learning for computer vision have driven the adoption\nof RGB camera-based adaptive traffic light systems to improve traffic safety\nand pedestrian comfort. However, these systems often overlook the needs of\npeople with mobility restrictions. Moreover, the use of RGB cameras presents\nsignificant challenges, including limited detection performance under adverse\nweather or low-visibility conditions, as well as heightened privacy concerns.\nTo address these issues, we propose a fully automated, thermal detector-based\ntraffic light system that dynamically adjusts signal durations for individuals\nwith walking impairments or mobility burden and triggers the auditory signal\nfor visually impaired individuals, thereby advancing towards barrier-free\nintersection for all users. To this end, we build the thermal dataset for\npeople with mobility restrictions (TD4PWMR), designed to capture diverse\npedestrian scenarios, particularly focusing on individuals with mobility aids\nor mobility burden under varying environmental conditions, such as different\nlighting, weather, and crowded urban settings. While thermal imaging offers\nadvantages in terms of privacy and robustness to adverse conditions, it also\nintroduces inherent hurdles for object detection due to its lack of color and\nfine texture details and generally lower resolution of thermal images. To\novercome these limitations, we develop YOLO-Thermal, a novel variant of the\nYOLO architecture that integrates advanced feature extraction and attention\nmechanisms for enhanced detection accuracy and robustness in thermal imaging.\nExperiments demonstrate that the proposed thermal detector outperforms existing\ndetectors, while the proposed traffic light system effectively enhances\nbarrier-free intersection. The source codes and dataset are available at\nhttps://github.com/leon2014dresden/YOLO-THERMAL.", "AI": {"tldr": "A thermal detector-based traffic light system (YOLO-Thermal) is proposed to address limitations of RGB camera systems, focusing on mobility-impaired individuals, with improved robustness and privacy.", "motivation": "Current RGB camera-based traffic light systems neglect mobility-impaired individuals and face challenges like poor visibility in adverse conditions and privacy concerns.", "method": "Developed YOLO-Thermal, a modified YOLO architecture with advanced feature extraction and attention mechanisms, using the TD4PWMR thermal dataset.", "result": "YOLO-Thermal outperforms existing detectors, and the system enhances barrier-free intersection accessibility.", "conclusion": "The thermal-based system offers a robust, privacy-friendly solution for inclusive traffic management."}}
{"id": "2505.01956", "pdf": "https://arxiv.org/pdf/2505.01956", "abs": "https://arxiv.org/abs/2505.01956", "authors": ["Ganesh Sapkota", "Sanjay Madria"], "title": "SafeNav: Safe Path Navigation using Landmark Based Localization in a GPS-denied Environment", "categories": ["cs.RO", "cs.AI"], "comment": "10 pages, conference paper. arXiv admin note: text overlap with\n  arXiv:2402.14280", "summary": "In battlefield environments, adversaries frequently disrupt GPS signals,\nrequiring alternative localization and navigation methods. Traditional\nvision-based approaches like Simultaneous Localization and Mapping (SLAM) and\nVisual Odometry (VO) involve complex sensor fusion and high computational\ndemand, whereas range-free methods like DV-HOP face accuracy and stability\nchallenges in sparse, dynamic networks. This paper proposes LanBLoc-BMM, a\nnavigation approach using landmark-based localization (LanBLoc) combined with a\nbattlefield-specific motion model (BMM) and Extended Kalman Filter (EKF). Its\nperformance is benchmarked against three state-of-the-art visual localization\nalgorithms integrated with BMM and Bayesian filters, evaluated on synthetic and\nreal-imitated trajectory datasets using metrics including Average Displacement\nError (ADE), Final Displacement Error (FDE), and a newly introduced Average\nWeighted Risk Score (AWRS). LanBLoc-BMM (with EKF) demonstrates superior\nperformance in ADE, FDE, and AWRS on real-imitated datasets. Additionally, two\nsafe navigation methods, SafeNav-CHull and SafeNav-Centroid, are introduced by\nintegrating LanBLoc-BMM(EKF) with a novel Risk-Aware RRT* (RAw-RRT*) algorithm\nfor obstacle avoidance and risk exposure minimization. Simulation results in\nbattlefield scenarios indicate SafeNav-Centroid excels in accuracy, risk\nexposure, and trajectory efficiency, while SafeNav-CHull provides superior\ncomputational speed.", "AI": {"tldr": "LanBLoc-BMM combines landmark-based localization with a battlefield motion model and EKF, outperforming visual methods in accuracy and risk metrics. SafeNav methods enhance navigation with obstacle avoidance.", "motivation": "GPS disruption in battlefields necessitates reliable, low-complexity localization alternatives to traditional vision-based or range-free methods.", "method": "Proposes LanBLoc-BMM (landmark-based localization + battlefield motion model + EKF) and benchmarks it against visual methods. Introduces SafeNav-CHull and SafeNav-Centroid for safe navigation.", "result": "LanBLoc-BMM (EKF) excels in accuracy (ADE, FDE) and risk (AWRS). SafeNav-Centroid is accurate and efficient; SafeNav-CHull is faster.", "conclusion": "LanBLoc-BMM and SafeNav methods offer robust, efficient solutions for battlefield navigation, balancing accuracy, risk, and computational speed."}}
{"id": "2410.17075", "pdf": "https://arxiv.org/pdf/2410.17075", "abs": "https://arxiv.org/abs/2410.17075", "authors": ["Xutong Liu", "Xiangxiang Dai", "Xuchuang Wang", "Mohammad Hajiesmaili", "John C. S. Lui"], "title": "Combinatorial Logistic Bandits", "categories": ["cs.LG"], "comment": "Accepted in ACM SIGMETRICS 2025", "summary": "We introduce a novel framework called combinatorial logistic bandits (CLogB),\nwhere in each round, a subset of base arms (called the super arm) is selected,\nwith the outcome of each base arm being binary and its expectation following a\nlogistic parametric model. The feedback is governed by a general arm triggering\nprocess. Our study covers CLogB with reward functions satisfying two smoothness\nconditions, capturing application scenarios such as online content delivery,\nonline learning to rank, and dynamic channel allocation. We first propose a\nsimple yet efficient algorithm, CLogUCB, utilizing a variance-agnostic\nexploration bonus. Under the 1-norm triggering probability modulated (TPM)\nsmoothness condition, CLogUCB achieves a regret bound of\n$\\tilde{O}(d\\sqrt{\\kappa KT})$, where $\\tilde{O}$ ignores logarithmic factors,\n$d$ is the dimension of the feature vector, $\\kappa$ represents the\nnonlinearity of the logistic model, and $K$ is the maximum number of base arms\na super arm can trigger. This result improves on prior work by a factor of\n$\\tilde{O}(\\sqrt{\\kappa})$. We then enhance CLogUCB with a variance-adaptive\nversion, VA-CLogUCB, which attains a regret bound of $\\tilde{O}(d\\sqrt{KT})$\nunder the same 1-norm TPM condition, improving another\n$\\tilde{O}(\\sqrt{\\kappa})$ factor. VA-CLogUCB shows even greater promise under\nthe stronger triggering probability and variance modulated (TPVM) condition,\nachieving a leading $\\tilde{O}(d\\sqrt{T})$ regret, thus removing the additional\ndependency on the action-size $K$. Furthermore, we enhance the computational\nefficiency of VA-CLogUCB by eliminating the nonconvex optimization process when\nthe context feature map is time-invariant while maintaining the tight\n$\\tilde{O}(d\\sqrt{T})$ regret. Finally, experiments on synthetic and real-world\ndatasets demonstrate the superior performance of our algorithms compared to\nbenchmark algorithms.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.08614", "pdf": "https://arxiv.org/pdf/2505.08614", "abs": "https://arxiv.org/abs/2505.08614", "authors": ["Ziyuan He", "Zhiqing Guo", "Liejun Wang", "Gaobo Yang", "Yunfeng Diao", "Dan Ma"], "title": "WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks", "categories": ["cs.CV"], "comment": "11 pages, 5 figures, 4 tables", "summary": "Deepfake technology poses increasing risks such as privacy invasion and\nidentity theft. To address these threats, we propose WaveGuard, a proactive\nwatermarking framework that enhances robustness and imperceptibility via\nfrequency-domain embedding and graph-based structural consistency.\nSpecifically, we embed watermarks into high-frequency sub-bands using Dual-Tree\nComplex Wavelet Transform (DT-CWT) and employ a Structural Consistency Graph\nNeural Network (SC-GNN) to preserve visual quality. We also design an attention\nmodule to refine embedding precision. Experimental results on face swap and\nreenactment tasks demonstrate that WaveGuard outperforms state-of-the-art\nmethods in both robustness and visual quality. Code is available at\nhttps://github.com/vpsg-research/WaveGuard.", "AI": {"tldr": "WaveGuard is a watermarking framework using DT-CWT and SC-GNN to combat deepfake threats with robust, imperceptible watermarks.", "motivation": "Addressing risks like privacy invasion and identity theft from deepfake technology.", "method": "Embeds watermarks in high-frequency sub-bands via DT-CWT and uses SC-GNN for visual quality. Includes an attention module for precision.", "result": "Outperforms state-of-the-art methods in robustness and visual quality on face swap and reenactment tasks.", "conclusion": "WaveGuard effectively mitigates deepfake risks with superior performance."}}
{"id": "2505.04260", "pdf": "https://arxiv.org/pdf/2505.04260", "abs": "https://arxiv.org/abs/2505.04260", "authors": ["Jessica Y. Bo", "Tianyu Xu", "Ishan Chatterjee", "Katrina Passarella-Ward", "Achin Kulshrestha", "D Shin"], "title": "Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) improve in their capacity to serve as\npersonal AI assistants, their ability to output uniquely tailored, personalized\nresponses that align with the soft preferences of their users is essential for\nenhancing user satisfaction and retention. However, untrained lay users have\npoor prompt specification abilities and often struggle with conveying their\nlatent preferences to AI assistants. To address this, we leverage activation\nsteering to guide LLMs to align with interpretable preference dimensions during\ninference. In contrast to memory-based personalization methods that require\nlonger user history, steering is extremely lightweight and can be easily\ncontrolled by the user via an linear strength factor. We embed steering into\nthree different interactive chatbot interfaces and conduct a within-subjects\nuser study (n=14) to investigate how end users prefer to personalize their\nconversations. The results demonstrate the effectiveness of preference-based\nsteering for aligning real-world conversations with hidden user preferences,\nand highlight further insights on how diverse values around control, usability,\nand transparency lead users to prefer different interfaces.", "AI": {"tldr": "The paper proposes activation steering to align LLM responses with user preferences, offering lightweight control via a linear strength factor. User studies show its effectiveness and interface preferences.", "motivation": "Untrained users struggle to convey latent preferences to AI assistants, necessitating a method to align LLM outputs with soft user preferences for better satisfaction.", "method": "Leverages activation steering to guide LLMs during inference, embedding it into three chatbot interfaces for a user study (n=14).", "result": "Preference-based steering effectively aligns conversations with hidden user preferences, with interface preferences varying based on control, usability, and transparency values.", "conclusion": "Activation steering is a lightweight, effective method for personalizing LLM responses, with user interface preferences highlighting diverse values."}}
{"id": "2412.09009", "pdf": "https://arxiv.org/pdf/2412.09009", "abs": "https://arxiv.org/abs/2412.09009", "authors": ["Sumanth Kumar Boya", "Deepak Subramani"], "title": "A physics-informed transformer neural operator for learning generalized solutions of initial boundary value problems", "categories": ["cs.LG", "physics.comp-ph", "35C05"], "comment": "30 pages, 14 figures, 9 tables", "summary": "Initial boundary value problems arise commonly in applications with\nengineering and natural systems governed by nonlinear partial differential\nequations (PDEs). Operator learning is an emerging field for solving these\nequations by using a neural network to learn a map between infinite dimensional\ninput and output function spaces. These neural operators are trained using a\ncombination of data (observations or simulations) and PDE-residuals\n(physics-loss). A major drawback of existing neural approaches is the\nrequirement to retrain with new initial/boundary conditions, and the necessity\nfor a large amount of simulation data for training. We develop a\nphysics-informed transformer neural operator (named PINTO) that efficiently\ngeneralizes to unseen initial and boundary conditions, trained in a\nsimulation-free setting using only physics loss. The main innovation lies in\nour new iterative kernel integral operator units, implemented using\ncross-attention, to transform the PDE solution's domain points into an\ninitial/boundary condition-aware representation vector, enabling efficient\nlearning of the solution function for new scenarios. The PINTO architecture is\napplied to simulate the solutions of important equations used in engineering\napplications: advection, Burgers, and steady and unsteady Navier-Stokes\nequations (three flow scenarios). For these five test cases, we show that the\nrelative errors during testing under challenging conditions of unseen\ninitial/boundary conditions are only one-fifth to one-third of other leading\nphysics informed operator learning methods. Moreover, our PINTO model is able\nto accurately solve the advection and Burgers equations at time steps that are\nnot included in the training collocation points. The code is available at\nhttps://github.com/quest-lab-iisc/PINTO", "AI": {"tldr": "PINTO, a physics-informed transformer neural operator, generalizes to unseen initial/boundary conditions without retraining, using only physics loss, outperforming existing methods in accuracy.", "motivation": "Existing neural approaches require retraining for new conditions and large simulation data. PINTO addresses these limitations by enabling efficient generalization and simulation-free training.", "method": "Uses iterative kernel integral operator units with cross-attention to transform PDE solution domain points into condition-aware vectors, learning solutions for new scenarios.", "result": "Achieves relative errors one-fifth to one-third of other methods for unseen conditions and solves equations accurately at untrained time steps.", "conclusion": "PINTO offers a robust, efficient solution for nonlinear PDEs, advancing physics-informed operator learning."}}
{"id": "2505.08765", "pdf": "https://arxiv.org/pdf/2505.08765", "abs": "https://arxiv.org/abs/2505.08765", "authors": ["Yatai Ji", "Zhengqiu Zhu", "Yong Zhao", "Beidan Liu", "Chen Gao", "Yihao Zhao", "Sihang Qiu", "Yue Hu", "Quanjun Yin", "Yong Li"], "title": "Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Aerial Visual Object Search (AVOS) tasks in urban environments require\nUnmanned Aerial Vehicles (UAVs) to autonomously search for and identify target\nobjects using visual and textual cues without external guidance. Existing\napproaches struggle in complex urban environments due to redundant semantic\nprocessing, similar object distinction, and the exploration-exploitation\ndilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS,\nthe first benchmark dataset for autonomous search of common urban objects. This\ndataset comprises 2,420 tasks across six object categories with varying\ndifficulty levels, enabling comprehensive evaluation of UAV agents' search\ncapabilities. To solve the AVOS tasks, we also propose PRPSearcher\n(Perception-Reasoning-Planning Searcher), a novel agentic method powered by\nmulti-modal large language models (MLLMs) that mimics human three-tier\ncognition. Specifically, PRPSearcher constructs three specialized maps: an\nobject-centric dynamic semantic map enhancing spatial perception, a 3D\ncognitive map based on semantic attraction values for target reasoning, and a\n3D uncertainty map for balanced exploration-exploitation search. Also, our\napproach incorporates a denoising mechanism to mitigate interference from\nsimilar objects and utilizes an Inspiration Promote Thought (IPT) prompting\nmechanism for adaptive action planning. Experimental results on CityAVOS\ndemonstrate that PRPSearcher surpasses existing baselines in both success rate\nand search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and\n-46.40% NE). While promising, the performance gap compared to humans highlights\nthe need for better semantic reasoning and spatial exploration capabilities in\nAVOS tasks. This work establishes a foundation for future advances in embodied\ntarget search. Dataset and source code are available at\nhttps://anonymous.4open.science/r/CityAVOS-3DF8.", "AI": {"tldr": "CityAVOS is a benchmark dataset for UAV-based object search in urban environments, paired with PRPSearcher, a novel agentic method using MLLMs for improved perception, reasoning, and planning.", "motivation": "Existing UAV object search methods struggle in complex urban settings due to redundant processing, similar object confusion, and exploration-exploitation trade-offs.", "method": "PRPSearcher uses multi-modal LLMs to create three specialized maps (dynamic semantic, 3D cognitive, and 3D uncertainty) and employs denoising and IPT prompting for adaptive planning.", "result": "PRPSearcher outperforms baselines (+37.69% success rate, +28.96% efficiency) but still lags behind human performance.", "conclusion": "The work lays groundwork for future embodied search advancements, highlighting the need for better semantic reasoning and exploration."}}
{"id": "2505.06795", "pdf": "https://arxiv.org/pdf/2505.06795", "abs": "https://arxiv.org/abs/2505.06795", "authors": ["Abhijit Gupta"], "title": "Decoding Futures Price Dynamics: A Regularized Sparse Autoencoder for Interpretable Multi-Horizon Forecasting and Factor Discovery", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Commodity price volatility creates economic challenges, necessitating\naccurate multi-horizon forecasting. Predicting prices for commodities like\ncopper and crude oil is complicated by diverse interacting factors\n(macroeconomic, supply/demand, geopolitical, etc.). Current models often lack\ntransparency, limiting strategic use. This paper presents a Regularized Sparse\nAutoencoder (RSAE), a deep learning framework for simultaneous multi-horizon\ncommodity price prediction and discovery of interpretable latent market\ndrivers. The RSAE forecasts prices at multiple horizons (e.g., 1-day, 1-week,\n1-month) using multivariate time series. Crucially, L1 regularization\n($\\|\\mathbf{z}\\|_1$) on its latent vector $\\mathbf{z}$ enforces sparsity,\npromoting parsimonious explanations of market dynamics through learned factors\nrepresenting underlying drivers (e.g., demand, supply shocks). Drawing from\nenergy-based models and sparse coding, the RSAE optimizes predictive accuracy\nwhile learning sparse representations. Evaluated on historical Copper and Crude\nOil data with numerous indicators, our findings indicate the RSAE offers\ncompetitive multi-horizon forecasting accuracy and data-driven insights into\nprice dynamics via its interpretable latent space, a key advantage over\ntraditional black-box approaches.", "AI": {"tldr": "The paper introduces a Regularized Sparse Autoencoder (RSAE) for multi-horizon commodity price forecasting, emphasizing interpretability of market drivers.", "motivation": "Commodity price volatility and the lack of transparency in current models necessitate accurate and interpretable forecasting methods.", "method": "The RSAE uses L1 regularization to enforce sparsity in latent vectors, enabling interpretable market driver discovery alongside multi-horizon price prediction.", "result": "The RSAE achieves competitive forecasting accuracy for copper and crude oil prices while providing insights into underlying market dynamics.", "conclusion": "The RSAE outperforms traditional black-box models by combining predictive accuracy with interpretability of latent market drivers."}}
{"id": "2412.21061", "pdf": "https://arxiv.org/pdf/2412.21061", "abs": "https://arxiv.org/abs/2412.21061", "authors": ["Yihan Wang", "Yiwei Lu", "Xiao-Shan Gao", "Gautam Kamath", "Yaoliang Yu"], "title": "BridgePure: Limited Protection Leakage Can Break Black-Box Data Protection", "categories": ["cs.LG"], "comment": "29 pages,18 figures", "summary": "Availability attacks, or unlearnable examples, are defensive techniques that\nallow data owners to modify their datasets in ways that prevent unauthorized\nmachine learning models from learning effectively while maintaining the data's\nintended functionality. It has led to the release of popular black-box tools\n(e.g., APIs) for users to upload personal data and receive protected\ncounterparts. In this work, we show that such black-box protections can be\nsubstantially compromised if a small set of unprotected in-distribution data is\navailable. Specifically, we propose a novel threat model of protection leakage,\nwhere an adversary can (1) easily acquire (unprotected, protected) pairs by\nquerying the black-box protections with a small unprotected dataset; and (2)\ntrain a diffusion bridge model to build a mapping between unprotected and\nprotected data. This mapping, termed BridgePure, can effectively remove the\nprotection from any previously unseen data within the same distribution.\nBridgePure demonstrates superior purification performance on classification and\nstyle mimicry tasks, exposing critical vulnerabilities in black-box data\nprotection. We suggest that practitioners implement multi-level countermeasures\nto mitigate such risks.", "AI": {"tldr": "The paper reveals vulnerabilities in black-box data protection tools by showing how unprotected data can be used to bypass protections via a diffusion bridge model called BridgePure.", "motivation": "To expose weaknesses in black-box data protection tools that claim to secure datasets against unauthorized machine learning.", "method": "Proposes a threat model where an adversary uses unprotected data to train a diffusion bridge model (BridgePure) to map and remove protections from data.", "result": "BridgePure effectively purifies protected data, demonstrating vulnerabilities in current protection methods.", "conclusion": "Practitioners should implement multi-level countermeasures to address these risks."}}
{"id": "2204.03139", "pdf": "https://arxiv.org/pdf/2204.03139", "abs": "https://arxiv.org/abs/2204.03139", "authors": ["Priya Sundaresan", "Rika Antonova", "Jeannette Bohg"], "title": "DiffCloud: Real-to-Sim from Point Clouds with Differentiable Simulation and Rendering of Deformable Objects", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": null, "summary": "Research in manipulation of deformable objects is typically conducted on a\nlimited range of scenarios, because handling each scenario on hardware takes\nsignificant effort. Realistic simulators with support for various types of\ndeformations and interactions have the potential to speed up experimentation\nwith novel tasks and algorithms. However, for highly deformable objects it is\nchallenging to align the output of a simulator with the behavior of real\nobjects. Manual tuning is not intuitive, hence automated methods are needed. We\nview this alignment problem as a joint perception-inference challenge and\ndemonstrate how to use recent neural network architectures to successfully\nperform simulation parameter inference from real point clouds. We analyze the\nperformance of various architectures, comparing their data and training\nrequirements. Furthermore, we propose to leverage differentiable point cloud\nsampling and differentiable simulation to significantly reduce the time to\nachieve the alignment. We employ an efficient way to propagate gradients from\npoint clouds to simulated meshes and further through to the physical simulation\nparameters, such as mass and stiffness. Experiments with highly deformable\nobjects show that our method can achieve comparable or better alignment with\nreal object behavior, while reducing the time needed to achieve this by more\nthan an order of magnitude. Videos and supplementary material are available at\nhttps://diffcloud.github.io.", "AI": {"tldr": "The paper proposes a neural network-based method to align simulator outputs with real deformable object behavior, reducing alignment time significantly.", "motivation": "Handling deformable objects in hardware is effort-intensive, and simulators need alignment with real behavior, which is challenging without automated methods.", "method": "Uses neural networks for simulation parameter inference from real point clouds, leveraging differentiable point cloud sampling and simulation for efficiency.", "result": "Achieves comparable or better alignment with real behavior, reducing alignment time by over an order of magnitude.", "conclusion": "The method effectively bridges the gap between simulation and reality for deformable objects, enabling faster experimentation."}}
{"id": "2505.07634", "pdf": "https://arxiv.org/pdf/2505.07634", "abs": "https://arxiv.org/abs/2505.07634", "authors": ["Jian Liu", "Xiongtao Shi", "Thai Duy Nguyen", "Haitian Zhang", "Tianxiang Zhang", "Wei Sun", "Yanjie Li", "Athanasios V. Vasilakos", "Giovanni Iacca", "Arshad Ali Khan", "Arvind Kumar", "Jae Won Cho", "Ajmal Mian", "Lihua Xie", "Erik Cambria", "Lin Wang"], "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "51 pages, 17 figures, 9 tables", "summary": "The rapid evolution of artificial intelligence (AI) has shifted from static,\ndata-driven models to dynamic systems capable of perceiving and interacting\nwith real-world environments. Despite advancements in pattern recognition and\nsymbolic reasoning, current AI systems, such as large language models, remain\ndisembodied, unable to physically engage with the world. This limitation has\ndriven the rise of embodied AI, where autonomous agents, such as humanoid\nrobots, must navigate and manipulate unstructured environments with human-like\nadaptability. At the core of this challenge lies the concept of Neural Brain, a\ncentral intelligence system designed to drive embodied agents with human-like\nadaptability. A Neural Brain must seamlessly integrate multimodal sensing and\nperception with cognitive capabilities. Achieving this also requires an\nadaptive memory system and energy-efficient hardware-software co-design,\nenabling real-time action in dynamic environments. This paper introduces a\nunified framework for the Neural Brain of embodied agents, addressing two\nfundamental challenges: (1) defining the core components of Neural Brain and\n(2) bridging the gap between static AI models and the dynamic adaptability\nrequired for real-world deployment. To this end, we propose a biologically\ninspired architecture that integrates multimodal active sensing,\nperception-cognition-action function, neuroplasticity-based memory storage and\nupdating, and neuromorphic hardware/software optimization. Furthermore, we also\nreview the latest research on embodied agents across these four aspects and\nanalyze the gap between current AI systems and human intelligence. By\nsynthesizing insights from neuroscience, we outline a roadmap towards the\ndevelopment of generalizable, autonomous agents capable of human-level\nintelligence in real-world scenarios.", "AI": {"tldr": "The paper proposes a unified framework for Neural Brain in embodied AI, addressing core components and bridging the gap between static AI and dynamic adaptability.", "motivation": "Current AI systems lack physical embodiment and adaptability, driving the need for embodied AI with human-like intelligence.", "method": "A biologically inspired architecture integrates multimodal sensing, cognition-action functions, neuroplastic memory, and neuromorphic hardware/software.", "result": "The framework outlines a roadmap for developing generalizable, autonomous agents with human-level intelligence.", "conclusion": "The paper synthesizes neuroscience insights to advance embodied AI towards real-world adaptability."}}
{"id": "2501.13223", "pdf": "https://arxiv.org/pdf/2501.13223", "abs": "https://arxiv.org/abs/2501.13223", "authors": ["Zahraa Al Sahili", "Ioannis Patras", "Matthew Purver"], "title": "A Comprehensive Social Bias Audit of Contrastive Vision Language Models", "categories": ["cs.LG"], "comment": null, "summary": "In the domain of text-to-image generative models, biases inherent in training\ndatasets often propagate into generated content, posing significant ethical\nchallenges, particularly in socially sensitive contexts. We introduce FairCoT,\na novel framework that enhances fairness in text-to-image models through\nChain-of-Thought (CoT) reasoning within multimodal generative large language\nmodels. FairCoT employs iterative CoT refinement to systematically mitigate\nbiases, and dynamically adjusts textual prompts in real time, ensuring diverse\nand equitable representation in generated images. By integrating iterative\nreasoning processes, FairCoT addresses the limitations of zero-shot CoT in\nsensitive scenarios, balancing creativity with ethical responsibility.\nExperimental evaluations across popular text-to-image systems--including DALL-E\nand various Stable Diffusion variants--demonstrate that FairCoT significantly\nenhances fairness and diversity without sacrificing image quality or semantic\nfidelity. By combining robust reasoning, lightweight deployment, and\nextensibility to multiple models, FairCoT represents a promising step toward\nmore socially responsible and transparent AI-driven content generation.", "AI": {"tldr": "FairCoT is a framework using Chain-of-Thought reasoning to reduce biases in text-to-image models, improving fairness and diversity without compromising quality.", "motivation": "Address ethical challenges from dataset biases in text-to-image models, especially in sensitive contexts.", "method": "Uses iterative CoT refinement to adjust prompts dynamically, ensuring equitable representation.", "result": "Significantly enhances fairness and diversity in models like DALL-E and Stable Diffusion, maintaining image quality.", "conclusion": "FairCoT advances ethical AI content generation by balancing creativity and responsibility."}}
{"id": "2311.00810", "pdf": "https://arxiv.org/pdf/2311.00810", "abs": "https://arxiv.org/abs/2311.00810", "authors": ["Afia Abedin", "Abdul Bais", "Cody Buntain", "Laura Courchesne", "Brian McQuinn", "Matthew E. Taylor", "Muhib Ullah"], "title": "A Call to Arms: AI Should be Critical for Social Media Analysis of Conflict Zones", "categories": ["cs.CY", "cs.CV", "cs.HC"], "comment": null, "summary": "The massive proliferation of social media data represents a transformative\nopportunity for conflict studies and for tracking the proliferation and use of\nweaponry, as conflicts are increasingly documented in these online spaces. At\nthe same time, the scale and types of data available are problematic for\ntraditional open-source intelligence. This paper focuses on identifying\nspecific weapon systems and the insignias of the armed groups using them as\ndocumented in the Ukraine war, as these tasks are critical to operational\nintelligence and tracking weapon proliferation, especially given the scale of\ninternational military aid given to Ukraine. The large scale of social media\nmakes manual assessment difficult, however, so this paper presents early work\nthat uses computer vision models to support this task. We demonstrate that\nthese models can both identify weapons embedded in images shared in social\nmedia and how the resulting collection of military-relevant images and their\npost times interact with the offline, real-world conflict. Not only can we then\ntrack changes in the prevalence of images of tanks, land mines, military\ntrucks, etc., we find correlations among time series data associated with these\nimages and the daily fatalities in this conflict. This work shows substantial\nopportunity for examining similar online documentation of conflict contexts,\nand we also point to future avenues where computer vision can be further\nimproved for these open-source intelligence tasks.", "AI": {"tldr": "The paper uses computer vision to identify weapons and armed group insignias in social media data from the Ukraine war, linking online imagery to real-world conflict dynamics.", "motivation": "Social media data offers a transformative opportunity for conflict studies and weapon tracking, but its scale challenges traditional methods.", "method": "Computer vision models are employed to identify weapons and insignias in social media images, analyzing their correlation with real-world conflict events.", "result": "The models successfully track weapon prevalence and correlate image time series with daily conflict fatalities.", "conclusion": "The work highlights the potential of computer vision for open-source intelligence in conflict contexts and suggests future improvements."}}
{"id": "2501.13786", "pdf": "https://arxiv.org/pdf/2501.13786", "abs": "https://arxiv.org/abs/2501.13786", "authors": ["Rahul Bordoloi", "Cl\u00e9mence R\u00e9da", "Saptarshi Bej", "Olaf Wolkenhauer"], "title": "Handling Missing Data in Downstream Tasks With Distribution-Preserving Guarantees", "categories": ["cs.LG"], "comment": null, "summary": "Missing feature values are a significant hurdle for downstream\nmachine-learning tasks such as classification. However, imputation methods for\nclassification might be time-consuming for high-dimensional data, and offer few\ntheoretical guarantees on the preservation of the data distribution and\nimputation quality, especially for not-missing-at-random mechanisms. First, we\npropose an imputation approach named F3I based on the iterative improvement of\na K-nearest neighbor imputation, where neighbor-specific weights are learned\nthrough the optimization of a novel concave, differentiable objective function\nrelated to the preservation of the data distribution on non-missing values. F3I\ncan then be chained to and jointly trained with any classifier architecture.\nSecond, we provide a theoretical analysis of imputation quality and data\ndistribution preservation by F3I for several types of missing mechanisms.\nFinally, we demonstrate the superior performance of F3I on several imputation\nand classification tasks, with applications to drug repurposing and\nhandwritten-digit recognition data.", "AI": {"tldr": "F3I is a novel imputation method for missing data in classification tasks, offering theoretical guarantees and superior performance.", "motivation": "Missing feature values hinder machine-learning tasks, and existing imputation methods lack efficiency and theoretical guarantees, especially for not-missing-at-random mechanisms.", "method": "F3I improves K-nearest neighbor imputation by learning neighbor-specific weights via a concave, differentiable objective function, preserving data distribution. It can be jointly trained with classifiers.", "result": "Theoretical analysis confirms F3I's imputation quality and data distribution preservation. It outperforms others in imputation and classification tasks, including drug repurposing and digit recognition.", "conclusion": "F3I is an effective, theoretically grounded imputation method for high-dimensional data, enhancing downstream classification performance."}}
{"id": "2405.20525", "pdf": "https://arxiv.org/pdf/2405.20525", "abs": "https://arxiv.org/abs/2405.20525", "authors": ["Kyle Henke", "Elijah Pelofske", "Garrett Kenyon", "Georg Hahn"], "title": "Comparing Quantum Annealing and Spiking Neuromorphic Computing for Sampling Binary Sparse Coding QUBO Problems", "categories": ["cs.ET", "cs.CV", "cs.DM", "cs.NE", "quant-ph"], "comment": null, "summary": "We consider the problem of computing a sparse binary representation of an\nimage. To be precise, given an image and an overcomplete, non-orthonormal\nbasis, we aim to find a sparse binary vector indicating the minimal set of\nbasis vectors that when added together best reconstruct the given input. We\nformulate this problem with an $L_2$ loss on the reconstruction error, and an\n$L_0$ (or, equivalently, an $L_1$) loss on the binary vector enforcing\nsparsity. This yields a quadratic unconstrained binary optimization problem\n(QUBO), whose optimal solution(s) in general is NP-hard to find. The\ncontribution of this work is twofold. First, we solve the sparse representation\nQUBOs by solving them both on a D-Wave quantum annealer with Pegasus chip\nconnectivity via minor embedding, as well as on the Intel Loihi 2 spiking\nneuromorphic processor using a stochastic Non-equilibrium Boltzmann Machine\n(NEBM). Second, we deploy Quantum Evolution Monte Carlo with Reverse Annealing\nand iterated warm starting on Loihi 2 to evolve the solution quality from the\nrespective machines. The solutions are benchmarked against simulated annealing,\na classical heuristic, and the optimal solutions are computed using CPLEX.\nIterated reverse quantum annealing performs similarly to simulated annealing,\nalthough simulated annealing is always able to sample the optimal solution\nwhereas quantum annealing was not always able to. The Loihi 2 solutions that\nare sampled are on average more sparse than the solutions from any of the other\nmethods. We demonstrate that both quantum annealing and neuromorphic computing\nare suitable for binary sparse coding QUBOs, and that Loihi 2 outperforms a\nD-Wave quantum annealer standard linear-schedule anneal, while iterated reverse\nquantum annealing performs much better than both unmodified linear-schedule\nquantum annealing and iterated warm starting on Loihi 2.", "AI": {"tldr": "The paper addresses sparse binary representation of images using QUBO, comparing quantum annealing (D-Wave) and neuromorphic computing (Loihi 2) with classical methods.", "motivation": "To find efficient methods for sparse binary coding of images, leveraging quantum and neuromorphic computing for NP-hard QUBO problems.", "method": "Formulates QUBO with L2 and L0/L1 losses, solves using D-Wave quantum annealing and Loihi 2 neuromorphic processor, and benchmarks against simulated annealing and CPLEX.", "result": "Loihi 2 yields sparser solutions; iterated reverse quantum annealing performs comparably to simulated annealing but not always optimally.", "conclusion": "Quantum annealing and neuromorphic computing are viable for sparse coding, with Loihi 2 outperforming D-Wave in some cases."}}
{"id": "2501.16393", "pdf": "https://arxiv.org/pdf/2501.16393", "abs": "https://arxiv.org/abs/2501.16393", "authors": ["Lili Zhang", "Quanyan Zhu", "Herman Ray", "Ying Xie"], "title": "Improving Network Threat Detection by Knowledge Graph, Large Language Model, and Imbalanced Learning", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "Accepted by \"Combining AI and OR/MS for Better Trustworthy Decision\n  Making\" Bridge Program co-organized by AAAI and INFORMS as poster and demo", "summary": "Network threat detection has been challenging due to the complexities of\nattack activities and the limitation of historical threat data to learn from.\nTo help enhance the existing practices of using analytics, machine learning,\nand artificial intelligence methods to detect the network threats, we propose\nan integrated modelling framework, where Knowledge Graph is used to analyze the\nusers' activity patterns, Imbalanced Learning techniques are used to prune and\nweigh Knowledge Graph, and LLM is used to retrieve and interpret the users'\nactivities from Knowledge Graph. The proposed framework is applied to Agile\nThreat Detection through Online Sequential Learning. The preliminary results\nshow the improved threat capture rate by 3%-4% and the increased\ninterpretabilities of risk predictions based on the users' activities.", "AI": {"tldr": "Proposes an integrated framework using Knowledge Graphs, Imbalanced Learning, and LLMs for network threat detection, improving threat capture rate by 3%-4%.", "motivation": "Challenges in network threat detection due to complex attack activities and limited historical data.", "method": "Combines Knowledge Graph for activity analysis, Imbalanced Learning for pruning, and LLM for interpretation.", "result": "Improved threat capture rate by 3%-4% and better interpretability of risk predictions.", "conclusion": "The framework enhances threat detection and interpretability, showing promise for practical applications."}}
{"id": "2409.12667", "pdf": "https://arxiv.org/pdf/2409.12667", "abs": "https://arxiv.org/abs/2409.12667", "authors": ["Ziang Guo", "Xinhao Lin", "Zakhar Yagudin", "Artem Lykov", "Yong Wang", "Yanqiang Li", "Dzmitry Tsetserukou"], "title": "METDrive: Multi-modal End-to-end Autonomous Driving with Temporal Guidance", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted by ICRA", "summary": "Multi-modal end-to-end autonomous driving has shown promising advancements in\nrecent work. By embedding more modalities into end-to-end networks, the\nsystem's understanding of both static and dynamic aspects of the driving\nenvironment is enhanced, thereby improving the safety of autonomous driving. In\nthis paper, we introduce METDrive, an end-to-end system that leverages temporal\nguidance from the embedded time series features of ego states, including\nrotation angles, steering, throttle signals, and waypoint vectors. The\ngeometric features derived from perception sensor data and the time series\nfeatures of ego state data jointly guide the waypoint prediction with the\nproposed temporal guidance loss function. We evaluated METDrive on the CARLA\nleaderboard benchmarks, achieving a driving score of 70%, a route completion\nscore of 94%, and an infraction score of 0.78.", "AI": {"tldr": "METDrive is an end-to-end autonomous driving system using multi-modal data and temporal guidance for improved safety and performance.", "motivation": "Enhancing autonomous driving safety by integrating multi-modal data and temporal features for better environment understanding.", "method": "Leverages temporal guidance from ego state time series features and geometric features from sensor data, using a proposed temporal guidance loss function.", "result": "Achieved a driving score of 70%, route completion of 94%, and infraction score of 0.78 on CARLA benchmarks.", "conclusion": "METDrive demonstrates improved performance in autonomous driving by effectively combining multi-modal data and temporal guidance."}}
{"id": "2502.00497", "pdf": "https://arxiv.org/pdf/2502.00497", "abs": "https://arxiv.org/abs/2502.00497", "authors": ["Sam Jeong", "Hae Yong Kim"], "title": "Convolutional Fourier Analysis Network (CFAN): A Unified Time-Frequency Approach for ECG Classification", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Machine learning has revolutionized biomedical signal analysis, particularly\nin electrocardiogram (ECG) classification. While convolutional neural networks\n(CNNs) excel at automatic feature extraction, the optimal integration of time-\nand frequency-domain information remains unresolved. This study introduces the\nConvolutional Fourier Analysis Network (CFAN), a novel architecture that\nunifies time-frequency analysis by embedding Fourier principles directly into\nCNN layers. We evaluate CFAN against four benchmarks - spectrogram-based 2D CNN\n(SPECT); 1D CNN (CNN1D); Fourier-based 1D CNN (FFT1D); and CNN1D with\nintegrated Fourier Analysis Network (CNN1D-FAN) - across three ECG tasks:\narrhythmia classification (MIT-BIH), identity recognition (ECG-ID), and apnea\ndetection (Apnea-ECG). CFAN achieved state-of-the-art performance, surpassing\nall competing methods with accuracies of 98.95% (MIT-BIH), 96.83% (ECG-ID), and\n95.01% (Apnea-ECG). Notably, on ECG-ID and Apnea-ECG, CFAN demonstrated\nstatistically significant improvements over the second-best method (CNN1D-FAN,\n$p \\leq 0.02$), further validating its superior performance. Key innovations\ninclude CONV-FAN blocks that combine sine, cosine and GELU activations in\nconvolutional layers to capture periodic features and joint time-frequency\nlearning without spectrogram conversion. Our results highlight CFAN's potential\nfor broader biomedical and signal classification applications.", "AI": {"tldr": "The paper introduces CFAN, a novel CNN architecture integrating Fourier principles for ECG classification, outperforming benchmarks in accuracy.", "motivation": "To resolve the unresolved optimal integration of time- and frequency-domain information in ECG classification using CNNs.", "method": "Proposes CFAN, embedding Fourier principles into CNN layers with CONV-FAN blocks for joint time-frequency learning.", "result": "CFAN achieved state-of-the-art accuracies: 98.95% (MIT-BIH), 96.83% (ECG-ID), and 95.01% (Apnea-ECG), with significant improvements over benchmarks.", "conclusion": "CFAN demonstrates superior performance and potential for broader biomedical signal classification applications."}}
{"id": "2409.15511", "pdf": "https://arxiv.org/pdf/2409.15511", "abs": "https://arxiv.org/abs/2409.15511", "authors": ["Abdul-Lateef Haji-Ali", "Marcelo Pereyra", "Luke Shaw", "Konstantinos Zygalakis"], "title": "Bayesian computation with generative diffusion models by Multilevel Monte Carlo", "categories": ["stat.CO", "cs.CV", "cs.LG"], "comment": "13 images", "summary": "Generative diffusion models have recently emerged as a powerful strategy to\nperform stochastic sampling in Bayesian inverse problems, delivering remarkably\naccurate solutions for a wide range of challenging applications. However,\ndiffusion models often require a large number of neural function evaluations\nper sample in order to deliver accurate posterior samples. As a result, using\ndiffusion models as stochastic samplers for Monte Carlo integration in Bayesian\ncomputation can be highly computationally expensive, particularly in\napplications that require a substantial number of Monte Carlo samples for\nconducting uncertainty quantification analyses. This cost is especially high in\nlarge-scale inverse problems such as computational imaging, which rely on large\nneural networks that are expensive to evaluate. With quantitative imaging\napplications in mind, this paper presents a Multilevel Monte Carlo strategy\nthat significantly reduces the cost of Bayesian computation with diffusion\nmodels. This is achieved by exploiting cost-accuracy trade-offs inherent to\ndiffusion models to carefully couple models of different levels of accuracy in\na manner that significantly reduces the overall cost of the calculation,\nwithout reducing the final accuracy. The proposed approach achieves a\n$4\\times$-to-$8\\times$ reduction in computational cost w.r.t. standard\ntechniques across three benchmark imaging problems.", "AI": {"tldr": "A Multilevel Monte Carlo strategy reduces computational costs of Bayesian computation with diffusion models by leveraging cost-accuracy trade-offs, achieving 4\u00d7-8\u00d7 cost reduction.", "motivation": "Diffusion models are computationally expensive for Bayesian inverse problems, especially in large-scale applications like computational imaging.", "method": "Proposes a Multilevel Monte Carlo strategy to couple models of varying accuracy, optimizing cost-accuracy trade-offs.", "result": "Achieves 4\u00d7-8\u00d7 computational cost reduction in benchmark imaging problems without sacrificing accuracy.", "conclusion": "The strategy significantly enhances efficiency of diffusion models in Bayesian computation for imaging applications."}}
{"id": "2502.08975", "pdf": "https://arxiv.org/pdf/2502.08975", "abs": "https://arxiv.org/abs/2502.08975", "authors": ["Kun Li", "Yida Xiong", "Hongzhi Zhang", "Xiantao Cai", "Jia Wu", "Bo Du", "Wenbin Hu"], "title": "Graph-structured Small Molecule Drug Discovery Through Deep Learning: Progress, Challenges, and Opportunities", "categories": ["cs.LG", "q-bio.BM"], "comment": "10 pages, 1 figures, 8 tables", "summary": "Due to their excellent drug-like and pharmacokinetic properties, small\nmolecule drugs are widely used to treat various diseases, making them a\ncritical component of drug discovery. In recent years, with the rapid\ndevelopment of deep learning (DL) techniques, DL-based small molecule drug\ndiscovery methods have achieved excellent performance in prediction accuracy,\nspeed, and complex molecular relationship modeling compared to traditional\nmachine learning approaches. These advancements enhance drug screening\nefficiency and optimization and provide more precise and effective solutions\nfor various drug discovery tasks. Contributing to this field's development,\nthis paper aims to systematically summarize and generalize the recent key tasks\nand representative techniques in graph-structured small molecule drug discovery\nin recent years. Specifically, we provide an overview of the major tasks in\nsmall molecule drug discovery and their interrelationships. Next, we analyze\nthe six core tasks, summarizing the related methods, commonly used datasets,\nand technological development trends. Finally, we discuss key challenges, such\nas interpretability and out-of-distribution generalization, and offer our\ninsights into future research directions for small molecule drug discovery.", "AI": {"tldr": "The paper reviews DL-based methods for small molecule drug discovery, highlighting their advantages over traditional approaches, summarizing key tasks, methods, datasets, and future challenges.", "motivation": "To enhance drug discovery efficiency and accuracy by leveraging DL techniques, addressing the need for systematic summaries of recent advancements in graph-structured small molecule drug discovery.", "method": "Systematic review and generalization of key tasks, methods, datasets, and trends in DL-based small molecule drug discovery, focusing on graph-structured approaches.", "result": "DL-based methods outperform traditional machine learning in accuracy, speed, and modeling complex molecular relationships, improving drug screening and optimization.", "conclusion": "The paper identifies challenges like interpretability and generalization, suggesting future research directions to advance small molecule drug discovery."}}
{"id": "2504.14219", "pdf": "https://arxiv.org/pdf/2504.14219", "abs": "https://arxiv.org/abs/2504.14219", "authors": ["Alara Dirik", "Tuanfeng Wang", "Duygu Ceylan", "Stefanos Zafeiriou", "Anna Fr\u00fchst\u00fcck"], "title": "PRISM: A Unified Framework for Photorealistic Reconstruction and Intrinsic Scene Modeling", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "We present PRISM, a unified framework that enables multiple image generation\nand editing tasks in a single foundational model. Starting from a pre-trained\ntext-to-image diffusion model, PRISM proposes an effective fine-tuning strategy\nto produce RGB images along with intrinsic maps (referred to as X layers)\nsimultaneously. Unlike previous approaches, which infer intrinsic properties\nindividually or require separate models for decomposition and conditional\ngeneration, PRISM maintains consistency across modalities by generating all\nintrinsic layers jointly. It supports diverse tasks, including text-to-RGBX\ngeneration, RGB-to-X decomposition, and X-to-RGBX conditional generation.\nAdditionally, PRISM enables both global and local image editing through\nconditioning on selected intrinsic layers and text prompts. Extensive\nexperiments demonstrate the competitive performance of PRISM both for intrinsic\nimage decomposition and conditional image generation while preserving the base\nmodel's text-to-image generation capability.", "AI": {"tldr": "PRISM is a unified framework for multiple image generation and editing tasks using a single model, generating RGB images and intrinsic maps (X layers) simultaneously.", "motivation": "To address the limitations of previous approaches that handle intrinsic properties individually or require separate models, PRISM aims to unify tasks like text-to-RGBX generation, decomposition, and conditional generation while maintaining consistency.", "method": "PRISM fine-tunes a pre-trained text-to-image diffusion model to jointly generate RGB images and intrinsic maps (X layers), supporting diverse tasks and enabling global/local editing via intrinsic layers and text prompts.", "result": "PRISM achieves competitive performance in intrinsic image decomposition and conditional generation while retaining the base model's text-to-image capabilities.", "conclusion": "PRISM offers a versatile and efficient solution for unified image generation and editing, outperforming previous methods in consistency and task diversity."}}
{"id": "2503.12662", "pdf": "https://arxiv.org/pdf/2503.12662", "abs": "https://arxiv.org/abs/2503.12662", "authors": ["Arthur Corr\u00eaa", "Crist\u00f3v\u00e3o Silva", "Liming Xu", "Alexandra Brintrup", "Samuel Moniz"], "title": "TuneNSearch: a hybrid transfer learning and local search approach for solving vehicle routing problems", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces TuneNSearch, a hybrid transfer learning and local\nsearch approach for addressing different variants of vehicle routing problems\n(VRP). Recently, multi-task learning has gained much attention for solving VRP\nvariants. However, this adaptability often compromises the performance of the\nmodels. To address this challenge, we first pre-train a reinforcement learning\nmodel on the multi-depot VRP, followed by a short fine-tuning phase to adapt it\nto different variants. By leveraging the complexity of the multi-depot VRP, the\npre-trained model learns richer node representations and gains more\ntransferable knowledge compared to models trained on simpler routing problems,\nsuch as the traveling salesman problem. TuneNSearch employs, in the first\nstage, a Transformer-based architecture, augmented with a residual edge-graph\nattention network to capture the impact of edge distances and residual\nconnections between layers. This architecture allows for a more precise capture\nof graph-structured data, improving the encoding of VRP's features. After\ninference, our model is also coupled with a second stage composed of a local\nsearch algorithm, which yields substantial performance gains with minimal\ncomputational overhead added. Results show that TuneNSearch outperforms many\nexisting state-of-the-art models trained for each VRP variant, requiring only\none-fifth of the training epochs. Our approach demonstrates strong\ngeneralization, achieving high performance across different tasks,\ndistributions and problem sizes, thus addressing a long-standing gap in the\nliterature.", "AI": {"tldr": "TuneNSearch combines transfer learning and local search to solve VRP variants efficiently, outperforming state-of-the-art models with minimal training epochs.", "motivation": "Address the trade-off between adaptability and performance in multi-task learning for VRP variants by leveraging pre-training on complex problems.", "method": "Pre-train a reinforcement learning model on multi-depot VRP, fine-tune for variants, and use a Transformer-based architecture with local search.", "result": "Outperforms existing models, requires fewer training epochs, and generalizes well across tasks and problem sizes.", "conclusion": "TuneNSearch bridges the gap in VRP literature by offering a high-performance, adaptable solution with strong generalization."}}
{"id": "2505.07887", "pdf": "https://arxiv.org/pdf/2505.07887", "abs": "https://arxiv.org/abs/2505.07887", "authors": ["Songyin Wu", "Zhaoyang Lv", "Yufeng Zhu", "Duncan Frost", "Zhengqin Li", "Ling-Qi Yan", "Carl Ren", "Richard Newcombe", "Zhao Dong"], "title": "Monocular Online Reconstruction with Enhanced Detail Preservation", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted to SIGGRAPH 2025 (Conference Track). Project page:\n  https://poiw.github.io/MODP", "summary": "We propose an online 3D Gaussian-based dense mapping framework for\nphotorealistic details reconstruction from a monocular image stream. Our\napproach addresses two key challenges in monocular online reconstruction:\ndistributing Gaussians without relying on depth maps and ensuring both local\nand global consistency in the reconstructed maps. To achieve this, we introduce\ntwo key modules: the Hierarchical Gaussian Management Module for effective\nGaussian distribution and the Global Consistency Optimization Module for\nmaintaining alignment and coherence at all scales. In addition, we present the\nMulti-level Occupancy Hash Voxels (MOHV), a structure that regularizes\nGaussians for capturing details across multiple levels of granularity. MOHV\nensures accurate reconstruction of both fine and coarse geometries and\ntextures, preserving intricate details while maintaining overall structural\nintegrity. Compared to state-of-the-art RGB-only and even RGB-D methods, our\nframework achieves superior reconstruction quality with high computational\nefficiency. Moreover, it integrates seamlessly with various tracking systems,\nensuring generality and scalability.", "AI": {"tldr": "An online 3D Gaussian-based dense mapping framework for photorealistic reconstruction from monocular images, addressing Gaussian distribution and consistency challenges.", "motivation": "To overcome limitations in monocular online reconstruction, such as reliance on depth maps and ensuring local/global consistency.", "method": "Uses Hierarchical Gaussian Management and Global Consistency Optimization modules, along with Multi-level Occupancy Hash Voxels (MOHV) for detail capture.", "result": "Superior reconstruction quality and computational efficiency compared to RGB-only and RGB-D methods.", "conclusion": "The framework is scalable, integrates with tracking systems, and excels in preserving details and structural integrity."}}
{"id": "2504.02692", "pdf": "https://arxiv.org/pdf/2504.02692", "abs": "https://arxiv.org/abs/2504.02692", "authors": ["Yuhang Li", "Ruokai Yin", "Donghyun Lee", "Shiting Xiao", "Priyadarshini Panda"], "title": "GPTAQ: Efficient Finetuning-Free Quantization for Asymmetric Calibration", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "We introduce GPTAQ, a novel finetuning-free quantization method for\ncompressing large-scale transformer architectures. Unlike the previous GPTQ\nmethod, which independently calibrates each layer, we always match the\nquantized layer's output to the exact output in the full-precision model,\nresulting in a scheme that we call asymmetric calibration. Such a scheme can\neffectively reduce the quantization error accumulated in previous layers. We\nanalyze this problem using optimal brain compression to derive a close-formed\nsolution. The new solution explicitly minimizes the quantization error as well\nas the accumulated asymmetry error. Furthermore, we utilize various techniques\nto parallelize the solution calculation, including channel parallelization,\nneuron decomposition, and Cholesky reformulation for matrix fusion. As a\nresult, GPTAQ is easy to implement, simply using 20 more lines of code than\nGPTQ but improving its performance under low-bit quantization. Remarkably, on a\nsingle GPU, we quantize a 405B language transformer as well as EVA-02, the rank\nfirst vision transformer that achieves 90% pretraining Imagenet accuracy. Code\nis available at Github.", "AI": {"tldr": "GPTAQ is a finetuning-free quantization method for transformers, improving upon GPTQ by reducing quantization errors through asymmetric calibration and parallelization techniques.", "motivation": "To compress large-scale transformer architectures without finetuning while minimizing quantization errors.", "method": "Uses asymmetric calibration to match quantized layer outputs to full-precision models, employs optimal brain compression for analysis, and parallelizes calculations with techniques like channel parallelization and Cholesky reformulation.", "result": "Achieves better performance under low-bit quantization, successfully quantizing a 405B language transformer and EVA-02 vision transformer on a single GPU.", "conclusion": "GPTAQ is efficient, easy to implement, and outperforms GPTQ in reducing quantization errors."}}
{"id": "2504.09192", "pdf": "https://arxiv.org/pdf/2504.09192", "abs": "https://arxiv.org/abs/2504.09192", "authors": ["Zhiyong Wang"], "title": "Towards More Efficient, Robust, Instance-adaptive, and Sequential Decision making", "categories": ["cs.LG"], "comment": "Ph.D. Thesis", "summary": "The primary goal of my Ph.D. study is to develop provably efficient and\npractical algorithms for data-driven sequential decision-making under\nuncertainty. My work focuses on reinforcement learning (RL), multi-armed\nbandits, and their applications, including recommendation systems, computer\nnetworks, video analytics, and large language models (LLMs). Sequential\ndecision-making methods, such as bandits and RL, have demonstrated remarkable\nsuccess - ranging from outperforming human players in complex games like Atari\nand Go to advancing robotics, recommendation systems, and fine-tuning LLMs.\nDespite these successes, many established algorithms rely on idealized models\nthat can fail under model misspecifications or adversarial perturbations,\nparticularly in settings where accurate prior knowledge of the underlying model\nclass is unavailable or where malicious users operate within dynamic systems.\nThese challenges are pervasive in real-world applications, where robust and\nadaptive solutions are critical. Furthermore, while worst-case guarantees\nprovide theoretical reliability, they often fail to capture instance-dependent\nperformance, which can lead to more efficient and practical solutions. Another\nkey challenge lies in generalizing to new, unseen environments, a crucial\nrequirement for deploying these methods in dynamic and unpredictable settings.\nTo address these limitations, my research aims to develop more efficient,\nrobust, instance-adaptive, and generalizable sequential decision-making\nalgorithms for both reinforcement learning and bandits. Towards this end, I\nfocus on developing more efficient, robust, instance-adaptive, and\ngeneralizable for both general reinforcement learning (RL) and bandits.", "AI": {"tldr": "Developing efficient, robust, and adaptive algorithms for sequential decision-making in RL and bandits, addressing real-world challenges like model misspecifications and adversarial perturbations.", "motivation": "Existing algorithms often rely on idealized models, failing in real-world scenarios with uncertainty, adversarial conditions, or lack of prior knowledge. Robust, adaptive, and instance-dependent solutions are needed.", "method": "Focuses on reinforcement learning (RL) and multi-armed bandits, aiming to improve efficiency, robustness, instance-adaptivity, and generalizability.", "result": "Not explicitly stated, but the goal is to create algorithms that perform better in dynamic, uncertain, and adversarial environments.", "conclusion": "The research aims to bridge the gap between theoretical guarantees and practical performance, enhancing the applicability of sequential decision-making methods in real-world settings."}}
{"id": "2504.11383", "pdf": "https://arxiv.org/pdf/2504.11383", "abs": "https://arxiv.org/abs/2504.11383", "authors": ["Wei Wang", "Maryam Hakimzadeh", "Haihui Ruan", "Somdatta Goswami"], "title": "Accelerating Multiscale Modeling with Hybrid Solvers: Coupling FEM and Neural Operators with Domain Decomposition", "categories": ["cs.LG"], "comment": null, "summary": "Numerical solvers for PDEs face challenges in balancing computational cost\nand accuracy, particularly for multiscale and dynamical systems. Neural\noperators (NOs) can significantly speed up simulations; however, they face\nchallenges such as error accumulation for dynamical systems and limited\ngeneralization in multiphysics problems. This work introduces a novel hybrid\nframework that integrates PI-NO with finite element method (FE) through domain\ndecomposition and leverages numerical analysis for time marching. The core\ninnovation lies in efficient coupling FE and NO subdomains via a Schwarz\nalternating method: regions with complex, nonlinear, or high-gradient behavior\nare resolved using a pretrained NO, while the remainder is handled by\nconventional FE. To address the challenges of dynamic systems, we embed a\ntime-stepping scheme directly into the NO architecture, substantially reducing\nlong-term error propagation. Also, an adaptive subdomain evolution strategy\nenables the ML resolved region to expand dynamically, capturing emerging fine\nscale features without remeshing. The framework efficacy has been validated\nacross a range of problems, spanning static, quasi-static, and dynamic regimes\n(e.g., linear elasticity, hyperelasticity, and elastodynamics), demonstrating\naccelerated convergence (up to 20% improvement in convergence compared to\nconventional FE coupling) while preserving solution fidelity with error margins\nconsistently below 1%. Our study shows that our hybrid solver: (1) maintains\nsolution continuity across subdomain interfaces, (2) reduces computational\ncosts by eliminating fine mesh requirements, (3) mitigates error accumulation\nin time dependent simulations, and (4) enables automatic adaptation to evolving\nphysical phenomena. This work bridges the gap between numerical methods and\nAI-driven surrogates, offering a scalable pathway for high-fidelity multiscale\nsimulations.", "AI": {"tldr": "A hybrid framework combining PI-NO with finite element method (FE) via domain decomposition improves PDE solver efficiency, reducing computational costs and error accumulation while maintaining accuracy.", "motivation": "Address challenges in balancing computational cost and accuracy for multiscale and dynamical PDE systems, leveraging neural operators (NOs) and FE methods.", "method": "Integrates PI-NO with FE through domain decomposition, using Schwarz alternating method for coupling. NO handles complex regions, FE handles the rest, with embedded time-stepping and adaptive subdomain evolution.", "result": "Validated across static, quasi-static, and dynamic regimes, showing 20% faster convergence and errors below 1%. Maintains solution continuity, reduces costs, and adapts to evolving phenomena.", "conclusion": "The hybrid solver bridges numerical methods and AI, offering scalable, high-fidelity multiscale simulations."}}
{"id": "2505.07086", "pdf": "https://arxiv.org/pdf/2505.07086", "abs": "https://arxiv.org/abs/2505.07086", "authors": ["Tong Chen", "Yinuo Zhang", "Sophia Tang", "Pranam Chatterjee"], "title": "Multi-Objective-Guided Discrete Flow Matching for Controllable Biological Sequence Design", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Designing biological sequences that satisfy multiple, often conflicting,\nfunctional and biophysical criteria remains a central challenge in biomolecule\nengineering. While discrete flow matching models have recently shown promise\nfor efficient sampling in high-dimensional sequence spaces, existing approaches\naddress only single objectives or require continuous embeddings that can\ndistort discrete distributions. We present Multi-Objective-Guided Discrete Flow\nMatching (MOG-DFM), a general framework to steer any pretrained discrete flow\nmatching generator toward Pareto-efficient trade-offs across multiple scalar\nobjectives. At each sampling step, MOG-DFM computes a hybrid rank-directional\nscore for candidate transitions and applies an adaptive hypercone filter to\nenforce consistent multi-objective progression. We also trained two\nunconditional discrete flow matching models, PepDFM for diverse peptide\ngeneration and EnhancerDFM for functional enhancer DNA generation, as base\ngeneration models for MOG-DFM. We demonstrate MOG-DFM's effectiveness in\ngenerating peptide binders optimized across five properties (hemolysis,\nnon-fouling, solubility, half-life, and binding affinity), and in designing DNA\nsequences with specific enhancer classes and DNA shapes. In total, MOG-DFM\nproves to be a powerful tool for multi-property-guided biomolecule sequence\ndesign.", "AI": {"tldr": "MOG-DFM is a framework for multi-objective-guided biomolecule sequence design, improving upon existing discrete flow matching models by addressing multiple conflicting objectives.", "motivation": "Existing methods for biomolecule engineering struggle with multiple conflicting objectives and often rely on continuous embeddings, which can distort discrete distributions.", "method": "MOG-DFM combines hybrid rank-directional scoring and adaptive hypercone filtering to steer pretrained discrete flow matching models toward Pareto-efficient trade-offs.", "result": "MOG-DFM successfully generates peptide binders and DNA sequences optimized for multiple properties, demonstrating its effectiveness in multi-property-guided design.", "conclusion": "MOG-DFM is a powerful tool for designing biomolecules with balanced trade-offs across multiple functional and biophysical criteria."}}
{"id": "2505.07961", "pdf": "https://arxiv.org/pdf/2505.07961", "abs": "https://arxiv.org/abs/2505.07961", "authors": ["Xuechen Zhang", "Zijian Huang", "Chenshun Ni", "Ziyang Xiong", "Jiasi Chen", "Samet Oymak"], "title": "Making Small Language Models Efficient Reasoners: Intervention, Supervision, Reinforcement", "categories": ["cs.LG"], "comment": null, "summary": "Recent research enhances language model reasoning by scaling test-time\ncompute via longer chain-of-thought traces. This often improves accuracy but\nalso introduces redundancy and high computational cost, especially for small\nlanguage models distilled with supervised fine-tuning (SFT). In this work, we\npropose new algorithms to improve token-efficient reasoning with small-scale\nmodels by effectively trading off accuracy and computation. We first show that\nthe post-SFT model fails to determine the optimal stopping point of the\nreasoning process, resulting in verbose and repetitive outputs. Verbosity also\nsignificantly varies across wrong vs correct responses. To address these\nissues, we propose two solutions: (1) Temperature scaling (TS) to control the\nstopping point for the thinking phase and thereby trace length, and (2) TLDR: a\nlength-regularized reinforcement learning method based on GRPO that facilitates\nmulti-level trace length control (e.g. short, medium, long reasoning).\nExperiments on four reasoning benchmarks, MATH500, AMC, AIME24 and\nOlympiadBench, demonstrate that TS is highly effective compared to s1's budget\nforcing approach and TLDR significantly improves token efficiency by about 50%\nwith minimal to no accuracy loss over the SFT baseline. Moreover, TLDR also\nfacilitates flexible control over the response length, offering a practical and\neffective solution for token-efficient reasoning in small models. Ultimately,\nour work reveals the importance of stopping time control, highlights\nshortcomings of pure SFT, and provides effective algorithmic recipes.", "AI": {"tldr": "The paper proposes two methods, Temperature Scaling (TS) and TLDR, to improve token-efficient reasoning in small language models by controlling trace length and reducing redundancy.", "motivation": "Small language models often produce verbose and repetitive outputs due to inability to determine optimal stopping points in reasoning, leading to high computational costs.", "method": "Two solutions are introduced: (1) Temperature Scaling (TS) to control trace length, and (2) TLDR, a length-regularized reinforcement learning method for multi-level trace length control.", "result": "Experiments show TS outperforms budget forcing, and TLDR improves token efficiency by ~50% with minimal accuracy loss. TLDR also enables flexible response length control.", "conclusion": "The work emphasizes the importance of stopping time control, identifies SFT limitations, and offers effective solutions for token-efficient reasoning in small models."}}
{"id": "2505.08320", "pdf": "https://arxiv.org/pdf/2505.08320", "abs": "https://arxiv.org/abs/2505.08320", "authors": ["Yoonhyuk Choi", "Chong-Kwon Kim"], "title": "SpecSphere: Dual-Pass Spectral-Spatial Graph Neural Networks with Certified Robustness", "categories": ["cs.LG"], "comment": null, "summary": "We introduce SpecSphere, the first dual-pass spectral-spatial GNN that\ncertifies every prediction against both $\\ell\\_{0}$ edge flips and\n$\\ell\\_{\\infty}$ feature perturbations, adapts to the full\nhomophily-heterophily spectrum, and surpasses the expressive power of\n1-Weisfeiler-Lehman while retaining linear-time complexity. Our model couples a\nChebyshev-polynomial spectral branch with an attention-gated spatial branch and\nfuses their representations through a lightweight MLP trained in a\ncooperative-adversarial min-max game. We further establish (i) a uniform\nChebyshev approximation theorem, (ii) minimax-optimal risk across the\nhomophily-heterophily spectrum, (iii) closed-form robustness certificates, and\n(iv) universal approximation strictly beyond 1-WL. SpecSphere achieves\nstate-of-the-art node-classification accuracy and delivers tighter certified\nrobustness guarantees on real-world benchmarks. These results demonstrate that\nhigh expressivity, heterophily adaptation, and provable robustness can coexist\nwithin a single, scalable architecture.", "AI": {"tldr": "SpecSphere is a dual-pass spectral-spatial GNN offering certified robustness, adaptability to homophily-heterophily, and expressive power beyond 1-WL, with state-of-the-art performance.", "motivation": "To create a GNN that combines high expressivity, adaptability, and provable robustness in a scalable architecture.", "method": "Couples a Chebyshev-polynomial spectral branch with an attention-gated spatial branch, fused via a lightweight MLP trained in a min-max game.", "result": "Achieves SOTA node-classification accuracy, tighter robustness guarantees, and theoretical advancements.", "conclusion": "SpecSphere proves that expressivity, adaptability, and robustness can coexist in a scalable GNN."}}
{"id": "2505.08550", "pdf": "https://arxiv.org/pdf/2505.08550", "abs": "https://arxiv.org/abs/2505.08550", "authors": ["Wenzhen Yue", "Yong Liu", "Haoxuan Li", "Hao Wang", "Xianghua Ying", "Ruohao Guo", "Bowei Xing", "Ji Shi"], "title": "OLinear: A Linear Model for Time Series Forecasting in Orthogonally Transformed Domain", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper presents $\\mathbf{OLinear}$, a $\\mathbf{linear}$-based\nmultivariate time series forecasting model that operates in an\n$\\mathbf{o}$rthogonally transformed domain. Recent forecasting models typically\nadopt the temporal forecast (TF) paradigm, which directly encode and decode\ntime series in the time domain. However, the entangled step-wise dependencies\nin series data can hinder the performance of TF. To address this, some\nforecasters conduct encoding and decoding in the transformed domain using\nfixed, dataset-independent bases (e.g., sine and cosine signals in the Fourier\ntransform). In contrast, we utilize $\\mathbf{OrthoTrans}$, a data-adaptive\ntransformation based on an orthogonal matrix that diagonalizes the series'\ntemporal Pearson correlation matrix. This approach enables more effective\nencoding and decoding in the decorrelated feature domain and can serve as a\nplug-in module to enhance existing forecasters. To enhance the representation\nlearning for multivariate time series, we introduce a customized linear layer,\n$\\mathbf{NormLin}$, which employs a normalized weight matrix to capture\nmultivariate dependencies. Empirically, the NormLin module shows a surprising\nperformance advantage over multi-head self-attention, while requiring nearly\nhalf the FLOPs. Extensive experiments on 24 benchmarks and 140 forecasting\ntasks demonstrate that OLinear consistently achieves state-of-the-art\nperformance with high efficiency. Notably, as a plug-in replacement for\nself-attention, the NormLin module consistently enhances Transformer-based\nforecasters. The code and datasets are available at\nhttps://anonymous.4open.science/r/OLinear", "AI": {"tldr": "OLinear is a linear-based multivariate time series forecasting model using an orthogonal transformation (OrthoTrans) for decorrelated feature encoding/decoding, outperforming traditional methods with high efficiency.", "motivation": "Traditional temporal forecast (TF) models struggle with entangled step-wise dependencies in time series. Fixed transformations (e.g., Fourier) lack adaptability, prompting the need for a data-adaptive orthogonal transformation.", "method": "OLinear uses OrthoTrans, a data-adaptive orthogonal matrix, to decorrelate features. It also introduces NormLin, a normalized linear layer, to capture multivariate dependencies efficiently.", "result": "OLinear achieves state-of-the-art performance on 24 benchmarks and 140 tasks. NormLin outperforms multi-head self-attention with fewer FLOPs and enhances Transformer-based models.", "conclusion": "OLinear offers an efficient, adaptable solution for multivariate time series forecasting, with NormLin proving superior to self-attention in performance and computational cost."}}
{"id": "2505.08740", "pdf": "https://arxiv.org/pdf/2505.08740", "abs": "https://arxiv.org/abs/2505.08740", "authors": ["Abdolmehdi Behroozi", "Chaopeng Shen and", "Daniel Kifer"], "title": "Sensitivity-Constrained Fourier Neural Operators for Forward and Inverse Problems in Parametric Differential Equations", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Parametric differential equations of the form du/dt = f(u, x, t, p) are\nfundamental in science and engineering. While deep learning frameworks such as\nthe Fourier Neural Operator (FNO) can efficiently approximate solutions, they\nstruggle with inverse problems, sensitivity estimation (du/dp), and concept\ndrift. We address these limitations by introducing a sensitivity-based\nregularization strategy, called Sensitivity-Constrained Fourier Neural\nOperators (SC-FNO). SC-FNO achieves high accuracy in predicting solution paths\nand consistently outperforms standard FNO and FNO with physics-informed\nregularization. It improves performance in parameter inversion tasks, scales to\nhigh-dimensional parameter spaces (tested with up to 82 parameters), and\nreduces both data and training requirements. These gains are achieved with a\nmodest increase in training time (30% to 130% per epoch) and generalize across\nvarious types of differential equations and neural operators. Code and selected\nexperiments are available at: https://github.com/AMBehroozi/SC_Neural_Operators", "AI": {"tldr": "SC-FNO improves FNO by adding sensitivity-based regularization, enhancing accuracy, scalability, and efficiency in solving parametric differential equations.", "motivation": "Standard FNO struggles with inverse problems, sensitivity estimation, and concept drift in parametric differential equations.", "method": "Introduces Sensitivity-Constrained Fourier Neural Operators (SC-FNO) with sensitivity-based regularization.", "result": "SC-FNO outperforms standard FNO, improves parameter inversion, scales to high dimensions, and reduces data/training needs.", "conclusion": "SC-FNO is a robust solution for parametric differential equations, generalizing well across various scenarios."}}
{"id": "2303.17496", "pdf": "https://arxiv.org/pdf/2303.17496", "abs": "https://arxiv.org/abs/2303.17496", "authors": ["Karl Otness", "Laure Zanna", "Joan Bruna"], "title": "Data-driven multiscale modeling for correcting dynamical systems", "categories": ["physics.ao-ph", "cs.LG"], "comment": "Extended with additional experiments", "summary": "We propose a multiscale approach for predicting quantities in dynamical\nsystems which is explicitly structured to extract information in both\nfine-to-coarse and coarse-to-fine directions. We envision this method being\ngenerally applicable to problems with significant self-similarity or in which\nthe prediction task is challenging and where stability of a learned model's\nimpact on the target dynamical system is important. We evaluate our approach on\na climate subgrid parameterization task in which our multiscale networks\ncorrect chaotic underlying models to reflect the contributions of unresolved,\nfine-scale dynamics.", "AI": {"tldr": "A multiscale approach for predicting dynamical systems, focusing on fine-to-coarse and coarse-to-fine information extraction, applied to climate subgrid parameterization.", "motivation": "Addressing challenges in prediction tasks with self-similarity or instability in learned models, particularly in dynamical systems like climate modeling.", "method": "Multiscale networks designed to extract and integrate information bidirectionally (fine-to-coarse and coarse-to-fine) to correct chaotic models.", "result": "The approach successfully corrects underlying chaotic models to account for unresolved fine-scale dynamics in climate subgrid parameterization.", "conclusion": "The multiscale method is effective for dynamical systems with self-similarity or challenging prediction tasks, demonstrating stability and accuracy in climate modeling."}}
{"id": "2402.06919", "pdf": "https://arxiv.org/pdf/2402.06919", "abs": "https://arxiv.org/abs/2402.06919", "authors": ["Omer Luxembourg", "Dor Tsur", "Haim Permuter"], "title": "TREET: TRansfer Entropy Estimation via Transformers", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Transfer entropy (TE) is an information theoretic measure that reveals the\ndirectional flow of information between processes, providing valuable insights\nfor a wide range of real-world applications. This work proposes Transfer\nEntropy Estimation via Transformers (TREET), a novel attention-based approach\nfor estimating TE for stationary processes. The proposed approach employs\nDonsker-Varadhan representation to TE and leverages the attention mechanism for\nthe task of neural estimation. We propose a detailed theoretical and empirical\nstudy of the TREET, comparing it to existing methods on a dedicated estimation\nbenchmark. To increase its applicability, we design an estimated TE\noptimization scheme that is motivated by the functional representation lemma,\nand use it to estimate the capacity of communication channels with memory,\nwhich is a canonical optimization problem in information theory. We further\ndemonstrate how an optimized TREET can be used to estimate underlying\ndensities, providing experimental results. Finally, we apply TREET to feature\nanalysis of patients with Apnea, demonstrating its applicability to real-world\nphysiological data. Our work, applied with state-of-the-art deep learning\nmethods, opens a new door for communication problems which are yet to be\nsolved.", "AI": {"tldr": "TREET is a novel attention-based method for estimating transfer entropy (TE) using transformers, outperforming existing methods and applied to real-world problems like communication channels and physiological data.", "motivation": "To improve TE estimation for stationary processes using deep learning, addressing limitations of existing methods and expanding applicability to real-world scenarios.", "method": "Uses Donsker-Varadhan representation and attention mechanisms for neural TE estimation, with theoretical and empirical validation. Includes an optimization scheme for TE and density estimation.", "result": "TREET outperforms existing methods on benchmarks and successfully estimates TE for communication channels and physiological data (e.g., Apnea patients).", "conclusion": "TREET advances TE estimation with deep learning, offering practical solutions for communication and medical applications, and opens new research avenues."}}
{"id": "2403.13952", "pdf": "https://arxiv.org/pdf/2403.13952", "abs": "https://arxiv.org/abs/2403.13952", "authors": ["Orlando A. Mendible", "Jonathan K. Whitmer", "Yamil J. Col\u00f3n"], "title": "Considerations in the use of ML interaction potentials for free energy calculations", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Machine learning force fields (MLFFs) promise to accurately describe the\npotential energy surface of molecules at the ab initio level of theory with\nimproved computational efficiency. Within MLFFs, equivariant graph neural\nnetworks (EQNNs) have shown great promise in accuracy and performance and are\nthe focus of this work. The capability of EQNNs to recover free energy surfaces\n(FES) remains to be thoroughly investigated. In this work, we investigate the\nimpact of collective variables (CVs) distribution within the training data on\nthe accuracy of EQNNs predicting the FES of butane and alanine dipeptide (ADP).\nA generalizable workflow is presented in which training configurations are\ngenerated with classical molecular dynamics simulations, and energies and\nforces are obtained with ab initio calculations. We evaluate how bond and angle\nconstraints in the training data influence the accuracy of EQNN force fields in\nreproducing the FES of the molecules at both classical and ab initio levels of\ntheory. Results indicate that the model's accuracy is unaffected by the\ndistribution of sampled CVs during training, given that the training data\nincludes configurations from characteristic regions of the system's FES.\nHowever, when the training data is obtained from classical simulations, the\nEQNN struggles to extrapolate the free energy for configurations with high free\nenergy. In contrast, models trained with the same configurations on ab initio\ndata show improved extrapolation accuracy. The findings underscore the\ndifficulties in creating a comprehensive training dataset for EQNNs to predict\nFESs and highlight the importance of prior knowledge of the system's FES.", "AI": {"tldr": "EQNNs' accuracy in predicting FES depends on training data distribution and prior knowledge of the system's FES. Classical simulations limit extrapolation, while ab initio data improves it.", "motivation": "To investigate how collective variables (CVs) distribution in training data affects EQNNs' accuracy in predicting free energy surfaces (FES) of molecules like butane and alanine dipeptide.", "method": "A workflow using classical MD simulations for training data generation and ab initio calculations for energies/forces. Evaluated bond/angle constraints' impact on EQNN accuracy.", "result": "EQNN accuracy is unaffected by CV distribution if training data covers characteristic FES regions. Classical data limits extrapolation; ab initio data improves it.", "conclusion": "Creating comprehensive training datasets for EQNNs is challenging, emphasizing the need for prior knowledge of the system's FES."}}
{"id": "2404.02171", "pdf": "https://arxiv.org/pdf/2404.02171", "abs": "https://arxiv.org/abs/2404.02171", "authors": ["Lucas Amoudruz", "Sergey Litvinov", "Petros Koumoutsakos"], "title": "Optimal navigation of magnetic artificial microswimmers in blood capillaries with deep reinforcement learning", "categories": ["physics.bio-ph", "cs.LG", "cs.RO"], "comment": null, "summary": "Biomedical applications such as targeted drug delivery, microsurgery, and\nsensing rely on reaching precise areas within the body in a minimally invasive\nway. Artificial bacterial flagella (ABFs) have emerged as potential tools for\nthis task by navigating through the circulatory system with the help of\nexternal magnetic fields. While their swimming characteristics are well\nunderstood in simple settings, their controlled navigation through realistic\ncapillary networks remains a significant challenge due to the complexity of\nblood flow and the high computational cost of detailed simulations. We address\nthis challenge by conducting numerical simulations of ABFs in retinal\ncapillaries, propelled by an external magnetic field. The simulations are based\non a validated blood model that predicts the dynamics of individual red blood\ncells and their hydrodynamic interactions with ABFs. The magnetic field follows\na control policy that brings the ABF to a prescribed target. The control policy\nis learned with an actor-critic, off-policy reinforcement learning algorithm\ncoupled with a reduced-order model of the system. We show that the same policy\nrobustly guides the ABF to a prescribed target in both the reduced-order model\nand the fine-grained blood simulations. This approach is suitable for designing\nrobust control policies for personalized medicine at moderate computational\ncost.", "AI": {"tldr": "The paper explores controlled navigation of artificial bacterial flagella (ABFs) in realistic capillary networks using simulations and reinforcement learning for robust targeting.", "motivation": "Precise biomedical applications like drug delivery require minimally invasive tools, but navigating ABFs through complex capillary networks is challenging due to blood flow dynamics and high computational costs.", "method": "Numerical simulations of ABFs in retinal capillaries, using a validated blood model and a reinforcement learning-based control policy for magnetic field guidance.", "result": "The learned control policy successfully guides ABFs to targets in both reduced-order and fine-grained blood simulations, demonstrating robustness.", "conclusion": "This approach enables efficient design of control policies for personalized medicine with manageable computational costs."}}
{"id": "2405.17955", "pdf": "https://arxiv.org/pdf/2405.17955", "abs": "https://arxiv.org/abs/2405.17955", "authors": ["O. Deniz Akyildiz", "Mark Girolami", "Andrew M. Stuart", "Arnaud Vadeboncoeur"], "title": "Efficient Prior Calibration From Indirect Data", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": null, "summary": "Bayesian inversion is central to the quantification of uncertainty within\nproblems arising from numerous applications in science and engineering. To\nformulate the approach, four ingredients are required: a forward model mapping\nthe unknown parameter to an element of a solution space, often the solution\nspace for a differential equation; an observation operator mapping an element\nof the solution space to the data space; a noise model describing how noise\npollutes the observations; and a prior model describing knowledge about the\nunknown parameter before the data is acquired. This paper is concerned with\nlearning the prior model from data; in particular, learning the prior from\nmultiple realizations of indirect data obtained through the noisy observation\nprocess. The prior is represented, using a generative model, as the pushforward\nof a Gaussian in a latent space; the pushforward map is learned by minimizing\nan appropriate loss function. A metric that is well-defined under empirical\napproximation is used to define the loss function for the pushforward map to\nmake an implementable methodology. Furthermore, an efficient residual-based\nneural operator approximation of the forward model is proposed and it is shown\nthat this may be learned concurrently with the pushforward map, using a bilevel\noptimization formulation of the problem; this use of neural operator\napproximation has the potential to make prior learning from indirect data more\ncomputationally efficient, especially when the observation process is\nexpensive, non-smooth or not known. The ideas are illustrated with the Darcy\nflow inverse problem of finding permeability from piezometric head\nmeasurements.", "AI": {"tldr": "The paper focuses on learning a prior model from indirect data using a generative approach and neural operator approximation for efficient Bayesian inversion.", "motivation": "Bayesian inversion is key for uncertainty quantification, but prior models are often assumed. This work aims to learn the prior from data, especially indirect noisy observations.", "method": "A generative model represents the prior as a pushforward of a Gaussian in latent space, optimized via a loss function. A neural operator approximates the forward model, learned concurrently using bilevel optimization.", "result": "The method provides an implementable way to learn priors from indirect data, with potential computational efficiency gains for expensive or non-smooth observation processes.", "conclusion": "The approach is demonstrated on the Darcy flow inverse problem, showing promise for practical applications in uncertainty quantification."}}
{"id": "2407.21062", "pdf": "https://arxiv.org/pdf/2407.21062", "abs": "https://arxiv.org/abs/2407.21062", "authors": ["Bahram Alidaee", "Haibo Wang", "Lutfu Sua", "Wade Liu"], "title": "Hybrid Heuristic Algorithms for Adiabatic Quantum Machine Learning Models", "categories": ["quant-ph", "cs.LG"], "comment": "23 pages and 7 tables", "summary": "Numerous established machine learning models and various neural network\narchitectures can be restructured as Quadratic Unconstrained Binary\nOptimization (QUBO) problems. A significant challenge in Adiabatic Quantum\nMachine Learning (AQML) is the computational demand of the training phase. To\nmitigate this, approximation techniques inspired by quantum annealing, like\nSimulated Annealing and Multiple Start Tabu Search (MSTS), have been employed\nto expedite QUBO-based AQML training. This paper introduces a novel hybrid\nalgorithm that incorporates an \"r-flip\" strategy. This strategy is aimed at\nsolving large-scale QUBO problems more effectively, offering better solution\nquality and lower computational costs compared to existing MSTS methods. The\nr-flip approach has practical applications in diverse fields, including\ncross-docking, supply chain management, machine scheduling, and fraud\ndetection. The paper details extensive computational experiments comparing this\nr-flip enhanced hybrid heuristic against a standard MSTS approach. These tests\nutilize both standard benchmark problems and three particularly large QUBO\ninstances. The results indicate that the r-flip enhanced method consistently\nproduces high-quality solutions efficiently, operating within practical time\nconstraints.", "AI": {"tldr": "A hybrid algorithm with an \"r-flip\" strategy is introduced to solve large-scale QUBO problems more efficiently than existing MSTS methods, showing better solution quality and lower computational costs.", "motivation": "The computational demand of training in Adiabatic Quantum Machine Learning (AQML) motivates the need for efficient approximation techniques like the proposed r-flip strategy.", "method": "The paper introduces a hybrid algorithm incorporating an r-flip strategy to expedite QUBO-based AQML training, tested against standard MSTS methods using benchmark and large-scale QUBO problems.", "result": "The r-flip enhanced method consistently produces high-quality solutions efficiently within practical time constraints, outperforming standard MSTS approaches.", "conclusion": "The r-flip strategy is effective for large-scale QUBO problems, with applications in cross-docking, supply chain, scheduling, and fraud detection."}}
{"id": "2409.02668", "pdf": "https://arxiv.org/pdf/2409.02668", "abs": "https://arxiv.org/abs/2409.02668", "authors": ["Laurent Younes"], "title": "Introduction to Machine Learning", "categories": ["stat.ML", "cs.LG"], "comment": "textbook", "summary": "This book introduces the mathematical foundations and techniques that lead to\nthe development and analysis of many of the algorithms that are used in machine\nlearning. It starts with an introductory chapter that describes notation used\nthroughout the book and serve at a reminder of basic concepts in calculus,\nlinear algebra and probability and also introduces some measure theoretic\nterminology, which can be used as a reading guide for the sections that use\nthese tools. The introductory chapters also provide background material on\nmatrix analysis and optimization. The latter chapter provides theoretical\nsupport to many algorithms that are used in the book, including stochastic\ngradient descent, proximal methods, etc. After discussing basic concepts for\nstatistical prediction, the book includes an introduction to reproducing kernel\ntheory and Hilbert space techniques, which are used in many places, before\naddressing the description of various algorithms for supervised statistical\nlearning, including linear methods, support vector machines, decision trees,\nboosting, or neural networks. The subject then switches to generative methods,\nstarting with a chapter that presents sampling methods and an introduction to\nthe theory of Markov chains. The following chapter describe the theory of\ngraphical models, an introduction to variational methods for models with latent\nvariables, and to deep-learning based generative models. The next chapters\nfocus on unsupervised learning methods, for clustering, factor analysis and\nmanifold learning. The final chapter of the book is theory-oriented and\ndiscusses concentration inequalities and generalization bounds.", "AI": {"tldr": "The book covers mathematical foundations and techniques for machine learning algorithms, starting with basics and advancing to supervised, generative, and unsupervised methods, concluding with theoretical bounds.", "motivation": "To provide a comprehensive mathematical foundation for understanding and developing machine learning algorithms.", "method": "Introduces notation and concepts in calculus, linear algebra, probability, and measure theory, followed by matrix analysis, optimization, and statistical prediction. Covers kernel theory, Hilbert spaces, and various learning algorithms.", "result": "A structured guide from basic concepts to advanced topics like supervised learning, generative models, and unsupervised methods.", "conclusion": "The book concludes with theoretical discussions on concentration inequalities and generalization bounds, emphasizing rigorous foundations for machine learning."}}
{"id": "2410.23238", "pdf": "https://arxiv.org/pdf/2410.23238", "abs": "https://arxiv.org/abs/2410.23238", "authors": ["A. A. Saoulis", "D. Piras", "A. Spurio Mancini", "B. Joachimi", "A. M. G. Ferreira"], "title": "Full-waveform earthquake source inversion using simulation-based inference", "categories": ["physics.geo-ph", "cs.LG", "physics.data-an"], "comment": "22 + 11 pages, 11 + 11 figures. Now published in GJI", "summary": "This paper presents a novel framework for full-waveform seismic source\ninversion using simulation-based inference (SBI). Traditional probabilistic\napproaches often rely on simplifying assumptions about data errors, which we\nshow can lead to inaccurate uncertainty quantification. SBI addresses this\nlimitation by building an empirical probabilistic model of the data errors\nusing machine learning models, known as neural density estimators, which can\nthen be integrated into the Bayesian inference framework. We apply the SBI\nframework to point-source moment tensor inversions as well as joint moment\ntensor and time-location inversions. We construct a range of synthetic examples\nto explore the quality of the SBI solutions, as well as to compare the SBI\nresults with standard Gaussian likelihood-based Bayesian inversions. We then\ndemonstrate that under real seismic noise, common Gaussian likelihood\nassumptions for treating full-waveform data yield overconfident posterior\ndistributions that underestimate the moment tensor component uncertainties by\nup to a factor of 3. We contrast this with SBI, which produces well-calibrated\nposteriors that generally agree with the true seismic source parameters, and\noffers an order-of-magnitude reduction in the number of simulations required to\nperform inference compared to standard Monte Carlo techniques. Finally, we\napply our methodology to a pair of moderate magnitude earthquakes in the North\nAtlantic. We utilise seismic waveforms recorded by the recent UPFLOW ocean\nbottom seismometer array as well as by regional land stations in the Azores,\ncomparing full moment tensor and source-time location posteriors between SBI\nand a Gaussian likelihood approach. We find that our adaptation of SBI can be\ndirectly applied to real earthquake sources to efficiently produce high quality\nposterior distributions that significantly improve upon Gaussian likelihood\napproaches.", "AI": {"tldr": "A novel framework for seismic source inversion using simulation-based inference (SBI) improves uncertainty quantification by replacing Gaussian assumptions with neural density estimators, outperforming traditional methods in accuracy and efficiency.", "motivation": "Traditional probabilistic methods for seismic source inversion rely on simplifying assumptions about data errors, leading to inaccurate uncertainty quantification. SBI addresses this by empirically modeling errors using machine learning.", "method": "The SBI framework employs neural density estimators to model data errors, integrating them into Bayesian inference. It is tested on synthetic and real seismic data, comparing results with Gaussian likelihood-based methods.", "result": "SBI produces well-calibrated posteriors, reducing moment tensor uncertainties by up to a factor of 3 compared to Gaussian methods. It also requires fewer simulations than Monte Carlo techniques.", "conclusion": "SBI significantly improves seismic source inversion, offering accurate uncertainty quantification and efficiency, as demonstrated in real-world earthquake data analysis."}}
{"id": "2412.01297", "pdf": "https://arxiv.org/pdf/2412.01297", "abs": "https://arxiv.org/abs/2412.01297", "authors": ["Fengze Xie", "Sizhe Wei", "Yue Song", "Yisong Yue", "Lu Gan"], "title": "Morphological-Symmetry-Equivariant Heterogeneous Graph Neural Network for Robotic Dynamics Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We present a morphological-symmetry-equivariant heterogeneous graph neural\nnetwork, namely MS-HGNN, for robotic dynamics learning, that integrates robotic\nkinematic structures and morphological symmetries into a single graph network.\nThese structural priors are embedded into the learning architecture as\nconstraints, ensuring high generalizability, sample and model efficiency. The\nproposed MS-HGNN is a versatile and general architecture that is applicable to\nvarious multi-body dynamic systems and a wide range of dynamics learning\nproblems. We formally prove the morphological-symmetry-equivariant property of\nour MS-HGNN and validate its effectiveness across multiple quadruped robot\nlearning problems using both real-world and simulated data. Our code is made\npublicly available at https://github.com/lunarlab-gatech/MorphSym-HGNN/.", "AI": {"tldr": "MS-HGNN is a graph neural network for robotic dynamics learning, integrating kinematic structures and morphological symmetries for improved generalizability and efficiency.", "motivation": "To enhance robotic dynamics learning by incorporating structural priors like kinematic structures and morphological symmetries into the learning architecture.", "method": "Develops MS-HGNN, a heterogeneous graph neural network that embeds structural priors as constraints, ensuring symmetry-equivariance.", "result": "Proven symmetry-equivariant property and validated effectiveness in quadruped robot learning using real-world and simulated data.", "conclusion": "MS-HGNN is a versatile and general architecture for multi-body dynamic systems, with public code available for broader use."}}
{"id": "2502.11331", "pdf": "https://arxiv.org/pdf/2502.11331", "abs": "https://arxiv.org/abs/2502.11331", "authors": ["Seok-Jin Kim", "Hongjie Liu", "Molei Liu", "Kaizheng Wang"], "title": "Transfer Learning of CATE with Kernel Ridge Regression", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "The proliferation of data has sparked significant interest in leveraging\nfindings from one study to estimate treatment effects in a different target\npopulation without direct outcome observations. However, the transfer learning\nprocess is frequently hindered by substantial covariate shift and limited\noverlap between (i) the source and target populations, as well as (ii) the\ntreatment and control groups within the source. We propose a novel method for\noverlap-adaptive transfer learning of conditional average treatment effect\n(CATE) using kernel ridge regression (KRR). Our approach involves partitioning\nthe labeled source data into two subsets. The first one is used to train\ncandidate CATE models based on regression adjustment and pseudo-outcomes. An\noptimal model is then selected using the second subset and unlabeled target\ndata, employing another pseudo-outcome-based strategy. We provide a theoretical\njustification for our method through sharp non-asymptotic MSE bounds,\nhighlighting its adaptivity to both weak overlaps and the complexity of CATE\nfunction. Extensive numerical studies confirm that our method achieves superior\nfinite-sample efficiency and adaptability. We conclude by demonstrating the\neffectiveness of our approach using a 401(k) eligibility dataset.", "AI": {"tldr": "A novel method for overlap-adaptive transfer learning of CATE using KRR is proposed, addressing covariate shift and limited overlap issues. It achieves superior efficiency and adaptability, validated by theoretical bounds and numerical studies.", "motivation": "Leveraging findings from one study to estimate treatment effects in a target population is challenging due to covariate shift and limited overlap.", "method": "Partition source data into subsets for training candidate CATE models and selecting an optimal model using pseudo-outcomes and unlabeled target data.", "result": "The method achieves superior finite-sample efficiency and adaptability, supported by theoretical MSE bounds.", "conclusion": "The approach is effective, as demonstrated using a 401(k) eligibility dataset."}}
{"id": "2502.12877", "pdf": "https://arxiv.org/pdf/2502.12877", "abs": "https://arxiv.org/abs/2502.12877", "authors": ["Roberto Battiti", "Mauro Brunato"], "title": "Pushing the Limits of the Reactive Affine Shaker Algorithm to Higher Dimensions", "categories": ["math.NA", "cs.LG", "cs.NA", "G.1.6; I.2.8"], "comment": "Accepted at: the 19th Learning and Intelligent Optimization\n  Conference (LION19), June 15-19 2025, Prague, Czech Republic\n  (https://lion19.org/)", "summary": "Bayesian Optimization (BO) for the minimization of expensive functions of\ncontinuous variables uses all the knowledge acquired from previous samples\n(${\\boldsymbol x}_i$ and $f({\\boldsymbol x}_i)$ values) to build a surrogate\nmodel based on Gaussian processes. The surrogate is then exploited to define\nthe next point to sample, through a careful balance of exploration and\nexploitation. Initially intended for low-dimensional spaces, BO has recently\nbeen modified and used also for very large-dimensional spaces (up to about one\nthousand dimensions).\n  In this paper we consider a much simpler algorithm, called \"Reactive Affine\nShaker\" (RAS). The next sample is always generated with a uniform probability\ndistribution inside a parallelepiped (the \"box\"). At each iteration, the form\nof the box is adapted during the search through an affine transformation, based\nonly on the point $\\boldsymbol x$ position and on the success or failure in\nimproving the function. The function values are therefore not used directly to\nmodify the search area and to generate the next sample. The entire\ndimensionality is kept (no active subspaces).\n  Despite its extreme simplicity and its use of only stochastic local search,\nsurprisingly the produced results are comparable to and not too far from the\nstate-of-the-art results of high-dimensional versions of BO, although with some\nmore function evaluations.\n  An ablation study and an analysis of probability distribution of directions\n(improving steps and prevailing box orientation) in very large-dimensional\nspaces are conducted to understand more about the behavior of RAS and to assess\nthe relative importance of the algorithmic building blocks for the final\nresults.", "AI": {"tldr": "The paper introduces Reactive Affine Shaker (RAS), a simpler alternative to Bayesian Optimization (BO) for high-dimensional spaces, achieving comparable results with more function evaluations.", "motivation": "To address the complexity of BO in high-dimensional spaces by proposing a simpler, stochastic local search method (RAS) that adapts search areas without directly using function values.", "method": "RAS generates samples uniformly inside a parallelepiped (box), adapting its shape via affine transformations based on success/failure of improving the function.", "result": "RAS performs comparably to high-dimensional BO, though requiring more function evaluations. An ablation study analyzes its behavior.", "conclusion": "RAS is a viable, simpler alternative to BO for high-dimensional optimization, with insights from its probability distribution analysis."}}
{"id": "2502.19086", "pdf": "https://arxiv.org/pdf/2502.19086", "abs": "https://arxiv.org/abs/2502.19086", "authors": ["Stefano Damato", "Dario Azzimonti", "Giorgio Corani"], "title": "Forecasting intermittent time series with Gaussian Processes and Tweedie likelihood", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "Under review", "summary": "We adopt Gaussian Processes (GPs) as latent functions for probabilistic\nforecasting of intermittent time series. The model is trained in a Bayesian\nframework that accounts for the uncertainty about the latent function and\nmarginalizes it out when making predictions. We couple the latent GP variable\nwith two types of forecast distributions: the negative binomial (NegBinGP) and\nthe Tweedie distribution (TweedieGP). While the negative binomial has already\nbeen used in forecasting intermittent time series, this is the first time in\nwhich a fully parameterized Tweedie density is used for intermittent time\nseries. We properly evaluate the Tweedie density, which has both a point mass\nat zero and heavy tails, avoiding simplifying assumptions made in existing\nmodels. We test our models on thousands of intermittent count time series.\nResults show that our models provide consistently better probabilistic\nforecasts than the competitors. In particular, TweedieGP obtains the best\nestimates of the highest quantiles, thus showing that it is more flexible than\nNegBinGP.", "AI": {"tldr": "The paper proposes Gaussian Processes (GPs) for probabilistic forecasting of intermittent time series, introducing TweedieGP and NegBinGP models, with TweedieGP outperforming competitors.", "motivation": "To improve probabilistic forecasting for intermittent time series by leveraging GPs and introducing a fully parameterized Tweedie distribution.", "method": "Uses GPs as latent functions in a Bayesian framework, coupling them with negative binomial and Tweedie distributions for forecasting.", "result": "TweedieGP provides better probabilistic forecasts, especially for high quantiles, compared to existing models.", "conclusion": "TweedieGP is more flexible and effective for intermittent time series forecasting than NegBinGP and other competitors."}}
{"id": "2503.18599", "pdf": "https://arxiv.org/pdf/2503.18599", "abs": "https://arxiv.org/abs/2503.18599", "authors": ["Minsu Kim", "Seongmin Hong", "RyeoWook Ko", "Soongyu Choi", "Hunjong Lee", "Junsoo Kim", "Joo-Young Kim", "Jongse Park"], "title": "Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization", "categories": ["cs.AR", "cs.LG"], "comment": "16 pages, 14 figures, and 4 tables", "summary": "Modern Large Language Model serving system batches multiple requests to\nachieve high throughput, while batching attention operations is challenging,\nrendering memory bandwidth a critical bottleneck. The community relies on\nhigh-end GPUs with multiple high-bandwidth memory channels. Unfortunately,\nHBM's high bandwidth often comes at the expense of limited memory capacity,\nwhich reduces core utilization and increases costs. Recent advancements\nenabling longer contexts for LLMs have substantially increased the key-value\ncache size, further intensifying the pressures on memory capacity. The\nliterature has explored KV cache quantization techniques, which commonly use\nlow bitwidth for most values, selectively using higher bitwidth for outlier\nvalues. While this approach helps achieve high accuracy and low bitwidth\nsimultaneously, it comes with the limitation that cost for online outlier\ndetection is excessively high, negating the advantages. We propose Oaken, an\nacceleration solution that achieves high accuracy and high performance\nsimultaneously through co-designing algorithm and hardware. To effectively find\na sweet spot in the accuracy-performance trade-off space of KV cache\nquantization, Oaken employs an online-offline hybrid approach, setting outlier\nthresholds offline, which are then used to determine the quantization scale\nonline. To translate the proposed algorithmic technique into tangible\nperformance gains, Oaken also comes with custom quantization engines and memory\nmanagement units that can be integrated with any LLM accelerators. We built an\nOaken accelerator on top of an LLM accelerator, LPU, and conducted a\ncomprehensive evaluation. Our experiments show that for a batch size of 256,\nOaken achieves up to 1.58x throughput improvement over NVIDIA A100 GPU,\nincurring a minimal accuracy loss of only 0.54\\% on average, compared to\nstate-of-the-art KV cache quantization techniques.", "AI": {"tldr": "Oaken is a co-designed algorithm-hardware solution for KV cache quantization in LLMs, improving throughput by 1.58x over A100 GPU with minimal accuracy loss.", "motivation": "Addressing the memory bandwidth bottleneck and high costs of KV cache quantization in LLM serving systems, exacerbated by longer contexts.", "method": "Oaken uses an online-offline hybrid approach for outlier detection and quantization, with custom hardware engines for performance.", "result": "Achieves 1.58x throughput improvement over A100 GPU with only 0.54% accuracy loss.", "conclusion": "Oaken effectively balances accuracy and performance in KV cache quantization, offering a practical solution for LLM serving."}}
{"id": "2504.05235", "pdf": "https://arxiv.org/pdf/2504.05235", "abs": "https://arxiv.org/abs/2504.05235", "authors": ["Sneh Pandya", "Yuanyuan Yang", "Nicholas Van Alfen", "Jonathan Blazek", "Robin Walters"], "title": "IAEmu: Learning Galaxy Intrinsic Alignment Correlations", "categories": ["astro-ph.CO", "astro-ph.GA", "cs.LG"], "comment": "16 pages, 10 figures, 1 table", "summary": "The intrinsic alignments (IA) of galaxies, a key contaminant in weak lensing\nanalyses, arise from correlations in galaxy shapes driven by tidal interactions\nand galaxy formation processes. Accurate IA modeling is essential for robust\ncosmological inference, but current approaches rely on perturbative methods\nthat break down on nonlinear scales or on expensive simulations. We introduce\nIAEmu, a neural network-based emulator that predicts the galaxy\nposition-position ($\\xi$), position-orientation ($\\omega$), and\norientation-orientation ($\\eta$) correlation functions and their uncertainties\nusing mock catalogs based on the halo occupation distribution (HOD) framework.\nCompared to simulations, IAEmu achieves ~3% average error for $\\xi$ and ~5% for\n$\\omega$, while capturing the stochasticity of $\\eta$ without overfitting. The\nemulator provides both aleatoric and epistemic uncertainties, helping identify\nregions where predictions may be less reliable. We also demonstrate\ngeneralization to non-HOD alignment signals by fitting to IllustrisTNG\nhydrodynamical simulation data. As a fully differentiable neural network, IAEmu\nenables $\\sim$10,000$\\times$ speed-ups in mapping HOD parameters to correlation\nfunctions on GPUs, compared to CPU-based simulations. This acceleration\nfacilitates inverse modeling via gradient-based sampling, making IAEmu a\npowerful surrogate model for galaxy bias and IA studies with direct\napplications to Stage IV weak lensing surveys.", "AI": {"tldr": "IAEmu is a neural network-based emulator for predicting galaxy correlation functions, offering high accuracy and speed for weak lensing studies.", "motivation": "Accurate modeling of intrinsic alignments (IA) is crucial for cosmological inference, but current methods are limited by nonlinear scales or computational cost.", "method": "IAEmu uses neural networks to predict galaxy correlation functions ($\\xi$, $\\omega$, $\\eta$) and their uncertainties, trained on HOD mock catalogs and tested on IllustrisTNG data.", "result": "The emulator achieves ~3% error for $\\xi$, ~5% for $\\omega$, and captures $\\eta$'s stochasticity. It provides uncertainties and speeds up computations by ~10,000x on GPUs.", "conclusion": "IAEmu is a powerful tool for IA studies, enabling efficient inverse modeling and applications in Stage IV weak lensing surveys."}}
{"id": "2504.06566", "pdf": "https://arxiv.org/pdf/2504.06566", "abs": "https://arxiv.org/abs/2504.06566", "authors": ["Minshuo Chen", "Renyuan Xu", "Yumin Xu", "Ruixun Zhang"], "title": "Diffusion Factor Models: Generating High-Dimensional Returns with Factor Structure", "categories": ["q-fin.ST", "cs.LG", "q-fin.MF"], "comment": null, "summary": "Financial scenario simulation is essential for risk management and portfolio\noptimization, yet it remains challenging especially in high-dimensional and\nsmall data settings common in finance. We propose a diffusion factor model that\nintegrates latent factor structure into generative diffusion processes,\nbridging econometrics with modern generative AI to address the challenges of\nthe curse of dimensionality and data scarcity in financial simulation. By\nexploiting the low-dimensional factor structure inherent in asset returns, we\ndecompose the score function--a key component in diffusion models--using\ntime-varying orthogonal projections, and this decomposition is incorporated\ninto the design of neural network architectures. We derive rigorous statistical\nguarantees, establishing nonasymptotic error bounds for both score estimation\nat O(d^{5/2} n^{-2/(k+5)}) and generated distribution at O(d^{5/4}\nn^{-1/2(k+5)}), primarily driven by the intrinsic factor dimension k rather\nthan the number of assets d, surpassing the dimension-dependent limits in the\nclassical nonparametric statistics literature and making the framework viable\nfor markets with thousands of assets. Numerical studies confirm superior\nperformance in latent subspace recovery under small data regimes. Empirical\nanalysis demonstrates the economic significance of our framework in\nconstructing mean-variance optimal portfolios and factor portfolios. This work\npresents the first theoretical integration of factor structure with diffusion\nmodels, offering a principled approach for high-dimensional financial\nsimulation with limited data. Our code is available at\nhttps://github.com/xymmmm00/diffusion_factor_model.", "AI": {"tldr": "A diffusion factor model integrates latent factors into generative diffusion processes to tackle high-dimensional financial simulation challenges, outperforming classical methods with theoretical guarantees.", "motivation": "Addressing the curse of dimensionality and data scarcity in financial scenario simulation, especially for risk management and portfolio optimization.", "method": "Proposes a diffusion factor model combining latent factor structure with generative diffusion processes, using time-varying orthogonal projections and neural networks.", "result": "Achieves superior performance in latent subspace recovery and mean-variance portfolio optimization, with nonasymptotic error bounds favoring intrinsic factor dimension over asset count.", "conclusion": "The first theoretical integration of factor structure with diffusion models, enabling viable high-dimensional financial simulation with limited data."}}
{"id": "2504.11436", "pdf": "https://arxiv.org/pdf/2504.11436", "abs": "https://arxiv.org/abs/2504.11436", "authors": ["Eleanor Wiske Dillon", "Sonia Jaffe", "Nicole Immorlica", "Christopher T. Stanton"], "title": "Shifting Work Patterns with Generative AI", "categories": ["econ.GN", "cs.LG", "q-fin.EC"], "comment": null, "summary": "We present evidence on how generative AI changes the work patterns of\nknowledge workers using data from a 6-month-long, cross-industry, randomized\nfield experiment. Half of the 7,137 workers in the study received access to a\ngenerative AI tool integrated into the applications they already used for\nemails, document creation, and meetings. We find that access to the AI tool\nduring the first year of its release primarily impacted behaviors that workers\ncould change independently and not behaviors that require coordination to\nchange: workers who used the tool in more than half of the sample weeks spent\n3.6 fewer hours, or 31% less time on email each week (intent to treat estimate\nis 1.3 hours) and completed documents moderately faster, but did not\nsignificantly change time spent in meetings.", "AI": {"tldr": "Generative AI reduces email time by 31% and speeds up document creation, but doesn't affect meeting time.", "motivation": "To study how generative AI impacts knowledge workers' work patterns.", "method": "A 6-month randomized field experiment with 7,137 workers, half given AI tool access.", "result": "AI users spent 3.6 fewer hours on email weekly and completed documents faster, but meeting time unchanged.", "conclusion": "Generative AI independently changes email and document work, but not coordinated tasks like meetings."}}
