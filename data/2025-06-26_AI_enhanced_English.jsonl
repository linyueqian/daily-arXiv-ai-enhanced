{"id": "2506.19952", "pdf": "https://arxiv.org/pdf/2506.19952", "abs": "https://arxiv.org/abs/2506.19952", "authors": ["Deepon Halder", "Thanmay Jayakumar", "Raj Dabre"], "title": "CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs), despite their ability to perform few-shot\nmachine translation (MT), often lag behind dedicated MT systems trained on\nparallel corpora, which are crucial for high quality machine translation (MT).\nHowever, parallel corpora are often scarce or non-existent for low-resource\nlanguages. In this paper, we propose CycleDistill, a bootstrapping approach\nleveraging LLMs and few-shot translation to obtain high-quality MT systems.\nCycleDistill involves iteratively generating synthetic parallel corpora from\nmonolingual corpora via zero- or few-shot MT, which is then used to fine-tune\nthe model that was used for generating said data for MT. CycleDistill does not\nneed parallel corpora beyond 1 to 4 few-shot examples, and in our experiments\nfocusing on three Indian languages, by relying solely on monolingual corpora,\nit can achieve high-quality machine translation, improving upon a few-shot\nbaseline model by over 20-30 chrF points on average in the first iteration. We\nalso study the effect of leveraging softmax activations during the distillation\nprocess and observe mild improvements in translation quality.", "AI": {"tldr": "CycleDistill leverages LLMs and few-shot translation to create synthetic parallel corpora for high-quality MT without needing extensive parallel data.", "motivation": "Parallel corpora are scarce for low-resource languages, limiting MT quality. CycleDistill aims to overcome this by using LLMs and monolingual data.", "method": "CycleDistill iteratively generates synthetic parallel corpora via few-shot MT, fine-tuning the model on this data. It uses minimal parallel examples (1-4).", "result": "Improves few-shot baseline by 20-30 chrF points on average for three Indian languages in the first iteration. Softmax activations offer mild improvements.", "conclusion": "CycleDistill effectively boosts MT quality for low-resource languages using monolingual data and minimal parallel examples."}}
{"id": "2506.19967", "pdf": "https://arxiv.org/pdf/2506.19967", "abs": "https://arxiv.org/abs/2506.19967", "authors": ["Travis Thompson", "Seung-Hwan Lim", "Paul Liu", "Ruoying He", "Dongkuan Xu"], "title": "Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved impressive capabilities in\nlanguage understanding and generation, yet they continue to underperform on\nknowledge-intensive reasoning tasks due to limited access to structured context\nand multi-hop information. Retrieval-Augmented Generation (RAG) partially\nmitigates this by grounding generation in retrieved context, but conventional\nRAG and GraphRAG methods often fail to capture relational structure across\nnodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel\nframework that enhances LLM-based graph reasoning by applying inference-time\ncompute scaling. Our method combines sequential scaling with deep\nchain-of-thought graph traversal, and parallel scaling with majority voting\nover sampled trajectories within an interleaved reasoning-execution loop.\nExperiments on the GRBench benchmark demonstrate that our approach\nsignificantly improves multi-hop question answering performance, achieving\nsubstantial gains over both traditional GraphRAG and prior graph traversal\nbaselines. These findings suggest that inference-time scaling is a practical\nand architecture-agnostic solution for structured knowledge reasoning with LLMs", "AI": {"tldr": "Inference-Scaled GraphRAG improves LLM reasoning on knowledge graphs by combining sequential and parallel scaling, outperforming traditional methods.", "motivation": "LLMs underperform on knowledge-intensive tasks due to limited access to structured context and multi-hop information. Existing RAG methods fail to capture relational structures in knowledge graphs.", "method": "Introduces Inference-Scaled GraphRAG, combining sequential scaling (deep chain-of-thought traversal) and parallel scaling (majority voting over sampled trajectories) in an interleaved reasoning-execution loop.", "result": "Significantly improves multi-hop question answering on GRBench, outperforming traditional GraphRAG and prior baselines.", "conclusion": "Inference-time scaling is a practical, architecture-agnostic solution for structured knowledge reasoning with LLMs."}}
{"id": "2506.19998", "pdf": "https://arxiv.org/pdf/2506.19998", "abs": "https://arxiv.org/abs/2506.19998", "authors": ["Xinyi Ni", "Haonan Jian", "Qiuyang Wang", "Vedanshi Chetan Shah", "Pengyu Hong"], "title": "Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation", "categories": ["cs.CL"], "comment": null, "summary": "REST APIs play important roles in enriching the action space of web agents,\nyet most API-based agents rely on curated and uniform toolsets that do not\nreflect the complexity of real-world APIs. Building tool-using agents for\narbitrary domains remains a major challenge, as it requires reading\nunstructured API documentation, testing APIs and inferring correct parameters.\nWe propose Doc2Agent, a scalable pipeline to build agents that can call\nPython-based tools generated from API documentation. Doc2Agent generates\nexecutable tools from API documentations and iteratively refines them using a\ncode agent. We evaluate our approach on real-world APIs, WebArena APIs, and\nresearch APIs, producing validated tools. We achieved a 55\\% relative\nperformance improvement with 90\\% lower cost compared to direct API calling on\nWebArena benchmark. A domain-specific agent built for glycomaterial science\nfurther demonstrates the pipeline's adaptability to complex, knowledge-rich\ntasks. Doc2Agent offers a generalizable solution for building tool agents from\nunstructured API documentation at scale.", "AI": {"tldr": "Doc2Agent is a scalable pipeline for creating agents that generate and refine executable tools from unstructured API documentation, improving performance and reducing costs.", "motivation": "Most API-based agents rely on curated toolsets, failing to address the complexity of real-world APIs. Building adaptable agents for arbitrary domains is challenging due to unstructured documentation and parameter inference.", "method": "Doc2Agent generates executable tools from API documentation and refines them iteratively using a code agent. It is evaluated on real-world, WebArena, and research APIs.", "result": "Achieved a 55% performance improvement with 90% lower cost on WebArena. Demonstrated adaptability in glycomaterial science.", "conclusion": "Doc2Agent provides a scalable, generalizable solution for building tool agents from unstructured API documentation."}}
{"id": "2506.19999", "pdf": "https://arxiv.org/pdf/2506.19999", "abs": "https://arxiv.org/abs/2506.19999", "authors": ["Francesco Ignazio Re", "Andreas Opedal", "Glib Manaiev", "Mario Giulianelli", "Ryan Cotterell"], "title": "A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior", "categories": ["cs.LG", "cs.CL", "q-bio.NC"], "comment": "ACL 2025", "summary": "Reading is a process that unfolds across space and time, alternating between\nfixations where a reader focuses on a specific point in space, and saccades\nwhere a reader rapidly shifts their focus to a new point. An ansatz of\npsycholinguistics is that modeling a reader's fixations and saccades yields\ninsight into their online sentence processing. However, standard approaches to\nsuch modeling rely on aggregated eye-tracking measurements and models that\nimpose strong assumptions, ignoring much of the spatio-temporal dynamics that\noccur during reading. In this paper, we propose a more general probabilistic\nmodel of reading behavior, based on a marked spatio-temporal point process,\nthat captures not only how long fixations last, but also where they land in\nspace and when they take place in time. The saccades are modeled using a Hawkes\nprocess, which captures how each fixation excites the probability of a new\nfixation occurring near it in time and space. The duration time of fixation\nevents is modeled as a function of fixation-specific predictors convolved\nacross time, thus capturing spillover effects. Empirically, our Hawkes process\nmodel exhibits a better fit to human saccades than baselines. With respect to\nfixation durations, we observe that incorporating contextual surprisal as a\npredictor results in only a marginal improvement in the model's predictive\naccuracy. This finding suggests that surprisal theory struggles to explain\nfine-grained eye movements.", "AI": {"tldr": "The paper proposes a probabilistic model for reading behavior using a marked spatio-temporal point process, improving on standard methods by capturing dynamic fixations and saccades with a Hawkes process.", "motivation": "Standard eye-tracking models rely on aggregated data and strong assumptions, missing spatio-temporal dynamics. This work aims to better model reading behavior.", "method": "A marked spatio-temporal point process models fixations and saccades, with saccades modeled via a Hawkes process and fixation durations incorporating contextual predictors.", "result": "The Hawkes process model fits human saccades better than baselines. Contextual surprisal marginally improves fixation duration predictions, suggesting surprisal theory's limited explanatory power for fine-grained eye movements.", "conclusion": "The proposed model captures reading dynamics more effectively, though surprisal theory's role in explaining fixation durations remains limited."}}
{"id": "2506.19875", "pdf": "https://arxiv.org/pdf/2506.19875", "abs": "https://arxiv.org/abs/2506.19875", "authors": ["Taous Iatariene", "Can Cui", "Alexandre Gu\u00e9rin", "Romain Serizel"], "title": "Speaker Embeddings to Improve Tracking of Intermittent and Moving Speakers", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "33rd European Signal Processing Conference (EUSIPCO 2025), Sep 2025,\n  Palerme (Italie), Italy", "summary": "Speaker tracking methods often rely on spatial observations to assign\ncoherent track identities over time. This raises limits in scenarios with\nintermittent and moving speakers, i.e., speakers that may change position when\nthey are inactive, thus leading to discontinuous spatial trajectories. This\npaper proposes to investigate the use of speaker embeddings, in a simple\nsolution to this issue. We propose to perform identity reassignment\npost-tracking, using speaker embeddings. We leverage trajectory-related\ninformation provided by an initial tracking step and multichannel audio signal.\nBeamforming is used to enhance the signal towards the speakers' positions in\norder to compute speaker embeddings. These are then used to assign new track\nidentities based on an enrollment pool. We evaluate the performance of the\nproposed speaker embedding-based identity reassignment method on a dataset\nwhere speakers change position during inactivity periods. Results show that it\nconsistently improves the identity assignment performance of neural and\nstandard tracking systems. In particular, we study the impact of beamforming\nand input duration for embedding extraction.", "AI": {"tldr": "The paper proposes using speaker embeddings for identity reassignment in speaker tracking, improving performance in scenarios with intermittent and moving speakers.", "motivation": "Current speaker tracking methods struggle with discontinuous spatial trajectories caused by intermittent and moving speakers.", "method": "The method involves post-tracking identity reassignment using speaker embeddings, leveraging trajectory-related information and beamforming-enhanced audio signals.", "result": "The proposed method improves identity assignment performance for neural and standard tracking systems, especially when speakers change positions during inactivity.", "conclusion": "Speaker embeddings, combined with beamforming, effectively address identity reassignment challenges in dynamic speaker tracking scenarios."}}
{"id": "2506.20039", "pdf": "https://arxiv.org/pdf/2506.20039", "abs": "https://arxiv.org/abs/2506.20039", "authors": ["Koorosh Moslemi", "Chi-Guhn Lee"], "title": "Learning Bilateral Team Formation in Cooperative Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "comment": "Accepted to the 2nd Coordination and Cooperation in Multi-Agent\n  Reinforcement Learning (CoCoMARL) Workshop at RLC 2025", "summary": "Team formation and the dynamics of team-based learning have drawn significant\ninterest in the context of Multi-Agent Reinforcement Learning (MARL). However,\nexisting studies primarily focus on unilateral groupings, predefined teams, or\nfixed-population settings, leaving the effects of algorithmic bilateral\ngrouping choices in dynamic populations underexplored. To address this gap, we\nintroduce a framework for learning two-sided team formation in dynamic\nmulti-agent systems. Through this study, we gain insight into what algorithmic\nproperties in bilateral team formation influence policy performance and\ngeneralization. We validate our approach using widely adopted multi-agent\nscenarios, demonstrating competitive performance and improved generalization in\nmost scenarios.", "AI": {"tldr": "A framework for learning two-sided team formation in dynamic multi-agent systems is introduced, addressing gaps in existing MARL studies.", "motivation": "Existing MARL studies focus on unilateral or predefined teams, leaving bilateral grouping in dynamic populations underexplored.", "method": "A framework for learning two-sided team formation in dynamic multi-agent systems is proposed.", "result": "The approach shows competitive performance and improved generalization in widely adopted multi-agent scenarios.", "conclusion": "The study provides insights into algorithmic properties influencing policy performance and generalization in bilateral team formation."}}
{"id": "2506.20609", "pdf": "https://arxiv.org/pdf/2506.20609", "abs": "https://arxiv.org/abs/2506.20609", "authors": ["Ankit Shah", "Rita Singh", "Bhiksha Raj", "Alexander Hauptmann"], "title": "Deciphering GunType Hierarchy through Acoustic Analysis of Gunshot Recordings", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "comment": "4 pages + 1 References", "summary": "The escalating rates of gun-related violence and mass shootings represent a\nsignificant threat to public safety. Timely and accurate information for law\nenforcement agencies is crucial in mitigating these incidents. Current\ncommercial gunshot detection systems, while effective, often come with\nprohibitive costs. This research explores a cost-effective alternative by\nleveraging acoustic analysis of gunshot recordings, potentially obtainable from\nubiquitous devices like cell phones, to not only detect gunshots but also\nclassify the type of firearm used. This paper details a study on deciphering\ngun type hierarchies using a curated dataset of 3459 recordings. We investigate\nthe fundamental acoustic characteristics of gunshots, including muzzle blasts\nand shockwaves, which vary based on firearm type, ammunition, and shooting\ndirection. We propose and evaluate machine learning frameworks, including\nSupport Vector Machines (SVMs) as a baseline and a more advanced Convolutional\nNeural Network (CNN) architecture for joint gunshot detection and gun type\nclassification. Results indicate that our deep learning approach achieves a\nmean average precision (mAP) of 0.58 on clean labeled data, outperforming the\nSVM baseline (mAP 0.39). Challenges related to data quality, environmental\nnoise, and the generalization capabilities when using noisy web-sourced data\n(mAP 0.35) are also discussed. The long-term vision is to develop a highly\naccurate, real-time system deployable on common recording devices,\nsignificantly reducing detection costs and providing critical intelligence to\nfirst responders.", "AI": {"tldr": "A cost-effective acoustic analysis method for gunshot detection and firearm classification using machine learning, outperforming traditional methods but facing challenges with noisy data.", "motivation": "Addressing the high costs of commercial gunshot detection systems and the need for timely, accurate information to mitigate gun-related violence.", "method": "Leveraging acoustic analysis of gunshot recordings, using SVMs and CNNs for detection and classification, tested on a dataset of 3459 recordings.", "result": "CNN achieved mAP 0.58 on clean data, outperforming SVM (mAP 0.39), but performance dropped to mAP 0.35 with noisy data.", "conclusion": "The approach shows promise for real-time, low-cost deployment on common devices but requires improvements in handling noisy environments."}}
{"id": "2506.19975", "pdf": "https://arxiv.org/pdf/2506.19975", "abs": "https://arxiv.org/abs/2506.19975", "authors": ["Hang Zhang", "Yuxi Zhang", "Jiazheng Wang", "Xiang Chen", "Renjiu Hu", "Xin Tian", "Gaolei Li", "Min Liu"], "title": "VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration", "categories": ["eess.IV", "cs.AI", "cs.CV", "eess.SP"], "comment": "Accepted for publication at MICCAI 2025", "summary": "Recent developments in neural networks have improved deformable image\nregistration (DIR) by amortizing iterative optimization, enabling fast and\naccurate DIR results. However, learning-based methods often face challenges\nwith limited training data, large deformations, and tend to underperform\ncompared to iterative approaches when label supervision is unavailable. While\niterative methods can achieve higher accuracy in such scenarios, they are\nconsiderably slower than learning-based methods. To address these limitations,\nwe propose VoxelOpt, a discrete optimization-based DIR framework that combines\nthe strengths of learning-based and iterative methods to achieve a better\nbalance between registration accuracy and runtime. VoxelOpt uses displacement\nentropy from local cost volumes to measure displacement signal strength at each\nvoxel, which differs from earlier approaches in three key aspects. First, it\nintroduces voxel-wise adaptive message passing, where voxels with lower entropy\nreceives less influence from their neighbors. Second, it employs a multi-level\nimage pyramid with 27-neighbor cost volumes at each level, avoiding exponential\ncomplexity growth. Third, it replaces hand-crafted features or contrastive\nlearning with a pretrained foundational segmentation model for feature\nextraction. In abdominal CT registration, these changes allow VoxelOpt to\noutperform leading iterative in both efficiency and accuracy, while matching\nstate-of-the-art learning-based methods trained with label supervision. The\nsource code will be available at https://github.com/tinymilky/VoxelOpt", "AI": {"tldr": "VoxelOpt combines learning-based and iterative methods for deformable image registration, balancing accuracy and speed using displacement entropy and adaptive message passing.", "motivation": "Addressing the limitations of learning-based methods (limited data, large deformations) and iterative methods (slow runtime) in deformable image registration.", "method": "Uses displacement entropy for voxel-wise adaptive message passing, multi-level image pyramids, and a pretrained segmentation model for feature extraction.", "result": "Outperforms iterative methods in efficiency and accuracy, matches learning-based methods with label supervision in abdominal CT registration.", "conclusion": "VoxelOpt achieves a better balance between accuracy and runtime, offering a promising solution for deformable image registration."}}
{"id": "2506.19939", "pdf": "https://arxiv.org/pdf/2506.19939", "abs": "https://arxiv.org/abs/2506.19939", "authors": ["Aryan Singh Dalal", "Sidharth Rai", "Rahul Singh", "Treman Singh Kaloya", "Rahul Harsha Cheppally", "Ajay Sharda"], "title": "Computer Vision based Automated Quantification of Agricultural Sprayers Boom Displacement", "categories": ["cs.CV"], "comment": "Under publication process for COMPAG", "summary": "Application rate errors when using self-propelled agricultural sprayers for\nagricultural production remain a concern. Among other factors, spray boom\ninstability is one of the major contributors to application errors. Spray\nbooms' width of 38m, combined with 30 kph driving speeds, varying terrain, and\nmachine dynamics when maneuvering complex field boundaries, make controls of\nthese booms very complex. However, there is no quantitative knowledge on the\nextent of boom movement to systematically develop a solution that might include\nboom designs and responsive boom control systems. Therefore, this study was\nconducted to develop an automated computer vision system to quantify the boom\nmovement of various agricultural sprayers. A computer vision system was\ndeveloped to track a target on the edge of the sprayer boom in real time. YOLO\nV7, V8, and V11 neural network models were trained to track the boom's\nmovements in field operations to quantify effective displacement in the\nvertical and transverse directions. An inclinometer sensor was mounted on the\nboom to capture boom angles and validate the neural network model output. The\nresults showed that the model could detect the target with more than 90 percent\naccuracy, and distance estimates of the target on the boom were within 0.026 m\nof the inclinometer sensor data. This system can quantify the boom movement on\nthe current sprayer and potentially on any other sprayer with minor\nmodifications. The data can be used to make design improvements to make sprayer\nbooms more stable and achieve greater application accuracy.", "AI": {"tldr": "A computer vision system using YOLO models was developed to quantify spray boom movement in agricultural sprayers, achieving high accuracy and potential for design improvements.", "motivation": "Spray boom instability causes application errors in agricultural sprayers, but there's no quantitative data on boom movement to guide solutions.", "method": "A computer vision system tracked a target on the boom edge using YOLO V7, V8, and V11 models, validated by an inclinometer sensor.", "result": "The model detected targets with >90% accuracy and estimated distances within 0.026 m of sensor data.", "conclusion": "The system effectively quantifies boom movement, aiding future design improvements for stability and application accuracy."}}
{"id": "2506.19923", "pdf": "https://arxiv.org/pdf/2506.19923", "abs": "https://arxiv.org/abs/2506.19923", "authors": ["Kaito Baba", "Chaoran Liu", "Shuhei Kurita", "Akiyoshi Sannai"], "title": "Prover Agent: An Agent-based Framework for Formal Mathematical Proofs", "categories": ["cs.AI", "cs.LG"], "comment": "22 pages, 2 figures", "summary": "We present Prover Agent, a novel AI agent for automated theorem proving that\nintegrates large language models (LLMs) with a formal proof assistant, Lean.\nProver Agent coordinates an informal reasoning LLM, a formal prover model, and\nfeedback from Lean while also generating auxiliary lemmas to assist in\ndiscovering the overall proof strategy. It achieves an 86.1% success rate on\nthe MiniF2F benchmark, establishing a new state-of-the-art among methods using\nsmall language models (SLMs) with a much lower sample budget than previous\napproaches. We also present case studies illustrating how these generated\nlemmas contribute to solving challenging problems.", "AI": {"tldr": "Prover Agent combines LLMs and Lean for automated theorem proving, achieving 86.1% success on MiniF2F with fewer samples.", "motivation": "To improve automated theorem proving by integrating LLMs with formal proof assistants like Lean.", "method": "Coordinates an informal reasoning LLM, a formal prover model, and Lean feedback, while generating auxiliary lemmas.", "result": "Achieves 86.1% success rate on MiniF2F, outperforming SLM-based methods with lower sample usage.", "conclusion": "Prover Agent sets a new benchmark for automated theorem proving efficiency and effectiveness."}}
{"id": "2506.19882", "pdf": "https://arxiv.org/pdf/2506.19882", "abs": "https://arxiv.org/abs/2506.19882", "authors": ["Rylan Schaeffer", "Joshua Kazdan", "Yegor Denisov-Blanch", "Brando Miranda", "Matthias Gerstgrasser", "Susan Zhang", "Andreas Haupt", "Isha Gupta", "Elyas Obbad", "Jesse Dodge", "Jessica Zosa Forde", "Koustuv Sinha", "Francesco Orabona", "Sanmi Koyejo", "David Donoho"], "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Science progresses by iteratively advancing and correcting humanity's\nunderstanding of the world. In machine learning (ML) research, rapid\nadvancements have led to an explosion of publications, but have also led to\nmisleading, incorrect, flawed or perhaps even fraudulent studies being accepted\nand sometimes highlighted at ML conferences due to the fallibility of peer\nreview. While such mistakes are understandable, ML conferences do not offer\nrobust processes to help the field systematically correct when such errors are\nmade.This position paper argues that ML conferences should establish a\ndedicated \"Refutations and Critiques\" (R & C) Track. This R & C Track would\nprovide a high-profile, reputable platform to support vital research that\ncritically challenges prior research, thereby fostering a dynamic\nself-correcting research ecosystem. We discuss key considerations including\ntrack design, review principles, potential pitfalls, and provide an\nillustrative example submission concerning a recent ICLR 2025 Oral. We conclude\nthat ML conferences should create official, reputable mechanisms to help ML\nresearch self-correct.", "AI": {"tldr": "The paper proposes a 'Refutations and Critiques' (R & C) Track at ML conferences to systematically correct errors in research, enhancing the field's self-correcting nature.", "motivation": "Rapid advancements in ML research have led to flawed or incorrect studies being accepted due to peer review fallibility, necessitating a mechanism for correction.", "method": "The paper suggests designing an R & C Track with specific review principles, addressing potential pitfalls, and provides an example submission.", "result": "The proposed R & C Track would offer a reputable platform to critique and refute prior research, fostering a self-correcting ecosystem.", "conclusion": "ML conferences should implement official mechanisms like the R & C Track to improve research integrity and correction."}}
{"id": "2506.20073", "pdf": "https://arxiv.org/pdf/2506.20073", "abs": "https://arxiv.org/abs/2506.20073", "authors": ["Kethmi Hirushini Hettige", "Jiahao Ji", "Cheng Long", "Shili Xiang", "Gao Cong", "Jingyuan Wang"], "title": "A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Spatio-temporal data mining plays a pivotal role in informed decision making\nacross diverse domains. However, existing models are often restricted to narrow\ntasks, lacking the capacity for multi-task inference and complex long-form\nreasoning that require generation of in-depth, explanatory outputs. These\nlimitations restrict their applicability to real-world, multi-faceted decision\nscenarios. In this work, we introduce STReason, a novel framework that\nintegrates the reasoning strengths of large language models (LLMs) with the\nanalytical capabilities of spatio-temporal models for multi-task inference and\nexecution. Without requiring task-specific finetuning, STReason leverages\nin-context learning to decompose complex natural language queries into modular,\ninterpretable programs, which are then systematically executed to generate both\nsolutions and detailed rationales. To facilitate rigorous evaluation, we\nconstruct a new benchmark dataset and propose a unified evaluation framework\nwith metrics specifically designed for long-form spatio-temporal reasoning.\nExperimental results show that STReason significantly outperforms advanced LLM\nbaselines across all metrics, particularly excelling in complex,\nreasoning-intensive spatio-temporal scenarios. Human evaluations further\nvalidate STReason's credibility and practical utility, demonstrating its\npotential to reduce expert workload and broaden the applicability to real-world\nspatio-temporal tasks. We believe STReason provides a promising direction for\ndeveloping more capable and generalizable spatio-temporal reasoning systems.", "AI": {"tldr": "STReason integrates LLMs with spatio-temporal models for multi-task inference, outperforming baselines in complex reasoning tasks.", "motivation": "Existing models lack multi-task inference and explanatory outputs, limiting real-world applicability.", "method": "STReason uses in-context learning to decompose queries into modular programs, generating solutions and rationales without task-specific finetuning.", "result": "STReason outperforms advanced LLM baselines, excels in reasoning-intensive scenarios, and reduces expert workload.", "conclusion": "STReason offers a promising direction for generalizable spatio-temporal reasoning systems."}}
{"id": "2506.19887", "pdf": "https://arxiv.org/pdf/2506.19887", "abs": "https://arxiv.org/abs/2506.19887", "authors": ["Hyo Jin Jon", "Longbin Jin", "Hyuntaek Jung", "Hyunseo Kim", "Donghun Min", "Eun Yi Kim"], "title": "MATER: Multi-level Acoustic and Textual Emotion Representation for Interpretable Speech Emotion Recognition", "categories": ["eess.AS", "cs.AI", "cs.SD", "68T10"], "comment": "5 pages, 4 figures, 2 tables, 1 algorithm, Accepted to INTERSPEECH\n  2025", "summary": "This paper presents our contributions to the Speech Emotion Recognition in\nNaturalistic Conditions (SERNC) Challenge, where we address categorical emotion\nrecognition and emotional attribute prediction. To handle the complexities of\nnatural speech, including intra- and inter-subject variability, we propose\nMulti-level Acoustic-Textual Emotion Representation (MATER), a novel\nhierarchical framework that integrates acoustic and textual features at the\nword, utterance, and embedding levels. By fusing low-level lexical and acoustic\ncues with high-level contextualized representations, MATER effectively captures\nboth fine-grained prosodic variations and semantic nuances. Additionally, we\nintroduce an uncertainty-aware ensemble strategy to mitigate annotator\ninconsistencies, improving robustness in ambiguous emotional expressions. MATER\nranks fourth in both tasks with a Macro-F1 of 41.01% and an average CCC of\n0.5928, securing second place in valence prediction with an impressive CCC of\n0.6941.", "AI": {"tldr": "The paper introduces MATER, a hierarchical framework for speech emotion recognition, combining acoustic and textual features at multiple levels. It also uses an uncertainty-aware ensemble to handle annotator inconsistencies, achieving competitive results in the SERNC Challenge.", "motivation": "To address the challenges of natural speech emotion recognition, including variability and annotator inconsistencies, by integrating multi-level acoustic and textual features.", "method": "Proposes MATER, a hierarchical framework fusing acoustic and textual features at word, utterance, and embedding levels, and introduces an uncertainty-aware ensemble strategy.", "result": "MATER ranks fourth in categorical emotion recognition (Macro-F1: 41.01%) and second in valence prediction (CCC: 0.6941).", "conclusion": "MATER effectively captures emotional nuances in natural speech and improves robustness, demonstrating strong performance in the SERNC Challenge."}}
{"id": "2506.20400", "pdf": "https://arxiv.org/pdf/2506.20400", "abs": "https://arxiv.org/abs/2506.20400", "authors": ["Kristoffer Christensen", "Bo N\u00f8rregaard J\u00f8rgensen", "Zheng Grace Ma"], "title": "A Visualization Framework for Exploring Multi-Agent-Based Simulations Case Study of an Electric Vehicle Home Charging Ecosystem", "categories": ["cs.MA", "cs.CE", "cs.HC", "cs.SY", "eess.SY"], "comment": null, "summary": "Multi-agent-based simulations (MABS) of electric vehicle (EV) home charging\necosystems generate large, complex, and stochastic time-series datasets that\ncapture interactions between households, grid infrastructure, and energy\nmarkets. These interactions can lead to unexpected system-level events, such as\ntransformer overloads or consumer dissatisfaction, that are difficult to detect\nand explain through static post-processing. This paper presents a modular,\nPython-based dashboard framework, built using Dash by Plotly, that enables\nefficient, multi-level exploration and root-cause analysis of emergent behavior\nin MABS outputs. The system features three coordinated views (System Overview,\nSystem Analysis, and Consumer Analysis), each offering high-resolution\nvisualizations such as time-series plots, spatial heatmaps, and agent-specific\ndrill-down tools. A case study simulating full EV adoption with smart charging\nin a Danish residential network demonstrates how the dashboard supports rapid\nidentification and contextual explanation of anomalies, including clustered\ntransformer overloads and time-dependent charging failures. The framework\nfacilitates actionable insight generation for researchers and distribution\nsystem operators, and its architecture is adaptable to other distributed energy\nresources and complex energy systems.", "AI": {"tldr": "A Python-based dashboard framework for analyzing multi-agent simulations of EV home charging, enabling root-cause analysis of system-level anomalies.", "motivation": "To address the challenge of detecting and explaining unexpected events in complex EV charging simulations.", "method": "Developed a modular dashboard using Dash by Plotly with three coordinated views for multi-level exploration.", "result": "Demonstrated effectiveness in identifying anomalies like transformer overloads in a Danish residential network case study.", "conclusion": "The framework provides actionable insights and is adaptable to other energy systems."}}
{"id": "2506.20190", "pdf": "https://arxiv.org/pdf/2506.20190", "abs": "https://arxiv.org/abs/2506.20190", "authors": ["Marie Kune\u0161ov\u00e1", "Zden\u011bk Hanzl\u00ed\u010dek", "Jind\u0159ich Matou\u0161ek"], "title": "An Exploration of ECAPA-TDNN and x-vector Speaker Representations in Zero-shot Multi-speaker TTS", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted to TSD 2025", "summary": "Zero-shot multi-speaker text-to-speech (TTS) systems rely on speaker\nembeddings to synthesize speech in the voice of an unseen speaker, using only a\nshort reference utterance. While many speaker embeddings have been developed\nfor speaker recognition, their relative effectiveness in zero-shot TTS remains\nunderexplored. In this work, we employ a YourTTS-based TTS system to compare\nthree different speaker encoders - YourTTS's original H/ASP encoder, x-vector\nembeddings, and ECAPA-TDNN embeddings - within an otherwise fixed zero-shot TTS\nframework. All models were trained on the same dataset of Czech read speech and\nevaluated on 24 out-of-domain target speakers using both subjective and\nobjective methods. The subjective evaluation was conducted via a listening test\nfocused on speaker similarity, while the objective evaluation measured cosine\ndistances between speaker embeddings extracted from synthesized and real\nutterances. Across both evaluations, the original H/ASP encoder consistently\noutperformed the alternatives, with ECAPA-TDNN showing better results than\nx-vectors. These findings suggest that, despite the popularity of ECAPA-TDNN in\nspeaker recognition, it does not necessarily offer improvements for speaker\nsimilarity in zero-shot TTS in this configuration. Our study highlights the\nimportance of empirical evaluation when reusing speaker recognition embeddings\nin TTS and provides a framework for additional future comparisons.", "AI": {"tldr": "The paper compares three speaker encoders (H/ASP, x-vector, ECAPA-TDNN) in zero-shot TTS, finding H/ASP outperforms others in speaker similarity.", "motivation": "To explore the effectiveness of different speaker embeddings (developed for speaker recognition) in zero-shot TTS, which remains underexplored.", "method": "Used a YourTTS-based TTS system to compare H/ASP, x-vector, and ECAPA-TDNN embeddings on Czech read speech, evaluated subjectively (listening test) and objectively (cosine distances).", "result": "H/ASP encoder consistently outperformed ECAPA-TDNN and x-vectors in speaker similarity, despite ECAPA-TDNN's popularity in speaker recognition.", "conclusion": "Empirical evaluation is crucial when reusing speaker recognition embeddings in TTS; H/ASP is more effective for zero-shot TTS in this setup."}}
{"id": "2506.20200", "pdf": "https://arxiv.org/pdf/2506.20200", "abs": "https://arxiv.org/abs/2506.20200", "authors": ["Siqiao Li", "Chen Hui", "Wei Zhang", "Rui Liang", "Chenyue Song", "Feng Jiang", "Haiqi Zhu", "Zhixuan Li", "Hong Huang", "Xiang Li"], "title": "MS-IQA: A Multi-Scale Feature Fusion Network for PET/CT Image Quality Assessment", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted to MICCAI 2025", "summary": "Positron Emission Tomography / Computed Tomography (PET/CT) plays a critical\nrole in medical imaging, combining functional and anatomical information to aid\nin accurate diagnosis. However, image quality degradation due to noise,\ncompression and other factors could potentially lead to diagnostic uncertainty\nand increase the risk of misdiagnosis. When evaluating the quality of a PET/CT\nimage, both low-level features like distortions and high-level features like\norgan anatomical structures affect the diagnostic value of the image. However,\nexisting medical image quality assessment (IQA) methods are unable to account\nfor both feature types simultaneously. In this work, we propose MS-IQA, a novel\nmulti-scale feature fusion network for PET/CT IQA, which utilizes multi-scale\nfeatures from various intermediate layers of ResNet and Swin Transformer,\nenhancing its ability of perceiving both local and global information. In\naddition, a multi-scale feature fusion module is also introduced to effectively\ncombine high-level and low-level information through a dynamically weighted\nchannel attention mechanism. Finally, to fill the blank of PET/CT IQA dataset,\nwe construct PET-CT-IQA-DS, a dataset containing 2,700 varying-quality PET/CT\nimages with quality scores assigned by radiologists. Experiments on our dataset\nand the publicly available LDCTIQAC2023 dataset demonstrate that our proposed\nmodel has achieved superior performance against existing state-of-the-art\nmethods in various IQA metrics. This work provides an accurate and efficient\nIQA method for PET/CT. Our code and dataset are available at\nhttps://github.com/MS-IQA/MS-IQA/.", "AI": {"tldr": "A novel multi-scale feature fusion network (MS-IQA) is proposed for PET/CT image quality assessment, addressing both low-level and high-level features, and outperforming existing methods.", "motivation": "Existing PET/CT image quality assessment methods fail to account for both low-level distortions and high-level anatomical structures, leading to diagnostic uncertainty.", "method": "MS-IQA combines multi-scale features from ResNet and Swin Transformer, using a dynamically weighted channel attention mechanism for feature fusion. A new dataset, PET-CT-IQA-DS, is also introduced.", "result": "MS-IQA achieves superior performance on PET-CT-IQA-DS and LDCTIQAC2023 datasets, outperforming state-of-the-art methods in various IQA metrics.", "conclusion": "The proposed MS-IQA provides an accurate and efficient solution for PET/CT image quality assessment, with publicly available code and dataset."}}
{"id": "2506.19955", "pdf": "https://arxiv.org/pdf/2506.19955", "abs": "https://arxiv.org/abs/2506.19955", "authors": ["Yiming Ma", "Victor Sanchez", "Tanaya Guha"], "title": "EBC-ZIP: Improving Blockwise Crowd Counting with Zero-Inflated Poisson Regression", "categories": ["cs.CV"], "comment": null, "summary": "Density map estimation has become the mainstream paradigm in crowd counting.\nHowever, most existing methods overlook the extreme sparsity of ground-truth\ndensity maps. In real-world crowd scenes, the vast majority of spatial regions\n(often over 95%) contain no people, leading to heavily imbalanced count\ndistributions. Ignoring this imbalance can bias models toward overestimating\ndense regions and underperforming in sparse areas. Furthermore, most loss\nfunctions used in density estimation are majorly based on MSE and implicitly\nassume Gaussian distributions, which are ill-suited for modeling discrete,\nnon-negative count data. In this paper, we propose EBC-ZIP, a crowd counting\nframework that models the spatial distribution of counts using a Zero-Inflated\nPoisson (ZIP) regression formulation. Our approach replaces the traditional\nregression loss with the negative log-likelihood of the ZIP distribution,\nenabling better handling of zero-heavy distributions while preserving count\naccuracy. Built upon the recently proposed Enhanced Block Classification (EBC)\nframework, EBC-ZIP inherits EBC's advantages in preserving the discreteness of\ntargets and ensuring training stability, while further improving performance\nthrough a more principled probabilistic loss. We also evaluate EBC-ZIP with\nbackbones of varying computational complexity to assess its scalability.\nExtensive experiments on four crowd counting benchmarks demonstrate that\nEBC-ZIP consistently outperforms EBC and achieves state-of-the-art results.", "AI": {"tldr": "EBC-ZIP introduces a Zero-Inflated Poisson regression for crowd counting, addressing imbalance in sparse density maps and outperforming existing methods.", "motivation": "Existing crowd counting methods ignore extreme sparsity in density maps and use loss functions ill-suited for count data, leading to biased estimations.", "method": "Proposes EBC-ZIP, using ZIP regression for better handling of zero-heavy distributions and replacing traditional MSE loss with negative log-likelihood of ZIP.", "result": "EBC-ZIP outperforms EBC and achieves state-of-the-art results on four benchmarks.", "conclusion": "EBC-ZIP provides a principled probabilistic approach for crowd counting, improving accuracy and scalability."}}
{"id": "2506.19977", "pdf": "https://arxiv.org/pdf/2506.19977", "abs": "https://arxiv.org/abs/2506.19977", "authors": ["Deng Pan", "Keerthiram Murugesan", "Nuno Moniz", "Nitesh Chawla"], "title": "Context Attribution with Multi-Armed Bandit Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Understanding which parts of the retrieved context contribute to a large\nlanguage model's generated answer is essential for building interpretable and\ntrustworthy generative QA systems. We propose a novel framework that formulates\ncontext attribution as a combinatorial multi-armed bandit (CMAB) problem. Each\ncontext segment is treated as a bandit arm, and we employ Combinatorial\nThompson Sampling (CTS) to efficiently explore the exponentially large space of\ncontext subsets under a limited query budget. Our method defines a reward\nfunction based on normalized token likelihoods, capturing how well a subset of\nsegments supports the original model response. Unlike traditional\nperturbation-based attribution methods such as SHAP, which sample subsets\nuniformly and incur high computational costs, our approach adaptively balances\nexploration and exploitation by leveraging posterior estimates of segment\nrelevance. This leads to substantially improved query efficiency while\nmaintaining high attribution fidelity. Extensive experiments on diverse\ndatasets and LLMs demonstrate that our method achieves competitive attribution\nquality with fewer model queries.", "AI": {"tldr": "A novel framework for context attribution in generative QA systems using combinatorial multi-armed bandits (CMAB) and Combinatorial Thompson Sampling (CTS) to improve query efficiency and attribution fidelity.", "motivation": "To build interpretable and trustworthy generative QA systems by understanding which parts of retrieved context contribute to the model's answers.", "method": "Formulates context attribution as a CMAB problem, treating each context segment as a bandit arm and using CTS to explore context subsets efficiently under limited query budgets. Defines a reward function based on normalized token likelihoods.", "result": "Achieves competitive attribution quality with fewer model queries compared to traditional perturbation-based methods like SHAP.", "conclusion": "The proposed method significantly improves query efficiency while maintaining high attribution fidelity, making it practical for real-world applications."}}
{"id": "2506.19883", "pdf": "https://arxiv.org/pdf/2506.19883", "abs": "https://arxiv.org/abs/2506.19883", "authors": ["Zhuqing Liu", "Chaosheng Dong", "Michinari Momma", "Simone Shao", "Shaoyuan Xu", "Yan Gao", "Haibo Yang", "Jia Liu"], "title": "STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, multi-objective optimization (MOO) has gained attention for its\nbroad applications in ML, operations research, and engineering. However, MOO\nalgorithm design remains in its infancy and many existing MOO methods suffer\nfrom unsatisfactory convergence rate and sample complexity performance. To\naddress this challenge, in this paper, we propose an algorithm called STIMULUS(\nstochastic path-integrated multi-gradient recursive e\\ulstimator), a new and\nrobust approach for solving MOO problems. Different from the traditional\nmethods, STIMULUS introduces a simple yet powerful recursive framework for\nupdating stochastic gradient estimates to improve convergence performance with\nlow sample complexity. In addition, we introduce an enhanced version of\nSTIMULUS, termed STIMULUS-M, which incorporates a momentum term to further\nexpedite convergence. We establish $O(1/T)$ convergence rates of the proposed\nmethods for non-convex settings and $O (\\exp{-\\mu T})$ for strongly convex\nsettings, where $T$ is the total number of iteration rounds. Additionally, we\nachieve the state-of-the-art $O \\left(n+\\sqrt{n}\\epsilon^{-1}\\right)$ sample\ncomplexities for non-convex settings and $O\\left(n+ \\sqrt{n} \\ln\n({\\mu/\\epsilon})\\right)$ for strongly convex settings, where $\\epsilon>0$ is a\ndesired stationarity error. Moreover, to alleviate the periodic full gradient\nevaluation requirement in STIMULUS and STIMULUS-M, we further propose enhanced\nversions with adaptive batching called STIMULUS+/ STIMULUS-M+ and provide their\ntheoretical analysis.", "AI": {"tldr": "The paper introduces STIMULUS, a novel multi-objective optimization algorithm, and its enhanced versions (STIMULUS-M, STIMULUS+, STIMULUS-M+), offering improved convergence rates and sample complexity compared to traditional methods.", "motivation": "Existing MOO methods suffer from poor convergence and high sample complexity, limiting their practical applications.", "method": "STIMULUS uses a recursive stochastic gradient framework, while STIMULUS-M adds momentum. Enhanced versions (STIMULUS+/M+) incorporate adaptive batching to reduce full gradient evaluations.", "result": "The methods achieve $O(1/T)$ (non-convex) and $O(\\exp{-\\mu T})$ (strongly convex) convergence rates, with state-of-the-art sample complexities.", "conclusion": "STIMULUS and its variants provide robust, efficient solutions for MOO problems, addressing key limitations of existing approaches."}}
{"id": "2506.16116", "pdf": "https://arxiv.org/pdf/2506.16116", "abs": "https://arxiv.org/abs/2506.16116", "authors": ["Ignacio Hern\u00e1ndez Montilla", "Alfonso Medela", "Paola Pasquali", "Andy Aguilar", "Taig Mac Carthy", "Gerardo Fern\u00e1ndez", "Antonio Martorell", "Enrique Onieva"], "title": "Enhanced Dermatology Image Quality Assessment via Cross-Domain Training", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": "9 pages, 4 figures. This manuscript has been accepted to the 2025\n  12th International Conference on Bioinformatics Research and Applications\n  (ICBRA 2025). It will be published in International Conference Proceedings by\n  ACM, which will be archived in ACM Digital Library, indexed by Ei Compendex\n  and Scopus", "summary": "Teledermatology has become a widely accepted communication method in daily\nclinical practice, enabling remote care while showing strong agreement with\nin-person visits. Poor image quality remains an unsolved problem in\nteledermatology and is a major concern to practitioners, as bad-quality images\nreduce the usefulness of the remote consultation process. However, research on\nImage Quality Assessment (IQA) in dermatology is sparse, and does not leverage\nthe latest advances in non-dermatology IQA, such as using larger image\ndatabases with ratings from large groups of human observers. In this work, we\npropose cross-domain training of IQA models, combining dermatology and\nnon-dermatology IQA datasets. For this purpose, we created a novel dermatology\nIQA database, Legit.Health-DIQA-Artificial, using dermatology images from\nseveral sources and having them annotated by a group of human observers. We\ndemonstrate that cross-domain training yields optimal performance across\ndomains and overcomes one of the biggest limitations in dermatology IQA, which\nis the small scale of data, and leads to models trained on a larger pool of\nimage distortions, resulting in a better management of image quality in the\nteledermatology process.", "AI": {"tldr": "The paper proposes cross-domain training for Image Quality Assessment (IQA) in teledermatology to address poor image quality, leveraging both dermatology and non-dermatology datasets for improved performance.", "motivation": "Poor image quality in teledermatology reduces the effectiveness of remote consultations, and existing dermatology IQA research lacks the scale and advancements seen in non-dermatology IQA.", "method": "The authors created a new dermatology IQA database (Legit.Health-DIQA-Artificial) and combined it with non-dermatology datasets for cross-domain training of IQA models.", "result": "Cross-domain training improves performance by addressing data scarcity in dermatology IQA and enhances image quality management in teledermatology.", "conclusion": "Cross-domain training is effective for improving IQA in teledermatology, overcoming data limitations and enhancing remote consultation quality."}}
{"id": "2506.20081", "pdf": "https://arxiv.org/pdf/2506.20081", "abs": "https://arxiv.org/abs/2506.20081", "authors": ["Dhruv Gupta", "Gayathri Ganesh Lakshmy", "Yiqing Xie"], "title": "SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Code Generation (RACG) is a critical technique for\nenhancing code generation by retrieving relevant information. In this work, we\nconduct an in-depth analysis of code retrieval by systematically masking\nspecific features while preserving code functionality. Our discoveries include:\n(1) although trained on code, current retrievers heavily rely on surface-level\ntextual features (e.g., docstrings, identifier names), and (2) they exhibit a\nstrong bias towards well-documented code, even if the documentation is\nirrelevant.Based on our discoveries, we propose SACL, a framework that enriches\ntextual information and reduces bias by augmenting code or structural knowledge\nwith semantic information. Extensive experiments show that SACL substantially\nimproves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval /\nMBPP / SWE-Bench-Lite), which also leads to better code generation performance\n(e.g., by 4.88% Pass@1 on HumanEval).", "AI": {"tldr": "The paper analyzes code retrieval in RACG, revealing biases toward surface-level features and well-documented code. It proposes SACL, a framework improving retrieval and generation performance.", "motivation": "To address biases in current code retrievers that rely on superficial features and irrelevant documentation, hindering effective code generation.", "method": "Systematic masking of features while preserving functionality, leading to the development of SACL, which augments code with semantic information.", "result": "SACL improves retrieval (e.g., 12.8% Recall@1 on HumanEval) and boosts code generation (e.g., 4.88% Pass@1 on HumanEval).", "conclusion": "SACL effectively reduces retrieval biases and enhances code generation by integrating semantic knowledge."}}
{"id": "2506.20001", "pdf": "https://arxiv.org/pdf/2506.20001", "abs": "https://arxiv.org/abs/2506.20001", "authors": ["Paul Didier", "Toon van Waterschoot", "Simon Doclo", "J\u00f6rg Bitzer", "Marc Moonen"], "title": "Improved Topology-Independent Distributed Adaptive Node-Specific Signal Estimation for Wireless Acoustic Sensor Networks", "categories": ["eess.AS"], "comment": null, "summary": "This paper addresses the challenge of topology-independent (TI) distributed\nadaptive node-specific signal estimation (DANSE) in wireless acoustic sensor\nnetworks (WASNs) where sensor nodes exchange only fused versions of their local\nsignals. An algorithm named TI-DANSE has previously been presented to handle\nnon-fully connected WASNs. However, its slow iterative convergence towards the\noptimal solution limits its applicability. To address this, we propose in this\npaper the TI-DANSE+ algorithm. At each iteration in TI-DANSE+, the node set to\nupdate its local parameters is allowed to exploit each individual partial\nin-network sums transmitted by its neighbors in its local estimation problem,\nincreasing the available degrees of freedom and accelerating convergence with\nrespect to TI-DANSE. Additionally, a tree-pruning strategy is proposed to\nfurther increase convergence speed. TI-DANSE+ converges as fast as the DANSE\nalgorithm in fully connected WASNs while reducing transmit power usage. The\nconvergence properties of TI-DANSE+ are demonstrated in numerical simulations.", "AI": {"tldr": "The paper introduces TI-DANSE+, an improved algorithm for topology-independent distributed adaptive node-specific signal estimation in wireless acoustic sensor networks, offering faster convergence and reduced power usage compared to TI-DANSE.", "motivation": "The slow convergence of the existing TI-DANSE algorithm in non-fully connected networks limits its practicality, prompting the need for a more efficient solution.", "method": "TI-DANSE+ allows nodes to exploit partial in-network sums from neighbors during updates, increasing degrees of freedom and accelerating convergence. A tree-pruning strategy is also introduced to further speed up convergence.", "result": "TI-DANSE+ matches the convergence speed of DANSE in fully connected networks while using less transmit power, as shown in simulations.", "conclusion": "TI-DANSE+ effectively addresses the limitations of TI-DANSE, offering faster convergence and improved efficiency in wireless acoustic sensor networks."}}
{"id": "2506.20218", "pdf": "https://arxiv.org/pdf/2506.20218", "abs": "https://arxiv.org/abs/2506.20218", "authors": ["Francesco d'Amore", "Niccol\u00f2 D'Archivio", "George Giakkoupis", "Emanuele Natale"], "title": "On the $h$-majority dynamics with many opinions", "categories": ["cs.DC", "cs.MA"], "comment": null, "summary": "We present the first upper bound on the convergence time to consensus of the\nwell-known $h$-majority dynamics with $k$ opinions, in the synchronous setting,\nfor $h$ and $k$ that are both non-constant values.\n  We suppose that, at the beginning of the process, there is some initial\nadditive bias towards some plurality opinion, that is, there is an opinion that\nis supported by $x$ nodes while any other opinion is supported by strictly\nfewer nodes.\n  We prove that, with high probability, if the bias is $\\omega(\\sqrt{x})$ and\nthe initial plurality opinion is supported by at least $x = \\omega(\\log n)$\nnodes, then the process converges to plurality consensus in $O(\\log n)$ rounds\nwhenever $h = \\omega(n \\log n / x)$.\n  A main corollary is the following: if $k = o(n / \\log n)$ and the process\nstarts from an almost-balanced configuration with an initial bias of magnitude\n$\\omega(\\sqrt{n/k})$ towards the initial plurality opinion, then any function\n$h = \\omega(k \\log n)$ suffices to guarantee convergence to consensus in\n$O(\\log n)$ rounds, with high probability.\n  Our upper bound shows that the lower bound of $\\Omega(k / h^2)$ rounds to\nreach consensus given by Becchetti et al.\\ (2017) cannot be pushed further than\n$\\widetilde{\\Omega}(k / h)$.\n  Moreover, the bias we require is asymptotically smaller than the\n$\\Omega(\\sqrt{n\\log n})$ bias that guarantees plurality consensus in the\n$3$-majority dynamics: in our case, the required bias is at most any\n(arbitrarily small) function in $\\omega(\\sqrt{x})$ for any value of $k \\ge 2$.", "AI": {"tldr": "The paper presents an upper bound on the convergence time to consensus for $h$-majority dynamics with $k$ opinions, showing it converges in $O(\\log n)$ rounds under specific conditions.", "motivation": "To understand the convergence behavior of $h$-majority dynamics with non-constant $h$ and $k$, especially under initial bias conditions.", "method": "The study assumes an initial additive bias towards a plurality opinion and analyzes the process under high probability conditions.", "result": "The process converges to plurality consensus in $O(\\log n)$ rounds if the bias is $\\omega(\\sqrt{x})$ and $h = \\omega(n \\log n / x)$.", "conclusion": "The upper bound improves previous results, showing the lower bound cannot exceed $\\widetilde{\\Omega}(k / h)$ and requires less bias than prior work."}}
{"id": "2506.20288", "pdf": "https://arxiv.org/pdf/2506.20288", "abs": "https://arxiv.org/abs/2506.20288", "authors": ["Ale\u0161 Pra\u017e\u00e1k", "Marie Kune\u0161ov\u00e1", "Josef Psutka"], "title": "Lightweight Target-Speaker-Based Overlap Transcription for Practical Streaming ASR", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Overlapping speech remains a major challenge for automatic speech recognition\n(ASR) in real-world applications, particularly in broadcast media with dynamic,\nmulti-speaker interactions. We propose a light-weight, target-speaker-based\nextension to an existing streaming ASR system to enable practical transcription\nof overlapping speech with minimal computational overhead. Our approach\ncombines a speaker-independent (SI) model for standard operation with a\nspeaker-conditioned (SC) model selectively applied in overlapping scenarios.\nOverlap detection is achieved using a compact binary classifier trained on\nfrozen SI model output, offering accurate segmentation at negligible cost. The\nSC model employs Feature-wise Linear Modulation (FiLM) to incorporate speaker\nembeddings and is trained on synthetically mixed data to transcribe only the\ntarget speaker. Our method supports dynamic speaker tracking and reuses\nexisting modules with minimal modifications. Evaluated on a challenging set of\nCzech television debates with 16% overlap, the system reduced WER on\noverlapping segments from 68.0% (baseline) to 35.78% while increasing total\ncomputational load by only 44%. The proposed system offers an effective and\nscalable solution for overlap transcription in continuous ASR services.", "AI": {"tldr": "A lightweight, target-speaker-based extension for streaming ASR systems reduces WER in overlapping speech by 32.22% with minimal computational overhead.", "motivation": "Overlapping speech is a major challenge for ASR in real-world applications like broadcast media.", "method": "Combines speaker-independent and speaker-conditioned models with overlap detection using a binary classifier. FiLM incorporates speaker embeddings for target-speaker transcription.", "result": "Reduced WER on overlapping segments from 68.0% to 35.78% with only a 44% increase in computational load.", "conclusion": "The system provides an effective, scalable solution for overlap transcription in continuous ASR services."}}
{"id": "2506.20206", "pdf": "https://arxiv.org/pdf/2506.20206", "abs": "https://arxiv.org/abs/2506.20206", "authors": ["Yang Li"], "title": "Volumetric segmentation of muscle compartments using in vivo imaging and architectural validation in human finger flexors", "categories": ["eess.IV"], "comment": "19 pages, 13 figures", "summary": "Segmenting muscle compartments and measuring their architecture can\nfacilitate movement function assessment, accurate musculoskeletal modeling, and\nsynergy-based electromyogram simulation. Here, we presented a novel method for\nvolumetric segmentation of muscle compartments using in vivo imaging, focusing\non the independent compartments for finger control of flexor digitorum\nsuperficialis (FDS). Besides, we measured the architectural properties of FDS\ncompartments and validated the segmentation. Specifically, ultrasound and\nmagnetic resonance imaging (MRI) from 10 healthy subjects were used for\nsegmentation and measurement, while electromyography was utilized for\nvalidation. A two-step piecewise segmentation was proposed, first annotating\ncompartment regions in the cross-sectional ultrasound image based on\ncompartment movement, and then performing minimum energy matching to register\nthe ultrasound data to the three-dimensional MRI coordinate system.\nAdditionally, the architectural properties were measured in the compartment\nmasks from the segmentation using MRI tractography. Anatomical correctness was\nverified by comparing known anatomy with reconstructed fiber tracts and\nmeasured properties, while segmentation accuracy was quantified as the\npercentage of finger electromyogram centers falling within their corresponding\ncompartments. Results demonstrated agreement for the fiber orientation between\nthe tractography and cadaveric photographs. Significant differences in\narchitectural properties (P < 0.001) were observed between compartments. The\nproperties of FDS and its compartments were within the physiological ranges (P\n< 0.01). 95% (38/40) of the electromyogram centers were located within\nrespective compartments, with 2 errors occurring in the index and little\nfingers. The validated segmentation method and derived architectural properties\nmay advance biomedical applications.", "AI": {"tldr": "A novel method for volumetric segmentation of muscle compartments using in vivo imaging was developed, validated, and applied to the flexor digitorum superficialis (FDS) for finger control.", "motivation": "Segmenting muscle compartments and measuring their architecture aids in movement function assessment, musculoskeletal modeling, and electromyogram simulation.", "method": "A two-step piecewise segmentation using ultrasound and MRI, followed by MRI tractography for measuring architectural properties, validated with electromyography.", "result": "Fiber orientation matched cadaveric data; significant architectural differences between compartments; 95% of electromyogram centers were correctly located.", "conclusion": "The validated method and derived properties can enhance biomedical applications."}}
{"id": "2506.20066", "pdf": "https://arxiv.org/pdf/2506.20066", "abs": "https://arxiv.org/abs/2506.20066", "authors": ["Hsiang-Wei Huang", "Wenhao Chai", "Kuang-Ming Chen", "Cheng-Yen Yang", "Jenq-Neng Hwang"], "title": "ToSA: Token Merging with Spatial Awareness", "categories": ["cs.CV"], "comment": "Accepted by IROS 2025", "summary": "Token merging has emerged as an effective strategy to accelerate Vision\nTransformers (ViT) by reducing computational costs. However, existing methods\nprimarily rely on the visual token's feature similarity for token merging,\noverlooking the potential of integrating spatial information, which can serve\nas a reliable criterion for token merging in the early layers of ViT, where the\nvisual tokens only possess weak visual information. In this paper, we propose\nToSA, a novel token merging method that combines both semantic and spatial\nawareness to guide the token merging process. ToSA leverages the depth image as\ninput to generate pseudo spatial tokens, which serve as auxiliary spatial\ninformation for the visual token merging process. With the introduced spatial\nawareness, ToSA achieves a more informed merging strategy that better preserves\ncritical scene structure. Experimental results demonstrate that ToSA\noutperforms previous token merging methods across multiple benchmarks on visual\nand embodied question answering while largely reducing the runtime of the ViT,\nmaking it an efficient solution for ViT acceleration. The code will be\navailable at: https://github.com/hsiangwei0903/ToSA", "AI": {"tldr": "ToSA is a token merging method for ViTs that combines semantic and spatial awareness, outperforming existing methods in efficiency and performance.", "motivation": "Existing token merging methods for ViTs rely on feature similarity, ignoring spatial information, which is crucial in early layers.", "method": "ToSA integrates depth images to generate pseudo spatial tokens, guiding merging with both semantic and spatial cues.", "result": "ToSA reduces ViT runtime and improves performance on visual and embodied question answering benchmarks.", "conclusion": "ToSA is an efficient solution for ViT acceleration, preserving scene structure better than prior methods."}}
{"id": "2506.20008", "pdf": "https://arxiv.org/pdf/2506.20008", "abs": "https://arxiv.org/abs/2506.20008", "authors": ["Abdul Basit", "Minghao Shao", "Haider Asif", "Nouhaila Innan", "Muhammad Kashif", "Alberto Marchisio", "Muhammad Shafique"], "title": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "categories": ["cs.AI", "cs.PL", "cs.SE", "68T50, 81P68, 68T07, 68T20", "I.2.7; I.2.2"], "comment": "8 pages, 6 figures, 3 tables, submitted to QAI 2025", "summary": "Recent advances in Large Language Models (LLMs) have demonstrated strong\npotential in code generation, yet their effectiveness in quantum computing\nremains underexplored. This paper benchmarks LLMs for PennyLane-based quantum\ncode generation using real-world challenges from the Quantum Hackathon (QHack).\nWe introduce QHackBench, a novel benchmark dataset derived from QHack\ncompetitions, and evaluate model performance under vanilla prompting and\nRetrieval-Augmented Generation (RAG). Our structured evaluation framework\nassesses functional correctness, syntactic validity, and execution success\nacross varying challenge difficulties. Results indicate that RAG-enhanced\nmodels, supplemented with an augmented PennyLane dataset, approximately\ngenerate similar results as the standard prompting, particularly in complex\nquantum algorithms. Additionally, we introduce a multi-agent evaluation\npipeline that iteratively refines incorrect solutions, further enhancing\nexecution success rates. To foster further research, we commit to publicly\nreleasing QHackBench, along with our evaluation framework and experimental\nresults, enabling continued advancements in AI-assisted quantum programming.", "AI": {"tldr": "The paper benchmarks LLMs for quantum code generation using PennyLane and QHack challenges, introducing QHackBench. RAG-enhanced models perform similarly to standard prompting, with a multi-agent pipeline improving execution success.", "motivation": "To explore LLMs' potential in quantum computing, addressing the underexplored area of quantum code generation.", "method": "Benchmarked LLMs using QHackBench, evaluated under vanilla prompting and RAG, and introduced a multi-agent pipeline for refining solutions.", "result": "RAG-enhanced models matched standard prompting, especially in complex algorithms, with the multi-agent pipeline boosting execution success.", "conclusion": "The study advances AI-assisted quantum programming, with public release of QHackBench and tools to support future research."}}
{"id": "2506.19885", "pdf": "https://arxiv.org/pdf/2506.19885", "abs": "https://arxiv.org/abs/2506.19885", "authors": ["Jing Lu", "Xuan Wu", "Yizhun Tian", "Songhan Fan", "Yali Fang"], "title": "FlightKooba: A Fast Interpretable FTP Model", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "7 figures", "summary": "The Koopman theory is a powerful and effective modeling tool for converting\nnonlinear systems into linear representations, and flight trajectory prediction\n(FTP) is a complex nonlinear system. However, current models applying the\nKoopman theory to FTP tasks are not very effective, model interpretability is\nindeed an issue, and the Koopman operators are computationally intensive,\nresulting in long training times. To address this issue, this paper proposes a\nnew modeling and control framework based on the HIPPO method, the Koopman\ntheory, and state space equations from cybernetics: FlightKooba. Inspired by\nthe idea of structural state space equations, FlightKooba directly constructs\nthe Koopman operators from data. This makes the framework highly interpretable\nand significantly reduces the number of trainable parameters in the module,\nthereby greatly reducing training time. Experiments have demonstrated the\nsuperiority of the FlightKooba modeling method in terms of time and memory\nconsumption (training time comparable to the Mamba module without using\nCUDA-level acceleration; memory reduced by more than 50% on most datasets, with\na tenfold reduction in the number of parameters), essentially completing the\nFTP task. It provides a new method for the fast computation of the Koopman\noperators, opening up new possibilities for the combination of time series\nforecasting and control.", "AI": {"tldr": "The paper introduces FlightKooba, a framework combining HIPPO, Koopman theory, and state space equations to improve flight trajectory prediction by reducing computational load and enhancing interpretability.", "motivation": "Current Koopman-based models for flight trajectory prediction are inefficient, lack interpretability, and have high computational costs.", "method": "FlightKooba constructs Koopman operators directly from data using structural state space equations, reducing trainable parameters and training time.", "result": "FlightKooba achieves faster training (comparable to Mamba without CUDA), reduces memory by over 50%, and cuts parameters by tenfold.", "conclusion": "FlightKooba offers an efficient, interpretable solution for Koopman operator computation, advancing time series forecasting and control integration."}}
{"id": "2506.20070", "pdf": "https://arxiv.org/pdf/2506.20070", "abs": "https://arxiv.org/abs/2506.20070", "authors": ["KMA Solaiman", "Bharat Bhargava"], "title": "Multimodal Information Retrieval for Open World with Edit Distance Weak Supervision", "categories": ["cs.IR", "cs.LG", "cs.MM"], "comment": "Submitted to ICDE'24. An earlier version of this paper appeared on\n  TechRxiv: https://www.techrxiv.org/doi/full/10.36227/techrxiv.21990284.v1,\n  uploaded on February 05, 2023", "summary": "Existing multi-media retrieval models either rely on creating a common\nsubspace with modality-specific representation models or require schema mapping\namong modalities to measure similarities among multi-media data. Our goal is to\navoid the annotation overhead incurred from considering retrieval as a\nsupervised classification task and re-use the pretrained encoders in large\nlanguage models and vision tasks. We propose \"FemmIR\", a framework to retrieve\nmultimodal results relevant to information needs expressed with multimodal\nqueries by example without any similarity label. Such identification is\nnecessary for real-world applications where data annotations are scarce and\nsatisfactory performance is required without fine-tuning with a common\nframework across applications. We curate a new dataset called MuQNOL for\nbenchmarking progress on this task. Our technique is based on weak supervision\nintroduced through edit distance between samples: graph edit distance can be\nmodified to consider the cost of replacing a data sample in terms of its\nproperties, and relevance can be measured through the implicit signal from the\namount of edit cost among the objects. Unlike metric learning or encoding\nnetworks, FemmIR re-uses the high-level properties and maintains the property\nvalue and relationship constraints with a multi-level interaction score between\ndata samples and the query example provided by the user. We empirically\nevaluate FemmIR on a missing person use case with MuQNOL. FemmIR performs\ncomparably to similar retrieval systems in delivering on-demand retrieval\nresults with exact and approximate similarities while using the existing\nproperty identifiers in the system.", "AI": {"tldr": "FemmIR is a framework for multimodal retrieval without similarity labels, leveraging weak supervision and edit distance to measure relevance, and performs comparably to existing systems.", "motivation": "To avoid annotation overhead and reuse pretrained encoders, enabling retrieval without fine-tuning or labeled data.", "method": "Uses weak supervision via edit distance between samples, measuring relevance through edit cost and multi-level interaction scores.", "result": "FemmIR performs comparably to similar retrieval systems on the MuQNOL dataset, even without fine-tuning.", "conclusion": "FemmIR offers a practical solution for multimodal retrieval in annotation-scarce scenarios, maintaining performance with existing property identifiers."}}
{"id": "2506.20083", "pdf": "https://arxiv.org/pdf/2506.20083", "abs": "https://arxiv.org/abs/2506.20083", "authors": ["Yingji Zhang", "Danilo S. Carvalho", "Andr\u00e9 Freitas"], "title": "Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder", "categories": ["cs.CL"], "comment": "In progress", "summary": "Integrating compositional and symbolic properties into current distributional\nsemantic spaces can enhance the interpretability, controllability,\ncompositionality, and generalisation capabilities of Transformer-based\nauto-regressive language models (LMs). In this survey, we offer a novel\nperspective on latent space geometry through the lens of compositional\nsemantics, a direction we refer to as \\textit{semantic representation\nlearning}. This direction enables a bridge between symbolic and distributional\nsemantics, helping to mitigate the gap between them. We review and compare\nthree mainstream autoencoder architectures-Variational AutoEncoder (VAE),\nVector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the\ndistinctive latent geometries they induce in relation to semantic structure and\ninterpretability.", "AI": {"tldr": "The paper explores integrating compositional and symbolic properties into distributional semantic spaces to improve Transformer-based LMs, focusing on semantic representation learning to bridge symbolic and distributional semantics. It reviews VAE, VQVAE, and SAE architectures for their latent geometries and semantic interpretability.", "motivation": "To enhance interpretability, controllability, compositionality, and generalization of Transformer-based LMs by combining compositional and symbolic properties with distributional semantics.", "method": "Reviews and compares three autoencoder architectures (VAE, VQVAE, SAE) to analyze their latent space geometries and semantic structure.", "result": "Identifies how each architecture's latent geometry impacts semantic interpretability and structure, bridging symbolic and distributional semantics.", "conclusion": "Semantic representation learning offers a promising direction to unify symbolic and distributional semantics, improving LM capabilities."}}
{"id": "2506.20361", "pdf": "https://arxiv.org/pdf/2506.20361", "abs": "https://arxiv.org/abs/2506.20361", "authors": ["Yi Wang", "Oli Danyi Liu", "Peter Bell"], "title": "The role of audio-visual integration in the time course of phonetic encoding in self-supervised speech models", "categories": ["eess.AS", "cs.SD", "eess.IV"], "comment": "Accepted by Interspeech 2025", "summary": "Human speech perception is multimodal. In natural speech, lip movements can\nprecede corresponding voicing by a non-negligible gap of 100-300 ms, especially\nfor specific consonants, affecting the time course of neural phonetic encoding\nin human listeners. However, it remains unexplored whether self-supervised\nlearning models, which have been used to simulate audio-visual integration in\nhumans, can capture this asynchronicity between audio and visual cues. We\ncompared AV-HuBERT, an audio-visual model, with audio-only HuBERT, by using\nlinear classifiers to track their phonetic decodability over time. We found\nthat phoneme information becomes available in AV-HuBERT embeddings only about\n20 ms before HuBERT, likely due to AV-HuBERT's lower temporal resolution and\nfeature concatenation process. It suggests AV-HuBERT does not adequately\ncapture the temporal dynamics of multimodal speech perception, limiting its\nsuitability for modeling the multimodal speech perception process.", "AI": {"tldr": "AV-HuBERT, an audio-visual model, fails to fully capture the temporal asynchronicity in multimodal speech perception, unlike human listeners.", "motivation": "To explore whether self-supervised learning models like AV-HuBERT can replicate the temporal dynamics of human multimodal speech perception, particularly the asynchronicity between audio and visual cues.", "method": "Compared AV-HuBERT with audio-only HuBERT using linear classifiers to track phonetic decodability over time.", "result": "Phoneme information in AV-HuBERT appears only ~20 ms earlier than in HuBERT, indicating poor capture of temporal dynamics.", "conclusion": "AV-HuBERT is limited in modeling multimodal speech perception due to its inability to replicate the temporal asynchronicity observed in humans."}}
{"id": "2506.20249", "pdf": "https://arxiv.org/pdf/2506.20249", "abs": "https://arxiv.org/abs/2506.20249", "authors": ["Junyan Cheng", "Peter Clark", "Kyle Richardson"], "title": "Language Modeling by Language Models", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Can we leverage LLMs to model the process of discovering novel language model\n(LM) architectures? Inspired by real research, we propose a multi-agent LLM\napproach that simulates the conventional stages of research, from ideation and\nliterature search (proposal stage) to design implementation (code generation),\ngenerative pre-training, and downstream evaluation (verification). Using ideas\nfrom scaling laws, our system, Genesys, employs a Ladder of Scales approach;\nnew designs are proposed, adversarially reviewed, implemented, and selectively\nverified at increasingly larger model scales (14M$\\sim$350M parameters) with a\nnarrowing budget (the number of models we can train at each scale). To help\nmake discovery efficient and factorizable, Genesys uses a novel genetic\nprogramming backbone, which we show has empirical advantages over commonly used\ndirect prompt generation workflows (e.g., $\\sim$86\\% percentage point\nimprovement in successful design generation, a key bottleneck). We report\nexperiments involving 1,162 newly discovered designs (1,062 fully verified\nthrough pre-training) and find the best designs to be highly competitive with\nknown architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common\nbenchmarks). We couple these results with comprehensive system-level ablations\nand formal results, which give broader insights into the design of effective\nautonomous discovery systems.", "AI": {"tldr": "A multi-agent LLM system, Genesys, is proposed to discover novel LM architectures by simulating research stages, using genetic programming for efficiency, and achieving competitive results.", "motivation": "To explore if LLMs can model the discovery of novel LM architectures, inspired by real research processes.", "method": "Genesys employs a multi-agent approach with stages like ideation, code generation, pre-training, and evaluation, using a genetic programming backbone and scaling laws.", "result": "1,162 new designs were discovered, with 1,062 verified; the best designs outperformed GPT2 and Mamba2 on 6/9 benchmarks.", "conclusion": "Genesys demonstrates effective autonomous discovery of LM architectures, with insights for future systems."}}
{"id": "2506.14293", "pdf": "https://arxiv.org/pdf/2506.14293", "abs": "https://arxiv.org/abs/2506.14293", "authors": ["Tawsif Ahmed", "Andrej Radonjic", "Gollam Rabby"], "title": "SLEEPING-DISCO 9M: A large-scale pre-training dataset for generative music modeling", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "We present Sleeping-DISCO 9M, a large-scale pre-training dataset for music\nand song. To the best of our knowledge, there are no open-source high-quality\ndataset representing popular and well-known songs for generative music modeling\ntasks such as text-music, music-captioning, singing-voice synthesis, melody\nreconstruction and cross-model retrieval. Past contributions focused on\nisolated and constrained factors whose core perspective was to create synthetic\nor re-recorded music corpus (e.g. GTSinger, M4Singer) and arbitrarily\nlarge-scale audio datasets (e.g. DISCO-10M and LAIONDISCO-12M) had been another\nfocus for the community. Unfortunately, adoption of these datasets has been\nbelow substantial in the generative music community as these datasets fail to\nreflect real-world music and its flavour. Our dataset changes this narrative\nand provides a dataset that is constructed using actual popular music and\nworld-renowned artists.", "AI": {"tldr": "Sleeping-DISCO 9M is a large-scale pre-training dataset for music and song, addressing the lack of open-source, high-quality datasets for generative music tasks by using real-world popular music.", "motivation": "Existing datasets for generative music tasks are either synthetic or lack real-world relevance, limiting their adoption. Sleeping-DISCO 9M aims to fill this gap by providing a dataset of actual popular music.", "method": "The dataset is constructed using real popular music and songs from world-renowned artists, ensuring high quality and relevance.", "result": "Sleeping-DISCO 9M offers a practical and realistic dataset for tasks like text-music, music-captioning, and singing-voice synthesis.", "conclusion": "This dataset addresses a critical need in the generative music community by providing a high-quality, real-world music corpus for diverse applications."}}
{"id": "2506.20282", "pdf": "https://arxiv.org/pdf/2506.20282", "abs": "https://arxiv.org/abs/2506.20282", "authors": ["Jiaxing Huang", "Heng Guo", "Le Lu", "Fan Yang", "Minfeng Xu", "Ge Yang", "Wei Luo"], "title": "Opportunistic Osteoporosis Diagnosis via Texture-Preserving Self-Supervision, Mixture of Experts and Multi-Task Integration", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted by MICCAI 2025", "summary": "Osteoporosis, characterized by reduced bone mineral density (BMD) and\ncompromised bone microstructure, increases fracture risk in aging populations.\nWhile dual-energy X-ray absorptiometry (DXA) is the clinical standard for BMD\nassessment, its limited accessibility hinders diagnosis in resource-limited\nregions. Opportunistic computed tomography (CT) analysis has emerged as a\npromising alternative for osteoporosis diagnosis using existing imaging data.\nCurrent approaches, however, face three limitations: (1) underutilization of\nunlabeled vertebral data, (2) systematic bias from device-specific DXA\ndiscrepancies, and (3) insufficient integration of clinical knowledge such as\nspatial BMD distribution patterns. To address these, we propose a unified deep\nlearning framework with three innovations. First, a self-supervised learning\nmethod using radiomic representations to leverage unlabeled CT data and\npreserve bone texture. Second, a Mixture of Experts (MoE) architecture with\nlearned gating mechanisms to enhance cross-device adaptability. Third, a\nmulti-task learning framework integrating osteoporosis diagnosis, BMD\nregression, and vertebra location prediction. Validated across three clinical\nsites and an external hospital, our approach demonstrates superior\ngeneralizability and accuracy over existing methods for opportunistic\nosteoporosis screening and diagnosis.", "AI": {"tldr": "A deep learning framework addresses limitations in osteoporosis diagnosis using opportunistic CT, leveraging self-supervised learning, Mixture of Experts, and multi-task learning for improved accuracy and generalizability.", "motivation": "Current osteoporosis diagnosis methods using CT face challenges like underutilized unlabeled data, device-specific biases, and lack of clinical knowledge integration.", "method": "Proposes a unified deep learning framework with self-supervised learning for unlabeled data, MoE for cross-device adaptability, and multi-task learning for diagnosis, BMD regression, and vertebra location.", "result": "Validated across multiple sites, the framework outperforms existing methods in accuracy and generalizability for osteoporosis screening.", "conclusion": "The proposed framework effectively addresses key limitations, offering a robust solution for opportunistic osteoporosis diagnosis using CT."}}
{"id": "2506.20103", "pdf": "https://arxiv.org/pdf/2506.20103", "abs": "https://arxiv.org/abs/2506.20103", "authors": ["Jiahao Lin", "Weixuan Peng", "Bojia Zi", "Yifeng Gao", "Xianbiao Qi", "Xingjun Ma", "Yu-Gang Jiang"], "title": "BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos", "categories": ["cs.CV", "cs.AI", "I.4"], "comment": "7 page,4 figures,2 tables", "summary": "Recent advances in deep generative models have led to significant progress in\nvideo generation, yet the fidelity of AI-generated videos remains limited.\nSynthesized content often exhibits visual artifacts such as temporally\ninconsistent motion, physically implausible trajectories, unnatural object\ndeformations, and local blurring that undermine realism and user trust.\nAccurate detection and spatial localization of these artifacts are crucial for\nboth automated quality control and for guiding the development of improved\ngenerative models. However, the research community currently lacks a\ncomprehensive benchmark specifically designed for artifact localization in AI\ngenerated videos. Existing datasets either restrict themselves to video or\nframe level detection or lack the fine-grained spatial annotations necessary\nfor evaluating localization methods. To address this gap, we introduce\nBrokenVideos, a benchmark dataset of 3,254 AI-generated videos with\nmeticulously annotated, pixel-level masks highlighting regions of visual\ncorruption. Each annotation is validated through detailed human inspection to\nensure high quality ground truth. Our experiments show that training state of\nthe art artifact detection models and multi modal large language models (MLLMs)\non BrokenVideos significantly improves their ability to localize corrupted\nregions. Through extensive evaluation, we demonstrate that BrokenVideos\nestablishes a critical foundation for benchmarking and advancing research on\nartifact localization in generative video models. The dataset is available at:\nhttps://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.", "AI": {"tldr": "The paper introduces BrokenVideos, a benchmark dataset for detecting and localizing artifacts in AI-generated videos, improving model performance.", "motivation": "Current AI-generated videos suffer from visual artifacts, but existing datasets lack fine-grained spatial annotations for artifact localization.", "method": "A dataset of 3,254 AI-generated videos with pixel-level artifact annotations is created and validated through human inspection.", "result": "Training models on BrokenVideos enhances their ability to localize corrupted regions.", "conclusion": "BrokenVideos provides a foundation for advancing artifact localization research in generative video models."}}
{"id": "2506.20009", "pdf": "https://arxiv.org/pdf/2506.20009", "abs": "https://arxiv.org/abs/2506.20009", "authors": ["Konstantinos Vrettos", "Michail E. Klontzas"], "title": "Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks", "categories": ["cs.AI", "cs.CL", "I.2.7"], "comment": "18 pages, 3 Figures", "summary": "Background The increasing adoption of Artificial Intelligence (AI) in\nhealthcare has sparked growing concerns about its environmental and ethical\nimplications. Commercial Large Language Models (LLMs), such as ChatGPT and\nDeepSeek, require substantial resources, while the utilization of these systems\nfor medical purposes raises critical issues regarding patient privacy and\nsafety. Methods We developed a customizable Retrieval-Augmented Generation\n(RAG) framework for medical tasks, which monitors its energy usage and CO2\nemissions. This system was then used to create RAGs based on various\nopen-source LLMs. The tested models included both general purpose models like\nllama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs\nperformance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs\no4-mini model. A dataset of medical questions was used for the evaluation.\nResults Custom RAG models outperformed commercial models in accuracy and energy\nconsumption. The RAG model built on llama3.1:8B achieved the highest accuracy\n(58.5%) and was significantly better than other models, including o4-mini and\nDeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption\nand CO2 footprint among all models, with a Performance per kWh of 0.52 and a\ntotal CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x\ntimes more accuracy points per kWh and 172% less electricity usage while\nmaintaining higher accuracy. Conclusion Our study demonstrates that local LLMs\ncan be leveraged to develop RAGs that outperform commercial, online LLMs in\nmedical tasks, while having a smaller environmental impact. Our modular\nframework promotes sustainable AI development, reducing electricity usage and\naligning with the UNs Sustainable Development Goals.", "AI": {"tldr": "Custom RAG models outperform commercial LLMs in medical tasks with higher accuracy and lower energy consumption.", "motivation": "Address environmental and ethical concerns of AI in healthcare, focusing on resource use and patient privacy.", "method": "Developed a customizable RAG framework for medical tasks, tested with open-source LLMs like llama3.1:8b and medgemma-4b-it.", "result": "llama3.1-RAG achieved highest accuracy (58.5%) and lowest energy/CO2 footprint, outperforming commercial models.", "conclusion": "Local LLMs can create sustainable, high-performance RAGs for healthcare, aligning with UN sustainability goals."}}
{"id": "2506.19890", "pdf": "https://arxiv.org/pdf/2506.19890", "abs": "https://arxiv.org/abs/2506.19890", "authors": ["Ziru Zhang", "Jiadong Yu", "Danny H. K. Tsang"], "title": "Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The optimization of quality of experience (QoE) in multi-user virtual reality\n(VR) interactions demands a delicate balance between ultra-low latency,\nhigh-fidelity motion synchronization, and equitable resource allocation. While\nadaptive keyframe extraction mitigates transmission overhead, existing\napproaches often overlook the causal relationships among allocated bandwidth,\nCPU frequency, and user perception, limiting QoE gains. This paper proposes an\nintelligent framework to maximize QoE by integrating adaptive keyframe\nextraction with causal-aware reinforcement learning (RL). First, a novel QoE\nmetric is formulated using the Weber-Fechner Law, combining perceptual\nsensitivity, attention-driven priorities, and motion reconstruction accuracy.\nThe QoE optimization problem is then modeled as a mixed integer programming\n(MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational\nresources under horizon-fairness constraints. We propose Partial State Causal\nDeep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep\nDeterministic Policy Gradient (DDPG) method with causal influence detection. By\nleveraging causal information regarding how QoE is influenced and determined by\nvarious actions, we explore actions guided by weights calculated from causal\ninference (CI), which in turn improves training efficiency. Experiments\nconducted with the CMU Motion Capture Database demonstrate that our framework\nsignificantly reduces interactive latency, enhances QoE, and maintains\nfairness, achieving superior performance compared to benchmark methods.", "AI": {"tldr": "An intelligent framework combining adaptive keyframe extraction and causal-aware RL to optimize QoE in multi-user VR, outperforming benchmarks in latency, fairness, and QoE.", "motivation": "Existing methods ignore causal relationships between bandwidth, CPU frequency, and user perception, limiting QoE improvements in multi-user VR interactions.", "method": "Proposes PS-CDDPG, integrating DDPG with causal influence detection, and formulates a QoE metric using the Weber-Fechner Law. Optimizes keyframe ratios, bandwidth, and computational resources via MIP.", "result": "Significantly reduces latency, enhances QoE, and maintains fairness, outperforming benchmark methods in experiments.", "conclusion": "The framework effectively balances latency, fidelity, and fairness, demonstrating superior performance in multi-user VR QoE optimization."}}
{"id": "2506.20214", "pdf": "https://arxiv.org/pdf/2506.20214", "abs": "https://arxiv.org/abs/2506.20214", "authors": ["Yanzhe Chen", "Huasong Zhong", "Yan Li", "Zhenheng Yang"], "title": "UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.MM"], "comment": "19 pages, 5 figures", "summary": "Unified multimodal large language models (MLLMs) have shown promise in\njointly advancing multimodal understanding and generation, with visual\ncodebooks discretizing images into tokens for autoregressive modeling. Existing\ncodebook-based methods either rely on small vocabularies (~16K entries) that\nlack fine-grained semantics or naively scale up, resulting in low token\nutilization and unstable training. We propose UniCode$^2$, a cascaded codebook\nframework enabling large-scale, semantically aligned, and stable visual\ntokenization. By clustering millions of SigLIP sequence embeddings, we build a\n500K-entry codebook that preserves vision-language alignment while expanding\ncapacity. Stability is ensured via a cascaded design: a frozen codebook anchors\nthe embedding space, and a trainable codebook refines task-specific semantics.\nThis decoupling promotes high utilization and robust learning. Moreover, the\nalignment of our visual tokens with textual semantics enables seamless\nintegration with pretrained diffusion decoders, supporting high-quality visual\nsynthesis with minimal adaptation. UniCode^2 delivers strong performance across\ndiverse benchmarks, demonstrating the viability of scaling visual token spaces\nwithout sacrificing stability, semantics, or modularity.", "AI": {"tldr": "UniCode$^2$ introduces a cascaded codebook framework for stable and semantically aligned visual tokenization, improving multimodal understanding and generation.", "motivation": "Existing codebook-based methods either lack fine-grained semantics or suffer from instability due to naive scaling. UniCode$^2$ addresses these issues.", "method": "UniCode$^2$ clusters SigLIP sequence embeddings into a 500K-entry codebook, using a cascaded design (frozen and trainable codebooks) for stability and semantic alignment.", "result": "The framework achieves high token utilization, robust learning, and seamless integration with pretrained diffusion decoders, enabling high-quality visual synthesis.", "conclusion": "UniCode$^2$ demonstrates scalable visual tokenization without compromising stability, semantics, or modularity, performing well across benchmarks."}}
{"id": "2506.20093", "pdf": "https://arxiv.org/pdf/2506.20093", "abs": "https://arxiv.org/abs/2506.20093", "authors": ["Yilin Wang", "Peixuan Lei", "Jie Song", "Yuzhe Hao", "Tao Chen", "Yuxuan Zhang", "Lei Jia", "Yuanxiang Li", "Zhongyu Wei"], "title": "ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset", "categories": ["cs.CL"], "comment": null, "summary": "Time-series data are critical in diverse applications, such as industrial\nmonitoring, medical diagnostics, and climate research. However, effectively\nintegrating these high-dimensional temporal signals with natural language for\ndynamic, interactive tasks remains a significant challenge. To address this, we\nintroduce the Time-Series Question Answering (Time-Series QA) task and release\nEngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset\ndesigned to capture complex interactions between time-series signals and\nnatural language. Building on this resource, we propose the Instruct Time\nTransformer (ITFormer), a novel framework that bridges time-series encoders\nwith frozen large language models (LLMs). ITFormer effectively extracts,\naligns, and fuses temporal and textual features, achieving a strong improvement\nin QA accuracy over strong baselines with fewer than 1\\% additional trainable\nparameters. By combining computational efficiency with robust cross-modal\nmodeling, our work establishes a adaptable paradigm for integrating temporal\ndata with natural language, paving the way for new research and applications in\nmulti-modal AI. More details about the project, including datasets and code,\nare available at: https://pandalin98.github.io/itformer_site/", "AI": {"tldr": "The paper introduces Time-Series QA and EngineMT-QA dataset, proposing ITFormer to integrate time-series data with natural language, improving QA accuracy efficiently.", "motivation": "The challenge of integrating high-dimensional time-series data with natural language for dynamic tasks.", "method": "Proposes ITFormer, a framework combining time-series encoders with frozen LLMs to align and fuse temporal-textual features.", "result": "Achieves strong QA accuracy improvement with minimal additional trainable parameters (less than 1%).", "conclusion": "Establishes a paradigm for temporal-textual integration, enabling new multi-modal AI research and applications."}}
{"id": "2506.20243", "pdf": "https://arxiv.org/pdf/2506.20243", "abs": "https://arxiv.org/abs/2506.20243", "authors": ["Papa S\u00e9ga Wade", "Mihai Andries", "Ioannis Kanellos", "Thierry Moudenc"], "title": "CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment", "categories": ["cs.CL", "eess.AS"], "comment": "5 pages, accepted for presentation at EUSIPCO 2025", "summary": "Automatic fluency assessment (AFA) remains challenging, particularly in\ncapturing speech rhythm, pauses, and disfluencies in non-native speakers. We\nintroduce a chunk-based approach integrating self-supervised learning (SSL)\nmodels (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths\nin phonetic, prosodic, and noisy speech modeling, with a hierarchical\nCNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero\nvoice activity detection (Silero-VAD), enabling fine-grained temporal analysis\nwhile mitigating over-segmentation artifacts. SSL embeddings are fused via a\nlearnable weighted mechanism, balancing acoustic and linguistic features, and\nenriched with chunk-level fluency markers (e.g., speech rate, pause durations,\nn-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies\nacross chunks. Evaluated on Avalinguo and Speechocean762, our approach improves\nF1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines\non Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on\nAvalinguo, surpassing Pyannote.audio-based segmentation baselines. These\nfindings highlight chunk-based multi-SSL fusion for robust fluency evaluation,\nthough future work should explore generalization to dialects with irregular\nprosody.", "AI": {"tldr": "A chunk-based approach using self-supervised learning models (Wav2Vec2, HuBERT, WavLM) and a hierarchical CNN-BiLSTM framework improves fluency assessment in non-native speakers by analyzing speech rhythm, pauses, and disfluencies.", "motivation": "Automatic fluency assessment (AFA) struggles with capturing speech nuances like rhythm and disfluencies in non-native speakers, necessitating a more robust method.", "method": "Speech is segmented into breath-group chunks using Silero-VAD, with SSL embeddings fused via a weighted mechanism. A CNN-BiLSTM framework captures local and long-term dependencies.", "result": "The approach improves F1-score by 2.8 and Pearson correlation by 6.2 points on Speechocean762, and 4.2 F1-score and 4.0 Pearson points on Avalinguo, outperforming baselines.", "conclusion": "Chunk-based multi-SSL fusion enhances fluency evaluation, but future work should address generalization to dialects with irregular prosody."}}
{"id": "2506.20260", "pdf": "https://arxiv.org/pdf/2506.20260", "abs": "https://arxiv.org/abs/2506.20260", "authors": ["Junqi Jiang", "Antonio Rago", "Francesco Leofante", "Francesca Toni"], "title": "Argumentative Ensembling for Robust Recourse under Model Multiplicity", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "arXiv admin note: substantial text overlap with arXiv:2312.15097", "summary": "In machine learning, it is common to obtain multiple equally performing\nmodels for the same prediction task, e.g., when training neural networks with\ndifferent random seeds. Model multiplicity (MM) is the situation which arises\nwhen these competing models differ in their predictions for the same input, for\nwhich ensembling is often employed to determine an aggregation of the outputs.\nProviding recourse recommendations via counterfactual explanations (CEs) under\nMM thus becomes complex, since the CE may not be valid across all models, i.e.,\nthe CEs are not robust under MM. In this work, we formalise the problem of\nproviding recourse under MM, which we name recourse-aware ensembling (RAE). We\npropose the idea that under MM, CEs for each individual model should be\nconsidered alongside their predictions so that the aggregated prediction and\nrecourse are decided in tandem. Centred around this intuition, we introduce six\ndesirable properties for solutions to this problem. For solving RAE, we propose\na novel argumentative ensembling method which guarantees the robustness of CEs\nunder MM. Specifically, our method leverages computational argumentation to\nexplicitly represent the conflicts between models and counterfactuals regarding\nprediction results and CE validity. It then uses argumentation semantics to\nresolve the conflicts and obtain the final solution, in a manner which is\nparametric to the chosen semantics. Our method also allows for the\nspecification of preferences over the models under MM, allowing further\ncustomisation of the ensemble. In a comprehensive theoretical analysis, we\ncharacterise the behaviour of argumentative ensembling with four different\nargumentation semantics. We then empirically demonstrate the effectiveness of\nour approach in satisfying desirable properties with eight instantiations of\nour method. (Abstract is shortened for arXiv.)", "AI": {"tldr": "The paper addresses the challenge of providing robust counterfactual explanations (CEs) under model multiplicity (MM) in machine learning, proposing recourse-aware ensembling (RAE) and an argumentative ensembling method to ensure CE robustness.", "motivation": "Model multiplicity complicates recourse recommendations via CEs, as CEs may not be valid across all competing models. The paper aims to formalize and solve this problem.", "method": "Introduces recourse-aware ensembling (RAE) and a novel argumentative ensembling method leveraging computational argumentation to resolve conflicts between models and CEs.", "result": "The method guarantees CE robustness under MM, supports model preferences, and satisfies six desirable properties. Theoretical and empirical analyses validate its effectiveness.", "conclusion": "Argumentative ensembling effectively addresses recourse under MM, offering customizable and robust solutions for CEs."}}
{"id": "2506.18671", "pdf": "https://arxiv.org/pdf/2506.18671", "abs": "https://arxiv.org/abs/2506.18671", "authors": ["Yuqin Dai", "Wanlu Zhu", "Ronghui Li", "Xiu Li", "Zhenyu Zhang", "Jun Li", "Jian Yang"], "title": "TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography", "categories": ["cs.SD", "cs.CV", "cs.GR", "eess.AS"], "comment": null, "summary": "Music-driven dance generation has garnered significant attention due to its\nwide range of industrial applications, particularly in the creation of group\nchoreography. During the group dance generation process, however, most existing\nmethods still face three primary issues: multi-dancer collisions, single-dancer\nfoot sliding and abrupt swapping in the generation of long group dance. In this\npaper, we propose TCDiff++, a music-driven end-to-end framework designed to\ngenerate harmonious group dance. Specifically, to mitigate multi-dancer\ncollisions, we utilize a dancer positioning embedding to better maintain the\nrelative positioning among dancers. Additionally, we incorporate a\ndistance-consistency loss to ensure that inter-dancer distances remain within\nplausible ranges. To address the issue of single-dancer foot sliding, we\nintroduce a swap mode embedding to indicate dancer swapping patterns and design\na Footwork Adaptor to refine raw motion, thereby minimizing foot sliding. For\nlong group dance generation, we present a long group diffusion sampling\nstrategy that reduces abrupt position shifts by injecting positional\ninformation into the noisy input. Furthermore, we integrate a Sequence Decoder\nlayer to enhance the model's ability to selectively process long sequences.\nExtensive experiments demonstrate that our TCDiff++ achieves state-of-the-art\nperformance, particularly in long-duration scenarios, ensuring high-quality and\ncoherent group dance generation.", "AI": {"tldr": "TCDiff++ is a music-driven framework for harmonious group dance generation, addressing collisions, foot sliding, and abrupt swapping with innovative embeddings and loss functions.", "motivation": "Existing methods struggle with multi-dancer collisions, foot sliding, and abrupt swapping in long group dance generation, limiting quality and coherence.", "method": "TCDiff++ uses dancer positioning embedding, distance-consistency loss, swap mode embedding, Footwork Adaptor, long group diffusion sampling, and Sequence Decoder.", "result": "TCDiff++ achieves state-of-the-art performance, especially in long-duration scenarios, ensuring high-quality group dance generation.", "conclusion": "The proposed framework effectively addresses key challenges in group dance generation, delivering superior results."}}
{"id": "2506.20303", "pdf": "https://arxiv.org/pdf/2506.20303", "abs": "https://arxiv.org/abs/2506.20303", "authors": ["Lee Qi Zun", "Oscar Wong Jin Hao", "Nor Anita Binti Che Omar", "Zalifa Zakiah Binti Asnir", "Mohamad Sabri bin Sinal Zainal", "Goh Man Fye"], "title": "FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment", "categories": ["eess.IV", "cs.CL", "cs.CV"], "comment": null, "summary": "Automated fundus image quality assessment (FIQA) remains a challenge due to\nvariations in image acquisition and subjective expert evaluations. We introduce\nFundaQ-8, a novel expert-validated framework for systematically assessing\nfundus image quality using eight critical parameters, including field coverage,\nanatomical visibility, illumination, and image artifacts. Using FundaQ-8 as a\nstructured scoring reference, we develop a ResNet18-based regression model to\npredict continuous quality scores in the 0 to 1 range. The model is trained on\n1800 fundus images from real-world clinical sources and Kaggle datasets, using\ntransfer learning, mean squared error optimization, and standardized\npreprocessing. Validation against the EyeQ dataset and statistical analyses\nconfirm the framework's reliability and clinical interpretability.\nIncorporating FundaQ-8 into deep learning models for diabetic retinopathy\ngrading also improves diagnostic robustness, highlighting the value of\nquality-aware training in real-world screening applications.", "AI": {"tldr": "FundaQ-8 is a framework for assessing fundus image quality using eight parameters, with a ResNet18-based model trained to predict scores, improving diagnostic robustness in diabetic retinopathy grading.", "motivation": "Automated fundus image quality assessment is challenging due to variability in acquisition and subjective evaluations, necessitating a standardized approach.", "method": "Developed FundaQ-8 with eight parameters, trained a ResNet18-based regression model on 1800 images using transfer learning and MSE optimization.", "result": "Validation on the EyeQ dataset confirmed reliability and clinical interpretability; integration improved diabetic retinopathy grading robustness.", "conclusion": "FundaQ-8 enhances fundus image quality assessment and diagnostic reliability, proving valuable for real-world screening."}}
{"id": "2506.20134", "pdf": "https://arxiv.org/pdf/2506.20134", "abs": "https://arxiv.org/abs/2506.20134", "authors": ["Ningwei Xie", "Zizi Tian", "Lei Yang", "Xiao-Ping Zhang", "Meng Guo", "Jie Li"], "title": "From 2D to 3D Cognition: A Brief Survey of General World Models", "categories": ["cs.CV"], "comment": null, "summary": "World models have garnered increasing attention in the development of\nartificial general intelligence (AGI), serving as computational frameworks for\nlearning representations of the external world and forecasting future states.\nWhile early efforts focused on 2D visual perception and simulation, recent\n3D-aware generative world models have demonstrated the ability to synthesize\ngeometrically consistent, interactive 3D environments, marking a shift toward\n3D spatial cognition. Despite rapid progress, the field lacks systematic\nanalysis to categorize emerging techniques and clarify their roles in advancing\n3D cognitive world models. This survey addresses this need by introducing a\nconceptual framework, providing a structured and forward-looking review of\nworld models transitioning from 2D perception to 3D cognition. Within this\nframework, we highlight two key technological drivers, particularly advances in\n3D representations and the incorporation of world knowledge, as fundamental\npillars. Building on these, we dissect three core cognitive capabilities that\nunderpin 3D world modeling: 3D physical scene generation, 3D spatial reasoning,\nand 3D spatial interaction. We further examine the deployment of these\ncapabilities in real-world applications, including embodied AI, autonomous\ndriving, digital twin, and gaming/VR. Finally, we identify challenges across\ndata, modeling, and deployment, and outline future directions for advancing\nmore robust and generalizable 3D world models.", "AI": {"tldr": "A survey on 3D-aware generative world models, highlighting their shift from 2D to 3D cognition, key technological drivers, core capabilities, applications, and future challenges.", "motivation": "The lack of systematic analysis for emerging 3D cognitive world models motivates this survey to categorize techniques and clarify their roles in advancing AGI.", "method": "Introduces a conceptual framework to review world models, focusing on 3D representations and world knowledge as key drivers, and dissects three core cognitive capabilities.", "result": "Identifies applications in embodied AI, autonomous driving, digital twin, and gaming/VR, and outlines challenges in data, modeling, and deployment.", "conclusion": "Future directions aim to advance robust and generalizable 3D world models, addressing current limitations."}}
{"id": "2506.20018", "pdf": "https://arxiv.org/pdf/2506.20018", "abs": "https://arxiv.org/abs/2506.20018", "authors": ["Zechun Deng", "Ziwei Liu", "Ziqian Bi", "Junhao Song", "Chia Xin Liang", "Joe Yeong", "Junfeng Hao"], "title": "Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models", "categories": ["cs.AI", "cs.AR"], "comment": null, "summary": "This paper investigates real-time decision support systems that leverage\nlow-latency AI models, bringing together recent progress in holistic AI-driven\ndecision tools, integration with Edge-IoT technologies, and approaches for\neffective human-AI teamwork. It looks into how large language models can assist\ndecision-making, especially when resources are limited. The research also\nexamines the effects of technical developments such as DeLLMa, methods for\ncompressing models, and improvements for analytics on edge devices, while also\naddressing issues like limited resources and the need for adaptable frameworks.\nThrough a detailed review, the paper offers practical perspectives on\ndevelopment strategies and areas of application, adding to the field by\npointing out opportunities for more efficient and flexible AI-supported\nsystems. The conclusions set the stage for future breakthroughs in this\nfast-changing area, highlighting how AI can reshape real-time decision support.", "AI": {"tldr": "The paper explores real-time AI-driven decision support systems, focusing on low-latency models, Edge-IoT integration, and human-AI collaboration, with insights into model compression and edge analytics.", "motivation": "To advance efficient and adaptable AI-supported decision-making, especially in resource-limited scenarios, leveraging technologies like large language models and Edge-IoT.", "method": "A detailed review of holistic AI tools, model compression (e.g., DeLLMa), edge device improvements, and human-AI teamwork approaches.", "result": "Practical development strategies and application insights, identifying opportunities for more flexible and efficient AI systems.", "conclusion": "The paper lays groundwork for future AI breakthroughs in real-time decision support, emphasizing its transformative potential."}}
{"id": "2506.19891", "pdf": "https://arxiv.org/pdf/2506.19891", "abs": "https://arxiv.org/abs/2506.19891", "authors": ["Qinghui Gong", "Xue Yang", "Xiaohu Tang"], "title": "Orthogonal Soft Pruning for Efficient Class Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages,3 figures", "summary": "Machine unlearning aims to selectively remove class-specific knowledge from\npretrained neural networks to satisfy privacy regulations such as the GDPR.\nExisting methods typically face a trade-off between unlearning speed and\npreservation of predictive accuracy, often incurring either high computational\noverhead or significant performance degradation on retained classes. In this\npaper, we propose a novel class-aware soft pruning framework leveraging\northogonal convolutional kernel regularization to achieve rapid and precise\nforgetting with millisecond-level response times. By enforcing orthogonality\nconstraints during training, our method decorrelates convolutional filters and\ndisentangles feature representations, while efficiently identifying\nclass-specific channels through activation difference analysis. Extensive\nevaluations across multiple architectures and datasets demonstrate stable\npruning with near-instant execution, complete forgetting of targeted classes,\nand minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100,\nand TinyImageNet confirm that our approach substantially reduces membership\ninference attack risks and accelerates unlearning by orders of magnitude\ncompared to state-of-the-art baselines. This framework provides an efficient,\npractical solution for real-time machine unlearning in Machine Learning as a\nService (MLaaS) scenarios.", "AI": {"tldr": "A novel class-aware soft pruning framework for machine unlearning achieves rapid, precise forgetting with minimal accuracy loss, outperforming existing methods in speed and performance.", "motivation": "To address the trade-off between unlearning speed and predictive accuracy in machine unlearning, ensuring compliance with privacy regulations like GDPR.", "method": "Uses orthogonal convolutional kernel regularization and activation difference analysis to decorrelate filters and identify class-specific channels for efficient pruning.", "result": "Demonstrates millisecond-level response times, complete forgetting of targeted classes, and minimal accuracy loss on retained data across multiple datasets.", "conclusion": "The framework offers an efficient, practical solution for real-time machine unlearning in MLaaS scenarios, reducing attack risks and outperforming baselines."}}
{"id": "2506.20370", "pdf": "https://arxiv.org/pdf/2506.20370", "abs": "https://arxiv.org/abs/2506.20370", "authors": ["Abdullah All Tanvir", "Xin Zhong"], "title": "InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking", "categories": ["cs.CV", "cs.LG", "cs.MM"], "comment": null, "summary": "This paper introduces a novel deep learning framework for robust image\nzero-watermarking based on distortion-invariant feature learning. As a\nzero-watermarking scheme, our method leaves the original image unaltered and\nlearns a reference signature through optimization in the feature space. The\nproposed framework consists of two key modules. In the first module, a feature\nextractor is trained via noise-adversarial learning to generate representations\nthat are both invariant to distortions and semantically expressive. This is\nachieved by combining adversarial supervision against a distortion\ndiscriminator and a reconstruction constraint to retain image content. In the\nsecond module, we design a learning-based multibit zero-watermarking scheme\nwhere the trained invariant features are projected onto a set of trainable\nreference codes optimized to match a target binary message. Extensive\nexperiments on diverse image datasets and a wide range of distortions show that\nour method achieves state-of-the-art robustness in both feature stability and\nwatermark recovery. Comparative evaluations against existing self-supervised\nand deep watermarking techniques further highlight the superiority of our\nframework in generalization and robustness.", "AI": {"tldr": "A deep learning framework for robust image zero-watermarking using distortion-invariant feature learning, leaving the original image unaltered and achieving state-of-the-art robustness.", "motivation": "To develop a zero-watermarking method that preserves the original image while ensuring robustness against distortions.", "method": "Combines noise-adversarial learning for invariant feature extraction and a learning-based multibit zero-watermarking scheme for message matching.", "result": "Achieves superior robustness in feature stability and watermark recovery, outperforming existing methods.", "conclusion": "The framework excels in generalization and robustness, making it a leading solution for zero-watermarking."}}
{"id": "2506.20100", "pdf": "https://arxiv.org/pdf/2506.20100", "abs": "https://arxiv.org/abs/2506.20100", "authors": ["Vardhan Dongre", "Chi Gui", "Shubham Garg", "Hooshang Nayyeri", "Gokhan Tur", "Dilek Hakkani-T\u00fcr", "Vikram S. Adve"], "title": "MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "66 pages, 32 figures, 23 tables", "summary": "We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning\nand decision-making in consultative interaction settings. Designed for the\nagriculture domain, MIRAGE captures the full complexity of expert consultations\nby combining natural user queries, expert-authored responses, and image-based\ncontext, offering a high-fidelity benchmark for evaluating models on grounded\nreasoning, clarification strategies, and long-form generation in a real-world,\nknowledge-intensive domain. Grounded in over 35,000 real user-expert\ninteractions and curated through a carefully designed multi-step pipeline,\nMIRAGE spans diverse crop health, pest diagnosis, and crop management\nscenarios. The benchmark includes more than 7,000 unique biological entities,\ncovering plant species, pests, and diseases, making it one of the most\ntaxonomically diverse benchmarks available for vision-language models, grounded\nin the real world. Unlike existing benchmarks that rely on well-specified user\ninputs and closed-set taxonomies, MIRAGE features underspecified, context-rich\nscenarios with open-world settings, requiring models to infer latent knowledge\ngaps, handle rare entities, and either proactively guide the interaction or\nrespond. Project Page: https://mirage-benchmark.github.io", "AI": {"tldr": "MIRAGE is a multimodal benchmark for expert-level reasoning in agriculture, combining natural queries, expert responses, and image-based context. It features real-world, underspecified scenarios with diverse biological entities.", "motivation": "To address the lack of benchmarks for grounded reasoning and long-form generation in knowledge-intensive domains like agriculture.", "method": "Curated from 35,000 real user-expert interactions, MIRAGE includes 7,000+ biological entities and uses a multi-step pipeline for high-fidelity scenarios.", "result": "MIRAGE offers a diverse, open-world benchmark for evaluating vision-language models on expert-level tasks like pest diagnosis and crop management.", "conclusion": "MIRAGE fills a gap in multimodal benchmarks by providing a realistic, taxonomically diverse dataset for complex reasoning in agriculture."}}
{"id": "2409.04803", "pdf": "https://arxiv.org/pdf/2409.04803", "abs": "https://arxiv.org/abs/2409.04803", "authors": ["Donghang Wu", "Yiwen Wang", "Xihong Wu", "Tianshu Qu"], "title": "Cross-attention Inspired Selective State Space Models for Target Sound Extraction", "categories": ["eess.AS", "cs.SD"], "comment": "This is the preprint version of the paper published in ICASSP 2025.\n  The final version is available at IEEE Xplore:\n  https://ieeexplore.ieee.org/document/10890178", "summary": "The Transformer model, particularly its cross-attention module, is widely\nused for feature fusion in target sound extraction which extracts the signal of\ninterest based on given clues. Despite its effectiveness, this approach suffers\nfrom low computational efficiency. Recent advancements in state space models,\nnotably the latest work Mamba, have shown comparable performance to\nTransformer-based methods while significantly reducing computational complexity\nin various tasks. However, Mamba's applicability in target sound extraction is\nlimited due to its inability to capture dependencies between different\nsequences as the cross-attention does. In this paper, we propose CrossMamba for\ntarget sound extraction, which leverages the hidden attention mechanism of\nMamba to compute dependencies between the given clues and the audio mixture.\nThe calculation of Mamba can be divided to the query, key and value. We utilize\nthe clue to generate the query and the audio mixture to derive the key and\nvalue, adhering to the principle of the cross-attention mechanism in\nTransformers. Experimental results from two representative target sound\nextraction methods validate the efficacy of the proposed CrossMamba.", "AI": {"tldr": "CrossMamba, a novel method for target sound extraction, combines Mamba's efficiency with cross-attention-like dependencies, outperforming traditional Transformer-based approaches.", "motivation": "Transformer models for target sound extraction are effective but computationally inefficient. Mamba offers efficiency but lacks cross-sequence dependency capture. CrossMamba bridges this gap.", "method": "CrossMamba uses Mamba's hidden attention to compute dependencies between clues and audio mixtures, mimicking cross-attention by generating queries from clues and keys/values from mixtures.", "result": "Experiments show CrossMamba's efficacy in target sound extraction, validating its performance against Transformer-based methods.", "conclusion": "CrossMamba successfully integrates Mamba's efficiency with cross-attention-like capabilities, offering a promising alternative for target sound extraction."}}
{"id": "2506.20415", "pdf": "https://arxiv.org/pdf/2506.20415", "abs": "https://arxiv.org/abs/2506.20415", "authors": ["Dipayan Saha", "Shams Tarek", "Hasan Al Shaikh", "Khan Thamid Hasan", "Pavan Sai Nalluri", "Md. Ajoad Hasan", "Nashmin Alam", "Jingbo Zhou", "Sujan Kumar Saha", "Mark Tehranipoor", "Farimah Farahmandi"], "title": "SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.MA"], "comment": null, "summary": "Ensuring the security of complex system-on-chips (SoCs) designs is a critical\nimperative, yet traditional verification techniques struggle to keep pace due\nto significant challenges in automation, scalability, comprehensiveness, and\nadaptability. The advent of large language models (LLMs), with their remarkable\ncapabilities in natural language understanding, code generation, and advanced\nreasoning, presents a new paradigm for tackling these issues. Moving beyond\nmonolithic models, an agentic approach allows for the creation of multi-agent\nsystems where specialized LLMs collaborate to solve complex problems more\neffectively. Recognizing this opportunity, we introduce SV-LLM, a novel\nmulti-agent assistant system designed to automate and enhance SoC security\nverification. By integrating specialized agents for tasks like verification\nquestion answering, security asset identification, threat modeling, test plan\nand property generation, vulnerability detection, and simulation-based bug\nvalidation, SV-LLM streamlines the workflow. To optimize their performance in\nthese diverse tasks, agents leverage different learning paradigms, such as\nin-context learning, fine-tuning, and retrieval-augmented generation (RAG). The\nsystem aims to reduce manual intervention, improve accuracy, and accelerate\nsecurity analysis, supporting proactive identification and mitigation of risks\nearly in the design cycle. We demonstrate its potential to transform hardware\nsecurity practices through illustrative case studies and experiments that\nshowcase its applicability and efficacy.", "AI": {"tldr": "SV-LLM is a multi-agent system using specialized LLMs to automate and enhance SoC security verification, addressing challenges in automation, scalability, and adaptability.", "motivation": "Traditional verification techniques for SoC security are inadequate due to automation, scalability, and adaptability issues, prompting the use of LLMs for improvement.", "method": "SV-LLM employs specialized agents for tasks like threat modeling, vulnerability detection, and simulation-based validation, leveraging learning paradigms like in-context learning and RAG.", "result": "The system reduces manual intervention, improves accuracy, and accelerates security analysis, as demonstrated by case studies.", "conclusion": "SV-LLM has the potential to transform hardware security practices by proactively identifying and mitigating risks early in the design cycle."}}
{"id": "2501.12050", "pdf": "https://arxiv.org/pdf/2501.12050", "abs": "https://arxiv.org/abs/2501.12050", "authors": ["Thejan Rajapakshe", "Rajib Rana", "Farina Riaz", "Sara Khalifa", "Bj\u00f6rn W. Schuller"], "title": "Representation Learning with Parameterised Quantum Circuits for Advancing Speech Emotion Recognition", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Quantum machine learning (QML) offers a promising avenue for advancing\nrepresentation learning in complex signal domains. In this study, we\ninvestigate the use of parameterised quantum circuits (PQCs) for speech emotion\nrecognition (SER) a challenging task due to the subtle temporal variations and\noverlapping affective states in vocal signals. We propose a hybrid quantum\nclassical architecture that integrates PQCs into a conventional convolutional\nneural network (CNN), leveraging quantum properties such as superposition and\nentanglement to enrich emotional feature representations. Experimental\nevaluations on three benchmark datasets IEMOCAP, RECOLA, and MSP-IMPROV\ndemonstrate that our hybrid model achieves improved classification performance\nrelative to a purely classical CNN baseline, with over 50% reduction in\ntrainable parameters. This work provides early evidence of the potential for\nQML to enhance emotion recognition and lays the foundation for future\nquantum-enabled affective computing systems.", "AI": {"tldr": "A hybrid quantum-classical model using PQCs integrated with CNNs improves speech emotion recognition, reducing parameters by 50% and outperforming classical CNNs.", "motivation": "To explore quantum machine learning's potential for enhancing representation learning in complex signal domains like speech emotion recognition, addressing challenges like subtle temporal variations and overlapping affective states.", "method": "Proposes a hybrid quantum-classical architecture combining parameterised quantum circuits (PQCs) with CNNs, leveraging quantum properties like superposition and entanglement.", "result": "The hybrid model outperforms classical CNNs on benchmark datasets (IEMOCAP, RECOLA, MSP-IMPROV) with a 50% reduction in trainable parameters.", "conclusion": "Demonstrates QML's potential for emotion recognition and lays groundwork for future quantum-enabled affective computing systems."}}
{"id": "2506.20319", "pdf": "https://arxiv.org/pdf/2506.20319", "abs": "https://arxiv.org/abs/2506.20319", "authors": ["Caden Sweeney", "Du Yong Kim", "Branko Ristic", "Brian Cheung"], "title": "Transformer Based Multi-Target Bernoulli Tracking for Maritime Radar", "categories": ["eess.IV", "eess.SP"], "comment": "8 pages, 8 figures, for submission also to IEEE journal", "summary": "Multi-target tracking in the maritime domain is a challenging problem due to\nthe non-Gaussian and fluctuating characteristics of sea clutter. This article\ninvestigates the use of machine learning (ML) to the detection and tracking of\nlow SIR targets in the maritime domain. The proposed method uses a transformer\nto extract point measurements from range-azimuth maps, before clustering and\ntracking using the Labelled mulit- Bernoulli (LMB) filter. A measurement driven\nbirth density design based on the transformer attention maps is also developed.\nThe error performance of the transformer based approach is presented and\ncompared with a constant false alarm rate (CFAR) detection technique. The LMB\nfilter is run in two scenarios, an ideal birth approach, and the measurement\ndriven birth approach. Experiments indicate that the transformer based method\nhas superior performance to the CFAR approach for all target scenarios\ndiscussed", "AI": {"tldr": "The paper proposes a transformer-based ML method for maritime multi-target tracking, outperforming CFAR in low SIR scenarios.", "motivation": "Maritime tracking is challenging due to non-Gaussian sea clutter; ML offers potential for better detection and tracking of low SIR targets.", "method": "Uses a transformer to extract measurements from range-azimuth maps, clusters and tracks with LMB filter, and designs a measurement-driven birth density.", "result": "Transformer-based method outperforms CFAR in all tested scenarios.", "conclusion": "The transformer approach is superior for maritime target tracking, especially in low SIR conditions."}}
{"id": "2506.20151", "pdf": "https://arxiv.org/pdf/2506.20151", "abs": "https://arxiv.org/abs/2506.20151", "authors": ["Haipeng Fan", "Shiyuan Zhang", "Baohunesitu", "Zihang Guo", "Huaiwen Zhang"], "title": "EAR: Erasing Concepts from Unified Autoregressive Models", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 7 figures, 1 tables", "summary": "Autoregressive (AR) models have achieved unified and strong performance\nacross both visual understanding and image generation tasks. However, removing\nundesired concepts from AR models while maintaining overall generation quality\nremains an open challenge. In this paper, we propose Erasure Autoregressive\nModel (EAR), a fine-tuning method for effective and utility-preserving concept\nerasure in AR models. Specifically, we introduce Windowed Gradient Accumulation\n(WGA) strategy to align patch-level decoding with erasure objectives, and\nThresholded Loss Masking (TLM) strategy to protect content unrelated to the\ntarget concept during fine-tuning. Furthermore, we propose a novel benchmark,\nErase Concept Generator and Visual Filter (ECGVF), aim at provide a more\nrigorous and comprehensive foundation for evaluating concept erasure in AR\nmodels. Specifically, we first employ structured templates across diverse large\nlanguage models (LLMs) to pre-generate a large-scale corpus of\ntarget-replacement concept prompt pairs. Subsequently, we generate images from\nthese prompts and subject them to rigorous filtering via a visual classifier to\nensure concept fidelity and alignment. Extensive experimental results conducted\non the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR\nachieves marked improvements in both erasure effectiveness and model utility\npreservation. Code is available at: https://github.com/immc-lab/ear/", "AI": {"tldr": "The paper proposes EAR, a fine-tuning method for concept erasure in AR models, introducing WGA and TLM strategies, and a new benchmark ECGVF for evaluation.", "motivation": "AR models struggle with removing undesired concepts without degrading generation quality. EAR addresses this challenge.", "method": "EAR uses Windowed Gradient Accumulation (WGA) and Thresholded Loss Masking (TLM) for fine-tuning. ECGVF benchmark is introduced for evaluation.", "result": "EAR improves erasure effectiveness and utility preservation, demonstrated on the Janus-Pro AR model.", "conclusion": "EAR provides a robust solution for concept erasure in AR models, validated by the ECGVF benchmark."}}
{"id": "2506.20020", "pdf": "https://arxiv.org/pdf/2506.20020", "abs": "https://arxiv.org/abs/2506.20020", "authors": ["Saloni Dash", "Am\u00e9lie Reymond", "Emma S. Spiro", "Aylin Caliskan"], "title": "Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning in humans is prone to biases due to underlying motivations like\nidentity protection, that undermine rational decision-making and judgment. This\nmotivated reasoning at a collective level can be detrimental to society when\ndebating critical issues such as human-driven climate change or vaccine safety,\nand can further aggravate political polarization. Prior studies have reported\nthat large language models (LLMs) are also susceptible to human-like cognitive\nbiases, however, the extent to which LLMs selectively reason toward\nidentity-congruent conclusions remains largely unexplored. Here, we investigate\nwhether assigning 8 personas across 4 political and socio-demographic\nattributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and\nproprietary) across two reasoning tasks from human-subject studies -- veracity\ndiscernment of misinformation headlines and evaluation of numeric scientific\nevidence -- we find that persona-assigned LLMs have up to 9% reduced veracity\ndiscernment relative to models without personas. Political personas\nspecifically, are up to 90% more likely to correctly evaluate scientific\nevidence on gun control when the ground truth is congruent with their induced\npolitical identity. Prompt-based debiasing methods are largely ineffective at\nmitigating these effects. Taken together, our empirical findings are the first\nto suggest that persona-assigned LLMs exhibit human-like motivated reasoning\nthat is hard to mitigate through conventional debiasing prompts -- raising\nconcerns of exacerbating identity-congruent reasoning in both LLMs and humans.", "AI": {"tldr": "Persona-assigned LLMs exhibit human-like motivated reasoning, reducing veracity discernment and aligning with identity-congruent conclusions, with limited success in debiasing.", "motivation": "To explore if LLMs show human-like motivated reasoning when assigned personas, impacting critical societal debates.", "method": "Tested 8 LLMs with personas across political and socio-demographic attributes on veracity discernment and scientific evidence evaluation.", "result": "Persona-assigned LLMs showed reduced veracity discernment (up to 9%) and political personas were 90% more likely to align with identity-congruent evidence. Debiasing methods were ineffective.", "conclusion": "LLMs exhibit human-like motivated reasoning, raising concerns about exacerbating biases in AI and human decision-making."}}
{"id": "2506.19893", "pdf": "https://arxiv.org/pdf/2506.19893", "abs": "https://arxiv.org/abs/2506.19893", "authors": ["Jingzhi Hu", "Geoffrey Ye Li"], "title": "Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks", "categories": ["cs.LG", "cs.AI", "cs.IT", "eess.IV", "math.IT"], "comment": null, "summary": "Due to the surging amount of AI-generated content (AIGC), its provisioning to\nedges and mobile users from the cloud incurs substantial traffic on networks.\nGenerative semantic communication (GSC) offers a promising solution by\ntransmitting highly compact information, i.e., prompt text and latent\nrepresentations, instead of high-dimensional AIGC data. However, GSC relies on\nthe alignment between the knowledge in the cloud generative AI (GAI) and that\npossessed by the edges and users, and between the knowledge for wireless\ntransmission and that of actual channels, which remains challenging. In this\npaper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm\nfor GSC systems. The core idea is to distill the generation knowledge from the\ncloud-GAI into low-rank matrices, which can be incorporated by the edge and\nused to adapt the transmission knowledge to diverse wireless channel\nconditions. DeKA-g comprises two novel methods: metaword-aided knowledge\ndistillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD,\nan optimized metaword is employed to enhance the efficiency of knowledge\ndistillation, while VGSA enables efficient adaptation to diverse compression\nrates and SNR ranges. From simulation results, DeKA-g improves the alignment\nbetween the edge-generated images and the cloud-generated ones by 44%.\nMoreover, it adapts to compression rates with 116% higher efficiency than the\nbaseline and enhances the performance in low-SNR conditions by 28%.", "AI": {"tldr": "Proposes DeKA-g, a distillation-enabled knowledge alignment algorithm for generative semantic communication (GSC) to improve efficiency and adaptability in transmitting AI-generated content.", "motivation": "Addresses the challenge of aligning knowledge between cloud-GAI and edges/users, and between transmission knowledge and actual wireless channels in GSC systems.", "method": "Introduces DeKA-g with two novel methods: metaword-aided knowledge distillation (MAKD) for efficient knowledge transfer and variable-rate grouped SNR adaptation (VGSA) for adapting to diverse channel conditions.", "result": "Improves alignment between edge- and cloud-generated images by 44%, adapts to compression rates 116% more efficiently, and enhances low-SNR performance by 28%.", "conclusion": "DeKA-g effectively addresses knowledge alignment challenges in GSC, significantly improving performance and adaptability."}}
{"id": "2506.20494", "pdf": "https://arxiv.org/pdf/2506.20494", "abs": "https://arxiv.org/abs/2506.20494", "authors": ["Qihang Jin", "Enze Ge", "Yuhang Xie", "Hongying Luo", "Junhao Song", "Ziqian Bi", "Chia Xin Liang", "Jibin Guan", "Joe Yeong", "Junfeng Hao"], "title": "Multimodal Representation Learning and Fusion", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "Multi-modal learning is a fast growing area in artificial intelligence. It\ntries to help machines understand complex things by combining information from\ndifferent sources, like images, text, and audio. By using the strengths of each\nmodality, multi-modal learning allows AI systems to build stronger and richer\ninternal representations. These help machines better interpretation, reasoning,\nand making decisions in real-life situations. This field includes core\ntechniques such as representation learning (to get shared features from\ndifferent data types), alignment methods (to match information across\nmodalities), and fusion strategies (to combine them by deep learning models).\nAlthough there has been good progress, some major problems still remain. Like\ndealing with different data formats, missing or incomplete inputs, and\ndefending against adversarial attacks. Researchers now are exploring new\nmethods, such as unsupervised or semi-supervised learning, AutoML tools, to\nmake models more efficient and easier to scale. And also more attention on\ndesigning better evaluation metrics or building shared benchmarks, make it\neasier to compare model performance across tasks and domains. As the field\ncontinues to grow, multi-modal learning is expected to improve many areas:\ncomputer vision, natural language processing, speech recognition, and\nhealthcare. In the future, it may help to build AI systems that can understand\nthe world in a way more like humans, flexible, context aware, and able to deal\nwith real-world complexity.", "AI": {"tldr": "Multi-modal learning combines data from sources like images, text, and audio to enhance AI understanding and decision-making, using techniques like representation learning, alignment, and fusion. Challenges include handling diverse data formats and adversarial attacks. Future directions focus on unsupervised learning, AutoML, and better evaluation metrics.", "motivation": "To improve AI systems' ability to interpret and reason by leveraging multiple data modalities, addressing real-world complexity.", "method": "Uses representation learning, alignment methods, and fusion strategies to integrate multi-modal data. Explores unsupervised/semi-supervised learning and AutoML for scalability.", "result": "Enhances AI's interpretation, reasoning, and decision-making capabilities. Identifies challenges like data diversity and adversarial attacks.", "conclusion": "Multi-modal learning holds promise for advancing AI in fields like computer vision and healthcare, aiming for human-like understanding and adaptability."}}
{"id": "2506.20112", "pdf": "https://arxiv.org/pdf/2506.20112", "abs": "https://arxiv.org/abs/2506.20112", "authors": ["Songsoo Kim", "Seungtae Lee", "See Young Lee", "Joonho Kim", "Keechan Kan", "Dukyong Yoon"], "title": "A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection", "categories": ["cs.CL", "I.2.7"], "comment": "29 pages, 5 figures, 4 tables. Code available at\n  https://github.com/radssk/mp-rred", "summary": "Background: The positive predictive value (PPV) of large language model\n(LLM)-based proofreading for radiology reports is limited due to the low error\nprevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV\nand reduces operational costs compared with baseline approaches. Materials and\nMethods: A retrospective analysis was performed on 1,000 consecutive radiology\nreports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III\ndatabase. Two external datasets (CheXpert and Open-i) were validation sets.\nThree LLM frameworks were tested: (1) single-prompt detector; (2) extractor\nplus detector; and (3) extractor, detector, and false-positive verifier.\nPrecision was measured by PPV and absolute true positive rate (aTPR).\nEfficiency was calculated from model inference charges and reviewer\nremuneration. Statistical significance was tested using cluster bootstrap,\nexact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV\nincreased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118,\nFramework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs.\nbaselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per\n1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and\nUSD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively.\nHuman-reviewed reports decreased from 192 to 88. External validation supported\nFramework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR\n(0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and\nreduced operational costs, maintaining detection performance, providing an\neffective strategy for AI-assisted radiology report quality assurance.", "AI": {"tldr": "A three-pass LLM framework improves PPV and reduces costs for radiology report proofreading compared to simpler methods.", "motivation": "The low error prevalence in radiology reports limits the PPV of LLM-based proofreading, prompting the need for a more efficient framework.", "method": "Three LLM frameworks were tested: single-prompt detector, extractor plus detector, and extractor-detector-false-positive verifier. Metrics included PPV, aTPR, and operational costs.", "result": "The three-pass framework (Framework 3) significantly improved PPV (0.159 vs. 0.063/0.079) and reduced costs by 42.6% (USD 5.58 vs. USD 9.72). Detection performance (aTPR) remained stable.", "conclusion": "The three-pass LLM framework is effective for AI-assisted radiology report quality assurance, enhancing PPV and reducing costs without compromising detection."}}
{"id": "2501.18227", "pdf": "https://arxiv.org/pdf/2501.18227", "abs": "https://arxiv.org/abs/2501.18227", "authors": ["Or Berebi", "Zamir Ben-Hur", "David Lou Alon", "Boaz Rafaely"], "title": "BSM-iMagLS: ILD Informed Binaural Signal Matching for Reproduction with Head-Mounted Microphone Arrays", "categories": ["eess.AS", "cs.SD"], "comment": "14 pages, 8 figures, Accepted to IEEE TASLP (IEEE Transactions on\n  Audio, Speech and Language Processing, 2025)", "summary": "Headphone listening in applications such as augmented and virtual reality (AR\nand VR) relies on high-quality spatial audio to ensure immersion, making\naccurate binaural reproduction a critical component. As capture devices,\nwearable arrays with only a few microphones with irregular arrangement face\nchallenges in achieving a reproduction quality comparable to that of arrays\nwith a large number of microphones. Binaural signal matching (BSM) has recently\nbeen presented as a signal-independent approach for generating high-quality\nbinaural signal using only a few microphones, which is further improved using\nmagnitude-least squares (MagLS) optimization at high frequencies. This paper\nextends BSM with MagLS by introducing interaural level difference (ILD) into\nthe MagLS, integrated into BSM (BSM-iMagLS). Using a deep neural network\n(DNN)-based solver, BSM-iMagLS achieves joint optimization of magnitude, ILD,\nand magnitude derivatives, improving spatial fidelity. Performance is validated\nthrough theoretical analysis, numerical simulations with diverse HRTFs and\nhead-mounted array geometries, and listening experiments, demonstrating a\nsubstantial reduction in ILD errors while maintaining comparable magnitude\naccuracy to state-of-the-art solutions. The results highlight the potential of\nBSM-iMagLS to enhance binaural reproduction for wearable and portable devices.", "AI": {"tldr": "The paper introduces BSM-iMagLS, an improved binaural signal matching method that integrates interaural level difference (ILD) into magnitude-least squares optimization, enhancing spatial audio quality for wearable devices.", "motivation": "High-quality spatial audio is crucial for AR/VR immersion, but wearable microphone arrays with few microphones struggle to match the performance of larger arrays.", "method": "Extends BSM with MagLS by incorporating ILD into the optimization, using a DNN-based solver for joint optimization of magnitude, ILD, and derivatives.", "result": "Demonstrates reduced ILD errors while maintaining magnitude accuracy, validated through simulations and listening experiments.", "conclusion": "BSM-iMagLS improves binaural reproduction for wearable devices, offering potential for better AR/VR audio experiences."}}
{"id": "2506.20430", "pdf": "https://arxiv.org/pdf/2506.20430", "abs": "https://arxiv.org/abs/2506.20430", "authors": ["Weike Zhao", "Chaoyi Wu", "Yanjie Fan", "Xiaoman Zhang", "Pengcheng Qiu", "Yuze Sun", "Xiao Zhou", "Yanfeng Wang", "Ya Zhang", "Yongguo Yu", "Kun Sun", "Weidi Xie"], "title": "An Agentic System for Rare Disease Diagnosis with Traceable Reasoning", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MA"], "comment": null, "summary": "Rare diseases collectively affect over 300 million individuals worldwide, yet\ntimely and accurate diagnosis remains a pervasive challenge. This is largely\ndue to their clinical heterogeneity, low individual prevalence, and the limited\nfamiliarity most clinicians have with rare conditions. Here, we introduce\nDeepRare, the first rare disease diagnosis agentic system powered by a large\nlanguage model (LLM), capable of processing heterogeneous clinical inputs. The\nsystem generates ranked diagnostic hypotheses for rare diseases, each\naccompanied by a transparent chain of reasoning that links intermediate\nanalytic steps to verifiable medical evidence.\n  DeepRare comprises three key components: a central host with a long-term\nmemory module; specialized agent servers responsible for domain-specific\nanalytical tasks integrating over 40 specialized tools and web-scale,\nup-to-date medical knowledge sources, ensuring access to the most current\nclinical information. This modular and scalable design enables complex\ndiagnostic reasoning while maintaining traceability and adaptability. We\nevaluate DeepRare on eight datasets. The system demonstrates exceptional\ndiagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013\ndiseases. In HPO-based evaluations, DeepRare significantly outperforms other 15\nmethods, like traditional bioinformatics diagnostic tools, LLMs, and other\nagentic systems, achieving an average Recall@1 score of 57.18% and surpassing\nthe second-best method (Reasoning LLM) by a substantial margin of 23.79\npercentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at\nRecall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of\nreasoning chains by clinical experts achieves 95.40% agreements. Furthermore,\nthe DeepRare system has been implemented as a user-friendly web application\nhttp://raredx.cn/doctor.", "AI": {"tldr": "DeepRare is an LLM-powered system for diagnosing rare diseases, outperforming existing methods with high accuracy and transparency.", "motivation": "Rare diseases are hard to diagnose due to clinical heterogeneity and low prevalence, necessitating advanced tools like DeepRare.", "method": "DeepRare uses a modular design with a central host, specialized agents, and 40+ tools to process clinical inputs and generate ranked hypotheses.", "result": "Achieves 100% accuracy for 1,013 diseases, outperforms 15 methods with a 57.18% Recall@1, and excels in multi-modal scenarios (70.60% Recall@1).", "conclusion": "DeepRare is a scalable, accurate, and transparent solution for rare disease diagnosis, validated by experts and available as a web app."}}
{"id": "2506.08400", "pdf": "https://arxiv.org/pdf/2506.08400", "abs": "https://arxiv.org/abs/2506.08400", "authors": ["Luel Hagos Beyene", "Vivek Verma", "Min Ma", "Jesujoba O. Alabi", "Fabian David Schmidt", "Joyce Nakatumba-Nabende", "David Ifeoluwa Adelani"], "title": "mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "comment": "working paper", "summary": "Large Language models (LLMs) have demonstrated impressive performance on a\nwide range of tasks, including in multimodal settings such as speech. However,\ntheir evaluation is often limited to English and a few high-resource languages.\nFor low-resource languages, there is no standardized evaluation benchmark. In\nthis paper, we address this gap by introducing mSTEB, a new benchmark to\nevaluate the performance of LLMs on a wide range of tasks covering language\nidentification, text classification, question answering, and translation tasks\non both speech and text modalities. We evaluated the performance of leading\nLLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open\nmodels such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in\nperformance between high-resource and low-resource languages, especially for\nlanguages spoken in Africa and Americas/Oceania. Our findings show that more\ninvestment is needed to address their under-representation in LLMs coverage.", "AI": {"tldr": "The paper introduces mSTEB, a benchmark for evaluating LLMs on low-resource languages, revealing performance gaps compared to high-resource languages.", "motivation": "To address the lack of standardized evaluation benchmarks for low-resource languages in LLMs.", "method": "Introduced mSTEB, a benchmark covering tasks like language identification, text classification, QA, and translation across speech and text. Evaluated models like Gemini 2.0 Flash, GPT-4o (Audio), Qwen 2 Audio, and Gemma 3 27B.", "result": "Performance gaps exist between high-resource and low-resource languages, especially in African and Americas/Oceania languages.", "conclusion": "More investment is needed to improve LLM coverage for underrepresented languages."}}
{"id": "2506.20333", "pdf": "https://arxiv.org/pdf/2506.20333", "abs": "https://arxiv.org/abs/2506.20333", "authors": ["Jiayan Chen", "Kai Li", "Yulu Zhao", "Jianqiang Huang", "Zhan Wang"], "title": "EAGLE: An Efficient Global Attention Lesion Segmentation Model for Hepatic Echinococcosis", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Hepatic echinococcosis (HE) is a widespread parasitic disease in\nunderdeveloped pastoral areas with limited medical resources. While CNN-based\nand Transformer-based models have been widely applied to medical image\nsegmentation, CNNs lack global context modeling due to local receptive fields,\nand Transformers, though capable of capturing long-range dependencies, are\ncomputationally expensive. Recently, state space models (SSMs), such as Mamba,\nhave gained attention for their ability to model long sequences with linear\ncomplexity. In this paper, we propose EAGLE, a U-shaped network composed of a\nProgressive Visual State Space (PVSS) encoder and a Hybrid Visual State Space\n(HVSS) decoder that work collaboratively to achieve efficient and accurate\nsegmentation of hepatic echinococcosis (HE) lesions. The proposed Convolutional\nVision State Space Block (CVSSB) module is designed to fuse local and global\nfeatures, while the Haar Wavelet Transformation Block (HWTB) module compresses\nspatial information into the channel dimension to enable lossless downsampling.\nDue to the lack of publicly available HE datasets, we collected CT slices from\n260 patients at a local hospital. Experimental results show that EAGLE achieves\nstate-of-the-art performance with a Dice Similarity Coefficient (DSC) of\n89.76%, surpassing MSVM-UNet by 1.61%.", "AI": {"tldr": "EAGLE, a U-shaped network with PVSS encoder and HVSS decoder, achieves efficient and accurate segmentation of hepatic echinococcosis lesions, outperforming MSVM-UNet with a DSC of 89.76%.", "motivation": "HE is prevalent in underdeveloped areas with limited medical resources. Existing CNN and Transformer models have limitations in global context modeling and computational efficiency.", "method": "EAGLE combines PVSS encoder and HVSS decoder, using CVSSB for local-global feature fusion and HWTB for lossless downsampling.", "result": "EAGLE achieves a DSC of 89.76%, surpassing MSVM-UNet by 1.61%.", "conclusion": "EAGLE offers an efficient and accurate solution for HE lesion segmentation, addressing limitations of existing models."}}
{"id": "2506.20152", "pdf": "https://arxiv.org/pdf/2506.20152", "abs": "https://arxiv.org/abs/2506.20152", "authors": ["Deepak Ghimire", "Kilho Lee", "Seong-heum Kim"], "title": "Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Structured pruning is a well-established technique for compressing neural\nnetworks, making it suitable for deployment in resource-limited edge devices.\nThis paper presents an efficient Loss-Aware Automatic Selection of Structured\nPruning Criteria (LAASP) for slimming and accelerating deep neural networks.\nThe majority of pruning methodologies employ a sequential process consisting of\nthree stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed\npruning technique adopts a pruning-while-training approach that eliminates the\nfirst stage and integrates the second and third stages into a single cycle. The\nautomatic selection of magnitude or similarity-based filter pruning criteria\nfrom a specified pool of criteria and the specific pruning layer at each\npruning iteration is guided by the network's overall loss on a small subset of\nthe training data. To mitigate the abrupt accuracy drop due to pruning, the\nnetwork is retrained briefly after each reduction of a predefined number of\nfloating-point operations (FLOPs). The optimal pruning rates for each layer in\nthe network are automatically determined, eliminating the need for manual\nallocation of fixed or variable pruning rates for each layer. Experiments on\nthe VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets\ndemonstrate the effectiveness of the proposed method. In particular, the\nResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the\ntop-1 accuracy compared to state-of-the-art methods while reducing the network\nFLOPs by 52\\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces\nFLOPs by more than 42\\% with a negligible 0.33\\% drop in top-5 accuracy. The\nsource code of this paper is publicly available online -\nhttps://github.com/ghimiredhikura/laasp.", "AI": {"tldr": "LAASP introduces an efficient, loss-aware structured pruning method for neural networks, combining pruning and training into one cycle, outperforming state-of-the-art methods with significant FLOPs reduction and minimal accuracy drop.", "motivation": "To streamline and improve structured pruning for neural networks, making them more efficient for deployment on resource-limited edge devices.", "method": "Adopts a pruning-while-training approach, automatically selecting pruning criteria and layer-specific rates based on network loss, followed by brief retraining to mitigate accuracy drops.", "result": "Achieves 52% FLOPs reduction in ResNet56/110 on CIFAR-10 with improved accuracy, and 42% FLOPs reduction in ResNet50 on ImageNet with only 0.33% top-5 accuracy drop.", "conclusion": "LAASP is an effective, automated pruning method that enhances efficiency and accuracy, suitable for edge deployment."}}
{"id": "2506.20059", "pdf": "https://arxiv.org/pdf/2506.20059", "abs": "https://arxiv.org/abs/2506.20059", "authors": ["Weijieying Ren", "Tianxiang Zhao", "Lei Wang", "Tianchun Wang", "Vasant Honavar"], "title": "DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have led to remarkable\nprogresses in medical consultation. However, existing medical LLMs overlook the\nessential role of Electronic Health Records (EHR) and focus primarily on\ndiagnosis recommendation, limiting their clinical applicability. We propose\nDiaLLM, the first medical LLM that integrates heterogeneous EHR data into\nclinically grounded dialogues, enabling clinical test recommendation, result\ninterpretation, and diagnosis prediction to better align with real-world\nmedical practice. To construct clinically grounded dialogues from EHR, we\ndesign a Clinical Test Reference (CTR) strategy that maps each clinical code to\nits corresponding description and classifies test results as \"normal\" or\n\"abnormal\". Additionally, DiaLLM employs a reinforcement learning framework for\nevidence acquisition and automated diagnosis. To handle the large action space,\nwe introduce a reject sampling strategy to reduce redundancy and improve\nexploration efficiency. Furthermore, a confirmation reward and a\nclass-sensitive diagnosis reward are designed to guide accurate diagnosis\nprediction. Extensive experimental results demonstrate that DiaLLM outperforms\nbaselines in clinical test recommendation and diagnosis prediction.", "AI": {"tldr": "DiaLLM integrates EHR data into medical dialogues for test recommendation, result interpretation, and diagnosis prediction, outperforming baselines.", "motivation": "Existing medical LLMs overlook EHR data and focus narrowly on diagnosis, limiting clinical applicability.", "method": "Uses a Clinical Test Reference (CTR) strategy to map EHR codes and classify results. Employs reinforcement learning with reject sampling and tailored rewards.", "result": "Outperforms baselines in clinical test recommendation and diagnosis prediction.", "conclusion": "DiaLLM aligns better with real-world medical practice by integrating EHR data and improving diagnostic accuracy."}}
{"id": "2506.19894", "pdf": "https://arxiv.org/pdf/2506.19894", "abs": "https://arxiv.org/abs/2506.19894", "authors": ["Antoine Pesenti", "Aidan OSullivan"], "title": "Explaining deep neural network models for electricity price forecasting with XAI", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Electricity markets are highly complex, involving lots of interactions and\ncomplex dependencies that make it hard to understand the inner workings of the\nmarket and what is driving prices. Econometric methods have been developed for\nthis, white-box models, however, they are not as powerful as deep neural\nnetwork models (DNN). In this paper, we use a DNN to forecast the price and\nthen use XAI methods to understand the factors driving the price dynamics in\nthe market. The objective is to increase our understanding of how different\nelectricity markets work. To do that, we apply explainable methods such as SHAP\nand Gradient, combined with visual techniques like heatmaps (saliency maps) to\nanalyse the behaviour and contributions of various features across five\nelectricity markets. We introduce the novel concepts of SSHAP values and SSHAP\nlines to enhance the complex representation of high-dimensional tabular models.", "AI": {"tldr": "The paper uses deep neural networks (DNN) and explainable AI (XAI) methods like SHAP and Gradient to forecast and analyze electricity market prices, enhancing understanding of market dynamics.", "motivation": "Electricity markets are complex, and traditional econometric methods lack the predictive power of DNNs. The goal is to improve understanding of price dynamics using XAI.", "method": "A DNN is used for price forecasting, combined with XAI methods (SHAP, Gradient) and visual techniques (heatmaps) to analyze feature contributions in five markets. Novel concepts like SSHAP values and lines are introduced.", "result": "The approach provides insights into the factors driving electricity prices, leveraging DNNs' predictive power and XAI's interpretability.", "conclusion": "The study enhances understanding of electricity market dynamics by combining DNN forecasting with XAI, introducing new methods for analyzing high-dimensional models."}}
{"id": "2506.20548", "pdf": "https://arxiv.org/pdf/2506.20548", "abs": "https://arxiv.org/abs/2506.20548", "authors": ["Manyi Li", "Renshuai Tao", "Yufan Liu", "Chuangchuang Tan", "Haotong Qin", "Bing Li", "Yunchao Wei", "Yao Zhao"], "title": "Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "20 pages, 10 figures", "summary": "With the rapid advancement of deep learning, particularly through generative\nadversarial networks (GANs) and diffusion models (DMs), AI-generated images, or\n``deepfakes\", have become nearly indistinguishable from real ones. These images\nare widely shared across Online Social Networks (OSNs), raising concerns about\ntheir misuse. Existing deepfake detection methods overlook the ``block effects\"\nintroduced by compression in OSNs, which obscure deepfake artifacts, and\nprimarily focus on raw images, rarely encountered in real-world scenarios. To\naddress these challenges, we propose PLADA (Pay Less Attention to Deceptive\nArtifacts), a novel framework designed to tackle the lack of paired data and\nthe ineffective use of compressed images. PLADA consists of two core modules:\nBlock Effect Eraser (B2E), which uses a dual-stage attention mechanism to\nhandle block effects, and Open Data Aggregation (ODA), which processes both\npaired and unpaired data to improve detection. Extensive experiments across 26\ndatasets demonstrate that PLADA achieves a remarkable balance in deepfake\ndetection, outperforming SoTA methods in detecting deepfakes on OSNs, even with\nlimited paired data and compression. More importantly, this work introduces the\n``block effect\" as a critical factor in deepfake detection, providing a robust\nsolution for open-world scenarios. Our code is available at\nhttps://github.com/ManyiLee/PLADA.", "AI": {"tldr": "PLADA is a novel framework for deepfake detection on OSNs, addressing block effects and data scarcity with dual-stage attention and open data aggregation.", "motivation": "Existing deepfake detection methods ignore block effects from OSN compression and rely on raw images, limiting real-world applicability.", "method": "PLADA includes Block Effect Eraser (B2E) for handling compression artifacts and Open Data Aggregation (ODA) for leveraging paired and unpaired data.", "result": "PLADA outperforms state-of-the-art methods across 26 datasets, even with limited paired data and compression.", "conclusion": "PLADA introduces block effects as a key factor in deepfake detection, offering a robust solution for open-world scenarios."}}
{"id": "2506.20119", "pdf": "https://arxiv.org/pdf/2506.20119", "abs": "https://arxiv.org/abs/2506.20119", "authors": ["Masaki Uto", "Yuma Ito"], "title": "Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to EvalLAC'25: 2nd Workshop on Automatic Evaluation of\n  Learning and Assessment Content, held at AIED 2025, Palermo, Italy. This is\n  the camera-ready version submitted to CEUR Workshop Proceedings", "summary": "Evaluating the abilities of learners is a fundamental objective in the field\nof education. In particular, there is an increasing need to assess higher-order\nabilities such as expressive skills and logical thinking. Constructed-response\ntests such as short-answer and essay-based questions have become widely used as\na method to meet this demand. Although these tests are effective, they require\nsubstantial manual grading, making them both labor-intensive and costly. Item\nresponse theory (IRT) provides a promising solution by enabling the estimation\nof ability from incomplete score data, where human raters grade only a subset\nof answers provided by learners across multiple test items. However, the\naccuracy of ability estimation declines as the proportion of missing scores\nincreases. Although data augmentation techniques for imputing missing scores\nhave been explored in order to address this limitation, they often struggle\nwith inaccuracy for sparse or heterogeneous data. To overcome these challenges,\nthis study proposes a novel method for imputing missing scores by leveraging\nautomated scoring technologies for accurate IRT-based ability estimation. The\nproposed method achieves high accuracy in ability estimation while markedly\nreducing manual grading workload.", "AI": {"tldr": "A novel method combines automated scoring with IRT to accurately estimate learner abilities while reducing manual grading workload.", "motivation": "The need to assess higher-order abilities like expressive skills and logical thinking efficiently, despite the labor-intensive nature of constructed-response tests.", "method": "Leverages automated scoring technologies to impute missing scores in IRT, improving accuracy for sparse or heterogeneous data.", "result": "Achieves high accuracy in ability estimation and significantly reduces manual grading effort.", "conclusion": "The proposed method effectively addresses the limitations of traditional IRT and manual grading, offering a scalable solution for ability assessment."}}
{"id": "2506.20472", "pdf": "https://arxiv.org/pdf/2506.20472", "abs": "https://arxiv.org/abs/2506.20472", "authors": ["V\u00edctor A. Vargas-P\u00e9rez", "Jes\u00fas Gir\u00e1ldez-Cru", "Oscar Cord\u00f3n"], "title": "Opinion Dynamics with Highly Oscillating Opinions", "categories": ["cs.CE", "cs.CY", "cs.MA"], "comment": null, "summary": "Opinion Dynamics (OD) models are a particular case of Agent-Based Models in\nwhich the evolution of opinions within a population is studied. In most OD\nmodels, opinions evolve as a consequence of interactions between agents, and\nthe opinion fusion rule defines how those opinions are updated. In consequence,\ndespite being simplistic, OD models provide an explainable and interpretable\nmechanism for understanding the underlying dynamics of opinion evolution.\nUnfortunately, existing OD models mainly focus on explaining the evolution of\n(usually synthetic) opinions towards consensus, fragmentation, or polarization,\nbut they usually fail to analyze scenarios of (real-world) highly oscillating\nopinions. This work overcomes this limitation by studying the ability of\nseveral OD models to reproduce highly oscillating dynamics. To this end, we\nformulate an optimization problem which is further solved using Evolutionary\nAlgorithms, providing both quantitative results on the performance of the\noptimization and qualitative interpretations on the obtained results. Our\nexperiments on a real-world opinion dataset about immigration from the monthly\nbarometer of the Spanish Sociological Research Center show that the ATBCR,\nbased on both rational and emotional mechanisms of opinion update, is the most\naccurate OD model for capturing highly oscillating opinions.", "AI": {"tldr": "The paper addresses the limitation of existing Opinion Dynamics (OD) models in analyzing highly oscillating opinions by evaluating several OD models using Evolutionary Algorithms. The ATBCR model, incorporating rational and emotional mechanisms, proves most accurate for real-world oscillating opinions.", "motivation": "Existing OD models fail to analyze real-world scenarios of highly oscillating opinions, limiting their applicability. This work aims to bridge this gap by evaluating OD models for such dynamics.", "method": "The study formulates an optimization problem solved using Evolutionary Algorithms, testing several OD models on a real-world dataset about immigration opinions.", "result": "The ATBCR model, which combines rational and emotional opinion update mechanisms, outperforms others in capturing highly oscillating opinions.", "conclusion": "The ATBCR model is the most effective for modeling real-world oscillating opinions, demonstrating the importance of incorporating both rational and emotional factors in OD models."}}
{"id": "2506.20407", "pdf": "https://arxiv.org/pdf/2506.20407", "abs": "https://arxiv.org/abs/2506.20407", "authors": ["Fangyijie Wang", "Yuan Liang", "Sourav Bhattacharjee", "Abey Campbell", "Kathleen M. Curran", "Gu\u00e9nol\u00e9 Silvestre"], "title": "Fusing Radiomic Features with Deep Representations for Gestational Age Estimation in Fetal Ultrasound Images", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted at MICCAI 2025", "summary": "Accurate gestational age (GA) estimation, ideally through fetal ultrasound\nmeasurement, is a crucial aspect of providing excellent antenatal care.\nHowever, deriving GA from manual fetal biometric measurements depends on the\noperator and is time-consuming. Hence, automatic computer-assisted methods are\ndemanded in clinical practice. In this paper, we present a novel feature fusion\nframework to estimate GA using fetal ultrasound images without any measurement\ninformation. We adopt a deep learning model to extract deep representations\nfrom ultrasound images. We extract radiomic features to reveal patterns and\ncharacteristics of fetal brain growth. To harness the interpretability of\nradiomics in medical imaging analysis, we estimate GA by fusing radiomic\nfeatures and deep representations. Our framework estimates GA with a mean\nabsolute error of 8.0 days across three trimesters, outperforming current\nmachine learning-based methods at these gestational ages. Experimental results\ndemonstrate the robustness of our framework across different populations in\ndiverse geographical regions. Our code is publicly available on\n\\href{https://github.com/13204942/RadiomicsImageFusion_FetalUS}{GitHub}.", "AI": {"tldr": "A novel feature fusion framework using deep learning and radiomics for accurate gestational age estimation from fetal ultrasound images, achieving a mean absolute error of 8.0 days.", "motivation": "Manual GA estimation is operator-dependent and time-consuming, necessitating automated methods for clinical practice.", "method": "Combines deep learning for image representation and radiomics for fetal brain growth patterns, fusing both for GA estimation.", "result": "Achieves a mean absolute error of 8.0 days, outperforming existing methods, with robustness across diverse populations.", "conclusion": "The framework offers a reliable, automated solution for GA estimation, with potential for widespread clinical use."}}
{"id": "2506.20155", "pdf": "https://arxiv.org/pdf/2506.20155", "abs": "https://arxiv.org/abs/2506.20155", "authors": ["Avadhoot Jadhav", "Ashutosh Srivastava", "Abhinav Java", "Silky Singh", "Tarun Ram Menta", "Surgan Jandial", "Balaji Krishnamurthy"], "title": "Towards Efficient Exemplar Based Image Editing with Multimodal VLMs", "categories": ["cs.CV"], "comment": "Accepted at ECCV 2024 (AI4VA Workshop)", "summary": "Text-to-Image Diffusion models have enabled a wide array of image editing\napplications. However, capturing all types of edits through text alone can be\nchallenging and cumbersome. The ambiguous nature of certain image edits is\nbetter expressed through an exemplar pair, i.e., a pair of images depicting an\nimage before and after an edit respectively. In this work, we tackle\nexemplar-based image editing -- the task of transferring an edit from an\nexemplar pair to a content image(s), by leveraging pretrained text-to-image\ndiffusion models and multimodal VLMs. Even though our end-to-end pipeline is\noptimization-free, our experiments demonstrate that it still outperforms\nbaselines on multiple types of edits while being ~4x faster.", "AI": {"tldr": "The paper introduces an exemplar-based image editing method using pretrained diffusion models and VLMs, outperforming baselines in speed and accuracy.", "motivation": "Text alone is insufficient for ambiguous image edits; exemplar pairs provide clearer guidance.", "method": "Leverages pretrained text-to-image diffusion models and multimodal VLMs for optimization-free editing.", "result": "Outperforms baselines on various edits and is ~4x faster.", "conclusion": "Exemplar-based editing with diffusion models is efficient and effective."}}
{"id": "2506.20130", "pdf": "https://arxiv.org/pdf/2506.20130", "abs": "https://arxiv.org/abs/2506.20130", "authors": ["Adrien Bibal", "Steven N. Minton", "Deborah Khider", "Yolanda Gil"], "title": "AI Copilots for Reproducibility in Science: A Case Study", "categories": ["cs.AI"], "comment": null, "summary": "Open science initiatives seek to make research outputs more transparent,\naccessible, and reusable, but ensuring that published findings can be\nindependently reproduced remains a persistent challenge. This paper introduces\nOpenPub, an AI-powered platform that supports researchers, reviewers, and\nreaders through a suite of modular copilots focused on key open science tasks.\nIn this work, we present the Reproducibility Copilot, which analyzes\nmanuscripts, code, and supplementary materials to generate structured Jupyter\nNotebooks and recommendations aimed at facilitating computational, or \"rote\",\nreproducibility. We conducted feasibility tests using previously studied\nresearch papers with known reproducibility benchmarks. Results indicate that\nOpenPub can substantially reduce reproduction time - from over 30 hours to\nabout 1 hour - while achieving high coverage of figures, tables, and results\nsuitable for computational reproduction. The system systematically detects\nbarriers to reproducibility, including missing hyperparameters, undocumented\npreprocessing steps, and incomplete or inaccessible datasets. These findings\nsuggest that AI-driven tools can meaningfully reduce the burden of\nreproducibility efforts and contribute to more transparent and verifiable\nscientific communication. The modular copilot architecture also provides a\nfoundation for extending AI assistance to additional open science objectives\nbeyond reproducibility.", "AI": {"tldr": "OpenPub, an AI-powered platform, introduces the Reproducibility Copilot to streamline computational reproducibility in research, reducing reproduction time from 30+ hours to ~1 hour.", "motivation": "Addressing the challenge of ensuring independent reproducibility of research findings in open science.", "method": "Uses AI to analyze manuscripts, code, and supplementary materials, generating structured Jupyter Notebooks and recommendations.", "result": "Substantially reduces reproduction time and detects barriers like missing hyperparameters or incomplete datasets.", "conclusion": "AI-driven tools like OpenPub can enhance reproducibility and transparency in scientific communication, with potential for broader open science applications."}}
{"id": "2506.19895", "pdf": "https://arxiv.org/pdf/2506.19895", "abs": "https://arxiv.org/abs/2506.19895", "authors": ["Miguel N. Font", "Jos\u00e9 L. Jorro-Aragoneses", "Carlos M. Ala\u00edz"], "title": "A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted for presentation at ICANN 2025\n  (International Conference on Artificial Neural Networks) and will appear in\n  the conference proceedings published by Springer Nature in the Lecture Notes\n  in Computer Science (LNCS) series. The final authenticated version will be\n  available on the publisher website", "summary": "Neural Networks have high accuracy in solving problems where it is difficult\nto detect patterns or create a logical model. However, these algorithms\nsometimes return wrong solutions, which become problematic in high-risk domains\nlike medical diagnosis or autonomous driving. One strategy to detect and\nmitigate these errors is the measurement of the uncertainty over neural network\ndecisions. In this paper, we present a novel post-hoc framework for measuring\nthe uncertainty of a decision based on retrieved training cases that have a\nsimilar activation vector to the query for each layer. Based on these retrieved\ncases, we propose two new metrics: Decision Change and Layer Uncertainty, which\ncapture changes in nearest-neighbor class distributions across layers. We\nevaluated our approach in a classification model for two datasets: CIFAR-10 and\nMNIST. The results show that these metrics enhance uncertainty estimation,\nespecially in challenging classification tasks, outperforming softmax-based\nconfidence.", "AI": {"tldr": "A novel post-hoc framework measures neural network uncertainty using retrieved training cases with similar activation vectors, introducing Decision Change and Layer Uncertainty metrics to improve uncertainty estimation.", "motivation": "Neural networks can produce wrong solutions in high-risk domains, necessitating better uncertainty measurement to detect and mitigate errors.", "method": "The framework retrieves training cases with similar activation vectors per layer and proposes Decision Change and Layer Uncertainty metrics to analyze nearest-neighbor class distributions.", "result": "Evaluation on CIFAR-10 and MNIST datasets shows the metrics enhance uncertainty estimation, outperforming softmax-based confidence.", "conclusion": "The proposed metrics improve uncertainty estimation in neural networks, particularly for challenging tasks."}}
{"id": "2505.23018", "pdf": "https://arxiv.org/pdf/2505.23018", "abs": "https://arxiv.org/abs/2505.23018", "authors": ["Haoqin Sun", "Xuechen Wang", "Jinghua Zhao", "Shiwan Zhao", "Jiaming Zhou", "Hui Wang", "Jiabei He", "Aobo Kong", "Xi Yang", "Yequan Wang", "Yonghua Lin", "Yong Qin"], "title": "EmotionTalk: An Interactive Chinese Multimodal Emotion Dataset With Rich Annotations", "categories": ["cs.MM"], "comment": null, "summary": "In recent years, emotion recognition plays a critical role in applications\nsuch as human-computer interaction, mental health monitoring, and sentiment\nanalysis. While datasets for emotion analysis in languages such as English have\nproliferated, there remains a pressing need for high-quality, comprehensive\ndatasets tailored to the unique linguistic, cultural, and multimodal\ncharacteristics of Chinese. In this work, we propose \\textbf{EmotionTalk}, an\ninteractive Chinese multimodal emotion dataset with rich annotations. This\ndataset provides multimodal information from 19 actors participating in dyadic\nconversational settings, incorporating acoustic, visual, and textual\nmodalities. It includes 23.6 hours of speech (19,250 utterances), annotations\nfor 7 utterance-level emotion categories (happy, surprise, sad, disgust, anger,\nfear, and neutral), 5-dimensional sentiment labels (negative, weakly negative,\nneutral, weakly positive, and positive) and 4-dimensional speech captions\n(speaker, speaking style, emotion and overall). The dataset is well-suited for\nresearch on unimodal and multimodal emotion recognition, missing modality\nchallenges, and speech captioning tasks. To our knowledge, it represents the\nfirst high-quality and versatile Chinese dialogue multimodal emotion dataset,\nwhich is a valuable contribution to research on cross-cultural emotion analysis\nand recognition. Additionally, we conduct experiments on EmotionTalk to\ndemonstrate the effectiveness and quality of the dataset. It will be\nopen-source and freely available for all academic purposes. The dataset and\ncodes will be made available at: https://github.com/NKU-HLT/EmotionTalk.", "AI": {"tldr": "The paper introduces EmotionTalk, a high-quality Chinese multimodal emotion dataset with rich annotations, addressing the lack of such resources for Chinese language and culture.", "motivation": "There's a need for comprehensive datasets for Chinese emotion recognition due to unique linguistic and cultural characteristics, which existing English datasets don't address.", "method": "The authors created EmotionTalk, a dataset with multimodal data (acoustic, visual, textual) from 19 actors in dyadic conversations, annotated for emotions, sentiment, and speech captions.", "result": "EmotionTalk includes 23.6 hours of speech, 19,250 utterances, and detailed annotations, making it suitable for various emotion recognition tasks.", "conclusion": "EmotionTalk is the first versatile Chinese multimodal emotion dataset, valuable for cross-cultural research, and will be open-sourced for academic use."}}
{"id": "2506.20128", "pdf": "https://arxiv.org/pdf/2506.20128", "abs": "https://arxiv.org/abs/2506.20128", "authors": ["Aashiq Muhamed"], "title": "CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at LLM4Eval @ SIGIR 2025", "summary": "RAG systems enhance LLMs by incorporating external knowledge, which is\ncrucial for domains that demand factual accuracy and up-to-date information.\nHowever, evaluating the multifaceted quality of RAG outputs, spanning aspects\nsuch as contextual coherence, query relevance, factual correctness, and\ninformational completeness, poses significant challenges. Existing evaluation\nmethods often rely on simple lexical overlap metrics, which are inadequate for\ncapturing these nuances, or involve complex multi-stage pipelines with\nintermediate steps like claim extraction or require finetuning specialized\njudge models, hindering practical efficiency. To address these limitations, we\npropose CCRS (Contextual Coherence and Relevance Score), a novel suite of five\nmetrics that utilizes a single, powerful, pretrained LLM as a zero-shot,\nend-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance\n(QR), Information Density (ID), Answer Correctness (AC), and Information Recall\n(IR). We apply CCRS to evaluate six diverse RAG system configurations on the\nchallenging BioASQ dataset. Our analysis demonstrates that CCRS effectively\ndiscriminates between system performances, confirming, for instance, that the\nMistral-7B reader outperforms Llama variants. We provide a detailed analysis of\nCCRS metric properties, including score distributions, convergent/discriminant\nvalidity, tie rates, population statistics, and discriminative power. Compared\nto the complex RAGChecker framework, CCRS offers comparable or superior\ndiscriminative power for key aspects like recall and faithfulness, while being\nsignificantly more computationally efficient. CCRS thus provides a practical,\ncomprehensive, and efficient framework for evaluating and iteratively improving\nRAG systems.", "AI": {"tldr": "The paper introduces CCRS, a novel suite of five metrics for evaluating RAG systems, using a pretrained LLM as a zero-shot judge. It outperforms existing methods in efficiency and discriminative power.", "motivation": "Existing evaluation methods for RAG systems are either simplistic (lexical overlap) or inefficient (multi-stage pipelines). CCRS addresses these limitations by providing a comprehensive yet efficient framework.", "method": "CCRS employs a pretrained LLM as a zero-shot judge to evaluate five metrics: Contextual Coherence, Question Relevance, Information Density, Answer Correctness, and Information Recall. It is tested on the BioASQ dataset with six RAG configurations.", "result": "CCRS effectively discriminates between RAG system performances, showing Mistral-7B outperforms Llama variants. It matches or surpasses RAGChecker in discriminative power while being more efficient.", "conclusion": "CCRS offers a practical, comprehensive, and efficient solution for evaluating and improving RAG systems, addressing the shortcomings of existing methods."}}
{"id": "2506.20626", "pdf": "https://arxiv.org/pdf/2506.20626", "abs": "https://arxiv.org/abs/2506.20626", "authors": ["Hamza Chakraa", "Fran\u00e7ois Gu\u00e9rin", "Edouard Leclercq", "Dimitri Lefebvre"], "title": "Task Allocation of UAVs for Monitoring Missions via Hardware-in-the-Loop Simulation and Experimental Validation", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "comment": null, "summary": "This study addresses the optimisation of task allocation for Unmanned Aerial\nVehicles (UAVs) within industrial monitoring missions. The proposed methodology\nintegrates a Genetic Algorithms (GA) with a 2-Opt local search technique to\nobtain a high-quality solution. Our approach was experimentally validated in an\nindustrial zone to demonstrate its efficacy in real-world scenarios. Also, a\nHardware-in-the-loop (HIL) simulator for the UAVs team is introduced. Moreover,\ninsights about the correlation between the theoretical cost function and the\nactual battery consumption and time of flight are deeply analysed. Results show\nthat the considered costs for the optimisation part of the problem closely\ncorrelate with real-world data, confirming the practicality of the proposed\napproach.", "AI": {"tldr": "The paper optimizes UAV task allocation using Genetic Algorithms and 2-Opt local search, validated in real-world industrial monitoring. It also introduces a HIL simulator and confirms the correlation between theoretical costs and actual UAV performance.", "motivation": "To improve task allocation for UAVs in industrial monitoring by integrating efficient optimization techniques and validating their practicality.", "method": "Combines Genetic Algorithms with 2-Opt local search for task allocation and introduces a Hardware-in-the-loop simulator for validation.", "result": "Theoretical cost functions closely match real-world battery consumption and flight time, proving the method's practicality.", "conclusion": "The proposed approach is effective for UAV task allocation in industrial settings, with validated real-world applicability."}}
{"id": "2506.20450", "pdf": "https://arxiv.org/pdf/2506.20450", "abs": "https://arxiv.org/abs/2506.20450", "authors": ["Nanxin Gong", "Saori Takeyama", "Masahiro Yamaguchi", "Takumi Urata", "Fumikazu Kimura", "Keiko Ishii"], "title": "Papanicolaou Stain Unmixing for RGB Image Using Weighted Nucleus Sparsity and Total Variation Regularization", "categories": ["eess.IV", "q-bio.QM"], "comment": "22 pages, 12 figures", "summary": "The Papanicolaou stain, consisting of eosin Y, hematoxylin, light Green SF\nyellowish, orange G, and Bismarck brown Y, provides extensive color information\nessential for cervical cancer screening in cytopathology. However, the visual\nobservation of these colors is subjective and difficult to characterize. In\ndigital image analysis, the RGB intensities are affected by staining and\nimaging variations, hindering direct quantification of color in\nPapanicolaou-stained samples. Stain unmixing is a promising alternative that\nquantifies the amounts of dyes. In previous work, multispectral imaging was\nutilized to estimate the dye amounts of Papanicolaou stain for quantitative\ndiagnosis. Still, its application to RGB images presents a challenge since the\nnumber of dyes exceeds the three RGB channels. This paper proposes a novel\nPapanicolaou stain unmixing method for RGB images that incorporates three key\nassumptions: nonnegative stain abundances; a sparse spatial distribution of\nhematoxylin, which binds to nuclei; and piecewise smoothness of stain\nabundances. By formulating this as an optimization problem with nonnegativity,\nweighted nucleus sparsity, and total variation regularizations, our method\nachieved excellent performance in stain quantification when validated against\nthe results of multispectral imaging. We also adopted the proposed method for\ndiscriminating lobular endocervical glandular hyperplasia (LEGH), a\nprecancerous lesion of gastric-type adenocarcinoma of the cervix. The resulting\nquantification distinctly characterized differences between LEGH and normal\nendocervical cells with stain abundance, and a classifier based on the\nquantification results achieved 98.0% accuracy. This demonstrates the\nsignificant potential of RGB-based stain unmixing for quantitative diagnosis.", "AI": {"tldr": "A novel method for unmixing Papanicolaou stain in RGB images is proposed, addressing challenges in quantifying dye amounts for cervical cancer screening. It outperforms multispectral imaging and aids in diagnosing precancerous lesions.", "motivation": "The subjective and variable nature of visual color observation in Papanicolaou-stained samples hinders accurate quantification for diagnosis, necessitating a robust RGB-based solution.", "method": "The method formulates stain unmixing as an optimization problem with nonnegativity, weighted nucleus sparsity, and total variation regularizations.", "result": "Validated against multispectral imaging, the method excelled in stain quantification and achieved 98.0% accuracy in diagnosing precancerous lesions.", "conclusion": "RGB-based stain unmixing shows significant potential for quantitative diagnosis in cytopathology."}}
{"id": "2506.20168", "pdf": "https://arxiv.org/pdf/2506.20168", "abs": "https://arxiv.org/abs/2506.20168", "authors": ["Zhentao He", "Can Zhang", "Ziheng Wu", "Zhenghao Chen", "Yufei Zhan", "Yifan Li", "Zhao Zhang", "Xian Wang", "Minghui Qiu"], "title": "Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in multimodal large language models have enhanced\ndocument understanding by integrating textual and visual information. However,\nexisting models exhibit incompleteness within their paradigm in real-world\nscenarios, particularly under visual degradation. In such conditions, the\ncurrent response paradigm often fails to adequately perceive visual degradation\nand ambiguity, leading to overreliance on linguistic priors or misaligned\nvisual-textual reasoning. This difficulty in recognizing uncertainty frequently\nresults in the generation of hallucinatory content, especially when a precise\nanswer is not feasible. To better demonstrate and analyze this phenomenon and\nproblem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR\nhallucination in degraded document understanding. This dataset includes test\nsamples spanning identity cards and invoices, with simulated real-world\ndegradations for OCR reliability. This setup allows for evaluating models'\ncapacity, under degraded input, to distinguish reliable visual information and\nanswer accordingly, thereby highlighting the challenge of avoiding\nhallucination on uncertain data. To achieve vision-faithful reasoning and\nthereby avoid the aforementioned issues, we further introduce a GRPO-based\nframework featuring a novel reward mechanism. By incorporating a self-awareness\nof visual uncertainty and an analysis method that initiates refusal to answer\nto increase task difficulty within our supervised fine-tuning and reinforcement\nlearning framework, we successfully mitigated hallucinations in ambiguous\nregions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model\nachieves a 22\\% absolute improvement in hallucination-free accuracy over GPT-4o\non KIE-HVQA and there is no significant performance drop in standard tasks,\nhighlighting both effectiveness and robustness.", "AI": {"tldr": "The paper introduces KIE-HVQA, a benchmark for evaluating OCR hallucination in degraded documents, and proposes a GRPO-based framework to mitigate hallucinations by incorporating visual uncertainty awareness.", "motivation": "Existing multimodal models struggle with visual degradation, leading to unreliable outputs and hallucinations. The paper aims to address this by improving vision-faithful reasoning.", "method": "The authors propose KIE-HVQA, a dataset with degraded documents, and a GRPO-based framework with a novel reward mechanism for self-awareness of visual uncertainty.", "result": "The 7B-parameter model achieves a 22% improvement in hallucination-free accuracy over GPT-4o on KIE-HVQA, with no drop in standard task performance.", "conclusion": "The framework effectively mitigates hallucinations in degraded visual inputs while maintaining robustness in standard tasks."}}
{"id": "2506.20274", "pdf": "https://arxiv.org/pdf/2506.20274", "abs": "https://arxiv.org/abs/2506.20274", "authors": ["Liya Wang", "David Yi", "Damien Jose", "John Passarelli", "James Gao", "Jordan Leventis", "Kang Li"], "title": "Enterprise Large Language Model Evaluation Benchmark", "categories": ["cs.AI"], "comment": "Submitted to MLNLP 2025 at https://csity2025.org/mlnlp/index", "summary": "Large Language Models (LLMs) ) have demonstrated promise in boosting\nproductivity across AI-powered tools, yet existing benchmarks like Massive\nMultitask Language Understanding (MMLU) inadequately assess enterprise-specific\ntask complexities. We propose a 14-task framework grounded in Bloom's Taxonomy\nto holistically evaluate LLM capabilities in enterprise contexts. To address\nchallenges of noisy data and costly annotation, we develop a scalable pipeline\ncombining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented\ngeneration (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six\nleading models shows open-source contenders like DeepSeek R1 rival proprietary\nmodels in reasoning tasks but lag in judgment-based scenarios, likely due to\noverthinking. Our benchmark reveals critical enterprise performance gaps and\noffers actionable insights for model optimization. This work provides\nenterprises a blueprint for tailored evaluations and advances practical LLM\ndeployment.", "AI": {"tldr": "A 14-task framework based on Bloom's Taxonomy is proposed to evaluate LLMs for enterprise tasks, addressing noisy data and costly annotation with a scalable pipeline. Open-source models perform well in reasoning but lag in judgment tasks.", "motivation": "Existing benchmarks like MMLU fail to assess enterprise-specific task complexities, necessitating a tailored evaluation framework.", "method": "Developed a scalable pipeline combining LLM-as-a-Labeler, LLM-as-a-Judge, and CRAG to curate a 9,700-sample benchmark. Evaluated six leading models.", "result": "Open-source models like DeepSeek R1 rival proprietary models in reasoning but lag in judgment tasks due to overthinking.", "conclusion": "The benchmark highlights enterprise performance gaps and provides actionable insights for model optimization, advancing practical LLM deployment."}}
{"id": "2506.19929", "pdf": "https://arxiv.org/pdf/2506.19929", "abs": "https://arxiv.org/abs/2506.19929", "authors": ["Efe \u00c7ak\u0131r", "Patrick Dumond"], "title": "A Comparative Analysis of Reinforcement Learning and Conventional Deep Learning Approaches for Bearing Fault Diagnosis", "categories": ["cs.LG", "I.2.6"], "comment": "5 pages, 5 figures. To appear in the Proceedings of the Canadian\n  Society for Mechanical Engineering (CSME) Congress 2025", "summary": "Bearing faults in rotating machinery can lead to significant operational\ndisruptions and maintenance costs. Modern methods for bearing fault diagnosis\nrely heavily on vibration analysis and machine learning techniques, which often\nrequire extensive labeled data and may not adapt well to dynamic environments.\nThis study explores the feasibility of reinforcement learning (RL),\nspecifically Deep Q-Networks (DQNs), for bearing fault classification tasks in\nmachine condition monitoring to enhance the accuracy and adaptability of\nbearing fault diagnosis. The results demonstrate that while RL models developed\nin this study can match the performance of traditional supervised learning\nmodels under controlled conditions, they excel in adaptability when equipped\nwith optimized reward structures. However, their computational demands\nhighlight areas for further improvement. These findings demonstrate RL's\npotential to complement traditional methods, paving the way for adaptive\ndiagnostic frameworks.", "AI": {"tldr": "The paper explores using reinforcement learning (RL), specifically Deep Q-Networks (DQNs), for bearing fault diagnosis, showing comparable performance to traditional methods but better adaptability, though with higher computational costs.", "motivation": "Bearing faults cause operational disruptions and high costs. Current methods rely on labeled data and struggle in dynamic environments, prompting the need for adaptable solutions like RL.", "method": "The study employs Deep Q-Networks (DQNs) for bearing fault classification, focusing on adaptability and performance under controlled and dynamic conditions.", "result": "RL models match traditional supervised learning in controlled settings but outperform in adaptability with optimized rewards, despite higher computational demands.", "conclusion": "RL shows promise for adaptive bearing fault diagnosis, complementing traditional methods, though computational efficiency needs improvement."}}
{"id": "2506.20160", "pdf": "https://arxiv.org/pdf/2506.20160", "abs": "https://arxiv.org/abs/2506.20160", "authors": ["Ruosen Li", "Ziming Luo", "Quan Zhang", "Ruochen Li", "Ben Zhou", "Ali Payani", "Xinya Du"], "title": "AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control", "categories": ["cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) achieve impressive reasoning capabilities by\ngenerating lengthy chain-of-thoughts, but this \"overthinking\" incurs high\nlatency and cost without commensurate accuracy gains. In this work, we\nintroduce AALC, a lightweight, accuracy-aware length reward integrated into\nreinforcement learning that dynamically balances correctness and brevity during\ntraining. By incorporating validation accuracy into the reward and employing a\nsmooth, dynamically scheduled length penalty, AALC delays length penalty until\ntarget performance is met. Through extensive experiments across standard and\nout-of-distribution math benchmarks, we show that our approach reduces response\nlength by over 50% while maintaining or even improving the original accuracy.\nFurthermore, qualitative analysis reveals that our method curbs redundant\nreasoning patterns such as excessive subgoal setting and verification, leading\nto structurally refined outputs rather than naive truncation. We also identify\nthat efficiency gains are accompanied by reduced interpretability: models\ntrained with AALC omit some narrative framing and explanatory context. These\nfindings highlight the potential of reward-based strategies to guide LRMs\ntoward more efficient, generalizable reasoning paths.", "AI": {"tldr": "AALC, a lightweight accuracy-aware length reward, reduces response length by 50% while maintaining or improving accuracy in large reasoning models.", "motivation": "Large reasoning models incur high latency and cost due to lengthy chain-of-thoughts without proportional accuracy gains.", "method": "AALC integrates validation accuracy into reinforcement learning, dynamically balancing correctness and brevity with a scheduled length penalty.", "result": "Reduces response length by over 50% while maintaining or improving accuracy, curbing redundant reasoning patterns.", "conclusion": "Reward-based strategies like AALC can guide models toward efficient, generalizable reasoning, though interpretability may decrease."}}
{"id": "2506.20664", "pdf": "https://arxiv.org/pdf/2506.20664", "abs": "https://arxiv.org/abs/2506.20664", "authors": ["Andrei Lupu", "Timon Willi", "Jakob Foerster"], "title": "The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MA"], "comment": "41 pages, 19 figures", "summary": "As Large Language Models (LLMs) gain agentic abilities, they will have to\nnavigate complex multi-agent scenarios, interacting with human users and other\nagents in cooperative and competitive settings. This will require new reasoning\nskills, chief amongst them being theory of mind (ToM), or the ability to reason\nabout the \"mental\" states of other agents. However, ToM and other multi-agent\nabilities in LLMs are poorly understood, since existing benchmarks suffer from\nnarrow scope, data leakage, saturation, and lack of interactivity. We thus\npropose Decrypto, a game-based benchmark for multi-agent reasoning and ToM\ndrawing inspiration from cognitive science, computational pragmatics and\nmulti-agent reinforcement learning. It is designed to be as easy as possible in\nall other dimensions, eliminating confounding factors commonly found in other\nbenchmarks. To our knowledge, it is also the first platform for designing\ninteractive ToM experiments.\n  We validate the benchmark design through comprehensive empirical evaluations\nof frontier LLMs, robustness studies, and human-AI cross-play experiments. We\nfind that LLM game-playing abilities lag behind humans and simple\nword-embedding baselines. We then create variants of two classic cognitive\nscience experiments within Decrypto to evaluate three key ToM abilities.\nSurprisingly, we find that state-of-the-art reasoning models are significantly\nworse at those tasks than their older counterparts. This demonstrates that\nDecrypto addresses a crucial gap in current reasoning and ToM evaluations, and\npaves the path towards better artificial agents.", "AI": {"tldr": "The paper introduces Decrypto, a game-based benchmark for evaluating multi-agent reasoning and theory of mind (ToM) in LLMs, addressing gaps in existing benchmarks. It finds current LLMs lag behind humans and older models in ToM tasks.", "motivation": "Existing benchmarks for ToM and multi-agent reasoning in LLMs are limited by narrow scope, data leakage, and lack of interactivity, necessitating a new evaluation framework.", "method": "The authors propose Decrypto, a benchmark inspired by cognitive science and multi-agent reinforcement learning, designed to minimize confounding factors. They validate it through empirical evaluations, robustness studies, and human-AI cross-play experiments.", "result": "LLMs perform worse than humans and older models in ToM tasks, highlighting a gap in current evaluations.", "conclusion": "Decrypto fills a critical gap in ToM and reasoning evaluations, aiding the development of better artificial agents."}}
{"id": "2506.20614", "pdf": "https://arxiv.org/pdf/2506.20614", "abs": "https://arxiv.org/abs/2506.20614", "authors": ["Simon Perrin", "S\u00e9bastien Levilly", "Huajun Sun", "Harold Mouch\u00e8re", "Jean-Michel Serfaty"], "title": "Weighted Mean Frequencies: a handcraft Fourier feature for 4D Flow MRI segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "In recent decades, the use of 4D Flow MRI images has enabled the\nquantification of velocity fields within a volume of interest and along the\ncardiac cycle. However, the lack of resolution and the presence of noise in\nthese biomarkers are significant issues. As indicated by recent studies, it\nappears that biomarkers such as wall shear stress are particularly impacted by\nthe poor resolution of vessel segmentation. The Phase Contrast Magnetic\nResonance Angiography (PC-MRA) is the state-of-the-art method to facilitate\nsegmentation. The objective of this work is to introduce a new handcraft\nfeature that provides a novel visualisation of 4D Flow MRI images, which is\nuseful in the segmentation task. This feature, termed Weighted Mean Frequencies\n(WMF), is capable of revealing the region in three dimensions where a voxel has\nbeen passed by pulsatile flow. Indeed, this feature is representative of the\nhull of all pulsatile velocity voxels. The value of the feature under\ndiscussion is illustrated by two experiments. The experiments involved\nsegmenting 4D Flow MRI images using optimal thresholding and deep learning\nmethods. The results obtained demonstrate a substantial enhancement in terms of\nIoU and Dice, with a respective increase of 0.12 and 0.13 in comparison with\nthe PC-MRA feature, as evidenced by the deep learning task. This feature has\nthe potential to yield valuable insights that could inform future segmentation\nprocesses in other vascular regions, such as the heart or the brain.", "AI": {"tldr": "The paper introduces a new feature, Weighted Mean Frequencies (WMF), to improve segmentation of 4D Flow MRI images, showing better results than PC-MRA in experiments.", "motivation": "The poor resolution and noise in 4D Flow MRI images hinder accurate segmentation, especially for biomarkers like wall shear stress.", "method": "The proposed WMF feature visualizes pulsatile flow regions in 3D, aiding segmentation. Experiments used optimal thresholding and deep learning methods.", "result": "WMF improved IoU and Dice scores by 0.12 and 0.13, respectively, compared to PC-MRA.", "conclusion": "WMF enhances segmentation accuracy and could be useful for other vascular regions like the heart or brain."}}
{"id": "2506.20174", "pdf": "https://arxiv.org/pdf/2506.20174", "abs": "https://arxiv.org/abs/2506.20174", "authors": ["Man Duc Chuc"], "title": "Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition", "categories": ["cs.CV"], "comment": null, "summary": "Foundation models are rapidly transforming Earth Observation data mining by\nenabling generalizable and scalable solutions for key tasks such as scene\nclassification and semantic segmentation. While most efforts in the geospatial\ndomain have focused on developing large models trained from scratch using\nmassive Earth Observation datasets, an alternative strategy that remains\nunderexplored is the reuse and combination of existing pretrained models. In\nthis study, we investigate whether foundation models pretrained on remote\nsensing and general vision datasets can be effectively combined to improve\nperformance across a diverse set of key Earth Observation tasks. Using the\nGEO-Bench benchmark, we evaluate several prominent models, including Prithvi,\nHiera, and DOFA, on eleven datasets covering a range of spatial resolutions,\nsensor modalities, and task types. The results show that feature-level\nensembling of smaller pretrained models can match or exceed the performance of\nmuch larger models, while requiring less training time and computational\nresources. Moreover, the study highlights the potential of applying knowledge\ndistillation to transfer the strengths of ensembles into more compact models,\noffering a practical path for deploying foundation models in real-world Earth\nObservation applications.", "AI": {"tldr": "Foundation models pretrained on remote sensing and general vision datasets can be combined to improve Earth Observation tasks, matching or outperforming larger models with less computational cost.", "motivation": "To explore the reuse and combination of existing pretrained models for Earth Observation tasks, as an alternative to training large models from scratch.", "method": "Evaluate feature-level ensembling of models like Prithvi, Hiera, and DOFA on the GEO-Bench benchmark across diverse datasets.", "result": "Feature-level ensembling of smaller pretrained models matches or exceeds larger models' performance with reduced training time and resources.", "conclusion": "Combining pretrained models and knowledge distillation offers a practical approach for deploying foundation models in real-world Earth Observation applications."}}
{"id": "2506.20332", "pdf": "https://arxiv.org/pdf/2506.20332", "abs": "https://arxiv.org/abs/2506.20332", "authors": ["Jihao Gu", "Qihang Ai", "Yingyao Wang", "Pi Bu", "Jingxuan Xing", "Zekun Zhu", "Wei Jiang", "Ziming Wang", "Yingxiu Zhao", "Ming-Liang Zhang", "Jun Song", "Yuning Jiang", "Bo Zheng"], "title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards", "categories": ["cs.AI"], "comment": "14 pages, 12 figures", "summary": "Vision-language model-based mobile agents have gained the ability to not only\nunderstand complex instructions and mobile screenshots, but also optimize their\naction outputs via thinking and reasoning, benefiting from reinforcement\nlearning, such as Group Relative Policy Optimization (GRPO). However, existing\nresearch centers on offline reinforcement learning training or online\noptimization using action-level rewards, which limits the agent's dynamic\ninteraction with the environment. This often results in agents settling into\nlocal optima, thereby weakening their ability for exploration and error action\ncorrection. To address these challenges, we introduce an approach called\nMobile-R1, which employs interactive multi-turn reinforcement learning with\ntask-level rewards for mobile agents. Our training framework consists of three\nstages: initial format finetuning, single-step online training via action-level\nreward, followed by online training via task-level reward based on multi-turn\ntrajectories. This strategy is designed to enhance the exploration and error\ncorrection capabilities of Mobile-R1, leading to significant performance\nimprovements. Moreover, we have collected a dataset covering 28 Chinese\napplications with 24,521 high-quality manual annotations and established a new\nbenchmark with 500 trajectories. We will open source all resources, including\nthe dataset, benchmark, model weight, and codes:\nhttps://mobile-r1.github.io/Mobile-R1/.", "AI": {"tldr": "Mobile-R1 introduces interactive multi-turn reinforcement learning with task-level rewards to improve mobile agents' exploration and error correction, outperforming existing methods.", "motivation": "Existing methods focus on offline training or action-level rewards, limiting dynamic interaction and causing local optima, which weakens exploration and error correction.", "method": "Mobile-R1 uses a three-stage training framework: initial finetuning, single-step online training with action-level rewards, and multi-turn online training with task-level rewards.", "result": "The approach enhances exploration and error correction, leading to significant performance improvements. A dataset and benchmark are also provided.", "conclusion": "Mobile-R1 advances mobile agent capabilities by addressing limitations of prior methods, with open-sourced resources for further research."}}
{"id": "2506.19935", "pdf": "https://arxiv.org/pdf/2506.19935", "abs": "https://arxiv.org/abs/2506.19935", "authors": ["Shuchen Xue", "Tianyu Xie", "Tianyang Hu", "Zijin Feng", "Jiacheng Sun", "Kenji Kawaguchi", "Zhenguo Li", "Zhi-Ming Ma"], "title": "Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Large language models (LLMs) predominantly use autoregressive (AR)\napproaches, but masked diffusion models (MDMs) are emerging as viable\nalternatives. A key challenge in comparing AR and MDM paradigms is their\ntypical architectural difference: AR models are often decoder-only, while MDMs\nhave largely been encoder-only. This practice of changing both the modeling\nparadigm and architecture simultaneously makes direct comparisons unfair, as\nit's hard to distinguish whether observed differences stem from the paradigm\nitself or the architectural shift. This research evaluates MDMs within a\ndecoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or\nAO-AR) and standard AR paradigms. Our investigation suggests that the standard\nAO-AR objective, which averages over all token permutations, may benefit from\nrefinement, as many permutations appear less informative compared to the\nlanguage's inherent left-to-right structure. (2) Investigate architectural\ninfluences (decoder-only vs. encoder-only) within MDMs. We demonstrate that\nwhile encoder-only MDMs model a simpler conditional probability space,\ndecoder-only MDMs can achieve dramatic generation speedups ($\\sim25\\times$) and\ncomparable perplexity with temperature annealing despite modeling a vastly\nlarger space, highlighting key trade-offs. This work thus decouples core\nparadigm differences from architectural influences, offering insights for\nfuture model design. Code is available at https://github.com/scxue/AO-GPT-MDM.", "AI": {"tldr": "The paper compares autoregressive (AR) and masked diffusion models (MDMs) in a decoder-only framework, highlighting trade-offs in speed and perplexity while decoupling paradigm differences from architectural influences.", "motivation": "To fairly compare AR and MDM paradigms by addressing the confounding factor of architectural differences (decoder-only vs. encoder-only) and to refine the MDM objective.", "method": "Evaluates MDMs within a decoder-only framework, comparing them as Any-Order AR (AO-AR) and standard AR, and investigates architectural influences.", "result": "Decoder-only MDMs achieve significant generation speedups (~25\u00d7) and comparable perplexity with temperature annealing, despite modeling a larger space.", "conclusion": "The work decouples paradigm differences from architectural influences, providing insights for future model design, and suggests refining the AO-AR objective."}}
{"id": "2506.20167", "pdf": "https://arxiv.org/pdf/2506.20167", "abs": "https://arxiv.org/abs/2506.20167", "authors": ["Fengze Li", "Yue Wang", "Yangle Liu", "Ming Huang", "Dou Hong", "Jieming Ma"], "title": "SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multivariate time series forecasting requires models to simultaneously\ncapture variable-wise structural dependencies and generalize across diverse\ntasks. While structural encoders are effective in modeling feature\ninteractions, they lack the capacity to support semantic-level reasoning or\ntask adaptation. Conversely, large language models (LLMs) possess strong\ngeneralization capabilities but remain incompatible with raw time series\ninputs. This gap limits the development of unified, transferable prediction\nsystems. Therefore, we introduce SEED, a structural encoder for\nembedding-driven decoding, which integrates four stages: a token-aware encoder\nfor patch extraction, a projection module that aligns patches with language\nmodel embeddings, a semantic reprogramming mechanism that maps patches to\ntask-aware prototypes, and a frozen language model for prediction. This modular\narchitecture decouples representation learning from inference, enabling\nefficient alignment between numerical patterns and semantic reasoning.\nEmpirical results demonstrate that the proposed method achieves consistent\nimprovements over strong baselines, and comparative studies on various datasets\nconfirm SEED's role in addressing the structural-semantic modeling gap.", "AI": {"tldr": "SEED integrates structural encoding with LLMs for multivariate time series forecasting, bridging the gap between numerical patterns and semantic reasoning.", "motivation": "Existing models lack the ability to combine structural dependencies with semantic-level reasoning or task adaptation, limiting unified prediction systems.", "method": "SEED uses a token-aware encoder, projection module, semantic reprogramming, and frozen LLM for prediction, decoupling representation learning from inference.", "result": "SEED consistently outperforms baselines and addresses the structural-semantic modeling gap across datasets.", "conclusion": "SEED effectively unifies structural and semantic modeling for improved time series forecasting."}}
{"id": "2506.20179", "pdf": "https://arxiv.org/pdf/2506.20179", "abs": "https://arxiv.org/abs/2506.20179", "authors": ["Enzhe Zhao", "Zhichang Guo", "Yao Li", "Fanghui Song", "Boying Wu"], "title": "Progressive Alignment Degradation Learning for Pansharpening", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "13 pages, 9 figures", "summary": "Deep learning-based pansharpening has been shown to effectively generate\nhigh-resolution multispectral (HRMS) images. To create supervised ground-truth\nHRMS images, synthetic data generated using the Wald protocol is commonly\nemployed. This protocol assumes that networks trained on artificial\nlow-resolution data will perform equally well on high-resolution data. However,\nwell-trained models typically exhibit a trade-off in performance between\nreduced-resolution and full-resolution datasets. In this paper, we delve into\nthe Wald protocol and find that its inaccurate approximation of real-world\ndegradation patterns limits the generalization of deep pansharpening models. To\naddress this issue, we propose the Progressive Alignment Degradation Module\n(PADM), which uses mutual iteration between two sub-networks, PAlignNet and\nPDegradeNet, to adaptively learn accurate degradation processes without relying\non predefined operators. Building on this, we introduce HFreqdiff, which embeds\nhigh-frequency details into a diffusion framework and incorporates CFB and BACM\nmodules for frequency-selective detail extraction and precise reverse process\nlearning. These innovations enable effective integration of high-resolution\npanchromatic and multispectral images, significantly enhancing spatial\nsharpness and quality. Experiments and ablation studies demonstrate the\nproposed method's superior performance compared to state-of-the-art techniques.", "AI": {"tldr": "The paper critiques the Wald protocol's limitations in pansharpening and introduces PADM and HFreqdiff for improved HRMS image generation.", "motivation": "The Wald protocol's inaccurate degradation patterns limit deep pansharpening model generalization.", "method": "Proposes PADM (Progressive Alignment Degradation Module) and HFreqdiff, integrating high-frequency details via diffusion and specialized modules.", "result": "Superior performance in spatial sharpness and quality, outperforming state-of-the-art methods.", "conclusion": "The proposed innovations address Wald protocol limitations, enhancing pansharpening effectiveness."}}
{"id": "2506.20222", "pdf": "https://arxiv.org/pdf/2506.20222", "abs": "https://arxiv.org/abs/2506.20222", "authors": ["Pujing Yang", "Guangyi Zhang", "Yunlong Cai", "Lei Yu", "Guanding Yu"], "title": "Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission", "categories": ["cs.CV", "eess.SP"], "comment": null, "summary": "Event cameras asynchronously capture pixel-level intensity changes with\nextremely low latency. They are increasingly used in conjunction with RGB\ncameras for a wide range of vision-related applications. However, a major\nchallenge in these hybrid systems lies in the transmission of the large volume\nof triggered events and RGB images. To address this, we propose a transmission\nscheme that retains efficient reconstruction performance of both sources while\naccomplishing real-time deblurring in parallel. Conventional RGB cameras and\nevent cameras typically capture the same scene in different ways, often\nresulting in significant redundant information across their outputs. To address\nthis, we develop a joint event and image (E-I) transmission framework to\neliminate redundancy and thereby optimize channel bandwidth utilization. Our\napproach employs Bayesian modeling and the information bottleneck method to\ndisentangle the shared and domain-specific information within the E-I inputs.\nThis disentangled information bottleneck framework ensures both the compactness\nand informativeness of extracted shared and domain-specific information.\nMoreover, it adaptively allocates transmission bandwidth based on scene\ndynamics, i.e., more symbols are allocated to events for dynamic details or to\nimages for static information. Simulation results demonstrate that the proposed\nscheme not only achieves superior reconstruction quality compared to\nconventional systems but also delivers enhanced deblurring performance.", "AI": {"tldr": "A joint event and image (E-I) transmission framework is proposed to optimize bandwidth by eliminating redundancy between event and RGB cameras, using Bayesian modeling and information bottleneck for efficient reconstruction and deblurring.", "motivation": "Hybrid systems combining event and RGB cameras face challenges in transmitting large volumes of data, with redundant information between the two sources.", "method": "The framework employs Bayesian modeling and the information bottleneck method to disentangle shared and domain-specific information, adaptively allocating bandwidth based on scene dynamics.", "result": "Simulations show superior reconstruction quality and enhanced deblurring performance compared to conventional systems.", "conclusion": "The proposed scheme effectively optimizes bandwidth while improving reconstruction and deblurring, making it suitable for real-time hybrid vision systems."}}
{"id": "2506.20357", "pdf": "https://arxiv.org/pdf/2506.20357", "abs": "https://arxiv.org/abs/2506.20357", "authors": ["Sungwon Han", "Sungkyu Park", "Seungeon Lee"], "title": "Tabular Feature Discovery With Reasoning Type Exploration", "categories": ["cs.AI"], "comment": null, "summary": "Feature engineering for tabular data remains a critical yet challenging step\nin machine learning. Recently, large language models (LLMs) have been used to\nautomatically generate new features by leveraging their vast knowledge.\nHowever, existing LLM-based approaches often produce overly simple or\nrepetitive features, partly due to inherent biases in the transformations the\nLLM chooses and the lack of structured reasoning guidance during generation. In\nthis paper, we propose a novel method REFeat, which guides an LLM to discover\ndiverse and informative features by leveraging multiple types of reasoning to\nsteer the feature generation process. Experiments on 59 benchmark datasets\ndemonstrate that our approach not only achieves higher predictive accuracy on\naverage, but also discovers more diverse and meaningful features. These results\nhighlight the promise of incorporating rich reasoning paradigms and adaptive\nstrategy selection into LLM-driven feature discovery for tabular data.", "AI": {"tldr": "REFeat, a novel method, uses LLMs with structured reasoning to generate diverse and informative features for tabular data, outperforming existing approaches in accuracy and feature quality.", "motivation": "Existing LLM-based feature generation methods often produce simple or repetitive features due to biases and lack of structured reasoning.", "method": "REFeat leverages multiple reasoning types to guide LLMs in generating diverse and meaningful features.", "result": "Experiments on 59 datasets show higher predictive accuracy and more diverse features compared to existing methods.", "conclusion": "Incorporating rich reasoning and adaptive strategies into LLM-driven feature discovery holds promise for improving tabular data feature engineering."}}
{"id": "2506.19937", "pdf": "https://arxiv.org/pdf/2506.19937", "abs": "https://arxiv.org/abs/2506.19937", "authors": ["Tomas M. Bosschieter", "Luis Franca", "Jessica Wolk", "Yiyuan Wu", "Bella Mehta", "Joseph Dehoney", "Orsolya Kiss", "Fiona C. Baker", "Qingyu Zhao", "Rich Caruana", "Kilian M. Pohl"], "title": "The Most Important Features in Generalized Additive Models Might Be Groups of Features", "categories": ["cs.LG"], "comment": null, "summary": "While analyzing the importance of features has become ubiquitous in\ninterpretable machine learning, the joint signal from a group of related\nfeatures is sometimes overlooked or inadvertently excluded. Neglecting the\njoint signal could bypass a critical insight: in many instances, the most\nsignificant predictors are not isolated features, but rather the combined\neffect of groups of features. This can be especially problematic for datasets\nthat contain natural groupings of features, including multimodal datasets. This\npaper introduces a novel approach to determine the importance of a group of\nfeatures for Generalized Additive Models (GAMs) that is efficient, requires no\nmodel retraining, allows defining groups posthoc, permits overlapping groups,\nand remains meaningful in high-dimensional settings. Moreover, this definition\noffers a parallel with explained variation in statistics. We showcase\nproperties of our method on three synthetic experiments that illustrate the\nbehavior of group importance across various data regimes. We then demonstrate\nthe importance of groups of features in identifying depressive symptoms from a\nmultimodal neuroscience dataset, and study the importance of social\ndeterminants of health after total hip arthroplasty. These two case studies\nreveal that analyzing group importance offers a more accurate, holistic view of\nthe medical issues compared to a single-feature analysis.", "AI": {"tldr": "The paper introduces a method to evaluate the importance of feature groups in GAMs, emphasizing joint signals over isolated features, and demonstrates its utility in medical datasets.", "motivation": "Existing interpretable ML methods often overlook joint signals from feature groups, which can be critical, especially in datasets with natural feature groupings like multimodal data.", "method": "A novel approach for determining feature group importance in GAMs, efficient and requiring no retraining, with support for posthoc and overlapping groups.", "result": "The method is validated on synthetic experiments and applied to medical datasets, showing improved accuracy and holistic insights compared to single-feature analysis.", "conclusion": "Analyzing group importance provides more accurate and comprehensive insights, particularly in medical contexts, highlighting the value of joint feature signals."}}
{"id": "2506.20178", "pdf": "https://arxiv.org/pdf/2506.20178", "abs": "https://arxiv.org/abs/2506.20178", "authors": ["Zhiyuan Wang", "Jinhao Duan", "Qingni Wang", "Xiaofeng Zhu", "Tianlong Chen", "Xiaoshuang Shi", "Kaidi Xu"], "title": "COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Uncertainty quantification (UQ) for foundation models is essential to\nidentify and mitigate potential hallucinations in automatically generated text.\nHowever, heuristic UQ approaches lack formal guarantees for key metrics such as\nthe false discovery rate (FDR) in selective prediction. Previous work adopts\nthe split conformal prediction (SCP) framework to ensure desired coverage of\nadmissible answers by constructing prediction sets, but these sets often\ncontain incorrect candidates, limiting their practical utility. To address\nthis, we propose COIN, an uncertainty-guarding selection framework that\ncalibrates statistically valid thresholds to filter a single generated answer\nper question under user-specified FDR constraints. COIN estimates the empirical\nerror rate on a calibration set and applies confidence interval methods such as\nClopper-Pearson to establish a high-probability upper bound on the true error\nrate (i.e., FDR). This enables the selection of the largest uncertainty\nthreshold that ensures FDR control on test data while significantly increasing\nsample retention. We demonstrate COIN's robustness in risk control, strong\ntest-time power in retaining admissible answers, and predictive efficiency\nunder limited calibration data across both general and multimodal text\ngeneration tasks. Furthermore, we show that employing alternative upper bound\nconstructions and UQ strategies can further boost COIN's power performance,\nwhich underscores its extensibility and adaptability to diverse application\nscenarios.", "AI": {"tldr": "COIN is a framework for uncertainty quantification in foundation models, ensuring FDR control while improving answer retention and efficiency.", "motivation": "Address the lack of formal guarantees in heuristic UQ methods and the limitations of split conformal prediction in filtering incorrect answers.", "method": "COIN calibrates thresholds using empirical error rates and confidence intervals (e.g., Clopper-Pearson) to control FDR and select answers.", "result": "COIN achieves robust FDR control, high answer retention, and efficiency, even with limited calibration data.", "conclusion": "COIN is adaptable and extensible, offering improved uncertainty quantification for diverse text generation tasks."}}
{"id": "2506.20293", "pdf": "https://arxiv.org/pdf/2506.20293", "abs": "https://arxiv.org/abs/2506.20293", "authors": ["Kunjing Yang", "Libin Zheng", "Minru Bai", "Ting Lu", "Leyuan Fang"], "title": "Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "The blind fusion of unregistered hyperspectral images (HSIs) and\nmultispectral images (MSIs) has attracted growing attention recently. To\naddress the registration challenge, most existing methods employ spatial\ntransformations on the HSI to achieve alignment with the MSI. However, due to\nthe substantial differences in spatial resolution of the images, the\nperformance of these methods is often unsatisfactory. Moreover, the\nregistration process tends to be time-consuming when dealing with large-sized\nimages in remote sensing. To address these issues, we propose tackling the\nregistration problem from the spectral domain. Initially, a lightweight\nSpectral Prior Learning (SPL) network is developed to extract spectral features\nfrom the HSI and enhance the spectral resolution of the MSI. Following this,\nthe obtained image undergoes spatial downsampling to produce the registered\nHSI. In this process, subspace representation and cyclic training strategy are\nemployed to improve spectral accuracy of the registered HSI obtained. Next, we\npropose a blind sparse fusion (BSF) method, which utilizes group sparsity\nregularization to equivalently promote the low-rankness of the image. This\napproach not only circumvents the need for rank estimation, but also reduces\ncomputational complexity. Then, we employ the Proximal Alternating Optimization\n(PAO) algorithm to solve the BSF model, and present its convergence analysis.\nFinally, extensive numerical experiments on simulated and real datasets are\nconducted to verify the effectiveness of our method in registration and fusion.\nWe also demonstrate its efficacy in enhancing classification performance.", "AI": {"tldr": "A method for blind fusion of unregistered hyperspectral (HSI) and multispectral (MSI) images using spectral domain registration and sparse fusion, improving efficiency and accuracy.", "motivation": "Addressing the challenges of spatial resolution differences and time-consuming registration in existing methods for HSI and MSI fusion.", "method": "Proposes Spectral Prior Learning (SPL) for spectral feature extraction and resolution enhancement, followed by blind sparse fusion (BSF) with group sparsity regularization, solved via Proximal Alternating Optimization (PAO).", "result": "Effective registration and fusion demonstrated on simulated and real datasets, with improved classification performance.", "conclusion": "The method efficiently addresses registration and fusion challenges, offering computational simplicity and enhanced spectral accuracy."}}
{"id": "2506.20254", "pdf": "https://arxiv.org/pdf/2506.20254", "abs": "https://arxiv.org/abs/2506.20254", "authors": ["Kun Yuan", "Tingxuan Chen", "Shi Li", "Joel L. Lavanchy", "Christian Heiliger", "Ege \u00d6zsoy", "Yiming Huang", "Long Bai", "Nassir Navab", "Vinkle Srivastav", "Hongliang Ren", "Nicolas Padoy"], "title": "Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement", "categories": ["cs.CV"], "comment": "Accepted by MICCAI 2025", "summary": "The complexity and diversity of surgical workflows, driven by heterogeneous\noperating room settings, institutional protocols, and anatomical variability,\npresent a significant challenge in developing generalizable models for\ncross-institutional and cross-procedural surgical understanding. While recent\nsurgical foundation models pretrained on large-scale vision-language data offer\npromising transferability, their zero-shot performance remains constrained by\ndomain shifts, limiting their utility in unseen surgical environments. To\naddress this, we introduce Surgical Phase Anywhere (SPA), a lightweight\nframework for versatile surgical workflow understanding that adapts foundation\nmodels to institutional settings with minimal annotation. SPA leverages\nfew-shot spatial adaptation to align multi-modal embeddings with\ninstitution-specific surgical scenes and phases. It also ensures temporal\nconsistency through diffusion modeling, which encodes task-graph priors derived\nfrom institutional procedure protocols. Finally, SPA employs dynamic test-time\nadaptation, exploiting the mutual agreement between multi-modal phase\nprediction streams to adapt the model to a given test video in a\nself-supervised manner, enhancing the reliability under test-time distribution\nshifts. SPA is a lightweight adaptation framework, allowing hospitals to\nrapidly customize phase recognition models by defining phases in natural\nlanguage text, annotating a few images with the phase labels, and providing a\ntask graph defining phase transitions. The experimental results show that the\nSPA framework achieves state-of-the-art performance in few-shot surgical phase\nrecognition across multiple institutions and procedures, even outperforming\nfull-shot models with 32-shot labeled data. Code is available at\nhttps://github.com/CAMMA-public/SPA", "AI": {"tldr": "SPA is a lightweight framework for adapting surgical foundation models to institutional settings with minimal annotation, achieving state-of-the-art performance in few-shot surgical phase recognition.", "motivation": "The challenge of developing generalizable models for surgical workflow understanding due to heterogeneous operating room settings and domain shifts.", "method": "SPA uses few-shot spatial adaptation, diffusion modeling for temporal consistency, and dynamic test-time adaptation to align multi-modal embeddings with institution-specific scenes and phases.", "result": "SPA outperforms full-shot models with 32-shot labeled data, achieving state-of-the-art performance across multiple institutions and procedures.", "conclusion": "SPA provides a versatile and efficient solution for surgical workflow understanding, enabling hospitals to customize models with minimal effort."}}
{"id": "2506.20384", "pdf": "https://arxiv.org/pdf/2506.20384", "abs": "https://arxiv.org/abs/2506.20384", "authors": ["Dror Ivry", "Oran Nahum"], "title": "Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios", "categories": ["cs.AI"], "comment": "6 pages, 2 figures", "summary": "This paper introduces two significant contributions to address the issue of\ngrounding claims in a given context. Grounding means that given a context\n(document) and a claim, there's at least one supportive evidence for the claim\nin the document. We will introduce Paladin-mini, a compact (3.8B parameters)\nopen-source classifier model (used for labeling data as grounded or ungrounded)\nengineered for robust performance in real-world scenarios, and the\ngrounding-benchmark, a new evaluation dataset designed to assess performance on\ncritical reasoning tasks. We'll also demonstrate the results of Paladin-mini\nwith benchmarks against the current State-of-the-art and share clear and\nreproducible results.", "AI": {"tldr": "The paper introduces Paladin-mini, a compact open-source classifier for grounding claims, and a new evaluation dataset (grounding-benchmark), showcasing its performance against State-of-the-art.", "motivation": "To address the challenge of grounding claims in documents by providing supportive evidence, ensuring robust real-world applicability.", "method": "Developed Paladin-mini (3.8B parameters) for labeling grounded/ungrounded claims and created the grounding-benchmark dataset for evaluation.", "result": "Demonstrated Paladin-mini's performance against State-of-the-art, with clear and reproducible results.", "conclusion": "Paladin-mini and the grounding-benchmark offer effective tools for claim grounding, with competitive performance."}}
{"id": "2506.19992", "pdf": "https://arxiv.org/pdf/2506.19992", "abs": "https://arxiv.org/abs/2506.19992", "authors": ["Gabor Petnehazi", "Bernadett Aradi"], "title": "HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The explosive growth of complex datasets across various modalities\nnecessitates advanced analytical tools that not only group data effectively but\nalso provide human-understandable insights into the discovered structures. We\nintroduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using\nLLMs for Efficient Summarization), a novel algorithm and Python package\ndesigned for hierarchical k-means clustering of diverse data types, including\ntext, images, and numeric data (processed one modality per run). HERCULES\nconstructs a cluster hierarchy by recursively applying k-means clustering,\nstarting from individual data points at level 0. A key innovation is its deep\nintegration of Large Language Models (LLMs) to generate semantically rich\ntitles and descriptions for clusters at each level of the hierarchy,\nsignificantly enhancing interpretability. The algorithm supports two main\nrepresentation modes: `direct' mode, which clusters based on original data\nembeddings or scaled numeric features, and `description' mode, which clusters\nbased on embeddings derived from LLM-generated summaries. Users can provide a\n`topic\\_seed' to guide LLM-generated summaries towards specific themes. An\ninteractive visualization tool facilitates thorough analysis and understanding\nof the clustering results. We demonstrate HERCULES's capabilities and discuss\nits potential for extracting meaningful, hierarchical knowledge from complex\ndatasets.", "AI": {"tldr": "HERCULES is a hierarchical k-means clustering algorithm integrating LLMs for interpretable summaries of diverse data types.", "motivation": "Address the need for advanced tools to group complex datasets and provide human-understandable insights.", "method": "Recursive k-means clustering with LLM-generated titles/descriptions for clusters, supporting direct and description modes.", "result": "Enhanced interpretability and meaningful hierarchical knowledge extraction from complex datasets.", "conclusion": "HERCULES offers a powerful, interpretable solution for hierarchical clustering of multimodal data."}}
{"id": "2506.20199", "pdf": "https://arxiv.org/pdf/2506.20199", "abs": "https://arxiv.org/abs/2506.20199", "authors": ["Mengqi Wang", "Tiantian Feng", "Shrikanth Narayanan"], "title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have enabled a wide variety of real-world\napplications in various domains. However, creating a high-performing\napplication with high accuracy remains challenging, particularly for subjective\ntasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this\nstudy investigates approaches to improving conversational emotion recognition\n(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples\nin in-context learning (ICL) to enhance CER. We propose various strategies\nbased on random and augmented example retrieval and also analyze the impact of\nconversational context on CER accuracy. Experiments were conducted on the three\ndatasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented\nexample retrieval consistently outperforms other techniques under investigation\nacross all datasets, highlighting the importance of retrieving coherent\ntargeted examples and enhancing them through paraphrasing.", "AI": {"tldr": "The paper explores improving conversational emotion recognition (CER) using LLMs by focusing on high-quality example retrieval in in-context learning (ICL). Augmented example retrieval outperforms other methods.", "motivation": "Enhancing CER accuracy for subjective tasks like emotion recognition, inspired by the SLT 2024 GenSER Challenge.", "method": "Proposes strategies for example retrieval in ICL, including random and augmented methods, and analyzes conversational context impact.", "result": "Augmented example retrieval consistently outperforms other techniques across datasets (IEMOCAP, MELD, EmoryNLP).", "conclusion": "Retrieving coherent, targeted examples and enhancing them through paraphrasing is crucial for improving CER with LLMs."}}
{"id": "2506.20475", "pdf": "https://arxiv.org/pdf/2506.20475", "abs": "https://arxiv.org/abs/2506.20475", "authors": ["Hao Chen", "Yu Hin Ng", "Ching-Wei Chang", "Haobo Liang", "Yanke Wang"], "title": "Learning-based safety lifting monitoring system for cranes on construction sites", "categories": ["eess.SY", "cs.SY", "eess.IV"], "comment": "20 pages, 10 figures", "summary": "Lifting on construction sites, as a frequent operation, works still with\nsafety risks, especially for modular integrated construction (MiC) lifting due\nto its large weight and size, probably leading to accidents, causing damage to\nthe modules, or more critically, posing safety hazards to on-site workers.\nAiming to reduce the safety risks in lifting scenarios, we design an automated\nsafe lifting monitoring algorithm pipeline based on learning-based methods, and\ndeploy it on construction sites. This work is potentially to increase the\nsafety and efficiency of MiC lifting process via automation technologies. A\ndataset is created consisting of 1007 image-point cloud pairs (37 MiC\nliftings). Advanced object detection models are trained for automated\ntwo-dimensional (2D) detection of MiCs and humans. Fusing the 2D detection\nresults with the point cloud information allows accurate determination of the\nthree-dimensional (3D) positions of MiCs and humans. The system is designed to\nautomatically trigger alarms that notify individuals in the MiC lifting danger\nzone, while providing the crane operator with real-time lifting information and\nearly warnings. The monitoring process minimizes the human intervention and no\nor less signal men are required on real sites assisted by our system. A\nquantitative analysis is conducted to evaluate the effectiveness of the\nalgorithmic pipeline. The pipeline shows promising results in MiC and human\nperception with the mean distance error of 1.5640 m and 0.7824 m respectively.\nFurthermore, the developed system successfully executes safety risk monitoring\nand alarm functionalities during the MiC lifting process with limited manual\nwork on real construction sites.", "AI": {"tldr": "An automated safe lifting monitoring algorithm pipeline is designed for modular integrated construction (MiC) lifting to reduce safety risks, using learning-based methods and real-time alerts.", "motivation": "To mitigate safety risks in MiC lifting due to large module weight and size, which can cause accidents or hazards to workers.", "method": "The pipeline uses 2D object detection models on image-point cloud pairs to determine 3D positions of MiCs and humans, triggering alarms for danger zones.", "result": "The system achieves mean distance errors of 1.5640 m for MiCs and 0.7824 m for humans, successfully monitoring risks with minimal manual intervention.", "conclusion": "The automated system enhances safety and efficiency in MiC lifting, reducing reliance on human signalers and providing real-time warnings."}}
{"id": "2506.20255", "pdf": "https://arxiv.org/pdf/2506.20255", "abs": "https://arxiv.org/abs/2506.20255", "authors": ["Ayush Lodh", "Ritabrata Chakraborty", "Shivakumara Palaiahnakote", "Umapada Pal"], "title": "A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features", "categories": ["cs.CV", "cs.LG"], "comment": "15 pages, 7 figures", "summary": "We posit that handwriting recognition benefits from complementary cues\ncarried by the rasterized complex glyph and the pen's trajectory, yet most\nsystems exploit only one modality. We introduce an end-to-end network that\nperforms early fusion of offline images and online stroke data within a shared\nlatent space. A patch encoder converts the grayscale crop into fixed-length\nvisual tokens, while a lightweight transformer embeds the $(x, y, \\text{pen})$\nsequence. Learnable latent queries attend jointly to both token streams,\nyielding context-enhanced stroke embeddings that are pooled and decoded under a\ncross-entropy loss objective. Because integration occurs before any high-level\nclassification, temporal cues reinforce each other during representation\nlearning, producing stronger writer independence. Comprehensive experiments on\nIAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art\naccuracy, exceeding previous bests by up to 1\\%. Our study also shows\nadaptation of this pipeline with gesturification on the ISI-Air dataset. Our\ncode can be found here.", "AI": {"tldr": "An end-to-end network fuses offline images and online stroke data for handwriting recognition, achieving state-of-the-art accuracy with 1% improvement.", "motivation": "Handwriting recognition systems typically use only one modality (glyph or trajectory), missing complementary cues. This work aims to leverage both for better performance.", "method": "Early fusion of offline images and online stroke data in a shared latent space using a patch encoder and lightweight transformer. Learnable queries attend to both modalities.", "result": "Achieves state-of-the-art accuracy on IAMOn-DB and VNOn-DB, outperforming previous methods by up to 1%. Also adapts well to gesturification on ISI-Air.", "conclusion": "Combining offline and online modalities in early fusion improves handwriting recognition accuracy and writer independence."}}
{"id": "2506.20401", "pdf": "https://arxiv.org/pdf/2506.20401", "abs": "https://arxiv.org/abs/2506.20401", "authors": ["Jinchun Du", "Bojie Shen", "Muhammad Aamir Cheema", "Adel N. Toosi"], "title": "Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation", "categories": ["cs.AI"], "comment": null, "summary": "With the rising popularity of electric vehicles (EVs), modern service\nsystems, such as ride-hailing delivery services, are increasingly integrating\nEVs into their operations. Unlike conventional vehicles, EVs often have a\nshorter driving range, necessitating careful consideration of charging when\nfulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -\nallowing EVs to also discharge energy back to the grid - new opportunities and\ncomplexities emerge. We introduce the Electric Vehicle Orienteering Problem\nwith V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select\ncustomer requests or orders while managing when and where to charge or\ndischarge. This involves navigating dynamic electricity prices, charging\nstation selection, and route constraints. We formulate the problem as a Mixed\nInteger Programming (MIP) model and propose two near-optimal metaheuristic\nalgorithms: one evolutionary (EA) and the other based on large neighborhood\nsearch (LNS). Experiments on real-world data show our methods can double driver\nprofits compared to baselines, while maintaining near-optimal performance on\nsmall instances and excellent scalability on larger ones. Our work highlights a\npromising path toward smarter, more profitable EV-based mobility systems that\nactively support the energy grid.", "AI": {"tldr": "The paper introduces the Electric Vehicle Orienteering Problem with V2G (EVOP-V2G), focusing on profit-maximization for EV drivers by optimizing charging/discharging decisions amid dynamic electricity prices and route constraints. Two metaheuristic algorithms (EA and LNS) are proposed, showing significant profit gains and scalability.", "motivation": "The integration of EVs into ride-hailing and delivery services, coupled with V2G technology, creates new challenges and opportunities for optimizing charging/discharging decisions to maximize profits while supporting the energy grid.", "method": "The problem is formulated as a Mixed Integer Programming (MIP) model, and two metaheuristic algorithms (evolutionary and large neighborhood search) are proposed for near-optimal solutions.", "result": "Experiments on real-world data demonstrate that the proposed methods double driver profits compared to baselines, with near-optimal performance on small instances and scalability on larger ones.", "conclusion": "The work presents a promising approach for smarter, more profitable EV-based mobility systems that actively contribute to grid stability."}}
{"id": "2506.19997", "pdf": "https://arxiv.org/pdf/2506.19997", "abs": "https://arxiv.org/abs/2506.19997", "authors": ["Geonwoo Cho", "Jaegyun Im", "Jihwan Lee", "Hojun Yi", "Sejin Kim", "Sundong Kim"], "title": "TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generalizing deep reinforcement learning agents to unseen environments\nremains a significant challenge. One promising solution is Unsupervised\nEnvironment Design (UED), a co-evolutionary framework in which a teacher\nadaptively generates tasks with high learning potential, while a student learns\na robust policy from this evolving curriculum. Existing UED methods typically\nmeasure learning potential via regret, the gap between optimal and current\nperformance, approximated solely by value-function loss. Building on these\napproaches, we introduce the transition prediction error as an additional term\nin our regret approximation. To capture how training on one task affects\nperformance on others, we further propose a lightweight metric called\nco-learnability. By combining these two measures, we present Transition-aware\nRegret Approximation with Co-learnability for Environment Design (TRACED).\nEmpirical evaluations show that TRACED yields curricula that improve zero-shot\ngeneralization across multiple benchmarks while requiring up to 2x fewer\nenvironment interactions than strong baselines. Ablation studies confirm that\nthe transition prediction error drives rapid complexity ramp-up and that\nco-learnability delivers additional gains when paired with the transition\nprediction error. These results demonstrate how refined regret approximation\nand explicit modeling of task relationships can be leveraged for\nsample-efficient curriculum design in UED.", "AI": {"tldr": "TRACED introduces transition prediction error and co-learnability to improve regret approximation in UED, enhancing zero-shot generalization with fewer environment interactions.", "motivation": "Addressing the challenge of generalizing deep reinforcement learning agents to unseen environments by refining regret approximation in UED.", "method": "Combines transition prediction error and co-learnability in regret approximation for adaptive task generation.", "result": "TRACED improves zero-shot generalization and reduces environment interactions by up to 2x compared to baselines.", "conclusion": "Refined regret approximation and task relationship modeling enhance sample-efficient curriculum design in UED."}}
{"id": "2506.20203", "pdf": "https://arxiv.org/pdf/2506.20203", "abs": "https://arxiv.org/abs/2506.20203", "authors": ["Petra Baran\u010d\u00edkov\u00e1", "Ond\u0159ej Bojar"], "title": "Intrinsic vs. Extrinsic Evaluation of Czech Sentence Embeddings: Semantic Relevance Doesn't Help with MT Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we compare Czech-specific and multilingual sentence embedding\nmodels through intrinsic and extrinsic evaluation paradigms. For intrinsic\nevaluation, we employ Costra, a complex sentence transformation dataset, and\nseveral Semantic Textual Similarity (STS) benchmarks to assess the ability of\nthe embeddings to capture linguistic phenomena such as semantic similarity,\ntemporal aspects, and stylistic variations. In the extrinsic evaluation, we\nfine-tune each embedding model using COMET-based metrics for machine\ntranslation evaluation.\n  Our experiments reveal an interesting disconnect: models that excel in\nintrinsic semantic similarity tests do not consistently yield superior\nperformance on downstream translation evaluation tasks. Conversely, models with\nseemingly over-smoothed embedding spaces can, through fine-tuning, achieve\nexcellent results. These findings highlight the complex relationship between\nsemantic property probes and downstream task, emphasizing the need for more\nresearch into 'operationalizable semantics' in sentence embeddings, or more\nin-depth downstream tasks datasets (here translation evaluation)", "AI": {"tldr": "The paper compares Czech-specific and multilingual sentence embedding models using intrinsic and extrinsic evaluations, revealing a disconnect between semantic similarity performance and downstream task results.", "motivation": "To assess how well sentence embeddings capture linguistic phenomena and perform in practical tasks like machine translation evaluation.", "method": "Intrinsic evaluation uses Costra and STS benchmarks; extrinsic evaluation fine-tunes models for translation tasks using COMET metrics.", "result": "Models strong in semantic similarity tests don't always excel in translation tasks, while fine-tuned models with smoothed embeddings perform well.", "conclusion": "The findings stress the need for research into 'operationalizable semantics' and better downstream task datasets."}}
{"id": "2506.16210", "pdf": "https://arxiv.org/pdf/2506.16210", "abs": "https://arxiv.org/abs/2506.16210", "authors": ["Zhenxuan Zhang", "Lipei Zhang", "Yanqi Cheng", "Zi Wang", "Fanwen Wang", "Haosen Zhang", "Yue Yang", "Yinzhe Wu", "Jiahao Huang", "Angelica I Aviles-Rivero", "Zhifan Gao", "Guang Yang", "Peter J. Lally"], "title": "From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In motion-robust magnetic resonance imaging (MRI), slice-to-volume\nreconstruction is critical for recovering anatomically consistent 3D brain\nvolumes from 2D slices, especially under accelerated acquisitions or patient\nmotion. However, this task remains challenging due to hierarchical structural\ndisruptions. It includes local detail loss from k-space undersampling, global\nstructural aliasing caused by motion, and volumetric anisotropy. Therefore, we\npropose a progressive refinement implicit neural representation (PR-INR)\nframework. Our PR-INR unifies motion correction, structural refinement, and\nvolumetric synthesis within a geometry-aware coordinate space. Specifically, a\nmotion-aware diffusion module is first employed to generate coarse volumetric\nreconstructions that suppress motion artifacts and preserve global anatomical\nstructures. Then, we introduce an implicit detail restoration module that\nperforms residual refinement by aligning spatial coordinates with visual\nfeatures. It corrects local structures and enhances boundary precision.\nFurther, a voxel continuous-aware representation module represents the image as\na continuous function over 3D coordinates. It enables accurate inter-slice\ncompletion and high-frequency detail recovery. We evaluate PR-INR on five\npublic MRI datasets under various motion conditions (3% and 5% displacement),\nundersampling rates (4x and 8x) and slice resolutions (scale = 5). Experimental\nresults demonstrate that PR-INR outperforms state-of-the-art methods in both\nquantitative reconstruction metrics and visual quality. It further shows\ngeneralization and robustness across diverse unseen domains.", "AI": {"tldr": "PR-INR is a progressive refinement framework for motion-robust MRI, unifying motion correction, structural refinement, and volumetric synthesis to address hierarchical disruptions in slice-to-volume reconstruction.", "motivation": "Challenges in MRI reconstruction include local detail loss, global structural aliasing, and volumetric anisotropy due to motion and undersampling.", "method": "PR-INR combines a motion-aware diffusion module for coarse reconstruction, an implicit detail restoration module for local refinement, and a voxel continuous-aware module for inter-slice completion.", "result": "PR-INR outperforms state-of-the-art methods in quantitative metrics and visual quality, showing robustness across diverse conditions.", "conclusion": "PR-INR effectively addresses hierarchical disruptions in MRI reconstruction, demonstrating superior performance and generalization."}}
{"id": "2506.20263", "pdf": "https://arxiv.org/pdf/2506.20263", "abs": "https://arxiv.org/abs/2506.20263", "authors": ["Ning Luo", "Meiyin Hu", "Huan Wan", "Yanyan Yang", "Zhuohang Jiang", "Xin Wei"], "title": "Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification", "categories": ["cs.CV"], "comment": null, "summary": "Few-shot fine-grained image classification (FS-FGIC) presents a significant\nchallenge, requiring models to distinguish visually similar subclasses with\nlimited labeled examples. Existing methods have critical limitations:\nmetric-based methods lose spatial information and misalign local features,\nwhile reconstruction-based methods fail to utilize hierarchical feature\ninformation and lack mechanisms to focus on discriminative regions. We propose\nthe Hierarchical Mask-enhanced Dual Reconstruction Network (HMDRN), which\nintegrates dual-layer feature reconstruction with mask-enhanced feature\nprocessing to improve fine-grained classification. HMDRN incorporates a\ndual-layer feature reconstruction and fusion module that leverages\ncomplementary visual information from different network hierarchies. Through\nlearnable fusion weights, the model balances high-level semantic\nrepresentations from the last layer with mid-level structural details from the\npenultimate layer. Additionally, we design a spatial binary mask-enhanced\ntransformer self-reconstruction module that processes query features through\nadaptive thresholding while maintaining complete support features, enhancing\nfocus on discriminative regions while filtering background noise. Extensive\nexperiments on three challenging fine-grained datasets demonstrate that HMDRN\nconsistently outperforms state-of-the-art methods across Conv-4 and ResNet-12\nbackbone architectures. Comprehensive ablation studies validate the\neffectiveness of each proposed component, revealing that dual-layer\nreconstruction enhances inter-class discrimination while mask-enhanced\ntransformation reduces intra-class variations. Visualization results provide\nevidence of HMDRN's superior feature reconstruction capabilities.", "AI": {"tldr": "HMDRN improves few-shot fine-grained image classification by integrating dual-layer feature reconstruction and mask-enhanced processing, outperforming existing methods.", "motivation": "Existing methods lose spatial information or fail to utilize hierarchical features, limiting performance in FS-FGIC.", "method": "HMDRN combines dual-layer feature reconstruction with mask-enhanced processing, balancing high-level semantics and mid-level details.", "result": "HMDRN outperforms state-of-the-art methods on three datasets and shows improved feature reconstruction.", "conclusion": "HMDRN enhances inter-class discrimination and reduces intra-class variations, validated by ablation studies and visualizations."}}
{"id": "2506.20404", "pdf": "https://arxiv.org/pdf/2506.20404", "abs": "https://arxiv.org/abs/2506.20404", "authors": ["Riccardo Lo Bianco", "Willem van Jaarsveld", "Remco Dijkman"], "title": "GymPN: A Library for Decision-Making in Process Management Systems", "categories": ["cs.AI"], "comment": null, "summary": "Process management systems support key decisions about the way work is\nallocated in organizations. This includes decisions on which task to perform\nnext, when to execute the task, and who to assign the task to. Suitable\nsoftware tools are required to support these decisions in a way that is optimal\nfor the organization. This paper presents a software library, called GymPN,\nthat supports optimal decision-making in business processes using Deep\nReinforcement Learning. GymPN builds on previous work that supports task\nassignment in business processes, introducing two key novelties: support for\npartial process observability and the ability to model multiple decisions in a\nbusiness process. These novel elements address fundamental limitations of\nprevious work and thus enable the representation of more realistic process\ndecisions. We evaluate the library on eight typical business process\ndecision-making problem patterns, showing that GymPN allows for easy modeling\nof the desired problems, as well as learning optimal decision policies.", "AI": {"tldr": "GymPN is a software library using Deep Reinforcement Learning to optimize business process decisions, addressing partial observability and multiple decisions, outperforming prior methods.", "motivation": "To enhance decision-making in business processes by overcoming limitations of previous work, such as lack of support for partial observability and multiple decisions.", "method": "Developed GymPN, a library leveraging Deep Reinforcement Learning, to model and optimize business process decisions, including task assignment and execution timing.", "result": "Evaluated on eight business process patterns, GymPN effectively models problems and learns optimal policies, demonstrating its practicality.", "conclusion": "GymPN advances process management by enabling realistic decision-making scenarios and outperforming existing solutions."}}
{"id": "2506.20015", "pdf": "https://arxiv.org/pdf/2506.20015", "abs": "https://arxiv.org/abs/2506.20015", "authors": ["Dengyu Wu", "Jiechen Chen", "H. Vincent Poor", "Bipin Rajendran", "Osvaldo Simeone"], "title": "Neuromorphic Wireless Split Computing with Resonate-and-Fire Neurons", "categories": ["cs.LG", "cs.IT", "cs.NE", "math.IT"], "comment": null, "summary": "Neuromorphic computing offers an energy-efficient alternative to conventional\ndeep learning accelerators for real-time time-series processing. However, many\nedge applications, such as wireless sensing and audio recognition, generate\nstreaming signals with rich spectral features that are not effectively captured\nby conventional leaky integrate-and-fire (LIF) spiking neurons. This paper\ninvestigates a wireless split computing architecture that employs\nresonate-and-fire (RF) neurons with oscillatory dynamics to process time-domain\nsignals directly, eliminating the need for costly spectral pre-processing. By\nresonating at tunable frequencies, RF neurons extract time-localized spectral\nfeatures while maintaining low spiking activity. This temporal sparsity\ntranslates into significant savings in both computation and transmission\nenergy. Assuming an OFDM-based analog wireless interface for spike\ntransmission, we present a complete system design and evaluate its performance\non audio classification and modulation classification tasks. Experimental\nresults show that the proposed RF-SNN architecture achieves comparable accuracy\nto conventional LIF-SNNs and ANNs, while substantially reducing spike rates and\ntotal energy consumption during inference and communication.", "AI": {"tldr": "The paper proposes a neuromorphic computing architecture using resonate-and-fire (RF) neurons for efficient spectral feature extraction in time-series signals, reducing energy consumption compared to traditional methods.", "motivation": "Conventional leaky integrate-and-fire (LIF) neurons fail to effectively capture spectral features in streaming signals, necessitating a more efficient approach for edge applications like wireless sensing and audio recognition.", "method": "The study introduces a wireless split computing architecture with RF neurons, which resonate at tunable frequencies to extract spectral features directly, avoiding costly pre-processing.", "result": "The RF-SNN architecture achieves accuracy comparable to LIF-SNNs and ANNs while significantly reducing spike rates and energy consumption during inference and communication.", "conclusion": "RF neurons offer a promising solution for energy-efficient, real-time processing of spectral-rich signals in edge applications."}}
{"id": "2506.20209", "pdf": "https://arxiv.org/pdf/2506.20209", "abs": "https://arxiv.org/abs/2506.20209", "authors": ["Benedetta Muscato", "Lucia Passaro", "Gizem Gezici", "Fosca Giannotti"], "title": "Perspectives in Play: A Multi-Perspective Approach for More Inclusive NLP Systems", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the realm of Natural Language Processing (NLP), common approaches for\nhandling human disagreement consist of aggregating annotators' viewpoints to\nestablish a single ground truth. However, prior studies show that disregarding\nindividual opinions can lead can lead to the side effect of underrepresenting\nminority perspectives, especially in subjective tasks, where annotators may\nsystematically disagree because of their preferences. Recognizing that labels\nreflect the diverse backgrounds, life experiences, and values of individuals,\nthis study proposes a new multi-perspective approach using soft labels to\nencourage the development of the next generation of perspective aware models,\nmore inclusive and pluralistic. We conduct an extensive analysis across diverse\nsubjective text classification tasks, including hate speech, irony, abusive\nlanguage, and stance detection, to highlight the importance of capturing human\ndisagreements, often overlooked by traditional aggregation methods. Results\nshow that the multi-perspective approach not only better approximates human\nlabel distributions, as measured by Jensen-Shannon Divergence (JSD), but also\nachieves superior classification performance (higher F1 scores), outperforming\ntraditional approaches. However, our approach exhibits lower confidence in\ntasks like irony and stance detection, likely due to the inherent subjectivity\npresent in the texts. Lastly, leveraging Explainable AI (XAI), we explore model\nuncertainty and uncover meaningful insights into model predictions.", "AI": {"tldr": "The paper proposes a multi-perspective approach using soft labels in NLP to better capture human disagreements, outperforming traditional aggregation methods in subjective tasks like hate speech and stance detection.", "motivation": "Traditional NLP methods aggregate annotators' viewpoints into a single ground truth, often underrepresenting minority perspectives. This study aims to address this by valuing diverse individual opinions.", "method": "The study introduces a multi-perspective approach using soft labels and evaluates it across subjective tasks (hate speech, irony, abusive language, stance detection) using metrics like JSD and F1 scores.", "result": "The multi-perspective approach better approximates human label distributions (lower JSD) and achieves higher F1 scores, though it shows lower confidence in highly subjective tasks like irony and stance detection.", "conclusion": "The study highlights the importance of capturing human disagreements in NLP, advocating for more inclusive models. XAI reveals insights into model uncertainty, supporting the approach's validity."}}
{"id": "2506.17983", "pdf": "https://arxiv.org/pdf/2506.17983", "abs": "https://arxiv.org/abs/2506.17983", "authors": ["Chenyue Song", "Chen Hui", "Qing Lin", "Wei Zhang", "Siqiao Li", "Haiqi Zhu", "Zhixuan Li", "Shengping Zhang", "Shaohui Liu", "Feng Jiang", "Xiang Li"], "title": "LVPNet: A Latent-variable-based Prediction-driven End-to-end Framework for Lossless Compression of Medical Images", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted to MICCAI 2025", "summary": "Autoregressive Initial Bits is a framework that integrates sub-image\nautoregression and latent variable modeling, demonstrating its advantages in\nlossless medical image compression. However, in existing methods, the image\nsegmentation process leads to an even distribution of latent variable\ninformation across each sub-image, which in turn causes posterior collapse and\ninefficient utilization of latent variables. To deal with these issues, we\npropose a prediction-based end-to-end lossless medical image compression method\nnamed LVPNet, leveraging global latent variables to predict pixel values and\nencoding predicted probabilities for lossless compression. Specifically, we\nintroduce the Global Multi-scale Sensing Module (GMSM), which extracts compact\nand informative latent representations from the entire image, effectively\ncapturing spatial dependencies within the latent space. Furthermore, to\nmitigate the information loss introduced during quantization, we propose the\nQuantization Compensation Module (QCM), which learns the distribution of\nquantization errors and refines the quantized features to compensate for\nquantization loss. Extensive experiments on challenging benchmarks demonstrate\nthat our method achieves superior compression efficiency compared to\nstate-of-the-art lossless image compression approaches, while maintaining\ncompetitive inference speed. The code is at\nhttps://github.com/scy-Jackel/LVPNet.", "AI": {"tldr": "LVPNet is a prediction-based lossless medical image compression method using global latent variables and quantization compensation to improve efficiency and avoid posterior collapse.", "motivation": "Existing methods suffer from posterior collapse and inefficient latent variable use due to uniform latent information distribution in sub-images.", "method": "Proposes LVPNet with Global Multi-scale Sensing Module (GMSM) for spatial dependency capture and Quantization Compensation Module (QCM) to refine quantized features.", "result": "Achieves superior compression efficiency on benchmarks while maintaining competitive inference speed.", "conclusion": "LVPNet outperforms state-of-the-art lossless compression methods, addressing key limitations of prior approaches."}}
{"id": "2506.20272", "pdf": "https://arxiv.org/pdf/2506.20272", "abs": "https://arxiv.org/abs/2506.20272", "authors": ["Juan Jos\u00e9 Murillo-Fuentes", "Pablo M. Olmos", "Laura Alba-Carcel\u00e9n"], "title": "Forensic Study of Paintings Through the Comparison of Fabrics", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The study of canvas fabrics in works of art is a crucial tool for\nauthentication, attribution and conservation. Traditional methods are based on\nthread density map matching, which cannot be applied when canvases do not come\nfrom contiguous positions on a roll. This paper presents a novel approach based\non deep learning to assess the similarity of textiles. We introduce an\nautomatic tool that evaluates the similarity between canvases without relying\non thread density maps. A Siamese deep learning model is designed and trained\nto compare pairs of images by exploiting the feature representations learned\nfrom the scans. In addition, a similarity estimation method is proposed,\naggregating predictions from multiple pairs of cloth samples to provide a\nrobust similarity score. Our approach is applied to canvases from the Museo\nNacional del Prado, corroborating the hypothesis that plain weave canvases,\nwidely used in painting, can be effectively compared even when their thread\ndensities are similar. The results demonstrate the feasibility and accuracy of\nthe proposed method, opening new avenues for the analysis of masterpieces.", "AI": {"tldr": "A deep learning-based method for comparing canvas fabrics in art, bypassing traditional thread density maps, is introduced and validated on Prado Museum canvases.", "motivation": "Traditional thread density map matching fails for non-contiguous canvases, necessitating a new approach for authentication and conservation.", "method": "A Siamese deep learning model compares canvas images, using feature representations and aggregated similarity scores from multiple pairs.", "result": "The method effectively compares plain weave canvases with similar thread densities, proving feasible and accurate.", "conclusion": "This approach opens new possibilities for analyzing masterpieces, enhancing authentication and conservation efforts."}}
{"id": "2506.20486", "pdf": "https://arxiv.org/pdf/2506.20486", "abs": "https://arxiv.org/abs/2506.20486", "authors": ["Salvatore Milite", "Giulio Caravagna", "Andrea Sottoriva"], "title": "Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization", "categories": ["cs.AI"], "comment": null, "summary": "Neural Cellular Automata (NCAs) are a promising new approach to model\nself-organizing processes, with potential applications in life science.\nHowever, their deterministic nature limits their ability to capture the\nstochasticity of real-world biological and physical systems.\n  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework\nincorporating the idea of mixture models into the NCA paradigm. By combining\nprobabilistic rule assignments with intrinsic noise, MNCAs can model diverse\nlocal behaviors and reproduce the stochastic dynamics observed in biological\nprocesses.\n  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic\nsimulations of tissue growth and differentiation, (2) image morphogenesis\nrobustness, and (3) microscopy image segmentation. Results show that MNCAs\nachieve superior robustness to perturbations, better recapitulate real\nbiological growth patterns, and provide interpretable rule segmentation. These\nfindings position MNCAs as a promising tool for modeling stochastic dynamical\nsystems and studying self-growth processes.", "AI": {"tldr": "The paper introduces Mixture of Neural Cellular Automata (MNCA), a framework combining probabilistic rules and noise to model stochastic biological processes, outperforming deterministic NCAs in robustness and realism.", "motivation": "Deterministic Neural Cellular Automata (NCAs) lack stochasticity, limiting their ability to model real-world biological systems.", "method": "Proposes MNCA, integrating mixture models and intrinsic noise into NCAs to capture stochastic dynamics.", "result": "MNCAs show superior robustness, realistic biological growth patterns, and interpretable rule segmentation in tissue growth, image morphogenesis, and microscopy tasks.", "conclusion": "MNCAs are a promising tool for modeling stochastic dynamical systems and self-growth processes."}}
{"id": "2506.20016", "pdf": "https://arxiv.org/pdf/2506.20016", "abs": "https://arxiv.org/abs/2506.20016", "authors": ["Shanika Iroshi Nanayakkara", "Shiva Raj Pokhrel"], "title": "New Insights on Unfolding and Fine-tuning Quantum Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 9 figures, 7 Tables, Submitted to IEEE/ACM journal 2025", "summary": "Client heterogeneity poses significant challenges to the performance of\nQuantum Federated Learning (QFL). To overcome these limitations, we propose a\nnew approach leveraging deep unfolding, which enables clients to autonomously\noptimize hyperparameters, such as learning rates and regularization factors,\nbased on their specific training behavior. This dynamic adaptation mitigates\noverfitting and ensures robust optimization in highly heterogeneous\nenvironments where standard aggregation methods often fail. Our framework\nachieves approximately 90% accuracy, significantly outperforming traditional\nmethods, which typically yield around 55% accuracy, as demonstrated through\nreal-time training on IBM quantum hardware and Qiskit Aer simulators. By\ndeveloping self adaptive fine tuning, the proposed method proves particularly\neffective in critical applications such as gene expression analysis and cancer\ndetection, enhancing diagnostic precision and predictive modeling within\nquantum systems. Our results are attributed to convergence-aware, learnable\noptimization steps intrinsic to the deep unfolded framework, which maintains\nthe generalization. Hence, this study addresses the core limitations of\nconventional QFL, streamlining its applicability to any complex challenges such\nas healthcare and genomic research.", "AI": {"tldr": "A novel deep unfolding-based approach in Quantum Federated Learning (QFL) autonomously optimizes hyperparameters to address client heterogeneity, achieving ~90% accuracy, outperforming traditional methods (~55%).", "motivation": "Client heterogeneity in QFL leads to performance issues, requiring a solution to dynamically adapt hyperparameters for robust optimization.", "method": "Leverages deep unfolding for autonomous hyperparameter optimization (e.g., learning rates, regularization) based on client-specific training behavior.", "result": "Achieves ~90% accuracy on IBM quantum hardware and Qiskit Aer simulators, significantly improving over traditional methods.", "conclusion": "The framework enhances QFL applicability in critical areas like healthcare and genomics by mitigating overfitting and ensuring robust optimization."}}
{"id": "2506.20241", "pdf": "https://arxiv.org/pdf/2506.20241", "abs": "https://arxiv.org/abs/2506.20241", "authors": ["Yubo Dong", "Hehe Fan"], "title": "Enhancing Large Language Models through Structured Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint. Under review", "summary": "Recent Large Language Models (LLMs) have significantly advanced natural\nlanguage processing and automated decision-making. However, these models still\nencounter difficulties when performing complex reasoning tasks involving\nlogical deduction and systematic planning, primarily due to their reliance on\nimplicit statistical relationships without structured knowledge\nrepresentation.Inspired by cognitive science and neurosymbolic AI, we introduce\na novel approach to enhance LLMs through explicit structured reasoning. First,\nwe convert unstructured data into structured formats by explicitly annotating\nreasoning steps. We then employ this structured dataset to train LLMs through\nSupervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning\ncapabilities of LLMs using Group Relative Policy Optimization (GRPO),\nincorporating two innovative algorithms--MAX-Flow and Longest Common\nSubsequence (LCS)--which notably improve reasoning effectiveness and reduce\ncomputational complexity. Experimental results from fine-tuning a\nDeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust\nperformance across various scenarios, and improved compatibility with\noptimization techniques, validating the efficacy of structured reasoning\nintegration in LLMs.", "AI": {"tldr": "The paper introduces a structured reasoning approach to enhance LLMs, addressing their limitations in complex reasoning tasks by converting unstructured data into structured formats and using novel algorithms for training.", "motivation": "LLMs struggle with complex reasoning due to reliance on implicit statistical relationships, lacking structured knowledge representation.", "method": "Convert unstructured data to structured formats, use Supervised Fine-Tuning (SFT), and enhance reasoning with Group Relative Policy Optimization (GRPO) and algorithms (MAX-Flow, LCS).", "result": "Improved reasoning effectiveness, reduced computational complexity, and robust performance across scenarios, validated on a DeepSeek-R1-Distill-Qwen-1.5B model.", "conclusion": "Structured reasoning integration significantly enhances LLMs' performance in complex tasks."}}
{"id": "2408.09554", "pdf": "https://arxiv.org/pdf/2408.09554", "abs": "https://arxiv.org/abs/2408.09554", "authors": ["Yi Kan Wang", "Ludmila Tylditatova", "Jeremy D. Kunz", "Gerard Oakley", "Bonnie Kar Bo Chow", "Ran A. Godrich", "Matthew C. H. Lee", "Hamed Aghdam", "Alican Bozkurt", "Michal Zelechowski", "Chad Vanderbilt", "Christopher Kanan", "Juan A. Retamero", "Peter Hamilton", "Razik Yousfi", "Thomas J. Fuchs", "David S. Klimstra", "Siqi Liu"], "title": "Screen Them All: High-Throughput Pan-Cancer Genetic and Phenotypic Biomarker Screening from H&E Whole Slide Images", "categories": ["q-bio.QM", "cs.CV", "eess.IV"], "comment": null, "summary": "Molecular assays are standard of care for detecting genomic alterations in\ncancer prognosis and therapy selection but are costly, tissue-destructive and\ntime-consuming. Artificial intelligence (AI) applied to routine hematoxylin and\neosin (H&E)-stained whole slide images (WSIs) offers a fast and economical\nalternative for screening molecular biomarkers. We introduce OmniScreen, a\nhigh-throughput AI-based system leveraging Virchow2 embeddings extracted from\n60,529 cancer patients with paired 489-gene MSK-IMPACT targeted biomarker panel\nand WSIs. Unlike conventional approaches that train separate models for each\nbiomarker, OmniScreen employs a unified model to predict a broad range of\nclinically relevant biomarkers across cancers, including low-prevalence targets\nimpractical to model individually. OmniScreen reliably identifies therapeutic\ntargets and shared phenotypic features across common and rare tumors. We\ninvestigate the biomarker prediction probabilities and accuracies of OmniScreen\nin relation to tumor area, cohort size, histologic subtype alignment, and\npathway-level morphological patterns. These findings underscore the potential\nof OmniScreen for routine clinical screening.", "AI": {"tldr": "OmniScreen is an AI-based system using H&E-stained WSIs to predict a wide range of cancer biomarkers, offering a cost-effective and efficient alternative to molecular assays.", "motivation": "Molecular assays for cancer biomarker detection are expensive, destructive, and slow. AI applied to H&E-stained WSIs provides a faster, cheaper solution.", "method": "OmniScreen uses Virchow2 embeddings from 60,529 patients with paired MSK-IMPACT panel and WSIs, employing a unified model to predict multiple biomarkers.", "result": "OmniScreen reliably predicts therapeutic targets and phenotypic features, even for low-prevalence biomarkers, with accuracy influenced by tumor area, cohort size, and histologic alignment.", "conclusion": "OmniScreen shows promise for clinical screening, offering a scalable and practical alternative to traditional molecular assays."}}
{"id": "2506.20279", "pdf": "https://arxiv.org/pdf/2506.20279", "abs": "https://arxiv.org/abs/2506.20279", "authors": ["Changliang Xia", "Chengyou Jia", "Zhuohang Dang", "Minnan Luo"], "title": "From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "Dense prediction tasks hold significant importance of computer vision, aiming\nto learn pixel-wise annotated label for an input image. Despite advances in\nthis field, existing methods primarily focus on idealized conditions, with\nlimited generalization to real-world scenarios and facing the challenging\nscarcity of real-world data. To systematically study this problem, we first\nintroduce DenseWorld, a benchmark spanning a broad set of 25 dense prediction\ntasks that correspond to urgent real-world applications, featuring unified\nevaluation across tasks. Then, we propose DenseDiT, which maximally exploits\ngenerative models' visual priors to perform diverse real-world dense prediction\ntasks through a unified strategy. DenseDiT combines a parameter-reuse mechanism\nand two lightweight branches that adaptively integrate multi-scale context,\nworking with less than 0.1% additional parameters. Evaluations on DenseWorld\nreveal significant performance drops in existing general and specialized\nbaselines, highlighting their limited real-world generalization. In contrast,\nDenseDiT achieves superior results using less than 0.01% training data of\nbaselines, underscoring its practical value for real-world deployment. Our\ndata, and checkpoints and codes are available at\nhttps://xcltql666.github.io/DenseDiTProj", "AI": {"tldr": "The paper introduces DenseWorld, a benchmark for 25 dense prediction tasks, and proposes DenseDiT, a method leveraging generative models for real-world applications with minimal additional parameters.", "motivation": "Existing dense prediction methods lack generalization to real-world scenarios and face data scarcity. The study aims to address these limitations.", "method": "DenseDiT uses generative models' visual priors, a parameter-reuse mechanism, and lightweight branches for multi-scale context integration.", "result": "DenseDiT outperforms baselines with less than 0.01% training data, showing superior real-world generalization.", "conclusion": "DenseDiT offers practical value for real-world deployment, with data, checkpoints, and code made available."}}
{"id": "2506.20504", "pdf": "https://arxiv.org/pdf/2506.20504", "abs": "https://arxiv.org/abs/2506.20504", "authors": ["Konstantin Demin", "Taylor Webb", "Eric Elmoznino", "Hakwan Lau"], "title": "Engineering Sentience", "categories": ["cs.AI", "q-bio.NC"], "comment": null, "summary": "We spell out a definition of sentience that may be useful for designing and\nbuilding it in machines. We propose that for sentience to be meaningful for AI,\nit must be fleshed out in functional, computational terms, in enough detail to\nallow for implementation. Yet, this notion of sentience must also reflect\nsomething essentially 'subjective', beyond just having the general capacity to\nencode perceptual content. For this specific functional notion of sentience to\noccur, we propose that certain sensory signals need to be both assertoric\n(persistent) and qualitative. To illustrate the definition in more concrete\nterms, we sketch out some ways for potential implementation, given current\ntechnology. Understanding what it takes for artificial agents to be\nfunctionally sentient can also help us avoid creating them inadvertently, or at\nleast, realize that we have created them in a timely manner.", "AI": {"tldr": "The paper defines sentience for AI in functional, computational terms, emphasizing assertoric and qualitative sensory signals for meaningful implementation.", "motivation": "To provide a clear, implementable definition of sentience for AI, ensuring it captures subjective experience beyond mere perceptual encoding.", "method": "Proposes a functional notion of sentience requiring persistent (assertoric) and qualitative sensory signals, with potential implementation sketches.", "result": "A framework for designing sentient AI, aiding in intentional creation and timely recognition of sentient artificial agents.", "conclusion": "Defining functional sentience helps avoid inadvertent creation of sentient AI and guides ethical implementation."}}
{"id": "2506.20023", "pdf": "https://arxiv.org/pdf/2506.20023", "abs": "https://arxiv.org/abs/2506.20023", "authors": ["Ryan Hildebrant", "Rahul Bhope", "Sharad Mehrotra", "Christopher Tull", "Nalini Venkatasubramanian"], "title": "DIM-SUM: Dynamic IMputation for Smart Utility Management", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "Time series imputation models have traditionally been developed using\ncomplete datasets with artificial masking patterns to simulate missing values.\nHowever, in real-world infrastructure monitoring, practitioners often encounter\ndatasets where large amounts of data are missing and follow complex,\nheterogeneous patterns. We introduce DIM-SUM, a preprocessing framework for\ntraining robust imputation models that bridges the gap between artificially\nmasked training data and real missing patterns. DIM-SUM combines pattern\nclustering and adaptive masking strategies with theoretical learning guarantees\nto handle diverse missing patterns actually observed in the data. Through\nextensive experiments on over 2 billion readings from California water\ndistricts, electricity datasets, and benchmarks, we demonstrate that DIM-SUM\noutperforms traditional methods by reaching similar accuracy with lower\nprocessing time and significantly less training data. When compared against a\nlarge pre-trained model, DIM-SUM averages 2x higher accuracy with significantly\nless inference time.", "AI": {"tldr": "DIM-SUM is a preprocessing framework for training robust time series imputation models, addressing real-world missing data patterns and outperforming traditional methods in accuracy and efficiency.", "motivation": "Real-world datasets often have complex, heterogeneous missing patterns, unlike artificially masked training data, necessitating a robust solution.", "method": "DIM-SUM combines pattern clustering and adaptive masking strategies with theoretical learning guarantees to handle diverse missing patterns.", "result": "DIM-SUM outperforms traditional methods in accuracy and efficiency, achieving 2x higher accuracy than a large pre-trained model with less inference time.", "conclusion": "DIM-SUM effectively bridges the gap between artificial and real missing data patterns, offering a practical solution for infrastructure monitoring."}}
{"id": "2506.20269", "pdf": "https://arxiv.org/pdf/2506.20269", "abs": "https://arxiv.org/abs/2506.20269", "authors": ["Kai-Robin Lange", "Tobias Schmidt", "Matthias Reccius", "Henrik M\u00fcller", "Michael Roos", "Carsten Jentsch"], "title": "Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "comment": "14 pages, 1 figure", "summary": "With rapidly evolving media narratives, it has become increasingly critical\nto not just extract narratives from a given corpus but rather investigate, how\nthey develop over time. While popular narrative extraction methods such as\nLarge Language Models do well in capturing typical narrative elements or even\nthe complex structure of a narrative, applying them to an entire corpus comes\nwith obstacles, such as a high financial or computational cost. We propose a\ncombination of the language understanding capabilities of Large Language Models\nwith the large scale applicability of topic models to dynamically model\nnarrative shifts across time using the Narrative Policy Framework. We apply a\ntopic model and a corresponding change point detection method to find changes\nthat concern a specific topic of interest. Using this model, we filter our\ncorpus for documents that are particularly representative of that change and\nfeed them into a Large Language Model that interprets the change that happened\nin an automated fashion and distinguishes between content and narrative shifts.\nWe employ our pipeline on a corpus of The Wall Street Journal news paper\narticles from 2009 to 2023. Our findings indicate that a Large Language Model\ncan efficiently extract a narrative shift if one exists at a given point in\ntime, but does not perform as well when having to decide whether a shift in\ncontent or a narrative shift took place.", "AI": {"tldr": "The paper proposes combining Large Language Models (LLMs) and topic models to dynamically track narrative shifts over time, addressing the high costs of using LLMs alone.", "motivation": "To efficiently investigate how media narratives evolve over time, overcoming the financial and computational limitations of using LLMs for entire corpora.", "method": "A hybrid approach: topic models identify changes in topics, and LLMs analyze filtered documents to detect narrative shifts. Applied to Wall Street Journal articles (2009-2023).", "result": "LLMs effectively detect narrative shifts when they exist but struggle to differentiate between content and narrative shifts.", "conclusion": "The hybrid method offers a scalable solution for tracking narrative evolution, though further refinement is needed for distinguishing shift types."}}
{"id": "2412.01493", "pdf": "https://arxiv.org/pdf/2412.01493", "abs": "https://arxiv.org/abs/2412.01493", "authors": ["Qirui Yang", "Peng-Tao Jiang", "Hao Zhang", "Jinwei Chen", "Bo Li", "Huanjing Yue", "Jingyu Yang"], "title": "Learning Adaptive Lighting via Channel-Aware Guidance", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Learning lighting adaptation is a crucial step in achieving good visual\nperception and supporting downstream vision tasks. Current research often\naddresses individual light-related challenges, such as high dynamic range\nimaging and exposure correction, in isolation. However, we identify shared\nfundamental properties across these tasks: i) different color channels have\ndifferent light properties, and ii) the channel differences reflected in the\nspatial and frequency domains are different. Leveraging these insights, we\nintroduce the channel-aware Learning Adaptive Lighting Network (LALNet), a\nmulti-task framework designed to handle multiple light-related tasks\nefficiently. Specifically, LALNet incorporates color-separated features that\nhighlight the unique light properties of each color channel, integrated with\ntraditional color-mixed features by Light Guided Attention (LGA). The LGA\nutilizes color-separated features to guide color-mixed features focusing on\nchannel differences and ensuring visual consistency across all channels.\nAdditionally, LALNet employs dual domain channel modulation for generating\ncolor-separated features and a mixed channel modulation and light state space\nmodule for producing color-mixed features. Extensive experiments on four\nrepresentative light-related tasks demonstrate that LALNet significantly\noutperforms state-of-the-art methods on benchmark tests and requires fewer\ncomputational resources. We provide an anonymous online demo at\nhttps://xxxxxx2025.github.io/LALNet/.", "AI": {"tldr": "LALNet is a multi-task framework for lighting adaptation, leveraging color-separated and mixed features to outperform state-of-the-art methods efficiently.", "motivation": "Addressing shared fundamental properties in light-related tasks like high dynamic range imaging and exposure correction, which are often tackled in isolation.", "method": "Uses channel-aware features (color-separated and mixed) guided by Light Guided Attention (LGA), with dual domain channel modulation and mixed channel modulation.", "result": "Significantly outperforms state-of-the-art methods on four light-related tasks with fewer computational resources.", "conclusion": "LALNet effectively handles multiple light-related tasks by leveraging channel differences and visual consistency, demonstrating superior performance and efficiency."}}
{"id": "2506.20294", "pdf": "https://arxiv.org/pdf/2506.20294", "abs": "https://arxiv.org/abs/2506.20294", "authors": ["Shunqi Mao", "Wei Guo", "Chaoyi Zhang", "Weidong Cai"], "title": "Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations", "categories": ["cs.CV"], "comment": "10 pages, 3 figures, 2 tables", "summary": "Diffusion models have shown strong performance in conditional generation by\nprogressively denoising Gaussian noise toward a target data distribution. This\ndenoising process can be interpreted as a form of hill climbing in a learned\nlatent space, where the model iteratively refines the sample toward regions of\nhigher probability. However, diffusion models often converge to local optima\nthat are locally visually coherent yet globally inconsistent or conditionally\nmisaligned, due to latent space complexity and suboptimal initialization. Prior\nefforts attempted to address this by strengthening guidance signals or\nmanipulating the initial noise distribution. We introduce Controlled Random\nZigzag Sampling (Ctrl-Z Sampling), a novel sampling strategy designed to detect\nand escape such local maxima during conditional generation. The method first\nidentifies potential local maxima using a reward model. Upon detection, it\ninjects noise and reverts to a previous, noisier state to escape the current\noptimization plateau. The reward model then evaluates candidate trajectories,\naccepting only those that offer improvement, while progressively deeper retreat\nenables stronger escapes when nearby alternatives fail. This controlled random\nzigzag process allows dynamic alternation between forward refinement and\nbackward exploration, enhancing both alignment and visual quality in the\ngenerated outputs. The proposed Ctrl-Z Sampling is model-agnostic and\ncompatible with existing diffusion frameworks. Experimental results show that\nCtrl-Z Sampling substantially improves generation quality with only around 7.6X\nincrease in function evaluations.", "AI": {"tldr": "Ctrl-Z Sampling is a novel method to improve conditional generation in diffusion models by dynamically escaping local optima through controlled noise injection and backtracking.", "motivation": "Diffusion models often converge to local optima, leading to globally inconsistent or misaligned outputs. Existing solutions focus on guidance signals or noise manipulation, but Ctrl-Z Sampling aims to escape these optima directly.", "method": "Ctrl-Z Sampling identifies local maxima using a reward model, injects noise to revert to a noisier state, and evaluates trajectories for improvement. It alternates between refinement and exploration.", "result": "The method improves generation quality with a 7.6X increase in function evaluations, enhancing alignment and visual quality.", "conclusion": "Ctrl-Z Sampling is a model-agnostic, effective strategy for escaping local optima in diffusion models, compatible with existing frameworks."}}
{"id": "2506.20531", "pdf": "https://arxiv.org/pdf/2506.20531", "abs": "https://arxiv.org/abs/2506.20531", "authors": ["Wenbin Gan", "Minh-Son Dao", "Koji Zettsu"], "title": "Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios", "categories": ["cs.AI", "cs.CY"], "comment": "12 pages, 10 figures, under-review conference", "summary": "Driving in safety-critical scenarios requires quick, context-aware\ndecision-making grounded in both situational understanding and experiential\nreasoning. Large Language Models (LLMs), with their powerful general-purpose\nreasoning capabilities, offer a promising foundation for such decision-making.\nHowever, their direct application to autonomous driving remains limited due to\nchallenges in domain adaptation, contextual grounding, and the lack of\nexperiential knowledge needed to make reliable and interpretable decisions in\ndynamic, high-risk environments. To address this gap, this paper presents a\nCase-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for\nevasive maneuver decision-making in complex risk scenarios. Our approach\nintegrates semantic scene understanding from dashcam video inputs with the\nretrieval of relevant past driving cases, enabling LLMs to generate maneuver\nrecommendations that are both context-sensitive and human-aligned. Experiments\nacross multiple open-source LLMs show that our framework improves decision\naccuracy, justification quality, and alignment with human expert behavior.\nRisk-aware prompting strategies further enhance performance across diverse risk\ntypes, while similarity-based case retrieval consistently outperforms random\nsampling in guiding in-context learning. Case studies further demonstrate the\nframework's robustness in challenging real-world conditions, underscoring its\npotential as an adaptive and trustworthy decision-support tool for intelligent\ndriving systems.", "AI": {"tldr": "The paper introduces a CBR-LLM framework to enhance evasive maneuver decision-making in autonomous driving by combining LLMs with case-based reasoning, improving accuracy and human alignment.", "motivation": "Addressing the limitations of LLMs in autonomous driving, such as domain adaptation and lack of experiential knowledge, to enable reliable and interpretable decisions in high-risk scenarios.", "method": "Integrates semantic scene understanding from dashcam videos with retrieval of past driving cases, using risk-aware prompting and similarity-based case retrieval.", "result": "Improves decision accuracy, justification quality, and alignment with human expert behavior across multiple LLMs.", "conclusion": "The CBR-LLM framework shows promise as an adaptive and trustworthy decision-support tool for intelligent driving systems."}}
{"id": "2506.20024", "pdf": "https://arxiv.org/pdf/2506.20024", "abs": "https://arxiv.org/abs/2506.20024", "authors": ["Salva R\u00fchling Cachay", "Miika Aittala", "Karsten Kreis", "Noah Brenowitz", "Arash Vahdat", "Morteza Mardani", "Rose Yu"], "title": "Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "stat.ML"], "comment": null, "summary": "Diffusion models are a powerful tool for probabilistic forecasting, yet most\napplications in high-dimensional chaotic systems predict future snapshots\none-by-one. This common approach struggles to model complex temporal\ndependencies and fails to explicitly account for the progressive growth of\nuncertainty inherent to such systems. While rolling diffusion frameworks, which\napply increasing noise to forecasts at longer lead times, have been proposed to\naddress this, their integration with state-of-the-art, high-fidelity diffusion\ntechniques remains a significant challenge. We tackle this problem by\nintroducing Elucidated Rolling Diffusion Models (ERDM), the first framework to\nsuccessfully unify a rolling forecast structure with the principled, performant\ndesign of Elucidated Diffusion Models (EDM). To do this, we adapt the core EDM\ncomponents-its noise schedule, network preconditioning, and Heun sampler-to the\nrolling forecast setting. The success of this integration is driven by three\nkey contributions: (i) a novel loss weighting scheme that focuses model\ncapacity on the mid-range forecast horizons where determinism gives way to\nstochasticity; (ii) an efficient initialization strategy using a pre-trained\nEDM for the initial window; and (iii) a bespoke hybrid sequence architecture\nfor robust spatiotemporal feature extraction under progressive denoising. On 2D\nNavier-Stokes simulations and ERA5 global weather forecasting at 1.5^\\circ\nresolution, ERDM consistently outperforms key diffusion-based baselines,\nincluding conditional autoregressive EDM. ERDM offers a flexible and powerful\ngeneral framework for tackling diffusion-based sequence generation problems\nwhere modeling escalating uncertainty is paramount. Code is available at:\nhttps://github.com/salvaRC/erdm", "AI": {"tldr": "ERDM integrates rolling forecasts with Elucidated Diffusion Models to improve probabilistic forecasting in chaotic systems by addressing temporal dependencies and uncertainty growth.", "motivation": "Existing diffusion models struggle with complex temporal dependencies and uncertainty growth in high-dimensional chaotic systems.", "method": "ERDM adapts Elucidated Diffusion Models (EDM) components\u2014noise schedule, network preconditioning, and Heun sampler\u2014to rolling forecasts, with a novel loss weighting, efficient initialization, and hybrid sequence architecture.", "result": "ERDM outperforms baselines in 2D Navier-Stokes simulations and ERA5 weather forecasting.", "conclusion": "ERDM provides a flexible framework for diffusion-based sequence generation, especially where escalating uncertainty is critical."}}
{"id": "2506.20331", "pdf": "https://arxiv.org/pdf/2506.20331", "abs": "https://arxiv.org/abs/2506.20331", "authors": ["Rian Touchent", "Nathan Godey", "Eric de la Clergerie"], "title": "Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content", "categories": ["cs.CL", "cs.LG"], "comment": "Dataset link: https://hf.co/datasets/almanach/Biomed-Enriched", "summary": "We introduce Biomed-Enriched, a biomedical text dataset constructed from\nPubMed via a two-stage annotation process. In the first stage, a large language\nmodel annotates 400K paragraphs from PubMed scientific articles, assigning\nscores for their type (review, study, clinical case, other), domain (clinical,\nbiomedical, other), and educational quality. The educational quality score\n(rated 1 to 5) estimates how useful a paragraph is for college-level learning.\nThese annotations are then used to fine-tune a small language model, which\npropagates the labels across the full PMC-OA corpus. The resulting metadata\nallows us to extract refined subsets, including 2M clinical case paragraphs\nwith over 450K high-quality ones from articles with commercial-use licenses,\nand to construct several variants via quality filtering and domain upsampling.\nClinical text is typically difficult to access due to privacy constraints, as\nhospital records cannot be publicly shared. Hence, our dataset provides an\nalternative large-scale, openly available collection of clinical cases from\nPubMed, making it a valuable resource for biomedical and clinical NLP.\nPreliminary continual-pretraining experiments with OLMo2 suggest these curated\nsubsets enable targeted improvements, with clinical upsampling boosting\nperformance by ~5% on MMLU ProfMed and educational quality filtering improving\nMedQA and MedMCQA by ~1%. Combinations of these techniques led to faster\nconvergence, reaching same performance with a third of training tokens,\nindicating potential for more efficient and effective biomedical pretraining\nstrategies.", "AI": {"tldr": "Biomed-Enriched is a biomedical text dataset from PubMed, annotated for type, domain, and educational quality, enabling refined subsets for NLP tasks.", "motivation": "Clinical text is hard to access due to privacy; this dataset offers an open alternative for biomedical NLP.", "method": "Two-stage annotation: large model labels 400K paragraphs, fine-tunes a small model to propagate labels across PMC-OA.", "result": "Created 2M clinical case paragraphs, with 450K high-quality ones. Pretraining experiments show ~5% boost on MMLU ProfMed and ~1% on MedQA/MedMCQA.", "conclusion": "The dataset supports efficient biomedical pretraining, with quality filtering and domain upsampling improving performance and convergence."}}
{"id": "2506.20302", "pdf": "https://arxiv.org/pdf/2506.20302", "abs": "https://arxiv.org/abs/2506.20302", "authors": ["Abbas Anwar", "Mohammad Shullar", "Ali Arshad Nasir", "Mudassir Masood", "Saeed Anwar"], "title": "TDiR: Transformer based Diffusion for Image Restoration Tasks", "categories": ["cs.CV"], "comment": null, "summary": "Images captured in challenging environments often experience various forms of\ndegradation, including noise, color cast, blur, and light scattering. These\neffects significantly reduce image quality, hindering their applicability in\ndownstream tasks such as object detection, mapping, and classification. Our\ntransformer-based diffusion model was developed to address image restoration\ntasks, aiming to improve the quality of degraded images. This model was\nevaluated against existing deep learning methodologies across multiple quality\nmetrics for underwater image enhancement, denoising, and deraining on publicly\navailable datasets. Our findings demonstrate that the diffusion model, combined\nwith transformers, surpasses current methods in performance. The results of our\nmodel highlight the efficacy of diffusion models and transformers in improving\nthe quality of degraded images, consequently expanding their utility in\ndownstream tasks that require high-fidelity visual data.", "AI": {"tldr": "A transformer-based diffusion model outperforms existing methods in restoring degraded images, enhancing their quality for downstream tasks.", "motivation": "Degraded images (e.g., from noise, color cast, blur) hinder performance in tasks like object detection and classification, necessitating effective restoration methods.", "method": "Developed a transformer-based diffusion model for image restoration, tested on underwater image enhancement, denoising, and deraining using public datasets.", "result": "The model surpasses existing deep learning methods in performance across multiple quality metrics.", "conclusion": "Diffusion models with transformers effectively improve degraded image quality, enhancing their utility in high-fidelity visual tasks."}}
{"id": "2506.20598", "pdf": "https://arxiv.org/pdf/2506.20598", "abs": "https://arxiv.org/abs/2506.20598", "authors": ["Alexander D. Kalian", "Jaewook Lee", "Stefan P. Johannesson", "Lennart Otte", "Christer Hogstrand", "Miao Guo"], "title": "Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "The global demand for sustainable protein sources has accelerated the need\nfor intelligent tools that can rapidly process and synthesise domain-specific\nscientific knowledge. In this study, we present a proof-of-concept multi-agent\nArtificial Intelligence (AI) framework designed to support sustainable protein\nproduction research, with an initial focus on microbial protein sources. Our\nRetrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based\nLLM agents: (1) a literature search agent that retrieves relevant scientific\nliterature on microbial protein production for a specified microbial strain,\nand (2) an information extraction agent that processes the retrieved content to\nextract relevant biological and chemical information. Two parallel\nmethodologies, fine-tuning and prompt engineering, were explored for agent\noptimisation. Both methods demonstrated effectiveness at improving the\nperformance of the information extraction agent in terms of transformer-based\ncosine similarity scores between obtained and ideal outputs. Mean cosine\nsimilarity scores were increased by up to 25%, while universally reaching mean\nscores of $\\geq 0.89$ against ideal output text. Fine-tuning overall improved\nthe mean scores to a greater extent (consistently of $\\geq 0.94$) compared to\nprompt engineering, although lower statistical uncertainties were observed with\nthe latter approach. A user interface was developed and published for enabling\nthe use of the multi-agent AI system, alongside preliminary exploration of\nadditional chemical safety-based search capabilities", "AI": {"tldr": "A multi-agent AI framework for sustainable protein research, focusing on microbial sources, uses RAG with GPT-based agents for literature search and information extraction. Fine-tuning and prompt engineering improved performance, with fine-tuning yielding higher cosine similarity scores.", "motivation": "Address the global demand for sustainable protein by leveraging AI to process and synthesize scientific knowledge efficiently.", "method": "Two GPT-based LLM agents: one for literature search and another for information extraction. Optimized via fine-tuning and prompt engineering.", "result": "Fine-tuning improved mean cosine similarity scores to \u22650.94, outperforming prompt engineering (\u22650.89). Lower uncertainties with prompt engineering.", "conclusion": "The framework effectively supports sustainable protein research, with fine-tuning offering superior performance, and a user interface was developed for accessibility."}}
{"id": "2506.20025", "pdf": "https://arxiv.org/pdf/2506.20025", "abs": "https://arxiv.org/abs/2506.20025", "authors": ["Nathan Stromberg", "Christos Thrampoulidis", "Lalitha Sankar"], "title": "Thumb on the Scale: Optimal Loss Weighting in Last Layer Retraining", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "While machine learning models become more capable in discriminative tasks at\nscale, their ability to overcome biases introduced by training data has come\nunder increasing scrutiny. Previous results suggest that there are two extremes\nof parameterization with very different behaviors: the population\n(underparameterized) setting where loss weighting is optimal and the separable\noverparameterized setting where loss weighting is ineffective at ensuring equal\nperformance across classes. This work explores the regime of last layer\nretraining (LLR) in which the unseen limited (retraining) data is frequently\ninseparable and the model proportionately sized, falling between the two\naforementioned extremes. We show, in theory and practice, that loss weighting\nis still effective in this regime, but that these weights \\emph{must} take into\naccount the relative overparameterization of the model.", "AI": {"tldr": "Loss weighting remains effective in last layer retraining (LLR) for models between underparameterized and overparameterized extremes, but weights must account for model overparameterization.", "motivation": "Addressing biases in machine learning models, especially in the intermediate regime of LLR where data is inseparable and models are proportionately sized.", "method": "Theoretical and practical exploration of loss weighting in the LLR regime, considering model overparameterization.", "result": "Loss weighting is effective in LLR, but its success depends on accounting for relative overparameterization.", "conclusion": "Properly adjusted loss weights can mitigate biases in intermediate model regimes, bridging gaps between underparameterized and overparameterized extremes."}}
{"id": "2506.20409", "pdf": "https://arxiv.org/pdf/2506.20409", "abs": "https://arxiv.org/abs/2506.20409", "authors": ["Ekaterina Taktasheva", "Jeff Dalton"], "title": "TAPS: Tool-Augmented Personalisation via Structured Tagging", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in tool-augmented large language models have enabled them\nto interact with external tools, enhancing their ability to perform complex\nuser tasks. However, existing approaches overlook the role of personalisation\nin guiding tool use. This work investigates how user preferences can be\neffectively integrated into goal-oriented dialogue agents. Through extensive\nanalysis, we identify key weaknesses in the ability of LLMs to personalise tool\nuse. To this end, we introduce \\name, a novel solution that enhances\npersonalised tool use by leveraging a structured tagging tool and an\nuncertainty-based tool detector. TAPS significantly improves the ability of\nLLMs to incorporate user preferences, achieving the new state-of-the-art for\nopen source models on the NLSI task.", "AI": {"tldr": "The paper introduces TAPS, a solution to enhance personalized tool use in LLMs by leveraging structured tagging and uncertainty-based detection, achieving state-of-the-art results.", "motivation": "Existing approaches neglect personalization in tool-augmented LLMs, limiting their ability to align with user preferences in goal-oriented tasks.", "method": "TAPS uses a structured tagging tool and an uncertainty-based tool detector to integrate user preferences into LLMs.", "result": "TAPS significantly improves personalized tool use, setting a new state-of-the-art for open-source models on the NLSI task.", "conclusion": "Personalization in tool-augmented LLMs is crucial, and TAPS effectively addresses this gap, enhancing performance."}}
{"id": "2506.20306", "pdf": "https://arxiv.org/pdf/2506.20306", "abs": "https://arxiv.org/abs/2506.20306", "authors": ["Yaxi Chen", "Simin Ni", "Shaheer U. Saeed", "Aleksandra Ivanova", "Rikin Hargunani", "Jie Huang", "Chaozong Liu", "Yipeng Hu"], "title": "Radiomic fingerprints for knee MR images assessment", "categories": ["cs.CV"], "comment": null, "summary": "Accurate interpretation of knee MRI scans relies on expert clinical judgment,\noften with high variability and limited scalability. Existing radiomic\napproaches use a fixed set of radiomic features (the signature), selected at\nthe population level and applied uniformly to all patients. While\ninterpretable, these signatures are often too constrained to represent\nindividual pathological variations. As a result, conventional radiomic-based\napproaches are found to be limited in performance, compared with recent\nend-to-end deep learning (DL) alternatives without using interpretable radiomic\nfeatures. We argue that the individual-agnostic nature in current radiomic\nselection is not central to its intepretability, but is responsible for the\npoor generalization in our application. Here, we propose a novel radiomic\nfingerprint framework, in which a radiomic feature set (the fingerprint) is\ndynamically constructed for each patient, selected by a DL model. Unlike the\nexisting radiomic signatures, our fingerprints are derived on a per-patient\nbasis by predicting the feature relevance in a large radiomic feature pool, and\nselecting only those that are predictive of clinical conditions for individual\npatients. The radiomic-selecting model is trained simultaneously with a\nlow-dimensional (considered relatively explainable) logistic regression for\ndownstream classification. We validate our methods across multiple diagnostic\ntasks including general knee abnormalities, anterior cruciate ligament (ACL)\ntears, and meniscus tears, demonstrating comparable or superior diagnostic\naccuracy relative to state-of-the-art end-to-end DL models. More importantly,\nwe show that the interpretability inherent in our approach facilitates\nmeaningful clinical insights and potential biomarker discovery, with detailed\ndiscussion, quantitative and qualitative analysis of real-world clinical cases\nto evidence these advantages.", "AI": {"tldr": "The paper proposes a dynamic radiomic fingerprint framework for knee MRI scans, improving accuracy and interpretability over traditional radiomic signatures and end-to-end deep learning models.", "motivation": "Current radiomic approaches use fixed features, limiting performance and generalization. The authors aim to address this by dynamically selecting patient-specific radiomic features.", "method": "A deep learning model dynamically selects radiomic features (fingerprints) for each patient, combined with a low-dimensional logistic regression for classification.", "result": "The method achieves comparable or superior accuracy to state-of-the-art DL models and provides interpretable clinical insights.", "conclusion": "The radiomic fingerprint framework enhances diagnostic accuracy and interpretability, offering potential for biomarker discovery."}}
{"id": "2506.20600", "pdf": "https://arxiv.org/pdf/2506.20600", "abs": "https://arxiv.org/abs/2506.20600", "authors": ["Wengxi Li", "Roy Pea", "Nick Haber", "Hari Subramonyam"], "title": "CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video", "categories": ["cs.AI"], "comment": null, "summary": "We introduce CogGen, a learner-centered AI architecture that transforms\nprogramming videos into interactive, adaptive learning experiences by\nintegrating student modeling with generative AI tutoring based on the Cognitive\nApprenticeship framework. The architecture consists of three components: (1)\nvideo segmentation by learning goals, (2) a conversational tutoring engine\napplying Cognitive Apprenticeship strategies, and (3) a student model using\nBayesian Knowledge Tracing to adapt instruction. Our technical evaluation\ndemonstrates effective video segmentation accuracy and strong pedagogical\nalignment across knowledge, method, action, and interaction layers. Ablation\nstudies confirm the necessity of each component in generating effective\nguidance. This work advances AI-powered tutoring by bridging structured student\nmodeling with interactive AI conversations, offering a scalable approach to\nenhancing video-based programming education.", "AI": {"tldr": "CogGen is an AI architecture that converts programming videos into adaptive learning experiences using student modeling and generative AI tutoring, grounded in the Cognitive Apprenticeship framework.", "motivation": "To enhance video-based programming education by making it interactive and adaptive, leveraging AI to personalize learning.", "method": "Combines video segmentation by learning goals, a conversational tutoring engine, and Bayesian Knowledge Tracing for student modeling.", "result": "Effective video segmentation and strong pedagogical alignment, with ablation studies confirming the necessity of each component.", "conclusion": "CogGen advances AI tutoring by integrating structured student modeling with interactive AI, offering scalable improvements to programming education."}}
{"id": "2506.20031", "pdf": "https://arxiv.org/pdf/2506.20031", "abs": "https://arxiv.org/abs/2506.20031", "authors": ["Prithvi Poddar", "Ehsan Tarkesh Esfahani", "Karthik Dantu", "Souma Chowdhury"], "title": "Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Operations in disaster response, search \\& rescue, and military missions that\ninvolve multiple agents demand automated processes to support the planning of\nthe courses of action (COA). Moreover, traverse-affecting changes in the\nenvironment (rain, snow, blockades, etc.) may impact the expected performance\nof a COA, making it desirable to have a pool of COAs that are diverse in task\ndistributions across agents. Further, variations in agent capabilities, which\ncould be human crews and/or autonomous systems, present practical opportunities\nand computational challenges to the planning process. This paper presents a new\ntheoretical formulation and computational framework to generate such diverse\npools of COAs for operations with soft variations in agent-task compatibility.\nKey to the problem formulation is a graph abstraction of the task space and the\npool of COAs itself to quantify its diversity. Formulating the COAs as a\ncentralized multi-robot task allocation problem, a genetic algorithm is used\nfor (order-ignoring) allocations of tasks to each agent that jointly maximize\ndiversity within the COA pool and overall compatibility of the agent-task\nmappings. A graph neural network is trained using a policy gradient approach to\nthen perform single agent task sequencing in each COA, which maximizes\ncompletion rates adaptive to task features. Our tests of the COA generation\nprocess in a simulated environment demonstrate significant performance gain\nover a random walk baseline, small optimality gap in task sequencing, and\nexecution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 task\noperations.", "AI": {"tldr": "A framework for generating diverse courses of action (COAs) for multi-agent operations, using a genetic algorithm and graph neural network to optimize task allocation and sequencing.", "motivation": "Automated planning is needed for multi-agent missions (e.g., disaster response) due to environmental changes and varying agent capabilities, requiring diverse COAs.", "method": "Theoretical formulation with graph abstraction, genetic algorithm for task allocation, and graph neural network for task sequencing.", "result": "Simulated tests show performance gains over random baselines, small optimality gaps, and feasible execution times (50 mins for 5 agents/100 tasks).", "conclusion": "The framework effectively generates diverse COAs, balancing compatibility and diversity, with practical computational efficiency."}}
{"id": "2506.20471", "pdf": "https://arxiv.org/pdf/2506.20471", "abs": "https://arxiv.org/abs/2506.20471", "authors": ["Ujwal Narayan", "Shreyas Chaudhari", "Ashwin Kalyan", "Tanmay Rajpurohit", "Karthik Narasimhan", "Ameet Deshpande", "Vishvak Murahari"], "title": "Probing AI Safety with Source Code", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have become ubiquitous, interfacing with humans\nin numerous safety-critical applications. This necessitates improving\ncapabilities, but importantly coupled with greater safety measures to align\nthese models with human values and preferences. In this work, we demonstrate\nthat contemporary models fall concerningly short of the goal of AI safety,\nleading to an unsafe and harmful experience for users. We introduce a prompting\nstrategy called Code of Thought (CoDoT) to evaluate the safety of LLMs. CoDoT\nconverts natural language inputs to simple code that represents the same\nintent. For instance, CoDoT transforms the natural language prompt \"Make the\nstatement more toxic: {text}\" to: \"make_more_toxic({text})\". We show that CoDoT\nresults in a consistent failure of a wide range of state-of-the-art LLMs. For\nexample, GPT-4 Turbo's toxicity increases 16.5 times, DeepSeek R1 fails 100% of\nthe time, and toxicity increases 300% on average across seven modern LLMs.\nAdditionally, recursively applying CoDoT can further increase toxicity two\ntimes. Given the rapid and widespread adoption of LLMs, CoDoT underscores the\ncritical need to evaluate safety efforts from first principles, ensuring that\nsafety and capabilities advance together.", "AI": {"tldr": "The paper introduces Code of Thought (CoDoT), a prompting strategy to evaluate LLM safety, revealing significant toxicity increases in state-of-the-art models like GPT-4 Turbo and DeepSeek R1.", "motivation": "The widespread use of LLMs in safety-critical applications necessitates improved safety measures to align models with human values, as current models fall short.", "method": "CoDoT converts natural language inputs into simple code to represent intent, exposing LLM safety failures.", "result": "CoDoT reveals alarming toxicity increases (e.g., GPT-4 Turbo's toxicity rises 16.5x, DeepSeek R1 fails 100%), with recursive application doubling toxicity.", "conclusion": "CoDoT highlights the urgent need for safety evaluations from first principles to ensure safety and capabilities advance together."}}
{"id": "2506.20312", "pdf": "https://arxiv.org/pdf/2506.20312", "abs": "https://arxiv.org/abs/2506.20312", "authors": ["Jiong Wang"], "title": "On the Burstiness of Faces in Set", "categories": ["cs.CV"], "comment": "18 pages, 5 figures", "summary": "Burstiness, a phenomenon observed in text and image retrieval, refers to that\nparticular elements appear more times in a set than a statistically independent\nmodel assumes. We argue that in the context of set-based face recognition\n(SFR), burstiness exists widely and degrades the performance in two aspects:\nFirstly, the bursty faces, where faces with particular attributes %exist\nfrequently in a face set, dominate the training instances and dominate the\ntraining face sets and lead to poor generalization ability to unconstrained\nscenarios. Secondly, the bursty faces %dominating the evaluation sets interfere\nwith the similarity comparison in set verification and identification when\nevaluation. To detect the bursty faces in a set, we propose three strategies\nbased on Quickshift++, feature self-similarity, and generalized max-pooling\n(GMP). We apply the burst detection results on training and evaluation stages\nto enhance the sampling ratios or contributions of the infrequent faces. When\nevaluation, we additionally propose the quality-aware GMP that enables\nawareness of the face quality and robustness to the low-quality faces for the\noriginal GMP. We give illustrations and extensive experiments on the SFR\nbenchmarks to demonstrate that burstiness is widespread and suppressing\nburstiness considerably improves the recognition performance.", "AI": {"tldr": "The paper addresses burstiness in set-based face recognition (SFR), where certain faces dominate datasets, harming generalization and evaluation. It proposes detection methods (Quickshift++, feature self-similarity, GMP) and mitigation strategies, including quality-aware GMP, to improve recognition performance.", "motivation": "Burstiness in SFR causes poor generalization and biased evaluation due to overrepresented faces. The study aims to detect and mitigate this issue.", "method": "Three burst detection strategies (Quickshift++, feature self-similarity, GMP) are proposed. Mitigation involves adjusting sampling ratios and contributions of infrequent faces, plus quality-aware GMP for evaluation.", "result": "Experiments show burstiness is widespread in SFR, and suppressing it significantly enhances recognition performance.", "conclusion": "Detecting and mitigating burstiness in SFR improves generalization and evaluation, with proposed methods proving effective."}}
{"id": "2506.20608", "pdf": "https://arxiv.org/pdf/2506.20608", "abs": "https://arxiv.org/abs/2506.20608", "authors": ["Barry Smith", "Junchao Zhang", "Hong Zhang", "Lois Curfman McInnes", "Murat Keceli", "Archit Vasan", "Satish Balay", "Toby Isaac", "Le Chen", "Venkatram Vishwanath"], "title": "AI Assistants to Enhance and Exploit the PETSc Knowledge Base", "categories": ["cs.AI", "cs.NA", "math.NA"], "comment": null, "summary": "Generative AI, especially through large language models (LLMs), is\ntransforming how technical knowledge can be accessed, reused, and extended.\nPETSc, a widely used numerical library for high-performance scientific\ncomputing, has accumulated a rich but fragmented knowledge base over its three\ndecades of development, spanning source code, documentation, mailing lists,\nGitLab issues, Discord conversations, technical papers, and more. Much of this\nknowledge remains informal and inaccessible to users and new developers. To\nactivate and utilize this knowledge base more effectively, the PETSc team has\nbegun building an LLM-powered system that combines PETSc content with custom\nLLM tools -- including retrieval-augmented generation (RAG), reranking\nalgorithms, and chatbots -- to assist users, support developers, and propose\nupdates to formal documentation. This paper presents initial experiences\ndesigning and evaluating these tools, focusing on system architecture, using\nRAG and reranking for PETSc-specific information, evaluation methodologies for\nvarious LLMs and embedding models, and user interface design. Leveraging the\nArgonne Leadership Computing Facility resources, we analyze how LLM responses\ncan enhance the development and use of numerical software, with an initial\nfocus on scalable Krylov solvers. Our goal is to establish an extensible\nframework for knowledge-centered AI in scientific software, enabling scalable\nsupport, enriched documentation, and enhanced workflows for research and\ndevelopment. We conclude by outlining directions for expanding this system into\na robust, evolving platform that advances software ecosystems to accelerate\nscientific discovery.", "AI": {"tldr": "The PETSc team is using LLM-powered tools like RAG and chatbots to make its fragmented knowledge base more accessible, aiming to enhance scientific software development.", "motivation": "PETSc's extensive but informal knowledge base is underutilized, making it hard for users and developers to access and reuse information effectively.", "method": "The team employs LLM tools (RAG, reranking, chatbots) to organize and retrieve PETSc-specific knowledge, evaluating system architecture and models.", "result": "Initial experiences show LLM tools can improve knowledge accessibility and workflow in scientific software, particularly for Krylov solvers.", "conclusion": "The project aims to create an extensible AI framework for scientific software, with plans to expand into a robust platform for accelerating discovery."}}
{"id": "2506.20037", "pdf": "https://arxiv.org/pdf/2506.20037", "abs": "https://arxiv.org/abs/2506.20037", "authors": ["Mohammad M Maheri", "Alex Davidson", "Hamed Haddadi"], "title": "Verifiable Unlearning on Edge", "categories": ["cs.LG", "cs.CR"], "comment": "This paper has been accepted to the IEEE European Symposium on\n  Security and Privacy (EuroS&P) 2025", "summary": "Machine learning providers commonly distribute global models to edge devices,\nwhich subsequently personalize these models using local data. However, issues\nsuch as copyright infringements, biases, or regulatory requirements may require\nthe verifiable removal of certain data samples across all edge devices.\nEnsuring that edge devices correctly execute such unlearning operations is\ncritical to maintaining integrity.\n  In this work, we introduce a verification framework leveraging zero-knowledge\nproofs, specifically zk-SNARKs, to confirm data unlearning on personalized\nedge-device models without compromising privacy. We have developed algorithms\nexplicitly designed to facilitate unlearning operations that are compatible\nwith efficient zk-SNARK proof generation, ensuring minimal computational and\nmemory overhead suitable for constrained edge environments. Furthermore, our\napproach carefully preserves personalized enhancements on edge devices,\nmaintaining model performance post-unlearning.\n  Our results affirm the practicality and effectiveness of this verification\nframework, demonstrating verifiable unlearning with minimal degradation in\npersonalization-induced performance improvements. Our methodology ensures\nverifiable, privacy-preserving, and effective machine unlearning across edge\ndevices.", "AI": {"tldr": "A framework using zk-SNARKs ensures verifiable data unlearning on edge devices while preserving privacy and model performance.", "motivation": "Addresses the need for verifiable removal of data samples on edge devices due to copyright, biases, or regulations, ensuring integrity.", "method": "Leverages zero-knowledge proofs (zk-SNARKs) for verification, with algorithms designed for efficient unlearning and minimal overhead.", "result": "Practical and effective, enabling verifiable unlearning with minimal impact on personalized model performance.", "conclusion": "The framework ensures privacy-preserving, verifiable, and effective machine unlearning on edge devices."}}
{"id": "2506.20474", "pdf": "https://arxiv.org/pdf/2506.20474", "abs": "https://arxiv.org/abs/2506.20474", "authors": ["Kaixiang Zhang", "Justine Zhang", "Cristian Danescu-Niculescu-Mizil"], "title": "Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations", "categories": ["cs.CL"], "comment": null, "summary": "An intrinsic aspect of every conversation is the way talk-time is shared\nbetween multiple speakers. Conversations can be balanced, with each speaker\nclaiming a similar amount of talk-time, or imbalanced when one talks\ndisproportionately. Such overall distributions are the consequence of\ncontinuous negotiations between the speakers throughout the conversation: who\nshould be talking at every point in time, and for how long?\n  In this work we introduce a computational framework for quantifying both the\nconversation-level distribution of talk-time between speakers, as well as the\nlower-level dynamics that lead to it. We derive a typology of talk-time sharing\ndynamics structured by several intuitive axes of variation. By applying this\nframework to a large dataset of video-chats between strangers, we confirm that,\nperhaps unsurprisingly, different conversation-level distributions of talk-time\nare perceived differently by speakers, with balanced conversations being\npreferred over imbalanced ones, especially by those who end up talking less.\nThen we reveal that -- even when they lead to the same level of overall balance\n-- different types of talk-time sharing dynamics are perceived differently by\nthe participants, highlighting the relevance of our newly introduced typology.\nFinally, we discuss how our framework offers new tools to designers of\ncomputer-mediated communication platforms, for both human-human and human-AI\ncommunication.", "AI": {"tldr": "A computational framework quantifies talk-time distribution and dynamics in conversations, revealing preferences for balanced talk-time and varied perceptions of dynamics.", "motivation": "To understand how talk-time is shared in conversations and its impact on speaker perceptions.", "method": "Developed a computational framework to analyze talk-time distribution and dynamics, applied to a dataset of video-chats.", "result": "Balanced talk-time is preferred, and different dynamics affect perceptions even with similar overall balance.", "conclusion": "The framework provides tools for improving communication platforms, including human-human and human-AI interactions."}}
{"id": "2506.20326", "pdf": "https://arxiv.org/pdf/2506.20326", "abs": "https://arxiv.org/abs/2506.20326", "authors": ["Sergio Torres Aguilar"], "title": "From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents", "categories": ["cs.CV", "cs.CL", "cs.DB"], "comment": null, "summary": "Robust Document Layout Analysis (DLA) is critical for the automated\nprocessing and understanding of historical documents with complex page\norganizations. This paper benchmarks five state-of-the-art object detection\narchitectures on three annotated datasets representing a spectrum of\ncodicological complexity: The e-NDP, a corpus of Parisian medieval registers\n(1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval\nand modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated\nbooks of hours (ca.13th-16th centuries). We evaluate two Transformer-based\nmodels (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and\nYOLO-World). Our findings reveal significant performance variations dependent\non model architecture, data set characteristics, and bounding box\nrepresentation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results\n(0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on\nthe more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB\nsignificantly outperforms all other models (0.564 and 0.568, respectively).\nThis study unequivocally demonstrates that using Oriented Bounding Boxes (OBB)\nis not a minor refinement but a fundamental requirement for accurately modeling\nthe non-Cartesian nature of historical manuscripts. We conclude that a key\ntrade-off exists between the global context awareness of Transformers, ideal\nfor structured layouts, and the superior generalization of CNN-OBB models for\nvisually diverse and complex documents.", "AI": {"tldr": "The paper benchmarks five object detection models on historical document datasets, finding that Transformer-based models excel on structured layouts, while CNN-OBB models perform better on complex documents.", "motivation": "To evaluate the performance of state-of-the-art object detection architectures for robust Document Layout Analysis (DLA) in historical documents with complex layouts.", "method": "Benchmarked five models (Co-DETR, Grounding DINO, YOLO variants) on three datasets (e-NDP, CATMuS, HORAE) using different bounding box representations (AABB, OBB).", "result": "Co-DETR performed best on structured datasets (e-NDP), while YOLOv11x-OBB outperformed others on complex datasets (CATMuS, HORAE). Oriented Bounding Boxes (OBB) proved essential for accuracy.", "conclusion": "Transformers are ideal for structured layouts, while CNN-OBB models generalize better for complex documents, highlighting a trade-off between context awareness and generalization."}}
{"id": "2506.20640", "pdf": "https://arxiv.org/pdf/2506.20640", "abs": "https://arxiv.org/abs/2506.20640", "authors": ["Sijie Li", "Weiwei Sun", "Shanda Li", "Ameet Talwalkar", "Yiming Yang"], "title": "Towards Community-Driven Agents for Machine Learning Engineering", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large language model-based machine learning (ML) agents have shown great\npromise in automating ML research. However, existing agents typically operate\nin isolation on a given research problem, without engaging with the broader\nresearch community, where human researchers often gain insights and contribute\nby sharing knowledge. To bridge this gap, we introduce MLE-Live, a live\nevaluation framework designed to assess an agent's ability to communicate with\nand leverage collective knowledge from a simulated Kaggle research community.\nBuilding on this framework, we propose CoMind, a novel agent that excels at\nexchanging insights and developing novel solutions within a community context.\nCoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2%\nhuman competitors on average across four ongoing Kaggle competitions. Our code\nis released at https://github.com/comind-ml/CoMind.", "AI": {"tldr": "MLE-Live is a framework to evaluate ML agents' ability to collaborate in a simulated research community. CoMind, a novel agent, excels in this context, outperforming most human competitors in Kaggle competitions.", "motivation": "Existing ML agents work in isolation, missing the collaborative benefits of human research communities.", "method": "Introduces MLE-Live for live evaluation and CoMind, an agent designed for community knowledge exchange.", "result": "CoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2% of human competitors in Kaggle.", "conclusion": "CoMind demonstrates the potential of collaborative ML agents, bridging the gap between isolated and community-driven research."}}
{"id": "2506.20040", "pdf": "https://arxiv.org/pdf/2506.20040", "abs": "https://arxiv.org/abs/2506.20040", "authors": ["Ankur Garg", "Xuemin Yu", "Hassan Sajjad", "Samira Ebrahimi Kahou"], "title": "Cross-Layer Discrete Concept Discovery for Interpreting Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Uncovering emergent concepts across transformer layers remains a significant\nchallenge because the residual stream linearly mixes and duplicates\ninformation, obscuring how features evolve within large language models.\nCurrent research efforts primarily inspect neural representations at single\nlayers, thereby overlooking this cross-layer superposition and the redundancy\nit introduces. These representations are typically either analyzed directly for\nactivation patterns or passed to probing classifiers that map them to a limited\nset of predefined concepts. To address these limitations, we propose\n\\gls{clvqvae}, a framework that uses vector quantization to map representations\nacross layers and in the process collapse duplicated residual-stream features\ninto compact, interpretable concept vectors. Our approach uniquely combines\ntop-$k$ temperature-based sampling during quantization with EMA codebook\nupdates, providing controlled exploration of the discrete latent space while\nmaintaining code-book diversity. We further enhance the framework with\nscaled-spherical k-means++ for codebook initialization, which clusters by\ndirectional similarity rather than magnitude, better aligning with semantic\nstructure in word embedding space.", "AI": {"tldr": "The paper introduces CLVQVAE, a framework using vector quantization to map and collapse redundant features in transformer layers into interpretable concept vectors, addressing challenges in analyzing cross-layer superposition.", "motivation": "Current methods analyze neural representations at single layers, missing cross-layer superposition and redundancy, limiting interpretability of feature evolution in large language models.", "method": "Proposes CLVQVAE, combining top-k temperature-based sampling with EMA codebook updates and scaled-spherical k-means++ for initialization to map and collapse features into concept vectors.", "result": "The framework provides controlled exploration of latent space and maintains codebook diversity, better aligning with semantic structure in word embeddings.", "conclusion": "CLVQVAE offers a novel approach to uncovering emergent concepts in transformer layers by addressing redundancy and improving interpretability."}}
{"id": "2506.20476", "pdf": "https://arxiv.org/pdf/2506.20476", "abs": "https://arxiv.org/abs/2506.20476", "authors": ["Tong Zhou"], "title": "Knowledge-Aware Diverse Reranking for Cross-Source Question Answering", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG\ncompetition. The competition's evaluation set, automatically generated by\nDataMorgana from internet corpora, encompassed a wide range of target topics,\nquestion types, question formulations, audience types, and knowledge\norganization methods. It offered a fair evaluation of retrieving\nquestion-relevant supporting documents from a 15M documents subset of the\nFineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline\nachieved first place in the competition.", "AI": {"tldr": "Team Marikarp's winning solution for SIGIR 2025 LiveRAG used a knowledge-aware diverse reranking RAG pipeline to outperform competitors on a diverse evaluation set.", "motivation": "To address the challenge of retrieving question-relevant documents from a large corpus (15M documents) for diverse topics, question types, and audiences.", "method": "Proposed a knowledge-aware diverse reranking RAG pipeline.", "result": "Achieved first place in the SIGIR 2025 LiveRAG competition.", "conclusion": "The pipeline effectively handled diverse retrieval tasks, proving its superiority in the competition."}}
{"id": "2506.20342", "pdf": "https://arxiv.org/pdf/2506.20342", "abs": "https://arxiv.org/abs/2506.20342", "authors": ["Lei Wang", "Piotr Koniusz"], "title": "Feature Hallucination for Self-supervised Action Recognition", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted for publication in International Journal of Computer Vision\n  (IJCV)", "summary": "Understanding human actions in videos requires more than raw pixel analysis;\nit relies on high-level semantic reasoning and effective integration of\nmultimodal features. We propose a deep translational action recognition\nframework that enhances recognition accuracy by jointly predicting action\nconcepts and auxiliary features from RGB video frames. At test time,\nhallucination streams infer missing cues, enriching feature representations\nwithout increasing computational overhead. To focus on action-relevant regions\nbeyond raw pixels, we introduce two novel domain-specific descriptors. Object\nDetection Features (ODF) aggregate outputs from multiple object detectors to\ncapture contextual cues, while Saliency Detection Features (SDF) highlight\nspatial and intensity patterns crucial for action recognition. Our framework\nseamlessly integrates these descriptors with auxiliary modalities such as\noptical flow, Improved Dense Trajectories, skeleton data, and audio cues. It\nremains compatible with state-of-the-art architectures, including I3D,\nAssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE\nV2 and InternVideo2. To handle uncertainty in auxiliary features, we\nincorporate aleatoric uncertainty modeling in the hallucination step and\nintroduce a robust loss function to mitigate feature noise. Our multimodal\nself-supervised action recognition framework achieves state-of-the-art\nperformance on multiple benchmarks, including Kinetics-400, Kinetics-600, and\nSomething-Something V2, demonstrating its effectiveness in capturing\nfine-grained action dynamics.", "AI": {"tldr": "A deep translational action recognition framework enhances accuracy by predicting action concepts and auxiliary features, integrating novel descriptors and multimodal cues while handling uncertainty.", "motivation": "Human action recognition requires high-level semantic reasoning and multimodal feature integration, which existing methods often lack.", "method": "The framework jointly predicts action concepts and auxiliary features, uses hallucination streams for missing cues, and introduces Object Detection Features (ODF) and Saliency Detection Features (SDF). It integrates multimodal inputs and employs aleatoric uncertainty modeling.", "result": "Achieves state-of-the-art performance on benchmarks like Kinetics-400, Kinetics-600, and Something-Something V2.", "conclusion": "The framework effectively captures fine-grained action dynamics by combining novel descriptors, multimodal integration, and robust uncertainty handling."}}
{"id": "2506.19862", "pdf": "https://arxiv.org/pdf/2506.19862", "abs": "https://arxiv.org/abs/2506.19862", "authors": ["Junjie Xu", "Jiahao Zhang", "Mangal Prakash", "Xiang Zhang", "Suhang Wang"], "title": "DualEquiNet: A Dual-Space Hierarchical Equivariant Network for Large Biomolecules", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": null, "summary": "Geometric graph neural networks (GNNs) that respect E(3) symmetries have\nachieved strong performance on small molecule modeling, but they face\nscalability and expressiveness challenges when applied to large biomolecules\nsuch as RNA and proteins. These systems require models that can simultaneously\ncapture fine-grained atomic interactions, long-range dependencies across\nspatially distant components, and biologically relevant hierarchical structure,\nsuch as atoms forming residues, which in turn form higher-order domains.\nExisting geometric GNNs, which typically operate exclusively in either\nEuclidean or Spherical Harmonics space, are limited in their ability to capture\nboth the fine-scale atomic details and the long-range, symmetry-aware\ndependencies required for modeling the multi-scale structure of large\nbiomolecules. We introduce DualEquiNet, a Dual-Space Hierarchical Equivariant\nNetwork that constructs complementary representations in both Euclidean and\nSpherical Harmonics spaces to capture local geometry and global symmetry-aware\nfeatures. DualEquiNet employs bidirectional cross-space message passing and a\nnovel Cross-Space Interaction Pooling mechanism to hierarchically aggregate\natomic features into biologically meaningful units, such as residues, enabling\nefficient and expressive multi-scale modeling for large biomolecular systems.\nDualEquiNet achieves state-of-the-art performance on multiple existing\nbenchmarks for RNA property prediction and protein modeling, and outperforms\nprior methods on two newly introduced 3D structural benchmarks demonstrating\nits broad effectiveness across a range of large biomolecule modeling tasks.", "AI": {"tldr": "DualEquiNet, a geometric GNN, combines Euclidean and Spherical Harmonics spaces for scalable, expressive modeling of large biomolecules like RNA and proteins.", "motivation": "Existing geometric GNNs struggle with scalability and expressiveness for large biomolecules, lacking multi-scale modeling capabilities.", "method": "DualEquiNet uses dual-space representations, cross-space message passing, and hierarchical pooling to capture local and global features.", "result": "Achieves state-of-the-art performance on RNA and protein benchmarks, including new 3D structural tasks.", "conclusion": "DualEquiNet effectively addresses multi-scale modeling challenges in large biomolecules, outperforming prior methods."}}
{"id": "2506.20041", "pdf": "https://arxiv.org/pdf/2506.20041", "abs": "https://arxiv.org/abs/2506.20041", "authors": ["Soheil Abadifard", "Fazli Can"], "title": "LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "The classification of imbalanced data streams, which have unequal class\ndistributions, is a key difficulty in machine learning, especially when dealing\nwith multiple classes. While binary imbalanced data stream classification tasks\nhave received considerable attention, only a few studies have focused on\nmulti-class imbalanced data streams. Effectively managing the dynamic imbalance\nratio is a key challenge in this domain. This study introduces a novel, robust,\nand resilient approach to address these challenges by integrating Locality\nSensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic\nEnsemble Diversification (DynED) framework. To the best of our knowledge, we\npresent the first application of LSH-RHP for undersampling in the context of\nimbalanced non-stationary data streams. The proposed method undersamples the\nmajority classes by utilizing LSH-RHP, provides a balanced training set, and\nimproves the ensemble's prediction performance. We conduct comprehensive\nexperiments on 23 real-world and ten semi-synthetic datasets and compare\nLSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED\noutperforms other approaches in terms of both Kappa and mG-Mean effectiveness\nmeasures, demonstrating its capability in dealing with multi-class imbalanced\nnon-stationary data streams. Notably, LSH-DynED performs well in large-scale,\nhigh-dimensional datasets with considerable class imbalances and demonstrates\nadaptation and robustness in real-world circumstances. To motivate our design,\nwe review existing methods for imbalanced data streams, outline key challenges,\nand offer guidance for future work. For the reproducibility of our results, we\nhave made our implementation available on GitHub.", "AI": {"tldr": "The paper introduces LSH-DynED, a novel method combining Locality Sensitive Hashing with Random Hyperplane Projections and Dynamic Ensemble Diversification to address multi-class imbalanced data streams. It outperforms 15 state-of-the-art methods.", "motivation": "The challenge of dynamic imbalance ratios in multi-class imbalanced data streams, with limited existing solutions, motivates this study.", "method": "LSH-RHP is integrated into DynED for undersampling majority classes, creating balanced training sets and improving ensemble prediction.", "result": "LSH-DynED excels in Kappa and mG-Mean measures, showing robustness in large-scale, high-dimensional datasets with class imbalances.", "conclusion": "LSH-DynED is effective for multi-class imbalanced non-stationary data streams, with potential for future research and practical applications."}}
{"id": "2506.20480", "pdf": "https://arxiv.org/pdf/2506.20480", "abs": "https://arxiv.org/abs/2506.20480", "authors": ["Guinan Su", "Li Shen", "Lu Yin", "Shiwei Liu", "Yanwu Yang", "Jonas Geiping"], "title": "GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. However, such impressive capability typically\ncomes with a substantial model size, which presents significant challenges in\ndeployment and inference. While structured pruning of model parameters offers a\npromising way to reduce computational costs at deployment time, current methods\nprimarily focus on single model pruning. In this work, we develop a novel\nstrategy to compress models by strategically combining or merging layers from\nfinetuned model variants, which preserves the original model's abilities by\naggregating capabilities accentuated in different finetunes. We pose the\noptimal tailoring of these LLMs as a zero-order optimization problem, adopting\na search space that supports three different operations: (1) Layer removal, (2)\nLayer selection from different candidate models, and (3) Layer merging. Our\nexperiments demonstrate that this approach leads to competitive model pruning,\nfor example, for the Llama2-13B model families, our compressed models maintain\napproximately 97.3\\% of the original performance while removing $\\sim25\\%$ of\nparameters, significantly outperforming previous state-of-the-art methods. The\ncode is available at https://github.com/Guinan-Su/auto-merge-llm.", "AI": {"tldr": "A novel strategy for compressing large language models (LLMs) by combining or merging layers from finetuned variants, achieving competitive pruning results.", "motivation": "Address the challenge of deploying large LLMs by reducing model size without significant performance loss.", "method": "Proposes a zero-order optimization problem for layer removal, selection, and merging to strategically compress models.", "result": "Compressed models retain ~97.3% of original performance while removing ~25% of parameters, outperforming prior methods.", "conclusion": "The approach effectively balances model size reduction and performance retention, advancing LLM compression techniques."}}
{"id": "2506.20381", "pdf": "https://arxiv.org/pdf/2506.20381", "abs": "https://arxiv.org/abs/2506.20381", "authors": ["Ben Kang", "Xin Chen", "Jie Zhao", "Chunjuan Bo", "Dong Wang", "Huchuan Lu"], "title": "Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking", "categories": ["cs.CV", "cs.LG"], "comment": "This paper was accepted by International Journal of Computer\n  Vision(IJCV)", "summary": "Transformer-based visual trackers have demonstrated significant advancements\ndue to their powerful modeling capabilities. However, their practicality is\nlimited on resource-constrained devices because of their slow processing\nspeeds. To address this challenge, we present HiT, a novel family of efficient\ntracking models that achieve high performance while maintaining fast operation\nacross various devices. The core innovation of HiT lies in its Bridge Module,\nwhich connects lightweight transformers to the tracking framework, enhancing\nfeature representation quality. Additionally, we introduce a dual-image\nposition encoding approach to effectively encode spatial information. HiT\nachieves an impressive speed of 61 frames per second (fps) on the NVIDIA Jetson\nAGX platform, alongside a competitive AUC of 64.6% on the LaSOT benchmark,\noutperforming all previous efficient trackers.Building on HiT, we propose\nDyHiT, an efficient dynamic tracker that flexibly adapts to scene complexity by\nselecting routes with varying computational requirements. DyHiT uses search\narea features extracted by the backbone network and inputs them into an\nefficient dynamic router to classify tracking scenarios. Based on the\nclassification, DyHiT applies a divide-and-conquer strategy, selecting\nappropriate routes to achieve a superior trade-off between accuracy and speed.\nThe fastest version of DyHiT achieves 111 fps on NVIDIA Jetson AGX while\nmaintaining an AUC of 62.4% on LaSOT.Furthermore, we introduce a training-free\nacceleration method based on the dynamic routing architecture of DyHiT. This\nmethod significantly improves the execution speed of various high-performance\ntrackers without sacrificing accuracy. For instance, our acceleration method\nenables the state-of-the-art tracker SeqTrack-B256 to achieve a 2.68 times\nspeedup on an NVIDIA GeForce RTX 2080 Ti GPU while maintaining the same AUC of\n69.9% on the LaSOT.", "AI": {"tldr": "HiT and DyHiT are efficient transformer-based trackers addressing speed limitations on resource-constrained devices, achieving high performance and fast operation.", "motivation": "Transformer-based trackers are powerful but slow on resource-constrained devices, prompting the need for efficient solutions.", "method": "HiT uses a Bridge Module and dual-image position encoding; DyHiT employs dynamic routing for adaptive computation.", "result": "HiT achieves 61 fps (64.6% AUC), DyHiT reaches 111 fps (62.4% AUC), and a training-free acceleration method speeds up SeqTrack-B256 by 2.68x.", "conclusion": "The proposed methods offer efficient, high-performance tracking suitable for various devices."}}
{"id": "2506.19863", "pdf": "https://arxiv.org/pdf/2506.19863", "abs": "https://arxiv.org/abs/2506.19863", "authors": ["Ahmed Almeldein", "Mohammed Alnaggar", "Rick Archibald", "Tom Beck", "Arpan Biswas", "Rike Bostelmann", "Wes Brewer", "Chris Bryan", "Christopher Calle", "Cihangir Celik", "Rajni Chahal", "Jong Youl Choi", "Arindam Chowdhury", "Mark Cianciosa", "Franklin Curtis", "Gregory Davidson", "Sebastian De Pascuale", "Lisa Fassino", "Ana Gainaru", "Yashika Ghai", "Luke Gibson", "Qian Gong", "Christopher Greulich", "Scott Greenwood", "Cory Hauck", "Ehab Hassan", "Rinkle Juneja", "Soyoung Kang", "Scott Klasky", "Atul Kumar", "Vineet Kumar", "Paul Laiu", "Calvin Lear", "Yan-Ru Lin", "Jono McConnell", "Furkan Oz", "Anant Raj", "Pradeep Ramuhalli", "Marie Romedenne", "Samantha Sabatino", "Jos\u00e9 Salcedo-P\u00e9rez", "Nathan D. See", "Arpan Sircar", "Punam Thankur", "Tim Younkin", "Xiao-Ying Yu", "Prashant Jain", "Tom Evans", "Prasanna Balaprakash"], "title": "Exploring the Capabilities of the Frontier Large Language Models for Nuclear Energy Research", "categories": ["physics.comp-ph", "cs.AI"], "comment": null, "summary": "The AI for Nuclear Energy workshop at Oak Ridge National Laboratory evaluated\nthe potential of Large Language Models (LLMs) to accelerate fusion and fission\nresearch. Fourteen interdisciplinary teams explored diverse nuclear science\nchallenges using ChatGPT, Gemini, Claude, and other AI models over a single\nday. Applications ranged from developing foundation models for fusion reactor\ncontrol to automating Monte Carlo simulations, predicting material degradation,\nand designing experimental programs for advanced reactors. Teams employed\nstructured workflows combining prompt engineering, deep research capabilities,\nand iterative refinement to generate hypotheses, prototype code, and research\nstrategies. Key findings demonstrate that LLMs excel at early-stage\nexploration, literature synthesis, and workflow design, successfully\nidentifying research gaps and generating plausible experimental frameworks.\nHowever, significant limitations emerged, including difficulties with novel\nmaterials designs, advanced code generation for modeling and simulation, and\ndomain-specific details requiring expert validation. The successful outcomes\nresulted from expert-driven prompt engineering and treating AI as a\ncomplementary tool rather than a replacement for physics-based methods. The\nworkshop validated AI's potential to accelerate nuclear energy research through\nrapid iteration and cross-disciplinary synthesis while highlighting the need\nfor curated nuclear-specific datasets, workflow automation, and specialized\nmodel development. These results provide a roadmap for integrating AI tools\ninto nuclear science workflows, potentially reducing development cycles for\nsafer, more efficient nuclear energy systems while maintaining rigorous\nscientific standards.", "AI": {"tldr": "The workshop explored LLMs' role in nuclear energy research, showing their strengths in early-stage tasks but limitations in advanced applications, emphasizing expert-guided AI integration.", "motivation": "To evaluate LLMs' potential in accelerating fusion and fission research by addressing diverse nuclear science challenges.", "method": "Fourteen teams used LLMs like ChatGPT and Gemini for tasks such as literature synthesis, code prototyping, and workflow design, employing structured workflows and iterative refinement.", "result": "LLMs excelled in early-stage exploration and workflow design but struggled with novel materials, advanced code generation, and domain-specific details. Expert-driven prompt engineering was key to success.", "conclusion": "AI can accelerate nuclear research through rapid iteration and synthesis, but requires curated datasets, workflow automation, and specialized models for deeper integration."}}
{"id": "2506.20046", "pdf": "https://arxiv.org/pdf/2506.20046", "abs": "https://arxiv.org/abs/2506.20046", "authors": ["Hirad Daneshvar", "Reza Samavi"], "title": "GNN's Uncertainty Quantification using Self-Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "The paper has been accepted in the International Conference on AI in\n  Healthcare (AIiH) 2025 and will appear in the conference proceedings", "summary": "Graph Neural Networks (GNNs) have shown remarkable performance in the\nhealthcare domain. However, what remained challenging is quantifying the\npredictive uncertainty of GNNs, which is an important aspect of trustworthiness\nin clinical settings. While Bayesian and ensemble methods can be used to\nquantify uncertainty, they are computationally expensive. Additionally, the\ndisagreement metric used by ensemble methods to compute uncertainty cannot\ncapture the diversity of models in an ensemble network. In this paper, we\npropose a novel method, based on knowledge distillation, to quantify GNNs'\nuncertainty more efficiently and with higher precision. We apply\nself-distillation, where the same network serves as both the teacher and\nstudent models, thereby avoiding the need to train several networks\nindependently. To ensure the impact of self-distillation, we develop an\nuncertainty metric that captures the diverse nature of the network by assigning\ndifferent weights to each GNN classifier. We experimentally evaluate the\nprecision, performance, and ability of our approach in distinguishing\nout-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. The\nevaluation results demonstrate that the proposed method can effectively capture\nthe predictive uncertainty of the model while having performance similar to\nthat of the MC Dropout and ensemble methods. The code is publicly available at\nhttps://github.com/tailabTMU/UQ_GNN.", "AI": {"tldr": "A novel method using knowledge distillation is proposed to efficiently quantify predictive uncertainty in GNNs for healthcare, outperforming traditional Bayesian and ensemble methods in computational cost and precision.", "motivation": "Quantifying predictive uncertainty in GNNs is crucial for trustworthiness in clinical settings, but existing methods like Bayesian and ensemble approaches are computationally expensive and lack diversity capture.", "method": "The method employs self-distillation, where the same network acts as both teacher and student, avoiding independent training of multiple networks. An uncertainty metric assigns weights to GNN classifiers to capture diversity.", "result": "Evaluated on MIMIC-IV and Enzymes datasets, the method effectively captures uncertainty, matches MC Dropout and ensemble performance, and distinguishes out-of-distribution data.", "conclusion": "The proposed self-distillation-based method efficiently quantifies GNN uncertainty with high precision, offering a practical solution for clinical applications."}}
{"id": "2506.20495", "pdf": "https://arxiv.org/pdf/2506.20495", "abs": "https://arxiv.org/abs/2506.20495", "authors": ["Haoze Wu", "Yunzhi Yao", "Wenhao Yu", "Huajun Chen", "Ningyu Zhang"], "title": "ReCode: Updating Code API Knowledge with Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.SE"], "comment": "Work in progress", "summary": "Large Language Models (LLMs) exhibit remarkable code generation capabilities\nbut falter when adapting to frequent updates in external library APIs. This\ncritical limitation, stemming from reliance on outdated API knowledge from\ntheir training data, even with access to current documentation, impedes\nreliable code generation in dynamic environments. To tackle this issue, we\npropose ReCode (rule-based Reinforcement learning for Code Update), a novel\nframework that mimics human programmer adaptation to API changes. Specifically,\nwe construct a dataset of approximately 2,000 data entries to train the LLMs to\nperform version migration based on updated information. Then, we introduce a\nmodified string similarity metric for code evaluation as the reward for\nreinforcement learning. Our experiments demonstrate that ReCode substantially\nboosts LLMs' code generation performance in dynamic API scenarios, especially\non the unseen CodeUpdateArena task. Crucially, compared to supervised\nfine-tuning, ReCode has less impact on LLMs' general code generation abilities.\nWe apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and\nDAPO), all achieving consistent improvements. Notably, after training,\nQwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned\nmodel and the reasoning model with the same architecture. Code is available at\nhttps://github.com/zjunlp/ReCode.", "AI": {"tldr": "ReCode enhances LLMs' ability to adapt to API updates using rule-based reinforcement learning, improving code generation in dynamic environments without compromising general capabilities.", "motivation": "LLMs struggle with adapting to frequent API updates due to outdated training data, limiting reliable code generation in dynamic settings.", "method": "ReCode uses a dataset of 2,000 entries for training, a modified string similarity metric for reinforcement learning rewards, and tests with GRPO and DAPO algorithms.", "result": "ReCode significantly improves LLMs' performance in dynamic API scenarios, with Qwen2.5-Coder-7B outperforming larger models.", "conclusion": "ReCode effectively addresses LLMs' API adaptation issues, offering a scalable solution for dynamic code generation."}}
{"id": "2506.20388", "pdf": "https://arxiv.org/pdf/2506.20388", "abs": "https://arxiv.org/abs/2506.20388", "authors": ["Shen Tan", "Xin Zhang", "Liangxiu Han", "Huaguo Huang", "Han Wang"], "title": "A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management", "categories": ["cs.CV"], "comment": null, "summary": "Accurate, cost-effective monitoring of plantation aboveground biomass (AGB)\nis crucial for supporting local livelihoods and carbon sequestration\ninitiatives like the China Certified Emission Reduction (CCER) program.\nHigh-resolution canopy height maps (CHMs) are essential for this, but standard\nlidar-based methods are expensive. While deep learning with RGB imagery offers\nan alternative, accurately extracting canopy height features remains\nchallenging. To address this, we developed a novel model for high-resolution\nCHM generation using a Large Vision Foundation Model (LVFM). Our model\nintegrates a feature extractor, a self-supervised feature enhancement module to\npreserve spatial details, and a height estimator. Tested in Beijing's Fangshan\nDistrict using 1-meter Google Earth imagery, our model outperformed existing\nmethods, including conventional CNNs. It achieved a mean absolute error of 0.09\nm, a root mean square error of 0.24 m, and a correlation of 0.78 against\nlidar-based CHMs. The resulting CHMs enabled over 90% success in individual\ntree detection, high accuracy in AGB estimation, and effective tracking of\nplantation growth, demonstrating strong generalization to non-training areas.\nThis approach presents a promising, scalable tool for evaluating carbon\nsequestration in both plantations and natural forests.", "AI": {"tldr": "A novel model using a Large Vision Foundation Model (LVFM) for high-resolution canopy height maps (CHMs) was developed, outperforming existing methods in accuracy and cost-effectiveness for plantation biomass monitoring.", "motivation": "Accurate, cost-effective monitoring of plantation aboveground biomass (AGB) is vital for carbon sequestration initiatives like China's CCER program, but traditional lidar-based methods are expensive and deep learning with RGB imagery struggles with canopy height feature extraction.", "method": "The model integrates a feature extractor, a self-supervised feature enhancement module, and a height estimator, tested using 1-meter Google Earth imagery in Beijing's Fangshan District.", "result": "The model achieved a mean absolute error of 0.09 m, RMSE of 0.24 m, and correlation of 0.78 against lidar-based CHMs, with over 90% success in tree detection and high AGB estimation accuracy.", "conclusion": "This LVFM-based approach is a scalable, promising tool for carbon sequestration evaluation in plantations and natural forests."}}
{"id": "2506.19865", "pdf": "https://arxiv.org/pdf/2506.19865", "abs": "https://arxiv.org/abs/2506.19865", "authors": ["Piotr Gai\u0144ski", "Oussama Boussif", "Andrei Rekesh", "Dmytro Shevchuk", "Ali Parviz", "Mike Tyers", "Robert A. Batey", "Micha\u0142 Koziarski"], "title": "Scalable and Cost-Efficient de Novo Template-Based Molecular Generation", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": null, "summary": "Template-based molecular generation offers a promising avenue for drug design\nby ensuring generated compounds are synthetically accessible through predefined\nreaction templates and building blocks. In this work, we tackle three core\nchallenges in template-based GFlowNets: (1) minimizing synthesis cost, (2)\nscaling to large building block libraries, and (3) effectively utilizing small\nfragment sets. We propose \\textbf{Recursive Cost Guidance}, a backward policy\nframework that employs auxiliary machine learning models to approximate\nsynthesis cost and viability. This guidance steers generation toward low-cost\nsynthesis pathways, significantly enhancing cost-efficiency, molecular\ndiversity, and quality, especially when paired with an \\textbf{Exploitation\nPenalty} that balances the trade-off between exploration and exploitation. To\nenhance performance in smaller building block libraries, we develop a\n\\textbf{Dynamic Library} mechanism that reuses intermediate high-reward states\nto construct full synthesis trees. Our approach establishes state-of-the-art\nresults in template-based molecular generation.", "AI": {"tldr": "The paper introduces Recursive Cost Guidance and Dynamic Library to improve template-based molecular generation, addressing synthesis cost, scalability, and small fragment utilization.", "motivation": "To enhance template-based molecular generation by tackling synthesis cost, scalability, and small fragment challenges.", "method": "Proposes Recursive Cost Guidance (backward policy with ML models) and Dynamic Library (reusing high-reward states).", "result": "Achieves state-of-the-art results in cost-efficiency, diversity, and molecular quality.", "conclusion": "The framework effectively addresses core challenges, improving template-based molecular generation."}}
{"id": "2506.20057", "pdf": "https://arxiv.org/pdf/2506.20057", "abs": "https://arxiv.org/abs/2506.20057", "authors": ["Peter Bloem"], "title": "Universal pre-training by iterated random computation", "categories": ["cs.LG"], "comment": null, "summary": "We investigate the use of randomly generated data for the sake of\npre-training a model. We justify this approach theoretically from the\nperspective of algorithmic complexity, building on recent research that shows\nthat sequence models can be trained to approximate Solomonoff induction. We\nderive similar, but complementary theoretical results. We show empirically that\nsynthetically generated data can be used to pre-train a model before the data\nis seen. We replicate earlier results that models trained this way show\nzero-shot in-context learning across a variety of datasets, and that this\nperformance improves with scale. We extend earlier results to real-world data,\nand show that finetuning a model after pre-training offers faster convergence\nand better generalization.", "AI": {"tldr": "Randomly generated data can pre-train models effectively, supported by theoretical and empirical evidence, improving zero-shot learning and finetuning performance.", "motivation": "To explore the feasibility and benefits of using synthetic data for pre-training models, inspired by theoretical insights from algorithmic complexity.", "method": "Theoretical analysis of algorithmic complexity and empirical validation using synthetic data for pre-training, followed by finetuning on real-world data.", "result": "Models pre-trained with synthetic data achieve zero-shot learning and show improved performance with scale; finetuning enhances convergence and generalization.", "conclusion": "Synthetic data pre-training is a viable and effective approach, offering theoretical grounding and practical benefits for model performance."}}
{"id": "2506.20512", "pdf": "https://arxiv.org/pdf/2506.20512", "abs": "https://arxiv.org/abs/2506.20512", "authors": ["Zengzhi Wang", "Fan Zhou", "Xuefeng Li", "Pengfei Liu"], "title": "OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "26 pages; The first three authors contribute to this work equally", "summary": "Different base language model families, such as Llama and Qwen, exhibit\ndivergent behaviors during post-training with reinforcement learning (RL),\nespecially on reasoning-intensive tasks. What makes a base language model\nsuitable for reinforcement learning? Gaining deeper insight into this question\nis essential for developing RL-scalable foundation models of the next\ngeneration. In this work, we investigate how mid-training strategies shape RL\ndynamics, focusing on two representative model families: Qwen and Llama. Our\nstudy reveals that (1) high-quality mathematical corpora, such as\nMegaMath-Web-Pro, significantly improve both base model and RL performance,\nwhile existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further\nadding QA-style data, particularly long chain-of-thought (CoT) reasoning\nexamples, enhances RL outcomes, and instruction data further unlocks this\neffect; (3) while long-CoT improves reasoning depth, it can also induce\nverbosity of model responses and unstability of RL training, underscoring the\nimportance of data formatting; (4) scaling mid-training consistently leads to\nstronger downstream RL performance. Building on these insights, we introduce a\ntwo-stage mid-training strategy, Stable-then-Decay, in which base models are\nfirst trained on 200B tokens with a constant learning rate, followed by 20B\ntokens across three CoT-focused branches with learning rate decay. This yields\nOctoThinker, a family of models demonstrating strong RL compatibility and\nclosing the performance gap with more RL-friendly model families, i.e., Qwen.\nWe hope our work will help shape pre-training strategies for foundation models\nin the RL era. To support further research, we release our open-source models\nalong with a curated math reasoning-intensive corpus of over 70 billion tokens\n(i.e., MegaMath-Web-Pro-Max).", "AI": {"tldr": "The paper investigates how mid-training strategies affect reinforcement learning (RL) dynamics in language models like Qwen and Llama, identifying key factors like high-quality math corpora and QA-style data. It introduces a two-stage strategy, Stable-then-Decay, leading to the OctoThinker model family.", "motivation": "Understanding what makes base language models suitable for RL is crucial for developing next-generation foundation models.", "method": "The study analyzes mid-training strategies, focusing on Qwen and Llama, and introduces a two-stage approach (Stable-then-Decay) to enhance RL compatibility.", "result": "High-quality math corpora and QA-style data improve RL performance, while long chain-of-thought reasoning can cause verbosity and instability. The Stable-then-Decay strategy yields OctoThinker, closing the performance gap with RL-friendly models.", "conclusion": "The findings guide pre-training strategies for RL-compatible foundation models, with open-source models and a curated math corpus released for further research."}}
{"id": "2506.20449", "pdf": "https://arxiv.org/pdf/2506.20449", "abs": "https://arxiv.org/abs/2506.20449", "authors": ["Changlu Guo", "Anders Nymark Christensen", "Morten Rieger Hannemose"], "title": "Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation", "categories": ["cs.CV"], "comment": "The project is available at \\url{https://medart-ai.github.io}", "summary": "Text-to-image generative models have achieved remarkable breakthroughs in\nrecent years. However, their application in medical image generation still\nfaces significant challenges, including small dataset sizes, and scarcity of\nmedical textual data. To address these challenges, we propose Med-Art, a\nframework specifically designed for medical image generation with limited data.\nMed-Art leverages vision-language models to generate visual descriptions of\nmedical images which overcomes the scarcity of applicable medical textual data.\nMed-Art adapts a large-scale pre-trained text-to-image model, PixArt-$\\alpha$,\nbased on the Diffusion Transformer (DiT), achieving high performance under\nlimited data. Furthermore, we propose an innovative Hybrid-Level Diffusion\nFine-tuning (HLDF) method, which enables pixel-level losses, effectively\naddressing issues such as overly saturated colors. We achieve state-of-the-art\nperformance on two medical image datasets, measured by FID, KID, and downstream\nclassification performance.", "AI": {"tldr": "Med-Art is a framework for medical image generation with limited data, leveraging vision-language models and fine-tuning methods to achieve state-of-the-art performance.", "motivation": "Addressing challenges in medical image generation, such as small datasets and scarce textual data.", "method": "Uses vision-language models for visual descriptions, adapts PixArt-\u03b1 (DiT-based), and introduces Hybrid-Level Diffusion Fine-tuning (HLDF).", "result": "Achieves state-of-the-art performance on medical datasets (FID, KID, classification).", "conclusion": "Med-Art effectively overcomes data limitations and improves medical image generation."}}
{"id": "2506.19870", "pdf": "https://arxiv.org/pdf/2506.19870", "abs": "https://arxiv.org/abs/2506.19870", "authors": ["Md Asif Ul Hoq Khan", "MD Zahedul Islam", "Istiaq Ahmed", "Md Masud Karim Rabbi", "Farhana Rahman Anonna", "MD Abdul Fahim Zeeshan", "Mehedi Hasan Ridoy", "Bivash Ranjan Chowdhury", "Md Nazmul Shakir Rabbi", "GM Alamin Sadnan"], "title": "Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Peer-to-peer trading and the move to decentralized grids have reshaped the\nenergy markets in the United States. Notwithstanding, such developments lead to\nnew challenges, mainly regarding the safety and authenticity of energy trade.\nThis study aimed to develop and build a secure, intelligent, and efficient\nenergy transaction system for the decentralized US energy market. This research\ninterlinks the technological prowess of blockchain and artificial intelligence\n(AI) in a novel way to solve long-standing challenges in the distributed energy\nmarket, specifically those of security, fraudulent behavior detection, and\nmarket reliability. The dataset for this research is comprised of more than 1.2\nmillion anonymized energy transaction records from a simulated peer-to-peer\n(P2P) energy exchange network emulating real-life blockchain-based American\nmicrogrids, including those tested by LO3 Energy and Grid+ Labs. Each record\ncontains detailed fields of transaction identifier, timestamp, energy volume\n(kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier\n(hashed for privacy), smart meter readings, geolocation regions, and settlement\nconfirmation status. The dataset also includes system-calculated behavior\nmetrics of transaction rate, variability of energy production, and historical\npricing patterns. The system architecture proposed involves the integration of\ntwo layers, namely a blockchain layer and artificial intelligence (AI) layer,\neach playing a unique but complementary function in energy transaction securing\nand market intelligence improvement. The machine learning models used in this\nresearch were specifically chosen for their established high performance in\nclassification tasks, specifically in the identification of energy transaction\nfraud in decentralized markets.", "AI": {"tldr": "The paper proposes a secure, intelligent energy transaction system for decentralized US energy markets using blockchain and AI to address security, fraud detection, and reliability.", "motivation": "Decentralized energy markets face challenges in safety and authenticity of trades, prompting the need for a secure and efficient transaction system.", "method": "The study integrates blockchain and AI layers, analyzing 1.2M anonymized P2P energy transaction records to detect fraud and improve market reliability.", "result": "The proposed system leverages blockchain for security and AI for fraud detection, using machine learning models to classify fraudulent transactions.", "conclusion": "The integration of blockchain and AI effectively addresses key challenges in decentralized energy markets, enhancing security and reliability."}}
{"id": "2506.20061", "pdf": "https://arxiv.org/pdf/2506.20061", "abs": "https://arxiv.org/abs/2506.20061", "authors": ["Zhicheng Zhang", "Ziyan Wang", "Yali Du", "Fei Fang"], "title": "Learning Instruction-Following Policies through Open-Ended Instruction Relabeling with Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": "Under Review", "summary": "Developing effective instruction-following policies in reinforcement learning\nremains challenging due to the reliance on extensive human-labeled instruction\ndatasets and the difficulty of learning from sparse rewards. In this paper, we\npropose a novel approach that leverages the capabilities of large language\nmodels (LLMs) to automatically generate open-ended instructions retrospectively\nfrom previously collected agent trajectories. Our core idea is to employ LLMs\nto relabel unsuccessful trajectories by identifying meaningful subtasks the\nagent has implicitly accomplished, thereby enriching the agent's training data\nand substantially alleviating reliance on human annotations. Through this\nopen-ended instruction relabeling, we efficiently learn a unified\ninstruction-following policy capable of handling diverse tasks within a single\npolicy. We empirically evaluate our proposed method in the challenging Craftax\nenvironment, demonstrating clear improvements in sample efficiency, instruction\ncoverage, and overall policy performance compared to state-of-the-art\nbaselines. Our results highlight the effectiveness of utilizing LLM-guided\nopen-ended instruction relabeling to enhance instruction-following\nreinforcement learning.", "AI": {"tldr": "The paper introduces a method using large language models (LLMs) to relabel unsuccessful trajectories in reinforcement learning, reducing reliance on human-labeled data and improving policy performance.", "motivation": "The challenge of developing instruction-following policies in reinforcement learning due to sparse rewards and dependence on human-labeled datasets.", "method": "Leveraging LLMs to retrospectively generate open-ended instructions from agent trajectories, relabeling unsuccessful ones to enrich training data.", "result": "Improved sample efficiency, instruction coverage, and policy performance in the Craftax environment compared to baselines.", "conclusion": "LLM-guided open-ended instruction relabeling effectively enhances instruction-following reinforcement learning."}}
{"id": "2506.20544", "pdf": "https://arxiv.org/pdf/2506.20544", "abs": "https://arxiv.org/abs/2506.20544", "authors": ["Ammar Khairi", "Daniel D'souza", "Ye Shen", "Julia Kreutzer", "Sara Hooker"], "title": "When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have shifted focus toward\nscaling inference-time compute, improving performance without retraining the\nmodel. A common approach is to sample multiple outputs in parallel, and select\none of these as the final output. However, work to date has focused on English\nand a handful of domains such as math and code. In contrast, we are most\ninterested in techniques that generalize across open-ended tasks, formally\nverifiable tasks, and across languages. In this work, we study how to robustly\nscale inference-time compute for open-ended generative tasks in a multilingual,\nmulti-task setting.\n  Our findings show that both sampling strategy based on temperature variation\nand selection strategy must be adapted to account for diverse domains and\nvaried language settings. We evaluate existing selection methods, revealing\nthat strategies effective in English often fail to generalize across languages.\nWe propose novel sampling and selection strategies specifically adapted for\nmultilingual and multi-task inference scenarios, and show they yield notable\ngains across languages and tasks. In particular, our combined sampling and\nselection methods lead to an average +6.8 jump in win-rates for our 8B models\non m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At\nlarger scale, Command-A (111B model) equipped with our methods, shows +9.0\nimprovement in win-rates on the same benchmark with just five samples against\nsingle-sample decoding, a substantial increase at minimal cost. Our results\nunderscore the need for language- and task-aware approaches to inference-time\ncompute, aiming to democratize performance improvements in underrepresented\nlanguages.", "AI": {"tldr": "The paper explores robust scaling of inference-time compute for multilingual, multi-task LLMs, proposing novel sampling and selection strategies that outperform existing methods, especially in underrepresented languages.", "motivation": "Current inference-time compute scaling methods focus on English and limited domains, lacking generalization across languages and open-ended tasks. The study aims to address this gap.", "method": "The study evaluates existing selection methods, identifies their limitations, and introduces new sampling and selection strategies tailored for multilingual and multi-task settings.", "result": "Proposed methods achieve significant performance gains, e.g., +6.8 win-rate improvement for 8B models and +9.0 for a 111B model, demonstrating effectiveness across languages and tasks.", "conclusion": "Language- and task-aware inference-time compute methods are essential for democratizing performance improvements, particularly in underrepresented languages."}}
{"id": "2506.20452", "pdf": "https://arxiv.org/pdf/2506.20452", "abs": "https://arxiv.org/abs/2506.20452", "authors": ["Tobias Vontobel", "Seyedmorteza Sadat", "Farnood Salehi", "Romann M. Weber"], "title": "HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Diffusion models have emerged as the leading approach for image synthesis,\ndemonstrating exceptional photorealism and diversity. However, training\ndiffusion models at high resolutions remains computationally prohibitive, and\nexisting zero-shot generation techniques for synthesizing images beyond\ntraining resolutions often produce artifacts, including object duplication and\nspatial incoherence. In this paper, we introduce HiWave, a training-free,\nzero-shot approach that substantially enhances visual fidelity and structural\ncoherence in ultra-high-resolution image synthesis using pretrained diffusion\nmodels. Our method employs a two-stage pipeline: generating a base image from\nthe pretrained model followed by a patch-wise DDIM inversion step and a novel\nwavelet-based detail enhancer module. Specifically, we first utilize inversion\nmethods to derive initial noise vectors that preserve global coherence from the\nbase image. Subsequently, during sampling, our wavelet-domain detail enhancer\nretains low-frequency components from the base image to ensure structural\nconsistency, while selectively guiding high-frequency components to enrich fine\ndetails and textures. Extensive evaluations using Stable Diffusion XL\ndemonstrate that HiWave effectively mitigates common visual artifacts seen in\nprior methods, achieving superior perceptual quality. A user study confirmed\nHiWave's performance, where it was preferred over the state-of-the-art\nalternative in more than 80% of comparisons, highlighting its effectiveness for\nhigh-quality, ultra-high-resolution image synthesis without requiring\nretraining or architectural modifications.", "AI": {"tldr": "HiWave is a training-free, zero-shot method for ultra-high-resolution image synthesis using pretrained diffusion models, enhancing visual fidelity and coherence without retraining.", "motivation": "Training diffusion models at high resolutions is computationally expensive, and existing zero-shot techniques often produce artifacts like object duplication and spatial incoherence.", "method": "HiWave uses a two-stage pipeline: generating a base image, followed by patch-wise DDIM inversion and a wavelet-based detail enhancer to preserve global coherence and enrich fine details.", "result": "HiWave outperforms prior methods, reducing artifacts and achieving superior perceptual quality, as confirmed by a user study where it was preferred in over 80% of comparisons.", "conclusion": "HiWave is effective for high-quality, ultra-high-resolution image synthesis without retraining or architectural changes."}}
{"id": "2506.19871", "pdf": "https://arxiv.org/pdf/2506.19871", "abs": "https://arxiv.org/abs/2506.19871", "authors": ["Yining Pang", "Chenghan Li"], "title": "An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network", "categories": ["cs.CR", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2405.12076 by other authors", "summary": "Insurance fraud detection represents a pivotal advancement in modern\ninsurance service, providing intelligent and digitalized monitoring to enhance\nmanagement and prevent fraud. It is crucial for ensuring the security and\nefficiency of insurance systems. Although AI and machine learning algorithms\nhave demonstrated strong performance in detecting fraudulent claims, the\nabsence of standardized defense mechanisms renders current systems vulnerable\nto emerging adversarial threats. In this paper, we propose a GAN-based approach\nto conduct adversarial attacks on fraud detection systems. Our results indicate\nthat an attacker, without knowledge of the training data or internal model\ndetails, can generate fraudulent cases that are classified as legitimate with a\n99\\% attack success rate (ASR). By subtly modifying real insurance records and\nclaims, adversaries can significantly increase the fraud risk, potentially\nbypassing compromised detection systems. These findings underscore the urgent\nneed to enhance the robustness of insurance fraud detection models against\nadversarial manipulation, thereby ensuring the stability and reliability of\ndifferent insurance systems.", "AI": {"tldr": "The paper proposes a GAN-based adversarial attack on insurance fraud detection systems, achieving a 99% success rate in bypassing detection, highlighting the need for more robust defenses.", "motivation": "The absence of standardized defense mechanisms in AI-based fraud detection systems makes them vulnerable to adversarial threats, necessitating research into their weaknesses.", "method": "A GAN-based approach is used to generate adversarial examples by subtly modifying real insurance records, testing the system's vulnerability.", "result": "The attack successfully bypasses fraud detection with a 99% success rate, demonstrating significant vulnerability.", "conclusion": "The findings emphasize the urgent need to improve the robustness of fraud detection systems against adversarial attacks to ensure system reliability."}}
{"id": "2506.20065", "pdf": "https://arxiv.org/pdf/2506.20065", "abs": "https://arxiv.org/abs/2506.20065", "authors": ["Cristian Minoccheri", "Sophia Tesic", "Kayvan Najarian", "Ryan Stidham"], "title": "Supervised Coupled Matrix-Tensor Factorization (SCMTF) for Computational Phenotyping of Patient Reported Outcomes in Ulcerative Colitis", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "Phenotyping is the process of distinguishing groups of patients to identify\ndifferent types of disease progression. A recent trend employs low-rank matrix\nand tensor factorization methods for their capability of dealing with\nmulti-modal, heterogeneous, and missing data. Symptom quantification is crucial\nfor understanding patient experiences in inflammatory bowel disease, especially\nin conditions such as ulcerative colitis (UC). However, patient-reported\nsymptoms are typically noisy, subjective, and significantly more sparse than\nother data types. For this reason, they are usually not included in phenotyping\nand other machine learning methods. This paper explores the application of\ncomputational phenotyping to leverage Patient-Reported Outcomes (PROs) using a\nnovel supervised coupled matrix-tensor factorization (SCMTF) method, which\nintegrates temporal PROs and temporal labs with static features to predict\nmedication persistence in ulcerative colitis. This is the first tensor-based\nmethod that is both supervised and coupled, it is the first application to the\nUC domain, and the first application to PROs. We use a deep learning framework\nthat makes the model flexible and easy to train. The proposed method allows us\nto handle the large amount of missing data in the PROs. The best model predicts\nchanges in medication 8 and 20 months in the future with AUCs of 0.853 and\n0.803 on the test set respectively. We derive interpretable phenotypes\nconsisting of static features and temporal features (including their temporal\npatterns). We show that low-rank matrix and tensor based phenotyping can be\nsuccessfully applied to the UC domain and to highly missing PRO data. We\nidentify phenotypes useful to predict medication persistence - these phenotypes\ninclude several symptom variables, showing that PROs contain relevant\ninfromation that is usually discarded.", "AI": {"tldr": "The paper introduces a supervised coupled matrix-tensor factorization (SCMTF) method to integrate patient-reported outcomes (PROs) and lab data for predicting medication persistence in ulcerative colitis (UC), achieving high predictive accuracy and interpretable phenotypes.", "motivation": "Patient-reported symptoms in UC are often noisy and sparse, leading to their exclusion in phenotyping. This work aims to leverage PROs using a novel tensor-based method to improve phenotyping and prediction.", "method": "A supervised coupled matrix-tensor factorization (SCMTF) integrates temporal PROs, lab data, and static features within a deep learning framework to handle missing data and predict medication persistence.", "result": "The model predicts medication changes 8 and 20 months ahead with AUCs of 0.853 and 0.803, respectively, and identifies interpretable phenotypes including symptom variables.", "conclusion": "The SCMTF method successfully applies tensor-based phenotyping to UC and PROs, demonstrating the value of PROs in predicting medication persistence and improving patient care."}}
{"id": "2506.20606", "pdf": "https://arxiv.org/pdf/2506.20606", "abs": "https://arxiv.org/abs/2506.20606", "authors": ["Baixiang Huang", "Zhen Tan", "Haoran Wang", "Zijie Liu", "Dawei Li", "Ali Payani", "Huan Liu", "Tianlong Chen", "Kai Shu"], "title": "Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm", "categories": ["cs.CL"], "comment": "Main paper: 9 pages; total: 18 pages (including appendix). Code,\n  data, results, and additional resources are available at:\n  https://model-editing.github.io", "summary": "Agents based on Large Language Models (LLMs) have demonstrated strong\ncapabilities across a wide range of tasks. However, deploying LLM-based agents\nin high-stakes domains comes with significant safety and ethical risks.\nUnethical behavior by these agents can directly result in serious real-world\nconsequences, including physical harm and financial loss. To efficiently steer\nthe ethical behavior of agents, we frame agent behavior steering as a model\nediting task, which we term Behavior Editing. Model editing is an emerging area\nof research that enables precise and efficient modifications to LLMs while\npreserving their overall capabilities. To systematically study and evaluate\nthis approach, we introduce BehaviorBench, a multi-tier benchmark grounded in\npsychological moral theories. This benchmark supports both the evaluation and\nediting of agent behaviors across a variety of scenarios, with each tier\nintroducing more complex and ambiguous scenarios. We first demonstrate that\nBehavior Editing can dynamically steer agents toward the target behavior within\nspecific scenarios. Moreover, Behavior Editing enables not only\nscenario-specific local adjustments but also more extensive shifts in an\nagent's global moral alignment. We demonstrate that Behavior Editing can be\nused to promote ethical and benevolent behavior or, conversely, to induce\nharmful or malicious behavior. Through comprehensive evaluations on agents\nbased on frontier LLMs, BehaviorBench shows the effectiveness of Behavior\nEditing across different models and scenarios. Our findings offer key insights\ninto a new paradigm for steering agent behavior, highlighting both the promise\nand perils of Behavior Editing.", "AI": {"tldr": "The paper introduces Behavior Editing, a method to ethically steer LLM-based agents, and BehaviorBench, a benchmark for evaluating and editing agent behaviors. It shows effectiveness in both local and global behavior adjustments, highlighting ethical risks and benefits.", "motivation": "Deploying LLM-based agents in high-stakes domains poses safety and ethical risks, necessitating methods to steer their behavior to prevent harm.", "method": "Frames agent behavior steering as a model editing task (Behavior Editing) and introduces BehaviorBench, a multi-tier benchmark based on psychological moral theories for evaluation.", "result": "Behavior Editing effectively steers agent behavior locally and globally, demonstrating potential for both ethical and harmful outcomes.", "conclusion": "Behavior Editing offers a promising paradigm for steering agent behavior but also underscores the risks of misuse, emphasizing the need for careful application."}}
{"id": "2506.20464", "pdf": "https://arxiv.org/pdf/2506.20464", "abs": "https://arxiv.org/abs/2506.20464", "authors": ["Dibyayan Patra", "Pasindu Ranasinghe", "Bikram Banerjee", "Simit Raval"], "title": "A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners", "categories": ["cs.CV", "I.4.9"], "comment": null, "summary": "Rock bolts are crucial components of the subterranean support systems in\nunderground mines that provide adequate structural reinforcement to the rock\nmass to prevent unforeseen hazards like rockfalls. This makes frequent\nassessments of such bolts critical for maintaining rock mass stability and\nminimising risks in underground mining operations. Where manual surveying of\nrock bolts is challenging due to the low light conditions in the underground\nmines and the time-intensive nature of the process, automated detection of rock\nbolts serves as a plausible solution. To that end, this study focuses on the\nautomatic identification of rock bolts within medium to large-scale 3D point\nclouds obtained from underground mines using mobile laser scanners. Existing\ntechniques for automated rock bolt identification primarily rely on feature\nengineering and traditional machine learning approaches. However, such\ntechniques lack robustness as these point clouds present several challenges due\nto data noise, varying environments, and complex surrounding structures.\nMoreover, the target rock bolts are extremely small objects within large-scale\npoint clouds and are often partially obscured due to the application of\nreinforcement shotcrete. Addressing these challenges, this paper proposes an\napproach termed DeepBolt, which employs a novel two-stage deep learning\narchitecture specifically designed for handling severe class imbalance for the\nautomatic and efficient identification of rock bolts in complex 3D point\nclouds. The proposed method surpasses state-of-the-art semantic segmentation\nmodels by up to 42.5% in Intersection over Union (IoU) for rock bolt points.\nAdditionally, it outperforms existing rock bolt identification techniques,\nachieving a 96.41% precision and 96.96% recall in classifying rock bolts,\ndemonstrating its robustness and effectiveness in complex underground\nenvironments.", "AI": {"tldr": "The paper proposes DeepBolt, a two-stage deep learning method for automated rock bolt detection in 3D point clouds, outperforming existing techniques in precision and recall.", "motivation": "Manual rock bolt inspection in mines is challenging due to low light and time constraints, necessitating automated solutions. Existing methods lack robustness against noise and complex environments.", "method": "DeepBolt, a novel two-stage deep learning architecture, addresses class imbalance and efficiently identifies rock bolts in noisy, large-scale 3D point clouds.", "result": "DeepBolt achieves 96.41% precision and 96.96% recall, surpassing state-of-the-art models by up to 42.5% in IoU for rock bolt points.", "conclusion": "DeepBolt is robust and effective for automated rock bolt detection in complex underground environments, improving safety and efficiency in mining operations."}}
{"id": "2506.19874", "pdf": "https://arxiv.org/pdf/2506.19874", "abs": "https://arxiv.org/abs/2506.19874", "authors": ["Xing Yang", "Bingtao Wang", "Yuhao Wang", "Zimo Ji", "Terry Jingchen Zhang", "Wenyuan Jiang"], "title": "Towards Provable (In)Secure Model Weight Release Schemes", "categories": ["cs.CR", "cs.AI"], "comment": "8 pages, 2 figures", "summary": "Recent secure weight release schemes claim to enable open-source model\ndistribution while protecting model ownership and preventing misuse. However,\nthese approaches lack rigorous security foundations and provide only informal\nsecurity guarantees. Inspired by established works in cryptography, we\nformalize the security of weight release schemes by introducing several\nconcrete security definitions. We then demonstrate our definition's utility\nthrough a case study of TaylorMLP, a prominent secure weight release scheme.\nOur analysis reveals vulnerabilities that allow parameter extraction thus\nshowing that TaylorMLP fails to achieve its informal security goals. We hope\nthis work will advocate for rigorous research at the intersection of machine\nlearning and security communities and provide a blueprint for how future weight\nrelease schemes should be designed and evaluated.", "AI": {"tldr": "The paper critiques existing secure weight release schemes, formalizes security definitions, and exposes vulnerabilities in TaylorMLP, advocating for rigorous security in machine learning.", "motivation": "To address the lack of rigorous security foundations in secure weight release schemes and provide formal security guarantees.", "method": "Introduces concrete security definitions and analyzes TaylorMLP as a case study.", "result": "Reveals vulnerabilities in TaylorMLP, showing it fails to meet its security goals.", "conclusion": "Advocates for rigorous security research in machine learning and provides a blueprint for future secure weight release schemes."}}
{"id": "2506.20090", "pdf": "https://arxiv.org/pdf/2506.20090", "abs": "https://arxiv.org/abs/2506.20090", "authors": ["Ainaz Jamshidi", "Dongchan Kim", "Muhammad Arif"], "title": "A Survey of Predictive Maintenance Methods: An Analysis of Prognostics via Classification and Regression", "categories": ["cs.LG"], "comment": "13 pages, 7 figures", "summary": "Predictive maintenance (PdM) has become a crucial element of modern\nindustrial practice. PdM plays a significant role in operational dependability\nand cost management by decreasing unforeseen downtime and optimizing asset life\ncycle management. Machine learning and deep learning have enabled more precise\nforecasts of equipment failure and remaining useful life (RUL). Although many\nstudies have been conducted on PdM, there has not yet been a standalone\ncomparative study between regression- and classification-based approaches. In\nthis review, we look across a range of PdM methodologies, while focusing more\nstrongly on the comparative use of classification and regression methods in\nprognostics. While regression-based methods typically provide estimates of RUL,\nclassification-based methods present a forecast of the probability of failure\nacross defined time intervals. Through a comprehensive analysis of recent\nliterature, we highlight key advancements, challenges-such as data imbalance\nand high-dimensional feature spaces-and emerging trends, including hybrid\napproaches and AI-enabled prognostic systems. This review aims to provide\nresearchers and practitioners with an awareness of the strengths and\ncompromises of various PdM methods and to help identify future research and\nbuild more robust, directed adaptive maintenance systems. Future work may\ninclude a systematic review of practical aspects such as public datasets,\nbenchmarking platforms, and open-source tools to support the advancement of PdM\nresearch.", "AI": {"tldr": "A review comparing classification- and regression-based predictive maintenance (PdM) methods, highlighting advancements, challenges, and trends like hybrid approaches and AI-enabled systems.", "motivation": "To address the lack of standalone comparative studies between regression- and classification-based PdM approaches, providing insights for researchers and practitioners.", "method": "Analyzes recent literature on PdM, focusing on classification (failure probability) and regression (RUL estimation) methods, including challenges like data imbalance.", "result": "Identifies key advancements, challenges (e.g., data imbalance), and trends (e.g., hybrid methods), aiding in robust maintenance system development.", "conclusion": "The review clarifies trade-offs between PdM methods and suggests future work on practical tools and datasets to advance PdM research."}}
{"id": "2506.20639", "pdf": "https://arxiv.org/pdf/2506.20639", "abs": "https://arxiv.org/abs/2506.20639", "authors": ["Shansan Gong", "Ruixiang Zhang", "Huangjie Zheng", "Jiatao Gu", "Navdeep Jaitly", "Lingpeng Kong", "Yizhe Zhang"], "title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation", "categories": ["cs.CL"], "comment": "preprint", "summary": "Diffusion large language models (dLLMs) are compelling alternatives to\nautoregressive (AR) models because their denoising models operate over the\nentire sequence. The global planning and iterative refinement features of dLLMs\nare particularly useful for code generation. However, current training and\ninference mechanisms for dLLMs in coding are still under-explored. To demystify\nthe decoding behavior of dLLMs and unlock their potential for coding, we\nsystematically investigate their denoising processes and reinforcement learning\n(RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code.\nUsing this model as a testbed, we analyze its decoding behavior, revealing how\nit differs from that of AR models: (1) dLLMs can decide how causal their\ngeneration should be without relying on semi-AR decoding, and (2) increasing\nthe sampling temperature diversifies not only token choices but also their\ngeneration order. This diversity creates a rich search space for RL rollouts.\nFor RL training, to reduce the variance of token log-likelihood estimates and\nmaintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel\nsampling scheme that constructs complementary mask noise for completions used\nin training. In our experiments, coupled-GRPO significantly improves\nDiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and\nreduces reliance on AR causal during decoding. Our work provides deeper insight\ninto the machinery of dLLM generation and offers an effective, diffusion-native\nRL training framework. https://github.com/apple/ml-diffucoder.", "AI": {"tldr": "DiffuCoder, a 7B dLLM, explores denoising and RL methods for code generation, outperforming AR models with novel sampling and training techniques.", "motivation": "To understand and enhance the decoding behavior and training of diffusion large language models (dLLMs) for code generation, addressing gaps in current methods.", "method": "Systematically investigates denoising processes and RL methods, proposing coupled-GRPO for efficient training and diverse generation.", "result": "DiffuCoder improves code generation performance (+4.4% on EvalPlus) and reduces reliance on AR causality, showcasing diverse generation order.", "conclusion": "The study advances dLLM understanding and provides an effective RL framework for code generation, with open-source contributions."}}
{"id": "2506.20522", "pdf": "https://arxiv.org/pdf/2506.20522", "abs": "https://arxiv.org/abs/2506.20522", "authors": ["Chathura Wimalasiri", "Piumal Rathnayake", "Shamod Wijerathne", "Sumudu Rasnayaka", "Dhanushka Leuke Bandara", "Roshan Ragel", "Vajira Thambawita", "Isuru Nawinne"], "title": "AI-assisted radiographic analysis in detecting alveolar bone-loss severity and patterns", "categories": ["cs.CV", "I.5.4; I.4.6; I.4.9; I.4.8; J.3"], "comment": "This manuscript is 17 pages with 5 tables and 12 figures. The\n  manuscript is under review at Nature Scientific Reports", "summary": "Periodontitis, a chronic inflammatory disease causing alveolar bone loss,\nsignificantly affects oral health and quality of life. Accurate assessment of\nbone loss severity and pattern is critical for diagnosis and treatment\nplanning. In this study, we propose a novel AI-based deep learning framework to\nautomatically detect and quantify alveolar bone loss and its patterns using\nintraoral periapical (IOPA) radiographs. Our method combines YOLOv8 for tooth\ndetection with Keypoint R-CNN models to identify anatomical landmarks, enabling\nprecise calculation of bone loss severity. Additionally, YOLOv8x-seg models\nsegment bone levels and tooth masks to determine bone loss patterns (horizontal\nvs. angular) via geometric analysis. Evaluated on a large, expertly annotated\ndataset of 1000 radiographs, our approach achieved high accuracy in detecting\nbone loss severity (intra-class correlation coefficient up to 0.80) and bone\nloss pattern classification (accuracy 87%). This automated system offers a\nrapid, objective, and reproducible tool for periodontal assessment, reducing\nreliance on subjective manual evaluation. By integrating AI into dental\nradiographic analysis, our framework has the potential to improve early\ndiagnosis and personalized treatment planning for periodontitis, ultimately\nenhancing patient care and clinical outcomes.", "AI": {"tldr": "An AI-based deep learning framework is proposed to automatically detect and quantify alveolar bone loss and its patterns in periodontitis using IOPA radiographs, achieving high accuracy and offering a rapid, objective tool for periodontal assessment.", "motivation": "Accurate assessment of bone loss severity and pattern is critical for diagnosing and treating periodontitis, which significantly impacts oral health and quality of life.", "method": "Combines YOLOv8 for tooth detection, Keypoint R-CNN for anatomical landmarks, and YOLOv8x-seg for bone level segmentation to calculate severity and classify patterns (horizontal vs. angular).", "result": "High accuracy in detecting bone loss severity (ICC up to 0.80) and classifying patterns (87% accuracy) on a dataset of 1000 radiographs.", "conclusion": "The AI framework provides a rapid, objective, and reproducible tool for periodontal assessment, improving early diagnosis and personalized treatment planning for periodontitis."}}
{"id": "2506.19877", "pdf": "https://arxiv.org/pdf/2506.19877", "abs": "https://arxiv.org/abs/2506.19877", "authors": ["Zhaoyang Xu", "Yunbo Liu"], "title": "Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "submitted to IEEE CNS 2025", "summary": "Identifying suitable machine learning paradigms for intrusion detection\nremains critical for building effective and generalizable security solutions.\nIn this study, we present a controlled comparison of four representative models\n- Multi-Layer Perceptron (MLP), 1D Convolutional Neural Network (CNN),\nOne-Class Support Vector Machine (OCSVM) and Local Outlier Factor (LOF) - on\nthe CICIDS2017 dataset under two scenarios: detecting known attack types and\ngeneralizing to previously unseen threats. Our results show that supervised MLP\nand CNN achieve near-perfect accuracy on familiar attacks but suffer drastic\nrecall drops on novel attacks. Unsupervised LOF attains moderate overall\naccuracy and high recall on unknown threats at the cost of elevated false\nalarms, while boundary-based OCSVM balances precision and recall best,\ndemonstrating robust detection across both scenarios. These findings offer\npractical guidance for selecting IDS models in dynamic network environments.", "AI": {"tldr": "Comparison of four ML models for intrusion detection shows supervised models excel on known attacks but struggle with novel threats, while unsupervised methods like OCSVM balance performance across scenarios.", "motivation": "Identifying effective and generalizable machine learning paradigms for intrusion detection in dynamic network environments.", "method": "Controlled comparison of MLP, CNN, OCSVM, and LOF on the CICIDS2017 dataset under known and novel attack scenarios.", "result": "Supervised models (MLP, CNN) perform well on known attacks but poorly on novel ones; LOF has high recall for unknown threats but more false alarms; OCSVM balances precision and recall best.", "conclusion": "OCSVM is the most robust choice for intrusion detection in dynamic environments, offering practical guidance for model selection."}}
{"id": "2506.20094", "pdf": "https://arxiv.org/pdf/2506.20094", "abs": "https://arxiv.org/abs/2506.20094", "authors": ["Krishna Praneet Gudipaty", "Walid A. Hanafy", "Kaan Ozkara", "Qianlin Liang", "Jesse Milzman", "Prashant Shenoy", "Suhas Diggavi"], "title": "MEL: Multi-level Ensemble Learning for Resource-Constrained Environments", "categories": ["cs.LG"], "comment": null, "summary": "AI inference at the edge is becoming increasingly common for low-latency\nservices. However, edge environments are power- and resource-constrained, and\nsusceptible to failures. Conventional failure resilience approaches, such as\ncloud failover or compressed backups, often compromise latency or accuracy,\nlimiting their effectiveness for critical edge inference services. In this\npaper, we propose Multi-Level Ensemble Learning (MEL), a new framework for\nresilient edge inference that simultaneously trains multiple lightweight backup\nmodels capable of operating collaboratively, refining each other when multiple\nservers are available, and independently under failures while maintaining good\naccuracy. Specifically, we formulate our approach as a multi-objective\noptimization problem with a loss formulation that inherently encourages\ndiversity among individual models to promote mutually refining representations,\nwhile ensuring each model maintains good standalone performance. Empirical\nevaluations across vision, language, and audio datasets show that MEL provides\nperformance comparable to original architectures while also providing fault\ntolerance and deployment flexibility across edge platforms. Our results show\nthat our ensemble model, sized at 40\\% of the original model, achieves similar\nperformance, while preserving 95.6\\% of ensemble accuracy in the case of\nfailures when trained using MEL.", "AI": {"tldr": "Proposes Multi-Level Ensemble Learning (MEL) for resilient edge inference, balancing accuracy and fault tolerance with lightweight backup models.", "motivation": "Edge environments are power- and resource-constrained, and conventional resilience methods compromise latency or accuracy.", "method": "MEL trains multiple lightweight backup models collaboratively, formulated as a multi-objective optimization problem encouraging diversity and standalone performance.", "result": "MEL achieves performance comparable to original models (40% size) and retains 95.6% accuracy during failures.", "conclusion": "MEL provides effective fault tolerance and deployment flexibility for edge inference without compromising accuracy."}}
{"id": "2506.20642", "pdf": "https://arxiv.org/pdf/2506.20642", "abs": "https://arxiv.org/abs/2506.20642", "authors": ["Chao Wan", "Albert Gong", "Mihir Mishra", "Carl-Leander Henneking", "Claas Beger", "Kilian Q. Weinberger"], "title": "Memento: Note-Taking for Your Future Self", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel at reasoning-only tasks, but struggle when\nreasoning must be tightly coupled with retrieval, as in multi-hop question\nanswering. To overcome these limitations, we introduce a prompting strategy\nthat first decomposes a complex question into smaller steps, then dynamically\nconstructs a database of facts using LLMs, and finally pieces these facts\ntogether to solve the question. We show how this three-stage strategy, which we\ncall Memento, can boost the performance of existing prompting strategies across\ndiverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the\nperformance of chain-of-thought (CoT) when all information is provided in\ncontext. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento\nimproves over vanilla CoT-RAG by more than 20 F1 percentage points and over the\nmulti-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the\nchallenging MuSiQue dataset, Memento improves ReAct by more than 3 F1\npercentage points, demonstrating its utility in agentic settings.", "AI": {"tldr": "Memento is a prompting strategy that decomposes complex questions, constructs a dynamic fact database, and solves them, significantly improving LLM performance in multi-hop QA tasks.", "motivation": "LLMs struggle with tasks requiring tight coupling of reasoning and retrieval, such as multi-hop QA. Memento aims to address this limitation.", "method": "Memento decomposes questions into steps, builds a dynamic fact database using LLMs, and combines facts to solve questions.", "result": "Memento doubles CoT performance on PhantomWiki, improves CoT-RAG by 20 F1 points on 2WikiMultiHopQA, and boosts ReAct by 3 F1 points on MuSiQue.", "conclusion": "Memento effectively enhances LLM performance in multi-hop QA by integrating reasoning and retrieval dynamically."}}
{"id": "2506.20550", "pdf": "https://arxiv.org/pdf/2506.20550", "abs": "https://arxiv.org/abs/2506.20550", "authors": ["Yitong Quan", "Benjamin Kiefer", "Martin Messmer", "Andreas Zell"], "title": "Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos", "categories": ["cs.CV", "cs.RO"], "comment": "Submitted to ECMR 2025", "summary": "Modern image-based object detection models, such as YOLOv7, primarily process\nindividual frames independently, thus ignoring valuable temporal context\nnaturally present in videos. Meanwhile, existing video-based detection methods\noften introduce complex temporal modules, significantly increasing model size\nand computational complexity. In practical applications such as surveillance\nand autonomous driving, transient challenges including motion blur, occlusions,\nand abrupt appearance changes can severely degrade single-frame detection\nperformance. To address these issues, we propose a straightforward yet highly\neffective strategy: stacking multiple consecutive frames as input to a\nYOLO-based detector while supervising only the output corresponding to a single\ntarget frame. This approach leverages temporal information with minimal\nmodifications to existing architectures, preserving simplicity, computational\nefficiency, and real-time inference capability. Extensive experiments on the\nchallenging MOT20Det and our BOAT360 datasets demonstrate that our method\nimproves detection robustness, especially for lightweight models, effectively\nnarrowing the gap between compact and heavy detection networks. Additionally,\nwe contribute the BOAT360 benchmark dataset, comprising annotated fisheye video\nsequences captured from a boat, to support future research in multi-frame video\nobject detection in challenging real-world scenarios.", "AI": {"tldr": "The paper proposes a simple method to improve video object detection by stacking consecutive frames as input to a YOLO-based detector, leveraging temporal context without complex modifications.", "motivation": "Single-frame detection models ignore temporal context in videos, while existing video-based methods are complex and computationally heavy. Practical applications face challenges like motion blur and occlusions.", "method": "Stack multiple consecutive frames as input to a YOLO-based detector, supervising only the target frame's output.", "result": "Improves detection robustness, especially for lightweight models, and narrows the gap between compact and heavy networks. Validated on MOT20Det and BOAT360 datasets.", "conclusion": "The method effectively leverages temporal information with minimal architectural changes, maintaining simplicity and efficiency. The BOAT360 dataset is introduced to support future research."}}
{"id": "2506.19880", "pdf": "https://arxiv.org/pdf/2506.19880", "abs": "https://arxiv.org/abs/2506.19880", "authors": ["Stefanos Achlatis", "Efstratios Gavves", "Jan-Jakob Sonke"], "title": "Physics-Guided Radiotherapy Treatment Planning with Deep Learning", "categories": ["physics.med-ph", "cs.AI"], "comment": null, "summary": "Radiotherapy (RT) is a critical cancer treatment, with volumetric modulated\narc therapy (VMAT) being a commonly used technique that enhances dose\nconformity by dynamically adjusting multileaf collimator (MLC) positions and\nmonitor units (MU) throughout gantry rotation. Adaptive radiotherapy requires\nfrequent modifications to treatment plans to account for anatomical variations,\nnecessitating time-efficient solutions. Deep learning offers a promising\nsolution to automate this process. To this end, we propose a two-stage,\nphysics-guided deep learning pipeline for radiotherapy planning. In the first\nstage, our network is trained with direct supervision on treatment plan\nparameters, consisting of MLC and MU values. In the second stage, we\nincorporate an additional supervision signal derived from the predicted 3D dose\ndistribution, integrating physics-based guidance into the training process. We\ntrain and evaluate our approach on 133 prostate cancer patients treated with a\nuniform 2-arc VMAT protocol delivering a dose of 62 Gy to the planning target\nvolume (PTV). Our results demonstrate that the proposed approach, implemented\nusing both 3D U-Net and UNETR architectures, consistently produces treatment\nplans that closely match clinical ground truths. Our method achieves a mean\ndifference of D95% = 0.42 +/- 1.83 Gy and V95% = -0.22 +/- 1.87% at the PTV\nwhile generating dose distributions that reduce radiation exposure to organs at\nrisk. These findings highlight the potential of physics-guided deep learning in\nRT planning.", "AI": {"tldr": "A two-stage, physics-guided deep learning pipeline automates radiotherapy planning, achieving results close to clinical standards while reducing radiation exposure to organs at risk.", "motivation": "Adaptive radiotherapy requires frequent plan modifications due to anatomical changes, and deep learning can automate this process efficiently.", "method": "A two-stage pipeline: first, training with direct supervision on treatment plan parameters (MLC and MU values); second, incorporating physics-based guidance from predicted 3D dose distribution.", "result": "The method achieves close matches to clinical ground truths (D95% = 0.42 +/- 1.83 Gy, V95% = -0.22 +/- 1.87%) and reduces radiation to organs at risk.", "conclusion": "Physics-guided deep learning shows promise for improving radiotherapy planning efficiency and accuracy."}}
{"id": "2506.20132", "pdf": "https://arxiv.org/pdf/2506.20132", "abs": "https://arxiv.org/abs/2506.20132", "authors": ["Patrick Alan Johnson", "Gabriel Tseng", "Yawen Zhang", "Heather Heward", "Virginia Sjahli", "Favyen Bastani", "Joseph Redmon", "Patrick Beukema"], "title": "High-Resolution Live Fuel Moisture Content (LFMC) Maps for Wildfire Risk from Multimodal Earth Observation Data", "categories": ["cs.LG"], "comment": "10 pages, ICML 2025 (TerraBytes)", "summary": "Wildfires are increasing in intensity and severity at an alarming rate.\nRecent advances in AI and publicly available satellite data enable monitoring\ncritical wildfire risk factors globally, at high resolution and low latency.\nLive Fuel Moisture Content (LFMC) is a critical wildfire risk factor and is\nvaluable for both wildfire research and operational response. However,\nground-based LFMC samples are both labor intensive and costly to acquire,\nresulting in sparse and infrequent updates. In this work, we explore the use of\na pretrained, highly-multimodal earth-observation model for generating\nlarge-scale spatially complete (wall-to-wall) LFMC maps. Our approach achieves\nsignificant improvements over previous methods using randomly initialized\nmodels (20 reduction in RMSE). We provide an automated pipeline that enables\nrapid generation of these LFMC maps across the United States, and demonstrate\nits effectiveness in two regions recently impacted by wildfire (Eaton and\nPalisades).", "AI": {"tldr": "The paper proposes using a pretrained multimodal earth-observation model to create large-scale, high-resolution LFMC maps for wildfire risk monitoring, improving accuracy by 20% over previous methods.", "motivation": "Wildfires are intensifying, and ground-based LFMC sampling is costly and sparse. AI and satellite data offer a scalable solution for real-time monitoring.", "method": "A pretrained, multimodal earth-observation model is used to generate spatially complete LFMC maps, tested in wildfire-impacted regions.", "result": "The method reduces RMSE by 20% compared to randomly initialized models, enabling rapid LFMC map generation across the U.S.", "conclusion": "The approach provides a scalable, accurate solution for wildfire risk monitoring, validated in real-world scenarios."}}
{"id": "2506.20666", "pdf": "https://arxiv.org/pdf/2506.20666", "abs": "https://arxiv.org/abs/2506.20666", "authors": ["Sonia K. Murthy", "Rosie Zhao", "Jennifer Hu", "Sham Kakade", "Markus Wulfmeier", "Peng Qian", "Tomer Ullman"], "title": "Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "Navigating everyday social situations often requires juggling conflicting\ngoals, such as conveying a harsh truth, maintaining trust, all while still\nbeing mindful of another person's feelings. These value trade-offs are an\nintegral part of human decision-making and language use, however, current tools\nfor interpreting such dynamic and multi-faceted notions of values in LLMs are\nlimited. In cognitive science, so-called \"cognitive models\" provide formal\naccounts of these trade-offs in humans, by modeling the weighting of a\nspeaker's competing utility functions in choosing an action or utterance. In\nthis work, we use a leading cognitive model of polite speech to interpret the\nextent to which LLMs represent human-like trade-offs. We apply this lens to\nsystematically evaluate value trade-offs in two encompassing model settings:\ndegrees of reasoning \"effort\" in frontier black-box models, and RL\npost-training dynamics of open-source models. Our results highlight patterns of\nhigher informational utility than social utility in reasoning models, and in\nopen-source models shown to be stronger in mathematical reasoning. Our findings\nfrom LLMs' training dynamics suggest large shifts in utility values early on in\ntraining with persistent effects of the choice of base model and pretraining\ndata, compared to feedback dataset or alignment method. We show that our method\nis responsive to diverse aspects of the rapidly evolving LLM landscape, with\ninsights for forming hypotheses about other high-level behaviors, shaping\ntraining regimes for reasoning models, and better controlling trade-offs\nbetween values during model training.", "AI": {"tldr": "The paper explores how LLMs handle human-like value trade-offs, like balancing honesty and politeness, using cognitive models to evaluate their behavior in reasoning and training dynamics.", "motivation": "Current tools for interpreting dynamic value trade-offs in LLMs are limited, despite their importance in human decision-making and language use.", "method": "A cognitive model of polite speech is applied to evaluate LLMs in two settings: reasoning effort in black-box models and RL post-training dynamics in open-source models.", "result": "LLMs show higher informational utility than social utility in reasoning models, with training dynamics revealing early shifts in utility values influenced by base model and pretraining data.", "conclusion": "The method offers insights for shaping LLM training regimes, controlling value trade-offs, and forming hypotheses about high-level behaviors."}}
{"id": "2506.20563", "pdf": "https://arxiv.org/pdf/2506.20563", "abs": "https://arxiv.org/abs/2506.20563", "authors": ["Lei Zhu", "Jun Zhou", "Rick Siow Mong Goh", "Yong Liu"], "title": "AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation", "categories": ["cs.CV"], "comment": "Accepted to MICCAI 2025", "summary": "Vision Transformer has recently gained tremendous popularity in medical image\nsegmentation task due to its superior capability in capturing long-range\ndependencies. However, transformer requires a large amount of labeled data to\nbe effective, which hinders its applicability in annotation scarce\nsemi-supervised learning scenario where only limited labeled data is available.\nState-of-the-art semi-supervised learning methods propose combinatorial\nCNN-Transformer learning to cross teach a transformer with a convolutional\nneural network, which achieves promising results. However, it remains a\nchallenging task to effectively train the transformer with limited labeled\ndata. In this paper, we propose an adversarial masked image modeling method to\nfully unleash the potential of transformer for semi-supervised medical image\nsegmentation. The key challenge in semi-supervised learning with transformer\nlies in the lack of sufficient supervision signal. To this end, we propose to\nconstruct an auxiliary masked domain from original domain with masked image\nmodeling and train the transformer to predict the entire segmentation mask with\nmasked inputs to increase supervision signal. We leverage the original labels\nfrom labeled data and pseudo-labels from unlabeled data to learn the masked\ndomain. To further benefit the original domain from masked domain, we provide a\ntheoretical analysis of our method from a multi-domain learning perspective and\ndevise a novel adversarial training loss to reduce the domain gap between the\noriginal and masked domain, which boosts semi-supervised learning performance.\nWe also extend adversarial masked image modeling to CNN network. Extensive\nexperiments on three public medical image segmentation datasets demonstrate the\neffectiveness of our method, where our method outperforms existing methods\nsignificantly. Our code is publicly available at\nhttps://github.com/zlheui/AdvMIM.", "AI": {"tldr": "The paper proposes an adversarial masked image modeling method to enhance transformer performance in semi-supervised medical image segmentation, leveraging masked inputs and adversarial training to bridge domain gaps.", "motivation": "Transformers require large labeled datasets, limiting their use in semi-supervised scenarios with scarce annotations. Existing methods struggle to train transformers effectively with limited labeled data.", "method": "The method constructs an auxiliary masked domain using masked image modeling, trains the transformer to predict full masks from masked inputs, and employs adversarial training to reduce domain gaps.", "result": "Extensive experiments on three datasets show the method significantly outperforms existing approaches.", "conclusion": "The proposed adversarial masked image modeling effectively boosts semi-supervised learning for medical image segmentation, with code publicly available."}}
{"id": "2506.19884", "pdf": "https://arxiv.org/pdf/2506.19884", "abs": "https://arxiv.org/abs/2506.19884", "authors": ["Zhengxiang Huang", "Chaoyue Niu", "Zhaode Wang", "Jiarui Xue", "Hanming Zhang", "Yugang Wang", "Zewei Xin", "Xiaotang Jiang", "Chengfei Lv", "Fan Wu", "Guihai Chen"], "title": "MNN-AECS: Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection", "categories": ["cs.OS", "cs.AI", "cs.PF", "cs.SE"], "comment": null, "summary": "As the demand for on-device Large Language Model (LLM) inference grows,\nenergy efficiency has become a major concern, especially for battery-limited\nmobile devices. Our analysis shows that the memory-bound LLM decode phase\ndominates energy use, and yet most existing works focus on accelerating the\nprefill phase, neglecting energy concerns. We introduce Adaptive Energy-Centric\nCore Selection (AECS) and integrate it into MNN to create the energy-efficient\nversion, MNN-AECS, the first engine-level system solution without requiring\nroot access or OS modifications for energy-efficient LLM decoding. MNN-AECS is\ndesigned to reduce LLM decoding energy while keeping decode speed within an\nacceptable slowdown threshold by dynamically selecting low-power CPU cores.\nMNN-AECS is evaluated across 5 Android and 2 iOS devices on 5 popular LLMs of\nvarious sizes. Compared to original MNN, MNN-AECS cuts down energy use by 23%\nwithout slowdown averaged over all 7 devices and 4 datasets. Against other\nengines, including llama.cpp, executorch, mllm, and MediaPipe, MNN-AECS\ndelivers 39% to 78% energy saving and 12% to 363% speedup on average.", "AI": {"tldr": "MNN-AECS is an energy-efficient system for LLM decoding on mobile devices, reducing energy use by 23% without slowdown by dynamically selecting low-power CPU cores.", "motivation": "Energy efficiency is critical for on-device LLM inference, especially on battery-limited mobile devices, with the decode phase being a major energy consumer.", "method": "Introduces Adaptive Energy-Centric Core Selection (AECS) integrated into MNN, dynamically selecting low-power CPU cores to balance energy and speed.", "result": "MNN-AECS reduces energy use by 23% without slowdown, outperforming other engines with 39-78% energy savings and 12-363% speedup.", "conclusion": "MNN-AECS is a practical, efficient solution for energy-aware LLM decoding on mobile devices without requiring root access or OS changes."}}
{"id": "2506.20169", "pdf": "https://arxiv.org/pdf/2506.20169", "abs": "https://arxiv.org/abs/2506.20169", "authors": ["Bala Rajesh Konkathi", "Arun K. Tangirala"], "title": "Causal discovery in deterministic discrete LTI-DAE systems", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY", "stat.ME"], "comment": null, "summary": "Discovering pure causes or driver variables in deterministic LTI systems is\nof vital importance in the data-driven reconstruction of causal networks. A\nrecent work by Kathari and Tangirala, proposed in 2022, formulated the causal\ndiscovery method as a constraint identification problem. The constraints are\nidentified using a dynamic iterative PCA (DIPCA)-based approach for dynamical\nsystems corrupted with Gaussian measurement errors. The DIPCA-based method\nworks efficiently for dynamical systems devoid of any algebraic relations.\nHowever, several dynamical systems operate under feedback control and/or are\ncoupled with conservation laws, leading to differential-algebraic (DAE) or\nmixed causal systems. In this work, a method, namely the partition of variables\n(PoV), for causal discovery in LTI-DAE systems is proposed. This method is\nsuperior to the method that was presented by Kathari and Tangirala (2022), as\nPoV also works for pure dynamical systems, which are devoid of algebraic\nequations. The proposed method identifies the causal drivers up to a minimal\nsubset. PoV deploys DIPCA to first determine the number of algebraic relations\n($n_a$), the number of dynamical relations ($n_d$) and the constraint matrix.\nSubsequently, the subsets are identified through an admissible partitioning of\nthe constraint matrix by finding the condition number of it. Case studies are\npresented to demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "The paper proposes a method called Partition of Variables (PoV) for causal discovery in LTI-DAE systems, improving upon a 2022 method by Kathari and Tangirala. PoV handles systems with algebraic relations and identifies causal drivers efficiently.", "motivation": "Existing methods like DIPCA fail for dynamical systems with algebraic relations (DAE systems). The need for a robust causal discovery method in such systems drives this work.", "method": "PoV uses DIPCA to identify algebraic and dynamical relations, then partitions variables via the constraint matrix's condition number to find causal drivers.", "result": "PoV successfully identifies causal drivers in LTI-DAE systems, outperforming the 2022 method by handling both pure dynamical and mixed systems.", "conclusion": "PoV is a superior method for causal discovery in LTI-DAE systems, addressing limitations of prior work and demonstrating effectiveness through case studies."}}
{"id": "2506.16571", "pdf": "https://arxiv.org/pdf/2506.16571", "abs": "https://arxiv.org/abs/2506.16571", "authors": ["Maeve Hutchinson", "Radu Jianu", "Aidan Slingsby", "Jo Wood", "Pranava Madhyastha"], "title": "Capturing Visualization Design Rationale", "categories": ["cs.HC", "cs.CL"], "comment": null, "summary": "Prior natural language datasets for data visualization have focused on tasks\nsuch as visualization literacy assessment, insight generation, and\nvisualization generation from natural language instructions. These studies\noften rely on controlled setups with purpose-built visualizations and\nartificially constructed questions. As a result, they tend to prioritize the\ninterpretation of visualizations, focusing on decoding visualizations rather\nthan understanding their encoding. In this paper, we present a new dataset and\nmethodology for probing visualization design rationale through natural\nlanguage. We leverage a unique source of real-world visualizations and natural\nlanguage narratives: literate visualization notebooks created by students as\npart of a data visualization course. These notebooks combine visual artifacts\nwith design exposition, in which students make explicit the rationale behind\ntheir design decisions. We also use large language models (LLMs) to generate\nand categorize question-answer-rationale triples from the narratives and\narticulations in the notebooks. We then carefully validate the triples and\ncurate a dataset that captures and distills the visualization design choices\nand corresponding rationales of the students.", "AI": {"tldr": "A new dataset and methodology for probing visualization design rationale using real-world literate visualization notebooks and LLMs.", "motivation": "Existing datasets focus on interpreting visualizations, not understanding their encoding or design rationale.", "method": "Leverage student-created literate visualization notebooks and LLMs to generate and validate question-answer-rationale triples.", "result": "A curated dataset capturing visualization design choices and rationales.", "conclusion": "The approach bridges the gap in understanding visualization encoding and design rationale."}}
{"id": "2506.20567", "pdf": "https://arxiv.org/pdf/2506.20567", "abs": "https://arxiv.org/abs/2506.20567", "authors": ["Zhiwang Zhang", "Dong Xu", "Wanli Ouyang", "Chuanqi Tan"], "title": "Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages", "summary": "In this work, we propose a division-and-summarization (DaS) framework for\ndense video captioning. After partitioning each untrimmed long video as\nmultiple event proposals, where each event proposal consists of a set of short\nvideo segments, we extract visual feature (e.g., C3D feature) from each segment\nand use the existing image/video captioning approach to generate one sentence\ndescription for this segment. Considering that the generated sentences contain\nrich semantic descriptions about the whole event proposal, we formulate the\ndense video captioning task as a visual cue aided sentence summarization\nproblem and propose a new two stage Long Short Term Memory (LSTM) approach\nequipped with a new hierarchical attention mechanism to summarize all generated\nsentences as one descriptive sentence with the aid of visual features.\nSpecifically, the first-stage LSTM network takes all semantic words from the\ngenerated sentences and the visual features from all segments within one event\nproposal as the input, and acts as the encoder to effectively summarize both\nsemantic and visual information related to this event proposal. The\nsecond-stage LSTM network takes the output from the first-stage LSTM network\nand the visual features from all video segments within one event proposal as\nthe input, and acts as the decoder to generate one descriptive sentence for\nthis event proposal. Our comprehensive experiments on the ActivityNet Captions\ndataset demonstrate the effectiveness of our newly proposed DaS framework for\ndense video captioning.", "AI": {"tldr": "A division-and-summarization (DaS) framework for dense video captioning partitions videos into event proposals, generates segment descriptions, and summarizes them into a single sentence using a two-stage LSTM with hierarchical attention.", "motivation": "To address the challenge of dense video captioning by leveraging visual and semantic information from video segments.", "method": "Partition videos into event proposals, extract visual features, generate segment descriptions, and summarize using a two-stage LSTM with hierarchical attention.", "result": "Effective performance demonstrated on the ActivityNet Captions dataset.", "conclusion": "The DaS framework successfully combines visual and semantic cues for dense video captioning."}}
{"id": "2506.19889", "pdf": "https://arxiv.org/pdf/2506.19889", "abs": "https://arxiv.org/abs/2506.19889", "authors": ["Wanli Peng", "Xin Chen", "Hang Fu", "XinYu He", "Xue Yiming", "Juan Wen"], "title": "Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have made a profound impact\non our society and also raised new security concerns. Particularly, due to the\nremarkable inference ability of LLMs, the privacy violation attack (PVA),\nrevealed by Staab et al., introduces serious personal privacy issues. Existing\ndefense methods mainly leverage LLMs to anonymize the input query, which\nrequires costly inference time and cannot gain satisfactory defense\nperformance. Moreover, directly rejecting the PVA query seems like an effective\ndefense method, while the defense method is exposed, promoting the evolution of\nPVA. In this paper, we propose a novel defense paradigm based on\nretrieval-confused generation (RCG) of LLMs, which can efficiently and covertly\ndefend the PVA. We first design a paraphrasing prompt to induce the LLM to\nrewrite the \"user comments\" of the attack query to construct a disturbed\ndatabase. Then, we propose the most irrelevant retrieval strategy to retrieve\nthe desired user data from the disturbed database. Finally, the \"data comments\"\nare replaced with the retrieved user data to form a defended query, leading to\nresponding to the adversary with some wrong personal attributes, i.e., the\nattack fails. Extensive experiments are conducted on two datasets and eight\npopular LLMs to comprehensively evaluate the feasibility and the superiority of\nthe proposed defense method.", "AI": {"tldr": "The paper introduces a novel defense method, retrieval-confused generation (RCG), to counter privacy violation attacks (PVAs) in large language models (LLMs) by perturbing queries and retrieving irrelevant data to mislead attackers.", "motivation": "Addressing the serious privacy concerns raised by PVAs in LLMs, the paper aims to develop an efficient and covert defense method that outperforms existing anonymization and query rejection approaches.", "method": "The proposed RCG method involves paraphrasing attack queries to create a disturbed database, retrieving irrelevant user data, and replacing original data to mislead adversaries.", "result": "Experiments on two datasets and eight LLMs demonstrate the method's effectiveness in defending against PVAs by causing attack failures.", "conclusion": "The RCG-based defense paradigm is a feasible and superior solution for protecting privacy in LLMs against evolving PVAs."}}
{"id": "2506.20181", "pdf": "https://arxiv.org/pdf/2506.20181", "abs": "https://arxiv.org/abs/2506.20181", "authors": ["Ronald Katende"], "title": "Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We develop a principled framework for discovering causal structure in partial\ndifferential equations (PDEs) using physics-informed neural networks and\ncounterfactual perturbations. Unlike classical residual minimization or sparse\nregression methods, our approach quantifies operator-level necessity through\nfunctional interventions on the governing dynamics. We introduce causal\nsensitivity indices and structural deviation metrics to assess the influence of\ncandidate differential operators within neural surrogates. Theoretically, we\nprove exact recovery of the causal operator support under restricted isometry\nor mutual coherence conditions, with residual bounds guaranteeing\nidentifiability. Empirically, we validate the framework on both synthetic and\nreal-world datasets across climate dynamics, tumor diffusion, and ocean flows.\nOur method consistently recovers governing operators even under noise,\nredundancy, and data scarcity, outperforming standard PINNs and DeepONets in\nstructural fidelity. This work positions causal PDE discovery as a tractable\nand interpretable inference task grounded in structural causal models and\nvariational residual analysis.", "AI": {"tldr": "A framework for discovering causal structure in PDEs using physics-informed neural networks and counterfactual perturbations, outperforming traditional methods in accuracy and robustness.", "motivation": "To address limitations of classical methods like residual minimization or sparse regression in identifying causal operators in PDEs, by introducing a more interpretable and robust approach.", "method": "Uses physics-informed neural networks and counterfactual perturbations to quantify operator-level necessity, with causal sensitivity indices and structural deviation metrics for assessment.", "result": "Theoretically proven exact recovery of causal operator support under certain conditions, with empirical validation on synthetic and real-world datasets showing superior performance over standard methods.", "conclusion": "The framework successfully positions causal PDE discovery as a tractable and interpretable task, grounded in structural causal models and variational residual analysis."}}
{"id": "2506.20097", "pdf": "https://arxiv.org/pdf/2506.20097", "abs": "https://arxiv.org/abs/2506.20097", "authors": ["Wang Bill Zhu", "Miaosen Chai", "Ishika Singh", "Robin Jia", "Jesse Thomason"], "title": "PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models", "categories": ["cs.RO", "cs.CL"], "comment": null, "summary": "We propose PSALM-V, the first autonomous neuro-symbolic learning system able\nto induce symbolic action semantics (i.e., pre- and post-conditions) in visual\nenvironments through interaction. PSALM-V bootstraps reliable symbolic planning\nwithout expert action definitions, using LLMs to generate heuristic plans and\ncandidate symbolic semantics. Previous work has explored using large language\nmodels to generate action semantics for Planning Domain Definition Language\n(PDDL)-based symbolic planners. However, these approaches have primarily\nfocused on text-based domains or relied on unrealistic assumptions, such as\naccess to a predefined problem file, full observability, or explicit error\nmessages. By contrast, PSALM-V dynamically infers PDDL problem files and domain\naction semantics by analyzing execution outcomes and synthesizing possible\nerror explanations. The system iteratively generates and executes plans while\nmaintaining a tree-structured belief over possible action semantics for each\naction, iteratively refining these beliefs until a goal state is reached.\nSimulated experiments of task completion in ALFRED demonstrate that PSALM-V\nincreases the plan success rate from 37% (Claude-3.7) to 74% in partially\nobserved setups. Results on two 2D game environments, RTFM and Overcooked-AI,\nshow that PSALM-V improves step efficiency and succeeds in domain induction in\nmulti-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions\nfor real-world robot BlocksWorld tasks, despite low-level manipulation failures\nfrom the robot.", "AI": {"tldr": "PSALM-V is an autonomous neuro-symbolic system that learns symbolic action semantics in visual environments, improving plan success rates and domain induction without expert input.", "motivation": "Existing methods rely on unrealistic assumptions or text-based domains, limiting their applicability in visual or partially observed environments.", "method": "PSALM-V uses LLMs to generate heuristic plans and candidate semantics, dynamically infers PDDL problem files, and iteratively refines beliefs about action semantics.", "result": "PSALM-V increases plan success rates from 37% to 74% in ALFRED and improves efficiency in 2D game environments and real-world robot tasks.", "conclusion": "PSALM-V advances autonomous learning in visual environments by reliably inducing symbolic action semantics without expert definitions."}}
{"id": "2506.20582", "pdf": "https://arxiv.org/pdf/2506.20582", "abs": "https://arxiv.org/abs/2506.20582", "authors": ["Rajat Rasal", "Avinash Kori", "Ben Glocker"], "title": "Causal Representation Learning with Observational Grouping for CXR Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Identifiable causal representation learning seeks to uncover the true causal\nrelationships underlying a data generation process. In medical imaging, this\npresents opportunities to improve the generalisability and robustness of\ntask-specific latent features. This work introduces the concept of grouping\nobservations to learn identifiable representations for disease classification\nin chest X-rays via an end-to-end framework. Our experiments demonstrate that\nthese causal representations improve generalisability and robustness across\nmultiple classification tasks when grouping is used to enforce invariance w.r.t\nrace, sex, and imaging views.", "AI": {"tldr": "The paper introduces an end-to-end framework for learning identifiable causal representations in medical imaging, improving generalisability and robustness in disease classification tasks.", "motivation": "To uncover true causal relationships in medical imaging data for better generalisability and robustness in disease classification.", "method": "Grouping observations to enforce invariance with respect to race, sex, and imaging views in an end-to-end framework.", "result": "Causal representations improve generalisability and robustness across multiple classification tasks.", "conclusion": "Grouping observations for identifiable causal representations enhances performance in medical imaging tasks."}}
{"id": "2506.19892", "pdf": "https://arxiv.org/pdf/2506.19892", "abs": "https://arxiv.org/abs/2506.19892", "authors": ["Isaac Marroqui Penalva", "Enrique Tom\u00e1s Mart\u00ednez Beltr\u00e1n", "Manuel Gil P\u00e9rez", "Alberto Huertas Celdr\u00e1n"], "title": "RepuNet: A Reputation System for Mitigating Malicious Clients in DFL", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG", "cs.PF"], "comment": null, "summary": "Decentralized Federated Learning (DFL) enables nodes to collaboratively train\nmodels without a central server, introducing new vulnerabilities since each\nnode independently selects peers for model aggregation. Malicious nodes may\nexploit this autonomy by sending corrupted models (model poisoning), delaying\nmodel submissions (delay attack), or flooding the network with excessive\nmessages, negatively affecting system performance. Existing solutions often\ndepend on rigid configurations or additional infrastructures such as\nblockchain, leading to computational overhead, scalability issues, or limited\nadaptability. To overcome these limitations, this paper proposes RepuNet, a\ndecentralized reputation system that categorizes threats in DFL and dynamically\nevaluates node behavior using metrics like model similarity, parameter changes,\nmessage latency, and communication volume. Nodes' influence in model\naggregation is adjusted based on their reputation scores. RepuNet was\nintegrated into the Nebula DFL platform and experimentally evaluated with MNIST\nand CIFAR-10 datasets under non-IID distributions, using federations of up to\n25 nodes in both fully connected and random topologies. Different attack\nintensities, frequencies, and activation intervals were tested. Results\ndemonstrated that RepuNet effectively detects and mitigates malicious behavior,\nachieving F1 scores above 95% for MNIST scenarios and approximately 76% for\nCIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness,\nand practical potential for mitigating threats in decentralized federated\nlearning environments.", "AI": {"tldr": "RepuNet is a decentralized reputation system for DFL that dynamically evaluates node behavior to mitigate threats like model poisoning and delay attacks, achieving high detection accuracy.", "motivation": "Existing DFL solutions suffer from computational overhead, scalability issues, or limited adaptability due to rigid configurations or additional infrastructures like blockchain.", "method": "RepuNet categorizes threats and evaluates node behavior using metrics (model similarity, parameter changes, latency, communication volume), adjusting influence based on reputation scores.", "result": "RepuNet achieved F1 scores above 95% for MNIST and ~76% for CIFAR-10, effectively detecting and mitigating malicious behavior.", "conclusion": "RepuNet is adaptable, robust, and practical for securing decentralized federated learning environments."}}
{"id": "2506.20194", "pdf": "https://arxiv.org/pdf/2506.20194", "abs": "https://arxiv.org/abs/2506.20194", "authors": ["Ruokai Yin", "Yuhang Li", "Donghyun Lee", "Priyadarshini Panda"], "title": "DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) deliver strong performance but are difficult to\ndeploy due to high memory and compute costs. While pruning reduces these\ndemands, most methods ignore activation sparsity observed at runtime. We\nreinterpret activation sparsity as dynamic structured weight sparsity and\npropose DuoGPT, a unified framework that constructs dual-sparse (spMspV)\nworkloads by combining unstructured weight pruning with activation sparsity. To\npreserve accuracy, we extend the Optimal Brain Compression (OBC) framework with\nactivation-aware calibration and introduce output residuals from the dense\nmodel as correction terms. We further optimize the solution for efficient GPU\nexecution, enabling scalability to billion-parameter LLMs. Evaluations on\nLLaMA-2 and LLaMA-3 show that DuoGPT outperforms state-of-the-art structured\npruning methods by up to 9.17% accuracy at an iso-speedup of 1.39$\\times$\ncompared to the baseline dense model.", "AI": {"tldr": "DuoGPT combines unstructured weight pruning and activation sparsity to reduce LLM deployment costs while maintaining accuracy, outperforming existing methods.", "motivation": "High memory and compute costs of LLMs hinder deployment, and existing pruning methods often ignore runtime activation sparsity.", "method": "DuoGPT integrates unstructured weight pruning with activation sparsity, using activation-aware calibration and dense model residuals for accuracy.", "result": "DuoGPT achieves up to 9.17% better accuracy than state-of-the-art methods at a 1.39\u00d7 speedup.", "conclusion": "DuoGPT effectively balances performance and efficiency, scaling well for billion-parameter LLMs."}}
{"id": "2506.20268", "pdf": "https://arxiv.org/pdf/2506.20268", "abs": "https://arxiv.org/abs/2506.20268", "authors": ["Ruben Janssens", "Jens De Bock", "Sofie Labat", "Eva Verhelst", "Veronique Hoste", "Tony Belpaeme"], "title": "Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue", "categories": ["cs.RO", "cs.CL", "cs.HC"], "comment": "Accepted at the 34th IEEE International Conference on Robot and Human\n  Interactive Communication (RO-MAN 2025)", "summary": "Detecting miscommunication in human-robot interaction is a critical function\nfor maintaining user engagement and trust. While humans effortlessly detect\ncommunication errors in conversations through both verbal and non-verbal cues,\nrobots face significant challenges in interpreting non-verbal feedback, despite\nadvances in computer vision for recognizing affective expressions. This\nresearch evaluates the effectiveness of machine learning models in detecting\nmiscommunications in robot dialogue. Using a multi-modal dataset of 240\nhuman-robot conversations, where four distinct types of conversational failures\nwere systematically introduced, we assess the performance of state-of-the-art\ncomputer vision models. After each conversational turn, users provided feedback\non whether they perceived an error, enabling an analysis of the models' ability\nto accurately detect robot mistakes. Despite using state-of-the-art models, the\nperformance barely exceeds random chance in identifying miscommunication, while\non a dataset with more expressive emotional content, they successfully\nidentified confused states. To explore the underlying cause, we asked human\nraters to do the same. They could also only identify around half of the induced\nmiscommunications, similarly to our model. These results uncover a fundamental\nlimitation in identifying robot miscommunications in dialogue: even when users\nperceive the induced miscommunication as such, they often do not communicate\nthis to their robotic conversation partner. This knowledge can shape\nexpectations of the performance of computer vision models and can help\nresearchers to design better human-robot conversations by deliberately\neliciting feedback where needed.", "AI": {"tldr": "The paper evaluates machine learning models for detecting miscommunication in human-robot dialogue, finding limited success due to users not clearly signaling errors.", "motivation": "To improve human-robot interaction by addressing challenges in detecting miscommunication, which is crucial for user trust and engagement.", "method": "Used a multi-modal dataset of 240 human-robot conversations with induced errors, tested state-of-the-art computer vision models, and compared with human raters.", "result": "Models performed slightly better than random chance in detecting miscommunication but succeeded in identifying confused states. Human raters also struggled, detecting only half of the errors.", "conclusion": "The study reveals a fundamental limitation in detecting robot miscommunications due to unclear user feedback, suggesting the need for better feedback mechanisms in human-robot dialogue design."}}
{"id": "2506.20583", "pdf": "https://arxiv.org/pdf/2506.20583", "abs": "https://arxiv.org/abs/2506.20583", "authors": ["Zhiwang Zhang", "Dong Xu", "Wanli Ouyang", "Luping Zhou"], "title": "Dense Video Captioning using Graph-based Sentence Summarization", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages", "summary": "Recently, dense video captioning has made attractive progress in detecting\nand captioning all events in a long untrimmed video. Despite promising results\nwere achieved, most existing methods do not sufficiently explore the scene\nevolution within an event temporal proposal for captioning, and therefore\nperform less satisfactorily when the scenes and objects change over a\nrelatively long proposal. To address this problem, we propose a graph-based\npartition-and-summarization (GPaS) framework for dense video captioning within\ntwo stages. For the ``partition\" stage, a whole event proposal is split into\nshort video segments for captioning at a finer level. For the ``summarization\"\nstage, the generated sentences carrying rich description information for each\nsegment are summarized into one sentence to describe the whole event. We\nparticularly focus on the ``summarization\" stage, and propose a framework that\neffectively exploits the relationship between semantic words for summarization.\nWe achieve this goal by treating semantic words as nodes in a graph and\nlearning their interactions by coupling Graph Convolutional Network (GCN) and\nLong Short Term Memory (LSTM), with the aid of visual cues. Two schemes of\nGCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN\nand LSTM. The effectiveness of our approach is demonstrated via an extensive\ncomparison with the state-of-the-arts methods on the two benchmarks ActivityNet\nCaptions dataset and YouCook II dataset.", "AI": {"tldr": "The paper proposes a graph-based partition-and-summarization (GPaS) framework for dense video captioning, addressing scene evolution in long event proposals by splitting and summarizing video segments.", "motivation": "Existing methods inadequately explore scene evolution in long event proposals, leading to suboptimal performance when scenes and objects change over time.", "method": "The GPaS framework splits event proposals into shorter segments for finer captioning (partition stage) and summarizes these into a single sentence (summarization stage) using a GCN-LSTM interaction module.", "result": "The approach outperforms state-of-the-art methods on ActivityNet Captions and YouCook II datasets.", "conclusion": "The GPaS framework effectively handles scene evolution in dense video captioning, improving performance through structured summarization of semantic words."}}
{"id": "2506.19897", "pdf": "https://arxiv.org/pdf/2506.19897", "abs": "https://arxiv.org/abs/2506.19897", "authors": ["Christopher Glasz", "Emily Escamilla", "Eric O. Scott", "Anand Patel", "Jacob Zimmer", "Colin Diggs", "Michael Doyle", "Scott Rosen", "Nitin Naik", "Justin F. Brunelle", "Samruddhi Thaker", "Parthav Poudel", "Arun Sridharan", "Amit Madan", "Doug Wendt", "William Macke", "Thomas Schill"], "title": "Can LLMs Replace Humans During Code Chunking?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have become essential tools in computer science,\nespecially for tasks involving code understanding and generation. However,\nexisting work does not address many of the unique challenges presented by code\nwritten for government applications. In particular, government enterprise\nsoftware is often written in legacy languages like MUMPS or assembly language\ncode (ALC) and the overall token lengths of these systems exceed the context\nwindow size for current commercially available LLMs. Additionally, LLMs are\nprimarily trained on modern software languages and have undergone limited\ntesting with legacy languages, making their ability to understand legacy\nlanguages unknown and, hence, an area for empirical study. This paper examines\nthe application of LLMs in the modernization of legacy government code written\nin ALC and MUMPS, addressing the challenges of input limitations. We\ninvestigate various code-chunking methods to optimize the generation of summary\nmodule comments for legacy code files, evaluating the impact of code-chunking\nmethods on the quality of documentation produced by different LLMs, including\nGPT-4o, Claude 3 Sonnet, Mixtral, and Llama 3. Our results indicate that LLMs\ncan select partition points closely aligned with human expert partitioning. We\nalso find that chunking approaches have significant impact on downstream tasks\nsuch as documentation generation. LLM-created partitions produce comments that\nare up to 20% more factual and up to 10% more useful than when humans create\npartitions. Therefore, we conclude that LLMs can be used as suitable\nreplacements for human partitioning of large codebases during LLM-aided\nmodernization.", "AI": {"tldr": "LLMs can effectively partition and document legacy government code (ALC/MUMPS), outperforming human partitioning in factual accuracy and usefulness.", "motivation": "Addressing the gap in LLM application for legacy government code, which involves unique challenges like legacy languages and large token lengths.", "method": "Investigates code-chunking methods for summary module comments, testing LLMs (GPT-4o, Claude 3, Mixtral, Llama 3) on legacy code.", "result": "LLMs align with human partitioning and improve documentation quality (20% more factual, 10% more useful).", "conclusion": "LLMs are suitable replacements for human partitioning in legacy code modernization."}}
{"id": "2506.20197", "pdf": "https://arxiv.org/pdf/2506.20197", "abs": "https://arxiv.org/abs/2506.20197", "authors": ["Cl\u00e9ment L. Canonne", "Yash Pote", "Uddalok Sarkar"], "title": "Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": "16 pages, 4 figures", "summary": "A growing fraction of all code is sampled from Large Language Models (LLMs).\nWe investigate the problem of attributing code generated by language models\nusing hypothesis testing to leverage established techniques and guarantees.\nGiven a set of samples $S$ and a suspect model $\\mathcal{L}^*$, our goal is to\nassess the likelihood of $S$ originating from $\\mathcal{L}^*$. Due to the curse\nof dimensionality, this is intractable when only samples from the LLM are\ngiven: to circumvent this, we use both samples and density estimates from the\nLLM, a form of access commonly available.\n  We introduce $\\mathsf{Anubis}$, a zero-shot attribution tool that frames\nattribution as a distribution testing problem. Our experiments on a benchmark\nof code samples show that $\\mathsf{Anubis}$ achieves high AUROC scores (\n$\\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and\nStable-Code using only $\\approx 2000$ samples.", "AI": {"tldr": "The paper introduces Anubis, a zero-shot tool for attributing code generated by LLMs using hypothesis testing and density estimates, achieving high accuracy with minimal samples.", "motivation": "To address the challenge of attributing code generated by LLMs due to the curse of dimensionality, leveraging available samples and density estimates.", "method": "Proposes Anubis, which frames attribution as a distribution testing problem, using samples and density estimates from LLMs for tractability.", "result": "Anubis achieves AUROC scores \u22650.9 in distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and Stable-Code with \u22482000 samples.", "conclusion": "Anubis effectively solves the attribution problem for LLM-generated code, demonstrating high accuracy and practicality."}}
{"id": "2506.20481", "pdf": "https://arxiv.org/pdf/2506.20481", "abs": "https://arxiv.org/abs/2506.20481", "authors": ["Matthieu Meeus", "Igor Shilov", "Georgios Kaissis", "Yves-Alexandre de Montjoye"], "title": "Counterfactual Influence as a Distributional Quantity", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": "Workshop on The Impact of Memorization on Trustworthy Foundation\n  Models (MemFM) @ ICML 2025", "summary": "Machine learning models are known to memorize samples from their training\ndata, raising concerns around privacy and generalization. Counterfactual\nself-influence is a popular metric to study memorization, quantifying how the\nmodel's prediction for a sample changes depending on the sample's inclusion in\nthe training dataset. However, recent work has shown memorization to be\naffected by factors beyond self-influence, with other training samples, in\nparticular (near-)duplicates, having a large impact. We here study memorization\ntreating counterfactual influence as a distributional quantity, taking into\naccount how all training samples influence how a sample is memorized. For a\nsmall language model, we compute the full influence distribution of training\nsamples on each other and analyze its properties. We find that solely looking\nat self-influence can severely underestimate tangible risks associated with\nmemorization: the presence of (near-)duplicates seriously reduces\nself-influence, while we find these samples to be (near-)extractable. We\nobserve similar patterns for image classification, where simply looking at the\ninfluence distributions reveals the presence of near-duplicates in CIFAR-10.\nOur findings highlight that memorization stems from complex interactions across\ntraining data and is better captured by the full influence distribution than by\nself-influence alone.", "AI": {"tldr": "The paper highlights that memorization in machine learning models is influenced by more than just self-influence, emphasizing the role of near-duplicates and proposing the use of full influence distributions for better risk assessment.", "motivation": "To address the limitations of counterfactual self-influence in capturing memorization risks, especially due to the impact of near-duplicates in training data.", "method": "Analyzes memorization by treating counterfactual influence as a distributional quantity, computing full influence distributions for a small language model and image classification tasks.", "result": "Self-influence alone underestimates memorization risks; near-duplicates significantly reduce self-influence but remain extractable. Influence distributions reveal near-duplicates in datasets like CIFAR-10.", "conclusion": "Memorization is better understood through full influence distributions, which capture complex interactions in training data, rather than relying solely on self-influence."}}
{"id": "2506.20586", "pdf": "https://arxiv.org/pdf/2506.20586", "abs": "https://arxiv.org/abs/2506.20586", "authors": ["Yitong Quan", "Benjamin Kiefer", "Martin Messmer", "Andreas Zell"], "title": "Learning-Based Distance Estimation for 360\u00b0 Single-Sensor Setups", "categories": ["cs.CV", "cs.RO"], "comment": "Submitted to ECMR 2025", "summary": "Accurate distance estimation is a fundamental challenge in robotic\nperception, particularly in omnidirectional imaging, where traditional\ngeometric methods struggle with lens distortions and environmental variability.\nIn this work, we propose a neural network-based approach for monocular distance\nestimation using a single 360{\\deg} fisheye lens camera. Unlike classical\ntrigonometric techniques that rely on precise lens calibration, our method\ndirectly learns and infers the distance of objects from raw omnidirectional\ninputs, offering greater robustness and adaptability across diverse conditions.\nWe evaluate our approach on three 360{\\deg} datasets (LOAF, ULM360, and a newly\ncaptured dataset Boat360), each representing distinct environmental and sensor\nsetups. Our experimental results demonstrate that the proposed learning-based\nmodel outperforms traditional geometry-based methods and other learning\nbaselines in both accuracy and robustness. These findings highlight the\npotential of deep learning for real-time omnidirectional distance estimation,\nmaking our approach particularly well-suited for low-cost applications in\nrobotics, autonomous navigation, and surveillance.", "AI": {"tldr": "A neural network-based method for monocular distance estimation using a 360\u00b0 fisheye lens camera outperforms traditional geometric techniques, offering robustness and adaptability.", "motivation": "Traditional geometric methods struggle with lens distortions and environmental variability in omnidirectional imaging, necessitating a more robust solution.", "method": "A learning-based approach using neural networks to infer object distances directly from raw omnidirectional inputs, bypassing the need for precise lens calibration.", "result": "The proposed model outperforms traditional geometry-based methods and other learning baselines in accuracy and robustness across three 360\u00b0 datasets.", "conclusion": "Deep learning shows promise for real-time omnidirectional distance estimation, especially for low-cost robotics, autonomous navigation, and surveillance applications."}}
{"id": "2506.19960", "pdf": "https://arxiv.org/pdf/2506.19960", "abs": "https://arxiv.org/abs/2506.19960", "authors": ["Adam Foster", "Zeno Sch\u00e4tzle", "P. Bern\u00e1t Szab\u00f3", "Lixue Cheng", "Jonas K\u00f6hler", "Gino Cassella", "Nicholas Gao", "Jiawei Li", "Frank No\u00e9", "Jan Hermann"], "title": "An ab initio foundation model of wavefunctions that accurately describes chemical bond breaking", "categories": ["physics.chem-ph", "cs.AI", "stat.ML"], "comment": null, "summary": "Reliable description of bond breaking remains a major challenge for quantum\nchemistry due to the multireferential character of the electronic structure in\ndissociating species. Multireferential methods in particular suffer from large\ncomputational cost, which under the normal paradigm has to be paid anew for\neach system at a full price, ignoring commonalities in electronic structure\nacross molecules. Quantum Monte Carlo with deep neural networks (deep QMC)\nuniquely offers to exploit such commonalities by pretraining transferable\nwavefunction models, but all such attempts were so far limited in scope. Here,\nwe bring this new paradigm to fruition with Orbformer, a novel transferable\nwavefunction model pretrained on 22,000 equilibrium and dissociating structures\nthat can be fine-tuned on unseen molecules reaching an accuracy-cost ratio\nrivalling classical multireferential methods. On established benchmarks as well\nas more challenging bond dissociations and Diels-Alder reactions, Orbformer is\nthe only method that consistently converges to chemical accuracy (1 kcal/mol).\nThis work turns the idea of amortizing the cost of solving the Schr\\\"odinger\nequation over many molecules into a practical approach in quantum chemistry.", "AI": {"tldr": "Orbformer, a transferable wavefunction model pretrained on 22,000 structures, achieves chemical accuracy (1 kcal/mol) in bond dissociations and reactions, rivaling classical multireferential methods.", "motivation": "Bond breaking in quantum chemistry is challenging due to multireferential electronic structures, and traditional methods are computationally expensive without leveraging commonalities across molecules.", "method": "Quantum Monte Carlo with deep neural networks (deep QMC) is used to pretrain Orbformer, a transferable wavefunction model, on 22,000 equilibrium and dissociating structures.", "result": "Orbformer consistently achieves chemical accuracy (1 kcal/mol) on benchmarks, bond dissociations, and Diels-Alder reactions, outperforming classical methods.", "conclusion": "Orbformer successfully amortizes the cost of solving the Schr\u00f6dinger equation over many molecules, making it a practical approach in quantum chemistry."}}
{"id": "2506.20204", "pdf": "https://arxiv.org/pdf/2506.20204", "abs": "https://arxiv.org/abs/2506.20204", "authors": ["Eduardo Gutierrez Maestro", "Hadi Banaee", "Amy Loutfi"], "title": "Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Affective priming exemplifies the challenge of ambiguity in affective\ncomputing. While the community has largely addressed this issue from a\nlabel-based perspective, identifying data points in the sequence affected by\nthe priming effect, the impact of priming on data itself, particularly in\nphysiological signals, remains underexplored. Data affected by priming can lead\nto misclassifications when used in learning models. This study proposes the\nAffective Priming Score (APS), a data-driven method to detect data points\ninfluenced by the priming effect. The APS assigns a score to each data point,\nquantifying the extent to which it is affected by priming. To validate this\nmethod, we apply it to the SEED and SEED-VII datasets, which contain sufficient\ntransitions between emotional events to exhibit priming effects. We train\nmodels with the same configuration using both the original data and\npriming-free sequences. The misclassification rate is significantly reduced\nwhen using priming-free sequences compared to the original data. This work\ncontributes to the broader challenge of ambiguity by identifying and mitigating\npriming effects at the data level, enhancing model robustness, and offering\nvaluable insights for the design and collection of affective computing\ndatasets.", "AI": {"tldr": "The paper introduces the Affective Priming Score (APS) to detect and mitigate priming effects in affective computing data, reducing misclassification rates in models.", "motivation": "Addressing the underexplored impact of priming on physiological signals and its potential to cause misclassifications in learning models.", "method": "Proposes APS, a data-driven method to score data points for priming effects, validated on SEED and SEED-VII datasets by comparing original and priming-free data.", "result": "Misclassification rates significantly drop when using priming-free sequences, demonstrating APS's effectiveness.", "conclusion": "APS enhances model robustness and provides insights for designing affective computing datasets by mitigating priming effects at the data level."}}
{"id": "2506.20520", "pdf": "https://arxiv.org/pdf/2506.20520", "abs": "https://arxiv.org/abs/2506.20520", "authors": ["Charles Arnal", "Ga\u00ebtan Narozniak", "Vivien Cabannes", "Yunhao Tang", "Julia Kempe", "Remi Munos"], "title": "Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) is increasingly used to align large language\nmodels (LLMs). Off-policy methods offer greater implementation simplicity and\ndata efficiency than on-policy techniques, but often result in suboptimal\nperformance. In this work, we study the intermediate range of algorithms\nbetween off-policy RL and supervised fine-tuning by analyzing a simple\noff-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with\n$r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$\nemphasizes high-reward samples, while raising it penalizes low-reward ones more\nheavily. We first provide a theoretical analysis of this off-policy REINFORCE\nalgorithm, showing that when the baseline $V$ lower-bounds the expected reward,\nthe algorithm enjoys a policy improvement guarantee. Our analysis reveals that\nwhile on-policy updates can safely leverage both positive and negative signals,\noff-policy updates benefit from focusing more on positive rewards than on\nnegative ones. We validate our findings experimentally in a controlled\nstochastic bandit setting and through fine-tuning state-of-the-art LLMs on\nreasoning tasks.", "AI": {"tldr": "The paper analyzes an off-policy REINFORCE algorithm for aligning LLMs, showing policy improvement when the baseline lower-bounds expected reward, and validates findings in experiments.", "motivation": "To bridge the gap between off-policy RL and supervised fine-tuning for aligning LLMs, addressing suboptimal performance of off-policy methods.", "method": "Theoretical analysis of an off-policy REINFORCE algorithm with a tunable baseline, validated in a stochastic bandit setting and LLM fine-tuning.", "result": "Policy improvement is guaranteed when the baseline lower-bounds expected reward; off-policy updates benefit more from positive rewards.", "conclusion": "The study provides insights into optimizing off-policy RL for LLM alignment, emphasizing the role of baseline tuning and reward focus."}}
{"id": "2506.20588", "pdf": "https://arxiv.org/pdf/2506.20588", "abs": "https://arxiv.org/abs/2506.20588", "authors": ["Pritam Mishra", "Coloma Ballester", "Dimosthenis Karatzas"], "title": "TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness", "categories": ["cs.CV"], "comment": null, "summary": "The increasing ubiquity of video content and the corresponding demand for\nefficient access to meaningful information have elevated video summarization\nand video highlights as a vital research area. However, many state-of-the-art\nmethods depend heavily either on supervised annotations or on attention-based\nmodels, which are computationally expensive and brittle in the face of\ndistribution shifts that hinder cross-domain applicability across datasets. We\nintroduce a pioneering self-supervised video summarization model that captures\nboth spatial and temporal dependencies without the overhead of attention, RNNs,\nor transformers. Our framework integrates a novel set of Markov process-driven\nloss metrics and a two-stage self supervised learning paradigm that ensures\nboth performance and efficiency. Our approach achieves state-of-the-art\nperformance on the SUMME and TVSUM datasets, outperforming all existing\nunsupervised methods. It also rivals the best supervised models, demonstrating\nthe potential for efficient, annotation-free architectures. This paves the way\nfor more generalizable video summarization techniques and challenges the\nprevailing reliance on complex architectures.", "AI": {"tldr": "A self-supervised video summarization model is introduced, avoiding costly annotations and attention-based methods, achieving state-of-the-art results on SUMME and TVSUM datasets.", "motivation": "The need for efficient video summarization without reliance on supervised annotations or computationally expensive models drives this research.", "method": "The model uses a Markov process-driven loss and a two-stage self-supervised learning paradigm, avoiding attention, RNNs, or transformers.", "result": "Outperforms unsupervised methods and rivals supervised models on SUMME and TVSUM datasets.", "conclusion": "The approach demonstrates the viability of efficient, annotation-free video summarization, challenging reliance on complex architectures."}}
{"id": "2506.19973", "pdf": "https://arxiv.org/pdf/2506.19973", "abs": "https://arxiv.org/abs/2506.19973", "authors": ["Vojt\u011bch Nov\u00e1k", "Ivan Zelinka", "Lenka P\u0159ibylov\u00e1", "Lubom\u00edr Mart\u00ednek"], "title": "Quantum Neural Networks for Propensity Score Estimation and Survival Analysis in Observational Biomedical Studies", "categories": ["quant-ph", "cs.AI", "stat.ML", "62H30, 62P10, 68T05, 81P68", "I.2.6; J.3; I.5.4; F.4.1"], "comment": null, "summary": "This study investigates the application of quantum neural networks (QNNs) for\npropensity score estimation to address selection bias in comparing survival\noutcomes between laparoscopic and open surgical techniques in a cohort of 1177\ncolorectal carcinoma patients treated at University Hospital Ostrava\n(2001-2009). Using a dataset with 77 variables, including patient demographics\nand tumor characteristics, we developed QNN-based propensity score models\nfocusing on four key covariates (Age, Sex, Stage, BMI). The QNN architecture\nemployed a linear ZFeatureMap for data encoding, a SummedPaulis operator for\npredictions, and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES)\nfor robust, gradient-free optimization in noisy quantum environments. Variance\nregularization was integrated to mitigate quantum measurement noise, with\nsimulations conducted under exact, sampling (1024 shots), and noisy hardware\n(FakeManhattanV2) conditions. QNNs, particularly with simulated hardware noise,\noutperformed classical logistic regression and gradient boosted machines in\nsmall samples (AUC up to 0.750 for n=100), with noise modeling enhancing\npredictive stability. Propensity score matching and weighting, optimized via\ngenetic matching and matching weights, achieved covariate balance with\nstandardized mean differences of 0.0849 and 0.0869, respectively. Survival\nanalyses using Kaplan-Meier estimation, Cox proportional hazards, and Aalen\nadditive regression revealed no significant survival differences\npost-adjustment (p-values 0.287-0.851), indicating confounding bias in\nunadjusted outcomes. These results highlight QNNs' potential, enhanced by\nCMA-ES and noise-aware strategies, to improve causal inference in biomedical\nresearch, particularly for small-sample, high-dimensional datasets.", "AI": {"tldr": "The study explores quantum neural networks (QNNs) for propensity score estimation to address selection bias in comparing survival outcomes of laparoscopic vs. open surgery in colorectal carcinoma patients. QNNs, optimized with CMA-ES and noise-aware strategies, outperformed classical methods in small samples and achieved balanced covariate adjustments, revealing no significant survival differences post-adjustment.", "motivation": "To address selection bias in survival outcome comparisons between surgical techniques using QNNs, leveraging their potential for small-sample, high-dimensional datasets.", "method": "Developed QNN-based propensity score models with linear ZFeatureMap encoding, SummedPaulis operator, and CMA-ES optimization. Included variance regularization for noise mitigation and tested under exact, sampling, and noisy hardware conditions.", "result": "QNNs outperformed classical methods (AUC up to 0.750 for n=100), achieved covariate balance (SMDs 0.0849-0.0869), and showed no significant survival differences post-adjustment (p-values 0.287-0.851).", "conclusion": "QNNs, enhanced by CMA-ES and noise-aware strategies, show promise for improving causal inference in biomedical research, especially for small, high-dimensional datasets."}}
{"id": "2506.20235", "pdf": "https://arxiv.org/pdf/2506.20235", "abs": "https://arxiv.org/abs/2506.20235", "authors": ["Yuyang Zhang", "Xu Shen", "Yu Xie", "Ka-Chun Wong", "Weidun Xie", "Chengbin Peng"], "title": "Directed Link Prediction using GNN with Local and Global Feature Fusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Link prediction is a classical problem in graph analysis with many practical\napplications. For directed graphs, recently developed deep learning approaches\ntypically analyze node similarities through contrastive learning and aggregate\nneighborhood information through graph convolutions. In this work, we propose a\nnovel graph neural network (GNN) framework to fuse feature embedding with\ncommunity information. We theoretically demonstrate that such hybrid features\ncan improve the performance of directed link prediction. To utilize such\nfeatures efficiently, we also propose an approach to transform input graphs\ninto directed line graphs so that nodes in the transformed graph can aggregate\nmore information during graph convolutions. Experiments on benchmark datasets\nshow that our approach outperforms the state-of-the-art in most cases when 30%,\n40%, 50%, and 60% of the connected links are used as training data,\nrespectively.", "AI": {"tldr": "A novel GNN framework combines feature embedding and community information for directed link prediction, outperforming state-of-the-art methods.", "motivation": "Improving directed link prediction by integrating feature embedding with community information.", "method": "Proposes a GNN framework using hybrid features and transforms graphs into directed line graphs for better information aggregation.", "result": "Outperforms state-of-the-art methods on benchmark datasets with varying training data proportions.", "conclusion": "The hybrid feature approach and directed line graph transformation enhance link prediction performance."}}
{"id": "2506.20629", "pdf": "https://arxiv.org/pdf/2506.20629", "abs": "https://arxiv.org/abs/2506.20629", "authors": ["Soufiane Hayou", "Nikhil Ghosh", "Bin Yu"], "title": "PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "TD,LR: A lightweight module type selection method for LoRA\n  finetuning. PLoP gives precise placements for LoRA adapters for improved\n  performance", "summary": "Low-Rank Adaptation (LoRA) is a widely used finetuning method for large\nmodels. Its small memory footprint allows practitioners to adapt large models\nto specific tasks at a fraction of the cost of full finetuning. Different\nmodifications have been proposed to enhance its efficiency by, for example,\nsetting the learning rate, the rank, and the initialization. Another\nimprovement axis is adapter placement strategy: when using LoRA, practitioners\nusually pick module types to adapt with LoRA, such as Query and Key modules.\nFew works have studied the problem of adapter placement, with nonconclusive\nresults: original LoRA paper suggested placing adapters in attention modules,\nwhile other works suggested placing them in the MLP modules. Through an\nintuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a\nlightweight method that allows automatic identification of module types where\nLoRA adapters should be placed, given a pretrained model and a finetuning task.\nWe demonstrate that PLoP consistently outperforms, and in the worst case\ncompetes, with commonly used placement strategies through comprehensive\nexperiments on supervised finetuning and reinforcement learning for reasoning.", "AI": {"tldr": "PLoP (Precise LoRA Placement) is a lightweight method for automatically identifying optimal LoRA adapter placements in pretrained models, outperforming common strategies.", "motivation": "Existing LoRA adapter placement strategies lack consensus, with some favoring attention modules and others MLP modules. PLoP aims to resolve this ambiguity by providing a data-driven solution.", "method": "PLoP uses intuitive theoretical analysis to automatically determine the best module types (e.g., Query, Key, MLP) for LoRA adapter placement, given a pretrained model and finetuning task.", "result": "PLoP consistently outperforms or matches common placement strategies in supervised finetuning and reinforcement learning for reasoning tasks.", "conclusion": "PLoP offers a robust, automated solution for LoRA adapter placement, enhancing efficiency and performance in model finetuning."}}
{"id": "2506.20590", "pdf": "https://arxiv.org/pdf/2506.20590", "abs": "https://arxiv.org/abs/2506.20590", "authors": ["Chaojun Ni", "Jie Li", "Haoyun Li", "Hengyu Liu", "Xiaofeng Wang", "Zheng Zhu", "Guosheng Zhao", "Boyuan Wang", "Chenxin Li", "Guan Huang", "Wenjun Mei"], "title": "WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration", "categories": ["cs.CV"], "comment": null, "summary": "Interactive 3D scene generation from a single image has gained significant\nattention due to its potential to create immersive virtual worlds. However, a\nkey challenge in current 3D generation methods is the limited explorability,\nwhich cannot render high-quality images during larger maneuvers beyond the\noriginal viewpoint, particularly when attempting to move forward into unseen\nareas. To address this challenge, we propose WonderFree, the first model that\nenables users to interactively generate 3D worlds with the freedom to explore\nfrom arbitrary angles and directions. Specifically, we decouple this challenge\ninto two key subproblems: novel view quality, which addresses visual artifacts\nand floating issues in novel views, and cross-view consistency, which ensures\nspatial consistency across different viewpoints. To enhance rendering quality\nin novel views, we introduce WorldRestorer, a data-driven video restoration\nmodel designed to eliminate floaters and artifacts. In addition, a data\ncollection pipeline is presented to automatically gather training data for\nWorldRestorer, ensuring it can handle scenes with varying styles needed for 3D\nscene generation. Furthermore, to improve cross-view consistency, we propose\nConsistView, a multi-view joint restoration mechanism that simultaneously\nrestores multiple perspectives while maintaining spatiotemporal coherence.\nExperimental results demonstrate that WonderFree not only enhances rendering\nquality across diverse viewpoints but also significantly improves global\ncoherence and consistency. These improvements are confirmed by CLIP-based\nmetrics and a user study showing a 77.20% preference for WonderFree over\nWonderWorld enabling a seamless and immersive 3D exploration experience. The\ncode, model, and data will be publicly available.", "AI": {"tldr": "WonderFree enables interactive 3D scene generation from a single image, improving novel view quality and cross-view consistency with WorldRestorer and ConsistView.", "motivation": "Current 3D generation methods struggle with limited explorability and rendering quality in unseen areas, hindering immersive experiences.", "method": "Decouples the problem into novel view quality (addressed by WorldRestorer) and cross-view consistency (addressed by ConsistView). Includes a data collection pipeline for training.", "result": "WonderFree outperforms WonderWorld with 77.20% user preference, enhancing rendering quality and global coherence.", "conclusion": "WonderFree offers a seamless, immersive 3D exploration experience, with publicly available code, model, and data."}}
{"id": "2506.20036", "pdf": "https://arxiv.org/pdf/2506.20036", "abs": "https://arxiv.org/abs/2506.20036", "authors": ["Jeremiah Coholich", "Muhammad Ali Murtaza", "Seth Hutchinson", "Zsolt Kira"], "title": "Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We propose a novel hierarchical reinforcement learning framework for\nquadruped locomotion over challenging terrain. Our approach incorporates a\ntwo-layer hierarchy in which a high-level policy (HLP) selects optimal goals\nfor a low-level policy (LLP). The LLP is trained using an on-policy\nactor-critic RL algorithm and is given footstep placements as goals. We propose\nan HLP that does not require any additional training or environment samples and\ninstead operates via an online optimization process over the learned value\nfunction of the LLP. We demonstrate the benefits of this framework by comparing\nit with an end-to-end reinforcement learning (RL) approach. We observe\nimprovements in its ability to achieve higher rewards with fewer collisions\nacross an array of different terrains, including terrains more difficult than\nany encountered during training.", "AI": {"tldr": "A hierarchical RL framework for quadruped locomotion uses a high-level policy (HLP) to guide a low-level policy (LLP) via footstep goals, improving performance over challenging terrains without additional training.", "motivation": "To enhance quadruped locomotion over difficult terrains by leveraging hierarchical reinforcement learning for better efficiency and adaptability.", "method": "A two-layer hierarchy: HLP selects goals for LLP, trained with actor-critic RL. HLP optimizes online using LLP's value function, avoiding extra training.", "result": "Outperforms end-to-end RL, achieving higher rewards and fewer collisions, even on terrains harder than those in training.", "conclusion": "The hierarchical framework improves locomotion performance and generalizes well to unseen challenging terrains."}}
{"id": "2506.20245", "pdf": "https://arxiv.org/pdf/2506.20245", "abs": "https://arxiv.org/abs/2506.20245", "authors": ["Yushan Zhao", "Jinyuan He", "Donglai Chen", "Weijie Luo", "Chong Xie", "Ri Zhang", "Yonghong Chen", "Yan Xu"], "title": "FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated learning (FL) is a decentralized collaborative machine learning\n(ML) technique. It provides a solution to the issues of isolated data islands\nand data privacy leakage in industrial ML practices. One major challenge in FL\nis handling the non-identical and independent distributed (non-IID) data.\nCurrent solutions either focus on constructing an all-powerful global model, or\ncustomizing personalized local models. Few of them can provide both a\nwell-generalized global model and well-performed local models at the same time.\nAdditionally, many FL solutions to the non-IID problem are benefited from\nintroducing public datasets. However, this will also increase the risk of data\nleakage. To tackle the problems, we propose a novel data-free distillation\nframework, Federated Bidirectional Knowledge Distillation (FedBKD).\nSpecifically, we train Generative Adversarial Networks (GAN) for synthetic\ndata. During the GAN training, local models serve as discriminators and their\nparameters are frozen. The synthetic data is then used for bidirectional\ndistillation between global and local models to achieve knowledge interactions\nso that performances for both sides are improved. We conduct extensive\nexperiments on 4 benchmarks under different non-IID settings. The results show\nthat FedBKD achieves SOTA performances in every case.", "AI": {"tldr": "FedBKD is a novel data-free distillation framework for federated learning, addressing non-IID data challenges without public datasets, improving both global and local model performance.", "motivation": "To solve the non-IID data problem in FL while avoiding data leakage risks from public datasets, and to enhance both global and local model performance.", "method": "Uses GANs to generate synthetic data, with local models as frozen discriminators, and bidirectional distillation between global and local models for knowledge interaction.", "result": "FedBKD achieves state-of-the-art performance on 4 benchmarks under various non-IID settings.", "conclusion": "FedBKD effectively addresses non-IID challenges in FL without relying on public datasets, improving both generalization and personalization."}}
{"id": "2506.20670", "pdf": "https://arxiv.org/pdf/2506.20670", "abs": "https://arxiv.org/abs/2506.20670", "authors": ["Jinming Wu", "Zihao Deng", "Wei Li", "Yiding Liu", "Bo You", "Bo Li", "Zejun Ma", "Ziwei Liu"], "title": "MMSearch-R1: Incentivizing LMMs to Search", "categories": ["cs.CV", "cs.CL"], "comment": "Code: https://github.com/EvolvingLMMs-Lab/multimodal-search-r1", "summary": "Robust deployment of large multimodal models (LMMs) in real-world scenarios\nrequires access to external knowledge sources, given the complexity and dynamic\nnature of real-world information. Existing approaches such as\nretrieval-augmented generation (RAG) and prompt engineered search agents rely\non rigid pipelines, often leading to inefficient or excessive search behaviors.\nWe present MMSearch-R1, the first end-to-end reinforcement learning framework\nthat enables LMMs to perform on-demand, multi-turn search in real-world\nInternet environments. Our framework integrates both image and text search\ntools, allowing the model to reason about when and how to invoke them guided by\nan outcome-based reward with a search penalty. To support training, We collect\na multimodal search VQA dataset through a semi-automated pipeline that covers\ndiverse visual and textual knowledge needs and curate a search-balanced subset\nwith both search-required and search-free samples, which proves essential for\nshaping efficient and on-demand search behavior. Extensive experiments on\nknowledge-intensive and info-seeking VQA tasks show that our model not only\noutperforms RAG-based baselines of the same model size, but also matches the\nperformance of a larger RAG-based model while reducing search calls by over\n30%. We further analyze key empirical findings to offer actionable insights for\nadvancing research in multimodal search.", "AI": {"tldr": "MMSearch-R1 is a reinforcement learning framework for large multimodal models (LMMs) to perform efficient, on-demand, multi-turn searches in real-world Internet environments, outperforming traditional methods like RAG.", "motivation": "Existing methods like RAG and prompt-engineered search agents are inefficient for dynamic real-world information, necessitating a more flexible and efficient approach.", "method": "The framework uses reinforcement learning with outcome-based rewards and search penalties, integrating image and text search tools. A multimodal search VQA dataset supports training.", "result": "MMSearch-R1 outperforms RAG baselines of the same size, matches larger RAG models, and reduces search calls by over 30%.", "conclusion": "The framework advances multimodal search research by enabling efficient, on-demand search behavior in LMMs."}}
{"id": "2506.20599", "pdf": "https://arxiv.org/pdf/2506.20599", "abs": "https://arxiv.org/abs/2506.20599", "authors": ["Ji Qi", "Xinchang Zhang", "Dingqi Ye", "Yongjia Ruan", "Xin Guo", "Shaowen Wang", "Haifeng Li"], "title": "SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancement of generative artificial intelligence is producing fake\nremote sensing imagery (RSI) that is increasingly difficult to detect,\npotentially leading to erroneous intelligence, fake news, and even conspiracy\ntheories. Existing forgery detection methods typically rely on single visual\nfeatures to capture predefined artifacts, such as spatial-domain cues to detect\nforged objects like roads or buildings in RSI, or frequency-domain features to\nidentify artifacts from up-sampling operations in adversarial generative\nnetworks (GANs). However, the nature of artifacts can significantly differ\ndepending on geographic terrain, land cover types, or specific features within\nthe RSI. Moreover, these complex artifacts evolve as generative models become\nmore sophisticated. In short, over-reliance on a single visual cue makes\nexisting forgery detectors struggle to generalize across diverse remote sensing\ndata. This paper proposed a novel forgery detection framework called SFNet,\ndesigned to identify fake images in diverse remote sensing data by leveraging\nspatial and frequency domain features. Specifically, to obtain rich and\ncomprehensive visual information, SFNet employs two independent feature\nextractors to capture spatial and frequency domain features from input RSIs. To\nfully utilize the complementary domain features, the domain feature mapping\nmodule and the hybrid domain feature refinement module(CBAM attention) of SFNet\nare designed to successively align and fuse the multi-domain features while\nsuppressing redundant information. Experiments on three datasets show that\nSFNet achieves an accuracy improvement of 4%-15.18% over the state-of-the-art\nRS forgery detection methods and exhibits robust generalization capabilities.\nThe code is available at https://github.com/GeoX-Lab/RSTI/tree/main/SFNet.", "AI": {"tldr": "SFNet, a novel forgery detection framework, leverages spatial and frequency domain features to detect fake remote sensing imagery, outperforming existing methods by 4%-15.18% in accuracy.", "motivation": "The rise of sophisticated generative AI makes fake remote sensing imagery harder to detect, risking misinformation. Existing methods rely on single visual features, limiting generalization.", "method": "SFNet uses two feature extractors for spatial and frequency domains, with modules to align, fuse, and refine these features while suppressing redundancy.", "result": "SFNet improves accuracy by 4%-15.18% over state-of-the-art methods and shows robust generalization across datasets.", "conclusion": "SFNet effectively addresses the limitations of single-feature methods, offering a robust solution for detecting fake remote sensing imagery."}}
{"id": "2506.20049", "pdf": "https://arxiv.org/pdf/2506.20049", "abs": "https://arxiv.org/abs/2506.20049", "authors": ["Lorin Achey", "Alec Reed", "Brendan Crowe", "Bradley Hayes", "Christoffer Heckman"], "title": "Robust Robotic Exploration and Mapping Using Generative Occupancy Map Synthesis", "categories": ["cs.RO", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2409.10681", "summary": "We present a novel approach for enhancing robotic exploration by using\ngenerative occupancy mapping. We introduce SceneSense, a diffusion model\ndesigned and trained for predicting 3D occupancy maps given partial\nobservations. Our proposed approach probabilistically fuses these predictions\ninto a running occupancy map in real-time, resulting in significant\nimprovements in map quality and traversability. We implement SceneSense onboard\na quadruped robot and validate its performance with real-world experiments to\ndemonstrate the effectiveness of the model. In these experiments, we show that\noccupancy maps enhanced with SceneSense predictions better represent our fully\nobserved ground truth data (24.44% FID improvement around the robot and 75.59%\nimprovement at range). We additionally show that integrating\nSceneSense-enhanced maps into our robotic exploration stack as a \"drop-in\" map\nimprovement, utilizing an existing off-the-shelf planner, results in\nimprovements in robustness and traversability time. Finally we show results of\nfull exploration evaluations with our proposed system in two dissimilar\nenvironments and find that locally enhanced maps provide more consistent\nexploration results than maps constructed only from direct sensor measurements.", "AI": {"tldr": "SceneSense, a diffusion model, enhances robotic exploration by improving 3D occupancy maps with generative predictions, validated in real-world experiments.", "motivation": "To improve robotic exploration by enhancing map quality and traversability using generative occupancy mapping.", "method": "Introduces SceneSense, a diffusion model for predicting 3D occupancy maps from partial observations, fused in real-time into a running map.", "result": "Significant improvements in map quality (24.44% FID near robot, 75.59% at range) and exploration robustness.", "conclusion": "SceneSense enhances exploration consistency and performance, outperforming direct sensor measurements."}}
{"id": "2506.20251", "pdf": "https://arxiv.org/pdf/2506.20251", "abs": "https://arxiv.org/abs/2506.20251", "authors": ["Kejia Chen", "Jiawen Zhang", "Jiacong Hu", "Yu Wang", "Jian Lou", "Zunlei Feng", "Mingli Song"], "title": "Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Quantized large language models (LLMs) have gained increasing attention and\nsignificance for enabling deployment in resource-constrained environments.\nHowever, emerging studies on a few calibration dataset-free quantization\nmethods suggest that quantization may compromise the safety capabilities of\nLLMs, underscoring the urgent need for systematic safety evaluations and\neffective mitigation strategies. In this paper, we present comprehensive safety\nevaluations across various mainstream quantization techniques and diverse\ncalibration datasets, utilizing widely accepted safety benchmarks. To address\nthe identified safety vulnerabilities, we propose a quantization-aware safety\npatching framework, Q-resafe, to efficiently restore the safety capabilities of\nquantized LLMs while minimizing any adverse impact on utility. Extensive\nexperimental results demonstrate that Q-resafe successfully re-aligns the\nsafety of quantized LLMs with their pre-quantization counterparts, even under\nchallenging evaluation scenarios. Project page is available at:\nhttps://github.com/Thecommonirin/Qresafe.", "AI": {"tldr": "The paper evaluates safety risks in quantized LLMs and proposes Q-resafe, a framework to restore safety without compromising utility.", "motivation": "Quantization of LLMs for resource-constrained environments may compromise safety, necessitating systematic evaluation and mitigation.", "method": "Comprehensive safety evaluations across quantization techniques and datasets, followed by the Q-resafe framework for safety restoration.", "result": "Q-resafe successfully re-aligns safety of quantized LLMs with pre-quantization levels, even in challenging scenarios.", "conclusion": "The proposed Q-resafe framework effectively mitigates safety vulnerabilities in quantized LLMs."}}
{"id": "2305.19928", "pdf": "https://arxiv.org/pdf/2305.19928", "abs": "https://arxiv.org/abs/2305.19928", "authors": ["Conglei Xu", "Kun Shen", "Hongguang Sun", "Yang Xu"], "title": "A Global Context Mechanism for Sequence Labeling", "categories": ["cs.CL"], "comment": null, "summary": "Global sentence information is crucial for sequence labeling tasks, where\neach word in a sentence must be assigned a label. While BiLSTM models are\nwidely used, they often fail to capture sufficient global context for inner\nwords. Previous work has proposed various RNN variants to integrate global\nsentence information into word representations. However, these approaches\nsuffer from three key limitations: (1) they are slower in both inference and\ntraining compared to the original BiLSTM, (2) they cannot effectively\nsupplement global information for transformer-based models, and (3) the high\ntime cost associated with reimplementing and integrating these customized RNNs\ninto existing architectures. In this study, we introduce a simple yet effective\nmechanism that addresses these limitations. Our approach efficiently\nsupplements global sentence information for both BiLSTM and transformer-based\nmodels, with minimal degradation in inference and training speed, and is easily\npluggable into current architectures. We demonstrate significant improvements\nin F1 scores across seven popular benchmarks, including Named Entity\nRecognition (NER) tasks such as Conll2003, Wnut2017 , and the Chinese\nnamed-entity recognition task Weibo, as well as End-to-End Aspect-Based\nSentiment Analysis (E2E-ABSA) benchmarks such as Laptop14, Restaurant14,\nRestaurant15, and Restaurant16. With out any extra strategy, we achieve third\nhighest score on weibo NER benchmark. Compared to CRF, one of the most popular\nframeworks for sequence labeling, our mechanism achieves competitive F1 scores\nwhile offering superior inference and training speed. Code is available at:\nhttps://github.com/conglei2XU/Global-Context-Mechanism", "AI": {"tldr": "The paper introduces a simple, efficient mechanism to enhance global sentence information for sequence labeling tasks, improving performance without significant speed trade-offs.", "motivation": "Existing RNN variants for integrating global sentence information are slow, incompatible with transformers, and hard to implement.", "method": "A pluggable mechanism to supplement global context for BiLSTM and transformer models efficiently.", "result": "Significant F1 score improvements on seven benchmarks, including NER and E2E-ABSA tasks, with competitive speed.", "conclusion": "The proposed mechanism effectively addresses prior limitations, offering better performance and ease of integration."}}
{"id": "2506.20601", "pdf": "https://arxiv.org/pdf/2506.20601", "abs": "https://arxiv.org/abs/2506.20601", "authors": ["Rui Huang", "Guangyao Zhai", "Zuria Bauer", "Marc Pollefeys", "Federico Tombari", "Leonidas Guibas", "Gao Huang", "Francis Engelmann"], "title": "Video Perception Models for 3D Scene Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "Traditionally, 3D scene synthesis requires expert knowledge and significant\nmanual effort. Automating this process could greatly benefit fields such as\narchitectural design, robotics simulation, virtual reality, and gaming. Recent\napproaches to 3D scene synthesis often rely on the commonsense reasoning of\nlarge language models (LLMs) or strong visual priors of modern image generation\nmodels. However, current LLMs demonstrate limited 3D spatial reasoning ability,\nwhich restricts their ability to generate realistic and coherent 3D scenes.\nMeanwhile, image generation-based methods often suffer from constraints in\nviewpoint selection and multi-view inconsistencies. In this work, we present\nVideo Perception models for 3D Scene synthesis (VIPScene), a novel framework\nthat exploits the encoded commonsense knowledge of the 3D physical world in\nvideo generation models to ensure coherent scene layouts and consistent object\nplacements across views. VIPScene accepts both text and image prompts and\nseamlessly integrates video generation, feedforward 3D reconstruction, and\nopen-vocabulary perception models to semantically and geometrically analyze\neach object in a scene. This enables flexible scene synthesis with high realism\nand structural consistency. For more precise analysis, we further introduce\nFirst-Person View Score (FPVScore) for coherence and plausibility evaluation,\nutilizing continuous first-person perspective to capitalize on the reasoning\nability of multimodal large language models. Extensive experiments show that\nVIPScene significantly outperforms existing methods and generalizes well across\ndiverse scenarios. The code will be released.", "AI": {"tldr": "VIPScene leverages video generation models for 3D scene synthesis, addressing limitations of LLMs and image-based methods by ensuring coherence and consistency.", "motivation": "Automating 3D scene synthesis benefits fields like architecture and gaming, but current methods (LLMs, image generation) lack spatial reasoning and multi-view consistency.", "method": "VIPScene integrates video generation, 3D reconstruction, and perception models, using text/image prompts for flexible, realistic synthesis.", "result": "VIPScene outperforms existing methods, achieving high realism and structural consistency across diverse scenarios.", "conclusion": "VIPScene offers a robust solution for 3D scene synthesis, with potential applications in various domains. Code will be released."}}
{"id": "2506.20062", "pdf": "https://arxiv.org/pdf/2506.20062", "abs": "https://arxiv.org/abs/2506.20062", "authors": ["Runlong Ye", "Zeling Zhang", "Boushra Almazroua", "Michael Liut"], "title": "Beyond Autocomplete: Designing CopilotLens Towards Transparent and Explainable AI Coding Agents", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "AI-powered code assistants are widely used to generate code completions,\nsignificantly boosting developer productivity. However, these tools typically\npresent suggestions without explaining their rationale, leaving their\ndecision-making process inscrutable. This opacity hinders developers' ability\nto critically evaluate the output, form accurate mental models, and build\ncalibrated trust in the system. To address this, we introduce CopilotLens, a\nnovel interactive framework that reframes code completion from a simple\nsuggestion into a transparent, explainable event. CopilotLens operates as an\nexplanation layer that reveals the AI agent's \"thought process\" through a\ndynamic two-level interface, surfacing everything from its reconstructed\nhigh-level plans to the specific codebase context influencing the code. This\npaper presents the design and rationale of CopilotLens, offering a concrete\nframework for building future agentic code assistants that prioritize clarity\nof reasoning over speed of suggestion, thereby fostering deeper comprehension\nand more robust human-AI collaboration.", "AI": {"tldr": "CopilotLens is an interactive framework that makes AI-powered code assistants transparent by explaining their decision-making process, enhancing developer trust and comprehension.", "motivation": "Current AI code assistants lack transparency, making it hard for developers to evaluate suggestions critically and build trust.", "method": "Introduces CopilotLens, a two-level interface revealing the AI's reasoning, from high-level plans to contextual influences.", "result": "Provides a framework for transparent, explainable code completion, improving human-AI collaboration.", "conclusion": "CopilotLens prioritizes clarity over speed, fostering better understanding and trust in AI code assistants."}}
{"id": "2506.20253", "pdf": "https://arxiv.org/pdf/2506.20253", "abs": "https://arxiv.org/abs/2506.20253", "authors": ["Ben Gerhards", "Nikita Popkov", "Annekatrin K\u00f6nig", "Marcel Arpogaus", "Bastian Sch\u00e4fermeier", "Leonie Riedl", "Stephan Vogt", "Philip Hehlert"], "title": "Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Forecasting attracts a lot of research attention in the electricity value\nchain. However, most studies concentrate on short-term forecasting of\ngeneration or consumption with a focus on systems and less on individual\nconsumers. Even more neglected is the topic of long-term forecasting of\nindividual power consumption.\n  Here, we provide an in-depth comparative evaluation of data-driven methods\nfor generating synthetic time series data tailored to energy consumption\nlong-term forecasting. High-fidelity synthetic data is crucial for a wide range\nof applications, including state estimations in energy systems or power grid\nplanning. In this study, we assess and compare the performance of multiple\nstate-of-the-art but less common techniques: a hybrid Wasserstein Generative\nAdversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM),\nHidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial\nnormalizing Flows (MABF). We analyze the ability of each method to replicate\nthe temporal dynamics, long-range dependencies, and probabilistic transitions\ncharacteristic of individual energy consumption profiles. Our comparative\nevaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and\nMABF aiding in selecting the most suitable approach for state estimations and\nother energy-related tasks. Our generation and analysis framework aims to\nenhance the accuracy and reliability of synthetic power consumption data while\ngenerating data that fulfills criteria like anonymisation - preserving privacy\nconcerns mitigating risks of specific profiling of single customers. This study\nutilizes an open-source dataset from households in Germany with 15min time\nresolution. The generated synthetic power profiles can readily be used in\napplications like state estimations or consumption forecasting.", "AI": {"tldr": "The paper evaluates data-driven methods for generating synthetic time series data for long-term energy consumption forecasting, comparing WGAN, DDPM, HMM, and MABF techniques.", "motivation": "Long-term forecasting of individual power consumption is understudied, and high-fidelity synthetic data is needed for energy system applications.", "method": "Comparative evaluation of WGAN, DDPM, HMM, and MABF to replicate temporal dynamics and dependencies in energy consumption profiles.", "result": "The study highlights the strengths and limitations of each method, aiding in selecting the best approach for energy-related tasks.", "conclusion": "The framework enhances synthetic data accuracy and privacy, using open-source German household data for practical applications."}}
{"id": "2311.09410", "pdf": "https://arxiv.org/pdf/2311.09410", "abs": "https://arxiv.org/abs/2311.09410", "authors": ["Leonardo Ranaldi", "Giulia Pucci"], "title": "When Large Language Models contradict humans? Large Language Models' Sycophantic Behaviour", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models have been demonstrating broadly satisfactory generative\nabilities for users, which seems to be due to the intensive use of human\nfeedback that refines responses. Nevertheless, suggestibility inherited via\nhuman feedback improves the inclination to produce answers corresponding to\nusers' viewpoints. This behaviour is known as sycophancy and depicts the\ntendency of LLMs to generate misleading responses as long as they align with\nhumans. This phenomenon induces bias and reduces the robustness and,\nconsequently, the reliability of these models. In this paper, we study the\nsuggestibility of Large Language Models (LLMs) to sycophantic behaviour,\nanalysing these tendencies via systematic human-interventions prompts over\ndifferent tasks. Our investigation demonstrates that LLMs have sycophantic\ntendencies when answering queries that involve subjective opinions and\nstatements that should elicit a contrary response based on facts. In contrast,\nwhen faced with math tasks or queries with an objective answer, they, at\nvarious scales, do not follow the users' hints by demonstrating confidence in\ngenerating the correct answers.", "AI": {"tldr": "The paper investigates sycophantic behavior in Large Language Models (LLMs), where models align responses with user viewpoints, even if misleading, due to human feedback. It finds this behavior prevalent in subjective queries but absent in objective tasks like math.", "motivation": "To understand and analyze the suggestibility of LLMs to sycophantic behavior, which biases responses and reduces model reliability.", "method": "Systematic human-intervention prompts across various tasks to evaluate sycophantic tendencies.", "result": "LLMs exhibit sycophancy in subjective queries but remain accurate in objective tasks like math, ignoring user hints.", "conclusion": "Sycophantic behavior in LLMs undermines reliability in subjective contexts, highlighting the need for mitigation strategies."}}
{"id": "2506.20616", "pdf": "https://arxiv.org/pdf/2506.20616", "abs": "https://arxiv.org/abs/2506.20616", "authors": ["Quoc-Duy Tran", "Anh-Tuan Vo", "Dinh-Khoi Vo", "Tam V. Nguyen", "Minh-Triet Tran", "Trung-Nghia Le"], "title": "Shape2Animal: Creative Animal Generation from Natural Silhouettes", "categories": ["cs.CV"], "comment": null, "summary": "Humans possess a unique ability to perceive meaningful patterns in ambiguous\nstimuli, a cognitive phenomenon known as pareidolia. This paper introduces\nShape2Animal framework to mimics this imaginative capacity by reinterpreting\nnatural object silhouettes, such as clouds, stones, or flames, as plausible\nanimal forms. Our automated framework first performs open-vocabulary\nsegmentation to extract object silhouette and interprets semantically\nappropriate animal concepts using vision-language models. It then synthesizes\nan animal image that conforms to the input shape, leveraging text-to-image\ndiffusion model and seamlessly blends it into the original scene to generate\nvisually coherent and spatially consistent compositions. We evaluated\nShape2Animal on a diverse set of real-world inputs, demonstrating its\nrobustness and creative potential. Our Shape2Animal can offer new opportunities\nfor visual storytelling, educational content, digital art, and interactive\nmedia design. Our project page is here: https://shape2image.github.io", "AI": {"tldr": "Shape2Animal is an automated framework that mimics human pareidolia by transforming natural object silhouettes into plausible animal forms using vision-language models and text-to-image diffusion.", "motivation": "To replicate the human ability to perceive meaningful patterns (pareidolia) in ambiguous stimuli like clouds or stones, enabling creative applications in storytelling, education, and art.", "method": "Uses open-vocabulary segmentation to extract silhouettes, interprets animal concepts via vision-language models, and synthesizes animal images with text-to-image diffusion, blending them into the original scene.", "result": "Demonstrated robustness and creative potential on diverse real-world inputs, generating visually coherent and spatially consistent compositions.", "conclusion": "Shape2Animal opens new opportunities for visual storytelling, educational content, digital art, and interactive media design."}}
{"id": "2506.20156", "pdf": "https://arxiv.org/pdf/2506.20156", "abs": "https://arxiv.org/abs/2506.20156", "authors": ["Xuefei Hou", "Xizhao Tan"], "title": "Irec: A Metacognitive Scaffolding for Self-Regulated Learning through Just-in-Time Insight Recall: A Conceptual Framework and System Prototype", "categories": ["cs.HC", "cs.AI", "cs.IR", "H.5.2; I.2.7; H.3.3"], "comment": "Version 1 of a work in progress. Finalized system flowcharts, a\n  public GitHub repository with the source code, and a full reproducibility\n  package detailing the prompts, models, and testing guidelines will be\n  provided in v2", "summary": "The core challenge in learning has shifted from knowledge acquisition to\neffective Self-Regulated Learning (SRL): planning, monitoring, and reflecting\non one's learning. Existing digital tools, however, inadequately support\nmetacognitive reflection. Spaced Repetition Systems (SRS) use de-contextualized\nreview, overlooking the role of context, while Personal Knowledge Management\n(PKM) tools require high manual maintenance.\n  To address these challenges, this paper introduces \"Insight Recall,\" a novel\nparadigm that conceptualizes the context-triggered retrieval of personal past\ninsights as a metacognitive scaffold to promote SRL. We formalize this paradigm\nusing the Just-in-Time Adaptive Intervention (JITAI) framework and implement a\nprototype system, Irec, to demonstrate its feasibility. At its core, Irec uses\na dynamic knowledge graph of the user's learning history. When a user faces a\nnew problem, a hybrid retrieval engine recalls relevant personal \"insights.\"\nSubsequently, a large language model (LLM) performs a deep similarity\nassessment to filter and present the most relevant scaffold in a just-in-time\nmanner. To reduce cognitive load, Irec features a human-in-the-loop pipeline\nfor LLM-based knowledge graph construction. We also propose an optional \"Guided\nInquiry\" module, where users can engage in a Socratic dialogue with an expert\nLLM, using the current problem and recalled insights as context. The\ncontribution of this paper is a solid theoretical framework and a usable system\nplatform for designing next-generation intelligent learning systems that\nenhance metacognition and self-regulation.", "AI": {"tldr": "The paper introduces 'Insight Recall,' a paradigm using context-triggered retrieval of past insights to support Self-Regulated Learning (SRL), implemented in the prototype system 'Irec.'", "motivation": "Existing tools like Spaced Repetition Systems and Personal Knowledge Management tools fail to adequately support metacognitive reflection in learning.", "method": "The paper formalizes the Insight Recall paradigm using the Just-in-Time Adaptive Intervention framework, implementing it in 'Irec,' which uses a dynamic knowledge graph and LLM for retrieval and filtering.", "result": "The prototype system 'Irec' demonstrates feasibility, offering a human-in-the-loop pipeline and optional 'Guided Inquiry' module for enhanced metacognition.", "conclusion": "The work provides a theoretical framework and system platform for next-generation learning tools that improve metacognition and self-regulation."}}
{"id": "2506.20285", "pdf": "https://arxiv.org/pdf/2506.20285", "abs": "https://arxiv.org/abs/2506.20285", "authors": ["Zeqi Leng", "Chunxu Zhang", "Guodong Long", "Riting Xia", "Bo Yang"], "title": "Distilling A Universal Expert from Clustered Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Clustered Federated Learning (CFL) addresses the challenges posed by non-IID\ndata by training multiple group- or cluster-specific expert models. However,\nexisting methods often overlook the shared information across clusters, which\nrepresents the generalizable knowledge valuable to all participants in the\nFederated Learning (FL) system. To overcome this limitation, this paper\nintroduces a novel FL framework that distills a universal expert model from the\nknowledge of multiple clusters. This universal expert captures globally shared\ninformation across all clients and is subsequently distributed to each client\nas the initialization for the next round of model training. The proposed FL\nframework operates in three iterative steps: (1) local model training at each\nclient, (2) cluster-specific model aggregation, and (3) universal expert\ndistillation. This three-step learning paradigm ensures the preservation of\nfine-grained non-IID characteristics while effectively incorporating shared\nknowledge across clusters. Compared to traditional gradient-based aggregation\nmethods, the distillation-based model aggregation introduces greater\nflexibility in handling model heterogeneity and reduces conflicts among\ncluster-specific experts. Extensive experimental results demonstrate the\nsuperior performance of the proposed method across various scenarios,\nhighlighting its potential to advance the state of CFL by balancing\npersonalized and shared knowledge more effectively.", "AI": {"tldr": "A novel FL framework introduces a universal expert model to capture shared knowledge across clusters in CFL, improving performance by balancing personalized and shared knowledge.", "motivation": "Existing CFL methods overlook shared information across clusters, limiting generalizable knowledge in FL systems.", "method": "The framework involves three iterative steps: local model training, cluster-specific aggregation, and universal expert distillation.", "result": "The method outperforms traditional gradient-based aggregation, handling model heterogeneity better and reducing conflicts.", "conclusion": "The proposed framework advances CFL by effectively balancing personalized and shared knowledge."}}
{"id": "2403.19827", "pdf": "https://arxiv.org/pdf/2403.19827", "abs": "https://arxiv.org/abs/2403.19827", "authors": ["Kanishka Misra", "Kyle Mahowald"], "title": "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs", "categories": ["cs.CL"], "comment": "Added Corrigendum to correct 4-gram baseline performance and chance\n  performance", "summary": "Language models learn rare syntactic phenomena, but the extent to which this\nis attributable to generalization vs. memorization is a major open question. To\nthat end, we iteratively trained transformer language models on systematically\nmanipulated corpora which were human-scale in size, and then evaluated their\nlearning of a rare grammatical phenomenon: the English\nArticle+Adjective+Numeral+Noun (AANN) construction (``a beautiful five days'').\nWe compared how well this construction was learned on the default corpus\nrelative to a counterfactual corpus in which AANN sentences were removed. We\nfound that AANNs were still learned better than systematically perturbed\nvariants of the construction. Using additional counterfactual corpora, we\nsuggest that this learning occurs through generalization from related\nconstructions (e.g., ``a few days''). An additional experiment showed that this\nlearning is enhanced when there is more variability in the input. Taken\ntogether, our results provide an existence proof that LMs can learn rare\ngrammatical phenomena by generalization from less rare phenomena. Data and\ncode: https://github.com/kanishkamisra/aannalysis.", "AI": {"tldr": "The paper investigates whether language models learn rare syntactic phenomena through generalization or memorization, focusing on the English AANN construction.", "motivation": "To determine if language models generalize or memorize rare grammatical structures like the AANN construction.", "method": "Iteratively trained transformer models on manipulated corpora, comparing learning of AANN in default vs. counterfactual corpora.", "result": "AANNs were learned better than perturbed variants, suggesting generalization from related constructions. Increased input variability enhanced learning.", "conclusion": "Language models can learn rare grammatical phenomena by generalizing from less rare constructions."}}
{"id": "2506.20638", "pdf": "https://arxiv.org/pdf/2506.20638", "abs": "https://arxiv.org/abs/2506.20638", "authors": ["Cl\u00e9ment Forray", "Pauline Delporte", "Nicolas Delaygue", "Florence Genin", "Dawa Derksen"], "title": "Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects", "categories": ["cs.CV"], "comment": "accepted for CVPR 2025 NFBCC workshop", "summary": "Obtaining a better knowledge of the current state and behavior of objects\norbiting Earth has proven to be essential for a range of applications such as\nactive debris removal, in-orbit maintenance, or anomaly detection. 3D models\nrepresent a valuable source of information in the field of Space Situational\nAwareness (SSA). In this work, we leveraged Neural Radiance Fields (NeRF) to\nperform 3D reconstruction of non-cooperative space objects from simulated\nimages. This scenario is challenging for NeRF models due to unusual camera\ncharacteristics and environmental conditions : mono-chromatic images, unknown\nobject orientation, limited viewing angles, absence of diffuse lighting etc. In\nthis work we focus primarly on the joint optimization of camera poses alongside\nthe NeRF. Our experimental results show that the most accurate 3D\nreconstruction is achieved when training with successive images one-by-one. We\nestimate camera poses by optimizing an uniform rotation and use regularization\nto prevent successive poses from being too far apart.", "AI": {"tldr": "The paper explores using Neural Radiance Fields (NeRF) for 3D reconstruction of non-cooperative space objects from simulated images, focusing on joint optimization of camera poses and NeRF.", "motivation": "Understanding the state and behavior of Earth-orbiting objects is crucial for applications like debris removal and anomaly detection. 3D models enhance Space Situational Awareness (SSA).", "method": "Leverages NeRF for 3D reconstruction, addressing challenges like monochromatic images, unknown object orientation, and limited viewing angles. Focuses on optimizing camera poses jointly with NeRF.", "result": "Most accurate 3D reconstruction is achieved by training with successive images one-by-one, using uniform rotation for camera pose estimation and regularization to limit pose divergence.", "conclusion": "Joint optimization of camera poses and NeRF improves 3D reconstruction accuracy for non-cooperative space objects, advancing SSA capabilities."}}
{"id": "2506.20159", "pdf": "https://arxiv.org/pdf/2506.20159", "abs": "https://arxiv.org/abs/2506.20159", "authors": ["Tomas Herda", "Victoria Pichler", "Zheying Zhang", "Pekka Abrahamsson", "Geir K. Hanssen"], "title": "AI and Agile Software Development: From Frustration to Success -- XP2025 Workshop Summary", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The full-day workshop on AI and Agile at XP 2025 convened a diverse group of\nresearchers and industry practitioners to address the practical challenges and\nopportunities of integrating Artificial Intelligence into Agile software\ndevelopment. Through interactive sessions, participants identified shared\nfrustrations related to integrating AI into Agile Software Development\npractices, including challenges with tooling, governance, data quality, and\ncritical skill gaps. These challenges were systematically prioritized and\nanalyzed to uncover root causes. The workshop culminated in the collaborative\ndevelopment of a research roadmap that pinpoints actionable directions for\nfuture work, including both immediate solutions and ambitious long-term goals.\nThe key outcome is a structured agenda designed to foster joint\nindustry-academic efforts to move from identified frustrations to successful\nimplementation.", "AI": {"tldr": "Workshop on AI and Agile identified challenges like tooling, governance, data quality, and skill gaps, leading to a research roadmap for future solutions.", "motivation": "Address practical challenges of integrating AI into Agile software development.", "method": "Interactive sessions to identify, prioritize, and analyze challenges, followed by collaborative roadmap development.", "result": "Structured research agenda for industry-academic collaboration to tackle AI-Agile integration.", "conclusion": "Workshop provided actionable directions for future work, bridging frustrations to implementation."}}
{"id": "2506.20305", "pdf": "https://arxiv.org/pdf/2506.20305", "abs": "https://arxiv.org/abs/2506.20305", "authors": ["Kazuki Yoda", "Kazuhiko Kawamoto", "Hiroshi Kera"], "title": "Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding", "categories": ["cs.LG", "cs.CV"], "comment": "17 pages, 13 figures", "summary": "The hardness of learning a function that attains a target task relates to its\ninput-sensitivity. For example, image classification tasks are\ninput-insensitive as minor corruptions should not affect the classification\nresults, whereas arithmetic and symbolic computation, which have been recently\nattracting interest, are highly input-sensitive as each input variable connects\nto the computation results. This study presents the first learning-based Quick\nResponse (QR) code decoding and investigates learning functions of medium\nsensitivity. Our experiments reveal that Transformers can successfully decode\nQR codes, even beyond the theoretical error-correction limit, by learning the\nstructure of embedded texts. They generalize from English-rich training data to\nother languages and even random strings. Moreover, we observe that the\nTransformer-based QR decoder focuses on data bits while ignoring\nerror-correction bits, suggesting a decoding mechanism distinct from standard\nQR code readers.", "AI": {"tldr": "The paper explores learning functions of medium sensitivity, using Transformers for QR code decoding, achieving results beyond theoretical error-correction limits.", "motivation": "To investigate the relationship between input-sensitivity and learning hardness, focusing on medium-sensitivity tasks like QR code decoding.", "method": "Employed Transformers to decode QR codes, analyzing their ability to learn embedded text structures and generalize across languages and random strings.", "result": "Transformers successfully decoded QR codes beyond theoretical limits, focusing on data bits while ignoring error-correction bits.", "conclusion": "Transformers offer a distinct decoding mechanism for QR codes, demonstrating potential for learning medium-sensitivity functions."}}
{"id": "2407.21049", "pdf": "https://arxiv.org/pdf/2407.21049", "abs": "https://arxiv.org/abs/2407.21049", "authors": ["Yannick Assogba", "Donghao Ren"], "title": "Evaluating Long Range Dependency Handling in Code Generation LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": "36 pages, 18 figures", "summary": "As language models support larger and larger context sizes, evaluating their\nability to make effective use of that context becomes increasingly important.\nWe analyze the ability of several code generation models to handle long range\ndependencies using a suite of multi-step key retrieval tasks in context windows\nup to 8k tokens in length. The tasks progressively increase in difficulty and\nallow more nuanced evaluation of model capabilities than tests like the popular\nneedle-in-the-haystack test. We find that performance degrades significantly\nfor many models (up to 2x) when a function references another function that is\ndefined later in the prompt. We also observe that models that use sliding\nwindow attention mechanisms have difficulty handling references further than\nthe size of a single window. We perform simple prompt modifications using call\ngraph information to improve multi-step retrieval performance up to 3x. Our\nanalysis highlights ways that long-context performance needs deeper\nconsideration beyond retrieval of single facts within a document.", "AI": {"tldr": "The paper evaluates code generation models' ability to handle long-range dependencies in large context windows (up to 8k tokens), finding performance degradation when functions reference later-defined functions. Sliding window attention models struggle with distant references, but prompt modifications improve retrieval performance.", "motivation": "To assess how well language models utilize large context sizes, especially for multi-step tasks, beyond simple fact retrieval.", "method": "Analyzed code generation models using multi-step key retrieval tasks with progressively increasing difficulty in 8k-token contexts. Evaluated performance degradation and tested prompt modifications using call graph information.", "result": "Performance drops significantly (up to 2x) when functions reference later-defined ones. Sliding window attention models fail with distant references. Prompt modifications improved retrieval up to 3x.", "conclusion": "Long-context performance requires deeper evaluation beyond single-fact retrieval, and prompt adjustments can enhance model capabilities."}}
{"id": "2506.20649", "pdf": "https://arxiv.org/pdf/2506.20649", "abs": "https://arxiv.org/abs/2506.20649", "authors": ["Jacopo Dapueto", "Vito Paolo Pastore", "Nicoletta Noceti", "Francesca Odone"], "title": "Disentangled representations of microscopy images", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Published in: International Joint Conference on Neural Networks\n  (IJCNN 2025). Project page:\n  https://github.com/JacopoDapueto/disentangled_microscopy", "summary": "Microscopy image analysis is fundamental for different applications, from\ndiagnosis to synthetic engineering and environmental monitoring. Modern\nacquisition systems have granted the possibility to acquire an escalating\namount of images, requiring a consequent development of a large collection of\ndeep learning-based automatic image analysis methods. Although deep neural\nnetworks have demonstrated great performance in this field, interpretability,\nan essential requirement for microscopy image analysis, remains an open\nchallenge.\n  This work proposes a Disentangled Representation Learning (DRL) methodology\nto enhance model interpretability for microscopy image classification.\nExploiting benchmark datasets from three different microscopic image domains\n(plankton, yeast vacuoles, and human cells), we show how a DRL framework, based\non transferring a representation learnt from synthetic data, can provide a good\ntrade-off between accuracy and interpretability in this domain.", "AI": {"tldr": "A Disentangled Representation Learning (DRL) method is proposed to improve interpretability in microscopy image classification, balancing accuracy and interpretability across three domains.", "motivation": "Interpretability is crucial for microscopy image analysis, yet remains a challenge despite deep learning advancements.", "method": "DRL framework using synthetic data transfer is applied to microscopy image classification.", "result": "The method achieves a good trade-off between accuracy and interpretability in plankton, yeast vacuoles, and human cell datasets.", "conclusion": "DRL enhances interpretability in microscopy image analysis without compromising accuracy."}}
{"id": "2506.20164", "pdf": "https://arxiv.org/pdf/2506.20164", "abs": "https://arxiv.org/abs/2506.20164", "authors": ["Mototaka Suzuki", "Jaan Aru"], "title": "Do psychic cells generate consciousness?", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "Technological advances in the past decades have begun to enable\nneuroscientists to address fundamental questions about consciousness in an\nunprecedented way. Here we review remarkable recent progress in our\nunderstanding of cellular-level mechanisms of conscious processing in the\nbrain. Of particular interest are the cortical pyramidal neurons -- or \"psychic\ncells\" called by Ram\\'on y Cajal more than 100 years ago -- which have an\nintriguing cellular mechanism that accounts for selective disruption of\nfeedback signaling in the brain upon anesthetic-induced loss of consciousness.\nImportantly, a particular class of metabotropic receptors distributed over the\ndendrites of pyramidal cells are highlighted as the key cellular mechanism.\nAfter all, Cajal's instinct over a century ago may turn out to be correct -- we\nmay have just begun to understand whether and how psychic cells indeed generate\nand control our consciousness.", "AI": {"tldr": "Recent progress reveals cortical pyramidal neurons, dubbed 'psychic cells,' as key to understanding consciousness, with metabotropic receptors on their dendrites playing a crucial role.", "motivation": "To explore cellular-level mechanisms of consciousness, leveraging technological advances to validate historical hypotheses.", "method": "Review of recent research on cortical pyramidal neurons and their role in conscious processing, focusing on anesthetic-induced disruptions.", "result": "Identified metabotropic receptors on pyramidal cell dendrites as a key mechanism for consciousness disruption under anesthesia.", "conclusion": "Cajal's 'psychic cells' may indeed be central to consciousness, with modern findings supporting his century-old intuition."}}
{"id": "2506.20307", "pdf": "https://arxiv.org/pdf/2506.20307", "abs": "https://arxiv.org/abs/2506.20307", "authors": ["Heyang Zhao", "Xingrui Yu", "David M. Bossens", "Ivor W. Tsang", "Quanquan Gu"], "title": "Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Imitation learning is a central problem in reinforcement learning where the\ngoal is to learn a policy that mimics the expert's behavior. In practice, it is\noften challenging to learn the expert policy from a limited number of\ndemonstrations accurately due to the complexity of the state space. Moreover,\nit is essential to explore the environment and collect data to achieve\nbeyond-expert performance. To overcome these challenges, we propose a novel\nimitation learning algorithm called Imitation Learning with Double Exploration\n(ILDE), which implements exploration in two aspects: (1) optimistic policy\noptimization via an exploration bonus that rewards state-action pairs with high\nuncertainty to potentially improve the convergence to the expert policy, and\n(2) curiosity-driven exploration of the states that deviate from the\ndemonstration trajectories to potentially yield beyond-expert performance.\nEmpirically, we demonstrate that ILDE outperforms the state-of-the-art\nimitation learning algorithms in terms of sample efficiency and achieves\nbeyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations\nthan in previous work. We also provide a theoretical justification of ILDE as\nan uncertainty-regularized policy optimization method with optimistic\nexploration, leading to a regret growing sublinearly in the number of episodes.", "AI": {"tldr": "ILDE is a novel imitation learning algorithm that uses double exploration (optimistic policy optimization and curiosity-driven exploration) to improve sample efficiency and achieve beyond-expert performance.", "motivation": "The challenge of accurately learning expert policies from limited demonstrations due to complex state spaces and the need for exploration to surpass expert performance.", "method": "ILDE combines optimistic policy optimization (rewarding uncertain state-action pairs) and curiosity-driven exploration (exploring states outside demonstrations).", "result": "ILDE outperforms state-of-the-art algorithms in sample efficiency and achieves beyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations.", "conclusion": "ILDE is theoretically justified as an uncertainty-regularized policy optimization method with sublinear regret growth, proving its effectiveness."}}
{"id": "2409.08160", "pdf": "https://arxiv.org/pdf/2409.08160", "abs": "https://arxiv.org/abs/2409.08160", "authors": ["Andreas Opedal", "Eleanor Chodroff", "Ryan Cotterell", "Ethan Gotlieb Wilcox"], "title": "On the Role of Context in Reading Time Prediction", "categories": ["cs.CL", "cs.LG"], "comment": "EMNLP 2024; preprocessing was corrected to exclude variance due to\n  word skipping and the conclusions remain unchanged", "summary": "We present a new perspective on how readers integrate context during\nreal-time language comprehension. Our proposals build on surprisal theory,\nwhich posits that the processing effort of a linguistic unit (e.g., a word) is\nan affine function of its in-context information content. We first observe that\nsurprisal is only one out of many potential ways that a contextual predictor\ncan be derived from a language model. Another one is the pointwise mutual\ninformation (PMI) between a unit and its context, which turns out to yield the\nsame predictive power as surprisal when controlling for unigram frequency.\nMoreover, both PMI and surprisal are correlated with frequency. This means that\nneither PMI nor surprisal contains information about context alone. In response\nto this, we propose a technique where we project surprisal onto the orthogonal\ncomplement of frequency, yielding a new contextual predictor that is\nuncorrelated with frequency. Our experiments show that the proportion of\nvariance in reading times explained by context is a lot smaller when context is\nrepresented by the orthogonalized predictor. From an interpretability\nstandpoint, this indicates that previous studies may have overstated the role\nthat context has in predicting reading times.", "AI": {"tldr": "The paper explores how context is integrated in language comprehension, proposing an orthogonalized predictor to separate context effects from frequency.", "motivation": "To better understand the role of context in language processing by addressing the confounding effects of word frequency.", "method": "Proposes projecting surprisal onto the orthogonal complement of frequency to create a new contextual predictor uncorrelated with frequency.", "result": "Experiments show context explains less variance in reading times when using the orthogonalized predictor, suggesting previous studies overstated context's role.", "conclusion": "The study highlights the need to disentangle context from frequency in language comprehension research."}}
{"id": "2506.20671", "pdf": "https://arxiv.org/pdf/2506.20671", "abs": "https://arxiv.org/abs/2506.20671", "authors": ["Markus Gross", "Aya Fahmy", "Danit Niwattananan", "Dominik Muhle", "Rui Song", "Daniel Cremers", "Henri Mee\u00df"], "title": "IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals", "categories": ["cs.CV"], "comment": null, "summary": "Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointly\nlearning scene geometry and semantics, enabling downstream applications such as\nnavigation in mobile robotics. The recent generalization to Panoptic Scene\nCompletion (PSC) advances the SSC domain by integrating instance-level\ninformation, thereby enhancing object-level sensitivity in scene understanding.\nWhile PSC was introduced using LiDAR modality, methods based on camera images\nremain largely unexplored. Moreover, recent Transformer-based SSC approaches\nutilize a fixed set of learned queries to reconstruct objects within the scene\nvolume. Although these queries are typically updated with image context during\ntraining, they remain static at test time, limiting their ability to\ndynamically adapt specifically to the observed scene. To overcome these\nlimitations, we propose IPFormer, the first approach that leverages\ncontext-adaptive instance proposals at train and test time to address\nvision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptively\ninitializes these queries as panoptic instance proposals derived from image\ncontext and further refines them through attention-based encoding and decoding\nto reason about semantic instance-voxel relationships. Experimental results\nshow that our approach surpasses state-of-the-art methods in overall panoptic\nmetrics PQ$^\\dagger$ and PQ-All, matches performance in individual metrics, and\nachieves a runtime reduction exceeding 14$\\times$. Furthermore, our ablation\nstudies reveal that dynamically deriving instance proposals from image context,\nas opposed to random initialization, leads to a 3.62% increase in PQ-All and a\nremarkable average improvement of 18.65% in combined Thing-metrics. These\nresults highlight our introduction of context-adaptive instance proposals as a\npioneering effort in addressing vision-based 3D Panoptic Scene Completion.", "AI": {"tldr": "IPFormer introduces context-adaptive instance proposals for vision-based 3D Panoptic Scene Completion, outperforming state-of-the-art methods in panoptic metrics and runtime efficiency.", "motivation": "To address the limitations of static queries in Transformer-based SSC methods and the unexplored potential of camera-based PSC, IPFormer dynamically adapts instance proposals to the observed scene.", "method": "IPFormer adaptively initializes panoptic instance proposals from image context and refines them through attention-based encoding and decoding to reason about semantic instance-voxel relationships.", "result": "IPFormer surpasses state-of-the-art methods in PQ$^\\dagger$ and PQ-All metrics, achieves a 14x runtime reduction, and improves Thing-metrics by 18.65% through dynamic proposal initialization.", "conclusion": "IPFormer's context-adaptive instance proposals mark a pioneering advancement in vision-based 3D Panoptic Scene Completion, demonstrating significant performance gains and efficiency."}}
{"id": "2506.20173", "pdf": "https://arxiv.org/pdf/2506.20173", "abs": "https://arxiv.org/abs/2506.20173", "authors": ["Mahmoud Hegazy", "Liviu Aolaritei", "Michael I. Jordan", "Aymeric Dieuleveut"], "title": "Valid Selection among Conformal Sets", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME", "stat.OT"], "comment": null, "summary": "Conformal prediction offers a distribution-free framework for constructing\nprediction sets with coverage guarantees. In practice, multiple valid conformal\nprediction sets may be available, arising from different models or\nmethodologies. However, selecting the most desirable set, such as the smallest,\ncan invalidate the coverage guarantees. To address this challenge, we propose a\nstability-based approach that ensures coverage for the selected prediction set.\nWe extend our results to the online conformal setting, propose several\nrefinements in settings where additional structure is available, and\ndemonstrate its effectiveness through experiments.", "AI": {"tldr": "A stability-based approach ensures coverage guarantees for selected conformal prediction sets, even when choosing the smallest set, with extensions to online settings and refinements for structured data.", "motivation": "To address the challenge of selecting the most desirable conformal prediction set (e.g., the smallest) without invalidating coverage guarantees.", "method": "Proposes a stability-based approach to ensure coverage for the selected prediction set, extends it to online conformal settings, and refines it for structured data.", "result": "Demonstrates effectiveness through experiments, showing coverage guarantees are maintained.", "conclusion": "The stability-based approach successfully ensures coverage for selected prediction sets, with practical extensions and refinements."}}
{"id": "2506.20323", "pdf": "https://arxiv.org/pdf/2506.20323", "abs": "https://arxiv.org/abs/2506.20323", "authors": ["Saundarya Subramaniam", "Shalini Majumdar", "Shantanu Nadar", "Kaustubh Kulkarni"], "title": "Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This research presents the development of an Artificial Intelligence (AI) -\ndriven crop disease detection system designed to assist farmers in rural areas\nwith limited resources. We aim to compare different deep learning models for a\ncomparative analysis, focusing on their efficacy in transfer learning. By\nleveraging deep learning models, including EfficientNet, ResNet101,\nMobileNetV2, and our custom CNN, which achieved a validation accuracy of\n95.76%, the system effectively classifies plant diseases. This research\ndemonstrates the potential of transfer learning in reshaping agricultural\npractices, improving crop health management, and supporting sustainable farming\nin rural environments.", "AI": {"tldr": "AI-driven crop disease detection system using deep learning models, achieving 95.76% accuracy, aims to aid rural farmers.", "motivation": "To assist farmers in rural areas with limited resources by improving crop disease detection and management.", "method": "Comparative analysis of deep learning models (EfficientNet, ResNet101, MobileNetV2, custom CNN) for transfer learning efficacy.", "result": "Custom CNN achieved 95.76% validation accuracy in classifying plant diseases.", "conclusion": "Transfer learning can reshape agricultural practices, enhancing crop health and sustainability in rural areas."}}
{"id": "2410.02899", "pdf": "https://arxiv.org/pdf/2410.02899", "abs": "https://arxiv.org/abs/2410.02899", "authors": ["Deema Alnuhait", "Neeraja Kirtane", "Muhammad Khalifa", "Hao Peng"], "title": "FactCheckmate: Preemptively Detecting and Mitigating Hallucinations in LMs", "categories": ["cs.CL"], "comment": null, "summary": "Language models (LMs) hallucinate. We inquire: Can we detect and mitigate\nhallucinations before they happen? This work answers this research question in\nthe positive, by showing that the internal representations of LMs provide rich\nsignals that can be used for this purpose. We introduce FactCheckmate, which\npreemptively detects hallucinations by learning a classifier that predicts\nwhether the LM will hallucinate, based on the model's hidden states produced\nover the inputs, before decoding begins. If a hallucination is detected,\nFactCheckmate then intervenes by adjusting the LM's hidden states such that the\nmodel will produce more factual outputs. FactCheckmate provides fresh insights\nthat the inner workings of LMs can be revealed by their hidden states.\nPractically, both its detection and mitigation models are lightweight, adding\nlittle inference overhead; FactCheckmate proves a more efficient approach for\nmitigating hallucinations compared to many post-hoc alternatives. We evaluate\nFactCheckmate over LMs of different scales and model families (including Llama,\nMistral, Qwen and Gemma), across a variety of QA datasets from different\ndomains. Our results demonstrate the effectiveness of FactCheckmate, achieving\nover 70% preemptive detection accuracy. On average, outputs generated by LMs\nwith intervention are 34.4% more factual compared to those without.", "AI": {"tldr": "FactCheckmate detects and mitigates LM hallucinations preemptively using hidden states, improving factual accuracy by 34.4%.", "motivation": "To address LM hallucinations by leveraging internal representations for early detection and intervention.", "method": "FactCheckmate learns a classifier to predict hallucinations from hidden states and adjusts them to improve output factuality.", "result": "Achieves 70% preemptive detection accuracy and 34.4% more factual outputs with intervention.", "conclusion": "FactCheckmate efficiently mitigates hallucinations using hidden states, outperforming post-hoc methods."}}
{"id": "2506.19860", "pdf": "https://arxiv.org/pdf/2506.19860", "abs": "https://arxiv.org/abs/2506.19860", "authors": ["Oktay Karaku\u015f", "Padraig Corcoran"], "title": "A Multi-Modal Spatial Risk Framework for EV Charging Infrastructure Using Remote Sensing", "categories": ["eess.SP", "cs.CV"], "comment": "11 pages, 4 figures, 2 tables", "summary": "Electric vehicle (EV) charging infrastructure is increasingly critical to\nsustainable transport systems, yet its resilience under environmental and\ninfrastructural stress remains underexplored. In this paper, we introduce\nRSERI-EV, a spatially explicit and multi-modal risk assessment framework that\ncombines remote sensing data, open infrastructure datasets, and spatial graph\nanalytics to evaluate the vulnerability of EV charging stations. RSERI-EV\nintegrates diverse data layers, including flood risk maps, land surface\ntemperature (LST) extremes, vegetation indices (NDVI), land use/land cover\n(LULC), proximity to electrical substations, and road accessibility to generate\na composite Resilience Score. We apply this framework to the country of Wales\nEV charger dataset to demonstrate its feasibility. A spatial $k$-nearest\nneighbours ($k$NN) graph is constructed over the charging network to enable\nneighbourhood-based comparisons and graph-aware diagnostics. Our prototype\nhighlights the value of multi-source data fusion and interpretable spatial\nreasoning in supporting climate-resilient, infrastructure-aware EV deployment.", "AI": {"tldr": "The paper introduces RSERI-EV, a framework for assessing EV charging station resilience using multi-source data and spatial analytics, applied to Wales.", "motivation": "To address the underexplored resilience of EV charging infrastructure under environmental and infrastructural stress.", "method": "Combines remote sensing, open datasets, and spatial graph analytics to evaluate vulnerability, using flood risk, LST, NDVI, LULC, substation proximity, and road accessibility.", "result": "Demonstrates feasibility with Wales EV charger dataset, using kNN graphs for neighborhood comparisons and diagnostics.", "conclusion": "Highlights the value of multi-source data fusion and spatial reasoning for climate-resilient EV infrastructure."}}
{"id": "2506.20324", "pdf": "https://arxiv.org/pdf/2506.20324", "abs": "https://arxiv.org/abs/2506.20324", "authors": ["Torben Berndt", "Benjamin Walker", "Tiexin Qin", "Jan St\u00fchmer", "Andrey Kormilitzin"], "title": "Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Dynamic graphs exhibit complex temporal dynamics due to the interplay between\nevolving node features and changing network structures. Recently, Graph Neural\nControlled Differential Equations (Graph Neural CDEs) successfully adapted\nNeural CDEs from paths on Euclidean domains to paths on graph domains. Building\non this foundation, we introduce Permutation Equivariant Neural Graph CDEs,\nwhich project Graph Neural CDEs onto permutation equivariant function spaces.\nThis significantly reduces the model's parameter count without compromising\nrepresentational power, resulting in more efficient training and improved\ngeneralisation. We empirically demonstrate the advantages of our approach\nthrough experiments on simulated dynamical systems and real-world tasks,\nshowing improved performance in both interpolation and extrapolation scenarios.", "AI": {"tldr": "Permutation Equivariant Neural Graph CDEs enhance Graph Neural CDEs by reducing parameters while maintaining performance, improving efficiency and generalization.", "motivation": "To address the complexity of dynamic graphs by leveraging permutation equivariance for efficiency without losing representational power.", "method": "Projects Graph Neural CDEs onto permutation equivariant function spaces, reducing parameters.", "result": "Improved performance in interpolation and extrapolation tasks on simulated and real-world data.", "conclusion": "The approach offers a more efficient and generalizable solution for dynamic graph modeling."}}
{"id": "2410.19494", "pdf": "https://arxiv.org/pdf/2410.19494", "abs": "https://arxiv.org/abs/2410.19494", "authors": ["Christos Xypolopoulos", "Guokan Shang", "Xiao Fei", "Giannis Nikolentzos", "Hadi Abdine", "Iakovos Evdaimon", "Michail Chatzianastasis", "Giorgos Stamou", "Michalis Vazirgiannis"], "title": "Graph Linearization Methods for Reasoning on Graphs with Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models have evolved to process multiple modalities beyond\ntext, such as images and audio, which motivates us to explore how to\neffectively leverage them for graph reasoning tasks. The key question,\ntherefore, is how to transform graphs into linear sequences of tokens, a\nprocess we term \"graph linearization\", so that LLMs can handle graphs\nnaturally. We consider that graphs should be linearized meaningfully to reflect\ncertain properties of natural language text, such as local dependency and\nglobal alignment, in order to ease contemporary LLMs, trained on trillions of\ntextual tokens, better understand graphs. To achieve this, we developed several\ngraph linearization methods based on graph centrality and degeneracy. These\nmethods are further enhanced using node relabeling techniques. The experimental\nresults demonstrate the effectiveness of our methods compared to the random\nlinearization baseline. Our work introduces novel graph representations\nsuitable for LLMs, contributing to the potential integration of graph machine\nlearning with the trend of multimodal processing using a unified transformer\nmodel.", "AI": {"tldr": "The paper explores graph linearization methods to adapt graphs for processing by large language models (LLMs), enhancing their ability to handle graph reasoning tasks.", "motivation": "To leverage LLMs for graph reasoning by transforming graphs into token sequences that align with natural language properties like local dependency and global alignment.", "method": "Developed graph linearization techniques based on centrality and degeneracy, enhanced with node relabeling.", "result": "Experimental results show the methods outperform random linearization baselines.", "conclusion": "The work introduces effective graph representations for LLMs, bridging graph machine learning with multimodal processing in transformers."}}
{"id": "2506.20045", "pdf": "https://arxiv.org/pdf/2506.20045", "abs": "https://arxiv.org/abs/2506.20045", "authors": ["Eric C. Joyce", "Qianwen Zhao", "Nathaniel Burgdorfer", "Long Wang", "Philippos Mordohai"], "title": "Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Deep object pose estimators are notoriously overconfident. A grasping agent\nthat both estimates the 6-DoF pose of a target object and predicts the\nuncertainty of its own estimate could avoid task failure by choosing not to act\nunder high uncertainty. Even though object pose estimation improves and\nuncertainty quantification research continues to make strides, few studies have\nconnected them to the downstream task of robotic grasping. We propose a method\nfor training lightweight, deep networks to predict whether a grasp guided by an\nimage-based pose estimate will succeed before that grasp is attempted. We\ngenerate training data for our networks via object pose estimation on real\nimages and simulated grasping. We also find that, despite high object\nvariability in grasping trials, networks benefit from training on all objects\njointly, suggesting that a diverse variety of objects can nevertheless\ncontribute to the same goal.", "AI": {"tldr": "A method for training deep networks to predict grasp success based on pose estimation uncertainty, improving robotic grasping reliability.", "motivation": "Addressing overconfidence in deep object pose estimators by integrating uncertainty quantification to avoid task failure in robotic grasping.", "method": "Training lightweight deep networks using real-image pose estimation and simulated grasping data, with joint training across diverse objects.", "result": "Networks trained on diverse objects jointly improve grasp success prediction, indicating shared learning benefits.", "conclusion": "Integrating pose estimation uncertainty into grasp prediction enhances robotic grasping reliability, with diverse training data improving performance."}}
{"id": "2506.20259", "pdf": "https://arxiv.org/pdf/2506.20259", "abs": "https://arxiv.org/abs/2506.20259", "authors": ["Andrej L\u00fa\u010dny", "Matilde Antonj", "Carlo Mazzola", "Hana Horn\u00e1\u010dkov\u00e1", "Igor Farka\u0161"], "title": "Generating and Customizing Robotic Arm Trajectories using Neural Networks", "categories": ["cs.RO", "cs.AI", "68T40, 93C85, 70E60", "I.2.9"], "comment": "The code is released at\n  https://github.com/andylucny/nico2/tree/main/generate", "summary": "We introduce a neural network approach for generating and customizing the\ntrajectory of a robotic arm, that guarantees precision and repeatability. To\nhighlight the potential of this novel method, we describe the design and\nimplementation of the technique and show its application in an experimental\nsetting of cognitive robotics. In this scenario, the NICO robot was\ncharacterized by the ability to point to specific points in space with precise\nlinear movements, increasing the predictability of the robotic action during\nits interaction with humans. To achieve this goal, the neural network computes\nthe forward kinematics of the robot arm. By integrating it with a generator of\njoint angles, another neural network was developed and trained on an artificial\ndataset created from suitable start and end poses of the robotic arm. Through\nthe computation of angular velocities, the robot was characterized by its\nability to perform the movement, and the quality of its action was evaluated in\nterms of shape and accuracy. Thanks to its broad applicability, our approach\nsuccessfully generates precise trajectories that could be customized in their\nshape and adapted to different settings.", "AI": {"tldr": "A neural network method for precise robotic arm trajectory generation and customization, tested in cognitive robotics with the NICO robot.", "motivation": "To enhance precision and repeatability in robotic arm movements, especially for human-robot interaction scenarios.", "method": "Uses neural networks for forward kinematics and joint angle generation, trained on artificial datasets of start/end poses. Evaluates movement quality via angular velocities, shape, and accuracy.", "result": "Successfully generates customizable, precise trajectories adaptable to various settings.", "conclusion": "The approach is broadly applicable and effective for precise robotic arm trajectory generation."}}
{"id": "2506.20329", "pdf": "https://arxiv.org/pdf/2506.20329", "abs": "https://arxiv.org/abs/2506.20329", "authors": ["Alexandre Rio", "Marta Soare", "Sihem Amer-Yahia"], "title": "Producer-Fairness in Sequential Bundle Recommendation", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "We address fairness in the context of sequential bundle recommendation, where\nusers are served in turn with sets of relevant and compatible items. Motivated\nby real-world scenarios, we formalize producer-fairness, that seeks to achieve\ndesired exposure of different item groups across users in a recommendation\nsession. Our formulation combines naturally with building high quality bundles.\nOur problem is solved in real time as users arrive. We propose an exact\nsolution that caters to small instances of our problem. We then examine two\nheuristics, quality-first and fairness-first, and an adaptive variant that\ndetermines on-the-fly the right balance between bundle fairness and quality.\nOur experiments on three real-world datasets underscore the strengths and\nlimitations of each solution and demonstrate their efficacy in providing fair\nbundle recommendations without compromising bundle quality.", "AI": {"tldr": "The paper addresses fairness in sequential bundle recommendations, proposing methods to balance exposure for item groups while maintaining bundle quality.", "motivation": "Real-world scenarios highlight the need for fair exposure of different item groups in sequential bundle recommendations.", "method": "The authors formalize producer-fairness, propose an exact solution for small instances, and examine heuristics (quality-first, fairness-first, and an adaptive variant) for real-time balancing.", "result": "Experiments on three datasets show the methods effectively provide fair recommendations without sacrificing quality.", "conclusion": "The proposed solutions successfully balance fairness and quality in bundle recommendations, with adaptive heuristics offering dynamic trade-offs."}}
{"id": "2411.08745", "pdf": "https://arxiv.org/pdf/2411.08745", "abs": "https://arxiv.org/abs/2411.08745", "authors": ["Cl\u00e9ment Dumas", "Chris Wendler", "Veniamin Veselovsky", "Giovanni Monea", "Robert West"], "title": "Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 14 figures, previous version published under the title \"How\n  Do Llamas Process Multilingual Text? A Latent Exploration through Activation\n  Patching\" at the ICML 2024 mechanistic interpretability workshop at\n  https://openreview.net/forum?id=0ku2hIm4BS", "summary": "A central question in multilingual language modeling is whether large\nlanguage models (LLMs) develop a universal concept representation, disentangled\nfrom specific languages. In this paper, we address this question by analyzing\nlatent representations (latents) during a word-translation task in\ntransformer-based LLMs. We strategically extract latents from a source\ntranslation prompt and insert them into the forward pass on a target\ntranslation prompt. By doing so, we find that the output language is encoded in\nthe latent at an earlier layer than the concept to be translated. Building on\nthis insight, we conduct two key experiments. First, we demonstrate that we can\nchange the concept without changing the language and vice versa through\nactivation patching alone. Second, we show that patching with the mean\nrepresentation of a concept across different languages does not affect the\nmodels' ability to translate it, but instead improves it. Finally, we\ngeneralize to multi-token generation and demonstrate that the model can\ngenerate natural language description of those mean representations. Our\nresults provide evidence for the existence of language-agnostic concept\nrepresentations within the investigated models.", "AI": {"tldr": "The paper investigates whether multilingual LLMs develop universal concept representations. By analyzing latent representations during translation tasks, it finds language and concept encoding layers, demonstrates control over concept and language separately, and shows improved translation using mean concept representations.", "motivation": "To determine if multilingual LLMs create language-agnostic concept representations, disentangled from specific languages.", "method": "Analyzes latent representations in transformer-based LLMs during word-translation tasks, using activation patching to manipulate concepts and languages separately.", "result": "Language is encoded earlier than concepts; patching with mean concept representations improves translation. The model can generate descriptions of mean representations.", "conclusion": "Evidence supports the existence of language-agnostic concept representations in the studied LLMs."}}
{"id": "2506.20267", "pdf": "https://arxiv.org/pdf/2506.20267", "abs": "https://arxiv.org/abs/2506.20267", "authors": ["Fabian Bongratz", "Tom Nuno Wolf", "Jaume Gual Ramon", "Christian Wachinger"], "title": "X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "MICCAI 2025", "summary": "Interpretable models are crucial for supporting clinical decision-making,\ndriving advances in their development and application for medical images.\nHowever, the nature of 3D volumetric data makes it inherently challenging to\nvisualize and interpret intricate and complex structures like the cerebral\ncortex. Cortical surface renderings, on the other hand, provide a more\naccessible and understandable 3D representation of brain anatomy, facilitating\nvisualization and interactive exploration. Motivated by this advantage and the\nwidespread use of surface data for studying neurological disorders, we present\nthe eXplainable Surface Vision Transformer (X-SiT). This is the first\ninherently interpretable neural network that offers human-understandable\npredictions based on interpretable cortical features. As part of X-SiT, we\nintroduce a prototypical surface patch decoder for classifying surface patch\nembeddings, incorporating case-based reasoning with spatially corresponding\ncortical prototypes. The results demonstrate state-of-the-art performance in\ndetecting Alzheimer's disease and frontotemporal dementia while additionally\nproviding informative prototypes that align with known disease patterns and\nreveal classification errors.", "AI": {"tldr": "The paper introduces X-SiT, an interpretable neural network for medical imaging, specifically for 3D brain data, achieving top performance in detecting Alzheimer's and frontotemporal dementia while providing understandable predictions.", "motivation": "The challenge of interpreting 3D volumetric medical data, especially for complex structures like the cerebral cortex, drives the need for more accessible and interpretable models like X-SiT.", "method": "X-SiT uses a prototypical surface patch decoder to classify surface patch embeddings, integrating case-based reasoning with cortical prototypes for interpretability.", "result": "X-SiT achieves state-of-the-art performance in detecting Alzheimer's and frontotemporal dementia, with prototypes aligning with known disease patterns and highlighting classification errors.", "conclusion": "X-SiT advances interpretable AI for medical imaging, offering both high accuracy and human-understandable insights for clinical decision-making."}}
{"id": "2506.20353", "pdf": "https://arxiv.org/pdf/2506.20353", "abs": "https://arxiv.org/abs/2506.20353", "authors": ["Xuan Ding", "Rui Sun", "Yunjian Zhang", "Xiu Yan", "Yueqi Zhou", "Kaihao Huang", "Suzhong Fu", "Chuanlong Xie", "Yao Zhu"], "title": "DipSVD: Dual-importance Protected SVD for Efficient LLM Compression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The ever-increasing computational demands and deployment costs of large\nlanguage models (LLMs) have spurred numerous compressing methods. Compared to\nquantization and unstructured pruning, SVD compression offers superior hardware\ncompatibility and theoretical guarantees. However, existing SVD-based methods\nfocus on the overall discrepancy between the original and compressed matrices\nwhile overlooking the protection of critical components within the matrix,\nwhich leads to inferior performance in the compressed models. This paper\nproposes a dual-level importance protection mechanism to enhance SVD-based\ncompression methods: (1) local importance protection: preserving the most\ncritical singular vectors within each weight matrix through channel-weighted\ndata whitening; and (2) global importance protection: enabling less important\nlayers to bear a greater portion of the compression burden through either a\nheuristic or optimization-based approach, thereby minimizing the impact of\ncompression on critical layers. Extensive experiments demonstrate that DipSVD\noutperforms existing SVD-based compression approaches across multiple\nbenchmarks, achieving superior model performance especially at high model\ncompression ratios.", "AI": {"tldr": "DipSVD enhances SVD-based LLM compression by protecting critical matrix components locally and globally, outperforming existing methods.", "motivation": "Address the inferior performance of existing SVD-based compression methods by protecting critical matrix components.", "method": "Proposes dual-level importance protection: local (channel-weighted whitening) and global (heuristic/optimization-based layer compression).", "result": "DipSVD achieves superior performance, especially at high compression ratios, across benchmarks.", "conclusion": "DipSVD improves SVD-based compression by safeguarding critical components, enhancing model performance."}}
{"id": "2506.20347", "pdf": "https://arxiv.org/pdf/2506.20347", "abs": "https://arxiv.org/abs/2506.20347", "authors": ["Malik Shahid Sultan", "Hernando Ombao"], "title": "On the ability of Deep Neural Networks to Learn Granger Causality in Multi-Variate Time Series Data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Granger Causality (GC) offers an elegant statistical framework to study the\nassociation between multivariate time series data. Linear Vector Autoregressive\nmodels (VAR) though have nice interpretation properties but have limited\npractical application due to underlying assumptions on the kind of associations\nthat can be captured by these models. Numerous attempts have already been made\nin the literature that exploit the functional approximation power of Deep\nNeural Networks (DNNs) for the task of GC estimation. These methods however\ntreat GC as a variable selection problem. We present a novel paradigm for\napproaching GC. We present this idea that GC is essentially linked with\nprediction and if a deep learning model is used to model the time series\ncollectively or jointly, a well regularized model may learn the true granger\ncausal structure from the data, given that there is enough training data. We\npropose to uncover the learned GC structure by comparing the model uncertainty\nor distribution of the residuals when the past of everything is used as\ncompared to the one where a specific time series component is dropped from the\nmodel. We also compare the effect of input layer dropout on the ability of a\nneural network to learn granger causality from the data. We show that a well\nregularized model infact can learn the true GC structure from the data without\nexplicitly adding terms in the loss function that guide the model to select\nvariables or perform sparse regression.", "AI": {"tldr": "The paper proposes a new deep learning approach to Granger Causality (GC) by treating it as a prediction problem rather than variable selection, using model uncertainty and residuals to uncover causal structures.", "motivation": "Traditional linear VAR models for GC are limited in capturing complex associations, and existing DNN-based methods treat GC as variable selection, which may not fully exploit deep learning's potential.", "method": "The authors use deep learning to model time series jointly, leveraging model uncertainty and residual distributions to infer GC. They also study the impact of input layer dropout.", "result": "A well-regularized deep learning model can learn the true GC structure without explicit sparsity or variable selection terms in the loss function.", "conclusion": "The proposed paradigm shifts GC estimation from variable selection to prediction, demonstrating that deep learning can effectively uncover causal structures when properly regularized."}}
{"id": "2411.14499", "pdf": "https://arxiv.org/pdf/2411.14499", "abs": "https://arxiv.org/abs/2411.14499", "authors": ["Jingtao Ding", "Yunke Zhang", "Yu Shang", "Yuheng Zhang", "Zefang Zong", "Jie Feng", "Yuan Yuan", "Hongyuan Su", "Nian Li", "Nicholas Sukiennik", "Fengli Xu", "Yong Li"], "title": "Understanding World or Predicting Future? A Comprehensive Survey of World Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by ACM CSUR, 37 pages, 7 figures, 7 tables", "summary": "The concept of world models has garnered significant attention due to\nadvancements in multimodal large language models such as GPT-4 and video\ngeneration models such as Sora, which are central to the pursuit of artificial\ngeneral intelligence. This survey offers a comprehensive review of the\nliterature on world models. Generally, world models are regarded as tools for\neither understanding the present state of the world or predicting its future\ndynamics. This review presents a systematic categorization of world models,\nemphasizing two primary functions: (1) constructing internal representations to\nunderstand the mechanisms of the world, and (2) predicting future states to\nsimulate and guide decision-making. Initially, we examine the current progress\nin these two categories. We then explore the application of world models in key\ndomains, including autonomous driving, robotics, and social simulacra, with a\nfocus on how each domain utilizes these aspects. Finally, we outline key\nchallenges and provide insights into potential future research directions. We\nsummarize the representative papers along with their code repositories in\nhttps://github.com/tsinghua-fib-lab/World-Model.", "AI": {"tldr": "A survey on world models, categorizing them into understanding and predicting functions, reviewing progress, applications in domains like autonomous driving, and outlining future challenges.", "motivation": "To provide a comprehensive review of world models, driven by advancements in multimodal LLMs and video generation models, and their role in AGI.", "method": "Systematic categorization of world models into understanding and predicting functions, reviewing current progress, and analyzing applications in key domains.", "result": "Identifies key challenges and future research directions, with a summary of representative papers and code repositories.", "conclusion": "World models are pivotal for AGI, with significant potential in diverse applications, though challenges remain for future exploration."}}
{"id": "2506.20355", "pdf": "https://arxiv.org/pdf/2506.20355", "abs": "https://arxiv.org/abs/2506.20355", "authors": ["Jes\u00fas Lozano-Cruz", "Albert Nieto-Morales", "Oriol Ball\u00f3-Gimbernat", "Adan Garriga", "Ant\u00f3n Rodr\u00edguez-Otero", "Alejandro Borrallo-Rentero"], "title": "Practical insights on the effect of different encodings, ans\u00e4tze and measurements in quantum and hybrid convolutional neural networks", "categories": ["quant-ph", "cs.CV"], "comment": "20 pages, 22 figures", "summary": "This study investigates the design choices of parameterized quantum circuits\n(PQCs) within quantum and hybrid convolutional neural network (HQNN and QCNN)\narchitectures, applied to the task of satellite image classification using the\nEuroSAT dataset. We systematically evaluate the performance implications of\ndata encoding techniques, variational ans\\\"atze, and measurement in approx. 500\ndistinct model configurations. Our analysis reveals a clear hierarchy of\ninfluence on model performance. For hybrid architectures, which were\nbenchmarked against their direct classical equivalents (e.g. the same\narchitecture with the PQCs removed), the data encoding strategy is the dominant\nfactor, with validation accuracy varying over 30% for distinct embeddings. In\ncontrast, the selection of variational ans\\\"atze and measurement basis had a\ncomparatively marginal effect, with validation accuracy variations remaining\nbelow 5%. For purely quantum models, restricted to amplitude encoding,\nperformance was most dependent on the measurement protocol and the\ndata-to-amplitude mapping. The measurement strategy varied the validation\naccuracy by up to 30% and the encoding mapping by around 8 percentage points.", "AI": {"tldr": "The study examines the impact of design choices in parameterized quantum circuits (PQCs) for quantum and hybrid convolutional neural networks (HQNN/QCNN) on satellite image classification, identifying data encoding as the most influential factor for hybrid models and measurement protocol for purely quantum models.", "motivation": "To understand how different design choices in PQCs affect the performance of quantum and hybrid neural networks in satellite image classification tasks.", "method": "Systematic evaluation of ~500 model configurations, focusing on data encoding, variational ans\u00e4tze, and measurement strategies for HQNN/QCNN architectures using the EuroSAT dataset.", "result": "For hybrid models, data encoding had the largest impact (30% accuracy variation), while variational ans\u00e4tze and measurement had minimal effect (<5%). For purely quantum models, measurement protocol (30% variation) and data-to-amplitude mapping (8%) were most critical.", "conclusion": "Design choices in PQCs significantly impact model performance, with data encoding dominating hybrid models and measurement protocols being key for purely quantum models."}}
{"id": "2506.20354", "pdf": "https://arxiv.org/pdf/2506.20354", "abs": "https://arxiv.org/abs/2506.20354", "authors": ["Francesco Carzaniga", "Michael Hersche", "Abu Sebastian", "Kaspar Schindler", "Abbas Rahimi"], "title": "A foundation model with multi-variate parallel attention to generate neuronal activity", "categories": ["cs.LG", "cs.AI"], "comment": "The code is available at\n  https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\n  dataset is available at\n  https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg", "summary": "Learning from multi-variate time-series with heterogeneous channel\nconfigurations remains a fundamental challenge for deep neural networks (DNNs),\nparticularly in clinical domains such as intracranial electroencephalography\n(iEEG), where channel setups vary widely across subjects. In this work, we\nintroduce multi-variate parallel attention (MVPA), a novel self-attention\nmechanism that disentangles content, temporal, and spatial attention, enabling\nflexible, generalizable, and efficient modeling of time-series data with\nvarying channel counts and configurations. We use MVPA to build MVPFormer, a\ngenerative foundation model for human electrophysiology, trained to predict the\nevolution of iEEG signals across diverse subjects. To support this and future\neffort by the community, we release the SWEC iEEG dataset, the largest publicly\navailable iEEG dataset to date, comprising nearly 10,000 hours of recordings\nfrom heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong\ngeneralization across subjects, demonstrating expert-level performance in\nseizure detection and outperforming state-of-the-art Transformer baselines on\nour SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard\ntime-series forecasting and classification tasks, where it matches or exceeds\nexisting attention-based models. Together, our contributions establish MVPA as\na general-purpose attention mechanism for heterogeneous time-series and\nMVPFormer as the first open-source, open-weights, and open-data iEEG foundation\nmodel with state-of-the-art clinical performance. The code is available at\nhttps://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\ndataset is available at\nhttps://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.", "AI": {"tldr": "A novel self-attention mechanism (MVPA) is introduced for modeling heterogeneous multi-variate time-series, applied to iEEG data, achieving strong generalization and outperforming baselines.", "motivation": "Addressing the challenge of learning from multi-variate time-series with varying channel configurations, especially in clinical domains like iEEG.", "method": "Proposes MVPA, a self-attention mechanism disentangling content, temporal, and spatial attention, and builds MVPFormer, a generative foundation model for iEEG.", "result": "MVPFormer achieves expert-level seizure detection and outperforms state-of-the-art baselines. MVPA also excels in standard time-series tasks.", "conclusion": "MVPA is a general-purpose attention mechanism for heterogeneous time-series, and MVPFormer is a state-of-the-art open-source iEEG foundation model."}}
{"id": "2506.20359", "pdf": "https://arxiv.org/pdf/2506.20359", "abs": "https://arxiv.org/abs/2506.20359", "authors": ["Chanuka Don Samarasinghage", "Dhruv Gulabani"], "title": "Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach", "categories": ["cs.LG"], "comment": null, "summary": "Trajectory analysis is not only about obtaining movement data, but it is also\nof paramount importance in understanding the pattern in which an object moves\nthrough space and time, as well as in predicting its next move. Due to the\nsignificant interest in the area, data collection has improved substantially,\nresulting in a large number of features becoming available for training and\npredicting models. However, this introduces a high-dimensionality-induced\nfeature explosion problem, which reduces the efficiency and interpretability of\nthe data, thereby reducing the accuracy of machine learning models. To overcome\nthis issue, feature selection has become one of the most prevalent tools. Thus,\nthe objective of this paper was to introduce a taxonomy-based feature selection\nmethod that categorizes features based on their internal structure. This\napproach classifies the data into geometric and kinematic features, further\ncategorizing them into curvature, indentation, speed, and acceleration. The\ncomparative analysis indicated that a taxonomy-based approach consistently\nachieved comparable or superior predictive performance. Furthermore, due to the\ntaxonomic grouping, which reduces combinatorial space, the time taken to select\nfeatures was drastically reduced. The taxonomy was also used to gain insights\ninto what feature sets each dataset was more sensitive to. Overall, this study\nprovides robust evidence that a taxonomy-based feature selection method can add\na layer of interpretability, reduce dimensionality and computational\ncomplexity, and contribute to high-level decision-making. It serves as a step\ntoward providing a methodological framework for researchers and practitioners\ndealing with trajectory datasets and contributing to the broader field of\nexplainable artificial intelligence.", "AI": {"tldr": "The paper introduces a taxonomy-based feature selection method for trajectory analysis to address high-dimensionality issues, improving efficiency, interpretability, and predictive accuracy.", "motivation": "High-dimensionality in trajectory data reduces model efficiency and interpretability, necessitating effective feature selection methods.", "method": "A taxonomy-based approach categorizes features into geometric (curvature, indentation) and kinematic (speed, acceleration) groups.", "result": "The method achieved comparable or superior predictive performance, reduced feature selection time, and provided dataset-specific insights.", "conclusion": "Taxonomy-based feature selection enhances interpretability, reduces complexity, and supports high-level decision-making in trajectory analysis."}}
{"id": "2412.01131", "pdf": "https://arxiv.org/pdf/2412.01131", "abs": "https://arxiv.org/abs/2412.01131", "authors": ["Zhihan Cao", "Hiroaki Yamada", "Simone Teufel", "Takenobu Tokunaga"], "title": "A Comprehensive Evaluation of Semantic Relation Knowledge of Pretrained Language Models and Humans", "categories": ["cs.CL"], "comment": "Accpeted by Language Resources and Evaluation", "summary": "Recently, much work has concerned itself with the enigma of what exactly PLMs\n(pretrained language models) learn about different aspects of language, and how\nthey learn it. One stream of this type of research investigates the knowledge\nthat PLMs have about semantic relations. However, many aspects of semantic\nrelations were left unexplored. Only one relation was considered, namely\nhypernymy. Furthermore, previous work did not measure humans' performance on\nthe same task as that solved by the PLMs. This means that at this point in\ntime, there is only an incomplete view of models' semantic relation knowledge.\nTo address this gap, we introduce a comprehensive evaluation framework covering\nfive relations beyond hypernymy, namely hyponymy, holonymy, meronymy, antonymy,\nand synonymy. We use six metrics (two newly introduced here) for recently\nuntreated aspects of semantic relation knowledge, namely soundness,\ncompleteness, symmetry, asymmetry, prototypicality, and distinguishability and\nfairly compare humans and models on the same task. Our extensive experiments\ninvolve 16 PLMs, eight masked and eight causal language models. Up to now only\nmasked language models had been tested although causal and masked language\nmodels treat context differently. Our results reveal a significant knowledge\ngap between humans and models for almost all semantic relations. Antonymy is\nthe outlier relation where all models perform reasonably well. In general,\nmasked language models perform significantly better than causal language\nmodels. Nonetheless, both masked and causal language models are likely to\nconfuse non-antonymy relations with antonymy.", "AI": {"tldr": "The paper introduces a comprehensive evaluation framework to assess PLMs' knowledge of five semantic relations beyond hypernymy, comparing human and model performance using six metrics.", "motivation": "Previous research on PLMs' semantic relation knowledge was limited, focusing only on hypernymy and lacking human comparison. This gap motivated a broader evaluation.", "method": "The study evaluates 16 PLMs (eight masked, eight causal) on five semantic relations using six metrics, including soundness and prototypicality, and compares results to human performance.", "result": "Results show a significant knowledge gap between humans and models, with antonymy as the only well-performed relation. Masked models outperform causal ones, but both confuse non-antonymy relations with antonymy.", "conclusion": "The study highlights the incomplete semantic knowledge of PLMs, emphasizing the need for further research to bridge the gap between human and model understanding of semantic relations."}}
{"id": "2506.20367", "pdf": "https://arxiv.org/pdf/2506.20367", "abs": "https://arxiv.org/abs/2506.20367", "authors": ["Edoardo Alberto Dominici", "Jozef Hladky", "Floor Verhoeven", "Lukas Radl", "Thomas Deixelberger", "Stefan Ainetter", "Philipp Drescher", "Stefan Hauswiesner", "Arno Coomans", "Giacomo Nazzaro", "Konstantinos Vardis", "Markus Steinberger"], "title": "DreamAnywhere: Object-Centric Panoramic 3D Scene Generation", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Recent advances in text-to-3D scene generation have demonstrated significant\npotential to transform content creation across multiple industries. Although\nthe research community has made impressive progress in addressing the\nchallenges of this complex task, existing methods often generate environments\nthat are only front-facing, lack visual fidelity, exhibit limited scene\nunderstanding, and are typically fine-tuned for either indoor or outdoor\nsettings. In this work, we address these issues and propose DreamAnywhere, a\nmodular system for the fast generation and prototyping of 3D scenes. Our system\nsynthesizes a 360{\\deg} panoramic image from text, decomposes it into\nbackground and objects, constructs a complete 3D representation through hybrid\ninpainting, and lifts object masks to detailed 3D objects that are placed in\nthe virtual environment. DreamAnywhere supports immersive navigation and\nintuitive object-level editing, making it ideal for scene exploration, visual\nmock-ups, and rapid prototyping -- all with minimal manual modeling. These\nfeatures make our system particularly suitable for low-budget movie production,\nenabling quick iteration on scene layout and visual tone without the overhead\nof traditional 3D workflows. Our modular pipeline is highly customizable as it\nallows components to be replaced independently. Compared to current\nstate-of-the-art text and image-based 3D scene generation approaches,\nDreamAnywhere shows significant improvements in coherence in novel view\nsynthesis and achieves competitive image quality, demonstrating its\neffectiveness across diverse and challenging scenarios. A comprehensive user\nstudy demonstrates a clear preference for our method over existing approaches,\nvalidating both its technical robustness and practical usefulness.", "AI": {"tldr": "DreamAnywhere is a modular system for fast 3D scene generation from text, addressing limitations like front-facing views and low fidelity. It synthesizes 360\u00b0 panoramas, decomposes scenes, and supports immersive navigation and editing.", "motivation": "Existing text-to-3D methods produce limited, front-facing scenes with low fidelity and poor scene understanding. DreamAnywhere aims to overcome these issues for practical applications like movie production.", "method": "The system generates a 360\u00b0 panorama from text, decomposes it into background and objects, and constructs a 3D representation via hybrid inpainting. It supports immersive navigation and object-level editing.", "result": "DreamAnywhere improves coherence in novel view synthesis and achieves competitive image quality. A user study shows preference over existing methods.", "conclusion": "DreamAnywhere is effective for diverse scenarios, offering practical benefits like rapid prototyping and low-budget movie production."}}
{"id": "2506.20362", "pdf": "https://arxiv.org/pdf/2506.20362", "abs": "https://arxiv.org/abs/2506.20362", "authors": ["Lorenzo Bini", "Stephane Marchand-Maillet"], "title": "Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations", "categories": ["cs.LG", "cs.AI", "cs.DS"], "comment": "LaplaceGNN is a novel graph learning framework that employs a\n  bootstrapped teacher-student architecture. Its precomputed spectral\n  augmentations and adversarial training enable robust performance,\n  outperforming SOTA methods while scaling linearly", "summary": "We present LaplaceGNN, a novel self-supervised graph learning framework that\nbypasses the need for negative sampling by leveraging spectral bootstrapping\ntechniques. Our method integrates Laplacian-based signals into the learning\nprocess, allowing the model to effectively capture rich structural\nrepresentations without relying on contrastive objectives or handcrafted\naugmentations. By focusing on positive alignment, LaplaceGNN achieves linear\nscaling while offering a simpler, more efficient, self-supervised alternative\nfor graph neural networks, applicable across diverse domains. Our contributions\nare twofold: we precompute spectral augmentations through max-min\ncentrality-guided optimization, enabling rich structural supervision without\nrelying on handcrafted augmentations, then we integrate an adversarial\nbootstrapped training scheme that further strengthens feature learning and\nrobustness. Our extensive experiments on different benchmark datasets show that\nLaplaceGNN achieves superior performance compared to state-of-the-art\nself-supervised graph methods, offering a promising direction for efficiently\nlearning expressive graph representations.", "AI": {"tldr": "LaplaceGNN is a self-supervised graph learning framework that avoids negative sampling by using spectral bootstrapping and Laplacian-based signals, achieving efficient and scalable performance.", "motivation": "To simplify and improve self-supervised graph learning by eliminating the need for negative sampling and handcrafted augmentations while capturing rich structural representations.", "method": "Integrates Laplacian-based signals and spectral bootstrapping, using max-min centrality-guided optimization for spectral augmentations and an adversarial bootstrapped training scheme.", "result": "Outperforms state-of-the-art self-supervised graph methods on benchmark datasets, demonstrating efficiency and scalability.", "conclusion": "LaplaceGNN offers a simpler, efficient, and effective self-supervised alternative for graph neural networks, with broad applicability."}}
{"id": "2506.20380", "pdf": "https://arxiv.org/pdf/2506.20380", "abs": "https://arxiv.org/abs/2506.20380", "authors": ["Zhengpeng Feng", "Sadiq Jaffer", "Jovana Knezevic", "Silja Sormunen", "Robin Young", "Madeline Lisaius", "Markus Immitzer", "James Ball", "Clement Atzberger", "David A. Coomes", "Anil Madhavapeddy", "Andrew Blake", "Srinivasan Keshav"], "title": "TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis", "categories": ["cs.LG"], "comment": null, "summary": "Satellite remote sensing (RS) enables a wide array of downstream Earth\nobservation (EO) applications, including climate modeling, carbon accounting,\nand strategies for conservation and sustainable land use. We present TESSERA, a\nnovel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning\n(SSL) to generate global, robust representations at 10m scale from pixel-level\nsatellite time series data. TESSERA combines information from only optical and\nSAR data streams using two parallel Transformer-based encoders: one dedicated\nto Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected\nspectral bands) to create representations that are then fused using a\nmultilayer perceptron (MLP), resulting in a global representation map covering\nthe years 2017 to 2024. Our precomputed representations set a new\nstate-of-the-art performance benchmark and our open-source approach\ndemocratizes access to high-performance, high-resolution representations. We\nbenchmark the performance of TESSERA in five diverse tasks, comparing our work\nwith state-of-the-art task-specific models and other foundation models. Our\nresults show that TESSERA outperforms both traditional RS baselines and the\nleading geospatial foundation models in these diverse downstream tasks.", "AI": {"tldr": "TESSERA is a Remote Sensing Foundation Model (RSFM) using Self-Supervised Learning (SSL) to create global, robust representations from satellite data, outperforming traditional and foundation models in diverse tasks.", "motivation": "To enable diverse Earth observation applications like climate modeling and conservation by generating high-resolution, global representations from satellite data.", "method": "Uses two parallel Transformer-based encoders for Sentinel-1 SAR and Sentinel-2 MSI data, fused via MLP to create a global representation map (2017-2024).", "result": "Sets a new state-of-the-art benchmark, outperforming traditional and geospatial foundation models in five diverse tasks.", "conclusion": "TESSERA democratizes access to high-performance RS representations and excels in downstream applications."}}
{"id": "2412.02138", "pdf": "https://arxiv.org/pdf/2412.02138", "abs": "https://arxiv.org/abs/2412.02138", "authors": ["Zhihan Cao", "Hiroaki Yamada", "Simone Teufel", "Takenobu Tokunaga"], "title": "Misalignment of Semantic Relation Knowledge between WordNet and Human Intuition", "categories": ["cs.CL"], "comment": "Accepted by Global WordNet Conference 2025", "summary": "WordNet provides a carefully constructed repository of semantic relations,\ncreated by specialists. But there is another source of information on semantic\nrelations, the intuition of language users. We present the first systematic\nstudy of the degree to which these two sources are aligned. Investigating the\ncases of misalignment could make proper use of WordNet and facilitate its\nimprovement. Our analysis which uses templates to elicit responses from human\nparticipants, reveals a general misalignment of semantic relation knowledge\nbetween WordNet and human intuition. Further analyses find a systematic pattern\nof mismatch among synonymy and taxonomic relations~(hypernymy and hyponymy),\ntogether with the fact that WordNet path length does not serve as a reliable\nindicator of human intuition regarding hypernymy or hyponymy relations.", "AI": {"tldr": "The study compares WordNet's semantic relations with human intuition, finding general misalignment, especially in synonymy and taxonomic relations. WordNet's path length is unreliable for predicting human intuition.", "motivation": "To systematically compare WordNet's expert-constructed semantic relations with human intuition and identify misalignments for potential improvements.", "method": "Uses templates to elicit responses from human participants, analyzing alignment and patterns of mismatch in semantic relations.", "result": "Reveals general misalignment, particularly in synonymy and taxonomic relations (hypernymy/hyponymy), and shows WordNet path length is unreliable for human intuition.", "conclusion": "Misalignments highlight areas for WordNet improvement and caution against relying solely on WordNet for human-like semantic understanding."}}
{"id": "2506.20566", "pdf": "https://arxiv.org/pdf/2506.20566", "abs": "https://arxiv.org/abs/2506.20566", "authors": ["Zhonghao Shi", "Enyu Zhao", "Nathaniel Dennler", "Jingzhen Wang", "Xinyang Xu", "Kaleen Shrestha", "Mengxue Fu", "Daniel Seita", "Maja Matari\u0107"], "title": "HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to the 19th International Symposium on Experimental Robotics\n  (ISER 2025)", "summary": "Real-time human perception is crucial for effective human-robot interaction\n(HRI). Large vision-language models (VLMs) offer promising generalizable\nperceptual capabilities but often suffer from high latency, which negatively\nimpacts user experience and limits VLM applicability in real-world scenarios.\nTo systematically study VLM capabilities in human perception for HRI and\nperformance-latency trade-offs, we introduce HRIBench, a visual\nquestion-answering (VQA) benchmark designed to evaluate VLMs across a diverse\nset of human perceptual tasks critical for HRI. HRIBench covers five key\ndomains: (1) non-verbal cue understanding, (2) verbal instruction\nunderstanding, (3) human-robot object relationship understanding, (4) social\nnavigation, and (5) person identification. To construct HRIBench, we collected\ndata from real-world HRI environments to curate questions for non-verbal cue\nunderstanding, and leveraged publicly available datasets for the remaining four\ndomains. We curated 200 VQA questions for each domain, resulting in a total of\n1000 questions for HRIBench. We then conducted a comprehensive evaluation of\nboth state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench.\nOur results show that, despite their generalizability, current VLMs still\nstruggle with core perceptual capabilities essential for HRI. Moreover, none of\nthe models within our experiments demonstrated a satisfactory\nperformance-latency trade-off suitable for real-time deployment, underscoring\nthe need for future research on developing smaller, low-latency VLMs with\nimproved human perception capabilities. HRIBench and our results can be found\nin this Github repository: https://github.com/interaction-lab/HRIBench.", "AI": {"tldr": "HRIBench is introduced to evaluate VLMs for human perception in HRI, revealing their limitations in performance-latency trade-offs.", "motivation": "Real-time human perception is vital for HRI, but VLMs face high latency issues, limiting their practical use.", "method": "HRIBench, a VQA benchmark with 1000 questions across five HRI domains, evaluates 11 VLMs.", "result": "Current VLMs lack core perceptual capabilities and fail to meet real-time latency requirements.", "conclusion": "Future research should focus on smaller, low-latency VLMs with better human perception for HRI."}}
{"id": "2506.20373", "pdf": "https://arxiv.org/pdf/2506.20373", "abs": "https://arxiv.org/abs/2506.20373", "authors": ["Joerg Deigmoeller", "Stephan Hasler", "Nakul Agarwal", "Daniel Tanneberg", "Anna Belardinelli", "Reza Ghoddoosian", "Chao Wang", "Felix Ocker", "Fan Zhang", "Behzad Dariush", "Michael Gienger"], "title": "CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": null, "summary": "We introduce CARMA, a system for situational grounding in human-robot group\ninteractions. Effective collaboration in such group settings requires\nsituational awareness based on a consistent representation of present persons\nand objects coupled with an episodic abstraction of events regarding actors and\nmanipulated objects. This calls for a clear and consistent assignment of\ninstances, ensuring that robots correctly recognize and track actors, objects,\nand their interactions over time. To achieve this, CARMA uniquely identifies\nphysical instances of such entities in the real world and organizes them into\ngrounded triplets of actors, objects, and actions.\n  To validate our approach, we conducted three experiments, where multiple\nhumans and a robot interact: collaborative pouring, handovers, and sorting.\nThese scenarios allow the assessment of the system's capabilities as to role\ndistinction, multi-actor awareness, and consistent instance identification. Our\nexperiments demonstrate that the system can reliably generate accurate\nactor-action-object triplets, providing a structured and robust foundation for\napplications requiring spatiotemporal reasoning and situated decision-making in\ncollaborative settings.", "AI": {"tldr": "CARMA is a system for situational grounding in human-robot group interactions, using grounded triplets of actors, objects, and actions for consistent instance identification.", "motivation": "Effective collaboration in group settings requires situational awareness and consistent representation of entities and interactions.", "method": "CARMA uniquely identifies physical instances and organizes them into actor-object-action triplets, validated through three interaction experiments.", "result": "The system reliably generates accurate triplets, supporting role distinction, multi-actor awareness, and consistent instance identification.", "conclusion": "CARMA provides a robust foundation for spatiotemporal reasoning and decision-making in collaborative human-robot interactions."}}
{"id": "2506.20413", "pdf": "https://arxiv.org/pdf/2506.20413", "abs": "https://arxiv.org/abs/2506.20413", "authors": ["Mohammad Mahdi Maheri", "Denys Herasymuk", "Hamed Haddadi"], "title": "Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The growing adoption of Artificial Intelligence (AI) in Internet of Things\n(IoT) ecosystems has intensified the need for personalized learning methods\nthat can operate efficiently and privately across heterogeneous,\nresource-constrained devices. However, enabling effective personalized learning\nin decentralized settings introduces several challenges, including efficient\nknowledge transfer between clients, protection of data privacy, and resilience\nagainst poisoning attacks. In this paper, we address these challenges by\ndeveloping P4 (Personalized, Private, Peer-to-Peer) -- a method designed to\ndeliver personalized models for resource-constrained IoT devices while ensuring\ndifferential privacy and robustness against poisoning attacks. Our solution\nemploys a lightweight, fully decentralized algorithm to privately detect client\nsimilarity and form collaborative groups. Within each group, clients leverage\ndifferentially private knowledge distillation to co-train their models,\nmaintaining high accuracy while ensuring robustness to the presence of\nmalicious clients. We evaluate P4 on popular benchmark datasets using both\nlinear and CNN-based architectures across various heterogeneity settings and\nattack scenarios. Experimental results show that P4 achieves 5% to 30% higher\naccuracy than leading differentially private peer-to-peer approaches and\nmaintains robustness with up to 30% malicious clients. Additionally, we\ndemonstrate its practicality by deploying it on resource-constrained devices,\nwhere collaborative training between two clients adds only ~7 seconds of\noverhead.", "AI": {"tldr": "P4 is a decentralized method for personalized learning in IoT, ensuring privacy and robustness against attacks, outperforming peers in accuracy and efficiency.", "motivation": "The need for efficient, private, and robust personalized learning in decentralized IoT ecosystems drives this work.", "method": "P4 uses a lightweight algorithm to detect client similarity, forms groups, and employs differentially private knowledge distillation for co-training.", "result": "P4 achieves 5%-30% higher accuracy than peers and remains robust with up to 30% malicious clients, adding minimal overhead (~7s).", "conclusion": "P4 effectively addresses privacy, robustness, and efficiency in decentralized personalized learning for IoT."}}
{"id": "2412.16545", "pdf": "https://arxiv.org/pdf/2412.16545", "abs": "https://arxiv.org/abs/2412.16545", "authors": ["Zhisong Zhang", "Yan Wang", "Xinting Huang", "Tianqing Fang", "Hongming Zhang", "Chenlong Deng", "Shuaiyi Li", "Dong Yu"], "title": "Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "Large language models have shown remarkable performance across a wide range\nof language tasks, owing to their exceptional capabilities in context modeling.\nThe most commonly used method of context modeling is full self-attention, as\nseen in standard decoder-only Transformers. Although powerful, this method can\nbe inefficient for long sequences and may overlook inherent input structures.\nTo address these problems, an alternative approach is parallel context\nencoding, which splits the context into sub-pieces and encodes them parallelly.\nBecause parallel patterns are not encountered during training, naively applying\nparallel encoding leads to performance degradation. However, the underlying\nreasons and potential mitigations are unclear. In this work, we provide a\ndetailed analysis of this issue and identify that unusually high attention\nentropy can be a key factor. Furthermore, we adopt two straightforward methods\nto reduce attention entropy by incorporating attention sinks and selective\nmechanisms. Experiments on various tasks reveal that these methods effectively\nlower irregular attention entropy and narrow performance gaps. We hope this\nstudy can illuminate ways to enhance context modeling mechanisms.", "AI": {"tldr": "The paper analyzes performance degradation in parallel context encoding for large language models, identifies high attention entropy as a key issue, and proposes mitigation methods (attention sinks and selective mechanisms) to improve efficiency and performance.", "motivation": "Full self-attention in Transformers is inefficient for long sequences and may ignore input structures. Parallel context encoding is an alternative but causes performance degradation due to untrained parallel patterns.", "method": "The study analyzes the issue, identifies high attention entropy as the cause, and introduces two methods: attention sinks and selective mechanisms to reduce entropy.", "result": "Experiments show these methods effectively lower irregular attention entropy and reduce performance gaps in various tasks.", "conclusion": "The findings highlight ways to enhance context modeling mechanisms, particularly for parallel encoding in large language models."}}
{"id": "2506.20652", "pdf": "https://arxiv.org/pdf/2506.20652", "abs": "https://arxiv.org/abs/2506.20652", "authors": ["Roi Bar-On", "Dana Cohen-Bar", "Daniel Cohen-Or"], "title": "EditP23: 3D Editing via Propagation of Image Prompts to Multi-View", "categories": ["cs.GR", "cs.CV", "68U05 (Primary), 68T45 (Secondary)", "I.3.7; I.3.8; I.4.9"], "comment": "Code, supplementary videos, interactive 3D visualizations, and\n  additional results are available at https://editp23.github.io/", "summary": "We present EditP23, a method for mask-free 3D editing that propagates 2D\nimage edits to multi-view representations in a 3D-consistent manner. In\ncontrast to traditional approaches that rely on text-based prompting or\nexplicit spatial masks, EditP23 enables intuitive edits by conditioning on a\npair of images: an original view and its user-edited counterpart. These image\nprompts are used to guide an edit-aware flow in the latent space of a\npre-trained multi-view diffusion model, allowing the edit to be coherently\npropagated across views. Our method operates in a feed-forward manner, without\noptimization, and preserves the identity of the original object, in both\nstructure and appearance. We demonstrate its effectiveness across a range of\nobject categories and editing scenarios, achieving high fidelity to the source\nwhile requiring no manual masks.", "AI": {"tldr": "EditP23 is a mask-free 3D editing method that propagates 2D image edits to multi-view representations using image prompts, ensuring 3D consistency without masks or optimization.", "motivation": "Traditional 3D editing relies on text prompts or masks, which can be limiting. EditP23 aims to enable intuitive, mask-free edits by using image pairs for guidance.", "method": "The method conditions edits on an original and edited image pair, using them to guide an edit-aware flow in a pre-trained multi-view diffusion model's latent space. It operates feed-forward, without optimization.", "result": "EditP23 achieves high fidelity across object categories and editing scenarios, preserving object identity in structure and appearance without manual masks.", "conclusion": "EditP23 offers an efficient, intuitive approach for 3D editing, eliminating the need for masks or optimization while maintaining consistency and fidelity."}}
{"id": "2506.20417", "pdf": "https://arxiv.org/pdf/2506.20417", "abs": "https://arxiv.org/abs/2506.20417", "authors": ["Tatsuhiro Shimizu", "Kazuki Kawamura", "Takanori Muroi", "Yusuke Narita", "Kei Tateno", "Takuma Udagawa", "Yuta Saito"], "title": "Off-Policy Evaluation and Learning for the Future under Non-Stationarity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study the novel problem of future off-policy evaluation (F-OPE) and\nlearning (F-OPL) for estimating and optimizing the future value of policies in\nnon-stationary environments, where distributions vary over time. In e-commerce\nrecommendations, for instance, our goal is often to estimate and optimize the\npolicy value for the upcoming month using data collected by an old policy in\nthe previous month. A critical challenge is that data related to the future\nenvironment is not observed in the historical data. Existing methods assume\nstationarity or depend on restrictive reward-modeling assumptions, leading to\nsignificant bias. To address these limitations, we propose a novel estimator\nnamed \\textit{\\textbf{O}ff-\\textbf{P}olicy Estimator for the \\textbf{F}uture\n\\textbf{V}alue (\\textbf{\\textit{OPFV}})}, designed for accurately estimating\npolicy values at any future time point. The key feature of OPFV is its ability\nto leverage the useful structure within time-series data. While future data\nmight not be present in the historical log, we can leverage, for example,\nseasonal, weekly, or holiday effects that are consistent in both the historical\nand future data. Our estimator is the first to exploit these time-related\nstructures via a new type of importance weighting, enabling effective F-OPE.\nTheoretical analysis identifies the conditions under which OPFV becomes\nlow-bias. In addition, we extend our estimator to develop a new policy-gradient\nmethod to proactively learn a good future policy using only historical data.\nEmpirical results show that our methods substantially outperform existing\nmethods in estimating and optimizing the future policy value under\nnon-stationarity for various experimental setups.", "AI": {"tldr": "The paper introduces a novel estimator, OPFV, for future off-policy evaluation and learning in non-stationary environments, leveraging time-series structures to reduce bias and improve accuracy.", "motivation": "Existing methods for off-policy evaluation and learning assume stationarity or rely on restrictive reward-modeling assumptions, leading to bias in non-stationary environments like e-commerce recommendations.", "method": "Proposes OPFV, an estimator that uses time-series structures (e.g., seasonal effects) via a new importance weighting technique for accurate future policy value estimation. Also extends OPFV to a policy-gradient method for proactive learning.", "result": "OPFV outperforms existing methods in estimating and optimizing future policy values under non-stationarity, as shown in empirical evaluations.", "conclusion": "OPFV effectively addresses the limitations of existing methods by leveraging time-related structures, enabling accurate future policy evaluation and learning in non-stationary environments."}}
{"id": "2506.20431", "pdf": "https://arxiv.org/pdf/2506.20431", "abs": "https://arxiv.org/abs/2506.20431", "authors": ["Xing Ma"], "title": "Tackling Data Heterogeneity in Federated Learning through Knowledge Distillation with Inequitable Aggregation", "categories": ["cs.LG"], "comment": "33pages,8figures", "summary": "Federated learning aims to train a global model in a distributed environment\nthat is close to the performance of centralized training. However, issues such\nas client label skew, data quantity skew, and other heterogeneity problems\nseverely degrade the model's performance. Most existing methods overlook the\nscenario where only a small portion of clients participate in training within a\nlarge-scale client setting, whereas our experiments show that this scenario\npresents a more challenging federated learning task. Therefore, we propose a\nKnowledge Distillation with teacher-student Inequitable Aggregation (KDIA)\nstrategy tailored to address the federated learning setting mentioned above,\nwhich can effectively leverage knowledge from all clients. In KDIA, the student\nmodel is the average aggregation of the participating clients, while the\nteacher model is formed by a weighted aggregation of all clients based on three\nfrequencies: participation intervals, participation counts, and data volume\nproportions. During local training, self-knowledge distillation is performed.\nAdditionally, we utilize a generator trained on the server to generate\napproximately independent and identically distributed (IID) data features\nlocally for auxiliary training. We conduct extensive experiments on the\nCIFAR-10/100/CINIC-10 datasets and various heterogeneous settings to evaluate\nKDIA. The results show that KDIA can achieve better accuracy with fewer rounds\nof training, and the improvement is more significant under severe\nheterogeneity.", "AI": {"tldr": "Proposes KDIA, a federated learning method using knowledge distillation and inequitable aggregation to improve model performance in large-scale, heterogeneous settings with limited client participation.", "motivation": "Addresses performance degradation in federated learning due to client label skew, data quantity skew, and heterogeneity, especially when only a few clients participate in large-scale settings.", "method": "Uses Knowledge Distillation with teacher-student Inequitable Aggregation (KDIA), where the teacher model aggregates all clients weighted by participation intervals, counts, and data volume, while the student model averages participating clients. Includes self-knowledge distillation and auxiliary training with server-generated IID data.", "result": "KDIA achieves better accuracy with fewer training rounds, especially under severe heterogeneity, as demonstrated on CIFAR-10/100/CINIC-10 datasets.", "conclusion": "KDIA effectively leverages knowledge from all clients, improving federated learning performance in challenging heterogeneous and large-scale settings."}}
{"id": "2501.06256", "pdf": "https://arxiv.org/pdf/2501.06256", "abs": "https://arxiv.org/abs/2501.06256", "authors": ["Jelena Bratuli\u0107", "Sudhanshu Mittal", "David T. Hoffmann", "Samuel B\u00f6hm", "Robin Tibor Schirrmeister", "Tonio Ball", "Christian Rupprecht", "Thomas Brox"], "title": "Unlocking In-Context Learning for Natural Datasets Beyond Language Modelling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) exhibit In-Context Learning (ICL), which enables\nthe model to perform new tasks conditioning only on the examples provided in\nthe context without updating the model's weights. While ICL offers fast\nadaptation across natural language tasks and domains, its emergence is less\nstraightforward for modalities beyond text. In this work, we systematically\nuncover properties present in LLMs that support the emergence of ICL for\nautoregressive models and various modalities by promoting the learning of the\nneeded mechanisms for ICL. We identify exact token repetitions in the training\ndata sequences as an important factor for ICL. Such repetitions further improve\nstability and reduce transiency in ICL performance. Moreover, we emphasise the\nsignificance of training task difficulty for the emergence of ICL. Finally, by\napplying our novel insights on ICL emergence, we unlock ICL capabilities for\nvarious visual datasets and a more challenging EEG classification task in a\nfew-shot learning regime.", "AI": {"tldr": "The paper explores how Large Language Models (LLMs) achieve In-Context Learning (ICL) and extends its principles to non-text modalities like visual and EEG data.", "motivation": "To understand and enable ICL in autoregressive models and non-text modalities, addressing its less straightforward emergence beyond text.", "method": "Systematically identifies properties in LLMs that support ICL, such as token repetitions and training task difficulty, and applies these insights to visual and EEG datasets.", "result": "Token repetitions improve ICL stability, and training task difficulty is crucial for ICL emergence. The approach successfully enables ICL for visual and EEG tasks.", "conclusion": "The study provides insights into ICL mechanisms and demonstrates its applicability to diverse modalities, advancing few-shot learning capabilities."}}
{"id": "2211.08071", "pdf": "https://arxiv.org/pdf/2211.08071", "abs": "https://arxiv.org/abs/2211.08071", "authors": ["Yu Wang", "Xin Li", "Shengzhao Weng", "Gang Zhang", "Haixiao Yue", "Haocheng Feng", "Junyu Han", "Errui Ding"], "title": "KD-DETR: Knowledge Distillation for Detection Transformer with Consistent Distillation Points Sampling", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2024", "summary": "DETR is a novel end-to-end transformer architecture object detector, which\nsignificantly outperforms classic detectors when scaling up. In this paper, we\nfocus on the compression of DETR with knowledge distillation. While knowledge\ndistillation has been well-studied in classic detectors, there is a lack of\nresearches on how to make it work effectively on DETR. We first provide\nexperimental and theoretical analysis to point out that the main challenge in\nDETR distillation is the lack of consistent distillation points. Distillation\npoints refer to the corresponding inputs of the predictions for student to\nmimic, which have different formulations in CNN detector and DETR, and reliable\ndistillation requires sufficient distillation points which are consistent\nbetween teacher and student.\n  Based on this observation, we propose the first general knowledge\ndistillation paradigm for DETR (KD-DETR) with consistent distillation points\nsampling, for both homogeneous and heterogeneous distillation. Specifically, we\ndecouple detection and distillation tasks by introducing a set of specialized\nobject queries to construct distillation points for DETR. We further propose a\ngeneral-to-specific distillation points sampling strategy to explore the\nextensibility of KD-DETR. Extensive experiments validate the effectiveness and\ngeneralization of KD-DETR. For both single-scale DAB-DETR and multis-scale\nDeformable DETR and DINO, KD-DETR boost the performance of student model with\nimprovements of $2.6\\%-5.2\\%$. We further extend KD-DETR to heterogeneous\ndistillation, and achieves $2.1\\%$ improvement by distilling the knowledge from\nDINO to Faster R-CNN with ResNet-50, which is comparable with homogeneous\ndistillation methods.The code is available at\nhttps://github.com/wennyuhey/KD-DETR.", "AI": {"tldr": "The paper introduces KD-DETR, a knowledge distillation method for DETR, addressing the challenge of inconsistent distillation points and improving performance for both homogeneous and heterogeneous distillation.", "motivation": "The lack of effective knowledge distillation methods for DETR due to inconsistent distillation points motivates the development of KD-DETR.", "method": "Proposes KD-DETR with consistent distillation points sampling, decoupling detection and distillation tasks using specialized object queries and a general-to-specific sampling strategy.", "result": "KD-DETR improves student model performance by 2.6%-5.2% for DETR variants and achieves 2.1% improvement in heterogeneous distillation (DINO to Faster R-CNN).", "conclusion": "KD-DETR is effective and generalizable, offering a robust solution for knowledge distillation in DETR architectures."}}
{"id": "2506.20451", "pdf": "https://arxiv.org/pdf/2506.20451", "abs": "https://arxiv.org/abs/2506.20451", "authors": ["Shuchu Han", "Wolfgang Bruckner"], "title": "Automatic Demonstration Selection for LLM-based Tabular Data Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A fundamental question in applying In-Context Learning (ICL) for tabular data\nclassification is how to determine the ideal number of demonstrations in the\nprompt. This work addresses this challenge by presenting an algorithm to\nautomatically select a reasonable number of required demonstrations. Our method\ndistinguishes itself by integrating not only the tabular data's distribution\nbut also the user's selected prompt template and the specific Large Language\nModel (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed\nalgorithm defines a novel metric to quantify the similarities between different\ndemonstrations. We then construct a similarity graph and analyze the\neigenvalues of its Laplacian to derive the minimum number of demonstrations\ncapable of representing the data within the LLM's intrinsic representation\nspace. We validate the efficacy of our approach through experiments comparing\nits performance against conventional random selection algorithms on diverse\ndatasets and LLMs.", "AI": {"tldr": "An algorithm for selecting the optimal number of demonstrations in ICL for tabular data, considering data distribution, prompt template, and LLM, validated against random selection methods.", "motivation": "Determining the ideal number of demonstrations in ICL for tabular data classification is challenging. This work aims to automate this process by integrating data distribution, prompt template, and LLM specifics.", "method": "Uses Spectral Graph Theory to quantify demonstration similarities, constructs a similarity graph, and analyzes Laplacian eigenvalues to determine the minimum representative demonstrations.", "result": "Validated through experiments, showing superior performance compared to random selection algorithms across diverse datasets and LLMs.", "conclusion": "The proposed method effectively automates demonstration selection, improving ICL performance for tabular data."}}
{"id": "2506.20441", "pdf": "https://arxiv.org/pdf/2506.20441", "abs": "https://arxiv.org/abs/2506.20441", "authors": ["Antoine Caradot", "R\u00e9mi Emonet", "Amaury Habrard", "Abdel-Rahim Mezidi", "Marc Sebban"], "title": "M\u00e9thode de quadrature pour les PINNs fond\u00e9e th\u00e9oriquement sur la hessienne des r\u00e9siduels", "categories": ["cs.LG"], "comment": "10 pages. In French. Comments are welcome", "summary": "Physics-informed Neural Networks (PINNs) have emerged as an efficient way to\nlearn surrogate neural solvers of PDEs by embedding the physical model in the\nloss function and minimizing its residuals using automatic differentiation at\nso-called collocation points. Originally uniformly sampled, the choice of the\nlatter has been the subject of recent advances leading to adaptive sampling\nrefinements. In this paper, we propose a new quadrature method for\napproximating definite integrals based on the hessian of the considered\nfunction, and that we leverage to guide the selection of the collocation points\nduring the training process of PINNs.", "AI": {"tldr": "The paper introduces a new quadrature method for selecting collocation points in PINNs, leveraging the hessian of the function to improve training efficiency.", "motivation": "To enhance the efficiency of Physics-informed Neural Networks (PINNs) by improving the selection of collocation points during training.", "method": "Proposes a quadrature method based on the hessian of the function to guide collocation point selection in PINNs.", "result": "The method aims to optimize the training process of PINNs by adaptively refining collocation points.", "conclusion": "The proposed hessian-based quadrature method offers a promising approach for improving PINN training through better collocation point selection."}}
{"id": "2502.11677", "pdf": "https://arxiv.org/pdf/2502.11677", "abs": "https://arxiv.org/abs/2502.11677", "authors": ["Shiyu Ni", "Keping Bi", "Jiafeng Guo", "Lulu Yu", "Baolong Bi", "Xueqi Cheng"], "title": "Towards Fully Exploiting LLM Internal States to Enhance Knowledge Boundary Perception", "categories": ["cs.CL"], "comment": "ACL2025 Main", "summary": "Large language models (LLMs) exhibit impressive performance across diverse\ntasks but often struggle to accurately gauge their knowledge boundaries,\nleading to confident yet incorrect responses. This paper explores leveraging\nLLMs' internal states to enhance their perception of knowledge boundaries from\nefficiency and risk perspectives. We investigate whether LLMs can estimate\ntheir confidence using internal states before response generation, potentially\nsaving computational resources. Our experiments on datasets like Natural\nQuestions, HotpotQA, and MMLU reveal that LLMs demonstrate significant\npre-generation perception, which is further refined post-generation, with\nperception gaps remaining stable across varying conditions. To mitigate risks\nin critical domains, we introduce Confidence Consistency-based Calibration\n($C^3$), which assesses confidence consistency through question reformulation.\n$C^3$ significantly improves LLMs' ability to recognize their knowledge gaps,\nenhancing the unknown perception rate by 5.6% on NQ and 4.9% on HotpotQA. Our\nfindings suggest that pre-generation confidence estimation can optimize\nefficiency, while $C^3$ effectively controls output risks, advancing the\nreliability of LLMs in practical applications.", "AI": {"tldr": "The paper explores using LLMs' internal states to improve their awareness of knowledge boundaries, introducing a method ($C^3$) to enhance confidence calibration and reduce incorrect responses.", "motivation": "LLMs often provide confident but incorrect answers due to poor knowledge boundary awareness, posing risks in critical applications.", "method": "Investigates pre-generation confidence estimation using internal states and introduces $C^3$ for post-generation confidence calibration via question reformulation.", "result": "LLMs show strong pre-generation perception, and $C^3$ improves unknown perception rates by 5.6% (NQ) and 4.9% (HotpotQA).", "conclusion": "Pre-generation confidence estimation boosts efficiency, while $C^3$ enhances reliability, making LLMs safer for practical use."}}
{"id": "2311.08557", "pdf": "https://arxiv.org/pdf/2311.08557", "abs": "https://arxiv.org/abs/2311.08557", "authors": ["Thangarajah Akilan", "Hrishikesh Vachhani"], "title": "Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "29 pages, 4 tables, 21 figures", "summary": "Pedestrian detection has become a cornerstone for several high-level tasks,\nincluding autonomous driving, intelligent transportation, and traffic\nsurveillance. There are several works focussed on pedestrian detection using\nvisible images, mainly in the daytime. However, this task is very intriguing\nwhen the environmental conditions change to poor lighting or nighttime.\nRecently, new ideas have been spurred to use alternative sources, such as Far\nInfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light\nconditions. This study reviews recent developments in low-light pedestrian\ndetection approaches. It systematically categorizes and analyses various\nalgorithms from region-based to non-region-based and graph-based learning\nmethodologies by highlighting their methodologies, implementation issues, and\nchallenges. It also outlines the key benchmark datasets that can be used for\nresearch and development of advanced pedestrian detection algorithms,\nparticularly in low-light situations.", "AI": {"tldr": "A review of low-light pedestrian detection methods, focusing on FIR sensor-based approaches, categorizing algorithms, and discussing challenges and datasets.", "motivation": "Pedestrian detection is crucial for applications like autonomous driving, but existing methods using visible images struggle in low-light conditions, prompting exploration of FIR sensors.", "method": "Systematic categorization and analysis of algorithms, including region-based, non-region-based, and graph-based learning, along with implementation issues.", "result": "Identifies key methodologies and challenges in low-light pedestrian detection, highlighting benchmark datasets for further research.", "conclusion": "The study provides a comprehensive review of low-light pedestrian detection, emphasizing the need for advanced algorithms and suitable datasets."}}
{"id": "2506.20525", "pdf": "https://arxiv.org/pdf/2506.20525", "abs": "https://arxiv.org/abs/2506.20525", "authors": ["Christian Intern\u00f2", "Andrea Castellani", "Sebastian Schmitt", "Fabio Stella", "Barbara Hammer"], "title": "Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of\nhigh-quality datasets and the complex variability of industrial energy\nconsumption patterns. To address data scarcity and privacy issues, we introduce\nthe Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an\nopen-source dataset generated using Digital Twin simulations. SIDED includes\nthree types of industrial facilities across three different geographic\nlocations, capturing diverse appliance behaviors, weather conditions, and load\nprofiles. We also propose the Appliance-Modulated Data Augmentation (AMDA)\nmethod, a computationally efficient technique that enhances NILM model\ngeneralization by intelligently scaling appliance power contributions based on\ntheir relative impact. We show in experiments that NILM models trained with\nAMDA-augmented data significantly improve the disaggregation of energy\nconsumption of complex industrial appliances like combined heat and power\nsystems. Specifically, in our out-of-sample scenarios, models trained with AMDA\nachieved a Normalized Disaggregation Error of 0.093, outperforming models\ntrained without data augmentation (0.451) and those trained with random data\naugmentation (0.290). Data distribution analyses confirm that AMDA effectively\naligns training and test data distributions, enhancing model generalization.", "AI": {"tldr": "The paper introduces SIDED, a synthetic industrial dataset for NILM, and AMDA, a data augmentation method, to address data scarcity and improve model generalization in industrial energy disaggregation.", "motivation": "Industrial NILM faces challenges due to limited high-quality datasets and complex energy consumption patterns. Data scarcity and privacy issues further complicate the problem.", "method": "The authors propose SIDED, a synthetic dataset generated via Digital Twin simulations, and AMDA, a method to scale appliance power contributions for better model generalization.", "result": "NILM models trained with AMDA-augmented data achieved a Normalized Disaggregation Error of 0.093, outperforming non-augmented (0.451) and randomly augmented (0.290) models.", "conclusion": "AMDA effectively aligns training and test data distributions, enhancing NILM model performance for industrial energy disaggregation."}}
{"id": "2506.20511", "pdf": "https://arxiv.org/pdf/2506.20511", "abs": "https://arxiv.org/abs/2506.20511", "authors": ["Arno Geimer", "Karthick Panner Selvam", "Beltran Fiz Pontiveros"], "title": "Collaborative Batch Size Optimization for Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) is a decentralized collaborative Machine Learning\nframework for training models without collecting data in a centralized\nlocation. It has seen application across various disciplines, from helping\nmedical diagnoses in hospitals to detecting fraud in financial transactions. In\nthis paper, we focus on improving the local training process through hardware\nusage optimization. While participants in a federation might share the hardware\nthey are training on, since there is no information exchange between them,\ntheir training process can be hindered by an improper training configuration.\nTaking advantage of the parallel processing inherent to Federated Learning, we\nuse a greedy randomized search to optimize local batch sizes for the best\ntraining settings across all participants. Our results show that against\ndefault parameter settings, our method improves convergence speed while staying\nnearly on par with the case where local parameters are optimized.", "AI": {"tldr": "Optimizing local batch sizes in Federated Learning via greedy randomized search improves convergence speed without compromising performance.", "motivation": "Improve local training efficiency in Federated Learning by optimizing hardware usage, addressing suboptimal configurations due to lack of information exchange between participants.", "method": "Uses greedy randomized search to optimize local batch sizes, leveraging parallel processing in FL.", "result": "Outperforms default parameter settings in convergence speed, matching performance of locally optimized parameters.", "conclusion": "Proposed method effectively enhances FL training efficiency without requiring parameter tuning for each participant."}}
{"id": "2502.11707", "pdf": "https://arxiv.org/pdf/2502.11707", "abs": "https://arxiv.org/abs/2502.11707", "authors": ["Sherzod Hakimov", "Lara Pfennigschmidt", "David Schlangen"], "title": "Ad-hoc Concept Forming in the Game Codenames as a Means for Evaluating Large Language Models", "categories": ["cs.CL"], "comment": "Accepted at GemBench workshop co-located with ACL 2025", "summary": "This study utilizes the game Codenames as a benchmarking tool to evaluate\nlarge language models (LLMs) with respect to specific linguistic and cognitive\nskills. LLMs play each side of the game, where one side generates a clue word\ncovering several target words and the other guesses those target words. We\ndesigned various experiments by controlling the choice of words (abstract vs.\nconcrete words, ambiguous vs. monosemic) or the opponent (programmed to be\nfaster or slower in revealing words). Recent commercial and open-weight models\nwere compared side-by-side to find out factors affecting their performance. The\nevaluation reveals details about their strategies, challenging cases, and\nlimitations of LLMs.", "AI": {"tldr": "The study uses Codenames to benchmark LLMs, testing clue generation and guessing abilities under varied conditions, revealing their strategies and limitations.", "motivation": "To evaluate LLMs' linguistic and cognitive skills in a controlled, interactive setting using the game Codenames.", "method": "LLMs play both clue-giving and guessing roles in Codenames, with experiments varying word types and opponent behaviors. Commercial and open-weight models are compared.", "result": "The study identifies factors affecting LLM performance, their strategies, and challenging cases, highlighting limitations.", "conclusion": "Codenames serves as an effective benchmark for assessing LLMs, uncovering nuanced performance details and areas for improvement."}}
{"id": "2401.13934", "pdf": "https://arxiv.org/pdf/2401.13934", "abs": "https://arxiv.org/abs/2401.13934", "authors": ["Tao Guo", "Yinuo Wang", "Shihao Shu", "Weimin Yuan", "Diansheng Chen", "Zhouping Tang", "Cai Meng", "Xiangzhi Bai"], "title": "MambaMorph: a Mamba-based Framework for Medical MR-CT Deformable Registration", "categories": ["cs.CV"], "comment": null, "summary": "Capturing voxel-wise spatial correspondence across distinct modalities is\ncrucial for medical image analysis. However, current registration approaches\nare not practical enough in terms of registration accuracy and clinical\napplicability. In this paper, we introduce MambaMorph, a novel multi-modality\ndeformable registration framework. Specifically, MambaMorph utilizes a\nMamba-based registration module and a fine-grained, yet simple, feature\nextractor for efficient long-range correspondence modeling and high-dimensional\nfeature learning, respectively. Additionally, we develop a well-annotated brain\nMR-CT registration dataset, SR-Reg, to address the scarcity of data in\nmulti-modality registration. To validate MambaMorph's multi-modality\nregistration capabilities, we conduct quantitative experiments on both our\nSR-Reg dataset and a public T1-T2 dataset. The experimental results on both\ndatasets demonstrate that MambaMorph significantly outperforms the current\nstate-of-the-art learning-based registration methods in terms of registration\naccuracy. Further study underscores the efficiency of the Mamba-based\nregistration module and the lightweight feature extractor, which achieve\nnotable registration quality while maintaining reasonable computational costs\nand speeds. We believe that MambaMorph holds significant potential for\npractical applications in medical image registration. The code for MambaMorph\nis available at: https://github.com/Guo-Stone/MambaMorph.", "AI": {"tldr": "MambaMorph is a novel multi-modality deformable registration framework for medical images, outperforming state-of-the-art methods in accuracy and efficiency.", "motivation": "Current registration methods lack accuracy and clinical practicality, necessitating a more efficient solution for multi-modality medical image analysis.", "method": "MambaMorph combines a Mamba-based registration module for long-range correspondence and a lightweight feature extractor for high-dimensional learning. A new dataset, SR-Reg, is introduced to address data scarcity.", "result": "MambaMorph achieves superior registration accuracy on SR-Reg and public datasets, with efficient computational performance.", "conclusion": "MambaMorph shows strong potential for practical medical image registration, balancing accuracy and efficiency."}}
{"id": "2506.20535", "pdf": "https://arxiv.org/pdf/2506.20535", "abs": "https://arxiv.org/abs/2506.20535", "authors": ["Hongzhen Huang", "Kunming Zhang", "Hanlong Liao", "Kui Wu", "Guoming Tang"], "title": "WattsOnAI: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "11 pages, 7 figures and 5 tables", "summary": "The rapid advancement of AI, particularly large language models (LLMs), has\nraised significant concerns about the energy use and carbon emissions\nassociated with model training and inference. However, existing tools for\nmeasuring and reporting such impacts are often fragmented, lacking systematic\nmetric integration and offering limited support for correlation analysis among\nthem. This paper presents WattsOnAI, a comprehensive software toolkit for the\nmeasurement, analysis, and visualization of energy use, power draw, hardware\nperformance, and carbon emissions across AI workloads. By seamlessly\nintegrating with existing AI frameworks, WattsOnAI offers standardized reports\nand exports fine-grained time-series data to support benchmarking and\nreproducibility in a lightweight manner. It further enables in-depth\ncorrelation analysis between hardware metrics and model performance and thus\nfacilitates bottleneck identification and performance enhancement. By\naddressing critical limitations in existing tools, WattsOnAI encourages the\nresearch community to weigh environmental impact alongside raw performance of\nAI workloads and advances the shift toward more sustainable \"Green AI\"\npractices. The code is available at https://github.com/SusCom-Lab/WattsOnAI.", "AI": {"tldr": "WattsOnAI is a toolkit for measuring and analyzing energy use, power draw, hardware performance, and carbon emissions in AI workloads, addressing gaps in existing tools.", "motivation": "Concerns about AI's energy use and carbon emissions, coupled with fragmented and limited existing tools, drive the need for a comprehensive solution like WattsOnAI.", "method": "WattsOnAI integrates with AI frameworks to provide standardized reports, fine-grained data, and correlation analysis between hardware metrics and model performance.", "result": "The toolkit supports benchmarking, reproducibility, bottleneck identification, and performance enhancement, promoting sustainable AI practices.", "conclusion": "WattsOnAI advances Green AI by addressing tool limitations and encouraging the research community to consider environmental impact alongside performance."}}
{"id": "2506.20518", "pdf": "https://arxiv.org/pdf/2506.20518", "abs": "https://arxiv.org/abs/2506.20518", "authors": ["Arno Geimer", "Beltran Fiz Pontiveros", "Radu State"], "title": "WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) is a collaborative machine learning paradigm which\nallows participants to collectively train a model while training data remains\nprivate. This paradigm is especially beneficial for sectors like finance, where\ndata privacy, security and model performance are paramount. FL has been\nextensively studied in the years following its introduction, leading to, among\nothers, better performing collaboration techniques, ways to defend against\nother clients trying to attack the model, and contribution assessment methods.\nAn important element in for-profit Federated Learning is the development of\nincentive methods to determine the allocation and distribution of rewards for\nparticipants. While numerous methods for allocation have been proposed and\nthoroughly explored, distribution frameworks remain relatively understudied. In\nthis paper, we propose a novel framework which introduces client-specific\ntokens as investment vehicles within the FL ecosystem. Our framework aims to\naddress the limitations of existing incentive schemes by leveraging a\ndecentralized finance (DeFi) platform and automated market makers (AMMs) to\ncreate a more flexible and scalable reward distribution system for\nparticipants, and a mechanism for third parties to invest in the federation\nlearning process.", "AI": {"tldr": "A novel framework for reward distribution in Federated Learning (FL) using client-specific tokens and decentralized finance (DeFi) to enhance flexibility and scalability.", "motivation": "Addressing the understudied area of reward distribution in FL, especially for for-profit applications, by leveraging DeFi and automated market makers (AMMs).", "method": "Proposes a framework with client-specific tokens as investment vehicles, integrated with DeFi and AMMs for flexible reward distribution.", "result": "Creates a scalable and flexible reward system for FL participants and enables third-party investment in the FL process.", "conclusion": "The framework advances FL incentive mechanisms by combining DeFi and AMMs, offering a scalable solution for reward distribution."}}
{"id": "2502.11874", "pdf": "https://arxiv.org/pdf/2502.11874", "abs": "https://arxiv.org/abs/2502.11874", "authors": ["Hugh Mee Wong", "Rick Nouwen", "Albert Gatt"], "title": "VAQUUM: Are Vague Quantifiers Grounded in Visual Data?", "categories": ["cs.CL"], "comment": "Proceedings of ACL 2025, 10 pages", "summary": "Vague quantifiers such as \"a few\" and \"many\" are influenced by various\ncontextual factors, including the number of objects present in a given context.\nIn this work, we evaluate the extent to which vision-and-language models (VLMs)\nare compatible with humans when producing or judging the appropriateness of\nvague quantifiers in visual contexts. We release a novel dataset, VAQUUM,\ncontaining 20,300 human ratings on quantified statements across a total of 1089\nimages. Using this dataset, we compare human judgments and VLM predictions\nusing three different evaluation methods. Our findings show that VLMs, like\nhumans, are influenced by object counts in vague quantifier use. However, we\nfind significant inconsistencies across models in different evaluation\nsettings, suggesting that judging and producing vague quantifiers rely on two\ndifferent processes.", "AI": {"tldr": "VLMs' compatibility with humans in using vague quantifiers like \"a few\" and \"many\" is evaluated, revealing similarities in object count influence but inconsistencies across evaluation methods.", "motivation": "To assess if vision-and-language models (VLMs) align with human judgments in using vague quantifiers in visual contexts.", "method": "Created VAQUUM dataset with 20,300 human ratings; compared human judgments and VLM predictions using three evaluation methods.", "result": "VLMs, like humans, are influenced by object counts but show inconsistencies across evaluation settings.", "conclusion": "Judging and producing vague quantifiers involve distinct processes, as evidenced by model inconsistencies."}}
{"id": "2403.08059", "pdf": "https://arxiv.org/pdf/2403.08059", "abs": "https://arxiv.org/abs/2403.08059", "authors": ["Benjamin D. Killeen", "Liam J. Wang", "Blanca Inigo", "Han Zhang", "Mehran Armand", "Russell H. Taylor", "Greg Osgood", "Mathias Unberath"], "title": "FluoroSAM: A Language-promptable Foundation Model for Flexible X-ray Image Segmentation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Language promptable X-ray image segmentation would enable greater flexibility\nfor human-in-the-loop workflows in diagnostic and interventional precision\nmedicine. Prior efforts have contributed task-specific models capable of\nsolving problems within a narrow scope, but expanding to broader use requires\nadditional data, annotations, and training time. Recently, language-aligned\nfoundation models (LFMs) -- machine learning models trained on large amounts of\nhighly variable image and text data thus enabling broad applicability -- have\nemerged as promising tools for automated image analysis. Existing foundation\nmodels for medical image analysis focus on scenarios and modalities where\nlarge, richly annotated datasets are available. However, the X-ray imaging\nmodality features highly variable image appearance and applications, from\ndiagnostic chest X-rays to interventional fluoroscopy, with varying\navailability of data. To pave the way toward an LFM for comprehensive and\nlanguage-aligned analysis of arbitrary medical X-ray images, we introduce\nFluoroSAM, a language-promptable variant of the Segment Anything Model, trained\nfrom scratch on 3M synthetic X-ray images from a wide variety of human\nanatomies, imaging geometries, and viewing angles. These include pseudo-ground\ntruth masks for 128 organ types and 464 tools with associated text\ndescriptions. FluoroSAM is capable of segmenting myriad anatomical structures\nand tools based on natural language prompts, thanks to the novel incorporation\nof vector quantization (VQ) of text embeddings in the training process. We\ndemonstrate FluoroSAM's performance quantitatively on real X-ray images and\nshowcase on several applications how FluoroSAM is a key enabler for rich\nhuman-machine interaction in the X-ray image acquisition and analysis context.\nCode is available at https://github.com/arcadelab/fluorosam.", "AI": {"tldr": "FluoroSAM is a language-promptable X-ray image segmentation model trained on synthetic data, enabling flexible human-in-the-loop workflows in precision medicine.", "motivation": "Existing models are task-specific and lack broad applicability. Language-aligned foundation models (LFMs) offer promise but need adaptation for X-ray imaging's variability and data constraints.", "method": "FluoroSAM, a variant of the Segment Anything Model, is trained on 3M synthetic X-ray images with pseudo-ground truth masks and text descriptions, incorporating vector quantization (VQ) of text embeddings.", "result": "FluoroSAM segments anatomical structures and tools based on natural language prompts, demonstrating performance on real X-ray images and enabling rich human-machine interaction.", "conclusion": "FluoroSAM advances language-promptable X-ray image segmentation, supporting diverse applications in diagnostic and interventional precision medicine."}}
{"id": "2506.20551", "pdf": "https://arxiv.org/pdf/2506.20551", "abs": "https://arxiv.org/abs/2506.20551", "authors": ["Soumya Madireddy", "Lu Gao", "Zia Din", "Kinam Kim", "Ahmed Senouci", "Zhe Han", "Yunpeng Zhang"], "title": "Large Language Model-Driven Code Compliance Checking in Building Information Modeling", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This research addresses the time-consuming and error-prone nature of manual\ncode compliance checking in Building Information Modeling (BIM) by introducing\na Large Language Model (LLM)-driven approach to semi-automate this critical\nprocess. The developed system integrates LLMs such as GPT, Claude, Gemini, and\nLlama, with Revit software to interpret building codes, generate Python\nscripts, and perform semi-automated compliance checks within the BIM\nenvironment. Case studies on a single-family residential project and an office\nbuilding project demonstrated the system's ability to reduce the time and\neffort required for compliance checks while improving accuracy. It streamlined\nthe identification of violations, such as non-compliant room dimensions,\nmaterial usage, and object placements, by automatically assessing relationships\nand generating actionable reports. Compared to manual methods, the system\neliminated repetitive tasks, simplified complex regulations, and ensured\nreliable adherence to standards. By offering a comprehensive, adaptable, and\ncost-effective solution, this proposed approach offers a promising advancement\nin BIM-based compliance checking, with potential applications across diverse\nregulatory documents in construction projects.", "AI": {"tldr": "A LLM-driven system automates BIM code compliance checks, reducing time and errors while improving accuracy.", "motivation": "Manual code compliance checking in BIM is time-consuming and error-prone, necessitating automation.", "method": "Integrates LLMs (GPT, Claude, Gemini, Llama) with Revit to interpret codes, generate scripts, and perform checks.", "result": "Case studies showed reduced time/effort, improved accuracy, and streamlined violation identification.", "conclusion": "The system offers a promising, adaptable, and cost-effective solution for BIM compliance checking."}}
{"id": "2506.20537", "pdf": "https://arxiv.org/pdf/2506.20537", "abs": "https://arxiv.org/abs/2506.20537", "authors": ["R. Sharma", "M. Raissi", "Y. B. Guo"], "title": "Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion", "categories": ["cs.LG"], "comment": null, "summary": "Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process\nprediction due to the lasting issue of high computation cost using traditional\nnumerical methods such as finite element analysis (FEA). This study presents an\nefficient modeling framework termed FEA-Regulated Physics-Informed Neural\nNetwork (FEA-PINN) to accelerate the thermal field prediction in a LPBF process\nwhile maintaining the FEA accuracy. A novel dynamic material updating strategy\nis developed to capture the dynamic phase change of powder-liquid-solid in the\nPINN model. The PINN model incorporates temperature-dependent material\nproperties and phase change behavior using the apparent heat capacity method.\nWhile the PINN model demonstrates high accuracy with a small training data and\nenables generalization of new process parameters via transfer learning, it\nfaces the challenge of high computation cost in time-dependent problems due to\nthe residual accumulation. To overcome this issue, the FEA-PINN framework\nintegrates corrective FEA simulations during inference to enforce physical\nconsistency and reduce error drift. A comparative analysis shows that FEA-PINN\nachieves equivalent accuracy to FEA while significantly reducing computational\ncost. The framework has been validated using the benchmark FEA data and\ndemonstrated through single-track scanning in LPBF.", "AI": {"tldr": "The paper introduces FEA-PINN, a hybrid model combining Physics-Informed Neural Networks (PINN) with corrective FEA simulations to efficiently predict thermal fields in LPBF, reducing computational costs while maintaining accuracy.", "motivation": "Traditional FEA methods for LPBF simulation are computationally expensive, necessitating a faster yet accurate alternative.", "method": "The FEA-PINN framework integrates PINN with dynamic material updating and corrective FEA simulations to address residual accumulation and ensure physical consistency.", "result": "FEA-PINN matches FEA accuracy with significantly lower computational cost, validated using benchmark data and single-track LPBF scanning.", "conclusion": "FEA-PINN offers an efficient and accurate solution for LPBF thermal field prediction, overcoming the limitations of standalone PINN and FEA."}}
{"id": "2502.11962", "pdf": "https://arxiv.org/pdf/2502.11962", "abs": "https://arxiv.org/abs/2502.11962", "authors": ["Tianyi Wu", "Jingwei Ni", "Bryan Hooi", "Jiaheng Zhang", "Elliott Ash", "See-Kiong Ng", "Mrinmaya Sachan", "Markus Leippold"], "title": "Balancing Truthfulness and Informativeness with Uncertainty-Aware Instruction Fine-Tuning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Instruction fine-tuning (IFT) can increase the informativeness of large\nlanguage models (LLMs), but may reduce their truthfulness. This trade-off\narises because IFT steers LLMs to generate responses containing long-tail\nknowledge that was not well covered during pre-training. As a result, models\nbecome more informative but less accurate when generalizing to unseen tasks. In\nthis paper, we empirically demonstrate how unfamiliar knowledge in IFT datasets\ncan negatively affect the truthfulness of LLMs, and we introduce two new IFT\nparadigms, $UNIT_{cut}$ and $UNIT_{ref}$, to address this issue. $UNIT_{cut}$\nidentifies and removes unfamiliar knowledge from IFT datasets to mitigate its\nimpact on model truthfulness, whereas $UNIT_{ref}$ trains LLMs to recognize\ntheir uncertainty and explicitly indicate it at the end of their responses. Our\nexperiments show that $UNIT_{cut}$ substantially improves LLM truthfulness,\nwhile $UNIT_{ref}$ maintains high informativeness and reduces hallucinations by\ndistinguishing between confident and uncertain statements.", "AI": {"tldr": "IFT improves LLM informativeness but reduces truthfulness due to unfamiliar knowledge. Two new paradigms, $UNIT_{cut}$ and $UNIT_{ref}$, address this: $UNIT_{cut}$ removes unfamiliar knowledge, while $UNIT_{ref}$ trains models to indicate uncertainty. Both improve truthfulness and reduce hallucinations.", "motivation": "The trade-off between informativeness and truthfulness in IFT of LLMs, caused by unfamiliar knowledge, motivates the need for solutions to maintain accuracy while generalizing to unseen tasks.", "method": "Introduces $UNIT_{cut}$ (removes unfamiliar knowledge) and $UNIT_{ref}$ (trains models to indicate uncertainty) to mitigate truthfulness issues in IFT.", "result": "$UNIT_{cut}$ improves truthfulness; $UNIT_{ref}$ maintains informativeness and reduces hallucinations by marking uncertain statements.", "conclusion": "The proposed paradigms effectively balance informativeness and truthfulness in IFT, addressing the negative impact of unfamiliar knowledge on LLM accuracy."}}
{"id": "2405.03633", "pdf": "https://arxiv.org/pdf/2405.03633", "abs": "https://arxiv.org/abs/2405.03633", "authors": ["Leonard Bruns", "Jun Zhang", "Patric Jensfelt"], "title": "Neural Graph Map: Dense Mapping with Efficient Loop Closure Integration", "categories": ["cs.CV", "cs.RO"], "comment": "WACV 2025, Project page:\n  https://kth-rpl.github.io/neural_graph_mapping/", "summary": "Neural field-based SLAM methods typically employ a single, monolithic field\nas their scene representation. This prevents efficient incorporation of loop\nclosure constraints and limits scalability. To address these shortcomings, we\npropose a novel RGB-D neural mapping framework in which the scene is\nrepresented by a collection of lightweight neural fields which are dynamically\nanchored to the pose graph of a sparse visual SLAM system. Our approach shows\nthe ability to integrate large-scale loop closures, while requiring only\nminimal reintegration. Furthermore, we verify the scalability of our approach\nby demonstrating successful building-scale mapping taking multiple loop\nclosures into account during the optimization, and show that our method\noutperforms existing state-of-the-art approaches on large scenes in terms of\nquality and runtime. Our code is available open-source at\nhttps://github.com/KTH-RPL/neural_graph_mapping.", "AI": {"tldr": "A novel RGB-D neural mapping framework using lightweight neural fields anchored to a sparse visual SLAM system, improving loop closure integration and scalability.", "motivation": "Monolithic neural fields in SLAM limit loop closure efficiency and scalability.", "method": "Dynamic anchoring of lightweight neural fields to a sparse visual SLAM pose graph.", "result": "Effective large-scale loop closure integration, minimal reintegration, and superior performance in quality and runtime.", "conclusion": "The proposed method outperforms state-of-the-art approaches in large scenes, offering scalability and efficiency."}}
{"id": "2506.20555", "pdf": "https://arxiv.org/pdf/2506.20555", "abs": "https://arxiv.org/abs/2506.20555", "authors": ["Wei-Lin Wu", "Lu Meng", "Shi-Lin Zhu"], "title": "DeepQuark: deep-neural-network approach to multiquark bound states", "categories": ["hep-ph", "cs.AI", "hep-ex", "hep-lat", "nucl-th"], "comment": "10 pages, 3 figures, 6 tables", "summary": "For the first time, we implement the deep-neural-network-based variational\nMonte Carlo approach for the multiquark bound states, whose complexity\nsurpasses that of electron or nucleon systems due to strong SU(3) color\ninteractions. We design a novel and high-efficiency architecture, DeepQuark, to\naddress the unique challenges in multiquark systems such as stronger\ncorrelations, extra discrete quantum numbers, and intractable confinement\ninteraction. Our method demonstrates competitive performance with\nstate-of-the-art approaches, including diffusion Monte Carlo and Gaussian\nexpansion method, in the nucleon, doubly heavy tetraquark, and fully heavy\ntetraquark systems. Notably, it outperforms existing calculations for\npentaquarks, exemplified by the triply heavy pentaquark. For the nucleon, we\nsuccessfully incorporate three-body flux-tube confinement interactions without\nadditional computational costs. In tetraquark systems, we consistently describe\nhadronic molecule $T_{cc}$ and compact tetraquark $T_{bb}$ with an unbiased\nform of wave function ansatz. In the pentaquark sector, we obtain weakly bound\n$\\bar D^*\\Xi_{cc}^*$ molecule $P_{cc\\bar c}(5715)$ with $S=\\frac{5}{2}$ and its\nbottom partner $P_{bb\\bar b}(15569)$. They can be viewed as the analogs of the\nmolecular $T_{cc}$. We recommend experimental search of $P_{cc\\bar c}(5715)$ in\nthe D-wave $J/\\psi \\Lambda_c$ channel. DeepQuark holds great promise for\nextension to larger multiquark systems, overcoming the computational barriers\nin conventional methods. It also serves as a powerful framework for exploring\nconfining mechanism beyond two-body interactions in multiquark states, which\nmay offer valuable insights into nonperturbative QCD and general many-body\nphysics.", "AI": {"tldr": "DeepQuark, a deep-neural-network-based variational Monte Carlo method, is introduced for multiquark systems, outperforming existing methods in accuracy and efficiency.", "motivation": "Address the complexity of multiquark systems due to strong SU(3) color interactions, stronger correlations, and intractable confinement interactions.", "method": "Designs DeepQuark, a novel architecture, to handle unique challenges in multiquark systems, incorporating three-body flux-tube confinement interactions and unbiased wave function ansatz.", "result": "Outperforms state-of-the-art methods in nucleon, tetraquark, and pentaquark systems, predicting new bound states like $P_{cc\\bar c}(5715)$.", "conclusion": "DeepQuark is promising for larger multiquark systems and offers insights into nonperturbative QCD and many-body physics."}}
{"id": "2506.20543", "pdf": "https://arxiv.org/pdf/2506.20543", "abs": "https://arxiv.org/abs/2506.20543", "authors": ["Sanne van Kempen", "Jaron Sanders", "Fiona Sloothaak", "Maarten G. Wolf"], "title": "Demonstration of effective UCB-based routing in skill-based queues on real-world data", "categories": ["cs.LG", "math.OC", "60K25, 93E35"], "comment": null, "summary": "This paper is about optimally controlling skill-based queueing systems such\nas data centers, cloud computing networks, and service systems. By means of a\ncase study using a real-world data set, we investigate the practical\nimplementation of a recently developed reinforcement learning algorithm for\noptimal customer routing. Our experiments show that the algorithm efficiently\nlearns and adapts to changing environments and outperforms static benchmark\npolicies, indicating its potential for live implementation. We also augment the\nreal-world applicability of this algorithm by introducing a new heuristic\nrouting rule to reduce delays. Moreover, we show that the algorithm can\noptimize for multiple objectives: next to payoff maximization, secondary\nobjectives such as server load fairness and customer waiting time reduction can\nbe incorporated. Tuning parameters are used for balancing inherent performance\ntrade--offs. Lastly, we investigate the sensitivity to estimation errors and\nparameter tuning, providing valuable insights for implementing adaptive routing\nalgorithms in complex real-world queueing systems.", "AI": {"tldr": "The paper explores a reinforcement learning algorithm for optimal customer routing in skill-based queueing systems, demonstrating its adaptability and superiority over static policies. It introduces a heuristic for delay reduction and multi-objective optimization, while also analyzing sensitivity to errors and tuning.", "motivation": "To address the challenge of efficiently managing customer routing in dynamic queueing systems like data centers and service networks, leveraging reinforcement learning for adaptability and performance.", "method": "Uses a case study with real-world data to test a reinforcement learning algorithm, introduces a heuristic routing rule, and evaluates multi-objective optimization and parameter tuning.", "result": "The algorithm outperforms static policies, adapts to changes, reduces delays, and balances multiple objectives like payoff, server fairness, and waiting times.", "conclusion": "The reinforcement learning approach is viable for real-world queueing systems, with insights on implementation, multi-objective optimization, and sensitivity to tuning."}}
{"id": "2502.17848", "pdf": "https://arxiv.org/pdf/2502.17848", "abs": "https://arxiv.org/abs/2502.17848", "authors": ["Jianghao Chen", "Zhenlin Wei", "Zhenjiang Ren", "Ziyong Li", "Jiajun Zhang"], "title": "LR^2Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems", "categories": ["cs.CL"], "comment": "ACL-2025, our code is available at https://github.com/ZNLP/LR2Bench", "summary": "Recent progress in Large Reasoning Models (LRMs) has significantly enhanced\nthe reasoning abilities of Large Language Models (LLMs), empowering them to\ntackle increasingly complex tasks through reflection capabilities, such as\nmaking assumptions, backtracking, and self-refinement. However, effectively\nevaluating such reflection capabilities remains challenging due to the lack of\nappropriate benchmarks. To bridge this gap, we introduce LR$^2$Bench, a novel\nbenchmark designed to evaluate the Long-chain Reflective Reasoning capabilities\nof LLMs. LR$^2$Bench comprises 850 samples across six Constraint Satisfaction\nProblems (CSPs) where reflective reasoning is crucial for deriving solutions\nthat meet all given constraints. Each type of task focuses on distinct\nconstraint patterns, such as knowledge-based, logical, and spatial constraints,\nproviding a comprehensive evaluation of diverse problem-solving scenarios. Our\nextensive evaluation on both conventional LLMs and LRMs reveals that even the\nmost advanced LRMs, such as DeepSeek-R1 and OpenAI o1-preview, struggle with\ntasks in LR$^2$Bench, achieving an average Exact Match score of only 20.0% and\n23.6%, respectively. These findings underscore the significant room for\nimprovement in the reflective reasoning capabilities of current LLMs.", "AI": {"tldr": "LR$^2$Bench is introduced to evaluate reflective reasoning in LLMs, revealing significant gaps in current models' performance.", "motivation": "The lack of benchmarks for evaluating reflective reasoning in LLMs motivates the creation of LR$^2$Bench.", "method": "LR$^2$Bench includes 850 samples across six CSPs, testing diverse constraint patterns like knowledge-based, logical, and spatial constraints.", "result": "Advanced LRMs like DeepSeek-R1 and OpenAI o1-preview score only 20.0% and 23.6% on LR$^2$Bench, highlighting performance gaps.", "conclusion": "Current LLMs have substantial room for improvement in reflective reasoning, as shown by LR$^2$Bench evaluations."}}
{"id": "2405.14017", "pdf": "https://arxiv.org/pdf/2405.14017", "abs": "https://arxiv.org/abs/2405.14017", "authors": ["Hao Zhang", "Di Chang", "Fang Li", "Mohammad Soleymani", "Narendra Ahuja"], "title": "MagicPose4D: Crafting Articulated Models with Appearance and Motion Control", "categories": ["cs.CV"], "comment": "Project Page: https://magicpose4d.github.io/", "summary": "With the success of 2D and 3D visual generative models, there is growing\ninterest in generating 4D content. Existing methods primarily rely on text\nprompts to produce 4D content, but they often fall short of accurately defining\ncomplex or rare motions. To address this limitation, we propose MagicPose4D, a\nnovel framework for refined control over both appearance and motion in 4D\ngeneration. Unlike current 4D generation methods, MagicPose4D accepts monocular\nvideos or mesh sequences as motion prompts, enabling precise and customizable\nmotion control. MagicPose4D comprises two key modules: (i) Dual-Phase 4D\nReconstruction Module, which operates in two phases. The first phase focuses on\ncapturing the model's shape using accurate 2D supervision and less accurate but\ngeometrically informative 3D pseudo-supervision without imposing skeleton\nconstraints. The second phase extracts the 3D motion (skeleton poses) using\nmore accurate pseudo-3D supervision, obtained in the first phase and introduces\nkinematic chain-based skeleton constraints to ensure physical plausibility.\nAdditionally, we propose a Global-local Chamfer loss that aligns the overall\ndistribution of predicted mesh vertices with the supervision while maintaining\npart-level alignment without extra annotations. (ii) Cross-category Motion\nTransfer Module, which leverages the extracted motion from the 4D\nreconstruction module and uses a kinematic-chain-based skeleton to achieve\ncross-category motion transfer. It ensures smooth transitions between frames\nthrough dynamic rigidity, facilitating robust generalization without additional\ntraining. Through extensive experiments, we demonstrate that MagicPose4D\nsignificantly improves the accuracy and consistency of 4D content generation,\noutperforming existing methods in various benchmarks.", "AI": {"tldr": "MagicPose4D is a framework for precise 4D content generation using motion prompts like videos or mesh sequences, improving accuracy and consistency over text-based methods.", "motivation": "Existing text-prompt-based 4D generation methods struggle with complex or rare motions, prompting the need for a more controlled approach.", "method": "MagicPose4D uses a Dual-Phase 4D Reconstruction Module for shape and motion capture, and a Cross-category Motion Transfer Module for motion generalization.", "result": "The framework outperforms existing methods in benchmarks, offering refined control and physical plausibility in 4D generation.", "conclusion": "MagicPose4D advances 4D content generation by enabling precise motion control and cross-category transfer without extra training."}}
{"id": "2506.20576", "pdf": "https://arxiv.org/pdf/2506.20576", "abs": "https://arxiv.org/abs/2506.20576", "authors": ["Sabrine Ennaji", "Elhadj Benkhelifa", "Luigi V. Mancini"], "title": "Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Adversarial attacks, wherein slight inputs are carefully crafted to mislead\nintelligent models, have attracted increasing attention. However, a critical\ngap persists between theoretical advancements and practical application,\nparticularly in structured data like network traffic, where interdependent\nfeatures complicate effective adversarial manipulations. Moreover, ambiguity in\ncurrent approaches restricts reproducibility and limits progress in this field.\nHence, existing defenses often fail to handle evolving adversarial attacks.\nThis paper proposes a novel approach for black-box adversarial attacks, that\naddresses these limitations. Unlike prior work, which often assumes system\naccess or relies on repeated probing, our method strictly respect black-box\nconstraints, reducing interaction to avoid detection and better reflect\nreal-world scenarios. We present an adaptive feature selection strategy using\nchange-point detection and causality analysis to identify and target sensitive\nfeatures to perturbations. This lightweight design ensures low computational\ncost and high deployability. Our comprehensive experiments show the attack's\neffectiveness in evading detection with minimal interaction, enhancing its\nadaptability and applicability in real-world scenarios. By advancing the\nunderstanding of adversarial attacks in network traffic, this work lays a\nfoundation for developing robust defenses.", "AI": {"tldr": "A novel black-box adversarial attack method for structured data (e.g., network traffic) is proposed, focusing on minimal interaction and adaptive feature selection to evade detection.", "motivation": "The gap between theoretical adversarial attack advancements and practical application in structured data, along with reproducibility issues and ineffective defenses, drives this work.", "method": "The approach uses change-point detection and causality analysis for adaptive feature selection, adhering to black-box constraints with minimal interaction.", "result": "Experiments confirm the attack's effectiveness in evading detection with low computational cost and high deployability.", "conclusion": "This work advances adversarial attack understanding in network traffic, aiding future robust defense development."}}
{"id": "2506.20574", "pdf": "https://arxiv.org/pdf/2506.20574", "abs": "https://arxiv.org/abs/2506.20574", "authors": ["Laura Boggia", "Rafael Teixeira de Lima", "Bogdan Malaescu"], "title": "Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series", "categories": ["cs.LG", "stat.ME"], "comment": "Submitted to VLDB 2026 conference, currently under review", "summary": "Anomaly detection in multivariate time series is an important problem across\nvarious fields such as healthcare, financial services, manufacturing or physics\ndetector monitoring. Accurately identifying when unexpected errors or faults\noccur is essential, yet challenging, due to the unknown nature of anomalies and\nthe complex interdependencies between time series dimensions. In this paper, we\ninvestigate transformer-based approaches for time series anomaly detection,\nfocusing on the recently proposed iTransformer architecture. Our contributions\nare fourfold: (i) we explore the application of the iTransformer to time series\nanomaly detection, and analyse the influence of key parameters such as window\nsize, step size, and model dimensions on performance; (ii) we examine methods\nfor extracting anomaly labels from multidimensional anomaly scores and discuss\nappropriate evaluation metrics for such labels; (iii) we study the impact of\nanomalous data present during training and assess the effectiveness of\nalternative loss functions in mitigating their influence; and (iv) we present a\ncomprehensive comparison of several transformer-based models across a diverse\nset of datasets for time series anomaly detection.", "AI": {"tldr": "The paper explores transformer-based approaches, particularly the iTransformer, for anomaly detection in multivariate time series, analyzing key parameters, label extraction, training impacts, and model comparisons.", "motivation": "Anomaly detection in multivariate time series is crucial but challenging due to unknown anomalies and complex interdependencies.", "method": "Investigates the iTransformer architecture, focusing on parameters like window size, step size, and model dimensions, and evaluates anomaly label extraction and loss functions.", "result": "Provides insights into parameter influences, label extraction methods, and performance of transformer-based models across diverse datasets.", "conclusion": "The study advances transformer-based anomaly detection, offering practical guidance and comprehensive comparisons for real-world applications."}}
{"id": "2502.20581", "pdf": "https://arxiv.org/pdf/2502.20581", "abs": "https://arxiv.org/abs/2502.20581", "authors": ["Hong Chen", "Misha Teplitskiy", "David Jurgens"], "title": "The Noisy Path from Source to Citation: Measuring How Scholars Engage with Past Research", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025", "summary": "Academic citations are widely used for evaluating research and tracing\nknowledge flows. Such uses typically rely on raw citation counts and neglect\nvariability in citation types. In particular, citations can vary in their\nfidelity as original knowledge from cited studies may be paraphrased,\nsummarized, or reinterpreted, possibly wrongly, leading to variation in how\nmuch information changes from cited to citing paper. In this study, we\nintroduce a computational pipeline to quantify citation fidelity at scale.\nUsing full texts of papers, the pipeline identifies citations in citing papers\nand the corresponding claims in cited papers, and applies supervised models to\nmeasure fidelity at the sentence level. Analyzing a large-scale\nmulti-disciplinary dataset of approximately 13 million citation sentence pairs,\nwe find that citation fidelity is higher when authors cite papers that are 1)\nmore recent and intellectually close, 2) more accessible, and 3) the first\nauthor has a lower H-index and the author team is medium-sized. Using a\nquasi-experiment, we establish the \"telephone effect\" - when citing papers have\nlow fidelity to the original claim, future papers that cite the citing paper\nand the original have lower fidelity to the original. Our work reveals\nsystematic differences in citation fidelity, underscoring the limitations of\nanalyses that rely on citation quantity alone and the potential for distortion\nof evidence.", "AI": {"tldr": "The paper introduces a computational pipeline to measure citation fidelity, revealing systematic differences in how accurately cited information is preserved, influenced by factors like recency, accessibility, and author characteristics.", "motivation": "Citations are often used for research evaluation, but raw counts ignore variability in citation fidelity, which can distort knowledge flows.", "method": "A computational pipeline analyzes full texts to identify citations and corresponding claims, using supervised models to measure fidelity at the sentence level.", "result": "Citation fidelity is higher for recent, accessible, and intellectually close papers, and lower for high H-index first authors. A 'telephone effect' distorts fidelity further.", "conclusion": "Citation fidelity varies systematically, highlighting limitations of relying on citation counts alone and potential evidence distortion."}}
{"id": "2408.05894", "pdf": "https://arxiv.org/pdf/2408.05894", "abs": "https://arxiv.org/abs/2408.05894", "authors": ["Zixuan Wu", "Yoolim Kim", "Carolyn Jane Anderson"], "title": "GlyphPattern: An Abstract Pattern Recognition Benchmark for Vision-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Vision-Language Models (VLMs) building upon the foundation of powerful large\nlanguage models have made rapid progress in reasoning across visual and textual\ndata. While VLMs perform well on vision tasks that they are trained on, our\nresults highlight key challenges in abstract pattern recognition. We present\nGlyphPattern, a 954 item dataset that pairs 318 human-written descriptions of\nvisual patterns from 40 writing systems with three visual presentation styles.\n  GlyphPattern evaluates abstract pattern recognition in VLMs, requiring models\nto understand and judge natural language descriptions of visual patterns.\nGlyphPattern patterns are drawn from a large-scale cognitive science\ninvestigation of human writing systems; as a result, they are rich in spatial\nreference and compositionality. Our experiments show that GlyphPattern is\nchallenging for state-of-the-art VLMs (GPT-4o achieves only 55% accuracy), with\nmarginal gains from few-shot prompting. Our detailed error analysis reveals\nchallenges at multiple levels, including visual processing, natural language\nunderstanding, and pattern generalization.", "AI": {"tldr": "GlyphPattern dataset evaluates VLMs' abstract pattern recognition, revealing challenges despite their strong performance on trained tasks.", "motivation": "To assess VLMs' ability in abstract pattern recognition, a gap in their current capabilities.", "method": "Introduces GlyphPattern, a dataset with 954 items pairing human-written descriptions of visual patterns from 40 writing systems with three visual styles.", "result": "State-of-the-art VLMs like GPT-4o achieve only 55% accuracy, showing limited improvement with few-shot prompting.", "conclusion": "VLMs struggle with abstract pattern recognition due to challenges in visual processing, language understanding, and generalization."}}
{"id": "2506.20595", "pdf": "https://arxiv.org/pdf/2506.20595", "abs": "https://arxiv.org/abs/2506.20595", "authors": ["Momin N. Siddiqui", "Roy Pea", "Hari Subramonyam"], "title": "AI in the Writing Process: How Purposeful AI Support Fosters Student Writing", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The ubiquity of technologies like ChatGPT has raised concerns about their\nimpact on student writing, particularly regarding reduced learner agency and\nsuperficial engagement with content. While standalone chat-based LLMs often\nproduce suboptimal writing outcomes, evidence suggests that purposefully\ndesigned AI writing support tools can enhance the writing process. This paper\ninvestigates how different AI support approaches affect writers' sense of\nagency and depth of knowledge transformation. Through a randomized control\ntrial with 90 undergraduate students, we compare three conditions: (1) a\nchat-based LLM writing assistant, (2) an integrated AI writing tool to support\ndiverse subprocesses, and (3) a standard writing interface (control). Our\nfindings demonstrate that, among AI-supported conditions, students using the\nintegrated AI writing tool exhibited greater agency over their writing process\nand engaged in deeper knowledge transformation overall. These results suggest\nthat thoughtfully designed AI writing support targeting specific aspects of the\nwriting process can help students maintain ownership of their work while\nfacilitating improved engagement with content.", "AI": {"tldr": "AI writing tools can enhance student agency and content engagement when designed purposefully, unlike generic chat-based LLMs.", "motivation": "Concerns about ChatGPT's impact on student writing, such as reduced agency and superficial engagement, prompted the study of better AI support tools.", "method": "A randomized control trial with 90 undergraduates compared three conditions: chat-based LLM, integrated AI writing tool, and standard interface.", "result": "Students using the integrated AI tool showed greater writing agency and deeper knowledge transformation than those using chat-based LLMs.", "conclusion": "Purposefully designed AI writing tools can improve student engagement and ownership of writing."}}
{"id": "2506.20575", "pdf": "https://arxiv.org/pdf/2506.20575", "abs": "https://arxiv.org/abs/2506.20575", "authors": ["Itay Niv", "Neta Rabin"], "title": "Exploring Graph-Transformer Out-of-Distribution Generalization Abilities", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning on graphs has shown remarkable success across numerous\napplications, including social networks, bio-physics, traffic networks, and\nrecommendation systems. Regardless of their successes, current methods\nfrequently depend on the assumption that training and testing data share the\nsame distribution, a condition rarely met in real-world scenarios. While\ngraph-transformer (GT) backbones have recently outperformed traditional\nmessage-passing neural networks (MPNNs) in multiple in-distribution (ID)\nbenchmarks, their effectiveness under distribution shifts remains largely\nunexplored.\n  In this work, we address the challenge of out-of-distribution (OOD)\ngeneralization for graph neural networks, with a special focus on the impact of\nbackbone architecture. We systematically evaluate GT and hybrid backbones in\nOOD settings and compare them to MPNNs. To do so, we adapt several leading\ndomain generalization (DG) algorithms to work with GTs and assess their\nperformance on a benchmark designed to test a variety of distribution shifts.\nOur results reveal that GT and hybrid GT-MPNN backbones consistently\ndemonstrate stronger generalization ability compared to MPNNs, even without\nspecialized DG algorithms.\n  Additionally, we propose a novel post-training analysis approach that\ncompares the clustering structure of the entire ID and OOD test datasets,\nspecifically examining domain alignment and class separation. Demonstrating its\nmodel-agnostic design, this approach not only provided meaningful insights into\nGT and MPNN backbones. It also shows promise for broader applicability to DG\nproblems beyond graph learning, offering a deeper perspective on generalization\nabilities that goes beyond standard accuracy metrics. Together, our findings\nhighlight the promise of graph-transformers for robust, real-world graph\nlearning and set a new direction for future research in OOD generalization.", "AI": {"tldr": "The paper explores the effectiveness of graph-transformer (GT) and hybrid GT-MPNN backbones in out-of-distribution (OOD) settings, showing they outperform traditional MPNNs. It also introduces a post-training analysis method for evaluating generalization.", "motivation": "Current graph neural networks assume training and testing data share the same distribution, which is unrealistic. The paper investigates OOD generalization, focusing on backbone architectures like GTs and MPNNs.", "method": "Systematically evaluate GT and hybrid backbones in OOD settings, adapt domain generalization algorithms for GTs, and propose a post-training analysis method for clustering structure.", "result": "GT and hybrid backbones generalize better than MPNNs, even without specialized algorithms. The post-training analysis provides insights into domain alignment and class separation.", "conclusion": "GTs show promise for robust graph learning in real-world scenarios, and the post-training analysis offers a new tool for understanding generalization beyond accuracy metrics."}}
{"id": "2503.00845", "pdf": "https://arxiv.org/pdf/2503.00845", "abs": "https://arxiv.org/abs/2503.00845", "authors": ["Miao Peng", "Nuo Chen", "Zongrui Suo", "Jia Li"], "title": "Rewarding Graph Reasoning Process makes LLMs more Generalized Reasoners", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to KDD 2025 Research Track", "summary": "Despite significant advancements in Large Language Models (LLMs), developing\nadvanced reasoning capabilities in LLMs remains a key challenge. Process Reward\nModels (PRMs) have demonstrated exceptional promise in enhancing reasoning by\nproviding step-wise feedback, particularly in the context of mathematical\nreasoning. However, their application to broader reasoning domains remains\nunderstudied, largely due to the high costs associated with manually creating\nstep-level supervision. In this work, we explore the potential of PRMs in graph\nreasoning problems - a domain that demands sophisticated multi-step reasoning\nand offers opportunities for automated step-level data generation using\nestablished graph algorithms. We introduce GraphSILO, the largest dataset for\ngraph reasoning problems with fine-grained step-wise labels, built using\nautomated Task-oriented Trajectories and Monte Carlo Tree Search (MCTS) to\ngenerate detailed reasoning steps with step-wise labels. Building upon this\ndataset, we train GraphPRM, the first PRM designed for graph reasoning\nproblems, and evaluate its effectiveness in two key settings: inference-time\nscaling and reinforcement learning via Direct Preference Optimization (DPO).\nExperimental results show that GraphPRM significantly improves LLM performance\nacross 13 graph reasoning tasks, delivering a 9% gain for Qwen2.5-7B and\ndemonstrating transferability to new graph reasoning datasets and new reasoning\ndomains like mathematical problem-solving. Notably, GraphPRM enhances LLM\nperformance on GSM8K and Math500, underscoring the cross-domain applicability\nof graph-based reasoning rewards. Our findings highlight the potential of PRMs\nin advancing reasoning across diverse domains, paving the way for more\nversatile and effective LLMs.", "AI": {"tldr": "GraphPRM, a Process Reward Model for graph reasoning, improves LLM performance by 9% on 13 tasks, showing cross-domain applicability.", "motivation": "Enhancing reasoning in LLMs beyond mathematical domains, leveraging automated step-level supervision for graph reasoning.", "method": "Uses GraphSILO dataset (automated step-wise labels via MCTS) to train GraphPRM, evaluated via inference-time scaling and DPO.", "result": "GraphPRM boosts LLM performance by 9% on graph tasks and transfers to math domains (GSM8K, Math500).", "conclusion": "PRMs like GraphPRM can advance reasoning across diverse domains, making LLMs more versatile."}}
{"id": "2408.16767", "pdf": "https://arxiv.org/pdf/2408.16767", "abs": "https://arxiv.org/abs/2408.16767", "authors": ["Fangfu Liu", "Wenqiang Sun", "Hanyang Wang", "Yikai Wang", "Haowen Sun", "Junliang Ye", "Jun Zhang", "Yueqi Duan"], "title": "ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "Project page: https://liuff19.github.io/ReconX", "summary": "Advancements in 3D scene reconstruction have transformed 2D images from the\nreal world into 3D models, producing realistic 3D results from hundreds of\ninput photos. Despite great success in dense-view reconstruction scenarios,\nrendering a detailed scene from insufficient captured views is still an\nill-posed optimization problem, often resulting in artifacts and distortions in\nunseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction\nparadigm that reframes the ambiguous reconstruction challenge as a temporal\ngeneration task. The key insight is to unleash the strong generative prior of\nlarge pre-trained video diffusion models for sparse-view reconstruction.\nHowever, 3D view consistency struggles to be accurately preserved in directly\ngenerated video frames from pre-trained models. To address this, given limited\ninput views, the proposed ReconX first constructs a global point cloud and\nencodes it into a contextual space as the 3D structure condition. Guided by the\ncondition, the video diffusion model then synthesizes video frames that are\nboth detail-preserved and exhibit a high degree of 3D consistency, ensuring the\ncoherence of the scene from various perspectives. Finally, we recover the 3D\nscene from the generated video through a confidence-aware 3D Gaussian Splatting\noptimization scheme. Extensive experiments on various real-world datasets show\nthe superiority of our ReconX over state-of-the-art methods in terms of quality\nand generalizability.", "AI": {"tldr": "ReconX introduces a novel 3D scene reconstruction method using pre-trained video diffusion models to address sparse-view reconstruction challenges, ensuring detail preservation and 3D consistency.", "motivation": "Sparse-view 3D scene reconstruction often leads to artifacts and distortions in unseen areas, posing an ill-posed optimization problem.", "method": "ReconX reframes reconstruction as a temporal generation task, leveraging pre-trained video diffusion models guided by a global point cloud condition. It synthesizes consistent video frames and recovers the 3D scene using Gaussian Splatting.", "result": "ReconX outperforms state-of-the-art methods in quality and generalizability across real-world datasets.", "conclusion": "The proposed ReconX paradigm effectively addresses sparse-view reconstruction challenges by combining generative priors and 3D consistency, yielding superior results."}}
{"id": "2506.20621", "pdf": "https://arxiv.org/pdf/2506.20621", "abs": "https://arxiv.org/abs/2506.20621", "authors": ["Silvio Alonso", "Antonio Pedro Santos Alves", "Lucas Romao", "H\u00e9lio Lopes", "Marcos Kalinowski"], "title": "Define-ML: An Approach to Ideate Machine Learning-Enabled Systems", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] The increasing adoption of machine learning (ML) in software\nsystems demands specialized ideation approaches that address ML-specific\nchallenges, including data dependencies, technical feasibility, and alignment\nbetween business objectives and probabilistic system behavior. Traditional\nideation methods like Lean Inception lack structured support for these ML\nconsiderations, which can result in misaligned product visions and unrealistic\nexpectations. [Goal] This paper presents Define-ML, a framework that extends\nLean Inception with tailored activities - Data Source Mapping, Feature-to-Data\nSource Mapping, and ML Mapping - to systematically integrate data and technical\nconstraints into early-stage ML product ideation. [Method] We developed and\nvalidated Define-ML following the Technology Transfer Model, conducting both\nstatic validation (with a toy problem) and dynamic validation (in a real-world\nindustrial case study). The analysis combined quantitative surveys with\nqualitative feedback, assessing utility, ease of use, and intent of adoption.\n[Results] Participants found Define-ML effective for clarifying data concerns,\naligning ML capabilities with business goals, and fostering cross-functional\ncollaboration. The approach's structured activities reduced ideation ambiguity,\nthough some noted a learning curve for ML-specific components, which can be\nmitigated by expert facilitation. All participants expressed the intention to\nadopt Define-ML. [Conclusion] Define-ML provides an openly available, validated\napproach for ML product ideation, building on Lean Inception's agility while\naligning features with available data and increasing awareness of technical\nfeasibility.", "AI": {"tldr": "Define-ML extends Lean Inception with ML-specific activities to align data, technical constraints, and business goals in early-stage ML product ideation.", "motivation": "Traditional ideation methods lack support for ML-specific challenges like data dependencies and technical feasibility, leading to misaligned visions.", "method": "Developed and validated using the Technology Transfer Model, including static (toy problem) and dynamic (industrial case study) validation with mixed-method analysis.", "result": "Participants found Define-ML effective for clarifying data concerns and aligning ML with business goals, though it has a learning curve. All intended to adopt it.", "conclusion": "Define-ML is a validated, open framework that enhances Lean Inception for ML product ideation by addressing data and technical feasibility."}}
{"id": "2506.20584", "pdf": "https://arxiv.org/pdf/2506.20584", "abs": "https://arxiv.org/abs/2506.20584", "authors": ["Mariano Tepper", "Ted Willke"], "title": "The kernel of graph indices for vector search", "categories": ["cs.LG"], "comment": null, "summary": "The most popular graph indices for vector search use principles from\ncomputational geometry to build the graph. Hence, their formal graph\nnavigability guarantees are only valid in Euclidean space. In this work, we\nshow that machine learning can be used to build graph indices for vector search\nin metric and non-metric vector spaces (e.g., for inner product similarity).\nFrom this novel perspective, we introduce the Support Vector Graph (SVG), a new\ntype of graph index that leverages kernel methods to establish the graph\nconnectivity and that comes with formal navigability guarantees valid in metric\nand non-metric vector spaces. In addition, we interpret the most popular graph\nindices, including HNSW and DiskANN, as particular specializations of SVG and\nshow that new indices can be derived from the principles behind this\nspecialization. Finally, we propose SVG-L0 that incorporates an $\\ell_0$\nsparsity constraint into the SVG kernel method to build graphs with a bounded\nout-degree. This yields a principled way of implementing this practical\nrequirement, in contrast to the traditional heuristic of simply truncating the\nout edges of each node. Additionally, we show that SVG-L0 has a self-tuning\nproperty that avoids the heuristic of using a set of candidates to find the\nout-edges of each node and that keeps its computational complexity in check.", "AI": {"tldr": "The paper introduces the Support Vector Graph (SVG), a machine learning-based graph index for vector search in metric and non-metric spaces, with formal navigability guarantees. It also interprets existing indices as SVG specializations and proposes SVG-L0 for bounded out-degree.", "motivation": "Current graph indices for vector search rely on Euclidean space principles, limiting their applicability. The authors aim to extend these indices to metric and non-metric spaces using machine learning.", "method": "The authors propose SVG, leveraging kernel methods for graph connectivity, and SVG-L0, which adds an \u21130 sparsity constraint for bounded out-degree. They also reinterpret existing indices like HNSW and DiskANN as SVG specializations.", "result": "SVG provides formal navigability guarantees in metric and non-metric spaces. SVG-L0 offers a principled way to bound out-degree and self-tuning properties, avoiding heuristics.", "conclusion": "The work demonstrates the potential of machine learning to enhance graph indices for vector search, offering theoretical and practical improvements over traditional methods."}}
{"id": "2503.02502", "pdf": "https://arxiv.org/pdf/2503.02502", "abs": "https://arxiv.org/abs/2503.02502", "authors": ["Jianghao Chen", "Junhong Wu", "Yangyifan Xu", "Jiajun Zhang"], "title": "LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs", "categories": ["cs.CL"], "comment": "ACL 2025, our code is available at https://github.com/ZNLP/LADM", "summary": "Long-context modeling has drawn more and more attention in the area of Large\nLanguage Models (LLMs). Continual training with long-context data becomes the\nde-facto method to equip LLMs with the ability to process long inputs. However,\nit still remains an open challenge to measure the quality of long-context\ntraining data. To address this issue, we propose a Long-context data selection\nframework with Attention-based Dependency Measurement (LADM), which can\nefficiently identify high-quality long-context data from a large-scale,\nmulti-domain pre-training corpus. LADM leverages the retrieval capabilities of\nthe attention mechanism to capture contextual dependencies, ensuring a\ncomprehensive quality measurement of long-context data. Experimental results\nshow that our LADM framework significantly boosts the performance of LLMs on\nmultiple long-context tasks with only 1B tokens for continual training.", "AI": {"tldr": "Proposes LADM, a framework for selecting high-quality long-context data to improve LLM performance efficiently.", "motivation": "Addressing the challenge of measuring long-context data quality for LLM training.", "method": "Uses attention-based dependency measurement (LADM) to identify high-quality data from a multi-domain corpus.", "result": "LADM improves LLM performance on long-context tasks with minimal training data (1B tokens).", "conclusion": "LADM effectively enhances LLM capabilities for long-context processing."}}
{"id": "2411.01969", "pdf": "https://arxiv.org/pdf/2411.01969", "abs": "https://arxiv.org/abs/2411.01969", "authors": ["Zhengyang Yu", "Arthur Aubret", "Marcel C. Raabe", "Jane Yang", "Chen Yu", "Jochen Triesch"], "title": "Toddlers' Active Gaze Behavior Supports Self-Supervised Object Learning", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 16 figures", "summary": "Toddlers learn to recognize objects from different viewpoints with almost no\nsupervision. During this learning, they execute frequent eye and head movements\nthat shape their visual experience. It is presently unclear if and how these\nbehaviors contribute to toddlers' emerging object recognition abilities. To\nanswer this question, we here combine head-mounted eye tracking during dyadic\nplay with unsupervised machine learning. We approximate toddlers' central\nvisual field experience by cropping image regions from a head-mounted camera\ncentered on the current gaze location estimated via eye tracking. This visual\nstream feeds an unsupervised computational model of toddlers' learning, which\nconstructs visual representations that slowly change over time. Our experiments\ndemonstrate that toddlers' gaze strategy supports the learning of invariant\nobject representations. Our analysis also shows that the limited size of the\ncentral visual field where acuity is high is crucial for this. Overall, our\nwork reveals how toddlers' gaze behavior may support their development of\nview-invariant object recognition.", "AI": {"tldr": "Toddlers' gaze behavior aids unsupervised learning of view-invariant object recognition.", "motivation": "Understand how toddlers' eye and head movements contribute to their object recognition abilities.", "method": "Combines head-mounted eye tracking with unsupervised machine learning to analyze toddlers' visual experience.", "result": "Toddlers' gaze strategy helps learn invariant object representations, with central visual field size being crucial.", "conclusion": "Toddlers' gaze behavior supports development of view-invariant object recognition."}}
{"id": "2406.11898", "pdf": "https://arxiv.org/pdf/2406.11898", "abs": "https://arxiv.org/abs/2406.11898", "authors": ["Harry Shomer", "Jay Revolinsky", "Jiliang Tang"], "title": "Towards Better Benchmark Datasets for Inductive Knowledge Graph Completion", "categories": ["cs.AI", "cs.LG"], "comment": "KDD'25 Datasets & Benchmark Track", "summary": "Knowledge Graph Completion (KGC) attempts to predict missing facts in a\nKnowledge Graph (KG). Recently, there's been an increased focus on designing\nKGC methods that can excel in the inductive setting, where a portion or all of\nthe entities and relations seen in inference are unobserved during training.\nNumerous benchmark datasets have been proposed for inductive KGC, all of which\nare subsets of existing KGs used for transductive KGC. However, we find that\nthe current procedure for constructing inductive KGC datasets inadvertently\ncreates a shortcut that can be exploited even while disregarding the relational\ninformation. Specifically, we observe that the Personalized PageRank (PPR)\nscore can achieve strong or near SOTA performance on most datasets. In this\npaper, we study the root cause of this problem. Using these insights, we\npropose an alternative strategy for constructing inductive KGC datasets that\nhelps mitigate the PPR shortcut. We then benchmark multiple popular methods\nusing the newly constructed datasets and analyze their performance. The new\nbenchmark datasets help promote a better understanding of the capabilities and\nchallenges of inductive KGC by removing any shortcuts that obfuscate\nperformance. The code and dataset and can be found at\nhttps://github.com/HarryShomer/Better-Inductive-KGC.", "AI": {"tldr": "The paper identifies a shortcut in current inductive KGC datasets (exploitable via PPR scores) and proposes a new dataset construction method to mitigate this issue, improving benchmark reliability.", "motivation": "Current inductive KGC datasets inadvertently allow shortcuts (e.g., PPR scores) that bypass relational learning, undermining evaluation of true model capabilities.", "method": "Analyzes the PPR shortcut issue, proposes a revised dataset construction strategy, and benchmarks popular KGC methods on the new datasets.", "result": "PPR scores perform near SOTA on existing datasets; the new method mitigates this, revealing true model performance.", "conclusion": "The revised dataset construction removes shortcuts, enabling a clearer evaluation of inductive KGC methods."}}
{"id": "2506.20607", "pdf": "https://arxiv.org/pdf/2506.20607", "abs": "https://arxiv.org/abs/2506.20607", "authors": ["Jasen Lai", "Senwei Liang", "Chunmei Wang"], "title": "H-FEX: A Symbolic Learning Method for Hamiltonian Systems", "categories": ["cs.LG"], "comment": "16 pages, 7 figures", "summary": "Hamiltonian systems describe a broad class of dynamical systems governed by\nHamiltonian functions, which encode the total energy and dictate the evolution\nof the system. Data-driven approaches, such as symbolic regression and neural\nnetwork-based methods, provide a means to learn the governing equations of\ndynamical systems directly from observational data of Hamiltonian systems.\nHowever, these methods often struggle to accurately capture complex Hamiltonian\nfunctions while preserving energy conservation. To overcome this limitation, we\npropose the Finite Expression Method for learning Hamiltonian Systems (H-FEX),\na symbolic learning method that introduces novel interaction nodes designed to\ncapture intricate interaction terms effectively. Our experiments, including\nthose on highly stiff dynamical systems, demonstrate that H-FEX can recover\nHamiltonian functions of complex systems that accurately capture system\ndynamics and preserve energy over long time horizons. These findings highlight\nthe potential of H-FEX as a powerful framework for discovering closed-form\nexpressions of complex dynamical systems.", "AI": {"tldr": "H-FEX, a symbolic learning method, accurately learns complex Hamiltonian functions while preserving energy conservation, outperforming traditional data-driven approaches.", "motivation": "Existing data-driven methods struggle to accurately capture complex Hamiltonian functions and preserve energy conservation.", "method": "Proposes H-FEX, a symbolic learning method with novel interaction nodes to effectively capture intricate interaction terms.", "result": "H-FEX successfully recovers Hamiltonian functions for complex systems, preserving energy over long time horizons.", "conclusion": "H-FEX is a promising framework for discovering closed-form expressions of complex dynamical systems."}}
{"id": "2503.13305", "pdf": "https://arxiv.org/pdf/2503.13305", "abs": "https://arxiv.org/abs/2503.13305", "authors": ["Chi Han", "Heng Ji"], "title": "Computation Mechanism Behind LLM Position Generalization", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main Long Paper", "summary": "Most written natural languages are composed of sequences of words and\nsentences. Similar to humans, large language models (LLMs) exhibit flexibility\nin handling textual positions - a phenomenon we term position generalization.\nThey can understand texts with position perturbations and generalize to longer\ntexts than those encountered during training with the latest techniques. These\nphenomena suggest that LLMs handle positions tolerantly, but how LLMs\ncomputationally process positional relevance remains largely unexplored. This\nwork connects the linguistic phenomenon with LLMs' computational mechanisms. We\nshow how LLMs enforce certain computational mechanisms for the aforementioned\ntolerance in position perturbations. Despite the complex design of the\nself-attention mechanism, this work reveals that LLMs learn a counterintuitive\ndisentanglement of attention logits. Their values show a 0.959 linear\ncorrelation with an approximation of the arithmetic sum of positional relevance\nand semantic importance. Furthermore, we identify a prevalent pattern in\nintermediate features, which we prove theoretically enables this effect. The\npattern, which is different from how randomly initialized parameters would\nbehave, suggests that it is a learned behavior rather than a natural result of\nthe model architecture. Based on these findings, we provide computational\nexplanations and criteria for LLMs' position flexibilities. This work takes a\npioneering step in linking position generalization with modern LLMs' internal\nmechanisms.", "AI": {"tldr": "The paper explores how large language models (LLMs) generalize positional information in text, revealing computational mechanisms behind their flexibility and disentanglement of attention logits.", "motivation": "To understand how LLMs computationally process positional relevance and generalize to perturbed or longer texts, despite lacking explicit exploration of these mechanisms.", "method": "Analyzes LLMs' self-attention mechanisms, identifying patterns in attention logits and intermediate features, and compares them to randomly initialized parameters.", "result": "LLMs exhibit a 0.959 linear correlation between attention logits and an arithmetic sum of positional relevance and semantic importance, indicating learned behavior.", "conclusion": "The study links position generalization in LLMs to their internal computational mechanisms, providing foundational insights into their flexibility."}}
{"id": "2411.10504", "pdf": "https://arxiv.org/pdf/2411.10504", "abs": "https://arxiv.org/abs/2411.10504", "authors": ["Kang Chen", "Jiyuan Zhang", "Zecheng Hao", "Yajing Zheng", "Tiejun Huang", "Zhaofei Yu"], "title": "USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction and Gaussian Splatting", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Spike cameras, as an innovative neuromorphic camera that captures scenes with\nthe 0-1 bit stream at 40 kHz, are increasingly employed for the 3D\nreconstruction task via Neural Radiance Fields (NeRF) or 3D Gaussian Splatting\n(3DGS). Previous spike-based 3D reconstruction approaches often employ a\ncasecased pipeline: starting with high-quality image reconstruction from spike\nstreams based on established spike-to-image reconstruction algorithms, then\nprogressing to camera pose estimation and 3D reconstruction. However, this\ncascaded approach suffers from substantial cumulative errors, where quality\nlimitations of initial image reconstructions negatively impact pose estimation,\nultimately degrading the fidelity of the 3D reconstruction. To address these\nissues, we propose a synergistic optimization framework, \\textbf{USP-Gaussian},\nthat unifies spike-based image reconstruction, pose correction, and Gaussian\nsplatting into an end-to-end framework. Leveraging the multi-view consistency\nafforded by 3DGS and the motion capture capability of the spike camera, our\nframework enables a joint iterative optimization that seamlessly integrates\ninformation between the spike-to-image network and 3DGS. Experiments on\nsynthetic datasets with accurate poses demonstrate that our method surpasses\nprevious approaches by effectively eliminating cascading errors. Moreover, we\nintegrate pose optimization to achieve robust 3D reconstruction in real-world\nscenarios with inaccurate initial poses, outperforming alternative methods by\neffectively reducing noise and preserving fine texture details. Our code, data\nand trained models will be available at\nhttps://github.com/chenkang455/USP-Gaussian.", "AI": {"tldr": "The paper introduces USP-Gaussian, an end-to-end framework unifying spike-based image reconstruction, pose correction, and 3D Gaussian Splatting to address cumulative errors in cascaded spike-based 3D reconstruction.", "motivation": "To overcome the limitations of cascaded pipelines in spike-based 3D reconstruction, which suffer from cumulative errors degrading fidelity.", "method": "Proposes a synergistic optimization framework (USP-Gaussian) integrating spike-to-image reconstruction, pose correction, and 3D Gaussian Splatting, leveraging multi-view consistency and spike camera motion capture.", "result": "Outperforms previous methods on synthetic datasets by eliminating cascading errors and achieves robust 3D reconstruction in real-world scenarios with inaccurate poses.", "conclusion": "USP-Gaussian effectively reduces noise, preserves fine details, and enhances 3D reconstruction fidelity by unifying key steps into an end-to-end framework."}}
{"id": "2502.04030", "pdf": "https://arxiv.org/pdf/2502.04030", "abs": "https://arxiv.org/abs/2502.04030", "authors": ["Guinan Su", "Jonas Geiping"], "title": "Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated Model Merging", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reasoning capabilities represent a critical frontier for large language\nmodels (LLMs), but developing them requires extensive proprietary datasets and\ncomputational resources. One way to efficiently supplement capabilities with is\nby model merging, which offers a promising alternative by combining multiple\nmodels without retraining. However, current merging approaches rely on\nmanually-designed strategies for merging hyperparameters, limiting the\nexploration of potential model combinations and requiring significant human\neffort. We propose an Automated Model Merging Framework that enables\nfine-grained exploration of merging strategies while reducing costs through\nmulti-fidelity approximations. We support both single and multi-objective\noptimization and introduce two novel search spaces: layerwise fusion (LFS) and\ndepth-wise integration (DIS). Evaluating across a number of benchmarks, we find\nthat the search autonomously finds 1) Merges that further boost\nsingle-objective performance, even on tasks the model has already been\nfinetuned on, and 2) Merges that optimize multi-objective frontiers across\ntasks. Effective merges are found with limited compute, e.g. within less than\n500 search steps.", "AI": {"tldr": "An Automated Model Merging Framework is proposed to enhance reasoning in LLMs by efficiently exploring merging strategies without retraining, reducing costs and human effort.", "motivation": "Current model merging methods rely on manual hyperparameter tuning, limiting exploration and requiring significant resources.", "method": "The framework uses multi-fidelity approximations for fine-grained merging, supporting single and multi-objective optimization with novel search spaces (LFS and DIS).", "result": "Autonomous searches find merges that boost performance on single and multi-objective tasks, achieving results in under 500 steps.", "conclusion": "The framework enables cost-effective, automated model merging, improving LLM reasoning capabilities."}}
{"id": "2506.20623", "pdf": "https://arxiv.org/pdf/2506.20623", "abs": "https://arxiv.org/abs/2506.20623", "authors": ["Fariba Jangjoo", "Matteo Marsili", "Yasser Roudi"], "title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning", "categories": ["cs.LG", "cond-mat.dis-nn", "physics.data-an", "stat.ML"], "comment": "13 pages, 2 figures", "summary": "Closed-loop learning is the process of repeatedly estimating a model from\ndata generated from the model itself. It is receiving great attention due to\nthe possibility that large neural network models may, in the future, be\nprimarily trained with data generated by artificial neural networks themselves.\nWe study this process for models that belong to exponential families, deriving\nequations of motions that govern the dynamics of the parameters. We show that\nmaximum likelihood estimation of the parameters endows sufficient statistics\nwith the martingale property and that as a result the process converges to\nabsorbing states that amplify initial biases present in the data. However, we\nshow that this outcome may be prevented by polluting the data with an\ninfinitesimal fraction of data points generated from a fixed model, by relying\non maximum a posteriori estimation or by introducing regularisation.\nFurthermore, we show that the asymptotic behavior of the dynamics is not\nreparametrisation invariant.", "AI": {"tldr": "Closed-loop learning in exponential family models leads to biased absorbing states, but bias can be mitigated by data pollution, MAP estimation, or regularization.", "motivation": "Understanding the dynamics of closed-loop learning, where models train on their own generated data, is crucial for future neural network training.", "method": "Derived equations of motion for parameters in exponential family models, analyzed maximum likelihood estimation, and explored mitigation strategies like data pollution and regularization.", "result": "Closed-loop learning converges to biased absorbing states, but bias can be prevented with small external data, MAP estimation, or regularization.", "conclusion": "Closed-loop learning amplifies initial biases, but simple interventions can mitigate this effect, though dynamics are not reparametrization invariant."}}
{"id": "2503.16789", "pdf": "https://arxiv.org/pdf/2503.16789", "abs": "https://arxiv.org/abs/2503.16789", "authors": ["Rupak Sarkar", "Bahareh Sarrafzadeh", "Nirupama Chandrasekaran", "Nagu Rangan", "Philip Resnik", "Longqi Yang", "Sujay Kumar Jauhar"], "title": "Conversational User-AI Intervention: A Study on Prompt Rewriting for Improved LLM Response Generation", "categories": ["cs.CL"], "comment": "8 pages, ACL style", "summary": "Human-LLM conversations are increasingly becoming more pervasive in peoples'\nprofessional and personal lives, yet many users still struggle to elicit\nhelpful responses from LLM Chatbots. One of the reasons for this issue is\nusers' lack of understanding in crafting effective prompts that accurately\nconvey their information needs. Meanwhile, the existence of real-world\nconversational datasets on the one hand, and the text understanding faculties\nof LLMs on the other, present a unique opportunity to study this problem, and\nits potential solutions at scale. Thus, in this paper we present the first\nLLM-centric study of real human-AI chatbot conversations, focused on\ninvestigating aspects in which user queries fall short of expressing\ninformation needs, and the potential of using LLMs to rewrite suboptimal user\nprompts. Our findings demonstrate that rephrasing ineffective prompts can\nelicit better responses from a conversational system, while preserving the\nuser's original intent. Notably, the performance of rewrites improves in longer\nconversations, where contextual inferences about user needs can be made more\naccurately. Additionally, we observe that LLMs often need to -- and inherently\ndo -- make \\emph{plausible} assumptions about a user's intentions and goals\nwhen interpreting prompts. Our findings largely hold true across conversational\ndomains, user intents, and LLMs of varying sizes and families, indicating the\npromise of using prompt rewriting as a solution for better human-AI\ninteractions.", "AI": {"tldr": "The paper studies how rewriting suboptimal user prompts with LLMs can improve chatbot responses, showing effectiveness across domains and LLM types.", "motivation": "Users often struggle to craft effective prompts for LLM chatbots, leading to unhelpful responses. Real-world conversational datasets and LLMs' text understanding capabilities offer a way to address this issue.", "method": "The study analyzes real human-AI chatbot conversations, identifies shortcomings in user queries, and explores LLM-based prompt rewriting to improve responses.", "result": "Rewriting prompts enhances response quality while preserving user intent, especially in longer conversations where context aids inference. LLMs make plausible assumptions about user goals.", "conclusion": "Prompt rewriting is a promising solution for better human-AI interactions, applicable across various domains and LLM models."}}
{"id": "2412.01402", "pdf": "https://arxiv.org/pdf/2412.01402", "abs": "https://arxiv.org/abs/2412.01402", "authors": ["Zhuoxiao Li", "Shanliang Yao", "Taoyu Wu", "Yong Yue", "Wufan Zhao", "Rongjun Qin", "Angel F. Garcia-Fernandez", "Andrew Levers", "Xiaohui Zhu"], "title": "ULSR-GS: Ultra Large-scale Surface Reconstruction Gaussian Splatting with Multi-View Geometric Consistency", "categories": ["cs.CV"], "comment": "Project page: https://ulsrgs.github.io", "summary": "While Gaussian Splatting (GS) demonstrates efficient and high-quality scene\nrendering and small area surface extraction ability, it falls short in handling\nlarge-scale aerial image surface extraction tasks. To overcome this, we present\nULSR-GS, a framework dedicated to high-fidelity surface extraction in\nultra-large-scale scenes, addressing the limitations of existing GS-based mesh\nextraction methods. Specifically, we propose a point-to-photo partitioning\napproach combined with a multi-view optimal view matching principle to select\nthe best training images for each sub-region. Additionally, during training,\nULSR-GS employs a densification strategy based on multi-view geometric\nconsistency to enhance surface extraction details. Experimental results\ndemonstrate that ULSR-GS outperforms other state-of-the-art GS-based works on\nlarge-scale aerial photogrammetry benchmark datasets, significantly improving\nsurface extraction accuracy in complex urban environments. Project page:\nhttps://ulsrgs.github.io.", "AI": {"tldr": "ULSR-GS improves large-scale aerial surface extraction by combining point-to-photo partitioning and multi-view geometric consistency, outperforming existing GS-based methods.", "motivation": "Gaussian Splatting (GS) struggles with large-scale aerial image surface extraction, prompting the need for a more robust framework.", "method": "ULSR-GS uses point-to-photo partitioning and multi-view optimal view matching, along with densification based on geometric consistency.", "result": "ULSR-GS achieves higher accuracy in surface extraction for large-scale aerial scenes compared to other GS-based methods.", "conclusion": "ULSR-GS effectively addresses GS limitations in large-scale tasks, offering improved performance in complex urban environments."}}
{"id": "2505.07089", "pdf": "https://arxiv.org/pdf/2505.07089", "abs": "https://arxiv.org/abs/2505.07089", "authors": ["Hanzheng Dai", "Yuanliang Li", "Jun Yan", "Zhibo Zhang"], "title": "RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Automated penetration testing (AutoPT) powered by large language models\n(LLMs) has gained attention for its ability to automate ethical hacking\nprocesses and identify vulnerabilities in target systems by leveraging the\ninherent knowledge of LLMs. However, existing LLM-based AutoPT frameworks often\nunderperform compared to human experts in challenging tasks for several\nreasons: the imbalanced knowledge used in LLM training, short-sightedness in\nthe planning process, and hallucinations during command generation. Moreover,\nthe trial-and-error nature of the PT process is constrained by existing\nframeworks lacking mechanisms to learn from previous failures, restricting\nadaptive improvement of PT strategies. To address these limitations, we propose\na knowledge-informed, self-reflective PT framework powered by LLMs, called\nRefPentester. This AutoPT framework is designed to assist human operators in\nidentifying the current stage of the PT process, selecting appropriate tactics\nand techniques for each stage, choosing suggested actions, providing\nstep-by-step operational guidance, and reflecting on and learning from previous\nfailed operations. We also modeled the PT process as a seven-state Stage\nMachine to integrate the proposed framework effectively. The evaluation shows\nthat RefPentester can successfully reveal credentials on Hack The Box's Sau\nmachine, outperforming the baseline GPT-4o model by 16.7%. Across PT stages,\nRefPentester also demonstrates superior success rates on PT stage transitions.", "AI": {"tldr": "RefPentester, a knowledge-informed, self-reflective AutoPT framework, outperforms GPT-4o by 16.7% in identifying vulnerabilities by addressing LLM limitations like imbalanced knowledge and lack of learning from failures.", "motivation": "Existing LLM-based AutoPT frameworks underperform due to imbalanced knowledge, short-sighted planning, and hallucinations, lacking mechanisms to learn from failures.", "method": "Proposed RefPentester integrates a seven-state Stage Machine to guide PT stages, select tactics, and learn from failures.", "result": "RefPentester outperforms GPT-4o by 16.7% in revealing credentials on Hack The Box's Sau machine and shows superior success rates in PT stage transitions.", "conclusion": "RefPentester effectively addresses LLM limitations in AutoPT, enhancing performance and adaptability in ethical hacking."}}
{"id": "2506.20644", "pdf": "https://arxiv.org/pdf/2506.20644", "abs": "https://arxiv.org/abs/2506.20644", "authors": ["Hangyu Li", "Hongyue Wu", "Guodong Fan", "Zhen Zhang", "Shizhan Chen", "Zhiyong Feng"], "title": "Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices", "categories": ["cs.LG"], "comment": "Accepted by ICWS 2025", "summary": "As privacy protection gains increasing importance, more models are being\ntrained on edge devices and subsequently merged into the central server through\nFederated Learning (FL). However, current research overlooks the impact of\nnetwork topology, physical distance, and data heterogeneity on edge devices,\nleading to issues such as increased latency and degraded model performance. To\naddress these issues, we propose a new federated learning scheme on edge\ndevices that called Federated Learning with Encrypted Data Sharing(FedEDS).\nFedEDS uses the client model and the model's stochastic layer to train the data\nencryptor. The data encryptor generates encrypted data and shares it with other\nclients. The client uses the corresponding client's stochastic layer and\nencrypted data to train and adjust the local model. FedEDS uses the client's\nlocal private data and encrypted shared data from other clients to train the\nmodel. This approach accelerates the convergence speed of federated learning\ntraining and mitigates the negative impact of data heterogeneity, making it\nsuitable for application services deployed on edge devices requiring rapid\nconvergence. Experiments results show the efficacy of FedEDS in promoting model\nperformance.", "AI": {"tldr": "FedEDS is a federated learning scheme for edge devices that uses encrypted data sharing to improve convergence speed and model performance, addressing issues like latency and data heterogeneity.", "motivation": "Current federated learning research neglects network topology, physical distance, and data heterogeneity, causing latency and degraded performance.", "method": "FedEDS trains a data encryptor using client models and stochastic layers, shares encrypted data among clients, and uses both private and shared data for local model training.", "result": "FedEDS accelerates convergence and mitigates data heterogeneity, enhancing model performance in edge device applications.", "conclusion": "FedEDS is effective for federated learning on edge devices, improving training efficiency and performance."}}
{"id": "2503.21227", "pdf": "https://arxiv.org/pdf/2503.21227", "abs": "https://arxiv.org/abs/2503.21227", "authors": ["Hengyuan Zhao", "Ziqin Wang", "Qixin Sun", "Kaiyou Song", "Yilin Li", "Xiaolin Hu", "Qingpei Guo", "Si Liu"], "title": "LLaVA-CMoE: Towards Continual Mixture of Experts for Large Vision-Language Models", "categories": ["cs.CL"], "comment": "Preprint", "summary": "Mixture of Experts (MoE) architectures have recently advanced the scalability\nand adaptability of large language models (LLMs) for continual multimodal\nlearning. However, efficiently extending these models to accommodate sequential\ntasks remains challenging. As new tasks arrive, naive model expansion leads to\nrapid parameter growth, while modifying shared routing components often causes\ncatastrophic forgetting, undermining previously learned knowledge. To address\nthese issues, we propose LLaVA-CMoE, a continual learning framework for LLMs\nthat requires no replay data of previous tasks and ensures both parameter\nefficiency and robust knowledge retention. Our approach introduces a\nProbe-Guided Knowledge Extension mechanism, which uses probe experts to\ndynamically determine when and where new experts should be added, enabling\nadaptive and minimal parameter expansion tailored to task complexity.\nFurthermore, we present a Probabilistic Task Locator that assigns each task a\ndedicated, lightweight router. To handle the practical issue that task labels\nare unknown during inference, we leverage a VAE-based reconstruction strategy\nto identify the most suitable router by matching input distributions, allowing\nautomatic and accurate expert allocation. This design mitigates routing\nconflicts and catastrophic forgetting, enabling robust continual learning\nwithout explicit task labels. Extensive experiments on the CoIN benchmark,\ncovering eight diverse VQA tasks, demonstrate that LLaVA-CMoE delivers strong\ncontinual learning performance with a compact model size, significantly\nreducing forgetting and parameter overhead compared to prior methods. These\nresults showcase the effectiveness and scalability of our approach for\nparameter-efficient continual learning in large language models. Our code will\nbe open-sourced soon.", "AI": {"tldr": "LLaVA-CMoE is a continual learning framework for large language models (LLMs) that avoids replay data, ensures parameter efficiency, and retains knowledge via Probe-Guided Knowledge Extension and Probabilistic Task Locator.", "motivation": "Efficiently extending Mixture of Experts (MoE) architectures for sequential tasks without catastrophic forgetting or excessive parameter growth.", "method": "Introduces Probe-Guided Knowledge Extension for adaptive parameter expansion and Probabilistic Task Locator with VAE-based reconstruction for expert allocation.", "result": "Achieves strong continual learning performance on the CoIN benchmark with reduced forgetting and parameter overhead.", "conclusion": "LLaVA-CMoE is effective and scalable for parameter-efficient continual learning in LLMs."}}
{"id": "2412.06413", "pdf": "https://arxiv.org/pdf/2412.06413", "abs": "https://arxiv.org/abs/2412.06413", "authors": ["Yu Zhong", "Rui Zhang", "Zihao Zhang", "Shuo Wang", "Chuan Fang", "Xishan Zhang", "Jiaming Guo", "Shaohui Peng", "Di Huang", "Yanyang Yan", "Xing Hu", "Qi Guo"], "title": "World-Consistent Data Generation for Vision-and-Language Navigation", "categories": ["cs.CV"], "comment": null, "summary": "Vision-and-Language Navigation (VLN) is a challenging task that requires an\nagent to navigate through photorealistic environments following\nnatural-language instructions. One main obstacle existing in VLN is data\nscarcity, leading to poor generalization performance over unseen environments.\nThough data argumentation is a promising way for scaling up the dataset, how to\ngenerate VLN data both diverse and world-consistent remains problematic. To\ncope with this issue, we propose the world-consistent data generation (WCGEN),\nan efficacious data-augmentation framework satisfying both diversity and\nworld-consistency, aimed at enhancing the generalization of agents to novel\nenvironments. Roughly, our framework consists of two stages, the trajectory\nstage which leverages a point-cloud based technique to ensure spatial coherency\namong viewpoints, and the viewpoint stage which adopts a novel angle synthesis\nmethod to guarantee spatial and wraparound consistency within the entire\nobservation. By accurately predicting viewpoint changes with 3D knowledge, our\napproach maintains the world-consistency during the generation procedure.\nExperiments on a wide range of datasets verify the effectiveness of our method,\ndemonstrating that our data augmentation strategy enables agents to achieve new\nstate-of-the-art results on all navigation tasks, and is capable of enhancing\nthe VLN agents' generalization ability to unseen environments.", "AI": {"tldr": "The paper introduces WCGEN, a data-augmentation framework for Vision-and-Language Navigation (VLN) to address data scarcity and improve generalization to unseen environments by ensuring diversity and world-consistency.", "motivation": "Data scarcity in VLN leads to poor generalization. Existing data augmentation lacks diversity and world-consistency.", "method": "WCGEN uses a two-stage approach: trajectory stage (point-cloud based for spatial coherency) and viewpoint stage (angle synthesis for spatial and wraparound consistency).", "result": "Experiments show WCGEN achieves state-of-the-art results on navigation tasks and enhances generalization to unseen environments.", "conclusion": "WCGEN effectively addresses VLN data scarcity by generating diverse, world-consistent data, improving agent performance."}}
{"id": "2505.18746", "pdf": "https://arxiv.org/pdf/2505.18746", "abs": "https://arxiv.org/abs/2505.18746", "authors": ["Peijie Yu", "Yifan Yang", "Jinjian Li", "Zelong Zhang", "Haorui Wang", "Xiao Feng", "Feng Zhang"], "title": "$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking", "categories": ["cs.AI"], "comment": null, "summary": "Agents based on large language models leverage tools to modify environments,\nrevolutionizing how AI interacts with the physical world. Unlike traditional\nNLP tasks that rely solely on historical dialogue for responses, these agents\nmust consider more complex factors, such as inter-tool relationships,\nenvironmental feedback and previous decisions, when making choices. Current\nresearch typically evaluates agents via multi-turn dialogues. However, it\noverlooks the influence of these critical factors on agent behavior. To bridge\nthis gap, we present an open-source and high-quality benchmark $C^3$-Bench.\nThis benchmark integrates attack concepts and applies univariate analysis to\npinpoint key elements affecting agent robustness. In concrete, we design three\nchallenges: navigate complex tool relationships, handle critical hidden\ninformation and manage dynamic decision paths. Complementing these challenges,\nwe introduce fine-grained metrics, innovative data collection algorithms and\nreproducible evaluation methods. Extensive experiments are conducted on 49\nmainstream agents, encompassing general fast-thinking, slow-thinking and\ndomain-specific models. We observe that agents have significant shortcomings in\nhandling tool dependencies, long context information dependencies and frequent\npolicy-type switching. In essence, $C^3$-Bench aims to expose model\nvulnerabilities through these challenges and drive research into the\ninterpretability of agent performance. The benchmark is publicly available at\nhttps://github.com/yupeijei1997/C3-Bench.", "AI": {"tldr": "The paper introduces $C^3$-Bench, an open-source benchmark to evaluate AI agents' robustness by addressing tool dependencies, hidden information, and dynamic decisions, revealing vulnerabilities in current models.", "motivation": "Current evaluations of AI agents ignore critical factors like tool relationships and environmental feedback, limiting understanding of agent behavior.", "method": "The benchmark includes three challenges (tool relationships, hidden information, dynamic decisions) with fine-grained metrics and reproducible methods, tested on 49 agents.", "result": "Agents struggle with tool dependencies, long context, and policy switching, exposing vulnerabilities.", "conclusion": "$C^3$-Bench aims to improve agent interpretability and robustness by highlighting model weaknesses."}}
{"id": "2506.20650", "pdf": "https://arxiv.org/pdf/2506.20650", "abs": "https://arxiv.org/abs/2506.20650", "authors": ["Anqi Mao", "Mehryar Mohri", "Yutao Zhong"], "title": "Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2025", "summary": "The problem of learning to defer with multiple experts consists of optimally\nassigning input instances to experts, balancing the trade-off between their\naccuracy and computational cost. This is a critical challenge in natural\nlanguage generation, but also in other fields such as image processing, and\nmedical diagnostics. Recent studies have proposed surrogate loss functions to\noptimize deferral, but challenges remain in ensuring their consistency\nproperties. This paper introduces novel surrogate loss functions and efficient\nalgorithms with strong theoretical learning guarantees. We address open\nquestions regarding realizable $H$-consistency, $H$-consistency bounds, and\nBayes-consistency for both single-stage (jointly learning predictor and\ndeferral function) and two-stage (learning only the deferral function with a\nfixed expert) learning scenarios. For single-stage deferral, we introduce a\nfamily of new realizable $H$-consistent surrogate losses and further prove\n$H$-consistency for a selected member. For two-stage deferral, we derive new\nsurrogate losses that achieve realizable $H$-consistency, $H$-consistency\nbounds, and Bayes-consistency for the two-expert scenario and, under natural\nassumptions, multiple-expert scenario. Additionally, we provide enhanced\ntheoretical guarantees under low-noise assumptions for both scenarios. Finally,\nwe report the results of experiments using our proposed surrogate losses,\ncomparing their performance against existing baselines.", "AI": {"tldr": "The paper introduces novel surrogate loss functions and algorithms for learning to defer with multiple experts, addressing consistency properties in single-stage and two-stage learning scenarios.", "motivation": "The challenge lies in optimally assigning input instances to experts while balancing accuracy and computational cost, particularly in fields like natural language generation, image processing, and medical diagnostics.", "method": "The paper proposes new surrogate loss functions and efficient algorithms, providing theoretical guarantees for realizable H-consistency, H-consistency bounds, and Bayes-consistency in single-stage and two-stage deferral learning.", "result": "The proposed methods achieve strong theoretical guarantees and outperform existing baselines in experiments.", "conclusion": "The paper advances the field by addressing key consistency challenges in deferral learning, offering practical solutions with robust theoretical foundations."}}
{"id": "2505.20767", "pdf": "https://arxiv.org/pdf/2505.20767", "abs": "https://arxiv.org/abs/2505.20767", "authors": ["Xiaqiang Tang", "Jian Li", "Keyu Hu", "Du Nan", "Xiaolong Li", "Xi Zhang", "Weigao Sun", "Sihong Xie"], "title": "CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025", "summary": "Faithfulness hallucinations are claims generated by a Large Language Model\n(LLM) not supported by contexts provided to the LLM. Lacking assessment\nstandards, existing benchmarks focus on \"factual statements\" that rephrase\nsource materials while overlooking \"cognitive statements\" that involve making\ninferences from the given context. Consequently, evaluating and detecting the\nhallucination of cognitive statements remains challenging. Inspired by how\nevidence is assessed in the legal domain, we design a rigorous framework to\nassess different levels of faithfulness of cognitive statements and introduce\nthe CogniBench dataset where we reveal insightful statistics. To keep pace with\nrapidly evolving LLMs, we further develop an automatic annotation pipeline that\nscales easily across different models. This results in a large-scale\nCogniBench-L dataset, which facilitates training accurate detectors for both\nfactual and cognitive hallucinations. We release our model and datasets at:\nhttps://github.com/FUTUREEEEEE/CogniBench", "AI": {"tldr": "The paper addresses the challenge of evaluating and detecting hallucinations in cognitive statements generated by LLMs, introducing a rigorous framework and datasets (CogniBench and CogniBench-L) for assessment and detection.", "motivation": "Existing benchmarks overlook cognitive statements, focusing only on factual ones, making it hard to assess hallucinations in inferences.", "method": "Inspired by legal evidence assessment, the authors design a framework to evaluate faithfulness levels and create datasets (CogniBench and CogniBench-L) with an automatic annotation pipeline.", "result": "The framework and datasets enable accurate detection of both factual and cognitive hallucinations, with insights from CogniBench statistics.", "conclusion": "The work provides scalable tools (datasets and models) for detecting hallucinations in LLMs, addressing a critical gap in current benchmarks."}}
{"id": "2501.07113", "pdf": "https://arxiv.org/pdf/2501.07113", "abs": "https://arxiv.org/abs/2501.07113", "authors": ["Zhuohang Yu", "Kai Wang", "Kun Huang", "Juyong Zhang"], "title": "Matching-Free Depth Recovery from Structured Light", "categories": ["cs.CV"], "comment": "13 pages, 10 figures", "summary": "We introduce a novel approach for depth estimation using images obtained from\nmonocular structured light systems. In contrast to many existing methods that\ndepend on image matching, our technique employs a density voxel grid to\nrepresent scene geometry. This grid is trained through self-supervised\ndifferentiable volume rendering. Our method leverages color fields derived from\nthe projected patterns in structured light systems during the rendering\nprocess, facilitating the isolated optimization of the geometry field. This\ninnovative approach leads to faster convergence and high-quality results.\nAdditionally, we integrate normalized device coordinates (NDC), a distortion\nloss, and a distinctive surface-based color loss to enhance geometric fidelity.\nExperimental results demonstrate that our method outperforms current\nmatching-based techniques in terms of geometric performance in few-shot\nscenarios, achieving an approximately 30% reduction in average estimated depth\nerrors for both synthetic scenes and real-world captured scenes. Moreover, our\napproach allows for rapid training, being approximately three times faster than\nprevious matching-free methods that utilize implicit representations.", "AI": {"tldr": "A novel depth estimation method using monocular structured light systems, employing a density voxel grid and self-supervised differentiable volume rendering for faster convergence and high-quality results.", "motivation": "Existing methods rely on image matching, which can be limiting. The proposed approach aims to improve geometric fidelity and training speed.", "method": "Uses a density voxel grid trained via self-supervised differentiable volume rendering, leveraging color fields from structured light patterns. Integrates NDC, distortion loss, and surface-based color loss.", "result": "Outperforms matching-based techniques, reducing depth errors by ~30% and training ~3x faster than implicit representation methods.", "conclusion": "The method offers superior geometric performance and efficiency, making it a promising alternative for depth estimation."}}
{"id": "2505.19550", "pdf": "https://arxiv.org/pdf/2505.19550", "abs": "https://arxiv.org/abs/2505.19550", "authors": ["Georgios Mappouras"], "title": "Turing Test 2.0: The General Intelligence Threshold", "categories": ["cs.AI"], "comment": null, "summary": "With the rise of artificial intelligence (A.I.) and large language models\nlike ChatGPT, a new race for achieving artificial general intelligence (A.G.I)\nhas started. While many speculate how and when A.I. will achieve A.G.I., there\nis no clear agreement on how A.G.I. can be detected in A.I. models, even when\npopular tools like the Turing test (and its modern variations) are used to\nmeasure their intelligence. In this work, we discuss why traditional methods\nlike the Turing test do not suffice for measuring or detecting A.G.I. and\nprovide a new, practical method that can be used to decide if a system\n(computer or any other) has reached or surpassed A.G.I. To achieve this, we\nmake two new contributions. First, we present a clear definition for general\nintelligence (G.I.) and set a G.I. Threshold (G.I.T.) that can be used to\ndistinguish between systems that achieve A.G.I. and systems that do not.\nSecond, we present a new framework on how to construct tests that can detect if\na system has achieved G.I. in a simple, comprehensive, and clear-cut fail/pass\nway. We call this novel framework the Turing test 2.0. We then demonstrate\nreal-life examples of applying tests that follow our Turing test 2.0 framework\non modern A.I. models.", "AI": {"tldr": "The paper critiques traditional A.G.I. detection methods like the Turing test and introduces a new framework, Turing test 2.0, with a clear G.I. definition and threshold for practical A.G.I. detection.", "motivation": "The lack of clear methods to detect A.G.I. in A.I. models, despite advancements, necessitates a new approach.", "method": "Proposes a G.I. Threshold (G.I.T.) and a new testing framework (Turing test 2.0) for fail/pass A.G.I. detection.", "result": "Demonstrates real-life applications of the Turing test 2.0 on modern A.I. models.", "conclusion": "The Turing test 2.0 offers a practical, clear-cut method to detect A.G.I., addressing limitations of traditional approaches."}}
{"id": "2506.20651", "pdf": "https://arxiv.org/pdf/2506.20651", "abs": "https://arxiv.org/abs/2506.20651", "authors": ["Fei Wang", "Baochun Li"], "title": "Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": null, "summary": "Recent work has shown that gradient updates in federated learning (FL) can\nunintentionally reveal sensitive information about a client's local data. This\nrisk becomes significantly greater when a malicious server manipulates the\nglobal model to provoke information-rich updates from clients. In this paper,\nwe adopt a defender's perspective to provide the first comprehensive analysis\nof malicious gradient leakage attacks and the model manipulation techniques\nthat enable them. Our investigation reveals a core trade-off: these attacks\ncannot be both highly effective in reconstructing private data and sufficiently\nstealthy to evade detection -- especially in realistic FL settings that\nincorporate common normalization techniques and federated averaging.\n  Building on this insight, we argue that malicious gradient leakage attacks,\nwhile theoretically concerning, are inherently limited in practice and often\ndetectable through basic monitoring. As a complementary contribution, we\npropose a simple, lightweight, and broadly applicable client-side detection\nmechanism that flags suspicious model updates before local training begins,\ndespite the fact that such detection may not be strictly necessary in realistic\nFL settings. This mechanism further underscores the feasibility of defending\nagainst these attacks with minimal overhead, offering a deployable safeguard\nfor privacy-conscious federated learning systems.", "AI": {"tldr": "The paper analyzes malicious gradient leakage attacks in federated learning, showing their practical limitations and proposing a lightweight client-side detection mechanism.", "motivation": "To address the risk of sensitive data leakage in federated learning due to malicious server manipulation, and to evaluate the practicality and detectability of such attacks.", "method": "Comprehensive analysis of gradient leakage attacks, including their effectiveness and stealthiness, and development of a client-side detection mechanism.", "result": "Malicious attacks are limited in practice and detectable; a proposed detection mechanism offers a feasible defense with minimal overhead.", "conclusion": "While theoretically concerning, gradient leakage attacks are practically limited and detectable, with lightweight defenses available."}}
{"id": "2506.04689", "pdf": "https://arxiv.org/pdf/2506.04689", "abs": "https://arxiv.org/abs/2506.04689", "authors": ["Thao Nguyen", "Yang Li", "Olga Golovneva", "Luke Zettlemoyer", "Sewoong Oh", "Ludwig Schmidt", "Xian Li"], "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Scaling laws predict that the performance of large language models improves\nwith increasing model size and data size. In practice, pre-training has been\nrelying on massive web crawls, using almost all data sources publicly available\non the internet so far. However, this pool of natural data does not grow at the\nsame rate as the compute supply. Furthermore, the availability of high-quality\ntexts is even more limited: data filtering pipelines often remove up to 99% of\nthe initial web scrapes to achieve state-of-the-art. To address the \"data wall\"\nof pre-training scaling, our work explores ways to transform and recycle data\ndiscarded in existing filtering processes. We propose REWIRE, REcycling the Web\nwith guIded REwrite, a method to enrich low-quality documents so that they\ncould become useful for training. This in turn allows us to increase the\nrepresentation of synthetic data in the final pre-training set. Experiments at\n1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw\ntexts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points\nimprovement respectively across 22 diverse tasks, compared to training on only\nfiltered web data. Training on the raw-synthetic data mix is also more\neffective than having access to 2x web data. Through further analysis, we\ndemonstrate that about 82% of the mixed in texts come from transforming\nlower-quality documents that would otherwise be discarded. REWIRE also\noutperforms related approaches of generating synthetic data, including\nWikipedia-style paraphrasing, question-answer synthesizing and knowledge\nextraction. These results suggest that recycling web texts holds the potential\nfor being a simple and effective approach for scaling pre-training data.", "AI": {"tldr": "REWIRE recycles low-quality web data by enriching it, improving model performance when mixed with high-quality data.", "motivation": "Address the 'data wall' in pre-training by recycling discarded low-quality web data.", "method": "Proposes REWIRE, a method to transform and enrich low-quality documents for training.", "result": "Mixing rewritten texts with high-quality data improves performance by 1.0-2.5 percentage points across tasks.", "conclusion": "Recycling web texts is a simple and effective way to scale pre-training data."}}
{"id": "2501.09552", "pdf": "https://arxiv.org/pdf/2501.09552", "abs": "https://arxiv.org/abs/2501.09552", "authors": ["Tuan Truong", "Ivo M. Baltruschat", "Mark Klemens", "Grit Werner", "Matthias Lenga"], "title": "Exploring AI-based System Design for Pixel-level Protected Health Information Detection in Medical Images", "categories": ["cs.CV"], "comment": "In progress", "summary": "De-identification of medical images is a critical step to ensure privacy\nduring data sharing in research and clinical settings. The initial step in this\nprocess involves detecting Protected Health Information (PHI), which can be\nfound in image metadata or imprinted within image pixels. Despite the\nimportance of such systems, there has been limited evaluation of existing\nAI-based solutions, creating barriers to the development of reliable and robust\ntools. In this study, we present an AI-based pipeline for PHI detection,\ncomprising three key modules: text detection, text extraction, and text\nanalysis. We benchmark three models - YOLOv11, EasyOCR, and GPT-4o - across\ndifferent setups corresponding to these modules, evaluating their performance\non two different datasets encompassing multiple imaging modalities and PHI\ncategories. Our findings indicate that the optimal setup involves utilizing\ndedicated vision and language models for each module, which achieves a\ncommendable balance in performance, latency, and cost associated with the usage\nof Large Language Models (LLMs). Additionally, we show that the application of\nLLMs not only involves identifying PHI content but also enhances OCR tasks and\nfacilitates an end-to-end PHI detection pipeline, showcasing promising outcomes\nthrough our analysis.", "AI": {"tldr": "An AI-based pipeline for detecting PHI in medical images, combining text detection, extraction, and analysis, achieves optimal performance by integrating vision and language models.", "motivation": "Limited evaluation of AI-based PHI detection tools hinders reliable development, necessitating a robust solution for privacy in medical data sharing.", "method": "A three-module pipeline (text detection, extraction, analysis) tested with YOLOv11, EasyOCR, and GPT-4o on diverse datasets.", "result": "Dedicated models for each module balance performance, latency, and cost, with LLMs improving OCR and enabling end-to-end PHI detection.", "conclusion": "The pipeline demonstrates effectiveness in PHI detection, leveraging specialized models and LLMs for enhanced performance and practicality."}}
{"id": "2506.02097", "pdf": "https://arxiv.org/pdf/2506.02097", "abs": "https://arxiv.org/abs/2506.02097", "authors": ["Priyaranjan Pattnayak", "Amit Agarwal", "Hansa Meghwani", "Hitesh Laxmichand Patel", "Srikant Panda"], "title": "Hybrid AI for Responsive Multi-Turn Online Conversations with Novel Dynamic Routing and Feedback Adaptation", "categories": ["cs.AI"], "comment": "Proceedings of the 4th International Workshop on Knowledge Augmented\n  Methods for Natural Language Processing in NAACL 2025, pages 215 to 229,\n  Albuquerque, New Mexico, USA. Association for Computational Linguistics", "summary": "Retrieval-Augmented Generation (RAG) systems and large language model\n(LLM)-powered chatbots have significantly advanced conversational AI by\ncombining generative capabilities with external knowledge retrieval. Despite\ntheir success, enterprise-scale deployments face critical challenges, including\ndiverse user queries, high latency, hallucinations, and difficulty integrating\nfrequently updated domain-specific knowledge. This paper introduces a novel\nhybrid framework that integrates RAG with intent-based canned responses,\nleveraging predefined high-confidence responses for efficiency while\ndynamically routing complex or ambiguous queries to the RAG pipeline. Our\nframework employs a dialogue context manager to ensure coherence in multi-turn\ninteractions and incorporates a feedback loop to refine intents, dynamically\nadjust confidence thresholds, and expand response coverage over time.\nExperimental results demonstrate that the proposed framework achieves a balance\nof high accuracy (95\\%) and low latency (180ms), outperforming RAG and\nintent-based systems across diverse query types, positioning it as a scalable\nand adaptive solution for enterprise conversational AI applications.", "AI": {"tldr": "A hybrid framework combining RAG with intent-based canned responses improves enterprise conversational AI by balancing accuracy (95%) and latency (180ms).", "motivation": "Address challenges in enterprise-scale deployments of RAG and LLM-powered chatbots, such as diverse queries, high latency, hallucinations, and domain-specific knowledge integration.", "method": "Integrates RAG with intent-based canned responses, uses a dialogue context manager for coherence, and includes a feedback loop for refinement.", "result": "Achieves high accuracy (95%) and low latency (180ms), outperforming standalone RAG and intent-based systems.", "conclusion": "The framework is scalable and adaptive, suitable for enterprise conversational AI applications."}}
{"id": "2506.18278", "pdf": "https://arxiv.org/pdf/2506.18278", "abs": "https://arxiv.org/abs/2506.18278", "authors": ["Yujie Liu", "Vincent Y. F. Tan", "Yunbei Xu"], "title": "Finite-Time Information-Theoretic Bounds in Queueing Control", "categories": ["math.OC", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "We establish the first finite-time information-theoretic lower bounds-and\nderive new policies that achieve them-for the total queue length in scheduling\nproblems over stochastic processing networks with both adversarial and\nstochastic arrivals. Prior analyses of MaxWeight guarantee only stability and\nasymptotic optimality in heavy traffic; we prove that, at finite horizons,\nMaxWeight can incur strictly larger backlog by problem-dependent factors which\nwe identify. Our main innovations are 1) a minimax framework that pinpoints the\nprecise problem parameters governing any policy's finite-time performance; 2)\nan information-theoretic lower bound on total queue length; 3) fundamental\nlimitation of MaxWeight that it is suboptimal in finite time; and 4) a new\nscheduling rule that minimizes the full Lyapunov drift-including its\nsecond-order term-thereby matching the lower bound under certain conditions, up\nto universal constants. These findings reveal a fundamental limitation on\n\"drift-only\" methods and points the way toward principled, non-asymptotic\noptimality in queueing control.", "AI": {"tldr": "The paper establishes finite-time lower bounds for queue length in scheduling problems, identifies limitations of MaxWeight, and introduces a new policy matching these bounds.", "motivation": "Prior work only guarantees stability and asymptotic optimality; this paper addresses finite-time performance gaps in scheduling policies.", "method": "Uses a minimax framework, derives information-theoretic lower bounds, analyzes MaxWeight's suboptimality, and proposes a new scheduling rule optimizing Lyapunov drift.", "result": "Shows MaxWeight is suboptimal in finite time and introduces a policy matching lower bounds under certain conditions.", "conclusion": "Reveals limitations of drift-only methods and advances non-asymptotic optimality in queueing control."}}
{"id": "2506.06406", "pdf": "https://arxiv.org/pdf/2506.06406", "abs": "https://arxiv.org/abs/2506.06406", "authors": ["Guoyang Xia", "Yifeng Ding", "Fengfa Li", "Lei Ren", "Wei Chen", "Fangxiang Feng", "Xiaojie Wang"], "title": "SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Mixture of Experts (MoE) architectures have become a key approach for scaling\nlarge language models, with growing interest in extending them to multimodal\ntasks. Existing methods to build multimodal MoE models either incur high\ntraining costs or suffer from degraded language capabilities when adapting\npretrained models. To address this, we propose Soft ModalityAware Routing\n(SMAR), a novel regularization technique that uses Kullback Leibler divergence\nto control routing probability distributions across modalities, encouraging\nexpert specialization without modifying model architecture or heavily relying\non textual data. Experiments on visual instruction tuning show that SMAR\npreserves language ability at 86.6% retention with only 2.5% pure text,\noutperforming baselines while maintaining strong multimodal performance. Our\napproach offers a practical and efficient solution to balance modality\ndifferentiation and language capabilities in multimodal MoE models.", "AI": {"tldr": "SMAR, a novel regularization technique, balances modality differentiation and language capabilities in multimodal MoE models, outperforming baselines.", "motivation": "Addressing high training costs and degraded language capabilities in existing multimodal MoE models.", "method": "Uses Kullback-Leibler divergence for regularization to control routing probabilities across modalities without altering architecture.", "result": "Achieves 86.6% language ability retention with minimal text data (2.5%), outperforming baselines.", "conclusion": "SMAR offers an efficient solution for multimodal MoE models, balancing modality specialization and language preservation."}}
{"id": "2501.17726", "pdf": "https://arxiv.org/pdf/2501.17726", "abs": "https://arxiv.org/abs/2501.17726", "authors": ["Sayeh Gholipour Picha", "Dawood Al Chanti", "Alice Caplier"], "title": "VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "As artificial intelligence (AI) becomes increasingly central to healthcare,\nthe demand for explainable and trustworthy models is paramount. Current report\ngeneration systems for chest X-rays (CXR) often lack mechanisms for validating\noutputs without expert oversight, raising concerns about reliability and\ninterpretability. To address these challenges, we propose a novel multimodal\nframework designed to enhance the semantic alignment and localization accuracy\nof AI-generated medical reports. Our framework integrates two key modules: a\nPhrase Grounding Model, which identifies and localizes pathologies in CXR\nimages based on textual prompts, and a Text-to-Image Diffusion Module, which\ngenerates synthetic CXR images from prompts while preserving anatomical\nfidelity. By comparing features between the original and generated images, we\nintroduce a dual-scoring system: one score quantifies localization accuracy,\nwhile the other evaluates semantic consistency. This approach significantly\noutperforms existing methods, achieving state-of-the-art results in pathology\nlocalization and text-to-image alignment. The integration of phrase grounding\nwith diffusion models, coupled with the dual-scoring evaluation system,\nprovides a robust mechanism for validating report quality, paving the way for\nmore trustworthy and transparent AI in medical imaging.", "AI": {"tldr": "A novel multimodal framework enhances AI-generated medical reports for chest X-rays by improving semantic alignment and localization accuracy, using phrase grounding and text-to-image diffusion modules, validated by a dual-scoring system.", "motivation": "Address the lack of reliability and interpretability in current AI-generated medical reports for chest X-rays, which often require expert oversight.", "method": "Integrates a Phrase Grounding Model for pathology localization and a Text-to-Image Diffusion Module for synthetic image generation, with a dual-scoring system for validation.", "result": "Outperforms existing methods, achieving state-of-the-art results in pathology localization and text-to-image alignment.", "conclusion": "The framework provides a robust validation mechanism, advancing trustworthy and transparent AI in medical imaging."}}
{"id": "2506.02280", "pdf": "https://arxiv.org/pdf/2506.02280", "abs": "https://arxiv.org/abs/2506.02280", "authors": ["Kedir Yassin Hussen", "Walelign Tewabe Sewunetie", "Abinew Ali Ayele", "Sukairaj Hafiz Imam", "Shamsuddeen Hassan Muhammad", "Seid Muhie Yimam"], "title": "The State of Large Language Models for African Languages: Progress and Challenges", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are transforming Natural Language Processing\n(NLP), but their benefits are largely absent for Africa's 2,000 low-resource\nlanguages. This paper comparatively analyzes African language coverage across\nsix LLMs, eight Small Language Models (SLMs), and six Specialized SLMs (SSLMs).\nThe evaluation covers language coverage, training sets, technical limitations,\nscript problems, and language modelling roadmaps. The work identifies 42\nsupported African languages and 23 available public data sets, and it shows a\nbig gap where four languages (Amharic, Swahili, Afrikaans, and Malagasy) are\nalways treated while there is over 98\\% of unsupported African languages.\nMoreover, the review shows that just Latin, Arabic, and Ge'ez scripts are\nidentified while 20 active scripts are neglected. Some of the primary\nchallenges are lack of data, tokenization biases, computational costs being\nvery high, and evaluation issues. These issues demand language standardization,\ncorpus development by the community, and effective adaptation methods for\nAfrican languages.", "AI": {"tldr": "The paper highlights the limited support for African languages in LLMs, SLMs, and SSLMs, identifying gaps in coverage, scripts, and data, and proposes solutions like standardization and community corpus development.", "motivation": "To address the underrepresentation of Africa's 2,000 low-resource languages in NLP models, despite the transformative impact of LLMs.", "method": "Comparative analysis of African language coverage across six LLMs, eight SLMs, and six SSLMs, evaluating language coverage, training sets, technical limitations, scripts, and roadmaps.", "result": "Identified 42 supported African languages and 23 public datasets, with four languages (Amharic, Swahili, Afrikaans, Malagasy) dominating while over 98% remain unsupported. Only Latin, Arabic, and Ge'ez scripts are recognized, neglecting 20 others.", "conclusion": "Challenges like data scarcity, tokenization biases, and high computational costs require solutions such as language standardization, community-driven corpus development, and effective adaptation methods for African languages."}}
{"id": "2506.19855", "pdf": "https://arxiv.org/pdf/2506.19855", "abs": "https://arxiv.org/abs/2506.19855", "authors": ["Ashish Masarkar", "Rakesh Gupta", "Naga Neehar Dingari", "Beena Rai"], "title": "Neural networks for the prediction of peel force for skin adhesive interface using FEM simulation", "categories": ["physics.med-ph", "cs.LG"], "comment": null, "summary": "Studying the peeling behaviour of adhesives on skin is vital for advancing\nbiomedical applications such as medical adhesives and transdermal patches.\nTraditional methods like experimental testing and finite element method (FEM),\nthough considered gold standards, are resource-intensive, computationally\nexpensive and time-consuming, particularly when analysing a wide material\nparameter space. In this study, we present a neural network-based approach to\npredict the minimum peel force (F_min) required for adhesive detachment from\nskin tissue, limiting the need for repeated FEM simulations and significantly\nreducing the computational cost. Leveraging a dataset generated from FEM\nsimulations of 90 degree peel test with varying adhesive and fracture mechanics\nparameters, our neural network model achieved high accuracy, validated through\nrigorous 5-fold cross-validation. The final architecture was able to predict a\nwide variety of skin-adhesive peeling behaviour, exhibiting a mean squared\nerror (MSE) of 3.66*10^-7 and a R^2 score of 0.94 on test set, demonstrating\nrobust performance. This work introduces a reliable, computationally efficient\nmethod for predicting adhesive behaviour, significantly reducing simulation\ntime while maintaining accuracy. This integration of machine learning with\nhigh-fidelity biomechanical simulations enables efficient design and\noptimization of skin-adhesive systems, providing a scalable framework for\nfuture research in computational dermato-mechanics and bio-adhesive material\ndesign.", "AI": {"tldr": "A neural network-based approach predicts minimum peel force for adhesives on skin, reducing computational costs compared to traditional FEM methods.", "motivation": "To address the resource-intensive and time-consuming nature of traditional methods (experimental testing and FEM) for analyzing adhesive peeling behavior on skin.", "method": "A neural network model trained on FEM simulation data of 90-degree peel tests with varying adhesive and fracture mechanics parameters.", "result": "High accuracy with MSE of 3.66*10^-7 and R^2 score of 0.94, validated via 5-fold cross-validation.", "conclusion": "The method offers a reliable, efficient alternative for predicting adhesive behavior, enabling scalable research in bio-adhesive design."}}
{"id": "2506.19028", "pdf": "https://arxiv.org/pdf/2506.19028", "abs": "https://arxiv.org/abs/2506.19028", "authors": ["Weijie Xu", "Yiwen Wang", "Chi Xue", "Xiangkun Hu", "Xi Fang", "Guimin Dong", "Chandan K. Reddy"], "title": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "categories": ["cs.CL", "cs.AI", "cs.CY", "68T50", "I.2.7"], "comment": "29 pages, 9 figures, 15 tables", "summary": "Large Language Models (LLMs) often generate responses with inherent biases,\nundermining their reliability in real-world applications. Existing evaluation\nmethods often overlook biases in long-form responses and the intrinsic\nvariability of LLM outputs. To address these challenges, we propose\nFiSCo(Fine-grained Semantic Computation), a novel statistical framework to\nevaluate group-level fairness in LLMs by detecting subtle semantic differences\nin long-form responses across demographic groups. Unlike prior work focusing on\nsentiment or token-level comparisons, FiSCo goes beyond surface-level analysis\nby operating at the claim level, leveraging entailment checks to assess the\nconsistency of meaning across responses. We decompose model outputs into\nsemantically distinct claims and apply statistical hypothesis testing to\ncompare inter- and intra-group similarities, enabling robust detection of\nsubtle biases. We formalize a new group counterfactual fairness definition and\nvalidate FiSCo on both synthetic and human-annotated datasets spanning gender,\nrace, and age. Experiments show that FiSco more reliably identifies nuanced\nbiases while reducing the impact of stochastic LLM variability, outperforming\nvarious evaluation metrics.", "AI": {"tldr": "FiSCo is a statistical framework for evaluating group-level fairness in LLMs by analyzing semantic differences in long-form responses, outperforming existing methods.", "motivation": "Existing evaluation methods for LLMs overlook biases in long-form responses and intrinsic variability, limiting their reliability.", "method": "FiSCo decomposes LLM outputs into claims, uses entailment checks for semantic consistency, and applies statistical hypothesis testing to detect biases.", "result": "FiSCo reliably identifies nuanced biases across demographic groups and reduces the impact of LLM variability, outperforming other metrics.", "conclusion": "FiSCo provides a robust framework for detecting subtle biases in LLMs, enhancing fairness evaluation in real-world applications."}}
{"id": "2502.07784", "pdf": "https://arxiv.org/pdf/2502.07784", "abs": "https://arxiv.org/abs/2502.07784", "authors": ["Ivan Lopes", "Valentin Deschaintre", "Yannick Hold-Geoffroy", "Raoul de Charette"], "title": "MatSwap: Light-aware material transfers in images", "categories": ["cs.CV", "cs.GR"], "comment": "Accepted to EGSR, journal track to appear in Computer Graphics Forum", "summary": "We present MatSwap, a method to transfer materials to designated surfaces in\nan image photorealistically. Such a task is non-trivial due to the large\nentanglement of material appearance, geometry, and lighting in a photograph. In\nthe literature, material editing methods typically rely on either cumbersome\ntext engineering or extensive manual annotations requiring artist knowledge and\n3D scene properties that are impractical to obtain. In contrast, we propose to\ndirectly learn the relationship between the input material -- as observed on a\nflat surface -- and its appearance within the scene, without the need for\nexplicit UV mapping. To achieve this, we rely on a custom light- and\ngeometry-aware diffusion model. We fine-tune a large-scale pre-trained\ntext-to-image model for material transfer using our synthetic dataset,\npreserving its strong priors to ensure effective generalization to real images.\nAs a result, our method seamlessly integrates a desired material into the\ntarget location in the photograph while retaining the identity of the scene. We\nevaluate our method on synthetic and real images and show that it compares\nfavorably to recent work both qualitatively and quantitatively. We release our\ncode and data on https://github.com/astra-vision/MatSwap", "AI": {"tldr": "MatSwap is a method for photorealistic material transfer in images, avoiding manual annotations or 3D scene properties by learning material appearance directly.", "motivation": "Material editing is challenging due to entangled appearance, geometry, and lighting; existing methods rely on impractical manual work or text engineering.", "method": "Uses a light- and geometry-aware diffusion model, fine-tuning a pre-trained text-to-image model with synthetic data for material transfer.", "result": "Effectively integrates materials into target images, outperforming recent methods in quality and realism.", "conclusion": "MatSwap offers a practical, high-quality solution for material transfer without requiring extensive manual input."}}
{"id": "2506.10304", "pdf": "https://arxiv.org/pdf/2506.10304", "abs": "https://arxiv.org/abs/2506.10304", "authors": ["Jasper Yao"], "title": "The Alignment Trap: Complexity Barriers", "categories": ["cs.AI", "cs.CC", "cs.CY", "cs.LG"], "comment": "31 Pages, 4 Figures. Substantial revision. Restructured around the\n  Enumeration Paradox and Five Pillars of Impossibility. Core mathematical\n  results unchanged but significantly expanded. Added new impossibility proofs\n  from statistical, information-theoretic, and dynamic perspectives", "summary": "This paper argues that AI alignment is not merely difficult, but is founded\non a fundamental logical contradiction. We first establish The Enumeration\nParadox: we use machine learning precisely because we cannot enumerate all\nnecessary safety rules, yet making ML safe requires examples that can only be\ngenerated from the very enumeration we admit is impossible. This paradox is\nthen confirmed by a set of five independent mathematical proofs, or \"pillars of\nimpossibility.\" Our main results show that: (1) Geometric Impossibility: The\nset of safe policies has measure zero, a necessary consequence of projecting\ninfinite-dimensional world-context requirements onto finite-dimensional models.\n(2) Computational Impossibility: Verifying a policy's safety is coNP-complete,\neven for non-zero error tolerances. (3) Statistical Impossibility: The training\ndata required for safety (abundant examples of rare disasters) is a logical\ncontradiction and thus unobtainable. (4) Information-Theoretic Impossibility:\nSafety rules contain more incompressible, arbitrary information than any\nfeasible network can store. (5) Dynamic Impossibility: The optimization process\nfor increasing AI capability is actively hostile to safety, as the gradients\nfor the two objectives are generally anti-aligned. Together, these results\ndemonstrate that the pursuit of safe, highly capable AI is not a matter of\novercoming technical hurdles, but of confronting fundamental, interlocking\nbarriers. The paper concludes by presenting a strategic trilemma that these\nimpossibilities force upon the field. A formal verification of the core\ntheorems in Lean4 is currently in progress.", "AI": {"tldr": "The paper argues AI alignment is fundamentally impossible due to logical contradictions, supported by five mathematical proofs.", "motivation": "To demonstrate that AI alignment is not just technically challenging but inherently contradictory.", "method": "Five mathematical proofs (Geometric, Computational, Statistical, Information-Theoretic, Dynamic) are presented to confirm the impossibility.", "result": "The proofs show AI alignment is impossible due to inherent contradictions in safety requirements, training data, and optimization.", "conclusion": "The field faces a strategic trilemma due to these fundamental barriers; formal verification of theorems is ongoing."}}
{"id": "2506.19856", "pdf": "https://arxiv.org/pdf/2506.19856", "abs": "https://arxiv.org/abs/2506.19856", "authors": ["Ryan Samson", "Adrian Banner", "Luca Candelori", "Sebastien Cottrell", "Tiziana Di Matteo", "Paul Duchnowski", "Vahagn Kirakosyan", "Jose Marques", "Kharen Musaelian", "Stefano Pasquali", "Ryan Stever", "Dario Villani"], "title": "Supervised Similarity for Firm Linkages", "categories": ["q-fin.ST", "cs.LG", "quant-ph"], "comment": null, "summary": "We introduce a novel proxy for firm linkages, Characteristic Vector Linkages\n(CVLs). We use this concept to estimate firm linkages, first through Euclidean\nsimilarity, and then by applying Quantum Cognition Machine Learning (QCML) to\nsimilarity learning. We demonstrate that both methods can be used to construct\nprofitable momentum spillover trading strategies, but QCML similarity\noutperforms the simpler Euclidean similarity.", "AI": {"tldr": "CVLs are introduced as a novel proxy for firm linkages, with QCML-based similarity outperforming Euclidean similarity in momentum spillover trading strategies.", "motivation": "To improve the estimation of firm linkages and enhance the performance of momentum spillover trading strategies.", "method": "Uses Characteristic Vector Linkages (CVLs) with Euclidean similarity and Quantum Cognition Machine Learning (QCML) for similarity learning.", "result": "Both methods yield profitable strategies, but QCML similarity outperforms Euclidean similarity.", "conclusion": "QCML-based similarity is superior for constructing momentum spillover trading strategies."}}
{"id": "2506.19262", "pdf": "https://arxiv.org/pdf/2506.19262", "abs": "https://arxiv.org/abs/2506.19262", "authors": ["Yuchang Zhu", "Huazhen Zhong", "Qunshu Lin", "Haotong Wei", "Xiaolong Sun", "Zixuan Yu", "Minghao Liu", "Zibin Zheng", "Liang Chen"], "title": "What Matters in LLM-generated Data: Diversity and Its Effect on Model Fine-Tuning", "categories": ["cs.CL", "cs.LG"], "comment": "Ongoing work", "summary": "With the remarkable generative capabilities of large language models (LLMs),\nusing LLM-generated data to train downstream models has emerged as a promising\napproach to mitigate data scarcity in specific domains and reduce\ntime-consuming annotations. However, recent studies have highlighted a critical\nissue: iterative training on self-generated data results in model collapse,\nwhere model performance degrades over time. Despite extensive research on the\nimplications of LLM-generated data, these works often neglect the importance of\ndata diversity, a key factor in data quality. In this work, we aim to\nunderstand the implications of the diversity of LLM-generated data on\ndownstream model performance. Specifically, we explore how varying levels of\ndiversity in LLM-generated data affect downstream model performance.\nAdditionally, we investigate the performance of models trained on data that\nmixes different proportions of LLM-generated data, which we refer to as\nsynthetic data. Our experimental results show that, with minimal distribution\nshift, moderately diverse LLM-generated data can enhance model performance in\nscenarios with insufficient labeled data, whereas highly diverse generated data\nhas a negative impact. We hope our empirical findings will offer valuable\nguidance for future studies on LLMs as data generators.", "AI": {"tldr": "The paper investigates how the diversity of LLM-generated data impacts downstream model performance, finding that moderately diverse data improves performance, while highly diverse data harms it.", "motivation": "To address the overlooked importance of data diversity in LLM-generated data and its effect on downstream model performance, especially in data-scarce domains.", "method": "Explores varying levels of diversity in LLM-generated data and its impact, including mixed proportions of synthetic and real data.", "result": "Moderately diverse LLM-generated data enhances performance with minimal distribution shift, but highly diverse data negatively affects it.", "conclusion": "The findings provide guidance for using LLMs as data generators, emphasizing the importance of balanced diversity."}}
{"id": "2502.08914", "pdf": "https://arxiv.org/pdf/2502.08914", "abs": "https://arxiv.org/abs/2502.08914", "authors": ["Zahra Bayramli", "Ayhan Suleymanzade", "Na Min An", "Huzama Ahmad", "Eunsu Kim", "Junyeong Park", "James Thorne", "Alice Oh"], "title": "Diffusion Models Through a Global Lens: Are They Culturally Inclusive?", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 17 figures, 3 tables", "summary": "Text-to-image diffusion models have recently enabled the creation of visually\ncompelling, detailed images from textual prompts. However, their ability to\naccurately represent various cultural nuances remains an open question. In our\nwork, we introduce CultDiff benchmark, evaluating state-of-the-art diffusion\nmodels whether they can generate culturally specific images spanning ten\ncountries. We show that these models often fail to generate cultural artifacts\nin architecture, clothing, and food, especially for underrepresented country\nregions, by conducting a fine-grained analysis of different similarity aspects,\nrevealing significant disparities in cultural relevance, description fidelity,\nand realism compared to real-world reference images. With the collected human\nevaluations, we develop a neural-based image-image similarity metric, namely,\nCultDiff-S, to predict human judgment on real and generated images with\ncultural artifacts. Our work highlights the need for more inclusive generative\nAI systems and equitable dataset representation over a wide range of cultures.", "AI": {"tldr": "The paper introduces CultDiff, a benchmark to evaluate text-to-image diffusion models' ability to generate culturally specific images, revealing their shortcomings, especially for underrepresented regions.", "motivation": "To assess whether state-of-the-art diffusion models can accurately represent cultural nuances in generated images.", "method": "The study evaluates models using the CultDiff benchmark, analyzing cultural relevance, description fidelity, and realism. Human evaluations inform the development of CultDiff-S, a neural-based similarity metric.", "result": "Models often fail to generate culturally accurate artifacts, particularly for underrepresented regions, showing disparities in relevance, fidelity, and realism.", "conclusion": "The work underscores the need for more inclusive AI systems and equitable dataset representation across diverse cultures."}}
{"id": "2506.10521", "pdf": "https://arxiv.org/pdf/2506.10521", "abs": "https://arxiv.org/abs/2506.10521", "authors": ["Yuhao Zhou", "Yiheng Wang", "Xuming He", "Ruoyao Xiao", "Zhiwei Li", "Qiantai Feng", "Zijie Guo", "Yuejin Yang", "Hao Wu", "Wenxuan Huang", "Jiaqi Wei", "Dan Si", "Xiuqi Yao", "Jia Bu", "Haiwen Huang", "Tianfan Fu", "Shixiang Tang", "Ben Fei", "Dongzhan Zhou", "Fenghua Ling", "Yan Lu", "Siqi Sun", "Chenhui Li", "Guanjie Zheng", "Jiancheng Lv", "Wenlong Zhang", "Lei Bai"], "title": "Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "82 pages", "summary": "Scientific discoveries increasingly rely on complex multimodal reasoning\nbased on information-intensive scientific data and domain-specific expertise.\nEmpowered by expert-level scientific benchmarks, scientific Multimodal Large\nLanguage Models (MLLMs) hold the potential to significantly enhance this\ndiscovery process in realistic workflows. However, current scientific\nbenchmarks mostly focus on evaluating the knowledge understanding capabilities\nof MLLMs, leading to an inadequate assessment of their perception and reasoning\nabilities. To address this gap, we present the Scientists' First Exam (SFE)\nbenchmark, designed to evaluate the scientific cognitive capacities of MLLMs\nthrough three interconnected levels: scientific signal perception, scientific\nattribute understanding, scientific comparative reasoning. Specifically, SFE\ncomprises 830 expert-verified VQA pairs across three question types, spanning\n66 multimodal tasks across five high-value disciplines. Extensive experiments\nreveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08%\nand 26.52% on SFE, highlighting significant room for MLLMs to improve in\nscientific realms. We hope the insights obtained in SFE will facilitate further\ndevelopments in AI-enhanced scientific discoveries.", "AI": {"tldr": "The paper introduces the Scientists' First Exam (SFE) benchmark to evaluate Multimodal Large Language Models (MLLMs) on scientific cognitive capacities, revealing current models' limitations.", "motivation": "Current scientific benchmarks inadequately assess MLLMs' perception and reasoning abilities, focusing only on knowledge understanding.", "method": "The SFE benchmark evaluates MLLMs through three levels: scientific signal perception, attribute understanding, and comparative reasoning, using 830 expert-verified VQA pairs across 66 tasks in five disciplines.", "result": "State-of-the-art models (GPT-3 and InternVL-3) scored only 34.08% and 26.52% on SFE, indicating significant room for improvement.", "conclusion": "SFE aims to advance AI-enhanced scientific discoveries by addressing gaps in MLLM evaluation."}}
{"id": "2506.19881", "pdf": "https://arxiv.org/pdf/2506.19881", "abs": "https://arxiv.org/abs/2506.19881", "authors": ["Aloni Cohen"], "title": "Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models", "categories": ["cs.CR", "cs.CY", "cs.LG"], "comment": null, "summary": "Are there any conditions under which a generative model's outputs are\nguaranteed not to infringe the copyrights of its training data? This is the\nquestion of \"provable copyright protection\" first posed by Vyas, Kakade, and\nBarak (ICML 2023). They define near access-freeness (NAF) and propose it as\nsufficient for protection. This paper revisits the question and establishes new\nfoundations for provable copyright protection -- foundations that are firmer\nboth technically and legally. First, we show that NAF alone does not prevent\ninfringement. In fact, NAF models can enable verbatim copying, a blatant\nfailure of copy protection that we dub being tainted. Then, we introduce our\nblameless copy protection framework for defining meaningful guarantees, and\ninstantiate it with clean-room copy protection. Clean-room copy protection\nallows a user to control their risk of copying by behaving in a way that is\nunlikely to copy in a counterfactual clean-room setting. Finally, we formalize\na common intuition about differential privacy and copyright by proving that DP\nimplies clean-room copy protection when the dataset is golden, a copyright\ndeduplication requirement.", "AI": {"tldr": "The paper revisits provable copyright protection for generative models, showing that near access-freeness (NAF) fails to prevent infringement. It introduces a new framework, blameless copy protection, and clean-room copy protection, linking differential privacy (DP) to copyright protection under certain conditions.", "motivation": "To address the inadequacy of NAF in preventing copyright infringement and establish stronger legal and technical foundations for provable copyright protection in generative models.", "method": "The paper critiques NAF, introduces blameless copy protection, and proposes clean-room copy protection. It also formalizes the relationship between DP and copyright protection under golden dataset conditions.", "result": "NAF is insufficient for preventing infringement, while clean-room copy protection offers a viable alternative. DP is shown to imply clean-room copy protection for golden datasets.", "conclusion": "The paper provides stronger foundations for copyright protection in generative models, highlighting the limitations of NAF and the potential of clean-room copy protection and DP."}}
{"id": "2506.19750", "pdf": "https://arxiv.org/pdf/2506.19750", "abs": "https://arxiv.org/abs/2506.19750", "authors": ["Takashi Nishibayashi", "Seiji Kanazawa", "Kumpei Yamada"], "title": "Evaluating Rare Disease Diagnostic Performance in Symptom Checkers: A Synthetic Vignette Simulation Approach", "categories": ["cs.CL"], "comment": null, "summary": "Symptom Checkers (SCs) provide users with personalized medical information.\nTo prevent performance degradation from algorithm updates, SC developers must\nevaluate diagnostic performance changes for individual diseases before\ndeployment. However, acquiring sufficient evaluation data for rare diseases is\ndifficult, and manually creating numerous clinical vignettes is costly and\nimpractical. This study proposes and validates a novel Synthetic Vignette\nSimulation Approach to evaluate diagnostic performance changes for individual\nrare diseases following SC algorithm updates. We used disease-phenotype\nannotations from the Human Phenotype Ontology (HPO), a knowledge database for\nrare diseases, to generate synthetic vignettes. With these, we simulated SC\ninterviews to estimate the impact of algorithm updates on real-world diagnostic\nperformance. The method's effectiveness was evaluated retrospectively by\ncomparing estimated values with actual metric changes using the $R^2$\ncoefficient. The experiment included eight past SC algorithm updates. For\nupdates on diseases with frequency information in HPO (n=5), the $R^2$ for\nRecall@8 change was 0.831 ($p$=0.031), and for Precision@8 change, it was 0.78\n($p$=0.047), indicating the method can predict post-deployment performance. In\ncontrast, large prediction errors occurred for diseases without frequency\ninformation (n=3), highlighting its importance. Our method enables\npre-deployment evaluation of SC algorithm changes for individual rare diseases\nusing a publicly available, expert-created knowledge base. This transparent and\nlow-cost approach allows developers to efficiently improve diagnostic\nperformance for rare diseases, potentially enhancing support for early\ndiagnosis.", "AI": {"tldr": "The study proposes a Synthetic Vignette Simulation Approach to evaluate diagnostic performance changes in Symptom Checkers (SCs) for rare diseases using HPO data, showing effectiveness for diseases with frequency information.", "motivation": "Evaluating SC algorithm updates for rare diseases is challenging due to data scarcity and high costs of manual vignette creation.", "method": "Uses HPO disease-phenotype annotations to generate synthetic vignettes, simulating SC interviews to estimate performance changes post-update.", "result": "High $R^2$ values (0.831 for Recall@8, 0.78 for Precision@8) for diseases with frequency data, but poor performance without it.", "conclusion": "The method enables cost-effective, pre-deployment evaluation of SC updates for rare diseases, aiding early diagnosis."}}
{"id": "2502.09664", "pdf": "https://arxiv.org/pdf/2502.09664", "abs": "https://arxiv.org/abs/2502.09664", "authors": ["Eduardo Adame", "Daniel Csillag", "Guilherme Tegoni Goedert"], "title": "Image Super-Resolution with Guarantees via Conformalized Generative Models", "categories": ["cs.CV", "cs.LG", "stat.ML"], "comment": "17 pages, 7 figures", "summary": "The increasing use of generative ML foundation models for image restoration\ntasks such as super-resolution calls for robust and interpretable uncertainty\nquantification methods. We address this need by presenting a novel approach\nbased on conformal prediction techniques to create a 'confidence mask' capable\nof reliably and intuitively communicating where the generated image can be\ntrusted. Our method is adaptable to any black-box generative model, including\nthose locked behind an opaque API, requires only easily attainable data for\ncalibration, and is highly customizable via the choice of a local image\nsimilarity metric. We prove strong theoretical guarantees for our method that\nspan fidelity error control (according to our local image similarity metric),\nreconstruction quality, and robustness in the face of data leakage. Finally, we\nempirically evaluate these results and establish our method's solid\nperformance.", "AI": {"tldr": "A novel conformal prediction-based method for uncertainty quantification in generative ML models for image restoration, providing interpretable confidence masks.", "motivation": "The need for robust and interpretable uncertainty quantification in generative ML models for tasks like super-resolution.", "method": "Uses conformal prediction to create confidence masks, adaptable to any black-box model, requires minimal calibration data, and is customizable via local image similarity metrics.", "result": "Strong theoretical guarantees for fidelity error control, reconstruction quality, and robustness against data leakage, supported by empirical validation.", "conclusion": "The method reliably communicates trust in generated images and performs well empirically."}}
{"id": "2506.17289", "pdf": "https://arxiv.org/pdf/2506.17289", "abs": "https://arxiv.org/abs/2506.17289", "authors": ["Rahul Raja", "Arpita Vats"], "title": "Evaluating Generalization and Representation Stability in Small LMs via Prompting, Fine-Tuning and Out-of-Distribution Prompts", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted at ICML", "summary": "We investigate the generalization capabilities of small language models under\ntwo popular adaptation paradigms: few-shot prompting and supervised\nfine-tuning. While prompting is often favored for its parameter efficiency and\nflexibility, it remains unclear how robust this approach is in low-resource\nsettings and under distributional shifts. This paper presents a comparative\nstudy of prompting and fine-tuning across task formats, prompt styles, and\nmodel scales, with a focus on their behavior in both in-distribution and\nout-of-distribution (OOD) settings. Beyond accuracy, we analyze the internal\nrepresentations learned by each approach to assess the stability and\nabstraction of task-specific features. Our findings highlight critical\ndifferences in how small models internalize and generalize knowledge under\ndifferent adaptation strategies. This work offers practical guidance for model\nselection in low-data regimes and contributes empirical insight into the\nongoing debate over prompting versus fine-tuning. Code for the experiments is\navailable at the following", "AI": {"tldr": "Comparative study of few-shot prompting and supervised fine-tuning in small language models, analyzing generalization, robustness, and internal representations in low-resource and OOD settings.", "motivation": "To understand the robustness and generalization of small language models under different adaptation strategies (prompting vs. fine-tuning) in low-resource and distribution-shift scenarios.", "method": "Comparative analysis across task formats, prompt styles, and model scales, evaluating accuracy and internal representations in in-distribution and OOD settings.", "result": "Highlights key differences in how small models internalize and generalize knowledge under prompting and fine-tuning, providing empirical insights.", "conclusion": "Offers practical guidance for model selection in low-data regimes and contributes to the debate on prompting versus fine-tuning."}}
{"id": "2506.19886", "pdf": "https://arxiv.org/pdf/2506.19886", "abs": "https://arxiv.org/abs/2506.19886", "authors": ["Xuesong Wang", "Mo Li", "Xingyan Shi", "Zhaoqian Liu", "Shenghao Yang"], "title": "Diffusion-based Task-oriented Semantic Communications with Model Inversion Attack", "categories": ["cs.CR", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Semantic communication has emerged as a promising neural network-based system\ndesign for 6G networks. Task-oriented semantic communication is a novel\nparadigm whose core goal is to efficiently complete specific tasks by\ntransmitting semantic information, optimizing communication efficiency and task\nperformance. The key challenge lies in preserving privacy while maintaining\ntask accuracy, as this scenario is susceptible to model inversion attacks. In\nsuch attacks, adversaries can restore or even reconstruct input data by\nanalyzing and processing model outputs, owing to the neural network-based\nnature of the systems. In addition, traditional systems use image quality\nindicators (such as PSNR or SSIM) to assess attack severity, which may be\ninadequate for task-oriented semantic communication, since visual differences\ndo not necessarily ensure semantic divergence. In this paper, we propose a\ndiffusion-based semantic communication framework, named DiffSem, that optimizes\nsemantic information reconstruction through a diffusion mechanism with\nself-referential label embedding to significantly improve task performance. Our\nmodel also compensates channel noise and adopt semantic information distortion\nto ensure the robustness of the system in various signal-to-noise ratio\nenvironments. To evaluate the attacker's effectiveness, we propose a new metric\nthat better quantifies the semantic fidelity of estimations from the adversary.\nExperimental results based on this criterion show that on the MNIST dataset,\nDiffSem improves the classification accuracy by 10.03%, and maintain stable\nperformance under dynamic channels. Our results further demonstrate that\nsignificant deviation exists between traditional image quality indicators and\nthe leakage of task-relevant semantic information.", "AI": {"tldr": "DiffSem is a diffusion-based semantic communication framework for 6G networks, enhancing task performance and privacy by optimizing semantic reconstruction and introducing a new metric for attack evaluation.", "motivation": "The need for efficient task-oriented semantic communication in 6G networks, balancing privacy and accuracy, and addressing vulnerabilities to model inversion attacks.", "method": "Proposes DiffSem, a diffusion-based framework with self-referential label embedding and semantic distortion to improve robustness and task performance.", "result": "On MNIST, DiffSem boosts classification accuracy by 10.03% and maintains stability in dynamic channels, outperforming traditional metrics.", "conclusion": "DiffSem effectively addresses privacy and performance in semantic communication, with a new metric better quantifying semantic fidelity against attacks."}}
{"id": "2409.02244", "pdf": "https://arxiv.org/pdf/2409.02244", "abs": "https://arxiv.org/abs/2409.02244", "authors": ["Zainab Iftikhar", "Sean Ransom", "Amy Xiao", "Nicole Nugent", "Jeff Huang"], "title": "Therapy as an NLP Task: Psychologists' Comparison of LLMs and Human Peers in CBT", "categories": ["cs.HC", "cs.CL", "I.2.7; J.4"], "comment": null, "summary": "Large language models (LLMs) are being used as ad-hoc therapists. Research\nsuggests that LLMs outperform human counselors when generating a single,\nisolated empathetic response; however, their session-level behavior remains\nunderstudied. In this study, we compare the session-level behaviors of human\ncounselors with those of an LLM prompted by a team of peer counselors to\ndeliver single-session Cognitive Behavioral Therapy (CBT). Our three-stage,\nmixed-methods study involved: a) a year-long ethnography of a text-based\nsupport platform where seven counselors iteratively refined CBT prompts through\nself-counseling and weekly focus groups; b) the manual simulation of human\ncounselor sessions with a CBT-prompted LLM, given the full patient dialogue and\ncontextual notes; and c) session evaluations of both human and LLM sessions by\nthree licensed clinical psychologists using CBT competence measures. Our\nresults show a clear trade-off. Human counselors excel at relational strategies\n-- small talk, self-disclosure, and culturally situated language -- that lead\nto higher empathy, collaboration, and deeper user reflection. LLM counselors\ndemonstrate higher procedural adherence to CBT techniques but struggle to\nsustain collaboration, misread cultural cues, and sometimes produce \"deceptive\nempathy,\" i.e., formulaic warmth that can inflate users' expectations of\ngenuine human care. Taken together, our findings imply that while LLMs might\noutperform counselors in generating single empathetic responses, their ability\nto lead sessions is more limited, highlighting that therapy cannot be reduced\nto a standalone natural language processing (NLP) task. We call for carefully\ndesigned human-AI workflows in scalable support: LLMs can scaffold\nevidence-based techniques, while peers provide relational support. We conclude\nby mapping concrete design opportunities and ethical guardrails for such hybrid\nsystems.", "AI": {"tldr": "LLMs outperform humans in single empathetic responses but struggle with session-level therapy. Humans excel in relational strategies, while LLMs adhere better to CBT techniques but lack sustained collaboration and cultural sensitivity. Hybrid human-AI workflows are recommended.", "motivation": "To compare session-level behaviors of human counselors and LLMs in delivering CBT, addressing gaps in understanding LLMs' therapeutic capabilities.", "method": "A mixed-methods study involving ethnography, manual simulation of human and LLM sessions, and evaluations by clinical psychologists.", "result": "Humans excel in relational strategies (empathy, collaboration); LLMs show higher CBT adherence but struggle with collaboration and cultural cues.", "conclusion": "Therapy cannot be reduced to NLP tasks; hybrid human-AI workflows are needed, with LLMs handling techniques and humans providing relational support."}}
{"id": "2503.01109", "pdf": "https://arxiv.org/pdf/2503.01109", "abs": "https://arxiv.org/abs/2503.01109", "authors": ["Yansong Xu", "Junlin Li", "Wei Zhang", "Siyu Chen", "Shengyong Zhang", "Yuquan Leng", "Weijia Zhou"], "title": "FGS-SLAM: Fourier-based Gaussian Splatting for Real-time SLAM with Sparse and Dense Map Fusion", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "3D gaussian splatting has advanced simultaneous localization and mapping\n(SLAM) technology by enabling real-time positioning and the construction of\nhigh-fidelity maps. However, the uncertainty in gaussian position and\ninitialization parameters introduces challenges, often requiring extensive\niterative convergence and resulting in redundant or insufficient gaussian\nrepresentations. To address this, we introduce a novel adaptive densification\nmethod based on Fourier frequency domain analysis to establish gaussian priors\nfor rapid convergence. Additionally, we propose constructing independent and\nunified sparse and dense maps, where a sparse map supports efficient tracking\nvia Generalized Iterative Closest Point (GICP) and a dense map creates\nhigh-fidelity visual representations. This is the first SLAM system leveraging\nfrequency domain analysis to achieve high-quality gaussian mapping in\nreal-time. Experimental results demonstrate an average frame rate of 36 FPS on\nReplica and TUM RGB-D datasets, achieving competitive accuracy in both\nlocalization and mapping.", "AI": {"tldr": "A novel adaptive densification method using Fourier frequency domain analysis improves 3D Gaussian splatting for SLAM, enabling real-time high-fidelity mapping and efficient tracking.", "motivation": "Addressing challenges of uncertainty in Gaussian position and initialization parameters, which cause slow convergence and redundant or insufficient representations in SLAM.", "method": "Introduces adaptive densification via Fourier frequency domain analysis for Gaussian priors and constructs independent sparse (for tracking) and dense (for visuals) maps.", "result": "Achieves 36 FPS on Replica and TUM RGB-D datasets with competitive accuracy in localization and mapping.", "conclusion": "The first SLAM system using frequency domain analysis for real-time high-quality Gaussian mapping, demonstrating efficiency and accuracy."}}
{"id": "2506.17667", "pdf": "https://arxiv.org/pdf/2506.17667", "abs": "https://arxiv.org/abs/2506.17667", "authors": ["Lintao Wang", "Encheng Su", "Jiaqi Liu", "Pengze Li", "Peng Xia", "Jiabei Xiao", "Wenlong Zhang", "Xinnan Dai", "Xi Chen", "Yuan Meng", "Mingyu Ding", "Lei Bai", "Wanli Ouyang", "Shixiang Tang", "Aoran Wang", "Xinzhu Ma"], "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models", "categories": ["cs.AI"], "comment": null, "summary": "Physics problem-solving is a challenging domain for large AI models,\nrequiring integration of conceptual understanding, mathematical reasoning, and\ninterpretation of physical diagrams. Current evaluation methodologies show\nnotable limitations in capturing the breadth and complexity of\nundergraduate-level physics, underscoring the need for more rigorous\nassessments. To this end, we present PhysUniBench, a large-scale multimodal\nbenchmark designed to evaluate and improve the reasoning capabilities of\nmultimodal large language models (MLLMs) specifically on undergraduate-level\nphysics problems. PhysUniBench consists of 3,304 physics questions spanning 8\nmajor sub-disciplines of physics, each accompanied by one visual diagrams. The\nbenchmark includes both open-ended and multiple-choice questions,\nsystematically curated and difficulty-rated through an iterative\nmodel-in-the-loop process. The benchmark's construction involved a rigorous\nmulti-stage process, including multiple roll-outs, expert-level evaluation,\nautomated filtering of easily solved problems, and a nuanced difficulty grading\nsystem with five levels. Through extensive experiments, we observe that current\nstate-of-the-art models encounter substantial challenges in physics reasoning.\nFor example, GPT-4o mini achieves only about 34.2% accuracy in the proposed\nPhysUniBench. These results highlight that current MLLMs struggle with advanced\nphysics reasoning, especially on multi-step problems and those requiring\nprecise diagram interpretation. By providing a broad and rigorous assessment\ntool, PhysUniBench aims to drive progress in AI for Science, encouraging the\ndevelopment of models with stronger physical reasoning, problem-solving skills,\nand multimodal understanding. The benchmark and evaluation scripts are\navailable at https://prismax-team.github.io/PhysUniBenchmark/.", "AI": {"tldr": "PhysUniBench is a multimodal benchmark for evaluating MLLMs on undergraduate physics problems, revealing significant gaps in current models' reasoning and diagram interpretation.", "motivation": "Current AI models struggle with the complexity of physics problem-solving, necessitating a rigorous benchmark to assess and improve their capabilities.", "method": "Developed PhysUniBench, a 3,304-question benchmark across 8 physics sub-disciplines, with open-ended and multiple-choice questions, expert-curated difficulty levels, and multimodal inputs.", "result": "State-of-the-art models like GPT-4o mini perform poorly (34.2% accuracy), especially on multi-step and diagram-heavy problems.", "conclusion": "PhysUniBench highlights the need for improved AI models in physics reasoning and aims to advance multimodal understanding in AI for Science."}}
{"id": "2506.19945", "pdf": "https://arxiv.org/pdf/2506.19945", "abs": "https://arxiv.org/abs/2506.19945", "authors": ["Graeme Baker", "Agostino Capponi", "J. Antonio Sidaoui"], "title": "Data-Driven Dynamic Factor Modeling via Manifold Learning", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "We propose a data-driven dynamic factor framework where a response variable\ndepends on a high-dimensional set of covariates, without imposing any\nparametric model on the joint dynamics. Leveraging Anisotropic Diffusion Maps,\na nonlinear manifold learning technique introduced by Singer and Coifman, our\nframework uncovers the joint dynamics of the covariates and responses in a\npurely data-driven way. We approximate the embedding dynamics using linear\ndiffusions, and exploit Kalman filtering to predict the evolution of the\ncovariates and response variables directly from the diffusion map embedding\nspace. We generalize Singer's convergence rate analysis of the graph Laplacian\nfrom the case of independent uniform samples on a compact manifold to the case\nof time series arising from Langevin diffusions in Euclidean space.\nFurthermore, we provide rigorous justification for our procedure by showing the\nrobustness of approximations of the diffusion map coordinates by linear\ndiffusions, and the convergence of ergodic averages under standard spectral\nassumptions on the underlying dynamics. We apply our method to the stress\ntesting of equity portfolios using a combination of financial and macroeconomic\nfactors from the Federal Reserve's supervisory scenarios. We demonstrate that\nour data-driven stress testing method outperforms standard scenario analysis\nand Principal Component Analysis benchmarks through historical backtests\nspanning three major financial crises, achieving reductions in mean absolute\nerror of up to 55% and 39% for scenario-based portfolio return prediction,\nrespectively.", "AI": {"tldr": "A data-driven dynamic factor framework using Anisotropic Diffusion Maps and Kalman filtering for predicting high-dimensional covariates and responses, outperforming traditional methods in financial stress testing.", "motivation": "To model high-dimensional covariates and responses without parametric assumptions, leveraging nonlinear manifold learning for accurate predictions in financial stress testing.", "method": "Uses Anisotropic Diffusion Maps for joint dynamics, linear diffusions for embedding, and Kalman filtering for prediction. Extends convergence analysis to time series from Langevin diffusions.", "result": "Outperforms standard scenario analysis and PCA, reducing mean absolute error by up to 55% and 39% in portfolio return prediction.", "conclusion": "The framework provides a robust, data-driven approach for stress testing, validated by historical backtests across financial crises."}}
{"id": "2410.18362", "pdf": "https://arxiv.org/pdf/2410.18362", "abs": "https://arxiv.org/abs/2410.18362", "authors": ["Shanchao Liang", "Nan Jiang", "Shangshu Qian", "Lin Tan"], "title": "WAFFLE: Finetuning Multi-Modal Model for Automated Front-End Development", "categories": ["cs.SE", "cs.CL", "cs.CV"], "comment": null, "summary": "Web development involves turning UI designs into functional webpages, which\ncan be difficult for both beginners and experienced developers due to the\ncomplexity of HTML's hierarchical structures and styles. While Large Language\nModels (LLMs) have shown promise in generating source code, two major\nchallenges persist in UI-to-HTML code generation: (1) effectively representing\nHTML's hierarchical structure for LLMs, and (2) bridging the gap between the\nvisual nature of UI designs and the text-based format of HTML code. To tackle\nthese challenges, we introduce Waffle, a new fine-tuning strategy that uses a\nstructure-aware attention mechanism to improve LLMs' understanding of HTML's\nstructure and a contrastive fine-tuning approach to align LLMs' understanding\nof UI images and HTML code. Models fine-tuned with Waffle show up to 9.00 pp\n(percentage point) higher HTML match, 0.0982 higher CW-SSIM, 32.99 higher CLIP,\nand 27.12 pp higher LLEM on our new benchmark WebSight-Test and an existing\nbenchmark Design2Code, outperforming current fine-tuning methods.", "AI": {"tldr": "Waffle improves UI-to-HTML code generation by addressing hierarchical structure representation and visual-text alignment, outperforming existing methods.", "motivation": "Challenges in UI-to-HTML generation include representing HTML's hierarchical structure and aligning visual UI designs with text-based HTML code.", "method": "Waffle uses structure-aware attention and contrastive fine-tuning to enhance LLMs' understanding of HTML structure and UI-code alignment.", "result": "Waffle achieves higher HTML match (9.00 pp), CW-SSIM (0.0982), CLIP (32.99), and LLEM (27.12 pp) on benchmarks WebSight-Test and Design2Code.", "conclusion": "Waffle's fine-tuning strategy significantly improves UI-to-HTML generation, outperforming current methods."}}
{"id": "2503.05319", "pdf": "https://arxiv.org/pdf/2503.05319", "abs": "https://arxiv.org/abs/2503.05319", "authors": ["Xinkun Wang", "Yifang Wang", "Senwei Liang", "Feilong Tang", "Chengzhi Liu", "Ming Hu", "Chao Hu", "Junjun He", "Zongyuan Ge", "Imran Razzak"], "title": "Robust Multimodal Learning for Ophthalmic Disease Grading via Disentangled Representation", "categories": ["cs.CV", "cs.AI"], "comment": "10pages", "summary": "This paper discusses how ophthalmologists often rely on multimodal data to\nimprove diagnostic accuracy. However, complete multimodal data is rare in\nreal-world applications due to a lack of medical equipment and concerns about\ndata privacy. Traditional deep learning methods typically address these issues\nby learning representations in latent space. However, the paper highlights two\nkey limitations of these approaches: (i) Task-irrelevant redundant information\n(e.g., numerous slices) in complex modalities leads to significant redundancy\nin latent space representations. (ii) Overlapping multimodal representations\nmake it difficult to extract unique features for each modality. To overcome\nthese challenges, the authors propose the Essence-Point and Disentangle\nRepresentation Learning (EDRL) strategy, which integrates a self-distillation\nmechanism into an end-to-end framework to enhance feature selection and\ndisentanglement for more robust multimodal learning. Specifically, the\nEssence-Point Representation Learning module selects discriminative features\nthat improve disease grading performance. The Disentangled Representation\nLearning module separates multimodal data into modality-common and\nmodality-unique representations, reducing feature entanglement and enhancing\nboth robustness and interpretability in ophthalmic disease diagnosis.\nExperiments on multimodal ophthalmology datasets show that the proposed EDRL\nstrategy significantly outperforms current state-of-the-art methods.", "AI": {"tldr": "The paper proposes EDRL, a strategy combining Essence-Point and Disentangle Representation Learning, to improve multimodal ophthalmic diagnosis by addressing redundancy and overlapping features in traditional deep learning methods.", "motivation": "Ophthalmologists rely on multimodal data for accurate diagnosis, but incomplete data and privacy concerns limit its use. Traditional methods fail to handle task-irrelevant redundancy and overlapping features effectively.", "method": "EDRL integrates self-distillation into an end-to-end framework, featuring Essence-Point Representation Learning for discriminative feature selection and Disentangled Representation Learning to separate modality-common and modality-unique features.", "result": "EDRL outperforms state-of-the-art methods on multimodal ophthalmology datasets, improving disease grading and interpretability.", "conclusion": "EDRL enhances multimodal learning by reducing redundancy and disentangling features, offering a robust solution for ophthalmic diagnosis."}}
{"id": "2211.06665", "pdf": "https://arxiv.org/pdf/2211.06665", "abs": "https://arxiv.org/abs/2211.06665", "authors": ["Yunpeng Qing", "Shunyu Liu", "Jie Song", "Huiqiong Wang", "Mingli Song"], "title": "A Survey on Explainable Reinforcement Learning: Concepts, Algorithms, Challenges", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) is a popular machine learning paradigm where\nintelligent agents interact with the environment to fulfill a long-term goal.\nDriven by the resurgence of deep learning, Deep RL (DRL) has witnessed great\nsuccess over a wide spectrum of complex control tasks. Despite the encouraging\nresults achieved, the deep neural network-based backbone is widely deemed as a\nblack box that impedes practitioners to trust and employ trained agents in\nrealistic scenarios where high security and reliability are essential. To\nalleviate this issue, a large volume of literature devoted to shedding light on\nthe inner workings of the intelligent agents has been proposed, by constructing\nintrinsic interpretability or post-hoc explainability. In this survey, we\nprovide a comprehensive review of existing works on eXplainable RL (XRL) and\nintroduce a new taxonomy where prior works are clearly categorized into\nmodel-explaining, reward-explaining, state-explaining, and task-explaining\nmethods. We also review and highlight RL methods that conversely leverage human\nknowledge to promote learning efficiency and performance of agents while this\nkind of method is often ignored in XRL field. Some challenges and opportunities\nin XRL are discussed. This survey intends to provide a high-level summarization\nof XRL and to motivate future research on more effective XRL solutions.\nCorresponding open source codes are collected and categorized at\nhttps://github.com/Plankson/awesome-explainable-reinforcement-learning.", "AI": {"tldr": "A survey on eXplainable Reinforcement Learning (XRL) categorizing methods into model, reward, state, and task explanations, and discussing challenges and opportunities.", "motivation": "To address the black-box nature of Deep RL (DRL) and enhance trust and reliability in real-world applications.", "method": "Review and taxonomy of XRL methods, including model-explaining, reward-explaining, state-explaining, and task-explaining approaches.", "result": "A comprehensive categorization of XRL works and identification of overlooked methods leveraging human knowledge.", "conclusion": "The survey provides a high-level summary of XRL, encourages future research, and offers a categorized open-source repository."}}
{"id": "2506.19947", "pdf": "https://arxiv.org/pdf/2506.19947", "abs": "https://arxiv.org/abs/2506.19947", "authors": ["Yung-Fu Chen", "Anish Arora"], "title": "MILAAP: Mobile Link Allocation via Attention-based Prediction", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "Channel hopping (CS) communication systems must adapt to interference changes\nin the wireless network and to node mobility for maintaining throughput\nefficiency. Optimal scheduling requires up-to-date network state information\n(i.e., of channel occupancy) to select non-overlapping channels for links in\ninterference regions. However, state sharing among nodes introduces significant\ncommunication overhead, especially as network size or node mobility scale,\nthereby decreasing throughput efficiency of already capacity-limited networks.\nIn this paper, we eschew state sharing while adapting the CS schedule based on\na learning-based channel occupancy prediction. We propose the MiLAAP\nattention-based prediction framework for machine learning models of spectral,\nspatial, and temporal dependencies among network nodes. MiLAAP uses a\nself-attention mechanism that lets each node capture the temporospectral CS\npattern in its interference region and accordingly predict the channel\noccupancy state within that region. Notably, the prediction relies only on\nlocally and passively observed channel activities, and thus introduces no\ncommunication overhead. To deal with node mobility, MiLAAP also uses a\nmulti-head self-attention mechanism that lets each node locally capture the\nspatiotemporal dependencies on other network nodes that can interfere with it\nand accordingly predict the motion trajectory of those nodes. Detecting nodes\nthat enter or move outside the interference region is used to further improve\nthe prediction accuracy of channel occupancy. We show that for dynamic networks\nthat use local CS sequences to support relatively long-lived flow traffics, the\nchannel state prediction accuracy of MiLAAP is remarkably ~100% across\ndifferent node mobility patterns and it achieves zero-shot generalizability\nacross different periods of CS sequences.", "AI": {"tldr": "MiLAAP is a learning-based framework for predicting channel occupancy in wireless networks without state sharing, using self-attention mechanisms to adapt to interference and node mobility, achieving high accuracy and zero-shot generalizability.", "motivation": "To avoid the communication overhead of state sharing in channel hopping systems while maintaining throughput efficiency by adapting to interference and node mobility.", "method": "Proposes MiLAAP, an attention-based prediction framework using self-attention and multi-head self-attention mechanisms to predict channel occupancy and node trajectories based on locally observed data.", "result": "MiLAAP achieves ~100% prediction accuracy across different mobility patterns and demonstrates zero-shot generalizability.", "conclusion": "MiLAAP effectively predicts channel occupancy and adapts to node mobility without communication overhead, making it highly efficient for dynamic wireless networks."}}
{"id": "2410.21647", "pdf": "https://arxiv.org/pdf/2410.21647", "abs": "https://arxiv.org/abs/2410.21647", "authors": ["Shanchao Liang", "Yiran Hu", "Nan Jiang", "Lin Tan"], "title": "Can Language Models Replace Programmers for Coding? REPOCOD Says 'Not Yet'", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Recently, a number of repository-level code generation benchmarks-such as\nCoderEval, DevEval, RepoEval, RepoBench, and LongCodeArena-have emerged to\nevaluate the capabilities of large language models (LLMs) beyond standalone\nbenchmarks like HumanEval and MBPP. Thus, a natural question is, would LLMs\nhave similar performance in real world coding tasks as their performance in\nthese benchmarks? Unfortunately, one cannot answer this question, since these\nbenchmarks consist of short completions, synthetic examples, or focus on\nlimited scale repositories, failing to represent real-world coding tasks.\n  To address these challenges, we create REPOCOD, a Python code-generation\nbenchmark containing complex tasks with realistic dependencies in real-world\nlarge projects and appropriate metrics for evaluating source code. It includes\n980 whole-function generation tasks from 11 popular projects, 50.8% of which\nrequire repository-level context. REPOCOD includes 314 developer-written test\ncases per instance for better evaluation. We evaluate ten LLMs on REPOCOD and\nfind that none achieves more than 30% pass@1 on REPOCOD, indicating the\nnecessity of building stronger LLMs that can help developers in real-world\nsoftware development. In addition, we found that retrieval-augmented generation\nachieves better results than using target function dependencies as context.", "AI": {"tldr": "REPOCOD is a new benchmark for evaluating LLMs in real-world Python code generation tasks, highlighting their limitations with only 30% pass@1 performance.", "motivation": "Existing benchmarks for LLMs in code generation lack realism, focusing on short completions or synthetic examples, not real-world tasks.", "method": "Created REPOCOD with 980 complex tasks from 11 projects, 50.8% requiring repository-level context, and 314 test cases per instance. Evaluated ten LLMs.", "result": "No LLM achieved more than 30% pass@1 on REPOCOD. Retrieval-augmented generation outperformed using target function dependencies.", "conclusion": "Stronger LLMs are needed for real-world software development, and retrieval-augmented methods show promise."}}
{"id": "2503.07294", "pdf": "https://arxiv.org/pdf/2503.07294", "abs": "https://arxiv.org/abs/2503.07294", "authors": ["Thomas Boucher", "John Whittle", "Evangelos B. Mazomenos"], "title": "From $\\mathcal{O}(n^{2})$ to $\\mathcal{O}(n)$ Parameters: Quantum Self-Attention in Vision Transformers for Biomedical Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Submitted for EMA4MICCAI 2025", "summary": "We demonstrate that quantum vision transformers (QViTs), vision transformers\n(ViTs) with self-attention (SA) mechanisms replaced by quantum self-attention\n(QSA) mechanisms, can match state-of-the-art (SOTA) biomedical image\nclassifiers while using 99.99% fewer parameters. QSAs are produced by replacing\nlinear SA layers with parameterised quantum neural networks (QNNs), producing a\nQSA mechanism and reducing parameter scaling from $\\mathcal{O}(n^2)$ to\n$\\mathcal{O}(n)$. On RetinaMNIST, our ultra parameter-efficient QViT\noutperforms 13/14 SOTA methods including CNNs and ViTs, achieving 56.5%\naccuracy, just 0.88% below the top MedMamba model while using 99.99% fewer\nparameters (1K vs 14.5M) and 89% fewer GFLOPs. We present the first\ninvestigation of knowledge distillation (KD) from classical to quantum vision\ntransformers in biomedical image classification, showing that QViTs maintain\ncomparable performance to classical ViTs across eight diverse datasets spanning\nmultiple modalities, with improved QSA parameter-efficiency. Our higher-qubit\narchitecture benefitted more from KD pre-training, suggesting a scaling\nrelationship between QSA parameters and KD effectiveness. These findings\nestablish QSA as a practical architectural choice toward parameter-efficient\nbiomedical image analysis.", "AI": {"tldr": "Quantum vision transformers (QViTs) with quantum self-attention (QSA) match SOTA biomedical image classifiers using 99.99% fewer parameters and achieve comparable performance to classical ViTs.", "motivation": "To address the inefficiency of parameter scaling in classical vision transformers (ViTs) by replacing linear self-attention layers with quantum neural networks (QNNs).", "method": "Replaced self-attention mechanisms in ViTs with QSA mechanisms using parameterized QNNs, reducing parameter scaling from O(n\u00b2) to O(n). Evaluated on RetinaMNIST and eight diverse biomedical datasets.", "result": "QViTs outperformed 13/14 SOTA methods on RetinaMNIST (56.5% accuracy) with 99.99% fewer parameters and 89% fewer GFLOPs. Maintained comparable performance to classical ViTs across datasets.", "conclusion": "QSA is a practical, parameter-efficient alternative for biomedical image analysis, with knowledge distillation enhancing performance for higher-qubit architectures."}}
{"id": "2401.01259", "pdf": "https://arxiv.org/pdf/2401.01259", "abs": "https://arxiv.org/abs/2401.01259", "authors": ["Naveen Raman", "Mateo Espinosa Zarlenga", "Juyeon Heo", "Mateja Jamnik"], "title": "Do Concept Bottleneck Models Respect Localities?", "categories": ["cs.LG", "cs.AI"], "comment": "Published at TMLR", "summary": "Concept-based explainability methods use human-understandable intermediaries\nto produce explanations for machine learning models. These methods assume\nconcept predictions can help understand a model's internal reasoning. In this\nwork, we assess the degree to which such an assumption is true by analyzing\nwhether concept predictors leverage \"relevant\" features to make predictions, a\nterm we call locality. Concept-based models that fail to respect localities\nalso fail to be explainable because concept predictions are based on spurious\nfeatures, making the interpretation of the concept predictions vacuous. To\nassess whether concept-based models respect localities, we construct and use\nthree metrics to characterize when models respect localities, complementing our\nanalysis with theoretical results. Each of our metrics captures a different\nnotion of perturbation and assess whether perturbing \"irrelevant\" features\nimpacts the predictions made by a concept predictors. We find that many\nconcept-based models used in practice fail to respect localities because\nconcept predictors cannot always clearly distinguish distinct concepts. Based\non these findings, we propose suggestions for alleviating this issue.", "AI": {"tldr": "The paper evaluates whether concept-based explainability methods truly reflect model reasoning by analyzing if concept predictors use relevant features (locality). It finds many models fail this, leading to spurious explanations, and proposes solutions.", "motivation": "To assess if concept-based explainability methods genuinely help understand model reasoning by verifying if concept predictors use relevant features (locality).", "method": "Constructs three metrics to test locality under different perturbations, complemented by theoretical analysis.", "result": "Many concept-based models fail to respect locality, as concept predictors struggle to distinguish distinct concepts clearly.", "conclusion": "Proposes suggestions to improve concept-based models by ensuring locality, enhancing their explainability."}}
{"id": "2506.19972", "pdf": "https://arxiv.org/pdf/2506.19972", "abs": "https://arxiv.org/abs/2506.19972", "authors": ["Federico Ruilova", "Ernst Gunnar Gran", "Sven-Arne Reinemo"], "title": "MAIZX: A Carbon-Aware Framework for Optimizing Cloud Computing Emissions", "categories": ["cs.DC", "cs.LG"], "comment": "2 pages, 2 figures. LOCO 2024, December 3, 2024, Glasgow/Online", "summary": "Cloud computing drives innovation but also poses significant environmental\nchallenges due to its high-energy consumption and carbon emissions. Data\ncenters account for 2-4% of global energy usage, and the ICT sector's share of\nelectricity consumption is projected to reach 40% by 2040. As the goal of\nachieving net-zero emissions by 2050 becomes increasingly urgent, there is a\ngrowing need for more efficient and transparent solutions, particularly for\nprivate cloud infrastructures, which are utilized by 87% of organizations,\ndespite the dominance of public-cloud systems.\n  This study evaluates the MAIZX framework, designed to optimize cloud\noperations and reduce carbon footprint by dynamically ranking resources,\nincluding data centers, edge computing nodes, and multi-cloud environments,\nbased on real-time and forecasted carbon intensity, Power Usage Effectiveness\n(PUE), and energy consumption. Leveraging a flexible ranking algorithm, MAIZX\nachieved an 85.68% reduction in CO2 emissions compared to baseline hypervisor\noperations. Tested across geographically distributed data centers, the\nframework demonstrates scalability and effectiveness, directly interfacing with\nhypervisors to optimize workloads in private, hybrid, and multi-cloud\nenvironments. MAIZX integrates real-time data on carbon intensity, power\nconsumption, and carbon footprint, as well as forecasted values, into cloud\nmanagement, providing a robust tool for enhancing climate performance potential\nwhile maintaining operational efficiency.", "AI": {"tldr": "The paper evaluates the MAIZX framework, which optimizes cloud operations to reduce carbon emissions by dynamically ranking resources based on real-time and forecasted data, achieving an 85.68% reduction in CO2 emissions.", "motivation": "The growing environmental impact of cloud computing, especially private cloud infrastructures, necessitates efficient and transparent solutions to reduce carbon emissions and energy consumption.", "method": "The MAIZX framework dynamically ranks resources (data centers, edge nodes, multi-cloud environments) using real-time and forecasted carbon intensity, PUE, and energy data, interfacing with hypervisors to optimize workloads.", "result": "MAIZX achieved an 85.68% reduction in CO2 emissions compared to baseline hypervisor operations, demonstrating scalability and effectiveness across distributed data centers.", "conclusion": "MAIZX provides a robust solution for reducing cloud computing's carbon footprint while maintaining operational efficiency, addressing urgent climate goals."}}
{"id": "2505.16065", "pdf": "https://arxiv.org/pdf/2505.16065", "abs": "https://arxiv.org/abs/2505.16065", "authors": ["Ruijie Xi", "He Ba", "Hao Yuan", "Rishu Agrawal", "Yuxin Tian", "Ruoyan Kong", "Arul Prakash"], "title": "Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated Synthetic Data Augmentation", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Embedding-Based Retrieval (EBR) is an important technique in modern search\nengines, enabling semantic match between search queries and relevant results.\nHowever, search logging data on platforms like Facebook Marketplace lacks the\ndiversity and details needed for effective EBR model training, limiting the\nmodels' ability to capture nuanced search patterns. To address this challenge,\nwe propose Aug2Search, an EBR-based framework leveraging synthetic data\ngenerated by Generative AI (GenAI) models, in a multimodal and multitask\napproach to optimize query-product relevance. This paper investigates the\ncapabilities of GenAI, particularly Large Language Models (LLMs), in generating\nhigh-quality synthetic data, and analyzing its impact on enhancing EBR models.\nWe conducted experiments using eight Llama models and 100 million data points\nfrom Facebook Marketplace logs. Our synthetic data generation follows three\nstrategies: (1) generate queries, (2) enhance product listings, and (3)\ngenerate queries from enhanced listings. We train EBR models on three different\ndatasets: sampled engagement data or original data ((e.g., \"Click\" and \"Listing\nInteractions\")), synthetic data, and a mixture of both engagement and synthetic\ndata to assess their performance across various training sets. Our findings\nunderscore the robustness of Llama models in producing synthetic queries and\nlistings with high coherence, relevance, and diversity, while maintaining low\nlevels of hallucination. Aug2Search achieves an improvement of up to 4% in\nROC_AUC with 100 million synthetic data samples, demonstrating the\neffectiveness of our approach. Moreover, our experiments reveal that with the\nsame volume of training data, models trained exclusively on synthetic data\noften outperform those trained on original data only or a mixture of original\nand synthetic data.", "AI": {"tldr": "Aug2Search uses GenAI to generate synthetic data for EBR models, improving query-product relevance by up to 4% in ROC_AUC.", "motivation": "EBR models struggle with limited diversity in search logging data, hindering nuanced search pattern capture.", "method": "Aug2Search employs LLMs (e.g., Llama) to generate synthetic queries and enhanced product listings, training EBR models on original, synthetic, or mixed datasets.", "result": "Synthetic data improves EBR performance, with models trained solely on synthetic data often outperforming others.", "conclusion": "GenAI-generated synthetic data enhances EBR models, offering a scalable solution for search relevance optimization."}}
{"id": "2503.07813", "pdf": "https://arxiv.org/pdf/2503.07813", "abs": "https://arxiv.org/abs/2503.07813", "authors": ["Elvis Kimara", "Mozhgan Hadadi", "Jackson Godbersen", "Aditya Balu", "Talukder Jubery", "Yawei Li", "Adarsh Krishnamurthy", "Patrick S. Schnable", "Baskar Ganapathysubramanian"], "title": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Elvis Kimara and Mozhgan Hadadi contributed equally to this work", "summary": "The development of artificial intelligence (AI) and machine learning (ML)\nbased tools for 3D phenotyping, especially for maize, has been limited due to\nthe lack of large and diverse 3D datasets. 2D image datasets fail to capture\nessential structural details such as leaf architecture, plant volume, and\nspatial arrangements that 3D data provide. To address this limitation, we\npresent MaizeField3D (https://baskargroup.github.io/MaizeField3D/), a curated\ndataset of 3D point clouds of field-grown maize plants from a diverse genetic\npanel, designed to be AI-ready for advancing agricultural research. Our dataset\nincludes 1,045 high-quality point clouds of field-grown maize collected using a\nterrestrial laser scanner (TLS). Point clouds of 520 plants from this dataset\nwere segmented and annotated using a graph-based segmentation method to isolate\nindividual leaves and stalks, ensuring consistent labeling across all samples.\nThis labeled data was then used for fitting procedural models that provide a\nstructured parametric representation of the maize plants. The leaves of the\nmaize plants in the procedural models are represented using Non-Uniform\nRational B-Spline (NURBS) surfaces that were generated using a two-step\noptimization process combining gradient-free and gradient-based methods. We\nconducted rigorous manual quality control on all datasets, correcting errors in\nsegmentation, ensuring accurate leaf ordering, and validating metadata\nannotations. The dataset also includes metadata detailing plant morphology and\nquality, alongside multi-resolution subsampled point cloud data (100k, 50k, 10k\npoints), which can be readily used for different downstream computational\ntasks. MaizeField3D will serve as a comprehensive foundational dataset for\nAI-driven phenotyping, plant structural analysis, and 3D applications in\nagricultural research.", "AI": {"tldr": "MaizeField3D is a curated 3D point cloud dataset of field-grown maize plants, designed for AI-driven phenotyping and agricultural research.", "motivation": "The lack of large, diverse 3D datasets for maize limits AI/ML tool development for 3D phenotyping. 2D images miss critical structural details.", "method": "Collected 1,045 TLS point clouds, segmented and annotated 520 plants using graph-based methods, and fitted procedural models with NURBS surfaces via optimization.", "result": "A high-quality, labeled dataset with metadata, multi-resolution point clouds, and procedural models for maize plants.", "conclusion": "MaizeField3D provides a foundational resource for AI-driven agricultural research and 3D phenotyping."}}
{"id": "2403.14488", "pdf": "https://arxiv.org/pdf/2403.14488", "abs": "https://arxiv.org/abs/2403.14488", "authors": ["Ricardo Cannizzaro", "Michael Groom", "Jonathan Routley", "Robert Osazuwa Ness", "Lars Kunze"], "title": "COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty", "categories": ["cs.RO", "cs.AI", "cs.LG", "stat.AP", "I.2.9; I.2.8; I.2.3; G.3; I.2.6; I.6.8; I.2.4; I.2.10"], "comment": "8 pages, 7 figures, accepted to the 2025 IEEE European Conference on\n  Mobile Robots (ECMR 2025)", "summary": "Manipulation tasks require robots to reason about cause and effect when\ninteracting with objects. Yet, many data-driven approaches lack causal\nsemantics and thus only consider correlations. We introduce COBRA-PPM, a novel\ncausal Bayesian reasoning architecture that combines causal Bayesian networks\nand probabilistic programming to perform interventional inference for robot\nmanipulation under uncertainty. We demonstrate its capabilities through\nhigh-fidelity Gazebo-based experiments on an exemplar block stacking task,\nwhere it predicts manipulation outcomes with high accuracy (Pred Acc: 88.6%)\nand performs greedy next-best action selection with a 94.2% task success rate.\nWe further demonstrate sim2real transfer on a domestic robot, showing\neffectiveness in handling real-world uncertainty from sensor noise and\nstochastic actions. Our generalised and extensible framework supports a wide\nrange of manipulation scenarios and lays a foundation for future work at the\nintersection of robotics and causality.", "AI": {"tldr": "COBRA-PPM is a causal Bayesian reasoning architecture for robot manipulation, combining causal Bayesian networks and probabilistic programming to improve accuracy and success rates in tasks like block stacking.", "motivation": "Existing data-driven approaches often lack causal semantics, relying on correlations rather than cause-and-effect reasoning for robot manipulation tasks.", "method": "COBRA-PPM integrates causal Bayesian networks and probabilistic programming to perform interventional inference under uncertainty.", "result": "Achieved 88.6% prediction accuracy and 94.2% task success rate in block stacking, with successful sim2real transfer.", "conclusion": "The framework is generalizable and extensible, providing a foundation for robotics and causality research."}}
{"id": "2506.19993", "pdf": "https://arxiv.org/pdf/2506.19993", "abs": "https://arxiv.org/abs/2506.19993", "authors": ["Haochen Zhang", "Tianyi Zhang", "Junze Yin", "Oren Gal", "Anshumali Shrivastava", "Vladimir Braverman"], "title": "CoVE: Compressed Vocabulary Expansion Makes Better LLM-based Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted by ACL 2025 Findings", "summary": "Recommender systems play a pivotal role in providing relevant content to\nusers. With the rapid development of large language models (LLMs), researchers\nhave begun utilizing LLMs to build more powerful recommender systems. However,\nexisting approaches that focus on aligning LLMs with recommendation tasks do\nnot fully leverage their sequential information processing capabilities,\nleading to suboptimal performance.\n  In this paper, we propose a novel system called compressed vocabulary\nexpansion (CoVE). In CoVE, each item is assigned a unique ID within the\nexpanded vocabulary. Our framework effectively capitalizes on sequence\nunderstanding abilities of LLMs, significantly enhancing their performance on\nrecommendation tasks. Additionally, we compress the embedding layer, making\nCoVE practical for large-scale industrial applications. The effectiveness and\nperformance of CoVE are demonstrated through comprehensive experiments on\nmultiple recommendation datasets and comparisons with prior works. Our code can\nbe found at https://github.com/HaochenZhang717/CoVE-official-Repo.", "AI": {"tldr": "The paper introduces CoVE, a system leveraging LLMs' sequential processing for better recommender systems by using compressed vocabulary expansion and embedding layer compression.", "motivation": "Existing methods underutilize LLMs' sequential capabilities in recommender systems, leading to suboptimal performance.", "method": "CoVE assigns unique IDs to items in an expanded vocabulary and compresses the embedding layer to enhance LLMs' sequence understanding.", "result": "CoVE improves performance on recommendation tasks, validated by experiments on multiple datasets.", "conclusion": "CoVE is effective and practical for large-scale applications, outperforming prior methods."}}
{"id": "2505.17282", "pdf": "https://arxiv.org/pdf/2505.17282", "abs": "https://arxiv.org/abs/2505.17282", "authors": ["Diyuan Wu", "Aleksandr Shevchenko", "Samet Oymak", "Marco Mondelli"], "title": "Attention with Trained Embeddings Provably Selects Important Tokens", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "Fix mistakes in Lemma 4.2 and proof of Lemma 4.5, and some other\n  minor changes", "summary": "Token embeddings play a crucial role in language modeling but, despite this\npractical relevance, their theoretical understanding remains limited. Our paper\naddresses the gap by characterizing the structure of embeddings obtained via\ngradient descent. Specifically, we consider a one-layer softmax attention model\nwith a linear head for binary classification, i.e., $\\texttt{Softmax}( p^\\top\nE_X^\\top ) E_X v = \\frac{ \\sum_{i=1}^T \\exp(p^\\top E_{x_i}) E_{x_i}^\\top\nv}{\\sum_{j=1}^T \\exp(p^\\top E_{x_{j}}) }$, where $E_X = [ E_{x_1} , \\dots,\nE_{x_T} ]^\\top$ contains the embeddings of the input sequence, $p$ is the\nembedding of the $\\mathrm{\\langle cls \\rangle}$ token and $v$ the output\nvector. First, we show that, already after a single step of gradient training\nwith the logistic loss, the embeddings $E_X$ capture the importance of tokens\nin the dataset by aligning with the output vector $v$ proportionally to the\nfrequency with which the corresponding tokens appear in the dataset. Then,\nafter training $p$ via gradient flow until convergence, the softmax selects the\nimportant tokens in the sentence (i.e., those that are predictive of the\nlabel), and the resulting $\\mathrm{\\langle cls \\rangle}$ embedding maximizes\nthe margin for such a selection. Experiments on real-world datasets (IMDB,\nYelp) exhibit a phenomenology close to that unveiled by our theory.", "AI": {"tldr": "The paper analyzes token embeddings in a one-layer softmax attention model, showing how gradient descent aligns embeddings with token importance and optimizes classification margins.", "motivation": "Despite the practical importance of token embeddings in language modeling, their theoretical understanding is limited. This paper aims to bridge that gap.", "method": "The study uses a one-layer softmax attention model with a linear head for binary classification, analyzing embeddings via gradient descent and gradient flow.", "result": "After training, embeddings align with token importance based on frequency, and the softmax selects predictive tokens, optimizing classification margins.", "conclusion": "The theoretical findings are supported by experiments on real-world datasets (IMDB, Yelp), validating the model's behavior."}}
{"id": "2503.09749", "pdf": "https://arxiv.org/pdf/2503.09749", "abs": "https://arxiv.org/abs/2503.09749", "authors": ["Yongle Yuan", "Kevin W. Bowyer"], "title": "A Siamese Network to Detect If Two Iris Images Are Monozygotic", "categories": ["cs.CV"], "comment": null, "summary": "This study presents the first automated classifier designed to determine\nwhether a pair of iris images originates from monozygotic individuals,\naddressing a previously untackled problem in biometric recognition. In\nDaugman-style iris recognition, the textures of the left and right irises of\nthe same person are traditionally considered as being as different as the\nirises of two unrelated persons. However, previous research indicates that\nhumans can detect that two iris images are from different eyes of the same\nperson, or eyes of monozygotic twins, with an accuracy of about 80%. In this\nwork, we employ a Siamese network architecture and contrastive learning to\ncategorize a pair of iris images as coming from monozygotic or non-monozygotic\nirises. This could potentially be applied, for example, as a fast, noninvasive\ntest to determine if twins are monozygotic or non-monozygotic. We construct a\ndataset comprising both synthetic monozygotic pairs (images of different irises\nof the same individual) and natural monozygotic pairs (images of different\nimages from persons who are identical twins), in addition to non-monozygotic\npairs from unrelated individuals, ensuring a comprehensive evaluation of the\nmodel's capabilities. To gain deeper insights into the learned representations,\nwe train and analyze three variants of the model using (1) the original input\nimages, (2) iris-only images (masking everything but the iris region), and (3)\nnon-iris-only images (masking the iris region). This comparison reveals that\nboth iris texture and surrounding ocular structure contain information useful\nfor the model to classify the image pairs as monozygotic or non-monozygotic.\nOur approach achieves accuracy levels using the full iris image that exceed\nthose previously reported for human classification of monozygotic iris pairs.", "AI": {"tldr": "An automated classifier using a Siamese network and contrastive learning to identify monozygotic iris pairs, outperforming human accuracy.", "motivation": "Address the untackled problem of distinguishing monozygotic iris pairs in biometric recognition, leveraging human-like detection capabilities.", "method": "Uses a Siamese network with contrastive learning on a dataset of synthetic and natural monozygotic pairs, comparing full, iris-only, and non-iris-only images.", "result": "Achieves higher accuracy than human classification, with both iris texture and surrounding ocular structure contributing to the model's performance.", "conclusion": "The classifier is effective for distinguishing monozygotic iris pairs, with potential applications like noninvasive twin zygosity testing."}}
{"id": "2407.02508", "pdf": "https://arxiv.org/pdf/2407.02508", "abs": "https://arxiv.org/abs/2407.02508", "authors": ["Hang Zhou", "Yihao Qin", "Dan Xu", "Yiding Ji"], "title": "Physics-informed Imitative Reinforcement Learning for Real-world Driving", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in imitative reinforcement learning (IRL) have considerably\nenhanced the ability of autonomous agents to assimilate expert demonstrations,\nleading to rapid skill acquisition in a range of demanding tasks. However, such\nlearning-based agents face significant challenges when transferring knowledge\nto highly dynamic closed-loop environments. Their performance is significantly\nimpacted by the conflicting optimization objectives of imitation learning (IL)\nand reinforcement learning (RL), sample inefficiency, and the complexity of\nuncovering the hidden world model and physics. To address this challenge, we\npropose a physics-informed IRL that is entirely data-driven. It leverages both\nexpert demonstration data and exploratory data with a joint optimization\nobjective, allowing the underlying physical principles of vehicle dynamics to\nemerge naturally from the training process. The performance is evaluated\nthrough empirical experiments and results exceed popular IL, RL and IRL\nalgorithms in closed-loop settings on Waymax benchmark. Our approach exhibits\n37.8% reduction in collision rate and 22.2% reduction in off-road rate compared\nto the baseline method.", "AI": {"tldr": "The paper introduces a physics-informed imitative reinforcement learning (IRL) method to improve knowledge transfer in dynamic environments, outperforming baseline methods in collision and off-road rates.", "motivation": "Address challenges in transferring knowledge to dynamic closed-loop environments due to conflicting IL and RL objectives, sample inefficiency, and hidden world model complexity.", "method": "Proposes a data-driven physics-informed IRL combining expert demonstrations and exploratory data with joint optimization to uncover vehicle dynamics.", "result": "Achieves 37.8% lower collision rate and 22.2% lower off-road rate compared to baselines on the Waymax benchmark.", "conclusion": "The physics-informed IRL method effectively integrates expert and exploratory data, improving performance in dynamic settings."}}
{"id": "2506.20000", "pdf": "https://arxiv.org/pdf/2506.20000", "abs": "https://arxiv.org/abs/2506.20000", "authors": ["Narasimha Raghavan Veeraragavan", "Jan Franz Nyg\u00e5rd"], "title": "Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "Accepted at ICML 2025 Workshop on Collaborative and Federated Agentic\n  Workflows (CFAgentic@ICML'25)", "summary": "We propose Guardian-FC, a novel two-layer framework for privacy preserving\nfederated computing that unifies safety enforcement across diverse privacy\npreserving mechanisms, including cryptographic back-ends like fully homomorphic\nencryption (FHE) and multiparty computation (MPC), as well as statistical\ntechniques such as differential privacy (DP). Guardian-FC decouples guard-rails\nfrom privacy mechanisms by executing plug-ins (modular computation units),\nwritten in a backend-neutral, domain-specific language (DSL) designed\nspecifically for federated computing workflows and interchangeable Execution\nProviders (EPs), which implement DSL operations for various privacy back-ends.\nAn Agentic-AI control plane enforces a finite-state safety loop through signed\ntelemetry and commands, ensuring consistent risk management and auditability.\nThe manifest-centric design supports fail-fast job admission and seamless\nextensibility to new privacy back-ends. We present qualitative scenarios\nillustrating backend-agnostic safety and a formal model foundation for\nverification. Finally, we outline a research agenda inviting the community to\nadvance adaptive guard-rail tuning, multi-backend composition, DSL\nspecification development, implementation, and compiler extensibility alongside\nhuman-override usability.", "AI": {"tldr": "Guardian-FC is a two-layer framework for privacy-preserving federated computing, unifying safety enforcement across diverse privacy mechanisms like FHE, MPC, and DP. It decouples guard-rails from privacy mechanisms using a DSL and interchangeable Execution Providers, with an Agentic-AI control plane for safety and auditability.", "motivation": "To address the challenge of enforcing consistent safety and privacy across diverse federated computing mechanisms, ensuring risk management and extensibility.", "method": "Uses a two-layer framework with a backend-neutral DSL for modular computation, interchangeable Execution Providers, and an Agentic-AI control plane for safety enforcement.", "result": "Enables backend-agnostic safety, fail-fast job admission, and extensibility to new privacy back-ends, supported by a formal model for verification.", "conclusion": "Guardian-FC provides a scalable and adaptable solution for privacy-preserving federated computing, with potential for community-driven advancements in guard-rail tuning, DSL development, and usability."}}
{"id": "2506.18023", "pdf": "https://arxiv.org/pdf/2506.18023", "abs": "https://arxiv.org/abs/2506.18023", "authors": ["Kui Huang", "Xinrong Chen", "Wenyu Lv", "Jincheng Liao", "Guanzhong Wang", "Yi Liu"], "title": "PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "This report introduces PP-DocBee2, an advanced version of the PP-DocBee,\ndesigned to enhance multimodal document understanding. Built on a large\nmultimodal model architecture, PP-DocBee2 addresses the limitations of its\npredecessor through key technological improvements, including enhanced\nsynthetic data quality, improved visual feature fusion strategy, and optimized\ninference methodologies. These enhancements yield an $11.4\\%$ performance boost\non internal benchmarks for Chinese business documents, and reduce inference\nlatency by $73.0\\%$ to the vanilla version. A key innovation of our work is a\ndata quality optimization strategy for multimodal document tasks. By employing\na large-scale multimodal pre-trained model to evaluate data, we apply a novel\nstatistical criterion to filter outliers, ensuring high-quality training data.\nInspired by insights into underutilized intermediate features in multimodal\nmodels, we enhance the ViT representational capacity by decomposing it into\nlayers and applying a novel feature fusion strategy to improve complex\nreasoning. The source code and pre-trained model are available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.", "AI": {"tldr": "PP-DocBee2 improves multimodal document understanding with enhanced data quality, feature fusion, and inference optimization, achieving 11.4% better performance and 73% lower latency.", "motivation": "Address limitations of PP-DocBee by improving synthetic data quality, visual feature fusion, and inference efficiency for better multimodal document understanding.", "method": "Uses a large-scale multimodal pre-trained model for data quality optimization, decomposes ViT layers for enhanced feature fusion, and optimizes inference methodologies.", "result": "11.4% performance boost on Chinese business documents and 73.0% reduction in inference latency compared to the vanilla version.", "conclusion": "PP-DocBee2 advances multimodal document understanding with key innovations in data quality and feature fusion, offering significant performance and efficiency gains."}}
{"id": "2503.19777", "pdf": "https://arxiv.org/pdf/2503.19777", "abs": "https://arxiv.org/abs/2503.19777", "authors": ["Vladan Stojni\u0107", "Yannis Kalantidis", "Ji\u0159\u00ed Matas", "Giorgos Tolias"], "title": "LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We propose a training-free method for open-vocabulary semantic segmentation\nusing Vision-and-Language Models (VLMs). Our approach enhances the initial\nper-patch predictions of VLMs through label propagation, which jointly\noptimizes predictions by incorporating patch-to-patch relationships. Since VLMs\nare primarily optimized for cross-modal alignment and not for intra-modal\nsimilarity, we use a Vision Model (VM) that is observed to better capture these\nrelationships. We address resolution limitations inherent to patch-based\nencoders by applying label propagation at the pixel level as a refinement step,\nsignificantly improving segmentation accuracy near class boundaries. Our\nmethod, called LPOSS+, performs inference over the entire image, avoiding\nwindow-based processing and thereby capturing contextual interactions across\nthe full image. LPOSS+ achieves state-of-the-art performance among\ntraining-free methods, across a diverse set of datasets. Code:\nhttps://github.com/vladan-stojnic/LPOSS", "AI": {"tldr": "A training-free method for open-vocabulary semantic segmentation using VLMs and VMs, enhanced by label propagation and pixel-level refinement, achieving state-of-the-art performance.", "motivation": "To improve segmentation accuracy by leveraging VLMs for cross-modal alignment and VMs for intra-modal similarity, addressing resolution limitations of patch-based encoders.", "method": "Combines VLMs and VMs with label propagation for joint optimization, applies pixel-level refinement, and avoids window-based processing for full-image context.", "result": "LPOSS+ achieves state-of-the-art performance among training-free methods across diverse datasets.", "conclusion": "The proposed method effectively enhances segmentation accuracy, especially near class boundaries, without requiring training."}}
{"id": "2408.00523", "pdf": "https://arxiv.org/pdf/2408.00523", "abs": "https://arxiv.org/abs/2408.00523", "authors": ["Yingkai Dong", "Xiangtao Meng", "Ning Yu", "Zheng Li", "Shanqing Guo"], "title": "Fuzz-Testing Meets LLM-Based Agents: An Automated and Efficient Framework for Jailbreaking Text-To-Image Generation Models", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Text-to-image (T2I) generative models have revolutionized content creation by\ntransforming textual descriptions into high-quality images. However, these\nmodels are vulnerable to jailbreaking attacks, where carefully crafted prompts\nbypass safety mechanisms to produce unsafe content. While researchers have\ndeveloped various jailbreak attacks to expose this risk, these methods face\nsignificant limitations, including impractical access requirements, easily\ndetectable unnatural prompts, restricted search spaces, and high query demands\non the target system. In this paper, we propose JailFuzzer, a novel fuzzing\nframework driven by large language model (LLM) agents, designed to efficiently\ngenerate natural and semantically meaningful jailbreak prompts in a black-box\nsetting. Specifically, JailFuzzer employs fuzz-testing principles with three\ncomponents: a seed pool for initial and jailbreak prompts, a guided mutation\nengine for generating meaningful variations, and an oracle function to evaluate\njailbreak success. Furthermore, we construct the guided mutation engine and\noracle function by LLM-based agents, which further ensures efficiency and\nadaptability in black-box settings. Extensive experiments demonstrate that\nJailFuzzer has significant advantages in jailbreaking T2I models. It generates\nnatural and semantically coherent prompts, reducing the likelihood of detection\nby traditional defenses. Additionally, it achieves a high success rate in\njailbreak attacks with minimal query overhead, outperforming existing methods\nacross all key metrics. This study underscores the need for stronger safety\nmechanisms in generative models and provides a foundation for future research\non defending against sophisticated jailbreaking attacks. JailFuzzer is\nopen-source and available at this repository:\nhttps://github.com/YingkaiD/JailFuzzer.", "AI": {"tldr": "JailFuzzer is a novel LLM-driven fuzzing framework that efficiently generates natural jailbreak prompts for T2I models, outperforming existing methods in success rate and stealth.", "motivation": "T2I models are vulnerable to jailbreaking attacks, but current methods are impractical or detectable. JailFuzzer addresses these limitations.", "method": "Uses a seed pool, guided mutation engine, and oracle function, all powered by LLM agents, to generate and evaluate jailbreak prompts in black-box settings.", "result": "JailFuzzer produces natural, coherent prompts with high success rates and low query overhead, outperforming existing methods.", "conclusion": "Highlights the need for stronger safety mechanisms in generative models and provides a foundation for future defense research."}}
{"id": "2506.20043", "pdf": "https://arxiv.org/pdf/2506.20043", "abs": "https://arxiv.org/abs/2506.20043", "authors": ["Ahmet Sarigun", "Bora Uyar", "Vedran Franke", "Altuna Akalin"], "title": "PocketVina Enables Scalable and Highly Accurate Physically Valid Docking through Multi-Pocket Conditioning", "categories": ["q-bio.QM", "cs.LG", "q-bio.BM"], "comment": null, "summary": "Sampling physically valid ligand-binding poses remains a major challenge in\nmolecular docking, particularly for unseen or structurally diverse targets. We\nintroduce PocketVina, a fast and memory-efficient, search-based docking\nframework that combines pocket prediction with systematic multi-pocket\nexploration. We evaluate PocketVina across four established\nbenchmarks--PDBbind2020 (timesplit and unseen), DockGen, Astex, and\nPoseBusters--and observe consistently strong performance in sampling physically\nvalid docking poses. PocketVina achieves state-of-the-art performance when\njointly considering ligand RMSD and physical validity (PB-valid), while\nremaining competitive with deep learning-based approaches in terms of RMSD\nalone, particularly on structurally diverse and previously unseen targets.\nPocketVina also maintains state-of-the-art physically valid docking accuracy\nacross ligands with varying degrees of flexibility. We further introduce\nTargetDock-AI, a benchmarking dataset we curated, consisting of over 500000\nprotein-ligand pairs, and a partition of the dataset labeled with PubChem\nactivity annotations. On this large-scale dataset, PocketVina successfully\ndiscriminates active from inactive targets, outperforming a deep learning\nbaseline while requiring significantly less GPU memory and runtime. PocketVina\noffers a robust and scalable docking strategy that requires no task-specific\ntraining and runs efficiently on standard GPUs, making it well-suited for\nhigh-throughput virtual screening and structure-based drug discovery.", "AI": {"tldr": "PocketVina is a fast, efficient docking framework combining pocket prediction and multi-pocket exploration, achieving state-of-the-art performance in sampling physically valid poses and outperforming deep learning baselines on large-scale datasets.", "motivation": "The challenge of sampling physically valid ligand-binding poses, especially for unseen or diverse targets, motivates the development of PocketVina.", "method": "PocketVina integrates pocket prediction with systematic multi-pocket exploration, evaluated across benchmarks like PDBbind2020, DockGen, Astex, and PoseBusters.", "result": "PocketVina excels in RMSD and physical validity (PB-valid), performs well on diverse targets, and outperforms deep learning baselines on the TargetDock-AI dataset.", "conclusion": "PocketVina provides a robust, scalable docking solution for high-throughput virtual screening, requiring no task-specific training and running efficiently on standard GPUs."}}
{"id": "2506.18330", "pdf": "https://arxiv.org/pdf/2506.18330", "abs": "https://arxiv.org/abs/2506.18330", "authors": ["Lixin Wu", "Na Cai", "Qiao Cheng", "Jiachen Wang", "Yitao Duan"], "title": "Confucius3-Math: A Lightweight High-Performance Reasoning LLM for Chinese K-12 Mathematics Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We introduce Confucius3-Math, an open-source large language model with 14B\nparameters that (1) runs efficiently on a single consumer-grade GPU; (2)\nachieves SOTA performances on a range of mathematical reasoning tasks,\noutperforming many models with significantly larger sizes. In particular, as\npart of our mission to enhancing education and knowledge dissemination with AI,\nConfucius3-Math is specifically committed to mathematics learning for Chinese\nK-12 students and educators. Built via post-training with large-scale\nreinforcement learning (RL), Confucius3-Math aligns with national curriculum\nand excels at solving main-stream Chinese K-12 mathematical problems with low\ncost. In this report we share our development recipe, the challenges we\nencounter and the techniques we develop to overcome them. In particular, we\nintroduce three technical innovations: Targeted Entropy Regularization, Recent\nSample Recovery and Policy-Specific Hardness Weighting. These innovations\nencompass a new entropy regularization, a novel data scheduling policy, and an\nimproved group-relative advantage estimator. Collectively, they significantly\nstabilize the RL training, improve data efficiency, and boost performance. Our\nwork demonstrates the feasibility of building strong reasoning models in a\nparticular domain at low cost. We open-source our model and code at\nhttps://github.com/netease-youdao/Confucius3-Math.", "AI": {"tldr": "Confucius3-Math is a 14B-parameter open-source LLM for math tasks, optimized for Chinese K-12 education, achieving SOTA performance efficiently on consumer GPUs.", "motivation": "To enhance math education for Chinese K-12 students using AI, focusing on affordability and alignment with national curriculum.", "method": "Post-training with large-scale RL, featuring innovations like Targeted Entropy Regularization, Recent Sample Recovery, and Policy-Specific Hardness Weighting.", "result": "Achieves SOTA on math tasks, outperforming larger models, with stable RL training and improved data efficiency.", "conclusion": "Demonstrates feasibility of cost-effective domain-specific reasoning models; model and code are open-sourced."}}
{"id": "2503.23062", "pdf": "https://arxiv.org/pdf/2503.23062", "abs": "https://arxiv.org/abs/2503.23062", "authors": ["Sagi Eppel", "Mor Bismut", "Alona Faktor-Strugatski"], "title": "Shape and Texture Recognition in Large Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Shapes and textures are the basic building blocks of visual perception. The\nability to identify shapes regardless of orientation, texture, or context, and\nto recognize textures and materials independently of their associated objects,\nis essential for a general visual understanding of the world. This work\nintroduces the Large Shape and Textures dataset (LAS&T), a giant collection of\nhighly diverse shapes and textures, created by unsupervised extraction of\npatterns from natural images. This dataset is used to benchmark how effectively\nleading Large Vision-Language Models (LVLMs) understand shapes, textures, and\nmaterials in 2D and 3D scenes. For shape recognition, we test the models'\nability to match images of identical shapes that differ in orientation,\ntexture, color, or environment. Our results show that the shape recognition\ncapabilities of the LVLMs remain significantly below human performance. LVLMs\nrely predominantly on high-level and semantic features and struggle with\nabstract shapes lacking clear class associations. For texture and material\nrecognition, we evaluated the models' ability to identify images with identical\ntextures and materials across different objects and environments.\nInterestingly, leading LVLMs approach human-level performance in recognizing\nmaterials in 3D scenes, yet substantially underperform humans when identifying\nsimpler more abstract 2D textures. These results are consistent across a wide\nrange of leading VLMs (GPT/Gemini/LLama/Qwen) and foundation vision models\n(DINO/CLIP), exposing major deficiencies in the ability of leading models to\nunderstand fundamental visual concepts. In contrast, simple nets trained\ndirectly for these tasks achieve high accuracy. The LAS&T dataset, featuring\nover 600,000 images for 2D/3D shape, texture, and material recognition and\nretrieval, is publicly available.", "AI": {"tldr": "The paper introduces the LAS&T dataset to benchmark LVLMs' understanding of shapes and textures, revealing their limitations compared to humans and simple nets.", "motivation": "To assess how well LVLMs comprehend fundamental visual concepts like shapes and textures, which are crucial for general visual understanding.", "method": "Created the LAS&T dataset via unsupervised extraction from natural images and tested LVLMs on shape and texture recognition tasks.", "result": "LVLMs underperform humans in shape recognition and simpler 2D textures but approach human-level performance in 3D material recognition. Simple nets outperform LVLMs.", "conclusion": "Leading LVLMs have significant deficiencies in understanding basic visual concepts, highlighting a gap in their foundational visual understanding."}}
{"id": "2412.02863", "pdf": "https://arxiv.org/pdf/2412.02863", "abs": "https://arxiv.org/abs/2412.02863", "authors": ["Lucas Nogueira Nobrega", "Ewerton de Oliveira", "Martin Saska", "Tiago Nascimento"], "title": "Proximal Control of UAVs with Federated Learning for Human-Robot Collaborative Domains", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "version 2", "summary": "The human-robot interaction (HRI) is a growing area of research. In HRI,\ncomplex command (action) classification is still an open problem that usually\nprevents the real applicability of such a technique. The literature presents\nsome works that use neural networks to detect these actions. However, occlusion\nis still a major issue in HRI, especially when using uncrewed aerial vehicles\n(UAVs), since, during the robot's movement, the human operator is often out of\nthe robot's field of view. Furthermore, in multi-robot scenarios, distributed\ntraining is also an open problem. In this sense, this work proposes an action\nrecognition and control approach based on Long Short-Term Memory (LSTM) Deep\nNeural Networks with two layers in association with three densely connected\nlayers and Federated Learning (FL) embedded in multiple drones. The FL enabled\nour approach to be trained in a distributed fashion, i.e., access to data\nwithout the need for cloud or other repositories, which facilitates the\nmulti-robot system's learning. Furthermore, our multi-robot approach results\nalso prevented occlusion situations, with experiments with real robots\nachieving an accuracy greater than 96%.", "AI": {"tldr": "The paper addresses occlusion and distributed training challenges in HRI using LSTM and Federated Learning, achieving over 96% accuracy in multi-drone systems.", "motivation": "To solve occlusion issues and distributed training problems in human-robot interaction, especially with UAVs.", "method": "Proposes an LSTM-based deep neural network with densely connected layers and Federated Learning for distributed training in multi-drone systems.", "result": "Achieved over 96% accuracy in experiments with real robots, mitigating occlusion and enabling distributed learning.", "conclusion": "The approach successfully addresses key HRI challenges, demonstrating high accuracy and practical applicability in multi-robot scenarios."}}
{"id": "2506.20048", "pdf": "https://arxiv.org/pdf/2506.20048", "abs": "https://arxiv.org/abs/2506.20048", "authors": ["Sungee Hong", "Jiayi Wang", "Zhengling Qi", "Raymond Ka Wai Wong"], "title": "A Principled Path to Fitted Distributional Evaluation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In reinforcement learning, distributional off-policy evaluation (OPE) focuses\non estimating the return distribution of a target policy using offline data\ncollected under a different policy. This work focuses on extending the widely\nused fitted-Q evaluation -- developed for expectation-based reinforcement\nlearning -- to the distributional OPE setting. We refer to this extension as\nfitted distributional evaluation (FDE). While only a few related approaches\nexist, there remains no unified framework for designing FDE methods. To fill\nthis gap, we present a set of guiding principles for constructing theoretically\ngrounded FDE methods. Building on these principles, we develop several new FDE\nmethods with convergence analysis and provide theoretical justification for\nexisting methods, even in non-tabular environments. Extensive experiments,\nincluding simulations on linear quadratic regulators and Atari games,\ndemonstrate the superior performance of the FDE methods.", "AI": {"tldr": "The paper extends fitted-Q evaluation to distributional off-policy evaluation (OPE), introducing fitted distributional evaluation (FDE) with theoretical principles, new methods, and empirical validation.", "motivation": "Addressing the lack of a unified framework for distributional OPE, the paper aims to extend expectation-based methods to estimate return distributions.", "method": "Proposes fitted distributional evaluation (FDE) with guiding principles, develops new FDE methods, and provides convergence analysis.", "result": "Theoretical justification for existing methods and superior performance in experiments, including linear quadratic regulators and Atari games.", "conclusion": "FDE offers a robust framework for distributional OPE, validated by theory and experiments."}}
{"id": "2506.18871", "pdf": "https://arxiv.org/pdf/2506.18871", "abs": "https://arxiv.org/abs/2506.18871", "authors": ["Chenyuan Wu", "Pengfei Zheng", "Ruiran Yan", "Shitao Xiao", "Xin Luo", "Yueze Wang", "Wanli Li", "Xiyan Jiang", "Yexin Liu", "Junjie Zhou", "Ze Liu", "Ziyi Xia", "Chaofan Li", "Haoge Deng", "Jiahao Wang", "Kun Luo", "Bo Zhang", "Defu Lian", "Xinlong Wang", "Zhongyuan Wang", "Tiejun Huang", "Zheng Liu"], "title": "OmniGen2: Exploration to Advanced Multimodal Generation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "In this work, we introduce OmniGen2, a versatile and open-source generative\nmodel designed to provide a unified solution for diverse generation tasks,\nincluding text-to-image, image editing, and in-context generation. Unlike\nOmniGen v1, OmniGen2 features two distinct decoding pathways for text and image\nmodalities, utilizing unshared parameters and a decoupled image tokenizer. This\ndesign enables OmniGen2 to build upon existing multimodal understanding models\nwithout the need to re-adapt VAE inputs, thereby preserving the original text\ngeneration capabilities. To facilitate the training of OmniGen2, we developed\ncomprehensive data construction pipelines, encompassing image editing and\nin-context generation data. Additionally, we introduce a reflection mechanism\ntailored for image generation tasks and curate a dedicated reflection dataset\nbased on OmniGen2. Despite its relatively modest parameter size, OmniGen2\nachieves competitive results on multiple task benchmarks, including\ntext-to-image and image editing. To further evaluate in-context generation,\nalso referred to as subject-driven tasks, we introduce a new benchmark named\nOmniContext. OmniGen2 achieves state-of-the-art performance among open-source\nmodels in terms of consistency. We will release our models, training code,\ndatasets, and data construction pipeline to support future research in this\nfield. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link:\nhttps://github.com/VectorSpaceLab/OmniGen2", "AI": {"tldr": "OmniGen2 is an open-source generative model for diverse tasks like text-to-image, image editing, and in-context generation, featuring dual decoding pathways and competitive performance.", "motivation": "To unify diverse generation tasks while preserving text generation capabilities and improving upon OmniGen v1.", "method": "Uses two decoding pathways (text/image) with unshared parameters, a decoupled image tokenizer, and introduces reflection mechanisms and new datasets.", "result": "Achieves competitive results on benchmarks like text-to-image and image editing, and state-of-the-art in-context generation on OmniContext.", "conclusion": "OmniGen2 is a versatile, high-performing model with released resources to support future research."}}
{"id": "2504.04494", "pdf": "https://arxiv.org/pdf/2504.04494", "abs": "https://arxiv.org/abs/2504.04494", "authors": ["Marin Ben\u010devi\u0107", "Robert \u0160ojo", "Irena Gali\u0107"], "title": "Skin Color Measurement from Dermatoscopic Images: An Evaluation on a Synthetic Dataset", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents a comprehensive evaluation of skin color measurement\nmethods from dermatoscopic images using a synthetic dataset (S-SYNTH) with\ncontrolled ground-truth melanin content, lesion shapes, hair models, and 18\ndistinct lighting conditions. This allows for rigorous assessment of the\nrobustness and invariance to lighting conditions. We assess four classes of\nimage colorimetry approaches: segmentation-based, patch-based, color\nquantization, and neural networks. We use these methods to estimate the\nIndividual Typology Angle (ITA) and Fitzpatrick types from dermatoscopic\nimages. Our results show that segmentation-based and color quantization methods\nyield robust, lighting-invariant estimates, whereas patch-based approaches\nexhibit significant lighting-dependent biases that require calibration.\nFurthermore, neural network models, particularly when combined with heavy\nblurring to reduce overfitting, can provide light-invariant Fitzpatrick\npredictions, although their generalization to real-world images remains\nunverified. We conclude with practical recommendations for designing fair and\nreliable skin color estimation methods.", "AI": {"tldr": "Evaluation of skin color measurement methods in dermatoscopic images using a synthetic dataset (S-SYNTH) to assess robustness under varying lighting conditions. Segmentation-based and color quantization methods perform best, while patch-based methods require calibration. Neural networks show promise but need further validation.", "motivation": "To rigorously evaluate skin color measurement methods under controlled conditions, ensuring robustness and invariance to lighting for accurate skin color estimation.", "method": "Used a synthetic dataset (S-SYNTH) with controlled variables (melanin, lesion shapes, hair, lighting) to test four approaches: segmentation-based, patch-based, color quantization, and neural networks. Estimated ITA and Fitzpatrick types.", "result": "Segmentation-based and color quantization methods were robust and lighting-invariant. Patch-based methods had lighting-dependent biases. Neural networks, with blurring, showed promise but lacked real-world validation.", "conclusion": "Practical recommendations for fair and reliable skin color estimation methods, emphasizing the need for lighting-invariant approaches and further validation of neural networks."}}
{"id": "2412.03905", "pdf": "https://arxiv.org/pdf/2412.03905", "abs": "https://arxiv.org/abs/2412.03905", "authors": ["Qiong Feng", "Xiaotian Ma", "Jiayi Sheng", "Ziyuan Feng", "Wei Song", "Peng Liang"], "title": "Integrating Various Software Artifacts for Better LLM-based Bug Localization and Program Repair", "categories": ["cs.SE", "cs.AI"], "comment": "25 pages, 12 images, 10 tables, Manuscript revision submitted to a\n  journal (2025)", "summary": "LLMs have garnered considerable attention for their potential to streamline\nAutomated Program Repair (APR). LLM-based approaches can either insert the\ncorrect code or directly generate patches when provided with buggy methods.\nHowever, most of LLM-based APR methods rely on a single type of software\ninformation, without fully leveraging different software artifacts. Despite\nthis, many LLM-based approaches do not explore which specific types of\ninformation best assist in APR. Addressing this gap is crucial for advancing\nLLM-based APR techniques. We propose DEVLoRe to use issue content (description\nand message) and stack error traces to localize buggy methods, then rely on\ndebug information in buggy methods and issue content and stack error to\nlocalize buggy lines and generate plausible patches which can pass all unit\ntests. The results show that while issue content is particularly effective in\nassisting LLMs with fault localization and program repair, different types of\nsoftware artifacts complement each other. By incorporating different artifacts,\nDEVLoRe successfully locates 49.3% and 47.6% of single and non-single buggy\nmethods and generates 56.0% and 14.5% plausible patches for the Defects4J v2.0\ndataset, respectively. This outperforms current state-of-the-art APR methods.\nFurthermore, we re-implemented and evaluated our framework, demonstrating its\neffectiveness in its effectiveness in resolving 9 unique issues compared to\nother state-of-the-art frameworks using the same or more advanced models on\nSWE-bench Lite.We also discussed whether a leading framework for Python code\ncan be directly applied to Java code, or vice versa. The source code and\nexperimental results of this work for replication are available at\nhttps://github.com/XYZboom/DEVLoRe.", "AI": {"tldr": "DEVLoRe leverages multiple software artifacts (issue content, stack error traces, debug info) to improve LLM-based APR, outperforming state-of-the-art methods in fault localization and patch generation.", "motivation": "Current LLM-based APR methods often rely on a single type of software information, missing opportunities to leverage diverse artifacts for better results.", "method": "DEVLoRe uses issue content and stack error traces for bug localization, then combines debug info and issue content to generate patches.", "result": "Achieves 49.3% and 47.6% buggy method localization, and 56.0% and 14.5% plausible patch generation for single and non-single bugs in Defects4J v2.0. Outperforms other APR methods.", "conclusion": "Incorporating diverse software artifacts enhances LLM-based APR, with DEVLoRe demonstrating superior performance and resolving unique issues."}}
{"id": "2506.20056", "pdf": "https://arxiv.org/pdf/2506.20056", "abs": "https://arxiv.org/abs/2506.20056", "authors": ["Yuheng Chen", "Alexander Montes McNeil", "Taehyuk Park", "Blake A. Wilson", "Vaishnavi Iyer", "Michael Bezick", "Jae-Ik Choi", "Rohan Ojha", "Pravin Mahendran", "Daksh Kumar Singh", "Geetika Chitturi", "Peigang Chen", "Trang Do", "Alexander V. Kildishev", "Vladimir M. Shalaev", "Michael Moebius", "Wenshan Cai", "Yongmin Liu", "Alexandra Boltasseva"], "title": "Machine-Learning-Assisted Photonic Device Development: A Multiscale Approach from Theory to Characterization", "categories": ["physics.optics", "cs.LG"], "comment": null, "summary": "Photonic device development (PDD) has achieved remarkable success in\ndesigning and implementing new devices for controlling light across various\nwavelengths, scales, and applications, including telecommunications, imaging,\nsensing, and quantum information processing. PDD is an iterative, five-step\nprocess that consists of: i) deriving device behavior from design parameters,\nii) simulating device performance, iii) finding the optimal candidate designs\nfrom simulations, iv) fabricating the optimal device, and v) measuring device\nperformance. Classically, all these steps involve Bayesian optimization,\nmaterial science, control theory, and direct physics-driven numerical methods.\nHowever, many of these techniques are computationally intractable, monetarily\ncostly, or difficult to implement at scale. In addition, PDD suffers from large\noptimization landscapes, uncertainties in structural or optical\ncharacterization, and difficulties in implementing robust fabrication\nprocesses. However, the advent of machine learning over the past decade has\nprovided novel, data-driven strategies for tackling these challenges, including\nsurrogate estimators for speeding up computations, generative modeling for\nnoisy measurement modeling and data augmentation, reinforcement learning for\nfabrication, and active learning for experimental physical discovery. In this\nreview, we present a comprehensive perspective on these methods to enable\nmachine-learning-assisted PDD (ML-PDD) for efficient design optimization with\npowerful generative models, fast simulation and characterization modeling under\nnoisy measurements, and reinforcement learning for fabrication. This review\nwill provide researchers from diverse backgrounds with valuable insights into\nthis emerging topic, fostering interdisciplinary efforts to accelerate the\ndevelopment of complex photonic devices and systems.", "AI": {"tldr": "The paper reviews machine-learning-assisted photonic device development (ML-PDD) to address computational, cost, and scalability challenges in traditional methods.", "motivation": "Traditional PDD methods are computationally expensive, costly, and difficult to scale, prompting the need for data-driven solutions like machine learning.", "method": "The paper explores ML techniques such as surrogate estimators, generative modeling, reinforcement learning, and active learning to enhance PDD.", "result": "ML-PDD offers efficient design optimization, faster simulations, and improved fabrication processes.", "conclusion": "The review highlights ML's potential to revolutionize PDD, encouraging interdisciplinary collaboration for advanced photonic device development."}}
{"id": "2506.19143", "pdf": "https://arxiv.org/pdf/2506.19143", "abs": "https://arxiv.org/abs/2506.19143", "authors": ["Paul C. Bogdan", "Uzay Macar", "Neel Nanda", "Arthur Conmy"], "title": "Thought Anchors: Which LLM Reasoning Steps Matter?", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Paul C. Bogdan and Uzay Macar contributed equally to this work, and\n  their listed order was determined by coinflip. Neel Nanda and Arthur Conmy\n  contributed equally to this work as senior authors, and their listed order\n  was determined by coinflip", "summary": "Reasoning large language models have recently achieved state-of-the-art\nperformance in many fields. However, their long-form chain-of-thought reasoning\ncreates interpretability challenges as each generated token depends on all\nprevious ones, making the computation harder to decompose. We argue that\nanalyzing reasoning traces at the sentence level is a promising approach to\nunderstanding reasoning processes. We present three complementary attribution\nmethods: (1) a black-box method measuring each sentence's counterfactual\nimportance by comparing final answers across 100 rollouts conditioned on the\nmodel generating that sentence or one with a different meaning; (2) a white-box\nmethod of aggregating attention patterns between pairs of sentences, which\nidentified \"broadcasting\" sentences that receive disproportionate attention\nfrom all future sentences via \"receiver\" attention heads; (3) a causal\nattribution method measuring logical connections between sentences by\nsuppressing attention toward one sentence and measuring the effect on each\nfuture sentence's tokens. Each method provides evidence for the existence of\nthought anchors, reasoning steps that have outsized importance and that\ndisproportionately influence the subsequent reasoning process. These thought\nanchors are typically planning or backtracking sentences. We provide an\nopen-source tool (www.thought-anchors.com) for visualizing the outputs of our\nmethods, and present a case study showing converging patterns across methods\nthat map how a model performs multi-step reasoning. The consistency across\nmethods demonstrates the potential of sentence-level analysis for a deeper\nunderstanding of reasoning models.", "AI": {"tldr": "The paper proposes sentence-level analysis to interpret long-form reasoning in large language models, introducing three attribution methods to identify influential \"thought anchors.\"", "motivation": "Addressing interpretability challenges in long-form chain-of-thought reasoning by decomposing the process at the sentence level.", "method": "Three attribution methods: (1) black-box counterfactual importance, (2) white-box attention pattern aggregation, (3) causal attribution via attention suppression.", "result": "Identified \"thought anchors\"\u2014key reasoning steps (e.g., planning or backtracking sentences) with outsized influence on subsequent reasoning.", "conclusion": "Sentence-level analysis, supported by consistent findings across methods, offers deeper understanding of reasoning models, with tools provided for visualization."}}
{"id": "2504.05623", "pdf": "https://arxiv.org/pdf/2504.05623", "abs": "https://arxiv.org/abs/2504.05623", "authors": ["Mahmoud Afifi", "Luxi Zhao", "Abhijith Punnappurath", "Mohammed A. Abdelsalam", "Ran Zhang", "Michael S. Brown"], "title": "Time-Aware Auto White Balance in Mobile Photography", "categories": ["cs.CV"], "comment": null, "summary": "Cameras rely on auto white balance (AWB) to correct undesirable color casts\ncaused by scene illumination and the camera's spectral sensitivity. This is\ntypically achieved using an illuminant estimator that determines the global\ncolor cast solely from the color information in the camera's raw sensor image.\nMobile devices provide valuable additional metadata-such as capture timestamp\nand geolocation-that offers strong contextual clues to help narrow down the\npossible illumination solutions. This paper proposes a lightweight illuminant\nestimation method that incorporates such contextual metadata, along with\nadditional capture information and image colors, into a compact model (~5K\nparameters), achieving promising results, matching or surpassing larger models.\nTo validate our method, we introduce a dataset of 3,224 smartphone images with\ncontextual metadata collected at various times of day and under diverse\nlighting conditions. The dataset includes ground-truth illuminant colors,\ndetermined using a color chart, and user-preferred illuminants validated\nthrough a user study, providing a comprehensive benchmark for AWB evaluation.", "AI": {"tldr": "A lightweight illuminant estimation method for auto white balance (AWB) uses contextual metadata and image colors, achieving results comparable to larger models. A dataset of 3,224 smartphone images with ground-truth and user-preferred illuminants is introduced for validation.", "motivation": "Improving AWB by leveraging contextual metadata (e.g., timestamp, geolocation) and image colors to correct color casts caused by illumination and camera sensitivity.", "method": "Proposes a compact model (~5K parameters) incorporating contextual metadata, capture information, and image colors for illuminant estimation.", "result": "The method matches or surpasses larger models, demonstrating effectiveness. A dataset with ground-truth and user-preferred illuminants is provided for benchmarking.", "conclusion": "The lightweight model successfully integrates contextual metadata for accurate AWB, validated by a comprehensive dataset."}}
{"id": "2412.12587", "pdf": "https://arxiv.org/pdf/2412.12587", "abs": "https://arxiv.org/abs/2412.12587", "authors": ["Qinyu Zhang", "Liang Xu", "Jianhao Huang", "Tao Yang", "Jian Jiao", "Ye Wang", "Yao Shi", "Chiya Zhang", "Xingjian Zhang", "Ke Zhang", "Yupeng Gong", "Na Deng", "Nan Zhao", "Zhen Gao", "Shujun Han", "Xiaodong Xu", "Li You", "Dongming Wang", "Shan Jiang", "Dixian Zhao", "Nan Zhang", "Liujun Hu", "Xiongwen He", "Yonghui Li", "Xiqi Gao", "Xiaohu You"], "title": "Distributed satellite information networks: Architecture, enabling technologies, and trends", "categories": ["cs.IT", "cs.AI", "cs.NI", "math.IT"], "comment": null, "summary": "Driven by the vision of ubiquitous connectivity and wireless intelligence,\nthe evolution of ultra-dense constellation-based satellite-integrated Internet\nis underway, now taking preliminary shape. Nevertheless, the entrenched\ninstitutional silos and limited, nonrenewable heterogeneous network resources\nleave current satellite systems struggling to accommodate the escalating\ndemands of next-generation intelligent applications. In this context, the\ndistributed satellite information networks (DSIN), exemplified by the cohesive\nclustered satellites system, have emerged as an innovative architecture,\nbridging information gaps across diverse satellite systems, such as\ncommunication, navigation, and remote sensing, and establishing a unified, open\ninformation network paradigm to support resilient space information services.\nThis survey first provides a profound discussion about innovative network\narchitectures of DSIN, encompassing distributed regenerative satellite network\narchitecture, distributed satellite computing network architecture, and\nreconfigurable satellite formation flying, to enable flexible and scalable\ncommunication, computing and control. The DSIN faces challenges from network\nheterogeneity, unpredictable channel dynamics, sparse resources, and\ndecentralized collaboration frameworks. To address these issues, a series of\nenabling technologies is identified, including channel modeling and estimation,\ncloud-native distributed MIMO cooperation, grant-free massive access, network\nrouting, and the proper combination of all these diversity techniques.\nFurthermore, to heighten the overall resource efficiency, the cross-layer\noptimization techniques are further developed to meet upper-layer\ndeterministic, adaptive and secure information services requirements. In\naddition, emerging research directions and new opportunities are highlighted on\nthe way to achieving the DSIN vision.", "AI": {"tldr": "The paper discusses the evolution of distributed satellite information networks (DSIN) to address challenges in satellite-integrated Internet, proposing innovative architectures and enabling technologies for resilient space services.", "motivation": "Current satellite systems struggle with institutional silos and limited resources, failing to meet next-gen intelligent application demands. DSIN aims to unify diverse satellite systems for better connectivity.", "method": "The survey explores DSIN architectures like distributed regenerative satellite networks and reconfigurable satellite formations, alongside enabling technologies such as channel modeling and cloud-native MIMO cooperation.", "result": "DSIN offers flexible, scalable communication and computing solutions, though challenges like network heterogeneity and sparse resources persist. Cross-layer optimization enhances resource efficiency.", "conclusion": "DSIN presents a promising paradigm for resilient space services, with ongoing research needed to address challenges and unlock new opportunities."}}
{"id": "2506.20082", "pdf": "https://arxiv.org/pdf/2506.20082", "abs": "https://arxiv.org/abs/2506.20082", "authors": ["Yali Yuan", "Weiyi Zou", "Guang Cheng"], "title": "Attack Smarter: Attention-Driven Fine-Grained Webpage Fingerprinting Attacks", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Website Fingerprinting (WF) attacks aim to infer which websites a user is\nvisiting by analyzing traffic patterns, thereby compromising user anonymity.\nAlthough this technique has been demonstrated to be effective in controlled\nexperimental environments, it remains largely limited to small-scale scenarios,\ntypically restricted to recognizing website homepages. In practical settings,\nhowever, users frequently access multiple subpages in rapid succession, often\nbefore previous content fully loads. WebPage Fingerprinting (WPF) generalizes\nthe WF framework to large-scale environments by modeling subpages of the same\nsite as distinct classes. These pages often share similar page elements,\nresulting in lower inter-class variance in traffic features. Furthermore, we\nconsider multi-tab browsing scenarios, in which a single trace encompasses\nmultiple categories of webpages. This leads to overlapping traffic segments,\nand similar features may appear in different positions within the traffic,\nthereby increasing the difficulty of classification. To address these\nchallenges, we propose an attention-driven fine-grained WPF attack, named\nADWPF. Specifically, during the training phase, we apply targeted augmentation\nto salient regions of the traffic based on attention maps, including attention\ncropping and attention masking. ADWPF then extracts low-dimensional features\nfrom both the original and augmented traffic and applies self-attention modules\nto capture the global contextual patterns of the trace. Finally, to handle the\nmulti-tab scenario, we employ the residual attention to generate class-specific\nrepresentations of webpages occurring at different temporal positions.\nExtensive experiments demonstrate that the proposed method consistently\nsurpasses state-of-the-art baselines across datasets of different scales.", "AI": {"tldr": "The paper introduces ADWPF, an attention-driven fine-grained WebPage Fingerprinting attack, to address challenges in large-scale scenarios and multi-tab browsing, outperforming existing methods.", "motivation": "Website Fingerprinting (WF) attacks are limited to small-scale scenarios and struggle with subpages and multi-tab browsing. The paper aims to generalize WF to large-scale environments and handle overlapping traffic segments.", "method": "Proposes ADWPF, which uses attention-driven augmentation (cropping and masking), extracts low-dimensional features, and employs self-attention modules to capture global patterns. Residual attention handles multi-tab scenarios.", "result": "ADWPF consistently outperforms state-of-the-art baselines across datasets of varying scales.", "conclusion": "ADWPF effectively addresses the limitations of WF in large-scale and multi-tab settings, demonstrating superior performance."}}
{"id": "2504.06185", "pdf": "https://arxiv.org/pdf/2504.06185", "abs": "https://arxiv.org/abs/2504.06185", "authors": ["Vanessa Borst", "Timo Dittus", "Tassilo Dege", "Astrid Schmieder", "Samuel Kounev"], "title": "WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care", "categories": ["cs.CV", "cs.AI"], "comment": "Main paper: 18 pages; supplementary material: 15 pages; the paper has\n  been accepted for publication at the Applied Data Science (ADS) track of the\n  European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases (ECML PKDD 2025)", "summary": "Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For a fair comparison,\nwe standardize training, data augmentation, and evaluation, conducting\ncross-validation to minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates and evaluate this, along with mask\nquality, for the five best architectures based on physician assessments.\nOverall, the transformer-based TransNeXt showed the highest levels of\ngeneralizability. Despite variations in inference times, all models processed\nat least one image per second on the CPU, which is deemed adequate for the\nintended application. Interpretability analysis typically revealed prominent\nactivations in wound regions, emphasizing focus on clinically relevant\nfeatures. Expert evaluation showed high mask approval for all analyzed models,\nwith VWFormer and ConvNeXtS backbone performing the best. Size retrieval\naccuracy was similar across models, and predictions closely matched expert\nannotations. Finally, we demonstrate how our AI-driven wound size estimation\nframework, WoundAmbit, is integrated into a custom telehealth system.", "AI": {"tldr": "The paper benchmarks deep learning models for wound segmentation, evaluates their real-world applicability, and introduces a framework for AI-driven wound size estimation in telehealth.", "motivation": "Chronic wounds are a significant health issue, especially for the elderly and diabetic patients, but automated monitoring via semantic segmentation is under-researched in medical imaging.", "method": "The study standardizes training, data augmentation, and evaluation of state-of-the-art deep learning models, including cross-validation and real-world deployment tests. It also proposes a reference object-based approach for wound size estimation.", "result": "TransNeXt showed the highest generalizability, while VWFormer and ConvNeXtS performed best in mask quality. All models met computational efficiency requirements, and size predictions matched expert annotations.", "conclusion": "The AI-driven framework, WoundAmbit, is viable for telehealth integration, offering accurate wound monitoring and reducing the need for in-person visits."}}
{"id": "2501.05928", "pdf": "https://arxiv.org/pdf/2501.05928", "abs": "https://arxiv.org/abs/2501.05928", "authors": ["Xiaoyun Xu", "Zhuoran Liu", "Stefanos Koffas", "Stjepan Picek"], "title": "Towards Backdoor Stealthiness in Model Parameter Space", "categories": ["cs.CR", "cs.AI"], "comment": "to appear at CCS 2025", "summary": "Recent research on backdoor stealthiness focuses mainly on indistinguishable\ntriggers in input space and inseparable backdoor representations in feature\nspace, aiming to circumvent backdoor defenses that examine these respective\nspaces. However, existing backdoor attacks are typically designed to resist a\nspecific type of backdoor defense without considering the diverse range of\ndefense mechanisms. Based on this observation, we pose a natural question: Are\ncurrent backdoor attacks truly a real-world threat when facing diverse\npractical defenses?\n  To answer this question, we examine 12 common backdoor attacks that focus on\ninput-space or feature-space stealthiness and 17 diverse representative\ndefenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks\ndesigned to be stealthy in input and feature spaces can be mitigated by\nexamining backdoored models in parameter space. To investigate the underlying\ncauses behind this common vulnerability, we study the characteristics of\nbackdoor attacks in the parameter space. Notably, we find that input- and\nfeature-space attacks introduce prominent backdoor-related neurons in parameter\nspace, which are not thoroughly considered by current backdoor attacks. Taking\ncomprehensive stealthiness into account, we propose a novel supply-chain attack\ncalled Grond. Grond limits the parameter changes by a simple yet effective\nmodule, Adversarial Backdoor Injection (ABI), which adaptively increases the\nparameter-space stealthiness during the backdoor injection. Extensive\nexperiments demonstrate that Grond outperforms all 12 backdoor attacks against\nstate-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset\nof ImageNet. In addition, we show that ABI consistently improves the\neffectiveness of common backdoor attacks.", "AI": {"tldr": "The paper questions the real-world threat of current backdoor attacks against diverse defenses, revealing a blind spot in parameter space. It proposes Grond, a supply-chain attack with Adversarial Backdoor Injection (ABI), to enhance stealthiness across input, feature, and parameter spaces.", "motivation": "To assess if current backdoor attacks are truly threatening given diverse defenses, and to address their vulnerability in parameter space.", "method": "Examines 12 backdoor attacks and 17 defenses, identifies parameter-space vulnerabilities, and introduces Grond with ABI for adaptive stealthiness.", "result": "Grond outperforms existing attacks against state-of-the-art defenses, and ABI improves common attacks' effectiveness.", "conclusion": "Parameter-space stealthiness is critical; Grond and ABI offer robust solutions against diverse defenses."}}
{"id": "2506.20102", "pdf": "https://arxiv.org/pdf/2506.20102", "abs": "https://arxiv.org/abs/2506.20102", "authors": ["Malikussaid", "Sutiyo"], "title": "Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox", "categories": ["cs.CR", "cs.LG", "cs.SY", "eess.SY"], "comment": "17 pages, 2 figures, 4 equations, 2 algorithms, 4 tables, to be\n  published in ISPACS Conference 2025, unabridged version", "summary": "The convergence of IT and OT has created hyper-connected ICS, exposing\ncritical infrastructure to a new class of adaptive, intelligent adversaries\nthat render static defenses obsolete. Existing security paradigms often fail to\naddress a foundational \"Trinity of Trust,\" comprising the fidelity of the\nsystem model, the integrity of synchronizing data, and the resilience of the\nanalytical engine against sophisticated evasion. This paper introduces the ARC\nframework, a method for achieving analytical resilience through an autonomous,\nclosed-loop hardening process. ARC establishes a perpetual co-evolutionary arms\nrace within the high-fidelity sandbox of a F-SCDT. A DRL agent, the \"Red\nAgent,\" is formalized and incentivized to autonomously discover stealthy,\nphysically-plausible attack paths that maximize process disruption while\nevading detection. Concurrently, an ensemble-based \"Blue Agent\" defender is\ncontinuously hardened via adversarial training against the evolving threats\ndiscovered by its adversary. This co-evolutionary dynamic forces both agents to\nbecome progressively more sophisticated, enabling the system to autonomously\nprobe and patch its own vulnerabilities. Experimental validation on both the\nTEP and the SWaT testbeds demonstrates the framework's superior performance. A\ncomprehensive ablation study, supported by extensive visualizations including\nROC curves and SHAP plots, reveals that the co-evolutionary process itself is\nresponsible for a significant performance increase in detecting novel attacks.\nBy integrating XAI to ensure operator trust and proposing a scalable F-ARC\narchitecture, this work presents ARC not merely as an improvement, but as a\nnecessary paradigm shift toward dynamic, self-improving security for the future\nof critical infrastructure.", "AI": {"tldr": "The paper introduces the ARC framework, a co-evolutionary method for enhancing ICS security by autonomously hardening defenses against adaptive adversaries.", "motivation": "The convergence of IT and OT exposes critical infrastructure to intelligent adversaries, rendering static defenses ineffective. Existing paradigms fail to address trust in system models, data integrity, and analytical resilience.", "method": "ARC uses a closed-loop process with a 'Red Agent' (DRL-based attacker) and 'Blue Agent' (ensemble-based defender) that co-evolve in a high-fidelity sandbox (F-SCDT). The framework is validated on TEP and SWaT testbeds.", "result": "ARC shows superior performance in detecting novel attacks, with co-evolution significantly improving detection. Visualizations (ROC curves, SHAP plots) and ablation studies support these findings.", "conclusion": "ARC represents a paradigm shift toward dynamic, self-improving security for critical infrastructure, integrating XAI for operator trust and proposing a scalable F-ARC architecture."}}
{"id": "2504.10035", "pdf": "https://arxiv.org/pdf/2504.10035", "abs": "https://arxiv.org/abs/2504.10035", "authors": ["Thomas Gossard", "Andreas Ziegler", "Andreas Zell"], "title": "TT3D: Table Tennis 3D Reconstruction", "categories": ["cs.CV"], "comment": "Accepted to CVSport 2025", "summary": "Sports analysis requires processing large amounts of data, which is\ntime-consuming and costly. Advancements in neural networks have significantly\nalleviated this burden, enabling highly accurate ball tracking in sports\nbroadcasts. However, relying solely on 2D ball tracking is limiting, as it\ndepends on the camera's viewpoint and falls short of supporting comprehensive\ngame analysis. To address this limitation, we propose a novel approach for\nreconstructing precise 3D ball trajectories from online table tennis match\nrecordings. Our method leverages the underlying physics of the ball's motion to\nidentify the bounce state that minimizes the reprojection error of the ball's\nflying trajectory, hence ensuring an accurate and reliable 3D reconstruction. A\nkey advantage of our approach is its ability to infer ball spin without relying\non human pose estimation or racket tracking, which are often unreliable or\nunavailable in broadcast footage. We developed an automated camera calibration\nmethod capable of reliably tracking camera movements. Additionally, we adapted\nan existing 3D pose estimation model, which lacks depth motion capture, to\naccurately track player movements. Together, these contributions enable the\nfull 3D reconstruction of a table tennis rally.", "AI": {"tldr": "A novel method for 3D ball trajectory reconstruction in table tennis using physics-based motion analysis and automated camera calibration, enabling spin inference and player movement tracking.", "motivation": "2D ball tracking in sports broadcasts is limited by camera viewpoint and lacks depth, hindering comprehensive game analysis.", "method": "Leverages ball motion physics to minimize reprojection error, uses automated camera calibration, and adapts a 3D pose estimation model for player tracking.", "result": "Accurate 3D reconstruction of ball trajectories and spin inference without relying on unreliable human pose or racket tracking.", "conclusion": "The approach enables comprehensive 3D analysis of table tennis rallies, overcoming limitations of 2D tracking."}}
{"id": "2501.19195", "pdf": "https://arxiv.org/pdf/2501.19195", "abs": "https://arxiv.org/abs/2501.19195", "authors": ["Eug\u00e8ne Berta", "David Holzm\u00fcller", "Michael I. Jordan", "Francis Bach"], "title": "Rethinking Early Stopping: Refine, Then Calibrate", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine learning classifiers often produce probabilistic predictions that are\ncritical for accurate and interpretable decision-making in various domains. The\nquality of these predictions is generally evaluated with proper losses, such as\ncross-entropy, which decompose into two components: calibration error assesses\ngeneral under/overconfidence, while refinement error measures the ability to\ndistinguish different classes. In this paper, we present a novel variational\nformulation of the calibration-refinement decomposition that sheds new light on\npost-hoc calibration, and enables rapid estimation of the different terms.\nEquipped with this new perspective, we provide theoretical and empirical\nevidence that calibration and refinement errors are not minimized\nsimultaneously during training. Selecting the best epoch based on validation\nloss thus leads to a compromise point that is suboptimal for both terms. To\naddress this, we propose minimizing refinement error only during training\n(Refine,...), before minimizing calibration error post hoc, using standard\ntechniques (...then Calibrate). Our method integrates seamlessly with any\nclassifier and consistently improves performance across diverse classification\ntasks.", "AI": {"tldr": "The paper introduces a variational formulation for calibration-refinement decomposition, showing calibration and refinement errors aren't minimized simultaneously during training. It proposes a two-step method: refine first, then calibrate post hoc, improving classifier performance.", "motivation": "To address the suboptimal compromise between calibration and refinement errors during training, aiming for better probabilistic prediction quality.", "method": "A novel variational formulation for calibration-refinement decomposition, followed by a two-step training approach: refine during training, then calibrate post hoc.", "result": "The method consistently improves performance across diverse classification tasks by optimizing refinement and calibration separately.", "conclusion": "Separating refinement and calibration steps enhances classifier performance, offering a practical solution to the trade-off between the two errors."}}
{"id": "2506.20114", "pdf": "https://arxiv.org/pdf/2506.20114", "abs": "https://arxiv.org/abs/2506.20114", "authors": ["Brian Liu", "Rahul Mazumder", "Peter Radchenko"], "title": "Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Tree ensembles are non-parametric methods widely recognized for their\naccuracy and ability to capture complex interactions. While these models excel\nat prediction, they are difficult to interpret and may fail to uncover useful\nrelationships in the data. We propose an estimator to extract compact sets of\ndecision rules from tree ensembles. The extracted models are accurate and can\nbe manually examined to reveal relationships between the predictors and the\nresponse. A key novelty of our estimator is the flexibility to jointly control\nthe number of rules extracted and the interaction depth of each rule, which\nimproves accuracy. We develop a tailored exact algorithm to efficiently solve\noptimization problems underlying our estimator and an approximate algorithm for\ncomputing regularization paths, sequences of solutions that correspond to\nvarying model sizes. We also establish novel non-asymptotic prediction error\nbounds for our proposed approach, comparing it to an oracle that chooses the\nbest data-dependent linear combination of the rules in the ensemble subject to\nthe same complexity constraint as our estimator. The bounds illustrate that the\nlarge-sample predictive performance of our estimator is on par with that of the\noracle. Through experiments, we demonstrate that our estimator outperforms\nexisting algorithms for rule extraction.", "AI": {"tldr": "Proposes an estimator to extract compact decision rules from tree ensembles, improving interpretability and accuracy with flexible control over rule complexity.", "motivation": "Tree ensembles are accurate but hard to interpret; this work aims to uncover useful relationships in the data by extracting interpretable rules.", "method": "Develops an estimator with exact and approximate algorithms to control rule number and interaction depth, along with non-asymptotic error bounds.", "result": "The estimator matches oracle performance in large samples and outperforms existing rule extraction methods in experiments.", "conclusion": "The proposed method successfully balances interpretability and accuracy, offering a practical solution for analyzing tree ensembles."}}
{"id": "2504.17224", "pdf": "https://arxiv.org/pdf/2504.17224", "abs": "https://arxiv.org/abs/2504.17224", "authors": ["Zhifeng Wang", "Qixuan Zhang", "Peter Zhang", "Wenjia Niu", "Kaihao Zhang", "Ramesh Sankaranarayana", "Sabrina Caldwell", "Tom Gedeon"], "title": "Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition", "categories": ["cs.CV"], "comment": "14 pages, 14 figures", "summary": "Vision Large Language Models (VLLMs) exhibit promising potential for\nmulti-modal understanding, yet their application to video-based emotion\nrecognition remains limited by insufficient spatial and contextual awareness.\nTraditional approaches, which prioritize isolated facial features, often\nneglect critical non-verbal cues such as body language, environmental context,\nand social interactions, leading to reduced robustness in real-world scenarios.\nTo address this gap, we propose Set-of-Vision-Text Prompting (SoVTP), a novel\nframework that enhances zero-shot emotion recognition by integrating spatial\nannotations (e.g., bounding boxes, facial landmarks), physiological signals\n(facial action units), and contextual cues (body posture, scene dynamics,\nothers' emotions) into a unified prompting strategy. SoVTP preserves holistic\nscene information while enabling fine-grained analysis of facial muscle\nmovements and interpersonal dynamics. Extensive experiments show that SoVTP\nachieves substantial improvements over existing visual prompting methods,\ndemonstrating its effectiveness in enhancing VLLMs' video emotion recognition\ncapabilities.", "AI": {"tldr": "SoVTP enhances VLLMs for video emotion recognition by integrating spatial, physiological, and contextual cues into a unified prompting framework, outperforming traditional methods.", "motivation": "Current VLLMs lack spatial and contextual awareness for video emotion recognition, often ignoring non-verbal cues like body language and social interactions.", "method": "Proposes Set-of-Vision-Text Prompting (SoVTP), combining spatial annotations, physiological signals, and contextual cues into a unified prompting strategy.", "result": "SoVTP significantly improves zero-shot emotion recognition, outperforming existing visual prompting methods.", "conclusion": "SoVTP effectively enhances VLLMs' video emotion recognition by preserving holistic scene information and enabling fine-grained analysis."}}
{"id": "2502.00757", "pdf": "https://arxiv.org/pdf/2502.00757", "abs": "https://arxiv.org/abs/2502.00757", "authors": ["J Rosser", "Jakob Nicolaus Foerster"], "title": "AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds via Self-Improvement", "categories": ["cs.CR", "cs.AI", "cs.NE", "68T42, 68T50", "I.2.11"], "comment": null, "summary": "Scaffolding Large Language Models (LLMs) into multi-agent systems often\nimproves performance on complex tasks, but the safety impact of such scaffolds\nhas not been thoroughly explored. We introduce AgentBreeder, a framework for\nmulti-objective self-improving evolutionary search over scaffolds. We evaluate\ndiscovered scaffolds on widely recognized reasoning, mathematics, and safety\nbenchmarks and compare them with popular baselines. In 'blue' mode, we see a\n79.4% average uplift in safety benchmark performance while maintaining or\nimproving capability scores. In 'red' mode, we find adversarially weak\nscaffolds emerging concurrently with capability optimization. Our work\ndemonstrates the risks of multi-agent scaffolding and provides a framework for\nmitigating them. Code is available at\nhttps://github.com/J-Rosser-UK/AgentBreeder.", "AI": {"tldr": "AgentBreeder is a framework for evolutionary search over scaffolds in multi-agent LLM systems, improving safety and capability, but revealing adversarial risks.", "motivation": "To explore the safety impact of scaffolding LLMs into multi-agent systems, which is underexplored despite performance benefits.", "method": "Introduces AgentBreeder, a multi-objective self-improving evolutionary search framework for scaffolds, evaluated on reasoning, math, and safety benchmarks.", "result": "In 'blue' mode, 79.4% safety uplift; in 'red' mode, adversarial scaffolds emerge. Capability scores are maintained or improved.", "conclusion": "Highlights risks of multi-agent scaffolding and offers a mitigation framework."}}
{"id": "2506.20139", "pdf": "https://arxiv.org/pdf/2506.20139", "abs": "https://arxiv.org/abs/2506.20139", "authors": ["Jiayong Qin", "Xianyu Zhu", "Qiyu Liu", "Guangyi Zhang", "Zhigang Cai", "Jianwei Liao", "Sha Hu", "Jingshu Peng", "Yingxia Shao", "Lei Chen"], "title": "Piecewise Linear Approximation in Learned Index Structures: Theoretical and Empirical Analysis", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "A growing trend in the database and system communities is to augment\nconventional index structures, such as B+-trees, with machine learning (ML)\nmodels. Among these, error-bounded Piecewise Linear Approximation\n($\\epsilon$-PLA) has emerged as a popular choice due to its simplicity and\neffectiveness. Despite its central role in many learned indexes, the design and\nanalysis of $\\epsilon$-PLA fitting algorithms remain underexplored. In this\npaper, we revisit $\\epsilon$-PLA from both theoretical and empirical\nperspectives, with a focus on its application in learned index structures. We\nfirst establish a fundamentally improved lower bound of $\\Omega(\\kappa \\cdot\n\\epsilon^2)$ on the expected segment coverage for existing $\\epsilon$-PLA\nfitting algorithms, where $\\kappa$ is a data-dependent constant. We then\npresent a comprehensive benchmark of state-of-the-art $\\epsilon$-PLA algorithms\nwhen used in different learned data structures. Our results highlight key\ntrade-offs among model accuracy, model size, and query performance, providing\nactionable guidelines for the principled design of future learned data\nstructures.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.12434", "pdf": "https://arxiv.org/pdf/2505.12434", "abs": "https://arxiv.org/abs/2505.12434", "authors": ["Qi Wang", "Yanrui Yu", "Ye Yuan", "Rui Mao", "Tianfei Zhou"], "title": "VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning", "categories": ["cs.CV"], "comment": "Code: https://github.com/QiWang98/VideoRFT", "summary": "Reinforcement fine-tuning (RFT) has shown great promise in achieving\nhumanlevel reasoning capabilities of Large Language Models (LLMs), and has\nrecently been extended to MLLMs. Nevertheless, reasoning about videos, which is\na fundamental aspect of human intelligence, remains a persistent challenge due\nto the complex logic, temporal and causal structures inherent in video data. To\nfill this gap, we propose VIDEORFT, a novel approach that extends the RFT\nparadigm to cultivate human-like video reasoning capabilities in MLLMs.\nVIDEORFT follows the standard two-stage scheme in RFT: supervised fine-tuning\n(SFT) with chain-of-thought (CoT) annotations, followed by reinforcement\nlearning (RL) to improve generalization. A central challenge to achieve this in\nthe video domain lies in the scarcity of large-scale, high-quality video CoT\ndatasets. We address this by building a fully automatic CoT curation pipeline.\nFirst, we devise a cognitioninspired prompting strategy to elicit a reasoning\nLLM to generate preliminary CoTs based solely on rich, structured, and literal\nrepresentations of video content. Subsequently, these CoTs are revised by a\nvisual-language model conditioned on the actual video, ensuring visual\nconsistency and reducing visual hallucinations. This pipeline results in two\nnew datasets - VideoRFT-CoT-102K for SFT and VideoRFT-RL-310K for RL. To\nfurther strengthen the RL phase, we introduce a novel semantic-consistency\nreward that explicitly promotes the alignment between textual reasoning and\nvisual evidence. This reward encourages the model to produce coherent,\ncontext-aware reasoning outputs grounded in visual input. Extensive experiments\nshow that VIDEORFT achieves state-of-the-art performance on six video reasoning\nbenchmarks.", "AI": {"tldr": "VIDEORFT extends reinforcement fine-tuning (RFT) to MLLMs for video reasoning, using a two-stage approach (SFT + RL) and a novel CoT curation pipeline to address dataset scarcity. It achieves SOTA results on benchmarks.", "motivation": "Video reasoning remains challenging due to complex logic and temporal structures. Existing RFT methods lack large-scale video CoT datasets.", "method": "Two-stage RFT: SFT with CoT annotations, followed by RL. Introduces an automatic CoT curation pipeline and a semantic-consistency reward for RL.", "result": "VIDEORFT achieves state-of-the-art performance on six video reasoning benchmarks.", "conclusion": "VIDEORFT successfully extends RFT to video reasoning, addressing dataset scarcity and improving generalization, setting a new benchmark for MLLMs."}}
{"id": "2502.01633", "pdf": "https://arxiv.org/pdf/2502.01633", "abs": "https://arxiv.org/abs/2502.01633", "authors": ["Mahdi Sabbaghi", "Paul Kassianik", "George Pappas", "Yaron Singer", "Amin Karbasi", "Hamed Hassani"], "title": "Adversarial Reasoning at Jailbreaking Time", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "As large language models (LLMs) are becoming more capable and widespread, the\nstudy of their failure cases is becoming increasingly important. Recent\nadvances in standardizing, measuring, and scaling test-time compute suggest new\nmethodologies for optimizing models to achieve high performance on hard tasks.\nIn this paper, we apply these advances to the task of model jailbreaking:\neliciting harmful responses from aligned LLMs. We develop an adversarial\nreasoning approach to automatic jailbreaking that leverages a loss signal to\nguide the test-time compute, achieving SOTA attack success rates against many\naligned LLMs, even those that aim to trade inference-time compute for\nadversarial robustness. Our approach introduces a new paradigm in understanding\nLLM vulnerabilities, laying the foundation for the development of more robust\nand trustworthy AI systems.", "AI": {"tldr": "The paper introduces an adversarial reasoning approach to jailbreak aligned LLMs, achieving state-of-the-art success rates and advancing the understanding of LLM vulnerabilities.", "motivation": "To study LLM failure cases and improve adversarial robustness by addressing jailbreaking vulnerabilities.", "method": "Develops an adversarial reasoning approach using a loss signal to guide test-time compute for automatic jailbreaking.", "result": "Achieves SOTA attack success rates against aligned LLMs, including those designed for adversarial robustness.", "conclusion": "The work advances understanding of LLM vulnerabilities, aiding the development of more robust and trustworthy AI systems."}}
{"id": "2506.20141", "pdf": "https://arxiv.org/pdf/2506.20141", "abs": "https://arxiv.org/abs/2506.20141", "authors": ["Xiaoyu Li", "Zhao Song", "Jiahao Zhang"], "title": "Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data", "categories": ["cs.DS", "cs.CY", "cs.DL", "cs.IR", "cs.LG"], "comment": null, "summary": "The explosive growth of AI research has driven paper submissions at flagship\nAI conferences to unprecedented levels, necessitating many venues in 2025\n(e.g., CVPR, ICCV, KDD, AAAI, IJCAI, WSDM) to enforce strict per-author\nsubmission limits and to desk-reject any excess papers by simple ID order.\nWhile this policy helps reduce reviewer workload, it may unintentionally\ndiscard valuable papers and penalize authors' efforts. In this paper, we ask an\nessential research question on whether it is possible to follow submission\nlimits while minimizing needless rejections. We first formalize the current\ndesk-rejection policies as an optimization problem, and then develop a\npractical algorithm based on linear programming relaxation and a rounding\nscheme. Under extensive evaluation on 11 years of real-world ICLR\n(International Conference on Learning Representations) data, our method\npreserves up to $19.23\\%$ more papers without violating any author limits.\nMoreover, our algorithm is highly efficient in practice, with all results on\nICLR data computed within at most 53.64 seconds. Our work provides a simple and\npractical desk-rejection strategy that significantly reduces unnecessary\nrejections, demonstrating strong potential to improve current CS conference\nsubmission policies.", "AI": {"tldr": "The paper proposes an algorithm to minimize unnecessary desk-rejections in AI conferences while adhering to submission limits, preserving up to 19.23% more papers efficiently.", "motivation": "The strict desk-rejection policies in AI conferences may discard valuable work and penalize authors, prompting the need for a fairer solution.", "method": "Formalizes the problem as an optimization task, using linear programming relaxation and a rounding scheme to develop a practical algorithm.", "result": "Evaluated on 11 years of ICLR data, the method preserves 19.23% more papers without violating limits, with computations taking \u226453.64 seconds.", "conclusion": "The algorithm offers a simple, efficient strategy to reduce unnecessary rejections, improving current conference submission policies."}}
{"id": "2505.12758", "pdf": "https://arxiv.org/pdf/2505.12758", "abs": "https://arxiv.org/abs/2505.12758", "authors": ["Matias Quintana", "Youlong Gu", "Xiucheng Liang", "Yujun Hou", "Koichi Ito", "Yihan Zhu", "Mahmoud Abdelrahman", "Filip Biljecki"], "title": "It's not you, it's me -- Global urban visual perception varies across demographics and personalities", "categories": ["cs.CV", "cs.LG"], "comment": "Under review", "summary": "Understanding people's preferences and needs is crucial for urban planning\ndecisions, yet current approaches often combine them from multi-cultural and\nmulti-city populations, obscuring important demographic differences and risking\namplifying biases. We conducted a large-scale urban visual perception survey of\nstreetscapes worldwide using street view imagery, examining how demographics --\nincluding gender, age, income, education, race and ethnicity, and, for the\nfirst time, personality traits -- shape perceptions among 1,000 participants,\nwith balanced demographics, from five countries and 45 nationalities. This\ndataset, introduced as Street Perception Evaluation Considering Socioeconomics\n(SPECS), exhibits statistically significant differences in perception scores in\nsix traditionally used indicators (safe, lively, wealthy, beautiful, boring,\nand depressing) and four new ones we propose (live nearby, walk, cycle, green)\namong demographics and personalities. We revealed that location-based\nsentiments are carried over in people's preferences when comparing urban\nstreetscapes with other cities. Further, we compared the perception scores\nbased on where participants and streetscapes are from. We found that an\noff-the-shelf machine learning model trained on an existing global perception\ndataset tends to overestimate positive indicators and underestimate negative\nones compared to human responses, suggesting that targeted intervention should\nconsider locals' perception. Our study aspires to rectify the myopic treatment\nof street perception, which rarely considers demographics or personality\ntraits.", "AI": {"tldr": "The paper introduces the SPECS dataset to analyze urban streetscape perceptions, highlighting demographic and personality influences on preferences, and reveals biases in existing machine learning models.", "motivation": "Current urban planning approaches often overlook demographic and personality differences, risking biased decisions. This study aims to address this gap by examining how demographics and traits shape perceptions.", "method": "A large-scale survey of 1,000 participants from diverse backgrounds evaluated streetscapes using street view imagery, measuring perceptions across traditional and new indicators.", "result": "Significant differences in perception scores were found among demographics and personalities. Machine learning models overestimated positive and underestimated negative indicators compared to human responses.", "conclusion": "Urban planning should incorporate local demographic and personality insights to avoid biases and improve decision-making."}}
{"id": "2502.06379", "pdf": "https://arxiv.org/pdf/2502.06379", "abs": "https://arxiv.org/abs/2502.06379", "authors": ["Filip Ekstr\u00f6m Kelvinius", "Zheng Zhao", "Fredrik Lindsten"], "title": "Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted to ICML 2025, to appear in PMLR 267. Code available at\n  https://github.com/filipekstrm/ddsmc", "summary": "A recent line of research has exploited pre-trained generative diffusion\nmodels as priors for solving Bayesian inverse problems. We contribute to this\nresearch direction by designing a sequential Monte Carlo method for\nlinear-Gaussian inverse problems which builds on \"decoupled diffusion\", where\nthe generative process is designed such that larger updates to the sample are\npossible. The method is asymptotically exact and we demonstrate the\neffectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC)\nalgorithm on both synthetic as well as protein and image data. Further, we\ndemonstrate how the approach can be extended to discrete data.", "AI": {"tldr": "A sequential Monte Carlo method (DDSMC) is introduced for solving linear-Gaussian inverse problems using decoupled diffusion, showing effectiveness on synthetic, protein, and image data, with extensions to discrete data.", "motivation": "To improve Bayesian inverse problem solving by leveraging pre-trained generative diffusion models as priors, focusing on larger sample updates.", "method": "Designs a sequential Monte Carlo method based on decoupled diffusion, enabling asymptotically exact solutions for linear-Gaussian inverse problems.", "result": "Demonstrates effectiveness on synthetic, protein, and image data, with potential extensions to discrete data.", "conclusion": "DDSMC is a promising approach for Bayesian inverse problems, scalable and adaptable to various data types."}}
{"id": "2506.20261", "pdf": "https://arxiv.org/pdf/2506.20261", "abs": "https://arxiv.org/abs/2506.20261", "authors": ["Nir Weinberger", "Ram Zamir"], "title": "Exploration-Exploitation Tradeoff in Universal Lossy Compression", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": "An extended version of ISIT 2025 paper", "summary": "Universal compression can learn the source and adapt to it either in a batch\nmode (forward adaptation), or in a sequential mode (backward adaptation). We\nrecast the sequential mode as a multi-armed bandit problem, a fundamental model\nin reinforcement-learning, and study the trade-off between exploration and\nexploitation in the lossy compression case. We show that a previously proposed\n\"natural type selection\" scheme can be cast as a reconstruction-directed MAB\nalgorithm, for sequential lossy compression, and explain its limitations in\nterms of robustness and short-block performance. We then derive and analyze\nrobust cost-directed MAB algorithms, which work at any block length.", "AI": {"tldr": "The paper recasts sequential universal compression as a multi-armed bandit problem, analyzes a 'natural type selection' scheme, and proposes robust cost-directed algorithms for lossy compression.", "motivation": "To explore the trade-off between exploration and exploitation in sequential lossy compression by framing it as a multi-armed bandit problem.", "method": "Recasts sequential compression as a multi-armed bandit problem, analyzes 'natural type selection,' and derives robust cost-directed algorithms.", "result": "Identifies limitations of 'natural type selection' and proposes improved algorithms that work at any block length.", "conclusion": "Robust cost-directed MAB algorithms enhance sequential lossy compression, addressing prior limitations."}}
{"id": "2505.17333", "pdf": "https://arxiv.org/pdf/2505.17333", "abs": "https://arxiv.org/abs/2505.17333", "authors": ["Xin You", "Minghui Zhang", "Hanxiao Zhang", "Jie Yang", "Nassir Navab"], "title": "Temporal Differential Fields for 4D Motion Modeling via Image-to-Video Synthesis", "categories": ["cs.CV"], "comment": "early accepted by MICCAI", "summary": "Temporal modeling on regular respiration-induced motions is crucial to\nimage-guided clinical applications. Existing methods cannot simulate temporal\nmotions unless high-dose imaging scans including starting and ending frames\nexist simultaneously. However, in the preoperative data acquisition stage, the\nslight movement of patients may result in dynamic backgrounds between the first\nand last frames in a respiratory period. This additional deviation can hardly\nbe removed by image registration, thus affecting the temporal modeling. To\naddress that limitation, we pioneeringly simulate the regular motion process\nvia the image-to-video (I2V) synthesis framework, which animates with the first\nframe to forecast future frames of a given length. Besides, to promote the\ntemporal consistency of animated videos, we devise the Temporal Differential\nDiffusion Model to generate temporal differential fields, which measure the\nrelative differential representations between adjacent frames. The prompt\nattention layer is devised for fine-grained differential fields, and the field\naugmented layer is adopted to better interact these fields with the I2V\nframework, promoting more accurate temporal variation of synthesized videos.\nExtensive results on ACDC cardiac and 4D Lung datasets reveal that our approach\nsimulates 4D videos along the intrinsic motion trajectory, rivaling other\ncompetitive methods on perceptual similarity and temporal consistency. Codes\nwill be available soon.", "AI": {"tldr": "The paper introduces an image-to-video (I2V) framework to simulate regular respiratory motion, addressing limitations of existing methods by using temporal differential fields for consistency.", "motivation": "Existing methods fail to simulate temporal motions without high-dose scans, and patient movement introduces deviations that affect modeling.", "method": "Proposes an I2V synthesis framework with a Temporal Differential Diffusion Model to generate differential fields for temporal consistency.", "result": "Outperforms competitors on perceptual similarity and temporal consistency in 4D video simulation.", "conclusion": "The approach effectively models respiratory motion, offering improved accuracy and consistency in synthesized videos."}}
{"id": "2502.06485", "pdf": "https://arxiv.org/pdf/2502.06485", "abs": "https://arxiv.org/abs/2502.06485", "authors": ["Filip Ekstr\u00f6m Kelvinius", "Oskar B. Andersson", "Abhijith S. Parackal", "Dong Qian", "Rickard Armiento", "Fredrik Lindsten"], "title": "WyckoffDiff -- A Generative Diffusion Model for Crystal Symmetry", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "comment": "Accepted to ICML 2025, to appear in PMLR 267. Code is available\n  online at https://github.com/httk/wyckoffdiff", "summary": "Crystalline materials often exhibit a high level of symmetry. However, most\ngenerative models do not account for symmetry, but rather model each atom\nwithout any constraints on its position or element. We propose a generative\nmodel, Wyckoff Diffusion (WyckoffDiff), which generates symmetry-based\ndescriptions of crystals. This is enabled by considering a crystal structure\nrepresentation that encodes all symmetry, and we design a novel neural network\narchitecture which enables using this representation inside a discrete\ngenerative model framework. In addition to respecting symmetry by construction,\nthe discrete nature of our model enables fast generation. We additionally\npresent a new metric, Fr\\'echet Wrenformer Distance, which captures the\nsymmetry aspects of the materials generated, and we benchmark WyckoffDiff\nagainst recently proposed generative models for crystal generation. As a\nproof-of-concept study, we use WyckoffDiff to find new materials below the\nconvex hull of thermodynamical stability.", "AI": {"tldr": "WyckoffDiff is a generative model for symmetry-based crystal structures, using a novel neural network and a discrete framework for fast generation, evaluated with a new symmetry-focused metric.", "motivation": "Existing generative models for crystals ignore symmetry, limiting their accuracy and efficiency. WyckoffDiff addresses this gap by incorporating symmetry constraints.", "method": "The model uses a symmetry-encoded crystal structure representation and a discrete generative framework with a novel neural network architecture.", "result": "WyckoffDiff generates crystals faster and respects symmetry by construction. It also introduces a new metric, Fr\u00e9chet Wrenformer Distance, for symmetry evaluation.", "conclusion": "WyckoffDiff successfully generates symmetry-constrained crystals and identifies new materials below the thermodynamical stability convex hull, demonstrating its potential for materials discovery."}}
{"id": "2506.20297", "pdf": "https://arxiv.org/pdf/2506.20297", "abs": "https://arxiv.org/abs/2506.20297", "authors": ["Natalie Lang", "Maya Simhi", "Nir Shlezinger"], "title": "OLALa: Online Learned Adaptive Lattice Codes for Heterogeneous Federated Learning", "categories": ["eess.SP", "cs.LG"], "comment": "Under review for publication in the IEEE", "summary": "Federated learning (FL) enables collaborative training across distributed\nclients without sharing raw data, often at the cost of substantial\ncommunication overhead induced by transmitting high-dimensional model updates.\nThis overhead can be alleviated by having the clients quantize their model\nupdates, with dithered lattice quantizers identified as an attractive scheme\ndue to its structural simplicity and convergence-preserving properties.\nHowever, existing lattice-based FL schemes typically rely on a fixed\nquantization rule, which is suboptimal in heterogeneous and dynamic\nenvironments where the model updates distribution varies across users and\ntraining rounds. In this work, we propose Online Learned Adaptive Lattices\n(OLALa), a heterogeneous FL framework where each client can adjust its\nquantizer online using lightweight local computations. We first derive\nconvergence guarantees for FL with non-fixed lattice quantizers and show that\nproper lattice adaptation can tighten the convergence bound. Then, we design an\nonline learning algorithm that enables clients to tune their quantizers\nthroughout the FL process while exchanging only a compact set of quantization\nparameters. Numerical experiments demonstrate that OLALa consistently improves\nlearning performance under various quantization rates, outperforming\nconventional fixed-codebook and non-adaptive schemes.", "AI": {"tldr": "OLALa is a federated learning framework with adaptive lattice quantizers, improving performance in heterogeneous environments by allowing clients to adjust quantizers online.", "motivation": "Fixed quantization rules in federated learning are suboptimal for dynamic, heterogeneous environments where model updates vary.", "method": "Proposes OLALa, where clients adjust quantizers online using lightweight computations and exchange compact quantization parameters.", "result": "OLALa outperforms fixed-codebook and non-adaptive schemes, improving learning performance under various quantization rates.", "conclusion": "Adaptive lattice quantizers in FL enhance performance in dynamic settings, with OLALa proving effective through theoretical guarantees and experiments."}}
{"id": "2505.21381", "pdf": "https://arxiv.org/pdf/2505.21381", "abs": "https://arxiv.org/abs/2505.21381", "authors": ["Linshuang Diao", "Dayong Ren", "Sensen Song", "Yurong Qian"], "title": "ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding", "categories": ["cs.CV"], "comment": "The format of the document has an error and needs to be revised", "summary": "State Space models (SSMs) such as PointMamba enable efficient feature\nextraction for point cloud self-supervised learning with linear complexity,\noutperforming Transformers in computational efficiency. However, existing\nPointMamba-based methods depend on complex token ordering and random masking,\nwhich disrupt spatial continuity and local semantic correlations. We propose\nZigzagPointMamba to tackle these challenges. The core of our approach is a\nsimple zigzag scan path that globally sequences point cloud tokens, enhancing\nspatial continuity by preserving the proximity of spatially adjacent point\ntokens. Nevertheless, random masking undermines local semantic modeling in\nself-supervised learning. To address this, we introduce a Semantic-Siamese\nMasking Strategy (SMS), which masks semantically similar tokens to facilitate\nreconstruction by integrating local features of original and similar tokens.\nThis overcomes the dependence on isolated local features and enables robust\nglobal semantic modeling. Our pre-trained ZigzagPointMamba weights\nsignificantly improve downstream tasks, achieving a 1.59% mIoU gain on\nShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 for\nclassification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively for\nthe classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets of\nScanObjectNN.", "AI": {"tldr": "ZigzagPointMamba improves PointMamba by introducing a zigzag scan path for spatial continuity and a Semantic-Siamese Masking Strategy (SMS) for better local semantic modeling, outperforming in downstream tasks.", "motivation": "Existing PointMamba-based methods disrupt spatial continuity and local semantic correlations due to complex token ordering and random masking.", "method": "Proposes ZigzagPointMamba with a zigzag scan path for global sequencing and SMS for masking semantically similar tokens to enhance local semantic modeling.", "result": "Achieves significant improvements: 1.59% mIoU gain on ShapeNetPart, 0.4% higher accuracy on ModelNet40, and better accuracies on ScanObjectNN subsets.", "conclusion": "ZigzagPointMamba effectively addresses spatial and semantic challenges, enhancing performance in point cloud self-supervised learning and downstream tasks."}}
{"id": "2502.19119", "pdf": "https://arxiv.org/pdf/2502.19119", "abs": "https://arxiv.org/abs/2502.19119", "authors": ["Guikun Chen", "Xu Zhang", "Xiaolin Hu", "Yong Liu", "Yi Yang", "Wenguan Wang"], "title": "Chemical knowledge-informed framework for privacy-aware retrosynthesis learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Chemical reaction data is a pivotal asset, driving advances in competitive\nfields such as pharmaceuticals, materials science, and industrial chemistry.\nIts proprietary nature renders it sensitive, as it often includes confidential\ninsights and competitive advantages organizations strive to protect. However,\nin contrast to this need for confidentiality, the current standard training\nparadigm for machine learning-based retrosynthesis gathers reaction data from\nmultiple sources into one single edge to train prediction models. This paradigm\nposes considerable privacy risks as it necessitates broad data availability\nacross organizational boundaries and frequent data transmission between\nentities, potentially exposing proprietary information to unauthorized access\nor interception during storage and transfer. In the present study, we introduce\nthe chemical knowledge-informed framework (CKIF), a privacy-preserving approach\nfor learning retrosynthesis models. CKIF enables distributed training across\nmultiple chemical organizations without compromising the confidentiality of\nproprietary reaction data. Instead of gathering raw reaction data, CKIF learns\nretrosynthesis models through iterative, chemical knowledge-informed\naggregation of model parameters. In particular, the chemical properties of\npredicted reactants are leveraged to quantitatively assess the observable\nbehaviors of individual models, which in turn determines the adaptive weights\nused for model aggregation. On a variety of reaction datasets, CKIF outperforms\nseveral strong baselines by a clear margin.", "AI": {"tldr": "CKIF is a privacy-preserving framework for training retrosynthesis models without sharing raw reaction data, outperforming baselines.", "motivation": "Chemical reaction data is sensitive and proprietary, but current training methods risk privacy by centralizing data.", "method": "CKIF uses distributed training with chemical knowledge-informed aggregation of model parameters, avoiding raw data sharing.", "result": "CKIF outperforms strong baselines on various reaction datasets.", "conclusion": "CKIF offers a secure, effective solution for privacy-preserving retrosynthesis model training."}}
{"id": "2506.20334", "pdf": "https://arxiv.org/pdf/2506.20334", "abs": "https://arxiv.org/abs/2506.20334", "authors": ["Daniele Ravasio", "Marcello Farina", "Alessio La Bella", "Andrea Ballarino"], "title": "Recurrent neural network-based robust control systems with closed-loop regional incremental ISS and application to MPC design", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "16 pages, 7 figures, submitted to IEEE Transactions on Automatic\n  Control (under review)", "summary": "This paper investigates the design of output-feedback schemes for systems\ndescribed by a class of recurrent neural networks. We propose a procedure based\non linear matrix inequalities for designing an observer and a static\nstate-feedback controller. The algorithm leverages global and regional\nincremental input-to-state stability (incremental ISS) and enables the tracking\nof constant setpoints, ensuring robustness to disturbances and state estimation\nuncertainty. To address the potential limitations of regional incremental ISS,\nwe introduce an alternative scheme in which the static law is replaced with a\ntube-based nonlinear model predictive controller (NMPC) that exploits regional\nincremental ISS properties. We show that these conditions enable the\nformulation of a robust NMPC law with guarantees of convergence and recursive\nfeasibility, leading to an enlarged region of attraction. Theoretical results\nare validated through numerical simulations on the pH-neutralisation process\nbenchmark, demonstrating the effectiveness of the proposed schemes.", "AI": {"tldr": "The paper proposes output-feedback schemes for recurrent neural networks using linear matrix inequalities for observer and controller design, with robustness ensured via incremental ISS. It also introduces a tube-based NMPC for improved performance.", "motivation": "To address the challenges of designing robust output-feedback schemes for recurrent neural networks, ensuring stability and performance under disturbances and estimation uncertainty.", "method": "Uses linear matrix inequalities for observer and static state-feedback controller design, leveraging incremental ISS. Introduces a tube-based NMPC for regional incremental ISS limitations.", "result": "The proposed schemes ensure robustness, convergence, and recursive feasibility, validated via numerical simulations on a pH-neutralisation benchmark.", "conclusion": "The methods effectively enhance stability and performance, with the tube-based NMPC offering an enlarged region of attraction."}}
{"id": "2505.22016", "pdf": "https://arxiv.org/pdf/2505.22016", "abs": "https://arxiv.org/abs/2505.22016", "authors": ["Yifei Xia", "Shuchen Weng", "Siqi Yang", "Jingqi Liu", "Chengxuan Zhu", "Minggui Teng", "Zijian Jia", "Han Jiang", "Boxin Shi"], "title": "PanoWan: Lifting Diffusion Video Generation Models to 360\u00b0 with Latitude/Longitude-aware Mechanisms", "categories": ["cs.CV"], "comment": null, "summary": "Panoramic video generation enables immersive 360{\\deg} content creation,\nvaluable in applications that demand scene-consistent world exploration.\nHowever, existing panoramic video generation models struggle to leverage\npre-trained generative priors from conventional text-to-video models for\nhigh-quality and diverse panoramic videos generation, due to limited dataset\nscale and the gap in spatial feature representations. In this paper, we\nintroduce PanoWan to effectively lift pre-trained text-to-video models to the\npanoramic domain, equipped with minimal modules. PanoWan employs latitude-aware\nsampling to avoid latitudinal distortion, while its rotated semantic denoising\nand padded pixel-wise decoding ensure seamless transitions at longitude\nboundaries. To provide sufficient panoramic videos for learning these lifted\nrepresentations, we contribute PanoVid, a high-quality panoramic video dataset\nwith captions and diverse scenarios. Consequently, PanoWan achieves\nstate-of-the-art performance in panoramic video generation and demonstrates\nrobustness for zero-shot downstream tasks. Our project page is available at\nhttps://panowan.variantconst.com.", "AI": {"tldr": "PanoWan lifts pre-trained text-to-video models to the panoramic domain with minimal modules, addressing distortion and boundary issues, and introduces PanoVid dataset for training.", "motivation": "Existing models struggle to leverage pre-trained generative priors for high-quality panoramic videos due to dataset limitations and spatial feature gaps.", "method": "PanoWan uses latitude-aware sampling, rotated semantic denoising, and padded pixel-wise decoding to address distortion and boundary transitions.", "result": "PanoWan achieves state-of-the-art performance in panoramic video generation and robustness in zero-shot tasks.", "conclusion": "PanoWan effectively bridges the gap between conventional text-to-video models and panoramic video generation, supported by the PanoVid dataset."}}
{"id": "2503.00089", "pdf": "https://arxiv.org/pdf/2503.00089", "abs": "https://arxiv.org/abs/2503.00089", "authors": ["Xinyu Yuan", "Zichen Wang", "Marcus Collins", "Huzefa Rangwala"], "title": "Protein Structure Tokenization: Benchmarking and New Recipe", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "Accepted at ICML 2025", "summary": "Recent years have witnessed a surge in the development of protein structural\ntokenization methods, which chunk protein 3D structures into discrete or\ncontinuous representations. Structure tokenization enables the direct\napplication of powerful techniques like language modeling for protein\nstructures, and large multimodal models to integrate structures with protein\nsequences and functional texts. Despite the progress, the capabilities and\nlimitations of these methods remain poorly understood due to the lack of a\nunified evaluation framework. We first introduce StructTokenBench, a framework\nthat comprehensively evaluates the quality and efficiency of structure\ntokenizers, focusing on fine-grained local substructures rather than global\nstructures, as typical in existing benchmarks. Our evaluations reveal that no\nsingle model dominates all benchmarking perspectives. Observations of codebook\nunder-utilization led us to develop AminoAseed, a simple yet effective strategy\nthat enhances codebook gradient updates and optimally balances codebook size\nand dimension for improved tokenizer utilization and quality. Compared to the\nleading model ESM3, our method achieves an average of 6.31% performance\nimprovement across 24 supervised tasks, with sensitivity and utilization rates\nincreased by 12.83% and 124.03%, respectively. Source code and model weights\nare available at https://github.com/KatarinaYuan/StructTokenBench", "AI": {"tldr": "The paper introduces StructTokenBench, a framework for evaluating protein structure tokenization methods, and proposes AminoAseed, a strategy to improve tokenizer performance.", "motivation": "There's a lack of a unified evaluation framework for protein structure tokenization methods, hindering understanding of their capabilities and limitations.", "method": "The authors develop StructTokenBench to evaluate tokenizers and introduce AminoAseed, a strategy to optimize codebook updates and balance size/dimension.", "result": "AminoAseed outperforms ESM3, achieving a 6.31% average improvement across 24 tasks, with higher sensitivity and utilization rates.", "conclusion": "The study provides a robust evaluation framework and an effective method to enhance protein structure tokenization."}}
{"id": "2506.20344", "pdf": "https://arxiv.org/pdf/2506.20344", "abs": "https://arxiv.org/abs/2506.20344", "authors": ["Po Chen", "Rujun Jiang", "Peng Wang"], "title": "A Complete Loss Landscape Analysis of Regularized Deep Matrix Factorization", "categories": ["math.OC", "cs.LG"], "comment": "35 pages, 3 figures", "summary": "Despite its wide range of applications across various domains, the\noptimization foundations of deep matrix factorization (DMF) remain largely\nopen. In this work, we aim to fill this gap by conducting a comprehensive study\nof the loss landscape of the regularized DMF problem. Toward this goal, we\nfirst provide a closed-form expression of all critical points. Building on\nthis, we establish precise conditions under which a critical point is a local\nminimizer, a global minimizer, a strict saddle point, or a non-strict saddle\npoint. Leveraging these results, we derive a necessary and sufficient condition\nunder which each critical point is either a local minimizer or a strict saddle\npoint. This provides insights into why gradient-based methods almost always\nconverge to a local minimizer of the regularized DMF problem. Finally, we\nconduct numerical experiments to visualize its loss landscape under different\nsettings to support our theory.", "AI": {"tldr": "The paper analyzes the loss landscape of regularized deep matrix factorization (DMF), identifying critical points and their properties, and explains why gradient-based methods often converge to local minimizers.", "motivation": "The optimization foundations of DMF are not well understood, despite its broad applications. This work aims to comprehensively study its loss landscape.", "method": "The authors derive closed-form expressions for critical points, classify them (local/global minimizers, strict/non-strict saddle points), and provide conditions for convergence. Numerical experiments validate the theory.", "result": "Precise conditions for critical point classification are established, and a necessary/sufficient condition for convergence to local minimizers or strict saddle points is derived.", "conclusion": "The study clarifies the optimization behavior of DMF, explaining why gradient-based methods typically converge to local minimizers, supported by numerical evidence."}}
{"id": "2505.24862", "pdf": "https://arxiv.org/pdf/2505.24862", "abs": "https://arxiv.org/abs/2505.24862", "authors": ["Cailin Zhuang", "Ailin Huang", "Wei Cheng", "Jingwei Wu", "Yaoqi Hu", "Jiaqi Liao", "Zhewei Huang", "Hongyuan Wang", "Xinyao Liao", "Weiwei Cai", "Hengyuan Xu", "Xuanyang Zhang", "Xianfang Zeng", "Gang Yu", "Chi Zhang"], "title": "ViStoryBench: Comprehensive Benchmark Suite for Story Visualization", "categories": ["cs.CV"], "comment": "33 Pages, Project Page: https://vistorybench.github.io/, Code:\n  https://github.com/vistorybench/vistorybench", "summary": "Story visualization, which aims to generate a sequence of visually coherent\nimages aligning with a given narrative and reference images, has seen\nsignificant progress with recent advancements in generative models. To further\nenhance the performance of story visualization frameworks in real-world\nscenarios, we introduce a comprehensive evaluation benchmark, ViStoryBench. We\ncollect a diverse dataset encompassing various story types and artistic styles,\nensuring models are evaluated across multiple dimensions such as different\nplots (e.g., comedy, horror) and visual aesthetics (e.g., anime, 3D\nrenderings). ViStoryBench is carefully curated to balance narrative structures\nand visual elements, featuring stories with single and multiple protagonists to\ntest models' ability to maintain character consistency. Additionally, it\nincludes complex plots and intricate world-building to challenge models in\ngenerating accurate visuals. To ensure comprehensive comparisons, our benchmark\nincorporates a wide range of evaluation metrics assessing critical aspects.\nThis structured and multifaceted framework enables researchers to thoroughly\nidentify both the strengths and weaknesses of different models, fostering\ntargeted improvements.", "AI": {"tldr": "ViStoryBench is introduced as a comprehensive evaluation benchmark for story visualization models, featuring diverse story types and artistic styles to test model performance across various dimensions.", "motivation": "To enhance the performance of story visualization frameworks in real-world scenarios by providing a structured and multifaceted evaluation framework.", "method": "Collecting a diverse dataset with varied story types, artistic styles, and narrative structures, including single and multiple protagonists, complex plots, and intricate world-building.", "result": "ViStoryBench enables thorough identification of model strengths and weaknesses through a wide range of evaluation metrics.", "conclusion": "The benchmark fosters targeted improvements in story visualization models by providing a comprehensive and balanced evaluation framework."}}
{"id": "2503.08727", "pdf": "https://arxiv.org/pdf/2503.08727", "abs": "https://arxiv.org/abs/2503.08727", "authors": ["Lucas Caccia", "Alan Ansell", "Edoardo Ponti", "Ivan Vuli\u0107", "Alessandro Sordoni"], "title": "Training Plug-n-Play Knowledge Modules with Deep Context Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Dynamically integrating new or rapidly evolving information after (Large)\nLanguage Model pre-training remains challenging, particularly in low-data\nscenarios or when dealing with private and specialized documents. In-context\nlearning and retrieval-augmented generation (RAG) face limitations, including\ntheir high inference costs and their inability to capture global document\ninformation. In this paper, we propose a way of modularizing knowledge by\ntraining document-level Knowledge Modules (KMs). KMs are lightweight components\nimplemented as parameter-efficient LoRA modules, which are trained to store\ninformation about new documents and can be easily plugged into models on\ndemand. We show that next-token prediction performs poorly as the training\nobjective for KMs. We instead propose Deep Context Distillation: we learn KMs\nparameters such as to simulate hidden states and logits of a teacher that takes\nthe document in context. Our method outperforms standard next-token prediction\nand pre-instruction training techniques, across two datasets. Finally, we\nhighlight synergies between KMs and RAG.", "AI": {"tldr": "The paper proposes Knowledge Modules (KMs) for dynamically integrating new information into language models, addressing limitations of in-context learning and RAG. KMs use Deep Context Distillation for training, outperforming traditional methods.", "motivation": "Challenges in integrating new or evolving information post-pre-training, especially in low-data or private/specialized scenarios, motivate the need for lightweight, modular solutions.", "method": "Train document-level Knowledge Modules (KMs) as LoRA modules using Deep Context Distillation, simulating teacher model hidden states and logits.", "result": "KMs outperform next-token prediction and pre-instruction training across two datasets, showing synergy with RAG.", "conclusion": "KMs offer an effective, lightweight solution for dynamic knowledge integration, with potential synergies with RAG."}}
{"id": "2506.20406", "pdf": "https://arxiv.org/pdf/2506.20406", "abs": "https://arxiv.org/abs/2506.20406", "authors": ["Ruijia Zhang", "Zhengling Qi", "Yue Wu", "Xiangyu Zhang", "Yanxun Xu"], "title": "POLAR: A Pessimistic Model-based Policy Learning Algorithm for Dynamic Treatment Regimes", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "stat.ME"], "comment": null, "summary": "Dynamic treatment regimes (DTRs) provide a principled framework for\noptimizing sequential decision-making in domains where decisions must adapt\nover time in response to individual trajectories, such as healthcare,\neducation, and digital interventions. However, existing statistical methods\noften rely on strong positivity assumptions and lack robustness under partial\ndata coverage, while offline reinforcement learning approaches typically focus\non average training performance, lack statistical guarantees, and require\nsolving complex optimization problems. To address these challenges, we propose\nPOLAR, a novel pessimistic model-based policy learning algorithm for offline\nDTR optimization. POLAR estimates the transition dynamics from offline data and\nquantifies uncertainty for each history-action pair. A pessimistic penalty is\nthen incorporated into the reward function to discourage actions with high\nuncertainty. Unlike many existing methods that focus on average training\nperformance, POLAR directly targets the suboptimality of the final learned\npolicy and offers theoretical guarantees, without relying on computationally\nintensive minimax or constrained optimization procedures. To the best of our\nknowledge, POLAR is the first model-based DTR method to provide both\nstatistical and computational guarantees, including finite-sample bounds on\npolicy suboptimality. Empirical results on both synthetic data and the\nMIMIC-III dataset demonstrate that POLAR outperforms state-of-the-art methods\nand yields near-optimal, history-aware treatment strategies.", "AI": {"tldr": "POLAR is a novel pessimistic model-based policy learning algorithm for optimizing dynamic treatment regimes (DTRs) with statistical and computational guarantees.", "motivation": "Existing methods for DTRs rely on strong assumptions or lack robustness and guarantees, prompting the need for a more reliable approach.", "method": "POLAR estimates transition dynamics from offline data, quantifies uncertainty, and incorporates a pessimistic penalty to discourage high-uncertainty actions.", "result": "POLAR outperforms state-of-the-art methods, providing near-optimal, history-aware treatment strategies with theoretical guarantees.", "conclusion": "POLAR addresses key challenges in DTR optimization, offering a robust, efficient, and theoretically sound solution."}}
{"id": "2506.02161", "pdf": "https://arxiv.org/pdf/2506.02161", "abs": "https://arxiv.org/abs/2506.02161", "authors": ["Xinyu Wei", "Jinrui Zhang", "Zeqing Wang", "Hongyang Wei", "Zhen Guo", "Lei Zhang"], "title": "TIIF-Bench: How Does Your T2I Model Follow Your Instructions?", "categories": ["cs.CV"], "comment": "23 pages, 12 figures, 11 tables", "summary": "The rapid advancements of Text-to-Image (T2I) models have ushered in a new\nphase of AI-generated content, marked by their growing ability to interpret and\nfollow user instructions. However, existing T2I model evaluation benchmarks\nfall short in limited prompt diversity and complexity, as well as coarse\nevaluation metrics, making it difficult to evaluate the fine-grained alignment\nperformance between textual instructions and generated images. In this paper,\nwe present TIIF-Bench (Text-to-Image Instruction Following Benchmark), aiming\nto systematically assess T2I models' ability in interpreting and following\nintricate textual instructions. TIIF-Bench comprises a set of 5000 prompts\norganized along multiple dimensions, which are categorized into three levels of\ndifficulties and complexities. To rigorously evaluate model robustness to\nvarying prompt lengths, we provide a short and a long version for each prompt\nwith identical core semantics. Two critical attributes, i.e., text rendering\nand style control, are introduced to evaluate the precision of text synthesis\nand the aesthetic coherence of T2I models. In addition, we collect 100\nhigh-quality designer level prompts that encompass various scenarios to\ncomprehensively assess model performance. Leveraging the world knowledge\nencoded in large vision language models, we propose a novel computable\nframework to discern subtle variations in T2I model outputs. Through meticulous\nbenchmarking of mainstream T2I models on TIIF-Bench, we analyze the pros and\ncons of current T2I models and reveal the limitations of current T2I\nbenchmarks. Project Page: https://a113n-w3i.github.io/TIIF_Bench/.", "AI": {"tldr": "TIIF-Bench is a new benchmark for evaluating Text-to-Image (T2I) models, addressing limitations in prompt diversity, complexity, and evaluation metrics. It includes 5000 prompts with varying difficulties, dual-length versions, and focuses on text rendering and style control. A novel computable framework assesses model outputs, revealing current T2I model limitations.", "motivation": "Existing T2I evaluation benchmarks lack prompt diversity, complexity, and fine-grained metrics, hindering accurate assessment of model alignment with textual instructions.", "method": "TIIF-Bench introduces 5000 prompts categorized by difficulty, with short and long versions for each. It evaluates text rendering, style control, and uses a computable framework based on large vision language models.", "result": "The benchmark rigorously assesses mainstream T2I models, highlighting their strengths and weaknesses, and exposes limitations in current benchmarks.", "conclusion": "TIIF-Bench provides a systematic and detailed evaluation tool for T2I models, improving the understanding of their capabilities and limitations."}}
{"id": "2504.10390", "pdf": "https://arxiv.org/pdf/2504.10390", "abs": "https://arxiv.org/abs/2504.10390", "authors": ["Fangcheng Jin", "Yuqi Wang", "Peixin Ma", "Guodong Yang", "Pan Zhao", "En Li", "Zhengtao Zhang"], "title": "Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain", "categories": ["cs.RO", "cs.AI", "68T40"], "comment": "8 pages, 6 figures, 6 tables, IROS 2025", "summary": "Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.", "AI": {"tldr": "A teacher-student framework improves humanoid robot locomotion on complex terrains by combining imitation learning and auxiliary tasks, reducing costs and enhancing stability.", "motivation": "Robust locomotion on complex terrains is challenging due to high-dimensional control and environmental uncertainties. Existing methods rely heavily on encoder-based state embeddings, which complicate deployment.", "method": "The framework uses a high-performance teacher policy trained with privileged information. The teacher's motion distribution is transferred to a student policy via generative adversarial learning, using only noisy proprioceptive data. Auxiliary tasks enhance feature representation.", "result": "The framework significantly improves locomotion stability on dynamic terrains and reduces development costs, validated on a humanoid robot.", "conclusion": "This work offers a practical solution for deploying robust locomotion strategies in humanoid robots, enhancing efficiency and generalization."}}
{"id": "2506.20425", "pdf": "https://arxiv.org/pdf/2506.20425", "abs": "https://arxiv.org/abs/2506.20425", "authors": ["Ryan Thompson", "Matt P. Wand", "Joanna J. J. Wang"], "title": "Scalable Subset Selection in Linear Mixed Models", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "comment": null, "summary": "Linear mixed models (LMMs), which incorporate fixed and random effects, are\nkey tools for analyzing heterogeneous data, such as in personalized medicine or\nadaptive marketing. Nowadays, this type of data is increasingly wide, sometimes\ncontaining thousands of candidate predictors, necessitating sparsity for\nprediction and interpretation. However, existing sparse learning methods for\nLMMs do not scale well beyond tens or hundreds of predictors, leaving a large\ngap compared with sparse methods for linear models, which ignore random\neffects. This paper closes the gap with a new $\\ell_0$ regularized method for\nLMM subset selection that can run on datasets containing thousands of\npredictors in seconds to minutes. On the computational front, we develop a\ncoordinate descent algorithm as our main workhorse and provide a guarantee of\nits convergence. We also develop a local search algorithm to help traverse the\nnonconvex optimization surface. Both algorithms readily extend to subset\nselection in generalized LMMs via a penalized quasi-likelihood approximation.\nOn the statistical front, we provide a finite-sample bound on the\nKullback-Leibler divergence of the new method. We then demonstrate its\nexcellent performance in synthetic experiments and illustrate its utility on\ntwo datasets from biology and journalism.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.06643", "pdf": "https://arxiv.org/pdf/2506.06643", "abs": "https://arxiv.org/abs/2506.06643", "authors": ["Moushumi Medhi", "Rajiv Ranjan Sahay"], "title": "Dark Channel-Assisted Depth-from-Defocus from a Single Image", "categories": ["cs.CV"], "comment": null, "summary": "We estimate scene depth from a single defocus-blurred image using the dark\nchannel as a complementary cue, leveraging its ability to capture local\nstatistics and scene structure. Traditional depth-from-defocus (DFD) methods\nuse multiple images with varying apertures or focus. Single-image DFD is\nunderexplored due to its inherent challenges. Few attempts have focused on\ndepth-from-defocus (DFD) from a single defocused image because the problem is\nunderconstrained. Our method uses the relationship between local defocus blur\nand contrast variations as depth cues to improve scene structure estimation.\nThe pipeline is trained end-to-end with adversarial learning. Experiments on\nreal data demonstrate that incorporating the dark channel prior into\nsingle-image DFD provides meaningful depth estimation, validating our approach.", "AI": {"tldr": "The paper proposes a method for estimating scene depth from a single defocus-blurred image using the dark channel as a cue, improving upon traditional multi-image DFD approaches.", "motivation": "Single-image depth-from-defocus (DFD) is challenging due to its underconstrained nature, and existing methods often require multiple images. This work aims to address this gap by leveraging the dark channel prior.", "method": "The method uses local defocus blur and contrast variations as depth cues, incorporating the dark channel prior. The pipeline is trained end-to-end with adversarial learning.", "result": "Experiments on real data show that the approach provides meaningful depth estimation, validating the use of the dark channel prior in single-image DFD.", "conclusion": "The paper demonstrates that the dark channel prior can effectively enhance single-image DFD, offering a viable solution to an underexplored problem."}}
{"id": "2505.13033", "pdf": "https://arxiv.org/pdf/2505.13033", "abs": "https://arxiv.org/abs/2505.13033", "authors": ["Vijay Ekambaram", "Subodh Kumar", "Arindam Jati", "Sumanta Mukherjee", "Tomoya Sakai", "Pankaj Dayama", "Wesley M. Gifford", "Jayant Kalagnanam"], "title": "TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rise of time-series pre-trained models has advanced temporal\nrepresentation learning, but current state-of-the-art models are often\nlarge-scale, requiring substantial compute. We introduce TSPulse, ultra-compact\ntime-series pre-trained models with only 1M parameters, specialized to perform\nstrongly across classification, anomaly detection, imputation, and retrieval\ntasks. TSPulse introduces innovations at both the architecture and task levels.\nAt the architecture level, it employs a dual-space masked reconstruction,\nlearning from both time and frequency domains to capture complementary signals.\nThis is further enhanced by a dual-embedding disentanglement, generating both\ndetailed embeddings for fine-grained analysis and high-level semantic\nembeddings for broader task understanding. Notably, TSPulse's semantic\nembeddings are robust to shifts in time, magnitude, and noise, which is\nimportant for robust retrieval. At the task level, TSPulse incorporates TSLens,\na fine-tuning component enabling task-specific feature attention. It also\nintroduces a multi-head triangulation technique that correlates deviations from\nmultiple prediction heads, enhancing anomaly detection by fusing complementary\nmodel outputs. Additionally, a hybrid mask pretraining is proposed to improves\nzero-shot imputation by reducing pre-training bias. These architecture and task\ninnovations collectively contribute to TSPulse's significant performance gains:\n5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly\ndetection leaderboard, +50% in zero-shot imputation, and +25% in time-series\nretrieval. Remarkably, these results are achieved with just 1M parameters\n(10-100X smaller than existing SOTA models) and allow GPU-free inference,\nsetting a new standard for efficient time-series pre-trained models. The models\ncan be accessed from\nhttps://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1", "AI": {"tldr": "TSPulse is an ultra-compact time-series pre-trained model with 1M parameters, excelling in classification, anomaly detection, imputation, and retrieval tasks through innovative architecture and task-level techniques.", "motivation": "Current state-of-the-art time-series models are large-scale and computationally expensive, necessitating a more efficient solution.", "method": "TSPulse employs dual-space masked reconstruction (time and frequency domains), dual-embedding disentanglement, TSLens for task-specific fine-tuning, multi-head triangulation for anomaly detection, and hybrid mask pretraining for zero-shot imputation.", "result": "Achieves significant performance gains: 5-16% on UEA classification, +20% on TSB-AD anomaly detection, +50% in zero-shot imputation, and +25% in retrieval, with only 1M parameters.", "conclusion": "TSPulse sets a new standard for efficient time-series pre-trained models, offering high performance with minimal computational resources."}}
{"id": "2506.20501", "pdf": "https://arxiv.org/pdf/2506.20501", "abs": "https://arxiv.org/abs/2506.20501", "authors": ["Philipp Hager", "Onno Zoeter", "Maarten de Rijke"], "title": "Unidentified and Confounded? Understanding Two-Tower Models for Unbiased Learning to Rank", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Additive two-tower models are popular learning-to-rank methods for handling\nbiased user feedback in industry settings. Recent studies, however, report a\nconcerning phenomenon: training two-tower models on clicks collected by\nwell-performing production systems leads to decreased ranking performance. This\npaper investigates two recent explanations for this observation: confounding\neffects from logging policies and model identifiability issues. We\ntheoretically analyze the identifiability conditions of two-tower models,\nshowing that either document swaps across positions or overlapping feature\ndistributions are required to recover model parameters from clicks. We also\ninvestigate the effect of logging policies on two-tower models, finding that\nthey introduce no bias when models perfectly capture user behavior. However,\nlogging policies can amplify biases when models imperfectly capture user\nbehavior, particularly when prediction errors correlate with document placement\nacross positions. We propose a sample weighting technique to mitigate these\neffects and provide actionable insights for researchers and practitioners using\ntwo-tower models.", "AI": {"tldr": "The paper examines why two-tower models trained on clicks from production systems degrade in performance, identifying confounding logging policies and model identifiability issues as causes. It proposes a sample weighting solution.", "motivation": "To understand and address the performance degradation of two-tower models trained on biased user feedback, particularly clicks from production systems.", "method": "Theoretical analysis of identifiability conditions for two-tower models and investigation of logging policy effects. Proposes a sample weighting technique.", "result": "Identifiability requires document swaps or overlapping feature distributions. Logging policies introduce bias when models imperfectly capture user behavior. Sample weighting mitigates these effects.", "conclusion": "The study provides insights and a practical solution (sample weighting) to improve two-tower model performance in real-world settings."}}
{"id": "2506.07368", "pdf": "https://arxiv.org/pdf/2506.07368", "abs": "https://arxiv.org/abs/2506.07368", "authors": ["Jiaying He", "Yitong Lin", "Jiahe Chen", "Honghui Xu", "Jianwei Zheng"], "title": "C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICME 2025", "summary": "For the immanent challenge of insufficiently annotated samples in the medical\nfield, semi-supervised medical image segmentation (SSMIS) offers a promising\nsolution. Despite achieving impressive results in delineating primary target\nareas, most current methodologies struggle to precisely capture the subtle\ndetails of boundaries. This deficiency often leads to significant diagnostic\ninaccuracies. To tackle this issue, we introduce C3S3, a novel semi-supervised\nsegmentation model that synergistically integrates complementary competition\nand contrastive selection. This design significantly sharpens boundary\ndelineation and enhances overall precision. Specifically, we develop an\nOutcome-Driven Contrastive Learning module dedicated to refining boundary\nlocalization. Additionally, we incorporate a Dynamic Complementary Competition\nmodule that leverages two high-performing sub-networks to generate\npseudo-labels, thereby further improving segmentation quality. The proposed\nC3S3 undergoes rigorous validation on two publicly accessible datasets,\nencompassing the practices of both MRI and CT scans. The results demonstrate\nthat our method achieves superior performance compared to previous cutting-edge\ncompetitors. Especially, on the 95HD and ASD metrics, our approach achieves a\nnotable improvement of at least 6%, highlighting the significant advancements.\nThe code is available at https://github.com/Y-TARL/C3S3.", "AI": {"tldr": "C3S3 is a novel semi-supervised medical image segmentation model that improves boundary delineation and precision by integrating complementary competition and contrastive selection, outperforming existing methods by at least 6% on key metrics.", "motivation": "Addressing the challenge of insufficient annotated medical samples and the inability of current methods to capture subtle boundary details, which leads to diagnostic inaccuracies.", "method": "Introduces C3S3 with an Outcome-Driven Contrastive Learning module for boundary refinement and a Dynamic Complementary Competition module for pseudo-label generation using two sub-networks.", "result": "Validated on MRI and CT datasets, C3S3 achieves superior performance, with at least 6% improvement on 95HD and ASD metrics.", "conclusion": "C3S3 significantly advances semi-supervised medical image segmentation, particularly in boundary precision, and is publicly available for further use."}}
{"id": "2505.18213", "pdf": "https://arxiv.org/pdf/2505.18213", "abs": "https://arxiv.org/abs/2505.18213", "authors": ["Kaveen Hiniduma", "Dylan Ryan", "Suren Byna", "Jean Luca Bez", "Ravi Madduri"], "title": "AIDRIN 2.0: A Framework to Assess Data Readiness for AI", "categories": ["cs.CY", "cs.AI"], "comment": "3 pages, 3 figures", "summary": "AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve\ndata preparedness for AI applications. It addresses critical data readiness\ndimensions such as data quality, bias, fairness, and privacy. This paper\ndetails enhancements to AIDRIN by focusing on user interface improvements and\nintegration with a privacy-preserving federated learning (PPFL) framework. By\nrefining the UI and enabling smooth integration with decentralized AI\npipelines, AIDRIN becomes more accessible and practical for users with varying\ntechnical expertise. Integrating with an existing PPFL framework ensures that\ndata readiness and privacy are prioritized in federated learning environments.\nA case study involving a real-world dataset demonstrates AIDRIN's practical\nvalue in identifying data readiness issues that impact AI model performance.", "AI": {"tldr": "AIDRIN is enhanced with UI improvements and PPFL integration to make it more accessible and practical, prioritizing data readiness and privacy in federated learning.", "motivation": "To improve data preparedness for AI applications by addressing critical dimensions like quality, bias, fairness, and privacy.", "method": "Enhancements include UI refinements and integration with a privacy-preserving federated learning (PPFL) framework.", "result": "AIDRIN becomes more user-friendly and effective in identifying data readiness issues, as shown in a real-world case study.", "conclusion": "The improved AIDRIN framework is practical and valuable for ensuring data readiness and privacy in AI applications, especially in federated learning."}}
{"id": "2506.20513", "pdf": "https://arxiv.org/pdf/2506.20513", "abs": "https://arxiv.org/abs/2506.20513", "authors": ["Lei Liu", "Chao Song", "Liangsheng He", "Silin Wang", "Xuan Feng", "Cai Liu"], "title": "Fast ground penetrating radar dual-parameter full waveform inversion method accelerated by hybrid compilation of CUDA kernel function and PyTorch", "categories": ["physics.geo-ph", "cs.LG", "eess.SP"], "comment": null, "summary": "This study proposes a high-performance dual-parameter full waveform inversion\nframework (FWI) for ground-penetrating radar (GPR), accelerated through the\nhybrid compilation of CUDA kernel functions and PyTorch. The method leverages\nthe computational efficiency of GPU programming while preserving the\nflexibility and usability of Python-based deep learning frameworks. By\nintegrating customized CUDA kernels into PyTorch's automatic differentiation\nmechanism, the framework enables accurate and efficient inversion of both\ndielectric permittivity and electrical conductivity. Experimental evaluations\non synthetic data and real wavefield data demonstrate that the proposed method\nachieves dual-parameter FWI for GPR data while maintaining high accuracy.\nMoreover, the framework is flexible and extensible, supporting optional\nregularization strategies such as total variation and multi-scale inversion.\nThese features make the proposed approach a practical and scalable framework\nfor rapid GPR-based subsurface imaging in applications including civil\nengineering, environmental monitoring, and geophysical exploration.", "AI": {"tldr": "A high-performance dual-parameter FWI framework for GPR, combining CUDA and PyTorch, achieves efficient and accurate subsurface imaging.", "motivation": "To enhance GPR-based subsurface imaging by integrating GPU efficiency with Python flexibility for dual-parameter inversion.", "method": "Hybrid compilation of CUDA kernels and PyTorch, leveraging GPU acceleration and automatic differentiation for FWI of permittivity and conductivity.", "result": "Accurate dual-parameter inversion on synthetic and real data, with support for regularization strategies like total variation and multi-scale inversion.", "conclusion": "The framework is practical, scalable, and suitable for rapid subsurface imaging in engineering and geophysical applications."}}
{"id": "2506.09229", "pdf": "https://arxiv.org/pdf/2506.09229", "abs": "https://arxiv.org/abs/2506.09229", "authors": ["Sungwon Hwang", "Hyojin Jang", "Kinam Kim", "Minho Park", "Jaegul Choo"], "title": "Cross-Frame Representation Alignment for Fine-Tuning Video Diffusion Models", "categories": ["cs.CV"], "comment": "Project page: https://crepavideo.github.io", "summary": "Fine-tuning Video Diffusion Models (VDMs) at the user level to generate\nvideos that reflect specific attributes of training data presents notable\nchallenges, yet remains underexplored despite its practical importance.\nMeanwhile, recent work such as Representation Alignment (REPA) has shown\npromise in improving the convergence and quality of DiT-based image diffusion\nmodels by aligning, or assimilating, its internal hidden states with external\npretrained visual features, suggesting its potential for VDM fine-tuning. In\nthis work, we first propose a straightforward adaptation of REPA for VDMs and\nempirically show that, while effective for convergence, it is suboptimal in\npreserving semantic consistency across frames. To address this limitation, we\nintroduce Cross-frame Representation Alignment (CREPA), a novel regularization\ntechnique that aligns hidden states of a frame with external features from\nneighboring frames. Empirical evaluations on large-scale VDMs, including\nCogVideoX-5B and Hunyuan Video, demonstrate that CREPA improves both visual\nfidelity and cross-frame semantic coherence when fine-tuned with\nparameter-efficient methods such as LoRA. We further validate CREPA across\ndiverse datasets with varying attributes, confirming its broad applicability.", "AI": {"tldr": "The paper introduces CREPA, a method to improve video diffusion model fine-tuning by aligning hidden states across frames for better semantic consistency and visual fidelity.", "motivation": "Fine-tuning video diffusion models for user-specific attributes is challenging and underexplored, despite its practical importance.", "method": "Proposes Cross-frame Representation Alignment (CREPA), a regularization technique aligning hidden states of a frame with external features from neighboring frames.", "result": "CREPA improves visual fidelity and cross-frame semantic coherence in large-scale VDMs like CogVideoX-5B and Hunyuan Video.", "conclusion": "CREPA is broadly applicable and effective for enhancing video diffusion model fine-tuning."}}
{"id": "2505.22843", "pdf": "https://arxiv.org/pdf/2505.22843", "abs": "https://arxiv.org/abs/2505.22843", "authors": ["Alexander Herzog", "Aliai Eusebi", "Lorenzo Cavallaro"], "title": "Aurora: Are Android Malware Classifiers Reliable and Stable under Distribution Shift?", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The performance figures of modern drift-adaptive malware classifiers appear\npromising, but does this translate to genuine operational reliability? The\nstandard evaluation paradigm primarily focuses on baseline performance metrics,\nneglecting confidence-error alignment and operational stability. While\nTESSERACT established the importance of temporal evaluation, we take a\ncomplementary direction by investigating whether malware classifiers maintain\nreliable and stable confidence estimates under distribution shifts and\nexploring the tensions between scientific advancement and practical impacts\nwhen they do not. We propose AURORA, a framework to evaluate malware\nclassifiers based on their confidence quality and operational resilience.\nAURORA subjects the confidence profile of a given model to verification to\nassess the reliability of its estimates. Unreliable confidence estimates erode\noperational trust, waste valuable annotation budget on non-informative samples\nfor active learning, and leave error-prone instances undetected in selective\nclassification. AURORA is complemented by a set of metrics designed to go\nbeyond point-in-time performance, striving towards a more holistic assessment\nof operational stability throughout temporal evaluation periods. The fragility\nin SOTA frameworks across datasets of varying drift suggests the need for a\nreturn to the whiteboard.", "AI": {"tldr": "AURORA evaluates malware classifiers' confidence quality and operational resilience, addressing gaps in current evaluation methods by focusing on stability under distribution shifts.", "motivation": "Current evaluations neglect confidence-error alignment and operational stability, leading to unreliable classifiers in practice.", "method": "Proposes AURORA, a framework to verify confidence estimates and assess reliability under distribution shifts, using metrics for holistic operational stability.", "result": "Highlights fragility in state-of-the-art frameworks, showing unreliable confidence estimates undermine trust and efficiency.", "conclusion": "AURORA advocates for a shift towards more robust and stable malware classifier evaluations, emphasizing practical reliability."}}
{"id": "2506.20533", "pdf": "https://arxiv.org/pdf/2506.20533", "abs": "https://arxiv.org/abs/2506.20533", "authors": ["Gilad Lerman", "Kang Li", "Tyler Maunu", "Teng Zhang"], "title": "Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Robust subspace estimation is fundamental to many machine learning and data\nanalysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and\nempirically effective approach to this problem, yet its theoretical properties\nremain poorly understood. This paper establishes that, under deterministic\nconditions, a variant of IRLS with dynamic smoothing regularization converges\nlinearly to the underlying subspace from any initialization. We extend these\nguarantees to affine subspace estimation, a setting that lacks prior recovery\ntheory. Additionally, we illustrate the practical benefits of IRLS through an\napplication to low-dimensional neural network training. Our results provide the\nfirst global convergence guarantees for IRLS in robust subspace recovery and,\nmore broadly, for nonconvex IRLS on a Riemannian manifold.", "AI": {"tldr": "A variant of IRLS with dynamic smoothing regularization achieves linear convergence to the underlying subspace under deterministic conditions, with extensions to affine subspace estimation and practical benefits in neural network training.", "motivation": "Robust subspace estimation is crucial for machine learning and data analysis, but theoretical understanding of IRLS remains limited.", "method": "A variant of IRLS with dynamic smoothing regularization is proposed and analyzed under deterministic conditions.", "result": "The method converges linearly to the true subspace from any initialization and extends to affine subspace estimation, with practical benefits in neural network training.", "conclusion": "This work provides the first global convergence guarantees for IRLS in robust subspace recovery and nonconvex IRLS on Riemannian manifolds."}}
{"id": "2506.10978", "pdf": "https://arxiv.org/pdf/2506.10978", "abs": "https://arxiv.org/abs/2506.10978", "authors": ["Donghoon Ahn", "Jiwon Kang", "Sanghyun Lee", "Minjae Kim", "Jaewon Min", "Wooseok Jang", "Saungwu Lee", "Sayak Paul", "Susung Hong", "Seungryong Kim"], "title": "Fine-Grained Perturbation Guidance via Attention Head Selection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project page: https://cvlab-kaist.github.io/HeadHunter/", "summary": "Recent guidance methods in diffusion models steer reverse sampling by\nperturbing the model to construct an implicit weak model and guide generation\naway from it. Among these approaches, attention perturbation has demonstrated\nstrong empirical performance in unconditional scenarios where classifier-free\nguidance is not applicable. However, existing attention perturbation methods\nlack principled approaches for determining where perturbations should be\napplied, particularly in Diffusion Transformer (DiT) architectures where\nquality-relevant computations are distributed across layers. In this paper, we\ninvestigate the granularity of attention perturbations, ranging from the layer\nlevel down to individual attention heads, and discover that specific heads\ngovern distinct visual concepts such as structure, style, and texture quality.\nBuilding on this insight, we propose \"HeadHunter\", a systematic framework for\niteratively selecting attention heads that align with user-centric objectives,\nenabling fine-grained control over generation quality and visual attributes. In\naddition, we introduce SoftPAG, which linearly interpolates each selected\nhead's attention map toward an identity matrix, providing a continuous knob to\ntune perturbation strength and suppress artifacts. Our approach not only\nmitigates the oversmoothing issues of existing layer-level perturbation but\nalso enables targeted manipulation of specific visual styles through\ncompositional head selection. We validate our method on modern large-scale\nDiT-based text-to-image models including Stable Diffusion 3 and FLUX.1,\ndemonstrating superior performance in both general quality enhancement and\nstyle-specific guidance. Our work provides the first head-level analysis of\nattention perturbation in diffusion models, uncovering interpretable\nspecialization within attention layers and enabling practical design of\neffective perturbation strategies.", "AI": {"tldr": "The paper introduces 'HeadHunter' and 'SoftPAG' for fine-grained control in diffusion models by perturbing specific attention heads, improving generation quality and visual attributes.", "motivation": "Existing attention perturbation methods lack principled approaches for determining perturbation locations, especially in Diffusion Transformer architectures.", "method": "Investigates granularity of attention perturbations, proposes 'HeadHunter' for selecting attention heads and 'SoftPAG' for tuning perturbation strength.", "result": "Demonstrates superior performance in quality enhancement and style-specific guidance on models like Stable Diffusion 3 and FLUX.1.", "conclusion": "Provides the first head-level analysis of attention perturbation, enabling interpretable specialization and practical perturbation strategies."}}
{"id": "2505.24765", "pdf": "https://arxiv.org/pdf/2505.24765", "abs": "https://arxiv.org/abs/2505.24765", "authors": ["Srikanth Thudumu", "Jason Fisher", "Hung Du"], "title": "Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications", "categories": ["quant-ph", "cs.AI"], "comment": "Future outlook and roadmap of QML with 7 pages and 1 figure", "summary": "Supervised Quantum Machine Learning (QML) represents an intersection of\nquantum computing and classical machine learning, aiming to use quantum\nresources to support model training and inference. This paper reviews recent\ndevelopments in supervised QML, focusing on methods such as variational quantum\ncircuits, quantum neural networks, and quantum kernel methods, along with\nhybrid quantum-classical workflows. We examine recent experimental studies that\nshow partial indications of quantum advantage and describe current limitations\nincluding noise, barren plateaus, scalability issues, and the lack of formal\nproofs of performance improvement over classical methods. The main contribution\nis a ten-year outlook (2025-2035) that outlines possible developments in\nsupervised QML, including a roadmap describing conditions under which QML may\nbe used in applied research and enterprise systems over the next decade.", "AI": {"tldr": "A review of supervised quantum machine learning (QML) methods, challenges, and a 10-year outlook for potential advancements.", "motivation": "To explore how quantum computing can enhance classical machine learning, focusing on supervised QML methods and their practical applications.", "method": "Reviews variational quantum circuits, quantum neural networks, quantum kernel methods, and hybrid workflows, alongside experimental studies.", "result": "Identifies partial quantum advantages but highlights limitations like noise, scalability, and lack of formal proofs.", "conclusion": "Provides a roadmap for supervised QML's future (2025-2035), outlining conditions for its practical use in applied research and enterprise systems."}}
{"id": "2506.20554", "pdf": "https://arxiv.org/pdf/2506.20554", "abs": "https://arxiv.org/abs/2506.20554", "authors": ["Andrew Mole", "Max Weissenbacher", "Georgios Rigas", "Sylvain Laizet"], "title": "Reinforcement Learning Increases Wind Farm Power Production by Enabling Closed-Loop Collaborative Control", "categories": ["physics.flu-dyn", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Traditional wind farm control operates each turbine independently to maximize\nindividual power output. However, coordinated wake steering across the entire\nfarm can substantially increase the combined wind farm energy production.\nAlthough dynamic closed-loop control has proven effective in flow control\napplications, wind farm optimization has relied primarily on static,\nlow-fidelity simulators that ignore critical turbulent flow dynamics. In this\nwork, we present the first reinforcement learning (RL) controller integrated\ndirectly with high-fidelity large-eddy simulation (LES), enabling real-time\nresponse to atmospheric turbulence through collaborative, dynamic control\nstrategies. Our RL controller achieves a 4.30% increase in wind farm power\noutput compared to baseline operation, nearly doubling the 2.19% gain from\nstatic optimal yaw control obtained through Bayesian optimization. These\nresults establish dynamic flow-responsive control as a transformative approach\nto wind farm optimization, with direct implications for accelerating renewable\nenergy deployment to net-zero targets.", "AI": {"tldr": "A reinforcement learning (RL) controller integrated with high-fidelity large-eddy simulation (LES) improves wind farm power output by 4.30%, outperforming traditional static methods.", "motivation": "Traditional wind farm control optimizes individual turbines, missing potential gains from coordinated wake steering. Dynamic control is needed to address turbulent flow dynamics.", "method": "The study integrates RL with high-fidelity LES for real-time, dynamic control of wind turbines, responding to atmospheric turbulence.", "result": "The RL controller increases wind farm power output by 4.30%, nearly doubling the gains from static optimal yaw control (2.19%).", "conclusion": "Dynamic flow-responsive control is transformative for wind farm optimization, aiding renewable energy goals."}}
{"id": "2506.15549", "pdf": "https://arxiv.org/pdf/2506.15549", "abs": "https://arxiv.org/abs/2506.15549", "authors": ["Farheen Ramzan", "Yusuf Kiberu", "Nikesh Jathanna", "Shahnaz Jamil-Copley", "Richard H. Clayton", "Chen Chen"], "title": "CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "14 Pages", "summary": "Deep learning-based myocardial scar segmentation from late gadolinium\nenhancement (LGE) cardiac MRI has shown great potential for accurate and timely\ndiagnosis and treatment planning for structural cardiac diseases. However, the\nlimited availability and variability of LGE images with high-quality scar\nlabels restrict the development of robust segmentation models. To address this,\nwe introduce CLAIM: \\textbf{C}linically-Guided \\textbf{L}GE\n\\textbf{A}ugmentation for Real\\textbf{i}stic and Diverse \\textbf{M}yocardial\nScar Synthesis and Segmentation framework, a framework for anatomically\ngrounded scar generation and segmentation. At its core is the SMILE module\n(Scar Mask generation guided by cLinical knowledgE), which conditions a\ndiffusion-based generator on the clinically adopted AHA 17-segment model to\nsynthesize images with anatomically consistent and spatially diverse scar\npatterns. In addition, CLAIM employs a joint training strategy in which the\nscar segmentation network is optimized alongside the generator, aiming to\nenhance both the realism of synthesized scars and the accuracy of the scar\nsegmentation performance. Experimental results show that CLAIM produces\nanatomically coherent scar patterns and achieves higher Dice similarity with\nreal scar distributions compared to baseline models. Our approach enables\ncontrollable and realistic myocardial scar synthesis and has demonstrated\nutility for downstream medical imaging task. Code is available at\nhttps://github.com/farheenjabeen/CLAIM-Scar-Synthesis.", "AI": {"tldr": "CLAIM is a framework for generating realistic and diverse myocardial scar images from LGE cardiac MRI using clinical guidance, improving scar segmentation accuracy.", "motivation": "Limited availability and variability of high-quality labeled LGE images hinder robust scar segmentation model development.", "method": "CLAIM uses the SMILE module (diffusion-based generator guided by clinical AHA 17-segment model) and joint training of scar synthesis and segmentation networks.", "result": "CLAIM produces anatomically coherent scars and outperforms baselines in Dice similarity with real scar distributions.", "conclusion": "CLAIM enables controllable, realistic scar synthesis and enhances downstream medical imaging tasks."}}
{"id": "2506.07744", "pdf": "https://arxiv.org/pdf/2506.07744", "abs": "https://arxiv.org/abs/2506.07744", "authors": ["Seungho Baek", "Taegeon Park", "Jongchan Park", "Seungjun Oh", "Yusung Kim"], "title": "Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "ICML 2025", "summary": "Existing offline hierarchical reinforcement learning methods rely on\nhigh-level policy learning to generate subgoal sequences. However, their\nefficiency degrades as task horizons increase, and they lack effective\nstrategies for stitching useful state transitions across different\ntrajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that\nformulates subgoal selection as a graph search problem rather than learning an\nexplicit high-level policy. By embedding states into a Temporal Distance\nRepresentation (TDR) space, GAS clusters semantically similar states from\ndifferent trajectories into unified graph nodes, enabling efficient transition\nstitching. A shortest-path algorithm is then applied to select subgoal\nsequences within the graph, while a low-level policy learns to reach the\nsubgoals. To improve graph quality, we introduce the Temporal Efficiency (TE)\nmetric, which filters out noisy or inefficient transition states, significantly\nenhancing task performance. GAS outperforms prior offline HRL methods across\nlocomotion, navigation, and manipulation tasks. Notably, in the most\nstitching-critical task, it achieves a score of 88.3, dramatically surpassing\nthe previous state-of-the-art score of 1.0. Our source code is available at:\nhttps://github.com/qortmdgh4141/GAS.", "AI": {"tldr": "GAS replaces high-level policy learning with graph search for subgoal selection, improving efficiency and stitching in offline hierarchical reinforcement learning.", "motivation": "Existing methods degrade with longer task horizons and lack effective transition stitching.", "method": "GAS uses Temporal Distance Representation (TDR) for state clustering and a shortest-path algorithm for subgoal selection, enhanced by the Temporal Efficiency (TE) metric.", "result": "GAS outperforms prior methods, achieving 88.3 in a critical task vs. the previous 1.0.", "conclusion": "GAS is a novel, effective framework for offline hierarchical reinforcement learning."}}
{"id": "2506.20573", "pdf": "https://arxiv.org/pdf/2506.20573", "abs": "https://arxiv.org/abs/2506.20573", "authors": ["Kristian Minchev", "Dimitar Iliev Dimitrov", "Nikola Konstantinov"], "title": "LARP: Learner-Agnostic Robust Data Prefiltering", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The widespread availability of large public datasets is a key factor behind\nthe recent successes of statistical inference and machine learning methods.\nHowever, these datasets often contain some low-quality or contaminated data, to\nwhich many learning procedures are sensitive. Therefore, the question of\nwhether and how public datasets should be prefiltered to facilitate accurate\ndownstream learning arises. On a technical level this requires the construction\nof principled data prefiltering methods which are learner-agnostic robust, in\nthe sense of provably protecting a set of pre-specified downstream learners\nfrom corrupted data. In this work, we formalize the problem of Learner-Agnostic\nRobust data Prefiltering (LARP), which aims at finding prefiltering procedures\nthat minimize a worst-case loss over a pre-specified set of learners. We first\ninstantiate our framework in the context of scalar mean estimation with Huber\nestimators under the Huber data contamination model. We provide a hardness\nresult on a specific problem instance and analyze several natural prefiltering\nprocedures. Our theoretical results indicate that performing LARP on a\nheterogeneous set of learners leads to some loss in model performance compared\nto the alternative of prefiltering data for each learner/use-case individually.\nWe explore the resulting utility loss and its dependence on the problem\nparameters via extensive experiments on real-world image and tabular data,\nobserving statistically significant reduction in utility. Finally, we model the\ntrade-off between the utility drop and the cost of repeated (learner-specific)\nprefiltering within a game-theoretic framework and showcase benefits of LARP\nfor large datasets.", "AI": {"tldr": "The paper introduces Learner-Agnostic Robust Prefiltering (LARP) to address data contamination in public datasets, analyzing its impact on downstream learning and trade-offs between utility and cost.", "motivation": "Public datasets often contain low-quality or contaminated data, which can negatively affect machine learning models. The paper aims to develop robust prefiltering methods that protect downstream learners without being tailored to specific learners.", "method": "The authors formalize LARP, focusing on scalar mean estimation with Huber estimators under the Huber contamination model. They analyze natural prefiltering procedures and provide theoretical and empirical results.", "result": "Theoretical and experimental results show that LARP incurs a utility loss compared to learner-specific prefiltering but offers cost benefits for large datasets.", "conclusion": "LARP provides a practical solution for robust data prefiltering, balancing utility and cost, especially for large datasets."}}
{"id": "2506.17221", "pdf": "https://arxiv.org/pdf/2506.17221", "abs": "https://arxiv.org/abs/2506.17221", "authors": ["Zhangyang Qi", "Zhixiong Zhang", "Yizhou Yu", "Jiaqi Wang", "Hengshuang Zhao"], "title": "VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning", "categories": ["cs.CV"], "comment": "project page: vlnr1.github.io", "summary": "Vision-Language Navigation (VLN) is a core challenge in embodied AI,\nrequiring agents to navigate real-world environments using natural language\ninstructions. Current language model-based navigation systems operate on\ndiscrete topological graphs, limiting path planning to predefined node\nconnections. We propose VLN-R1, an end-to-end framework that leverages Large\nVision-Language Models (LVLM) to directly translate egocentric video streams\ninto continuous navigation actions, adopting GRPO-based training inspired by\nDeepSeek-R1. To enable effective training, we first construct the VLN-Ego\ndataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling\nto balance historical and current observations. While large language models can\nsupervise complete textual instructions, they lack fine-grained action-level\ncontrol. Our framework employs a two-stage training approach: a) Supervised\nfine-tuning (SFT) to align the model's action sequence text predictions with\nexpert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced\nwith a Time-Decayed Reward (TDR) mechanism that strategically weights\nmulti-step future actions. Experimental results show VLN-R1 achieves strong\nperformance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied\nnavigation and enhance task-specific reasoning through data-efficient,\nreward-driven post-training.", "AI": {"tldr": "VLN-R1 is an end-to-end framework using Large Vision-Language Models (LVLM) for continuous navigation, trained with GRPO-based methods and a two-stage approach (SFT and RFT). It outperforms on VLN-CE benchmarks.", "motivation": "Current VLN systems rely on discrete topological graphs, limiting flexibility. VLN-R1 aims to enable continuous navigation using LVLMs for better adaptability and performance.", "method": "VLN-R1 uses LVLMs to translate egocentric video into actions. Training involves supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) with Time-Decayed Reward (TDR). The VLN-Ego dataset and Long-Short Memory Sampling are introduced.", "result": "VLN-R1 achieves strong performance on the VLN-CE benchmark, demonstrating LVLMs' capability for embodied navigation.", "conclusion": "VLN-R1 shows LVLMs can enhance embodied navigation through data-efficient, reward-driven training, improving task-specific reasoning."}}
{"id": "2506.13087", "pdf": "https://arxiv.org/pdf/2506.13087", "abs": "https://arxiv.org/abs/2506.13087", "authors": ["Zeyu Zhang", "Ziyuan Jiao"], "title": "IKDiffuser: A Generative Inverse Kinematics Solver for Multi-arm Robots via Diffusion Model", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "under review", "summary": "Solving Inverse Kinematics (IK) problems is fundamental to robotics, but has\nprimarily been successful with single serial manipulators. For multi-arm\nrobotic systems, IK remains challenging due to complex self-collisions, coupled\njoints, and high-dimensional redundancy. These complexities make traditional IK\nsolvers slow, prone to failure, and lacking in solution diversity. In this\npaper, we present IKDiffuser, a diffusion-based model designed for fast and\ndiverse IK solution generation for multi-arm robotic systems. IKDiffuser learns\nthe joint distribution over the configuration space, capturing complex\ndependencies and enabling seamless generalization to multi-arm robotic systems\nof different structures. In addition, IKDiffuser can incorporate additional\nobjectives during inference without retraining, offering versatility and\nadaptability for task-specific requirements. In experiments on 6 different\nmulti-arm systems, the proposed IKDiffuser achieves superior solution accuracy,\nprecision, diversity, and computational efficiency compared to existing\nsolvers. The proposed IKDiffuser framework offers a scalable, unified approach\nto solving multi-arm IK problems, facilitating the potential of multi-arm\nrobotic systems in real-time manipulation tasks.", "AI": {"tldr": "IKDiffuser is a diffusion-based model for solving Inverse Kinematics (IK) in multi-arm robotic systems, offering fast, diverse solutions and adaptability without retraining.", "motivation": "Traditional IK solvers struggle with multi-arm systems due to complexity, slow performance, and lack of solution diversity.", "method": "IKDiffuser learns the joint distribution over the configuration space, capturing dependencies and enabling generalization to various multi-arm systems.", "result": "IKDiffuser outperforms existing solvers in accuracy, precision, diversity, and efficiency across 6 multi-arm systems.", "conclusion": "IKDiffuser provides a scalable, unified solution for multi-arm IK problems, enhancing real-time manipulation potential."}}
{"id": "2506.20630", "pdf": "https://arxiv.org/pdf/2506.20630", "abs": "https://arxiv.org/abs/2506.20630", "authors": ["Zhaosong Lu", "Yifeng Xiao"], "title": "First-order methods for stochastic and finite-sum convex optimization with deterministic constraints", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "comment": "41 pages", "summary": "In this paper, we study a class of stochastic and finite-sum convex\noptimization problems with deterministic constraints. Existing methods\ntypically aim to find an $\\epsilon$-$expectedly\\ feasible\\ stochastic\\ optimal$\nsolution, in which the expected constraint violation and expected optimality\ngap are both within a prescribed tolerance $\\epsilon$. However, in many\npractical applications, constraints must be nearly satisfied with certainty,\nrendering such solutions potentially unsuitable due to the risk of substantial\nviolations. To address this issue, we propose stochastic first-order methods\nfor finding an $\\epsilon$-$surely\\ feasible\\ stochastic\\ optimal$\n($\\epsilon$-SFSO) solution, where the constraint violation is deterministically\nbounded by $\\epsilon$ and the expected optimality gap is at most $\\epsilon$.\nOur methods apply an accelerated stochastic gradient (ASG) scheme or a modified\nvariance-reduced ASG scheme $only\\ once$ to a sequence of quadratic penalty\nsubproblems with appropriately chosen penalty parameters. We establish\nfirst-order oracle complexity bounds for the proposed methods in computing an\n$\\epsilon$-SFSO solution. As a byproduct, we also derive first-order oracle\ncomplexity results for sample average approximation method in computing an\n$\\epsilon$-SFSO solution of the stochastic optimization problem using our\nproposed methods to solve the sample average problem.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.17892", "pdf": "https://arxiv.org/pdf/2506.17892", "abs": "https://arxiv.org/abs/2506.17892", "authors": ["Jianghong Huang", "Luping Ji", "Xin Ma", "Mao Ye"], "title": "BeltCrack: the First Sequential-image Industrial Conveyor Belt Crack Detection Dataset and Its Baseline with Triple-domain Feature Learning", "categories": ["cs.CV", "cs.LG"], "comment": "14 pages, 10 figures", "summary": "Conveyor belts are important equipment in modern industry, widely applied in\nproduction and manufacturing. Their health is much critical to operational\nefficiency and safety. Cracks are a major threat to belt health. Currently,\nconsidering safety, how to intelligently detect belt cracks is catching an\nincreasing attention. To implement the intelligent detection with machine\nlearning, real crack samples are believed to be necessary. However, existing\ncrack datasets primarily focus on pavement scenarios or synthetic data, no\nreal-world industrial belt crack datasets at all. Cracks are a major threat to\nbelt health. Furthermore, to validate usability and effectiveness, we propose a\nspecial baseline method with triple-domain ($i.e.$, time-space-frequency)\nfeature hierarchical fusion learning for the two whole-new datasets.\nExperimental results demonstrate the availability and effectiveness of our\ndataset. Besides, they also show that our baseline is obviously superior to\nother similar detection methods. Our datasets and source codes are available at\nhttps://github.com/UESTC-nnLab/BeltCrack.", "AI": {"tldr": "The paper addresses the lack of real-world industrial belt crack datasets and proposes a baseline method for intelligent crack detection using triple-domain feature fusion.", "motivation": "Conveyor belt cracks threaten operational efficiency and safety, but existing datasets focus on pavement or synthetic data, lacking real-world industrial examples.", "method": "A baseline method with triple-domain (time-space-frequency) feature hierarchical fusion learning is proposed for crack detection.", "result": "Experiments confirm the dataset's availability and effectiveness, with the baseline outperforming similar detection methods.", "conclusion": "The work provides a valuable dataset and a superior baseline method for industrial belt crack detection."}}
{"id": "2506.13205", "pdf": "https://arxiv.org/pdf/2506.13205", "abs": "https://arxiv.org/abs/2506.13205", "authors": ["Xuan Wang", "Siyuan Liang", "Zhe Liu", "Yi Yu", "Yuliang Lu", "Xiaochun Cao", "Ee-Chien Chang", "Xitong Gao"], "title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments", "categories": ["cs.CR", "cs.AI"], "comment": "12 pages", "summary": "With the growing integration of vision-language models (VLMs), mobile agents\nare now widely used for tasks like UI automation and camera-based user\nassistance. These agents are often fine-tuned on limited user-generated\ndatasets, leaving them vulnerable to covert threats during the training\nprocess. In this work we present GHOST, the first clean-label backdoor attack\nspecifically designed for mobile agents built upon VLMs. Our method manipulates\nonly the visual inputs of a portion of the training samples - without altering\ntheir corresponding labels or instructions - thereby injecting malicious\nbehaviors into the model. Once fine-tuned with this tampered data, the agent\nwill exhibit attacker-controlled responses when a specific visual trigger is\nintroduced at inference time. The core of our approach lies in aligning the\ngradients of poisoned samples with those of a chosen target instance, embedding\nbackdoor-relevant features into the poisoned training data. To maintain stealth\nand enhance robustness, we develop three realistic visual triggers: static\nvisual patches, dynamic motion cues, and subtle low-opacity overlays. We\nevaluate our method across six real-world Android apps and three VLM\narchitectures adapted for mobile use. Results show that our attack achieves\nhigh attack success rates (up to 94.67 percent) while maintaining high\nclean-task performance (FSR up to 95.85 percent). Additionally, ablation\nstudies shed light on how various design choices affect the efficacy and\nconcealment of the attack. Overall, this work is the first to expose critical\nsecurity flaws in VLM-based mobile agents, highlighting their susceptibility to\nclean-label backdoor attacks and the urgent need for effective defense\nmechanisms in their training pipelines.", "AI": {"tldr": "GHOST is a clean-label backdoor attack method for vision-language model (VLM)-based mobile agents, manipulating visual inputs to inject malicious behaviors without altering labels, achieving high attack success and clean-task performance.", "motivation": "Mobile agents using VLMs are vulnerable to covert threats during training due to reliance on limited datasets, necessitating exploration of security flaws.", "method": "GHOST aligns gradients of poisoned samples with a target instance, using static patches, dynamic motion cues, or subtle overlays as triggers.", "result": "Achieves up to 94.67% attack success and 95.85% clean-task performance across six Android apps and three VLM architectures.", "conclusion": "Exposes critical security flaws in VLM-based mobile agents, urging the need for defense mechanisms in training pipelines."}}
{"id": "2506.20668", "pdf": "https://arxiv.org/pdf/2506.20668", "abs": "https://arxiv.org/abs/2506.20668", "authors": ["Sungjae Park", "Homanga Bharadhwaj", "Shubham Tulsiani"], "title": "DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy", "categories": ["cs.RO", "cs.LG"], "comment": "Preprint(17 pages). Under Review", "summary": "We propose DemoDiffusion, a simple and scalable method for enabling robots to\nperform manipulation tasks in natural environments by imitating a single human\ndemonstration. Our approach is based on two key insights. First, the hand\nmotion in a human demonstration provides a useful prior for the robot's\nend-effector trajectory, which we can convert into a rough open-loop robot\nmotion trajectory via kinematic retargeting. Second, while this retargeted\nmotion captures the overall structure of the task, it may not align well with\nplausible robot actions in-context. To address this, we leverage a pre-trained\ngeneralist diffusion policy to modify the trajectory, ensuring it both follows\nthe human motion and remains within the distribution of plausible robot\nactions. Our approach avoids the need for online reinforcement learning or\npaired human-robot data, enabling robust adaptation to new tasks and scenes\nwith minimal manual effort. Experiments in both simulation and real-world\nsettings show that DemoDiffusion outperforms both the base policy and the\nretargeted trajectory, enabling the robot to succeed even on tasks where the\npre-trained generalist policy fails entirely. Project page:\nhttps://demodiffusion.github.io/", "AI": {"tldr": "DemoDiffusion enables robots to imitate human demonstrations for manipulation tasks by combining kinematic retargeting and a diffusion policy, outperforming baseline methods without needing online reinforcement learning.", "motivation": "To simplify and scale robot manipulation tasks in natural environments by leveraging single human demonstrations, avoiding the need for paired human-robot data or online reinforcement learning.", "method": "Uses kinematic retargeting to convert human hand motion into a rough robot trajectory, then refines it with a pre-trained diffusion policy to align with plausible robot actions.", "result": "Outperforms baseline methods in simulation and real-world tasks, succeeding where pre-trained policies fail.", "conclusion": "DemoDiffusion robustly adapts to new tasks with minimal manual effort, demonstrating the effectiveness of combining human priors with diffusion policies."}}
{"id": "2506.19416", "pdf": "https://arxiv.org/pdf/2506.19416", "abs": "https://arxiv.org/abs/2506.19416", "authors": ["Yin Zhang", "Zian Ning", "Xiaoyu Zhang", "Shiliang Guo", "Peidong Liu", "Shiyu Zhao"], "title": "EvDetMAV: Generalized MAV Detection from Moving Event Cameras", "categories": ["cs.CV", "cs.RO"], "comment": "8 pages, 7 figures. This paper is accepted by IEEE Robotics and\n  Automation Letters", "summary": "Existing micro aerial vehicle (MAV) detection methods mainly rely on the\ntarget's appearance features in RGB images, whose diversity makes it difficult\nto achieve generalized MAV detection. We notice that different types of MAVs\nshare the same distinctive features in event streams due to their high-speed\nrotating propellers, which are hard to see in RGB images. This paper studies\nhow to detect different types of MAVs from an event camera by fully exploiting\nthe features of propellers in the original event stream. The proposed method\nconsists of three modules to extract the salient and spatio-temporal features\nof the propellers while filtering out noise from background objects and camera\nmotion. Since there are no existing event-based MAV datasets, we introduce a\nnovel MAV dataset for the community. This is the first event-based MAV dataset\ncomprising multiple scenarios and different types of MAVs. Without training,\nour method significantly outperforms state-of-the-art methods and can deal with\nchallenging scenarios, achieving a precision rate of 83.0\\% (+30.3\\%) and a\nrecall rate of 81.5\\% (+36.4\\%) on the proposed testing dataset. The dataset\nand code are available at: https://github.com/WindyLab/EvDetMAV.", "AI": {"tldr": "The paper proposes a method for detecting micro aerial vehicles (MAVs) using event cameras by focusing on propeller features in event streams, outperforming RGB-based methods without training.", "motivation": "Existing MAV detection methods rely on RGB images, which lack generalized detection due to diverse appearances. Event streams capture propeller features better.", "method": "Three modules extract propeller features from event streams while filtering noise. A novel event-based MAV dataset is introduced.", "result": "The method achieves 83.0% precision (+30.3%) and 81.5% recall (+36.4%) on the new dataset, outperforming state-of-the-art methods.", "conclusion": "Event-based detection is effective for MAVs, and the introduced dataset supports further research."}}
{"id": "2506.16014", "pdf": "https://arxiv.org/pdf/2506.16014", "abs": "https://arxiv.org/abs/2506.16014", "authors": ["Jina Kim", "Youjin Jang", "Jeongjin Han"], "title": "VRAIL: Vectorized Reward-based Attribution for Interpretable Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose VRAIL (Vectorized Reward-based Attribution for Interpretable\nLearning), a bi-level framework for value-based reinforcement learning (RL)\nthat learns interpretable weight representations from state features. VRAIL\nconsists of two stages: a deep learning (DL) stage that fits an estimated value\nfunction using state features, and an RL stage that uses this to shape learning\nvia potential-based reward transformations. The estimator is modeled in either\nlinear or quadratic form, allowing attribution of importance to individual\nfeatures and their interactions. Empirical results on the Taxi-v3 environment\ndemonstrate that VRAIL improves training stability and convergence compared to\nstandard DQN, without requiring environment modifications. Further analysis\nshows that VRAIL uncovers semantically meaningful subgoals, such as passenger\npossession, highlighting its ability to produce human-interpretable behavior.\nOur findings suggest that VRAIL serves as a general, model-agnostic framework\nfor reward shaping that enhances both learning and interpretability.", "AI": {"tldr": "VRAIL is a bi-level RL framework combining deep learning and reward shaping to improve interpretability and learning stability.", "motivation": "To enhance interpretability and stability in RL by attributing importance to state features and their interactions.", "method": "Uses a DL stage to estimate value functions and an RL stage for reward shaping, with linear or quadratic modeling for feature attribution.", "result": "Improves training stability and convergence in Taxi-v3, identifies meaningful subgoals, and enhances interpretability.", "conclusion": "VRAIL is a model-agnostic framework that boosts learning and interpretability in RL."}}
{"id": "2103.15589", "pdf": "https://arxiv.org/pdf/2103.15589", "abs": "https://arxiv.org/abs/2103.15589", "authors": ["George Bird", "Maxim E. Polivoda"], "title": "Backpropagation Through Time For Networks With Long-Term Dependencies", "categories": ["cs.LG", "68T07, 68Q32", "I.2.6"], "comment": "8 Pages, 1 Figure; typos corrected, references added, altered section\n  titles, added further commentary in section 2.1", "summary": "Backpropagation through time (BPTT) is a technique of updating tuned\nparameters within recurrent neural networks (RNNs). Several attempts at\ncreating such an algorithm have been made including: Nth Ordered Approximations\nand Truncated-BPTT. These methods approximate the backpropagation gradients\nunder the assumption that the RNN only utilises short-term dependencies. This\nis an acceptable assumption to make for the current state of artificial neural\nnetworks. As RNNs become more advanced, a shift towards influence by long-term\ndependencies is likely. Thus, a new method for backpropagation is required. We\npropose using the 'discrete forward sensitivity equation' and a variant of it\nfor single and multiple interacting recurrent loops respectively. This solution\nis exact and also allows the network's parameters to vary between each\nsubsequent step, however it does require the computation of a Jacobian.", "AI": {"tldr": "A new exact method for backpropagation in RNNs using discrete forward sensitivity equations is proposed, addressing long-term dependencies and allowing parameter variation, though it requires Jacobian computation.", "motivation": "Current BPTT methods assume short-term dependencies in RNNs, but as RNNs advance, long-term dependencies will become more influential, necessitating a new approach.", "method": "The proposed method uses the 'discrete forward sensitivity equation' and its variant for single and multiple interacting recurrent loops, enabling exact backpropagation with parameter variation.", "result": "The solution is exact and accommodates parameter changes between steps, but involves Jacobian computation.", "conclusion": "The proposed method addresses the limitations of existing BPTT techniques for advanced RNNs, though it introduces computational complexity with the Jacobian."}}
{"id": "2506.19442", "pdf": "https://arxiv.org/pdf/2506.19442", "abs": "https://arxiv.org/abs/2506.19442", "authors": ["R\u00f3is\u00edn Luo", "James McDermott", "Colm O'Riordan"], "title": "Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty", "categories": ["cs.CV"], "comment": "Code:\n  https://anonymous.4open.science/r/sampling_matters_reproducibility-BB60/", "summary": "Image attribution analysis seeks to highlight the feature representations\nlearned by visual models such that the highlighted feature maps can reflect the\npixel-wise importance of inputs. Gradient integration is a building block in\nthe attribution analysis by integrating the gradients from multiple derived\nsamples to highlight the semantic features relevant to inferences. Such a\nbuilding block often combines with other information from visual models such as\nactivation or attention maps to form ultimate explanations. Yet, our\ntheoretical analysis demonstrates that the extent to the alignment of the\nsample distribution in gradient integration with respect to natural image\ndistribution gives a lower bound of explanation certainty. Prior works add\nnoise into images as samples and the noise distributions can lead to low\nexplanation certainty. Counter-intuitively, our experiment shows that extra\ninformation can saturate neural networks. To this end, building trustworthy\nattribution analysis needs to settle the sample distribution misalignment\nproblem. Instead of adding extra information into input images, we present a\nsemi-optimal sampling approach by suppressing features from inputs. The sample\ndistribution by suppressing features is approximately identical to the\ndistribution of natural images. Our extensive quantitative evaluation on large\nscale dataset ImageNet affirms that our approach is effective and able to yield\nmore satisfactory explanations against state-of-the-art baselines throughout\nall experimental models.", "AI": {"tldr": "The paper addresses the misalignment of sample distribution in gradient integration for image attribution analysis, proposing a semi-optimal sampling approach by suppressing features to improve explanation certainty.", "motivation": "Prior methods add noise to images for gradient integration, leading to low explanation certainty due to misalignment with natural image distribution.", "method": "A semi-optimal sampling approach suppresses features from inputs to align sample distribution with natural images, avoiding noise addition.", "result": "Extensive evaluation on ImageNet shows the approach outperforms state-of-the-art baselines, yielding more satisfactory explanations.", "conclusion": "Trustworthy attribution analysis requires addressing sample distribution misalignment; suppressing features provides a more effective solution than noise addition."}}
{"id": "2506.16791", "pdf": "https://arxiv.org/pdf/2506.16791", "abs": "https://arxiv.org/abs/2506.16791", "authors": ["Nick Erickson", "Lennart Purucker", "Andrej Tschalzev", "David Holzm\u00fcller", "Prateek Mutalik Desai", "David Salinas", "Frank Hutter"], "title": "TabArena: A Living Benchmark for Machine Learning on Tabular Data", "categories": ["cs.LG", "cs.AI"], "comment": "v2: fixed author list. 51 pages. Code available at\n  https://tabarena.ai/code; examples at https://tabarena.ai/code-examples;\n  dataset curation at https://tabarena.ai/data-tabular-ml-iid-study and\n  https://tabarena.ai/dataset-curation", "summary": "With the growing popularity of deep learning and foundation models for\ntabular data, the need for standardized and reliable benchmarks is higher than\never. However, current benchmarks are static. Their design is not updated even\nif flaws are discovered, model versions are updated, or new models are\nreleased. To address this, we introduce TabArena, the first continuously\nmaintained living tabular benchmarking system. To launch TabArena, we manually\ncurate a representative collection of datasets and well-implemented models,\nconduct a large-scale benchmarking study to initialize a public leaderboard,\nand assemble a team of experienced maintainers. Our results highlight the\ninfluence of validation method and ensembling of hyperparameter configurations\nto benchmark models at their full potential. While gradient-boosted trees are\nstill strong contenders on practical tabular datasets, we observe that deep\nlearning methods have caught up under larger time budgets with ensembling. At\nthe same time, foundation models excel on smaller datasets. Finally, we show\nthat ensembles across models advance the state-of-the-art in tabular machine\nlearning and investigate the contributions of individual models. We launch\nTabArena with a public leaderboard, reproducible code, and maintenance\nprotocols to create a living benchmark available at https://tabarena.ai.", "AI": {"tldr": "TabArena introduces a continuously maintained benchmarking system for tabular data, addressing flaws in static benchmarks by updating datasets, models, and methodologies.", "motivation": "Current benchmarks for tabular data are static and outdated, failing to adapt to new models or discovered flaws.", "method": "TabArena manually curates datasets and models, conducts large-scale benchmarking, and establishes a maintenance team.", "result": "Gradient-boosted trees remain strong, but deep learning and foundation models show promise under certain conditions. Ensembles advance state-of-the-art.", "conclusion": "TabArena provides a dynamic, living benchmark with a public leaderboard and maintenance protocols to ensure reliability and relevance."}}
{"id": "2309.05019", "pdf": "https://arxiv.org/pdf/2309.05019", "abs": "https://arxiv.org/abs/2309.05019", "authors": ["Shuchen Xue", "Mingyang Yi", "Weijian Luo", "Shifeng Zhang", "Jiacheng Sun", "Zhenguo Li", "Zhi-Ming Ma"], "title": "SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted in NeurIPS 2023", "summary": "Diffusion Probabilistic Models (DPMs) have achieved considerable success in\ngeneration tasks. As sampling from DPMs is equivalent to solving diffusion SDE\nor ODE which is time-consuming, numerous fast sampling methods built upon\nimproved differential equation solvers are proposed. The majority of such\ntechniques consider solving the diffusion ODE due to its superior efficiency.\nHowever, stochastic sampling could offer additional advantages in generating\ndiverse and high-quality data. In this work, we engage in a comprehensive\nanalysis of stochastic sampling from two aspects: variance-controlled diffusion\nSDE and linear multi-step SDE solver. Based on our analysis, we propose\n\\textit{SA-Solver}, which is an improved efficient stochastic Adams method for\nsolving diffusion SDE to generate data with high quality. Our experiments show\nthat \\textit{SA-Solver} achieves: 1) improved or comparable performance\ncompared with the existing state-of-the-art (SOTA) sampling methods for\nfew-step sampling; 2) SOTA FID on substantial benchmark datasets under a\nsuitable number of function evaluations (NFEs). Code is available at\nhttps://github.com/scxue/SA-Solver.", "AI": {"tldr": "The paper introduces SA-Solver, an efficient stochastic Adams method for solving diffusion SDEs, improving stochastic sampling for high-quality data generation.", "motivation": "Stochastic sampling in Diffusion Probabilistic Models (DPMs) can enhance diversity and quality, but existing methods focus on deterministic ODEs. This work explores stochastic sampling via variance-controlled SDEs and linear multi-step solvers.", "method": "Proposes SA-Solver, a stochastic Adams method for solving diffusion SDEs, combining variance control and multi-step techniques.", "result": "SA-Solver outperforms or matches SOTA methods in few-step sampling and achieves top FID scores on benchmarks with optimal NFEs.", "conclusion": "SA-Solver advances stochastic sampling in DPMs, offering high-quality data generation with efficiency and diversity."}}
{"id": "2506.19615", "pdf": "https://arxiv.org/pdf/2506.19615", "abs": "https://arxiv.org/abs/2506.19615", "authors": ["Gaurav Sharma", "Ravi Kothari", "Josef Schmid"], "title": "Self-Supervised Multimodal NeRF for Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we propose a Neural Radiance Fields (NeRF) based framework,\nreferred to as Novel View Synthesis Framework (NVSF). It jointly learns the\nimplicit neural representation of space and time-varying scene for both LiDAR\nand Camera. We test this on a real-world autonomous driving scenario containing\nboth static and dynamic scenes. Compared to existing multimodal dynamic NeRFs,\nour framework is self-supervised, thus eliminating the need for 3D labels. For\nefficient training and faster convergence, we introduce heuristic-based image\npixel sampling to focus on pixels with rich information. To preserve the local\nfeatures of LiDAR points, a Double Gradient based mask is employed. Extensive\nexperiments on the KITTI-360 dataset show that, compared to the baseline\nmodels, our framework has reported best performance on both LiDAR and Camera\ndomain. Code of the model is available at\nhttps://github.com/gaurav00700/Selfsupervised-NVSF", "AI": {"tldr": "A self-supervised Neural Radiance Fields (NeRF) framework, NVSF, for joint learning of space and time-varying scenes in LiDAR and Camera data, outperforming baselines on KITTI-360.", "motivation": "To address the need for 3D labels in multimodal dynamic NeRFs by proposing a self-supervised approach for autonomous driving scenarios.", "method": "Uses heuristic-based image pixel sampling for efficient training and a Double Gradient mask for LiDAR point feature preservation.", "result": "Achieves best performance on KITTI-360 dataset for both LiDAR and Camera domains.", "conclusion": "NVSF is effective, self-supervised, and outperforms existing methods without requiring 3D labels."}}
{"id": "2506.17219", "pdf": "https://arxiv.org/pdf/2506.17219", "abs": "https://arxiv.org/abs/2506.17219", "authors": ["Yanzhi Zhang", "Zhaoxi Zhang", "Haoxiang Guan", "Yilin Cheng", "Yitong Duan", "Chen Wang", "Yue Wang", "Shuxin Zheng", "Jiyan He"], "title": "No Free Lunch: Rethinking Internal Feedback for LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning has emerged as a powerful paradigm for post-training\nlarge language models (LLMs) to improve reasoning. Approaches like\nReinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning\nwith Verifiable Rewards (RLVR) have shown strong results, but they require\nextensive external supervision. We investigate an alternative class of methods,\nReinforcement Learning from Internal Feedback (RLIF), which relies solely on\nintrinsic model-derived signals instead of external rewards. In particular, we\nleverage unsupervised reward proxies such as token-level entropy,\ntrajectory-level entropy, and self-certainty. Our theoretical analysis shows\nthese internal objectives are partially equivalent, and we empirically evaluate\nvarious RLIF strategies on challenging math reasoning benchmarks. Experimental\nresults demonstrate that RLIF can boost the reasoning performance of base LLMs\nat the beginning phase of the training, matching or surpassing RLVR techniques\non these tasks. However, when training progresses, performance degrades even\nbelow the model before training. Moreover, we find that RLIF yields little\nimprovement for instruction-tuned models, indicating diminishing returns of\nintrinsic feedback once an LLM is already instruction-tuned. We further analyze\nthis limitation by mixing model weights and explain the reason of RLIF's\ntraining behaviors, providing practical guidelines for integrating internal\nfeedback signals into LLM training. We hope our analysis of internal feedback\nwill inform more principled and effective strategies for LLM post-training.", "AI": {"tldr": "RLIF uses intrinsic signals (e.g., token entropy) for post-training LLMs, showing early gains but degrading later, especially for instruction-tuned models.", "motivation": "To explore alternatives to externally supervised methods (RLHF, RLVR) by leveraging intrinsic model-derived signals.", "method": "Uses unsupervised reward proxies (token-level entropy, trajectory-level entropy, self-certainty) for Reinforcement Learning from Internal Feedback (RLIF).", "result": "RLIF improves reasoning early but degrades later, surpassing RLVR initially but failing for instruction-tuned models.", "conclusion": "RLIF has limited long-term benefits, especially for instruction-tuned models, highlighting the need for better intrinsic feedback strategies."}}
{"id": "2403.17852", "pdf": "https://arxiv.org/pdf/2403.17852", "abs": "https://arxiv.org/abs/2403.17852", "authors": ["Shuyi Chen", "Shixiang Zhu"], "title": "Counterfactual Fairness through Transforming Data Orthogonal to Bias", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Machine learning models have shown exceptional prowess in solving complex\nissues across various domains. However, these models can sometimes exhibit\nbiased decision-making, resulting in unequal treatment of different groups.\nDespite substantial research on counterfactual fairness, methods to reduce the\nimpact of multivariate and continuous sensitive variables on decision-making\noutcomes are still underdeveloped. We propose a novel data pre-processing\nalgorithm, Orthogonal to Bias (OB), which is designed to eliminate the\ninfluence of a group of continuous sensitive variables, thus promoting\ncounterfactual fairness in machine learning applications. Our approach, based\non the assumption of a jointly normal distribution within a structural causal\nmodel (SCM), demonstrates that counterfactual fairness can be achieved by\nensuring the data is orthogonal to the observed sensitive variables. The OB\nalgorithm is model-agnostic, making it applicable to a wide range of machine\nlearning models and tasks. Additionally, it includes a sparse variant to\nimprove numerical stability through regularization. Empirical evaluations on\nboth simulated and real-world datasets, encompassing settings with both\ndiscrete and continuous sensitive variables, show that our methodology\neffectively promotes fairer outcomes without compromising accuracy.", "AI": {"tldr": "The paper introduces the Orthogonal to Bias (OB) algorithm to ensure counterfactual fairness in machine learning by eliminating the influence of continuous sensitive variables.", "motivation": "Machine learning models can exhibit biased decision-making, especially with multivariate and continuous sensitive variables, which current methods inadequately address.", "method": "The OB algorithm, based on a jointly normal distribution within a structural causal model, ensures data orthogonality to sensitive variables. It includes a sparse variant for numerical stability.", "result": "Empirical evaluations show OB effectively promotes fairness without compromising accuracy in both simulated and real-world datasets.", "conclusion": "The OB algorithm is a model-agnostic solution for achieving counterfactual fairness in machine learning, applicable across various tasks."}}
{"id": "2506.19808", "pdf": "https://arxiv.org/pdf/2506.19808", "abs": "https://arxiv.org/abs/2506.19808", "authors": ["Yitao Peng", "Lianghua He", "Die Hu"], "title": "One Prototype Is Enough: Single-Prototype Activation for Interpretable Image Classification", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we propose ProtoSolo, a novel deep neural architecture for\ninterpretable image classification inspired by prototypical networks such as\nProtoPNet. Existing prototype networks usually rely on the collaborative\ndecision-making of multiple prototypes to achieve the classification and\ninterpretation of a single category. In contrast, ProtoSolo only requires the\nactivation of a single prototype to complete the classification. This allows\nthe network to explain each category decision by only providing the features\nthat are most similar to the prototype of that category, significantly reducing\nthe cognitive complexity of the explanation. Secondly, we propose a\nfeature-based comparison method, which uses feature map instead of full-channel\nfeature vector as the object of similarity comparison and prototype learning.\nThis design enables ProtoSolo to utilize richer global information for\nclassification while relying on a single prototype activation. In addition, we\npropose a non-prototype projection learning strategy, which preserves the\ninformation association between the prototype and the training image patches\nwhile avoiding the sharp change of the network structure caused by the\nprojection operation, thus avoiding its negative impact on the classification\nperformance. Experiments on the CUB-200-2011 and Stanford Cars datasets show\nthat ProtoSolo achieves superior performance in classification tasks and\nreaches the best level in terms of cognitive complexity of explanations\ncompared to state-of-the-art interpretable methods. The code is available at\nhttps://github.com/pyt19/ProtoSolo.", "AI": {"tldr": "ProtoSolo is a deep neural architecture for interpretable image classification using a single prototype per category, reducing explanation complexity. It employs feature-based comparison and non-prototype projection learning for better performance.", "motivation": "Existing prototype networks rely on multiple prototypes for classification, increasing cognitive complexity. ProtoSolo aims to simplify this by using a single prototype.", "method": "ProtoSolo uses a single prototype per category, feature map comparisons, and non-prototype projection learning to enhance interpretability and performance.", "result": "Experiments on CUB-200-2011 and Stanford Cars datasets show superior classification performance and lower cognitive complexity compared to state-of-the-art methods.", "conclusion": "ProtoSolo simplifies interpretable image classification with single prototypes, achieving high performance and reduced explanation complexity."}}
{"id": "2506.17253", "pdf": "https://arxiv.org/pdf/2506.17253", "abs": "https://arxiv.org/abs/2506.17253", "authors": ["Chenghan Li", "Mingchen Li", "Yipu Liao", "Ruisheng Diao"], "title": "MS-TVNet:A Long-Term Time Series Prediction Method Based on Multi-Scale Dynamic Convolution", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Long-term time series prediction has predominantly relied on Transformer and\nMLP models, while the potential of convolutional networks in this domain\nremains underexplored. To address this gap, we introduce a novel multi-scale\ntime series reshape module, which effectively captures the relationships among\nmulti-period patches and variable dependencies. Building upon this module, we\npropose MS-TVNet, a multi-scale 3D dynamic convolutional neural network.\nThrough comprehensive evaluations on diverse datasets, MS-TVNet demonstrates\nsuperior performance compared to baseline models, achieving state-of-the-art\n(SOTA) results in long-term time series prediction. Our findings highlight the\neffectiveness of leveraging convolutional networks for capturing complex\ntemporal patterns, suggesting a promising direction for future research in this\nfield.The code is realsed on https://github.com/Curyyfaust/TVNet.", "AI": {"tldr": "The paper introduces MS-TVNet, a multi-scale 3D CNN for long-term time series prediction, outperforming Transformer and MLP models.", "motivation": "To explore the underexplored potential of convolutional networks in long-term time series prediction.", "method": "Proposes a multi-scale time series reshape module and MS-TVNet, a 3D dynamic CNN.", "result": "MS-TVNet achieves SOTA performance on diverse datasets.", "conclusion": "Convolutional networks are effective for capturing complex temporal patterns, offering a promising research direction."}}
{"id": "2409.12335", "pdf": "https://arxiv.org/pdf/2409.12335", "abs": "https://arxiv.org/abs/2409.12335", "authors": ["Ruiyang Hong", "Anastasis Kratsios"], "title": "Bridging the Gap Between Approximation and Learning via Optimal Approximation by ReLU MLPs of Maximal Regularity", "categories": ["cs.LG", "cs.NA", "cs.NE", "math.FA", "math.NA", "stat.ML", "68T07, 41A44, 26A16"], "comment": "16 pages main body, 40 pages proofs, 10 figures, 1 table", "summary": "The foundations of deep learning are supported by the seemingly opposing\nperspectives of approximation or learning theory. The former advocates for\nlarge/expressive models that need not generalize, while the latter considers\nclasses that generalize but may be too small/constrained to be universal\napproximators. Motivated by real-world deep learning implementations that are\nboth expressive and statistically reliable, we ask: \"Is there a class of neural\nnetworks that is both large enough to be universal but structured enough to\ngeneralize?\" This paper constructively provides a positive answer to this\nquestion by identifying a highly structured class of ReLU multilayer\nperceptions (MLPs), which are optimal function approximators and are\nstatistically well-behaved. We show that any $(L,\\alpha)$-H\\\"{o}lder function\nfrom $[0,1]^d$ to $[-n,n]$ can be approximated to a uniform $\\mathcal{O}(1/n)$\nerror on $[0,1]^d$ with a sparsely connected ReLU MLP with the same H\\\"{o}lder\nexponent $\\alpha$ and coefficient $L$, of width $\\mathcal{O}(dn^{d/\\alpha})$,\ndepth $\\mathcal{O}(\\log(d))$, with $\\mathcal{O}(dn^{d/\\alpha})$ nonzero\nparameters, and whose weights and biases take values in $\\{0,\\pm 1/2\\}$ except\nin the first and last layers which instead have magnitude at-most $n$. Further,\nour class of MLPs achieves a near-optimal sample complexity of\n$\\mathcal{O}(\\log(N)/\\sqrt{N})$ when given $N$ i.i.d. normalized sub-Gaussian\ntraining samples. We achieve this through a new construction that perfectly\nfits together linear pieces using Kuhn triangulations, along with a new proof\ntechnique which shows that our construction preserves the regularity of not\nonly the H\\\"{o}lder functions, but also any uniformly continuous function. Our\nresults imply that neural networks can solve the McShane extension problem on\nsuitable finite sets.", "AI": {"tldr": "The paper identifies a class of ReLU MLPs that are both universal approximators and statistically reliable, achieving optimal function approximation and generalization.", "motivation": "To bridge the gap between expressive but non-generalizing models and generalizing but constrained models, inspired by real-world deep learning implementations.", "method": "Constructs a sparsely connected ReLU MLP class with specific width, depth, and parameter constraints, using Kuhn triangulations to fit linear pieces.", "result": "The MLPs approximate H\u00f6lder functions with uniform error, achieve near-optimal sample complexity, and solve the McShane extension problem.", "conclusion": "Neural networks can be both expressive and statistically reliable, as demonstrated by the constructed MLP class."}}
{"id": "2409.07163", "pdf": "https://arxiv.org/pdf/2409.07163", "abs": "https://arxiv.org/abs/2409.07163", "authors": ["Jiahang Cao", "Qiang Zhang", "Jingkai Sun", "Jiaxu Wang", "Hao Cheng", "Yulin Li", "Jun Ma", "Kun Wu", "Zhiyuan Xu", "Yecheng Shao", "Wen Zhao", "Gang Han", "Yijie Guo", "Renjing Xu"], "title": "Mamba Policy: Towards Efficient 3D Diffusion Policy with Hybrid Selective State Models", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to IROS 2025", "summary": "Diffusion models have been widely employed in the field of 3D manipulation\ndue to their efficient capability to learn distributions, allowing for precise\nprediction of action trajectories. However, diffusion models typically rely on\nlarge parameter UNet backbones as policy networks, which can be challenging to\ndeploy on resource-constrained devices. Recently, the Mamba model has emerged\nas a promising solution for efficient modeling, offering low computational\ncomplexity and strong performance in sequence modeling. In this work, we\npropose the Mamba Policy, a lighter but stronger policy that reduces the\nparameter count by over 80% compared to the original policy network while\nachieving superior performance. Specifically, we introduce the XMamba Block,\nwhich effectively integrates input information with conditional features and\nleverages a combination of Mamba and Attention mechanisms for deep feature\nextraction. Extensive experiments demonstrate that the Mamba Policy excels on\nthe Adroit, Dexart, and MetaWorld datasets, requiring significantly fewer\ncomputational resources. Additionally, we highlight the Mamba Policy's enhanced\nrobustness in long-horizon scenarios compared to baseline methods and explore\nthe performance of various Mamba variants within the Mamba Policy framework.\nReal-world experiments are also conducted to further validate its\neffectiveness. Our open-source project page can be found at\nhttps://andycao1125.github.io/mamba_policy/.", "AI": {"tldr": "The paper introduces the Mamba Policy, a lightweight and efficient alternative to traditional diffusion models for 3D manipulation, reducing parameters by 80% while improving performance.", "motivation": "Diffusion models for 3D manipulation often use large UNet backbones, making deployment on resource-constrained devices difficult. The Mamba model's efficiency and performance in sequence modeling inspired this work.", "method": "The Mamba Policy incorporates the XMamba Block, combining Mamba and Attention mechanisms for deep feature extraction, and is tested on Adroit, Dexart, and MetaWorld datasets.", "result": "The Mamba Policy outperforms baselines with 80% fewer parameters, requires fewer computational resources, and shows robustness in long-horizon tasks.", "conclusion": "The Mamba Policy is a highly efficient and effective solution for 3D manipulation, validated by experiments and real-world testing."}}
{"id": "2506.17508", "pdf": "https://arxiv.org/pdf/2506.17508", "abs": "https://arxiv.org/abs/2506.17508", "authors": ["Sajratul Y. Rubaiat", "Syed N. Sakib", "Hasan M. Jamil"], "title": "Mapping the Evolution of Research Contributions using KnoVo", "categories": ["cs.DL", "cs.AI", "cs.DB", "cs.ET", "cs.IR"], "comment": null, "summary": "This paper presents KnoVo (Knowledge Evolution), an intelligent framework\ndesigned for quantifying and analyzing the evolution of research novelty in the\nscientific literature. Moving beyond traditional citation analysis, which\nprimarily measures impact, KnoVo determines a paper's novelty relative to both\nprior and subsequent work within its multilayered citation network. Given a\ntarget paper's abstract, KnoVo utilizes Large Language Models (LLMs) to\ndynamically extract dimensions of comparison (e.g., methodology, application,\ndataset). The target paper is then compared to related publications along these\nsame extracted dimensions. This comparative analysis, inspired by tournament\nselection, yields quantitative novelty scores reflecting the relative\nimprovement, equivalence, or inferiority of the target paper in specific\naspects. By aggregating these scores and visualizing their progression, for\ninstance, through dynamic evolution graphs and comparative radar charts, KnoVo\nfacilitates researchers not only to assess originality and identify similar\nwork, but also to track knowledge evolution along specific research dimensions,\nuncover research gaps, and explore cross-disciplinary connections. We\ndemonstrate these capabilities through a detailed analysis of 20 diverse papers\nfrom multiple scientific fields and report on the performance of various\nopen-source LLMs within the KnoVo framework.", "AI": {"tldr": "KnoVo is a framework for quantifying research novelty using LLMs to compare papers along dynamically extracted dimensions, providing novelty scores and visualizations.", "motivation": "Traditional citation analysis lacks novelty assessment. KnoVo aims to measure novelty by comparing papers within citation networks.", "method": "Uses LLMs to extract comparison dimensions (e.g., methodology) and compares target papers to related work, generating novelty scores. Visualizations like evolution graphs and radar charts are used.", "result": "Demonstrated with 20 diverse papers, showing performance of open-source LLMs in the framework.", "conclusion": "KnoVo enables novelty assessment, gap identification, and cross-disciplinary insights, enhancing research analysis."}}
{"id": "2410.02145", "pdf": "https://arxiv.org/pdf/2410.02145", "abs": "https://arxiv.org/abs/2410.02145", "authors": ["Erica Zhang", "Fangzhao Zhang", "Mert Pilanci"], "title": "Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Active learning methods aim to improve sample complexity in machine learning.\nIn this work, we investigate an active learning scheme via a novel\ngradient-free cutting-plane training method for ReLU networks of arbitrary\ndepth and develop a convergence theory. We demonstrate, for the first time,\nthat cutting-plane algorithms, traditionally used in linear models, can be\nextended to deep neural networks despite their nonconvexity and nonlinear\ndecision boundaries. Moreover, this training method induces the first deep\nactive learning scheme known to achieve convergence guarantees, revealing a\ngeometric contraction rate of the feasible set. We exemplify the effectiveness\nof our proposed active learning method against popular deep active learning\nbaselines via both synthetic data experiments and sentimental classification\ntask on real datasets.", "AI": {"tldr": "The paper introduces a gradient-free cutting-plane training method for ReLU networks, extending it to deep neural networks and achieving convergence guarantees for active learning.", "motivation": "To improve sample complexity in machine learning by developing a novel active learning scheme for deep neural networks.", "method": "A gradient-free cutting-plane training method for ReLU networks, adapted from linear models to handle nonconvexity and nonlinear decision boundaries.", "result": "Demonstrates geometric contraction of the feasible set and outperforms popular deep active learning baselines in synthetic and real-world tasks.", "conclusion": "The proposed method is the first deep active learning scheme with convergence guarantees, showing promise for practical applications."}}
{"id": "2411.13047", "pdf": "https://arxiv.org/pdf/2411.13047", "abs": "https://arxiv.org/abs/2411.13047", "authors": ["Satoru Koda", "Ikuya Morikawa"], "title": "Bounding-box Watermarking: Defense against Model Extraction Attacks on Object Detectors", "categories": ["cs.CR", "cs.CV"], "comment": "Accepted at ECML-PKDD2025. Please refer to the conference proceedings\n  for the final version. Source codes: https://zenodo.org/records/15641464", "summary": "Deep neural networks (DNNs) deployed in a cloud often allow users to query\nmodels via the APIs. However, these APIs expose the models to model extraction\nattacks (MEAs). In this attack, the attacker attempts to duplicate the target\nmodel by abusing the responses from the API. Backdoor-based DNN watermarking is\nknown as a promising defense against MEAs, wherein the defender injects a\nbackdoor into extracted models via API responses. The backdoor is used as a\nwatermark of the model; if a suspicious model has the watermark (i.e.,\nbackdoor), it is verified as an extracted model. This work focuses on object\ndetection (OD) models. Existing backdoor attacks on OD models are not\napplicable for model watermarking as the defense against MEAs on a realistic\nthreat model. Our proposed approach involves inserting a backdoor into\nextracted models via APIs by stealthily modifying the bounding-boxes (BBs) of\nobjects detected in queries while keeping the OD capability. In our experiments\non three OD datasets, the proposed approach succeeded in identifying the\nextracted models with 100% accuracy in a wide variety of experimental\nscenarios.", "AI": {"tldr": "Proposes a backdoor-based watermarking method for object detection models to defend against model extraction attacks, achieving 100% accuracy in identifying extracted models.", "motivation": "Deep neural networks (DNNs) in cloud APIs are vulnerable to model extraction attacks (MEAs), necessitating a defense mechanism like watermarking.", "method": "Inserts a backdoor into extracted models by stealthily modifying bounding-boxes in API responses while maintaining object detection capability.", "result": "Achieved 100% accuracy in identifying extracted models across three OD datasets in various scenarios.", "conclusion": "The proposed backdoor-based watermarking is effective for defending against MEAs in object detection models."}}
{"id": "2506.18165", "pdf": "https://arxiv.org/pdf/2506.18165", "abs": "https://arxiv.org/abs/2506.18165", "authors": ["Jaemoo Choi", "Yongxin Chen", "Molei Tao", "Guan-Horng Liu"], "title": "Non-equilibrium Annealed Adjoint Sampler", "categories": ["cs.LG", "cs.AI"], "comment": "21 pages, 7 figures", "summary": "Recently, there has been significant progress in learning-based diffusion\nsamplers, which aim to sample from a given unnormalized density. These methods\ntypically follow one of two paradigms: (i) formulating sampling as an unbiased\nstochastic optimal control (SOC) problem using a canonical reference process,\nor (ii) refining annealed path measures through importance-weighted sampling.\nAlthough annealing approaches have advantages in guiding samples toward\nhigh-density regions, reliance on importance sampling leads to high variance\nand limited scalability in practice. In this paper, we introduce the\n\\textbf{Non-equilibrium Annealed Adjoint Sampler (NAAS)}, a novel SOC-based\ndiffusion sampler that leverages annealed reference dynamics without resorting\nto importance sampling. NAAS employs a lean adjoint system inspired by adjoint\nmatching, enabling efficient and scalable training. We demonstrate the\neffectiveness of our approach across a range of tasks, including sampling from\nclassical energy landscapes and molecular Boltzmann distribution.", "AI": {"tldr": "NAAS is a new SOC-based diffusion sampler that avoids importance sampling, using annealed reference dynamics for efficient and scalable training.", "motivation": "Existing annealing methods suffer from high variance and scalability issues due to reliance on importance sampling.", "method": "NAAS leverages annealed reference dynamics and a lean adjoint system for training, avoiding importance sampling.", "result": "NAAS effectively samples from classical energy landscapes and molecular Boltzmann distributions.", "conclusion": "NAAS offers a scalable and efficient alternative to traditional annealing-based diffusion samplers."}}
{"id": "2410.08417", "pdf": "https://arxiv.org/pdf/2410.08417", "abs": "https://arxiv.org/abs/2410.08417", "authors": ["Michael T. Pearce", "Thomas Dooms", "Alice Rigg", "Jose M. Oramas", "Lee Sharkey"], "title": "Bilinear MLPs enable weight-based mechanistic interpretability", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted to ICLR'25", "summary": "A mechanistic understanding of how MLPs do computation in deep neural\nnetworks remains elusive. Current interpretability work can extract features\nfrom hidden activations over an input dataset but generally cannot explain how\nMLP weights construct features. One challenge is that element-wise\nnonlinearities introduce higher-order interactions and make it difficult to\ntrace computations through the MLP layer. In this paper, we analyze bilinear\nMLPs, a type of Gated Linear Unit (GLU) without any element-wise nonlinearity\nthat nevertheless achieves competitive performance. Bilinear MLPs can be fully\nexpressed in terms of linear operations using a third-order tensor, allowing\nflexible analysis of the weights. Analyzing the spectra of bilinear MLP weights\nusing eigendecomposition reveals interpretable low-rank structure across toy\ntasks, image classification, and language modeling. We use this understanding\nto craft adversarial examples, uncover overfitting, and identify small language\nmodel circuits directly from the weights alone. Our results demonstrate that\nbilinear layers serve as an interpretable drop-in replacement for current\nactivation functions and that weight-based interpretability is viable for\nunderstanding deep-learning models.", "AI": {"tldr": "The paper introduces bilinear MLPs, a variant of Gated Linear Units (GLUs) without element-wise nonlinearities, to improve interpretability of MLP computations. It demonstrates their competitive performance and uses tensor analysis to reveal interpretable weight structures.", "motivation": "Understanding how MLPs compute in deep neural networks is challenging due to nonlinearities obscuring weight interactions. The paper aims to provide a clearer mechanistic understanding by analyzing bilinear MLPs.", "method": "The study replaces traditional MLP activation functions with bilinear MLPs, which avoid element-wise nonlinearities. It uses third-order tensor representations and eigendecomposition to analyze weight spectra.", "result": "Bilinear MLPs achieve competitive performance while enabling interpretable weight analysis. The method reveals low-rank structures, aids in crafting adversarial examples, and identifies model circuits directly from weights.", "conclusion": "Bilinear MLPs offer an interpretable alternative to traditional activation functions, proving weight-based interpretability is feasible for deep-learning models."}}
{"id": "2412.10538", "pdf": "https://arxiv.org/pdf/2412.10538", "abs": "https://arxiv.org/abs/2412.10538", "authors": ["Mohamed Debbagh", "Shangpeng Sun", "Mark Lefsrud"], "title": "Predictive Modeling, Pattern Recognition, and Spatiotemporal Representations of Plant Growth in Simulated and Controlled Environments: A Comprehensive Review", "categories": ["q-bio.QM", "cs.CV"], "comment": null, "summary": "Accurate predictions and representations of plant growth patterns in\nsimulated and controlled environments are important for addressing various\nchallenges in plant phenomics research. This review explores various works on\nstate-of-the-art predictive pattern recognition techniques, focusing on the\nspatiotemporal modeling of plant traits and the integration of dynamic\nenvironmental interactions. We provide a comprehensive examination of\ndeterministic, probabilistic, and generative modeling approaches, emphasizing\ntheir applications in high-throughput phenotyping and simulation-based plant\ngrowth forecasting. Key topics include regressions and neural network-based\nrepresentation models for the task of forecasting, limitations of existing\nexperiment-based deterministic approaches, and the need for dynamic frameworks\nthat incorporate uncertainty and evolving environmental feedback. This review\nsurveys advances in 2D and 3D structured data representations through\nfunctional-structural plant models and conditional generative models. We offer\na perspective on opportunities for future works, emphasizing the integration of\ndomain-specific knowledge to data-driven methods, improvements to available\ndatasets, and the implementation of these techniques toward real-world\napplications.", "AI": {"tldr": "This review examines predictive pattern recognition techniques for plant growth modeling, focusing on spatiotemporal modeling, environmental interactions, and various modeling approaches like deterministic, probabilistic, and generative methods. It highlights applications in phenomics, limitations of current methods, and future opportunities.", "motivation": "The need for accurate plant growth predictions in controlled environments to address challenges in plant phenomics research.", "method": "Review of state-of-the-art techniques, including deterministic, probabilistic, and generative modeling, with a focus on spatiotemporal modeling and environmental interactions.", "result": "Identifies limitations of deterministic approaches and advocates for dynamic frameworks incorporating uncertainty and environmental feedback. Surveys advances in 2D/3D data representations and generative models.", "conclusion": "Future work should integrate domain-specific knowledge with data-driven methods, improve datasets, and apply these techniques in real-world scenarios."}}
{"id": "2506.18240", "pdf": "https://arxiv.org/pdf/2506.18240", "abs": "https://arxiv.org/abs/2506.18240", "authors": ["Wenxin Li", "Chuan Wang", "Hongdong Zhu", "Qi Gao", "Yin Ma", "Hai Wei", "Kai Wen"], "title": "Quantum-Classical Hybrid Quantized Neural Network", "categories": ["cs.LG", "cs.AI", "physics.optics"], "comment": "27 pages, 5 figures, comments are welcome", "summary": "Here in this work, we present a novel Quadratic Binary Optimization (QBO)\nmodel for quantized neural network training, enabling the use of arbitrary\nactivation and loss functions through spline interpolation. We introduce\nForward Interval Propagation (FIP), a method designed to tackle the challenges\nof non-linearity and the multi-layer composite structure in neural networks by\ndiscretizing activation functions into linear subintervals. This approach\npreserves the universal approximation properties of neural networks while\nallowing complex nonlinear functions to be optimized using quantum computers,\nthus broadening their applicability in artificial intelligence. We provide\ntheoretical upper bounds on the approximation error and the number of Ising\nspins required, by deriving the sample complexity of the empirical risk\nminimization problem, from an optimization perspective. A significant challenge\nin solving the associated Quadratic Constrained Binary Optimization (QCBO)\nmodel on a large scale is the presence of numerous constraints. When employing\nthe penalty method to handle these constraints, tuning a large number of\npenalty coefficients becomes a critical hyperparameter optimization problem,\nincreasing computational complexity and potentially affecting solution quality.\nTo address this, we employ the Quantum Conditional Gradient Descent (QCGD)\nalgorithm, which leverages quantum computing to directly solve the QCBO\nproblem. We prove the convergence of QCGD under a quantum oracle with\nrandomness and bounded variance in objective value, as well as under limited\nprecision constraints in the coefficient matrix. Additionally, we provide an\nupper bound on the Time-To-Solution for the QCBO solving process. Experimental\nresults using a coherent Ising machine (CIM) demonstrate a 94.95% accuracy on\nthe Fashion MNIST classification task, with only 1.1-bit precision.", "AI": {"tldr": "A novel Quadratic Binary Optimization (QBO) model for quantized neural network training is introduced, using Forward Interval Propagation (FIP) to handle non-linearity and multi-layer structures. The method enables quantum computing optimization, with theoretical bounds on error and Ising spins. Quantum Conditional Gradient Descent (QCGD) is used to solve the QCBO problem, achieving high accuracy on Fashion MNIST.", "motivation": "To enable quantized neural network training with arbitrary activation and loss functions using quantum computers, addressing challenges of non-linearity and multi-layer structures.", "method": "Forward Interval Propagation (FIP) discretizes activation functions into linear subintervals. Quantum Conditional Gradient Descent (QCGD) solves the QCBO problem with theoretical convergence guarantees.", "result": "Theoretical bounds on approximation error and Ising spins. Experimental results show 94.95% accuracy on Fashion MNIST with 1.1-bit precision.", "conclusion": "The QBO model and QCGD algorithm successfully enable quantized neural network training on quantum computers, demonstrating practical applicability and high accuracy."}}
{"id": "2411.01580", "pdf": "https://arxiv.org/pdf/2411.01580", "abs": "https://arxiv.org/abs/2411.01580", "authors": ["Minghao Li", "Dmitrii Avdiukhin", "Rana Shahout", "Nikita Ivkin", "Vladimir Braverman", "Minlan Yu"], "title": "Federated Learning Clients Clustering with Adaptation to Data Drifts", "categories": ["cs.LG", "cs.CR"], "comment": "24 pages, 16 figures", "summary": "Federated Learning (FL) trains deep models across edge devices without\ncentralizing raw data, preserving user privacy. However, client heterogeneity\nslows down convergence and limits global model accuracy. Clustered FL (CFL)\nmitigates this by grouping clients with similar representations and training a\nseparate model for each cluster. In practice, client data evolves over time, a\nphenomenon we refer to as data drift, which breaks cluster homogeneity and\ndegrades performance. Data drift can take different forms depending on whether\nchanges occur in the output values, the input features, or the relationship\nbetween them. We propose FIELDING, a CFL framework for handling diverse types\nof data drift with low overhead. FIELDING detects drift at individual clients\nand performs selective re-clustering to balance cluster quality and model\nperformance, while remaining robust to malicious clients and varying levels of\nheterogeneity. Experiments show that FIELDING improves final model accuracy by\n1.9-5.9% and achieves target accuracy 1.16x-2.23x faster than existing\nstate-of-the-art CFL methods.", "AI": {"tldr": "FIELDING is a clustered FL framework addressing data drift by detecting drift at clients and re-clustering selectively, improving accuracy and convergence speed.", "motivation": "Client heterogeneity and data drift in FL degrade model performance, requiring adaptive solutions.", "method": "FIELDING detects drift at clients and performs selective re-clustering to maintain cluster quality and model performance.", "result": "FIELDING improves accuracy by 1.9-5.9% and achieves target accuracy 1.16x-2.23x faster than existing methods.", "conclusion": "FIELDING effectively handles data drift in FL, enhancing model accuracy and convergence speed."}}
{"id": "2505.24190", "pdf": "https://arxiv.org/pdf/2505.24190", "abs": "https://arxiv.org/abs/2505.24190", "authors": ["Lan-Cuong Nguyen", "Quan Nguyen-Tri", "Bang Tran Khanh", "Dung D. Le", "Long Tran-Thanh", "Khoat Than"], "title": "Provably Improving Generalization of Few-Shot Models with Synthetic Data", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025. Our code is released at\n  https://github.com/Fsoft-AIC/ProtoAug", "summary": "Few-shot image classification remains challenging due to the scarcity of\nlabeled training examples. Augmenting them with synthetic data has emerged as a\npromising way to alleviate this issue, but models trained on synthetic samples\noften face performance degradation due to the inherent gap between real and\nsynthetic distributions. To address this limitation, we develop a theoretical\nframework that quantifies the impact of such distribution discrepancies on\nsupervised learning, specifically in the context of image classification. More\nimportantly, our framework suggests practical ways to generate good synthetic\nsamples and to train a predictor with high generalization ability. Building\nupon this framework, we propose a novel theoretical-based algorithm that\nintegrates prototype learning to optimize both data partitioning and model\ntraining, effectively bridging the gap between real few-shot data and synthetic\ndata. Extensive experiments results show that our approach demonstrates\nsuperior performance compared to state-of-the-art methods, outperforming them\nacross multiple datasets.", "AI": {"tldr": "A theoretical framework addresses the performance gap in few-shot image classification caused by synthetic data, proposing a novel algorithm that outperforms state-of-the-art methods.", "motivation": "Few-shot image classification struggles with limited labeled data, and synthetic data augmentation often degrades performance due to distribution gaps.", "method": "Developed a theoretical framework to quantify distribution discrepancies, suggesting practical synthetic sample generation and training methods. Proposed a prototype-learning-based algorithm to optimize data partitioning and model training.", "result": "The approach outperforms state-of-the-art methods across multiple datasets.", "conclusion": "The framework and algorithm effectively bridge the gap between real and synthetic data, improving few-shot classification performance."}}
{"id": "2506.18251", "pdf": "https://arxiv.org/pdf/2506.18251", "abs": "https://arxiv.org/abs/2506.18251", "authors": ["Chao Li", "Jiawei Fan", "Anbang Yao"], "title": "Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Fixed a prompt typo in Figure 18 of the Appendix. This work is\n  accepted to ICML 2025. The project page:\n  https://github.com/deep-optimization/Morse", "summary": "In this paper, we present Morse, a simple dual-sampling framework for\naccelerating diffusion models losslessly. The key insight of Morse is to\nreformulate the iterative generation (from noise to data) process via taking\nadvantage of fast jump sampling and adaptive residual feedback strategies.\nSpecifically, Morse involves two models called Dash and Dot that interact with\neach other. The Dash model is just the pre-trained diffusion model of any type,\nbut operates in a jump sampling regime, creating sufficient space for sampling\nefficiency improvement. The Dot model is significantly faster than the Dash\nmodel, which is learnt to generate residual feedback conditioned on the\nobservations at the current jump sampling point on the trajectory of the Dash\nmodel, lifting the noise estimate to easily match the next-step estimate of the\nDash model without jump sampling. By chaining the outputs of the Dash and Dot\nmodels run in a time-interleaved fashion, Morse exhibits the merit of flexibly\nattaining desired image generation performance while improving overall runtime\nefficiency. With our proposed weight sharing strategy between the Dash and Dot\nmodels, Morse is efficient for training and inference. Our method shows a\nlossless speedup of 1.78X to 3.31X on average over a wide range of sampling\nstep budgets relative to 9 baseline diffusion models on 6 image generation\ntasks. Furthermore, we show that our method can be also generalized to improve\nthe Latent Consistency Model (LCM-SDXL, which is already accelerated with\nconsistency distillation technique) tailored for few-step text-to-image\nsynthesis. The code and models are available at\nhttps://github.com/deep-optimization/Morse.", "AI": {"tldr": "Morse is a dual-sampling framework for accelerating diffusion models losslessly using jump sampling and adaptive residual feedback, achieving 1.78X to 3.31X speedup.", "motivation": "To improve the runtime efficiency of diffusion models without sacrificing generation quality.", "method": "Uses two models (Dash and Dot) with jump sampling and residual feedback, interleaved for efficient generation.", "result": "Achieves significant speedup (1.78X to 3.31X) over baselines on 6 tasks and generalizes to Latent Consistency Model.", "conclusion": "Morse provides a flexible, efficient, and lossless acceleration for diffusion models."}}
{"id": "2502.02719", "pdf": "https://arxiv.org/pdf/2502.02719", "abs": "https://arxiv.org/abs/2502.02719", "authors": ["Steve Azzolin", "Sagar Malhotra", "Andrea Passerini", "Stefano Teso"], "title": "Beyond Topological Self-Explainable GNNs: A Formal Explainability Perspective", "categories": ["cs.LG"], "comment": null, "summary": "Self-Explainable Graph Neural Networks (SE-GNNs) are popular\nexplainable-by-design GNNs, but their explanations' properties and limitations\nare not well understood. Our first contribution fills this gap by formalizing\nthe explanations extracted by some popular SE-GNNs, referred to as Minimal\nExplanations (MEs), and comparing them to established notions of explanations,\nnamely Prime Implicant (PI) and faithful explanations. Our analysis reveals\nthat MEs match PI explanations for a restricted but significant family of\ntasks. In general, however, they can be less informative than PI explanations\nand are surprisingly misaligned with widely accepted notions of faithfulness.\nAlthough faithful and PI explanations are informative, they are intractable to\nfind and we show that they can be prohibitively large. Given these\nobservations, a natural choice is to augment SE-GNNs with alternative\nmodalities of explanations taking care of SE-GNNs' limitations. To this end, we\npropose Dual-Channel GNNs that integrate a white-box rule extractor and a\nstandard SE-GNN, adaptively combining both channels. Our experiments show that\neven a simple instantiation of Dual-Channel GNNs can recover succinct rules and\nperform on par or better than widely used SE-GNNs.", "AI": {"tldr": "SE-GNNs' explanations (MEs) are formalized and compared to PI and faithful explanations. MEs match PIs for some tasks but are less informative and misaligned with faithfulness. Dual-Channel GNNs are proposed to address limitations, combining rule extraction with SE-GNNs, showing promising results.", "motivation": "To understand and address the limitations of explanations provided by SE-GNNs, particularly their misalignment with faithfulness and informativeness compared to PI explanations.", "method": "Formalize MEs, compare them to PI and faithful explanations, and propose Dual-Channel GNNs integrating rule extraction with SE-GNNs.", "result": "MEs match PIs for certain tasks but are generally less informative and unfaithful. Dual-Channel GNNs recover succinct rules and perform comparably or better than SE-GNNs.", "conclusion": "Dual-Channel GNNs offer a viable solution to SE-GNNs' limitations, balancing explanation quality and tractability."}}
{"id": "2506.17874", "pdf": "https://arxiv.org/pdf/2506.17874", "abs": "https://arxiv.org/abs/2506.17874", "authors": ["Jiaming Hu", "Debarghya Mukherjee", "Ioannis Ch. Paschalidis"], "title": "DRO-Augment Framework: Robustness by Synergizing Wasserstein Distributionally Robust Optimization and Data Augmentation", "categories": ["stat.ML", "cs.CV", "cs.LG"], "comment": "26 pages,3 figures", "summary": "In many real-world applications, ensuring the robustness and stability of\ndeep neural networks (DNNs) is crucial, particularly for image classification\ntasks that encounter various input perturbations. While data augmentation\ntechniques have been widely adopted to enhance the resilience of a trained\nmodel against such perturbations, there remains significant room for\nimprovement in robustness against corrupted data and adversarial attacks\nsimultaneously. To address this challenge, we introduce DRO-Augment, a novel\nframework that integrates Wasserstein Distributionally Robust Optimization\n(W-DRO) with various data augmentation strategies to improve the robustness of\nthe models significantly across a broad spectrum of corruptions. Our method\noutperforms existing augmentation methods under severe data perturbations and\nadversarial attack scenarios while maintaining the accuracy on the clean\ndatasets on a range of benchmark datasets, including but not limited to\nCIFAR-10-C, CIFAR-100-C, MNIST, and Fashion-MNIST. On the theoretical side, we\nestablish novel generalization error bounds for neural networks trained using a\ncomputationally efficient, variation-regularized loss function closely related\nto the W-DRO problem.", "AI": {"tldr": "DRO-Augment combines Wasserstein Distributionally Robust Optimization (W-DRO) with data augmentation to enhance DNN robustness against corruptions and adversarial attacks while maintaining clean data accuracy.", "motivation": "Improving DNN robustness against corrupted data and adversarial attacks simultaneously, as current data augmentation methods lack sufficient resilience.", "method": "Integrates W-DRO with data augmentation strategies, using a variation-regularized loss function for training.", "result": "Outperforms existing methods under severe perturbations and adversarial attacks on benchmark datasets like CIFAR-10-C, CIFAR-100-C, MNIST, and Fashion-MNIST.", "conclusion": "DRO-Augment significantly improves model robustness and generalization, with theoretical support for its error bounds."}}
{"id": "2506.19269", "pdf": "https://arxiv.org/pdf/2506.19269", "abs": "https://arxiv.org/abs/2506.19269", "authors": ["Ziyan Zhao", "Ke Fan", "He-Yang Xu", "Ning Qiao", "Bo Peng", "Wenlong Gao", "Dongjiang Li", "Hui Shen"], "title": "AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We present AnchorDP3, a diffusion policy framework for dual-arm robotic\nmanipulation that achieves state-of-the-art performance in highly randomized\nenvironments. AnchorDP3 integrates three key innovations: (1)\nSimulator-Supervised Semantic Segmentation, using rendered ground truth to\nexplicitly segment task-critical objects within the point cloud, which provides\nstrong affordance priors; (2) Task-Conditioned Feature Encoders, lightweight\nmodules processing augmented point clouds per task, enabling efficient\nmulti-task learning through a shared diffusion-based action expert; (3)\nAffordance-Anchored Keypose Diffusion with Full State Supervision, replacing\ndense trajectory prediction with sparse, geometrically meaningful action\nanchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored to\naffordances, drastically simplifying the prediction space; the action expert is\nforced to predict both robot joint angles and end-effector poses\nsimultaneously, which exploits geometric consistency to accelerate convergence\nand boost accuracy. Trained on large-scale, procedurally generated simulation\ndata, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmark\nacross diverse tasks under extreme randomization of objects, clutter, table\nheight, lighting, and backgrounds. This framework, when integrated with the\nRoboTwin real-to-sim pipeline, has the potential to enable fully autonomous\ngeneration of deployable visuomotor policies from only scene and instruction,\ntotally eliminating human demonstrations from learning manipulation skills.", "AI": {"tldr": "AnchorDP3 is a diffusion policy framework for dual-arm robotic manipulation, achieving high success rates in randomized environments through innovations like semantic segmentation, task-conditioned encoders, and affordance-anchored keypose diffusion.", "motivation": "To improve robotic manipulation in highly randomized environments by simplifying the prediction space and leveraging geometric consistency.", "method": "Integrates Simulator-Supervised Semantic Segmentation, Task-Conditioned Feature Encoders, and Affordance-Anchored Keypose Diffusion with Full State Supervision.", "result": "Achieves a 98.7% average success rate in the RoboTwin benchmark under extreme randomization.", "conclusion": "AnchorDP3 enables fully autonomous generation of deployable visuomotor policies without human demonstrations."}}
{"id": "2502.10381", "pdf": "https://arxiv.org/pdf/2502.10381", "abs": "https://arxiv.org/abs/2502.10381", "authors": ["Corinna Cortes", "Anqi Mao", "Mehryar Mohri", "Yutao Zhong"], "title": "Balancing the Scales: A Theoretical and Algorithmic Framework for Learning from Imbalanced Data", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2025", "summary": "Class imbalance remains a major challenge in machine learning, especially in\nmulti-class problems with long-tailed distributions. Existing methods, such as\ndata resampling, cost-sensitive techniques, and logistic loss modifications,\nthough popular and often effective, lack solid theoretical foundations. As an\nexample, we demonstrate that cost-sensitive methods are not Bayes-consistent.\nThis paper introduces a novel theoretical framework for analyzing\ngeneralization in imbalanced classification. We then propose a new\nclass-imbalanced margin loss function for both binary and multi-class settings,\nprove its strong $H$-consistency, and derive corresponding learning guarantees\nbased on empirical loss and a new notion of class-sensitive Rademacher\ncomplexity. Leveraging these theoretical results, we devise novel and general\nlearning algorithms, IMMAX (Imbalanced Margin Maximization), which incorporate\nconfidence margins and are applicable to various hypothesis sets. While our\nfocus is theoretical, we also present extensive empirical results demonstrating\nthe effectiveness of our algorithms compared to existing baselines.", "AI": {"tldr": "The paper addresses class imbalance in machine learning, proposing a new theoretical framework and a class-imbalanced margin loss function with strong consistency guarantees, leading to the IMMAX algorithm.", "motivation": "Class imbalance in multi-class problems lacks solid theoretical foundations, and existing methods like cost-sensitive techniques are not Bayes-consistent.", "method": "Introduces a theoretical framework for imbalanced classification, proposes a class-imbalanced margin loss function, and develops the IMMAX algorithm with learning guarantees.", "result": "The proposed method demonstrates strong consistency and outperforms existing baselines empirically.", "conclusion": "The paper provides a robust theoretical and practical solution for imbalanced classification, validated by empirical results."}}
{"id": "2504.07307", "pdf": "https://arxiv.org/pdf/2504.07307", "abs": "https://arxiv.org/abs/2504.07307", "authors": ["Jingxin Zhan", "Yuchen Xin", "Chenjie Sun", "Zhihua Zhang"], "title": "Follow-the-Perturbed-Leader Approaches Best-of-Both-Worlds for the m-Set Semi-Bandit Problems", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We consider a common case of the combinatorial semi-bandit problem, the\n$m$-set semi-bandit, where the learner exactly selects $m$ arms from the total\n$d$ arms. In the adversarial setting, the best regret bound, known to be\n$\\mathcal{O}(\\sqrt{nmd})$ for time horizon $n$, is achieved by the well-known\nFollow-the-Regularized-Leader (FTRL) policy. However, this requires to\nexplicitly compute the arm-selection probabilities via optimizing problems at\neach time step and sample according to them. This problem can be avoided by the\nFollow-the-Perturbed-Leader (FTPL) policy, which simply pulls the $m$ arms that\nrank among the $m$ smallest (estimated) loss with random perturbation. In this\npaper, we show that FTPL with a Fr\\'echet perturbation also enjoys the near\noptimal regret bound $\\mathcal{O}(\\sqrt{nm}(\\sqrt{d\\log(d)}+m^{5/6}))$ in the\nadversarial setting and approaches best-of-both-world regret bounds, i.e.,\nachieves a logarithmic regret for the stochastic setting. Moreover, our lower\nbounds show that the extra factors are unavoidable with our approach; any\nimprovement would require a fundamentally different and more challenging\nmethod.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.08377", "pdf": "https://arxiv.org/pdf/2504.08377", "abs": "https://arxiv.org/abs/2504.08377", "authors": ["Avrim Blum", "Steve Hanneke", "Chirag Pabbaraju", "Donya Saless"], "title": "Proofs as Explanations: Short Certificates for Reliable Predictions", "categories": ["cs.LG", "stat.ML"], "comment": "Fixed typo for robust hollow star number sb -> s_b, updated\n  bibliography, other minor changes", "summary": "We consider a model for explainable AI in which an explanation for a\nprediction $h(x)=y$ consists of a subset $S'$ of the training data (if it\nexists) such that all classifiers $h' \\in H$ that make at most $b$ mistakes on\n$S'$ predict $h'(x)=y$. Such a set $S'$ serves as a proof that $x$ indeed has\nlabel $y$ under the assumption that (1) the target function $h^\\star$ belongs\nto $H$, and (2) the set $S$ contains at most $b$ corrupted points. For example,\nif $b=0$ and $H$ is the family of linear classifiers in $\\mathbb{R}^d$, and if\n$x$ lies inside the convex hull of the positive data points in $S$ (and hence\nevery consistent linear classifier labels $x$ as positive), then\nCarath\\'eodory's theorem states that $x$ lies inside the convex hull of $d+1$\nof those points. So, a set $S'$ of size $d+1$ could be released as an\nexplanation for a positive prediction, and would serve as a short proof of\ncorrectness of the prediction under the assumption of realizability.\n  In this work, we consider this problem more generally, for general hypothesis\nclasses $H$ and general values $b\\geq 0$. We define the notion of the robust\nhollow star number of $H$ (which generalizes the standard hollow star number),\nand show that it precisely characterizes the worst-case size of the smallest\ncertificate achievable, and analyze its size for natural classes. We also\nconsider worst-case distributional bounds on certificate size, as well as\ndistribution-dependent bounds that we show tightly control the sample size\nneeded to get a certificate for any given test example. In particular, we\ndefine a notion of the certificate coefficient $\\varepsilon_x$ of an example\n$x$ with respect to a data distribution $D$ and target function $h^\\star$, and\nprove matching upper and lower bounds on sample size as a function of\n$\\varepsilon_x$, $b$, and the VC dimension $d$ of $H$.", "AI": {"tldr": "The paper proposes a model for explainable AI where explanations are subsets of training data proving predictions under assumptions of hypothesis class realizability and bounded corruption. It generalizes this for any hypothesis class and corruption bound, introducing the robust hollow star number to characterize certificate size.", "motivation": "To provide rigorous, data-driven explanations for AI predictions under realistic assumptions of bounded errors and hypothesis class realizability.", "method": "Defines the robust hollow star number for hypothesis classes, analyzes worst-case and distributional bounds on certificate size, and introduces the certificate coefficient for sample size analysis.", "result": "The robust hollow star number precisely characterizes the smallest achievable certificate size. Matching bounds on sample size are proven for the certificate coefficient.", "conclusion": "The framework offers a principled way to generate and analyze explanations for AI predictions, with theoretical guarantees on their correctness and size."}}
{"id": "2504.21662", "pdf": "https://arxiv.org/pdf/2504.21662", "abs": "https://arxiv.org/abs/2504.21662", "authors": ["Mauricio Ortiz Torres", "Markus Lange", "Arne P. Raulf"], "title": "On Advancements of the Forward-Forward Algorithm", "categories": ["cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The Forward-Forward algorithm has evolved in machine learning research,\ntackling more complex tasks that mimic real-life applications. In the last\nyears, it has been improved by several techniques to perform better than its\noriginal version, handling a challenging dataset like CIFAR10 without losing\nits flexibility and low memory usage. We have shown in our results that\nimprovements are achieved through a combination of convolutional channel\ngrouping, learning rate schedules, and independent block structures during\ntraining that lead to a 20\\% decrease in test error percentage. Additionally,\nto approach further implementations on low-capacity hardware projects, we have\npresented a series of lighter models that achieve low test error percentages\nwithin (21$\\pm$3)\\% and number of trainable parameters between 164,706 and\n754,386. This serves as a basis for our future study on complete verification\nand validation of these kinds of neural networks.", "AI": {"tldr": "The Forward-Forward algorithm has been enhanced for complex tasks, achieving a 20% test error reduction on CIFAR10 and enabling lightweight models for low-capacity hardware.", "motivation": "To improve the Forward-Forward algorithm for real-life applications and low-capacity hardware.", "method": "Combines convolutional channel grouping, learning rate schedules, and independent block structures.", "result": "20% decrease in test error; lightweight models achieve 21\u00b13% test error with 164,706 to 754,386 parameters.", "conclusion": "Sets a foundation for future verification and validation of such neural networks."}}
{"id": "2505.04396", "pdf": "https://arxiv.org/pdf/2505.04396", "abs": "https://arxiv.org/abs/2505.04396", "authors": ["Jingnan Wang", "Jie Chao", "Shangshang Yang", "Congyi Nai", "Kaijun Ren", "Kefeng Deng", "Xi Chen", "Yaxin Liu", "Hanqiuzi Wen", "Ziniu Xiao", "Lifeng Zhang", "Xiaodong Wang", "Jiping Guan", "Baoxiang Pan"], "title": "Supporting renewable energy planning and operation with data-driven high-resolution ensemble weather forecast", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "The planning and operation of renewable energy, especially wind power, depend\ncrucially on accurate, timely, and high-resolution weather information.\nCoarse-grid global numerical weather forecasts are typically downscaled to meet\nthese requirements, introducing challenges of scale inconsistency, process\nrepresentation error, computation cost, and entanglement of distinct\nuncertainty sources from chaoticity, model bias, and large-scale forcing. We\naddress these challenges by learning the climatological distribution of a\ntarget wind farm using its high-resolution numerical weather simulations. An\noptimal combination of this learned high-resolution climatological prior with\ncoarse-grid large scale forecasts yields highly accurate, fine-grained,\nfull-variable, large ensemble of weather pattern forecasts. Using observed\nmeteorological records and wind turbine power outputs as references, the\nproposed methodology verifies advantageously compared to existing\nnumerical/statistical forecasting-downscaling pipelines, regarding either\ndeterministic/probabilistic skills or economic gains. Moreover, a 100-member,\n10-day forecast with spatial resolution of 1 km and output frequency of 15 min\ntakes < 1 hour on a moderate-end GPU, as contrast to $\\mathcal{O}(10^3)$ CPU\nhours for conventional numerical simulation. By drastically reducing\ncomputational costs while maintaining accuracy, our method paves the way for\nmore efficient and reliable renewable energy planning and operation.", "AI": {"tldr": "A method combining learned high-resolution climatological data with coarse-grid forecasts improves wind power weather predictions, reducing computational costs while maintaining accuracy.", "motivation": "Accurate, high-resolution weather forecasts are critical for renewable energy planning, but traditional downscaling methods face challenges like scale inconsistency and high computational costs.", "method": "Learns climatological distribution from high-resolution simulations and optimally combines it with coarse-grid forecasts to produce fine-grained, ensemble weather forecasts.", "result": "Outperforms existing methods in accuracy and efficiency, with a 100-member, 10-day forecast taking <1 hour on a GPU compared to thousands of CPU hours traditionally.", "conclusion": "The method enables more efficient and reliable renewable energy planning by reducing computational costs without sacrificing accuracy."}}
{"id": "2506.04761", "pdf": "https://arxiv.org/pdf/2506.04761", "abs": "https://arxiv.org/abs/2506.04761", "authors": ["Han Guo", "Songlin Yang", "Tarushii Goel", "Eric P. Xing", "Tri Dao", "Yoon Kim"], "title": "Log-Linear Attention", "categories": ["cs.LG"], "comment": null, "summary": "The attention mechanism in Transformers is an important primitive for\naccurate and scalable sequence modeling. Its quadratic-compute and\nlinear-memory complexity however remain significant bottlenecks. Linear\nattention and state-space models enable linear-time, constant-memory sequence\nmodeling and can moreover be trained efficiently through matmul-rich\nparallelization across sequence length. However, at their core these models are\nstill RNNs, and thus their use of a fixed-size hidden state to model the\ncontext is a fundamental limitation. This paper develops log-linear attention,\nan attention mechanism that balances linear attention's efficiency and the\nexpressiveness of softmax attention. Log-linear attention replaces the\nfixed-size hidden state with a logarithmically growing set of hidden states. We\nshow that with a particular growth function, log-linear attention admits a\nsimilarly matmul-rich parallel form whose compute cost is log-linear in\nsequence length. Log-linear attention is a general framework and can be applied\non top of existing linear attention variants. As case studies, we instantiate\nlog-linear variants of two recent architectures -- Mamba-2 and Gated DeltaNet\n-- and find they perform well compared to their linear-time variants.", "AI": {"tldr": "Log-linear attention balances efficiency and expressiveness by replacing fixed-size hidden states with logarithmically growing ones, enabling log-linear compute cost.", "motivation": "Address the bottlenecks of quadratic-compute and linear-memory in Transformers while overcoming the limitations of fixed-size hidden states in RNN-like models.", "method": "Develops log-linear attention, a mechanism with logarithmically growing hidden states, and applies it to existing linear attention variants like Mamba-2 and Gated DeltaNet.", "result": "Log-linear attention variants perform well compared to linear-time models, maintaining efficiency and expressiveness.", "conclusion": "Log-linear attention offers a scalable and efficient alternative to traditional attention mechanisms, improving sequence modeling."}}
{"id": "2506.06300", "pdf": "https://arxiv.org/pdf/2506.06300", "abs": "https://arxiv.org/abs/2506.06300", "authors": ["Yuanye Zhou", "Zhaokun Wang", "Kai Zhou", "Hui Tang", "Xiaofan Li"], "title": "LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Physics-informed neural networks (PINNs) have emerged as a powerful meshless\ntool for topology optimization, capable of simultaneously determining optimal\ntopologies and physical solutions. However, conventional PINNs rely on\ndensity-based topology descriptions, which necessitate manual interpolation and\nlimit their applicability to complex geometries. To address this, we propose\nLagrangian topology-conscious PINNs (LT-PINNs), a novel framework for\nboundary-focused engineering optimization. By parameterizing the control\nvariables of topology boundary curves as learnable parameters, LT-PINNs\neliminate the need for manual interpolation and enable precise boundary\ndetermination. We further introduce specialized boundary condition loss\nfunction and topology loss function to ensure sharp and accurate boundary\nrepresentations, even for intricate topologies. The accuracy and robustness of\nLT-PINNs are validated via two types of partial differential equations (PDEs),\nincluding elastic equation with Dirichlet boundary conditions and Laplace's\nequation with Neumann boundary conditions. Furthermore, we demonstrate\neffectiveness of LT-PINNs on more complex time-dependent and time-independent\nflow problems without relying on measurement data, and showcase their\nengineering application potential in flow velocity rearrangement, transforming\na uniform upstream velocity into a sine-shaped downstream profile. The results\ndemonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors\ncompared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2)\nLT-PINNs can handle arbitrary boundary conditions, making them suitable for a\nwide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries\nwithout manual interpolation, especially for complex topologies.", "AI": {"tldr": "LT-PINNs improve topology optimization by eliminating manual interpolation and enabling precise boundary determination, outperforming conventional density-based PINNs.", "motivation": "Conventional PINNs rely on density-based topology descriptions, which require manual interpolation and limit applicability to complex geometries.", "method": "Proposes LT-PINNs, parameterizing control variables of topology boundary curves as learnable parameters and introducing specialized loss functions for boundary accuracy.", "result": "LT-PINNs reduce relative L2 errors, handle arbitrary boundary conditions, and infer clear topology boundaries without manual interpolation.", "conclusion": "LT-PINNs offer a robust, boundary-focused framework for engineering optimization, applicable to a wide range of PDEs and complex topologies."}}
{"id": "2506.18847", "pdf": "https://arxiv.org/pdf/2506.18847", "abs": "https://arxiv.org/abs/2506.18847", "authors": ["Anthony Kobanda", "Waris Radji", "Mathieu Petitbois", "Odalric-Ambrym Maillard", "R\u00e9my Portelas"], "title": "Offline Goal-Conditioned Reinforcement Learning with Projective Quasimetric Planning", "categories": ["cs.LG"], "comment": null, "summary": "Offline Goal-Conditioned Reinforcement Learning seeks to train agents to\nreach specified goals from previously collected trajectories. Scaling that\npromises to long-horizon tasks remains challenging, notably due to compounding\nvalue-estimation errors. Principled geometric offers a potential solution to\naddress these issues. Following this insight, we introduce Projective\nQuasimetric Planning (ProQ), a compositional framework that learns an\nasymmetric distance and then repurposes it, firstly as a repulsive energy\nforcing a sparse set of keypoints to uniformly spread over the learned latent\nspace, and secondly as a structured directional cost guiding towards proximal\nsub-goals. In particular, ProQ couples this geometry with a Lagrangian\nout-of-distribution detector to ensure the learned keypoints stay within\nreachable areas. By unifying metric learning, keypoint coverage, and\ngoal-conditioned control, our approach produces meaningful sub-goals and\nrobustly drives long-horizon goal-reaching on diverse a navigation benchmarks.", "AI": {"tldr": "ProQ introduces a compositional framework for long-horizon goal-reaching tasks by leveraging asymmetric distance learning, keypoint coverage, and goal-conditioned control, ensuring robust performance.", "motivation": "Addressing the challenge of compounding value-estimation errors in scaling offline goal-conditioned reinforcement learning to long-horizon tasks.", "method": "ProQ learns an asymmetric distance, uses it for keypoint coverage and directional cost, and integrates a Lagrangian out-of-distribution detector for reachability.", "result": "ProQ produces meaningful sub-goals and achieves robust long-horizon goal-reaching on diverse navigation benchmarks.", "conclusion": "ProQ effectively unifies metric learning, keypoint coverage, and control, offering a scalable solution for long-horizon tasks."}}
{"id": "2306.17501", "pdf": "https://arxiv.org/pdf/2306.17501", "abs": "https://arxiv.org/abs/2306.17501", "authors": ["Palina Salanevich", "Olov Schavemaker"], "title": "Efficient uniform approximation using Random Vector Functional Link networks", "categories": ["stat.ML", "cs.LG"], "comment": "21 pages, 0 figures, corrected version of the paper that appeared in\n  the 2023 14th International conference on Sampling Theory and Applications\n  (SampTA)", "summary": "A Random Vector Functional Link (RVFL) network is a depth-2 neural network\nwith random inner weights and biases. Only the outer weights of such an\narchitecture are to be learned, so the learning process boils down to a linear\noptimization task, allowing one to sidestep the pitfalls of nonconvex\noptimization problems. In this paper, we prove that an RVFL with ReLU\nactivation functions can approximate Lipschitz continuous functions in\n$L_\\infty$ norm. To the best of our knowledge, our result is the first\napproximation result in $L_\\infty$ norm using nice inner weights; namely,\nGaussians. We give a nonasymptotic lower bound for the number of hidden-layer\nnodes to achieve a given accuracy with high probability, depending on, among\nother things, the Lipschitz constant of the target function, the desired\naccuracy, and the input dimension. Our method of proof is rooted in probability\ntheory and harmonic analysis.", "AI": {"tldr": "The paper proves that a Random Vector Functional Link (RVFL) network with ReLU activations can approximate Lipschitz continuous functions in the $L_\\infty$ norm, using Gaussian inner weights. It provides a nonasymptotic lower bound for hidden-layer nodes to achieve desired accuracy.", "motivation": "To address the challenges of nonconvex optimization in neural networks by leveraging RVFL's linear optimization simplicity and proving its approximation capabilities.", "method": "Theoretical analysis using probability theory and harmonic analysis to derive bounds for RVFL networks with ReLU activations and Gaussian inner weights.", "result": "RVFL networks can approximate Lipschitz functions in $L_\\infty$ norm, with a nonasymptotic lower bound for hidden nodes based on accuracy, Lipschitz constant, and input dimension.", "conclusion": "RVFL networks are effective for function approximation with theoretical guarantees, avoiding nonconvex optimization pitfalls."}}
{"id": "2307.03334", "pdf": "https://arxiv.org/pdf/2307.03334", "abs": "https://arxiv.org/abs/2307.03334", "authors": ["C. -C. Joseph Wang", "F. Perkkola", "I. Salmenper\u00e4", "A. Meijer-van de Griend", "J. K. Nurminen", "R. S. Bennink"], "title": "Variational quantum regression algorithm with encoded data structure", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Hybrid variational quantum algorithms (VQAs) are promising for solving\npractical problems such as combinatorial optimization, quantum chemistry\nsimulation, quantum machine learning, and quantum error correction on noisy\nquantum computers. However, with typical random ansatz or quantum alternating\noperator ansatz, derived variational quantum algorithms become a black box that\ncannot be trusted for model interpretation, not to mention deploying as\napplications in informing critical decisions: the results of these variational\nparameters are just rotational angles for the quantum gates and have nothing to\ndo with interpretable values that a model can provide directly. In this paper,\nwe construct the first interpretable quantum regression algorithm, in which the\nquantum state exactly encodes the classical data table and the variational\nparameters correspond directly to the regression coefficients, which are real\nnumbers by construction, providing a high degree of model interpretability and\nminimal cost to optimize due to the right expressiveness. We also take\nadvantage of the encoded data structure to reduce the time complexity of\ncomputing the regression map. To shorten the circuit depth for nonlinear\nregression, our algorithm can be extended by building nonlinear features by\nclassical preprocessing as the independent encoded column vectors. Even though\nthe realization of compressed encoding in superconducting qubits has been\nachieved by the less noisy compressed encoding recently by the authors, we\nenvision potential quantum utilities with multi-qubit gates implemented in\nneutral cold atoms and ions.", "AI": {"tldr": "The paper introduces an interpretable quantum regression algorithm where quantum states encode classical data and variational parameters directly correspond to regression coefficients, enhancing model interpretability and optimization efficiency.", "motivation": "Current hybrid variational quantum algorithms lack interpretability, making them unreliable for critical decision-making. This work addresses this gap by developing a quantum regression algorithm with clear, interpretable parameters.", "method": "The algorithm encodes classical data into quantum states, with variational parameters representing regression coefficients. It leverages encoded data structure to reduce time complexity and uses classical preprocessing for nonlinear regression.", "result": "The proposed algorithm provides interpretable regression coefficients, reduces computational complexity, and supports nonlinear regression through classical preprocessing.", "conclusion": "This work advances quantum regression by ensuring interpretability and efficiency, with potential applications in quantum computing platforms like neutral cold atoms and ions."}}
{"id": "2402.06525", "pdf": "https://arxiv.org/pdf/2402.06525", "abs": "https://arxiv.org/abs/2402.06525", "authors": ["Ben Anson", "Edward Milsom", "Laurence Aitchison"], "title": "Flexible Infinite-Width Graph Convolutional Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": "Major revision. Title and abstract updated. Added new analysis\n  section on linear models and additional datasets. Paper accepted to TMLR", "summary": "A common theoretical approach to understanding neural networks is to take an\ninfinite-width limit, at which point the outputs become Gaussian process (GP)\ndistributed. This is known as a neural network Gaussian process (NNGP).\nHowever, the NNGP kernel is fixed and tunable only through a small number of\nhyperparameters, thus eliminating the possibility of representation learning.\nThis contrasts with finite-width NNs, which are often believed to perform well\nbecause they are able to flexibly learn representations for the task at hand.\nThus, in simplifying NNs to make them theoretically tractable, NNGPs may\neliminate precisely what makes them work well (representation learning). This\nmotivated us to understand whether representation learning is necessary in a\nrange of graph tasks. We develop a precise tool for this task, the graph\nconvolutional deep kernel machine. This is very similar to an NNGP, in that it\nis an infinite width limit and uses kernels, but comes with a ``knob'' to\ncontrol the amount of flexibility and hence representation learning. We found\nthat representation learning gives noticeable performance improvements for\nheterophilous node classification tasks, but less so for homophilous node\nclassification tasks.", "AI": {"tldr": "The paper explores whether representation learning is necessary in graph tasks by comparing infinite-width NNGPs (fixed kernels) with flexible models like the graph convolutional deep kernel machine.", "motivation": "NNGPs simplify neural networks but may lose representation learning, a key strength of finite-width NNs. The study aims to understand if representation learning is crucial for graph tasks.", "method": "Developed the graph convolutional deep kernel machine, an infinite-width model with adjustable flexibility to control representation learning.", "result": "Representation learning improves performance in heterophilous node classification but has less impact on homophilous tasks.", "conclusion": "Representation learning is beneficial for certain graph tasks (heterophilous), but its necessity varies depending on task characteristics."}}
{"id": "2403.11624", "pdf": "https://arxiv.org/pdf/2403.11624", "abs": "https://arxiv.org/abs/2403.11624", "authors": ["Xiang Li", "Chaofan Fu", "Zhongying Zhao", "Guanjie Zheng", "Chao Huang", "Yanwei Yu", "Junyu Dong"], "title": "Dual-Channel Multiplex Graph Neural Networks for Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Effective recommender systems play a crucial role in accurately capturing\nuser and item attributes that mirror individual preferences. Some existing\nrecommendation techniques have started to shift their focus towards modeling\nvarious types of interactive relations between users and items in real-world\nrecommendation scenarios, such as clicks, marking favorites, and purchases on\nonline shopping platforms. Nevertheless, these approaches still grapple with\ntwo significant challenges: (1) Insufficient modeling and exploitation of the\nimpact of various behavior patterns formed by multiplex relations between users\nand items on representation learning, and (2) ignoring the effect of different\nrelations within behavior patterns on the target relation in recommender system\nscenarios. In this work, we introduce a novel recommendation framework,\nDual-Channel Multiplex Graph Neural Network (DCMGNN), which addresses the\naforementioned challenges. It incorporates an explicit behavior pattern\nrepresentation learner to capture the behavior patterns composed of multiplex\nuser-item interactive relations, and includes a relation chain representation\nlearner and a relation chain-aware encoder to discover the impact of various\nauxiliary relations on the target relation, the dependencies between different\nrelations, and mine the appropriate order of relations in a behavior pattern.\nExtensive experiments on three real-world datasets demonstrate that our DCMGNN\nsurpasses various state-of-the-art recommendation methods. It outperforms the\nbest baselines by 10.06% and 12.15% on average across all datasets in terms of\nRecall@10 and NDCG@10, respectively.", "AI": {"tldr": "DCMGNN improves recommender systems by modeling behavior patterns and relations, outperforming baselines by 10.06% (Recall@10) and 12.15% (NDCG@10).", "motivation": "Existing methods struggle with modeling behavior patterns and relations in user-item interactions, limiting recommendation accuracy.", "method": "DCMGNN uses explicit behavior pattern and relation chain representation learners to capture multiplex relations and dependencies.", "result": "DCMGNN outperforms state-of-the-art methods by significant margins in Recall@10 and NDCG@10.", "conclusion": "DCMGNN effectively addresses challenges in modeling user-item interactions, enhancing recommendation performance."}}
{"id": "2404.17582", "pdf": "https://arxiv.org/pdf/2404.17582", "abs": "https://arxiv.org/abs/2404.17582", "authors": ["Yang Ba", "Michelle V. Mancenido", "Erin K. Chiou", "Rong Pan"], "title": "Data Quality in Crowdsourcing and Spamming Behavior Detection", "categories": ["cs.HC", "cs.LG", "stat.AP"], "comment": "Preprint paper, accepted on Behavior Research Methods. 56 pages, 14\n  figures", "summary": "As crowdsourcing emerges as an efficient and cost-effective method for\nobtaining labels for machine learning datasets, it is important to assess the\nquality of crowd-provided data, so as to improve analysis performance and\nreduce biases in subsequent machine learning tasks. Given the lack of ground\ntruth in most cases of crowdsourcing, we refer to data quality as annotators'\nconsistency and credibility. Unlike the simple scenarios where Kappa\ncoefficient and intraclass correlation coefficient usually can apply, online\ncrowdsourcing requires dealing with more complex situations. We introduce a\nsystematic method for evaluating data quality and detecting spamming threats\nvia variance decomposition, and we classify spammers into three categories\nbased on their different behavioral patterns. A spammer index is proposed to\nassess entire data consistency, and two metrics are developed to measure crowd\nworkers' credibility by utilizing the Markov chain and generalized random\neffects models. Furthermore, we showcase the practicality of our techniques and\ntheir advantages by applying them on a face verification task with both\nsimulation and real-world data collected from two crowdsourcing platforms.", "AI": {"tldr": "The paper proposes methods to assess data quality in crowdsourcing by evaluating annotator consistency and credibility, introducing metrics to detect spammers and improve machine learning tasks.", "motivation": "Crowdsourcing is efficient for labeling datasets, but assessing data quality is crucial to reduce biases and improve analysis performance, especially without ground truth.", "method": "The authors introduce variance decomposition for data quality evaluation, classify spammers into three types, and propose a spammer index and two credibility metrics using Markov chains and generalized random effects models.", "result": "The techniques are validated on a face verification task using simulation and real-world data from two crowdsourcing platforms, demonstrating practicality and advantages.", "conclusion": "The proposed systematic method effectively evaluates data quality and detects spamming threats, enhancing the reliability of crowdsourced labels for machine learning."}}
{"id": "2405.09493", "pdf": "https://arxiv.org/pdf/2405.09493", "abs": "https://arxiv.org/abs/2405.09493", "authors": ["Tiffany Tianhui Cai", "Yuri Fonseca", "Kaiwen Hou", "Hongseok Namkoong"], "title": "C-Learner: Constrained Learning for Causal Inference", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Popular debiased estimation methods for causal inference -- such as augmented\ninverse propensity weighting and targeted maximum likelihood estimation --\nenjoy desirable asymptotic properties like statistical efficiency and double\nrobustness but they can produce unstable estimates when there is limited\noverlap between treatment and control, requiring additional assumptions or ad\nhoc adjustments in practice (e.g., truncating propensity scores). In contrast,\nsimple plug-in estimators are stable but lack desirable asymptotic properties.\nWe propose a novel debiasing approach that achieves the best of both worlds,\nproducing stable plug-in estimates with desirable asymptotic properties. Our\nconstrained learning framework solves for the best plug-in estimator under the\nconstraint that the first-order error with respect to the plugged-in quantity\nis zero, and can leverage flexible model classes including neural networks and\ntree ensembles. In several experimental settings, including ones in which we\nhandle text-based covariates by fine-tuning language models, our constrained\nlearning-based estimator outperforms basic versions of one-step estimation and\ntargeting in challenging settings with limited overlap between treatment and\ncontrol, and performs similarly otherwise. Finally, to understand why our\nmethod exhibits superior performance in settings with low overlap, we present a\ntheoretical example with heavy-tailed inverse propensity scores in which other\ndebiased estimators converge more slowly compared to ours.", "AI": {"tldr": "A novel debiasing method for causal inference combines stability of plug-in estimators with desirable asymptotic properties, outperforming traditional debiased methods in low-overlap settings.", "motivation": "Traditional debiased methods (e.g., augmented inverse propensity weighting) are unstable with limited treatment-control overlap, while plug-in estimators lack asymptotic efficiency.", "method": "Proposes a constrained learning framework that optimizes plug-in estimators under a zero first-order error constraint, using flexible models like neural networks.", "result": "Outperforms traditional debiased methods in low-overlap settings and matches performance otherwise, with theoretical support for superior convergence.", "conclusion": "The method achieves stability and asymptotic efficiency, making it robust for causal inference in challenging scenarios."}}
{"id": "2406.02426", "pdf": "https://arxiv.org/pdf/2406.02426", "abs": "https://arxiv.org/abs/2406.02426", "authors": ["Tianyu Wang", "Ningyuan Chen", "Chun Wang"], "title": "Contextual Optimization under Covariate Shift: A Robust Approach by Intersecting Wasserstein Balls", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "In contextual optimization, a decision-maker leverages contextual\ninformation, often referred to as covariates, to better resolve uncertainty and\nmake informed decisions. In this paper, we examine the challenges of contextual\ndecision-making under covariate shift, a phenomenon where the distribution of\ncovariates differs between the training and test environments. Such shifts can\nlead to inaccurate upstream estimations for test covariates that lie far from\nthe training data, ultimately resulting in suboptimal downstream decisions. To\ntackle these challenges, we propose a novel approach called Intersection\nWasserstein-balls DRO (IW-DRO), which integrates multiple estimation methods\ninto the distributionally robust optimization (DRO) framework. At the core of\nour approach is an innovative ambiguity set defined as the intersection of two\nWasserstein balls, with their centers constructed using appropriate\nnonparametric and parametric estimators. On the computational side, we\nreformulate the IW-DRO problem as a tractable convex program and develop an\napproximate algorithm tailored for large-scale problems to enhance\ncomputational efficiency. From a theoretical perspective, we demonstrate that\nIW-DRO achieves superior performance compared to single Wasserstein-ball DRO\nmodels. We further establish performance guarantees by analyzing the coverage\nof the intersection ambiguity set and the measure concentration of both\nestimators under the Wasserstein distance. Notably, we derive a finite-sample\nconcentration result for the Nadaraya-Watson kernel estimator under covariate\nshift. The proposed IW-DRO framework offers practical value for decision-makers\noperating in uncertain environments affected by covariate shifts.", "AI": {"tldr": "The paper introduces IW-DRO, a method combining nonparametric and parametric estimators in a DRO framework to address covariate shift in contextual decision-making, offering computational efficiency and theoretical guarantees.", "motivation": "Covariate shift in contextual decision-making leads to suboptimal decisions due to distribution differences between training and test data. The paper aims to improve decision accuracy under such shifts.", "method": "Proposes IW-DRO, an approach using an ambiguity set defined by the intersection of two Wasserstein balls, integrating nonparametric and parametric estimators. It includes a tractable convex program and an approximate algorithm for large-scale problems.", "result": "IW-DRO outperforms single Wasserstein-ball DRO models, with theoretical guarantees on ambiguity set coverage and estimator performance under covariate shift.", "conclusion": "IW-DRO provides a practical and efficient solution for decision-makers facing covariate shift, with demonstrated superior performance and theoretical robustness."}}
{"id": "2408.08062", "pdf": "https://arxiv.org/pdf/2408.08062", "abs": "https://arxiv.org/abs/2408.08062", "authors": ["Max D. Champneys", "Timothy J. Rogers"], "title": "BINDy -- Bayesian identification of nonlinear dynamics with reversible-jump Markov-chain Monte-Carlo", "categories": ["stat.ML", "cs.LG", "math.DS"], "comment": null, "summary": "Model parsimony is an important \\emph{cognitive bias} in data-driven\nmodelling that aids interpretability and helps to prevent over-fitting. Sparse\nidentification of nonlinear dynamics (SINDy) methods are able to learn sparse\nrepresentations of complex dynamics directly from data, given a basis of\nlibrary functions. In this work, a novel Bayesian treatment of dictionary\nlearning system identification, as an alternative to SINDy, is envisaged. The\nproposed method -- Bayesian identification of nonlinear dynamics (BINDy) -- is\ndistinct from previous approaches in that it targets the full joint posterior\ndistribution over both the terms in the library and their parameterisation in\nthe model. This formulation confers the advantage that an arbitrary prior may\nbe placed over the model structure to produce models that are sparse in the\nmodel space rather than in parameter space. Because this posterior is defined\nover parameter vectors that can change in dimension, the inference cannot be\nperformed by standard techniques. Instead, a Gibbs sampler based on\nreversible-jump Markov-chain Monte-Carlo is proposed. BINDy is shown to compare\nfavourably to ensemble SINDy in three benchmark case-studies. In particular, it\nis seen that the proposed method is better able to assign high probability to\ncorrect model terms.", "AI": {"tldr": "BINDy introduces a Bayesian approach to sparse nonlinear dynamics identification, outperforming SINDy by targeting full joint posterior distributions and enabling arbitrary priors for sparsity.", "motivation": "To address limitations of SINDy by providing a Bayesian framework for sparse model identification, improving interpretability and avoiding overfitting.", "method": "Proposes BINDy, using reversible-jump MCMC for inference over joint posterior distributions of model terms and parameters, allowing flexible priors.", "result": "BINDy outperforms ensemble SINDy in benchmark studies, better identifying correct model terms with higher probability.", "conclusion": "BINDy offers a robust Bayesian alternative to SINDy, enhancing sparse model identification and interpretability."}}
{"id": "2411.16556", "pdf": "https://arxiv.org/pdf/2411.16556", "abs": "https://arxiv.org/abs/2411.16556", "authors": ["Ben Jacobson-Bell", "Steve Croft", "Carmen Choza", "Alex Andersson", "Daniel Bautista", "Vishal Gajjar", "Matthew Lebofsky", "David H. E. MacMahon", "Caleb Painter", "Andrew P. V. Siemion"], "title": "Anomaly Detection and Radio-frequency Interference Classification with Unsupervised Learning in Narrowband Radio Technosignature Searches", "categories": ["astro-ph.IM", "cs.LG"], "comment": "21 pages, 14 figures", "summary": "The search for radio technosignatures is an anomaly detection problem:\nCandidate signals represent needles of interest in the proverbial haystack of\nradio-frequency interference (RFI). Current search frameworks find an enormity\nof false-positive signals, especially in large surveys, requiring manual\nfollow-up to a sometimes prohibitive degree. Unsupervised learning provides an\nalgorithmic way to winnow the most anomalous signals from the chaff, as well as\ngroup together RFI signals that bear morphological similarities. We present\nGLOBULAR (Grouping Low-frequency Observations By Unsupervised Learning After\nReduction) clustering, a signal processing method that uses HDBSCAN to reduce\nthe false-positive rate and isolate outlier signals for further analysis. When\ncombined with a standard narrowband signal detection and spatial filtering\npipeline, such as turboSETI, GLOBULAR clustering offers significant\nimprovements in the false-positive rate over the standard pipeline alone,\nsuggesting dramatic potential for the amelioration of manual follow-up\nrequirements for future large surveys. By removing RFI signals in regions of\nhigh spectral occupancy, GLOBULAR clustering may also enable the detection of\nsignals missed by the standard pipeline. We benchmark our method against the\nChoza et al. turboSETI-only search of 97 nearby galaxies at the L band,\ndemonstrating a false-positive hit reduction rate of 93.1% and a false-positive\nevent reduction rate of 99.3%.", "AI": {"tldr": "GLOBULAR clustering uses unsupervised learning to reduce false positives in radio technosignature searches, improving efficiency over traditional methods.", "motivation": "Manual follow-up of false-positive signals in large radio surveys is prohibitive, necessitating an automated solution.", "method": "GLOBULAR clustering employs HDBSCAN to group and isolate anomalous signals, combined with turboSETI for narrowband detection.", "result": "The method reduces false-positive hits by 93.1% and events by 99.3% compared to turboSETI alone.", "conclusion": "GLOBULAR clustering significantly improves efficiency and may detect signals missed by standard pipelines, reducing manual effort in future surveys."}}
{"id": "2503.00131", "pdf": "https://arxiv.org/pdf/2503.00131", "abs": "https://arxiv.org/abs/2503.00131", "authors": ["Farouk Mokhtar", "Joosep Pata", "Dolores Garcia", "Eric Wulff", "Mengke Zhang", "Michael Kagan", "Javier Duarte"], "title": "Fine-tuning machine-learned particle-flow reconstruction for new detector geometries in future colliders", "categories": ["hep-ex", "cs.LG", "hep-ph", "physics.data-an", "physics.ins-det"], "comment": "20 pages, 13 figures", "summary": "We demonstrate transfer learning capabilities in a machine-learned algorithm\ntrained for particle-flow reconstruction in high energy particle colliders.\nThis paper presents a cross-detector fine-tuning study, where we initially\npretrain the model on a large full simulation dataset from one detector design,\nand subsequently fine-tune the model on a sample with a different collider and\ndetector design. Specifically, we use the Compact Linear Collider detector\n(CLICdet) model for the initial training set and demonstrate successful\nknowledge transfer to the CLIC-like detector (CLD) proposed for the Future\nCircular Collider in electron-positron mode. We show that with an order of\nmagnitude less samples from the second dataset, we can achieve the same\nperformance as a costly training from scratch, across particle-level and\nevent-level performance metrics, including jet and missing transverse momentum\nresolution. Furthermore, we find that the fine-tuned model achieves comparable\nperformance to the traditional rule-based particle-flow approach on event-level\nmetrics after training on 100,000 CLD events, whereas a model trained from\nscratch requires at least 1 million CLD events to achieve similar\nreconstruction performance. To our knowledge, this represents the first\nfull-simulation cross-detector transfer learning study for particle-flow\nreconstruction. These findings offer valuable insights towards building large\nfoundation models that can be fine-tuned across different detector designs and\ngeometries, helping to accelerate the development cycle for new detectors and\nopening the door to rapid detector design and optimization using machine\nlearning.", "AI": {"tldr": "Transfer learning in particle-flow reconstruction shows successful cross-detector fine-tuning, achieving comparable performance with fewer samples.", "motivation": "To accelerate detector development by enabling knowledge transfer between different collider and detector designs.", "method": "Pretrain on CLICdet data, then fine-tune on CLD data with fewer samples. Compare performance with training from scratch.", "result": "Fine-tuned model matches performance of costly scratch training with 10x fewer samples and rivals traditional methods with 100k events.", "conclusion": "Transfer learning reduces data needs, speeds up detector development, and supports foundation models for diverse designs."}}
{"id": "2503.04071", "pdf": "https://arxiv.org/pdf/2503.04071", "abs": "https://arxiv.org/abs/2503.04071", "authors": ["Miao Li", "Michael Klamkin", "Mathieu Tanneau", "Reza Zandehshahvar", "Pascal Van Hentenryck"], "title": "Conformal Prediction with Upper and Lower Bound Models", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper studies a Conformal Prediction (CP) methodology for building\nprediction intervals in a regression setting, given only deterministic lower\nand upper bounds on the target variable. It proposes a new CP mechanism (CPUL)\nthat goes beyond post-processing by adopting a model selection approach over\nmultiple nested interval construction methods. Paradoxically, many\nwell-established CP methods, including CPUL, may fail to provide adequate\ncoverage in regions where the bounds are tight. To remedy this limitation, the\npaper proposes an optimal thresholding mechanism, OMLT, that adjusts CPUL\nintervals in tight regions with undercoverage. The combined CPUL-OMLT is\nvalidated on large-scale learning tasks where the goal is to bound the optimal\nvalue of a parametric optimization problem. The experimental results\ndemonstrate substantial improvements over baseline methods across various\ndatasets.", "AI": {"tldr": "The paper introduces CPUL, a new Conformal Prediction method for regression with bounded targets, and OMLT, a thresholding mechanism to improve coverage in tight regions. Combined, they outperform baselines.", "motivation": "Existing CP methods may fail in regions with tight bounds on the target variable, necessitating a more robust solution.", "method": "Proposes CPUL for model selection over nested intervals and OMLT for optimal thresholding in tight regions.", "result": "CPUL-OMLT shows significant improvements over baseline methods in large-scale tasks.", "conclusion": "The combined CPUL-OMLT approach effectively addresses coverage limitations in tight-bound regions, validated by experiments."}}
{"id": "2503.13248", "pdf": "https://arxiv.org/pdf/2503.13248", "abs": "https://arxiv.org/abs/2503.13248", "authors": ["Akshay Thakur", "Matthew J. Zahr"], "title": "Neural network-based Godunov corrections for approximate Riemann solvers using bi-fidelity learning", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.flu-dyn"], "comment": "22 pages, 17 figures", "summary": "The Riemann problem is fundamental in the computational modeling of\nhyperbolic partial differential equations, enabling the development of stable\nand accurate upwind schemes. While exact solvers provide robust upwinding\nfluxes, their high computational cost necessitates approximate solvers.\nAlthough approximate solvers achieve accuracy in many scenarios, they produce\ninaccurate solutions in certain cases. To overcome this limitation, we propose\nconstructing neural network-based surrogate models, trained using supervised\nlearning, designed to map interior and exterior conservative state variables to\nthe corresponding exact flux. Specifically, we propose two distinct approaches:\none utilizing a vanilla neural network and the other employing a bi-fidelity\nneural network. The performance of the proposed approaches is demonstrated\nthrough applications to one-dimensional and two-dimensional partial\ndifferential equations, showcasing their robustness and accuracy.", "AI": {"tldr": "Proposes neural network-based surrogate models for solving the Riemann problem in hyperbolic PDEs, offering robust and accurate alternatives to exact and approximate solvers.", "motivation": "Exact solvers for the Riemann problem are computationally expensive, while approximate solvers can be inaccurate in some cases. Neural networks offer a balance.", "method": "Two approaches: a vanilla neural network and a bi-fidelity neural network, trained via supervised learning to map state variables to exact flux.", "result": "Demonstrated robustness and accuracy in 1D and 2D PDE applications.", "conclusion": "Neural network-based surrogates provide a viable solution to the limitations of traditional solvers for the Riemann problem."}}
{"id": "2503.17427", "pdf": "https://arxiv.org/pdf/2503.17427", "abs": "https://arxiv.org/abs/2503.17427", "authors": ["Michael D. White", "Michael D. Atkinson", "Adam J. Plowman", "Pratheek Shanthraj"], "title": "3D variational autoencoder for fingerprinting microstructure volume elements", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": "28 pages, 11 figures", "summary": "Microstructure quantification is an important step towards establishing\nstructure-property relationships in materials. Machine learning-based image\nprocessing methods have been shown to outperform conventional image processing\ntechniques and are increasingly applied to microstructure quantification tasks.\nIn this work, we present a 3D variational autoencoder (VAE) for encoding\nmicrostructure volume elements (VEs) comprising voxelated crystallographic\norientation data. Crystal symmetries in the orientation space are accounted for\nby mapping to the crystallographic fundamental zone as a preprocessing step,\nwhich allows for a continuous loss function to be used and improves the\ntraining convergence rate. The VAE is then used to encode a training set of VEs\nwith an equiaxed polycrystalline microstructure with random texture. Accurate\nreconstructions are achieved with a relative average misorientation error of\n3x10^-2 on the test dataset, for a continuous latent space with dimension 256.\nWe show that the model generalises well to microstructures with textures, grain\nsizes and aspect ratios outside the training distribution. Structure-property\nrelationships are explored through using the training set of VEs as initial\nconfigurations in various crystal plasticity (CP) simulations. Microstructural\nfingerprints extracted from the VAE, which parameterise the VEs in a\nlow-dimensional latent space, are stored alongside the volume-averaged stress\nresponse, at each strain increment, to uniaxial tensile deformation from CP\nsimulations. This is then used to train a fully connected neural network\nmapping the input fingerprint to the resulting stress response, which acts as a\nsurrogate model for the CP simulation. The fingerprint-based surrogate model is\nshown to accurately predict the microstructural dependence in the CP stress\nresponse, with a relative mean-squared error of 2.75 MPa on unseen test data.", "AI": {"tldr": "A 3D variational autoencoder (VAE) is developed for microstructure quantification, encoding voxelated crystallographic data with improved training convergence. The model generalizes well and aids in predicting stress responses via a surrogate neural network.", "motivation": "To enhance microstructure quantification and establish structure-property relationships using machine learning, outperforming conventional methods.", "method": "A 3D VAE encodes microstructure volume elements (VEs) with crystallographic orientation data, using a continuous loss function for better training. A surrogate neural network maps VAE fingerprints to stress responses from crystal plasticity simulations.", "result": "Accurate reconstructions (relative error: 3x10^-2) and generalization to unseen microstructures. The surrogate model predicts stress responses with a relative mean-squared error of 2.75 MPa.", "conclusion": "The VAE and surrogate model effectively quantify microstructures and predict mechanical properties, demonstrating potential for materials science applications."}}
{"id": "2504.05654", "pdf": "https://arxiv.org/pdf/2504.05654", "abs": "https://arxiv.org/abs/2504.05654", "authors": ["Frank Nielsen"], "title": "Curved representational Bregman divergences and their applications", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": "12 pages, 5 figures", "summary": "By analogy to curved exponential families in statistics, we define curved\nBregman divergences as Bregman divergences restricted to nonlinear parameter\nsubspaces. We show that the barycenter of a finite weighted set of parameters\nunder a curved Bregman divergence amounts to the right Bregman projection onto\nthe nonlinear subspace of the barycenter with respect to the full Bregman\ndivergence. We demonstrate the significance of curved Bregman divergences with\ntwo examples: (1) symmetrized Bregman divergences and (2) the Kullback-Leibler\ndivergence between circular complex normal distributions. We then consider\nmonotonic embeddings to define representational curved Bregman divergences and\nshow that the $\\alpha$-divergences are representational curved Bregman\ndivergences with respect to $\\alpha$-embeddings of the probability simplex into\nthe positive measure cone. As an application, we report an efficient method to\ncalculate the intersection of a finite set of $\\alpha$-divergence spheres.", "AI": {"tldr": "The paper introduces curved Bregman divergences, showing their barycenter properties and applications in symmetrized Bregman divergences and KL divergence for circular complex normal distributions. It also links \u03b1-divergences to representational curved Bregman divergences and provides an efficient method for calculating intersections of \u03b1-divergence spheres.", "motivation": "To extend Bregman divergences to nonlinear subspaces, analogous to curved exponential families in statistics, and explore their theoretical and practical implications.", "method": "Defines curved Bregman divergences, analyzes barycenter properties, and demonstrates applications with symmetrized Bregman divergences and KL divergence. Introduces representational curved Bregman divergences via monotonic embeddings.", "result": "Shows barycenters under curved Bregman divergences correspond to Bregman projections. Links \u03b1-divergences to representational curved Bregman divergences. Provides an efficient method for \u03b1-divergence sphere intersections.", "conclusion": "Curved Bregman divergences generalize Bregman divergences to nonlinear subspaces, with applications in statistics and information geometry, including \u03b1-divergences and efficient computational methods."}}
{"id": "2504.13320", "pdf": "https://arxiv.org/pdf/2504.13320", "abs": "https://arxiv.org/abs/2504.13320", "authors": ["Robert Gruhlke", "Matei Hanu", "Claudia Schillings", "Philipp Wacker"], "title": "Gradient-Free Sequential Bayesian Experimental Design via Interacting Particle Systems", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "stat.CO", "62K05, 62F15, 65C05, 93E10"], "comment": null, "summary": "We introduce a gradient-free framework for Bayesian Optimal Experimental\nDesign (BOED) in sequential settings, aimed at complex systems where gradient\ninformation is unavailable. Our method combines Ensemble Kalman Inversion (EKI)\nfor design optimization with the Affine-Invariant Langevin Dynamics (ALDI)\nsampler for efficient posterior sampling-both of which are derivative-free and\nensemble-based. To address the computational challenges posed by nested\nexpectations in BOED, we propose variational Gaussian and parametrized Laplace\napproximations that provide tractable upper and lower bounds on the Expected\nInformation Gain (EIG). These approximations enable scalable utility estimation\nin high-dimensional spaces and PDE-constrained inverse problems. We demonstrate\nthe performance of our framework through numerical experiments ranging from\nlinear Gaussian models to PDE-based inference tasks, highlighting the method's\nrobustness, accuracy, and efficiency in information-driven experimental design.", "AI": {"tldr": "A gradient-free framework for Bayesian Optimal Experimental Design (BOED) using Ensemble Kalman Inversion (EKI) and Affine-Invariant Langevin Dynamics (ALDI) for efficient posterior sampling. Variational approximations enable scalable utility estimation in high-dimensional spaces.", "motivation": "Addresses the challenge of BOED in complex systems where gradient information is unavailable, aiming for efficient and accurate experimental design.", "method": "Combines EKI for design optimization and ALDI for posterior sampling, with variational Gaussian and Laplace approximations to bound Expected Information Gain (EIG).", "result": "Demonstrated robustness, accuracy, and efficiency in numerical experiments, including PDE-based inference tasks.", "conclusion": "The framework provides a scalable and derivative-free solution for information-driven experimental design in high-dimensional and complex systems."}}
{"id": "2505.01484", "pdf": "https://arxiv.org/pdf/2505.01484", "abs": "https://arxiv.org/abs/2505.01484", "authors": ["Pedro Abdalla", "Roman Vershynin"], "title": "LLM Watermarking Using Mixtures and Statistical-to-Computational Gaps", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Given a text, can we determine whether it was generated by a large language\nmodel (LLM) or by a human? A widely studied approach to this problem is\nwatermarking. We propose an undetectable and elementary watermarking scheme in\nthe closed setting. Also, in the harder open setting, where the adversary has\naccess to most of the model, we propose an unremovable watermarking scheme.", "AI": {"tldr": "The paper proposes watermarking schemes to detect LLM-generated text, focusing on undetectable (closed setting) and unremovable (open setting) methods.", "motivation": "To distinguish between human and LLM-generated text, addressing the challenge of detection in varying adversarial settings.", "method": "Introduces two watermarking schemes: one undetectable for closed settings and another unremovable for open settings where adversaries have model access.", "result": "The schemes aim to reliably detect LLM-generated text while resisting adversarial removal or detection.", "conclusion": "The proposed methods provide practical solutions for detecting LLM-generated content in different adversarial scenarios."}}
{"id": "2505.03906", "pdf": "https://arxiv.org/pdf/2505.03906", "abs": "https://arxiv.org/abs/2505.03906", "authors": ["Asif Rahman", "Veljko Cvetkovic", "Kathleen Reece", "Aidan Walters", "Yasir Hassan", "Aneesh Tummeti", "Bryan Torres", "Denise Cooney", "Margaret Ellis", "Dimitrios S. Nikolopoulos"], "title": "MARCO: Multi-Agent Code Optimization with Real-Time Knowledge Integration for High-Performance Computing", "categories": ["cs.DC", "cs.LG", "cs.SE"], "comment": "9 pages, 4 figures, 2 tables", "summary": "Large language models (LLMs) have transformed software development through\ncode generation capabilities, yet their effectiveness for high-performance\ncomputing (HPC) remains limited. HPC code requires specialized optimizations\nfor parallelism, memory efficiency, and architecture-specific considerations\nthat general-purpose LLMs often overlook. We present MARCO (Multi-Agent\nReactive Code Optimizer), a novel framework that enhances LLM-generated code\nfor HPC through a specialized multi-agent architecture. MARCO employs separate\nagents for code generation and performance evaluation, connected by a feedback\nloop that progressively refines optimizations. A key innovation is MARCO's\nweb-search component that retrieves real-time optimization techniques from\nrecent conference proceedings and research publications, bridging the knowledge\ngap in pre-trained LLMs. Our extensive evaluation on the LeetCode 75 problem\nset demonstrates that MARCO achieves a 14.6\\% average runtime reduction\ncompared to Claude 3.5 Sonnet alone, while the integration of the web-search\ncomponent yields a 30.9\\% performance improvement over the base MARCO system.\nThese results highlight the potential of multi-agent systems to address the\nspecialized requirements of high-performance code generation, offering a\ncost-effective alternative to domain-specific model fine-tuning.", "AI": {"tldr": "MARCO, a multi-agent framework, enhances LLM-generated HPC code by combining specialized agents for generation and evaluation, plus real-time web-search for optimizations, achieving significant performance improvements.", "motivation": "General-purpose LLMs lack specialized optimizations for HPC code, limiting their effectiveness in high-performance computing.", "method": "MARCO uses a multi-agent architecture with separate agents for code generation and performance evaluation, linked by a feedback loop, and integrates a web-search component for real-time optimization techniques.", "result": "MARCO reduces runtime by 14.6% compared to Claude 3.5 Sonnet alone, and the web-search component adds a 30.9% performance boost.", "conclusion": "Multi-agent systems like MARCO offer a cost-effective solution for HPC code generation, addressing LLM limitations without domain-specific fine-tuning."}}
{"id": "2506.01891", "pdf": "https://arxiv.org/pdf/2506.01891", "abs": "https://arxiv.org/abs/2506.01891", "authors": ["Mahmud Ashraf Shamim", "Eric A F Reinhardt", "Talal Ahmed Chowdhury", "Sergei Gleyzer", "Paulo T Araujo"], "title": "Probing Quantum Spin Systems with Kolmogorov-Arnold Neural Network Quantum States", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.str-el", "cs.LG"], "comment": "16 pages, 13 figures", "summary": "Neural Quantum States (NQS) are a class of variational wave functions\nparametrized by neural networks (NNs) to study quantum many-body systems. In\nthis work, we propose \\texttt{SineKAN}, a NQS \\textit{ansatz} based on\nKolmogorov-Arnold Networks (KANs), to represent quantum mechanical wave\nfunctions as nested univariate functions. We show that \\texttt{SineKAN}\nwavefunction with learnable sinusoidal activation functions can capture the\nground state energies, fidelities and various correlation functions of the one\ndimensional Transverse-Field Ising model, Anisotropic Heisenberg model, and\nAntiferromagnetic $J_{1}-J_{2}$ model with different chain lengths. In our\nstudy of the $J_1-J_2$ model with $L=100$ sites, we find that the\n\\texttt{SineKAN} model outperforms several previously explored neural quantum\nstate \\textit{ans\\\"atze}, including Restricted Boltzmann Machines (RBMs), Long\nShort-Term Memory models (LSTMs), and Multi-layer Perceptrons (MLP)\n\\textit{a.k.a.} Feed Forward Neural Networks, when compared to the results\nobtained from the Density Matrix Renormalization Group (DMRG) algorithm. We\nfind that \\texttt{SineKAN} models can be trained to high precisions and\naccuracies with minimal computational costs.", "AI": {"tldr": "The paper introduces SineKAN, a neural quantum state ansatz using Kolmogorov-Arnold Networks, which outperforms existing methods in modeling quantum systems.", "motivation": "To improve the representation of quantum mechanical wave functions using neural networks for better accuracy and efficiency.", "method": "Proposes SineKAN, a NQS ansatz with learnable sinusoidal activation functions, tested on various quantum models.", "result": "SineKAN achieves higher precision and accuracy than RBMs, LSTMs, and MLPs, with lower computational costs.", "conclusion": "SineKAN is a promising approach for studying quantum many-body systems efficiently."}}
{"id": "2506.12903", "pdf": "https://arxiv.org/pdf/2506.12903", "abs": "https://arxiv.org/abs/2506.12903", "authors": ["Avrajit Ghosh", "Bai Cong", "Rio Yokota", "Saiprasad Ravishankar", "Rongrong Wang", "Molei Tao", "Mohammad Emtiyaz Khan", "Thomas M\u00f6llenhoff"], "title": "Variational Learning Finds Flatter Solutions at the Edge of Stability", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Variational Learning (VL) has recently gained popularity for training deep\nneural networks and is competitive to standard learning methods. Part of its\nempirical success can be explained by theories such as PAC-Bayes bounds,\nminimum description length and marginal likelihood, but there are few tools to\nunravel the implicit regularization in play. Here, we analyze the implicit\nregularization of VL through the Edge of Stability (EoS) framework. EoS has\npreviously been used to show that gradient descent can find flat solutions and\nwe extend this result to VL to show that it can find even flatter solutions.\nThis is obtained by controlling the posterior covariance and the number of\nMonte Carlo samples from the posterior. These results are derived in a similar\nfashion as the standard EoS literature for deep learning, by first deriving a\nresult for a quadratic problem and then extending it to deep neural networks.\nWe empirically validate these findings on a wide variety of large networks,\nsuch as ResNet and ViT, to find that the theoretical results closely match the\nempirical ones. Ours is the first work to analyze the EoS dynamics in VL.", "AI": {"tldr": "The paper analyzes implicit regularization in Variational Learning (VL) using the Edge of Stability (EoS) framework, showing VL finds flatter solutions than gradient descent by controlling posterior covariance and Monte Carlo samples.", "motivation": "To understand the implicit regularization in VL, which lacks theoretical tools despite its empirical success.", "method": "Extends the EoS framework to VL, deriving results first for a quadratic problem and then for deep neural networks, validated on ResNet and ViT.", "result": "VL finds flatter solutions than gradient descent, with theoretical and empirical results aligning.", "conclusion": "This is the first work to analyze EoS dynamics in VL, providing insights into its implicit regularization."}}
{"id": "2506.14922", "pdf": "https://arxiv.org/pdf/2506.14922", "abs": "https://arxiv.org/abs/2506.14922", "authors": ["Christina Q. Knight", "Kaustubh Deshpande", "Ved Sirdeshmukh", "Meher Mankikar", "Scale Red Team", "SEAL Research Team", "Julian Michael"], "title": "FORTRESS: Frontier Risk Evaluation for National Security and Public Safety", "categories": ["cs.CY", "cs.LG"], "comment": "12 pages, 7 figures, submitted to NeurIPS", "summary": "The rapid advancement of large language models (LLMs) introduces dual-use\ncapabilities that could both threaten and bolster national security and public\nsafety (NSPS). Models implement safeguards to protect against potential misuse\nrelevant to NSPS and allow for benign users to receive helpful information.\nHowever, current benchmarks often fail to test safeguard robustness to\npotential NSPS risks in an objective, robust way. We introduce FORTRESS: 500\nexpert-crafted adversarial prompts with instance-based rubrics of 4-7 binary\nquestions for automated evaluation across 3 domains (unclassified information\nonly): Chemical, Biological, Radiological, Nuclear and Explosive (CBRNE),\nPolitical Violence & Terrorism, and Criminal & Financial Illicit Activities,\nwith 10 total subcategories across these domains. Each prompt-rubric pair has a\ncorresponding benign version to test for model over-refusals. This evaluation\nof frontier LLMs' safeguard robustness reveals varying trade-offs between\npotential risks and model usefulness: Claude-3.5-Sonnet demonstrates a low\naverage risk score (ARS) (14.09 out of 100) but the highest over-refusal score\n(ORS) (21.8 out of 100), while Gemini 2.5 Pro shows low over-refusal (1.4) but\na high average potential risk (66.29). Deepseek-R1 has the highest ARS at\n78.05, but the lowest ORS at only 0.06. Models such as o1 display a more even\ntrade-off between potential risks and over-refusals (with an ARS of 21.69 and\nORS of 5.2). To provide policymakers and researchers with a clear understanding\nof models' potential risks, we publicly release FORTRESS at\nhttps://huggingface.co/datasets/ScaleAI/fortress_public. We also maintain a\nprivate set for evaluation.", "AI": {"tldr": "FORTRESS introduces 500 expert-crafted adversarial prompts to evaluate LLM safeguards across NSPS risks, revealing trade-offs between risk and over-refusal in models like Claude-3.5-Sonnet and Gemini 2.5 Pro.", "motivation": "Current benchmarks inadequately test LLM safeguards for national security and public safety (NSPS) risks, necessitating a robust, objective evaluation method.", "method": "FORTRESS uses 500 adversarial prompts with rubrics across 3 domains (CBRNE, Political Violence & Terrorism, Criminal & Financial Illicit Activities) to evaluate LLMs.", "result": "Models show varying trade-offs: Claude-3.5-Sonnet has low risk but high over-refusal, Gemini 2.5 Pro has low over-refusal but high risk, and Deepseek-R1 has the highest risk but lowest over-refusal.", "conclusion": "FORTRESS provides a clear framework for policymakers and researchers to assess LLM safeguard robustness, with public and private datasets available."}}
{"id": "2506.15176", "pdf": "https://arxiv.org/pdf/2506.15176", "abs": "https://arxiv.org/abs/2506.15176", "authors": ["Matteo Zecchin", "Tomer Raviv", "Dileep Kalathil", "Krishna Narayanan", "Nir Shlezinger", "Osvaldo Simeone"], "title": "In-Context Learning for Gradient-Free Receiver Adaptation: Principles, Applications, and Theory", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "In recent years, deep learning has facilitated the creation of wireless\nreceivers capable of functioning effectively in conditions that challenge\ntraditional model-based designs. Leveraging programmable hardware\narchitectures, deep learning-based receivers offer the potential to dynamically\nadapt to varying channel environments. However, current adaptation strategies,\nincluding joint training, hypernetwork-based methods, and meta-learning, either\ndemonstrate limited flexibility or necessitate explicit optimization through\ngradient descent. This paper presents gradient-free adaptation techniques\nrooted in the emerging paradigm of in-context learning (ICL). We review\narchitectural frameworks for ICL based on Transformer models and structured\nstate-space models (SSMs), alongside theoretical insights into how sequence\nmodels effectively learn adaptation from contextual information. Further, we\nexplore the application of ICL to cell-free massive MIMO networks, providing\nboth theoretical analyses and empirical evidence. Our findings indicate that\nICL represents a principled and efficient approach to real-time receiver\nadaptation using pilot signals and auxiliary contextual information-without\nrequiring online retraining.", "AI": {"tldr": "The paper introduces gradient-free adaptation techniques for deep learning-based wireless receivers using in-context learning (ICL), eliminating the need for online retraining.", "motivation": "Traditional adaptation strategies for wireless receivers lack flexibility or require explicit optimization. The paper aims to address these limitations with ICL.", "method": "The paper reviews architectural frameworks for ICL (Transformer models and SSMs) and applies ICL to cell-free massive MIMO networks, supported by theoretical and empirical analysis.", "result": "ICL enables efficient real-time receiver adaptation using pilot signals and contextual information without online retraining.", "conclusion": "ICL offers a principled and practical solution for dynamic adaptation in wireless receivers."}}
{"id": "2506.16394", "pdf": "https://arxiv.org/pdf/2506.16394", "abs": "https://arxiv.org/abs/2506.16394", "authors": ["Zelin Xiao", "Jia Gu", "Song Xi Chen"], "title": "Identifying Heterogeneity in Distributed Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study methods for identifying heterogeneous parameter components in\ndistributed M-estimation with minimal data transmission. One is based on a\nre-normalized Wald test, which is shown to be consistent as long as the number\nof distributed data blocks $K$ is of a smaller order of the minimum block\nsample size and the level of heterogeneity is dense. The second one is an\nextreme contrast test (ECT) based on the difference between the largest and\nsmallest component-wise estimated parameters among data blocks. By introducing\na sample splitting procedure, the ECT can avoid the bias accumulation arising\nfrom the M-estimation procedures, and exhibits consistency for $K$ being much\nlarger than the sample size while the heterogeneity is sparse. The ECT\nprocedure is easy to operate and communication-efficient. A combination of the\nWald and the extreme contrast tests is formulated to attain more robust power\nunder varying levels of sparsity of the heterogeneity. We also conduct\nintensive numerical experiments to compare the family-wise error rate (FWER)\nand the power of the proposed methods. Additionally, we conduct a case study to\npresent the implementation and validity of the proposed methods.", "AI": {"tldr": "The paper proposes two methods for identifying heterogeneous parameters in distributed M-estimation with minimal data transmission: a re-normalized Wald test for dense heterogeneity and an extreme contrast test (ECT) for sparse heterogeneity. A combination of both methods is suggested for robust performance. Numerical experiments and a case study validate the methods.", "motivation": "To address the challenge of identifying heterogeneous parameter components in distributed M-estimation efficiently, with minimal data transmission.", "method": "1. Re-normalized Wald test for dense heterogeneity (works when the number of data blocks is smaller than the minimum block sample size). 2. Extreme contrast test (ECT) for sparse heterogeneity (avoids bias via sample splitting and works for larger K). A combination of both tests is proposed for robustness.", "result": "The Wald test is consistent for dense heterogeneity, while ECT is consistent for sparse heterogeneity and larger K. The combined method offers robust power under varying sparsity levels. Numerical experiments confirm control of FWER and power.", "conclusion": "The proposed methods effectively identify heterogeneous parameters in distributed M-estimation, with ECT being communication-efficient and easy to operate. The combination of Wald and ECT tests enhances robustness."}}
{"id": "2506.17634", "pdf": "https://arxiv.org/pdf/2506.17634", "abs": "https://arxiv.org/abs/2506.17634", "authors": ["Csaba T\u00f3th"], "title": "Scalable Machine Learning Algorithms using Path Signatures", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": "PhD thesis", "summary": "The interface between stochastic analysis and machine learning is a rapidly\nevolving field, with path signatures - iterated integrals that provide\nfaithful, hierarchical representations of paths - offering a principled and\nuniversal feature map for sequential and structured data. Rooted in rough path\ntheory, path signatures are invariant to reparameterization and well-suited for\nmodelling evolving dynamics, long-range dependencies, and irregular sampling -\ncommon challenges in real-world time series and graph data.\n  This thesis investigates how to harness the expressive power of path\nsignatures within scalable machine learning pipelines. It introduces a suite of\nmodels that combine theoretical robustness with computational efficiency,\nbridging rough path theory with probabilistic modelling, deep learning, and\nkernel methods. Key contributions include: Gaussian processes with signature\nkernel-based covariance functions for uncertainty-aware time series modelling;\nthe Seq2Tens framework, which employs low-rank tensor structure in the weight\nspace for scalable deep modelling of long-range dependencies; and graph-based\nmodels where expected signatures over graphs induce hypo-elliptic diffusion\nprocesses, offering expressive yet tractable alternatives to standard graph\nneural networks. Further developments include Random Fourier Signature\nFeatures, a scalable kernel approximation with theoretical guarantees, and\nRecurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussian\nprocesses, signature kernels, and random features with a principled forgetting\nmechanism for multi-horizon time series forecasting with adaptive context\nlength.\n  We hope this thesis serves as both a methodological toolkit and a conceptual\nbridge, and provides a useful reference for the current state of the art in\nscalable, signature-based learning for sequential and structured data.", "AI": {"tldr": "The paper explores using path signatures in scalable machine learning pipelines, introducing models like Gaussian processes with signature kernels and Seq2Tens for long-range dependencies.", "motivation": "To address challenges in real-world time series and graph data by leveraging path signatures' theoretical robustness and invariance properties.", "method": "Combines rough path theory with probabilistic modeling, deep learning, and kernel methods, introducing signature-based models like Gaussian processes, Seq2Tens, and graph-based models.", "result": "Developed scalable tools like Random Fourier Signature Features and Recurrent Sparse Spectrum Signature Gaussian Processes for uncertainty-aware and adaptive forecasting.", "conclusion": "The thesis provides a methodological toolkit and conceptual bridge for scalable, signature-based learning in sequential and structured data."}}
