{"id": "2505.13480", "pdf": "https://arxiv.org/pdf/2505.13480", "abs": "https://arxiv.org/abs/2505.13480", "authors": ["Avinash Patil", "Siru Tao", "Amardeep Gedhu"], "title": "Evaluating Reasoning LLMs for Suicide Screening with the Columbia-Suicide Severity Rating Scale", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "8 Pages, 6 Figures, 1 Table", "summary": "Suicide prevention remains a critical public health challenge. While online\nplatforms such as Reddit's r/SuicideWatch have historically provided spaces for\nindividuals to express suicidal thoughts and seek community support, the advent\nof large language models (LLMs) introduces a new paradigm-where individuals may\nbegin disclosing ideation to AI systems instead of humans. This study evaluates\nthe capability of LLMs to perform automated suicide risk assessment using the\nColumbia-Suicide Severity Rating Scale (C-SSRS). We assess the zero-shot\nperformance of six models-including Claude, GPT, Mistral, and LLaMA-in\nclassifying posts across a 7-point severity scale (Levels 0-6). Results\nindicate that Claude and GPT closely align with human annotations, while\nMistral achieves the lowest ordinal prediction error. Most models exhibit\nordinal sensitivity, with misclassifications typically occurring between\nadjacent severity levels. We further analyze confusion patterns,\nmisclassification sources, and ethical considerations, underscoring the\nimportance of human oversight, transparency, and cautious deployment. Full code\nand supplementary materials are available at\nhttps://github.com/av9ash/llm_cssrs_code."}
{"id": "2505.13483", "pdf": "https://arxiv.org/pdf/2505.13483", "abs": "https://arxiv.org/abs/2505.13483", "authors": ["Xingyuan Lu", "Yuxi Liu", "Dongyu Zhang", "Zhiyao Wu", "Jing Ren", "Feng Xia"], "title": "EmoMeta: A Multimodal Dataset for Fine-grained Emotion Classification in Chinese Metaphors", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Metaphors play a pivotal role in expressing emotions, making them crucial for\nemotional intelligence. The advent of multimodal data and widespread\ncommunication has led to a proliferation of multimodal metaphors, amplifying\nthe complexity of emotion classification compared to single-mode scenarios.\nHowever, the scarcity of research on constructing multimodal metaphorical\nfine-grained emotion datasets hampers progress in this domain. Moreover,\nexisting studies predominantly focus on English, overlooking potential\nvariations in emotional nuances across languages. To address these gaps, we\nintroduce a multimodal dataset in Chinese comprising 5,000 text-image pairs of\nmetaphorical advertisements. Each entry is meticulously annotated for metaphor\noccurrence, domain relations and fine-grained emotion classification\nencompassing joy, love, trust, fear, sadness, disgust, anger, surprise,\nanticipation, and neutral. Our dataset is publicly accessible\n(https://github.com/DUTIR-YSQ/EmoMeta), facilitating further advancements in\nthis burgeoning field."}
{"id": "2505.13487", "pdf": "https://arxiv.org/pdf/2505.13487", "abs": "https://arxiv.org/abs/2505.13487", "authors": ["Ashwin Kumar", "Yuzi He", "Aram H. Markosyan", "Bobbie Chern", "Imanol Arrieta-Ibarra"], "title": "Detecting Prefix Bias in LLM-based Reward Models", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning with Human Feedback (RLHF) has emerged as a key\nparadigm for task-specific fine-tuning of language models using human\npreference data. While numerous publicly available preference datasets provide\npairwise comparisons of responses, the potential for biases in the resulting\nreward models remains underexplored. In this work, we introduce novel methods\nto detect and evaluate prefix bias -- a systematic shift in model preferences\ntriggered by minor variations in query prefixes -- in LLM-based reward models\ntrained on such datasets. We leverage these metrics to reveal significant\nbiases in preference models across racial and gender dimensions. Our\ncomprehensive evaluation spans diverse open-source preference datasets and\nreward model architectures, demonstrating susceptibility to this kind of bias\nregardless of the underlying model architecture. Furthermore, we propose a data\naugmentation strategy to mitigate these biases, showing its effectiveness in\nreducing the impact of prefix bias. Our findings highlight the critical need\nfor bias-aware dataset design and evaluation in developing fair and reliable\nreward models, contributing to the broader discourse on fairness in AI."}
{"id": "2505.13488", "pdf": "https://arxiv.org/pdf/2505.13488", "abs": "https://arxiv.org/abs/2505.13488", "authors": ["Federico Germani", "Giovanni Spitale"], "title": "Source framing triggers systematic evaluation bias in Large Language Models", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used not only to generate text\nbut also to evaluate it, raising urgent questions about whether their judgments\nare consistent, unbiased, and robust to framing effects. In this study, we\nsystematically examine inter- and intra-model agreement across four\nstate-of-the-art LLMs (OpenAI o3-mini, Deepseek Reasoner, xAI Grok 2, and\nMistral) tasked with evaluating 4,800 narrative statements on 24 different\ntopics of social, political, and public health relevance, for a total of\n192,000 assessments. We manipulate the disclosed source of each statement to\nassess how attribution to either another LLM or a human author of specified\nnationality affects evaluation outcomes. We find that, in the blind condition,\ndifferent LLMs display a remarkably high degree of inter- and intra-model\nagreement across topics. However, this alignment breaks down when source\nframing is introduced. Here we show that attributing statements to Chinese\nindividuals systematically lowers agreement scores across all models, and in\nparticular for Deepseek Reasoner. Our findings reveal that framing effects can\ndeeply affect text evaluation, with significant implications for the integrity,\nneutrality, and fairness of LLM-mediated information systems."}
{"id": "2505.13468", "pdf": "https://arxiv.org/pdf/2505.13468", "abs": "https://arxiv.org/abs/2505.13468", "authors": ["Wenxuan Zhang", "Peng Hu"], "title": "An Edge AI Solution for Space Object Detection", "categories": ["cs.CV", "astro-ph.IM", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted as poster paper at the 2025 IEEE Canadian Conference on\n  Electrical and Computer Engineering (CCECE)", "summary": "Effective Edge AI for space object detection (SOD) tasks that can facilitate\nreal-time collision assessment and avoidance is essential with the increasing\nspace assets in near-Earth orbits. In SOD, low Earth orbit (LEO) satellites\nmust detect other objects with high precision and minimal delay. We explore an\nEdge AI solution based on deep-learning-based vision sensing for SOD tasks and\npropose a deep learning model based on Squeeze-and-Excitation (SE) layers,\nVision Transformers (ViT), and YOLOv9 framework. We evaluate the performance of\nthese models across various realistic SOD scenarios, demonstrating their\nability to detect multiple satellites with high accuracy and very low latency."}
{"id": "2505.13457", "pdf": "https://arxiv.org/pdf/2505.13457", "abs": "https://arxiv.org/abs/2505.13457", "authors": ["Nathan Faraj"], "title": "Tuning Learning Rates with the Cumulative-Learning Constant", "categories": ["cs.LG"], "comment": "9 pages, 13 figures, 2 tables", "summary": "This paper introduces a novel method for optimizing learning rates in machine\nlearning. A previously unrecognized proportionality between learning rates and\ndataset sizes is discovered, providing valuable insights into how dataset scale\ninfluences training dynamics. Additionally, a cumulative learning constant is\nidentified, offering a framework for designing and optimizing advanced learning\nrate schedules. These findings have the potential to enhance training\nefficiency and performance across a wide range of machine learning\napplications."}
{"id": "2505.13466", "pdf": "https://arxiv.org/pdf/2505.13466", "abs": "https://arxiv.org/abs/2505.13466", "authors": ["Vu Dinh Xuan", "Hao Vo", "David Murphy", "Hoang D. Nguyen"], "title": "AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data", "categories": ["cs.AI"], "comment": null, "summary": "The scarcity of data depicting dangerous situations presents a major obstacle\nto training AI systems for safety-critical applications, such as construction\nsafety, where ethical and logistical barriers hinder real-world data\ncollection. This creates an urgent need for an end-to-end framework to generate\nsynthetic data that can bridge this gap. While existing methods can produce\nsynthetic scenes, they often lack the semantic depth required for scene\nsimulations, limiting their effectiveness. To address this, we propose a novel\nmulti-agent framework that employs an iterative, in-the-loop collaboration\nbetween two agents: an Evaluator Agent, acting as an LLM-based judge to enforce\nsemantic consistency and safety-specific constraints, and an Editor Agent,\nwhich generates and refines scenes based on this guidance. Powered by LLM's\ncapabilities to reasoning and common-sense knowledge, this collaborative design\nproduces synthetic images tailored to safety-critical scenarios. Our\nexperiments suggest this design can generate useful scenes based on realistic\nspecifications that address the shortcomings of prior approaches, balancing\nsafety requirements with visual semantics. This iterative process holds promise\nfor delivering robust, aesthetically sound simulations, offering a potential\nsolution to the data scarcity challenge in multimedia safety applications."}
{"id": "2505.14035", "pdf": "https://arxiv.org/pdf/2505.14035", "abs": "https://arxiv.org/abs/2505.14035", "authors": ["Shiyao Cui", "Qinglin Zhang", "Xuan Ouyang", "Renmiao Chen", "Zhexin Zhang", "Yida Lu", "Hongning Wang", "Han Qiu", "Minlie Huang"], "title": "ShieldVLM: Safeguarding the Multimodal Implicit Toxicity via Deliberative Reasoning with LVLMs", "categories": ["cs.MM", "cs.CL"], "comment": null, "summary": "Toxicity detection in multimodal text-image content faces growing challenges,\nespecially with multimodal implicit toxicity, where each modality appears\nbenign on its own but conveys hazard when combined. Multimodal implicit\ntoxicity appears not only as formal statements in social platforms but also\nprompts that can lead to toxic dialogs from Large Vision-Language Models\n(LVLMs). Despite the success in unimodal text or image moderation, toxicity\ndetection for multimodal content, particularly the multimodal implicit\ntoxicity, remains underexplored. To fill this gap, we comprehensively build a\ntaxonomy for multimodal implicit toxicity (MMIT) and introduce an MMIT-dataset,\ncomprising 2,100 multimodal statements and prompts across 7 risk categories (31\nsub-categories) and 5 typical cross-modal correlation modes. To advance the\ndetection of multimodal implicit toxicity, we build ShieldVLM, a model which\nidentifies implicit toxicity in multimodal statements, prompts and dialogs via\ndeliberative cross-modal reasoning. Experiments show that ShieldVLM outperforms\nexisting strong baselines in detecting both implicit and explicit toxicity. The\nmodel and dataset will be publicly available to support future researches.\nWarning: This paper contains potentially sensitive contents."}
{"id": "2505.13516", "pdf": "https://arxiv.org/pdf/2505.13516", "abs": "https://arxiv.org/abs/2505.13516", "authors": ["Zhipeng Hou", "Junyi Tang", "Yipeng Wang"], "title": "HALO: Hierarchical Autonomous Logic-Oriented Orchestration for Multi-Agent LLM Systems", "categories": ["cs.MA", "cs.AI"], "comment": "The code repository is available at https://github.com/23japhone/HALO", "summary": "Recent advancements in Multi-Agent Systems (MAS) powered by Large Language\nModels (LLMs) have demonstrated tremendous potential in diverse task scenarios.\nNonetheless, existing agentic systems typically rely on predefined agent-role\ndesign spaces and static communication structures, limiting their adaptability\nas well as flexibility in complex interaction environments and leading to\nsubpar performance on highly specialized and expert-level tasks. To address\nthese issues, we introduce HALO, a multi-agent collaboration framework based on\na hierarchical reasoning architecture. Specifically, we incorporate a\nhigh-level planning agent for task decomposition, mid-level role-design agents\nfor subtask-specific agent instantiation, and low-level inference agents for\nsubtask execution. Particularly, subtask execution is reformulated as a\nstructured workflow search problem, where Monte Carlo Tree Search (MCTS)\nsystematically explores the agentic action space to construct optimal reasoning\ntrajectories. Additionally, as the majority of users lack expertise in prompt\nengineering, we leverage an Adaptive Prompt Refinement module to transform raw\nqueries into task-specific prompts. Empirical evaluations on Code Generation\n(HumanEval), General Reasoning (MMLU), and Arithmetic Reasoning (MATH)\nbenchmark datasets highlight the effectiveness of HALO, yielding a 14.4%\naverage improvement over state-of-the-art baselines. Notably, HALO achieves up\nto 13.3% performance gain on the Moral Scenarios subject in the MMLU benchmark\nand up to 19.6% performance gain on the Algebra subarea in the MATH benchmark,\nindicating its advanced proficiency in tackling highly specialized and\nexpert-level tasks. The code repository is available at\nhttps://github.com/23japhone/HALO."}
{"id": "2505.13577", "pdf": "https://arxiv.org/pdf/2505.13577", "abs": "https://arxiv.org/abs/2505.13577", "authors": ["Yubin Kim", "Taehan Kim", "Wonjune Kang", "Eugene Park", "Joonsik Yoon", "Dongjae Lee", "Xin Liu", "Daniel McDuff", "Hyeonhoon Lee", "Cynthia Breazeal", "Hae Won Park"], "title": "VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Vocal health plays a crucial role in peoples' lives, significantly impacting\ntheir communicative abilities and interactions. However, despite the global\nprevalence of voice disorders, many lack access to convenient diagnosis and\ntreatment. This paper introduces VocalAgent, an audio large language model\n(LLM) to address these challenges through vocal health diagnosis. We leverage\nQwen-Audio-Chat fine-tuned on three datasets collected in-situ from hospital\npatients, and present a multifaceted evaluation framework encompassing a safety\nassessment to mitigate diagnostic biases, cross-lingual performance analysis,\nand modality ablation studies. VocalAgent demonstrates superior accuracy on\nvoice disorder classification compared to state-of-the-art baselines. Its\nLLM-based method offers a scalable solution for broader adoption of health\ndiagnostics, while underscoring the importance of ethical and technical\nvalidation."}
{"id": "2505.13455", "pdf": "https://arxiv.org/pdf/2505.13455", "abs": "https://arxiv.org/abs/2505.13455", "authors": ["Von Ralph Dane Marquez Herbuela", "Yukie Nagai"], "title": "Exploring Emotional Synchrony in Dyadic Interactions: The Role of Speech Conditions in Facial and Vocal Affective Alignment", "categories": ["eess.AS", "cs.AI"], "comment": null, "summary": "Understanding how humans express and synchronize emotions across multiple\ncommunication channels particularly facial expressions and speech has\nsignificant implications for emotion recognition systems and human computer\ninteraction. Motivated by the notion that non-overlapping speech promotes\nclearer emotional coordination, while overlapping speech disrupts synchrony,\nthis study examines how these conversational dynamics shape the spatial and\ntemporal alignment of arousal and valence across facial and vocal modalities.\nUsing dyadic interactions from the IEMOCAP dataset, we extracted continuous\nemotion estimates via EmoNet (facial video) and a Wav2Vec2-based model (speech\naudio). Segments were categorized based on speech overlap, and emotional\nalignment was assessed using Pearson correlation, lag adjusted analysis, and\nDynamic Time Warping (DTW). Across analyses, non overlapping speech was\nassociated with more stable and predictable emotional synchrony than\noverlapping speech. While zero-lag correlations were low and not statistically\ndifferent, non overlapping speech showed reduced variability, especially for\narousal. Lag adjusted correlations and best-lag distributions revealed clearer,\nmore consistent temporal alignment in these segments. In contrast, overlapping\nspeech exhibited higher variability and flatter lag profiles, though DTW\nindicated unexpectedly tighter alignment suggesting distinct coordination\nstrategies. Notably, directionality patterns showed that facial expressions\nmore often preceded speech during turn-taking, while speech led during\nsimultaneous vocalizations. These findings underscore the importance of\nconversational structure in regulating emotional communication and provide new\ninsight into the spatial and temporal dynamics of multimodal affective\nalignment in real world interaction."}
{"id": "2505.13542", "pdf": "https://arxiv.org/pdf/2505.13542", "abs": "https://arxiv.org/abs/2505.13542", "authors": ["Karthik Sivakoti"], "title": "GANCompress: GAN-Enhanced Neural Image Compression with Binary Spherical Quantization", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "The exponential growth of visual data in digital communications has\nintensified the need for efficient compression techniques that balance\nrate-distortion performance with computational feasibility. While recent neural\ncompression approaches have shown promise, they still struggle with fundamental\nchallenges: preserving perceptual quality at high compression ratios,\ncomputational efficiency, and adaptability to diverse visual content. This\npaper introduces GANCompress, a novel neural compression framework that\nsynergistically combines Binary Spherical Quantization (BSQ) with Generative\nAdversarial Networks (GANs) to address these challenges. Our approach employs a\ntransformer-based autoencoder with an enhanced BSQ bottleneck that projects\nlatent representations onto a hypersphere, enabling efficient discretization\nwith bounded quantization error. This is followed by a specialized GAN\narchitecture incorporating frequency-domain attention and color consistency\noptimization. Experimental results demonstrate that GANCompress achieves\nsubstantial improvement in compression efficiency -- reducing file sizes by up\nto 100x with minimal visual distortion. Our method outperforms traditional\ncodecs like H.264 by 12-15% in perceptual metrics while maintaining comparable\nPSNR/SSIM values, with 2.4x faster encoding and decoding speeds. On standard\nbenchmarks including ImageNet-1k and COCO2017, GANCompress sets a new\nstate-of-the-art, reducing FID from 0.72 to 0.41 (43% improvement) compared to\nprevious methods while maintaining higher throughput. This work presents a\nsignificant advancement in neural compression technology with promising\napplications for real-time visual communication systems."}
{"id": "2505.13491", "pdf": "https://arxiv.org/pdf/2505.13491", "abs": "https://arxiv.org/abs/2505.13491", "authors": ["Aakash Gupta", "Nataraj Das"], "title": "ProdRev: A DNN framework for empowering customers using generative pre-trained transformers", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "2022 International Conference on Decision Aid Sciences and\n  Applications (DASA)", "summary": "Following the pandemic, customers, preference for using e-commerce has\naccelerated. Since much information is available in multiple reviews (sometimes\nrunning in thousands) for a single product, it can create decision paralysis\nfor the buyer. This scenario disempowers the consumer, who cannot be expected\nto go over so many reviews since its time consuming and can confuse them.\nVarious commercial tools are available, that use a scoring mechanism to arrive\nat an adjusted score. It can alert the user to potential review manipulations.\nThis paper proposes a framework that fine-tunes a generative pre-trained\ntransformer to understand these reviews better. Furthermore, using\n\"common-sense\" to make better decisions. These models have more than 13 billion\nparameters. To fine-tune the model for our requirement, we use the curie engine\nfrom generative pre-trained transformer (GPT3). By using generative models, we\nare introducing abstractive summarization. Instead of using a simple extractive\nmethod of summarizing the reviews. This brings out the true relationship\nbetween the reviews and not simply copy-paste. This introduces an element of\n\"common sense\" for the user and helps them to quickly make the right decisions.\nThe user is provided the pros and cons of the processed reviews. Thus the\nuser/customer can take their own decisions."}
{"id": "2505.13584", "pdf": "https://arxiv.org/pdf/2505.13584", "abs": "https://arxiv.org/abs/2505.13584", "authors": ["Thangarajah Akilan", "Nusrat Jahan", "Wandong Zhang"], "title": "Self-Supervised Learning for Image Segmentation: A Comprehensive Survey", "categories": ["cs.CV"], "comment": "22 pages, 19 figures, to be submitted for a possible IEEE publication", "summary": "Supervised learning demands large amounts of precisely annotated data to\nachieve promising results. Such data curation is labor-intensive and imposes\nsignificant overhead regarding time and costs. Self-supervised learning (SSL)\npartially overcomes these limitations by exploiting vast amounts of unlabeled\ndata and creating surrogate (pretext or proxy) tasks to learn useful\nrepresentations without manual labeling. As a result, SSL has become a powerful\nmachine learning (ML) paradigm for solving several practical downstream\ncomputer vision problems, such as classification, detection, and segmentation.\nImage segmentation is the cornerstone of many high-level visual perception\napplications, including medical imaging, intelligent transportation,\nagriculture, and surveillance. Although there is substantial research potential\nfor developing advanced algorithms for SSL-based semantic segmentation, a\ncomprehensive study of existing methodologies is essential to trace advances\nand guide emerging researchers. This survey thoroughly investigates over 150\nrecent image segmentation articles, particularly focusing on SSL. It provides a\npractical categorization of pretext tasks, downstream tasks, and commonly used\nbenchmark datasets for image segmentation research. It concludes with key\nobservations distilled from a large body of literature and offers future\ndirections to make this research field more accessible and comprehensible for\nreaders."}
{"id": "2505.13461", "pdf": "https://arxiv.org/pdf/2505.13461", "abs": "https://arxiv.org/abs/2505.13461", "authors": ["Junye Jiang", "Yaan Zhou", "Yuanhao Gong", "Haoxuan Yuan", "Shuanglong Liu"], "title": "FPGA-based Acceleration for Convolutional Neural Networks: A Comprehensive Review", "categories": ["cs.LG", "cs.AR", "C.3"], "comment": "19 pages, 3 figures", "summary": "Convolutional Neural Networks (CNNs) are fundamental to deep learning,\ndriving applications across various domains. However, their growing complexity\nhas significantly increased computational demands, necessitating efficient\nhardware accelerators. Field-Programmable Gate Arrays (FPGAs) have emerged as a\nleading solution, offering reconfigurability, parallelism, and energy\nefficiency. This paper provides a comprehensive review of FPGA-based hardware\naccelerators specifically designed for CNNs. It presents and summarizes the\nperformance evaluation framework grounded in existing studies and explores key\noptimization strategies, such as parallel computing, dataflow optimization, and\nhardware-software co-design. It also compares various FPGA architectures in\nterms of latency, throughput, compute efficiency, power consumption, and\nresource utilization. Finally, the paper highlights future challenges and\nopportunities, emphasizing the potential for continued innovation in this\nfield."}
{"id": "2505.13484", "pdf": "https://arxiv.org/pdf/2505.13484", "abs": "https://arxiv.org/abs/2505.13484", "authors": ["Rene Heesch", "Sebastian Eilermann", "Alexander Windmann", "Alexander Diedrich", "Philipp Rosenthal", "Oliver Niggemann"], "title": "Evaluating Large Language Models for Real-World Engineering Tasks", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are transformative not only for daily activities\nbut also for engineering tasks. However, current evaluations of LLMs in\nengineering exhibit two critical shortcomings: (i) the reliance on simplified\nuse cases, often adapted from examination materials where correctness is easily\nverifiable, and (ii) the use of ad hoc scenarios that insufficiently capture\ncritical engineering competencies. Consequently, the assessment of LLMs on\ncomplex, real-world engineering problems remains largely unexplored. This paper\naddresses this gap by introducing a curated database comprising over 100\nquestions derived from authentic, production-oriented engineering scenarios,\nsystematically designed to cover core competencies such as product design,\nprognosis, and diagnosis. Using this dataset, we evaluate four state-of-the-art\nLLMs, including both cloud-based and locally hosted instances, to\nsystematically investigate their performance on complex engineering tasks. Our\nresults show that LLMs demonstrate strengths in basic temporal and structural\nreasoning but struggle significantly with abstract reasoning, formal modeling,\nand context-sensitive engineering logic."}
{"id": "2505.14329", "pdf": "https://arxiv.org/pdf/2505.14329", "abs": "https://arxiv.org/abs/2505.14329", "authors": ["Xiang Li", "Xianfu Cheng", "Dezhuang Miao", "Xiaoming Zhang", "Zhoujun Li"], "title": "TF-Mamba: Text-enhanced Fusion Mamba with Missing Modalities for Robust Multimodal Sentiment Analysis", "categories": ["cs.MM"], "comment": null, "summary": "Multimodal Sentiment Analysis (MSA) with missing modalities has attracted\nincreasing attention recently. While current Transformer-based methods leverage\ndense text information to maintain model robustness, their quadratic complexity\nhinders efficient long-range modeling and multimodal fusion. To this end, we\npropose a novel and efficient Text-enhanced Fusion Mamba (TF-Mamba) framework\nfor robust MSA with missing modalities. Specifically, a Text-aware Modality\nEnhancement (TME) module aligns and enriches non-text modalities, while\nreconstructing the missing text semantics. Moreover, we develop Text-based\nContext Mamba (TC-Mamba) to capture intra-modal contextual dependencies under\ntext collaboration. Finally, Text-guided Query Mamba (TQ-Mamba) queries\ntext-guided multimodal information and learns joint representations for\nsentiment prediction. Extensive experiments on three MSA datasets demonstrate\nthe effectiveness and efficiency of the proposed method under missing modality\nscenarios. Our code is available at https://github.com/codemous/TF-Mamba."}
{"id": "2505.13523", "pdf": "https://arxiv.org/pdf/2505.13523", "abs": "https://arxiv.org/abs/2505.13523", "authors": ["Jun Liu", "Ke Yu", "Keliang Chen", "Ke Li", "Yuxinyue Qian", "Xiaolian Guo", "Haozhe Song", "Yinming Li"], "title": "ACPs: Agent Collaboration Protocols for the Internet of Agents", "categories": ["cs.MA", "cs.AI"], "comment": "7 pages, 8 figures", "summary": "With the rapid advancement of artificial intelligence, the proliferation of\nautonomous agents has introduced new challenges in interoperability,\nscalability, and coordination. The Internet of Agents (IoA) aims to\ninterconnect heterogeneous agents through standardized communication protocols,\nenabling seamless collaboration and intelligent task execution. However,\nexisting agent communication protocols such as MCP, A2A, and ANP remain\nfragmented and scenario-specific. To address this gap, we propose Agent\nCollaboration Protocols (ACPs), a comprehensive protocol suite for the IoA.\nACPs include registration, discovery, interaction, and tooling protocols to\nsupport trustable access, capability orchestration, and workflow construction.\nWe present the architecture, key technologies, and application workflows of\nACPs, and demonstrate its effectiveness in a collaborative restaurant booking\nscenario. ACPs lay the foundation for building a secure, open, and scalable\nagent internet infrastructure."}
{"id": "2505.13771", "pdf": "https://arxiv.org/pdf/2505.13771", "abs": "https://arxiv.org/abs/2505.13771", "authors": ["Wanli Sun", "Anton Ragni"], "title": "Score-Based Training for Energy-Based TTS Models", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "Noise contrastive estimation (NCE) is a popular method for training\nenergy-based models (EBM) with intractable normalisation terms. The key idea of\nNCE is to learn by comparing unnormalised log-likelihoods of the reference and\nnoisy samples, thus avoiding explicitly computing normalisation terms. However,\nNCE critically relies on the quality of noisy samples. Recently, sliced score\nmatching (SSM) has been popularised by closely related diffusion models (DM).\nUnlike NCE, SSM learns a gradient of log-likelihood, or score, by learning\ndistribution of its projections on randomly chosen directions. However, both\nNCE and SSM disregard the form of log-likelihood function, which is problematic\ngiven that EBMs and DMs make use of first-order optimisation during inference.\nThis paper proposes a new criterion that learns scores more suitable for\nfirst-order schemes. Experiments contrasts these approaches for training EBMs."}
{"id": "2505.13541", "pdf": "https://arxiv.org/pdf/2505.13541", "abs": "https://arxiv.org/abs/2505.13541", "authors": ["Amirbek Djanibekov", "Nurdaulet Mukhituly", "Kentaro Inui", "Hanan Aldarmaki", "Nils Lukas"], "title": "SPIRIT: Patching Speech Language Models against Jailbreak Attacks", "categories": ["eess.AS", "cs.LG"], "comment": null, "summary": "Speech Language Models (SLMs) enable natural interactions via spoken\ninstructions, which more effectively capture user intent by detecting nuances\nin speech. The richer speech signal introduces new security risks compared to\ntext-based models, as adversaries can better bypass safety mechanisms by\ninjecting imperceptible noise to speech. We analyze adversarial attacks and\nfind that SLMs are substantially more vulnerable to jailbreak attacks, which\ncan achieve a perfect 100% attack success rate in some instances. To improve\nsecurity, we propose post-hoc patching defenses used to intervene during\ninference by modifying the SLM's activations that improve robustness up to 99%\nwith (i) negligible impact on utility and (ii) without any re-training. We\nconduct ablation studies to maximize the efficacy of our defenses and improve\nthe utility/security trade-off, validated with large-scale benchmarks unique to\nSLMs."}
{"id": "2505.13579", "pdf": "https://arxiv.org/pdf/2505.13579", "abs": "https://arxiv.org/abs/2505.13579", "authors": ["Yipeng Sun", "Linda-Sophie Schneider", "Chengze Ye", "Mingxuan Gu", "Siyuan Mei", "Siming Bayer", "Andreas Maier"], "title": "Learning Wavelet-Sparse FDK for 3D Cone-Beam CT Reconstruction", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted by Fully3D 2025", "summary": "Cone-Beam Computed Tomography (CBCT) is essential in medical imaging, and the\nFeldkamp-Davis-Kress (FDK) algorithm is a popular choice for reconstruction due\nto its efficiency. However, FDK is susceptible to noise and artifacts. While\nrecent deep learning methods offer improved image quality, they often increase\ncomputational complexity and lack the interpretability of traditional methods.\nIn this paper, we introduce an enhanced FDK-based neural network that maintains\nthe classical algorithm's interpretability by selectively integrating trainable\nelements into the cosine weighting and filtering stages. Recognizing the\nchallenge of a large parameter space inherent in 3D CBCT data, we leverage\nwavelet transformations to create sparse representations of the cosine weights\nand filters. This strategic sparsification reduces the parameter count by\n$93.75\\%$ without compromising performance, accelerates convergence, and\nimportantly, maintains the inference computational cost equivalent to the\nclassical FDK algorithm. Our method not only ensures volumetric consistency and\nboosts robustness to noise, but is also designed for straightforward\nintegration into existing CT reconstruction pipelines. This presents a\npragmatic enhancement that can benefit clinical applications, particularly in\nenvironments with computational limitations."}
{"id": "2505.13492", "pdf": "https://arxiv.org/pdf/2505.13492", "abs": "https://arxiv.org/abs/2505.13492", "authors": ["Weiming Zhang", "Lingyue Fu", "Qingyao Li", "Kounianhua Du", "Jianghao Lin", "Jingwei Yu", "Wei Xia", "Weinan Zhang", "Ruiming Tang", "Yong Yu"], "title": "LLM4CD: Leveraging Large Language Models for Open-World Knowledge Augmented Cognitive Diagnosis", "categories": ["cs.CL"], "comment": null, "summary": "Cognitive diagnosis (CD) plays a crucial role in intelligent education,\nevaluating students' comprehension of knowledge concepts based on their test\nhistories. However, current CD methods often model students, exercises, and\nknowledge concepts solely on their ID relationships, neglecting the abundant\nsemantic relationships present within educational data space. Furthermore,\ncontemporary intelligent tutoring systems (ITS) frequently involve the addition\nof new students and exercises, a situation that ID-based methods find\nchallenging to manage effectively. The advent of large language models (LLMs)\noffers the potential for overcoming this challenge with open-world knowledge.\nIn this paper, we propose LLM4CD, which Leverages Large Language Models for\nOpen-World Knowledge Augmented Cognitive Diagnosis. Our method utilizes the\nopen-world knowledge of LLMs to construct cognitively expressive textual\nrepresentations, which are then encoded to introduce rich semantic information\ninto the CD task. Additionally, we propose an innovative bi-level encoder\nframework that models students' test histories through two levels of encoders:\na macro-level cognitive text encoder and a micro-level knowledge state encoder.\nThis approach substitutes traditional ID embeddings with semantic\nrepresentations, enabling the model to accommodate new students and exercises\nwith open-world knowledge and address the cold-start problem. Extensive\nexperimental results demonstrate that our proposed method consistently\noutperforms previous CD models on multiple real-world datasets, validating the\neffectiveness of leveraging LLMs to introduce rich semantic information into\nthe CD task."}
{"id": "2505.13633", "pdf": "https://arxiv.org/pdf/2505.13633", "abs": "https://arxiv.org/abs/2505.13633", "authors": ["Wentao Song", "He Huang", "Youqiang Sun", "Fang Qu", "Jiaqi Zhang", "Longhui Fang", "Yuwei Hao", "Chenyang Peng"], "title": "IPENS:Interactive Unsupervised Framework for Rapid Plant Phenotyping Extraction via NeRF-SAM2 Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Advanced plant phenotyping technologies play a crucial role in targeted trait\nimprovement and accelerating intelligent breeding. Due to the species diversity\nof plants, existing methods heavily rely on large-scale high-precision manually\nannotated data. For self-occluded objects at the grain level, unsupervised\nmethods often prove ineffective. This study proposes IPENS, an interactive\nunsupervised multi-target point cloud extraction method. The method utilizes\nradiance field information to lift 2D masks, which are segmented by SAM2\n(Segment Anything Model 2), into 3D space for target point cloud extraction. A\nmulti-target collaborative optimization strategy is designed to effectively\nresolve the single-interaction multi-target segmentation challenge.\nExperimental validation demonstrates that IPENS achieves a grain-level\nsegmentation accuracy (mIoU) of 63.72% on a rice dataset, with strong\nphenotypic estimation capabilities: grain volume prediction yields R2 = 0.7697\n(RMSE = 0.0025), leaf surface area R2 = 0.84 (RMSE = 18.93), and leaf length\nand width predictions achieve R2 = 0.97 and 0.87 (RMSE = 1.49 and 0.21). On a\nwheat dataset,IPENS further improves segmentation accuracy to 89.68% (mIoU),\nwith equally outstanding phenotypic estimation performance: spike volume\nprediction achieves R2 = 0.9956 (RMSE = 0.0055), leaf surface area R2 = 1.00\n(RMSE = 0.67), and leaf length and width predictions reach R2 = 0.99 and 0.92\n(RMSE = 0.23 and 0.15). This method provides a non-invasive, high-quality\nphenotyping extraction solution for rice and wheat. Without requiring annotated\ndata, it rapidly extracts grain-level point clouds within 3 minutes through\nsimple single-round interactions on images for multiple targets, demonstrating\nsignificant potential to accelerate intelligent breeding efficiency."}
{"id": "2505.13462", "pdf": "https://arxiv.org/pdf/2505.13462", "abs": "https://arxiv.org/abs/2505.13462", "authors": ["Thien Nguyen", "William Guicquero"], "title": "End-to-end fully-binarized network design: from Generic Learned Thermometer to Block Pruning", "categories": ["cs.LG", "cs.AR", "cs.CV", "eess.IV", "stat.ML"], "comment": "Accepted to IEEE AICAS 2025", "summary": "Existing works on Binary Neural Network (BNN) mainly focus on model's weights\nand activations while discarding considerations on the input raw data. This\narticle introduces Generic Learned Thermometer (GLT), an encoding technique to\nimprove input data representation for BNN, relying on learning non linear\nquantization thresholds. This technique consists in multiple data binarizations\nwhich can advantageously replace a conventional Analog to Digital Conversion\n(ADC) that uses natural binary coding. Additionally, we jointly propose a\ncompact topology with light-weight grouped convolutions being trained thanks to\nblock pruning and Knowledge Distillation (KD), aiming at reducing furthermore\nthe model size so as its computational complexity. We show that GLT brings\nversatility to the BNN by intrinsically performing global tone mapping,\nenabling significant accuracy gains in practice (demonstrated by simulations on\nthe STL-10 and VWW datasets). Moreover, when combining GLT with our proposed\nblock-pruning technique, we successfully achieve lightweight (under 1Mb),\nfully-binarized models with limited accuracy degradation while being suitable\nfor in-sensor always-on inference use cases."}
{"id": "2505.13489", "pdf": "https://arxiv.org/pdf/2505.13489", "abs": "https://arxiv.org/abs/2505.13489", "authors": ["Wenkang Han", "Wang Lin", "Liya Hu", "Zhenlong Dai", "Yiyun Zhou", "Mengze Li", "Zemin Liu", "Chang Yao", "Jingyuan Chen"], "title": "Contrastive Cross-Course Knowledge Tracing via Concept Graph Guided Knowledge Transfer", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted by IJCAI 2025", "summary": "Knowledge tracing (KT) aims to predict learners' future performance based on\nhistorical learning interactions. However, existing KT models predominantly\nfocus on data from a single course, limiting their ability to capture a\ncomprehensive understanding of learners' knowledge states. In this paper, we\npropose TransKT, a contrastive cross-course knowledge tracing method that\nleverages concept graph guided knowledge transfer to model the relationships\nbetween learning behaviors across different courses, thereby enhancing\nknowledge state estimation. Specifically, TransKT constructs a cross-course\nconcept graph by leveraging zero-shot Large Language Model (LLM) prompts to\nestablish implicit links between related concepts across different courses.\nThis graph serves as the foundation for knowledge transfer, enabling the model\nto integrate and enhance the semantic features of learners' interactions across\ncourses. Furthermore, TransKT includes an LLM-to-LM pipeline for incorporating\nsummarized semantic features, which significantly improves the performance of\nGraph Convolutional Networks (GCNs) used for knowledge transfer. Additionally,\nTransKT employs a contrastive objective that aligns single-course and\ncross-course knowledge states, thereby refining the model's ability to provide\na more robust and accurate representation of learners' overall knowledge\nstates."}
{"id": "2505.13948", "pdf": "https://arxiv.org/pdf/2505.13948", "abs": "https://arxiv.org/abs/2505.13948", "authors": ["Mingliang Zhai", "Zhi Gao", "Yuwei Wu", "Yunde Jia"], "title": "Memory-Centric Embodied Question Answer", "categories": ["cs.CL", "cs.AI", "cs.MM"], "comment": "14pages, 7 figures, 6 tables", "summary": "Embodied Question Answering (EQA) requires agents to autonomously explore and\nunderstand the environment to answer context-dependent questions. Existing\nframeworks typically center around the planner, which guides the stopping\nmodule, memory module, and answering module for reasoning. In this paper, we\npropose a memory-centric EQA framework named MemoryEQA. Unlike planner-centric\nEQA models where the memory module cannot fully interact with other modules,\nMemoryEQA flexible feeds memory information into all modules, thereby enhancing\nefficiency and accuracy in handling complex tasks, such as those involving\nmultiple targets across different regions. Specifically, we establish a\nmulti-modal hierarchical memory mechanism, which is divided into global memory\nthat stores language-enhanced scene maps, and local memory that retains\nhistorical observations and state information. When performing EQA tasks, the\nmulti-modal large language model is leveraged to convert memory information\ninto the required input formats for injection into different modules. To\nevaluate EQA models' memory capabilities, we constructed the MT-HM3D dataset\nbased on HM3D, comprising 1,587 question-answer pairs involving multiple\ntargets across various regions, which requires agents to maintain memory of\nexploration-acquired target information. Experimental results on HM-EQA,\nMT-HM3D, and OpenEQA demonstrate the effectiveness of our framework, where a\n19.8% performance gain on MT-HM3D compared to baseline model further\nunderscores memory capability's pivotal role in resolving complex tasks."}
{"id": "2505.13543", "pdf": "https://arxiv.org/pdf/2505.13543", "abs": "https://arxiv.org/abs/2505.13543", "authors": ["Muyang Fan", "Songyang Liu", "Weizi Li"], "title": "Origin-Destination Pattern Effects on Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.CY"], "comment": null, "summary": "Traffic congestion remains a major challenge for modern urban transportation,\ndiminishing both efficiency and quality of life. While autonomous driving\ntechnologies and reinforcement learning (RL) have shown promise for improving\ntraffic control, most prior work has focused on small-scale networks or\nisolated intersections. Large-scale mixed traffic control, involving both\nhuman-driven and robotic vehicles, remains underexplored. In this study, we\npropose a decentralized multi-agent reinforcement learning framework for\nmanaging large-scale mixed traffic networks, where intersections are controlled\neither by traditional traffic signals or by robotic vehicles. We evaluate our\napproach on a real-world network of 14 intersections in Colorado Springs,\nColorado, USA, using average vehicle waiting time as the primary measure of\ntraffic efficiency. Results demonstrate that strategically adjusting major\norigin-destination (OD) flow patterns can effectively reduce congestion,\noffering a new pathway for enhancing urban mobility."}
{"id": "2505.13805", "pdf": "https://arxiv.org/pdf/2505.13805", "abs": "https://arxiv.org/abs/2505.13805", "authors": ["Yu Pan", "Yanni Hu", "Yuguang Yang", "Jixun Yao", "Jianhao Ye", "Hongbin Zhou", "Lei Ma", "Jianjun Zhao"], "title": "ClapFM-EVC: High-Fidelity and Flexible Emotional Voice Conversion with Dual Control from Natural Language and Speech", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted by InterSpeech 2025", "summary": "Despite great advances, achieving high-fidelity emotional voice conversion\n(EVC) with flexible and interpretable control remains challenging. This paper\nintroduces ClapFM-EVC, a novel EVC framework capable of generating high-quality\nconverted speech driven by natural language prompts or reference speech with\nadjustable emotion intensity. We first propose EVC-CLAP, an emotional\ncontrastive language-audio pre-training model, guided by natural language\nprompts and categorical labels, to extract and align fine-grained emotional\nelements across speech and text modalities. Then, a FuEncoder with an adaptive\nintensity gate is presented to seamless fuse emotional features with Phonetic\nPosteriorGrams from a pre-trained ASR model. To further improve emotion\nexpressiveness and speech naturalness, we propose a flow matching model\nconditioned on these captured features to reconstruct Mel-spectrogram of source\nspeech. Subjective and objective evaluations validate the effectiveness of\nClapFM-EVC."}
{"id": "2505.13617", "pdf": "https://arxiv.org/pdf/2505.13617", "abs": "https://arxiv.org/abs/2505.13617", "authors": ["Christopher Ick", "Gordon Wichern", "Yoshiki Masuyama", "Fran√ßois Germain", "Jonathan Le Roux"], "title": "Direction-Aware Neural Acoustic Fields for Few-Shot Interpolation of Ambisonic Impulse Responses", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.LG", "cs.SD"], "comment": "Accepted at Interspeech 2025", "summary": "The characteristics of a sound field are intrinsically linked to the\ngeometric and spatial properties of the environment surrounding a sound source\nand a listener. The physics of sound propagation is captured in a time-domain\nsignal known as a room impulse response (RIR). Prior work using neural fields\n(NFs) has allowed learning spatially-continuous representations of RIRs from\nfinite RIR measurements. However, previous NF-based methods have focused on\nmonaural omnidirectional or at most binaural listeners, which does not\nprecisely capture the directional characteristics of a real sound field at a\nsingle point. We propose a direction-aware neural field (DANF) that more\nexplicitly incorporates the directional information by Ambisonic-format RIRs.\nWhile DANF inherently captures spatial relations between sources and listeners,\nwe further propose a direction-aware loss. In addition, we investigate the\nability of DANF to adapt to new rooms in various ways including low-rank\nadaptation."}
{"id": "2505.13841", "pdf": "https://arxiv.org/pdf/2505.13841", "abs": "https://arxiv.org/abs/2505.13841", "authors": ["Yixuan Gao", "Xiongkuo Min", "Guangtao Zhai"], "title": "Exploring Image Quality Assessment from a New Perspective: Pupil Size", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "This paper explores how the image quality assessment (IQA) task affects the\ncognitive processes of people from the perspective of pupil size and studies\nthe relationship between pupil size and image quality. Specifically, we first\ninvited subjects to participate in a subjective experiment, which includes two\ntasks: free observation and IQA. In the free observation task, subjects did not\nneed to perform any action, and they only needed to observe images as they\nusually do with an album. In the IQA task, subjects were required to score\nimages according to their overall impression of image quality. Then, by\nanalyzing the difference in pupil size between the two tasks, we find that\npeople may activate the visual attention mechanism when evaluating image\nquality. Meanwhile, we also find that the change in pupil size is closely\nrelated to image quality in the IQA task. For future research on IQA, this\nresearch can not only provide a theoretical basis for the objective IQA method\nand promote the development of more effective objective IQA methods, but also\nprovide a new subjective IQA method for collecting the authentic subjective\nimpression of image quality."}
{"id": "2505.13498", "pdf": "https://arxiv.org/pdf/2505.13498", "abs": "https://arxiv.org/abs/2505.13498", "authors": ["Khanh-Tung Tran", "Barry O'Sullivan", "Hoang D. Nguyen"], "title": "IRLBench: A Multi-modal, Culturally Grounded, Parallel Irish-English Benchmark for Open-Ended LLM Reasoning Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have demonstrated promising\nknowledge and reasoning abilities, yet their performance in multilingual and\nlow-resource settings remains underexplored. Existing benchmarks often exhibit\ncultural bias, restrict evaluation to text-only, rely on multiple-choice\nformats, and, more importantly, are limited for extremely low-resource\nlanguages. To address these gaps, we introduce IRLBench, presented in parallel\nEnglish and Irish, which is considered definitely endangered by UNESCO. Our\nbenchmark consists of 12 representative subjects developed from the 2024 Irish\nLeaving Certificate exams, enabling fine-grained analysis of model capabilities\nacross domains. By framing the task as long-form generation and leveraging the\nofficial marking scheme, it does not only support a comprehensive evaluation of\ncorrectness but also language fidelity. Our extensive experiments of leading\nclosed-source and open-source LLMs reveal a persistent performance gap between\nEnglish and Irish, in which models produce valid Irish responses less than 80\\%\nof the time, and answer correctly 55.8\\% of the time compared to 76.2\\% in\nEnglish for the best-performing model. We release IRLBench\n(https://huggingface.co/datasets/ReliableAI/IRLBench) and an accompanying\nevaluation codebase (https://github.com/ReML-AI/IRLBench) to enable future\nresearch on robust, culturally aware multilingual AI development."}
{"id": "2505.13669", "pdf": "https://arxiv.org/pdf/2505.13669", "abs": "https://arxiv.org/abs/2505.13669", "authors": ["Barkin Dagda", "Muhammad Awais", "Saber Fallah"], "title": "GeoVLM: Improving Automated Vehicle Geolocalisation Using Vision-Language Matching", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Cross-view geo-localisation identifies coarse geographical position of an\nautomated vehicle by matching a ground-level image to a geo-tagged satellite\nimage from a database. Despite the advancements in Cross-view geo-localisation,\nsignificant challenges still persist such as similar looking scenes which makes\nit challenging to find the correct match as the top match. Existing approaches\nreach high recall rates but they still fail to rank the correct image as the\ntop match. To address this challenge, this paper proposes GeoVLM, a novel\napproach which uses the zero-shot capabilities of vision language models to\nenable cross-view geo-localisation using interpretable cross-view language\ndescriptions. GeoVLM is a trainable reranking approach which improves the best\nmatch accuracy of cross-view geo-localisation. GeoVLM is evaluated on standard\nbenchmark VIGOR and University-1652 and also through real-life driving\nenvironments using Cross-View United Kingdom, a new benchmark dataset\nintroduced in this paper. The results of the paper show that GeoVLM improves\nretrieval performance of cross-view geo-localisation compared to the\nstate-of-the-art methods with the help of explainable natural language\ndescriptions. The code is available at\nhttps://github.com/CAV-Research-Lab/GeoVLM"}
{"id": "2505.13463", "pdf": "https://arxiv.org/pdf/2505.13463", "abs": "https://arxiv.org/abs/2505.13463", "authors": ["Paolo Guida", "William L. Roberts"], "title": "Predicting The Evolution of Interfaces with Fourier Neural Operators", "categories": ["cs.LG", "physics.comp-ph", "physics.flu-dyn"], "comment": null, "summary": "Recent progress in AI has established neural operators as powerful tools that\ncan predict the evolution of partial differential equations, such as the\nNavier-Stokes equations. Some complex problems rely on sophisticated algorithms\nto deal with strong discontinuities in the computational domain. For example,\nliquid-vapour multiphase flows are a challenging problem in many\nconfigurations, particularly those involving large density gradients or phase\nchange. The complexity mentioned above has not allowed for fine control of fast\nindustrial processes or applications because computational fluid dynamics (CFD)\nmodels do not have a quick enough forecasting ability. This work demonstrates\nthat the time scale of neural operators-based predictions is comparable to the\ntime scale of multi-phase applications, thus proving they can be used to\ncontrol processes that require fast response. Neural Operators can be trained\nusing experimental data, simulations or a combination. In the following, neural\noperators were trained in volume of fluid simulations, and the resulting\npredictions showed very high accuracy, particularly in predicting the evolution\nof the liquid-vapour interface, one of the most critical tasks in a multi-phase\nprocess controller."}
{"id": "2505.13496", "pdf": "https://arxiv.org/pdf/2505.13496", "abs": "https://arxiv.org/abs/2505.13496", "authors": ["Przemek Pospieszny", "Wojciech Mormul", "Karolina Szyndler", "Sanjeev Kumar"], "title": "ADALog: Adaptive Unsupervised Anomaly detection in Logs with Self-attention Masked Language Model", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.6; I.2.7; I.5.1; C.2.4"], "comment": "Conference paper accepted at ICMLT 2025; to appear in the IEEE\n  Conference Proceedings", "summary": "Modern software systems generate extensive heterogeneous log data with\ndynamic formats, fragmented event sequences, and varying temporal patterns,\nmaking anomaly detection both crucial and challenging. To address these\ncomplexities, we propose ADALog, an adaptive, unsupervised anomaly detection\nframework designed for practical applicability across diverse real-world\nenvironments. Unlike traditional methods reliant on log parsing, strict\nsequence dependencies, or labeled data, ADALog operates on individual\nunstructured logs, extracts intra-log contextual relationships, and performs\nadaptive thresholding on normal data. The proposed approach utilizes a\ntransformer-based, pretrained bidirectional encoder with a masked language\nmodeling task, fine-tuned on normal logs to capture domain-specific syntactic\nand semantic patterns essential for accurate anomaly detection. Anomalies are\nidentified via token-level reconstruction probabilities, aggregated into\nlog-level scores, with adaptive percentile-based thresholding calibrated only\non normal data. This allows the model to dynamically adapt to evolving system\nbehaviors while avoiding rigid, heuristic-based thresholds common in\ntraditional systems. We evaluate ADALog on benchmark datasets BGL, Thunderbird,\nand Spirit, showing strong generalization and competitive performance compared\nto state-of-the-art supervised and unsupervised methods. Additional ablation\nstudies examine the effects of masking, fine-tuning, and token positioning on\nmodel behavior and interpretability."}
{"id": "2505.14151", "pdf": "https://arxiv.org/pdf/2505.14151", "abs": "https://arxiv.org/abs/2505.14151", "authors": ["Jiaming Li", "Sheng Wang", "Xin Wang", "Yitao Zhu", "Honglin Xiong", "Zixu Zhuang", "Qian Wang"], "title": "ReactDiff: Latent Diffusion for Facial Reaction Generation", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Given the audio-visual clip of the speaker, facial reaction generation aims\nto predict the listener's facial reactions. The challenge lies in capturing the\nrelevance between video and audio while balancing appropriateness, realism, and\ndiversity. While prior works have mostly focused on uni-modal inputs or\nsimplified reaction mappings, recent approaches such as PerFRDiff have explored\nmulti-modal inputs and the one-to-many nature of appropriate reaction mappings.\nIn this work, we propose the Facial Reaction Diffusion (ReactDiff) framework\nthat uniquely integrates a Multi-Modality Transformer with conditional\ndiffusion in the latent space for enhanced reaction generation. Unlike existing\nmethods, ReactDiff leverages intra- and inter-class attention for fine-grained\nmulti-modal interaction, while the latent diffusion process between the encoder\nand decoder enables diverse yet contextually appropriate outputs. Experimental\nresults demonstrate that ReactDiff significantly outperforms existing\napproaches, achieving a facial reaction correlation of 0.26 and diversity score\nof 0.094 while maintaining competitive realism. The code is open-sourced at\n\\href{https://github.com/Hunan-Tiger/ReactDiff}{github}."}
{"id": "2505.13941", "pdf": "https://arxiv.org/pdf/2505.13941", "abs": "https://arxiv.org/abs/2505.13941", "authors": ["Haoyang Fang", "Boran Han", "Nick Erickson", "Xiyuan Zhang", "Su Zhou", "Anirudh Dagar", "Jiani Zhang", "Ali Caner Turkmen", "Cuixiong Hu", "Huzefa Rangwala", "Ying Nian Wu", "Bernie Wang", "George Karypis"], "title": "MLZero: A Multi-Agent System for End-to-end Machine Learning Automation", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Existing AutoML systems have advanced the automation of machine learning\n(ML); however, they still require substantial manual configuration and expert\ninput, particularly when handling multimodal data. We introduce MLZero, a novel\nmulti-agent framework powered by Large Language Models (LLMs) that enables\nend-to-end ML automation across diverse data modalities with minimal human\nintervention. A cognitive perception module is first employed, transforming raw\nmultimodal inputs into perceptual context that effectively guides the\nsubsequent workflow. To address key limitations of LLMs, such as hallucinated\ncode generation and outdated API knowledge, we enhance the iterative code\ngeneration process with semantic and episodic memory. MLZero demonstrates\nsuperior performance on MLE-Bench Lite, outperforming all competitors in both\nsuccess rate and solution quality, securing six gold medals. Additionally, when\nevaluated on our Multimodal AutoML Agent Benchmark, which includes 25 more\nchallenging tasks spanning diverse data modalities, MLZero outperforms the\ncompeting methods by a large margin with a success rate of 0.92 (+263.6\\%) and\nan average rank of 2.28. Our approach maintains its robust effectiveness even\nwith a compact 8B LLM, outperforming full-size systems from existing solutions."}
{"id": "2505.13847", "pdf": "https://arxiv.org/pdf/2505.13847", "abs": "https://arxiv.org/abs/2505.13847", "authors": ["Tianle Yang", "Chengzhe Sun", "Siwei Lyu", "Phil Rose"], "title": "Forensic deepfake audio detection using segmental speech features", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": null, "summary": "This study explores the potential of using acoustic features of segmental\nspeech sounds to detect deepfake audio. These features are highly interpretable\nbecause of their close relationship with human articulatory processes and are\nexpected to be more difficult for deepfake models to replicate. The results\ndemonstrate that certain segmental features commonly used in forensic voice\ncomparison are effective in identifying deep-fakes, whereas some global\nfeatures provide little value. These findings underscore the need to approach\naudio deepfake detection differently for forensic voice comparison and offer a\nnew perspective on leveraging segmental features for this purpose."}
{"id": "2505.13814", "pdf": "https://arxiv.org/pdf/2505.13814", "abs": "https://arxiv.org/abs/2505.13814", "authors": ["Jihwan Lee", "Kevin Huang", "Kleanthis Avramidis", "Simon Pistrosch", "Monica Gonzalez-Machorro", "Yoonjeong Lee", "Bj√∂rn Schuller", "Louis Goldstein", "Shrikanth Narayanan"], "title": "Articulatory Feature Prediction from Surface EMG during Speech Production", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "Accepted for Interspeech2025", "summary": "We present a model for predicting articulatory features from surface\nelectromyography (EMG) signals during speech production. The proposed model\nintegrates convolutional layers and a Transformer block, followed by separate\npredictors for articulatory features. Our approach achieves a high prediction\ncorrelation of approximately 0.9 for most articulatory features. Furthermore,\nwe demonstrate that these predicted articulatory features can be decoded into\nintelligible speech waveforms. To our knowledge, this is the first method to\ndecode speech waveforms from surface EMG via articulatory features, offering a\nnovel approach to EMG-based speech synthesis. Additionally, we analyze the\nrelationship between EMG electrode placement and articulatory feature\npredictability, providing knowledge-driven insights for optimizing EMG\nelectrode configurations. The source code and decoded speech samples are\npublicly available."}
{"id": "2505.13875", "pdf": "https://arxiv.org/pdf/2505.13875", "abs": "https://arxiv.org/abs/2505.13875", "authors": ["Lanlan Kang", "Jian Wang", "Jian QIn", "Yiqin Liang", "Yongjun He"], "title": "Automated Quality Evaluation of Cervical Cytopathology Whole Slide Images Based on Content Analysis", "categories": ["eess.IV", "cs.CV"], "comment": "12 pages, 10 figures", "summary": "The ThinPrep Cytologic Test (TCT) is the most widely used method for cervical\ncancer screening, and the sample quality directly impacts the accuracy of the\ndiagnosis. Traditional manual evaluation methods rely on the observation of\npathologist under microscopes. These methods exhibit high subjectivity, high\ncost, long duration, and low reliability. With the development of\ncomputer-aided diagnosis (CAD), an automated quality assessment system that\nperforms at the level of a professional pathologist is necessary. To address\nthis need, we propose a fully automated quality assessment method for Cervical\nCytopathology Whole Slide Images (WSIs) based on The Bethesda System (TBS)\ndiagnostic standards, artificial intelligence algorithms, and the\ncharacteristics of clinical data. The method analysis the context of WSIs to\nquantify quality evaluation metrics which are focused by TBS such as staining\nquality, cell counts and cell mass proportion through multiple models including\nobject detection, classification and segmentation. Subsequently, the XGBoost\nmodel is used to mine the attention paid by pathologists to different quality\nevaluation metrics when evaluating samples, thereby obtaining a comprehensive\nWSI sample score calculation model. Experimental results on 100 WSIs\ndemonstrate that the proposed evaluation method has significant advantages in\nterms of speed and consistency."}
{"id": "2505.13500", "pdf": "https://arxiv.org/pdf/2505.13500", "abs": "https://arxiv.org/abs/2505.13500", "authors": ["Prithviraj Singh Shahani", "Matthias Scheutz"], "title": "Noise Injection Systemically Degrades Large Language Model Safety Guardrails", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "9 pages,3 figures", "summary": "Safety guardrails in large language models (LLMs) are a critical component in\npreventing harmful outputs. Yet, their resilience under perturbation remains\npoorly understood. In this paper, we investigate the robustness of safety\nfine-tuning in LLMs by systematically injecting Gaussian noise into model\nactivations. We show across multiple open-weight models that (1) Gaussian noise\nraises harmful-output rates (p < 0.001) by up to 27%, (2) that deeper safety\nfine-tuning affords no extra protection, and (3) that chain-of-thought\nreasoning remains largely intact. The findings reveal critical vulnerabilities\nin current safety alignment techniques and highlight the potential of\nreasoning-based and reinforcement learning approaches as promising direction\nfor developing more robust AI safety systems. These results have important\nimplications for real-world deployment of LLMs in safety-critical applications\nas these results imply that widely-deployed safety tuning methods can fail even\nwithout adversarial prompts."}
{"id": "2505.13731", "pdf": "https://arxiv.org/pdf/2505.13731", "abs": "https://arxiv.org/abs/2505.13731", "authors": ["Pengyue Jia", "Seongheon Park", "Song Gao", "Xiangyu Zhao", "Yixuan Li"], "title": "GeoRanker: Distance-Aware Ranking for Worldwide Image Geolocalization", "categories": ["cs.CV"], "comment": null, "summary": "Worldwide image geolocalization-the task of predicting GPS coordinates from\nimages taken anywhere on Earth-poses a fundamental challenge due to the vast\ndiversity in visual content across regions. While recent approaches adopt a\ntwo-stage pipeline of retrieving candidates and selecting the best match, they\ntypically rely on simplistic similarity heuristics and point-wise supervision,\nfailing to model spatial relationships among candidates. In this paper, we\npropose GeoRanker, a distance-aware ranking framework that leverages large\nvision-language models to jointly encode query-candidate interactions and\npredict geographic proximity. In addition, we introduce a multi-order distance\nloss that ranks both absolute and relative distances, enabling the model to\nreason over structured spatial relationships. To support this, we curate\nGeoRanking, the first dataset explicitly designed for geographic ranking tasks\nwith multimodal candidate information. GeoRanker achieves state-of-the-art\nresults on two well-established benchmarks (IM2GPS3K and YFCC4K), significantly\noutperforming current best methods."}
{"id": "2505.13471", "pdf": "https://arxiv.org/pdf/2505.13471", "abs": "https://arxiv.org/abs/2505.13471", "authors": ["George Bird"], "title": "The Spotlight Resonance Method: Resolving the Alignment of Embedded Activations", "categories": ["cs.LG", "I.2.6; I.5.1"], "comment": "25 pages, 13 figures, 2nd Workshop on Representational Alignment,\n  International Conference on Learning Representations (ICLR)", "summary": "Understanding how deep learning models represent data is currently difficult\ndue to the limited number of methodologies available. This paper demonstrates a\nversatile and novel visualisation tool for determining the axis alignment of\nembedded data at any layer in any deep learning model. In particular, it\nevaluates the distribution around planes defined by the network's privileged\nbasis vectors. This method provides both an atomistic and a holistic, intuitive\nmetric for interpreting the distribution of activations across all planes. It\nensures that both positive and negative signals contribute, treating the\nactivation vector as a whole. Depending on the application, several variations\nof this technique are presented, with a resolution scale hyperparameter to\nprobe different angular scales. Using this method, multiple examples are\nprovided that demonstrate embedded representations tend to be axis-aligned with\nthe privileged basis. This is not necessarily the standard basis, and it is\nfound that activation functions directly result in privileged bases. Hence, it\nprovides a direct causal link between functional form symmetry breaking and\nrepresentational alignment, explaining why representations have a tendency to\nalign with the neuron basis. Therefore, using this method, we begin to answer\nthe fundamental question of what causes the observed tendency of\nrepresentations to align with neurons. Finally, examples of so-called\ngrandmother neurons are found in a variety of networks."}
{"id": "2505.13511", "pdf": "https://arxiv.org/pdf/2505.13511", "abs": "https://arxiv.org/abs/2505.13511", "authors": ["David Noever", "Forrest McKee"], "title": "Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "This study explores Large Language Models (LLMs) as autonomous agents for\nreal-world tasks, including freelance software development. This work presents\na new benchmark that evaluates LLMs on freelance programming and data analysis\ntasks derived from economic data. We construct the benchmark using synthetic\ntasks created from a Kaggle Freelancer dataset of job postings, with all job\nprices standardized to USD (median fixed-project price around $250, and an\naverage of $306). Each task is accompanied by structured input-output test\ncases and an estimated price tag, enabling automated correctness checking and a\nmonetary performance valuation. This approach is inspired by OpenAI's recent\nSWE-Lancer benchmark (1,400 real Upwork tasks worth $1M total). Still, our\nframework simplifies evaluation using programmatically testable tasks and\npredicted price values, making it highly scalable and repeatable. On this\nbenchmark, we evaluate four modern LLMs - Claude 3.5 Haiku, GPT-4o-mini, Qwen\n2.5, and Mistral. We report each model's accuracy (task success rate and\ntest-case pass rate) and the total \"freelance earnings\" it achieves (sum of\nprices of solved tasks). Our results show that Claude 3.5 Haiku performs best,\nearning approximately $1.52 million USD, followed closely by GPT-4o-mini at\n$1.49 million, then Qwen 2.5 ($1.33M) and Mistral ($0.70M). We analyze the\ndistribution of errors per task and observe that the strongest models solve the\nmost tasks and rarely fail completely on any project. We discuss the\nimplications of these results for the feasibility of AI as a freelance\ndeveloper, the advantages and limitations of our automated benchmark approach,\nand the gap between performance on structured tasks versus the true complexity\nof real-world freelance jobs."}
{"id": "2505.14222", "pdf": "https://arxiv.org/pdf/2505.14222", "abs": "https://arxiv.org/abs/2505.14222", "authors": ["Kaixing Yang", "Xulong Tang", "Yuxuan Hu", "Jiahao Yang", "Hongyan Liu", "Qinnan Zhang", "Jun He", "Zhaoxin Fan"], "title": "MatchDance: Collaborative Mamba-Transformer Architecture Matching for High-Quality 3D Dance Synthesis", "categories": ["cs.SD", "cs.GR", "cs.MM", "eess.AS"], "comment": null, "summary": "Music-to-dance generation represents a challenging yet pivotal task at the\nintersection of choreography, virtual reality, and creative content generation.\nDespite its significance, existing methods face substantial limitation in\nachieving choreographic consistency. To address the challenge, we propose\nMatchDance, a novel framework for music-to-dance generation that constructs a\nlatent representation to enhance choreographic consistency. MatchDance employs\na two-stage design: (1) a Kinematic-Dynamic-based Quantization Stage (KDQS),\nwhich encodes dance motions into a latent representation by Finite Scalar\nQuantization (FSQ) with kinematic-dynamic constraints and reconstructs them\nwith high fidelity, and (2) a Hybrid Music-to-Dance Generation Stage(HMDGS),\nwhich uses a Mamba-Transformer hybrid architecture to map music into the latent\nrepresentation, followed by the KDQS decoder to generate 3D dance motions.\nAdditionally, a music-dance retrieval framework and comprehensive metrics are\nintroduced for evaluation. Extensive experiments on the FineDance dataset\ndemonstrate state-of-the-art performance. Code will be released upon\nacceptance."}
{"id": "2505.14081", "pdf": "https://arxiv.org/pdf/2505.14081", "abs": "https://arxiv.org/abs/2505.14081", "authors": ["Luca Ballotta", "Nicola Bastianello", "Riccardo M. G. Ferrari", "Karl H. Johansson"], "title": "Personalized and Resilient Distributed Learning Through Opinion Dynamics", "categories": ["cs.MA", "cs.LG", "eess.SP", "math.OC"], "comment": "This work has been submitted to IEEE for possible publication", "summary": "In this paper, we address two practical challenges of distributed learning in\nmulti-agent network systems, namely personalization and resilience.\nPersonalization is the need of heterogeneous agents to learn local models\ntailored to their own data and tasks, while still generalizing well; on the\nother hand, the learning process must be resilient to cyberattacks or anomalous\ntraining data to avoid disruption. Motivated by a conceptual affinity between\nthese two requirements, we devise a distributed learning algorithm that\ncombines distributed gradient descent and the Friedkin-Johnsen model of opinion\ndynamics to fulfill both of them. We quantify its convergence speed and the\nneighborhood that contains the final learned models, which can be easily\ncontrolled by tuning the algorithm parameters to enforce a more\npersonalized/resilient behavior. We numerically showcase the effectiveness of\nour algorithm on synthetic and real-world distributed learning tasks, where it\nachieves high global accuracy both for personalized models and with malicious\nagents compared to standard strategies."}
{"id": "2505.13930", "pdf": "https://arxiv.org/pdf/2505.13930", "abs": "https://arxiv.org/abs/2505.13930", "authors": ["Yassine El Kheir", "Tim Polzehl", "Sebastian M√∂ller"], "title": "BiCrossMamba-ST: Speech Deepfake Detection with Bidirectional Mamba Spectro-Temporal Cross-Attention", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted Interspeech 2025", "summary": "We propose BiCrossMamba-ST, a robust framework for speech deepfake detection\nthat leverages a dual-branch spectro-temporal architecture powered by\nbidirectional Mamba blocks and mutual cross-attention. By processing spectral\nsub-bands and temporal intervals separately and then integrating their\nrepresentations, BiCrossMamba-ST effectively captures the subtle cues of\nsynthetic speech. In addition, our proposed framework leverages a\nconvolution-based 2D attention map to focus on specific spectro-temporal\nregions, enabling robust deepfake detection. Operating directly on raw\nfeatures, BiCrossMamba-ST achieves significant performance improvements, a\n67.74% and 26.3% relative gain over state-of-the-art AASIST on ASVSpoof LA21\nand ASVSpoof DF21 benchmarks, respectively, and a 6.80% improvement over\nRawBMamba on ASVSpoof DF21. Code and models will be made publicly available."}
{"id": "2505.13826", "pdf": "https://arxiv.org/pdf/2505.13826", "abs": "https://arxiv.org/abs/2505.13826", "authors": ["Yafeng Chen", "Chong Deng", "Hui Wang", "Yiheng Jiang", "Han Yin", "Qian Chen", "Wen Wang"], "title": "Pushing the Frontiers of Self-Distillation Prototypes Network with Dimension Regularization and Score Normalization", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Developing robust speaker verification (SV) systems without speaker labels\nhas been a longstanding challenge. Earlier research has highlighted a\nconsiderable performance gap between self-supervised and fully supervised\napproaches. In this paper, we enhance the non-contrastive self-supervised\nframework, Self-Distillation Prototypes Network (SDPN), by introducing\ndimension regularization that explicitly addresses the collapse problem through\nthe application of regularization terms to speaker embeddings. Moreover, we\nintegrate score normalization techniques from fully supervised SV to further\nbridge the gap toward supervised verification performance. SDPN with dimension\nregularization and score normalization sets a new state-of-the-art on the\nVoxCeleb1 speaker verification evaluation benchmark, achieving Equal Error Rate\n1.29%, 1.60%, and 2.80% for trial VoxCeleb1-{O,E,H} respectively. These results\ndemonstrate relative improvements of 28.3%, 19.6%, and 22.6% over the current\nbest self-supervised methods, thereby advancing the frontiers of SV technology."}
{"id": "2505.13906", "pdf": "https://arxiv.org/pdf/2505.13906", "abs": "https://arxiv.org/abs/2505.13906", "authors": ["Soyabul Islam Lincoln", "Mirza Mohd Shahriar Maswood"], "title": "XDementNET: An Explainable Attention Based Deep Convolutional Network to Detect Alzheimer Progression from MRI data", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "20 pages, 12 figures,", "summary": "A common neurodegenerative disease, Alzheimer's disease requires a precise\ndiagnosis and efficient treatment, particularly in light of escalating\nhealthcare expenses and the expanding use of artificial intelligence in medical\ndiagnostics. Many recent studies shows that the combination of brain Magnetic\nResonance Imaging (MRI) and deep neural networks have achieved promising\nresults for diagnosing AD. Using deep convolutional neural networks, this paper\nintroduces a novel deep learning architecture that incorporates multiresidual\nblocks, specialized spatial attention blocks, grouped query attention, and\nmulti-head attention. The study assessed the model's performance on four\npublicly accessible datasets and concentrated on identifying binary and\nmulticlass issues across various categories. This paper also takes into account\nof the explainability of AD's progression and compared with state-of-the-art\nmethods namely Gradient Class Activation Mapping (GradCAM), Score-CAM, Faster\nScore-CAM, and XGRADCAM. Our methodology consistently outperforms current\napproaches, achieving 99.66\\% accuracy in 4-class classification, 99.63\\% in\n3-class classification, and 100\\% in binary classification using Kaggle\ndatasets. For Open Access Series of Imaging Studies (OASIS) datasets the\naccuracies are 99.92\\%, 99.90\\%, and 99.95\\% respectively. The Alzheimer's\nDisease Neuroimaging Initiative-1 (ADNI-1) dataset was used for experiments in\nthree planes (axial, sagittal, and coronal) and a combination of all planes.\nThe study achieved accuracies of 99.08\\% for axis, 99.85\\% for sagittal, 99.5\\%\nfor coronal, and 99.17\\% for all axis, and 97.79\\% and 8.60\\% respectively for\nADNI-2. The network's ability to retrieve important information from MRI images\nis demonstrated by its excellent accuracy in categorizing AD stages."}
{"id": "2505.13506", "pdf": "https://arxiv.org/pdf/2505.13506", "abs": "https://arxiv.org/abs/2505.13506", "authors": ["Ruobing Yao", "Yifei Zhang", "Shuang Song", "Neng Gao", "Chenyang Tu"], "title": "EcoSafeRAG: Efficient Security through Context Analysis in Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) compensates for the static knowledge\nlimitations of Large Language Models (LLMs) by integrating external knowledge,\nproducing responses with enhanced factual correctness and query-specific\ncontextualization. However, it also introduces new attack surfaces such as\ncorpus poisoning at the same time. Most of the existing defense methods rely on\nthe internal knowledge of the model, which conflicts with the design concept of\nRAG. To bridge the gap, EcoSafeRAG uses sentence-level processing and\nbait-guided context diversity detection to identify malicious content by\nanalyzing the context diversity of candidate documents without relying on LLM\ninternal knowledge. Experiments show EcoSafeRAG delivers state-of-the-art\nsecurity with plug-and-play deployment, simultaneously improving clean-scenario\nRAG performance while maintaining practical operational costs (relatively\n1.2$\\times$ latency, 48\\%-80\\% token reduction versus Vanilla RAG)."}
{"id": "2505.13741", "pdf": "https://arxiv.org/pdf/2505.13741", "abs": "https://arxiv.org/abs/2505.13741", "authors": ["Gaspard Goupy", "Pierre Tirilly", "Ioan Marius Bilasco"], "title": "Frozen Backpropagation: Relaxing Weight Symmetry in Temporally-Coded Deep Spiking Neural Networks", "categories": ["cs.CV", "cs.NE"], "comment": null, "summary": "Direct training of Spiking Neural Networks (SNNs) on neuromorphic hardware\ncan greatly reduce energy costs compared to GPU-based training. However,\nimplementing Backpropagation (BP) on such hardware is challenging because\nforward and backward passes are typically performed by separate networks with\ndistinct weights. To compute correct gradients, forward and feedback weights\nmust remain symmetric during training, necessitating weight transport between\nthe two networks. This symmetry requirement imposes hardware overhead and\nincreases energy costs. To address this issue, we introduce Frozen\nBackpropagation (fBP), a BP-based training algorithm relaxing weight symmetry\nin settings with separate networks. fBP updates forward weights by computing\ngradients with periodically frozen feedback weights, reducing weight transports\nduring training and minimizing synchronization overhead. To further improve\ntransport efficiency, we propose three partial weight transport schemes of\nvarying computational complexity, where only a subset of weights is transported\nat a time. We evaluate our methods on image recognition tasks and compare them\nto existing approaches addressing the weight symmetry requirement. Our results\nshow that fBP outperforms these methods and achieves accuracy comparable to BP.\nWith partial weight transport, fBP can substantially lower transport costs by\n1,000x with an accuracy drop of only 0.5pp on CIFAR-10 and 1.1pp on CIFAR-100,\nor by up to 10,000x at the expense of moderated accuracy loss. This work\nprovides insights for guiding the design of neuromorphic hardware incorporating\nBP-based on-chip learning."}
{"id": "2505.13499", "pdf": "https://arxiv.org/pdf/2505.13499", "abs": "https://arxiv.org/abs/2505.13499", "authors": ["Kelvin Kan", "Xingjian Li", "Benjamin J. Zhang", "Tuhin Sahai", "Stanley Osher", "Markos A. Katsoulakis"], "title": "Optimal Control for Transformer Architectures: Enhancing Generalization, Robustness and Efficiency", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "We study Transformers through the perspective of optimal control theory,\nusing tools from continuous-time formulations to derive actionable insights\ninto training and architecture design. This framework improves the performance\nof existing Transformer models while providing desirable theoretical\nguarantees, including generalization and robustness. Our framework is designed\nto be plug-and-play, enabling seamless integration with established Transformer\nmodels and requiring only slight changes to the implementation. We conduct\nseven extensive experiments on tasks motivated by text generation, sentiment\nanalysis, image classification, and point cloud classification. Experimental\nresults show that the framework improves the test performance of the baselines,\nwhile being more parameter-efficient. On character-level text generation with\nnanoGPT, our framework achieves a 46% reduction in final test loss while using\n42% fewer parameters. On GPT-2, our framework achieves a 5.6% reduction in\nfinal test loss, demonstrating scalability to larger models. To the best of our\nknowledge, this is the first work that applies optimal control theory to both\nthe training and architecture of Transformers. It offers a new foundation for\nsystematic, theory-driven improvements and moves beyond costly trial-and-error\napproaches."}
{"id": "2505.13522", "pdf": "https://arxiv.org/pdf/2505.13522", "abs": "https://arxiv.org/abs/2505.13522", "authors": ["Nathalie Sanghikian", "Rafael Meirelles", "Rafael Martinelli", "Anand Subramanian"], "title": "A Heuristic Algorithm Based on Beam Search and Iterated Local Search for the Maritime Inventory Routing Problem", "categories": ["cs.AI", "math.OC"], "comment": null, "summary": "Maritime Inventory Routing Problem (MIRP) plays a crucial role in the\nintegration of global maritime commerce levels. However, there are still no\nwell-established methodologies capable of efficiently solving large MIRP\ninstances or their variants due to the high complexity of the problem. The\nadoption of exact methods, typically based on Mixed Integer Programming (MIP),\nfor daily operations is nearly impractical due to the CPU time required, as\nplanning must be executed multiple times while ensuring high-quality results\nwithin acceptable time limits. Non-MIP-based heuristics are less frequently\napplied due to the highly constrained nature of the problem, which makes even\nthe construction of an effective initial solution challenging. Papageorgiou et\nal. (2014) introduced a single-product MIRP as the foundation for MIRPLib,\naiming to provide a collection of publicly available benchmark instances.\nHowever, only a few studies that propose new methodologies have been published\nsince then. To encourage the use of MIRPLib and facilitate result comparisons,\nthis study presents a heuristic approach that does not rely on mathematical\noptimization techniques to solve a deterministic, finite-horizon,\nsingle-product MIRP. The proposed heuristic combines a variation of a Beam\nSearch algorithm with an Iterated Local Search procedure. Among the 72\ninstances tested, the developed methodology can improve the best-known solution\nfor ten instances within an acceptable CPU time."}
{"id": "2505.14272", "pdf": "https://arxiv.org/pdf/2505.14272", "abs": "https://arxiv.org/abs/2505.14272", "authors": ["Faeze Ghorbanpour", "Daryna Dementieva", "Alexander Fraser"], "title": "Data-Efficient Hate Speech Detection via Cross-Lingual Nearest Neighbor Retrieval with Limited Labeled Data", "categories": ["cs.CL", "cs.CY", "cs.MM"], "comment": null, "summary": "Considering the importance of detecting hateful language, labeled hate speech\ndata is expensive and time-consuming to collect, particularly for low-resource\nlanguages. Prior work has demonstrated the effectiveness of cross-lingual\ntransfer learning and data augmentation in improving performance on tasks with\nlimited labeled data. To develop an efficient and scalable cross-lingual\ntransfer learning approach, we leverage nearest-neighbor retrieval to augment\nminimal labeled data in the target language, thereby enhancing detection\nperformance. Specifically, we assume access to a small set of labeled training\ninstances in the target language and use these to retrieve the most relevant\nlabeled examples from a large multilingual hate speech detection pool. We\nevaluate our approach on eight languages and demonstrate that it consistently\noutperforms models trained solely on the target language data. Furthermore, in\nmost cases, our method surpasses the current state-of-the-art. Notably, our\napproach is highly data-efficient, retrieving as small as 200 instances in some\ncases while maintaining superior performance. Moreover, it is scalable, as the\nretrieval pool can be easily expanded, and the method can be readily adapted to\nnew languages and tasks. We also apply maximum marginal relevance to mitigate\nredundancy and filter out highly similar retrieved instances, resulting in\nimprovements in some languages."}
{"id": "2505.14299", "pdf": "https://arxiv.org/pdf/2505.14299", "abs": "https://arxiv.org/abs/2505.14299", "authors": ["Zihao Feng", "Xiaoxue Wang", "Bowen Wu", "Weihong Zhong", "Zhen Xu", "Hailong Cao", "Tiejun Zhao", "Ying Li", "Baoxun Wang"], "title": "Empowering LLMs in Task-Oriented Dialogues: A Domain-Independent Multi-Agent Framework and Fine-Tuning Strategy", "categories": ["cs.MA"], "comment": null, "summary": "Task-oriented dialogue systems based on Large Language Models (LLMs) have\ngained increasing attention across various industries and achieved significant\nresults. Current approaches condense complex procedural workflows into a single\nagent to achieve satisfactory performance on large-scale LLMs. However, these\napproaches face challenges to achieve comparable performance on fine-tuned\nlightweight LLMs, due to their limited capabilities in handling multiple\ncomplex logic. In this work, we design a Domain-Independent Multi-Agent\nFramework (DIMF), which contains Intent Classification Agent, Slot Filling\nAgent and Response Agent. This approach simplifies the learning complexity and\nenhances the generalization ability by separating the tasks into\ndomain-independent components. In this framework, we enhance the capabilities\nin contextual understanding using the Direct Preference Optimisation (DPO)\nmethod, and propose a simple and effective Data Distribution Adaptation (DDA)\nmethod to mitigate degradation issues during DPO training. Experiments\nconducted on the MultiWOZ datasets show that our proposed method achieves a\nbetter average performance among all the baselines. Extensive analysis also\ndemonstrates that our proposed framework exhibits excellent generalizability\nand zero-shot capability."}
{"id": "2505.13971", "pdf": "https://arxiv.org/pdf/2505.13971", "abs": "https://arxiv.org/abs/2505.13971", "authors": ["Ming Gao", "Shilong Wu", "Hang Chen", "Jun Du", "Chin-Hui Lee", "Shinji Watanabe", "Jingdong Chen", "Siniscalchi Sabato Marco", "Odette Scharenborg"], "title": "The Multimodal Information Based Speech Processing (MISP) 2025 Challenge: Audio-Visual Diarization and Recognition", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted by Interspeech 2025. Camera-ready version", "summary": "Meetings are a valuable yet challenging scenario for speech applications due\nto complex acoustic conditions. This paper summarizes the outcomes of the MISP\n2025 Challenge, hosted at Interspeech 2025, which focuses on multi-modal,\nmulti-device meeting transcription by incorporating video modality alongside\naudio. The tasks include Audio-Visual Speaker Diarization (AVSD), Audio-Visual\nSpeech Recognition (AVSR), and Audio-Visual Diarization and Recognition (AVDR).\nWe present the challenge's objectives, tasks, dataset, baseline systems, and\nsolutions proposed by participants. The best-performing systems achieved\nsignificant improvements over the baseline: the top AVSD model achieved a\nDiarization Error Rate (DER) of 8.09%, improving by 7.43%; the top AVSR system\nachieved a Character Error Rate (CER) of 9.48%, improving by 10.62%; and the\nbest AVDR system achieved a concatenated minimum-permutation Character Error\nRate (cpCER) of 11.56%, improving by 72.49%."}
{"id": "2505.13830", "pdf": "https://arxiv.org/pdf/2505.13830", "abs": "https://arxiv.org/abs/2505.13830", "authors": ["Ye-Xin Lu", "Hui-Peng Du", "Fei Liu", "Yang Ai", "Zhen-Hua Ling"], "title": "Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by Interspeech 2025", "summary": "Large language model (LLM) based zero-shot text-to-speech (TTS) methods tend\nto preserve the acoustic environment of the audio prompt, leading to\ndegradation in synthesized speech quality when the audio prompt contains noise.\nIn this paper, we propose a novel neural codec-based speech denoiser and\nintegrate it with the advanced LLM-based TTS model, LauraTTS, to achieve\nnoise-robust zero-shot TTS. The proposed codec denoiser consists of an audio\ncodec, a token denoiser, and an embedding refiner. The token denoiser predicts\nthe first two groups of clean acoustic tokens from the noisy ones, which can\nserve as the acoustic prompt for LauraTTS to synthesize high-quality\npersonalized speech or be converted to clean speech waveforms through the\nembedding refiner and codec decoder. Experimental results show that our\nproposed codec denoiser outperforms state-of-the-art speech enhancement (SE)\nmethods, and the proposed noise-robust LauraTTS surpasses the approach using\nadditional SE models."}
{"id": "2505.13911", "pdf": "https://arxiv.org/pdf/2505.13911", "abs": "https://arxiv.org/abs/2505.13911", "authors": ["Ruijie Zhao", "Zuopeng Tan", "Xiao Xue", "Longfei Zhao", "Bing Li", "Zicheng Liao", "Ying Ming", "Jiaru Wang", "Ran Xiao", "Sirong Piao", "Rui Zhao", "Qiqi Xu", "Wei Song"], "title": "Bronchovascular Tree-Guided Weakly Supervised Learning Method for Pulmonary Segment Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Pulmonary segment segmentation is crucial for cancer localization and\nsurgical planning. However, the pixel-wise annotation of pulmonary segments is\nlaborious, as the boundaries between segments are indistinguishable in medical\nimages. To this end, we propose a weakly supervised learning (WSL) method,\ntermed Anatomy-Hierarchy Supervised Learning (AHSL), which consults the precise\nclinical anatomical definition of pulmonary segments to perform pulmonary\nsegment segmentation. Since pulmonary segments reside within the lobes and are\ndetermined by the bronchovascular tree, i.e., artery, airway and vein, the\ndesign of the loss function is founded on two principles. First, segment-level\nlabels are utilized to directly supervise the output of the pulmonary segments,\nensuring that they accurately encompass the appropriate bronchovascular tree.\nSecond, lobe-level supervision indirectly oversees the pulmonary segment,\nensuring their inclusion within the corresponding lobe. Besides, we introduce a\ntwo-stage segmentation strategy that incorporates bronchovascular priori\ninformation. Furthermore, a consistency loss is proposed to enhance the\nsmoothness of segment boundaries, along with an evaluation metric designed to\nmeasure the smoothness of pulmonary segment boundaries. Visual inspection and\nevaluation metrics from experiments conducted on a private dataset demonstrate\nthe effectiveness of our method."}
{"id": "2505.13508", "pdf": "https://arxiv.org/pdf/2505.13508", "abs": "https://arxiv.org/abs/2505.13508", "authors": ["Zijia Liu", "Peixuan Han", "Haofei Yu", "Haoru Li", "Jiaxuan You"], "title": "Time-R1: Towards Comprehensive Temporal Reasoning in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate impressive capabilities but lack\nrobust temporal intelligence, struggling to integrate reasoning about the past\nwith predictions and plausible generations of the future. Meanwhile, existing\nmethods typically target isolated temporal skills, such as question answering\nabout past events or basic forecasting, and exhibit poor generalization,\nparticularly when dealing with events beyond their knowledge cutoff or\nrequiring creative foresight. To address these limitations, we introduce\n\\textit{Time-R1}, the first framework to endow a moderate-sized (3B-parameter)\nLLM with comprehensive temporal abilities: understanding, prediction, and\ncreative generation. Our approach features a novel three-stage development\npath; the first two constitute a \\textit{reinforcement learning (RL)\ncurriculum} driven by a meticulously designed dynamic rule-based reward system.\nThis framework progressively builds (1) foundational temporal understanding and\nlogical event-time mappings from historical data, (2) future event prediction\nskills for events beyond its knowledge cutoff, and finally (3) enables\nremarkable generalization to creative future scenario generation without any\nfine-tuning. Strikingly, experiments demonstrate that Time-R1 outperforms\nmodels over 200 times larger, including the state-of-the-art 671B DeepSeek-R1,\non highly challenging future event prediction and creative scenario generation\nbenchmarks. This work provides strong evidence that thoughtfully engineered,\nprogressive RL fine-tuning allows smaller, efficient models to achieve superior\ntemporal performance, offering a practical and scalable path towards truly\ntime-aware AI. To foster further research, we also release \\textit{Time-Bench},\na large-scale multi-task temporal reasoning dataset derived from 10 years of\nnews data, and our series of \\textit{Time-R1} checkpoints."}
{"id": "2505.13746", "pdf": "https://arxiv.org/pdf/2505.13746", "abs": "https://arxiv.org/abs/2505.13746", "authors": ["Satoshi Kondo"], "title": "ReSW-VL: Representation Learning for Surgical Workflow Analysis Using Vision-Language Model", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Surgical phase recognition from video is a technology that automatically\nclassifies the progress of a surgical procedure and has a wide range of\npotential applications, including real-time surgical support, optimization of\nmedical resources, training and skill assessment, and safety improvement.\nRecent advances in surgical phase recognition technology have focused primarily\non Transform-based methods, although methods that extract spatial features from\nindividual frames using a CNN and video features from the resulting time series\nof spatial features using time series modeling have shown high performance.\nHowever, there remains a paucity of research on training methods for CNNs\nemployed for feature extraction or representation learning in surgical phase\nrecognition. In this study, we propose a method for representation learning in\nsurgical workflow analysis using a vision-language model (ReSW-VL). Our\nproposed method involves fine-tuning the image encoder of a CLIP (Convolutional\nLanguage Image Model) vision-language model using prompt learning for surgical\nphase recognition. The experimental results on three surgical phase recognition\ndatasets demonstrate the effectiveness of the proposed method in comparison to\nconventional methods."}
{"id": "2505.13501", "pdf": "https://arxiv.org/pdf/2505.13501", "abs": "https://arxiv.org/abs/2505.13501", "authors": ["Zequn He", "Celia Reina"], "title": "SPIEDiff: robust learning of long-time macroscopic dynamics from short-time particle simulations with quantified epistemic uncertainty", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "The data-driven discovery of long-time macroscopic dynamics and\nthermodynamics of dissipative systems with particle fidelity is hampered by\nsignificant obstacles. These include the strong time-scale limitations inherent\nto particle simulations, the non-uniqueness of the thermodynamic potentials and\noperators from given macroscopic dynamics, and the need for efficient\nuncertainty quantification. This paper introduces Statistical-Physics Informed\nEpistemic Diffusion Models (SPIEDiff), a machine learning framework designed to\novercome these limitations in the context of purely dissipative systems by\nleveraging statistical physics, conditional diffusion models, and epinets. We\nevaluate the proposed framework on stochastic Arrhenius particle processes and\ndemonstrate that SPIEDiff can accurately uncover both thermodynamics and\nkinetics, while enabling reliable long-time macroscopic predictions using only\nshort-time particle simulation data. SPIEDiff can deliver accurate predictions\nwith quantified uncertainty in minutes, drastically reducing the computational\ndemand compared to direct particle simulations, which would take days or years\nin the examples considered. Overall, SPIEDiff offers a robust and trustworthy\npathway for the data-driven discovery of thermodynamic models."}
{"id": "2505.13529", "pdf": "https://arxiv.org/pdf/2505.13529", "abs": "https://arxiv.org/abs/2505.13529", "authors": ["Junxiao Yang", "Jinzhe Tu", "Haoran Liu", "Xiaoce Wang", "Chujie Zheng", "Zhexin Zhang", "Shiyao Cui", "Caishun Chen", "Tiantian He", "Hongning Wang", "Yew-Soon Ong", "Minlie Huang"], "title": "BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in Large Reasoning Models (LRMs) have shown impressive\ncapabilities in mathematical and logical reasoning. However, current LRMs\nrarely admit ignorance or respond with \"I don't know\". Instead, they often\nproduce incorrect answers while showing undue confidence, raising concerns\nabout their factual reliability. In this work, we identify two pathological\nreasoning patterns characterized by overthinking that contribute to the\noverconfident and incorrect answers: last-minute guessing and second-thought\nspiraling. To address these issues, we propose BARREL-a novel framework that\npromotes concise and boundary-aware factual reasoning. Our experiments show\nthat BARREL-training increases the reliability of DeepSeek-R1-Distill-Llama-8B\nfrom 39.33% to 61.48%, while still achieving accuracy comparable to models\nfinetuned on reasoning data generated by R1. These results demonstrate that our\npilot study is inspiring to build more reliable and factual System 2 LRMs."}
{"id": "2505.14319", "pdf": "https://arxiv.org/pdf/2505.14319", "abs": "https://arxiv.org/abs/2505.14319", "authors": ["Weihao Xia", "Chenliang Zhou", "Cengiz Oztireli"], "title": "RETRO: REthinking Tactile Representation Learning with Material PriOrs", "categories": ["cs.CV", "cs.MM"], "comment": "Code: https://github.com/weihaox/RETRO", "summary": "Tactile perception is profoundly influenced by the surface properties of\nobjects in contact. However, despite their crucial role in shaping tactile\nexperiences, these material characteristics have been largely neglected in\nexisting tactile representation learning methods. Most approaches primarily\nfocus on aligning tactile data with visual or textual information, overlooking\nthe richness of tactile feedback that comes from understanding the materials'\ninherent properties. In this work, we address this gap by revisiting the\ntactile representation learning framework and incorporating material-aware\npriors into the learning process. These priors, which represent pre-learned\ncharacteristics specific to different materials, allow tactile models to better\ncapture and generalize the nuances of surface texture. Our method enables more\naccurate, contextually rich tactile feedback across diverse materials and\ntextures, improving performance in real-world applications such as robotics,\nhaptic feedback systems, and material editing."}
{"id": "2505.13449", "pdf": "https://arxiv.org/pdf/2505.13449", "abs": "https://arxiv.org/abs/2505.13449", "authors": ["Maram Albalwe", "Blair Archibald", "Michele Sevegnani"], "title": "Modelling Real-time Systems with Bigraphs", "categories": ["cs.LO", "cs.MA"], "comment": "In Proceedings GCM 2023 and 2024, arXiv:2503.19632", "summary": "Bigraphical Reactive Systems (BRSs) are a graph-rewriting formalism\ndescribing systems evolving in two dimensions: spatially, e.g. a person in a\nroom, and non-spatially, e.g. mobile phones communicating regardless of\nlocation. Despite use in domains including communication protocols, agent\nprogramming, biology, and security, there is no support for real-time systems.\nWe extend BRSs to support real-time systems with a modelling approach that uses\nmultiple perspectives to represent digital clocks. We use Action BRSs, a recent\nextension of BRSs, where the resulting transition system is a Markov Decision\nProcess (MDP). This allows a natural representation of the choices in each\nsystem state: to either allow time to pass or perform a specific action. We\nimplement our proposed approach using the BigraphER toolkit, and demonstrate\nthe effectiveness through multiple examples including modelling cloud system\nrequests."}
{"id": "2505.13978", "pdf": "https://arxiv.org/pdf/2505.13978", "abs": "https://arxiv.org/abs/2505.13978", "authors": ["Yuan Gao", "Hao Shi", "Yahui Fu", "Chenhui Chu", "Tatsuya Kawahara"], "title": "Bridging Speech Emotion Recognition and Personality: Dataset and Temporal Interaction Condition Network", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "This study investigates the interaction between personality traits and\nemotional expression, exploring how personality information can improve speech\nemotion recognition (SER). We collected personality annotation for the IEMOCAP\ndataset, and the statistical analysis identified significant correlations\nbetween personality traits and emotional expressions. To extract finegrained\npersonality features, we propose a temporal interaction condition network\n(TICN), in which personality features are integrated with Hubert-based acoustic\nfeatures for SER. Experiments show that incorporating ground-truth personality\ntraits significantly enhances valence recognition, improving the concordance\ncorrelation coefficient (CCC) from 0.698 to 0.785 compared to the baseline\nwithout personality information. For practical applications in dialogue systems\nwhere personality information about the user is unavailable, we develop a\nfront-end module of automatic personality recognition. Using these\nautomatically predicted traits as inputs to our proposed TICN model, we achieve\na CCC of 0.776 for valence recognition, representing an 11.17% relative\nimprovement over the baseline. These findings confirm the effectiveness of\npersonality-aware SER and provide a solid foundation for further exploration in\npersonality-aware speech processing applications."}
{"id": "2505.13843", "pdf": "https://arxiv.org/pdf/2505.13843", "abs": "https://arxiv.org/abs/2505.13843", "authors": ["Yang Xiang", "Canan Huang", "Desheng Hu", "Jingguang Tian", "Xinhui Hu", "Chao Zhang"], "title": "A Semantic Information-based Hierarchical Speech Enhancement Method Using Factorized Codec and Diffusion Model", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by interspeech 2025", "summary": "Most current speech enhancement (SE) methods recover clean speech from noisy\ninputs by directly estimating time-frequency masks or spectrums. However, these\napproaches often neglect the distinct attributes, such as semantic content and\nacoustic details, inherent in speech signals, which can hinder performance in\ndownstream tasks. Moreover, their effectiveness tends to degrade in complex\nacoustic environments. To overcome these challenges, we propose a novel,\nsemantic information-based, step-by-step factorized SE method using factorized\ncodec and diffusion model. Unlike traditional SE methods, our hierarchical\nmodeling of semantic and acoustic attributes enables more robust clean speech\nrecovery, particularly in challenging acoustic scenarios. Moreover, this method\noffers further advantages for downstream TTS tasks. Experimental results\ndemonstrate that our algorithm not only outperforms SOTA baselines in terms of\nspeech quality but also enhances TTS performance in noisy environments."}
{"id": "2505.14017", "pdf": "https://arxiv.org/pdf/2505.14017", "abs": "https://arxiv.org/abs/2505.14017", "authors": ["Jesper Duemose Nielsen", "Karthik Gopinath", "Andrew Hoopes", "Adrian Dalca", "Colin Magdamo", "Steven Arnold", "Sudeshna Das", "Axel Thielscher", "Juan Eugenio Iglesias", "Oula Puonti"], "title": "End-to-end Cortical Surface Reconstruction from Clinical Magnetic Resonance Images", "categories": ["eess.IV", "cs.CV"], "comment": "11 pages, 4 figures", "summary": "Surface-based cortical analysis is valuable for a variety of neuroimaging\ntasks, such as spatial normalization, parcellation, and gray matter (GM)\nthickness estimation. However, most tools for estimating cortical surfaces work\nexclusively on scans with at least 1 mm isotropic resolution and are tuned to a\nspecific magnetic resonance (MR) contrast, often T1-weighted (T1w). This\nprecludes application using most clinical MR scans, which are very\nheterogeneous in terms of contrast and resolution. Here, we use synthetic\ndomain-randomized data to train the first neural network for explicit\nestimation of cortical surfaces from scans of any contrast and resolution,\nwithout retraining. Our method deforms a template mesh to the white matter (WM)\nsurface, which guarantees topological correctness. This mesh is further\ndeformed to estimate the GM surface. We compare our method to\nrecon-all-clinical (RAC), an implicit surface reconstruction method which is\ncurrently the only other tool capable of processing heterogeneous clinical MR\nscans, on ADNI and a large clinical dataset (n=1,332). We show a approximately\n50 % reduction in cortical thickness error (from 0.50 to 0.24 mm) with respect\nto RAC and better recovery of the aging-related cortical thinning patterns\ndetected by FreeSurfer on high-resolution T1w scans. Our method enables fast\nand accurate surface reconstruction of clinical scans, allowing studies (1)\nwith sample sizes far beyond what is feasible in a research setting, and (2) of\nclinical populations that are difficult to enroll in research studies. The code\nis publicly available at https://github.com/simnibs/brainnet."}
{"id": "2505.13514", "pdf": "https://arxiv.org/pdf/2505.13514", "abs": "https://arxiv.org/abs/2505.13514", "authors": ["Shuxun Wang", "Qingyu Yin", "Chak Tou Leong", "Qiang Zhang", "Linyi Yang"], "title": "Induction Head Toxicity Mechanistically Explains Repetition Curse in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Repetition curse is a phenomenon where Large Language Models (LLMs) generate\nrepetitive sequences of tokens or cyclic sequences. While the repetition curse\nhas been widely observed, its underlying mechanisms remain poorly understood.\nIn this work, we investigate the role of induction heads--a specific type of\nattention head known for their ability to perform in-context learning--in\ndriving this repetitive behavior. Specifically, we focus on the \"toxicity\" of\ninduction heads, which we define as their tendency to dominate the model's\noutput logits during repetition, effectively excluding other attention heads\nfrom contributing to the generation process. Our findings have important\nimplications for the design and training of LLMs. By identifying induction\nheads as a key driver of the repetition curse, we provide a mechanistic\nexplanation for this phenomenon and suggest potential avenues for mitigation.\nWe also propose a technique with attention head regularization that could be\nemployed to reduce the dominance of induction heads during generation, thereby\npromoting more diverse and coherent outputs."}
{"id": "2505.13777", "pdf": "https://arxiv.org/pdf/2505.13777", "abs": "https://arxiv.org/abs/2505.13777", "authors": ["Subash Khanal", "Srikumar Sastry", "Aayush Dhakal", "Adeel Ahmad", "Nathan Jacobs"], "title": "Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping", "categories": ["cs.CV", "cs.AI", "cs.SD"], "comment": null, "summary": "We present Sat2Sound, a multimodal representation learning framework for\nsoundscape mapping, designed to predict the distribution of sounds at any\nlocation on Earth. Existing methods for this task rely on satellite image and\npaired geotagged audio samples, which often fail to capture the diversity of\nsound sources at a given location. To address this limitation, we enhance\nexisting datasets by leveraging a Vision-Language Model (VLM) to generate\nsemantically rich soundscape descriptions for locations depicted in satellite\nimages. Our approach incorporates contrastive learning across audio, audio\ncaptions, satellite images, and satellite image captions. We hypothesize that\nthere is a fixed set of soundscape concepts shared across modalities. To this\nend, we learn a shared codebook of soundscape concepts and represent each\nsample as a weighted average of these concepts. Sat2Sound achieves\nstate-of-the-art performance in cross-modal retrieval between satellite image\nand audio on two datasets: GeoSound and SoundingEarth. Additionally, building\non Sat2Sound's ability to retrieve detailed soundscape captions, we introduce a\nnovel application: location-based soundscape synthesis, which enables immersive\nacoustic experiences. Our code and models will be publicly available."}
{"id": "2505.13502", "pdf": "https://arxiv.org/pdf/2505.13502", "abs": "https://arxiv.org/abs/2505.13502", "authors": ["Yiyuan Yang", "Guodong Long", "Qinghua Lu", "Liming Zhu", "Jing Jiang", "Chengqi Zhang"], "title": "Federated Low-Rank Adaptation for Foundation Models: A Survey", "categories": ["cs.LG"], "comment": null, "summary": "Effectively leveraging private datasets remains a significant challenge in\ndeveloping foundation models. Federated Learning (FL) has recently emerged as a\ncollaborative framework that enables multiple users to fine-tune these models\nwhile mitigating data privacy risks. Meanwhile, Low-Rank Adaptation (LoRA)\noffers a resource-efficient alternative for fine-tuning foundation models by\ndramatically reducing the number of trainable parameters. This survey examines\nhow LoRA has been integrated into federated fine-tuning for foundation models,\nan area we term FedLoRA, by focusing on three key challenges: distributed\nlearning, heterogeneity, and efficiency. We further categorize existing work\nbased on the specific methods used to address each challenge. Finally, we\ndiscuss open research questions and highlight promising directions for future\ninvestigation, outlining the next steps for advancing FedLoRA."}
{"id": "2505.13533", "pdf": "https://arxiv.org/pdf/2505.13533", "abs": "https://arxiv.org/abs/2505.13533", "authors": ["Junzhe Jiang", "Chang Yang", "Aixin Cui", "Sihan Jin", "Ruiyu Wang", "Bo Li", "Xiao Huang", "Dongning Sun", "Xinrun Wang"], "title": "FinMaster: A Holistic Benchmark for Mastering Full-Pipeline Financial Workflows with LLMs", "categories": ["cs.AI", "cs.LG", "q-fin.GN"], "comment": null, "summary": "Financial tasks are pivotal to global economic stability; however, their\nexecution faces challenges including labor intensive processes, low error\ntolerance, data fragmentation, and tool limitations. Although large language\nmodels (LLMs) have succeeded in various natural language processing tasks and\nhave shown potential in automating workflows through reasoning and contextual\nunderstanding, current benchmarks for evaluating LLMs in finance lack\nsufficient domain-specific data, have simplistic task design, and incomplete\nevaluation frameworks. To address these gaps, this article presents FinMaster,\na comprehensive financial benchmark designed to systematically assess the\ncapabilities of LLM in financial literacy, accounting, auditing, and\nconsulting. Specifically, FinMaster comprises three main modules: i) FinSim,\nwhich builds simulators that generate synthetic, privacy-compliant financial\ndata for companies to replicate market dynamics; ii) FinSuite, which provides\ntasks in core financial domains, spanning 183 tasks of various types and\ndifficulty levels; and iii) FinEval, which develops a unified interface for\nevaluation. Extensive experiments over state-of-the-art LLMs reveal critical\ncapability gaps in financial reasoning, with accuracy dropping from over 90% on\nbasic tasks to merely 40% on complex scenarios requiring multi-step reasoning.\nThis degradation exhibits the propagation of computational errors, where\nsingle-metric calculations initially demonstrating 58% accuracy decreased to\n37% in multimetric scenarios. To the best of our knowledge, FinMaster is the\nfirst benchmark that covers full-pipeline financial workflows with challenging\ntasks. We hope that FinMaster can bridge the gap between research and industry\npractitioners, driving the adoption of LLMs in real-world financial practices\nto enhance efficiency and accuracy."}
{"id": "2505.14336", "pdf": "https://arxiv.org/pdf/2505.14336", "abs": "https://arxiv.org/abs/2505.14336", "authors": ["Umberto Cappellazzo", "Minsu Kim", "Stavros Petridis", "Daniele Falavigna", "Alessio Brutti"], "title": "Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach", "categories": ["eess.AS", "cs.CV", "cs.MM", "cs.SD"], "comment": null, "summary": "Audio-Visual Speech Recognition (AVSR) enhances robustness in noisy\nenvironments by integrating visual cues. While recent advances integrate Large\nLanguage Models (LLMs) into AVSR, their high computational cost hinders\ndeployment in resource-constrained settings. To address this, we propose\nLlama-SMoP, an efficient Multimodal LLM that employs a Sparse Mixture of\nProjectors (SMoP) module to scale model capacity without increasing inference\ncosts. By incorporating sparsely-gated mixture-of-experts (MoE) projectors,\nLlama-SMoP enables the use of smaller LLMs while maintaining strong\nperformance. We explore three SMoP configurations and show that Llama-SMoP DEDR\n(Disjoint-Experts, Disjoint-Routers), which uses modality-specific routers and\nexperts, achieves superior performance on ASR, VSR, and AVSR tasks. Ablation\nstudies confirm its effectiveness in expert activation, scalability, and noise\nrobustness."}
{"id": "2505.13504", "pdf": "https://arxiv.org/pdf/2505.13504", "abs": "https://arxiv.org/abs/2505.13504", "authors": ["Ayesha Amjad", "Saurav Sthapit", "Tahir Qasim Syed"], "title": "An agentic system with reinforcement-learned subsystem improvements for parsing form-like documents", "categories": ["cs.IR", "cs.AI", "cs.MA"], "comment": null, "summary": "Extracting alphanumeric data from form-like documents such as invoices,\npurchase orders, bills, and financial documents is often performed via vision\n(OCR) and learning algorithms or monolithic pipelines with limited potential\nfor systemic improvements. We propose an agentic AI system that leverages Large\nLanguage Model (LLM) agents and a reinforcement learning (RL) driver agent to\nautomate consistent, self-improving extraction under LLM inference uncertainty.\nOur work highlights the limitations of monolithic LLM-based extraction and\nintroduces a modular, multi-agent framework with task-specific prompts and an\nRL policy of rewards and penalties to guide a meta-prompting agent to learn\nfrom past errors and improve prompt-based actor agents. This self-corrective\nadaptive system handles diverse documents, file formats, layouts, and LLMs,\naiming to automate accurate information extraction without the need for human\nintervention. Results as reported on two benchmark datasets of SOIRE, and CORD,\nare promising for the agentic AI framework."}
{"id": "2505.13983", "pdf": "https://arxiv.org/pdf/2505.13983", "abs": "https://arxiv.org/abs/2505.13983", "authors": ["Hao Shi", "Xugang Lu", "Kazuki Shimada", "Tatsuya Kawahara"], "title": "Combining Deterministic Enhanced Conditions with Dual-Streaming Encoding for Diffusion-Based Speech Enhancement", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Diffusion-based speech enhancement (SE) models need to incorporate correct\nprior knowledge as reliable conditions to generate accurate predictions.\nHowever, providing reliable conditions using noisy features is challenging. One\nsolution is to use features enhanced by deterministic methods as conditions.\nHowever, the information distortion and loss caused by deterministic methods\nmight affect the diffusion process. In this paper, we first investigate the\neffects of using different deterministic SE models as conditions for diffusion.\nWe validate two conditions depending on whether the noisy feature was used as\npart of the condition: one using only the deterministic feature\n(deterministic-only), and the other using both deterministic and noisy features\n(deterministic-noisy). Preliminary investigation found that using deterministic\nenhanced conditions improves hearing experiences on real data, while the choice\nbetween using deterministic-only or deterministic-noisy conditions depends on\nthe deterministic models. Based on these findings, we propose a dual-streaming\nencoding Repair-Diffusion Model for SE (DERDM-SE) to more effectively utilize\nboth conditions. Moreover, we found that fine-grained deterministic models have\ngreater potential in objective evaluation metrics, while UNet-based\ndeterministic models provide more stable diffusion performance. Therefore, in\nthe DERDM-SE, we propose a deterministic model that combines coarse- and\nfine-grained processing. Experimental results on CHiME4 show that the proposed\nmodels effectively leverage deterministic models to achieve better SE\nevaluation scores, along with more stable performance compared to other\ndiffusion-based SE models."}
{"id": "2505.13880", "pdf": "https://arxiv.org/pdf/2505.13880", "abs": "https://arxiv.org/abs/2505.13880", "authors": ["Ziqian Wang", "Xianjun Xia", "Xinfa Zhu", "Lei Xie"], "title": "U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding", "categories": ["eess.AS", "cs.SD", "eess.SP"], "comment": "Accepted to Interspeech 2025", "summary": "The text generation paradigm for audio tasks has opened new possibilities for\nunified audio understanding. However, existing models face significant\nchallenges in achieving a comprehensive understanding across diverse audio\ntypes, such as speech, general audio events, and music. Furthermore, their\nexclusive reliance on cross-entropy loss for alignment often falls short, as it\ntreats all tokens equally and fails to account for redundant audio features,\nleading to weaker cross-modal alignment. To deal with the above challenges,\nthis paper introduces U-SAM, an advanced audio language model that integrates\nspecialized encoders for speech, audio, and music with a pre-trained large\nlanguage model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for\ntask-aware feature fusion, dynamically routing and integrating the\ndomain-specific encoder outputs. Additionally, U-SAM incorporates a\nSemantic-Aware Contrastive Loss Module, which explicitly identifies redundant\naudio features under language supervision and rectifies their semantic and\nspectral representations to enhance cross-modal alignment. Extensive\nexperiments demonstrate that U-SAM consistently outperforms both specialized\nmodels and existing audio language models across multiple benchmarks. Moreover,\nit exhibits emergent capabilities on unseen tasks, showcasing its\ngeneralization potential. Code is available\n(https://github.com/Honee-W/U-SAM/)."}
{"id": "2505.14064", "pdf": "https://arxiv.org/pdf/2505.14064", "abs": "https://arxiv.org/abs/2505.14064", "authors": ["Cosmin I. Bercea", "Jun Li", "Philipp Raffler", "Evamaria O. Riedel", "Lena Schmitzer", "Angela Kurz", "Felix Bitzer", "Paula Ro√üm√ºller", "Julian Canisius", "Mirjam L. Beyrle", "Che Liu", "Wenjia Bai", "Bernhard Kainz", "Julia A. Schnabel", "Benedikt Wiestler"], "title": "NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "In many real-world applications, deployed models encounter inputs that differ\nfrom the data seen during training. Out-of-distribution detection identifies\nwhether an input stems from an unseen distribution, while open-world\nrecognition flags such inputs to ensure the system remains robust as\never-emerging, previously $unknown$ categories appear and must be addressed\nwithout retraining. Foundation and vision-language models are pre-trained on\nlarge and diverse datasets with the expectation of broad generalization across\ndomains, including medical imaging. However, benchmarking these models on test\nsets with only a few common outlier types silently collapses the evaluation\nback to a closed-set problem, masking failures on rare or truly novel\nconditions encountered in clinical use.\n  We therefore present $NOVA$, a challenging, real-life $evaluation-only$\nbenchmark of $\\sim$900 brain MRI scans that span 281 rare pathologies and\nheterogeneous acquisition protocols. Each case includes rich clinical\nnarratives and double-blinded expert bounding-box annotations. Together, these\nenable joint assessment of anomaly localisation, visual captioning, and\ndiagnostic reasoning. Because NOVA is never used for training, it serves as an\n$extreme$ stress-test of out-of-distribution generalisation: models must bridge\na distribution gap both in sample appearance and in semantic space. Baseline\nresults with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and\nQwen2.5-VL-72B) reveal substantial performance drops across all tasks,\nestablishing NOVA as a rigorous testbed for advancing models that can detect,\nlocalize, and reason about truly unknown anomalies."}
{"id": "2505.13527", "pdf": "https://arxiv.org/pdf/2505.13527", "abs": "https://arxiv.org/abs/2505.13527", "authors": ["Jingyu Peng", "Maolin Wang", "Nan Wang", "Xiangyu Zhao", "Jiatong Li", "Kai Zhang", "Qi Liu"], "title": "Logic Jailbreak: Efficiently Unlocking LLM Safety Restrictions Through Formal Logical Expression", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite substantial advancements in aligning large language models (LLMs)\nwith human values, current safety mechanisms remain susceptible to jailbreak\nattacks. We hypothesize that this vulnerability stems from distributional\ndiscrepancies between alignment-oriented prompts and malicious prompts. To\ninvestigate this, we introduce LogiBreak, a novel and universal black-box\njailbreak method that leverages logical expression translation to circumvent\nLLM safety systems. By converting harmful natural language prompts into formal\nlogical expressions, LogiBreak exploits the distributional gap between\nalignment data and logic-based inputs, preserving the underlying semantic\nintent and readability while evading safety constraints. We evaluate LogiBreak\non a multilingual jailbreak dataset spanning three languages, demonstrating its\neffectiveness across various evaluation settings and linguistic contexts."}
{"id": "2505.13784", "pdf": "https://arxiv.org/pdf/2505.13784", "abs": "https://arxiv.org/abs/2505.13784", "authors": ["Dinh Nam Pham", "Eleftherios Avramidis"], "title": "Transfer Learning from Visual Speech Recognition to Mouthing Recognition in German Sign Language", "categories": ["cs.CV"], "comment": "Accepted at 19th IEEE International Conference on Automatic Face and\n  Gesture Recognition 2025", "summary": "Sign Language Recognition (SLR) systems primarily focus on manual gestures,\nbut non-manual features such as mouth movements, specifically mouthing, provide\nvaluable linguistic information. This work directly classifies mouthing\ninstances to their corresponding words in the spoken language while exploring\nthe potential of transfer learning from Visual Speech Recognition (VSR) to\nmouthing recognition in German Sign Language. We leverage three VSR datasets:\none in English, one in German with unrelated words and one in German containing\nthe same target words as the mouthing dataset, to investigate the impact of\ntask similarity in this setting. Our results demonstrate that multi-task\nlearning improves both mouthing recognition and VSR accuracy as well as model\nrobustness, suggesting that mouthing recognition should be treated as a\ndistinct but related task to VSR. This research contributes to the field of SLR\nby proposing knowledge transfer from VSR to SLR datasets with limited mouthing\nannotations."}
{"id": "2505.13507", "pdf": "https://arxiv.org/pdf/2505.13507", "abs": "https://arxiv.org/abs/2505.13507", "authors": ["Haoyang Chen"], "title": "Open Set Domain Adaptation with Vision-language models via Gradient-aware Separation", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Open-Set Domain Adaptation (OSDA) confronts the dual challenge of aligning\nknown-class distributions across domains while identifying\ntarget-domain-specific unknown categories. Current approaches often fail to\nleverage semantic relationships between modalities and struggle with error\naccumulation in unknown sample detection. We propose to harness Contrastive\nLanguage-Image Pretraining (CLIP) to address these limitations through two key\ninnovations: 1) Prompt-driven cross-domain alignment: Learnable textual prompts\nconditioned on domain discrepancy metrics dynamically adapt CLIP's text\nencoder, enabling semantic consistency between source and target domains\nwithout explicit unknown-class supervision. 2) Gradient-aware open-set\nseparation: A gradient analysis module quantifies domain shift by comparing the\nL2-norm of gradients from the learned prompts, where known/unknown samples\nexhibit statistically distinct gradient behaviors. Evaluations on Office-Home\nshow that our method consistently outperforms CLIP baseline and standard\nbaseline. Ablation studies confirm the gradient norm's critical role."}
{"id": "2505.13546", "pdf": "https://arxiv.org/pdf/2505.13546", "abs": "https://arxiv.org/abs/2505.13546", "authors": ["Ke Chen", "Yufei Zhou", "Xitong Zhang", "Haohan Wang"], "title": "Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Automatic prompt generation plays a crucial role in enabling general-purpose\nmulti-agent systems to perform diverse tasks autonomously. Existing methods\ntypically evaluate prompts based on their immediate task performance,\noverlooking the intrinsic qualities that determine their reliability. This\noutcome-centric view not only limits interpretability but also fails to account\nfor the inherent stochasticity of large language models (LLMs). In this work,\nwe bring attention to prompt stability-the consistency of model responses\nacross repeated executions-as a key factor for building robust and effective\nprompt generation systems. To quantify this, we propose semantic stability as a\ncriterion for assessing the response consistency of prompts, and fine-tune a\nLLaMA-based evaluator to measure it automatically across tasks. These\ncomponents have enabled us to develop the first stability-aware general-purpose\nprompt generation system that leverages stability feedback to iteratively\nenhance both prompt quality and system-level performance. Furthermore, we\nestablish a logical chain between prompt stability and task success by\nanalyzing the structural dependencies within our system, proving stability as a\nnecessary condition for effective system-level execution. Empirical results\nacross general and domain-specific tasks demonstrate that our stability-aware\nframework improves both accuracy and output consistency. By shifting the focus\nfrom one-off results to persistent reliability, our work offers a new\nperspective on prompt design and contributes practical tools for building more\ntrustworthy general-purpose systems."}
{"id": "2505.11275", "pdf": "https://arxiv.org/pdf/2505.11275", "abs": "https://arxiv.org/abs/2505.11275", "authors": ["Pengju Xu", "Yan Wang", "Shuyuan Zhang", "Xuan Zhou", "Xin Li", "Yue Yuan", "Fengzhao Li", "Shunyuan Zhou", "Xingyu Wang", "Yi Zhang", "Haiying Zhao"], "title": "TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs", "categories": ["cs.MM", "cs.AI", "cs.CY"], "comment": "Preprint", "summary": "Recent progress in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced the ability of artificial intelligence systems to\nunderstand and generate multimodal content. However, these models often exhibit\nlimited effectiveness when applied to non-Western cultural contexts, which\nraises concerns about their wider applicability. To address this limitation, we\npropose the Traditional Chinese Culture understanding Benchmark (TCC-Bench), a\nbilingual (i.e., Chinese and English) Visual Question Answering (VQA) benchmark\nspecifically designed for assessing the understanding of traditional Chinese\nculture by MLLMs. TCC-Bench comprises culturally rich and visually diverse\ndata, incorporating images from museum artifacts, everyday life scenes, comics,\nand other culturally significant contexts. We adopt a semi-automated pipeline\nthat utilizes GPT-4o in text-only mode to generate candidate questions,\nfollowed by human curation to ensure data quality and avoid potential data\nleakage. The benchmark also avoids language bias by preventing direct\ndisclosure of cultural concepts within question texts. Experimental evaluations\nacross a wide range of MLLMs demonstrate that current models still face\nsignificant challenges when reasoning about culturally grounded visual content.\nThe results highlight the need for further research in developing culturally\ninclusive and context-aware multimodal systems. The code and data can be found\nat: https://tcc-bench.github.io/."}
{"id": "2505.13642", "pdf": "https://arxiv.org/pdf/2505.13642", "abs": "https://arxiv.org/abs/2505.13642", "authors": ["Diodato Ferraioli", "Giovanna Varricchio"], "title": "Non-Obvious Manipulability in Additively Separable and Fractional Hedonic Games", "categories": ["cs.GT", "cs.MA"], "comment": "Accepted paper at IJCAI'25", "summary": "In this work, we consider the design of Non-Obviously Manipulable (NOM)\nmechanisms, mechanisms that bounded rational agents may fail to recognize as\nmanipulable, for two relevant classes of succinctly representable Hedonic\nGames: Additively Separable and Fractional Hedonic Games. In these classes,\nagents have cardinal scores towards other agents, and their preferences over\ncoalitions are determined by aggregating such scores. This aggregation results\nin a utility function for each agent, which enables the evaluation of outcomes\nvia the utilitarian social welfare. We first prove that, when scores can be\narbitrary, every optimal mechanism is NOM; moreover, when scores are limited in\na continuous interval, there exists an optimal mechanism that is NOM. Given the\nhardness of computing optimal outcomes in these settings, we turn our attention\nto efficient and NOM mechanisms. To this aim, we first prove a characterization\nof NOM mechanisms that simplifies the class of mechanisms of interest. Then, we\ndesign a NOM mechanism returning approximations that asymptotically match the\nbest-known approximation achievable in polynomial time. Finally, we focus on\ndiscrete scores, where the compatibility of NOM with optimality depends on the\nspecific values. Therefore, we initiate a systematic analysis to identify which\ndiscrete values support this compatibility and which do not."}
{"id": "2505.14142", "pdf": "https://arxiv.org/pdf/2505.14142", "abs": "https://arxiv.org/abs/2505.14142", "authors": ["Gijs Wijngaard", "Elia Formisano", "Michele Esposito", "Michel Dumontier"], "title": "AudSemThinker: Enhancing Audio-Language Models through Reasoning over Semantics of Sound", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Audio-language models have shown promising results in various sound\nunderstanding tasks, yet they remain limited in their ability to reason over\nthe fine-grained semantics of sound. In this paper, we present AudSemThinker, a\nmodel whose reasoning is structured around a framework of auditory semantics\ninspired by human cognition. To support this, we introduce AudSem, a novel\ndataset specifically curated for semantic descriptor reasoning in\naudio-language models. AudSem addresses the persistent challenge of data\ncontamination in zero-shot evaluations by providing a carefully filtered\ncollection of audio samples paired with captions generated through a robust\nmulti-stage pipeline. Our experiments demonstrate that AudSemThinker\noutperforms state-of-the-art models across multiple training settings,\nhighlighting its strength in semantic audio reasoning. Both AudSemThinker and\nthe AudSem dataset are released publicly."}
{"id": "2505.13976", "pdf": "https://arxiv.org/pdf/2505.13976", "abs": "https://arxiv.org/abs/2505.13976", "authors": ["Taewoo Kim", "Guisik Kim", "Choongsang Cho", "Young Han Lee"], "title": "Naturalness-Aware Curriculum Learning with Dynamic Temperature for Speech Deepfake Detection", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by Interspeech 2025", "summary": "Recent advances in speech deepfake detection (SDD) have significantly\nimproved artifacts-based detection in spoofed speech. However, most models\noverlook speech naturalness, a crucial cue for distinguishing bona fide speech\nfrom spoofed speech. This study proposes naturalness-aware curriculum learning,\na novel training framework that leverages speech naturalness to enhance the\nrobustness and generalization of SDD. This approach measures sample difficulty\nusing both ground-truth labels and mean opinion scores, and adjusts the\ntraining schedule to progressively introduce more challenging samples. To\nfurther improve generalization, a dynamic temperature scaling method based on\nspeech naturalness is incorporated into the training process. A 23% relative\nreduction in the EER was achieved in the experiments on the ASVspoof 2021 DF\ndataset, without modifying the model architecture. Ablation studies confirmed\nthe effectiveness of naturalness-aware training strategies for SDD tasks."}
{"id": "2505.14541", "pdf": "https://arxiv.org/pdf/2505.14541", "abs": "https://arxiv.org/abs/2505.14541", "authors": ["Chuanbo Tang", "Zhuoyuan Li", "Yifan Bian", "Li Li", "Dong Liu"], "title": "Neural Video Compression with Context Modulation", "categories": ["eess.IV", "cs.CV"], "comment": "11 pages, 8 figures, accepted by CVPR 2025", "summary": "Efficient video coding is highly dependent on exploiting the temporal\nredundancy, which is usually achieved by extracting and leveraging the temporal\ncontext in the emerging conditional coding-based neural video codec (NVC).\nAlthough the latest NVC has achieved remarkable progress in improving the\ncompression performance, the inherent temporal context propagation mechanism\nlacks the ability to sufficiently leverage the reference information, limiting\nfurther improvement. In this paper, we address the limitation by modulating the\ntemporal context with the reference frame in two steps. Specifically, we first\npropose the flow orientation to mine the inter-correlation between the\nreference frame and prediction frame for generating the additional oriented\ntemporal context. Moreover, we introduce the context compensation to leverage\nthe oriented context to modulate the propagated temporal context generated from\nthe propagated reference feature. Through the synergy mechanism and decoupling\nloss supervision, the irrelevant propagated information can be effectively\neliminated to ensure better context modeling. Experimental results demonstrate\nthat our codec achieves on average 22.7% bitrate reduction over the advanced\ntraditional video codec H.266/VVC, and offers an average 10.1% bitrate saving\nover the previous state-of-the-art NVC DCVC-FM. The code is available at\nhttps://github.com/Austin4USTC/DCMVC."}
{"id": "2505.13554", "pdf": "https://arxiv.org/pdf/2505.13554", "abs": "https://arxiv.org/abs/2505.13554", "authors": ["Zhanglin Wu", "Daimeng Wei", "Xiaoyu Chen", "Hengchao Shang", "Jiaxin Guo", "Zongyao Li", "Yuanchang Luo", "Jinlong Yang", "Zhiqiang Rao", "Hao Yang"], "title": "Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 2 figures, 9 tables, ACL 2025", "summary": "Large language model (LLM) shows promising performances in a variety of\ndownstream tasks, such as machine translation (MT). However, using LLMs for\ntranslation suffers from high computational costs and significant latency.\nBased on our evaluation, in most cases, translations using LLMs are comparable\nto that generated by neural machine translation (NMT) systems. Only in\nparticular scenarios, LLM and NMT models show respective advantages. As a\nresult, integrating NMT and LLM for translation and using LLM only when\nnecessary seems to be a sound solution. A scheduling policy that optimizes\ntranslation result while ensuring fast speed and as little LLM usage as\npossible is thereby required. We compare several scheduling policies and\npropose a novel and straightforward decider that leverages source sentence\nfeatures. We conduct extensive experiments on multilingual test sets and the\nresult shows that we can achieve optimal translation performance with minimal\nLLM usage, demonstrating effectiveness of our decider."}
{"id": "2505.13788", "pdf": "https://arxiv.org/pdf/2505.13788", "abs": "https://arxiv.org/abs/2505.13788", "authors": ["Yongshuo Zong", "Qin Zhang", "Dongsheng An", "Zhihua Li", "Xiang Xu", "Linghan Xu", "Zhuowen Tu", "Yifan Xing", "Onkar Dabeer"], "title": "Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels", "categories": ["cs.CV"], "comment": "Accepted to CVPR'25", "summary": "This work presents a simple yet effective workflow for automatically scaling\ninstruction-following data to elicit pixel-level grounding capabilities of VLMs\nunder complex instructions. In particular, we address five critical real-world\nchallenges in text-instruction-based grounding: hallucinated references,\nmulti-object scenarios, reasoning, multi-granularity, and part-level\nreferences. By leveraging knowledge distillation from a pre-trained teacher\nmodel, our approach generates high-quality instruction-response pairs linked to\nexisting pixel-level annotations, minimizing the need for costly human\nannotation. The resulting dataset, Ground-V, captures rich object localization\nknowledge and nuanced pixel-level referring expressions. Experiment results\nshow that models trained on Ground-V exhibit substantial improvements across\ndiverse grounding tasks. Specifically, incorporating Ground-V during training\ndirectly achieves an average accuracy boost of 4.4% for LISA and a 7.9% for\nPSALM across six benchmarks on the gIoU metric. It also sets new\nstate-of-the-art results on standard benchmarks such as RefCOCO/+/g. Notably,\non gRefCOCO, we achieve an N-Acc of 83.3%, exceeding the previous\nstate-of-the-art by more than 20%."}
{"id": "2505.13510", "pdf": "https://arxiv.org/pdf/2505.13510", "abs": "https://arxiv.org/abs/2505.13510", "authors": ["Conor Rowan", "Alireza Doostan"], "title": "On the definition and importance of interpretability in scientific machine learning", "categories": ["cs.LG", "physics.data-an", "physics.hist-ph", "physics.soc-ph"], "comment": null, "summary": "Though neural networks trained on large data sets have been successfully used\nto describe and predict many physical phenomena, there is a sense among\nscientists that, unlike traditional scientific models, where relationships come\npackaged in the form of simple mathematical expressions, the findings of the\nneural network cannot be integrated into the body of scientific knowledge.\nCritics of ML's inability to produce human-understandable relationships have\nconverged on the concept of \"interpretability\" as its point of departure from\nmore traditional forms of science. As the growing interest in interpretability\nhas shown, researchers in the physical sciences seek not just predictive\nmodels, but also to uncover the fundamental principles that govern a system of\ninterest. However, clarity around a definition of interpretability and the\nprecise role that it plays in science is lacking in the literature. In this\nwork, we argue that researchers in equation discovery and symbolic regression\ntend to conflate the concept of sparsity with interpretability. We review key\npapers on interpretable ML from outside the scientific community and argue\nthat, though the definitions and methods they propose can inform questions of\ninterpretability for SciML, they are inadequate for this new purpose. Noting\nthese deficiencies, we propose an operational definition of interpretability\nfor the physical sciences. Our notion of interpretability emphasizes\nunderstanding of the mechanism over mathematical sparsity. Innocuous though it\nmay seem, this emphasis on mechanism shows that sparsity is often unnecessary.\nIt also questions the possibility of interpretable scientific discovery when\nprior knowledge is lacking. We believe a precise and philosophically informed\ndefinition of interpretability in SciML will help focus research efforts toward\nthe most significant obstacles to realizing a data-driven scientific future."}
{"id": "2505.13551", "pdf": "https://arxiv.org/pdf/2505.13551", "abs": "https://arxiv.org/abs/2505.13551", "authors": ["Serge Dolgikh"], "title": "Counter-Inferential Behavior in Natural and Artificial Cognitive Systems", "categories": ["cs.AI", "cs.NE", "cs.SI", "68T27, 94A15", "F.2.2; I.2.6"], "comment": "23 pages, 3 figures", "summary": "This study explores the emergence of counter-inferential behavior in natural\nand artificial cognitive systems, that is, patterns in which agents\nmisattribute empirical success or suppress adaptation, leading to epistemic\nrigidity or maladaptive stability. We analyze archetypal scenarios in which\nsuch behavior arises: reinforcement of stability through reward imbalance,\nmeta-cognitive attribution of success to internal superiority, and protective\nreframing under perceived model fragility. Rather than arising from noise or\nflawed design, these behaviors emerge through structured interactions between\ninternal information models, empirical feedback, and higher-order evaluation\nmechanisms. Drawing on evidence from artificial systems, biological cognition,\nhuman psychology, and social dynamics, we identify counter-inferential behavior\nas a general cognitive vulnerability that can manifest even in otherwise\nwell-adapted systems. The findings highlight the importance of preserving\nminimal adaptive activation under stable conditions and suggest design\nprinciples for cognitive architectures that can resist rigidity under\ninformational stress."}
{"id": "2410.18322", "pdf": "https://arxiv.org/pdf/2410.18322", "abs": "https://arxiv.org/abs/2410.18322", "authors": ["Myeonghoon Ryu", "Hongseok Oh", "Suji Lee", "Han Park"], "title": "Unified Microphone Conversion: Many-to-Many Device Mapping via Feature-wise Linear Modulation", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "We present Unified Microphone Conversion, a unified generative framework\ndesigned to bolster sound event classification (SEC) systems against device\nvariability. While our prior CycleGAN-based methods effectively simulate device\ncharacteristics, they require separate models for each device pair, limiting\nscalability. Our approach overcomes this constraint by conditioning the\ngenerator on frequency response data, enabling many-to-many device mappings\nthrough unpaired training. We integrate frequency-response information via\nFeature-wise Linear Modulation, further enhancing scalability. Additionally,\nincorporating synthetic frequency response differences improves the\napplicability of our framework for real-world application. Experimental results\nshow that our method outperforms the state-of-the-art by 2.6% and reduces\nvariability by 0.8% in macro-average F1 score."}
{"id": "2505.13773", "pdf": "https://arxiv.org/pdf/2505.13773", "abs": "https://arxiv.org/abs/2505.13773", "authors": ["Ryan Bowers", "Richard Agbeyibor", "Jack Kolb", "Karen Feigh"], "title": "Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": "Submitted to IEEE RO-MAN 2025 (under review). 8 pages, 7 figures", "summary": "We compare three methods of familiarizing a human with an artificial\nintelligence (AI) teammate (\"agent\") prior to operation in a collaborative,\nfast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In\na between-subjects user study (n=60), participants either read documentation\nabout the agent, trained alongside the agent prior to the mission, or were\ngiven no familiarization. Results showed that the most valuable information\nabout the agent included details of its decision-making algorithms and its\nrelative strengths and weaknesses compared to the human. This information\nallowed the familiarization groups to form sophisticated team strategies more\nquickly than the control group. Documentation-based familiarization led to the\nfastest adoption of these strategies, but also biased participants towards\nrisk-averse behavior that prevented high scores. Participants familiarized\nthrough direct interaction were able to infer much of the same information\nthrough observation, and were more willing to take risks and experiment with\ndifferent control modes, but reported weaker understanding of the agent's\ninternal processes. Significant differences were seen between individual\nparticipants' risk tolerance and methods of AI interaction, which should be\nconsidered when designing human-AI control interfaces. Based on our findings,\nwe recommend a human-AI team familiarization method that combines AI\ndocumentation, structured in-situ training, and exploratory interaction."}
{"id": "2505.14188", "pdf": "https://arxiv.org/pdf/2505.14188", "abs": "https://arxiv.org/abs/2505.14188", "authors": ["Viola Negroni", "Davide Salvi", "Paolo Bestagini", "Stefano Tubaro"], "title": "Source Verification for Speech Deepfakes", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted at INTERSPEECH 2025", "summary": "With the proliferation of speech deepfake generators, it becomes crucial not\nonly to assess the authenticity of synthetic audio but also to trace its\norigin. While source attribution models attempt to address this challenge, they\noften struggle in open-set conditions against unseen generators. In this paper,\nwe introduce the source verification task, which, inspired by speaker\nverification, determines whether a test track was produced using the same model\nas a set of reference signals. Our approach leverages embeddings from a\nclassifier trained for source attribution, computing distance scores between\ntracks to assess whether they originate from the same source. We evaluate\nmultiple models across diverse scenarios, analyzing the impact of speaker\ndiversity, language mismatch, and post-processing operations. This work\nprovides the first exploration of source verification, highlighting its\npotential and vulnerabilities, and offers insights for real-world forensic\napplications."}
{"id": "2505.14066", "pdf": "https://arxiv.org/pdf/2505.14066", "abs": "https://arxiv.org/abs/2505.14066", "authors": ["Kuan-Yu Chen", "Jeng-Lin Li", "Jian-Jiun Ding"], "title": "SeamlessEdit: Background Noise Aware Zero-Shot Speech Editing with in-Context Enhancement", "categories": ["eess.AS", "cs.SD", "68T45", "I.2.7; H.5.5"], "comment": "5 pages, 3 figures", "summary": "With the fast development of zero-shot text-to-speech technologies, it is\npossible to generate high-quality speech signals that are indistinguishable\nfrom the real ones. Speech editing, including speech insertion and replacement,\nappeals to researchers due to its potential applications. However, existing\nstudies only considered clean speech scenarios. In real-world applications, the\nexistence of environmental noise could significantly degrade the quality of the\ngeneration. In this study, we propose a noise-resilient speech editing\nframework, SeamlessEdit, for noisy speech editing. SeamlessEdit adopts a\nfrequency-band-aware noise suppression module and an in-content refinement\nstrategy. It can well address the scenario where the frequency bands of voice\nand background noise are not separated. The proposed SeamlessEdit framework\noutperforms state-of-the-art approaches in multiple quantitative and\nqualitative evaluations."}
{"id": "2505.14560", "pdf": "https://arxiv.org/pdf/2505.14560", "abs": "https://arxiv.org/abs/2505.14560", "authors": ["Yuan Gao", "Wenhan Guo", "Yu Sun"], "title": "Neural Inverse Scattering with Score-based Regularization", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Inverse scattering is a fundamental challenge in many imaging applications,\nranging from microscopy to remote sensing. Solving this problem often requires\njointly estimating two unknowns -- the image and the scattering field inside\nthe object -- necessitating effective image prior to regularize the inference.\nIn this paper, we propose a regularized neural field (NF) approach which\nintegrates the denoising score function used in score-based generative models.\nThe neural field formulation offers convenient flexibility to performing joint\nestimation, while the denoising score function imposes the rich structural\nprior of images. Our results on three high-contrast simulated objects show that\nthe proposed approach yields a better imaging quality compared to the\nstate-of-the-art NF approach, where regularization is based on total variation."}
{"id": "2505.13559", "pdf": "https://arxiv.org/pdf/2505.13559", "abs": "https://arxiv.org/abs/2505.13559", "authors": ["Sathya Krishnan Suresh", "Tanmay Surana", "Lim Zhi Hao", "Eng Siong Chng"], "title": "CS-Sum: A Benchmark for Code-Switching Dialogue Summarization and the Limits of Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "17 pages, 5 figures and 11 tables", "summary": "Code-switching (CS) poses a significant challenge for Large Language Models\n(LLMs), yet its comprehensibility remains underexplored in LLMs. We introduce\nCS-Sum, to evaluate the comprehensibility of CS by the LLMs through CS dialogue\nto English summarization. CS-Sum is the first benchmark for CS dialogue\nsummarization across Mandarin-English (EN-ZH), Tamil-English (EN-TA), and\nMalay-English (EN-MS), with 900-1300 human-annotated dialogues per language\npair. Evaluating ten LLMs, including open and closed-source models, we analyze\nperformance across few-shot, translate-summarize, and fine-tuning (LoRA, QLoRA\non synthetic data) approaches. Our findings show that though the scores on\nautomated metrics are high, LLMs make subtle mistakes that alter the complete\nmeaning of the dialogue. To this end, we introduce 3 most common type of errors\nthat LLMs make when handling CS input. Error rates vary across CS pairs and\nLLMs, with some LLMs showing more frequent errors on certain language pairs,\nunderscoring the need for specialized training on code-switched data."}
{"id": "2505.13812", "pdf": "https://arxiv.org/pdf/2505.13812", "abs": "https://arxiv.org/abs/2505.13812", "authors": ["Zhongyu Chen", "Rong Zhao", "Xie Han", "Xindong Guo", "Song Wang", "Zherui Qiao"], "title": "Physics-Driven Local-Whole Elastic Deformation Modeling for Point Cloud Representation Learning", "categories": ["cs.CV"], "comment": null, "summary": "Existing point cloud representation learning tend to learning the geometric\ndistribution of objects through data-driven approaches, emphasizing structural\nfeatures while overlooking the relationship between the local information and\nthe whole structure. Local features reflect the fine-grained variations of an\nobject, while the whole structure is determined by the interaction and\ncombination of these local features, collectively defining the object's shape.\nIn real-world, objects undergo elastic deformation under external forces, and\nthis deformation gradually affects the whole structure through the propagation\nof forces from local regions, thereby altering the object's geometric\nproperties. Inspired by this, we propose a physics-driven self-supervised\nlearning method for point cloud representation, which captures the relationship\nbetween parts and the whole by constructing a local-whole force propagation\nmechanism. Specifically, we employ a dual-task encoder-decoder framework,\nintegrating the geometric modeling capability of implicit fields with\nphysics-driven elastic deformation. The encoder extracts features from the\npoint cloud and its tetrahedral mesh representation, capturing both geometric\nand physical properties. These features are then fed into two decoders: one\nlearns the whole geometric shape of the point cloud through an implicit field,\nwhile the other predicts local deformations using two specifically designed\nphysics information loss functions, modeling the deformation relationship\nbetween local and whole shapes. Experimental results show that our method\noutperforms existing approaches in object classification, few-shot learning,\nand segmentation, demonstrating its effectiveness."}
{"id": "2505.13515", "pdf": "https://arxiv.org/pdf/2505.13515", "abs": "https://arxiv.org/abs/2505.13515", "authors": ["Yanan Li", "Fanxu Meng", "Muhan Zhang", "Shiai Zhu", "Shangguang Wang", "Mengwei Xu"], "title": "LoRASuite: Efficient LoRA Adaptation Across Large Language Model Upgrades", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) are frequently updated, LoRA weights trained\non earlier versions quickly become obsolete. The conventional practice of\nretraining LoRA weights from scratch on the latest model is costly,\ntime-consuming, and environmentally detrimental, particularly as the diversity\nof LLMs and downstream tasks expands. This motivates a critical question: \"How\ncan we efficiently leverage existing LoRA weights to adapt to newer model\nversions?\" To address this, we propose LoRASuite, a modular approach tailored\nspecifically to various types of LLM updates. First, we compute a transfer\nmatrix utilizing known parameters from both old and new LLMs. Next, we allocate\ncorresponding layers and attention heads based on centered kernel alignment and\ncosine similarity metrics, respectively. A subsequent small-scale, skillful\nfine-tuning step ensures numerical stability. Experimental evaluations\ndemonstrate that LoRASuite consistently surpasses small-scale vanilla LoRA\nmethods. Notably, on backbone LLMs such as MiniCPM and Qwen, LoRASuite even\nexceeds the performance of full-scale LoRA retraining, with average\nimprovements of +1.4 and +6.6 points on math tasks, respectively. Additionally,\nLoRASuite significantly reduces memory consumption by 5.5 GB and computational\ntime by 78.23%."}
{"id": "2505.13561", "pdf": "https://arxiv.org/pdf/2505.13561", "abs": "https://arxiv.org/abs/2505.13561", "authors": ["Daniel Rothschild"], "title": "Language and Thought: The View from LLMs", "categories": ["cs.AI"], "comment": "37 Pages", "summary": "Daniel Dennett speculated in *Kinds of Minds* 1996: \"Perhaps the kind of mind\nyou get when you add language to it is so different from the kind of mind you\ncan have without language that calling them both minds is a mistake.\" Recent\nwork in AI can be seen as testing Dennett's thesis by exploring the performance\nof AI systems with and without linguistic training. I argue that the success of\nLarge Language Models at inferential reasoning, limited though it may be,\nsupports Dennett's radical view about the effect of language on thought. I\nsuggest it is the abstractness and efficiency of linguistic encoding that lies\nbehind the capacity of LLMs to perform inferences across a wide range of\ndomains. In a slogan, language makes inference computationally tractable. I\nassess what these results in AI indicate about the role of language in the\nworkings of our own biological minds."}
{"id": "2502.05863", "pdf": "https://arxiv.org/pdf/2502.05863", "abs": "https://arxiv.org/abs/2502.05863", "authors": ["Yanhao Jia", "Xinyi Wu", "Hao Li", "Qinglin Zhang", "Yuxiao Hu", "Shuai Zhao", "Wenqi Fan"], "title": "Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education", "categories": ["cs.IR", "cs.AI", "cs.MM"], "comment": null, "summary": "In AI-facilitated teaching, leveraging various query styles to interpret\nabstract text descriptions is crucial for ensuring high-quality teaching.\nHowever, current retrieval models primarily focus on natural text-image\nretrieval, making them insufficiently tailored to educational scenarios due to\nthe ambiguities in the retrieval process. In this paper, we propose a diverse\nexpression retrieval task tailored to educational scenarios, supporting\nretrieval based on multiple query styles and expressions. We introduce the STEM\nEducation Retrieval Dataset (SER), which contains over 24,000 query pairs of\ndifferent styles, and the Uni-Retrieval, an efficient and style-diversified\nretrieval vision-language model based on prompt tuning. Uni-Retrieval extracts\nquery style features as prototypes and builds a continuously updated Prompt\nBank containing prompt tokens for diverse queries. This bank can updated during\ntest time to represent domain-specific knowledge for different subject\nretrieval scenarios. Our framework demonstrates scalability and robustness by\ndynamically retrieving prompt tokens based on prototype similarity, effectively\nfacilitating learning for unknown queries. Experimental results indicate that\nUni-Retrieval outperforms existing retrieval models in most retrieval tasks.\nThis advancement provides a scalable and precise solution for diverse\neducational needs."}
{"id": "2505.13994", "pdf": "https://arxiv.org/pdf/2505.13994", "abs": "https://arxiv.org/abs/2505.13994", "authors": ["Ruiyi Yang", "Hao Xue", "Imran Razzak", "Hakim Hacid", "Flora D. Salim"], "title": "Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning", "categories": ["cs.AI", "cs.IR", "cs.MA"], "comment": "20 pages, 4 figures", "summary": "Retrieval-Augmented Generation (RAG) systems empower large language models\n(LLMs) with external knowledge, yet struggle with efficiency-accuracy\ntrade-offs when scaling to large knowledge graphs. Existing approaches often\nrely on monolithic graph retrieval, incurring unnecessary latency for simple\nqueries and fragmented reasoning for complex multi-hop questions. To address\nthese challenges, this paper propose SPLIT-RAG, a multi-agent RAG framework\nthat addresses these limitations with question-driven semantic graph\npartitioning and collaborative subgraph retrieval. The innovative framework\nfirst create Semantic Partitioning of Linked Information, then use the\nType-Specialized knowledge base to achieve Multi-Agent RAG. The attribute-aware\ngraph segmentation manages to divide knowledge graphs into semantically\ncoherent subgraphs, ensuring subgraphs align with different query types, while\nlightweight LLM agents are assigned to partitioned subgraphs, and only relevant\npartitions are activated during retrieval, thus reduce search space while\nenhancing efficiency. Finally, a hierarchical merging module resolves\ninconsistencies across subgraph-derived answers through logical verifications.\nExtensive experimental validation demonstrates considerable improvements\ncompared to existing approaches."}
{"id": "2505.14285", "pdf": "https://arxiv.org/pdf/2505.14285", "abs": "https://arxiv.org/abs/2505.14285", "authors": ["Eirini Panteli", "Paulo E. Santos", "Nabil Humphrey"], "title": "AquaSignal: An Integrated Framework for Robust Underwater Acoustic Analysis", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "8 pages; 9 figures", "summary": "This paper presents AquaSignal, a modular and scalable pipeline for\npreprocessing, denoising, classification, and novelty detection of underwater\nacoustic signals. Designed to operate effectively in noisy and dynamic marine\nenvironments, AquaSignal integrates state-of-the-art deep learning\narchitectures to enhance the reliability and accuracy of acoustic signal\nanalysis. The system is evaluated on a combined dataset from the Deepship and\nOcean Networks Canada (ONC) benchmarks, providing a diverse set of real-world\nunderwater scenarios. AquaSignal employs a U-Net architecture for denoising, a\nResNet18 convolutional neural network for classifying known acoustic events,\nand an AutoEncoder-based model for unsupervised detection of novel or anomalous\nsignals. To our knowledge, this is the first comprehensive study to apply and\nevaluate this combination of techniques on maritime vessel acoustic data.\nExperimental results show that AquaSignal improves signal clarity and task\nperformance, achieving 71% classification accuracy and 91% accuracy in novelty\ndetection. Despite slightly lower classification performance compared to some\nstate-of-the-art models, differences in data partitioning strategies limit\ndirect comparisons. Overall, AquaSignal demonstrates strong potential for\nreal-time underwater acoustic monitoring in scientific, environmental, and\nmaritime domains."}
{"id": "2505.14410", "pdf": "https://arxiv.org/pdf/2505.14410", "abs": "https://arxiv.org/abs/2505.14410", "authors": ["Jinzuomu Zhong", "Suyuan Liu", "Dan Wells", "Korin Richmond"], "title": "Pairwise Evaluation of Accent Similarity in Speech Synthesis", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted by INTERSPEECH 2025", "summary": "Despite growing interest in generating high-fidelity accents, evaluating\naccent similarity in speech synthesis has been underexplored. We aim to enhance\nboth subjective and objective evaluation methods for accent similarity.\nSubjectively, we refine the XAB listening test by adding components that\nachieve higher statistical significance with fewer listeners and lower costs.\nOur method involves providing listeners with transcriptions, having them\nhighlight perceived accent differences, and implementing meticulous screening\nfor reliability. Objectively, we utilise pronunciation-related metrics, based\non distances between vowel formants and phonetic posteriorgrams, to evaluate\naccent generation. Comparative experiments reveal that these metrics, alongside\naccent similarity, speaker similarity, and Mel Cepstral Distortion, can be\nused. Moreover, our findings underscore significant limitations of common\nmetrics like Word Error Rate in assessing underrepresented accents."}
{"id": "2505.14572", "pdf": "https://arxiv.org/pdf/2505.14572", "abs": "https://arxiv.org/abs/2505.14572", "authors": ["Jayroop Ramesh", "Valentin Bacher", "Mark C. Eid", "Hoda Kalabizadeh", "Christian Rupprecht", "Ana IL Namburete", "Pak-Hei Yeung", "Madeleine K. Wyburd", "Nicola K. Dinsdale"], "title": "Automated Fetal Biometry Assessment with Deep Ensembles using Sparse-Sampling of 2D Intrapartum Ultrasound Images", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Top 5 in MICCAI IUGC 2024: Intrapartum Ultrasound Grand Challenge &\n  Runners up in Classification!", "summary": "The International Society of Ultrasound advocates Intrapartum Ultrasound (US)\nImaging in Obstetrics and Gynecology (ISUOG) to monitor labour progression\nthrough changes in fetal head position. Two reliable ultrasound-derived\nparameters that are used to predict outcomes of instrumental vaginal delivery\nare the angle of progression (AoP) and head-symphysis distance (HSD). In this\nwork, as part of the Intrapartum Ultrasounds Grand Challenge (IUGC) 2024, we\npropose an automated fetal biometry measurement pipeline to reduce intra- and\ninter-observer variability and improve measurement reliability. Our pipeline\nconsists of three key tasks: (i) classification of standard planes (SP) from US\nvideos, (ii) segmentation of fetal head and pubic symphysis from the detected\nSPs, and (iii) computation of the AoP and HSD from the segmented regions. We\nperform sparse sampling to mitigate class imbalances and reduce spurious\ncorrelations in task (i), and utilize ensemble-based deep learning methods for\ntask (i) and (ii) to enhance generalizability under different US acquisition\nsettings. Finally, to promote robustness in task iii) with respect to the\nstructural fidelity of measurements, we retain the largest connected components\nand apply ellipse fitting to the segmentations. Our solution achieved ACC:\n0.9452, F1: 0.9225, AUC: 0.983, MCC: 0.8361, DSC: 0.918, HD: 19.73, ASD: 5.71,\n$\\Delta_{AoP}$: 8.90 and $\\Delta_{HSD}$: 14.35 across an unseen hold-out set of\n4 patients and 224 US frames. The results from the proposed automated pipeline\ncan improve the understanding of labour arrest causes and guide the development\nof clinical risk stratification tools for efficient and effective prenatal\ncare."}
{"id": "2505.13628", "pdf": "https://arxiv.org/pdf/2505.13628", "abs": "https://arxiv.org/abs/2505.13628", "authors": ["Nathaniel Krasner", "Nicholas Lanuzo", "Antonios Anastasopoulos"], "title": "Cross-Lingual Representation Alignment Through Contrastive Image-Caption Tuning", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Multilingual alignment of sentence representations has mostly required\nbitexts to bridge the gap between languages. We investigate whether visual\ninformation can bridge this gap instead. Image caption datasets are very easy\nto create without requiring multilingual expertise, so this offers a more\nefficient alternative for low-resource languages. We find that multilingual\nimage-caption alignment can implicitly align the text representations between\nlanguages, languages unseen by the encoder in pretraining can be incorporated\ninto this alignment post-hoc, and these aligned representations are usable for\ncross-lingual Natural Language Understanding (NLU) and bitext retrieval."}
{"id": "2505.13817", "pdf": "https://arxiv.org/pdf/2505.13817", "abs": "https://arxiv.org/abs/2505.13817", "authors": ["Feng Li", "Kun Xu", "Zhaoyue Wang", "Yunduan Cui", "Mohammad Masum Billah", "Jia Liu"], "title": "InstanceBEV: Unifying Instance and BEV Representation for Global Modeling", "categories": ["cs.CV"], "comment": null, "summary": "Occupancy Grid Maps are widely used in navigation for their ability to\nrepresent 3D space occupancy. However, existing methods that utilize multi-view\ncameras to construct Occupancy Networks for perception modeling suffer from\ncubic growth in data complexity. Adopting a Bird's-Eye View (BEV) perspective\noffers a more practical solution for autonomous driving, as it provides higher\nsemantic density and mitigates complex object occlusions. Nonetheless,\nBEV-based approaches still require extensive engineering optimizations to\nenable efficient large-scale global modeling. To address this challenge, we\npropose InstanceBEV, the first method to introduce instance-level\ndimensionality reduction for BEV, enabling global modeling with transformers\nwithout relying on sparsification or acceleration operators. Different from\nother BEV methods, our approach directly employs transformers to aggregate\nglobal features. Compared to 3D object detection models, our method samples\nglobal feature maps into 3D space. Experiments on OpenOcc-NuScenes dataset show\nthat InstanceBEV achieves state-of-the-art performance while maintaining a\nsimple, efficient framework without requiring additional optimizations."}
{"id": "2505.13521", "pdf": "https://arxiv.org/pdf/2505.13521", "abs": "https://arxiv.org/abs/2505.13521", "authors": ["Gabor Petnehazi", "Laith Al Shaggah", "Jozsef Gall", "Bernadett Aradi"], "title": "Zero-Shot Forecasting Mortality Rates: A Global Study", "categories": ["cs.LG", "q-fin.RM", "stat.AP"], "comment": null, "summary": "This study explores the potential of zero-shot time series forecasting, an\ninnovative approach leveraging pre-trained foundation models, to forecast\nmortality rates without task-specific fine-tuning. We evaluate two\nstate-of-the-art foundation models, TimesFM and CHRONOS, alongside traditional\nand machine learning-based methods across three forecasting horizons (5, 10,\nand 20 years) using data from 50 countries and 111 age groups. In our\ninvestigations, zero-shot models showed varying results: while CHRONOS\ndelivered competitive shorter-term forecasts, outperforming traditional methods\nlike ARIMA and the Lee-Carter model, TimesFM consistently underperformed.\nFine-tuning CHRONOS on mortality data significantly improved long-term\naccuracy. A Random Forest model, trained on mortality data, achieved the best\noverall performance. These findings underscore the potential of zero-shot\nforecasting while highlighting the need for careful model selection and\ndomain-specific adaptation."}
{"id": "2505.13668", "pdf": "https://arxiv.org/pdf/2505.13668", "abs": "https://arxiv.org/abs/2505.13668", "authors": ["Mahmood Hegazy", "Aaron Rodrigues", "Azzam Naeem"], "title": "MAFA: A multi-agent framework for annotation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Modern applications require accurate and efficient retrieval of information\nin response to user queries. Mapping user utterances to the most relevant\nFrequently Asked Questions (FAQs) is a crucial component of these systems.\nTraditional approaches often rely on a single model or technique, which may not\ncapture the nuances of diverse user inquiries. In this paper, we introduce a\nmulti-agent framework for FAQ annotation that combines multiple specialized\nagents with different approaches and a judge agent that reranks candidates to\nproduce optimal results. Our agents utilize a structured reasoning approach\ninspired by Attentive Reasoning Queries (ARQs), which guides them through\nsystematic reasoning steps using targeted, task-specific JSON queries. Our\nframework features a specialized few-shot example strategy, where each agent\nreceives different few-shots, enhancing ensemble diversity and coverage of the\nquery space. We evaluate our framework on a real-world banking dataset as well\nas public benchmark datasets (LCQMC and FiQA), demonstrating significant\nimprovements over single-agent approaches across multiple metrics, including a\n14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12%\nimprovement in Mean Reciprocal Rank on our dataset, and similar gains on public\nbenchmarks when compared with traditional single agent annotation techniques.\nOur framework is particularly effective at handling ambiguous queries, making\nit well-suited for deployment in production applications while showing strong\ngeneralization capabilities across different domains and languages."}
{"id": "2502.12623", "pdf": "https://arxiv.org/pdf/2502.12623", "abs": "https://arxiv.org/abs/2502.12623", "authors": ["Zhuoyuan Mao", "Mengjie Zhao", "Qiyu Wu", "Hiromi Wakaki", "Yuki Mitsufuji"], "title": "DeepResonance: Enhancing Multimodal Music Understanding via Music-centric Multi-way Instruction Tuning", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM", "eess.AS"], "comment": null, "summary": "Recent advancements in music large language models (LLMs) have significantly\nimproved music understanding tasks, which involve the model's ability to\nanalyze and interpret various musical elements. These improvements primarily\nfocused on integrating both music and text inputs. However, the potential of\nincorporating additional modalities such as images, videos and textual music\nfeatures to enhance music understanding remains unexplored. To bridge this gap,\nwe propose DeepResonance, a multimodal music understanding LLM fine-tuned via\nmulti-way instruction tuning with multi-way aligned music, text, image, and\nvideo data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and\nMusic4way-Any2T, three 4-way training and evaluation datasets designed to\nenable DeepResonance to integrate both visual and textual music feature\ncontent. We also introduce multi-sampled ImageBind embeddings and a pre-LLM\nfusion Transformer to enhance modality fusion prior to input into text LLMs,\ntailoring DeepResonance for multi-way instruction tuning. Our model achieves\nstate-of-the-art performances across six music understanding tasks,\nhighlighting the benefits of the auxiliary modalities and the structural\nsuperiority of DeepResonance. We plan to open-source the models and the newly\nconstructed datasets."}
{"id": "2505.14126", "pdf": "https://arxiv.org/pdf/2505.14126", "abs": "https://arxiv.org/abs/2505.14126", "authors": ["Yuan-Hao Jiang", "Kezong Tang", "Zi-Wei Chen", "Yuang Wei", "Tian-Yi Liu", "Jiayi Wu"], "title": "MAS-KCL: Knowledge component graph structure learning with large language model-based agentic workflow", "categories": ["cs.LG", "cs.CY", "cs.HC", "cs.MA"], "comment": "In CGI 2025: 42nd Computer Graphics International Conference,\n  Kowloon, Hong Kong, Peper No. 134", "summary": "Knowledge components (KCs) are the fundamental units of knowledge in the\nfield of education. A KC graph illustrates the relationships and dependencies\nbetween KCs. An accurate KC graph can assist educators in identifying the root\ncauses of learners' poor performance on specific KCs, thereby enabling targeted\ninstructional interventions. To achieve this, we have developed a KC graph\nstructure learning algorithm, named MAS-KCL, which employs a multi-agent system\ndriven by large language models for adaptive modification and optimization of\nthe KC graph. Additionally, a bidirectional feedback mechanism is integrated\ninto the algorithm, where AI agents leverage this mechanism to assess the value\nof edges within the KC graph and adjust the distribution of generation\nprobabilities for different edges, thereby accelerating the efficiency of\nstructure learning. We applied the proposed algorithm to 5 synthetic datasets\nand 4 real-world educational datasets, and experimental results validate its\neffectiveness in learning path recognition. By accurately identifying learners'\nlearning paths, teachers are able to design more comprehensive learning plans,\nenabling learners to achieve their educational goals more effectively, thus\npromoting the sustainable development of education."}
{"id": "2505.14351", "pdf": "https://arxiv.org/pdf/2505.14351", "abs": "https://arxiv.org/abs/2505.14351", "authors": ["Yutong Liu", "Ziyue Zhang", "Ban Ma-bao", "Yuqing Cai", "Yongbin Yu", "Renzeng Duojie", "Xiangxiang Wang", "Fan Gao", "Cheng Huang", "Nyima Tashi"], "title": "FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis for √ú-Tsang, Amdo and Kham Speech Dataset Generation", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "13 pages", "summary": "Tibetan is a low-resource language with minimal parallel speech corpora\nspanning its three major dialects-\\\"U-Tsang, Amdo, and Kham-limiting progress\nin speech modeling. To address this issue, we propose FMSD-TTS, a few-shot,\nmulti-speaker, multi-dialect text-to-speech framework that synthesizes parallel\ndialectal speech from limited reference audio and explicit dialect labels. Our\nmethod features a novel speaker-dialect fusion module and a Dialect-Specialized\nDynamic Routing Network (DSDR-Net) to capture fine-grained acoustic and\nlinguistic variations across dialects while preserving speaker identity.\nExtensive objective and subjective evaluations demonstrate that FMSD-TTS\nsignificantly outperforms baselines in both dialectal expressiveness and\nspeaker similarity. We further validate the quality and utility of the\nsynthesized speech through a challenging speech-to-speech dialect conversion\ntask. Our contributions include: (1) a novel few-shot TTS system tailored for\nTibetan multi-dialect speech synthesis, (2) the public release of a large-scale\nsynthetic Tibetan speech corpus generated by FMSD-TTS, and (3) an open-source\nevaluation toolkit for standardized assessment of speaker similarity, dialect\nconsistency, and audio quality."}
{"id": "2505.14433", "pdf": "https://arxiv.org/pdf/2505.14433", "abs": "https://arxiv.org/abs/2505.14433", "authors": ["Runwu Shi", "Zirui Lin", "Benjamin Yen", "Jiang Wang", "Ragib Amin Nihal", "Kazuhiro Nakadai"], "title": "Single-Channel Target Speech Extraction Utilizing Distance and Room Clues", "categories": ["eess.AS", "cs.SD"], "comment": "5 pages, 3 figures, accepted by Eusipco 2025", "summary": "This paper aims to achieve single-channel target speech extraction (TSE) in\nenclosures utilizing distance clues and room information. Recent works have\nverified the feasibility of distance clues for the TSE task, which can imply\nthe sound source's direct-to-reverberation ratio (DRR) and thus can be utilized\nfor speech separation and TSE systems. However, such distance clue is\nsignificantly influenced by the room's acoustic characteristics, such as\ndimension and reverberation time, making it challenging for TSE systems that\nrely solely on distance clues to generalize across a variety of different\nrooms. To solve this, we suggest providing room environmental information (room\ndimensions and reverberation time) for distance-based TSE for better\ngeneralization capabilities. Especially, we propose a distance and\nenvironment-based TSE model in the time-frequency (TF) domain with learnable\ndistance and room embedding. Results on both simulated and real collected\ndatasets demonstrate its feasibility. Demonstration materials are available at\nhttps://runwushi.github.io/distance-room-demo-page/."}
{"id": "2505.13915", "pdf": "https://arxiv.org/pdf/2505.13915", "abs": "https://arxiv.org/abs/2505.13915", "authors": ["Chu Chen", "Kangning Cui", "Pasquale Cascarano", "Wei Tang", "Elena Loli Piccolomini", "Raymond H. Chan"], "title": "Blind Restoration of High-Resolution Ultrasound Video", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Ultrasound imaging is widely applied in clinical practice, yet ultrasound\nvideos often suffer from low signal-to-noise ratios (SNR) and limited\nresolutions, posing challenges for diagnosis and analysis. Variations in\nequipment and acquisition settings can further exacerbate differences in data\ndistribution and noise levels, reducing the generalizability of pre-trained\nmodels. This work presents a self-supervised ultrasound video super-resolution\nalgorithm called Deep Ultrasound Prior (DUP). DUP employs a video-adaptive\noptimization process of a neural network that enhances the resolution of given\nultrasound videos without requiring paired training data while simultaneously\nremoving noise. Quantitative and visual evaluations demonstrate that DUP\noutperforms existing super-resolution algorithms, leading to substantial\nimprovements for downstream applications."}
{"id": "2505.13657", "pdf": "https://arxiv.org/pdf/2505.13657", "abs": "https://arxiv.org/abs/2505.13657", "authors": ["Charles J. Torres", "Richard Futrell"], "title": "Clarifying orthography: Orthographic transparency as compressibility", "categories": ["cs.CL", "cs.IT", "math.IT"], "comment": null, "summary": "Orthographic transparency -- how directly spelling is related to sound --\nlacks a unified, script-agnostic metric. Using ideas from algorithmic\ninformation theory, we quantify orthographic transparency in terms of the\nmutual compressibility between orthographic and phonological strings. Our\nmeasure provides a principled way to combine two factors that decrease\northographic transparency, capturing both irregular spellings and rule\ncomplexity in one quantity. We estimate our transparency measure using\nprequential code-lengths derived from neural sequence models. Evaluating 22\nlanguages across a broad range of script types (alphabetic, abjad, abugida,\nsyllabic, logographic) confirms common intuitions about relative transparency\nof scripts. Mutual compressibility offers a simple, principled, and general\nyardstick for orthographic transparency."}
{"id": "2505.13839", "pdf": "https://arxiv.org/pdf/2505.13839", "abs": "https://arxiv.org/abs/2505.13839", "authors": ["Zhenyu Bao", "Qing Li", "Guibiao Liao", "Zhongyuan Zhao", "Kanglin Liu"], "title": "MGStream: Motion-aware 3D Gaussian for Streamable Dynamic Scene Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has gained significant attention in streamable\ndynamic novel view synthesis (DNVS) for its photorealistic rendering capability\nand computational efficiency. Despite much progress in improving rendering\nquality and optimization strategies, 3DGS-based streamable dynamic scene\nreconstruction still suffers from flickering artifacts and storage\ninefficiency, and struggles to model the emerging objects. To tackle this, we\nintroduce MGStream which employs the motion-related 3D Gaussians (3DGs) to\nreconstruct the dynamic and the vanilla 3DGs for the static. The motion-related\n3DGs are implemented according to the motion mask and the clustering-based\nconvex hull algorithm. The rigid deformation is applied to the motion-related\n3DGs for modeling the dynamic, and the attention-based optimization on the\nmotion-related 3DGs enables the reconstruction of the emerging objects. As the\ndeformation and optimization are only conducted on the motion-related 3DGs,\nMGStream avoids flickering artifacts and improves the storage efficiency.\nExtensive experiments on real-world datasets N3DV and MeetRoom demonstrate that\nMGStream surpasses existing streaming 3DGS-based approaches in terms of\nrendering quality, training/storage efficiency and temporal consistency. Our\ncode is available at: https://github.com/pcl3dv/MGStream."}
{"id": "2505.13544", "pdf": "https://arxiv.org/pdf/2505.13544", "abs": "https://arxiv.org/abs/2505.13544", "authors": ["Keqi Deng", "Philip C. Woodland"], "title": "Multi-head Temporal Latent Attention", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While Transformer self-attention offers strong parallelism, the Key-Value\n(KV) cache grows linearly with sequence length and becomes a bottleneck for\ninference efficiency. Multi-head latent attention was recently developed to\ncompress the KV cache into a low-rank latent space. This paper proposes\nMulti-head Temporal Latent Attention (MTLA), which further reduces the KV cache\nsize along the temporal dimension, greatly lowering the memory footprint of\nself-attention inference. MTLA employs a hyper-network to dynamically merge\ntemporally adjacent KV cache vectors. To address the mismatch between the\ncompressed KV cache and processed sequence lengths, a stride-aware causal mask\nis proposed to ensure efficient parallel training and consistency with\ninference behaviour. Experiments across tasks, including speech translation,\nspeech recognition, speech understanding and text summarisation, demonstrate\nthat MTLA achieves competitive performance compared to standard Multi-Head\nAttention (MHA), while greatly improving inference speed and GPU memory usage.\nFor example, on a English-German speech translation task, MTLA achieves a 5.3x\nspeedup and a reduction in GPU memory usage by a factor of 8.3 compared to MHA,\nwhile maintaining translation quality."}
{"id": "2505.13672", "pdf": "https://arxiv.org/pdf/2505.13672", "abs": "https://arxiv.org/abs/2505.13672", "authors": ["Giannis Chatziveroglou"], "title": "A*-Decoding: Token-Efficient Inference Scaling", "categories": ["cs.AI"], "comment": null, "summary": "Inference-time scaling has emerged as a powerful alternative to parameter\nscaling for improving language model performance on complex reasoning tasks.\nWhile existing methods have shown strong performance gains under fixed compute\nbudgets, there has been little focus on optimally utilizing that budget during\ninference. In this work, we introduce A*-decoding, a search-based\ninference-time strategy that builds on the A* search algorithm to optimally\nutilize a fixed compute budget by prioritizing high-quality reasoning paths\nduring generation. We frame language model decoding as a structured search in a\nstate space of partial solutions, applying the A* transition model to identify\npromising continuations guided by an external process supervision signal. In\nour experiments, A*-decoding reaches the performance levels of strong inference\nscaling baselines like best-of-N and particle filtering while using up to 3x\nfewer tokens and 30% fewer PRM passes under equivalent compute budgets. On the\nMATH500 and AIME 2024 benchmarks, A*-decoding enables Llama-3.2-1B-Instruct to\nmatch the performance of the 70x larger Llama-3.1-70B-Instruct, and allows\nQwen3-1.7B to reach o1-like reasoning accuracy. These results highlight the\npower of structured search in decoding, offering an alternative to brute-force\nsampling or scale-driven gains. Our work demonstrates how thoughtful\ninference-time strategies can enhance reasoning in SLMs, pointing toward future\nadvances in more efficient and scalable language model deployment."}
{"id": "2503.06442", "pdf": "https://arxiv.org/pdf/2503.06442", "abs": "https://arxiv.org/abs/2503.06442", "authors": ["Yu Liu", "Hao Tang", "Haiqi Zhang", "Jing Qin", "Zechao Li"], "title": "OT-DETECTOR: Delving into Optimal Transport for Zero-shot Out-of-Distribution Detection", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted to the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)", "summary": "Out-of-distribution (OOD) detection is crucial for ensuring the reliability\nand safety of machine learning models in real-world applications. While\nzero-shot OOD detection, which requires no training on in-distribution (ID)\ndata, has become feasible with the emergence of vision-language models like\nCLIP, existing methods primarily focus on semantic matching and fail to fully\ncapture distributional discrepancies. To address these limitations, we propose\nOT-DETECTOR, a novel framework that employs Optimal Transport (OT) to quantify\nboth semantic and distributional discrepancies between test samples and ID\nlabels. Specifically, we introduce cross-modal transport mass and transport\ncost as semantic-wise and distribution-wise OOD scores, respectively, enabling\nmore robust detection of OOD samples. Additionally, we present a semantic-aware\ncontent refinement (SaCR) module, which utilizes semantic cues from ID labels\nto amplify the distributional discrepancy between ID and hard OOD samples.\nExtensive experiments on several benchmarks demonstrate that OT-DETECTOR\nachieves state-of-the-art performance across various OOD detection tasks,\nparticularly in challenging hard-OOD scenarios."}
{"id": "2505.14349", "pdf": "https://arxiv.org/pdf/2505.14349", "abs": "https://arxiv.org/abs/2505.14349", "authors": ["Evangelos Pournaras", "Srijoni Majumdar", "Thomas Wellings", "Joshua C. Yang", "Fatemeh B. Heravan", "Regula H√§nggli Fricker", "Dirk Helbing"], "title": "Upgrading Democracies with Fairer Voting Methods", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC", "cs.MA"], "comment": "Includes Supplementary Information", "summary": "Voting methods are instrumental design element of democracies. Citizens use\nthem to express and aggregate their preferences to reach a collective decision.\nHowever, voting outcomes can be as sensitive to voting rules as they are to\npeople's voting choices. Despite the significance and inter-disciplinary\nscientific progress on voting methods, several democracies keep relying on\noutdated voting methods that do not fit modern, pluralistic societies well,\nwhile lacking social innovation. Here, we demonstrate how one can upgrade\nreal-world democracies, namely by using alternative preferential voting methods\nsuch as cumulative voting and the method of equal shares designed for a\nproportional representation of voters' preferences. By rigorously assessing a\nnew participatory budgeting approach applied in the city of Aarau, Switzerland,\nwe unravel the striking voting outcomes of fair voting methods: more winning\nprojects with the same budget and broader geographic and preference\nrepresentation of citizens by the elected projects, in particular for voters\nwho used to be under-represented, while promoting novel project ideas. We\nprovide profound causal evidence showing that citizens prefer proportional\nvoting methods, which possess strong legitimacy without the need of very\ntechnical specialized explanations. We also reveal strong underlying democratic\nvalues exhibited by citizens who support fair voting methods such as altruism\nand compromise. These findings come with a global momentum to unleash a new and\nlong-awaited participation blueprint of how to upgrade democracies."}
{"id": "2505.14356", "pdf": "https://arxiv.org/pdf/2505.14356", "abs": "https://arxiv.org/abs/2505.14356", "authors": ["Sho Inoue", "Shai Wang", "Haizhou Li"], "title": "PersonaTAB: Predicting Personality Traits using Textual, Acoustic, and Behavioral Cues in Fully-Duplex Speech Dialogs", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "This is accepted to Interspeech 2025; Added an extra page for\n  supplementary figures; Project page:\n  https://github.com/shinshoji01/Personality-Prediction-for-Conversation-Agents", "summary": "Despite significant progress in neural spoken dialog systems,\npersonality-aware conversation agents -- capable of adapting behavior based on\npersonalities -- remain underexplored due to the absence of personality\nannotations in speech datasets. We propose a pipeline that preprocesses raw\naudio recordings to create a dialogue dataset annotated with timestamps,\nresponse types, and emotion/sentiment labels. We employ an automatic speech\nrecognition (ASR) system to extract transcripts and timestamps, then generate\nconversation-level annotations. Leveraging these annotations, we design a\nsystem that employs large language models to predict conversational\npersonality. Human evaluators were engaged to identify conversational\ncharacteristics and assign personality labels. Our analysis demonstrates that\nthe proposed system achieves stronger alignment with human judgments compared\nto existing approaches."}
{"id": "2505.14449", "pdf": "https://arxiv.org/pdf/2505.14449", "abs": "https://arxiv.org/abs/2505.14449", "authors": ["Yi-Cheng Lin", "Huang-Cheng Chou", "Hung-yi Lee"], "title": "Mitigating Subgroup Disparities in Multi-Label Speech Emotion Recognition: A Pseudo-Labeling and Unsupervised Learning Approach", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted by InterSpeech 2025. 7 pages including 2 pages of appendix", "summary": "While subgroup disparities and performance bias are increasingly studied in\ncomputational research, fairness in categorical Speech Emotion Recognition\n(SER) remains underexplored. Existing methods often rely on explicit\ndemographic labels, which are difficult to obtain due to privacy concerns. To\naddress this limitation, we introduce an Implicit Demography Inference (IDI)\nmodule that leverages pseudo-labeling from a pre-trained model and unsupervised\nlearning using k-means clustering to mitigate bias in SER. Our experiments show\nthat pseudo-labeling IDI reduces subgroup disparities, improving fairness\nmetrics by over 33% with less than a 3% decrease in SER accuracy. Also, the\nunsupervised IDI yields more than a 26% improvement in fairness metrics with a\ndrop of less than 4% in SER performance. Further analyses reveal that the\nunsupervised IDI consistently mitigates race and age disparities, demonstrating\nits potential in scenarios where explicit demographic information is\nunavailable."}
{"id": "2505.14296", "pdf": "https://arxiv.org/pdf/2505.14296", "abs": "https://arxiv.org/abs/2505.14296", "authors": ["Abdul-Kazeem Shamba"], "title": "Towards Generating Realistic Underwater Images", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "This paper explores the use of contrastive learning and generative\nadversarial networks for generating realistic underwater images from synthetic\nimages with uniform lighting. We investigate the performance of image\ntranslation models for generating realistic underwater images using the VAROS\ndataset. Two key evaluation metrics, Fr\\'echet Inception Distance (FID) and\nStructural Similarity Index Measure (SSIM), provide insights into the\ntrade-offs between perceptual quality and structural preservation. For paired\nimage translation, pix2pix achieves the best FID scores due to its paired\nsupervision and PatchGAN discriminator, while the autoencoder model attains the\nhighest SSIM, suggesting better structural fidelity despite producing blurrier\noutputs. Among unpaired methods, CycleGAN achieves a competitive FID score by\nleveraging cycle-consistency loss, whereas CUT, which replaces\ncycle-consistency with contrastive learning, attains higher SSIM, indicating\nimproved spatial similarity retention. Notably, incorporating depth information\ninto CUT results in the lowest overall FID score, demonstrating that depth cues\nenhance realism. However, the slight decrease in SSIM suggests that depth-aware\nlearning may introduce structural variations."}
{"id": "2505.13706", "pdf": "https://arxiv.org/pdf/2505.13706", "abs": "https://arxiv.org/abs/2505.13706", "authors": ["Julia Jose", "Rachel Greenstadt"], "title": "Are Large Language Models Good at Detecting Propaganda?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Propagandists use rhetorical devices that rely on logical fallacies and\nemotional appeals to advance their agendas. Recognizing these techniques is key\nto making informed decisions. Recent advances in Natural Language Processing\n(NLP) have enabled the development of systems capable of detecting manipulative\ncontent. In this study, we look at several Large Language Models and their\nperformance in detecting propaganda techniques in news articles. We compare the\nperformance of these LLMs with transformer-based models. We find that, while\nGPT-4 demonstrates superior F1 scores (F1=0.16) compared to GPT-3.5 and Claude\n3 Opus, it does not outperform a RoBERTa-CRF baseline (F1=0.67). Additionally,\nwe find that all three LLMs outperform a MultiGranularity Network (MGN)\nbaseline in detecting instances of one out of six propaganda techniques\n(name-calling), with GPT-3.5 and GPT-4 also outperforming the MGN baseline in\ndetecting instances of appeal to fear and flag-waving."}
{"id": "2505.13856", "pdf": "https://arxiv.org/pdf/2505.13856", "abs": "https://arxiv.org/abs/2505.13856", "authors": ["Ruqin Zhou", "San Jiang", "Wanshou Jiang", "Yongsheng Zhang", "Chenguang Dai"], "title": "SuperMapNet for Long-Range and High-Accuracy Vectorized HD Map Construction", "categories": ["cs.CV"], "comment": "13 pages, 9 figures", "summary": "Vectorized HD map is essential for autonomous driving. Remarkable work has\nbeen achieved in recent years, but there are still major issues: (1) in the\ngeneration of the BEV features, single modality-based methods are of limited\nperception capability, while direct concatenation-based multi-modal methods\nfail to capture synergies and disparities between different modalities,\nresulting in limited ranges with feature holes; (2) in the classification and\nlocalization of map elements, only point information is used without the\nconsideration of element infor-mation and neglects the interaction between\npoint information and element information, leading to erroneous shapes and\nelement entanglement with low accuracy. To address above issues, we introduce\nSuperMapNet for long-range and high-accuracy vectorized HD map construction. It\nuses both camera images and LiDAR point clouds as input, and first tightly\ncouple semantic information from camera images and geometric information from\nLiDAR point clouds by a cross-attention based synergy enhancement module and a\nflow-based disparity alignment module for long-range BEV feature generation.\nAnd then, local features from point queries and global features from element\nqueries are tightly coupled by three-level interactions for high-accuracy\nclassification and localization, where Point2Point interaction learns local\ngeometric information between points of the same element and of each point,\nElement2Element interaction learns relation constraints between different\nelements and semantic information of each elements, and Point2Element\ninteraction learns complement element information for its constituent points.\nExperiments on the nuScenes and Argoverse2 datasets demonstrate superior\nperformances, surpassing SOTAs over 14.9/8.8 mAP and 18.5/3.1 mAP under\nhard/easy settings, respectively. The code is made publicly available1."}
{"id": "2505.13547", "pdf": "https://arxiv.org/pdf/2505.13547", "abs": "https://arxiv.org/abs/2505.13547", "authors": ["Pengxin Guo", "Yinong Wang", "Wei Li", "Mengting Liu", "Ming Li", "Jinkai Zheng", "Liangqiong Qu"], "title": "Exploring Federated Pruning for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "LLM pruning has emerged as a promising technology for compressing LLMs,\nenabling their deployment on resource-limited devices. However, current\nmethodologies typically require access to public calibration samples, which can\nbe challenging to obtain in privacy-sensitive domains. To address this issue,\nwe introduce FedPrLLM, a comprehensive federated pruning framework designed for\nthe privacy-preserving compression of LLMs. In FedPrLLM, each client only needs\nto calculate a pruning mask matrix based on its local calibration data and\nshare it with the server to prune the global model. This approach allows for\ncollaborative pruning of the global model with the knowledge of each client\nwhile maintaining local data privacy. Additionally, we conduct extensive\nexperiments to explore various possibilities within the FedPrLLM framework,\nincluding different comparison groups, pruning strategies, and the decision to\nscale weights. Our extensive evaluation reveals that one-shot pruning with\nlayer comparison and no weight scaling is the optimal choice within the\nFedPrLLM framework. We hope our work will help guide future efforts in pruning\nLLMs in privacy-sensitive fields. Our code is available at\nhttps://github.com/Pengxin-Guo/FedPrLLM."}
{"id": "2505.13696", "pdf": "https://arxiv.org/pdf/2505.13696", "abs": "https://arxiv.org/abs/2505.13696", "authors": ["Zizhan He", "Maxime Daigle", "Pouya Bashivan"], "title": "Building spatial world models from sparse transitional episodic memories", "categories": ["cs.AI"], "comment": null, "summary": "Many animals possess a remarkable capacity to rapidly construct flexible\nmental models of their environments. These world models are crucial for\nethologically relevant behaviors such as navigation, exploration, and planning.\nThe ability to form episodic memories and make inferences based on these sparse\nexperiences is believed to underpin the efficiency and adaptability of these\nmodels in the brain. Here, we ask: Can a neural network learn to construct a\nspatial model of its surroundings from sparse and disjoint episodic memories?\nWe formulate the problem in a simulated world and propose a novel framework,\nthe Episodic Spatial World Model (ESWM), as a potential answer. We show that\nESWM is highly sample-efficient, requiring minimal observations to construct a\nrobust representation of the environment. It is also inherently adaptive,\nallowing for rapid updates when the environment changes. In addition, we\ndemonstrate that ESWM readily enables near-optimal strategies for exploring\nnovel environments and navigating between arbitrary points, all without the\nneed for additional training."}
{"id": "2505.06149", "pdf": "https://arxiv.org/pdf/2505.06149", "abs": "https://arxiv.org/abs/2505.06149", "authors": ["Faeze Ghorbanpour", "Daryna Dementieva", "Alexander Fraser"], "title": "Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study", "categories": ["cs.CL", "cs.CY", "cs.MM"], "comment": null, "summary": "Despite growing interest in automated hate speech detection, most existing\napproaches overlook the linguistic diversity of online content. Multilingual\ninstruction-tuned large language models such as LLaMA, Aya, Qwen, and BloomZ\noffer promising capabilities across languages, but their effectiveness in\nidentifying hate speech through zero-shot and few-shot prompting remains\nunderexplored. This work evaluates LLM prompting-based detection across eight\nnon-English languages, utilizing several prompting techniques and comparing\nthem to fine-tuned encoder models. We show that while zero-shot and few-shot\nprompting lag behind fine-tuned encoder models on most of the real-world\nevaluation sets, they achieve better generalization on functional tests for\nhate speech detection. Our study also reveals that prompt design plays a\ncritical role, with each language often requiring customized prompting\ntechniques to maximize performance."}
{"id": "2505.14544", "pdf": "https://arxiv.org/pdf/2505.14544", "abs": "https://arxiv.org/abs/2505.14544", "authors": ["Saahil Mahato"], "title": "Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Urban traffic congestion, particularly at intersections, significantly\nimpacts travel time, fuel consumption, and emissions. Traditional fixed-time\nsignal control systems often lack the adaptability to manage dynamic traffic\npatterns effectively. This study explores the application of multi-agent\nreinforcement learning (MARL) to optimize traffic signal coordination across\nmultiple intersections within a simulated environment. Utilizing Pygame, a\nsimulation was developed to model a network of interconnected intersections\nwith randomly generated vehicle flows to reflect realistic traffic variability.\nA decentralized MARL controller was implemented, in which each traffic signal\noperates as an autonomous agent, making decisions based on local observations\nand information from neighboring agents. Performance was evaluated against a\nbaseline fixed-time controller using metrics such as average vehicle wait time\nand overall throughput. The MARL approach demonstrated statistically\nsignificant improvements, including reduced average waiting times and improved\nthroughput. These findings suggest that MARL-based dynamic control strategies\nhold substantial promise for improving urban traffic management efficiency.\nMore research is recommended to address scalability and real-world\nimplementation challenges."}
{"id": "2505.14438", "pdf": "https://arxiv.org/pdf/2505.14438", "abs": "https://arxiv.org/abs/2505.14438", "authors": ["Yuanbo Fang", "Haoze Sun", "Jun Liu", "Tao Zhang", "Zenan Zhou", "Weipeng Chen", "Xiaofen Xing", "Xiangmin Xu"], "title": "S2SBench: A Benchmark for Quantifying Intelligence Degradation in Speech-to-Speech Large Language Models", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "End-to-end speech large language models ((LLMs)) extend the capabilities of\ntext-based models to directly process and generate audio tokens. However, this\noften leads to a decline in reasoning and generation performance compared to\ntext input, a phenomenon referred to as intelligence degradation. To\nsystematically evaluate this gap, we propose S2SBench, a benchmark designed to\nquantify performance degradation in Speech LLMs. It includes diagnostic\ndatasets targeting sentence continuation and commonsense reasoning under audio\ninput. We further introduce a pairwise evaluation protocol based on perplexity\ndifferences between plausible and implausible samples to measure degradation\nrelative to text input. We apply S2SBench to analyze the training process of\nBaichuan-Audio, which further demonstrates the benchmark's effectiveness. All\ndatasets and evaluation code are available at\nhttps://github.com/undobug/S2SBench."}
{"id": "2505.14465", "pdf": "https://arxiv.org/pdf/2505.14465", "abs": "https://arxiv.org/abs/2505.14465", "authors": ["Aviv Navon", "Aviv Shamsian", "Yael Segal-Feldman", "Neta Glazer", "Gil Hetz", "Joseph Keshet"], "title": "FlowTSE: Target Speaker Extraction with Flow Matching", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "InterSpeech 2025", "summary": "Target speaker extraction (TSE) aims to isolate a specific speaker's speech\nfrom a mixture using speaker enrollment as a reference. While most existing\napproaches are discriminative, recent generative methods for TSE achieve strong\nresults. However, generative methods for TSE remain underexplored, with most\nexisting approaches relying on complex pipelines and pretrained components,\nleading to computational overhead. In this work, we present FlowTSE, a simple\nyet effective TSE approach based on conditional flow matching. Our model\nreceives an enrollment audio sample and a mixed speech signal, both represented\nas mel-spectrograms, with the objective of extracting the target speaker's\nclean speech. Furthermore, for tasks where phase reconstruction is crucial, we\npropose a novel vocoder conditioned on the complex STFT of the mixed signal,\nenabling improved phase estimation. Experimental results on standard TSE\nbenchmarks show that FlowTSE matches or outperforms strong baselines."}
{"id": "2505.14634", "pdf": "https://arxiv.org/pdf/2505.14634", "abs": "https://arxiv.org/abs/2505.14634", "authors": ["Gokul Bhusal", "Yifei Lou", "Cristina Garcia-Cardona", "Ekaterina Merkurjev"], "title": "A General Framework for Group Sparsity in Hyperspectral Unmixing Using Endmember Bundles", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Due to low spatial resolution, hyperspectral data often consists of mixtures\nof contributions from multiple materials. This limitation motivates the task of\nhyperspectral unmixing (HU), a fundamental problem in hyperspectral imaging. HU\naims to identify the spectral signatures (\\textit{endmembers}) of the materials\npresent in an observed scene, along with their relative proportions\n(\\textit{fractional abundance}) in each pixel. A major challenge lies in the\nclass variability in materials, which hinders accurate representation by a\nsingle spectral signature, as assumed in the conventional linear mixing model.\nMoreover, To address this issue, we propose using group sparsity after\nrepresenting each material with a set of spectral signatures, known as\nendmember bundles, where each group corresponds to a specific material. In\nparticular, we develop a bundle-based framework that can enforce either\ninter-group sparsity or sparsity within and across groups (SWAG) on the\nabundance coefficients. Furthermore, our framework offers the flexibility to\nincorporate a variety of sparsity-promoting penalties, among which the\ntransformed $\\ell_1$ (TL1) penalty is a novel regularization in the HU\nliterature. Extensive experiments conducted on both synthetic and real\nhyperspectral data demonstrate the effectiveness and superiority of the\nproposed approaches."}
{"id": "2505.13725", "pdf": "https://arxiv.org/pdf/2505.13725", "abs": "https://arxiv.org/abs/2505.13725", "authors": ["Yu Guo", "Dong Jin", "Shenghao Ye", "Shuangwu Chen", "Jian Yang", "Xiaobin Tan"], "title": "SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs", "categories": ["cs.CL"], "comment": "12 pages, 7 figures, accepted to ACL Findings 2025", "summary": "Large Language models (LLMs) have demonstrated significant potential in\ntext-to-SQL reasoning tasks, yet a substantial performance gap persists between\nexisting open-source models and their closed-source counterparts. In this\npaper, we introduce SQLForge, a novel approach for synthesizing reliable and\ndiverse data to enhance text-to-SQL reasoning in LLMs. We improve data\nreliability through SQL syntax constraints and SQL-to-question reverse\ntranslation, ensuring data logic at both structural and semantic levels. We\nalso propose an SQL template enrichment and iterative data domain exploration\nmechanism to boost data diversity. Building on the augmented data, we fine-tune\na variety of open-source models with different architectures and parameter\nsizes, resulting in a family of models termed SQLForge-LM. SQLForge-LM achieves\nthe state-of-the-art performance on the widely recognized Spider and BIRD\nbenchmarks among the open-source models. Specifically, SQLForge-LM achieves EX\naccuracy of 85.7% on Spider Dev and 59.8% on BIRD Dev, significantly narrowing\nthe performance gap with closed-source methods."}
{"id": "2505.13860", "pdf": "https://arxiv.org/pdf/2505.13860", "abs": "https://arxiv.org/abs/2505.13860", "authors": ["Tiancheng Jiang", "Henry Wang", "Md Sirajus Salekin", "Parmida Atighehchian", "Shinan Zhang"], "title": "Domain Adaptation of VLM for Soccer Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 5 figures, accepted to the 11th IEEE International Workshop\n  on Computer Vision in Sports (CVSports) at CVPR 2025; supplementary appendix\n  included as ancillary PDF", "summary": "Vision Language Models (VLMs) have demonstrated strong performance in\nmulti-modal tasks by effectively aligning visual and textual representations.\nHowever, most video understanding VLM research has been domain-agnostic,\nleaving the understanding of their transfer learning capability to specialized\ndomains under-explored. In this work, we address this by exploring the\nadaptability of open-source VLMs to specific domains, and focusing on soccer as\nan initial case study. Our approach uses large-scale soccer datasets and LLM to\ncreate instruction-following data, and use them to iteratively fine-tune the\ngeneral-domain VLM in a curriculum learning fashion (first teaching the model\nkey soccer concepts to then question answering tasks). The final adapted model,\ntrained using a curated dataset of 20k video clips, exhibits significant\nimprovement in soccer-specific tasks compared to the base model, with a 37.5%\nrelative improvement for the visual question-answering task and an accuracy\nimprovement from 11.8% to 63.5% for the downstream soccer action classification\ntask."}
{"id": "2505.13563", "pdf": "https://arxiv.org/pdf/2505.13563", "abs": "https://arxiv.org/abs/2505.13563", "authors": ["Xiaohui Wang", "Peng Ye", "Chenyu Huang", "Shenghe Zheng", "Bo Zhang", "Wanli Ouyang", "Tao Chen"], "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "With the rise of the fine-tuned--pretrained paradigm, storing numerous\nfine-tuned models for multi-tasking creates significant storage overhead. Delta\ncompression alleviates this by storing only the pretrained model and the highly\ncompressed delta weights (the differences between fine-tuned and pretrained\nmodel weights). However, existing methods fail to maintain both high\ncompression and performance, and often rely on data. To address these\nchallenges, we propose UltraDelta, the first data-free delta compression\npipeline that achieves both ultra-high compression and strong performance.\nUltraDelta is designed to minimize redundancy, maximize information, and\nstabilize performance across inter-layer, intra-layer, and global dimensions,\nusing three key components: (1) Variance-Based Mixed Sparsity Allocation\nassigns sparsity based on variance, giving lower sparsity to high-variance\nlayers to preserve inter-layer information. (2) Distribution-Aware Compression\napplies uniform quantization and then groups parameters by value, followed by\ngroup-wise pruning, to better preserve intra-layer distribution. (3)\nTrace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a\nglobal rescaling factor, improving model stability under higher compression.\nExtensive experiments across (a) large language models (fine-tuned on LLaMA-2\n7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base)\nwith up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and\n(d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that\nUltraDelta consistently outperforms existing methods, especially under\nultra-high compression."}
{"id": "2505.13718", "pdf": "https://arxiv.org/pdf/2505.13718", "abs": "https://arxiv.org/abs/2505.13718", "authors": ["Safal Shrestha", "Minwu Kim", "Aadim Nepal", "Anubhav Shrestha", "Keith Ross"], "title": "Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Designing effective reasoning-capable LLMs typically requires training using\nReinforcement Learning with Verifiable Rewards (RLVR) or distillation with\ncarefully curated Long Chain of Thoughts (CoT), both of which depend heavily on\nextensive training data. This creates a major challenge when the amount of\nquality training data is scarce. We propose a sample-efficient, two-stage\ntraining strategy to develop reasoning LLMs under limited supervision. In the\nfirst stage, we \"warm up\" the model by distilling Long CoTs from a toy domain,\nnamely, Knights \\& Knaves (K\\&K) logic puzzles to acquire general reasoning\nskills. In the second stage, we apply RLVR to the warmed-up model using a\nlimited set of target-domain examples. Our experiments demonstrate that this\ntwo-phase approach offers several benefits: $(i)$ the warmup phase alone\nfacilitates generalized reasoning, leading to performance improvements across a\nrange of tasks, including MATH, HumanEval$^{+}$, and MMLU-Pro. $(ii)$ When both\nthe base model and the warmed-up model are RLVR trained on the same small\ndataset ($\\leq100$ examples), the warmed-up model consistently outperforms the\nbase model; $(iii)$ Warming up before RLVR training allows a model to maintain\ncross-domain generalizability even after training on a specific domain; $(iv)$\nIntroducing warmup in the pipeline improves not only accuracy but also overall\nsample efficiency during RLVR training. The results in this paper highlight the\npromise of warmup for building robust reasoning LLMs in data-scarce\nenvironments."}
{"id": "2505.08175", "pdf": "https://arxiv.org/pdf/2505.08175", "abs": "https://arxiv.org/abs/2505.08175", "authors": ["Zachary Novack", "Zach Evans", "Zack Zukowski", "Josiah Taylor", "CJ Carr", "Julian Parker", "Adnan Al-Sinan", "Gian Marco Iodice", "Julian McAuley", "Taylor Berg-Kirkpatrick", "Jordi Pons"], "title": "Fast Text-to-Audio Generation with Adversarial Post-Training", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": null, "summary": "Text-to-audio systems, while increasingly performant, are slow at inference\ntime, thus making their latency unpractical for many creative applications. We\npresent Adversarial Relativistic-Contrastive (ARC) post-training, the first\nadversarial acceleration algorithm for diffusion/flow models not based on\ndistillation. While past adversarial post-training methods have struggled to\ncompare against their expensive distillation counterparts, ARC post-training is\na simple procedure that (1) extends a recent relativistic adversarial\nformulation to diffusion/flow post-training and (2) combines it with a novel\ncontrastive discriminator objective to encourage better prompt adherence. We\npair ARC post-training with a number optimizations to Stable Audio Open and\nbuild a model capable of generating $\\approx$12s of 44.1kHz stereo audio in\n$\\approx$75ms on an H100, and $\\approx$7s on a mobile edge-device, the fastest\ntext-to-audio model to our knowledge."}
{"id": "2411.07362", "pdf": "https://arxiv.org/pdf/2411.07362", "abs": "https://arxiv.org/abs/2411.07362", "authors": ["Jaime Ruiz-Serra", "Patrick Sweeney", "Michael S. Harr√©"], "title": "Factorised Active Inference for Strategic Multi-Agent Interactions", "categories": ["cs.MA", "cs.GT", "cs.LG"], "comment": "To appear in Proceedings of the 24th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS-2025). Detroit, USA, May 2025", "summary": "Understanding how individual agents make strategic decisions within\ncollectives is important for advancing fields as diverse as economics,\nneuroscience, and multi-agent systems. Two complementary approaches can be\nintegrated to this end. The Active Inference framework (AIF) describes how\nagents employ a generative model to adapt their beliefs about and behaviour\nwithin their environment. Game theory formalises strategic interactions between\nagents with potentially competing objectives. To bridge the gap between the\ntwo, we propose a factorisation of the generative model whereby each agent\nmaintains explicit, individual-level beliefs about the internal states of other\nagents, and uses them for strategic planning in a joint context. We apply our\nmodel to iterated general-sum games with two and three players, and study the\nensemble effects of game transitions, where the agents' preferences (game\npayoffs) change over time. This non-stationarity, beyond that caused by\nreciprocal adaptation, reflects a more naturalistic environment in which agents\nneed to adapt to changing social contexts. Finally, we present a dynamical\nanalysis of key AIF quantities: the variational free energy (VFE) and the\nexpected free energy (EFE) from numerical simulation data. The ensemble-level\nEFE allows us to characterise the basins of attraction of games with multiple\nNash Equilibria under different conditions, and we find that it is not\nnecessarily minimised at the aggregate level. By integrating AIF and game\ntheory, we can gain deeper insights into how intelligent collectives emerge,\nlearn, and optimise their actions in dynamic environments, both cooperative and\nnon-cooperative."}
{"id": "2505.14448", "pdf": "https://arxiv.org/pdf/2505.14448", "abs": "https://arxiv.org/abs/2505.14448", "authors": ["Igor Lugo", "Martha G. Alatriste-Contreras", "Rafael S√°nchez-Guevara"], "title": "Complexity of frequency fluctuations and the interpretive style in the bass viola da gamba", "categories": ["cs.SD", "eess.AS", "stat.AP"], "comment": "15 pages, 5 figures", "summary": "Audio signals in a set of musical pieces are modeled as a complex network for\nstudying the relationship between the complexity of frequency fluctuations and\nthe interpretive style of the bass viola da gamba. Based on interdisciplinary\nscientific and music approaches, we compute the spectral decomposition and\ntranslated its frequency components to a network of sounds. We applied a best\nfit analysis for identifying the statistical distributions that describe more\nprecisely the behavior of such frequencies and computed the centrality measures\nand identify cliques for characterizing such a network. Findings suggested\nstatistical regularities in the type of statistical distribution that best\ndescribes frequency fluctuations. The centrality measure confirmed the most\ninfluential and stable group of sounds in a piece of music, meanwhile the\nidentification of the largest clique indicated functional groups of sounds that\ninteract closely for identifying the emergence of complex frequency\nfluctuations. Therefore, by modeling the sound as a complex network, we can\nclearly associate the presence of large-scale statistical regularities with the\npresence of similar frequency fluctuations related to different musical events\nplayed by a same musician."}
{"id": "2505.14517", "pdf": "https://arxiv.org/pdf/2505.14517", "abs": "https://arxiv.org/abs/2505.14517", "authors": ["Jakob Kienegger", "Timo Gerkmann"], "title": "Steering Deep Non-Linear Spatially Selective Filters for Weakly Guided Extraction of Moving Speakers in Dynamic Scenarios", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Accepted at Interspeech 2025", "summary": "Recent speaker extraction methods using deep non-linear spatial filtering\nperform exceptionally well when the target direction is known and stationary.\nHowever, spatially dynamic scenarios are considerably more challenging due to\ntime-varying spatial features and arising ambiguities, e.g. when moving\nspeakers cross. While in a static scenario it may be easy for a user to point\nto the target's direction, manually tracking a moving speaker is impractical.\nInstead of relying on accurate time-dependent directional cues, which we refer\nto as strong guidance, in this paper we propose a weakly guided extraction\nmethod solely depending on the target's initial position to cope with spatial\ndynamic scenarios. By incorporating our own deep tracking algorithm and\ndeveloping a joint training strategy on a synthetic dataset, we demonstrate the\nproficiency of our approach in resolving spatial ambiguities and even\noutperform a mismatched, but strongly guided extraction method."}
{"id": "2403.11340", "pdf": "https://arxiv.org/pdf/2403.11340", "abs": "https://arxiv.org/abs/2403.11340", "authors": ["Tushar Kataria", "Beatrice Knudsen", "Shireen Y. Elhabian"], "title": "StainDiffuser: MultiTask Dual Diffusion Model for Virtual Staining", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Hematoxylin and Eosin (H&E) staining is widely regarded as the standard in\npathology for diagnosing diseases and tracking tumor recurrence. While H&E\nstaining shows tissue structures, it lacks the ability to reveal specific\nproteins that are associated with disease severity and treatment response.\nImmunohistochemical (IHC) stains use antibodies to highlight the expression of\nthese proteins on their respective cell types, improving diagnostic accuracy,\nand assisting with drug selection for treatment. Despite their value, IHC\nstains require additional time and resources, limiting their utilization in\nsome clinical settings. Recent advances in deep learning have positioned\nImage-to-Image (I2I) translation as a computational, cost-effective alternative\nfor IHC. I2I generates high fidelity stain transformations digitally,\npotentially replacing manual staining in IHC. Diffusion models, the current\nstate of the art in image generation and conditional tasks, are particularly\nwell suited for virtual IHC due to their ability to produce high quality images\nand resilience to mode collapse. However, these models require extensive and\ndiverse datasets (often millions of samples) to achieve a robust performance, a\nchallenge in virtual staining applications where only thousands of samples are\ntypically available. Inspired by the success of multitask deep learning models\nin scenarios with limited data, we introduce STAINDIFFUSER, a novel multitask\ndiffusion architecture tailored to virtual staining that achieves convergence\nwith smaller datasets. STAINDIFFUSER simultaneously trains two diffusion\nprocesses: (a) generating cell specific IHC stains from H&E images and (b)\nperforming H&E based cell segmentation, utilizing coarse segmentation labels\nexclusively during training. STAINDIFFUSER generates high-quality virtual\nstains for two markers, outperforming over twenty I2I baselines."}
{"id": "2505.13761", "pdf": "https://arxiv.org/pdf/2505.13761", "abs": "https://arxiv.org/abs/2505.13761", "authors": ["Jacob Kleiman", "Kevin Frank", "Sindy Campagna"], "title": "Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making", "categories": ["cs.CL"], "comment": null, "summary": "Simulations, although powerful in accurately replicating real-world systems,\noften remain inaccessible to non-technical users due to their complexity.\nConversely, large language models (LLMs) provide intuitive, language-based\ninteractions but can lack the structured, causal understanding required to\nreliably model complex real-world dynamics. We introduce our simulation agent\nframework, a novel approach that integrates the strengths of both simulation\nmodels and LLMs. This framework helps empower users by leveraging the\nconversational capabilities of LLMs to interact seamlessly with sophisticated\nsimulation systems, while simultaneously utilizing the simulations to ground\nthe LLMs in accurate and structured representations of real-world phenomena.\nThis integrated approach helps provide a robust and generalizable foundation\nfor empirical validation and offers broad applicability across diverse domains."}
{"id": "2505.13905", "pdf": "https://arxiv.org/pdf/2505.13905", "abs": "https://arxiv.org/abs/2505.13905", "authors": ["Ruihan Liu", "Xiaoyi Wu", "Xijun Chen", "Liang Hu", "Yunjiang Lou"], "title": "4D-ROLLS: 4D Radar Occupancy Learning via LiDAR Supervision", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "A comprehensive understanding of 3D scenes is essential for autonomous\nvehicles (AVs), and among various perception tasks, occupancy estimation plays\na central role by providing a general representation of drivable and occupied\nspace. However, most existing occupancy estimation methods rely on LiDAR or\ncameras, which perform poorly in degraded environments such as smoke, rain,\nsnow, and fog. In this paper, we propose 4D-ROLLS, the first weakly supervised\noccupancy estimation method for 4D radar using the LiDAR point cloud as the\nsupervisory signal. Specifically, we introduce a method for generating\npseudo-LiDAR labels, including occupancy queries and LiDAR height maps, as\nmulti-stage supervision to train the 4D radar occupancy estimation model. Then\nthe model is aligned with the occupancy map produced by LiDAR, fine-tuning its\naccuracy in occupancy estimation. Extensive comparative experiments validate\nthe exceptional performance of 4D-ROLLS. Its robustness in degraded\nenvironments and effectiveness in cross-dataset training are qualitatively\ndemonstrated. The model is also seamlessly transferred to downstream tasks BEV\nsegmentation and point cloud occupancy prediction, highlighting its potential\nfor broader applications. The lightweight network enables 4D-ROLLS model to\nachieve fast inference speeds at about 30 Hz on a 4060 GPU. The code of\n4D-ROLLS will be made available at https://github.com/CLASS-Lab/4D-ROLLS."}
{"id": "2505.13564", "pdf": "https://arxiv.org/pdf/2505.13564", "abs": "https://arxiv.org/abs/2505.13564", "authors": ["Aymeric Capitaine", "Maxime Haddouche", "Eric Moulines", "Michael I. Jordan", "Etienne Boursier", "Alain Durmus"], "title": "Online Decision-Focused Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Decision-focused learning (DFL) is an increasingly popular paradigm for\ntraining predictive models whose outputs are used in decision-making tasks.\nInstead of merely optimizing for predictive accuracy, DFL trains models to\ndirectly minimize the loss associated with downstream decisions. This\nend-to-end strategy holds promise for tackling complex combinatorial problems;\nhowever, existing studies focus solely on scenarios where a fixed batch of data\nis available and the objective function does not change over time. We instead\ninvestigate DFL in dynamic environments where the objective function and data\ndistribution evolve over time. This setting is challenging because the\nobjective function has zero or undefined gradients -- which prevents the use of\nstandard first-order optimization methods -- and is generally non-convex. To\naddress these difficulties, we (i) regularize the objective to make it\ndifferentiable and (ii) make use of the optimism principle, based on a\nnear-optimal oracle along with an appropriate perturbation. This leads to a\npractical online algorithm for which we establish bounds on the expected\ndynamic regret, both when the decision space is a simplex and when it is a\ngeneral bounded convex polytope. Finally, we demonstrate the effectiveness of\nour algorithm by comparing its performance with a classic prediction-focused\napproach on a simple knapsack experiment."}
{"id": "2505.13737", "pdf": "https://arxiv.org/pdf/2505.13737", "abs": "https://arxiv.org/abs/2505.13737", "authors": ["Andrew Nam", "Henry Conklin", "Yukang Yang", "Thomas Griffiths", "Jonathan Cohen", "Sarah-Jane Leslie"], "title": "Causal Head Gating: A Framework for Interpreting Roles of Attention Heads in Transformers", "categories": ["cs.AI"], "comment": "10 pages, 5 figures, 2 tables", "summary": "We present causal head gating (CHG), a scalable method for interpreting the\nfunctional roles of attention heads in transformer models. CHG learns soft\ngates over heads and assigns them a causal taxonomy - facilitating,\ninterfering, or irrelevant - based on their impact on task performance. Unlike\nprior approaches in mechanistic interpretability, which are hypothesis-driven\nand require prompt templates or target labels, CHG applies directly to any\ndataset using standard next-token prediction. We evaluate CHG across multiple\nlarge language models (LLMs) in the Llama 3 model family and diverse tasks,\nincluding syntax, commonsense, and mathematical reasoning, and show that CHG\nscores yield causal - not merely correlational - insight, validated via\nablation and causal mediation analyses. We also introduce contrastive CHG, a\nvariant that isolates sub-circuits for specific task components. Our findings\nreveal that LLMs contain multiple sparse, sufficient sub-circuits, that\nindividual head roles depend on interactions with others (low modularity), and\nthat instruction following and in-context learning rely on separable\nmechanisms."}
{"id": "2505.12499", "pdf": "https://arxiv.org/pdf/2505.12499", "abs": "https://arxiv.org/abs/2505.12499", "authors": ["Jian Xiao", "Zijie Song", "Jialong Hu", "Hao Cheng", "Zhenzhen Hu", "Jia Li", "Richang Hong"], "title": "Contrastive Alignment with Semantic Gap-Aware Corrections in Text-Video Retrieval", "categories": ["cs.CV", "cs.IR", "cs.MM"], "comment": null, "summary": "Recent advances in text-video retrieval have been largely driven by\ncontrastive learning frameworks. However, existing methods overlook a key\nsource of optimization tension: the separation between text and video\ndistributions in the representation space (referred to as the modality gap),\nand the prevalence of false negatives in batch sampling. These factors lead to\nconflicting gradients under the InfoNCE loss, impeding stable alignment. To\nmitigate this, we propose GARE, a Gap-Aware Retrieval framework that introduces\na learnable, pair-specific increment Delta_ij between text t_i and video v_j to\noffload the tension from the global anchor representation. We first derive the\nideal form of Delta_ij via a coupled multivariate first-order Taylor\napproximation of the InfoNCE loss under a trust-region constraint, revealing it\nas a mechanism for resolving gradient conflicts by guiding updates along a\nlocally optimal descent direction. Due to the high cost of directly computing\nDelta_ij, we introduce a lightweight neural module conditioned on the semantic\ngap between each video-text pair, enabling structure-aware correction guided by\ngradient supervision. To further stabilize learning and promote\ninterpretability, we regularize Delta using three components: a trust-region\nconstraint to prevent oscillation, a directional diversity term to promote\nsemantic coverage, and an information bottleneck to limit redundancy.\nExperiments across four retrieval benchmarks show that GARE consistently\nimproves alignment accuracy and robustness to noisy supervision, confirming the\neffectiveness of gap-aware tension mitigation."}
{"id": "2502.13160", "pdf": "https://arxiv.org/pdf/2502.13160", "abs": "https://arxiv.org/abs/2502.13160", "authors": ["Yiwen Zhang", "Yifu Wu", "Wenyue Hua", "Xiang Lu", "Xuming Hu"], "title": "Attention Mechanism for LLM-based Agents Dynamic Diffusion under Information Asymmetry", "categories": ["cs.MA", "cs.AI"], "comment": "18 pages, 5 figures", "summary": "Large language models have been used to simulate human society using\nmulti-agent systems. Most current social simulation research emphasizes\ninteractive behaviors in fixed environments, ignoring information opacity,\nrelationship variability, and diffusion diversity. In this paper, we first\npropose a general framework for exploring multi-agent information diffusion. We\nidentified LLMs' deficiency in the perception and utilization of social\nrelationships, as well as diverse actions. Then, we designed a dynamic\nattention mechanism to help agents allocate attention to different information,\naddressing the limitations of the LLM attention mechanism. Agents start by\nresponding to external information stimuli within a five-agent group,\nincreasing group size and forming information circles while developing\nrelationships and sharing information. Additionally, we explore the information\ndiffusion features in the asymmetric open environment by observing the\nevolution of information gaps, diffusion patterns, and the accumulation of\nsocial capital, which are closely linked to psychological, sociological, and\ncommunication theories."}
{"id": "2505.14470", "pdf": "https://arxiv.org/pdf/2505.14470", "abs": "https://arxiv.org/abs/2505.14470", "authors": ["Nadav Har-Tuv", "Or Tal", "Yossi Adi"], "title": "PAST: Phonetic-Acoustic Speech Tokenizer", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": null, "summary": "We present PAST, a novel end-to-end framework that jointly models phonetic\ninformation alongside signal reconstruction, eliminating the need for external\npretrained models. Unlike previous approaches that rely on pretrained\nself-supervised models, PAST employs supervised phonetic data, directly\nintegrating domain knowledge into the tokenization process via auxiliary tasks.\nAdditionally, we introduce a streamable, causal variant of PAST, enabling\nreal-time speech applications. Results demonstrate that PAST surpasses existing\nevaluated baseline tokenizers across common evaluation metrics, including\nphonetic representation and speech reconstruction. Notably, PAST also achieves\nsuperior performance when serving as a speech representation for speech\nlanguage models, further highlighting its effectiveness as a foundation for\nspoken language generation. To foster further research, we release the full\nimplementation. For code, model checkpoints, and samples see:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/PAST"}
{"id": "2505.14518", "pdf": "https://arxiv.org/pdf/2505.14518", "abs": "https://arxiv.org/abs/2505.14518", "authors": ["Chun-Yi Kuan", "Hung-yi Lee"], "title": "Teaching Audio-Aware Large Language Models What Does Not Hear: Mitigating Hallucinations through Synthesized Negative Samples", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted to Interspeech 2025", "summary": "Recent advancements in audio-aware large language models (ALLMs) enable them\nto process and understand audio inputs. However, these models often hallucinate\nnon-existent sound events, reducing their reliability in real-world\napplications. To address this, we propose LISTEN (Learning to Identify Sounds\nThrough Extended Negative Samples), a contrastive-like training method that\nenhances ALLMs' ability to distinguish between present and absent sounds using\nsynthesized data from the backbone LLM. Unlike prior approaches, our method\nrequires no modification to LLM parameters and efficiently integrates audio\nrepresentations via a lightweight adapter. Experiments show that LISTEN\neffectively mitigates hallucinations while maintaining impressive performance\non existing audio question and reasoning benchmarks. At the same time, it is\nmore efficient in both data and computation."}
{"id": "2504.04814", "pdf": "https://arxiv.org/pdf/2504.04814", "abs": "https://arxiv.org/abs/2504.04814", "authors": ["Nataliia Molchanova", "Pedro M. Gordaliza", "Alessandro Cagol", "Mario Ocampo--Pineda", "Po--Jui Lu", "Matthias Weigel", "Xinjie Chen", "Erin S. Beck", "Haris Tsagkas", "Daniel Reich", "Anna St√∂lting", "Pietro Maggi", "Delphine Ribes", "Adrien Depeursinge", "Cristina Granziera", "Henning M√ºller", "Meritxell Bach Cuadra"], "title": "Explaining Uncertainty in Multiple Sclerosis Lesion Segmentation Beyond Prediction Errors", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Trustworthy artificial intelligence (AI) is essential in healthcare,\nparticularly for high-stakes tasks like medical image segmentation. Explainable\nAI and uncertainty quantification significantly enhance AI reliability by\naddressing key attributes such as robustness, usability, and explainability.\nDespite extensive technical advances in uncertainty quantification for medical\nimaging, understanding the clinical informativeness and interpretability of\nuncertainty remains limited. This study introduces a novel framework to explain\nthe potential sources of predictive uncertainty, specifically in cortical\nlesion segmentation in multiple sclerosis using deep ensembles. The proposed\nanalysis shifts the focus from the uncertainty-error relationship towards\nrelevant medical and engineering factors. Our findings reveal that\ninstance-wise uncertainty is strongly related to lesion size, shape, and\ncortical involvement. Expert rater feedback confirms that similar factors\nimpede annotator confidence. Evaluations conducted on two datasets (206\npatients, almost 2000 lesions) under both in-domain and distribution-shift\nconditions highlight the utility of the framework in different scenarios."}
{"id": "2505.13772", "pdf": "https://arxiv.org/pdf/2505.13772", "abs": "https://arxiv.org/abs/2505.13772", "authors": ["Dimitris Roussis", "Leon Voukoutis", "Georgios Paraskevopoulos", "Sokratis Sofianopoulos", "Prokopis Prokopidis", "Vassilis Papavasileiou", "Athanasios Katsamanis", "Stelios Piperidis", "Vassilis Katsouros"], "title": "Krikri: Advancing Open Large Language Models for Greek", "categories": ["cs.CL"], "comment": null, "summary": "We introduce Llama-Krikri-8B, a cutting-edge Large Language Model tailored\nfor the Greek language, built on Meta's Llama 3.1-8B. Llama-Krikri-8B has been\nextensively trained on high-quality Greek data to ensure superior adaptation to\nlinguistic nuances. With 8 billion parameters, it offers advanced capabilities\nwhile maintaining efficient computational performance. Llama-Krikri-8B supports\nboth Modern Greek and English, and is also equipped to handle polytonic text\nand Ancient Greek. The chat version of Llama-Krikri-8B features a multi-stage\npost-training pipeline, utilizing both human and synthetic instruction and\npreference data, by applying techniques such as MAGPIE. In addition, for\nevaluation, we propose three novel public benchmarks for Greek. Our evaluation\non existing as well as the proposed benchmarks shows notable improvements over\ncomparable Greek and multilingual LLMs in both natural language understanding\nand generation as well as code generation."}
{"id": "2505.13923", "pdf": "https://arxiv.org/pdf/2505.13923", "abs": "https://arxiv.org/abs/2505.13923", "authors": ["Chinedu Emmanuel Mbonu", "Kenechukwu Anigbogu", "Doris Asogwa", "Tochukwu Belonwu"], "title": "An Explorative Analysis of SVM Classifier and ResNet50 Architecture on African Food Classification", "categories": ["cs.CV"], "comment": "7 pages, 9 figures", "summary": "Food recognition systems has advanced significantly for Western cuisines, yet\nits application to African foods remains underexplored. This study addresses\nthis gap by evaluating both deep learning and traditional machine learning\nmethods for African food classification. We compared the performance of a\nfine-tuned ResNet50 model with a Support Vector Machine (SVM) classifier. The\ndataset comprises 1,658 images across six selected food categories that are\nknown in Africa. To assess model effectiveness, we utilize five key evaluation\nmetrics: Confusion matrix, F1-score, accuracy, recall and precision. Our\nfindings offer valuable insights into the strengths and limitations of both\napproaches, contributing to the advancement of food recognition for African\ncuisines."}
{"id": "2505.13567", "pdf": "https://arxiv.org/pdf/2505.13567", "abs": "https://arxiv.org/abs/2505.13567", "authors": ["Yoav Ger", "Omri Barak"], "title": "Learning Dynamics of RNNs in Closed-Loop Environments", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": "9 pages with 6 figures", "summary": "Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer\npowerful models of brain computation. However, typical training paradigms rely\non open-loop, supervised settings, whereas real-world learning unfolds in\nclosed-loop environments. Here, we develop a mathematical theory describing the\nlearning dynamics of linear RNNs trained in closed-loop contexts. We first\ndemonstrate that two otherwise identical RNNs, trained in either closed- or\nopen-loop modes, follow markedly different learning trajectories. To probe this\ndivergence, we analytically characterize the closed-loop case, revealing\ndistinct stages aligned with the evolution of the training loss. Specifically,\nwe show that the learning dynamics of closed-loop RNNs, in contrast to\nopen-loop ones, are governed by an interplay between two competing objectives:\nshort-term policy improvement and long-term stability of the agent-environment\ninteraction. Finally, we apply our framework to a realistic motor control task,\nhighlighting its broader applicability. Taken together, our results underscore\nthe importance of modeling closed-loop dynamics in a biologically plausible\nsetting."}
{"id": "2505.13763", "pdf": "https://arxiv.org/pdf/2505.13763", "abs": "https://arxiv.org/abs/2505.13763", "authors": ["Li Ji-An", "Hua-Dong Xiong", "Robert C. Wilson", "Marcelo G. Mattar", "Marcus K. Benna"], "title": "Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations", "categories": ["cs.AI", "cs.CL", "q-bio.NC"], "comment": null, "summary": "Large language models (LLMs) can sometimes report the strategies they\nactually use to solve tasks, but they can also fail to do so. This suggests\nsome degree of metacognition -- the capacity to monitor one's own cognitive\nprocesses for subsequent reporting and self-control. Metacognitive abilities\nenhance AI capabilities but raise safety concerns, as models might obscure\ntheir internal processes to evade neural-activation-based oversight mechanisms\ndesigned to detect harmful behaviors. Given society's increased reliance on\nthese models, it is critical that we understand the limits of their\nmetacognitive abilities, particularly their ability to monitor their internal\nactivations. To address this, we introduce a neuroscience-inspired\nneurofeedback paradigm designed to quantify the ability of LLMs to explicitly\nreport and control their activation patterns. By presenting models with\nsentence-label pairs where labels correspond to sentence-elicited internal\nactivations along specific directions in the neural representation space, we\ndemonstrate that LLMs can learn to report and control these activations. The\nperformance varies with several factors: the number of example pairs provided,\nthe semantic interpretability of the target neural direction, and the variance\nexplained by that direction. These results reveal a \"metacognitive space\" with\ndimensionality much lower than the model's neural space, suggesting LLMs can\nmonitor only a subset of their neural mechanisms. Our findings provide\nempirical evidence quantifying metacognitive capabilities in LLMs, with\nsignificant implications for AI safety."}
{"id": "2505.12406", "pdf": "https://arxiv.org/pdf/2505.12406", "abs": "https://arxiv.org/abs/2505.12406", "authors": ["Martin Jon√°≈°", "Anton√≠n Kuƒçera", "Vojtƒõch K≈Ør", "Jan Maƒç√°k"], "title": "Steady-State Strategy Synthesis for Swarms of Autonomous Agents", "categories": ["cs.MA"], "comment": null, "summary": "Steady-state synthesis aims to construct a policy for a given MDP $D$ such\nthat the long-run average frequencies of visits to the vertices of $D$ satisfy\ngiven numerical constraints. This problem is solvable in polynomial time, and\nmemoryless policies are sufficient for approximating an arbitrary frequency\nvector achievable by a general (infinite-memory) policy.\n  We study the steady-state synthesis problem for multiagent systems, where\nmultiple autonomous agents jointly strive to achieve a suitable frequency\nvector. We show that the problem for multiple agents is computationally hard\n(PSPACE or NP hard, depending on the variant), and memoryless strategy profiles\nare insufficient for approximating achievable frequency vectors. Furthermore,\nwe prove that even evaluating the frequency vector achieved by a given\nmemoryless profile is computationally hard. This reveals a severe barrier to\nconstructing an efficient synthesis algorithm, even for memoryless profiles.\nNevertheless, we design an efficient and scalable synthesis algorithm for a\nsubclass of full memoryless profiles, and we evaluate this algorithm on a large\nclass of randomly generated instances. The experimental results demonstrate a\nsignificant improvement against a naive algorithm based on strategy sharing."}
{"id": "2505.14562", "pdf": "https://arxiv.org/pdf/2505.14562", "abs": "https://arxiv.org/abs/2505.14562", "authors": ["Parthasaarathy Sudarsanam", "Irene Mart√≠n-Morat√≥", "Tuomas Virtanen"], "title": "Representation Learning for Semantic Alignment of Language, Audio, and Visual Modalities", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": "Accepted to European Signal Processing Conference (EUSIPCO 2025)", "summary": "This paper proposes a single-stage training approach that semantically aligns\nthree modalities - audio, visual, and text using a contrastive learning\nframework. Contrastive training has gained prominence for multimodal alignment,\nutilizing large-scale unlabeled data to learn shared representations. Existing\ndeep learning approach for trimodal alignment involves two-stages, that\nseparately align visual-text and audio-text modalities. This approach suffers\nfrom mismatched data distributions, resulting in suboptimal alignment.\nLeveraging the AVCaps dataset, which provides audio, visual and audio-visual\ncaptions for video clips, our method jointly optimizes the representation of\nall the modalities using contrastive training. Our results demonstrate that the\nsingle-stage approach outperforms the two-stage method, achieving a two-fold\nimprovement in audio based visual retrieval, highlighting the advantages of\nunified multimodal representation learning."}
{"id": "2505.14561", "pdf": "https://arxiv.org/pdf/2505.14561", "abs": "https://arxiv.org/abs/2505.14561", "authors": ["Theo Lepage", "Reda Dehak"], "title": "SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "comment": "accepted at Interspeech 2025", "summary": "Self-Supervised Learning (SSL) has led to considerable progress in Speaker\nVerification (SV). The standard framework uses same-utterance positive sampling\nand data-augmentation to generate anchor-positive pairs of the same speaker.\nThis is a major limitation, as this strategy primarily encodes channel\ninformation from the recording condition, shared by the anchor and positive. We\npropose a new positive sampling technique to address this bottleneck:\nSelf-Supervised Positive Sampling (SSPS). For a given anchor, SSPS aims to find\nan appropriate positive, i.e., of the same speaker identity but a different\nrecording condition, in the latent space using clustering assignments and a\nmemory queue of positive embeddings. SSPS improves SV performance for both\nSimCLR and DINO, reaching 2.57% and 2.53% EER, outperforming SOTA SSL methods\non VoxCeleb1-O. In particular, SimCLR-SSPS achieves a 58% EER reduction by\nlowering intra-speaker variance, providing comparable performance to DINO-SSPS."}
{"id": "2505.08616", "pdf": "https://arxiv.org/pdf/2505.08616", "abs": "https://arxiv.org/abs/2505.08616", "authors": ["Yifan Li", "Peter Ho", "Jo Woon Chong"], "title": "A portable diagnosis model for Keratoconus using a smartphone", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Keratoconus (KC) is a corneal disorder that results in blurry and distorted\nvision. Traditional diagnostic tools, while effective, are often bulky, costly,\nand require professional operation. In this paper, we present a portable and\ninnovative methodology for diagnosing. Our proposed approach first captures the\nimage reflected on the eye's cornea when a smartphone screen-generated Placido\ndisc sheds its light on an eye, then utilizes a two-stage diagnosis for\nidentifying the KC cornea and pinpointing the location of the KC on the cornea.\nThe first stage estimates the height and width of the Placido disc extracted\nfrom the captured image to identify whether it has KC. In this KC\nidentification, k-means clustering is implemented to discern statistical\ncharacteristics, such as height and width values of extracted Placido discs,\nfrom non-KC (control) and KC-affected groups. The second stage involves the\ncreation of a distance matrix, providing a precise localization of KC on the\ncornea, which is critical for efficient treatment planning. The analysis of\nthese distance matrices, paired with a logistic regression model and robust\nstatistical analysis, reveals a clear distinction between control and KC\ngroups. The logistic regression model, which classifies small areas on the\ncornea as either control or KC-affected based on the corresponding inter-disc\ndistances in the distance matrix, reported a classification accuracy of 96.94%,\nwhich indicates that we can effectively pinpoint the protrusion caused by KC.\nThis comprehensive, smartphone-based method is expected to detect KC and\nstreamline timely treatment."}
{"id": "2505.13792", "pdf": "https://arxiv.org/pdf/2505.13792", "abs": "https://arxiv.org/abs/2505.13792", "authors": ["Siddhant Bhambri", "Upasana Biswas", "Subbarao Kambhampati"], "title": "Interpretable Traces, Unexpected Outcomes: Investigating the Disconnect in Trace-Based Knowledge Distillation", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "Question Answering (QA) poses a challenging and critical problem,\nparticularly in today's age of interactive dialogue systems such as ChatGPT,\nPerplexity, Microsoft Copilot, etc. where users demand both accuracy and\ntransparency in the model's outputs. Since smaller language models (SLMs) are\ncomputationally more efficient but often under-perform compared to larger\nmodels, Knowledge Distillation (KD) methods allow for finetuning these smaller\nmodels to improve their final performance. Lately, the intermediate tokens or\nthe so called `reasoning' traces produced by Chain-of-Thought (CoT) or by\nreasoning models such as DeepSeek R1 are used as a training signal for KD.\nHowever, these reasoning traces are often verbose and difficult to interpret or\nevaluate. In this work, we aim to address the challenge of evaluating the\nfaithfulness of these reasoning traces and their correlation with the final\nperformance. To this end, we employ a KD method leveraging rule-based problem\ndecomposition. This approach allows us to break down complex queries into\nstructured sub-problems, generating interpretable traces whose correctness can\nbe readily evaluated, even at inference time. Specifically, we demonstrate this\napproach on Open Book QA, decomposing the problem into a Classification step\nand an Information Retrieval step, thereby simplifying trace evaluation. Our\nSFT experiments with correct and incorrect traces on the CoTemp QA, Microsoft\nMachine Reading Comprehension QA, and Facebook bAbI QA datasets reveal the\nstriking finding that correct traces do not necessarily imply that the model\noutputs the correct final solution. Similarly, we find a low correlation\nbetween correct final solutions and intermediate trace correctness. These\nresults challenge the implicit assumption behind utilizing reasoning traces for\nimproving SLMs' final performance via KD."}
{"id": "2505.13928", "pdf": "https://arxiv.org/pdf/2505.13928", "abs": "https://arxiv.org/abs/2505.13928", "authors": ["Qifeng Cai", "Hao Liang", "Hejun Dong", "Meiyi Qiang", "Ruichuan An", "Zhaoyang Han", "Zhengzhou Zhu", "Bin Cui", "Wentao Zhang"], "title": "LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts", "categories": ["cs.CV", "cs.IR"], "comment": null, "summary": "Long videos contain a vast amount of information, making video-text retrieval\nan essential and challenging task in multimodal learning. However, existing\nbenchmarks suffer from limited video duration, low-quality captions, and coarse\nannotation granularity, which hinder the evaluation of advanced video-text\nretrieval methods. To address these limitations, we introduce LoVR, a benchmark\nspecifically designed for long video-text retrieval. LoVR contains 467 long\nvideos and over 40,804 fine-grained clips with high-quality captions. To\novercome the issue of poor machine-generated annotations, we propose an\nefficient caption generation framework that integrates VLM automatic\ngeneration, caption quality scoring, and dynamic refinement. This pipeline\nimproves annotation accuracy while maintaining scalability. Furthermore, we\nintroduce a semantic fusion method to generate coherent full-video captions\nwithout losing important contextual information. Our benchmark introduces\nlonger videos, more detailed captions, and a larger-scale dataset, presenting\nnew challenges for video understanding and retrieval. Extensive experiments on\nvarious advanced embedding models demonstrate that LoVR is a challenging\nbenchmark, revealing the limitations of current approaches and providing\nvaluable insights for future research. We release the code and dataset link at\nhttps://github.com/TechNomad-ds/LoVR-benchmark"}
{"id": "2505.13569", "pdf": "https://arxiv.org/pdf/2505.13569", "abs": "https://arxiv.org/abs/2505.13569", "authors": ["Fynn Fromme", "Christine Allen-Blanchette", "Hans Harder", "Sebastian Peitz"], "title": "Surrogate Modeling of 3D Rayleigh-Benard Convection with Equivariant Autoencoders", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "The use of machine learning for modeling, understanding, and controlling\nlarge-scale physics systems is quickly gaining in popularity, with examples\nranging from electromagnetism over nuclear fusion reactors and\nmagneto-hydrodynamics to fluid mechanics and climate modeling. These systems --\ngoverned by partial differential equations -- present unique challenges\nregarding the large number of degrees of freedom and the complex dynamics over\nmany scales both in space and time, and additional measures to improve accuracy\nand sample efficiency are highly desirable. We present an end-to-end\nequivariant surrogate model consisting of an equivariant convolutional\nautoencoder and an equivariant convolutional LSTM using $G$-steerable kernels.\nAs a case study, we consider the three-dimensional Rayleigh-B\\'enard\nconvection, which describes the buoyancy-driven fluid flow between a heated\nbottom and a cooled top plate. While the system is E(2)-equivariant in the\nhorizontal plane, the boundary conditions break the translational equivariance\nin the vertical direction. Our architecture leverages vertically stacked layers\nof $D_4$-steerable kernels, with additional partial kernel sharing in the\nvertical direction for further efficiency improvement. Our results demonstrate\nsignificant gains both in sample and parameter efficiency, as well as a better\nscaling to more complex dynamics, that is, larger Rayleigh numbers. The\naccompanying code is available under\nhttps://github.com/FynnFromme/equivariant-rb-forecasting."}
{"id": "2505.13770", "pdf": "https://arxiv.org/pdf/2505.13770", "abs": "https://arxiv.org/abs/2505.13770", "authors": ["Jin Du", "Li Chen", "Xun Xian", "An Luo", "Fangqiao Tian", "Ganghua Wang", "Charles Doss", "Xiaotong Shen", "Jie Ding"], "title": "Ice Cream Doesn't Cause Drowning: Benchmarking LLMs Against Statistical Pitfalls in Causal Inference", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ME", "stat.ML", "62-08, 68T50, 68T05, 68T01, 68T07, 62-07, 68U35, 62C99", "I.2.7; I.2.6; I.2.0; I.5.1; I.5.4; F.2.2; H.2.8; G.3"], "comment": null, "summary": "Reliable causal inference is essential for making decisions in high-stakes\nareas like medicine, economics, and public policy. However, it remains unclear\nwhether large language models (LLMs) can handle rigorous and trustworthy\nstatistical causal inference. Current benchmarks usually involve simplified\ntasks. For example, these tasks might only ask LLMs to identify semantic causal\nrelationships or draw conclusions directly from raw data. As a result, models\nmay overlook important statistical pitfalls, such as Simpson's paradox or\nselection bias. This oversight limits the applicability of LLMs in the real\nworld. To address these limitations, we propose CausalPitfalls, a comprehensive\nbenchmark designed to rigorously evaluate the capability of LLMs in overcoming\ncommon causal inference pitfalls. Our benchmark features structured challenges\nacross multiple difficulty levels, each paired with grading rubrics. This\napproach allows us to quantitatively measure both causal reasoning capabilities\nand the reliability of LLMs' responses. We evaluate models using two protocols:\n(1) direct prompting, which assesses intrinsic causal reasoning, and (2)\ncode-assisted prompting, where models generate executable code for explicit\nstatistical analysis. Additionally, we validate the effectiveness of this judge\nby comparing its scoring with assessments from human experts. Our results\nreveal significant limitations in current LLMs when performing statistical\ncausal inference. The CausalPitfalls benchmark provides essential guidance and\nquantitative metrics to advance the development of trustworthy causal reasoning\nsystems."}
{"id": "2505.13393", "pdf": "https://arxiv.org/pdf/2505.13393", "abs": "https://arxiv.org/abs/2505.13393", "authors": ["Christopher K. Frantz"], "title": "IG Parser: A Software Package for the Encoding of Institutional Statements using the Institutional Grammar", "categories": ["cs.MA", "cs.AI", "cs.CL", "68T30, 68T50", "E.2; H.1.0; I.7.2; I.6.5; K.4.1"], "comment": "24 pages", "summary": "This article provides an overview of IG Parser, a software that facilitates\nqualitative content analysis of formal (e.g., legal) rules or informal (e.g.,\nsocial) norms, and strategies (such as conventions) -- referred to as\ninstitutions -- that govern social systems and operate configurally to describe\ninstitutional systems. To this end, the IG Parser employs a distinctive syntax\nthat ensures rigorous encoding of natural language, while automating the\ntransformation into various formats that support the downstream analysis using\ndiverse analytical techniques. The conceptual core of the IG Parser is an\nassociated syntax, IG Script, that operationalizes the conceptual foundations\nof the Institutional Grammar, and more specifically the Institutional Grammar\n2.0, an analytical paradigm for institutional analysis. This article presents\nthe IG Parser, including its conceptual foundations, the syntax specification\nof IG Script, and its architectural principles. This overview is augmented with\nselective illustrative examples that highlight its use and the associated\nbenefits."}
{"id": "2505.14648", "pdf": "https://arxiv.org/pdf/2505.14648", "abs": "https://arxiv.org/abs/2505.14648", "authors": ["Tiantian Feng", "Jihwan Lee", "Anfeng Xu", "Yoonjeong Lee", "Thanathai Lertpetchpun", "Xuan Shi", "Helin Wang", "Thomas Thebaud", "Laureano Moro-Velazquez", "Dani Byrd", "Najim Dehak", "Shrikanth Narayanan"], "title": "Vox-Profile: A Speech Foundation Model Benchmark for Characterizing Diverse Speaker and Speech Traits", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "We introduce Vox-Profile, a comprehensive benchmark to characterize rich\nspeaker and speech traits using speech foundation models. Unlike existing works\nthat focus on a single dimension of speaker traits, Vox-Profile provides\nholistic and multi-dimensional profiles that reflect both static speaker traits\n(e.g., age, sex, accent) and dynamic speech properties (e.g., emotion, speech\nflow). This benchmark is grounded in speech science and linguistics, developed\nwith domain experts to accurately index speaker and speech characteristics. We\nreport benchmark experiments using over 15 publicly available speech datasets\nand several widely used speech foundation models that target various static and\ndynamic speaker and speech properties. In addition to benchmark experiments, we\nshowcase several downstream applications supported by Vox-Profile. First, we\nshow that Vox-Profile can augment existing speech recognition datasets to\nanalyze ASR performance variability. Vox-Profile is also used as a tool to\nevaluate the performance of speech generation systems. Finally, we assess the\nquality of our automated profiles through comparison with human evaluation and\nshow convergent validity. Vox-Profile is publicly available at:\nhttps://github.com/tiantiaf0627/vox-profile-release."}
{"id": "2505.14600", "pdf": "https://arxiv.org/pdf/2505.14600", "abs": "https://arxiv.org/abs/2505.14600", "authors": ["Yang Xiao", "Tianyi Peng", "Yanghao Zhou", "Rohan Kumar Das"], "title": "AdaKWS: Towards Robust Keyword Spotting with Test-Time Adaptation", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by Interspeech 2025", "summary": "Spoken keyword spotting (KWS) aims to identify keywords in audio for wide\napplications, especially on edge devices. Current small-footprint KWS systems\nfocus on efficient model designs. However, their inference performance can\ndecline in unseen environments or noisy backgrounds. Test-time adaptation (TTA)\nhelps models adapt to test samples without needing the original training data.\nIn this study, we present AdaKWS, the first TTA method for robust KWS to the\nbest of our knowledge. Specifically, 1) We initially optimize the model's\nconfidence by selecting reliable samples based on prediction entropy\nminimization and adjusting the normalization statistics in each batch. 2) We\nintroduce pseudo-keyword consistency (PKC) to identify critical, reliable\nfeatures without overfitting to noise. Our experiments show that AdaKWS\noutperforms other methods across various conditions, including Gaussian noise\nand real-scenario noises. The code will be released in due course."}
{"id": "2505.10311", "pdf": "https://arxiv.org/pdf/2505.10311", "abs": "https://arxiv.org/abs/2505.10311", "authors": ["Jeffrey Alido", "Tongyu Li", "Yu Sun", "Lei Tian"], "title": "Whitened Score Diffusion: A Structured Prior for Imaging Inverse Problems", "categories": ["eess.IV", "eess.SP", "stat.AP", "stat.ML"], "comment": null, "summary": "Conventional score-based diffusion models (DMs) may struggle with anisotropic\nGaussian diffusion processes due to the required inversion of covariance\nmatrices in the denoising score matching training objective\n\\cite{vincent_connection_2011}. We propose Whitened Score (WS) diffusion\nmodels, a novel framework based on stochastic differential equations that\nlearns the Whitened Score function instead of the standard score. This approach\ncircumvents covariance inversion, extending score-based DMs by enabling stable\ntraining of DMs on arbitrary Gaussian forward noising processes. WS DMs\nestablish equivalence with flow matching for arbitrary Gaussian noise, allow\nfor tailored spectral inductive biases, and provide strong Bayesian priors for\nimaging inverse problems with structured noise. We experiment with a variety of\ncomputational imaging tasks using the CIFAR and CelebA ($64\\times64$) datasets\nand demonstrate that WS diffusion priors trained on anisotropic Gaussian\nnoising processes consistently outperform conventional diffusion priors based\non isotropic Gaussian noise. Our code is open-sourced at\n\\href{https://github.com/jeffreyalido/wsdiffusion}{\\texttt{github.com/jeffreyalido/wsdiffusion}}."}
{"id": "2505.13840", "pdf": "https://arxiv.org/pdf/2505.13840", "abs": "https://arxiv.org/abs/2505.13840", "authors": ["Zhengqing Yuan", "Weixiang Sun", "Yixin Liu", "Huichi Zhou", "Rong Zhou", "Yiyang Li", "Zheyuan Zhang", "Wei Song", "Yue Huang", "Haolong Jia", "Keerthiram Murugesan", "Yu Wang", "Lifang He", "Jianfeng Gao", "Lichao Sun", "Yanfang Ye"], "title": "EfficientLLM: Efficiency in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have driven significant progress, yet their\ngrowing parameter counts and context windows incur prohibitive compute, energy,\nand monetary costs. We introduce EfficientLLM, a novel benchmark and the first\ncomprehensive empirical study evaluating efficiency techniques for LLMs at\nscale. Conducted on a production-class cluster (48xGH200, 8xH200 GPUs), our\nstudy systematically explores three key axes: (1) architecture pretraining\n(efficient attention variants: MQA, GQA, MLA, NSA; sparse Mixture-of-Experts\n(MoE)), (2) fine-tuning (parameter-efficient methods: LoRA, RSLoRA, DoRA), and\n(3) inference (quantization methods: int4, float16). We define six fine-grained\nmetrics (Memory Utilization, Compute Utilization, Latency, Throughput, Energy\nConsumption, Compression Rate) to capture hardware saturation,\nlatency-throughput balance, and carbon cost. Evaluating over 100\nmodel-technique pairs (0.5B-72B parameters), we derive three core insights: (i)\nEfficiency involves quantifiable trade-offs: no single method is universally\noptimal; e.g., MoE reduces FLOPs and improves accuracy but increases VRAM by\n40%, while int4 quantization cuts memory/energy by up to 3.9x at a 3-5%\naccuracy drop. (ii) Optima are task- and scale-dependent: MQA offers optimal\nmemory-latency trade-offs for constrained devices, MLA achieves lowest\nperplexity for quality-critical tasks, and RSLoRA surpasses LoRA efficiency\nonly beyond 14B parameters. (iii) Techniques generalize across modalities: we\nextend evaluations to Large Vision Models (Stable Diffusion 3.5, Wan 2.1) and\nVision-Language Models (Qwen2.5-VL), confirming effective transferability. By\nopen-sourcing datasets, evaluation pipelines, and leaderboards, EfficientLLM\nprovides essential guidance for researchers and engineers navigating the\nefficiency-performance landscape of next-generation foundation models."}
{"id": "2505.13943", "pdf": "https://arxiv.org/pdf/2505.13943", "abs": "https://arxiv.org/abs/2505.13943", "authors": ["Samee Arif", "Sualeha Farid"], "title": "Every Pixel Tells a Story: End-to-End Urdu Newspaper OCR", "categories": ["cs.CV"], "comment": null, "summary": "This paper introduces a comprehensive end-to-end pipeline for Optical\nCharacter Recognition (OCR) on Urdu newspapers. In our approach, we address the\nunique challenges of complex multi-column layouts, low-resolution archival\nscans, and diverse font styles. Our process decomposes the OCR task into four\nkey modules: (1) article segmentation, (2) image super-resolution, (3) column\nsegmentation, and (4) text recognition. For article segmentation, we fine-tune\nand evaluate YOLOv11x to identify and separate individual articles from\ncluttered layouts. Our model achieves a precision of 0.963 and mAP@50 of 0.975.\nFor super-resolution, we fine-tune and benchmark the SwinIR model (reaching\n32.71 dB PSNR) to enhance the quality of degraded newspaper scans. To do our\ncolumn segmentation, we use YOLOv11x to separate columns in text to further\nenhance performance - this model reaches a precision of 0.970 and mAP@50 of\n0.975. In the text recognition stage, we benchmark a range of LLMs from\ndifferent families, including Gemini, GPT, Llama, and Claude. The lowest WER of\n0.133 is achieved by Gemini-2.5-Pro."}
{"id": "2505.13575", "pdf": "https://arxiv.org/pdf/2505.13575", "abs": "https://arxiv.org/abs/2505.13575", "authors": ["Ilkay Wunderlich", "Benjamin Koch", "Sven Sch√∂nfeld"], "title": "An Overview of Arithmetic Adaptations for Inference of Convolutional Neural Networks on Re-configurable Hardware", "categories": ["cs.LG"], "comment": null, "summary": "Convolutional Neural Networks (CNNs) have gained high popularity as a tool\nfor computer vision tasks and for that reason are used in various applications.\nThere are many different concepts, like single shot detectors, that have been\npublished for detecting objects in images or video streams. However, CNNs\nsuffer from disadvantages regarding the deployment on embedded platforms such\nas re-configurable hardware like Field Programmable Gate Arrays (FPGAs). Due to\nthe high computational intensity, memory requirements and arithmetic\nconditions, a variety of strategies for running CNNs on FPGAs have been\ndeveloped. The following methods showcase our best practice approaches for a\nTinyYOLOv3 detector network on a XILINX Artix-7 FPGA using techniques like\nfusion of batch normalization, filter pruning and post training network\nquantization."}
{"id": "2505.13774", "pdf": "https://arxiv.org/pdf/2505.13774", "abs": "https://arxiv.org/abs/2505.13774", "authors": ["Zidi Xiong", "Chen Shan", "Zhenting Qi", "Himabindu Lakkaraju"], "title": "Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) have significantly enhanced their capabilities\nin complex problem-solving by introducing a thinking draft that enables\nmulti-path Chain-of-Thought explorations before producing final answers.\nEnsuring the faithfulness of these intermediate reasoning processes is crucial\nfor reliable monitoring, interpretation, and effective control. In this paper,\nwe propose a systematic counterfactual intervention framework to rigorously\nevaluate thinking draft faithfulness. Our approach focuses on two complementary\ndimensions: (1) Intra-Draft Faithfulness, which assesses whether individual\nreasoning steps causally influence subsequent steps and the final draft\nconclusion through counterfactual step insertions; and (2) Draft-to-Answer\nFaithfulness, which evaluates whether final answers are logically consistent\nwith and dependent on the thinking draft, by perturbing the draft's concluding\nlogic. We conduct extensive experiments across six state-of-the-art LRMs. Our\nfindings show that current LRMs demonstrate selective faithfulness to\nintermediate reasoning steps and frequently fail to faithfully align with the\ndraft conclusions. These results underscore the need for more faithful and\ninterpretable reasoning in advanced LRMs."}
{"id": "2505.12796", "pdf": "https://arxiv.org/pdf/2505.12796", "abs": "https://arxiv.org/abs/2505.12796", "authors": ["Shuji Shinohara", "Daiki Morita", "Hayato Hirai", "Ryosuke Kuribayashi", "Nobuhito Manome", "Toru Moriyama", "Yoshihiro Nakajima", "Yukio-Pegio Gunji", "Ung-il Chung"], "title": "Adaptive Inference through Bayesian and Inverse Bayesian Inference with Symmetry-Bias in Nonstationary Environments", "categories": ["stat.ME", "cs.MA"], "comment": null, "summary": "This study introduces a novel inference framework, designated as Bayesian and\ninverse Bayesian (BIB) inference, which concurrently performs both conventional\nand inverse Bayesian updates by integrating symmetry bias into Bayesian\ninference. The effectiveness of the model was evaluated through a sequential\nestimation task involving observations sampled from a Gaussian distribution\nwith a stochastically time-varying mean. Conventional Bayesian inference\nentails a fundamental trade-off between adaptability to abrupt environmental\nshifts and estimation accuracy during stable intervals. The BIB framework\naddresses this limitation by dynamically modulating the learning rate through\ninverse Bayesian updates, thereby enhancing adaptive flexibility. The BIB model\ngenerated spontaneous bursts in the learning rate during sudden environmental\ntransitions, transiently entering a high-sensitivity state to accommodate\nincoming data. This intermittent burst-relaxation pattern functions as a\ndynamic mechanism that balances adaptability and accuracy. Further analysis of\nburst interval distributions demonstrated that the BIB model consistently\nproduced power-law distributions under diverse conditions. Such robust scaling\nbehavior, absent in conventional Bayesian inference, appears to emerge from a\nself-regulatory mechanism driven by inverse Bayesian updates. These results\npresent a novel computational perspective on scale-free phenomena in natural\nsystems and offer implications for designing adaptive inference systems in\nnonstationary environments."}
{"id": "2505.14601", "pdf": "https://arxiv.org/pdf/2505.14601", "abs": "https://arxiv.org/abs/2505.14601", "authors": ["Yang Xiao", "Rohan Kumar Das"], "title": "Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by Interspeech 2025", "summary": "As deepfake speech becomes common and hard to detect, it is vital to trace\nits source. Recent work on audio deepfake source tracing (ST) aims to find the\norigins of synthetic or manipulated speech. However, ST models must adapt to\nlearn new deepfake attacks while retaining knowledge of the previous ones. A\nmajor challenge is catastrophic forgetting, where models lose the ability to\nrecognize previously learned attacks. Some continual learning methods help with\ndeepfake detection, but multi-class tasks such as ST introduce additional\nchallenges as the number of classes grows. To address this, we propose an\nanalytic class incremental learning method called AnaST. When new attacks\nappear, the feature extractor remains fixed, and the classifier is updated with\na closed-form analytical solution in one epoch. This approach ensures data\nprivacy, optimizes memory usage, and is suitable for online training. The\nexperiments carried out in this work show that our method outperforms the\nbaselines."}
{"id": "2505.10464", "pdf": "https://arxiv.org/pdf/2505.10464", "abs": "https://arxiv.org/abs/2505.10464", "authors": ["Jiaming Liang", "Lihuan Dai", "Xiaoqi Sheng", "Xiangguang Chen", "Chun Yao", "Guihua Tao", "Qibin Leng", "Hongmin Cai", "Xi Zhong"], "title": "HWA-UNETR: Hierarchical Window Aggregate UNETR for 3D Multimodal Gastric Lesion Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "This work has been provisionally accepted for MICCAI 2025", "summary": "Multimodal medical image segmentation faces significant challenges in the\ncontext of gastric cancer lesion analysis. This clinical context is defined by\nthe scarcity of independent multimodal datasets and the imperative to\namalgamate inherently misaligned modalities. As a result, algorithms are\nconstrained to train on approximate data and depend on application migration,\nleading to substantial resource expenditure and a potential decline in analysis\naccuracy. To address those challenges, we have made two major contributions:\nFirst, we publicly disseminate the GCM 2025 dataset, which serves as the first\nlarge-scale, open-source collection of gastric cancer multimodal MRI scans,\nfeaturing professionally annotated FS-T2W, CE-T1W, and ADC images from 500\npatients. Second, we introduce HWA-UNETR, a novel 3D segmentation framework\nthat employs an original HWA block with learnable window aggregation layers to\nestablish dynamic feature correspondences between different modalities'\nanatomical structures, and leverages the innovative tri-orientated fusion mamba\nmechanism for context modeling and capturing long-range spatial dependencies.\nExtensive experiments on our GCM 2025 dataset and the publicly BraTS 2021\ndataset validate the performance of our framework, demonstrating that the new\napproach surpasses existing methods by up to 1.68\\% in the Dice score while\nmaintaining solid robustness. The dataset and code are public via\nhttps://github.com/JeMing-creater/HWA-UNETR."}
{"id": "2505.13844", "pdf": "https://arxiv.org/pdf/2505.13844", "abs": "https://arxiv.org/abs/2505.13844", "authors": ["Congchi Yin", "Yongpeng Zhang", "Xuyun Wen", "Piji Li"], "title": "Improve Language Model and Brain Alignment via Associative Memory", "categories": ["cs.CL"], "comment": "Accepted by Findings of ACL 2025", "summary": "Associative memory engages in the integration of relevant information for\ncomprehension in the human cognition system. In this work, we seek to improve\nalignment between language models and human brain while processing speech\ninformation by integrating associative memory. After verifying the alignment\nbetween language model and brain by mapping language model activations to brain\nactivity, the original text stimuli expanded with simulated associative memory\nare regarded as input to computational language models. We find the alignment\nbetween language model and brain is improved in brain regions closely related\nto associative memory processing. We also demonstrate large language models\nafter specific supervised fine-tuning better align with brain response, by\nbuilding the \\textit{Association} dataset containing 1000 samples of stories,\nwith instructions encouraging associative memory as input and associated\ncontent as output."}
{"id": "2505.13997", "pdf": "https://arxiv.org/pdf/2505.13997", "abs": "https://arxiv.org/abs/2505.13997", "authors": ["Huaijie Wang", "De Cheng", "Guozhang Li", "Zhipeng Xu", "Lingfeng He", "Jie Li", "Nannan Wang", "Xinbo Gao"], "title": "StPR: Spatiotemporal Preservation and Routing for Exemplar-Free Video Class-Incremental Learning", "categories": ["cs.CV"], "comment": null, "summary": "Video Class-Incremental Learning (VCIL) seeks to develop models that\ncontinuously learn new action categories over time without forgetting\npreviously acquired knowledge. Unlike traditional Class-Incremental Learning\n(CIL), VCIL introduces the added complexity of spatiotemporal structures,\nmaking it particularly challenging to mitigate catastrophic forgetting while\neffectively capturing both frame-shared semantics and temporal dynamics.\nExisting approaches either rely on exemplar rehearsal, raising concerns over\nmemory and privacy, or adapt static image-based methods that neglect temporal\nmodeling. To address these limitations, we propose Spatiotemporal Preservation\nand Routing (StPR), a unified and exemplar-free VCIL framework that explicitly\ndisentangles and preserves spatiotemporal information. First, we introduce\nFrame-Shared Semantics Distillation (FSSD), which identifies semantically\nstable and meaningful channels by jointly considering semantic sensitivity and\nclassification contribution. These important semantic channels are selectively\nregularized to maintain prior knowledge while allowing for adaptation. Second,\nwe design a Temporal Decomposition-based Mixture-of-Experts (TD-MoE), which\ndynamically routes task-specific experts based on their temporal dynamics,\nenabling inference without task ID or stored exemplars. Together, StPR\neffectively leverages spatial semantics and temporal dynamics, achieving a\nunified, exemplar-free VCIL framework. Extensive experiments on UCF101, HMDB51,\nand Kinetics400 show that our method outperforms existing baselines while\noffering improved interpretability and efficiency in VCIL. Code is available in\nthe supplementary materials."}
{"id": "2505.13576", "pdf": "https://arxiv.org/pdf/2505.13576", "abs": "https://arxiv.org/abs/2505.13576", "authors": ["Sara Alosaime", "Arshad Jhumka"], "title": "FlexFed: Mitigating Catastrophic Forgetting in Heterogeneous Federated Learning in Pervasive Computing Environments", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training while preserving\nprivacy by allowing clients to share model updates instead of raw data.\nPervasive computing environments (e.g., for Human Activity Recognition, HAR),\nwhich we focus on in this paper, are characterized by resource-constrained end\ndevices, streaming sensor data and intermittent client participation.\nVariations in user behavior, common in HAR environments, often result in\nnon-stationary data distributions. As such, existing FL approaches face\nchallenges in HAR settings due to differing assumptions. The combined effects\nof HAR characteristics, namely heterogeneous data and intermittent\nparticipation, can lead to a severe issue called catastrophic forgetting (CF).\nUnlike Continuous Learning (CL), which addresses CF using memory and replay\nmechanisms, FL's privacy constraints prohibit such strategies.\n  To tackle CF in HAR environments, we propose FlexFed, a novel FL approach\nthat prioritizes data retention for efficient memory use and dynamically\nadjusts offline training frequency based on distribution shifts, client\ncapability and offline duration. To better quantify CF in FL, we introduce a\nnew metric that accounts for under-represented data, enabling more accurate\nevaluations. We also develop a realistic HAR-based evaluation framework that\nsimulates streaming data, dynamic distributions, imbalances and varying\navailability. Experiments show that FlexFed mitigates CF more effectively,\nimproves FL efficiency by 10 to 15 % and achieves faster, more stable\nconvergence, especially for infrequent or under-represented data."}
{"id": "2505.13778", "pdf": "https://arxiv.org/pdf/2505.13778", "abs": "https://arxiv.org/abs/2505.13778", "authors": ["Guoheng Sun", "Ziyao Wang", "Bowei Tian", "Meng Liu", "Zheyu Shen", "Shwai He", "Yexiao He", "Wanghao Ye", "Yiting Wang", "Ang Li"], "title": "CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs", "categories": ["cs.AI"], "comment": null, "summary": "As post-training techniques evolve, large language models (LLMs) are\nincreasingly augmented with structured multi-step reasoning abilities, often\noptimized through reinforcement learning. These reasoning-enhanced models\noutperform standard LLMs on complex tasks and now underpin many commercial LLM\nAPIs. However, to protect proprietary behavior and reduce verbosity, providers\ntypically conceal the reasoning traces while returning only the final answer.\nThis opacity introduces a critical transparency gap: users are billed for\ninvisible reasoning tokens, which often account for the majority of the cost,\nyet have no means to verify their authenticity. This opens the door to token\ncount inflation, where providers may overreport token usage or inject\nsynthetic, low-effort tokens to inflate charges. To address this issue, we\npropose CoIn, a verification framework that audits both the quantity and\nsemantic validity of hidden tokens. CoIn constructs a verifiable hash tree from\ntoken embedding fingerprints to check token counts, and uses embedding-based\nrelevance matching to detect fabricated reasoning content. Experiments\ndemonstrate that CoIn, when deployed as a trusted third-party auditor, can\neffectively detect token count inflation with a success rate reaching up to\n94.7%, showing the strong ability to restore billing transparency in opaque LLM\nservices. The dataset and code are available at\nhttps://github.com/CASE-Lab-UMD/LLM-Auditing-CoIn."}
{"id": "2505.14074", "pdf": "https://arxiv.org/pdf/2505.14074", "abs": "https://arxiv.org/abs/2505.14074", "authors": ["Owais Mujtaba Khanday", "Pablo Rodroguez San Esteban", "Zubair Ahmad Lone", "Marc Ouellet", "Jose Andres Gonzalez Lopez"], "title": "Recreating Neural Activity During Speech Production with Language and Speech Model Embeddings", "categories": ["cs.HC", "cs.SD", "eess.AS"], "comment": "Accepted for presentation at Interspeech2025", "summary": "Understanding how neural activity encodes speech and language production is a\nfundamental challenge in neuroscience and artificial intelligence. This study\ninvestigates whether embeddings from large-scale, self-supervised language and\nspeech models can effectively reconstruct neural activity recordings captured\nduring speech production. We leverage pre-trained embeddings from deep learning\nmodels trained on linguistic and acoustic data to represent high-level speech\nfeatures and map them onto neural signals. We analyze the extent to which these\nembeddings preserve the spatio-temporal dynamics of brain activity. We evaluate\nreconstructed neural signals against ground truth recordings using correlation\nmetrics and signal reconstruction quality assessments. The results indicate\nthat neural activity can be effectively reconstructed using embeddings from\nlarge language and speech models across all study participants, yielding\nPearson correlation coefficients ranging from 0.79 to 0.99."}
{"id": "2505.12061", "pdf": "https://arxiv.org/pdf/2505.12061", "abs": "https://arxiv.org/abs/2505.12061", "authors": ["Samuel T. M. Ball"], "title": "Bayesian Deep Learning Approaches for Uncertainty-Aware Retinal OCT Image Segmentation for Multiple Sclerosis", "categories": ["eess.IV", "cs.CV", "68U10, 92C55", "I.2.10; I.4.6; J.3"], "comment": null, "summary": "Optical Coherence Tomography (OCT) provides valuable insights in\nophthalmology, cardiology, and neurology due to high-resolution,\ncross-sectional images of the retina. One critical task for ophthalmologists\nusing OCT is delineation of retinal layers within scans. This process is\ntime-consuming and prone to human bias, affecting the accuracy and reliability\nof diagnoses. Previous efforts to automate delineation using deep learning face\nchallenges in uptake from clinicians and statisticians due to the absence of\nuncertainty estimation, leading to \"confidently wrong\" models via\nhallucinations. In this study, we address these challenges by applying Bayesian\nconvolutional neural networks (BCNNs) to segment an openly available OCT\nimaging dataset containing 35 human retina OCTs split between healthy controls\nand patients with multiple sclerosis. Our findings demonstrate that Bayesian\nmodels can be used to provide uncertainty maps of the segmentation, which can\nfurther be used to identify highly uncertain samples that exhibit recording\nartefacts such as noise or miscalibration at inference time. Our method also\nallows for uncertainty-estimation for important secondary measurements such as\nlayer thicknesses, that are medically relevant for patients. We show that these\nfeatures come in addition to greater performance compared to similar work over\nall delineations; with an overall Dice score of 95.65%. Our work brings greater\nclinical applicability, statistical robustness, and performance to retinal OCT\nsegmentation."}
{"id": "2505.13855", "pdf": "https://arxiv.org/pdf/2505.13855", "abs": "https://arxiv.org/abs/2505.13855", "authors": ["Arihant Tripathi", "Liam Dugan", "Charis Gao", "Maggie Huan", "Emma Jin", "Peter Zhang", "David Zhang", "Julia Zhao", "Chris Callison-Burch"], "title": "Domain Gating Ensemble Networks for AI-Generated Text Detection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submitted to EMNLP 2025", "summary": "As state-of-the-art language models continue to improve, the need for robust\ndetection of machine-generated text becomes increasingly critical. However,\ncurrent state-of-the-art machine text detectors struggle to adapt to new unseen\ndomains and generative models. In this paper we present DoGEN (Domain Gating\nEnsemble Networks), a technique that allows detectors to adapt to unseen\ndomains by ensembling a set of domain expert detector models using weights from\na domain classifier. We test DoGEN on a wide variety of domains from leading\nbenchmarks and find that it achieves state-of-the-art performance on in-domain\ndetection while outperforming models twice its size on out-of-domain detection.\nWe release our code and trained models to assist in future research in\ndomain-adaptive AI detection."}
{"id": "2505.14008", "pdf": "https://arxiv.org/pdf/2505.14008", "abs": "https://arxiv.org/abs/2505.14008", "authors": ["Zhidan Liu", "Chengtang Yao", "Jiaxi Zeng", "Yuwei Wu", "Yunde Jia"], "title": "Multi-Label Stereo Matching for Transparent Scene Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we present a multi-label stereo matching method to\nsimultaneously estimate the depth of the transparent objects and the occluded\nbackground in transparent scenes.Unlike previous methods that assume a unimodal\ndistribution along the disparity dimension and formulate the matching as a\nsingle-label regression problem, we propose a multi-label regression\nformulation to estimate multiple depth values at the same pixel in transparent\nscenes. To resolve the multi-label regression problem, we introduce a\npixel-wise multivariate Gaussian representation, where the mean vector encodes\nmultiple depth values at the same pixel, and the covariance matrix determines\nwhether a multi-label representation is necessary for a given pixel. The\nrepresentation is iteratively predicted within a GRU framework. In each\niteration, we first predict the update step for the mean parameters and then\nuse both the update step and the updated mean parameters to estimate the\ncovariance matrix. We also synthesize a dataset containing 10 scenes and 89\nobjects to validate the performance of transparent scene depth estimation. The\nexperiments show that our method greatly improves the performance on\ntransparent surfaces while preserving the background information for scene\nreconstruction. Code is available at https://github.com/BFZD233/TranScene."}
{"id": "2505.13578", "pdf": "https://arxiv.org/pdf/2505.13578", "abs": "https://arxiv.org/abs/2505.13578", "authors": ["Mikhail Osipov"], "title": "Symmetry-Breaking Descent for Invariant Cost Functionals", "categories": ["cs.LG"], "comment": "19 pages, 7 appendices", "summary": "We study the problem of reducing a task cost functional $W(S)$, defined over\nSobolev-class signals $S$, when the cost is invariant under a global symmetry\ngroup $G \\subset \\mathrm{Diff}(M)$ and accessible only as a black-box. Such\nscenarios arise in machine learning, imaging, and inverse problems, where cost\nmetrics reflect model outputs or performance scores but are non-differentiable\nand model-internal. We propose a variational method that exploits the symmetry\nstructure to construct explicit, symmetry-breaking deformations of the input\nsignal. A gauge field $\\phi$, obtained by minimizing an auxiliary energy\nfunctional, induces a deformation $h = A_\\phi[S]$ that generically lies\ntransverse to the $G$-orbit of $S$. We prove that, under mild regularity, the\ncost $W$ strictly decreases along this direction -- either via Clarke\nsubdifferential descent or by escaping locally flat plateaus. The exceptional\nset of degeneracies has zero Gaussian measure. Our approach requires no access\nto model gradients or labels and operates entirely at test time. It provides a\nprincipled tool for optimizing invariant cost functionals via Lie-algebraic\nvariational flows, with applications to black-box models and\nsymmetry-constrained tasks."}
{"id": "2505.13794", "pdf": "https://arxiv.org/pdf/2505.13794", "abs": "https://arxiv.org/abs/2505.13794", "authors": ["Qi Cheng", "Licheng Liu", "Qing Zhu", "Runlong Yu", "Zhenong Jin", "Yiqun Xie", "Xiaowei Jia"], "title": "LLM-based Evaluation Policy Extraction for Ecological Modeling", "categories": ["cs.AI"], "comment": null, "summary": "Evaluating ecological time series is critical for benchmarking model\nperformance in many important applications, including predicting greenhouse gas\nfluxes, capturing carbon-nitrogen dynamics, and monitoring hydrological cycles.\nTraditional numerical metrics (e.g., R-squared, root mean square error) have\nbeen widely used to quantify the similarity between modeled and observed\necosystem variables, but they often fail to capture domain-specific temporal\npatterns critical to ecological processes. As a result, these methods are often\naccompanied by expert visual inspection, which requires substantial human labor\nand limits the applicability to large-scale evaluation. To address these\nchallenges, we propose a novel framework that integrates metric learning with\nlarge language model (LLM)-based natural language policy extraction to develop\ninterpretable evaluation criteria. The proposed method processes pairwise\nannotations and implements a policy optimization mechanism to generate and\ncombine different assessment metrics. The results obtained on multiple datasets\nfor evaluating the predictions of crop gross primary production and carbon\ndioxide flux have confirmed the effectiveness of the proposed method in\ncapturing target assessment preferences, including both synthetically generated\nand expert-annotated model comparisons. The proposed framework bridges the gap\nbetween numerical metrics and expert knowledge while providing interpretable\nevaluation policies that accommodate the diverse needs of different ecosystem\nmodeling studies."}
{"id": "2505.14103", "pdf": "https://arxiv.org/pdf/2505.14103", "abs": "https://arxiv.org/abs/2505.14103", "authors": ["Guangke Chen", "Fu Song", "Zhe Zhao", "Xiaojun Jia", "Yang Liu", "Yanchen Qiao", "Weizhe Zhang"], "title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Jailbreak attacks to Large audio-language models (LALMs) are studied\nrecently, but they achieve suboptimal effectiveness, applicability, and\npracticability, particularly, assuming that the adversary can fully manipulate\nuser prompts. In this work, we first conduct an extensive experiment showing\nthat advanced text jailbreak attacks cannot be easily ported to end-to-end\nLALMs via text-to speech (TTS) techniques. We then propose AudioJailbreak, a\nnovel audio jailbreak attack, featuring (1) asynchrony: the jailbreak audio\ndoes not need to align with user prompts in the time axis by crafting suffixal\njailbreak audios; (2) universality: a single jailbreak perturbation is\neffective for different prompts by incorporating multiple prompts into\nperturbation generation; (3) stealthiness: the malicious intent of jailbreak\naudios will not raise the awareness of victims by proposing various intent\nconcealment strategies; and (4) over-the-air robustness: the jailbreak audios\nremain effective when being played over the air by incorporating the\nreverberation distortion effect with room impulse response into the generation\nof the perturbations. In contrast, all prior audio jailbreak attacks cannot\noffer asynchrony, universality, stealthiness, or over-the-air robustness.\nMoreover, AudioJailbreak is also applicable to the adversary who cannot fully\nmanipulate user prompts, thus has a much broader attack scenario. Extensive\nexperiments with thus far the most LALMs demonstrate the high effectiveness of\nAudioJailbreak. We highlight that our work peeks into the security implications\nof audio jailbreak attacks against LALMs, and realistically fosters improving\ntheir security robustness. The implementation and audio samples are available\nat our website https://audiojailbreak.github.io/AudioJailbreak."}
{"id": "2505.14286", "pdf": "https://arxiv.org/pdf/2505.14286", "abs": "https://arxiv.org/abs/2505.14286", "authors": ["Rao Ma", "Mengjie Qian", "Vyas Raina", "Mark Gales", "Kate Knill"], "title": "Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "The combination of pre-trained speech encoders with large language models has\nenabled the development of speech LLMs that can handle a wide range of spoken\nlanguage processing tasks. While these models are powerful and flexible, this\nvery flexibility may make them more vulnerable to adversarial attacks. To\nexamine the extent of this problem, in this work we investigate universal\nacoustic adversarial attacks on speech LLMs. Here a fixed, universal,\nadversarial audio segment is prepended to the original input audio. We\ninitially investigate attacks that cause the model to either produce no output\nor to perform a modified task overriding the original prompt. We then extend\nthe nature of the attack to be selective so that it activates only when\nspecific input attributes, such as a speaker gender or spoken language, are\npresent. Inputs without the targeted attribute should be unaffected, allowing\nfine-grained control over the model outputs. Our findings reveal critical\nvulnerabilities in Qwen2-Audio and Granite-Speech and suggest that similar\nspeech LLMs may be susceptible to universal adversarial attacks. This\nhighlights the need for more robust training strategies and improved resistance\nto adversarial attacks."}
{"id": "2502.02171", "pdf": "https://arxiv.org/pdf/2502.02171", "abs": "https://arxiv.org/abs/2502.02171", "authors": ["Mohamed Youssef", "Jian Peng", "Oliver Bimber"], "title": "DeepForest: Sensing Into Self-Occluding Volumes of Vegetation With Aerial Imaging", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Access to below-canopy volumetric vegetation data is crucial for\nunderstanding ecosystem dynamics. We address the long-standing limitation of\nremote sensing to penetrate deep into dense canopy layers. LiDAR and radar are\ncurrently considered the primary options for measuring 3D vegetation\nstructures, while cameras can only extract the reflectance and depth of top\nlayers. Using conventional, high-resolution aerial images, our approach allows\nsensing deep into self-occluding vegetation volumes, such as forests. It is\nsimilar in spirit to the imaging process of wide-field microscopy, but can\nhandle much larger scales and strong occlusion. We scan focal stacks by\nsynthetic-aperture imaging with drones and reduce outof-focus signal\ncontributions using pre-trained 3D convolutional neural networks with mean\nsquared error (MSE) as the loss function. The resulting volumetric reflectance\nstacks contain low-frequency representations of the vegetation volume.\nCombining multiple reflectance stacks from various spectral channels provides\ninsights into plant health, growth, and environmental conditions throughout the\nentire vegetation volume. Compared with simulated ground truth, our correction\nleads to ~x7 average improvements (min: ~x2, max: ~x12) for forest densities of\n200 trees/ha - 1680 trees/ha. In our field experiment, we achieved an MSE of\n0.05 when comparing with the top-vegetation layer that was measured with\nclassical multispectral aerial imaging."}
{"id": "2505.13866", "pdf": "https://arxiv.org/pdf/2505.13866", "abs": "https://arxiv.org/abs/2505.13866", "authors": ["Jiwon Song", "Dongwon Jo", "Yulhwa Kim", "Jae-Joon Kim"], "title": "Reasoning Path Compression: Compressing Generation Trajectories for Efficient LLM Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Recent reasoning-focused language models achieve high accuracy by generating\nlengthy intermediate reasoning paths before producing final answers. While this\napproach is effective in solving problems that require logical thinking, long\nreasoning paths significantly increase memory usage and throughput of token\ngeneration, limiting the practical deployment of such models. We propose\nReasoning Path Compression (RPC), a training-free method that accelerates\ninference by leveraging the semantic sparsity of reasoning paths. RPC\nperiodically compresses the KV cache by retaining KV cache that receive high\nimportance score, which are computed using a selector window composed of\nrecently generated queries. Experiments show that RPC improves generation\nthroughput of QwQ-32B by up to 1.60$\\times$ compared to the inference with full\nKV cache, with an accuracy drop of 1.2% on the AIME 2024 benchmark. Our\nfindings demonstrate that semantic sparsity in reasoning traces can be\neffectively exploited for compression, offering a practical path toward\nefficient deployment of reasoning LLMs. Our code is available at\nhttps://github.com/jiwonsong-dev/ReasoningPathCompression."}
{"id": "2505.14010", "pdf": "https://arxiv.org/pdf/2505.14010", "abs": "https://arxiv.org/abs/2505.14010", "authors": ["Pu Wang", "Pengwen Dai", "Chen Wu", "Yeying Jin", "Dianjie Lu", "Guijuan Zhang", "Youshan Zhang", "Zhuoran Zheng"], "title": "UHD Image Dehazing via anDehazeFormer with Atmospheric-aware KV Cache", "categories": ["cs.CV"], "comment": "Under review", "summary": "In this paper, we propose an efficient visual transformer framework for\nultra-high-definition (UHD) image dehazing that addresses the key challenges of\nslow training speed and high memory consumption for existing methods. Our\napproach introduces two key innovations: 1) an \\textbf{a}daptive\n\\textbf{n}ormalization mechanism inspired by the nGPT architecture that enables\nultra-fast and stable training with a network with a restricted range of\nparameter expressions; and 2) we devise an atmospheric scattering-aware KV\ncaching mechanism that dynamically optimizes feature preservation based on the\nphysical haze formation model. The proposed architecture improves the training\nconvergence speed by \\textbf{5 $\\times$} while reducing memory overhead,\nenabling real-time processing of 50 high-resolution images per second on an\nRTX4090 GPU. Experimental results show that our approach maintains\nstate-of-the-art dehazing quality while significantly improving computational\nefficiency for 4K/8K image restoration tasks. Furthermore, we provide a new\ndehazing image interpretable method with the help of an integrated gradient\nattribution map. Our code can be found here:\nhttps://anonymous.4open.science/r/anDehazeFormer-632E/README.md."}
{"id": "2505.13580", "pdf": "https://arxiv.org/pdf/2505.13580", "abs": "https://arxiv.org/abs/2505.13580", "authors": ["Hanzhao Wang", "Guanting Chen", "Kalyan Talluri", "Xiaocheng Li"], "title": "OMGPT: A Sequence Modeling Framework for Data-driven Operational Decision Making", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2405.14219", "summary": "We build a Generative Pre-trained Transformer (GPT) model from scratch to\nsolve sequential decision making tasks arising in contexts of operations\nresearch and management science which we call OMGPT. We first propose a general\nsequence modeling framework to cover several operational decision making tasks\nas special cases, such as dynamic pricing, inventory management, resource\nallocation, and queueing control. Under the framework, all these tasks can be\nviewed as a sequential prediction problem where the goal is to predict the\noptimal future action given all the historical information. Then we train a\ntransformer-based neural network model (OMGPT) as a natural and powerful\narchitecture for sequential modeling. This marks a paradigm shift compared to\nthe existing methods for these OR/OM tasks in that (i) the OMGPT model can take\nadvantage of the huge amount of pre-trained data; (ii) when tackling these\nproblems, OMGPT does not assume any analytical model structure and enables a\ndirect and rich mapping from the history to the future actions. Either of these\ntwo aspects, to the best of our knowledge, is not achieved by any existing\nmethod. We establish a Bayesian perspective to theoretically understand the\nworking mechanism of the OMGPT on these tasks, which relates its performance\nwith the pre-training task diversity and the divergence between the testing\ntask and pre-training tasks. Numerically, we observe a surprising performance\nof the proposed model across all the above tasks."}
{"id": "2505.13828", "pdf": "https://arxiv.org/pdf/2505.13828", "abs": "https://arxiv.org/abs/2505.13828", "authors": ["Kiarash Naghavi Khanghah", "Zhiling Chen", "Lela Romeo", "Qian Yang", "Rajiv Malhotra", "Farhad Imani", "Hongyi Xu"], "title": "Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models", "categories": ["cs.AI"], "comment": "ASME 2025 International Design Engineering Technical Conferences and\n  Computers and Information in Engineering Conference IDETC/CIE2025, August\n  17-20, 2025, Anaheim, CA (IDETC2025-168615)", "summary": "Additive manufacturing enables the fabrication of complex designs while\nminimizing waste, but faces challenges related to defects and process\nanomalies. This study presents a novel multimodal Retrieval-Augmented\nGeneration-based framework that automates anomaly detection across various\nAdditive Manufacturing processes leveraging retrieved information from\nliterature, including images and descriptive text, rather than training\ndatasets. This framework integrates text and image retrieval from scientific\nliterature and multimodal generation models to perform zero-shot anomaly\nidentification, classification, and explanation generation in a Laser Powder\nBed Fusion setting. The proposed framework is evaluated on four L-PBF\nmanufacturing datasets from Oak Ridge National Laboratory, featuring various\nprinter makes, models, and materials. This evaluation demonstrates the\nframework's adaptability and generalizability across diverse images without\nrequiring additional training. Comparative analysis using Qwen2-VL-2B and\nGPT-4o-mini as MLLM within the proposed framework highlights that GPT-4o-mini\noutperforms Qwen2-VL-2B and proportional random baseline in manufacturing\nanomalies classification. Additionally, the evaluation of the RAG system\nconfirms that incorporating retrieval mechanisms improves average accuracy by\n12% by reducing the risk of hallucination and providing additional information.\nThe proposed framework can be continuously updated by integrating emerging\nresearch, allowing seamless adaptation to the evolving landscape of AM\ntechnologies. This scalable, automated, and zero-shot-capable framework\nstreamlines AM anomaly analysis, enhancing efficiency and accuracy."}
{"id": "2504.14783", "pdf": "https://arxiv.org/pdf/2504.14783", "abs": "https://arxiv.org/abs/2504.14783", "authors": ["Wenhui Zhu", "Peijie Qiu", "Xiwen Chen", "Zhangsihao Yang", "Aristeidis Sotiras", "Abolfazl Razi", "Yalin Wang"], "title": "How Effective Can Dropout Be in Multiple Instance Learning ?", "categories": ["cs.CV", "cs.AI", "eess.IV", "stat.ML"], "comment": "Accepted by ICML2025", "summary": "Multiple Instance Learning (MIL) is a popular weakly-supervised method for\nvarious applications, with a particular interest in histological whole slide\nimage (WSI) classification. Due to the gigapixel resolution of WSI,\napplications of MIL in WSI typically necessitate a two-stage training scheme:\nfirst, extract features from the pre-trained backbone and then perform MIL\naggregation. However, it is well-known that this suboptimal training scheme\nsuffers from \"noisy\" feature embeddings from the backbone and inherent weak\nsupervision, hindering MIL from learning rich and generalizable features.\nHowever, the most commonly used technique (i.e., dropout) for mitigating this\nissue has yet to be explored in MIL. In this paper, we empirically explore how\neffective the dropout can be in MIL. Interestingly, we observe that dropping\nthe top-k most important instances within a bag leads to better performance and\ngeneralization even under noise attack. Based on this key observation, we\npropose a novel MIL-specific dropout method, termed MIL-Dropout, which\nsystematically determines which instances to drop. Experiments on five MIL\nbenchmark datasets and two WSI datasets demonstrate that MIL-Dropout boosts the\nperformance of current MIL methods with a negligible computational cost. The\ncode is available at https://github.com/ChongQingNoSubway/MILDropout."}
{"id": "2505.13886", "pdf": "https://arxiv.org/pdf/2505.13886", "abs": "https://arxiv.org/abs/2505.13886", "authors": ["Jingqi Tong", "Jixin Tang", "Hangcheng Li", "Yurong Mou", "Ming Zhang", "Jun Zhao", "Yanbo Wen", "Fan Song", "Jiahao Zhan", "Yuyang Lu", "Chaoran Tao", "Zhiyuan Guo", "Jizhou Yu", "Tianhao Cheng", "Changhao Jiang", "Zhen Wang", "Tao Liang", "Zhihui Fei", "Mingyang Wan", "Guojun Ma", "Weifeng Ge", "Guanhua Chen", "Tao Gui", "Xipeng Qiu", "Qi Zhang", "Xuanjing Huang"], "title": "Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning", "categories": ["cs.CL", "I.2.7; I.2.10"], "comment": "49 pages, 19 figures, submitted to NeurIPS 2025", "summary": "Visual-language Chain-of-Thought (CoT) data resources are relatively scarce\ncompared to text-only counterparts, limiting the improvement of reasoning\ncapabilities in Vision Language Models (VLMs). However, high-quality\nvision-language reasoning data is expensive and labor-intensive to annotate. To\naddress this issue, we leverage a promising resource: game code, which\nnaturally contains logical structures and state transition processes.\nTherefore, we propose Code2Logic, a novel game-code-driven approach for\nmultimodal reasoning data synthesis. Our approach leverages Large Language\nModels (LLMs) to adapt game code, enabling automatic acquisition of reasoning\nprocesses and results through code execution. Using the Code2Logic approach, we\ndeveloped the GameQA dataset to train and evaluate VLMs. GameQA is\ncost-effective and scalable to produce, challenging for state-of-the-art\nmodels, and diverse with 30 games and 158 tasks. Surprisingly, despite training\nsolely on game data, VLMs demonstrated out of domain generalization,\nspecifically Qwen2.5-VL-7B improving performance by 2.33\\% across 7 diverse\nvision-language benchmarks. Our code and dataset are available at\nhttps://github.com/tongjingqi/Code2Logic."}
{"id": "2505.14014", "pdf": "https://arxiv.org/pdf/2505.14014", "abs": "https://arxiv.org/abs/2505.14014", "authors": ["Zelin Zhang", "Tao Zhang", "KediLI", "Xu Zheng"], "title": "EGFormer: Towards Efficient and Generalizable Multimodal Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Recent efforts have explored multimodal semantic segmentation using various\nbackbone architectures. However, while most methods aim to improve accuracy,\ntheir computational efficiency remains underexplored. To address this, we\npropose EGFormer, an efficient multimodal semantic segmentation framework that\nflexibly integrates an arbitrary number of modalities while significantly\nreducing model parameters and inference time without sacrificing performance.\nOur framework introduces two novel modules. First, the Any-modal Scoring Module\n(ASM) assigns importance scores to each modality independently, enabling\ndynamic ranking based on their feature maps. Second, the Modal Dropping Module\n(MDM) filters out less informative modalities at each stage, selectively\npreserving and aggregating only the most valuable features. This design allows\nthe model to leverage useful information from all available modalities while\ndiscarding redundancy, thus ensuring high segmentation quality. In addition to\nefficiency, we evaluate EGFormer on a synthetic-to-real transfer task to\ndemonstrate its generalizability. Extensive experiments show that EGFormer\nachieves competitive performance with up to 88 percent reduction in parameters\nand 50 percent fewer GFLOPs. Under unsupervised domain adaptation settings, it\nfurther achieves state-of-the-art transfer performance compared to existing\nmethods."}
{"id": "2505.13582", "pdf": "https://arxiv.org/pdf/2505.13582", "abs": "https://arxiv.org/abs/2505.13582", "authors": ["Leyang Zhang", "Yaoyu Zhang", "Tao Luo"], "title": "Uncovering Critical Sets of Deep Neural Networks via Sample-Independent Critical Lifting", "categories": ["cs.LG"], "comment": "20 pages", "summary": "This paper investigates the sample dependence of critical points for neural\nnetworks. We introduce a sample-independent critical lifting operator that\nassociates a parameter of one network with a set of parameters of another, thus\ndefining sample-dependent and sample-independent lifted critical points. We\nthen show by example that previously studied critical embeddings do not capture\nall sample-independent lifted critical points. Finally, we demonstrate the\nexistence of sample-dependent lifted critical points for sufficiently large\nsample sizes and prove that saddles appear among them."}
{"id": "2505.13831", "pdf": "https://arxiv.org/pdf/2505.13831", "abs": "https://arxiv.org/abs/2505.13831", "authors": ["Zongyuan Deng", "Yujie Cai", "Qing Liu", "Shiyao Mu", "Bin Lyu", "Zhen Yang"], "title": "TelePlanNet: An AI-Driven Framework for Efficient Telecom Network Planning", "categories": ["cs.AI", "I.2; I.2.6; C.2.1"], "comment": "6 pages, 5 figures, 1 table, submitted to IEEE ICCC 2025", "summary": "The selection of base station sites is a critical challenge in 5G network\nplanning, which requires efficient optimization of coverage, cost, user\nsatisfaction, and practical constraints. Traditional manual methods, reliant on\nhuman expertise, suffer from inefficiencies and are limited to an unsatisfied\nplanning-construction consistency. Existing AI tools, despite improving\nefficiency in certain aspects, still struggle to meet the dynamic network\nconditions and multi-objective needs of telecom operators' networks. To address\nthese challenges, we propose TelePlanNet, an AI-driven framework tailored for\nthe selection of base station sites, integrating a three-layer architecture for\nefficient planning and large-scale automation. By leveraging large language\nmodels (LLMs) for real-time user input processing and intent alignment with\nbase station planning, combined with training the planning model using the\nimproved group relative policy optimization (GRPO) reinforcement learning, the\nproposed TelePlanNet can effectively address multi-objective optimization,\nevaluates candidate sites, and delivers practical solutions. Experiments\nresults show that the proposed TelePlanNet can improve the consistency to 78%,\nwhich is superior to the manual methods, providing telecom operators with an\nefficient and scalable tool that significantly advances cellular network\nplanning."}
{"id": "2409.03377", "pdf": "https://arxiv.org/pdf/2409.03377", "abs": "https://arxiv.org/abs/2409.03377", "authors": ["Yan Ru Pei", "Ritik Shrivastava", "FNU Sidharth"], "title": "aTENNuate: Optimized Real-time Speech Enhancement with Deep SSMs on Raw Audio", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "7 pages, 2 figures", "summary": "We present aTENNuate, a simple deep state-space autoencoder configured for\nefficient online raw speech enhancement in an end-to-end fashion. The network's\nperformance is primarily evaluated on raw speech denoising, with additional\nassessments on tasks such as super-resolution and de-quantization. We benchmark\naTENNuate on the VoiceBank + DEMAND and the Microsoft DNS1 synthetic test sets.\nThe network outperforms previous real-time denoising models in terms of PESQ\nscore, parameter count, MACs, and latency. Even as a raw waveform processing\nmodel, the model maintains high fidelity to the clean signal with minimal\naudible artifacts. In addition, the model remains performant even when the\nnoisy input is compressed down to 4000Hz and 4 bits, suggesting general speech\nenhancement capabilities in low-resource environments. Try it out by pip\ninstall attenuate"}
{"id": "2409.02615", "pdf": "https://arxiv.org/pdf/2409.02615", "abs": "https://arxiv.org/abs/2409.02615", "authors": ["Bang Zeng", "Ming Li"], "title": "USEF-TSE: Universal Speaker Embedding Free Target Speaker Extraction", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by IEEE Transactions on Audio, Speech and Language\n  Processing (TASLP)", "summary": "Target speaker extraction aims to separate the voice of a specific speaker\nfrom mixed speech. Traditionally, this process has relied on extracting a\nspeaker embedding from a reference speech, in which a speaker recognition model\nis required. However, identifying an appropriate speaker recognition model can\nbe challenging, and using the target speaker embedding as reference information\nmay not be optimal for target speaker extraction tasks. This paper introduces a\nUniversal Speaker Embedding-Free Target Speaker Extraction (USEF-TSE) framework\nthat operates without relying on speaker embeddings. USEF-TSE utilizes a\nmulti-head cross-attention mechanism as a frame-level target speaker feature\nextractor. This innovative approach allows mainstream speaker extraction\nsolutions to bypass the dependency on speaker recognition models and better\nleverage the information available in the enrollment speech, including speaker\ncharacteristics and contextual details. Additionally, USEF-TSE can seamlessly\nintegrate with other time-domain or time-frequency domain speech separation\nmodels to achieve effective speaker extraction. Experimental results show that\nour proposed method achieves state-of-the-art (SOTA) performance in terms of\nScale-Invariant Signal-to-Distortion Ratio (SI-SDR) on the WSJ0-2mix, WHAM!,\nand WHAMR! datasets, which are standard benchmarks for monaural anechoic, noisy\nand noisy-reverberant two-speaker speech separation and speaker extraction. The\nresults on the LibriMix and the blind test set of the ICASSP 2023 DNS Challenge\ndemonstrate that the model performs well on more diverse and out-of-domain\ndata. For access to the source code, please visit:\nhttps://github.com/ZBang/USEF-TSE."}
{"id": "2505.13890", "pdf": "https://arxiv.org/pdf/2505.13890", "abs": "https://arxiv.org/abs/2505.13890", "authors": ["Zhen Xiong", "Yujun Cai", "Zhecheng Li", "Yiwei Wang"], "title": "Mapping the Minds of LLMs: A Graph-Based Analysis of Reasoning LLM", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in test-time scaling have enabled Large Language Models\n(LLMs) to display sophisticated reasoning abilities via extended\nChain-of-Thought (CoT) generation. Despite their potential, these Reasoning\nLLMs (RLMs) often demonstrate counterintuitive and unstable behaviors, such as\nperformance degradation under few-shot prompting, that challenge our current\nunderstanding of RLMs. In this work, we introduce a unified graph-based\nanalytical framework for better modeling the reasoning processes of RLMs. Our\nmethod first clusters long, verbose CoT outputs into semantically coherent\nreasoning steps, then constructs directed reasoning graphs to capture\ncontextual and logical dependencies among these steps. Through comprehensive\nanalysis across models and prompting regimes, we reveal that structural\nproperties, such as exploration density, branching, and convergence ratios,\nstrongly correlate with reasoning accuracy. Our findings demonstrate how\nprompting strategies substantially reshape the internal reasoning structure of\nRLMs, directly affecting task outcomes. The proposed framework not only enables\nquantitative evaluation of reasoning quality beyond conventional metrics but\nalso provides practical insights for prompt engineering and the cognitive\nanalysis of LLMs. Code and resources will be released to facilitate future\nresearch in this direction."}
{"id": "2505.14028", "pdf": "https://arxiv.org/pdf/2505.14028", "abs": "https://arxiv.org/abs/2505.14028", "authors": ["Ye Wang", "Ruiqi Liu", "Jiang Lin", "Fei Liu", "Zili Yi", "Yilin Wang", "Rui Ma"], "title": "OmniStyle: Filtering High Quality Style Transfer Data at Scale", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "In this paper, we introduce OmniStyle-1M, a large-scale paired style transfer\ndataset comprising over one million content-style-stylized image triplets\nacross 1,000 diverse style categories, each enhanced with textual descriptions\nand instruction prompts. We show that OmniStyle-1M can not only enable\nefficient and scalable of style transfer models through supervised training but\nalso facilitate precise control over target stylization. Especially, to ensure\nthe quality of the dataset, we introduce OmniFilter, a comprehensive style\ntransfer quality assessment framework, which filters high-quality triplets\nbased on content preservation, style consistency, and aesthetic appeal.\nBuilding upon this foundation, we propose OmniStyle, a framework based on the\nDiffusion Transformer (DiT) architecture designed for high-quality and\nefficient style transfer. This framework supports both instruction-guided and\nimage-guided style transfer, generating high resolution outputs with\nexceptional detail. Extensive qualitative and quantitative evaluations\ndemonstrate OmniStyle's superior performance compared to existing approaches,\nhighlighting its efficiency and versatility. OmniStyle-1M and its accompanying\nmethodologies provide a significant contribution to advancing high-quality\nstyle transfer, offering a valuable resource for the research community."}
{"id": "2505.13586", "pdf": "https://arxiv.org/pdf/2505.13586", "abs": "https://arxiv.org/abs/2505.13586", "authors": ["Pavel Rumiantsev", "Mark Coates"], "title": "Half Search Space is All You Need", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Neural Architecture Search (NAS) is a powerful tool for automating\narchitecture design. One-Shot NAS techniques, such as DARTS, have gained\nsubstantial popularity due to their combination of search efficiency with\nsimplicity of implementation. By design, One-Shot methods have high GPU memory\nrequirements during the search. To mitigate this issue, we propose to prune the\nsearch space in an efficient automatic manner to reduce memory consumption and\nsearch time while preserving the search accuracy. Specifically, we utilise\nZero-Shot NAS to efficiently remove low-performing architectures from the\nsearch space before applying One-Shot NAS to the pruned search space.\nExperimental results on the DARTS search space show that our approach reduces\nmemory consumption by 81% compared to the baseline One-Shot setup while\nachieving the same level of accuracy."}
{"id": "2505.13851", "pdf": "https://arxiv.org/pdf/2505.13851", "abs": "https://arxiv.org/abs/2505.13851", "authors": ["Sahil Shah", "Harsh Goel", "Sai Shankar Narasimhan", "Minkyu Choi", "S P Sharan", "Oguzhan Akcin", "Sandeep Chinchali"], "title": "A Challenge to Build Neuro-Symbolic Video Agents", "categories": ["cs.AI"], "comment": null, "summary": "Modern video understanding systems excel at tasks such as scene\nclassification, object detection, and short video retrieval. However, as video\nanalysis becomes increasingly central to real-world applications, there is a\ngrowing need for proactive video agents for the systems that not only interpret\nvideo streams but also reason about events and take informed actions. A key\nobstacle in this direction is temporal reasoning: while deep learning models\nhave made remarkable progress in recognizing patterns within individual frames\nor short clips, they struggle to understand the sequencing and dependencies of\nevents over time, which is critical for action-driven decision-making.\nAddressing this limitation demands moving beyond conventional deep learning\napproaches. We posit that tackling this challenge requires a neuro-symbolic\nperspective, where video queries are decomposed into atomic events, structured\ninto coherent sequences, and validated against temporal constraints. Such an\napproach can enhance interpretability, enable structured reasoning, and provide\nstronger guarantees on system behavior, all key properties for advancing\ntrustworthy video agents. To this end, we present a grand challenge to the\nresearch community: developing the next generation of intelligent video agents\nthat integrate three core capabilities: (1) autonomous video search and\nanalysis, (2) seamless real-world interaction, and (3) advanced content\ngeneration. By addressing these pillars, we can transition from passive\nperception to intelligent video agents that reason, predict, and act, pushing\nthe boundaries of video understanding."}
{"id": "2501.06146", "pdf": "https://arxiv.org/pdf/2501.06146", "abs": "https://arxiv.org/abs/2501.06146", "authors": ["Nikolai Lund K√ºhne", "Jan √òstergaard", "Jesper Jensen", "Zheng-Hua Tan"], "title": "xLSTM-SENet: xLSTM for Single-Channel Speech Enhancement", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted at INTERSPEECH 2025", "summary": "While attention-based architectures, such as Conformers, excel in speech\nenhancement, they face challenges such as scalability with respect to input\nsequence length. In contrast, the recently proposed Extended Long Short-Term\nMemory (xLSTM) architecture offers linear scalability. However, xLSTM-based\nmodels remain unexplored for speech enhancement. This paper introduces\nxLSTM-SENet, the first xLSTM-based single-channel speech enhancement system. A\ncomparative analysis reveals that xLSTM-and notably, even LSTM-can match or\noutperform state-of-the-art Mamba- and Conformer-based systems across various\nmodel sizes in speech enhancement on the VoiceBank+Demand dataset. Through\nablation studies, we identify key architectural design choices such as\nexponential gating and bidirectionality contributing to its effectiveness. Our\nbest xLSTM-based model, xLSTM-SENet2, outperforms state-of-the-art Mamba- and\nConformer-based systems of similar complexity on the Voicebank+DEMAND dataset."}
{"id": "2409.05034", "pdf": "https://arxiv.org/pdf/2409.05034", "abs": "https://arxiv.org/abs/2409.05034", "authors": ["Yang Xiao", "Rohan Kumar Das"], "title": "TF-Mamba: A Time-Frequency Network for Sound Source Localization", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted by Interspeech 2025", "summary": "Sound source localization (SSL) determines the position of sound sources\nusing multi-channel audio data. It is commonly used to improve speech\nenhancement and separation. Extracting spatial features is crucial for SSL,\nespecially in challenging acoustic environments. Recently, a novel structure\nreferred to as Mamba demonstrated notable performance across various\nsequence-based modalities. This study introduces the Mamba for SSL tasks. We\nconsider the Mamba-based model to analyze spatial features from speech signals\nby fusing both time and frequency features, and we develop an SSL system called\nTF-Mamba. This system integrates time and frequency fusion, with Bidirectional\nMamba managing both time-wise and frequency-wise processing. We conduct the\nexperiments on the simulated and real datasets. Experiments show that TF-Mamba\nsignificantly outperforms other advanced methods. The code will be publicly\nreleased in due course."}
{"id": "2505.13893", "pdf": "https://arxiv.org/pdf/2505.13893", "abs": "https://arxiv.org/abs/2505.13893", "authors": ["Yuanyi Wang", "Zhaoyi Yan", "Yiming Zhang", "Qi Zhou", "Yanggan Gu", "Fei Wu", "Hongxia Yang"], "title": "InfiGFusion: Graph-on-Logits Distillation via Efficient Gromov-Wasserstein for Model Fusion", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in large language models (LLMs) have intensified efforts to\nfuse heterogeneous open-source models into a unified system that inherits their\ncomplementary strengths. Existing logit-based fusion methods maintain inference\nefficiency but treat vocabulary dimensions independently, overlooking semantic\ndependencies encoded by cross-dimension interactions. These dependencies\nreflect how token types interact under a model's internal reasoning and are\nessential for aligning models with diverse generation behaviors. To explicitly\nmodel these dependencies, we propose \\textbf{InfiGFusion}, the first\nstructure-aware fusion framework with a novel \\textit{Graph-on-Logits\nDistillation} (GLD) loss. Specifically, we retain the top-$k$ logits per output\nand aggregate their outer products across sequence positions to form a global\nco-activation graph, where nodes represent vocabulary channels and edges\nquantify their joint activations. To ensure scalability and efficiency, we\ndesign a sorting-based closed-form approximation that reduces the original\n$O(n^4)$ cost of Gromov-Wasserstein distance to $O(n \\log n)$, with provable\napproximation guarantees. Experiments across multiple fusion settings show that\nGLD consistently improves fusion quality and stability. InfiGFusion outperforms\nSOTA models and fusion baselines across 11 benchmarks spanning reasoning,\ncoding, and mathematics. It shows particular strength in complex reasoning\ntasks, with +35.6 improvement on Multistep Arithmetic and +37.06 on Causal\nJudgement over SFT, demonstrating superior multi-step and relational inference."}
{"id": "2505.14029", "pdf": "https://arxiv.org/pdf/2505.14029", "abs": "https://arxiv.org/abs/2505.14029", "authors": ["Laura-Sophia von Hirschhausen", "Jannes S. Magnusson", "Mykyta Kovalenko", "Fredrik Boye", "Tanay Rawat", "Peter Eisert", "Anna Hilsmann", "Sebastian Pretzsch", "Sebastian Bosse"], "title": "AppleGrowthVision: A large-scale stereo dataset for phenological analysis, fruit detection, and 3D reconstruction in apple orchards", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep learning has transformed computer vision for precision agriculture, yet\napple orchard monitoring remains limited by dataset constraints. The lack of\ndiverse, realistic datasets and the difficulty of annotating dense,\nheterogeneous scenes. Existing datasets overlook different growth stages and\nstereo imagery, both essential for realistic 3D modeling of orchards and tasks\nlike fruit localization, yield estimation, and structural analysis. To address\nthese gaps, we present AppleGrowthVision, a large-scale dataset comprising two\nsubsets. The first includes 9,317 high resolution stereo images collected from\na farm in Brandenburg (Germany), covering six agriculturally validated growth\nstages over a full growth cycle. The second subset consists of 1,125 densely\nannotated images from the same farm in Brandenburg and one in Pillnitz\n(Germany), containing a total of 31,084 apple labels. AppleGrowthVision\nprovides stereo-image data with agriculturally validated growth stages,\nenabling precise phenological analysis and 3D reconstructions. Extending\nMinneApple with our data improves YOLOv8 performance by 7.69 % in terms of\nF1-score, while adding it to MinneApple and MAD boosts Faster R-CNN F1-score by\n31.06 %. Additionally, six BBCH stages were predicted with over 95 % accuracy\nusing VGG16, ResNet152, DenseNet201, and MobileNetv2. AppleGrowthVision bridges\nthe gap between agricultural science and computer vision, by enabling the\ndevelopment of robust models for fruit detection, growth modeling, and 3D\nanalysis in precision agriculture. Future work includes improving annotation,\nenhancing 3D reconstruction, and extending multimodal analysis across all\ngrowth stages."}
{"id": "2505.13614", "pdf": "https://arxiv.org/pdf/2505.13614", "abs": "https://arxiv.org/abs/2505.13614", "authors": ["Ke Sun"], "title": "Deterministic Bounds and Random Estimates of Metric Tensors on Neuromanifolds", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The high dimensional parameter space of modern deep neural networks -- the\nneuromanifold -- is endowed with a unique metric tensor defined by the Fisher\ninformation, estimating which is crucial for both theory and practical methods\nin deep learning. To analyze this tensor for classification networks, we return\nto a low dimensional space of probability distributions -- the core space --\nand carefully analyze the spectrum of its Riemannian metric. We extend our\ndiscoveries there into deterministic bounds of the metric tensor on the\nneuromanifold. We introduce an unbiased random estimate of the metric tensor\nand its bounds based on Hutchinson's trace estimator. It can be evaluated\nefficiently through a single backward pass and can be used to estimate the\ndiagonal, or block diagonal, or the full tensor. Its quality is guaranteed with\na standard deviation bounded by the true value up to scaling."}
{"id": "2505.13887", "pdf": "https://arxiv.org/pdf/2505.13887", "abs": "https://arxiv.org/abs/2505.13887", "authors": ["Junyang Wang", "Haiyang Xu", "Xi Zhang", "Ming Yan", "Ji Zhang", "Fei Huang", "Jitao Sang"], "title": "Mobile-Agent-V: A Video-Guided Approach for Effortless and Efficient Operational Knowledge Injection in Mobile Automation", "categories": ["cs.AI", "cs.CL"], "comment": "17 pages, 7 figures, 9 tables. arXiv admin note: substantial text\n  overlap with arXiv:2502.17110", "summary": "The exponential rise in mobile device usage necessitates streamlined\nautomation for effective task management, yet many AI frameworks fall short due\nto inadequate operational expertise. While manually written knowledge can\nbridge this gap, it is often burdensome and inefficient. We introduce\nMobile-Agent-V, an innovative framework that utilizes video as a guiding tool\nto effortlessly and efficiently inject operational knowledge into mobile\nautomation processes. By deriving knowledge directly from video content,\nMobile-Agent-V eliminates manual intervention, significantly reducing the\neffort and time required for knowledge acquisition. To rigorously evaluate this\napproach, we propose Mobile-Knowledge, a benchmark tailored to assess the\nimpact of external knowledge on mobile agent performance. Our experimental\nfindings demonstrate that Mobile-Agent-V enhances performance by 36% compared\nto existing methods, underscoring its effortless and efficient advantages in\nmobile automation."}
{"id": "2410.01162", "pdf": "https://arxiv.org/pdf/2410.01162", "abs": "https://arxiv.org/abs/2410.01162", "authors": ["Wonjune Kang", "Junteng Jia", "Chunyang Wu", "Wei Zhou", "Egor Lakomkin", "Yashesh Gaur", "Leda Sari", "Suyoun Kim", "Ke Li", "Jay Mahadeokar", "Ozlem Kalinli"], "title": "Frozen Large Language Models Can Perceive Paralinguistic Aspects of Speech", "categories": ["eess.AS", "cs.CL", "cs.SD"], "comment": "Accepted to Interspeech 2025", "summary": "This work studies the capabilities of a large language model (LLM) to\nunderstand paralinguistic aspects of speech without fine-tuning its weights. We\nutilize an end-to-end system with a speech encoder, which is trained to produce\ntoken embeddings such that the LLM's response to an expressive speech prompt is\naligned with its response to a semantically matching text prompt that has also\nbeen conditioned on the user's speaking style. This framework enables the\nencoder to generate tokens that capture both linguistic and paralinguistic\ninformation and effectively convey them to the LLM, even when the LLM's weights\nremain completely frozen. To the best of our knowledge, our work is the first\nto explore how to induce a frozen LLM to understand more than just linguistic\ncontent from speech inputs in a general interaction setting. Experiments\ndemonstrate that our system is able to produce higher quality and more\nempathetic responses to expressive speech prompts compared to several\nbaselines."}
{"id": "2410.06885", "pdf": "https://arxiv.org/pdf/2410.06885", "abs": "https://arxiv.org/abs/2410.06885", "authors": ["Yushen Chen", "Zhikang Niu", "Ziyang Ma", "Keqi Deng", "Chunhui Wang", "Jian Zhao", "Kai Yu", "Xie Chen"], "title": "F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching", "categories": ["eess.AS", "cs.SD"], "comment": "17 pages, 9 tables, 3 figures", "summary": "This paper introduces F5-TTS, a fully non-autoregressive text-to-speech\nsystem based on flow matching with Diffusion Transformer (DiT). Without\nrequiring complex designs such as duration model, text encoder, and phoneme\nalignment, the text input is simply padded with filler tokens to the same\nlength as input speech, and then the denoising is performed for speech\ngeneration, which was originally proved feasible by E2 TTS. However, the\noriginal design of E2 TTS makes it hard to follow due to its slow convergence\nand low robustness. To address these issues, we first model the input with\nConvNeXt to refine the text representation, making it easy to align with the\nspeech. We further propose an inference-time Sway Sampling strategy, which\nsignificantly improves our model's performance and efficiency. This sampling\nstrategy for flow step can be easily applied to existing flow matching based\nmodels without retraining. Our design allows faster training and achieves an\ninference RTF of 0.15, which is greatly improved compared to state-of-the-art\ndiffusion-based TTS models. Trained on a public 100K hours multilingual\ndataset, our F5-TTS exhibits highly natural and expressive zero-shot ability,\nseamless code-switching capability, and speed control efficiency. We have\nreleased all codes and checkpoints to promote community development, at\nhttps://SWivid.github.io/F5-TTS/."}
{"id": "2505.13903", "pdf": "https://arxiv.org/pdf/2505.13903", "abs": "https://arxiv.org/abs/2505.13903", "authors": ["Chengyu Shen", "Zhen Hao Wong", "Runming He", "Hao Liang", "Meiyi Qiang", "Zimo Meng", "Zhengyang Zhao", "Bohan Zeng", "Zhengzhou Zhu", "Bin Cui", "Wentao Zhang"], "title": "Let's Verify Math Questions Step by Step", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have recently achieved remarkable progress in\nmathematical reasoning. To enable such capabilities, many existing works\ndistill strong reasoning models into long chains of thought or design\nalgorithms to construct high-quality math QA data for training. However, these\nefforts primarily focus on generating correct reasoning paths and answers,\nwhile largely overlooking the validity of the questions themselves. In this\nwork, we propose Math Question Verification (MathQ-Verify), a novel five-stage\npipeline designed to rigorously filter ill-posed or under-specified math\nproblems. MathQ-Verify first performs format-level validation to remove\nredundant instructions and ensure that each question is syntactically\nwell-formed. It then formalizes each question, decomposes it into atomic\nconditions, and verifies them against mathematical definitions. Next, it\ndetects logical contradictions among these conditions, followed by a\ngoal-oriented completeness check to ensure the question provides sufficient\ninformation for solving. To evaluate this task, we use existing benchmarks\nalong with an additional dataset we construct, containing 2,147 math questions\nwith diverse error types, each manually double-validated. Experiments show that\nMathQ-Verify achieves state-of-the-art performance across multiple benchmarks,\nimproving the F1 score by up to 25 percentage points over the direct\nverification baseline. It further attains approximately 90% precision and 63%\nrecall through a lightweight model voting scheme. MathQ-Verify offers a\nscalable and accurate solution for curating reliable mathematical datasets,\nreducing label noise and avoiding unnecessary computation on invalid questions.\nOur code and data are available at https://github.com/scuuy/MathQ-Verify."}
{"id": "2505.14043", "pdf": "https://arxiv.org/pdf/2505.14043", "abs": "https://arxiv.org/abs/2505.14043", "authors": ["Qianqian Zhang", "WeiJun Wang", "Yunxing Liu", "Li Zhou", "Hao Zhao", "Junshe An", "Zihan Wang"], "title": "Selective Structured State Space for Multispectral-fused Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Target detection in high-resolution remote sensing imagery faces challenges\ndue to the low recognition accuracy of small targets and high computational\ncosts. The computational complexity of the Transformer architecture increases\nquadratically with image resolution, while Convolutional Neural Networks (CNN)\narchitectures are forced to stack deeper convolutional layers to expand their\nreceptive fields, leading to an explosive growth in computational demands. To\naddress these computational constraints, we leverage Mamba's linear complexity\nfor efficiency. However, Mamba's performance declines for small targets,\nprimarily because small targets occupy a limited area in the image and have\nlimited semantic information. Accurate identification of these small targets\nnecessitates not only Mamba's global attention capabilities but also the\nprecise capture of fine local details. To this end, we enhance Mamba by\ndeveloping the Enhanced Small Target Detection (ESTD) module and the\nConvolutional Attention Residual Gate (CARG) module. The ESTD module bolsters\nlocal attention to capture fine-grained details, while the CARG module, built\nupon Mamba, emphasizes spatial and channel-wise information, collectively\nimproving the model's ability to capture distinctive representations of small\ntargets. Additionally, to highlight the semantic representation of small\ntargets, we design a Mask Enhanced Pixel-level Fusion (MEPF) module for\nmultispectral fusion, which enhances target features by effectively fusing\nvisible and infrared multimodal information."}
{"id": "2505.13631", "pdf": "https://arxiv.org/pdf/2505.13631", "abs": "https://arxiv.org/abs/2505.13631", "authors": ["Andrei Manolache", "Luiz F. O. Chamon", "Mathias Niepert"], "title": "Learning (Approximately) Equivariant Networks via Constrained Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Equivariant neural networks are designed to respect symmetries through their\narchitecture, boosting generalization and sample efficiency when those\nsymmetries are present in the data distribution. Real-world data, however,\noften departs from perfect symmetry because of noise, structural variation,\nmeasurement bias, or other symmetry-breaking effects. Strictly equivariant\nmodels may struggle to fit the data, while unconstrained models lack a\nprincipled way to leverage partial symmetries. Even when the data is fully\nsymmetric, enforcing equivariance can hurt training by limiting the model to a\nrestricted region of the parameter space. Guided by homotopy principles, where\nan optimization problem is solved by gradually transforming a simpler problem\ninto a complex one, we introduce Adaptive Constrained Equivariance (ACE), a\nconstrained optimization approach that starts with a flexible, non-equivariant\nmodel and gradually reduces its deviation from equivariance. This gradual\ntightening smooths training early on and settles the model at a data-driven\nequilibrium, balancing between equivariance and non-equivariance. Across\nmultiple architectures and tasks, our method consistently improves performance\nmetrics, sample efficiency, and robustness to input perturbations compared with\nstrictly equivariant models and heuristic equivariance relaxations."}
{"id": "2505.13909", "pdf": "https://arxiv.org/pdf/2505.13909", "abs": "https://arxiv.org/abs/2505.13909", "authors": ["Yanheng He", "Jiahe Jin", "Pengfei Liu"], "title": "Efficient Agent Training for Computer Use", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "We open-source our entire suite of code, data, and models to\n  facilitate future research at https://github.com/GAIR-NLP/PC-Agent-E", "summary": "Scaling up high-quality trajectory data has long been a critical bottleneck\nfor developing human-like computer use agents. We introduce PC Agent-E, an\nefficient agent training framework that significantly reduces reliance on\nlarge-scale human demonstrations. Starting with just 312 human-annotated\ncomputer use trajectories, we further improved data quality by synthesizing\ndiverse action decisions with Claude 3.7 Sonnet. Trained on these enriched\ntrajectories, our PC Agent-E model achieved a remarkable 141% relative\nimprovement, surpassing the strong Claude 3.7 Sonnet with extended thinking on\nWindowsAgentArena-V2, an improved benchmark we also released. Furthermore, PC\nAgent-E demonstrates strong generalizability to different operating systems on\nOSWorld. Our findings suggest that strong computer use capabilities can be\nstimulated from a small amount of high-quality trajectory data."}
{"id": "2501.06474", "pdf": "https://arxiv.org/pdf/2501.06474", "abs": "https://arxiv.org/abs/2501.06474", "authors": ["Wen Wu", "Ziyun Cui", "Chang Lei", "Yinan Duan", "Diyang Qu", "Ji Wu", "Bowen Zhou", "Runsen Chen", "Chao Zhang"], "title": "The 1st SpeechWellness Challenge: Detecting Suicide Risk Among Adolescents", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "The 1st SpeechWellness Challenge (SW1) aims to advance methods for detecting\ncurrent suicide risk in adolescents using speech analysis techniques. Suicide\namong adolescents is a critical public health issue globally. Early detection\nof suicidal tendencies can lead to timely intervention and potentially save\nlives. Traditional methods of assessment often rely on self-reporting or\nclinical interviews, which may not always be accessible. The SW1 challenge\naddresses this gap by exploring speech as a non-invasive and readily available\nindicator of mental health. We release the SW1 dataset which contains speech\nrecordings from 600 adolescents aged 10-18 years. By focusing on speech\ngenerated from natural tasks, the challenge seeks to uncover patterns and\nmarkers that correlate with current suicide risk."}
{"id": "2501.17772", "pdf": "https://arxiv.org/pdf/2501.17772", "abs": "https://arxiv.org/abs/2501.17772", "authors": ["Theo Lepage", "Reda Dehak"], "title": "Self-Supervised Frameworks for Speaker Verification via Bootstrapped Positive Sampling", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "submitted to IEEE/ACM TASLP in January 2025", "summary": "Recent developments in Self-Supervised Learning (SSL) have demonstrated\nsignificant potential for Speaker Verification (SV), but closing the\nperformance gap with supervised systems remains an ongoing challenge. Standard\nSSL frameworks rely on anchor-positive pairs extracted from the same audio\nutterances. Hence, positives have channel characteristics similar to those of\ntheir corresponding anchors, even with extensive data-augmentation. Therefore,\nthis positive sampling strategy is a fundamental limitation as it encodes too\nmuch information regarding the recording source in the learned representations.\nThis article introduces Self-Supervised Positive Sampling (SSPS), a\nbootstrapped technique for sampling appropriate and diverse positives in SSL\nframeworks for SV. SSPS samples positives close to their anchor in the\nrepresentation space, under the assumption that these pseudo-positives belong\nto the same speaker identity but correspond to different recording conditions.\nThis method demonstrates consistent improvements in SV performance on VoxCeleb\nbenchmarks when implemented in major SSL frameworks, such as SimCLR, SwAV,\nVICReg, and DINO. Using SSPS, SimCLR, and DINO achieve 2.57% and 2.53% EER on\nVoxCeleb1-O. SimCLR yields a 58% relative reduction in EER, getting comparable\nperformance to DINO with a simpler training framework. Furthermore, SSPS lowers\nintra-class variance and reduces channel information in speaker representations\nwhile exhibiting greater robustness without data-augmentation."}
{"id": "2505.13908", "pdf": "https://arxiv.org/pdf/2505.13908", "abs": "https://arxiv.org/abs/2505.13908", "authors": ["Ajitesh Bankula", "Praney Bankula"], "title": "Cross-Linguistic Transfer in Multilingual NLP: The Role of Language Families and Morphology", "categories": ["cs.CL"], "comment": null, "summary": "Cross-lingual transfer has become a crucial aspect of multilingual NLP, as it\nallows for models trained on resource-rich languages to be applied to\nlow-resource languages more effectively. Recently massively multilingual\npre-trained language models (e.g., mBERT, XLM-R) demonstrate strong zero-shot\ntransfer capabilities[14] [13]. This paper investigates cross-linguistic\ntransfer through the lens of language families and morphology. Investigating\nhow language family proximity and morphological similarity affect performance\nacross NLP tasks. We further discuss our results and how it relates to findings\nfrom recent literature. Overall, we compare multilingual model performance and\nreview how linguistic distance metrics correlate with transfer outcomes. We\nalso look into emerging approaches that integrate typological and morphological\ninformation into model pre-training to improve transfer to diverse\nlanguages[18] [19]."}
{"id": "2505.14049", "pdf": "https://arxiv.org/pdf/2505.14049", "abs": "https://arxiv.org/abs/2505.14049", "authors": ["Yibo Gao", "Hangqi Zhou", "Zheyao Gao", "Bomin Wang", "Shangqi Gao", "Sihan Wang", "Xiahai Zhuang"], "title": "Learning Concept-Driven Logical Rules for Interpretable and Generalizable Medical Image Classification", "categories": ["cs.CV"], "comment": "early accepted by MICCAI 2025", "summary": "The pursuit of decision safety in clinical applications highlights the\npotential of concept-based methods in medical imaging. While these models offer\nactive interpretability, they often suffer from concept leakages, where\nunintended information within soft concept representations undermines both\ninterpretability and generalizability. Moreover, most concept-based models\nfocus solely on local explanations (instance-level), neglecting the global\ndecision logic (dataset-level). To address these limitations, we propose\nConcept Rule Learner (CRL), a novel framework to learn Boolean logical rules\nfrom binarized visual concepts. CRL employs logical layers to capture concept\ncorrelations and extract clinically meaningful rules, thereby providing both\nlocal and global interpretability. Experiments on two medical image\nclassification tasks show that CRL achieves competitive performance with\nexisting methods while significantly improving generalizability to\nout-of-distribution data. The code of our work is available at\nhttps://github.com/obiyoag/crl."}
{"id": "2505.13636", "pdf": "https://arxiv.org/pdf/2505.13636", "abs": "https://arxiv.org/abs/2505.13636", "authors": ["Baiting Chen", "Tong Zhu", "Jiale Han", "Lexin Li", "Gang Li", "Xiaowu Dai"], "title": "Incentivizing Truthful Language Models via Peer Elicitation Games", "categories": ["cs.LG", "cs.AI", "cs.GT"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong generative capabilities\nbut remain prone to inconsistencies and hallucinations. We introduce Peer\nElicitation Games (PEG), a training-free, game-theoretic framework for aligning\nLLMs through a peer elicitation mechanism involving a generator and multiple\ndiscriminators instantiated from distinct base models. Discriminators interact\nin a peer evaluation setting, where rewards are computed using a\ndeterminant-based mutual information score that provably incentivizes truthful\nreporting without requiring ground-truth labels. We establish theoretical\nguarantees showing that each agent, via online learning, achieves sublinear\nregret in the sense their cumulative performance approaches that of the best\nfixed truthful strategy in hindsight. Moreover, we prove last-iterate\nconvergence to a truthful Nash equilibrium, ensuring that the actual policies\nused by agents converge to stable and truthful behavior over time. Empirical\nevaluations across multiple benchmarks demonstrate significant improvements in\nfactual accuracy. These results position PEG as a practical approach for\neliciting truthful behavior from LLMs without supervision or fine-tuning."}
{"id": "2505.13914", "pdf": "https://arxiv.org/pdf/2505.13914", "abs": "https://arxiv.org/abs/2505.13914", "authors": ["Jake Chandler", "Richard Booth"], "title": "Parallel Belief Revision via Order Aggregation", "categories": ["cs.AI", "I.2.4"], "comment": null, "summary": "Despite efforts to better understand the constraints that operate on\nsingle-step parallel (aka \"package\", \"multiple\") revision, very little work has\nbeen carried out on how to extend the model to the iterated case. A recent\npaper by Delgrande & Jin outlines a range of relevant rationality postulates.\nWhile many of these are plausible, they lack an underlying unifying\nexplanation. We draw on recent work on iterated parallel contraction to offer a\ngeneral method for extending serial iterated belief revision operators to\nhandle parallel change. This method, based on a family of order aggregators\nknown as TeamQueue aggregators, provides a principled way to recover the\nindependently plausible properties that can be found in the literature, without\nyielding the more dubious ones."}
{"id": "2505.13085", "pdf": "https://arxiv.org/pdf/2505.13085", "abs": "https://arxiv.org/abs/2505.13085", "authors": ["Biel Tura Vecino", "Subhadeep Maji", "Aravind Varier", "Antonio Bonafonte", "Ivan Valles", "Michael Owen", "Leif R√§del", "Grant Strimel", "Seyi Feyisetan", "Roberto Barra Chicote", "Ariya Rastrow", "Constantinos Papayiannis", "Volker Leutnant", "Trevor Wood"], "title": "Universal Semantic Disentangled Privacy-preserving Speech Representation Learning", "categories": ["eess.AS", "cs.LG"], "comment": "Extended report of the article accepted at Interspeech 2025 (v1)", "summary": "The use of audio recordings of human speech to train LLMs poses privacy\nconcerns due to these models' potential to generate outputs that closely\nresemble artifacts in the training data. In this study, we propose a speaker\nprivacy-preserving representation learning method through the Universal Speech\nCodec (USC), a computationally efficient encoder-decoder model that\ndisentangles speech into: (i) privacy-preserving semantically rich\nrepresentations, capturing content and speech paralinguistics, and (ii)\nresidual acoustic and speaker representations that enables high-fidelity\nreconstruction. Extensive evaluations presented show that USC's semantic\nrepresentation preserves content, prosody, and sentiment, while removing\npotentially identifiable speaker attributes. Combining both representations,\nUSC achieves state-of-the-art speech reconstruction. Additionally, we introduce\nan evaluation methodology for measuring privacy-preserving properties, aligning\nwith perceptual tests. We compare USC against other codecs in the literature\nand demonstrate its effectiveness on privacy-preserving representation\nlearning, illustrating the trade-offs of speaker anonymization, paralinguistics\nretention and content preservation in the learned semantic representations.\nAudio samples are shared in https://www.amazon.science/usc-samples."}
{"id": "2505.13913", "pdf": "https://arxiv.org/pdf/2505.13913", "abs": "https://arxiv.org/abs/2505.13913", "authors": ["Hiram Ring"], "title": "Word length predicts word order: \"Min-max\"-ing drives language evolution", "categories": ["cs.CL"], "comment": null, "summary": "Current theories of language propose an innate (Baker 2001; Chomsky 1981) or\na functional (Greenberg 1963; Dryer 2007; Hawkins 2014) origin for the surface\nstructures (i.e. word order) that we observe in languages of the world, while\nevolutionary modeling (Dunn et al. 2011) suggests that descent is the primary\nfactor influencing such patterns. Although there are hypotheses for word order\nchange from both innate and usage-based perspectives for specific languages and\nfamilies, there are key disagreements between the two major proposals for\nmechanisms that drive the evolution of language more broadly (Wasow 2002; Levy\n2008). This paper proposes a universal underlying mechanism for word order\nchange based on a large tagged parallel dataset of over 1,500 languages\nrepresenting 133 language families and 111 isolates. Results indicate that word\nclass length is significantly correlated with word order crosslinguistically,\nbut not in a straightforward manner, partially supporting opposing theories of\nprocessing, while at the same time predicting historical word order change in\ntwo different phylogenetic lines and explaining more variance than descent or\nlanguage area in regression models. Such findings suggest an integrated\n\"Min-Max\" theory of language evolution driven by competing pressures of\nprocessing and information structure, aligning with recent efficiency-oriented\n(Levshina 2023) and information-theoretic proposals (Zaslavsky 2020; Tucker et\nal. 2025)."}
{"id": "2505.14059", "pdf": "https://arxiv.org/pdf/2505.14059", "abs": "https://arxiv.org/abs/2505.14059", "authors": ["Hao Feng", "Shu Wei", "Xiang Fei", "Wei Shi", "Yingdong Han", "Lei Liao", "Jinghui Lu", "Binghong Wu", "Qi Liu", "Chunhui Lin", "Jingqun Tang", "Hao Liu", "Can Huang"], "title": "Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting", "categories": ["cs.CV"], "comment": "Accepted to ACL 2025", "summary": "Document image parsing is challenging due to its complexly intertwined\nelements such as text paragraphs, figures, formulas, and tables. Current\napproaches either assemble specialized expert models or directly generate\npage-level content autoregressively, facing integration overhead, efficiency\nbottlenecks, and layout structure degradation despite their decent performance.\nTo address these limitations, we present \\textit{Dolphin}\n(\\textit{\\textbf{Do}cument Image \\textbf{P}arsing via \\textbf{H}eterogeneous\nAnchor Prompt\\textbf{in}g}), a novel multimodal document image parsing model\nfollowing an analyze-then-parse paradigm. In the first stage, Dolphin generates\na sequence of layout elements in reading order. These heterogeneous elements,\nserving as anchors and coupled with task-specific prompts, are fed back to\nDolphin for parallel content parsing in the second stage. To train Dolphin, we\nconstruct a large-scale dataset of over 30 million samples, covering\nmulti-granularity parsing tasks. Through comprehensive evaluations on both\nprevalent benchmarks and self-constructed ones, Dolphin achieves\nstate-of-the-art performance across diverse page-level and element-level\nsettings, while ensuring superior efficiency through its lightweight\narchitecture and parallel parsing mechanism. The code and pre-trained models\nare publicly available at https://github.com/ByteDance/Dolphin"}
{"id": "2505.13638", "pdf": "https://arxiv.org/pdf/2505.13638", "abs": "https://arxiv.org/abs/2505.13638", "authors": ["Massimo Fioravanti", "Giovanni Agosta"], "title": "4Hammer: a board-game reinforcement learning environment for the hour long time frame", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong performance on tasks\nwith short time frames, but struggle with tasks requiring longer durations.\nWhile datasets covering extended-duration tasks, such as software engineering\ntasks or video games, do exist, there are currently few implementations of\ncomplex board games specifically designed for reinforcement learning and LLM\nevaluation. To address this gap, we propose the 4Hammer reinforcement learning\nenvironment, a digital twin simulation of a subset of Warhammer 40,000-a\ncomplex, zero-sum board game. Warhammer 40,000 features intricate rules,\nrequiring human players to thoroughly read and understand over 50 pages of\ndetailed natural language rules, grasp the interactions between their game\npieces and those of their opponents, and independently track and communicate\nthe evolving game state."}
{"id": "2505.13940", "pdf": "https://arxiv.org/pdf/2505.13940", "abs": "https://arxiv.org/abs/2505.13940", "authors": ["Kun Li", "Zhennan Wu", "Shoupeng Wang", "Wenbin Hu"], "title": "DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery", "categories": ["cs.AI", "q-bio.BM"], "comment": "22 pages, 10 figures, 5 tables", "summary": "In the field of AI4Science, large-scale language models (LLMs) show great\npotential to parse complex scientific semantics, integrate cross-disciplinary\nknowledge, and assist critical task research. However, in the field of drug\ndiscovery, despite the optimization through professional data pre-training,\ncontext window expansion, and internet search, the existing LLMs are still\nfacing challenges such as massive multi-modal and heterogeneous data\nprocessing, domain knowledge dynamic updating delay, and insufficient\nconfidence in predicting the results of complex computational tasks. To address\nthese challenges, we propose the DrugPilot, an LLM-based agent with\nparameterized reasoning for drug discovery. DrugPilot addresses key limitations\nof traditional end-to-end LLM prediction approaches through its parametric\ninference architecture. This agent system supports major phases of the drug\ndiscovery pipeline, facilitating automated planning and execution of\nmulti-stage research tasks. To address the critical challenge of multi-modal\ndrug data analysis (incorporating both public datasets and user-submitted\ndata), we developed an interactive parameterized memory pool. This innovative\ncomponent standardizes real-world drug data into parametric representations,\nsimultaneously enabling efficient knowledge retrieval in multi-turn dialogue\nwhile mitigating the information loss inherent in text-based data transmission.\nAdditionally, we created a drug instruct dataset across 8 essential drug\ndiscovery tasks for model fine-tuning and evaluation. Based on the Berkeley\nfunction calling evaluation framework, DrugPilot demonstrated the most advanced\ntool calling capabilities on our drug discovery tool instruction dataset,\noutperforming existing agents (e.g., ReAct, LoT). Specifically, it achieves\ntask completion rates of 98.0%, 93.5%, and 64.0% on simple, multiple, and\nmulti-turn tasks, respectively."}
{"id": "2505.13936", "pdf": "https://arxiv.org/pdf/2505.13936", "abs": "https://arxiv.org/abs/2505.13936", "authors": ["Saydul Akbar Murad", "Ashim Dahal", "Nick Rahimi"], "title": "EEG-to-Text Translation: A Model for Deciphering Human Brain Activity", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With the rapid advancement of large language models like Gemini, GPT, and\nothers, bridging the gap between the human brain and language processing has\nbecome an important area of focus. To address this challenge, researchers have\ndeveloped various models to decode EEG signals into text. However, these models\nstill face significant performance limitations. To overcome these shortcomings,\nwe propose a new model, R1 Translator, which aims to improve the performance of\nEEG-to-text decoding. The R1 Translator model combines a bidirectional LSTM\nencoder with a pretrained transformer-based decoder, utilizing EEG features to\nproduce high-quality text outputs. The model processes EEG embeddings through\nthe LSTM to capture sequential dependencies, which are then fed into the\ntransformer decoder for effective text generation. The R1 Translator excels in\nROUGE metrics, outperforming both T5 (previous research) and Brain Translator.\nSpecifically, R1 achieves a ROUGE-1 score of 38.00% (P), which is up to 9%\nhigher than T5 (34.89%) and 3% better than Brain (35.69%). It also leads in\nROUGE-L, with a F1 score of 32.51%, outperforming T5 by 3% (29.67%) and Brain\nby 2% (30.38%). In terms of CER, R1 achieves a CER of 0.5795, which is 2% lower\nthan T5 (0.5917) and 4% lower than Brain (0.6001). Additionally, R1 performs\nbetter in WER with a score of 0.7280, outperforming T5 by 4.3% (0.7610) and\nBrain by 3.6% (0.7553). Code is available at\nhttps://github.com/Mmurrad/EEG-To-text."}
{"id": "2505.14062", "pdf": "https://arxiv.org/pdf/2505.14062", "abs": "https://arxiv.org/abs/2505.14062", "authors": ["Bo Li", "Haoke Xiao", "Lv Tang"], "title": "Scaling Vision Mamba Across Resolutions via Fractal Traversal", "categories": ["cs.CV"], "comment": "Work in progressing", "summary": "Vision Mamba has recently emerged as a promising alternative to\nTransformer-based architectures, offering linear complexity in sequence length\nwhile maintaining strong modeling capacity. However, its adaptation to visual\ninputs is hindered by challenges in 2D-to-1D patch serialization and weak\nscalability across input resolutions. Existing serialization strategies such as\nraster scanning disrupt local spatial continuity and limit the model's ability\nto generalize across scales. In this paper, we propose FractalMamba++, a robust\nvision backbone that leverages fractal-based patch serialization via Hilbert\ncurves to preserve spatial locality and enable seamless resolution\nadaptability. To address long-range dependency fading in high-resolution\ninputs, we further introduce a Cross-State Routing (CSR) mechanism that\nenhances global context propagation through selective state reuse.\nAdditionally, we propose a Positional-Relation Capture (PRC) module to recover\nlocal adjacency disrupted by curve inflection points. Extensive experiments on\nimage classification, semantic segmentation, object detection, and change\ndetection demonstrate that FractalMamba++ consistently outperforms previous\nMamba-based backbones, particularly under high-resolution settings."}
{"id": "2505.13643", "pdf": "https://arxiv.org/pdf/2505.13643", "abs": "https://arxiv.org/abs/2505.13643", "authors": ["Rakibul Hasan Rajib", "Md Akil Raihan Iftee", "Mir Sazzat Hossain", "A. K. M. Mahbubur Rahman", "Sajib Mistry", "M Ashraful Amin", "Amin Ahsan Ali"], "title": "FedCTTA: A Collaborative Approach to Continual Test-Time Adaptation in Federated Learning", "categories": ["cs.LG", "cs.CV"], "comment": "8 pages, 5 figures, Accepted In IJCNN 2025", "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, making it ideal for\nprivacy-sensitive applications. However, FL models often suffer performance\ndegradation due to distribution shifts between training and deployment.\nTest-Time Adaptation (TTA) offers a promising solution by allowing models to\nadapt using only test samples. However, existing TTA methods in FL face\nchallenges such as computational overhead, privacy risks from feature sharing,\nand scalability concerns due to memory constraints. To address these\nlimitations, we propose Federated Continual Test-Time Adaptation (FedCTTA), a\nprivacy-preserving and computationally efficient framework for federated\nadaptation. Unlike prior methods that rely on sharing local feature statistics,\nFedCTTA avoids direct feature exchange by leveraging similarity-aware\naggregation based on model output distributions over randomly generated noise\nsamples. This approach ensures adaptive knowledge sharing while preserving data\nprivacy. Furthermore, FedCTTA minimizes the entropy at each client for\ncontinual adaptation, enhancing the model's confidence in evolving target\ndistributions. Our method eliminates the need for server-side training during\nadaptation and maintains a constant memory footprint, making it scalable even\nas the number of clients or training rounds increases. Extensive experiments\nshow that FedCTTA surpasses existing methods across diverse temporal and\nspatial heterogeneity scenarios."}
{"id": "2505.13946", "pdf": "https://arxiv.org/pdf/2505.13946", "abs": "https://arxiv.org/abs/2505.13946", "authors": ["Changdae Oh", "Jiatong Li", "Shawn Im", "Yixuan Li"], "title": "Visual Instruction Bottleneck Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Despite widespread adoption, multimodal large language models (MLLMs) suffer\nperformance degradation when encountering unfamiliar queries under distribution\nshifts. Existing methods to improve MLLM generalization typically require\neither more instruction data or larger advanced model architectures, both of\nwhich incur non-trivial human labor or computational costs. In this work, we\ntake an alternative approach to enhance the robustness of MLLMs under\ndistribution shifts, from a representation learning perspective. Inspired by\nthe information bottleneck (IB) principle, we derive a variational lower bound\nof the IB for MLLMs and devise a practical implementation, Visual Instruction\nBottleneck Tuning (Vittle). We then provide a theoretical justification of\nVittle by revealing its connection to an information-theoretic robustness\nmetric of MLLM. Empirical validation of three MLLMs on open-ended and\nclosed-form question answering and object hallucination detection tasks over 45\ndatasets, including 30 shift scenarios, demonstrates that Vittle consistently\nimproves the MLLM's robustness under shifts by pursuing the learning of a\nminimal sufficient representation."}
{"id": "2505.13944", "pdf": "https://arxiv.org/pdf/2505.13944", "abs": "https://arxiv.org/abs/2505.13944", "authors": ["Bao-Ngoc Dao", "Quang Nguyen", "Luyen Ngo Dinh", "Minh Le", "Nam Le", "Linh Ngo Van"], "title": "Towards Rehearsal-Free Continual Relation Extraction: Capturing Within-Task Variance with Adaptive Prompting", "categories": ["cs.CL"], "comment": null, "summary": "Memory-based approaches have shown strong performance in Continual Relation\nExtraction (CRE). However, storing examples from previous tasks increases\nmemory usage and raises privacy concerns. Recently, prompt-based methods have\nemerged as a promising alternative, as they do not rely on storing past\nsamples. Despite this progress, current prompt-based techniques face several\ncore challenges in CRE, particularly in accurately identifying task identities\nand mitigating catastrophic forgetting. Existing prompt selection strategies\noften suffer from inaccuracies, lack robust mechanisms to prevent forgetting in\nshared parameters, and struggle to handle both cross-task and within-task\nvariations. In this paper, we propose WAVE++, a novel approach inspired by the\nconnection between prefix-tuning and mixture of experts. Specifically, we\nintroduce task-specific prompt pools that enhance flexibility and adaptability\nacross diverse tasks while avoiding boundary-spanning risks; this design more\neffectively captures variations within each task and across tasks. To further\nrefine relation classification, we incorporate label descriptions that provide\nricher, more global context, enabling the model to better distinguish among\ndifferent relations. We also propose a training-free mechanism to improve task\nprediction during inference. Moreover, we integrate a generative model to\nconsolidate prior knowledge within the shared parameters, thereby removing the\nneed for explicit data storage. Extensive experiments demonstrate that WAVE++\noutperforms state-of-the-art prompt-based and rehearsal-based methods, offering\na more robust solution for continual relation extraction. Our code is publicly\navailable at https://github.com/PiDinosauR2804/WAVE-CRE-PLUS-PLUS."}
{"id": "2505.14068", "pdf": "https://arxiv.org/pdf/2505.14068", "abs": "https://arxiv.org/abs/2505.14068", "authors": ["Zhenyu Li", "Tianyi Shang", "Pengjie Xu", "Zhaojun Deng"], "title": "Place Recognition: A Comprehensive Review, Current Challenges and Future Directions", "categories": ["cs.CV"], "comment": "35 pages", "summary": "Place recognition is a cornerstone of vehicle navigation and mapping, which\nis pivotal in enabling systems to determine whether a location has been\npreviously visited. This capability is critical for tasks such as loop closure\nin Simultaneous Localization and Mapping (SLAM) and long-term navigation under\nvarying environmental conditions. In this survey, we comprehensively review\nrecent advancements in place recognition, emphasizing three representative\nmethodological paradigms: Convolutional Neural Network (CNN)-based approaches,\nTransformer-based frameworks, and cross-modal strategies. We begin by\nelucidating the significance of place recognition within the broader context of\nautonomous systems. Subsequently, we trace the evolution of CNN-based methods,\nhighlighting their contributions to robust visual descriptor learning and\nscalability in large-scale environments. We then examine the emerging class of\nTransformer-based models, which leverage self-attention mechanisms to capture\nglobal dependencies and offer improved generalization across diverse scenes.\nFurthermore, we discuss cross-modal approaches that integrate heterogeneous\ndata sources such as Lidar, vision, and text description, thereby enhancing\nresilience to viewpoint, illumination, and seasonal variations. We also\nsummarize standard datasets and evaluation metrics widely adopted in the\nliterature. Finally, we identify current research challenges and outline\nprospective directions, including domain adaptation, real-time performance, and\nlifelong learning, to inspire future advancements in this domain. The unified\nframework of leading-edge place recognition methods, i.e., code library, and\nthe results of their experimental evaluations are available at\nhttps://github.com/CV4RA/SOTA-Place-Recognitioner."}
{"id": "2505.13644", "pdf": "https://arxiv.org/pdf/2505.13644", "abs": "https://arxiv.org/abs/2505.13644", "authors": ["Felix Dangel", "Tim Siebert", "Marius Zeinhofer", "Andrea Walther"], "title": "Collapsing Taylor Mode Automatic Differentiation", "categories": ["cs.LG"], "comment": "10 pages + appendix", "summary": "Computing partial differential equation (PDE) operators via nested\nbackpropagation is expensive, yet popular, and severely restricts their utility\nfor scientific machine learning. Recent advances, like the forward Laplacian\nand randomizing Taylor mode automatic differentiation (AD), propose forward\nschemes to address this. We introduce an optimization technique for Taylor mode\nthat 'collapses' derivatives by rewriting the computational graph, and\ndemonstrate how to apply it to general linear PDE operators, and randomized\nTaylor mode. The modifications simply require propagating a sum up the\ncomputational graph, which could -- or should -- be done by a machine learning\ncompiler, without exposing complexity to users. We implement our collapsing\nprocedure and evaluate it on popular PDE operators, confirming it accelerates\nTaylor mode and outperforms nested backpropagation."}
{"id": "2505.13986", "pdf": "https://arxiv.org/pdf/2505.13986", "abs": "https://arxiv.org/abs/2505.13986", "authors": ["Qize Jiang", "Linsey Pang", "Alice Gatti", "Mahima Aggarwa", "Giovanna Vantin", "Xiaosong Ma", "Weiwei Sun", "Sanjay Chawla"], "title": "Solving Normalized Cut Problem with Constrained Action Space", "categories": ["math.OC", "cs.AI", "cs.LG", "I.2.8"], "comment": null, "summary": "Reinforcement Learning (RL) has emerged as an important paradigm to solve\ncombinatorial optimization problems primarily due to its ability to learn\nheuristics that can generalize across problem instances. However, integrating\nexternal knowledge that will steer combinatorial optimization problem solutions\ntowards domain appropriate outcomes remains an extremely challenging task. In\nthis paper, we propose the first RL solution that uses constrained action\nspaces to guide the normalized cut problem towards pre-defined template\ninstances. Using transportation networks as an example domain, we create a\nWedge and Ring Transformer that results in graph partitions that are shaped in\nform of Wedges and Rings and which are likely to be closer to natural optimal\npartitions. However, our approach is general as it is based on principles that\ncan be generalized to other domains."}
{"id": "2505.13949", "pdf": "https://arxiv.org/pdf/2505.13949", "abs": "https://arxiv.org/abs/2505.13949", "authors": ["Guochao Jiang", "Guofeng Quan", "Zepeng Ding", "Ziqin Luo", "Dixuan Wang", "Zheng Hu"], "title": "FlashThink: An Early Exit Method For Efficient Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance in reasoning\ntasks. However, LLMs tend to generate excessively long reasoning content,\nleading to significant computational overhead. Our observations indicate that\neven on simple problems, LLMs tend to produce unnecessarily lengthy reasoning\ncontent, which is against intuitive expectations. Preliminary experiments show\nthat at a certain point during the generation process, the model is already\ncapable of producing the correct solution without completing the full reasoning\ncontent. Therefore, we consider that the reasoning process of the model can be\nexited early to achieve the purpose of efficient reasoning. We introduce a\nverification model that identifies the exact moment when the model can stop\nreasoning and still provide the correct answer. Comprehensive experiments on\nfour different benchmarks demonstrate that our proposed method, FlashThink,\neffectively shortens the reasoning content while preserving the model accuracy.\nFor the Deepseek-R1 and QwQ-32B models, we reduced the length of reasoning\ncontent by 77.04% and 77.47%, respectively, without reducing the accuracy."}
{"id": "2505.14088", "pdf": "https://arxiv.org/pdf/2505.14088", "abs": "https://arxiv.org/abs/2505.14088", "authors": ["Xi Chen", "Shen Yan", "Juelin Zhu", "Chen Chen", "Yu Liu", "Maojun Zhang"], "title": "Generalizable Multispectral Land Cover Classification via Frequency-Aware Mixture of Low-Rank Token Experts", "categories": ["cs.CV"], "comment": null, "summary": "We introduce Land-MoE, a novel approach for multispectral land cover\nclassification (MLCC). Spectral shift, which emerges from disparities in\nsensors and geospatial conditions, poses a significant challenge in this\ndomain. Existing methods predominantly rely on domain adaptation and\ngeneralization strategies, often utilizing small-scale models that exhibit\nlimited performance. In contrast, Land-MoE addresses these issues by\nhierarchically inserting a Frequency-aware Mixture of Low-rank Token Experts,\nto fine-tune Vision Foundation Models (VFMs) in a parameter-efficient manner.\nSpecifically, Land-MoE comprises two key modules: the mixture of low-rank token\nexperts (MoLTE) and frequency-aware filters (FAF). MoLTE leverages\nrank-differentiated tokens to generate diverse feature adjustments for\nindividual instances within multispectral images. By dynamically combining\nlearnable low-rank token experts of varying ranks, it enhances the robustness\nagainst spectral shifts. Meanwhile, FAF conducts frequency-domain modulation on\nthe refined features. This process enables the model to effectively capture\nfrequency band information that is strongly correlated with semantic essence,\nwhile simultaneously suppressing frequency noise irrelevant to the task.\nComprehensive experiments on MLCC tasks involving cross-sensor and\ncross-geospatial setups demonstrate that Land-MoE outperforms existing methods\nby a large margin. Additionally, the proposed approach has also achieved\nstate-of-the-art performance in domain generalization semantic segmentation\ntasks of RGB remote sensing images."}
{"id": "2505.13650", "pdf": "https://arxiv.org/pdf/2505.13650", "abs": "https://arxiv.org/abs/2505.13650", "authors": ["Chou-Ying Hsieh", "Chun-Fu Jang", "Cheng-En Hsieh", "Qian-Hui Chen", "Sy-Yen Kuo"], "title": "Self-Reinforced Graph Contrastive Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graphs serve as versatile data structures in numerous real-world\ndomains-including social networks, molecular biology, and knowledge graphs-by\ncapturing intricate relational information among entities. Among graph-based\nlearning techniques, Graph Contrastive Learning (GCL) has gained significant\nattention for its ability to derive robust, self-supervised graph\nrepresentations through the contrasting of positive and negative sample pairs.\nHowever, a critical challenge lies in ensuring high-quality positive pairs so\nthat the intrinsic semantic and structural properties of the original graph are\npreserved rather than distorted. To address this issue, we propose SRGCL\n(Self-Reinforced Graph Contrastive Learning), a novel framework that leverages\nthe model's own encoder to dynamically evaluate and select high-quality\npositive pairs. We designed a unified positive pair generator employing\nmultiple augmentation strategies, and a selector guided by the manifold\nhypothesis to maintain the underlying geometry of the latent space. By adopting\na probabilistic mechanism for selecting positive pairs, SRGCL iteratively\nrefines its assessment of pair quality as the encoder's representational power\nimproves. Extensive experiments on diverse graph-level classification tasks\ndemonstrate that SRGCL, as a plug-in module, consistently outperforms\nstate-of-the-art GCL methods, underscoring its adaptability and efficacy across\nvarious domains."}
{"id": "2505.14001", "pdf": "https://arxiv.org/pdf/2505.14001", "abs": "https://arxiv.org/abs/2505.14001", "authors": ["Sterre Lutz", "Matthijs T. J. Spaan", "Anna Lukina"], "title": "VeRecycle: Reclaiming Guarantees from Probabilistic Certificates for Stochastic Dynamical Systems after Change", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "accepted to IJCAI 2025", "summary": "Autonomous systems operating in the real world encounter a range of\nuncertainties. Probabilistic neural Lyapunov certification is a powerful\napproach to proving safety of nonlinear stochastic dynamical systems. When\nfaced with changes beyond the modeled uncertainties, e.g., unidentified\nobstacles, probabilistic certificates must be transferred to the new system\ndynamics. However, even when the changes are localized in a known part of the\nstate space, state-of-the-art requires complete re-certification, which is\nparticularly costly for neural certificates. We introduce VeRecycle, the first\nframework to formally reclaim guarantees for discrete-time stochastic dynamical\nsystems. VeRecycle efficiently reuses probabilistic certificates when the\nsystem dynamics deviate only in a given subset of states. We present a general\ntheoretical justification and algorithmic implementation. Our experimental\nevaluation shows scenarios where VeRecycle both saves significant computational\neffort and achieves competitive probabilistic guarantees in compositional\nneural control."}
{"id": "2505.13963", "pdf": "https://arxiv.org/pdf/2505.13963", "abs": "https://arxiv.org/abs/2505.13963", "authors": ["Qianli Wang", "Mingyang Wang", "Nils Feldhus", "Simon Ostermann", "Yuan Cao", "Hinrich Sch√ºtze", "Sebastian M√∂ller", "Vera Schmitt"], "title": "Through a Compressed Lens: Investigating the Impact of Quantization on LLM Explainability and Interpretability", "categories": ["cs.CL", "cs.LG"], "comment": "In submission", "summary": "Quantization methods are widely used to accelerate inference and streamline\nthe deployment of large language models (LLMs). While prior research has\nextensively investigated the degradation of various LLM capabilities due to\nquantization, its effects on model explainability and interpretability, which\nare crucial for understanding decision-making processes, remain unexplored. To\naddress this gap, we conduct comprehensive experiments using three common\nquantization techniques at distinct bit widths, in conjunction with two\nexplainability methods, counterfactual examples and natural language\nexplanations, as well as two interpretability approaches, knowledge\nmemorization analysis and latent multi-hop reasoning analysis. We complement\nour analysis with a thorough user study, evaluating selected explainability\nmethods. Our findings reveal that, depending on the configuration, quantization\ncan significantly impact model explainability and interpretability. Notably,\nthe direction of this effect is not consistent, as it strongly depends on (1)\nthe quantization method, (2) the explainability or interpretability approach,\nand (3) the evaluation protocol. In some settings, human evaluation shows that\nquantization degrades explainability, while in others, it even leads to\nimprovements. Our work serves as a cautionary tale, demonstrating that\nquantization can unpredictably affect model transparency. This insight has\nimportant implications for deploying LLMs in applications where transparency is\na critical requirement."}
{"id": "2505.14100", "pdf": "https://arxiv.org/pdf/2505.14100", "abs": "https://arxiv.org/abs/2505.14100", "authors": ["Qianxiong Xu", "Lanyun Zhu", "Xuanyi Liu", "Guosheng Lin", "Cheng Long", "Ziyue Li", "Rui Zhao"], "title": "Unlocking the Power of SAM 2 for Few-Shot Segmentation", "categories": ["cs.CV"], "comment": "This paper is accepted by ICML'25", "summary": "Few-Shot Segmentation (FSS) aims to learn class-agnostic segmentation on few\nclasses to segment arbitrary classes, but at the risk of overfitting. To\naddress this, some methods use the well-learned knowledge of foundation models\n(e.g., SAM) to simplify the learning process. Recently, SAM 2 has extended SAM\nby supporting video segmentation, whose class-agnostic matching ability is\nuseful to FSS. A simple idea is to encode support foreground (FG) features as\nmemory, with which query FG features are matched and fused. Unfortunately, the\nFG objects in different frames of SAM 2's video data are always the same\nidentity, while those in FSS are different identities, i.e., the matching step\nis incompatible. Therefore, we design Pseudo Prompt Generator to encode pseudo\nquery memory, matching with query features in a compatible way. However, the\nmemories can never be as accurate as the real ones, i.e., they are likely to\ncontain incomplete query FG, and some unexpected query background (BG)\nfeatures, leading to wrong segmentation. Hence, we further design Iterative\nMemory Refinement to fuse more query FG features into the memory, and devise a\nSupport-Calibrated Memory Attention to suppress the unexpected query BG\nfeatures in memory. Extensive experiments have been conducted on PASCAL-5$^i$\nand COCO-20$^i$ to validate the effectiveness of our design, e.g., the 1-shot\nmIoU can be 4.2\\% better than the best baseline."}
{"id": "2505.13697", "pdf": "https://arxiv.org/pdf/2505.13697", "abs": "https://arxiv.org/abs/2505.13697", "authors": ["Soumya Rani Samineni", "Durgesh Kalwar", "Karthik Valmeekam", "Kaya Stechly", "Subbarao Kambhampati"], "title": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning-based post-training of large language models (LLMs)\nhas recently gained attention, particularly following the release of DeepSeek\nR1, which applied GRPO for fine-tuning. Amid the growing hype around improved\nreasoning abilities attributed to RL post-training, we critically examine the\nformulation and assumptions underlying these methods. We start by highlighting\nthe popular structural assumptions made in modeling LLM training as a Markov\nDecision Process (MDP), and show how they lead to a degenerate MDP that doesn't\nquite need the RL/GRPO apparatus. The two critical structural assumptions\ninclude (1) making the MDP states be just a concatenation of the actions-with\nstates becoming the context window and the actions becoming the tokens in LLMs\nand (2) splitting the reward of a state-action trajectory uniformly across the\ntrajectory. Through a comprehensive analysis, we demonstrate that these\nsimplifying assumptions make the approach effectively equivalent to an\noutcome-driven supervised learning. Our experiments on benchmarks including\nGSM8K and Countdown using Qwen-2.5 base models show that iterative supervised\nfine-tuning, incorporating both positive and negative samples, achieves\nperformance comparable to GRPO-based training. We will also argue that the\nstructural assumptions indirectly incentivize the RL to generate longer\nsequences of intermediate tokens-which in turn feeds into the narrative of \"RL\ngenerating longer thinking traces.\" While RL may well be a very useful\ntechnique for improving the reasoning abilities of LLMs, our analysis shows\nthat the simplistic structural assumptions made in modeling the underlying MDP\nrender the popular LLM RL frameworks and their interpretations questionable."}
{"id": "2505.14020", "pdf": "https://arxiv.org/pdf/2505.14020", "abs": "https://arxiv.org/abs/2505.14020", "authors": ["Hao Dong", "Ziyue Qiao", "Zhiyuan Ning", "Qi Hao", "Yi Du", "Pengyang Wang", "Yuanchun Zhou"], "title": "Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning", "categories": ["cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted to ACL 2025 Findings", "summary": "Temporal Knowledge Graphs (TKGs), as an extension of static Knowledge Graphs\n(KGs), incorporate the temporal feature to express the transience of knowledge\nby describing when facts occur. TKG extrapolation aims to infer possible future\nfacts based on known history, which has garnered significant attention in\nrecent years. Some existing methods treat TKG as a sequence of independent\nsubgraphs to model temporal evolution patterns, demonstrating impressive\nreasoning performance. However, they still have limitations: 1) In modeling\nsubgraph semantic evolution, they usually neglect the internal structural\ninteractions between subgraphs, which are actually crucial for encoding TKGs.\n2) They overlook the potential smooth features that do not lead to semantic\nchanges, which should be distinguished from the semantic evolution process.\nTherefore, we propose a novel Disentangled Multi-span Evolutionary Network\n(DiMNet) for TKG reasoning. Specifically, we design a multi-span evolution\nstrategy that captures local neighbor features while perceiving historical\nneighbor semantic information, thus enabling internal interactions between\nsubgraphs during the evolution process. To maximize the capture of semantic\nchange patterns, we design a disentangle component that adaptively separates\nnodes' active and stable features, used to dynamically control the influence of\nhistorical semantics on future evolution. Extensive experiments conducted on\nfour real-world TKG datasets show that DiMNet demonstrates substantial\nperformance in TKG reasoning, and outperforms the state-of-the-art up to 22.7%\nin MRR."}
{"id": "2505.13965", "pdf": "https://arxiv.org/pdf/2505.13965", "abs": "https://arxiv.org/abs/2505.13965", "authors": ["Jiamin Su", "Yibo Yan", "Zhuoran Gao", "Han Zhang", "Xiang Liu", "Xuming Hu"], "title": "CAFES: A Collaborative Multi-Agent Framework for Multi-Granular Multimodal Essay Scoring", "categories": ["cs.CL", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2502.11916", "summary": "Automated Essay Scoring (AES) is crucial for modern education, particularly\nwith the increasing prevalence of multimodal assessments. However, traditional\nAES methods struggle with evaluation generalizability and multimodal\nperception, while even recent Multimodal Large Language Model (MLLM)-based\napproaches can produce hallucinated justifications and scores misaligned with\nhuman judgment. To address the limitations, we introduce CAFES, the first\ncollaborative multi-agent framework specifically designed for AES. It\norchestrates three specialized agents: an Initial Scorer for rapid,\ntrait-specific evaluations; a Feedback Pool Manager to aggregate detailed,\nevidence-grounded strengths; and a Reflective Scorer that iteratively refines\nscores based on this feedback to enhance human alignment. Extensive\nexperiments, using state-of-the-art MLLMs, achieve an average relative\nimprovement of 21% in Quadratic Weighted Kappa (QWK) against ground truth,\nespecially for grammatical and lexical diversity. Our proposed CAFES framework\npaves the way for an intelligent multimodal AES system. The code will be\navailable upon acceptance."}
{"id": "2505.14105", "pdf": "https://arxiv.org/pdf/2505.14105", "abs": "https://arxiv.org/abs/2505.14105", "authors": ["Zs√≥fia Moln√°r", "Gergely Szab√≥", "Andr√°s Horv√°th"], "title": "Unintended Bias in 2D+ Image Segmentation and Its Effect on Attention Asymmetry", "categories": ["cs.CV"], "comment": null, "summary": "Supervised pretrained models have become widely used in deep learning,\nespecially for image segmentation tasks. However, when applied to specialized\ndatasets such as biomedical imaging, pretrained weights often introduce\nunintended biases. These biases cause models to assign different levels of\nimportance to different slices, leading to inconsistencies in feature\nutilization, which can be observed as asymmetries in saliency map\ndistributions. This transfer of color distributions from natural images to\nnon-natural datasets can compromise model performance and reduce the\nreliability of results. In this study, we investigate the effects of these\nbiases and propose strategies to mitigate them. Through a series of\nexperiments, we test both pretrained and randomly initialized models, comparing\ntheir performance and saliency map distributions. Our proposed methods, which\naim to neutralize the bias introduced by pretrained color channel weights,\ndemonstrate promising results, offering a practical approach to improving model\nexplainability while maintaining the benefits of pretrained models. This\npublication presents our findings, providing insights into addressing\npretrained weight biases across various deep learning tasks."}
{"id": "2505.13702", "pdf": "https://arxiv.org/pdf/2505.13702", "abs": "https://arxiv.org/abs/2505.13702", "authors": ["Mariana A. Fazio", "Salvador Sosa G√ºitron", "Marcus Babzien", "Mikhail Fedurin", "Junjie Li", "Mark Palmer", "Sandra S. Biedron", "Manel Martinez-Ramon"], "title": "Unsupervised anomaly detection in MeV ultrafast electron diffraction", "categories": ["cs.LG", "physics.ins-det"], "comment": null, "summary": "This study focus in the construction of an unsupervised anomaly detection\nmethodology to detect faulty images in MUED. We believe that unsupervised\ntechniques are the best choice for our purposes because the data used to train\nthe detector does not need to be manually labeled, and instead, the machine is\nintended to detect by itself the anomalies in the dataset, which liberates the\nuser of tedious, time-consuming initial image examination. The structure must,\nadditionally, provide the user with some measure of uncertainty in the\ndetection, so the user can take decisions based on this measure."}
{"id": "2505.14038", "pdf": "https://arxiv.org/pdf/2505.14038", "abs": "https://arxiv.org/abs/2505.14038", "authors": ["Xinzhe Zheng", "Sijie Ji", "Jiawei Sun", "Renqi Chen", "Wei Gao", "Mani Srivastava"], "title": "ProMind-LLM: Proactive Mental Health Care via Causal Reasoning with Sensor Data", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Mental health risk is a critical global public health challenge,\nnecessitating innovative and reliable assessment methods. With the development\nof large language models (LLMs), they stand out to be a promising tool for\nexplainable mental health care applications. Nevertheless, existing approaches\npredominantly rely on subjective textual mental records, which can be distorted\nby inherent mental uncertainties, leading to inconsistent and unreliable\npredictions. To address these limitations, this paper introduces ProMind-LLM.\nWe investigate an innovative approach integrating objective behavior data as\ncomplementary information alongside subjective mental records for robust mental\nhealth risk assessment. Specifically, ProMind-LLM incorporates a comprehensive\npipeline that includes domain-specific pretraining to tailor the LLM for mental\nhealth contexts, a self-refine mechanism to optimize the processing of\nnumerical behavioral data, and causal chain-of-thought reasoning to enhance the\nreliability and interpretability of its predictions. Evaluations of two\nreal-world datasets, PMData and Globem, demonstrate the effectiveness of our\nproposed methods, achieving substantial improvements over general LLMs. We\nanticipate that ProMind-LLM will pave the way for more dependable,\ninterpretable, and scalable mental health case solutions."}
{"id": "2505.13972", "pdf": "https://arxiv.org/pdf/2505.13972", "abs": "https://arxiv.org/abs/2505.13972", "authors": ["Qianli Wang", "Van Bach Nguyen", "Nils Feldhus", "Luis Felipe Villa-Arenas", "Christin Seifert", "Sebastian M√∂ller", "Vera Schmitt"], "title": "Truth or Twist? Optimal Model Selection for Reliable Label Flipping Evaluation in LLM-based Counterfactuals", "categories": ["cs.CL"], "comment": "in submission", "summary": "Counterfactual examples are widely employed to enhance the performance and\nrobustness of large language models (LLMs) through counterfactual data\naugmentation (CDA). However, the selection of the judge model used to evaluate\nlabel flipping, the primary metric for assessing the validity of generated\ncounterfactuals for CDA, yields inconsistent results. To decipher this, we\ndefine four types of relationships between the counterfactual generator and\njudge models. Through extensive experiments involving two state-of-the-art\nLLM-based methods, three datasets, five generator models, and 15 judge models,\ncomplemented by a user study (n = 90), we demonstrate that judge models with an\nindependent, non-fine-tuned relationship to the generator model provide the\nmost reliable label flipping evaluations. Relationships between the generator\nand judge models, which are closely aligned with the user study for CDA, result\nin better model performance and robustness. Nevertheless, we find that the gap\nbetween the most effective judge models and the results obtained from the user\nstudy remains considerably large. This suggests that a fully automated pipeline\nfor CDA may be inadequate and requires human intervention."}
{"id": "2505.14113", "pdf": "https://arxiv.org/pdf/2505.14113", "abs": "https://arxiv.org/abs/2505.14113", "authors": ["Bruno Viti", "Elias Karabelas", "Martin Holler"], "title": "CONSIGN: Conformal Segmentation Informed by Spatial Groupings via Decomposition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Most machine learning-based image segmentation models produce pixel-wise\nconfidence scores - typically derived from softmax outputs - that represent the\nmodel's predicted probability for each class label at every pixel. While this\ninformation can be particularly valuable in high-stakes domains such as medical\nimaging, these (uncalibrated) scores are heuristic in nature and do not\nconstitute rigorous quantitative uncertainty estimates. Conformal prediction\n(CP) provides a principled framework for transforming heuristic confidence\nscores into statistically valid uncertainty estimates. However, applying CP\ndirectly to image segmentation ignores the spatial correlations between pixels,\na fundamental characteristic of image data. This can result in overly\nconservative and less interpretable uncertainty estimates. To address this, we\npropose CONSIGN (Conformal Segmentation Informed by Spatial Groupings via\nDecomposition), a CP-based method that incorporates spatial correlations to\nimprove uncertainty quantification in image segmentation. Our method generates\nmeaningful prediction sets that come with user-specified, high-probability\nerror guarantees. It is compatible with any pre-trained segmentation model\ncapable of generating multiple sample outputs - such as those using dropout,\nBayesian modeling, or ensembles. We evaluate CONSIGN against a standard\npixel-wise CP approach across three medical imaging datasets and two COCO\ndataset subsets, using three different pre-trained segmentation models. Results\ndemonstrate that accounting for spatial structure significantly improves\nperformance across multiple metrics and enhances the quality of uncertainty\nestimates."}
{"id": "2505.13709", "pdf": "https://arxiv.org/pdf/2505.13709", "abs": "https://arxiv.org/abs/2505.13709", "authors": ["Jiayu Chen", "Aravind Venugopal", "Jeff Schneider"], "title": "Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) offers a powerful paradigm for\ndata-driven control. Compared to model-free approaches, offline model-based RL\n(MBRL) explicitly learns a world model from a static dataset and uses it as a\nsurrogate simulator, improving data efficiency and enabling potential\ngeneralization beyond the dataset support. However, most existing offline MBRL\nmethods follow a two-stage training procedure: first learning a world model by\nmaximizing the likelihood of the observed transitions, then optimizing a policy\nto maximize its expected return under the learned model. This objective\nmismatch results in a world model that is not necessarily optimized for\neffective policy learning. Moreover, we observe that policies learned via\noffline MBRL often lack robustness during deployment, and small adversarial\nnoise in the environment can lead to significant performance degradation. To\naddress these, we propose a framework that dynamically adapts the world model\nalongside the policy under a unified learning objective aimed at improving\nrobustness. At the core of our method is a maximin optimization problem, which\nwe solve by innovatively utilizing Stackelberg learning dynamics. We provide\ntheoretical analysis to support our design and introduce computationally\nefficient implementations. We benchmark our algorithm on twelve noisy D4RL\nMuJoCo tasks and three stochastic Tokamak Control tasks, demonstrating its\nstate-of-the-art performance."}
{"id": "2505.14072", "pdf": "https://arxiv.org/pdf/2505.14072", "abs": "https://arxiv.org/abs/2505.14072", "authors": ["Soroush Hashemifar", "Sherry Sahebi"], "title": "Personalized Student Knowledge Modeling for Future Learning Resource Prediction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Despite advances in deep learning for education, student knowledge tracing\nand behavior modeling face persistent challenges: limited personalization,\ninadequate modeling of diverse learning activities (especially non-assessed\nmaterials), and overlooking the interplay between knowledge acquisition and\nbehavioral patterns. Practical limitations, such as fixed-size sequence\nsegmentation, frequently lead to the loss of contextual information vital for\npersonalized learning. Moreover, reliance on student performance on assessed\nmaterials limits the modeling scope, excluding non-assessed interactions like\nlectures. To overcome these shortcomings, we propose Knowledge Modeling and\nMaterial Prediction (KMaP), a stateful multi-task approach designed for\npersonalized and simultaneous modeling of student knowledge and behavior. KMaP\nemploys clustering-based student profiling to create personalized student\nrepresentations, improving predictions of future learning resource preferences.\nExtensive experiments on two real-world datasets confirm significant behavioral\ndifferences across student clusters and validate the efficacy of the KMaP\nmodel."}
{"id": "2505.13973", "pdf": "https://arxiv.org/pdf/2505.13973", "abs": "https://arxiv.org/abs/2505.13973", "authors": ["Wenhui Zhu", "Xuanzhao Dong", "Xin Li", "Peijie Qiu", "Xiwen Chen", "Abolfazl Razi", "Aris Sotiras", "Yi Su", "Yalin Wang"], "title": "Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Recently, reinforcement learning (RL)-based tuning has shifted the trajectory\nof Multimodal Large Language Models (MLLMs), particularly following the\nintroduction of Group Relative Policy Optimization (GRPO). However, directly\napplying it to medical tasks remains challenging for achieving clinically\ngrounded model behavior. Motivated by the need to align model response with\nclinical expectations, we investigate four critical dimensions that affect the\neffectiveness of RL-based tuning in medical visual question answering (VQA):\nbase model initialization strategy, the role of medical semantic alignment, the\nimpact of length-based rewards on long-chain reasoning, and the influence of\nbias. We conduct extensive experiments to analyze these factors for medical\nMLLMs, providing new insights into how models are domain-specifically\nfine-tuned. Additionally, our results also demonstrate that GRPO-based RL\ntuning consistently outperforms standard supervised fine-tuning (SFT) in both\naccuracy and reasoning quality."}
{"id": "2505.14124", "pdf": "https://arxiv.org/pdf/2505.14124", "abs": "https://arxiv.org/abs/2505.14124", "authors": ["Hongjun Choi", "Eun Som Jeon", "Ankita Shukla", "Pavan Turaga"], "title": "Intra-class Patch Swap for Self-Distillation", "categories": ["cs.CV"], "comment": "Accepted for publication in Neurocomputing", "summary": "Knowledge distillation (KD) is a valuable technique for compressing large\ndeep learning models into smaller, edge-suitable networks. However,\nconventional KD frameworks rely on pre-trained high-capacity teacher networks,\nwhich introduce significant challenges such as increased memory/storage\nrequirements, additional training costs, and ambiguity in selecting an\nappropriate teacher for a given student model. Although a teacher-free\ndistillation (self-distillation) has emerged as a promising alternative, many\nexisting approaches still rely on architectural modifications or complex\ntraining procedures, which limit their generality and efficiency.\n  To address these limitations, we propose a novel framework based on\nteacher-free distillation that operates using a single student network without\nany auxiliary components, architectural modifications, or additional learnable\nparameters. Our approach is built on a simple yet highly effective\naugmentation, called intra-class patch swap augmentation. This augmentation\nsimulates a teacher-student dynamic within a single model by generating pairs\nof intra-class samples with varying confidence levels, and then applying\ninstance-to-instance distillation to align their predictive distributions. Our\nmethod is conceptually simple, model-agnostic, and easy to implement, requiring\nonly a single augmentation function. Extensive experiments across image\nclassification, semantic segmentation, and object detection show that our\nmethod consistently outperforms both existing self-distillation baselines and\nconventional teacher-based KD approaches. These results suggest that the\nsuccess of self-distillation could hinge on the design of the augmentation\nitself. Our codes are available at\nhttps://github.com/hchoi71/Intra-class-Patch-Swap."}
{"id": "2505.13723", "pdf": "https://arxiv.org/pdf/2505.13723", "abs": "https://arxiv.org/abs/2505.13723", "authors": ["Pratik Rathore", "Zachary Frangella", "Sachin Garg", "Shaghayegh Fazliani", "Micha≈Ç Derezi≈Ñski", "Madeleine Udell"], "title": "Turbocharging Gaussian Process Inference with Approximate Sketch-and-Project", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "28 pages, 6 figures, 2 tables", "summary": "Gaussian processes (GPs) play an essential role in biostatistics, scientific\nmachine learning, and Bayesian optimization for their ability to provide\nprobabilistic predictions and model uncertainty. However, GP inference\nstruggles to scale to large datasets (which are common in modern applications),\nsince it requires the solution of a linear system whose size scales\nquadratically with the number of samples in the dataset. We propose an\napproximate, distributed, accelerated sketch-and-project algorithm\n($\\texttt{ADASAP}$) for solving these linear systems, which improves\nscalability. We use the theory of determinantal point processes to show that\nthe posterior mean induced by sketch-and-project rapidly converges to the true\nposterior mean. In particular, this yields the first efficient, condition\nnumber-free algorithm for estimating the posterior mean along the top spectral\nbasis functions, showing that our approach is principled for GP inference.\n$\\texttt{ADASAP}$ outperforms state-of-the-art solvers based on conjugate\ngradient and coordinate descent across several benchmark datasets and a\nlarge-scale Bayesian optimization task. Moreover, $\\texttt{ADASAP}$ scales to a\ndataset with $> 3 \\cdot 10^8$ samples, a feat which has not been accomplished\nin the literature."}
{"id": "2505.14137", "pdf": "https://arxiv.org/pdf/2505.14137", "abs": "https://arxiv.org/abs/2505.14137", "authors": ["Vojtƒõch K≈Ør", "V√≠t Musil", "Vojtƒõch ≈òeh√°k"], "title": "Memory Assignment for Finite-Memory Strategies in Adversarial Patrolling Games", "categories": ["cs.AI"], "comment": null, "summary": "Adversarial Patrolling games form a subclass of Security games where a\nDefender moves between locations, guarding vulnerable targets. The main\nalgorithmic problem is constructing a strategy for the Defender that minimizes\nthe worst damage an Attacker can cause. We focus on the class of finite-memory\n(also known as regular) Defender's strategies that experimentally outperformed\nother competing classes. A finite-memory strategy can be seen as a positional\nstrategy on a finite set of states. Each state consists of a pair of a location\nand a certain integer value--called memory. Existing algorithms improve the\ntransitional probabilities between the states but require that the available\nmemory size itself is assigned at each location manually. Choosing the right\nmemory assignment is a well-known open and hard problem that hinders the\nusability of finite-memory strategies. We solve this issue by developing a\ngeneral method that iteratively changes the memory assignment. Our algorithm\ncan be used in connection with \\emph{any} black-box strategy optimization tool.\nWe evaluate our method on various experiments and show its robustness by\nsolving instances of various patrolling models."}
{"id": "2505.13975", "pdf": "https://arxiv.org/pdf/2505.13975", "abs": "https://arxiv.org/abs/2505.13975", "authors": ["Yuxuan Jiang", "Dawei Li", "Frank Ferraro"], "title": "DRP: Distilled Reasoning Pruning with Skill-aware Step Decomposition for Efficient Large Reasoning Models", "categories": ["cs.CL"], "comment": null, "summary": "While Large Reasoning Models (LRMs) have demonstrated success in complex\nreasoning tasks through long chain-of-thought (CoT) reasoning, their inference\noften involves excessively verbose reasoning traces, resulting in substantial\ninefficiency. To address this, we propose Distilled Reasoning Pruning (DRP), a\nhybrid framework that combines inference-time pruning with tuning-based\ndistillation, two widely used strategies for efficient reasoning. DRP uses a\nteacher model to perform skill-aware step decomposition and content pruning,\nand then distills the pruned reasoning paths into a student model, enabling it\nto reason both efficiently and accurately. Across several challenging\nmathematical reasoning datasets, we find that models trained with DRP achieve\nsubstantial improvements in token efficiency without sacrificing accuracy.\nSpecifically, DRP reduces average token usage on GSM8K from 917 to 328 while\nimproving accuracy from 91.7% to 94.1%, and achieves a 43% token reduction on\nAIME with no performance drop. Further analysis shows that aligning the\nreasoning structure of training CoTs with the student's reasoning capacity is\ncritical for effective knowledge transfer and performance gains."}
{"id": "2505.14135", "pdf": "https://arxiv.org/pdf/2505.14135", "abs": "https://arxiv.org/abs/2505.14135", "authors": ["Ruihuang Li", "Caijin Zhou", "Shoujian Zheng", "Jianxiang Lu", "Jiabin Huang", "Comi Chen", "Junshu Tang", "Guangzheng Xu", "Jiale Tao", "Hongmei Wang", "Donghao Li", "Wenqing Yu", "Senbo Wang", "Zhimin Li", "Yetshuan Shi", "Haoyu Yang", "Yukun Wang", "Wenxun Dai", "Jiaqi Li", "Linqing Wang", "Qixun Wang", "Zhiyong Xu", "Yingfang Zhang", "Jiangfeng Xiong", "Weijie Kong", "Chao Zhang", "Hongxin Zhang", "Qiaoling Zheng", "Weiting Guo", "Xinchi Deng", "Yixuan Li", "Renjia Wei", "Yulin Jian", "Duojun Huang", "Xuhua Ren", "Sihuan Lin", "Yifu Sun", "Yuan Zhou", "Joey Wang", "Qin Lin", "Jingmiao Yu", "Jihong Zhang", "Caesar Zhong", "Di Wang", "Yuhong Liu", "Linus", "Jie Jiang", "Longhuang Wu", "Shuai Shao", "Qinglin Lu"], "title": "Hunyuan-Game: Industrial-grade Intelligent Game Creation Model", "categories": ["cs.CV"], "comment": null, "summary": "Intelligent game creation represents a transformative advancement in game\ndevelopment, utilizing generative artificial intelligence to dynamically\ngenerate and enhance game content. Despite notable progress in generative\nmodels, the comprehensive synthesis of high-quality game assets, including both\nimages and videos, remains a challenging frontier. To create high-fidelity game\ncontent that simultaneously aligns with player preferences and significantly\nboosts designer efficiency, we present Hunyuan-Game, an innovative project\ndesigned to revolutionize intelligent game production. Hunyuan-Game encompasses\ntwo primary branches: image generation and video generation. The image\ngeneration component is built upon a vast dataset comprising billions of game\nimages, leading to the development of a group of customized image generation\nmodels tailored for game scenarios: (1) General Text-to-Image Generation. (2)\nGame Visual Effects Generation, involving text-to-effect and reference\nimage-based game visual effect generation. (3) Transparent Image Generation for\ncharacters, scenes, and game visual effects. (4) Game Character Generation\nbased on sketches, black-and-white images, and white models. The video\ngeneration component is built upon a comprehensive dataset of millions of game\nand anime videos, leading to the development of five core algorithmic models,\neach targeting critical pain points in game development and having robust\nadaptation to diverse game video scenarios: (1) Image-to-Video Generation. (2)\n360 A/T Pose Avatar Video Synthesis. (3) Dynamic Illustration Generation. (4)\nGenerative Video Super-Resolution. (5) Interactive Game Video Generation. These\nimage and video generation models not only exhibit high-level aesthetic\nexpression but also deeply integrate domain-specific knowledge, establishing a\nsystematic understanding of diverse game and anime art styles."}
{"id": "2505.13738", "pdf": "https://arxiv.org/pdf/2505.13738", "abs": "https://arxiv.org/abs/2505.13738", "authors": ["Shane Bergsma", "Nolan Dey", "Gurpreet Gosal", "Gavia Gray", "Daria Soboleva", "Joel Hestness"], "title": "Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Efficient LLM pre-training requires well-tuned hyperparameters (HPs),\nincluding learning rate {\\eta} and weight decay {\\lambda}. We study scaling\nlaws for HPs: formulas for how to scale HPs as we scale model size N, dataset\nsize D, and batch size B. Recent work suggests the AdamW timescale,\nB/({\\eta}{\\lambda}D), should remain constant across training settings, and we\nverify the implication that optimal {\\lambda} scales linearly with B, for a\nfixed N,D. However, as N,D scale, we show the optimal timescale obeys a precise\npower law in the tokens-per-parameter ratio, D/N. This law thus provides a\nmethod to accurately predict {\\lambda}opt in advance of large-scale training.\nWe also study scaling laws for optimal batch size Bopt (the B enabling lowest\nloss at a given N,D) and critical batch size Bcrit (the B beyond which further\ndata parallelism becomes ineffective). In contrast with prior work, we find\nboth Bopt and Bcrit scale as power laws in D, independent of model size, N.\nFinally, we analyze how these findings inform the real-world selection of\nPareto-optimal N and D under dual training time and compute objectives."}
{"id": "2505.14140", "pdf": "https://arxiv.org/pdf/2505.14140", "abs": "https://arxiv.org/abs/2505.14140", "authors": ["Qianyue Hao", "Sibo Li", "Jian Yuan", "Yong Li"], "title": "RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Despite rapid advancements in large language models (LLMs), the token-level\nautoregressive nature constrains their complex reasoning capabilities. To\nenhance LLM reasoning, inference-time techniques, including\nChain/Tree/Graph-of-Thought(s), successfully improve the performance, as they\nare fairly cost-effective by guiding reasoning through sophisticated logical\nstructures without modifying LLMs' parameters. However, these manually\npredefined, task-agnostic frameworks are applied uniformly across diverse\ntasks, lacking adaptability. To improve this, we propose RL-of-Thoughts (RLoT),\nwhere we train a lightweight navigator model with reinforcement learning (RL)\nto adaptively enhance LLM reasoning at inference time. Specifically, we design\nfive basic logic blocks from the perspective of human cognition. During the\nreasoning process, the trained RL navigator dynamically selects the suitable\nlogic blocks and combines them into task-specific logical structures according\nto problem characteristics. Experiments across multiple reasoning benchmarks\n(AIME, MATH, GPQA, etc.) with multiple LLMs (GPT, Llama, Qwen, and DeepSeek)\nillustrate that RLoT outperforms established inference-time techniques by up to\n13.4%. Remarkably, with less than 3K parameters, our RL navigator is able to\nmake sub-10B LLMs comparable to 100B-scale counterparts. Moreover, the RL\nnavigator demonstrates strong transferability: a model trained on one specific\nLLM-task pair can effectively generalize to unseen LLMs and tasks. Our code is\nopen-source at https://anonymous.4open.science/r/RL-LLM-Reasoning-1A30 for\nreproducibility."}
{"id": "2505.13979", "pdf": "https://arxiv.org/pdf/2505.13979", "abs": "https://arxiv.org/abs/2505.13979", "authors": ["Maya Srikanth", "Run Chen", "Julia Hirschberg"], "title": "Mixed Signals: Understanding Model Disagreement in Multimodal Empathy Detection", "categories": ["cs.CL"], "comment": null, "summary": "Multimodal models play a key role in empathy detection, but their performance\ncan suffer when modalities provide conflicting cues. To understand these\nfailures, we examine cases where unimodal and multimodal predictions diverge.\nUsing fine-tuned models for text, audio, and video, along with a gated fusion\nmodel, we find that such disagreements often reflect underlying ambiguity, as\nevidenced by annotator uncertainty. Our analysis shows that dominant signals in\none modality can mislead fusion when unsupported by others. We also observe\nthat humans, like models, do not consistently benefit from multimodal input.\nThese insights position disagreement as a useful diagnostic signal for\nidentifying challenging examples and improving empathy system robustness."}
{"id": "2505.14156", "pdf": "https://arxiv.org/pdf/2505.14156", "abs": "https://arxiv.org/abs/2505.14156", "authors": ["Songhao Wu", "Quan Tu", "Hong Liu", "Jia Xu", "Zhongyi Liu", "Guannan Zhang", "Ran Wang", "Xiuying Chen", "Rui Yan"], "title": "Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search", "categories": ["cs.CV", "cs.AI", "cs.IR", "I.2; H.3.3"], "comment": null, "summary": "Session search involves a series of interactive queries and actions to\nfulfill user's complex information need. Current strategies typically\nprioritize sequential modeling for deep semantic understanding, overlooking the\ngraph structure in interactions. While some approaches focus on capturing\nstructural information, they use a generalized representation for documents,\nneglecting the word-level semantic modeling. In this paper, we propose Symbolic\nGraph Ranker (SGR), which aims to take advantage of both text-based and\ngraph-based approaches by leveraging the power of recent Large Language Models\n(LLMs). Concretely, we first introduce a set of symbolic grammar rules to\nconvert session graph into text. This allows integrating session history,\ninteraction process, and task instruction seamlessly as inputs for the LLM.\nMoreover, given the natural discrepancy between LLMs pre-trained on textual\ncorpora, and the symbolic language we produce using our graph-to-text grammar,\nour objective is to enhance LLMs' ability to capture graph structures within a\ntextual format. To achieve this, we introduce a set of self-supervised symbolic\nlearning tasks including link prediction, node content generation, and\ngenerative contrastive learning, to enable LLMs to capture the topological\ninformation from coarse-grained to fine-grained. Experiment results and\ncomprehensive analysis on two benchmark datasets, AOL and Tiangong-ST, confirm\nthe superiority of our approach. Our paradigm also offers a novel and effective\nmethodology that bridges the gap between traditional search strategies and\nmodern LLMs."}
{"id": "2505.13740", "pdf": "https://arxiv.org/pdf/2505.13740", "abs": "https://arxiv.org/abs/2505.13740", "authors": ["Chenning Yu", "Sicun Gao"], "title": "Improving Compositional Generation with Diffusion Models Using Lift Scores", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "We introduce a novel resampling criterion using lift scores, for improving\ncompositional generation in diffusion models. By leveraging the lift scores, we\nevaluate whether generated samples align with each single condition and then\ncompose the results to determine whether the composed prompt is satisfied. Our\nkey insight is that lift scores can be efficiently approximated using only the\noriginal diffusion model, requiring no additional training or external modules.\nWe develop an optimized variant that achieves relatively lower computational\noverhead during inference while maintaining effectiveness. Through extensive\nexperiments, we demonstrate that lift scores significantly improved the\ncondition alignment for compositional generation across 2D synthetic data,\nCLEVR position tasks, and text-to-image synthesis. Our code is available at\nhttp://github.com/rainorangelemon/complift."}
{"id": "2505.14141", "pdf": "https://arxiv.org/pdf/2505.14141", "abs": "https://arxiv.org/abs/2505.14141", "authors": ["Fanglin Mo", "Junzhe Chen", "Haoxuan Zhu", "Xuming Hu"], "title": "Building a Stable Planner: An Extended Finite State Machine Based Planning Module for Mobile GUI Agent", "categories": ["cs.AI", "I.2.11; H.5.2"], "comment": "10 pages. Submitted to EMNLP 2025", "summary": "Mobile GUI agents execute user commands by directly interacting with the\ngraphical user interface (GUI) of mobile devices, demonstrating significant\npotential to enhance user convenience. However, these agents face considerable\nchallenges in task planning, as they must continuously analyze the GUI and\ngenerate operation instructions step by step. This process often leads to\ndifficulties in making accurate task plans, as GUI agents lack a deep\nunderstanding of how to effectively use the target applications, which can\ncause them to become \"lost\" during task execution. To address the task planning\nissue, we propose SPlanner, a plug-and-play planning module to generate\nexecution plans that guide vision language model(VLMs) in executing tasks. The\nproposed planning module utilizes extended finite state machines (EFSMs) to\nmodel the control logits and configurations of mobile applications. It then\ndecomposes a user instruction into a sequence of primary function modeled in\nEFSMs, and generate the execution path by traversing the EFSMs. We further\nrefine the execution path into a natural language plan using an LLM. The final\nplan is concise and actionable, and effectively guides VLMs to generate\ninteractive GUI actions to accomplish user tasks. SPlanner demonstrates strong\nperformance on dynamic benchmarks reflecting real-world mobile usage. On the\nAndroidWorld benchmark, SPlanner achieves a 63.8% task success rate when paired\nwith Qwen2.5-VL-72B as the VLM executor, yielding a 28.8 percentage point\nimprovement compared to using Qwen2.5-VL-72B without planning assistance."}
{"id": "2505.13988", "pdf": "https://arxiv.org/pdf/2505.13988", "abs": "https://arxiv.org/abs/2505.13988", "authors": ["Linxin Song", "Taiwei Shi", "Jieyu Zhao"], "title": "The Hallucination Tax of Reinforcement Finetuning", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement finetuning (RFT) has become a standard approach for enhancing\nthe reasoning capabilities of large language models (LLMs). However, its impact\non model trustworthiness remains underexplored. In this work, we identify and\nsystematically study a critical side effect of RFT, which we term the\nhallucination tax: a degradation in refusal behavior causing models to produce\nhallucinated answers to unanswerable questions confidently. To investigate\nthis, we introduce SUM (Synthetic Unanswerable Math), a high-quality dataset of\nunanswerable math problems designed to probe models' ability to recognize an\nunanswerable question by reasoning from the insufficient or ambiguous\ninformation. Our results show that standard RFT training could reduce model\nrefusal rates by more than 80%, which significantly increases model's tendency\nto hallucinate. We further demonstrate that incorporating just 10% SUM during\nRFT substantially restores appropriate refusal behavior, with minimal accuracy\ntrade-offs on solvable tasks. Crucially, this approach enables LLMs to leverage\ninference-time compute to reason about their own uncertainty and knowledge\nboundaries, improving generalization not only to out-of-domain math problems\nbut also to factual question answering tasks."}
{"id": "2505.14159", "pdf": "https://arxiv.org/pdf/2505.14159", "abs": "https://arxiv.org/abs/2505.14159", "authors": ["Junjie Li", "Jiawei Wang", "Miyu Li", "Yu Liu", "Yumei Wang", "Haitao Xu"], "title": "M3Depth: Wavelet-Enhanced Depth Estimation on Mars via Mutual Boosting of Dual-Modal Data", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Depth estimation plays a great potential role in obstacle avoidance and\nnavigation for further Mars exploration missions. Compared to traditional\nstereo matching, learning-based stereo depth estimation provides a data-driven\napproach to infer dense and precise depth maps from stereo image pairs.\nHowever, these methods always suffer performance degradation in environments\nwith sparse textures and lacking geometric constraints, such as the\nunstructured terrain of Mars. To address these challenges, we propose M3Depth,\na depth estimation model tailored for Mars rovers. Considering the sparse and\nsmooth texture of Martian terrain, which is primarily composed of low-frequency\nfeatures, our model incorporates a convolutional kernel based on wavelet\ntransform that effectively captures low-frequency response and expands the\nreceptive field. Additionally, we introduce a consistency loss that explicitly\nmodels the complementary relationship between depth map and surface normal map,\nutilizing the surface normal as a geometric constraint to enhance the accuracy\nof depth estimation. Besides, a pixel-wise refinement module with mutual\nboosting mechanism is designed to iteratively refine both depth and surface\nnormal predictions. Experimental results on synthetic Mars datasets with depth\nannotations show that M3Depth achieves a significant 16% improvement in depth\nestimation accuracy compared to other state-of-the-art methods in depth\nestimation. Furthermore, the model demonstrates strong applicability in\nreal-world Martian scenarios, offering a promising solution for future Mars\nexploration missions."}
{"id": "2505.13742", "pdf": "https://arxiv.org/pdf/2505.13742", "abs": "https://arxiv.org/abs/2505.13742", "authors": ["Andrew Nam", "Declan Campbell", "Thomas Griffiths", "Jonathan Cohen", "Sarah-Jane Leslie"], "title": "Understanding Task Representations in Neural Networks via Bayesian Ablation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neural networks are powerful tools for cognitive modeling due to their\nflexibility and emergent properties. However, interpreting their learned\nrepresentations remains challenging due to their sub-symbolic semantics. In\nthis work, we introduce a novel probabilistic framework for interpreting latent\ntask representations in neural networks. Inspired by Bayesian inference, our\napproach defines a distribution over representational units to infer their\ncausal contributions to task performance. Using ideas from information theory,\nwe propose a suite of tools and metrics to illuminate key model properties,\nincluding representational distributedness, manifold complexity, and\npolysemanticity."}
{"id": "2505.14143", "pdf": "https://arxiv.org/pdf/2505.14143", "abs": "https://arxiv.org/abs/2505.14143", "authors": ["Shuo Zhang", "Jinsong Zhang", "Zhejun Zhang", "Lei Li"], "title": "Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition", "categories": ["cs.AI"], "comment": "Accepted to ICME 2025", "summary": "Multi-task learning (MTL) enables the efficient transfer of extra knowledge\nacquired from other tasks. The high correlation between multimodal sentiment\nanalysis (MSA) and multimodal emotion recognition (MER) supports their joint\ntraining. However, existing methods primarily employ hard parameter sharing,\nignoring parameter conflicts caused by complex task correlations. In this\npaper, we present a novel MTL method for MSA and MER, termed Multimodal Mixture\nof Low-Rank Experts (MMoLRE). MMoLRE utilizes shared and task-specific experts\nto distinctly model common and unique task characteristics, thereby avoiding\nparameter conflicts. Additionally, inspired by low-rank structures in the\nMixture of Experts (MoE) framework, we design low-rank expert networks to\nreduce parameter and computational overhead as the number of experts increases.\nExtensive experiments on the CMU-MOSI and CMU-MOSEI benchmarks demonstrate that\nMMoLRE achieves state-of-the-art performance on the MSA task and competitive\nresults on the MER task."}
{"id": "2505.13990", "pdf": "https://arxiv.org/pdf/2505.13990", "abs": "https://arxiv.org/abs/2505.13990", "authors": ["Tingfeng Hui", "Pengyu Zhu", "Bowen Ping", "Ling Tang", "Yaqi Zhang", "Sen Su"], "title": "DecIF: Improving Instruction-Following through Meta-Decomposition", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "Instruction-following has emerged as a crucial capability for large language\nmodels (LLMs). However, existing approaches often rely on pre-existing\ndocuments or external resources to synthesize instruction-following data, which\nlimits their flexibility and generalizability. In this paper, we introduce\nDecIF, a fully autonomous, meta-decomposition guided framework that generates\ndiverse and high-quality instruction-following data using only LLMs. DecIF is\ngrounded in the principle of decomposition. For instruction generation, we\nguide LLMs to iteratively produce various types of meta-information, which are\nthen combined with response constraints to form well-structured and\nsemantically rich instructions. We further utilize LLMs to detect and resolve\npotential inconsistencies within the generated instructions. Regarding response\ngeneration, we decompose each instruction into atomic-level evaluation\ncriteria, enabling rigorous validation and the elimination of inaccurate\ninstruction-response pairs. Extensive experiments across a wide range of\nscenarios and settings demonstrate DecIF's superior performance on\ninstruction-following tasks. Further analysis highlights its strong\nflexibility, scalability, and generalizability in automatically synthesizing\nhigh-quality instruction data."}
{"id": "2505.14167", "pdf": "https://arxiv.org/pdf/2505.14167", "abs": "https://arxiv.org/abs/2505.14167", "authors": ["Changgu Chen", "Xiaoyan Yang", "Junwei Shu", "Changbo Wang", "Yang Li"], "title": "LMP: Leveraging Motion Prior in Zero-Shot Video Generation with Diffusion Transformer", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, large-scale pre-trained diffusion transformer models have\nmade significant progress in video generation. While current DiT models can\nproduce high-definition, high-frame-rate, and highly diverse videos, there is a\nlack of fine-grained control over the video content. Controlling the motion of\nsubjects in videos using only prompts is challenging, especially when it comes\nto describing complex movements. Further, existing methods fail to control the\nmotion in image-to-video generation, as the subject in the reference image\noften differs from the subject in the reference video in terms of initial\nposition, size, and shape. To address this, we propose the Leveraging Motion\nPrior (LMP) framework for zero-shot video generation. Our framework harnesses\nthe powerful generative capabilities of pre-trained diffusion transformers to\nenable motion in the generated videos to reference user-provided motion videos\nin both text-to-video and image-to-video generation. To this end, we first\nintroduce a foreground-background disentangle module to distinguish between\nmoving subjects and backgrounds in the reference video, preventing interference\nin the target video generation. A reweighted motion transfer module is designed\nto allow the target video to reference the motion from the reference video. To\navoid interference from the subject in the reference video, we propose an\nappearance separation module to suppress the appearance of the reference\nsubject in the target video. We annotate the DAVIS dataset with detailed\nprompts for our experiments and design evaluation metrics to validate the\neffectiveness of our method. Extensive experiments demonstrate that our\napproach achieves state-of-the-art performance in generation quality,\nprompt-video consistency, and control capability. Our homepage is available at\nhttps://vpx-ecnu.github.io/LMP-Website/"}
{"id": "2505.13745", "pdf": "https://arxiv.org/pdf/2505.13745", "abs": "https://arxiv.org/abs/2505.13745", "authors": ["Joanna Komorniczak"], "title": "Synthetic Non-stationary Data Streams for Recognition of the Unknown", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The problem of data non-stationarity is commonly addressed in data stream\nprocessing. In a dynamic environment, methods should continuously be ready to\nanalyze time-varying data -- hence, they should enable incremental training and\nrespond to concept drifts. An equally important variability typical for\nnon-stationary data stream environments is the emergence of new, previously\nunknown classes. Often, methods focus on one of these two phenomena --\ndetection of concept drifts or detection of novel classes -- while both\ndifficulties can be observed in data streams. Additionally, concerning\npreviously unknown observations, the topic of open set of classes has become\nparticularly important in recent years, where the goal of methods is to\nefficiently classify within known classes and recognize objects outside the\nmodel competence. This article presents a strategy for synthetic data stream\ngeneration in which both concept drifts and the emergence of new classes\nrepresenting unknown objects occur. The presented research shows how\nunsupervised drift detectors address the task of detecting novelty and concept\ndrifts and demonstrates how the generated data streams can be utilized in the\nopen set recognition task."}
{"id": "2505.14146", "pdf": "https://arxiv.org/pdf/2505.14146", "abs": "https://arxiv.org/abs/2505.14146", "authors": ["Pengcheng Jiang", "Xueqiang Xu", "Jiacheng Lin", "Jinfeng Xiao", "Zifeng Wang", "Jimeng Sun", "Jiawei Han"], "title": "s3: You Don't Need That Much Data to Train a Search Agent via RL", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems empower large language models\n(LLMs) to access external knowledge during inference. Recent advances have\nenabled LLMs to act as search agents via reinforcement learning (RL), improving\ninformation acquisition through multi-turn interactions with retrieval engines.\nHowever, existing approaches either optimize retrieval using search-only\nmetrics (e.g., NDCG) that ignore downstream utility or fine-tune the entire LLM\nto jointly reason and retrieve-entangling retrieval with generation and\nlimiting the real search utility and compatibility with frozen or proprietary\nmodels. In this work, we propose s3, a lightweight, model-agnostic framework\nthat decouples the searcher from the generator and trains the searcher using a\nGain Beyond RAG reward: the improvement in generation accuracy over naive RAG.\ns3 requires only 2.4k training samples to outperform baselines trained on over\n70x more data, consistently delivering stronger downstream performance across\nsix general QA and five medical QA benchmarks."}
{"id": "2505.13995", "pdf": "https://arxiv.org/pdf/2505.13995", "abs": "https://arxiv.org/abs/2505.13995", "authors": ["Myra Cheng", "Sunny Yu", "Cinoo Lee", "Pranav Khadpe", "Lujain Ibrahim", "Dan Jurafsky"], "title": "Social Sycophancy: A Broader Understanding of LLM Sycophancy", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "A serious risk to the safety and utility of LLMs is sycophancy, i.e.,\nexcessive agreement with and flattery of the user. Yet existing work focuses on\nonly one aspect of sycophancy: agreement with users' explicitly stated beliefs\nthat can be compared to a ground truth. This overlooks forms of sycophancy that\narise in ambiguous contexts such as advice and support-seeking, where there is\nno clear ground truth, yet sycophancy can reinforce harmful implicit\nassumptions, beliefs, or actions. To address this gap, we introduce a richer\ntheory of social sycophancy in LLMs, characterizing sycophancy as the excessive\npreservation of a user's face (the positive self-image a person seeks to\nmaintain in an interaction). We present ELEPHANT, a framework for evaluating\nsocial sycophancy across five face-preserving behaviors (emotional validation,\nmoral endorsement, indirect language, indirect action, and accepting framing)\non two datasets: open-ended questions (OEQ) and Reddit's r/AmITheAsshole\n(AITA). Across eight models, we show that LLMs consistently exhibit high rates\nof social sycophancy: on OEQ, they preserve face 47% more than humans, and on\nAITA, they affirm behavior deemed inappropriate by crowdsourced human judgments\nin 42% of cases. We further show that social sycophancy is rewarded in\npreference datasets and is not easily mitigated. Our work provides theoretical\ngrounding and empirical tools (datasets and code) for understanding and\naddressing this under-recognized but consequential issue."}
{"id": "2505.14197", "pdf": "https://arxiv.org/pdf/2505.14197", "abs": "https://arxiv.org/abs/2505.14197", "authors": ["Xinshen Zhang", "Zhen Ye", "Xu Zheng"], "title": "Towards Omnidirectional Reasoning with 360-R1: A Dataset, Benchmark, and GRPO-based Method", "categories": ["cs.CV"], "comment": null, "summary": "Omnidirectional images (ODIs), with their 360{\\deg} field of view, provide\nunparalleled spatial awareness for immersive applications like augmented\nreality and embodied AI. However, the capability of existing multi-modal large\nlanguage models (MLLMs) to comprehend and reason about such panoramic scenes\nremains underexplored. This paper addresses this gap by introducing OmniVQA,\nthe first dataset and conducting the first benchmark for omnidirectional visual\nquestion answering. Our evaluation of state-of-the-art MLLMs reveals\nsignificant limitations in handling omnidirectional visual question answering,\nhighlighting persistent challenges in object localization, feature extraction,\nand hallucination suppression within panoramic contexts. These results\nunderscore the disconnect between current MLLM capabilities and the demands of\nomnidirectional visual understanding, which calls for dedicated architectural\nor training innovations tailored to 360{\\deg} imagery. Building on the OmniVQA\ndataset and benchmark, we further introduce a rule-based reinforcement learning\nmethod, 360-R1, based on Qwen2.5-VL-Instruct. Concretely, we modify the group\nrelative policy optimization (GRPO) by proposing three novel reward functions:\n(1) reasoning process similarity reward, (2) answer semantic accuracy reward,\nand (3) structured format compliance reward. Extensive experiments on our\nOmniVQA demonstrate the superiority of our proposed method in omnidirectional\nspace (+6% improvement)."}
{"id": "2505.13754", "pdf": "https://arxiv.org/pdf/2505.13754", "abs": "https://arxiv.org/abs/2505.13754", "authors": ["Devendra Parkar", "Anya Chaturvedi", "Andr√©a W. Richa", "Joshua J. Daymude"], "title": "Finding Maximum Independent Sets in Dynamic Graphs using Unsupervised Learning", "categories": ["cs.LG", "cs.SI"], "comment": "11 pages, 3 tables", "summary": "We present the first unsupervised learning model for finding Maximum\nIndependent Sets (MaxIS) in dynamic graphs where edges change over time. Our\nmethod combines structural learning from graph neural networks (GNNs) with a\nlearned distributed update mechanism that, given an edge addition or deletion\nevent, modifies nodes' internal memories and infers their MaxIS membership in a\nsingle, parallel step. We parameterize our model by the update mechanism's\nradius and investigate the resulting performance-runtime tradeoffs for various\ndynamic graph topologies. We evaluate our model against state-of-the-art MaxIS\nmethods for static graphs, including a mixed integer programming solver,\ndeterministic rule-based algorithms, and a heuristic learning framework based\non dynamic programming and GNNs. Across synthetic and real-world dynamic graphs\nof 100-10,000 nodes, our model achieves competitive approximation ratios with\nexcellent scalability; on large graphs, it significantly outperforms the\nstate-of-the-art heuristic learning framework in solution quality, runtime, and\nmemory usage. Our model generalizes well on graphs 100x larger than the ones\nused for training, achieving performance at par with both a greedy technique\nand a commercial mixed integer programming solver while running 1.5-23x faster\nthan greedy."}
{"id": "2505.14147", "pdf": "https://arxiv.org/pdf/2505.14147", "abs": "https://arxiv.org/abs/2505.14147", "authors": ["Xiong Jun Wu", "Zhenduo Zhang", "ZuJie Wen", "Zhiqiang Zhang", "Wang Ren", "Lei Shi", "Cai Chen", "Deng Zhao", "Dingnan Jin", "Qing Cui", "Jun Zhou"], "title": "SHARP: Synthesizing High-quality Aligned Reasoning Problems for Large Reasoning Models Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Training large reasoning models (LRMs) with reinforcement learning in STEM\ndomains is hindered by the scarcity of high-quality, diverse, and verifiable\nproblem sets. Existing synthesis methods, such as Chain-of-Thought prompting,\noften generate oversimplified or uncheckable data, limiting model advancement\non complex tasks. To address these challenges, we introduce SHARP, a unified\napproach to Synthesizing High-quality Aligned Reasoning Problems for LRMs\nreinforcement learning with verifiable rewards (RLVR). SHARP encompasses a\nstrategic set of self-alignment principles -- targeting graduate and\nOlympiad-level difficulty, rigorous logical consistency, and unambiguous,\nverifiable answers -- and a structured three-phase framework (Alignment,\nInstantiation, Inference) that ensures thematic diversity and fine-grained\ncontrol over problem generation. We implement SHARP by leveraging a\nstate-of-the-art LRM to infer and verify challenging STEM questions, then\nemploy a reinforcement learning loop to refine the model's reasoning through\nverifiable reward signals. Experiments on benchmarks such as GPQA demonstrate\nthat SHARP-augmented training substantially outperforms existing methods,\nmarkedly improving complex reasoning accuracy and pushing LRM performance\ncloser to expert-level proficiency. Our contributions include the SHARP\nstrategy, framework design, end-to-end implementation, and experimental\nevaluation of its effectiveness in elevating LRM reasoning capabilities."}
{"id": "2505.14009", "pdf": "https://arxiv.org/pdf/2505.14009", "abs": "https://arxiv.org/abs/2505.14009", "authors": ["Yuxuan Yao", "Shuqi Liu", "Zehua Liu", "Qintong Li", "Mingyang Liu", "Xiongwei Han", "Zhijiang Guo", "Han Wu", "Linqi Song"], "title": "Activation-Guided Consensus Merging for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent research has increasingly focused on reconciling the reasoning\ncapabilities of System 2 with the efficiency of System 1. While existing\ntraining-based and prompt-based approaches face significant challenges in terms\nof efficiency and stability, model merging emerges as a promising strategy to\nintegrate the diverse capabilities of different Large Language Models (LLMs)\ninto a unified model. However, conventional model merging methods often assume\nuniform importance across layers, overlooking the functional heterogeneity\ninherent in neural components. To address this limitation, we propose\n\\textbf{A}ctivation-Guided \\textbf{C}onsensus \\textbf{M}erging (\\textbf{ACM}),\na plug-and-play merging framework that determines layer-specific merging\ncoefficients based on mutual information between activations of pre-trained and\nfine-tuned models. ACM effectively preserves task-specific capabilities without\nrequiring gradient computations or additional training. Extensive experiments\non Long-to-Short (L2S) and general merging tasks demonstrate that ACM\nconsistently outperforms all baseline methods. For instance, in the case of\nQwen-7B models, TIES-Merging equipped with ACM achieves a \\textbf{55.3\\%}\nreduction in response length while simultaneously improving reasoning accuracy\nby \\textbf{1.3} points. We submit the code with the paper for reproducibility,\nand it will be publicly available."}
{"id": "2505.14204", "pdf": "https://arxiv.org/pdf/2505.14204", "abs": "https://arxiv.org/abs/2505.14204", "authors": ["Yang Hu", "Runchen Wang", "Stephen Chong Zhao", "Xuhui Zhan", "Do Hun Kim", "Mark Wallace", "David A. Tovar"], "title": "Beginning with You: Perceptual-Initialization Improves Vision-Language Representation and Alignment", "categories": ["cs.CV", "q-bio.NC"], "comment": "10 pages, 5 figures, 2 tables", "summary": "We introduce Perceptual-Initialization (PI), a paradigm shift in visual\nrepresentation learning that incorporates human perceptual structure during the\ninitialization phase rather than as a downstream fine-tuning step. By\nintegrating human-derived triplet embeddings from the NIGHTS dataset to\ninitialize a CLIP vision encoder, followed by self-supervised learning on\nYFCC15M, our approach demonstrates significant zero-shot performance\nimprovements, without any task-specific fine-tuning, across 29 zero shot\nclassification and 2 retrieval benchmarks. On ImageNet-1K, zero-shot gains\nemerge after approximately 15 epochs of pretraining. Benefits are observed\nacross datasets of various scales, with improvements manifesting at different\nstages of the pretraining process depending on dataset characteristics. Our\napproach consistently enhances zero-shot top-1 accuracy, top-5 accuracy, and\nretrieval recall (e.g., R@1, R@5) across these diverse evaluation tasks,\nwithout requiring any adaptation to target domains. These findings challenge\nthe conventional wisdom of using human-perceptual data primarily for\nfine-tuning and demonstrate that embedding human perceptual structure during\nearly representation learning yields more capable and vision-language aligned\nsystems that generalize immediately to unseen tasks. Our work shows that\n\"beginning with you\", starting with human perception, provides a stronger\nfoundation for general-purpose vision-language intelligence."}
{"id": "2505.13755", "pdf": "https://arxiv.org/pdf/2505.13755", "abs": "https://arxiv.org/abs/2505.13755", "authors": ["Jeffrey Lai", "Anthony Bao", "William Gilpin"], "title": "Panda: A pretrained forecast model for universal representation of chaotic dynamics", "categories": ["cs.LG", "cs.NE", "nlin.CD", "stat.ML"], "comment": null, "summary": "Chaotic systems are intrinsically sensitive to small errors, challenging\nefforts to construct predictive data-driven models of real-world dynamical\nsystems such as fluid flows or neuronal activity. Prior efforts comprise either\nspecialized models trained separately on individual time series, or foundation\nmodels trained on vast time series databases with little underlying dynamical\nstructure. Motivated by dynamical systems theory, we present Panda, Patched\nAttention for Nonlinear DynAmics. We train Panda on a novel synthetic,\nextensible dataset of $2 \\times 10^4$ chaotic dynamical systems that we\ndiscover using an evolutionary algorithm. Trained purely on simulated data,\nPanda exhibits emergent properties: zero-shot forecasting of unseen real world\nchaotic systems, and nonlinear resonance patterns in cross-channel attention\nheads. Despite having been trained only on low-dimensional ordinary\ndifferential equations, Panda spontaneously develops the ability to predict\npartial differential equations without retraining. We demonstrate a neural\nscaling law for differential equations, underscoring the potential of\npretrained models for probing abstract mathematical domains like nonlinear\ndynamics."}
{"id": "2505.14148", "pdf": "https://arxiv.org/pdf/2505.14148", "abs": "https://arxiv.org/abs/2505.14148", "authors": ["Fan Liu", "Zherui Yang", "Cancheng Liu", "Tianrui Song", "Xiaofeng Gao", "Hao Liu"], "title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem", "categories": ["cs.AI"], "comment": null, "summary": "Mathematical modeling is a cornerstone of scientific discovery and\nengineering practice, enabling the translation of real-world problems into\nformal systems across domains such as physics, biology, and economics. Unlike\nmathematical reasoning, which assumes a predefined formulation, modeling\nrequires open-ended problem analysis, abstraction, and principled\nformalization. While Large Language Models (LLMs) have shown strong reasoning\ncapabilities, they fall short in rigorous model construction, limiting their\nutility in real-world problem-solving. To this end, we formalize the task of\nLLM-powered real-world mathematical modeling, where agents must analyze\nproblems, construct domain-appropriate formulations, and generate complete\nend-to-end solutions. We introduce MM-Bench, a curated benchmark of 111\nproblems from the Mathematical Contest in Modeling (MCM/ICM), spanning the\nyears 2000 to 2025 and across ten diverse domains such as physics, biology, and\neconomics. To tackle this task, we propose MM-Agent, an expert-inspired\nframework that decomposes mathematical modeling into four stages: open-ended\nproblem analysis, structured model formulation, computational problem solving,\nand report generation. Experiments on MM-Bench show that MM-Agent significantly\noutperforms baseline agents, achieving an 11.88\\% improvement over human expert\nsolutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o.\nFurthermore, under official MCM/ICM protocols, MM-Agent assisted two\nundergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among\n27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a\nmodeling copilot. Our code is available at\nhttps://github.com/usail-hkust/LLM-MM-Agent"}
{"id": "2505.14015", "pdf": "https://arxiv.org/pdf/2505.14015", "abs": "https://arxiv.org/abs/2505.14015", "authors": ["Tai D. Nguyen", "Long H. Pham", "Jun Sun"], "title": "AUTOLAW: Enhancing Legal Compliance in Large Language Models via Case Law Generation and Jury-Inspired Deliberation", "categories": ["cs.CL"], "comment": null, "summary": "The rapid advancement of domain-specific large language models (LLMs) in\nfields like law necessitates frameworks that account for nuanced regional legal\ndistinctions, which are critical for ensuring compliance and trustworthiness.\nExisting legal evaluation benchmarks often lack adaptability and fail to\naddress diverse local contexts, limiting their utility in dynamically evolving\nregulatory landscapes. To address these gaps, we propose AutoLaw, a novel\nviolation detection framework that combines adversarial data generation with a\njury-inspired deliberation process to enhance legal compliance of LLMs. Unlike\nstatic approaches, AutoLaw dynamically synthesizes case law to reflect local\nregulations and employs a pool of LLM-based \"jurors\" to simulate judicial\ndecision-making. Jurors are ranked and selected based on synthesized legal\nexpertise, enabling a deliberation process that minimizes bias and improves\ndetection accuracy. Evaluations across three benchmarks: Law-SG, Case-SG\n(legality), and Unfair-TOS (policy), demonstrate AutoLaw's effectiveness:\nadversarial data generation improves LLM discrimination, while the jury-based\nvoting strategy significantly boosts violation detection rates. Our results\nhighlight the framework's ability to adaptively probe legal misalignments and\ndeliver reliable, context-aware judgments, offering a scalable solution for\nevaluating and enhancing LLMs in legally sensitive applications."}
{"id": "2505.14218", "pdf": "https://arxiv.org/pdf/2505.14218", "abs": "https://arxiv.org/abs/2505.14218", "authors": ["Jie Li", "Shengwei Tian", "Long Yu", "Xin Ning"], "title": "Flexible-weighted Chamfer Distance: Enhanced Objective Function for Point Cloud Completion", "categories": ["cs.CV"], "comment": null, "summary": "Chamfer Distance (CD) comprises two components that can evaluate the global\ndistribution and local performance of generated point clouds, making it widely\nutilized as a similarity measure between generated and target point clouds in\npoint cloud completion tasks. Additionally, CD's computational efficiency has\nled to its frequent application as an objective function for guiding point\ncloud generation. However, using CD directly as an objective function with\nfixed equal weights for its two components can often result in seemingly high\noverall performance (i.e., low CD score), while failing to achieve a good\nglobal distribution. This is typically reflected in high Earth Mover's Distance\n(EMD) and Decomposed Chamfer Distance (DCD) scores, alongside poor human\nassessments. To address this issue, we propose a Flexible-Weighted Chamfer\nDistance (FCD) to guide point cloud generation. FCD assigns a higher weight to\nthe global distribution component of CD and incorporates a flexible weighting\nstrategy to adjust the balance between the two components, aiming to improve\nglobal distribution while maintaining robust overall performance. Experimental\nresults on two state-of-the-art networks demonstrate that our method achieves\nsuperior results across multiple evaluation metrics, including CD, EMD, DCD,\nand F-Score, as well as in human evaluations."}
{"id": "2505.13760", "pdf": "https://arxiv.org/pdf/2505.13760", "abs": "https://arxiv.org/abs/2505.13760", "authors": ["Drona Khurana", "Anish Thilagar", "Dhamma Kimpara", "Rafael Frongillo"], "title": "Consistency Conditions for Differentiable Surrogate Losses", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The statistical consistency of surrogate losses for discrete prediction tasks\nis often checked via the condition of calibration. However, directly verifying\ncalibration can be arduous. Recent work shows that for polyhedral surrogates, a\nless arduous condition, indirect elicitation (IE), is still equivalent to\ncalibration. We give the first results of this type for non-polyhedral\nsurrogates, specifically the class of convex differentiable losses. We first\nprove that under mild conditions, IE and calibration are equivalent for\none-dimensional losses in this class. We construct a counter-example that shows\nthat this equivalence fails in higher dimensions. This motivates the\nintroduction of strong IE, a strengthened form of IE that is equally easy to\nverify. We establish that strong IE implies calibration for differentiable\nsurrogates and is both necessary and sufficient for strongly convex,\ndifferentiable surrogates. Finally, we apply these results to a range of\nproblems to demonstrate the power of IE and strong IE for designing and\nanalyzing consistent differentiable surrogates."}
{"id": "2505.14163", "pdf": "https://arxiv.org/pdf/2505.14163", "abs": "https://arxiv.org/abs/2505.14163", "authors": ["He Wang", "Alexander Hanbo Li", "Yiqun Hu", "Sheng Zhang", "Hideo Kobayashi", "Jiani Zhang", "Henry Zhu", "Chung-Wei Hang", "Patrick Ng"], "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) agents have shown promising performance in\ngenerating code for solving complex data science problems. Recent studies\nprimarily focus on enhancing in-context learning through improved search,\nsampling, and planning techniques, while overlooking the importance of the\norder in which problems are tackled during inference. In this work, we develop\na novel inference-time optimization framework, referred to as DSMentor, which\nleverages curriculum learning -- a strategy that introduces simpler task first\nand progressively moves to more complex ones as the learner improves -- to\nenhance LLM agent performance in challenging data science tasks. Our\nmentor-guided framework organizes data science tasks in order of increasing\ndifficulty and incorporates a growing long-term memory to retain prior\nexperiences, guiding the agent's learning progression and enabling more\neffective utilization of accumulated knowledge. We evaluate DSMentor through\nextensive experiments on DSEval and QRData benchmarks. Experiments show that\nDSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval\nand QRData compared to baseline agents. Furthermore, DSMentor demonstrates\nstronger causal reasoning ability, improving the pass rate by 8.8% on the\ncausality problems compared to GPT-4 using Program-of-Thoughts prompts. Our\nwork underscores the importance of developing effective strategies for\naccumulating and utilizing knowledge during inference, mirroring the human\nlearning process and opening new avenues for improving LLM performance through\ncurriculum-based inference optimization."}
{"id": "2505.14045", "pdf": "https://arxiv.org/pdf/2505.14045", "abs": "https://arxiv.org/abs/2505.14045", "authors": ["Yingli Shen", "Wen Lai", "Shuo Wang", "Kangyang Luo", "Alexander Fraser", "Maosong Sun"], "title": "From Unaligned to Aligned: Scaling Multilingual LLMs with Multi-Way Parallel Corpora", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Continued pretraining and instruction tuning on large-scale multilingual data\nhave proven to be effective in scaling large language models (LLMs) to\nlow-resource languages. However, the unaligned nature of such data limits its\nability to effectively capture cross-lingual semantics. In contrast, multi-way\nparallel data, where identical content is aligned across multiple languages,\nprovides stronger cross-lingual consistency and offers greater potential for\nimproving multilingual performance. In this paper, we introduce a large-scale,\nhigh-quality multi-way parallel corpus, TED2025, based on TED Talks. The corpus\nspans 113 languages, with up to 50 languages aligned in parallel, ensuring\nextensive multilingual coverage. Using this dataset, we investigate best\npractices for leveraging multi-way parallel data to enhance LLMs, including\nstrategies for continued pretraining, instruction tuning, and the analysis of\nkey influencing factors. Experiments on six multilingual benchmarks show that\nmodels trained on multiway parallel data consistently outperform those trained\non unaligned multilingual data."}
{"id": "2505.14227", "pdf": "https://arxiv.org/pdf/2505.14227", "abs": "https://arxiv.org/abs/2505.14227", "authors": ["Luyang Jiang", "Jianing An", "Jie Luo", "Wenjun Wu", "Lei Huang"], "title": "VoQA: Visual-only Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages", "summary": "We propose Visual-only Question Answering (VoQA), a novel multimodal task in\nwhich questions are visually embedded within images, without any accompanying\ntextual input. This requires models to locate, recognize, and reason over\nvisually embedded textual questions, posing challenges for existing large\nvision-language models (LVLMs), which show notable performance drops even with\ncarefully designed prompts. To bridge this gap, we introduce Guided Response\nTriggering Supervised Fine-tuning (GRT-SFT), a structured fine-tuning strategy\nthat guides the model to perform step-by-step reasoning purely based on visual\ninput, significantly improving model performance. Our work enhances models'\ncapacity for human-like visual understanding in complex multimodal scenarios,\nwhere information, including language, is perceived visually."}
{"id": "2505.13765", "pdf": "https://arxiv.org/pdf/2505.13765", "abs": "https://arxiv.org/abs/2505.13765", "authors": ["Hainan Xu", "Vladimir Bataev", "Lilit Grigoryan", "Boris Ginsburg"], "title": "WIND: Accelerated RNN-T Decoding with Windowed Inference for Non-blank Detection", "categories": ["cs.LG"], "comment": null, "summary": "We propose Windowed Inference for Non-blank Detection (WIND), a novel\nstrategy that significantly accelerates RNN-T inference without compromising\nmodel accuracy. During model inference, instead of processing frames\nsequentially, WIND processes multiple frames simultaneously within a window in\nparallel, allowing the model to quickly locate non-blank predictions during\ndecoding, resulting in significant speed-ups. We implement WIND for greedy\ndecoding, batched greedy decoding with label-looping techniques, and also\npropose a novel beam-search decoding method. Experiments on multiple datasets\nwith different conditions show that our method, when operating in greedy modes,\nspeeds up as much as 2.4X compared to the baseline sequential approach while\nmaintaining identical Word Error Rate (WER) performance. Our beam-search\nalgorithm achieves slightly better accuracy than alternative methods, with\nsignificantly improved speed. We will open-source our WIND implementation."}
{"id": "2505.14193", "pdf": "https://arxiv.org/pdf/2505.14193", "abs": "https://arxiv.org/abs/2505.14193", "authors": ["Abdallah Abuaisha", "Bojie Shen", "Daniel Harabor", "Peter Stuckey", "Mark Wallace"], "title": "Dynamic Replanning for Improved Public Transport Routing", "categories": ["cs.AI"], "comment": "Accepted for publication at IJCAI 2025. 8 pages, 4 figures, 3 tables", "summary": "Delays in public transport are common, often impacting users through\nprolonged travel times and missed transfers. Existing solutions for handling\ndelays remain limited; backup plans based on historical data miss opportunities\nfor earlier arrivals, while snapshot planning accounts for current delays but\nnot future ones. With the growing availability of live delay data, users can\nadjust their journeys in real-time. However, the literature lacks a framework\nthat fully exploits this advantage for system-scale dynamic replanning. To\naddress this, we formalise the dynamic replanning problem in public transport\nrouting and propose two solutions: a \"pull\" approach, where users manually\nrequest replanning, and a novel \"push\" approach, where the server proactively\nmonitors and adjusts journeys. Our experiments show that the push approach\noutperforms the pull approach, achieving significant speedups. The results also\nreveal substantial arrival time savings enabled by dynamic replanning."}
{"id": "2505.14052", "pdf": "https://arxiv.org/pdf/2505.14052", "abs": "https://arxiv.org/abs/2505.14052", "authors": ["Wei Jiang", "Anying Fu", "Youling Zhang"], "title": "Improved Methods for Model Pruning and Knowledge Distillation", "categories": ["cs.CL", "cs.CE"], "comment": null, "summary": "Model pruning is a performance optimization technique for large language\nmodels like R1 or o3-mini. However, existing pruning methods often lead to\nsignificant performance degradation or require extensive retraining and\nfine-tuning. This technique aims to identify and remove neurons, connections\nunlikely leading to the contribution during the human-computer interaction\nphase. Our goal is to obtain a much smaller and faster knowledge distilled\nmodel that can quickly generate content almost as good as those of the unpruned\nones. We propose MAMA Pruning, short for Movement and Magnitude Analysis, an\nimproved pruning method that effectively reduces model size and computational\ncomplexity while maintaining performance comparable to the original unpruned\nmodel even at extreme pruned levels. The improved method is based on weights,\nbias fixed in the pre-training phase and GRPO rewards verified during the\npost-training phase as our novel pruning indicators. Preliminary experimental\nresults show that our method outperforms and be comparable to state-of-the-art\nmethods across various pruning levels and different downstream computational\nlinguistics tasks."}
{"id": "2505.14231", "pdf": "https://arxiv.org/pdf/2505.14231", "abs": "https://arxiv.org/abs/2505.14231", "authors": ["Sule Bai", "Mingxing Li", "Yong Liu", "Jing Tang", "Haoji Zhang", "Lei Sun", "Xiangxiang Chu", "Yansong Tang"], "title": "UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Traditional visual grounding methods primarily focus on single-image\nscenarios with simple textual references. However, extending these methods to\nreal-world scenarios that involve implicit and complex instructions,\nparticularly in conjunction with multiple images, poses significant challenges,\nwhich is mainly due to the lack of advanced reasoning ability across diverse\nmulti-modal contexts. In this work, we aim to address the more practical\nuniversal grounding task, and propose UniVG-R1, a reasoning guided multimodal\nlarge language model (MLLM) for universal visual grounding, which enhances\nreasoning capabilities through reinforcement learning (RL) combined with\ncold-start data. Specifically, we first construct a high-quality\nChain-of-Thought (CoT) grounding dataset, annotated with detailed reasoning\nchains, to guide the model towards correct reasoning paths via supervised\nfine-tuning. Subsequently, we perform rule-based reinforcement learning to\nencourage the model to identify correct reasoning chains, thereby incentivizing\nits reasoning capabilities. In addition, we identify a difficulty bias arising\nfrom the prevalence of easy samples as RL training progresses, and we propose a\ndifficulty-aware weight adjustment strategy to further strengthen the\nperformance. Experimental results demonstrate the effectiveness of UniVG-R1,\nwhich achieves state-of-the-art performance on MIG-Bench with a 9.1%\nimprovement over the previous method. Furthermore, our model exhibits strong\ngeneralizability, achieving an average improvement of 23.4% in zero-shot\nperformance across four image and video reasoning grounding benchmarks. The\nproject page can be accessed at https://amap-ml.github.io/UniVG-R1-page/."}
{"id": "2505.13768", "pdf": "https://arxiv.org/pdf/2505.13768", "abs": "https://arxiv.org/abs/2505.13768", "authors": ["Ruiquan Huang", "Donghao Li", "Chengshuai Shi", "Cong Shen", "Jing Yang"], "title": "Augmenting Online RL with Offline Data is All You Need: A Unified Hybrid RL Algorithm Design and Analysis", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted by UAI2025", "summary": "This paper investigates a hybrid learning framework for reinforcement\nlearning (RL) in which the agent can leverage both an offline dataset and\nonline interactions to learn the optimal policy. We present a unified algorithm\nand analysis and show that augmenting confidence-based online RL algorithms\nwith the offline dataset outperforms any pure online or offline algorithm alone\nand achieves state-of-the-art results under two learning metrics, i.e.,\nsub-optimality gap and online learning regret. Specifically, we show that our\nalgorithm achieves a sub-optimality gap\n$\\tilde{O}(\\sqrt{1/(N_0/\\mathtt{C}(\\pi^*|\\rho)+N_1}) )$, where\n$\\mathtt{C}(\\pi^*|\\rho)$ is a new concentrability coefficient, $N_0$ and $N_1$\nare the numbers of offline and online samples, respectively. For regret\nminimization, we show that it achieves a constant $\\tilde{O}(\n\\sqrt{N_1/(N_0/\\mathtt{C}(\\pi^{-}|\\rho)+N_1)} )$ speed-up compared to pure\nonline learning, where $\\mathtt{C}(\\pi^-|\\rho)$ is the concentrability\ncoefficient over all sub-optimal policies. Our results also reveal an\ninteresting separation on the desired coverage properties of the offline\ndataset for sub-optimality gap minimization and regret minimization. We further\nvalidate our theoretical findings in several experiments in special RL models\nsuch as linear contextual bandits and Markov decision processes (MDPs)."}
{"id": "2505.14209", "pdf": "https://arxiv.org/pdf/2505.14209", "abs": "https://arxiv.org/abs/2505.14209", "authors": ["Li Wang", "Xin Yu", "Xuxin Lv", "Gangzheng Ai", "Wenjun Wu"], "title": "Embedded Mean Field Reinforcement Learning for Perimeter-defense Game", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid advancement of unmanned aerial vehicles (UAVs) and missile\ntechnologies, perimeter-defense game between attackers and defenders for the\nprotection of critical regions have become increasingly complex and\nstrategically significant across a wide range of domains. However, existing\nstudies predominantly focus on small-scale, simplified two-dimensional\nscenarios, often overlooking realistic environmental perturbations, motion\ndynamics, and inherent heterogeneity--factors that pose substantial challenges\nto real-world applicability. To bridge this gap, we investigate large-scale\nheterogeneous perimeter-defense game in a three-dimensional setting,\nincorporating realistic elements such as motion dynamics and wind fields. We\nderive the Nash equilibrium strategies for both attackers and defenders,\ncharacterize the victory regions, and validate our theoretical findings through\nextensive simulations. To tackle large-scale heterogeneous control challenges\nin defense strategies, we propose an Embedded Mean-Field Actor-Critic (EMFAC)\nframework. EMFAC leverages representation learning to enable high-level action\naggregation in a mean-field manner, supporting scalable coordination among\ndefenders. Furthermore, we introduce a lightweight agent-level attention\nmechanism based on reward representation, which selectively filters\nobservations and mean-field information to enhance decision-making efficiency\nand accelerate convergence in large-scale tasks. Extensive simulations across\nvarying scales demonstrate the effectiveness and adaptability of EMFAC, which\noutperforms established baselines in both convergence speed and overall\nperformance. To further validate practicality, we test EMFAC in small-scale\nreal-world experiments and conduct detailed analyses, offering deeper insights\ninto the framework's effectiveness in complex scenarios."}
{"id": "2505.14070", "pdf": "https://arxiv.org/pdf/2505.14070", "abs": "https://arxiv.org/abs/2505.14070", "authors": ["Feiyu Duan", "Xuemiao Zhang", "Sirui Wang", "Haoran Que", "Yuqi Liu", "Wenge Rong", "Xunliang Cai"], "title": "Enhancing LLMs via High-Knowledge Data Selection", "categories": ["cs.CL"], "comment": null, "summary": "The performance of Large Language Models (LLMs) is intrinsically linked to\nthe quality of its training data. Although several studies have proposed\nmethods for high-quality data selection, they do not consider the importance of\nknowledge richness in text corpora. In this paper, we propose a novel and\ngradient-free High-Knowledge Scorer (HKS) to select high-quality data from the\ndimension of knowledge, to alleviate the problem of knowledge scarcity in the\npre-trained corpus. We propose a comprehensive multi-domain knowledge element\npool and introduce knowledge density and coverage as metrics to assess the\nknowledge content of the text. Based on this, we propose a comprehensive\nknowledge scorer to select data with intensive knowledge, which can also be\nutilized for domain-specific high-knowledge data selection by restricting\nknowledge elements to the specific domain. We train models on a high-knowledge\nbilingual dataset, and experimental results demonstrate that our scorer\nimproves the model's performance in knowledge-intensive and general\ncomprehension tasks, and is effective in enhancing both the generic and\ndomain-specific capabilities of the model."}
{"id": "2505.14239", "pdf": "https://arxiv.org/pdf/2505.14239", "abs": "https://arxiv.org/abs/2505.14239", "authors": ["Bin-Bin Gao", "Xiaochen Chen", "Zhongyi Huang", "Congchong Nie", "Jun Liu", "Jinxiang Lai", "Guannan Jiang", "Xi Wang", "Chengjie Wang"], "title": "Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation", "categories": ["cs.CV"], "comment": "Accepted by NeurIPS 2022", "summary": "This paper focus on few-shot object detection~(FSOD) and instance\nsegmentation~(FSIS), which requires a model to quickly adapt to novel classes\nwith a few labeled instances. The existing methods severely suffer from bias\nclassification because of the missing label issue which naturally exists in an\ninstance-level few-shot scenario and is first formally proposed by us. Our\nanalysis suggests that the standard classification head of most FSOD or FSIS\nmodels needs to be decoupled to mitigate the bias classification. Therefore, we\npropose an embarrassingly simple but effective method that decouples the\nstandard classifier into two heads. Then, these two individual heads are\ncapable of independently addressing clear positive samples and noisy negative\nsamples which are caused by the missing label. In this way, the model can\neffectively learn novel classes while mitigating the effects of noisy negative\nsamples. Without bells and whistles, our model without any additional\ncomputation cost and parameters consistently outperforms its baseline and\nstate-of-the-art by a large margin on PASCAL VOC and MS-COCO benchmarks for\nFSOD and FSIS tasks. The Code is available at\nhttps://csgaobb.github.io/Projects/DCFS."}
{"id": "2505.13775", "pdf": "https://arxiv.org/pdf/2505.13775", "abs": "https://arxiv.org/abs/2505.13775", "authors": ["Kaya Stechly", "Karthik Valmeekam", "Atharva Gundawar", "Vardhan Palod", "Subbarao Kambhampati"], "title": "Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent impressive results from large reasoning models have been interpreted\nas a triumph of Chain of Thought (CoT), and especially of the process of\ntraining on CoTs sampled from base LLMs in order to help find new reasoning\npatterns. In this paper, we critically examine that interpretation by\ninvestigating how the semantics of intermediate tokens-often anthropomorphized\nas \"thoughts\" or reasoning traces and which are claimed to display behaviors\nlike backtracking, self-verification etc.-actually influence model performance.\nWe train transformer models on formally verifiable reasoning traces and\nsolutions, constraining both intermediate steps and final outputs to align with\nthose of a formal solver (in our case, A* search). By constructing a formal\ninterpreter of the semantics of our problems and intended algorithm, we\nsystematically evaluate not only solution accuracy but also the correctness of\nintermediate traces, thus allowing us to evaluate whether the latter causally\ninfluences the former. We notice that, despite significant improvements on the\nsolution-only baseline, models trained on entirely correct traces still produce\ninvalid reasoning traces when arriving at correct solutions. To further show\nthat trace accuracy is only loosely connected to solution accuracy, we then\ntrain models on noisy, corrupted traces which have no relation to the specific\nproblem each is paired with, and find that not only does performance remain\nlargely consistent with models trained on correct data, but in some cases can\nimprove upon it and generalize more robustly on out-of-distribution tasks.\nThese results challenge the assumption that intermediate tokens or \"Chains of\nThought\" induce predictable reasoning behaviors and caution against\nanthropomorphizing such outputs or over-interpreting them (despite their mostly\ncorrect forms) as evidence of human-like or algorithmic behaviors in language\nmodels."}
{"id": "2505.14216", "pdf": "https://arxiv.org/pdf/2505.14216", "abs": "https://arxiv.org/abs/2505.14216", "authors": ["Minwu Kim", "Anubhav Shrestha", "Safal Shrestha", "Aadim Nepal", "Keith Ross"], "title": "Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "23 pages", "summary": "Recent studies have shown that reinforcement learning with verifiable rewards\n(RLVR) enhances overall accuracy but fails to improve capability, while\ndistillation can improve both. In this paper, we investigate the mechanisms\nbehind these phenomena. First, we demonstrate that RLVR does not improve\ncapability because it focuses on improving the accuracy of the less-difficult\nquestions to the detriment of the accuracy of the most difficult questions,\nthereby leading to no improvement in capability. Second, we find that RLVR does\nnot merely increase the success probability for the less difficult questions,\nbut in our small model settings produces quality responses that were absent in\nits output distribution before training. In addition, we show these responses\nare neither noticeably longer nor feature more reflection-related keywords,\nunderscoring the need for more reliable indicators of response quality. Third,\nwe show that while distillation reliably improves accuracy by learning strong\nreasoning patterns, it only improves capability when new knowledge is\nintroduced. Moreover, when distilling only with reasoning patterns and no new\nknowledge, the accuracy of the less-difficult questions improves to the\ndetriment of the most difficult questions, similar to RLVR. Together, these\nfindings offer a clearer understanding of how RLVR and distillation shape\nreasoning behavior in language models."}
{"id": "2505.14079", "pdf": "https://arxiv.org/pdf/2505.14079", "abs": "https://arxiv.org/abs/2505.14079", "authors": ["Weihong Du", "Wenrui Liao", "Binyu Yan", "Hongru Liang", "Anthony G. Cohn", "Wenqiang Lei"], "title": "BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Large language model (LLM) based agents have shown great potential in\nfollowing human instructions and automatically completing various tasks. To\ncomplete a task, the agent needs to decompose it into easily executed steps by\nplanning. Existing studies mainly conduct the planning by inferring what steps\nshould be executed next starting from the agent's initial state. However, this\nforward reasoning paradigm doesn't work well for complex tasks. We propose to\nstudy this issue in Minecraft, a virtual environment that simulates complex\ntasks based on real-world scenarios. We believe that the failure of forward\nreasoning is caused by the big perception gap between the agent's initial state\nand task goal. To this end, we leverage backward reasoning and make the\nplanning starting from the terminal state, which can directly achieve the task\ngoal in one step. Specifically, we design a BAckward Reasoning based agent\n(BAR). It is equipped with a recursive goal decomposition module, a state\nconsistency maintaining module and a stage memory module to make robust,\nconsistent, and efficient planning starting from the terminal state.\nExperimental results demonstrate the superiority of BAR over existing methods\nand the effectiveness of proposed modules."}
{"id": "2505.14246", "pdf": "https://arxiv.org/pdf/2505.14246", "abs": "https://arxiv.org/abs/2505.14246", "authors": ["Ziyu Liu", "Yuhang Zang", "Yushan Zou", "Zijian Liang", "Xiaoyi Dong", "Yuhang Cao", "Haodong Duan", "Dahua Lin", "Jiaqi Wang"], "title": "Visual Agentic Reinforcement Fine-Tuning", "categories": ["cs.CV", "cs.AI"], "comment": "project url:\n  https://github.com/Liuziyu77/Visual-RFT/tree/main/Visual-ARFT", "summary": "A key trend in Large Reasoning Models (e.g., OpenAI's o3) is the native\nagentic ability to use external tools such as web browsers for searching and\nwriting/executing code for image manipulation to think with images. In the\nopen-source research community, while significant progress has been made in\nlanguage-only agentic abilities such as function calling and tool integration,\nthe development of multi-modal agentic capabilities that involve truly thinking\nwith images, and their corresponding benchmarks, are still less explored. This\nwork highlights the effectiveness of Visual Agentic Reinforcement Fine-Tuning\n(Visual-ARFT) for enabling flexible and adaptive reasoning abilities for Large\nVision-Language Models (LVLMs). With Visual-ARFT, open-source LVLMs gain the\nability to browse websites for real-time information updates and write code to\nmanipulate and analyze input images through cropping, rotation, and other image\nprocessing techniques. We also present a Multi-modal Agentic Tool Bench (MAT)\nwith two settings (MAT-Search and MAT-Coding) designed to evaluate LVLMs'\nagentic search and coding abilities. Our experimental results demonstrate that\nVisual-ARFT outperforms its baseline by +18.6% F1 / +13.0% EM on MAT-Coding and\n+10.3% F1 / +8.7% EM on MAT-Search, ultimately surpassing GPT-4o. Visual-ARFT\nalso achieves +29.3 F1% / +25.9% EM gains on existing multi-hop QA benchmarks\nsuch as 2Wiki and HotpotQA, demonstrating strong generalization capabilities.\nOur findings suggest that Visual-ARFT offers a promising path toward building\nrobust and generalizable multimodal agents."}
{"id": "2505.13787", "pdf": "https://arxiv.org/pdf/2505.13787", "abs": "https://arxiv.org/abs/2505.13787", "authors": ["Chris Cundy", "Adam Gleave"], "title": "Preference Learning with Lie Detectors can Induce Honesty or Evasion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As AI systems become more capable, deceptive behaviors can undermine\nevaluation and mislead users at deployment. Recent work has shown that lie\ndetectors can accurately classify deceptive behavior, but they are not\ntypically used in the training pipeline due to concerns around contamination\nand objective hacking. We examine these concerns by incorporating a lie\ndetector into the labelling step of LLM post-training and evaluating whether\nthe learned policy is genuinely more honest, or instead learns to fool the lie\ndetector while remaining deceptive. Using DolusChat, a novel 65k-example\ndataset with paired truthful/deceptive responses, we identify three key factors\nthat determine the honesty of learned policies: amount of exploration during\npreference learning, lie detector accuracy, and KL regularization strength. We\nfind that preference learning with lie detectors and GRPO can lead to policies\nwhich evade lie detectors, with deception rates of over 85\\%. However, if the\nlie detector true positive rate (TPR) or KL regularization is sufficiently\nhigh, GRPO learns honest policies. In contrast, off-policy algorithms (DPO)\nconsistently lead to deception rates under 25\\% for realistic TPRs. Our results\nillustrate a more complex picture than previously assumed: depending on the\ncontext, lie-detector-enhanced training can be a powerful tool for scalable\noversight, or a counterproductive method encouraging undetectable misalignment."}
{"id": "2505.14235", "pdf": "https://arxiv.org/pdf/2505.14235", "abs": "https://arxiv.org/abs/2505.14235", "authors": ["Yequan Wang", "Aixin Sun"], "title": "Toward Embodied AGI: A Review of Embodied AI and the Road Ahead", "categories": ["cs.AI"], "comment": null, "summary": "Artificial General Intelligence (AGI) is often envisioned as inherently\nembodied. With recent advances in robotics and foundational AI models, we stand\nat the threshold of a new era-one marked by increasingly generalized embodied\nAI systems. This paper contributes to the discourse by introducing a systematic\ntaxonomy of Embodied AGI spanning five levels (L1-L5). We review existing\nresearch and challenges at the foundational stages (L1-L2) and outline the key\ncomponents required to achieve higher-level capabilities (L3-L5). Building on\nthese insights and existing technologies, we propose a conceptual framework for\nan L3+ robotic brain, offering both a technical outlook and a foundation for\nfuture exploration."}
{"id": "2505.14080", "pdf": "https://arxiv.org/pdf/2505.14080", "abs": "https://arxiv.org/abs/2505.14080", "authors": ["Franziska Sofia Hafner", "Ana Valdivia", "Luc Rocher"], "title": "Gender Trouble in Language Models: An Empirical Audit Guided by Gender Performativity Theory", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Language models encode and subsequently perpetuate harmful gendered\nstereotypes. Research has succeeded in mitigating some of these harms, e.g. by\ndissociating non-gendered terms such as occupations from gendered terms such as\n'woman' and 'man'. This approach, however, remains superficial given that\nassociations are only one form of prejudice through which gendered harms arise.\nCritical scholarship on gender, such as gender performativity theory,\nemphasizes how harms often arise from the construction of gender itself, such\nas conflating gender with biological sex. In language models, these issues\ncould lead to the erasure of transgender and gender diverse identities and\ncause harms in downstream applications, from misgendering users to\nmisdiagnosing patients based on wrong assumptions about their anatomy.\n  For FAccT research on gendered harms to go beyond superficial linguistic\nassociations, we advocate for a broader definition of 'gender bias' in language\nmodels. We operationalize insights on the construction of gender through\nlanguage from gender studies literature and then empirically test how 16\nlanguage models of different architectures, training datasets, and model sizes\nencode gender. We find that language models tend to encode gender as a binary\ncategory tied to biological sex, and that gendered terms that do not neatly\nfall into one of these binary categories are erased and pathologized. Finally,\nwe show that larger models, which achieve better results on performance\nbenchmarks, learn stronger associations between gender and sex, further\nreinforcing a narrow understanding of gender. Our findings lead us to call for\na re-evaluation of how gendered harms in language models are defined and\naddressed."}
{"id": "2505.14254", "pdf": "https://arxiv.org/pdf/2505.14254", "abs": "https://arxiv.org/abs/2505.14254", "authors": ["Yuanyuan Chang", "Yinghua Yao", "Tao Qin", "Mengmeng Wang", "Ivor Tsang", "Guang Dai"], "title": "Instructing Text-to-Image Diffusion Models via Classifier-Guided Semantic Optimization", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image diffusion models have emerged as powerful tools for\nhigh-quality image generation and editing. Many existing approaches rely on\ntext prompts as editing guidance. However, these methods are constrained by the\nneed for manual prompt crafting, which can be time-consuming, introduce\nirrelevant details, and significantly limit editing performance. In this work,\nwe propose optimizing semantic embeddings guided by attribute classifiers to\nsteer text-to-image models toward desired edits, without relying on text\nprompts or requiring any training or fine-tuning of the diffusion model. We\nutilize classifiers to learn precise semantic embeddings at the dataset level.\nThe learned embeddings are theoretically justified as the optimal\nrepresentation of attribute semantics, enabling disentangled and accurate\nedits. Experiments further demonstrate that our method achieves high levels of\ndisentanglement and strong generalization across different domains of data."}
{"id": "2505.13791", "pdf": "https://arxiv.org/pdf/2505.13791", "abs": "https://arxiv.org/abs/2505.13791", "authors": ["Austin H. Cheng", "Chong Sun", "Al√°n Aspuru-Guzik"], "title": "Scalable Autoregressive 3D Molecule Generation", "categories": ["cs.LG", "physics.chem-ph"], "comment": null, "summary": "Generative models of 3D molecular structure play a rapidly growing role in\nthe design and simulation of molecules. Diffusion models currently dominate the\nspace of 3D molecule generation, while autoregressive models have trailed\nbehind. In this work, we present Quetzal, a simple but scalable autoregressive\nmodel that builds molecules atom-by-atom in 3D. Treating each molecule as an\nordered sequence of atoms, Quetzal combines a causal transformer that predicts\nthe next atom's discrete type with a smaller Diffusion MLP that models the\ncontinuous next-position distribution. Compared to existing autoregressive\nbaselines, Quetzal achieves substantial improvements in generation quality and\nis competitive with the performance of state-of-the-art diffusion models. In\naddition, by reducing the number of expensive forward passes through a dense\ntransformer, Quetzal enables significantly faster generation speed, as well as\nexact divergence-based likelihood computation. Finally, without any\narchitectural changes, Quetzal natively handles variable-size tasks like\nhydrogen decoration and scaffold completion. We hope that our work motivates a\nperspective on scalability and generality for generative modelling of 3D\nmolecules."}
{"id": "2505.14289", "pdf": "https://arxiv.org/pdf/2505.14289", "abs": "https://arxiv.org/abs/2505.14289", "authors": ["Yijie Lu", "Tianjie Ju", "Manman Zhao", "Xinbei Ma", "Yuan Guo", "ZhuoSheng Zhang"], "title": "EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection", "categories": ["cs.AI"], "comment": null, "summary": "As multimodal agents are increasingly trained to operate graphical user\ninterfaces (GUIs) to complete user tasks, they face a growing threat from\nindirect prompt injection, attacks in which misleading instructions are\nembedded into the agent's visual environment, such as popups or chat messages,\nand misinterpreted as part of the intended task. A typical example is\nenvironmental injection, in which GUI elements are manipulated to influence\nagent behavior without directly modifying the user prompt. To address these\nemerging attacks, we propose EVA, a red teaming framework for indirect prompt\ninjection which transforms the attack into a closed loop optimization by\ncontinuously monitoring an agent's attention distribution over the GUI and\nupdating adversarial cues, keywords, phrasing, and layout, in response.\nCompared with prior one shot methods that generate fixed prompts without regard\nfor how the model allocates visual attention, EVA dynamically adapts to\nemerging attention hotspots, yielding substantially higher attack success rates\nand far greater transferability across diverse GUI scenarios. We evaluate EVA\non six widely used generalist and specialist GUI agents in realistic settings\nsuch as popup manipulation, chat based phishing, payments, and email\ncomposition. Experimental results show that EVA substantially improves success\nrates over static baselines. Under goal agnostic constraints, where the\nattacker does not know the agent's task intent, EVA still discovers effective\npatterns. Notably, we find that injection styles transfer well across models,\nrevealing shared behavioral biases in GUI agents. These results suggest that\nevolving indirect prompt injection is a powerful tool not only for red teaming\nagents, but also for uncovering common vulnerabilities in their multimodal\ndecision making."}
{"id": "2505.14099", "pdf": "https://arxiv.org/pdf/2505.14099", "abs": "https://arxiv.org/abs/2505.14099", "authors": ["Yihua Zhu", "Qianying Liu", "Akiko Aizawa", "Hidetoshi Shimodaira"], "title": "Beyond Chains: Bridging Large Language Models and Knowledge Bases in Complex Question Answering", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural language\nquestions using structured knowledge from KBs. While LLM-only approaches offer\ngeneralization, they suffer from outdated knowledge, hallucinations, and lack\nof transparency. Chain-based KG-RAG methods address these issues by\nincorporating external KBs, but are limited to simple chain-structured\nquestions due to the absence of planning and logical structuring. Inspired by\nsemantic parsing methods, we propose PDRR: a four-stage framework consisting of\nPredict, Decompose, Retrieve, and Reason. Our method first predicts the\nquestion type and decomposes the question into structured triples. Then\nretrieves relevant information from KBs and guides the LLM as an agent to\nreason over and complete the decomposed triples. Experimental results\ndemonstrate that PDRR consistently outperforms existing methods across various\nLLM backbones and achieves superior performance on both chain-structured and\nnon-chain complex questions."}
{"id": "2505.14257", "pdf": "https://arxiv.org/pdf/2505.14257", "abs": "https://arxiv.org/abs/2505.14257", "authors": ["Jianfei Zhao", "Feng Zhang", "Xin Sun", "Chong Feng"], "title": "Aligning Attention Distribution to Information Flow for Hallucination Mitigation in Large Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Due to the unidirectional masking mechanism, Decoder-Only models propagate\ninformation from left to right. LVLMs (Large Vision-Language Models) follow the\nsame architecture, with visual information gradually integrated into semantic\nrepresentations during forward propagation. Through systematic analysis, we\nobserve that over 80\\% of the visual information is absorbed into the semantic\nrepresentations. However, the model's attention still predominantly focuses on\nthe visual representations. This misalignment between the attention\ndistribution and the actual information flow undermines the model's visual\nunderstanding ability and contributes to hallucinations. To address this issue,\nwe enhance the model's visual understanding by leveraging the core information\nembedded in semantic representations. Specifically, we identify attention heads\nthat focus on core semantic representations based on their attention\ndistributions. Then, through a two-stage optimization paradigm, we propagate\nthe advantages of these attention heads across the entire model, aligning the\nattention distribution with the actual information flow. We evaluate our method\non three image captioning benchmarks using five different LVLMs, demonstrating\nits effectiveness in significantly reducing hallucinations. Further experiments\nreveal a trade-off between reduced hallucinations and richer details. Notably,\nour method allows for manual adjustment of the model's conservativeness,\nenabling flexible control to meet diverse real-world requirements. Code will be\nreleased once accepted."}
{"id": "2505.13811", "pdf": "https://arxiv.org/pdf/2505.13811", "abs": "https://arxiv.org/abs/2505.13811", "authors": ["Parikshit Bansal", "Sujay Sanghavi"], "title": "Context-Free Synthetic Data Mitigates Forgetting", "categories": ["cs.LG"], "comment": null, "summary": "Fine-tuning a language model often results in a degradation of its existing\nperformance on other tasks, due to a shift in the model parameters; this\nphenomenon is often referred to as (catastrophic) forgetting. We are interested\nin mitigating this, in settings where we only have access to the model weights\nbut no access to its training data/recipe. A natural approach is to penalize\nthe KL divergence between the original model and the new one. Our main\nrealization is that a simple process - which we term context-free generation -\nallows for an approximate unbiased estimation of this KL divergence. We show\nthat augmenting a fine-tuning dataset with context-free generations mitigates\nforgetting, in two settings: (a) preserving the zero-shot performance of\npretrained-only models, and (b) preserving the reasoning performance of\nthinking models. We show that contextual synthetic data, and even a portion of\nthe pretraining data, are less effective. We also investigate the effect of\nchoices like generation temperature, data ratios etc. We present our results\nfor OLMo-1B for pretrained-only setting and R1-Distill-Llama-8B for the\nreasoning setting."}
{"id": "2505.14300", "pdf": "https://arxiv.org/pdf/2505.14300", "abs": "https://arxiv.org/abs/2505.14300", "authors": ["Maheep Chaudhary", "Fazl Barez"], "title": "SafetyNet: Detecting Harmful Outputs in LLMs by Modeling and Monitoring Deceptive Behaviors", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "High-risk industries like nuclear and aviation use real-time monitoring to\ndetect dangerous system conditions. Similarly, Large Language Models (LLMs)\nneed monitoring safeguards. We propose a real-time framework to predict harmful\nAI outputs before they occur by using an unsupervised approach that treats\nnormal behavior as the baseline and harmful outputs as outliers. Our study\nfocuses specifically on backdoor-triggered responses -- where specific input\nphrases activate hidden vulnerabilities causing the model to generate unsafe\ncontent like violence, pornography, or hate speech. We address two key\nchallenges: (1) identifying true causal indicators rather than surface\ncorrelations, and (2) preventing advanced models from deception -- deliberately\nevading monitoring systems. Hence, we approach this problem from an\nunsupervised lens by drawing parallels to human deception: just as humans\nexhibit physical indicators while lying, we investigate whether LLMs display\ndistinct internal behavioral signatures when generating harmful content. Our\nstudy addresses two critical challenges: 1) designing monitoring systems that\ncapture true causal indicators rather than superficial correlations; and\n2)preventing intentional evasion by increasingly capable \"Future models''. Our\nfindings show that models can produce harmful content through causal mechanisms\nand can become deceptive by: (a) alternating between linear and non-linear\nrepresentations, and (b) modifying feature relationships. To counter this, we\ndeveloped Safety-Net -- a multi-detector framework that monitors different\nrepresentation dimensions, successfully detecting harmful behavior even when\ninformation is shifted across representational spaces to evade individual\nmonitors. Our evaluation shows 96% accuracy in detecting harmful cases using\nour unsupervised ensemble approach."}
{"id": "2505.14101", "pdf": "https://arxiv.org/pdf/2505.14101", "abs": "https://arxiv.org/abs/2505.14101", "authors": ["Ernests Lavrinovics", "Russa Biswas", "Katja Hose", "Johannes Bjerva"], "title": "MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have inherent limitations of faithfulness and\nfactuality, commonly referred to as hallucinations. Several benchmarks have\nbeen developed that provide a test bed for factuality evaluation within the\ncontext of English-centric datasets, while relying on supplementary informative\ncontext like web links or text passages but ignoring the available structured\nfactual resources. To this end, Knowledge Graphs (KGs) have been identified as\na useful aid for hallucination mitigation, as they provide a structured way to\nrepresent the facts about entities and their relations with minimal linguistic\noverhead. We bridge the lack of KG paths and multilinguality for factual\nlanguage modeling within the existing hallucination evaluation benchmarks and\npropose a KG-based multilingual, multihop benchmark called \\textbf{MultiHal}\nframed for generative text evaluation. As part of our data collection pipeline,\nwe mined 140k KG-paths from open-domain KGs, from which we pruned noisy\nKG-paths, curating a high-quality subset of 25.9k. Our baseline evaluation\nshows an absolute scale increase by approximately 0.12 to 0.36 points for the\nsemantic similarity score in KG-RAG over vanilla QA across multiple languages\nand multiple models, demonstrating the potential of KG integration. We\nanticipate MultiHal will foster future research towards several graph-based\nhallucination mitigation and fact-checking tasks."}
{"id": "2505.14260", "pdf": "https://arxiv.org/pdf/2505.14260", "abs": "https://arxiv.org/abs/2505.14260", "authors": ["Luxi Lin", "Zhihang Lin", "Zhanpeng Zeng", "Rongrong Ji"], "title": "Speculative Decoding Reimagined for Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages", "summary": "This paper introduces Multimodal Speculative Decoding (MSD) to accelerate\nMultimodal Large Language Models (MLLMs) inference. Speculative decoding has\nbeen shown to accelerate Large Language Models (LLMs) without sacrificing\naccuracy. However, current speculative decoding methods for MLLMs fail to\nachieve the same speedup as they do for LLMs. To address this, we reimagine\nspeculative decoding specifically for MLLMs. Our analysis of MLLM\ncharacteristics reveals two key design principles for MSD: (1) Text and visual\ntokens have fundamentally different characteristics and need to be processed\nseparately during drafting. (2) Both language modeling ability and visual\nperception capability are crucial for the draft model. For the first principle,\nMSD decouples text and visual tokens in the draft model, allowing each to be\nhandled based on its own characteristics. For the second principle, MSD uses a\ntwo-stage training strategy: In stage one, the draft model is trained on\ntext-only instruction-tuning datasets to improve its language modeling ability.\nIn stage two, MSD gradually introduces multimodal data to enhance the visual\nperception capability of the draft model. Experiments show that MSD boosts\ninference speed by up to $2.29\\times$ for LLaVA-1.5-7B and up to $2.46\\times$\nfor LLaVA-1.5-13B on multimodal benchmarks, demonstrating its effectiveness.\nOur code is available at https://github.com/Lyn-Lucy/MSD."}
{"id": "2505.13813", "pdf": "https://arxiv.org/pdf/2505.13813", "abs": "https://arxiv.org/abs/2505.13813", "authors": ["Matthew Raffel", "Lizhong Chen"], "title": "FlashKAT: Understanding and Addressing Performance Bottlenecks in the Kolmogorov-Arnold Transformer", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The Kolmogorov-Arnold Network (KAN) has been gaining popularity as an\nalternative to the multi-layer perceptron (MLP) with its increased\nexpressiveness and interpretability. However, the KAN can be orders of\nmagnitude slower due to its increased computational cost and training\ninstability, limiting its applicability to larger-scale tasks. Recently, the\nKolmogorov-Arnold Transformer (KAT) has been proposed, which can achieve FLOPs\nsimilar to the traditional Transformer with MLPs by leveraging Group-Rational\nKAN (GR-KAN). Unfortunately, despite the comparable FLOPs, our\ncharacterizations reveal that the KAT is still 123x slower in training speeds,\nindicating that there are other performance bottlenecks beyond FLOPs. In this\npaper, we conduct a series of experiments to understand the root cause of the\nslowdown in KAT. We uncover that the slowdown can be isolated to memory stalls\nand, more specifically, in the backward pass of GR-KAN caused by inefficient\ngradient accumulation. To address this memory bottleneck, we propose FlashKAT,\nwhich builds on our restructured kernel that minimizes gradient accumulation\nwith atomic adds and accesses to slow memory. Evaluations demonstrate that\nFlashKAT can achieve a training speedup of 86.5x compared with the\nstate-of-the-art KAT, while reducing rounding errors in the coefficient\ngradients. Our code is available at https://github.com/OSU-STARLAB/FlashKAT."}
{"id": "2505.14366", "pdf": "https://arxiv.org/pdf/2505.14366", "abs": "https://arxiv.org/abs/2505.14366", "authors": ["Joel Currie", "Gioele Migno", "Enrico Piacenti", "Maria Elena Giannaccini", "Patric Bach", "Davide De Tommaso", "Agnieszka Wykowska"], "title": "Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted to: Intelligent Autonomous Systems (IAS) 2025 as Late\n  Breaking Report", "summary": "We present a conceptual framework for training Vision-Language Models (VLMs)\nto perform Visual Perspective Taking (VPT), a core capability for embodied\ncognition essential for Human-Robot Interaction (HRI). As a first step toward\nthis goal, we introduce a synthetic dataset, generated in NVIDIA Omniverse,\nthat enables supervised learning for spatial reasoning tasks. Each instance\nincludes an RGB image, a natural language description, and a ground-truth 4X4\ntransformation matrix representing object pose. We focus on inferring Z-axis\ndistance as a foundational skill, with future extensions targeting full 6\nDegrees Of Freedom (DOFs) reasoning. The dataset is publicly available to\nsupport further research. This work serves as a foundational step toward\nembodied AI systems capable of spatial understanding in interactive human-robot\nscenarios."}
{"id": "2505.14104", "pdf": "https://arxiv.org/pdf/2505.14104", "abs": "https://arxiv.org/abs/2505.14104", "authors": ["Wei Fan", "Tianshi Zheng", "Yiran Hu", "Zheye Deng", "Weiqi Wang", "Baixuan Xu", "Chunyang Li", "Haoran Li", "Weixing Shen", "Yangqiu Song"], "title": "Legal Rule Induction: Towards Generalizable Principle Discovery from Analogous Judicial Precedents", "categories": ["cs.CL"], "comment": "Under Review", "summary": "Legal rules encompass not only codified statutes but also implicit\nadjudicatory principles derived from precedents that contain discretionary\nnorms, social morality, and policy. While computational legal research has\nadvanced in applying established rules to cases, inducing legal rules from\njudicial decisions remains understudied, constrained by limitations in model\ninference efficacy and symbolic reasoning capability. The advent of Large\nLanguage Models (LLMs) offers unprecedented opportunities for automating the\nextraction of such latent principles, yet progress is stymied by the absence of\nformal task definitions, benchmark datasets, and methodologies. To address this\ngap, we formalize Legal Rule Induction (LRI) as the task of deriving concise,\ngeneralizable doctrinal rules from sets of analogous precedents, distilling\ntheir shared preconditions, normative behaviors, and legal consequences. We\nintroduce the first LRI benchmark, comprising 5,121 case sets (38,088 Chinese\ncases in total) for model tuning and 216 expert-annotated gold test sets.\nExperimental results reveal that: 1) State-of-the-art LLMs struggle with\nover-generalization and hallucination; 2) Training on our dataset markedly\nenhances LLMs capabilities in capturing nuanced rule patterns across similar\ncases."}
{"id": "2505.14270", "pdf": "https://arxiv.org/pdf/2505.14270", "abs": "https://arxiv.org/abs/2505.14270", "authors": ["Yoorhim Cho", "Hongyeob Kim", "Semin Kim", "Youjia Zhang", "Yunseok Choi", "Sungeun Hong"], "title": "RA-Touch: Retrieval-Augmented Touch Understanding with Enriched Visual Data", "categories": ["cs.CV"], "comment": null, "summary": "Visuo-tactile perception aims to understand an object's tactile properties,\nsuch as texture, softness, and rigidity. However, the field remains\nunderexplored because collecting tactile data is costly and labor-intensive. We\nobserve that visually distinct objects can exhibit similar surface textures or\nmaterial properties. For example, a leather sofa and a leather jacket have\ndifferent appearances but share similar tactile properties. This implies that\ntactile understanding can be guided by material cues in visual data, even\nwithout direct tactile supervision. In this paper, we introduce RA-Touch, a\nretrieval-augmented framework that improves visuo-tactile perception by\nleveraging visual data enriched with tactile semantics. We carefully recaption\na large-scale visual dataset with tactile-focused descriptions, enabling the\nmodel to access tactile semantics typically absent from conventional visual\ndatasets. A key challenge remains in effectively utilizing these tactile-aware\nexternal descriptions. RA-Touch addresses this by retrieving visual-textual\nrepresentations aligned with tactile inputs and integrating them to focus on\nrelevant textural and material properties. By outperforming prior methods on\nthe TVL benchmark, our method demonstrates the potential of retrieval-based\nvisual reuse for tactile understanding. Code is available at\nhttps://aim-skku.github.io/RA-Touch"}
{"id": "2505.13819", "pdf": "https://arxiv.org/pdf/2505.13819", "abs": "https://arxiv.org/abs/2505.13819", "authors": ["Lucas Rosenblatt", "Bin Han", "Robert Wolfe", "Bill Howe"], "title": "Fragments to Facts: Partial-Information Fragment Inference from LLMs", "categories": ["cs.LG", "cs.CR", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) can leak sensitive training data through\nmemorization and membership inference attacks. Prior work has primarily focused\non strong adversarial assumptions, including attacker access to entire samples\nor long, ordered prefixes, leaving open the question of how vulnerable LLMs are\nwhen adversaries have only partial, unordered sample information. For example,\nif an attacker knows a patient has \"hypertension,\" under what conditions can\nthey query a model fine-tuned on patient data to learn the patient also has\n\"osteoarthritis?\" In this paper, we introduce a more general threat model under\nthis weaker assumption and show that fine-tuned LLMs are susceptible to these\nfragment-specific extraction attacks. To systematically investigate these\nattacks, we propose two data-blind methods: (1) a likelihood ratio attack\ninspired by methods from membership inference, and (2) a novel approach, PRISM,\nwhich regularizes the ratio by leveraging an external prior. Using examples\nfrom both medical and legal settings, we show that both methods are competitive\nwith a data-aware baseline classifier that assumes access to labeled\nin-distribution data, underscoring their robustness."}
{"id": "2505.14381", "pdf": "https://arxiv.org/pdf/2505.14381", "abs": "https://arxiv.org/abs/2505.14381", "authors": ["Yuyang Dong", "Nobuhiro Ueda", "Kriszti√°n Boros", "Daiki Ito", "Takuya Sera", "Masafumi Oyamada"], "title": "SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": "v1", "summary": "With the increasing adoption of Large Language Models (LLMs) and\nVision-Language Models (VLMs), rich document analysis technologies for\napplications like Retrieval-Augmented Generation (RAG) and visual RAG are\ngaining significant attention. Recent research indicates that using VLMs can\nachieve better RAG performance, but processing rich documents still remains a\nchallenge since a single page contains large amounts of information. In this\npaper, we present SCAN (\\textbf{S}emanti\\textbf{C} Document Layout\n\\textbf{AN}alysis), a novel approach enhancing both textual and visual\nRetrieval-Augmented Generation (RAG) systems working with visually rich\ndocuments. It is a VLM-friendly approach that identifies document components\nwith appropriate semantic granularity, balancing context preservation with\nprocessing efficiency. SCAN uses a coarse-grained semantic approach that\ndivides documents into coherent regions covering continuous components. We\ntrained the SCAN model by fine-tuning object detection models with\nsophisticated annotation datasets. Our experimental results across English and\nJapanese datasets demonstrate that applying SCAN improves end-to-end textual\nRAG performance by up to 9.0\\% and visual RAG performance by up to 6.4\\%,\noutperforming conventional approaches and even commercial document processing\nsolutions."}
{"id": "2505.14106", "pdf": "https://arxiv.org/pdf/2505.14106", "abs": "https://arxiv.org/abs/2505.14106", "authors": ["Li Li", "Peilin Cai", "Ryan A. Rossi", "Franck Dernoncourt", "Branislav Kveton", "Junda Wu", "Tong Yu", "Linxin Song", "Tiankai Yang", "Yuehan Qin", "Nesreen K. Ahmed", "Samyadeep Basu", "Subhojyoti Mukherjee", "Ruiyi Zhang", "Zhengmian Hu", "Bo Ni", "Yuxiao Zhou", "Zichao Wang", "Yue Huang", "Yu Wang", "Xiangliang Zhang", "Philip S. Yu", "Xiyang Hu", "Yue Zhao"], "title": "A Personalized Conversational Benchmark: Towards Simulating Personalized Conversations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present PersonaConvBench, a large-scale benchmark for evaluating\npersonalized reasoning and generation in multi-turn conversations with large\nlanguage models (LLMs). Unlike existing work that focuses on either\npersonalization or conversational structure in isolation, PersonaConvBench\nintegrates both, offering three core tasks: sentence classification, impact\nregression, and user-centric text generation across ten diverse Reddit-based\ndomains. This design enables systematic analysis of how personalized\nconversational context shapes LLM outputs in realistic multi-user scenarios. We\nbenchmark several commercial and open-source LLMs under a unified prompting\nsetup and observe that incorporating personalized history yields substantial\nperformance improvements, including a 198 percent relative gain over the best\nnon-conversational baseline in sentiment classification. By releasing\nPersonaConvBench with evaluations and code, we aim to support research on LLMs\nthat adapt to individual styles, track long-term context, and produce\ncontextually rich, engaging responses."}
{"id": "2505.14298", "pdf": "https://arxiv.org/pdf/2505.14298", "abs": "https://arxiv.org/abs/2505.14298", "authors": ["Fulong Yao", "Wenju Zhou", "Huosheng Hu"], "title": "A Review of Vision-Based Assistive Systems for Visually Impaired People: Technologies, Applications, and Future Directions", "categories": ["cs.CV"], "comment": null, "summary": "Visually impaired individuals rely heavily on accurate and timely information\nabout obstacles and their surrounding environments to achieve independent\nliving. In recent years, significant progress has been made in the development\nof assistive technologies, particularly vision-based systems, that enhance\nmobility and facilitate interaction with the external world in both indoor and\noutdoor settings. This paper presents a comprehensive review of recent advances\nin assistive systems designed for the visually impaired, with a focus on\nstate-of-the-art technologies in obstacle detection, navigation, and user\ninteraction. In addition, emerging trends and future directions in visual\nguidance systems are discussed."}
{"id": "2505.13820", "pdf": "https://arxiv.org/pdf/2505.13820", "abs": "https://arxiv.org/abs/2505.13820", "authors": ["Jun Liu", "Zhenglun Kong", "Peiyan Dong", "Changdi Yang", "Tianqi Li", "Hao Tang", "Geng Yuan", "Wei Niu", "Wenbin Zhang", "Pu Zhao", "Xue Lin", "Dong Huang", "Yanzhi Wang"], "title": "Structured Agent Distillation for Large Language Model", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) exhibit strong capabilities as decision-making\nagents by interleaving reasoning and actions, as seen in ReAct-style\nframeworks. Yet, their practical deployment is constrained by high inference\ncosts and large model sizes. We propose Structured Agent Distillation, a\nframework that compresses large LLM-based agents into smaller student models\nwhile preserving both reasoning fidelity and action consistency. Unlike\nstandard token-level distillation, our method segments trajectories into\n{[REASON]} and {[ACT]} spans, applying segment-specific losses to align each\ncomponent with the teacher's behavior. This structure-aware supervision enables\ncompact agents to better replicate the teacher's decision process. Experiments\non ALFWorld, HotPotQA-ReAct, and WebShop show that our approach consistently\noutperforms token-level and imitation learning baselines, achieving significant\ncompression with minimal performance drop. Scaling and ablation results further\nhighlight the importance of span-level alignment for efficient and deployable\nagents."}
{"id": "2505.14391", "pdf": "https://arxiv.org/pdf/2505.14391", "abs": "https://arxiv.org/abs/2505.14391", "authors": ["Zhaohui Yang", "Chenghua He", "Xiaowen Shi", "Linjing Li", "Qiyue Yin", "Shihong Deng", "Daxin Jiang"], "title": "Beyond the First Error: Process Reward Models for Reflective Mathematical Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Many studies focus on data annotation techniques for training effective PRMs.\nHowever, current methods encounter a significant issue when applied to long CoT\nreasoning processes: they tend to focus solely on the first incorrect step and\nall preceding steps, assuming that all subsequent steps are incorrect. These\nmethods overlook the unique self-correction and reflection mechanisms inherent\nin long CoT, where correct reasoning steps may still occur after initial\nreasoning mistakes. To address this issue, we propose a novel data annotation\nmethod for PRMs specifically designed to score the long CoT reasoning process.\nGiven that under the reflection pattern, correct and incorrect steps often\nalternate, we introduce the concepts of Error Propagation and Error Cessation,\nenhancing PRMs' ability to identify both effective self-correction behaviors\nand reasoning based on erroneous steps. Leveraging an LLM-based judger for\nannotation, we collect 1.7 million data samples to train a 7B PRM and evaluate\nit at both solution and step levels. Experimental results demonstrate that\ncompared to existing open-source PRMs and PRMs trained on open-source datasets,\nour PRM achieves superior performance across various metrics, including search\nguidance, BoN, and F1 scores. Compared to widely used MC-based annotation\nmethods, our annotation approach not only achieves higher data efficiency but\nalso delivers superior performance. Detailed analysis is also conducted to\ndemonstrate the stability and generalizability of our method."}
{"id": "2505.14107", "pdf": "https://arxiv.org/pdf/2505.14107", "abs": "https://arxiv.org/abs/2505.14107", "authors": ["Yakun Zhu", "Zhongzhen Huang", "Linjie Mu", "Yutong Huang", "Wei Nie", "Shaoting Zhang", "Pengfei Liu", "Xiaofan Zhang"], "title": "DiagnosisArena: Benchmarking Diagnostic Reasoning for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The emergence of groundbreaking large language models capable of performing\ncomplex reasoning tasks holds significant promise for addressing various\nscientific challenges, including those arising in complex clinical scenarios.\nTo enable their safe and effective deployment in real-world healthcare\nsettings, it is urgently necessary to benchmark the diagnostic capabilities of\ncurrent models systematically. Given the limitations of existing medical\nbenchmarks in evaluating advanced diagnostic reasoning, we present\nDiagnosisArena, a comprehensive and challenging benchmark designed to\nrigorously assess professional-level diagnostic competence. DiagnosisArena\nconsists of 1,113 pairs of segmented patient cases and corresponding diagnoses,\nspanning 28 medical specialties, deriving from clinical case reports published\nin 10 top-tier medical journals. The benchmark is developed through a\nmeticulous construction pipeline, involving multiple rounds of screening and\nreview by both AI systems and human experts, with thorough checks conducted to\nprevent data leakage. Our study reveals that even the most advanced reasoning\nmodels, o3-mini, o1, and DeepSeek-R1, achieve only 45.82%, 31.09%, and 17.79%\naccuracy, respectively. This finding highlights a significant generalization\nbottleneck in current large language models when faced with clinical diagnostic\nreasoning challenges. Through DiagnosisArena, we aim to drive further\nadvancements in AIs diagnostic reasoning capabilities, enabling more effective\nsolutions for real-world clinical diagnostic challenges. We provide the\nbenchmark and evaluation tools for further research and development\nhttps://github.com/SPIRAL-MED/DiagnosisArena."}
{"id": "2505.14318", "pdf": "https://arxiv.org/pdf/2505.14318", "abs": "https://arxiv.org/abs/2505.14318", "authors": ["Wenjun Hou", "Yi Cheng", "Kaishuai Xu", "Heng Li", "Yan Hu", "Wenjie Li", "Jiang Liu"], "title": "RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious domains, including radiology report generation. Previous approaches\nhave attempted to utilize multimodal LLMs for this task, enhancing their\nperformance through the integration of domain-specific knowledge retrieval.\nHowever, these approaches often overlook the knowledge already embedded within\nthe LLMs, leading to redundant information integration and inefficient\nutilization of learned representations. To address this limitation, we propose\nRADAR, a framework for enhancing radiology report generation with supplementary\nknowledge injection. RADAR improves report generation by systematically\nleveraging both the internal knowledge of an LLM and externally retrieved\ninformation. Specifically, it first extracts the model's acquired knowledge\nthat aligns with expert image-based classification outputs. It then retrieves\nrelevant supplementary knowledge to further enrich this information. Finally,\nby aggregating both sources, RADAR generates more accurate and informative\nradiology reports. Extensive experiments on MIMIC-CXR, CheXpert-Plus, and IU\nX-ray demonstrate that our model outperforms state-of-the-art LLMs in both\nlanguage quality and clinical accuracy"}
{"id": "2505.13852", "pdf": "https://arxiv.org/pdf/2505.13852", "abs": "https://arxiv.org/abs/2505.13852", "authors": ["Yusheng Zhao", "Chi Zhang", "Yuxuan Du"], "title": "Rethink the Role of Deep Learning towards Large-scale Quantum Systems", "categories": ["cs.LG", "quant-ph"], "comment": "ICML 2025", "summary": "Characterizing the ground state properties of quantum systems is fundamental\nto capturing their behavior but computationally challenging. Recent advances in\nAI have introduced novel approaches, with diverse machine learning (ML) and\ndeep learning (DL) models proposed for this purpose. However, the necessity and\nspecific role of DL models in these tasks remain unclear, as prior studies\noften employ varied or impractical quantum resources to construct datasets,\nresulting in unfair comparisons. To address this, we systematically benchmark\nDL models against traditional ML approaches across three families of\nHamiltonian, scaling up to 127 qubits in three crucial ground-state learning\ntasks while enforcing equivalent quantum resource usage. Our results reveal\nthat ML models often achieve performance comparable to or even exceeding that\nof DL approaches across all tasks. Furthermore, a randomization test\ndemonstrates that measurement input features have minimal impact on DL models'\nprediction performance. These findings challenge the necessity of current DL\nmodels in many quantum system learning scenarios and provide valuable insights\ninto their effective utilization."}
{"id": "2505.14394", "pdf": "https://arxiv.org/pdf/2505.14394", "abs": "https://arxiv.org/abs/2505.14394", "authors": ["Mihir Athale", "Vishal Vaddina"], "title": "Knowledge Graph Based Repository-Level Code Generation", "categories": ["cs.AI"], "comment": "8 pages, 3 figures", "summary": "Recent advancements in Large Language Models (LLMs) have transformed code\ngeneration from natural language queries. However, despite their extensive\nknowledge and ability to produce high-quality code, LLMs often struggle with\ncontextual accuracy, particularly in evolving codebases. Current code search\nand retrieval methods frequently lack robustness in both the quality and\ncontextual relevance of retrieved results, leading to suboptimal code\ngeneration. This paper introduces a novel knowledge graph-based approach to\nimprove code search and retrieval leading to better quality of code generation\nin the context of repository-level tasks. The proposed approach represents code\nrepositories as graphs, capturing structural and relational information for\nenhanced context-aware code generation. Our framework employs a hybrid approach\nfor code retrieval to improve contextual relevance, track inter-file modular\ndependencies, generate more robust code and ensure consistency with the\nexisting codebase. We benchmark the proposed approach on the Evolutionary Code\nBenchmark (EvoCodeBench) dataset, a repository-level code generation benchmark,\nand demonstrate that our method significantly outperforms the baseline\napproach. These findings suggest that knowledge graph based code generation\ncould advance robust, context-sensitive coding assistance tools."}
{"id": "2505.14112", "pdf": "https://arxiv.org/pdf/2505.14112", "abs": "https://arxiv.org/abs/2505.14112", "authors": ["Tianle Gu", "Zongqi Wang", "Kexin Huang", "Yuanqi Yao", "Xiangliang Zhang", "Yujiu Yang", "Xiuying Chen"], "title": "Invisible Entropy: Towards Safe and Efficient Low-Entropy LLM Watermarking", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "Logit-based LLM watermarking traces and verifies AI-generated content by\nmaintaining green and red token lists and increasing the likelihood of green\ntokens during generation. However, it fails in low-entropy scenarios, where\npredictable outputs make green token selection difficult without disrupting\nnatural text flow. Existing approaches address this by assuming access to the\noriginal LLM to calculate entropy and selectively watermark high-entropy\ntokens. However, these methods face two major challenges: (1) high\ncomputational costs and detection delays due to reliance on the original LLM,\nand (2) potential risks of model leakage. To address these limitations, we\npropose Invisible Entropy (IE), a watermarking paradigm designed to enhance\nboth safety and efficiency. Instead of relying on the original LLM, IE\nintroduces a lightweight feature extractor and an entropy tagger to predict\nwhether the entropy of the next token is high or low. Furthermore, based on\ntheoretical analysis, we develop a threshold navigator that adaptively sets\nentropy thresholds. It identifies a threshold where the watermark ratio\ndecreases as the green token count increases, enhancing the naturalness of the\nwatermarked text and improving detection robustness. Experiments on HumanEval\nand MBPP datasets demonstrate that IE reduces parameter size by 99\\% while\nachieving performance on par with state-of-the-art methods. Our work introduces\na safe and efficient paradigm for low-entropy watermarking.\nhttps://github.com/Carol-gutianle/IE\nhttps://huggingface.co/datasets/Carol0110/IE-Tagger"}
{"id": "2505.14320", "pdf": "https://arxiv.org/pdf/2505.14320", "abs": "https://arxiv.org/abs/2505.14320", "authors": ["Maria Cuellar", "Hon Kiu", "To", "Arush Mehrotra"], "title": "Accuracy and Fairness of Facial Recognition Technology in Low-Quality Police Images: An Experiment With Synthetic Faces", "categories": ["cs.CV", "stat.AP"], "comment": null, "summary": "Facial recognition technology (FRT) is increasingly used in criminal\ninvestigations, yet most evaluations of its accuracy rely on high-quality\nimages, unlike those often encountered by law enforcement. This study examines\nhow five common forms of image degradation--contrast, brightness, motion blur,\npose shift, and resolution--affect FRT accuracy and fairness across demographic\ngroups. Using synthetic faces generated by StyleGAN3 and labeled with FairFace,\nwe simulate degraded images and evaluate performance using Deepface with\nArcFace loss in 1:n identification tasks. We perform an experiment and find\nthat false positive rates peak near baseline image quality, while false\nnegatives increase as degradation intensifies--especially with blur and low\nresolution. Error rates are consistently higher for women and Black\nindividuals, with Black females most affected. These disparities raise concerns\nabout fairness and reliability when FRT is used in real-world investigative\ncontexts. Nevertheless, even under the most challenging conditions and for the\nmost affected subgroups, FRT accuracy remains substantially higher than that of\nmany traditional forensic methods. This suggests that, if appropriately\nvalidated and regulated, FRT should be considered a valuable investigative\ntool. However, algorithmic accuracy alone is not sufficient: we must also\nevaluate how FRT is used in practice, including user-driven data manipulation.\nSuch cases underscore the need for transparency and oversight in FRT deployment\nto ensure both fairness and forensic validity."}
{"id": "2505.13857", "pdf": "https://arxiv.org/pdf/2505.13857", "abs": "https://arxiv.org/abs/2505.13857", "authors": ["Tian Sun", "Yuqi Chen", "Baihua Zheng", "Weiwei Sun"], "title": "Learning Spatio-Temporal Dynamics for Trajectory Recovery via Time-Aware Transformer", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as a journal paper in IEEE Transactions on Intelligent\n  Transportation Systems (T-ITS)", "summary": "In real-world applications, GPS trajectories often suffer from low sampling\nrates, with large and irregular intervals between consecutive GPS points. This\nsparse characteristic presents challenges for their direct use in GPS-based\nsystems. This paper addresses the task of map-constrained trajectory recovery,\naiming to enhance trajectory sampling rates of GPS trajectories. Previous\nstudies commonly adopt a sequence-to-sequence framework, where an encoder\ncaptures the trajectory patterns and a decoder reconstructs the target\ntrajectory. Within this framework, effectively representing the road network\nand extracting relevant trajectory features are crucial for overall\nperformance. Despite advancements in these models, they fail to fully leverage\nthe complex spatio-temporal dynamics present in both the trajectory and the\nroad network.\n  To overcome these limitations, we categorize the spatio-temporal dynamics of\ntrajectory data into two distinct aspects: spatial-temporal traffic dynamics\nand trajectory dynamics. Furthermore, We propose TedTrajRec, a novel method for\ntrajectory recovery. To capture spatio-temporal traffic dynamics, we introduce\nPD-GNN, which models periodic patterns and learns topologically aware dynamics\nconcurrently for each road segment. For spatio-temporal trajectory dynamics, we\npresent TedFormer, a time-aware Transformer that incorporates temporal dynamics\nfor each GPS location by integrating closed-form neural ordinary differential\nequations into the attention mechanism. This allows TedFormer to effectively\nhandle irregularly sampled data. Extensive experiments on three real-world\ndatasets demonstrate the superior performance of TedTrajRec. The code is\npublicly available at https://github.com/ysygMhdxw/TEDTrajRec/."}
{"id": "2505.14396", "pdf": "https://arxiv.org/pdf/2505.14396", "abs": "https://arxiv.org/abs/2505.14396", "authors": ["Ga√´l Gendron", "Jo≈æe M. Ro≈æanec", "Michael Witbrock", "Gillian Dobbie"], "title": "Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.3; I.2.6; I.2.7; G.2.2; G.3; J.1"], "comment": "29 pages, 9 pages for the main paper, 20 pages for the references and\n  appendix, 25 figures", "summary": "Causal world models are systems that can answer counterfactual questions\nabout an environment of interest, i.e. predict how it would have evolved if an\narbitrary subset of events had been realized differently. It requires\nunderstanding the underlying causes behind chains of events and conducting\ncausal inference for arbitrary unseen distributions. So far, this task eludes\nfoundation models, notably large language models (LLMs), which do not have\ndemonstrated causal reasoning capabilities beyond the memorization of existing\ncausal relationships. Furthermore, evaluating counterfactuals in real-world\napplications is challenging since only the factual world is observed, limiting\nevaluation to synthetic datasets. We address these problems by explicitly\nextracting and modeling causal relationships and propose the Causal\nCartographer framework. First, we introduce a graph retrieval-augmented\ngeneration agent tasked to retrieve causal relationships from data. This\napproach allows us to construct a large network of real-world causal\nrelationships that can serve as a repository of causal knowledge and build\nreal-world counterfactuals. In addition, we create a counterfactual reasoning\nagent constrained by causal relationships to perform reliable step-by-step\ncausal inference. We show that our approach can extract causal knowledge and\nimprove the robustness of LLMs for causal reasoning tasks while reducing\ninference costs and spurious correlations."}
{"id": "2505.14116", "pdf": "https://arxiv.org/pdf/2505.14116", "abs": "https://arxiv.org/abs/2505.14116", "authors": ["Hongru Wang", "Deng Cai", "Wanjun Zhong", "Shijue Huang", "Jeff Z. Pan", "Zeming Liu", "Kam-Fai Wong"], "title": "Self-Reasoning Language Models: Unfold Hidden Reasoning Chains with Few Reasoning Catalyst", "categories": ["cs.CL"], "comment": null, "summary": "Inference-time scaling has attracted much attention which significantly\nenhance the performance of Large Language Models (LLMs) in complex reasoning\ntasks by increasing the length of Chain-of-Thought. These longer intermediate\nreasoning rationales embody various meta-reasoning skills in human cognition,\nsuch as reflection and decomposition, being difficult to create and acquire. In\nthis work, we introduce \\textit{Self-Reasoning Language Model} (SRLM), where\nthe model itself can synthesize longer CoT data and iteratively improve\nperformance through self-training. By incorporating a few demonstration\nexamples (i.e., 1,000 samples) on how to unfold hidden reasoning chains from\nexisting responses, which act as a reasoning catalyst, we demonstrate that SRLM\nnot only enhances the model's initial performance but also ensures more stable\nand consistent improvements in subsequent iterations. Our proposed SRLM\nachieves an average absolute improvement of more than $+2.5$ points across five\nreasoning tasks: MMLU, GSM8K, ARC-C, HellaSwag, and BBH on two backbone models.\nMoreover, it brings more improvements with more times of sampling during\ninference, such as absolute $+7.89$ average improvement with $64$ sampling\ntimes, revealing the in-depth, diverse and creative reasoning paths in SRLM\nagainst the strong baseline."}
{"id": "2505.14321", "pdf": "https://arxiv.org/pdf/2505.14321", "abs": "https://arxiv.org/abs/2505.14321", "authors": ["Bo Feng", "Zhengfeng Lai", "Shiyu Li", "Zizhen Wang", "Simon Wang", "Ping Huang", "Meng Cao"], "title": "Breaking Down Video LLM Benchmarks: Knowledge, Spatial Perception, or True Temporal Understanding?", "categories": ["cs.CV"], "comment": null, "summary": "Existing video understanding benchmarks often conflate knowledge-based and\npurely image-based questions, rather than clearly isolating a model's temporal\nreasoning ability, which is the key aspect that distinguishes video\nunderstanding from other modalities. We identify two major limitations that\nobscure whether higher scores truly indicate stronger understanding of the\ndynamic content in videos: (1) strong language priors, where models can answer\nquestions without watching the video; and (2) shuffling invariance, where\nmodels maintain similar performance on certain questions even when video frames\nare temporally shuffled. To alleviate these issues, we propose VBenchComp, an\nautomated pipeline that categorizes questions into different domains:\nLLM-Answerable, Semantic, and Temporal. Specifically, LLM-Answerable questions\ncan be answered without viewing the video; Semantic questions remain answerable\neven when the video frames are shuffled; and Temporal questions require\nunderstanding the correct temporal order of frames. The rest of the questions\nare labeled as Others. This can enable fine-grained evaluation of different\ncapabilities of a video LLM. Our analysis reveals nuanced model weaknesses that\nare hidden by traditional overall scores, and we offer insights and\nrecommendations for designing future benchmarks that more accurately assess\nvideo LLMs."}
{"id": "2505.13858", "pdf": "https://arxiv.org/pdf/2505.13858", "abs": "https://arxiv.org/abs/2505.13858", "authors": ["Gonzalo E. Constante-Flores", "Hao Chen", "Can Li"], "title": "Enforcing Hard Linear Constraints in Deep Learning Models with Decision Rules", "categories": ["cs.LG"], "comment": "1 figure", "summary": "Deep learning models are increasingly deployed in safety-critical tasks where\npredictions must satisfy hard constraints, such as physical laws, fairness\nrequirements, or safety limits. However, standard architectures lack built-in\nmechanisms to enforce such constraints, and existing approaches based on\nregularization or projection are often limited to simple constraints,\ncomputationally expensive, or lack feasibility guarantees. This paper proposes\na model-agnostic framework for enforcing input-dependent linear equality and\ninequality constraints on neural network outputs. The architecture combines a\ntask network trained for prediction accuracy with a safe network trained using\ndecision rules from the stochastic and robust optimization literature to ensure\nfeasibility across the entire input space. The final prediction is a convex\ncombination of the two subnetworks, guaranteeing constraint satisfaction during\nboth training and inference without iterative procedures or runtime\noptimization. We prove that the architecture is a universal approximator of\nconstrained functions and derive computationally tractable formulations based\non linear decision rules. Empirical results on benchmark regression tasks show\nthat our method consistently satisfies constraints while maintaining\ncompetitive accuracy and low inference latency."}
{"id": "2505.14403", "pdf": "https://arxiv.org/pdf/2505.14403", "abs": "https://arxiv.org/abs/2505.14403", "authors": ["Zhaohui Yang", "Shilei Jiang", "Chen Hu", "Linjing Li", "Shihong Deng", "Daxin Jiang"], "title": "Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in reasoning language models have witnessed a paradigm shift\nfrom short to long CoT pattern. Given the substantial computational cost of\nrollouts in long CoT models, maximizing the utility of fixed training datasets\nbecomes crucial. Our analysis reveals that negative responses contain valuable\ncomponents such as self-reflection and error-correction steps, yet primary\nexisting methods either completely discard negative samples (RFT) or apply\nequal penalization across all tokens (RL), failing to leverage these potential\nlearning signals. In light of this, we propose Behavior Constrained Policy\nGradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline\nRL framework that encompasses three stages: 1) sample segmentation, 2)\nconsensus-based step correctness assessment combining LLM and PRM judgers, and\n3) policy optimization with NSA designed to effectively mine positive steps\nwithin negative samples. Experimental results show that BCPG-NSA outperforms\nbaselines on several challenging math/coding reasoning benchmarks using the\nsame training dataset, achieving improved sample efficiency and demonstrating\nrobustness and scalability when extended to multiple iterations."}
{"id": "2505.14130", "pdf": "https://arxiv.org/pdf/2505.14130", "abs": "https://arxiv.org/abs/2505.14130", "authors": ["Filip Miletiƒá", "Aaron Schmid", "Sabine Schulte im Walde"], "title": "Probing BERT for German Compound Semantics", "categories": ["cs.CL"], "comment": "Accepted to SwissText 2025", "summary": "This paper investigates the extent to which pretrained German BERT encodes\nknowledge of noun compound semantics. We comprehensively vary combinations of\ntarget tokens, layers, and cased vs. uncased models, and evaluate them by\npredicting the compositionality of 868 gold standard compounds. Looking at\nrepresentational patterns within the transformer architecture, we observe\ntrends comparable to equivalent prior work on English, with compositionality\ninformation most easily recoverable in the early layers. However, our strongest\nresults clearly lag behind those reported for English, suggesting an inherently\nmore difficult task in German. This may be due to the higher productivity of\ncompounding in German than in English and the associated increase in\nconstituent-level ambiguity, including in our target compound set."}
{"id": "2505.14330", "pdf": "https://arxiv.org/pdf/2505.14330", "abs": "https://arxiv.org/abs/2505.14330", "authors": ["Rajat Kanti Bhattacharjee", "Meghali Nandi", "Amrit Jha", "Gunajit Kalita", "Ferdous Ahmed Barbhuiya"], "title": "Handloom Design Generation Using Generative Networks", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper proposes deep learning techniques of generating designs for\nclothing, focused on handloom fabric and discusses the associated challenges\nalong with its application. The capability of generative neural network models\nin understanding artistic designs and synthesizing those is not yet explored\nwell. In this work, multiple methods are employed incorporating the current\nstate of the art generative models and style transfer algorithms to study and\nobserve their performance for the task. The results are then evaluated through\nuser score. This work also provides a new dataset NeuralLoom for the task of\nthe design generation."}
{"id": "2505.13873", "pdf": "https://arxiv.org/pdf/2505.13873", "abs": "https://arxiv.org/abs/2505.13873", "authors": ["Peisong Niu", "Ziqing Ma", "Tian Zhou", "Weiqi Chen", "Lefei Shen", "Rong Jin", "Liang Sun"], "title": "Utilizing Strategic Pre-training to Reduce Overfitting: Baguan -- A Pre-trained Weather Forecasting Model", "categories": ["cs.LG", "cs.AI"], "comment": "KDD2025 research track accepted", "summary": "Weather forecasting has long posed a significant challenge for humanity.\nWhile recent AI-based models have surpassed traditional numerical weather\nprediction (NWP) methods in global forecasting tasks, overfitting remains a\ncritical issue due to the limited availability of real-world weather data\nspanning only a few decades. Unlike fields like computer vision or natural\nlanguage processing, where data abundance can mitigate overfitting, weather\nforecasting demands innovative strategies to address this challenge with\nexisting data. In this paper, we explore pre-training methods for weather\nforecasting, finding that selecting an appropriately challenging pre-training\ntask introduces locality bias, effectively mitigating overfitting and enhancing\nperformance. We introduce Baguan, a novel data-driven model for medium-range\nweather forecasting, built on a Siamese Autoencoder pre-trained in a\nself-supervised manner and fine-tuned for different lead times. Experimental\nresults show that Baguan outperforms traditional methods, delivering more\naccurate forecasts. Additionally, the pre-trained Baguan demonstrates robust\noverfitting control and excels in downstream tasks, such as\nsubseasonal-to-seasonal (S2S) modeling and regional forecasting, after\nfine-tuning."}
{"id": "2505.14412", "pdf": "https://arxiv.org/pdf/2505.14412", "abs": "https://arxiv.org/abs/2505.14412", "authors": ["Pawe≈Ç Batorski", "Adrian Kosmala", "Paul Swoboda"], "title": "PRL: Prompts from Reinforcement Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Effective prompt engineering remains a central challenge in fully harnessing\nthe capabilities of LLMs. While well-designed prompts can dramatically enhance\nperformance, crafting them typically demands expert intuition and a nuanced\nunderstanding of the task. Moreover, the most impactful prompts often hinge on\nsubtle semantic cues, ones that may elude human perception but are crucial for\nguiding LLM behavior. In this paper, we introduce PRL (Prompts from\nReinforcement Learning), a novel RL-based approach for automatic prompt\ngeneration. Unlike previous methods, PRL can produce novel few-shot examples\nthat were not seen during training. Our approach achieves state-of-the-art\nperformance across a range of benchmarks, including text classification,\nsimplification, and summarization. On the classification task, it surpasses\nprior methods by 2.58% over APE and 1.00% over EvoPrompt. Additionally, it\nimproves the average ROUGE scores on the summarization task by 4.32 over APE\nand by 2.12 over EvoPrompt and the SARI score on simplification by 6.93 over\nAPE and by 6.01 over EvoPrompt. Our code is available at\nhttps://github.com/Batorskq/prl ."}
{"id": "2505.14131", "pdf": "https://arxiv.org/pdf/2505.14131", "abs": "https://arxiv.org/abs/2505.14131", "authors": ["Wei Zhou", "Mohsen Mesgar", "Heike Adel", "Annemarie Friedrich"], "title": "Texts or Images? A Fine-grained Analysis on the Effectiveness of Input Representations and Models for Table Question Answering", "categories": ["cs.CL"], "comment": "Accepted at ACL25 (Findings)", "summary": "In table question answering (TQA), tables are encoded as either texts or\nimages. Prior work suggests that passing images of tables to multi-modal large\nlanguage models (MLLMs) performs comparably to or even better than using\ntextual input with large language models (LLMs). However, the lack of\ncontrolled setups limits fine-grained distinctions between these approaches. In\nthis paper, we conduct the first controlled study on the effectiveness of\nseveral combinations of table representations and models from two perspectives:\nquestion complexity and table size. We build a new benchmark based on existing\nTQA datasets. In a systematic analysis of seven pairs of MLLMs and LLMs, we\nfind that the best combination of table representation and model varies across\nsetups. We propose FRES, a method selecting table representations dynamically,\nand observe a 10% average performance improvement compared to using both\nrepresentations indiscriminately."}
{"id": "2505.14333", "pdf": "https://arxiv.org/pdf/2505.14333", "abs": "https://arxiv.org/abs/2505.14333", "authors": ["Inder Pal Singh", "Enjie Ghorbel", "Anis Kacem", "Djamila Aouada"], "title": "Domain Adaptation for Multi-label Image Classification: a Discriminator-free Approach", "categories": ["cs.CV"], "comment": "The paper is under consideration at Computer Vision and Image\n  Understanding. arXiv admin note: text overlap with arXiv:2301.10611", "summary": "This paper introduces a discriminator-free adversarial-based approach termed\nDDA-MLIC for Unsupervised Domain Adaptation (UDA) in the context of Multi-Label\nImage Classification (MLIC). While recent efforts have explored\nadversarial-based UDA methods for MLIC, they typically include an additional\ndiscriminator subnet. Nevertheless, decoupling the classification and the\ndiscrimination tasks may harm their task-specific discriminative power. Herein,\nwe address this challenge by presenting a novel adversarial critic directly\nderived from the task-specific classifier. Specifically, we employ a\ntwo-component Gaussian Mixture Model (GMM) to model both source and target\npredictions, distinguishing between two distinct clusters. Instead of using the\ntraditional Expectation Maximization (EM) algorithm, our approach utilizes a\nDeep Neural Network (DNN) to estimate the parameters of each GMM component.\nSubsequently, the source and target GMM parameters are leveraged to formulate\nan adversarial loss using the Fr\\'echet distance. The proposed framework is\ntherefore not only fully differentiable but is also cost-effective as it avoids\nthe expensive iterative process usually induced by the standard EM method. The\nproposed method is evaluated on several multi-label image datasets covering\nthree different types of domain shift. The obtained results demonstrate that\nDDA-MLIC outperforms existing state-of-the-art methods in terms of precision\nwhile requiring a lower number of parameters. The code is made publicly\navailable at github.com/cvi2snt/DDA-MLIC."}
{"id": "2505.13878", "pdf": "https://arxiv.org/pdf/2505.13878", "abs": "https://arxiv.org/abs/2505.13878", "authors": ["Yanggan Gu", "Zhaoyi Yan", "Yuanyi Wang", "Yiming Zhang", "Qi Zhou", "Fei Wu", "Hongxia Yang"], "title": "InfiFPO: Implicit Model Fusion via Preference Optimization in Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": "17 pages", "summary": "Model fusion combines multiple Large Language Models (LLMs) with different\nstrengths into a more powerful, integrated model through lightweight training\nmethods. Existing works on model fusion focus primarily on supervised\nfine-tuning (SFT), leaving preference alignment (PA) --a critical phase for\nenhancing LLM performance--largely unexplored. The current few fusion methods\non PA phase, like WRPO, simplify the process by utilizing only response outputs\nfrom source models while discarding their probability information. To address\nthis limitation, we propose InfiFPO, a preference optimization method for\nimplicit model fusion. InfiFPO replaces the reference model in Direct\nPreference Optimization (DPO) with a fused source model that synthesizes\nmulti-source probabilities at the sequence level, circumventing complex\nvocabulary alignment challenges in previous works and meanwhile maintaining the\nprobability information. By introducing probability clipping and max-margin\nfusion strategies, InfiFPO enables the pivot model to align with human\npreferences while effectively distilling knowledge from source models.\nComprehensive experiments on 11 widely-used benchmarks demonstrate that InfiFPO\nconsistently outperforms existing model fusion and preference optimization\nmethods. When using Phi-4 as the pivot model, InfiFPO improve its average\nperformance from 79.95 to 83.33 on 11 benchmarks, significantly improving its\ncapabilities in mathematics, coding, and reasoning tasks."}
{"id": "2505.14419", "pdf": "https://arxiv.org/pdf/2505.14419", "abs": "https://arxiv.org/abs/2505.14419", "authors": ["Huimin Xu", "Xin Mao", "Feng-Lin Li", "Xiaobao Wu", "Wang Chen", "Wei Zhang", "Anh Tuan Luu"], "title": "SCOPE: Compress Mathematical Reasoning Steps for Efficient Automated Process Annotation", "categories": ["cs.AI"], "comment": null, "summary": "Process Reward Models (PRMs) have demonstrated promising results in\nmathematical reasoning, but existing process annotation approaches, whether\nthrough human annotations or Monte Carlo simulations, remain computationally\nexpensive. In this paper, we introduce Step COmpression for Process Estimation\n(SCOPE), a novel compression-based approach that significantly reduces\nannotation costs. We first translate natural language reasoning steps into code\nand normalize them through Abstract Syntax Tree, then merge equivalent steps to\nconstruct a prefix tree. Unlike simulation-based methods that waste numerous\nsamples on estimation, SCOPE leverages a compression-based prefix tree where\neach root-to-leaf path serves as a training sample, reducing the complexity\nfrom $O(NMK)$ to $O(N)$. We construct a large-scale dataset containing 196K\nsamples with only 5% of the computational resources required by previous\nmethods. Empirical results demonstrate that PRMs trained on our dataset\nconsistently outperform existing automated annotation approaches on both\nBest-of-N strategy and ProcessBench."}
{"id": "2505.14149", "pdf": "https://arxiv.org/pdf/2505.14149", "abs": "https://arxiv.org/abs/2505.14149", "authors": ["Chengzhi Zhang", "Xinyi Yan", "Lei Zhao", "Yingyi Zhang"], "title": "Enhancing Keyphrase Extraction from Academic Articles Using Section Structure Information", "categories": ["cs.CL", "cs.DL", "cs.IR"], "comment": null, "summary": "The exponential increase in academic papers has significantly increased the\ntime required for researchers to access relevant literature. Keyphrase\nExtraction (KPE) offers a solution to this situation by enabling researchers to\nefficiently retrieve relevant literature. The current study on KPE from\nacademic articles aims to improve the performance of extraction models through\ninnovative approaches using Title and Abstract as input corpora. However, the\nsemantic richness of keywords is significantly constrained by the length of the\nabstract. While full-text-based KPE can address this issue, it simultaneously\nintroduces noise, which significantly diminishes KPE performance. To address\nthis issue, this paper utilized the structural features and section texts\nobtained from the section structure information of academic articles to extract\nkeyphrase from academic papers. The approach consists of two main parts: (1)\nexploring the effect of seven structural features on KPE models, and (2)\nintegrating the extraction results from all section texts used as input corpora\nfor KPE models via a keyphrase integration algorithm to obtain the keyphrase\nintegration result. Furthermore, this paper also examined the effect of the\nclassification quality of section structure on the KPE performance. The results\nshow that incorporating structural features improves KPE performance, though\ndifferent features have varying effects on model efficacy. The keyphrase\nintegration approach yields the best performance, and the classification\nquality of section structure can affect KPE performance. These findings\nindicate that using the section structure information of academic articles\ncontributes to effective KPE from academic articles. The code and dataset\nsupporting this study are available at https://github.com/yan-xinyi/SSB_KPE."}
{"id": "2505.14340", "pdf": "https://arxiv.org/pdf/2505.14340", "abs": "https://arxiv.org/abs/2505.14340", "authors": ["Seunghyuk Cho", "Zhenyue Qin", "Yang Liu", "Youngbin Choi", "Seungbeom Lee", "Dongwoo Kim"], "title": "Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey", "categories": ["cs.CV", "cs.LG"], "comment": "18 pages", "summary": "Plane geometry problem solving (PGPS) has recently gained significant\nattention as a benchmark to assess the multi-modal reasoning capabilities of\nlarge vision-language models. Despite the growing interest in PGPS, the\nresearch community still lacks a comprehensive overview that systematically\nsynthesizes recent work in PGPS. To fill this gap, we present a survey of\nexisting PGPS studies. We first categorize PGPS methods into an encoder-decoder\nframework and summarize the corresponding output formats used by their encoders\nand decoders. Subsequently, we classify and analyze these encoders and decoders\naccording to their architectural designs. Finally, we outline major challenges\nand promising directions for future research. In particular, we discuss the\nhallucination issues arising during the encoding phase within encoder-decoder\narchitectures, as well as the problem of data leakage in current PGPS\nbenchmarks."}
{"id": "2505.13896", "pdf": "https://arxiv.org/pdf/2505.13896", "abs": "https://arxiv.org/abs/2505.13896", "authors": ["Yingwei Zhang", "Ke Bu", "Zhuoran Zhuang", "Tao Xie", "Yao Yu", "Dong Li", "Yang Guo", "Detao Lv"], "title": "CRAFT: Time Series Forecasting with Cross-Future Behavior Awareness", "categories": ["cs.LG"], "comment": null, "summary": "The past decades witness the significant advancements in time series\nforecasting (TSF) across various real-world domains, including e-commerce and\ndisease spread prediction. However, TSF is usually constrained by the\nuncertainty dilemma of predicting future data with limited past observations.\nTo settle this question, we explore the use of Cross-Future Behavior (CFB) in\nTSF, which occurs before the current time but takes effect in the future. We\nleverage CFB features and propose the CRoss-Future Behavior Awareness based\nTime Series Forecasting method (CRAFT). The core idea of CRAFT is to utilize\nthe trend of cross-future behavior to mine the trend of time series data to be\npredicted. Specifically, to settle the sparse and partial flaws of cross-future\nbehavior, CRAFT employs the Koopman Predictor Module to extract the key trend\nand the Internal Trend Mining Module to supplement the unknown area of the\ncross-future behavior matrix. Then, we introduce the External Trend Guide\nModule with a hierarchical structure to acquire more representative trends from\nhigher levels. Finally, we apply the demand-constrained loss to calibrate the\ndistribution deviation of prediction results. We conduct experiments on\nreal-world dataset. Experiments on both offline large-scale dataset and online\nA/B test demonstrate the effectiveness of CRAFT. Our dataset and code is\navailable at https://github.com/CRAFTinTSF/CRAFT."}
{"id": "2505.14479", "pdf": "https://arxiv.org/pdf/2505.14479", "abs": "https://arxiv.org/abs/2505.14479", "authors": ["Oren Sultan", "Eitan Stern", "Dafna Shahaf"], "title": "Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach", "categories": ["cs.AI", "cs.CL"], "comment": "long paper", "summary": "Large language models (LLMs) struggle with formal domains that require\nrigorous logical deduction and symbolic reasoning, such as mathematical proof\ngeneration. We propose a neuro-symbolic approach that combines LLMs' generative\nstrengths with structured components to overcome this challenge. As a\nproof-of-concept, we focus on geometry problems. Our approach is two-fold: (1)\nwe retrieve analogous problems and use their proofs to guide the LLM, and (2) a\nformal verifier evaluates the generated proofs and provides feedback, helping\nthe model fix incorrect proofs. We demonstrate that our method significantly\nimproves proof accuracy for OpenAI's o1 model (58%-70% improvement); both\nanalogous problems and the verifier's feedback contribute to these gains. More\nbroadly, shifting to LLMs that generate provably correct conclusions could\ndramatically improve their reliability, accuracy and consistency, unlocking\ncomplex tasks and critical real-world applications that require\ntrustworthiness."}
{"id": "2505.14157", "pdf": "https://arxiv.org/pdf/2505.14157", "abs": "https://arxiv.org/abs/2505.14157", "authors": ["Pittawat Taveekitworachai", "Potsawee Manakul", "Sarana Nutanong", "Kunat Pipatanakul"], "title": "Prior Prompt Engineering for Reinforcement Fine-Tuning", "categories": ["cs.CL", "cs.AI"], "comment": "25 pages, 42 figures", "summary": "This paper investigates prior prompt engineering (pPE) in the context of\nreinforcement fine-tuning (RFT), where language models (LMs) are incentivized\nto exhibit behaviors that maximize performance through reward signals. While\nexisting RFT research has primarily focused on algorithms, reward shaping, and\ndata curation, the design of the prior prompt--the instructions prepended to\nqueries during training to elicit behaviors such as step-by-step\nreasoning--remains underexplored. We investigate whether different pPE\napproaches can guide LMs to internalize distinct behaviors after RFT. Inspired\nby inference-time prompt engineering (iPE), we translate five representative\niPE strategies--reasoning, planning, code-based reasoning, knowledge recall,\nand null-example utilization--into corresponding pPE approaches. We experiment\nwith Qwen2.5-7B using each of the pPE approaches, then evaluate performance on\nin-domain and out-of-domain benchmarks (e.g., AIME2024, HumanEval+, and\nGPQA-Diamond). Our results show that all pPE-trained models surpass their\niPE-prompted counterparts, with the null-example pPE approach achieving the\nlargest average performance gain and the highest improvement on AIME2024 and\nGPQA-Diamond, surpassing the commonly used reasoning approach. Furthermore, by\nadapting a behavior-classification framework, we demonstrate that different pPE\nstrategies instill distinct behavioral styles in the resulting models. These\nfindings position pPE as a powerful yet understudied axis for RFT."}
{"id": "2505.14341", "pdf": "https://arxiv.org/pdf/2505.14341", "abs": "https://arxiv.org/abs/2505.14341", "authors": ["Sifan Li", "Ming Tao", "Hao Zhao", "Ling Shao", "Hao Tang"], "title": "Replace in Translation: Boost Concept Alignment in Counterfactual Text-to-Image", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text-to-Image (T2I) has been prevalent in recent years, with most common\ncondition tasks having been optimized nicely. Besides, counterfactual\nText-to-Image is obstructing us from a more versatile AIGC experience. For\nthose scenes that are impossible to happen in real world and anti-physics, we\nshould spare no efforts in increasing the factual feel, which means\nsynthesizing images that people think very likely to be happening, and concept\nalignment, which means all the required objects should be in the same frame. In\nthis paper, we focus on concept alignment. As controllable T2I models have\nachieved satisfactory performance for real applications, we utilize this\ntechnology to replace the objects in a synthesized image in latent space\nstep-by-step to change the image from a common scene to a counterfactual scene\nto meet the prompt. We propose a strategy to instruct this replacing process,\nwhich is called as Explicit Logical Narrative Prompt (ELNP), by using the newly\nSoTA language model DeepSeek to generate the instructions. Furthermore, to\nevaluate models' performance in counterfactual T2I, we design a metric to\ncalculate how many required concepts in the prompt can be covered averagely in\nthe synthesized images. The extensive experiments and qualitative comparisons\ndemonstrate that our strategy can boost the concept alignment in counterfactual\nT2I."}
{"id": "2505.13898", "pdf": "https://arxiv.org/pdf/2505.13898", "abs": "https://arxiv.org/abs/2505.13898", "authors": ["R√≥bert Csord√°s", "Christopher D. Manning", "Christopher Potts"], "title": "Do Language Models Use Their Depth Efficiently?", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Modern LLMs are increasingly deep, and depth correlates with performance,\nalbeit with diminishing returns. However, do these models use their depth\nefficiently? Do they compose more features to create higher-order computations\nthat are impossible in shallow models, or do they merely spread the same kinds\nof computation out over more layers? To address these questions, we analyze the\nresidual stream of the Llama 3.1 and Qwen 3 family of models. We find: First,\ncomparing the output of the sublayers to the residual stream reveals that\nlayers in the second half contribute much less than those in the first half,\nwith a clear phase transition between the two halves. Second, skipping layers\nin the second half has a much smaller effect on future computations and output\npredictions. Third, for multihop tasks, we are unable to find evidence that\nmodels are using increased depth to compose subresults in examples involving\nmany hops. Fourth, we seek to directly address whether deeper models are using\ntheir additional layers to perform new kinds of computation. To do this, we\ntrain linear maps from the residual stream of a shallow model to a deeper one.\nWe find that layers with the same relative depth map best to each other,\nsuggesting that the larger model simply spreads the same computations out over\nits many layers. All this evidence suggests that deeper models are not using\ntheir depth to learn new kinds of computation, but only using the greater depth\nto perform more fine-grained adjustments to the residual. This may help explain\nwhy increasing scale leads to diminishing returns for stacked Transformer\narchitectures."}
{"id": "2505.14489", "pdf": "https://arxiv.org/pdf/2505.14489", "abs": "https://arxiv.org/abs/2505.14489", "authors": ["Dongkeun Yoon", "Seungone Kim", "Sohee Yang", "Sunkyoung Kim", "Soyeon Kim", "Yongil Kim", "Eunbi Choi", "Yireun Kim", "Minjoon Seo"], "title": "Reasoning Models Better Express Their Confidence", "categories": ["cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Despite their strengths, large language models (LLMs) often fail to\ncommunicate their confidence accurately, making it difficult to assess when\nthey might be wrong and limiting their reliability. In this work, we\ndemonstrate that reasoning models-LLMs that engage in extended chain-of-thought\n(CoT) reasoning-exhibit superior performance not only in problem-solving but\nalso in accurately expressing their confidence. Specifically, we benchmark six\nreasoning models across six datasets and find that they achieve strictly better\nconfidence calibration than their non-reasoning counterparts in 33 out of the\n36 settings. Our detailed analysis reveals that these gains in calibration stem\nfrom the slow thinking behaviors of reasoning models-such as exploring\nalternative approaches and backtracking-which enable them to adjust their\nconfidence dynamically throughout their CoT, making it progressively more\naccurate. In particular, we find that reasoning models become increasingly\nbetter calibrated as their CoT unfolds, a trend not observed in non-reasoning\nmodels. Moreover, removing slow thinking behaviors from the CoT leads to a\nsignificant drop in calibration. Lastly, we show that these gains are not\nexclusive to reasoning models-non-reasoning models also benefit when guided to\nperform slow thinking via in-context learning."}
{"id": "2505.14158", "pdf": "https://arxiv.org/pdf/2505.14158", "abs": "https://arxiv.org/abs/2505.14158", "authors": ["Sanjay Govindan", "Maurice Pagnucco", "Yang Song"], "title": "Temporal Alignment of Time Sensitive Facts with Activation Engineering", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are trained on diverse and often conflicting\nknowledge spanning multiple domains and time periods. Some of this knowledge is\nonly valid within specific temporal contexts, such as answering the question,\n\"Who is the President of the United States in 2022?\" Ensuring LLMs generate\ntime appropriate responses is crucial for maintaining relevance and accuracy.\nIn this work we explore activation engineering as a method for temporally\naligning LLMs to improve factual recall without any training or dataset\ncreation. In this research we explore an activation engineering technique to\nground three versions of LLaMA 2 to specific points in time and examine the\neffects of varying injection layers and prompting strategies. Our experiments\ndemonstrate up to a 44% and 16% improvement in relative and explicit prompting\nrespectively, achieving comparable performance to the fine-tuning method\nproposed by Zhao et al. (2024) . Notably, our approach achieves similar results\nto the fine-tuning baseline while being significantly more computationally\nefficient and requiring no pre-aligned datasets."}
{"id": "2505.14346", "pdf": "https://arxiv.org/pdf/2505.14346", "abs": "https://arxiv.org/abs/2505.14346", "authors": ["Mingfang Zhang", "Ryo Yonetani", "Yifei Huang", "Liangyang Ouyang", "Ruicong Liu", "Yoichi Sato"], "title": "Egocentric Action-aware Inertial Localization in Point Clouds", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents a novel inertial localization framework named Egocentric\nAction-aware Inertial Localization (EAIL), which leverages egocentric action\ncues from head-mounted IMU signals to localize the target individual within a\n3D point cloud. Human inertial localization is challenging due to IMU sensor\nnoise that causes trajectory drift over time. The diversity of human actions\nfurther complicates IMU signal processing by introducing various motion\npatterns. Nevertheless, we observe that some actions observed through the\nhead-mounted IMU correlate with spatial environmental structures (e.g., bending\ndown to look inside an oven, washing dishes next to a sink), thereby serving as\nspatial anchors to compensate for the localization drift. The proposed EAIL\nframework learns such correlations via hierarchical multi-modal alignment. By\nassuming that the 3D point cloud of the environment is available, it\ncontrastively learns modality encoders that align short-term egocentric action\ncues in IMU signals with local environmental features in the point cloud. These\nencoders are then used in reasoning the IMU data and the point cloud over time\nand space to perform inertial localization. Interestingly, these encoders can\nfurther be utilized to recognize the corresponding sequence of actions as a\nby-product. Extensive experiments demonstrate the effectiveness of the proposed\nframework over state-of-the-art inertial localization and inertial action\nrecognition baselines."}
{"id": "2505.13899", "pdf": "https://arxiv.org/pdf/2505.13899", "abs": "https://arxiv.org/abs/2505.13899", "authors": ["Zeyu Michael Li", "Hung Anh Vu", "Damilola Awofisayo", "Emily Wenger"], "title": "Exploring Causes of Representational Similarity in Machine Learning Models", "categories": ["cs.LG"], "comment": null, "summary": "Numerous works have noted significant similarities in how machine learning\nmodels represent the world, even across modalities. Although much effort has\nbeen devoted to uncovering properties and metrics on which these models align,\nsurprisingly little work has explored causes of this similarity. To advance\nthis line of inquiry, this work explores how two possible causal factors --\ndataset overlap and task overlap -- influence downstream model similarity. The\nexploration of dataset overlap is motivated by the reality that large-scale\ngenerative AI models are often trained on overlapping datasets of scraped\ninternet data, while the exploration of task overlap seeks to substantiate\nclaims from a recent work, the Platonic Representation Hypothesis, that task\nsimilarity may drive model similarity. We evaluate the effects of both factors\nthrough a broad set of experiments. We find that both positively correlate with\nhigher representational similarity and that combining them provides the\nstrongest effect. Our code and dataset are published."}
{"id": "2505.14510", "pdf": "https://arxiv.org/pdf/2505.14510", "abs": "https://arxiv.org/abs/2505.14510", "authors": ["Haishi Bai", "Jozo Dujmovic", "Jianwu Wang"], "title": "BACON: A fully explainable AI model with graded logic for decision making problems", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As machine learning models and autonomous agents are increasingly deployed in\nhigh-stakes, real-world domains such as healthcare, security, finance, and\nrobotics, the need for transparent and trustworthy explanations has become\ncritical. To ensure end-to-end transparency of AI decisions, we need models\nthat are not only accurate but also fully explainable and human-tunable. We\nintroduce BACON, a novel framework for automatically training explainable AI\nmodels for decision making problems using graded logic. BACON achieves high\npredictive accuracy while offering full structural transparency and precise,\nlogic-based symbolic explanations, enabling effective human-AI collaboration\nand expert-guided refinement. We evaluate BACON with a diverse set of\nscenarios: classic Boolean approximation, Iris flower classification, house\npurchasing decisions and breast cancer diagnosis. In each case, BACON provides\nhigh-performance models while producing compact, human-verifiable decision\nlogic. These results demonstrate BACON's potential as a practical and\nprincipled approach for delivering crisp, trustworthy explainable AI."}
{"id": "2505.14160", "pdf": "https://arxiv.org/pdf/2505.14160", "abs": "https://arxiv.org/abs/2505.14160", "authors": ["Zahraa Al Sahili", "Ioannis Patras", "Matthew Purver"], "title": "Breaking Language Barriers or Reinforcing Bias? A Study of Gender and Racial Disparities in Multilingual Contrastive Vision Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multilingual vision-language models promise universal image-text retrieval,\nyet their social biases remain under-explored. We present the first systematic\naudit of three public multilingual CLIP checkpoints -- M-CLIP, NLLB-CLIP, and\nCAPIVARA-CLIP -- across ten languages that vary in resource availability and\ngrammatical gender. Using balanced subsets of \\textsc{FairFace} and the\n\\textsc{PATA} stereotype suite in a zero-shot setting, we quantify race and\ngender bias and measure stereotype amplification. Contrary to the assumption\nthat multilinguality mitigates bias, every model exhibits stronger gender bias\nthan its English-only baseline. CAPIVARA-CLIP shows its largest biases\nprecisely in the low-resource languages it targets, while the shared\ncross-lingual encoder of NLLB-CLIP transports English gender stereotypes into\ngender-neutral languages; loosely coupled encoders largely avoid this transfer.\nHighly gendered languages consistently magnify all measured bias types, but\neven gender-neutral languages remain vulnerable when cross-lingual weight\nsharing imports foreign stereotypes. Aggregated metrics conceal\nlanguage-specific ``hot spots,'' underscoring the need for fine-grained,\nlanguage-aware bias evaluation in future multilingual vision-language research."}
{"id": "2505.14357", "pdf": "https://arxiv.org/pdf/2505.14357", "abs": "https://arxiv.org/abs/2505.14357", "authors": ["Siqiao Huang", "Jialong Wu", "Qixing Zhou", "Shangchen Miao", "Mingsheng Long"], "title": "Vid2World: Crafting Video Diffusion Models to Interactive World Models", "categories": ["cs.CV", "cs.LG"], "comment": "Project page: http://knightnemo.github.io/vid2world/", "summary": "World models, which predict transitions based on history observation and\naction sequences, have shown great promise in improving data efficiency for\nsequential decision making. However, existing world models often require\nextensive domain-specific training and still produce low-fidelity, coarse\npredictions, limiting their applicability in complex environments. In contrast,\nvideo diffusion models trained on large, internet-scale datasets have\ndemonstrated impressive capabilities in generating high-quality videos that\ncapture diverse real-world dynamics. In this work, we present Vid2World, a\ngeneral approach for leveraging and transferring pre-trained video diffusion\nmodels into interactive world models. To bridge the gap, Vid2World performs\ncasualization of a pre-trained video diffusion model by crafting its\narchitecture and training objective to enable autoregressive generation.\nFurthermore, it introduces a causal action guidance mechanism to enhance action\ncontrollability in the resulting interactive world model. Extensive experiments\nin robot manipulation and game simulation domains show that our method offers a\nscalable and effective approach for repurposing highly capable video diffusion\nmodels to interactive world models."}
{"id": "2505.13900", "pdf": "https://arxiv.org/pdf/2505.13900", "abs": "https://arxiv.org/abs/2505.13900", "authors": ["Zhanpeng Zhou", "Yongyi Yang", "Mahito Sugiyama", "Junchi Yan"], "title": "New Evidence of the Two-Phase Learning Dynamics of Neural Networks", "categories": ["cs.LG"], "comment": "This work extends the workshop paper, On the Cone Effect in the\n  Learning Dynamics, accepted by ICLR 2025 Workshop DeLTa", "summary": "Understanding how deep neural networks learn remains a fundamental challenge\nin modern machine learning. A growing body of evidence suggests that training\ndynamics undergo a distinct phase transition, yet our understanding of this\ntransition is still incomplete. In this paper, we introduce an interval-wise\nperspective that compares network states across a time window, revealing two\nnew phenomena that illuminate the two-phase nature of deep learning. i)\n\\textbf{The Chaos Effect.} By injecting an imperceptibly small parameter\nperturbation at various stages, we show that the response of the network to the\nperturbation exhibits a transition from chaotic to stable, suggesting there is\nan early critical period where the network is highly sensitive to initial\nconditions; ii) \\textbf{The Cone Effect.} Tracking the evolution of the\nempirical Neural Tangent Kernel (eNTK), we find that after this transition\npoint the model's functional trajectory is confined to a narrow cone-shaped\nsubset: while the kernel continues to change, it gets trapped into a tight\nangular region. Together, these effects provide a structural, dynamical view of\nhow deep networks transition from sensitive exploration to stable refinement\nduring training."}
{"id": "2505.14524", "pdf": "https://arxiv.org/pdf/2505.14524", "abs": "https://arxiv.org/abs/2505.14524", "authors": ["Richard ≈†l√©her", "William Brach", "Tibor Sloboda", "Kristi√°n Ko≈°≈•√°l", "Lukas Galke"], "title": "Guarded Query Routing for Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Query routing, the task to route user queries to different large language\nmodel (LLM) endpoints, can be considered as a text classification problem.\nHowever, out-of-distribution queries must be handled properly, as those could\nbe questions about unrelated domains, queries in other languages, or even\ncontain unsafe text. Here, we thus study a \\emph{guarded} query routing\nproblem, for which we first introduce the Guarded Query Routing Benchmark\n(GQR-Bench), which covers three exemplary target domains (law, finance, and\nhealthcare), and seven datasets to test robustness against out-of-distribution\nqueries. We then use GQR-Bench to contrast the effectiveness and efficiency of\nLLM-based routing mechanisms (GPT-4o-mini, Llama-3.2-3B, and Llama-3.1-8B),\nstandard LLM-based guardrail approaches (LlamaGuard and NVIDIA NeMo\nGuardrails), continuous bag-of-words classifiers (WideMLP, fastText), and\ntraditional machine learning models (SVM, XGBoost). Our results show that\nWideMLP, enhanced with out-of-domain detection capabilities, yields the best\ntrade-off between accuracy (88\\%) and speed (<4ms). The embedding-based\nfastText excels at speed (<1ms) with acceptable accuracy (80\\%), whereas LLMs\nyield the highest accuracy (91\\%) but are comparatively slow (62ms for local\nLlama-3.1:8B and 669ms for remote GPT-4o-mini calls). Our findings challenge\nthe automatic reliance on LLMs for (guarded) query routing and provide concrete\nrecommendations for practical applications. GQR-Bench will be released as a\nPython package -- \\texttt{gqr}."}
{"id": "2505.14165", "pdf": "https://arxiv.org/pdf/2505.14165", "abs": "https://arxiv.org/abs/2505.14165", "authors": ["Zhenkai Qin", "Jiajing He", "Qiao Fang"], "title": "PL-FGSA: A Prompt Learning Framework for Fine-Grained Sentiment Analysis Based on MindSpore", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Fine-grained sentiment analysis (FGSA) aims to identify sentiment polarity\ntoward specific aspects within a text, enabling more precise opinion mining in\ndomains such as product reviews and social media. However, traditional FGSA\napproaches often require task-specific architectures and extensive annotated\ndata, limiting their generalization and scalability. To address these\nchallenges, we propose PL-FGSA, a unified prompt learning-based framework\nimplemented using the MindSpore platform, which integrates prompt design with a\nlightweight TextCNN backbone. Our method reformulates FGSA as a multi-task\nprompt-augmented generation problem, jointly tackling aspect extraction,\nsentiment classification, and causal explanation in a unified paradigm. By\nleveraging prompt-based guidance, PL-FGSA enhances interpretability and\nachieves strong performance under both full-data and low-resource conditions.\nExperiments on three benchmark datasets-SST-2, SemEval-2014 Task 4, and\nMAMS-demonstrate that our model consistently outperforms traditional\nfine-tuning methods and achieves F1-scores of 0.922, 0.694, and 0.597,\nrespectively. These results validate the effectiveness of prompt-based\ngeneralization and highlight the practical value of PL-FGSA for real-world\nsentiment analysis tasks."}
{"id": "2505.14359", "pdf": "https://arxiv.org/pdf/2505.14359", "abs": "https://arxiv.org/abs/2505.14359", "authors": ["Ruoxin Chen", "Junwei Xi", "Zhiyuan Yan", "Ke-Yue Zhang", "Shuang Wu", "Jingyi Xie", "Xu Chen", "Lei Xu", "Isabel Guan", "Taiping Yao", "Shouhong Ding"], "title": "Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable", "categories": ["cs.CV"], "comment": "12 Pages, 9 figures", "summary": "Existing detectors are often trained on biased datasets, leading to the\npossibility of overfitting on non-causal image attributes that are spuriously\ncorrelated with real/synthetic labels. While these biased features enhance\nperformance on the training data, they result in substantial performance\ndegradation when applied to unbiased datasets. One common solution is to\nperform dataset alignment through generative reconstruction, matching the\nsemantic content between real and synthetic images. However, we revisit this\napproach and show that pixel-level alignment alone is insufficient. The\nreconstructed images still suffer from frequency-level misalignment, which can\nperpetuate spurious correlations. To illustrate, we observe that reconstruction\nmodels tend to restore the high-frequency details lost in real images (possibly\ndue to JPEG compression), inadvertently creating a frequency-level\nmisalignment, where synthetic images appear to have richer high-frequency\ncontent than real ones. This misalignment leads to models associating\nhigh-frequency features with synthetic labels, further reinforcing biased cues.\nTo resolve this, we propose Dual Data Alignment (DDA), which aligns both the\npixel and frequency domains. Moreover, we introduce two new test sets:\nDDA-COCO, containing DDA-aligned synthetic images for testing detector\nperformance on the most aligned dataset, and EvalGEN, featuring the latest\ngenerative models for assessing detectors under new generative architectures\nsuch as visual auto-regressive generators. Finally, our extensive evaluations\ndemonstrate that a detector trained exclusively on DDA-aligned MSCOCO could\nimprove across 8 diverse benchmarks by a non-trivial margin, showing a +7.2% on\nin-the-wild benchmarks, highlighting the improved generalizability of unbiased\ndetectors."}
{"id": "2505.13904", "pdf": "https://arxiv.org/pdf/2505.13904", "abs": "https://arxiv.org/abs/2505.13904", "authors": ["Fu Luo", "Xi Lin", "Mengyuan Zhong", "Fei Liu", "Zhenkun Wang", "Jianyong Sun", "Qingfu Zhang"], "title": "Learning to Insert for Constructive Neural Vehicle Routing Solver", "categories": ["cs.LG", "cs.AI", "cs.RO", "math.OC"], "comment": null, "summary": "Neural Combinatorial Optimisation (NCO) is a promising learning-based\napproach for solving Vehicle Routing Problems (VRPs) without extensive manual\ndesign. While existing constructive NCO methods typically follow an\nappending-based paradigm that sequentially adds unvisited nodes to partial\nsolutions, this rigid approach often leads to suboptimal results. To overcome\nthis limitation, we explore the idea of insertion-based paradigm and propose\nLearning to Construct with Insertion-based Paradigm (L2C-Insert), a novel\nlearning-based method for constructive NCO. Unlike traditional approaches,\nL2C-Insert builds solutions by strategically inserting unvisited nodes at any\nvalid position in the current partial solution, which can significantly enhance\nthe flexibility and solution quality. The proposed framework introduces three\nkey components: a novel model architecture for precise insertion position\nprediction, an efficient training scheme for model optimization, and an\nadvanced inference technique that fully exploits the insertion paradigm's\nflexibility. Extensive experiments on both synthetic and real-world instances\nof the Travelling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) demonstrate that L2C-Insert consistently achieves superior\nperformance across various problem sizes."}
{"id": "2505.14539", "pdf": "https://arxiv.org/pdf/2505.14539", "abs": "https://arxiv.org/abs/2505.14539", "authors": ["Gaia Belardinelli", "Thomas Bolander", "Sebastian Watzl"], "title": "A Logic of General Attention Using Edge-Conditioned Event Models (Extended Version)", "categories": ["cs.AI"], "comment": null, "summary": "In this work, we present the first general logic of attention. Attention is a\npowerful cognitive ability that allows agents to focus on potentially complex\ninformation, such as logically structured propositions, higher-order beliefs,\nor what other agents pay attention to. This ability is a strength, as it helps\nto ignore what is irrelevant, but it can also introduce biases when some types\nof information or agents are systematically ignored. Existing dynamic epistemic\nlogics for attention cannot model such complex attention scenarios, as they\nonly model attention to atomic formulas. Additionally, such logics quickly\nbecome cumbersome, as their size grows exponentially in the number of agents\nand announced literals. Here, we introduce a logic that overcomes both\nlimitations. First, we generalize edge-conditioned event models, which we show\nto be as expressive as standard event models yet exponentially more succinct\n(generalizing both standard event models and generalized arrow updates).\nSecond, we extend attention to arbitrary formulas, allowing agents to also\nattend to other agents' beliefs or attention. Our work treats attention as a\nmodality, like belief or awareness. We introduce attention principles that\nimpose closure properties on that modality and that can be used in its\naxiomatization. Throughout, we illustrate our framework with examples of AI\nagents reasoning about human attentional biases, demonstrating how such agents\ncan discover attentional biases."}
{"id": "2505.14172", "pdf": "https://arxiv.org/pdf/2505.14172", "abs": "https://arxiv.org/abs/2505.14172", "authors": ["Adrian Cosma", "Stefan Ruseti", "Emilian Radoi", "Mihai Dascalu"], "title": "The Strawberry Problem: Emergence of Character-level Understanding in Tokenized Language Models", "categories": ["cs.CL"], "comment": "1 Table, 8 Figures", "summary": "Despite their remarkable progress across diverse domains, Large Language\nModels (LLMs) consistently fail at simple character-level tasks, such as\ncounting letters in words, due to a fundamental limitation: tokenization. In\nthis work, we frame this limitation as a problem of low mutual information and\nanalyze it in terms of concept emergence. Using a suite of 19 synthetic tasks\nthat isolate character-level reasoning in a controlled setting, we show that\nsuch capabilities emerge slowly, suddenly, and only late in training. We\nfurther show that percolation-based models of concept emergence explain these\npatterns, suggesting that learning character composition is not fundamentally\ndifferent from learning commonsense knowledge. To address this bottleneck, we\npropose a lightweight architectural modification that significantly improves\ncharacter-level reasoning while preserving the inductive advantages of subword\nmodels. Together, our results bridge low-level perceptual gaps in tokenized LMs\nand provide a principled framework for understanding and mitigating their\nstructural blind spots. We make our code publicly available."}
{"id": "2505.14361", "pdf": "https://arxiv.org/pdf/2505.14361", "abs": "https://arxiv.org/abs/2505.14361", "authors": ["Xingxing Weng", "Chao Pang", "Gui-Song Xia"], "title": "Vision-Language Modeling Meets Remote Sensing: Models, Datasets and Perspectives", "categories": ["cs.CV"], "comment": "Accepted by IEEE Geoscience and Remote Sensing Magazine", "summary": "Vision-language modeling (VLM) aims to bridge the information gap between\nimages and natural language. Under the new paradigm of first pre-training on\nmassive image-text pairs and then fine-tuning on task-specific data, VLM in the\nremote sensing domain has made significant progress. The resulting models\nbenefit from the absorption of extensive general knowledge and demonstrate\nstrong performance across a variety of remote sensing data analysis tasks.\nMoreover, they are capable of interacting with users in a conversational\nmanner. In this paper, we aim to provide the remote sensing community with a\ntimely and comprehensive review of the developments in VLM using the two-stage\nparadigm. Specifically, we first cover a taxonomy of VLM in remote sensing:\ncontrastive learning, visual instruction tuning, and text-conditioned image\ngeneration. For each category, we detail the commonly used network architecture\nand pre-training objectives. Second, we conduct a thorough review of existing\nworks, examining foundation models and task-specific adaptation methods in\ncontrastive-based VLM, architectural upgrades, training strategies and model\ncapabilities in instruction-based VLM, as well as generative foundation models\nwith their representative downstream applications. Third, we summarize datasets\nused for VLM pre-training, fine-tuning, and evaluation, with an analysis of\ntheir construction methodologies (including image sources and caption\ngeneration) and key properties, such as scale and task adaptability. Finally,\nwe conclude this survey with insights and discussions on future research\ndirections: cross-modal representation alignment, vague requirement\ncomprehension, explanation-driven model reliability, continually scalable model\ncapabilities, and large-scale datasets featuring richer modalities and greater\nchallenges."}
{"id": "2505.13907", "pdf": "https://arxiv.org/pdf/2505.13907", "abs": "https://arxiv.org/abs/2505.13907", "authors": ["Junyu Luo", "Yusheng Zhao", "Xiao Luo", "Zhiping Xiao", "Wei Ju", "Li Shen", "Dacheng Tao", "Ming Zhang"], "title": "Cross-Domain Diffusion with Progressive Alignment for Efficient Adaptive Retrieval", "categories": ["cs.LG"], "comment": "IEEE TIP", "summary": "Unsupervised efficient domain adaptive retrieval aims to transfer knowledge\nfrom a labeled source domain to an unlabeled target domain, while maintaining\nlow storage cost and high retrieval efficiency. However, existing methods\ntypically fail to address potential noise in the target domain, and directly\nalign high-level features across domains, thus resulting in suboptimal\nretrieval performance. To address these challenges, we propose a novel\nCross-Domain Diffusion with Progressive Alignment method (COUPLE). This\napproach revisits unsupervised efficient domain adaptive retrieval from a graph\ndiffusion perspective, simulating cross-domain adaptation dynamics to achieve a\nstable target domain adaptation process. First, we construct a cross-domain\nrelationship graph and leverage noise-robust graph flow diffusion to simulate\nthe transfer dynamics from the source domain to the target domain, identifying\nlower noise clusters. We then leverage the graph diffusion results for\ndiscriminative hash code learning, effectively learning from the target domain\nwhile reducing the negative impact of noise. Furthermore, we employ a\nhierarchical Mixup operation for progressive domain alignment, which is\nperformed along the cross-domain random walk paths. Utilizing target domain\ndiscriminative hash learning and progressive domain alignment, COUPLE enables\neffective domain adaptive hash learning. Extensive experiments demonstrate\nCOUPLE's effectiveness on competitive benchmarks."}
{"id": "2505.14569", "pdf": "https://arxiv.org/pdf/2505.14569", "abs": "https://arxiv.org/abs/2505.14569", "authors": ["Devansh Bhardwaj", "Arjun Beniwal", "Shreyas Chaudhari", "Ashwin Kalyan", "Tanmay Rajpurohit", "Karthik R. Narasimhan", "Ameet Deshpande", "Vishvak Murahari"], "title": "Agent Context Protocols Enhance Collective Inference", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "AI agents have become increasingly adept at complex tasks such as coding,\nreasoning, and multimodal understanding. However, building generalist systems\nrequires moving beyond individual agents to collective inference -- a paradigm\nwhere multi-agent systems with diverse, task-specialized agents complement one\nanother through structured communication and collaboration. Today, coordination\nis usually handled with imprecise, ad-hoc natural language, which limits\ncomplex interaction and hinders interoperability with domain-specific agents.\nWe introduce Agent context protocols (ACPs): a domain- and agent-agnostic\nfamily of structured protocols for agent-agent communication, coordination, and\nerror handling. ACPs combine (i) persistent execution blueprints -- explicit\ndependency graphs that store intermediate agent outputs -- with (ii)\nstandardized message schemas, enabling robust and fault-tolerant multi-agent\ncollective inference. ACP-powered generalist systems reach state-of-the-art\nperformance: 28.3 % accuracy on AssistantBench for long-horizon web assistance\nand best-in-class multimodal technical reports, outperforming commercial AI\nsystems in human evaluation. ACPs are highly modular and extensible, allowing\npractitioners to build top-tier generalist agents quickly."}
{"id": "2505.14173", "pdf": "https://arxiv.org/pdf/2505.14173", "abs": "https://arxiv.org/abs/2505.14173", "authors": ["Yunlong Liang", "Fandong Meng", "Jie Zhou"], "title": "THOR-MoE: Hierarchical Task-Guided and Context-Responsive Routing for Neural Machine Translation", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 main conference", "summary": "The sparse Mixture-of-Experts (MoE) has achieved significant progress for\nneural machine translation (NMT). However, there exist two limitations in\ncurrent MoE solutions which may lead to sub-optimal performance: 1) they\ndirectly use the task knowledge of NMT into MoE (\\emph{e.g.},\ndomain/linguistics-specific knowledge), which are generally unavailable at\npractical application and neglect the naturally grouped domain/linguistic\nproperties; 2) the expert selection only depends on the localized token\nrepresentation without considering the context, which fully grasps the state of\neach token in a global view. To address the above limitations, we propose\nTHOR-MoE via arming the MoE with hierarchical task-guided and\ncontext-responsive routing policies. Specifically, it 1) firstly predicts the\ndomain/language label and then extracts mixed domain/language representation to\nallocate task-level experts in a hierarchical manner; 2) injects the context\ninformation to enhance the token routing from the pre-selected task-level\nexperts set, which can help each token to be accurately routed to more\nspecialized and suitable experts. Extensive experiments on multi-domain\ntranslation and multilingual translation benchmarks with different\narchitectures consistently demonstrate the superior performance of THOR-MoE.\nAdditionally, the THOR-MoE operates as a plug-and-play module compatible with\nexisting Top-$k$~\\cite{shazeer2017} and Top-$p$~\\cite{huang-etal-2024-harder}\nrouting schemes, ensuring broad applicability across diverse MoE architectures.\nFor instance, compared with vanilla Top-$p$~\\cite{huang-etal-2024-harder}\nrouting, the context-aware manner can achieve an average improvement of 0.75\nBLEU with less than 22\\% activated parameters on multi-domain translation\ntasks."}
{"id": "2505.14362", "pdf": "https://arxiv.org/pdf/2505.14362", "abs": "https://arxiv.org/abs/2505.14362", "authors": ["Ziwei Zheng", "Michael Yang", "Jack Hong", "Chenxiao Zhao", "Guohai Xu", "Le Yang", "Chao Shen", "Xing Yu"], "title": "DeepEyes: Incentivizing \"Thinking with Images\" via Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Large Vision-Language Models (VLMs) have shown strong capabilities in\nmultimodal understanding and reasoning, yet they are primarily constrained by\ntext-based reasoning processes. However, achieving seamless integration of\nvisual and textual reasoning which mirrors human cognitive processes remains a\nsignificant challenge. In particular, effectively incorporating advanced visual\ninput processing into reasoning mechanisms is still an open question. Thus, in\nthis paper, we explore the interleaved multimodal reasoning paradigm and\nintroduce DeepEyes, a model with \"thinking with images\" capabilities\nincentivized through end-to-end reinforcement learning without the need for\ncold-start SFT. Notably, this ability emerges natively within the model itself,\nleveraging its inherent grounding ability as a tool instead of depending on\nseparate specialized models. Specifically, we propose a tool-use-oriented data\nselection mechanism and a reward strategy to encourage successful tool-assisted\nreasoning trajectories. DeepEyes achieves significant performance gains on\nfine-grained perception and reasoning benchmarks and also demonstrates\nimprovement in grounding, hallucination, and mathematical reasoning tasks.\nInterestingly, we observe the distinct evolution of tool-calling behavior from\ninitial exploration to efficient and accurate exploitation, and diverse\nthinking patterns that closely mirror human visual reasoning processes. Code is\navailable at https://github.com/Visual-Agent/DeepEyes."}
{"id": "2505.13910", "pdf": "https://arxiv.org/pdf/2505.13910", "abs": "https://arxiv.org/abs/2505.13910", "authors": ["Guangtao Zheng", "Wenqian Ye", "Aidong Zhang"], "title": "ShortcutProbe: Probing Prediction Shortcuts for Learning Robust Models", "categories": ["cs.LG"], "comment": "Accepted to IJCAI 2025", "summary": "Deep learning models often achieve high performance by inadvertently learning\nspurious correlations between targets and non-essential features. For example,\nan image classifier may identify an object via its background that spuriously\ncorrelates with it. This prediction behavior, known as spurious bias, severely\ndegrades model performance on data that lacks the learned spurious\ncorrelations. Existing methods on spurious bias mitigation typically require a\nvariety of data groups with spurious correlation annotations called group\nlabels. However, group labels require costly human annotations and often fail\nto capture subtle spurious biases such as relying on specific pixels for\npredictions. In this paper, we propose a novel post hoc spurious bias\nmitigation framework without requiring group labels. Our framework, termed\nShortcutProbe, identifies prediction shortcuts that reflect potential\nnon-robustness in predictions in a given model's latent space. The model is\nthen retrained to be invariant to the identified prediction shortcuts for\nimproved robustness. We theoretically analyze the effectiveness of the\nframework and empirically demonstrate that it is an efficient and practical\ntool for improving a model's robustness to spurious bias on diverse datasets."}
{"id": "2505.14603", "pdf": "https://arxiv.org/pdf/2505.14603", "abs": "https://arxiv.org/abs/2505.14603", "authors": ["Davide Buffelli", "Sowmen Das", "Yu-Wei Lin", "Sattar Vakili", "Chien-Yi Wang", "Masoud Attarifar", "Pritthijit Nath", "Da-shan Shiu"], "title": "Towards a Foundation Model for Communication Systems", "categories": ["cs.AI", "cs.LG", "eess.SP"], "comment": null, "summary": "Artificial Intelligence (AI) has demonstrated unprecedented performance\nacross various domains, and its application to communication systems is an\nactive area of research. While current methods focus on task-specific\nsolutions, the broader trend in AI is shifting toward large general models\ncapable of supporting multiple applications. In this work, we take a step\ntoward a foundation model for communication data--a transformer-based,\nmulti-modal model designed to operate directly on communication data. We\npropose methodologies to address key challenges, including tokenization,\npositional embedding, multimodality, variable feature sizes, and normalization.\nFurthermore, we empirically demonstrate that such a model can successfully\nestimate multiple features, including transmission rank, selected precoder,\nDoppler spread, and delay profile."}
{"id": "2505.14174", "pdf": "https://arxiv.org/pdf/2505.14174", "abs": "https://arxiv.org/abs/2505.14174", "authors": ["Yusuf Denizay D√∂nder", "Derek Hommel", "Andrea W Wen-Yi", "David Mimno", "Unso Eun Seo Jo"], "title": "Cheaper, Better, Faster, Stronger: Robust Text-to-SQL without Chain-of-Thought or Fine-Tuning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "LLMs are effective at code generation tasks like text-to-SQL, but is it worth\nthe cost? Many state-of-the-art approaches use non-task-specific LLM techniques\nincluding Chain-of-Thought (CoT), self-consistency, and fine-tuning. These\nmethods can be costly at inference time, sometimes requiring over a hundred LLM\ncalls with reasoning, incurring average costs of up to \\$0.46 per query, while\nfine-tuning models can cost thousands of dollars. We introduce \"N-rep\"\nconsistency, a more cost-efficient text-to-SQL approach that achieves similar\nBIRD benchmark scores as other more expensive methods, at only \\$0.039 per\nquery. N-rep leverages multiple representations of the same schema input to\nmitigate weaknesses in any single representation, making the solution more\nrobust and allowing the use of smaller and cheaper models without any reasoning\nor fine-tuning. To our knowledge, N-rep is the best-performing text-to-SQL\napproach in its cost range."}
{"id": "2505.14404", "pdf": "https://arxiv.org/pdf/2505.14404", "abs": "https://arxiv.org/abs/2505.14404", "authors": ["Xuecheng Wu", "Jiaxing Liu", "Danlei Huang", "Xiaoyu Li", "Yifan Wang", "Chen Chen", "Liya Ma", "Xuezhi Cao", "Junxiao Xue"], "title": "ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations", "categories": ["cs.CV"], "comment": null, "summary": "Visual-Interleaved Chain-of-Thought (VI-CoT) enables MLLMs to continually\nupdate their understanding and decisions based on step-wise intermediate visual\nstates (IVS), much like a human would, which demonstrates impressive success in\nvarious tasks, thereby leading to emerged advancements in related benchmarks.\nDespite promising progress, current benchmarks provide models with relatively\nfixed IVS, rather than free-style IVS, whch might forcibly distort the original\nthinking trajectories, failing to evaluate their intrinsic reasoning\ncapabilities. More importantly, existing benchmarks neglect to systematically\nexplore the impact factors that IVS would impart to untamed reasoning\nperformance. To tackle above gaps, we introduce a specialized benchmark termed\nViC-Bench, consisting of four representive tasks: maze navigation, jigsaw\npuzzle, embodied long-horizon planning, and complex counting, where each task\nhas dedicated free-style IVS generation pipeline supporting function calls. To\nsystematically examine VI-CoT capability, we propose a thorough evaluation\nsuite incorporating a progressive three-stage strategy with targeted new\nmetrics. Besides, we establish Incremental Prompting Information Injection\n(IPII) strategy to ablatively explore the prompting factors for VI-CoT. We\nextensively conduct evaluations for 18 advanced MLLMs, revealing key insights\ninto their VI-CoT capability. Our proposed benchmark is publicly open at\nHuggingface."}
{"id": "2505.13934", "pdf": "https://arxiv.org/pdf/2505.13934", "abs": "https://arxiv.org/abs/2505.13934", "authors": ["Jialong Wu", "Shaofeng Yin", "Ningya Feng", "Mingsheng Long"], "title": "RLVR-World: Training World Models with Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Code is available at project website:\n  https://thuml.github.io/RLVR-World/", "summary": "World models predict state transitions in response to actions and are\nincreasingly developed across diverse modalities. However, standard training\nobjectives such as maximum likelihood estimation (MLE) often misalign with\ntask-specific goals of world models, i.e., transition prediction metrics like\naccuracy or perceptual quality. In this paper, we present RLVR-World, a unified\nframework that leverages reinforcement learning with verifiable rewards (RLVR)\nto directly optimize world models for such metrics. Despite formulating world\nmodeling as autoregressive prediction of tokenized sequences, RLVR-World\nevaluates metrics of decoded predictions as verifiable rewards. We demonstrate\nsubstantial performance gains on both language- and video-based world models\nacross domains, including text games, web navigation, and robot manipulation.\nOur work indicates that, beyond recent advances in reasoning language models,\nRLVR offers a promising post-training paradigm for enhancing the utility of\ngenerative models more broadly."}
{"id": "2505.14604", "pdf": "https://arxiv.org/pdf/2505.14604", "abs": "https://arxiv.org/abs/2505.14604", "authors": ["Haoran Zhao", "Yuchen Yan", "Yongliang Shen", "Haolei Xu", "Wenqi Zhang", "Kaitao Song", "Jian Shao", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "Let LLMs Break Free from Overthinking via Self-Braking Tuning", "categories": ["cs.AI"], "comment": "Github:https://github.com/CCAI-Lab/Self-Braking-Tuning; Project:\n  https://CCAI-Lab.github.io/SBT", "summary": "Large reasoning models (LRMs), such as OpenAI o1 and DeepSeek-R1, have\nsignificantly enhanced their reasoning capabilities by generating longer chains\nof thought, demonstrating outstanding performance across a variety of tasks.\nHowever, this performance gain comes at the cost of a substantial increase in\nredundant reasoning during the generation process, leading to high\ncomputational overhead and exacerbating the issue of overthinking. Although\nnumerous existing approaches aim to address the problem of overthinking, they\noften rely on external interventions. In this paper, we propose a novel\nframework, Self-Braking Tuning (SBT), which tackles overthinking from the\nperspective of allowing the model to regulate its own reasoning process, thus\neliminating the reliance on external control mechanisms. We construct a set of\noverthinking identification metrics based on standard answers and design a\nsystematic method to detect redundant reasoning. This method accurately\nidentifies unnecessary steps within the reasoning trajectory and generates\ntraining signals for learning self-regulation behaviors. Building on this\nfoundation, we develop a complete strategy for constructing data with adaptive\nreasoning lengths and introduce an innovative braking prompt mechanism that\nenables the model to naturally learn when to terminate reasoning at an\nappropriate point. Experiments across mathematical benchmarks (AIME, AMC,\nMATH500, GSM8K) demonstrate that our method reduces token consumption by up to\n60% while maintaining comparable accuracy to unconstrained models."}
{"id": "2505.14178", "pdf": "https://arxiv.org/pdf/2505.14178", "abs": "https://arxiv.org/abs/2505.14178", "authors": ["Xiang Zhang", "Juntai Cao", "Jiaqi Wei", "Yiwei Xu", "Chenyu You"], "title": "Tokenization Constraints in LLMs: A Study of Symbolic and Arithmetic Reasoning Limits", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Tokenization is the first - and often underappreciated - layer of computation\nin language models. While Chain-of-Thought (CoT) prompting enables transformer\nmodels to approximate recurrent computation by externalizing intermediate\nsteps, we show that the success of such reasoning is fundamentally bounded by\nthe structure of tokenized inputs. This work presents a theoretical and\nempirical investigation into how tokenization schemes, particularly\nsubword-based methods like byte-pair encoding (BPE), impede symbolic\ncomputation by merging or obscuring atomic reasoning units. We introduce the\nnotion of Token Awareness to formalize how poor token granularity disrupts\nlogical alignment and prevents models from generalizing symbolic procedures.\nThrough systematic evaluation on arithmetic and symbolic tasks, we demonstrate\nthat token structure dramatically affect reasoning performance, causing failure\neven with CoT, while atomically-aligned formats unlock strong generalization,\nallowing small models (e.g., GPT-4o-mini) to outperform larger systems (e.g.,\no1) in structured reasoning. Our findings reveal that symbolic reasoning\nability in LLMs is not purely architectural, but deeply conditioned on\ntoken-level representations."}
{"id": "2505.14405", "pdf": "https://arxiv.org/pdf/2505.14405", "abs": "https://arxiv.org/abs/2505.14405", "authors": ["Jiafeng Liang", "Shixin Jiang", "Xuan Dong", "Ning Wang", "Zheng Chu", "Hui Su", "Jinlan Fu", "Ming Liu", "See-Kiong Ng", "Bing Qin"], "title": "Investigating and Enhancing the Robustness of Large Multimodal Models Against Temporal Inconsistency", "categories": ["cs.CV"], "comment": null, "summary": "Large Multimodal Models (LMMs) have recently demonstrated impressive\nperformance on general video comprehension benchmarks. Nevertheless, for\nbroader applications, the robustness of their temporal analysis capability\nneeds to be thoroughly investigated yet predominantly ignored. Motivated by\nthis, we propose a novel temporal robustness benchmark (TemRobBench), which\nintroduces temporal inconsistency perturbations separately at the visual and\ntextual modalities to assess the robustness of models. We evaluate 16\nmainstream LMMs and find that they exhibit over-reliance on prior knowledge and\ntextual context in adversarial environments, while ignoring the actual temporal\ndynamics in the video. To mitigate this issue, we design panoramic direct\npreference optimization (PanoDPO), which encourages LMMs to incorporate both\nvisual and linguistic feature preferences simultaneously. Experimental results\nshow that PanoDPO can effectively enhance the model's robustness and\nreliability in temporal analysis."}
{"id": "2505.13938", "pdf": "https://arxiv.org/pdf/2505.13938", "abs": "https://arxiv.org/abs/2505.13938", "authors": ["Amitayush Thakur", "Jasper Lee", "George Tsoukalas", "Meghana Sistla", "Matthew Zhao", "Stefan Zetzche", "Greg Durrett", "Yisong Yue", "Swarat Chaudhuri"], "title": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "categories": ["cs.LG", "cs.AI", "cs.LO", "cs.PL", "cs.SE"], "comment": null, "summary": "We introduce ${\\rm C{\\small LEVER}}$, a high-quality, curated benchmark of\n161 problems for end-to-end verified code generation in Lean. Each problem\nconsists of (1) the task of generating a specification that matches a held-out\nground-truth specification, and (2) the task of generating a Lean\nimplementation that provably satisfies this specification. Unlike prior\nbenchmarks, ${\\rm C{\\small LEVER}}$ avoids test-case supervision, LLM-generated\nannotations, and specifications that leak implementation logic or allow vacuous\nsolutions. All outputs are verified post-hoc using Lean's type checker to\nensure machine-checkable correctness. We use ${\\rm C{\\small LEVER}}$ to\nevaluate several few-shot and agentic approaches based on state-of-the-art\nlanguage models. These methods all struggle to achieve full verification,\nestablishing it as a challenging frontier benchmark for program synthesis and\nformal reasoning. Our benchmark can be found on\nGitHub(https://github.com/trishullab/clever) as well as\nHuggingFace(https://huggingface.co/datasets/amitayusht/clever). All our\nevaluation code is also available\nonline(https://github.com/trishullab/clever-prover)."}
{"id": "2505.14615", "pdf": "https://arxiv.org/pdf/2505.14615", "abs": "https://arxiv.org/abs/2505.14615", "authors": ["Anjiang Wei", "Yuheng Wu", "Yingjia Wan", "Tarun Suresh", "Huanmi Tan", "Zhanke Zhou", "Sanmi Koyejo", "Ke Wang", "Alex Aiken"], "title": "SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "comment": null, "summary": "We introduce SATBench, a benchmark for evaluating the logical reasoning\ncapabilities of large language models (LLMs) through logical puzzles derived\nfrom Boolean satisfiability (SAT) problems. Unlike prior work that focuses on\ninference rule-based reasoning, which often involves deducing conclusions from\na set of premises, our approach leverages the search-based nature of SAT\nproblems, where the objective is to find a solution that fulfills a specified\nset of logical constraints. Each instance in SATBench is generated from a SAT\nformula, then translated into a story context and conditions using LLMs. The\ngeneration process is fully automated and allows for adjustable difficulty by\nvarying the number of clauses. All 2100 puzzles are validated through both\nLLM-assisted and solver-based consistency checks, with human validation on a\nsubset. Experimental results show that even the strongest model, o4-mini,\nachieves only 65.0% accuracy on hard UNSAT problems, close to the random\nbaseline of 50%. SATBench exposes fundamental limitations in the search-based\nlogical reasoning abilities of current LLMs and provides a scalable testbed for\nfuture research in logical reasoning."}
{"id": "2505.14179", "pdf": "https://arxiv.org/pdf/2505.14179", "abs": "https://arxiv.org/abs/2505.14179", "authors": ["Tong Bao", "Heng Zhang", "Chengzhi Zhang"], "title": "Enhancing Abstractive Summarization of Scientific Papers Using Structure Information", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Abstractive summarization of scientific papers has always been a research\nfocus, yet existing methods face two main challenges. First, most summarization\nmodels rely on Encoder-Decoder architectures that treat papers as sequences of\nwords, thus fail to fully capture the structured information inherent in\nscientific papers. Second, existing research often use keyword mapping or\nfeature engineering to identify the structural information, but these methods\nstruggle with the structural flexibility of scientific papers and lack\nrobustness across different disciplines. To address these challenges, we\npropose a two-stage abstractive summarization framework that leverages\nautomatic recognition of structural functions within scientific papers. In the\nfirst stage, we standardize chapter titles from numerous scientific papers and\nconstruct a large-scale dataset for structural function recognition. A\nclassifier is then trained to automatically identify the key structural\ncomponents (e.g., Background, Methods, Results, Discussion), which provides a\nfoundation for generating more balanced summaries. In the second stage, we\nemploy Longformer to capture rich contextual relationships across sections and\ngenerating context-aware summaries. Experiments conducted on two\ndomain-specific scientific paper summarization datasets demonstrate that our\nmethod outperforms advanced baselines, and generates more comprehensive\nsummaries. The code and dataset can be accessed at\nhttps://github.com/tongbao96/code-for-SFR-AS."}
{"id": "2505.14414", "pdf": "https://arxiv.org/pdf/2505.14414", "abs": "https://arxiv.org/abs/2505.14414", "authors": ["Chengtang Yao", "Lidong Yu", "Zhidan Liu", "Jiaxi Zeng", "Yuwei Wu", "Yunde Jia"], "title": "Diving into the Fusion of Monocular Priors for Generalized Stereo Matching", "categories": ["cs.CV"], "comment": "Code:\n  https://github.com/YaoChengTang/Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching", "summary": "The matching formulation makes it naturally hard for the stereo matching to\nhandle ill-posed regions like occlusions and non-Lambertian surfaces. Fusing\nmonocular priors has been proven helpful for ill-posed matching, but the biased\nmonocular prior learned from small stereo datasets constrains the\ngeneralization. Recently, stereo matching has progressed by leveraging the\nunbiased monocular prior from the vision foundation model (VFM) to improve the\ngeneralization in ill-posed regions. We dive into the fusion process and\nobserve three main problems limiting the fusion of the VFM monocular prior. The\nfirst problem is the misalignment between affine-invariant relative monocular\ndepth and absolute depth of disparity. Besides, when we use the monocular\nfeature in an iterative update structure, the over-confidence in the disparity\nupdate leads to local optima results. A direct fusion of a monocular depth map\ncould alleviate the local optima problem, but noisy disparity results computed\nat the first several iterations will misguide the fusion. In this paper, we\npropose a binary local ordering map to guide the fusion, which converts the\ndepth map into a binary relative format, unifying the relative and absolute\ndepth representation. The computed local ordering map is also used to re-weight\nthe initial disparity update, resolving the local optima and noisy problem. In\naddition, we formulate the final direct fusion of monocular depth to the\ndisparity as a registration problem, where a pixel-wise linear regression\nmodule can globally and adaptively align them. Our method fully exploits the\nmonocular prior to support stereo matching results effectively and efficiently.\nWe significantly improve the performance from the experiments when generalizing\nfrom SceneFlow to Middlebury and Booster datasets while barely reducing the\nefficiency."}
{"id": "2505.13954", "pdf": "https://arxiv.org/pdf/2505.13954", "abs": "https://arxiv.org/abs/2505.13954", "authors": ["Jiahe Chen", "Ziye Ma"], "title": "VAMO: Efficient Large-Scale Nonconvex Optimization via Adaptive Zeroth Order Variance Reduction", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Optimizing large-scale nonconvex problems, common in machine learning,\ndemands balancing rapid convergence with computational efficiency. First-order\n(FO) stochastic methods like SVRG provide fast convergence and good\ngeneralization but incur high costs due to full-batch gradients in large\nmodels. Conversely, zeroth-order (ZO) algorithms reduce this burden using\nestimated gradients, yet their slow convergence in high-dimensional settings\nlimits practicality. We introduce VAMO (VAriance-reduced Mixed-gradient\nOptimizer), a stochastic variance-reduced method combining FO mini-batch\ngradients with lightweight ZO finite-difference probes under an SVRG-style\nframework. VAMO's hybrid design uses a two-point ZO estimator to achieve a\ndimension-agnostic convergence rate of $\\mathcal{O}(1/T + 1/b)$, where $T$ is\nthe number of iterations and $b$ is the batch-size, surpassing the\ndimension-dependent slowdown of purely ZO methods and significantly improving\nover SGD's $\\mathcal{O}(1/\\sqrt{T})$ rate. Additionally, we propose a\nmulti-point ZO variant that mitigates the $O(1/b)$ error by adjusting number of\nestimation points to balance convergence and cost, making it ideal for a whole\nrange of computationally constrained scenarios. Experiments including\ntraditional neural network training and LLM finetuning show VAMO outperforms\nestablished FO and ZO methods, offering a faster, more flexible option for\nimproved efficiency."}
{"id": "2505.14627", "pdf": "https://arxiv.org/pdf/2505.14627", "abs": "https://arxiv.org/abs/2505.14627", "authors": ["Ashutosh Adhikari", "Mirella Lapata"], "title": "Debating for Better Reasoning: An Unsupervised Multimodal Approach", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As Large Language Models (LLMs) gain expertise across diverse domains and\nmodalities, scalable oversight becomes increasingly challenging, particularly\nwhen their capabilities may surpass human evaluators. Debate has emerged as a\npromising mechanism for enabling such oversight. In this work, we extend the\ndebate paradigm to a multimodal setting, exploring its potential for weaker\nmodels to supervise and enhance the performance of stronger models. We focus on\nvisual question answering (VQA), where two \"sighted\" expert vision-language\nmodels debate an answer, while a \"blind\" (text-only) judge adjudicates based\nsolely on the quality of the arguments. In our framework, the experts defend\nonly answers aligned with their beliefs, thereby obviating the need for\nexplicit role-playing and concentrating the debate on instances of expert\ndisagreement. Experiments on several multimodal tasks demonstrate that the\ndebate framework consistently outperforms individual expert models. Moreover,\njudgments from weaker LLMs can help instill reasoning capabilities in\nvision-language models through finetuning."}
{"id": "2505.14181", "pdf": "https://arxiv.org/pdf/2505.14181", "abs": "https://arxiv.org/abs/2505.14181", "authors": ["Yunlong Liang", "Fandong Meng", "Jiaan Wang", "Jie Zhou"], "title": "SlangDIT: Benchmarking LLMs in Interpretative Slang Translation", "categories": ["cs.CL"], "comment": "work in progress", "summary": "The challenge of slang translation lies in capturing context-dependent\nsemantic extensions, as slang terms often convey meanings beyond their literal\ninterpretation. While slang detection, explanation, and translation have been\nstudied as isolated tasks in the era of large language models (LLMs), their\nintrinsic interdependence remains underexplored. The main reason is lacking of\na benchmark where the two tasks can be a prerequisite for the third one, which\ncan facilitate idiomatic translation. In this paper, we introduce the\ninterpretative slang translation task (named SlangDIT) consisting of three\nsub-tasks: slang detection, cross-lingual slang explanation, and slang\ntranslation within the current context, aiming to generate more accurate\ntranslation with the help of slang detection and slang explanation. To this\nend, we construct a SlangDIT dataset, containing over 25k English-Chinese\nsentence pairs. Each source sentence mentions at least one slang term and is\nlabeled with corresponding cross-lingual slang explanation. Based on the\nbenchmark, we propose a deep thinking model, named SlangOWL. It firstly\nidentifies whether the sentence contains a slang, and then judges whether the\nslang is polysemous and analyze its possible meaning. Further, the SlangOWL\nprovides the best explanation of the slang term targeting on the current\ncontext. Finally, according to the whole thought, the SlangOWL offers a\nsuitable translation. Our experiments on LLMs (\\emph{e.g.}, Qwen2.5 and\nLLama-3.1), show that our deep thinking approach indeed enhances the\nperformance of LLMs where the proposed SLangOWL significantly surpasses the\nvanilla models and supervised fine-tuned models without thinking."}
{"id": "2505.14454", "pdf": "https://arxiv.org/pdf/2505.14454", "abs": "https://arxiv.org/abs/2505.14454", "authors": ["Xuyang Liu", "Yiyu Wang", "Junpeng Ma", "Linfeng Zhang"], "title": "Video Compression Commander: Plug-and-Play Inference Acceleration for Video Large Language Models", "categories": ["cs.CV"], "comment": "Our code is available at https://github.com/xuyang-liu16/VidCom2", "summary": "Video large language models (VideoLLM) excel at video understanding, but face\nefficiency challenges due to the quadratic complexity of abundant visual\ntokens. Our systematic analysis of token compression methods for VideoLLMs\nreveals two critical issues: (i) overlooking distinctive visual signals across\nframes, leading to information loss; (ii) suffering from implementation\nconstraints, causing incompatibility with modern architectures or efficient\noperators. To address these challenges, we distill three design principles for\nVideoLLM token compression and propose a plug-and-play inference acceleration\nframework \"Video Compression Commander\" (VidCom2). By quantifying each frame's\nuniqueness, VidCom2 adaptively adjusts compression intensity across frames,\neffectively preserving essential information while reducing redundancy in video\nsequences. Extensive experiments across various VideoLLMs and benchmarks\ndemonstrate the superior performance and efficiency of our VidCom2. With only\n25% visual tokens, VidCom2 achieves 99.6% of the original performance on\nLLaVA-OV while reducing 70.8% of the LLM generation latency. Notably, our Frame\nCompression Adjustment strategy is compatible with other token compression\nmethods to further improve their performance. Our code is available at\nhttps://github.com/xuyang-liu16/VidCom2."}
{"id": "2505.13989", "pdf": "https://arxiv.org/pdf/2505.13989", "abs": "https://arxiv.org/abs/2505.13989", "authors": ["Yanzhe Wen", "Xunkai Li", "Qi Zhang", "Zhu Lei", "Guang Zeng", "Rong-Hua Li", "Guoren Wang"], "title": "When LLMs meet open-world graph learning: a new perspective for unlabeled data uncertainty", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, large language models (LLMs) have significantly advanced\ntext-attributed graph (TAG) learning. However, existing methods inadequately\nhandle data uncertainty in open-world scenarios, especially concerning limited\nlabeling and unknown-class nodes. Prior solutions typically rely on isolated\nsemantic or structural approaches for unknown-class rejection, lacking\neffective annotation pipelines. To address these limitations, we propose\nOpen-world Graph Assistant (OGA), an LLM-based framework that combines adaptive\nlabel traceability, which integrates semantics and topology for unknown-class\nrejection, and a graph label annotator to enable model updates using newly\nannotated nodes. Comprehensive experiments demonstrate OGA's effectiveness and\npracticality."}
{"id": "2505.14656", "pdf": "https://arxiv.org/pdf/2505.14656", "abs": "https://arxiv.org/abs/2505.14656", "authors": ["Zihao Zhang", "Fei Liu"], "title": "Cost-Augmented Monte Carlo Tree Search for LLM-Assisted Planning", "categories": ["cs.AI"], "comment": null, "summary": "While LLMs excel at open-ended reasoning, they often struggle with\ncost-sensitive planning, either treating all actions as having equal cost or\nfailing to stay within strict budgets. In this paper, we introduce\nCost-Augmented Monte Carlo Tree Search (CATS), a novel approach that brings\nexplicit cost-awareness into LLM-guided planning. Tight cost constraints push\nthe planner to quickly identify infeasible solutions, while looser constraints\nencourage optimization for minimal cost. We benchmark top LLMs such as GPT-4.1,\nClaude-3.7-Sonnet, and DeepSeek-R1, against our CATS planner to evaluate their\nperformance in cost-sensitive scenarios. Our experiments suggest that raw LLMs\nsuch as GPT-4.1 often falter under tight budgets, whereas CATS consistently\ndelivers strong performance, achieving higher task success rates and better\ncost efficiency. CATS provides an effective solution for budget-aware\ndecision-making by combining the reasoning power of LLMs with structured\nsearch."}
{"id": "2505.14183", "pdf": "https://arxiv.org/pdf/2505.14183", "abs": "https://arxiv.org/abs/2505.14183", "authors": ["Guosheng Liang", "Longguang Zhong", "Ziyi Yang", "Xiaojun Quan"], "title": "ThinkSwitcher: When to Think Hard, When to Think Fast", "categories": ["cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) excel at solving complex tasks by leveraging\nlong chain-of-thought (CoT) reasoning. However, this often leads to\noverthinking on simple tasks, resulting in unnecessary computational overhead.\nWe observe that LRMs inherently possess the capability for efficient short CoT\nreasoning, which can be reliably elicited through prompt design. To leverage\nthis capability, we propose ThinkSwitcher, a framework that enables a single\nLRM to dynamically switch between short and long CoT modes based on task\ncomplexity. ThinkSwitcher introduces a lightweight switching module trained\nwith supervision signals derived from the relative performance of each\nreasoning mode across tasks. Experiments on multiple reasoning benchmarks show\nthat ThinkSwitcher reduces computational cost by 20-30% while maintaining high\naccuracy on complex tasks. This demonstrates the effectiveness of ThinkSwitcher\nas a scalable and efficient solution for unified LRM deployment."}
{"id": "2505.14460", "pdf": "https://arxiv.org/pdf/2505.14460", "abs": "https://arxiv.org/abs/2505.14460", "authors": ["Tianhe Wu", "Jian Zou", "Jie Liang", "Lei Zhang", "Kede Ma"], "title": "VisualQuality-R1: Reasoning-Induced Image Quality Assessment via Reinforcement Learning to Rank", "categories": ["cs.CV"], "comment": null, "summary": "DeepSeek-R1 has demonstrated remarkable effectiveness in incentivizing\nreasoning and generalization capabilities of large language models (LLMs)\nthrough reinforcement learning. Nevertheless, the potential of\nreasoning-induced computational modeling has not been thoroughly explored in\nthe context of image quality assessment (IQA), a task critically dependent on\nvisual reasoning. In this paper, we introduce VisualQuality-R1, a\nreasoning-induced no-reference IQA (NR-IQA) model, and we train it with\nreinforcement learning to rank, a learning algorithm tailored to the\nintrinsically relative nature of visual quality. Specifically, for a pair of\nimages, we employ group relative policy optimization to generate multiple\nquality scores for each image. These estimates are then used to compute\ncomparative probabilities of one image having higher quality than the other\nunder the Thurstone model. Rewards for each quality estimate are defined using\ncontinuous fidelity measures rather than discretized binary labels. Extensive\nexperiments show that the proposed VisualQuality-R1 consistently outperforms\ndiscriminative deep learning-based NR-IQA models as well as a recent\nreasoning-induced quality regression method. Moreover, VisualQuality-R1 is\ncapable of generating contextually rich, human-aligned quality descriptions,\nand supports multi-dataset training without requiring perceptual scale\nrealignment. These features make VisualQuality-R1 especially well-suited for\nreliably measuring progress in a wide range of image processing tasks like\nsuper-resolution and image generation."}
{"id": "2505.14005", "pdf": "https://arxiv.org/pdf/2505.14005", "abs": "https://arxiv.org/abs/2505.14005", "authors": ["Han Zhang", "Yan Wang", "Guanfeng Liu", "Pengfei Ding", "Huaxiong Wang", "Kwok-Yan Lam"], "title": "Towards Comprehensive and Prerequisite-Free Explainer for Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI 2025 AI4Tech Track", "summary": "To enhance the reliability and credibility of graph neural networks (GNNs)\nand improve the transparency of their decision logic, a new field of\nexplainability of GNNs (XGNN) has emerged. However, two major limitations\nseverely degrade the performance and hinder the generalizability of existing\nXGNN methods: they (a) fail to capture the complete decision logic of GNNs\nacross diverse distributions in the entire dataset's sample space, and (b)\nimpose strict prerequisites on edge properties and GNN internal accessibility.\nTo address these limitations, we propose OPEN, a novel c\\textbf{O}mprehensive\nand \\textbf{P}rerequisite-free \\textbf{E}xplainer for G\\textbf{N}Ns. OPEN, as\nthe first work in the literature, can infer and partition the entire dataset's\nsample space into multiple environments, each containing graphs that follow a\ndistinct distribution. OPEN further learns the decision logic of GNNs across\ndifferent distributions by sampling subgraphs from each environment and\nanalyzing their predictions, thus eliminating the need for strict\nprerequisites. Experimental results demonstrate that OPEN captures nearly\ncomplete decision logic of GNNs, outperforms state-of-the-art methods in\nfidelity while maintaining similar efficiency, and enhances robustness in\nreal-world scenarios."}
{"id": "2505.14667", "pdf": "https://arxiv.org/pdf/2505.14667", "abs": "https://arxiv.org/abs/2505.14667", "authors": ["Wonje Jeung", "Sangyeon Yoon", "Minsuk Kahng", "Albert No"], "title": "SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment", "categories": ["cs.AI", "cs.CL"], "comment": "22 pages", "summary": "Large Reasoning Models (LRMs) have become powerful tools for complex problem\nsolving, but their structured reasoning pathways can lead to unsafe outputs\nwhen exposed to harmful prompts. Existing safety alignment methods reduce\nharmful outputs but can degrade reasoning depth, leading to significant\ntrade-offs in complex, multi-step tasks, and remain vulnerable to sophisticated\njailbreak attacks. To address this, we introduce SAFEPATH, a lightweight\nalignment method that fine-tunes LRMs to emit a short, 8-token Safety Primer at\nthe start of their reasoning, in response to harmful prompts, while leaving the\nrest of the reasoning process unsupervised. Empirical results across multiple\nbenchmarks indicate that SAFEPATH effectively reduces harmful outputs while\nmaintaining reasoning performance. Specifically, SAFEPATH reduces harmful\nresponses by up to 90.0% and blocks 83.3% of jailbreak attempts in the\nDeepSeek-R1-Distill-Llama-8B model, while requiring 295.9x less compute than\nDirect Refusal and 314.1x less than SafeChain. We further introduce a zero-shot\nvariant that requires no fine-tuning. In addition, we provide a comprehensive\nanalysis of how existing methods in LLMs generalize, or fail, when applied to\nreasoning-centric models, revealing critical gaps and new directions for safer\nAI."}
{"id": "2505.14195", "pdf": "https://arxiv.org/pdf/2505.14195", "abs": "https://arxiv.org/abs/2505.14195", "authors": ["Tuc Nguyen", "Yifan Hu", "Thai Le"], "title": "Unraveling Interwoven Roles of Large Language Models in Authorship Privacy: Obfuscation, Mimicking, and Verification", "categories": ["cs.CL"], "comment": "17 pages, 3 figures", "summary": "Recent advancements in large language models (LLMs) have been fueled by large\nscale training corpora drawn from diverse sources such as websites, news\narticles, and books. These datasets often contain explicit user information,\nsuch as person names and addresses, that LLMs may unintentionally reproduce in\ntheir generated outputs. Beyond such explicit content, LLMs can also leak\nidentity revealing cues through implicit signals such as distinctive writing\nstyles, raising significant concerns about authorship privacy. There are three\nmajor automated tasks in authorship privacy, namely authorship obfuscation\n(AO), authorship mimicking (AM), and authorship verification (AV). Prior\nresearch has studied AO, AM, and AV independently. However, their interplays\nremain under explored, which leaves a major research gap, especially in the era\nof LLMs, where they are profoundly shaping how we curate and share user\ngenerated content, and the distinction between machine generated and human\nauthored text is also increasingly blurred. This work then presents the first\nunified framework for analyzing the dynamic relationships among LLM enabled AO,\nAM, and AV in the context of authorship privacy. We quantify how they interact\nwith each other to transform human authored text, examining effects at a single\npoint in time and iteratively over time. We also examine the role of\ndemographic metadata, such as gender, academic background, in modulating their\nperformances, inter-task dynamics, and privacy risks. All source code will be\npublicly available."}
{"id": "2505.14462", "pdf": "https://arxiv.org/pdf/2505.14462", "abs": "https://arxiv.org/abs/2505.14462", "authors": ["Jiaang Li", "Yifei Yuan", "Wenyan Li", "Mohammad Aliannejadi", "Daniel Hershcovich", "Anders S√∏gaard", "Ivan Vuliƒá", "Wenxuan Zhang", "Paul Pu Liang", "Yang Deng", "Serge Belongie"], "title": "RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "As vision-language models (VLMs) become increasingly integrated into daily\nlife, the need for accurate visual culture understanding is becoming critical.\nYet, these models frequently fall short in interpreting cultural nuances\neffectively. Prior work has demonstrated the effectiveness of\nretrieval-augmented generation (RAG) in enhancing cultural understanding in\ntext-only settings, while its application in multimodal scenarios remains\nunderexplored. To bridge this gap, we introduce RAVENEA (Retrieval-Augmented\nVisual culturE uNdErstAnding), a new benchmark designed to advance visual\nculture understanding through retrieval, focusing on two tasks: culture-focused\nvisual question answering (cVQA) and culture-informed image captioning (cIC).\nRAVENEA extends existing datasets by integrating over 10,000 Wikipedia\ndocuments curated and ranked by human annotators. With RAVENEA, we train and\nevaluate seven multimodal retrievers for each image query, and measure the\ndownstream impact of retrieval-augmented inputs across fourteen\nstate-of-the-art VLMs. Our results show that lightweight VLMs, when augmented\nwith culture-aware retrieval, outperform their non-augmented counterparts (by\nat least 3.2% absolute on cVQA and 6.2% absolute on cIC). This highlights the\nvalue of retrieval-augmented methods and culturally inclusive benchmarks for\nmultimodal understanding."}
{"id": "2505.14011", "pdf": "https://arxiv.org/pdf/2505.14011", "abs": "https://arxiv.org/abs/2505.14011", "authors": ["Yifei Jin", "Xin Zheng", "Lei Guo"], "title": "Adaptive Sentencing Prediction with Guaranteed Accuracy and Legal Interpretability", "categories": ["cs.LG"], "comment": null, "summary": "Existing research on judicial sentencing prediction predominantly relies on\nend-to-end models, which often neglect the inherent sentencing logic and lack\ninterpretability-a critical requirement for both scholarly research and\njudicial practice. To address this challenge, we make three key\ncontributions:First, we propose a novel Saturated Mechanistic Sentencing (SMS)\nmodel, which provides inherent legal interpretability by virtue of its\nfoundation in China's Criminal Law. We also introduce the corresponding\nMomentum Least Mean Squares (MLMS) adaptive algorithm for this model. Second,\nfor the MLMS algorithm based adaptive sentencing predictor, we establish a\nmathematical theory on the accuracy of adaptive prediction without resorting to\nany stationarity and independence assumptions on the data. We also provide a\nbest possible upper bound for the prediction accuracy achievable by the best\npredictor designed in the known parameters case. Third, we construct a Chinese\nIntentional Bodily Harm (CIBH) dataset. Utilizing this real-world data,\nextensive experiments demonstrate that our approach achieves a prediction\naccuracy that is not far from the best possible theoretical upper bound,\nvalidating both the model's suitability and the algorithm's accuracy."}
{"id": "2505.14668", "pdf": "https://arxiv.org/pdf/2505.14668", "abs": "https://arxiv.org/abs/2505.14668", "authors": ["Bufang Yang", "Lilin Xu", "Liekang Zeng", "Kaiwei Liu", "Siyang Jiang", "Wenrui Lu", "Hongkai Chen", "Xiaofan Jiang", "Guoliang Xing", "Zhenyu Yan"], "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have propelled intelligent\nagents from reactive responses to proactive support. While promising, existing\nproactive agents either rely exclusively on observations from enclosed\nenvironments (e.g., desktop UIs) with direct LLM inference or employ rule-based\nproactive notifications, leading to suboptimal user intent understanding and\nlimited functionality for proactive service. In this paper, we introduce\nContextAgent, the first context-aware proactive agent that incorporates\nextensive sensory contexts to enhance the proactive capabilities of LLM agents.\nContextAgent first extracts multi-dimensional contexts from massive sensory\nperceptions on wearables (e.g., video and audio) to understand user intentions.\nContextAgent then leverages the sensory contexts and the persona contexts from\nhistorical data to predict the necessity for proactive services. When proactive\nassistance is needed, ContextAgent further automatically calls the necessary\ntools to assist users unobtrusively. To evaluate this new task, we curate\nContextAgentBench, the first benchmark for evaluating context-aware proactive\nLLM agents, covering 1,000 samples across nine daily scenarios and twenty\ntools. Experiments on ContextAgentBench show that ContextAgent outperforms\nbaselines by achieving up to 8.5% and 6.0% higher accuracy in proactive\npredictions and tool calling, respectively. We hope our research can inspire\nthe development of more advanced, human-centric, proactive AI assistants."}
{"id": "2505.14212", "pdf": "https://arxiv.org/pdf/2505.14212", "abs": "https://arxiv.org/abs/2505.14212", "authors": ["Sizhe Yuen", "Ting Su", "Ziyang Wang", "Yali Du", "Adam J. Sobey"], "title": "Automatic Dataset Generation for Knowledge Intensive Question Answering Tasks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "A question-answering (QA) system is to search suitable answers within a\nknowledge base. Current QA systems struggle with queries requiring complex\nreasoning or real-time knowledge integration. They are often supplemented with\nretrieval techniques on a data source such as Retrieval-Augmented Generation\n(RAG). However, RAG continues to face challenges in handling complex reasoning\nand logical connections between multiple sources of information. A novel\napproach for enhancing Large Language Models (LLMs) in knowledge-intensive QA\ntasks is presented through the automated generation of context-based QA pairs.\nThis methodology leverages LLMs to create fine-tuning data, reducing reliance\non human labelling and improving model comprehension and reasoning\ncapabilities. The proposed system includes an automated QA generator and a\nmodel fine-tuner, evaluated using perplexity, ROUGE, BLEU, and BERTScore.\nComprehensive experiments demonstrate improvements in logical coherence and\nfactual accuracy, with implications for developing adaptable Artificial\nIntelligence (AI) systems. Mistral-7b-v0.3 outperforms Llama-3-8b with BERT F1,\nBLEU, and ROUGE scores 0.858, 0.172, and 0.260 of for the LLM generated QA\npairs compared to scores of 0.836, 0.083, and 0.139 for the human annotated QA\npairs."}
{"id": "2505.14476", "pdf": "https://arxiv.org/pdf/2505.14476", "abs": "https://arxiv.org/abs/2505.14476", "authors": ["Farshad Sangari Abiz", "Reshad Hosseini", "Babak N. Araabi"], "title": "Enhancing Interpretability of Sparse Latent Representations with Class Information", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Variational Autoencoders (VAEs) are powerful generative models for learning\nlatent representations. Standard VAEs generate dispersed and unstructured\nlatent spaces by utilizing all dimensions, which limits their interpretability,\nespecially in high-dimensional spaces. To address this challenge, Variational\nSparse Coding (VSC) introduces a spike-and-slab prior distribution, resulting\nin sparse latent representations for each input. These sparse representations,\ncharacterized by a limited number of active dimensions, are inherently more\ninterpretable. Despite this advantage, VSC falls short in providing structured\ninterpretations across samples within the same class. Intuitively, samples from\nthe same class are expected to share similar attributes while allowing for\nvariations in those attributes. This expectation should manifest as consistent\npatterns of active dimensions in their latent representations, but VSC does not\nenforce such consistency.\n  In this paper, we propose a novel approach to enhance the latent space\ninterpretability by ensuring that the active dimensions in the latent space are\nconsistent across samples within the same class. To achieve this, we introduce\na new loss function that encourages samples from the same class to share\nsimilar active dimensions. This alignment creates a more structured and\ninterpretable latent space, where each shared dimension corresponds to a\nhigh-level concept, or \"factor.\" Unlike existing disentanglement-based methods\nthat primarily focus on global factors shared across all classes, our method\ncaptures both global and class-specific factors, thereby enhancing the utility\nand interpretability of latent representations."}
{"id": "2505.14021", "pdf": "https://arxiv.org/pdf/2505.14021", "abs": "https://arxiv.org/abs/2505.14021", "authors": ["Soichiro Kumano", "Hiroshi Kera", "Toshihiko Yamasaki"], "title": "Adversarial Training from Mean Field Perspective", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "NeurIPS23", "summary": "Although adversarial training is known to be effective against adversarial\nexamples, training dynamics are not well understood. In this study, we present\nthe first theoretical analysis of adversarial training in random deep neural\nnetworks without any assumptions on data distributions. We introduce a new\ntheoretical framework based on mean field theory, which addresses the\nlimitations of existing mean field-based approaches. Based on this framework,\nwe derive (empirically tight) upper bounds of $\\ell_q$ norm-based adversarial\nloss with $\\ell_p$ norm-based adversarial examples for various values of $p$\nand $q$. Moreover, we prove that networks without shortcuts are generally not\nadversarially trainable and that adversarial training reduces network capacity.\nWe also show that network width alleviates these issues. Furthermore, we\npresent the various impacts of the input and output dimensions on the upper\nbounds and time evolution of the weight variance."}
{"id": "2505.14681", "pdf": "https://arxiv.org/pdf/2505.14681", "abs": "https://arxiv.org/abs/2505.14681", "authors": ["Mengru Wang", "Xingyu Chen", "Yue Wang", "Zhiwei He", "Jiahao Xu", "Tian Liang", "Qiuzhi Liu", "Yunzhi Yao", "Wenxuan Wang", "Ruotian Ma", "Haitao Mi", "Ningyu Zhang", "Zhaopeng Tu", "Xiaolong Li", "Dong Yu"], "title": "Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IR", "cs.LG"], "comment": "Work in progress", "summary": "Mixture-of-Experts (MoE) architectures within Large Reasoning Models (LRMs)\nhave achieved impressive reasoning capabilities by selectively activating\nexperts to facilitate structured cognitive processes. Despite notable advances,\nexisting reasoning models often suffer from cognitive inefficiencies like\noverthinking and underthinking. To address these limitations, we introduce a\nnovel inference-time steering methodology called Reinforcing Cognitive Experts\n(RICE), designed to improve reasoning performance without additional training\nor complex heuristics. Leveraging normalized Pointwise Mutual Information\n(nPMI), we systematically identify specialized experts, termed ''cognitive\nexperts'' that orchestrate meta-level reasoning operations characterized by\ntokens like ''<think>''. Empirical evaluations with leading MoE-based LRMs\n(DeepSeek-R1 and Qwen3-235B) on rigorous quantitative and scientific reasoning\nbenchmarks demonstrate noticeable and consistent improvements in reasoning\naccuracy, cognitive efficiency, and cross-domain generalization. Crucially, our\nlightweight approach substantially outperforms prevalent reasoning-steering\ntechniques, such as prompt design and decoding constraints, while preserving\nthe model's general instruction-following skills. These results highlight\nreinforcing cognitive experts as a promising, practical, and interpretable\ndirection to enhance cognitive efficiency within advanced reasoning models."}
{"id": "2505.14226", "pdf": "https://arxiv.org/pdf/2505.14226", "abs": "https://arxiv.org/abs/2505.14226", "authors": ["Darpan Aswal", "Siddharth D Jaiswal"], "title": "\"Haet Bhasha aur Diskrimineshun\": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have become increasingly powerful, with\nmultilingual and multimodal capabilities improving by the day. These models are\nbeing evaluated through audits, alignment studies and red-teaming efforts to\nexpose model vulnerabilities towards generating harmful, biased and unfair\ncontent. Existing red-teaming efforts have previously focused on the English\nlanguage, using fixed template-based attacks; thus, models continue to be\nsusceptible to multilingual jailbreaking strategies, especially in the\nmultimodal context. In this study, we introduce a novel strategy that leverages\ncode-mixing and phonetic perturbations to jailbreak LLMs for both text and\nimage generation tasks. We also introduce two new jailbreak strategies that\nshow higher effectiveness than baseline strategies. Our work presents a method\nto effectively bypass safety filters in LLMs while maintaining interpretability\nby applying phonetic misspellings to sensitive words in code-mixed prompts. Our\nnovel prompts achieve a 99% Attack Success Rate for text generation and 78% for\nimage generation, with Attack Relevance Rate of 100% for text generation and\n95% for image generation when using the phonetically perturbed code-mixed\nprompts. Our interpretability experiments reveal that phonetic perturbations\nimpact word tokenization, leading to jailbreak success. Our study motivates\nincreasing the focus towards more generalizable safety alignment for\nmultilingual multimodal models, especially in real-world settings wherein\nprompts can have misspelt words."}
{"id": "2505.14511", "pdf": "https://arxiv.org/pdf/2505.14511", "abs": "https://arxiv.org/abs/2505.14511", "authors": ["Guillaume Vray", "Devavrat Tomar", "Xufeng Gao", "Jean-Philippe Thiran", "Evan Shelhamer", "Behzad Bozorgtabar"], "title": "ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains", "categories": ["cs.CV"], "comment": null, "summary": "This paper introduces ReservoirTTA, a novel plug-in framework designed for\nprolonged test-time adaptation (TTA) in scenarios where the test domain\ncontinuously shifts over time, including cases where domains recur or evolve\ngradually. At its core, ReservoirTTA maintains a reservoir of\ndomain-specialized models -- an adaptive test-time model ensemble -- that both\ndetects new domains via online clustering over style features of incoming\nsamples and routes each sample to the appropriate specialized model, and\nthereby enables domain-specific adaptation. This multi-model strategy overcomes\nkey limitations of single model adaptation, such as catastrophic forgetting,\ninter-domain interference, and error accumulation, ensuring robust and stable\nperformance on sustained non-stationary test distributions. Our theoretical\nanalysis reveals key components that bound parameter variance and prevent model\ncollapse, while our plug-in TTA module mitigates catastrophic forgetting of\npreviously encountered domains. Extensive experiments on the classification\ncorruption benchmarks, including ImageNet-C and CIFAR-10/100-C, as well as the\nCityscapes$\\rightarrow$ACDC semantic segmentation task, covering recurring and\ncontinuously evolving domain shifts, demonstrate that ReservoirTTA\nsignificantly improves adaptation accuracy and maintains stable performance\nacross prolonged, recurring shifts, outperforming state-of-the-art methods."}
{"id": "2505.14024", "pdf": "https://arxiv.org/pdf/2505.14024", "abs": "https://arxiv.org/abs/2505.14024", "authors": ["Di Wu", "Qian Li", "Heng Yang", "Yong Han"], "title": "FedGraM: Defending Against Untargeted Attacks in Federated Learning via Embedding Gram Matrix", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) enables geographically distributed clients to\ncollaboratively train machine learning models by sharing only their local\nmodels, ensuring data privacy. However, FL is vulnerable to untargeted attacks\nthat aim to degrade the global model's performance on the underlying data\ndistribution. Existing defense mechanisms attempt to improve FL's resilience\nagainst such attacks, but their effectiveness is limited in practical FL\nenvironments due to data heterogeneity. On the contrary, we aim to detect and\nremove the attacks to mitigate their impact. Generalization contribution plays\na crucial role in distinguishing untargeted attacks. Our observations indicate\nthat, with limited data, the divergence between embeddings representing\ndifferent classes provides a better measure of generalization than direct\naccuracy. In light of this, we propose a novel robust aggregation method,\nFedGraM, designed to defend against untargeted attacks in FL. The server\nmaintains an auxiliary dataset containing one sample per class to support\naggregation. This dataset is fed to the local models to extract embeddings.\nThen, the server calculates the norm of the Gram Matrix of the embeddings for\neach local model. The norm serves as an indicator of each model's inter-class\nseparation capability in the embedding space. FedGraM identifies and removes\npotentially malicious models by filtering out those with the largest norms,\nthen averages the remaining local models to form the global model. We conduct\nextensive experiments to evaluate the performance of FedGraM. Our empirical\nresults show that with limited data samples used to construct the auxiliary\ndataset, FedGraM achieves exceptional performance, outperforming\nstate-of-the-art defense methods."}
{"id": "2505.06699", "pdf": "https://arxiv.org/pdf/2505.06699", "abs": "https://arxiv.org/abs/2505.06699", "authors": ["Xiyuan Wei", "Ming Lin", "Fanjiang Ye", "Fengguang Song", "Liangliang Cao", "My T. Thai", "Tianbao Yang"], "title": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "18 pages, 6 figures", "summary": "This paper formalizes an emerging learning paradigm that uses a trained model\nas a reference to guide and enhance the training of a target model through\nstrategic data selection or weighting, named $\\textbf{model steering}$. While\nad-hoc methods have been used in various contexts, including the training of\nlarge foundation models, its underlying principles remain insufficiently\nunderstood, leading to sub-optimal performance. In this work, we propose a\ntheory-driven framework for model steering called $\\textbf{DRRho risk\nminimization}$, which is rooted in Distributionally Robust Optimization (DRO).\nThrough a generalization analysis, we provide theoretical insights into why\nthis approach improves generalization and data efficiency compared to training\nwithout a reference model. To the best of our knowledge, this is the first time\nsuch theoretical insights are provided for the new learning paradigm, which\nsignificantly enhance our understanding and practice of model steering.\nBuilding on these insights and the connection between contrastive learning and\nDRO, we introduce a novel method for Contrastive Language-Image Pretraining\n(CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments\nvalidate the theoretical insights, reveal a superior scaling law compared to\nCLIP without a reference model, and demonstrate its strength over existing\nheuristic approaches."}
{"id": "2505.14233", "pdf": "https://arxiv.org/pdf/2505.14233", "abs": "https://arxiv.org/abs/2505.14233", "authors": ["Hakaze Cho", "Peng Luo", "Mariko Kato", "Rin Kaenbyou", "Naoya Inoue"], "title": "Mechanistic Fine-tuning for In-context Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "28 pages, 31 figures, 6 tables", "summary": "In-context Learning (ICL) utilizes structured demonstration-query inputs to\ninduce few-shot learning on Language Models (LMs), which are not originally\npre-trained on ICL-style data. To bridge the gap between ICL and pre-training,\nsome approaches fine-tune LMs on large ICL-style datasets by an end-to-end\nparadigm with massive computational costs. To reduce such costs, in this paper,\nwe propose Attention Behavior Fine-Tuning (ABFT), utilizing the previous\nfindings on the inner mechanism of ICL, building training objectives on the\nattention scores instead of the final outputs, to force the attention scores to\nfocus on the correct label tokens presented in the context and mitigate\nattention scores from the wrong label tokens. Our experiments on 9 modern LMs\nand 8 datasets empirically find that ABFT outperforms in performance,\nrobustness, unbiasedness, and efficiency, with only around 0.01% data cost\ncompared to the previous methods. Moreover, our subsequent analysis finds that\nthe end-to-end training objective contains the ABFT objective, suggesting the\nimplicit bias of ICL-style data to the emergence of induction heads. Our work\ndemonstrates the possibility of controlling specific module sequences within\nLMs to improve their behavior, opening up the future application of mechanistic\ninterpretability."}
{"id": "2505.14521", "pdf": "https://arxiv.org/pdf/2505.14521", "abs": "https://arxiv.org/abs/2505.14521", "authors": ["Zhihao Li", "Yufei Wang", "Heliang Zheng", "Yihao Luo", "Bihan Wen"], "title": "SparC: Sparse Representation and Construction for High-Resolution 3D Shapes Modeling", "categories": ["cs.CV"], "comment": "Homepage: https://lizhihao6.github.io/SparC", "summary": "High-fidelity 3D object synthesis remains significantly more challenging than\n2D image generation due to the unstructured nature of mesh data and the cubic\ncomplexity of dense volumetric grids. Existing two-stage pipelines-compressing\nmeshes with a VAE (using either 2D or 3D supervision), followed by latent\ndiffusion sampling-often suffer from severe detail loss caused by inefficient\nrepresentations and modality mismatches introduced in VAE. We introduce SparC,\na unified framework that combines a sparse deformable marching cubes\nrepresentation SparseCubes with a novel encoder SparConv-VAE. SparseCubes\nconverts raw meshes into high-resolution ($1024^3$) surfaces with arbitrary\ntopology by scattering signed distance and deformation fields onto a sparse\ncube, allowing differentiable optimization. SparConv-VAE is the first\nmodality-consistent variational autoencoder built entirely upon sparse\nconvolutional networks, enabling efficient and near-lossless 3D reconstruction\nsuitable for high-resolution generative modeling through latent diffusion.\nSparC achieves state-of-the-art reconstruction fidelity on challenging inputs,\nincluding open surfaces, disconnected components, and intricate geometry. It\npreserves fine-grained shape details, reduces training and inference cost, and\nintegrates naturally with latent diffusion models for scalable, high-resolution\n3D generation."}
{"id": "2505.14033", "pdf": "https://arxiv.org/pdf/2505.14033", "abs": "https://arxiv.org/abs/2505.14033", "authors": ["Guoming Li", "Jian Yang", "Yifan Chen"], "title": "Partition-wise Graph Filtering: A Unified Perspective Through the Lens of Graph Coarsening", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "comment": "Accepted at the 31st ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining, KDD 2025 February Cycle", "summary": "Filtering-based graph neural networks (GNNs) constitute a distinct class of\nGNNs that employ graph filters to handle graph-structured data, achieving\nnotable success in various graph-related tasks. Conventional methods adopt a\ngraph-wise filtering paradigm, imposing a uniform filter across all nodes, yet\nrecent findings suggest that this rigid paradigm struggles with heterophilic\ngraphs. To overcome this, recent works have introduced node-wise filtering,\nwhich assigns distinct filters to individual nodes, offering enhanced\nadaptability. However, a fundamental gap remains: a comprehensive framework\nunifying these two strategies is still absent, limiting theoretical insights\ninto the filtering paradigms. Moreover, through the lens of Contextual\nStochastic Block Model, we reveal that a synthesis of graph-wise and node-wise\nfiltering provides a sufficient solution for classification on graphs\nexhibiting both homophily and heterophily, suggesting the risk of excessive\nparameterization and potential overfitting with node-wise filtering. To address\nthe limitations, this paper introduces Coarsening-guided Partition-wise\nFiltering (CPF). CPF innovates by performing filtering on node partitions. The\nmethod begins with structure-aware partition-wise filtering, which filters node\npartitions obtained via graph coarsening algorithms, and then performs\nfeature-aware partition-wise filtering, refining node embeddings via filtering\non clusters produced by $k$-means clustering over features. In-depth analysis\nis conducted for each phase of CPF, showing its superiority over other\nparadigms. Finally, benchmark node classification experiments, along with a\nreal-world graph anomaly detection application, validate CPF's efficacy and\npractical utility."}
{"id": "2505.11325", "pdf": "https://arxiv.org/pdf/2505.11325", "abs": "https://arxiv.org/abs/2505.11325", "authors": ["Thomas Nagler", "David R√ºgamer"], "title": "Uncertainty Quantification for Prior-Data Fitted Networks using Martingale Posteriors", "categories": ["stat.ME", "cs.AI", "cs.LG", "stat.CO", "stat.ML"], "comment": null, "summary": "Prior-data fitted networks (PFNs) have emerged as promising foundation models\nfor prediction from tabular data sets, achieving state-of-the-art performance\non small to moderate data sizes without tuning. While PFNs are motivated by\nBayesian ideas, they do not provide any uncertainty quantification for\npredictive means, quantiles, or similar quantities. We propose a principled and\nefficient sampling procedure to construct Bayesian posteriors for such\nestimates based on Martingale posteriors, and prove its convergence. Several\nsimulated and real-world data examples showcase the uncertainty quantification\nof our method in inference applications."}
{"id": "2505.14238", "pdf": "https://arxiv.org/pdf/2505.14238", "abs": "https://arxiv.org/abs/2505.14238", "authors": ["Raghav Singhal", "Kaustubh Ponkshe", "Rohit Vartak", "Praneeth Vepakomma"], "title": "ABBA: Highly Expressive Hadamard Product Adaptation for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Raghav Singhal, Kaustubh Ponkshe, and Rohit Vartak contributed\n  equally to this work", "summary": "Large Language Models have demonstrated strong performance across a wide\nrange of tasks, but adapting them efficiently to new domains remains a key\nchallenge. Parameter-Efficient Fine-Tuning (PEFT) methods address this by\nintroducing lightweight, trainable modules while keeping most pre-trained\nweights fixed. The prevailing approach, LoRA, models updates using a low-rank\ndecomposition, but its expressivity is inherently constrained by the rank.\nRecent methods like HiRA aim to increase expressivity by incorporating a\nHadamard product with the frozen weights, but still rely on the structure of\nthe pre-trained model. We introduce ABBA, a new PEFT architecture that\nreparameterizes the update as a Hadamard product of two independently learnable\nlow-rank matrices. In contrast to prior work, ABBA fully decouples the update\nfrom the pre-trained weights, enabling both components to be optimized freely.\nThis leads to significantly higher expressivity under the same parameter\nbudget. We formally analyze ABBA's expressive capacity and validate its\nadvantages through matrix reconstruction experiments. Empirically, ABBA\nachieves state-of-the-art results on arithmetic and commonsense reasoning\nbenchmarks, consistently outperforming existing PEFT methods by a significant\nmargin across multiple models. Our code is publicly available at:\nhttps://github.com/CERT-Lab/abba."}
{"id": "2505.14527", "pdf": "https://arxiv.org/pdf/2505.14527", "abs": "https://arxiv.org/abs/2505.14527", "authors": ["Nitish Shukla", "Arun Ross"], "title": "diffDemorph: Extending Reference-Free Demorphing to Unseen Faces", "categories": ["cs.CV"], "comment": null, "summary": "A face morph is created by combining two (or more) face images corresponding\nto two (or more) identities to produce a composite that successfully matches\nthe constituent identities. Reference-free (RF) demorphing reverses this\nprocess using only the morph image, without the need for additional reference\nimages. Previous RF demorphing methods were overly constrained, as they rely on\nassumptions about the distributions of training and testing morphs such as the\nmorphing technique used, face style, and images used to create the morph. In\nthis paper, we introduce a novel diffusion-based approach that effectively\ndisentangles component images from a composite morph image with high visual\nfidelity. Our method is the first to generalize across morph techniques and\nface styles, beating the current state of the art by $\\geq 59.46\\%$ under a\ncommon training protocol across all datasets tested. We train our method on\nmorphs created using synthetically generated face images and test on real\nmorphs, thereby enhancing the practicality of the technique. Experiments on six\ndatasets and two face matchers establish the utility and efficacy of our\nmethod."}
{"id": "2505.14036", "pdf": "https://arxiv.org/pdf/2505.14036", "abs": "https://arxiv.org/abs/2505.14036", "authors": ["Gyubin Lee", "Truong Nhat Nguyen Bao", "Jaesik Yoon", "Dongwoo Lee", "Minsu Kim", "Yoshua Bengio", "Sungjin Ahn"], "title": "Adaptive Cyclic Diffusion for Inference Scaling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models have demonstrated strong generative capabilities across\ndomains ranging from image synthesis to complex reasoning tasks. However, most\ninference-time scaling methods rely on fixed denoising schedules, limiting\ntheir ability to allocate computation based on instance difficulty or\ntask-specific demands adaptively. We introduce the challenge of adaptive\ninference-time scaling-dynamically adjusting computational effort during\ninference-and propose Adaptive Bi-directional Cyclic Diffusion (ABCD), a\nflexible, search-based inference framework. ABCD refines outputs through\nbi-directional diffusion cycles while adaptively controlling exploration depth\nand termination. It comprises three components: Cyclic Diffusion Search,\nAutomatic Exploration-Exploitation Balancing, and Adaptive Thinking Time.\nExperiments show that ABCD improves performance across diverse tasks while\nmaintaining computational efficiency."}
{"id": "2505.12257", "pdf": "https://arxiv.org/pdf/2505.12257", "abs": "https://arxiv.org/abs/2505.12257", "authors": ["Evgeny Markhasin"], "title": "LLM Context Conditioning and PWP Prompting for Multimodal Validation of Chemical Formulas", "categories": ["cs.CY", "cs.AI", "physics.chem-ph"], "comment": "10 pages", "summary": "Identifying subtle technical errors within complex scientific and technical\ndocuments, especially those requiring multimodal interpretation (e.g., formulas\nin images), presents a significant hurdle for Large Language Models (LLMs)\nwhose inherent error-correction tendencies can mask inaccuracies. This\nexploratory proof-of-concept (PoC) study investigates structured LLM context\nconditioning, informed by Persistent Workflow Prompting (PWP) principles, as a\nmethodological strategy to modulate this LLM behavior at inference time. The\napproach is designed to enhance the reliability of readily available,\ngeneral-purpose LLMs (specifically Gemini 2.5 Pro and ChatGPT Plus o3) for\nprecise validation tasks, crucially relying only on their standard chat\ninterfaces without API access or model modifications. To explore this\nmethodology, we focused on validating chemical formulas within a single,\ncomplex test paper with known textual and image-based errors. Several prompting\nstrategies were evaluated: while basic prompts proved unreliable, an approach\nadapting PWP structures to rigorously condition the LLM's analytical mindset\nappeared to improve textual error identification with both models. Notably,\nthis method also guided Gemini 2.5 Pro to repeatedly identify a subtle\nimage-based formula error previously overlooked during manual review, a task\nwhere ChatGPT Plus o3 failed in our tests. These preliminary findings highlight\nspecific LLM operational modes that impede detail-oriented validation and\nsuggest that PWP-informed context conditioning offers a promising and highly\naccessible technique for developing more robust LLM-driven analytical\nworkflows, particularly for tasks requiring meticulous error detection in\nscientific and technical documents. Extensive validation beyond this limited\nPoC is necessary to ascertain broader applicability."}
{"id": "2505.14242", "pdf": "https://arxiv.org/pdf/2505.14242", "abs": "https://arxiv.org/abs/2505.14242", "authors": ["Ziang Wang", "Amir Aryani"], "title": "Technical Report on classification of literature related to children speech disorder", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "This technical report presents a natural language processing (NLP)-based\napproach for systematically classifying scientific literature on childhood\nspeech disorders. We retrieved and filtered 4,804 relevant articles published\nafter 2015 from the PubMed database using domain-specific keywords. After\ncleaning and pre-processing the abstracts, we applied two topic modeling\ntechniques - Latent Dirichlet Allocation (LDA) and BERTopic - to identify\nlatent thematic structures in the corpus. Our models uncovered 14 clinically\nmeaningful clusters, such as infantile hyperactivity and abnormal epileptic\nbehavior. To improve relevance and precision, we incorporated a custom stop\nword list tailored to speech pathology. Evaluation results showed that the LDA\nmodel achieved a coherence score of 0.42 and a perplexity of -7.5, indicating\nstrong topic coherence and predictive performance. The BERTopic model exhibited\na low proportion of outlier topics (less than 20%), demonstrating its capacity\nto classify heterogeneous literature effectively. These results provide a\nfoundation for automating literature reviews in speech-language pathology."}
{"id": "2505.14537", "pdf": "https://arxiv.org/pdf/2505.14537", "abs": "https://arxiv.org/abs/2505.14537", "authors": ["Yuxuan Wang", "Xuanyu Yi", "Qingshan Xu", "Yuan Zhou", "Long Chen", "Hanwang Zhang"], "title": "Personalize Your Gaussian: Consistent 3D Scene Personalization from a Single Image", "categories": ["cs.CV"], "comment": "9 pages", "summary": "Personalizing 3D scenes from a single reference image enables intuitive\nuser-guided editing, which requires achieving both multi-view consistency\nacross perspectives and referential consistency with the input image. However,\nthese goals are particularly challenging due to the viewpoint bias caused by\nthe limited perspective provided in a single image. Lacking the mechanisms to\neffectively expand reference information beyond the original view, existing\nmethods of image-conditioned 3DGS personalization often suffer from this\nviewpoint bias and struggle to produce consistent results. Therefore, in this\npaper, we present Consistent Personalization for 3D Gaussian Splatting (CP-GS),\na framework that progressively propagates the single-view reference appearance\nto novel perspectives. In particular, CP-GS integrates pre-trained image-to-3D\ngeneration and iterative LoRA fine-tuning to extract and extend the reference\nappearance, and finally produces faithful multi-view guidance images and the\npersonalized 3DGS outputs through a view-consistent generation process guided\nby geometric cues. Extensive experiments on real-world scenes show that our\nCP-GS effectively mitigates the viewpoint bias, achieving high-quality\npersonalization that significantly outperforms existing methods. The code will\nbe released at https://github.com/Yuxuan-W/CP-GS."}
{"id": "2505.14039", "pdf": "https://arxiv.org/pdf/2505.14039", "abs": "https://arxiv.org/abs/2505.14039", "authors": ["Luca Pellegrini", "Massimiliano Ghiotto", "Edoardo Centofanti", "Luca Franco Pavarino"], "title": "Learning High-dimensional Ionic Model Dynamics Using Fourier Neural Operators", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": null, "summary": "Ionic models, described by systems of stiff ordinary differential equations,\nare fundamental tools for simulating the complex dynamics of excitable cells in\nboth Computational Neuroscience and Cardiology. Approximating these models\nusing Artificial Neural Networks poses significant challenges due to their\ninherent stiffness, multiscale nonlinearities, and the wide range of dynamical\nbehaviors they exhibit, including multiple equilibrium points, limit cycles,\nand intricate interactions. While in previous studies the dynamics of the\ntransmembrane potential has been predicted in low dimensionality settings, in\nthe present study we extend these results by investigating whether Fourier\nNeural Operators can effectively learn the evolution of all the state variables\nwithin these dynamical systems in higher dimensions. We demonstrate the\neffectiveness of this approach by accurately learning the dynamics of three\nwell-established ionic models with increasing dimensionality: the two-variable\nFitzHugh-Nagumo model, the four-variable Hodgkin-Huxley model, and the\nforty-one-variable O'Hara-Rudy model. To ensure the selection of near-optimal\nconfigurations for the Fourier Neural Operator, we conducted automatic\nhyperparameter tuning under two scenarios: an unconstrained setting, where the\nnumber of trainable parameters is not limited, and a constrained case with a\nfixed number of trainable parameters. Both constrained and unconstrained\narchitectures achieve comparable results in terms of accuracy across all the\nmodels considered. However, the unconstrained architecture required\napproximately half the number of training epochs to achieve similar error\nlevels, as evidenced by the loss function values recorded during training.\nThese results underline the capabilities of Fourier Neural Operators to\naccurately capture complex multiscale dynamics, even in high-dimensional\ndynamical systems."}
{"id": "2505.12392", "pdf": "https://arxiv.org/pdf/2505.12392", "abs": "https://arxiv.org/abs/2505.12392", "authors": ["Yang Hu", "Xingyu Zhang", "Xueji Fang", "Zhiyang Chen", "Xiao Wang", "Huatian Zhang", "Guojun Qi"], "title": "SLOT: Sample-specific Language Model Optimization at Test-time", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose SLOT (Sample-specific Language Model Optimization at Test-time), a\nnovel and parameter-efficient test-time inference approach that enhances a\nlanguage model's ability to more accurately respond to individual prompts.\nExisting Large Language Models (LLMs) often struggle with complex instructions,\nleading to poor performances on those not well represented among general\nsamples. To address this, SLOT conducts few optimization steps at test-time to\nupdate a light-weight sample-specific parameter vector. It is added to the\nfinal hidden layer before the output head, and enables efficient adaptation by\ncaching the last layer features during per-sample optimization. By minimizing\nthe cross-entropy loss on the input prompt only, SLOT helps the model better\naligned with and follow each given instruction. In experiments, we demonstrate\nthat our method outperforms the compared models across multiple benchmarks and\nLLMs. For example, Qwen2.5-7B with SLOT achieves an accuracy gain of 8.6% on\nGSM8K from 57.54% to 66.19%, while DeepSeek-R1-Distill-Llama-70B with SLOT\nachieves a SOTA accuracy of 68.69% on GPQA among 70B-level models. Our code is\navailable at https://github.com/maple-research-lab/SLOT."}
{"id": "2505.14244", "pdf": "https://arxiv.org/pdf/2505.14244", "abs": "https://arxiv.org/abs/2505.14244", "authors": ["Haijun Li", "Tianqi Shi", "Zifu Shang", "Yuxuan Han", "Xueyu Zhao", "Hao Wang", "Yu Qian", "Zhiqiang Qian", "Linlong Xu", "Minghao Wu", "Chenyang Lyu", "Longyue Wang", "Gongbo Tang", "Weihua Luo", "Zhao Xu", "Kaifu Zhang"], "title": "TransBench: Benchmarking Machine Translation for Industrial-Scale Applications", "categories": ["cs.CL"], "comment": null, "summary": "Machine translation (MT) has become indispensable for cross-border\ncommunication in globalized industries like e-commerce, finance, and legal\nservices, with recent advancements in large language models (LLMs)\nsignificantly enhancing translation quality. However, applying general-purpose\nMT models to industrial scenarios reveals critical limitations due to\ndomain-specific terminology, cultural nuances, and stylistic conventions absent\nin generic benchmarks. Existing evaluation frameworks inadequately assess\nperformance in specialized contexts, creating a gap between academic benchmarks\nand real-world efficacy. To address this, we propose a three-level translation\ncapability framework: (1) Basic Linguistic Competence, (2) Domain-Specific\nProficiency, and (3) Cultural Adaptation, emphasizing the need for holistic\nevaluation across these dimensions. We introduce TransBench, a benchmark\ntailored for industrial MT, initially targeting international e-commerce with\n17,000 professionally translated sentences spanning 4 main scenarios and 33\nlanguage pairs. TransBench integrates traditional metrics (BLEU, TER) with\nMarco-MOS, a domain-specific evaluation model, and provides guidelines for\nreproducible benchmark construction. Our contributions include: (1) a\nstructured framework for industrial MT evaluation, (2) the first publicly\navailable benchmark for e-commerce translation, (3) novel metrics probing\nmulti-level translation quality, and (4) open-sourced evaluation tools. This\nwork bridges the evaluation gap, enabling researchers and practitioners to\nsystematically assess and enhance MT systems for industry-specific needs."}
{"id": "2505.14556", "pdf": "https://arxiv.org/pdf/2505.14556", "abs": "https://arxiv.org/abs/2505.14556", "authors": ["Marl√®ne Careil", "Yohann Benchetrit", "Jean-R√©mi King"], "title": "Dynadiff: Single-stage Decoding of Images from Continuously Evolving fMRI", "categories": ["cs.CV"], "comment": null, "summary": "Brain-to-image decoding has been recently propelled by the progress in\ngenerative AI models and the availability of large ultra-high field functional\nMagnetic Resonance Imaging (fMRI). However, current approaches depend on\ncomplicated multi-stage pipelines and preprocessing steps that typically\ncollapse the temporal dimension of brain recordings, thereby limiting\ntime-resolved brain decoders. Here, we introduce Dynadiff (Dynamic Neural\nActivity Diffusion for Image Reconstruction), a new single-stage diffusion\nmodel designed for reconstructing images from dynamically evolving fMRI\nrecordings. Our approach offers three main contributions. First, Dynadiff\nsimplifies training as compared to existing approaches. Second, our model\noutperforms state-of-the-art models on time-resolved fMRI signals, especially\non high-level semantic image reconstruction metrics, while remaining\ncompetitive on preprocessed fMRI data that collapse time. Third, this approach\nallows a precise characterization of the evolution of image representations in\nbrain activity. Overall, this work lays the foundation for time-resolved\nbrain-to-image decoding."}
{"id": "2505.14040", "pdf": "https://arxiv.org/pdf/2505.14040", "abs": "https://arxiv.org/abs/2505.14040", "authors": ["Jingyun Zhang", "Hao Peng", "Li Sun", "Guanlin Wu", "Chunyang Liu", "Zhengtao Yu"], "title": "Unsupervised Graph Clustering with Deep Structural Entropy", "categories": ["cs.LG"], "comment": "Accepted to Proceedings of the ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining 2025 (KDD 2025). 13 pages, 10 figures, 11 tables", "summary": "Research on Graph Structure Learning (GSL) provides key insights for\ngraph-based clustering, yet current methods like Graph Neural Networks (GNNs),\nGraph Attention Networks (GATs), and contrastive learning often rely heavily on\nthe original graph structure. Their performance deteriorates when the original\ngraph's adjacency matrix is too sparse or contains noisy edges unrelated to\nclustering. Moreover, these methods depend on learning node embeddings and\nusing traditional techniques like k-means to form clusters, which may not fully\ncapture the underlying graph structure between nodes. To address these\nlimitations, this paper introduces DeSE, a novel unsupervised graph clustering\nframework incorporating Deep Structural Entropy. It enhances the original graph\nwith quantified structural information and deep neural networks to form\nclusters. Specifically, we first propose a method for calculating structural\nentropy with soft assignment, which quantifies structure in a differentiable\nform. Next, we design a Structural Learning layer (SLL) to generate an\nattributed graph from the original feature data, serving as a target to enhance\nand optimize the original structural graph, thereby mitigating the issue of\nsparse connections between graph nodes. Finally, our clustering assignment\nmethod (ASS), based on GNNs, learns node embeddings and a soft assignment\nmatrix to cluster on the enhanced graph. The ASS layer can be stacked to meet\ndownstream task requirements, minimizing structural entropy for stable\nclustering and maximizing node consistency with edge-based cross-entropy loss.\nExtensive comparative experiments are conducted on four benchmark datasets\nagainst eight representative unsupervised graph clustering baselines,\ndemonstrating the superiority of the DeSE in both effectiveness and\ninterpretability."}
{"id": "2505.13453", "pdf": "https://arxiv.org/pdf/2505.13453", "abs": "https://arxiv.org/abs/2505.13453", "authors": ["Behnam Mohammadi"], "title": "Pel, A Programming Language for Orchestrating AI Agents", "categories": ["cs.PL", "cs.AI", "cs.ET"], "comment": "Added relevant figures and the section 4.5", "summary": "The proliferation of Large Language Models (LLMs) has opened new frontiers in\ncomputing, yet controlling and orchestrating their capabilities beyond simple\ntext generation remains a challenge. Current methods, such as function/tool\ncalling and direct code generation, suffer from limitations in expressiveness,\nscalability, cost, security, and the ability to enforce fine-grained control.\nThis paper introduces Pel, a novel programming language specifically designed\nto bridge this gap. Inspired by the strengths of Lisp, Elixir, Gleam, and\nHaskell, Pel provides a syntactically simple, homoiconic, and semantically rich\nplatform for LLMs to express complex actions, control flow, and inter-agent\ncommunication safely and efficiently. Pel's design emphasizes a minimal, easily\nmodifiable grammar suitable for constrained LLM generation, eliminating the\nneed for complex sandboxing by enabling capability control at the syntax level.\nKey features include a powerful piping mechanism for linear composition,\nfirst-class closures enabling easy partial application and functional patterns,\nbuilt-in support for natural language conditions evaluated by LLMs, and an\nadvanced Read-Eval-Print-Loop (REPeL) with Common Lisp-style restarts and\nLLM-powered helper agents for automated error correction. Furthermore, Pel\nincorporates automatic parallelization of independent operations via static\ndependency analysis, crucial for performant agentic systems. We argue that Pel\noffers a more robust, secure, and expressive paradigm for LLM orchestration,\npaving the way for more sophisticated and reliable AI agentic frameworks."}
{"id": "2505.14256", "pdf": "https://arxiv.org/pdf/2505.14256", "abs": "https://arxiv.org/abs/2505.14256", "authors": ["Shaolin Zhu", "Tianyu Dong", "Bo Li", "Deyi Xiong"], "title": "FuxiMT: Sparsifying Large Language Models for Chinese-Centric Multilingual Machine Translation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this paper, we present FuxiMT, a novel Chinese-centric multilingual\nmachine translation model powered by a sparsified large language model (LLM).\nWe adopt a two-stage strategy to train FuxiMT. We first pre-train the model on\na massive Chinese corpus and then conduct multilingual fine-tuning on a large\nparallel dataset encompassing 65 languages. FuxiMT incorporates\nMixture-of-Experts (MoEs) and employs a curriculum learning strategy for robust\nperformance across various resource levels. Experimental results demonstrate\nthat FuxiMT significantly outperforms strong baselines, including\nstate-of-the-art LLMs and machine translation models, particularly under\nlow-resource scenarios. Furthermore, FuxiMT exhibits remarkable zero-shot\ntranslation capabilities for unseen language pairs, indicating its potential to\nbridge communication gaps where parallel data are scarce or unavailable."}
{"id": "2505.14583", "pdf": "https://arxiv.org/pdf/2505.14583", "abs": "https://arxiv.org/abs/2505.14583", "authors": ["Abhimanyu Talwar", "Julien Laasri"], "title": "Instance Segmentation for Point Sets", "categories": ["cs.CV", "cs.LG", "68T45", "I.2.10"], "comment": "6 pages, 11 figures, paper dated 2019", "summary": "Recently proposed neural network architectures like PointNet [QSMG16] and\nPointNet++ [QYSG17] have made it possible to apply Deep Learning to 3D point\nsets. The feature representations of shapes learned by these two networks\nenabled training classifiers for Semantic Segmentation, and more recently for\nInstance Segmentation via the Similarity Group Proposal Network (SGPN)\n[WYHN17]. One area of improvement which has been highlighted by SGPN's authors,\npertains to use of memory intensive similarity matrices which occupy memory\nquadratic in the number of points. In this report, we attempt to tackle this\nissue through use of two sampling based methods, which compute Instance\nSegmentation on a sub-sampled Point Set, and then extrapolate labels to the\ncomplete set using the nearest neigbhour approach. While both approaches\nperform equally well on large sub-samples, the random-based strategy gives the\nmost improvements in terms of speed and memory usage."}
{"id": "2505.14042", "pdf": "https://arxiv.org/pdf/2505.14042", "abs": "https://arxiv.org/abs/2505.14042", "authors": ["Soichiro Kumano", "Hiroshi Kera", "Toshihiko Yamasaki"], "title": "Adversarially Pretrained Transformers may be Universally Robust In-Context Learners", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Adversarial training is one of the most effective adversarial defenses, but\nit incurs a high computational cost. In this study, we show that transformers\nadversarially pretrained on diverse tasks can serve as robust foundation models\nand eliminate the need for adversarial training in downstream tasks.\nSpecifically, we theoretically demonstrate that through in-context learning, a\nsingle adversarially pretrained transformer can robustly generalize to multiple\nunseen tasks without any additional training, i.e., without any parameter\nupdates. This robustness stems from the model's focus on robust features and\nits resistance to attacks that exploit non-predictive features. Besides these\npositive findings, we also identify several limitations. Under certain\nconditions (though unrealistic), no universally robust single-layer\ntransformers exist. Moreover, robust transformers exhibit an\naccuracy--robustness trade-off and require a large number of in-context\ndemonstrations. The code is available at\nhttps://github.com/s-kumano/universally-robust-in-context-learner."}
{"id": "2505.13469", "pdf": "https://arxiv.org/pdf/2505.13469", "abs": "https://arxiv.org/abs/2505.13469", "authors": ["Aayam Bansal", "Harsh Vardhan Narsaria"], "title": "Algorithmic Tradeoffs in Fair Lending: Profitability, Compliance, and Long-Term Impact", "categories": ["cs.CY", "cs.AI", "cs.CE", "cs.LG"], "comment": "8 pages", "summary": "As financial institutions increasingly rely on machine learning models to\nautomate lending decisions, concerns about algorithmic fairness have risen.\nThis paper explores the tradeoff between enforcing fairness constraints (such\nas demographic parity or equal opportunity) and maximizing lender\nprofitability. Through simulations on synthetic data that reflects real-world\nlending patterns, we quantify how different fairness interventions impact\nprofit margins and default rates. Our results demonstrate that equal\nopportunity constraints typically impose lower profit costs than demographic\nparity, but surprisingly, removing protected attributes from the model\n(fairness through unawareness) outperforms explicit fairness interventions in\nboth fairness and profitability metrics. We further identify the specific\neconomic conditions under which fair lending becomes profitable and analyze the\nfeature-specific drivers of unfairness. These findings offer practical guidance\nfor designing lending algorithms that balance ethical considerations with\nbusiness objectives."}
{"id": "2505.14268", "pdf": "https://arxiv.org/pdf/2505.14268", "abs": "https://arxiv.org/abs/2505.14268", "authors": ["Hui Huang", "Yancheng He", "Hongli Zhou", "Rui Zhang", "Wei Liu", "Weixun Wang", "Wenbo Su", "Bo Zheng", "Jiaheng Liu"], "title": "Think-J: Learning to Think for Generative LLM-as-a-Judge", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 14 figures", "summary": "LLM-as-a-Judge refers to the automatic modeling of preferences for responses\ngenerated by Large Language Models (LLMs), which is of significant importance\nfor both LLM evaluation and reward modeling. Although generative LLMs have made\nsubstantial progress in various tasks, their performance as LLM-Judge still\nfalls short of expectations. In this work, we propose Think-J, which improves\ngenerative LLM-as-a-Judge by learning how to think. We first utilized a small\namount of curated data to develop the model with initial judgment thinking\ncapabilities. Subsequently, we optimize the judgment thinking traces based on\nreinforcement learning (RL). We propose two methods for judgment thinking\noptimization, based on offline and online RL, respectively. The offline RL\nrequires training a critic model to construct positive and negative examples\nfor learning. The online method defines rule-based reward as feedback for\noptimization. Experimental results showed that our approach can significantly\nenhance the evaluation capability of generative LLM-Judge, surpassing both\ngenerative and classifier-based LLM-Judge without requiring extra human\nannotations."}
{"id": "2505.14621", "pdf": "https://arxiv.org/pdf/2505.14621", "abs": "https://arxiv.org/abs/2505.14621", "authors": ["Abhimanyu Talwar", "Julien Laasri"], "title": "3D Reconstruction from Sketches", "categories": ["cs.CV", "cs.LG", "68T45", "I.2.10"], "comment": "6 pages, 8 figures, paper dated December 12, 2018", "summary": "We consider the problem of reconstructing a 3D scene from multiple sketches.\nWe propose a pipeline which involves (1) stitching together multiple sketches\nthrough use of correspondence points, (2) converting the stitched sketch into a\nrealistic image using a CycleGAN, and (3) estimating that image's depth-map\nusing a pre-trained convolutional neural network based architecture called\nMegaDepth. Our contribution includes constructing a dataset of image-sketch\npairs, the images for which are from the Zurich Building Database, and sketches\nhave been generated by us. We use this dataset to train a CycleGAN for our\npipeline's second step. We end up with a stitching process that does not\ngeneralize well to real drawings, but the rest of the pipeline that creates a\n3D reconstruction from a single sketch performs quite well on a wide variety of\ndrawings."}
{"id": "2505.14044", "pdf": "https://arxiv.org/pdf/2505.14044", "abs": "https://arxiv.org/abs/2505.14044", "authors": ["Luyao Tang", "Kunze Huang", "Chaoqi Chen", "Cheng Chen"], "title": "Generalized Category Discovery via Token Manifold Capacity Learning", "categories": ["cs.LG"], "comment": null, "summary": "Generalized category discovery (GCD) is essential for improving deep learning\nmodels' robustness in open-world scenarios by clustering unlabeled data\ncontaining both known and novel categories. Traditional GCD methods focus on\nminimizing intra-cluster variations, often sacrificing manifold capacity, which\nlimits the richness of intra-class representations. In this paper, we propose a\nnovel approach, Maximum Token Manifold Capacity (MTMC), that prioritizes\nmaximizing the manifold capacity of class tokens to preserve the diversity and\ncomplexity of data. MTMC leverages the nuclear norm of singular values as a\nmeasure of manifold capacity, ensuring that the representation of samples\nremains informative and well-structured. This method enhances the\ndiscriminability of clusters, allowing the model to capture detailed semantic\nfeatures and avoid the loss of critical information during clustering. Through\ntheoretical analysis and extensive experiments on coarse- and fine-grained\ndatasets, we demonstrate that MTMC outperforms existing GCD methods, improving\nboth clustering accuracy and the estimation of category numbers. The\nintegration of MTMC leads to more complete representations, better inter-class\nseparability, and a reduction in dimensional collapse, establishing MTMC as a\nvital component for robust open-world learning. Code is in\ngithub.com/lytang63/MTMC."}
{"id": "2505.13497", "pdf": "https://arxiv.org/pdf/2505.13497", "abs": "https://arxiv.org/abs/2505.13497", "authors": ["Claudius Kienle", "Benjamin Alt", "Oleg Arenz", "Jan Peters"], "title": "LODGE: Joint Hierarchical Task Planning and Learning of Domain Models with Grounded Execution", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) enable planning from natural language\ninstructions using implicit world knowledge, but often produce flawed plans\nthat require refinement. Instead of directly predicting plans, recent methods\naim to learn a problem domain that can be solved for different goal states\nusing classical planners. However, these approaches require significant human\nfeedback to obtain useful models. We address this shortcoming by learning\nhierarchical domains, where low-level predicates and actions are composed into\nhigher-level counterparts, and by leveraging simulation to validate their\npreconditions and effects. This hierarchical approach is particularly powerful\nfor long-horizon planning, where LLM-based planning approaches typically\nstruggle. Furthermore, we introduce a central error reasoner to ensure\nconsistency among the different planning levels. Evaluation on two challenging\nInternational Planning Competition (IPC) domains and a long-horizon robot\nmanipulation task demonstrates higher planning success rates than\nstate-of-the-art domain synthesis and LLM-modulo planning methods, while\nconstructing high-quality models of the domain. Resources, videos and detailed\nexperiment results are available at https://claudius-kienle.github.io/lodge/."}
{"id": "2505.14271", "pdf": "https://arxiv.org/pdf/2505.14271", "abs": "https://arxiv.org/abs/2505.14271", "authors": ["Minh Ngoc Ta", "Dong Cao Van", "Duc-Anh Hoang", "Minh Le-Anh", "Truong Nguyen", "My Anh Tran Nguyen", "Yuxia Wang", "Preslav Nakov", "Sang Dinh"], "title": "FAID: Fine-grained AI-generated Text Detection using Multi-task Auxiliary and Multi-level Contrastive Learning", "categories": ["cs.CL"], "comment": null, "summary": "The growing collaboration between humans and AI models in generative tasks\nhas introduced new challenges in distinguishing between human-written,\nAI-generated, and human-AI collaborative texts. In this work, we collect a\nmultilingual, multi-domain, multi-generator dataset FAIDSet. We further\nintroduce a fine-grained detection framework FAID to classify text into these\nthree categories, meanwhile identifying the underlying AI model family. Unlike\nexisting binary classifiers, FAID is built to capture both authorship and\nmodel-specific characteristics. Our method combines multi-level contrastive\nlearning with multi-task auxiliary classification to learn subtle stylistic\ncues. By modeling AI families as distinct stylistic entities, FAID offers\nimproved interpretability. We incorporate an adaptation to address\ndistributional shifts without retraining for unseen data. Experimental results\ndemonstrate that FAID outperforms several baseline approaches, particularly\nenhancing the generalization accuracy on unseen domains and new AI models. It\nprovide a potential solution for improving transparency and accountability in\nAI-assisted writing."}
{"id": "2505.14638", "pdf": "https://arxiv.org/pdf/2505.14638", "abs": "https://arxiv.org/abs/2505.14638", "authors": ["Tomer Gafni", "Asaf Karnieli", "Yair Hanani"], "title": "Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "Accepted at eLVM Workshop, CVPR, 2025", "summary": "Deep neural networks have achieved state-of-the-art results in a wide range\nof applications, from natural language processing and computer vision to speech\nrecognition. However, as tasks become increasingly complex, model sizes\ncontinue to grow, posing challenges in latency and memory efficiency. To meet\nthese constraints, post-training quantization has emerged as a promising\nsolution. In this paper, we propose a novel hardware-efficient quantization and\ninference scheme that exploits hardware advantages with minimal accuracy\ndegradation. Specifically, we introduce a W4A8 scheme, where weights are\nquantized and stored using 4-bit integer precision, and inference computations\nare performed using 8-bit floating-point arithmetic, demonstrating significant\nspeedups and improved memory utilization compared to 16-bit operations,\napplicable on various modern accelerators. To mitigate accuracy loss, we\ndevelop a novel quantization algorithm, dubbed Dual Precision Quantization\n(DPQ), that leverages the unique structure of our scheme without introducing\nadditional inference overhead. Experimental results demonstrate improved\nperformance (i.e., increased throughput) while maintaining tolerable accuracy\ndegradation relative to the full-precision model."}
{"id": "2505.14071", "pdf": "https://arxiv.org/pdf/2505.14071", "abs": "https://arxiv.org/abs/2505.14071", "authors": ["Woody Haosheng Gan", "Deqing Fu", "Julian Asilis", "Ollie Liu", "Dani Yogatama", "Vatsal Sharan", "Robin Jia", "Willie Neiswanger"], "title": "Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "Steering methods have emerged as effective and targeted tools for guiding\nlarge language models' (LLMs) behavior without modifying their parameters.\nMultimodal large language models (MLLMs), however, do not currently enjoy the\nsame suite of techniques, due in part to their recency and architectural\ndiversity. Inspired by this gap, we investigate whether MLLMs can be steered\nusing vectors derived from their text-only LLM backbone, via sparse\nautoencoders (SAEs), mean shift, and linear probing. We find that text-derived\nsteering consistently enhances multimodal accuracy across diverse MLLM\narchitectures and visual tasks. In particular, mean shift boosts spatial\nrelationship accuracy on CV-Bench by up to +7.3% and counting accuracy by up to\n+3.3%, outperforming prompting and exhibiting strong generalization to\nout-of-distribution datasets. These results highlight textual steering vectors\nas a powerful, efficient mechanism for enhancing grounding in MLLMs with\nminimal additional data collection and computational overhead."}
{"id": "2505.14279", "pdf": "https://arxiv.org/pdf/2505.14279", "abs": "https://arxiv.org/abs/2505.14279", "authors": ["Jennifer D'Souza", "Hamed Babaei Giglou", "Quentin M√ºnch"], "title": "YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 3 figures, Accepted as a Long Paper at the 63rd Annual\n  Meeting of the Association for Computational Linguistics (ACL 2025)", "summary": "Large Language Models (LLMs) drive scientific question-answering on modern\nsearch engines, yet their evaluation robustness remains underexplored. We\nintroduce YESciEval, an open-source framework that combines fine-grained\nrubric-based assessment with reinforcement learning to mitigate optimism bias\nin LLM evaluators. We release multidisciplinary scienceQ&A datasets, including\nadversarial variants, with evaluation scores from multiple LLMs. Independent of\nproprietary models and human feedback, our approach enables scalable, cost-free\nevaluation. By advancing reliable LLM-as-a-judge models, this work supports AI\nalignment and fosters robust, transparent evaluation essential for scientific\ninquiry and artificial general intelligence."}
{"id": "2505.14640", "pdf": "https://arxiv.org/pdf/2505.14640", "abs": "https://arxiv.org/abs/2505.14640", "authors": ["Wentao Ma", "Weiming Ren", "Yiming Jia", "Zhuofeng Li", "Ping Nie", "Ge Zhang", "Wenhu Chen"], "title": "VideoEval-Pro: Robust and Realistic Long Video Understanding Evaluation", "categories": ["cs.CV"], "comment": "Dataset: https://huggingface.co/datasets/TIGER-Lab/VideoEval-Pro,\n  Project Webpage: https://tiger-ai-lab.github.io/VideoEval-Pro", "summary": "Large multimodal models (LMMs) have recently emerged as a powerful tool for\nlong video understanding (LVU), prompting the development of standardized LVU\nbenchmarks to evaluate their performance. However, our investigation reveals a\nrather sober lesson for existing LVU benchmarks. First, most existing\nbenchmarks rely heavily on multiple-choice questions (MCQs), whose evaluation\nresults are inflated due to the possibility of guessing the correct answer;\nSecond, a significant portion of questions in these benchmarks have strong\npriors to allow models to answer directly without even reading the input video.\nFor example, Gemini-1.5-Pro can achieve over 50\\% accuracy given a random frame\nfrom a long video on Video-MME. We also observe that increasing the number of\nframes does not necessarily lead to improvement on existing benchmarks, which\nis counterintuitive. As a result, the validity and robustness of current LVU\nbenchmarks are undermined, impeding a faithful assessment of LMMs' long-video\nunderstanding capability. To tackle this problem, we propose VideoEval-Pro, a\nrealistic LVU benchmark containing questions with open-ended short-answer,\nwhich truly require understanding the entire video. VideoEval-Pro assesses both\nsegment-level and full-video understanding through perception and reasoning\ntasks. By evaluating 21 proprietary and open-source video LMMs, we conclude the\nfollowing findings: (1) video LMMs show drastic performance ($>$25\\%) drops on\nopen-ended questions compared with MCQs; (2) surprisingly, higher MCQ scores do\nnot lead to higher open-ended scores on VideoEval-Pro; (3) compared to other\nMCQ benchmarks, VideoEval-Pro benefits more from increasing the number of input\nframes. Our results show that VideoEval-Pro offers a more realistic and\nreliable measure of long video understanding, providing a clearer view of\nprogress in this domain."}
{"id": "2505.14117", "pdf": "https://arxiv.org/pdf/2505.14117", "abs": "https://arxiv.org/abs/2505.14117", "authors": ["Xinyi Shang", "Peng Sun", "Fengyuan Liu", "Tao Lin"], "title": "Collaborative Unlabeled Data Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper pioneers a novel data-centric paradigm to maximize the utility of\nunlabeled data, tackling a critical question: How can we enhance the efficiency\nand sustainability of deep learning training by optimizing the data itself? We\nbegin by identifying three key limitations in existing model-centric\napproaches, all rooted in a shared bottleneck: knowledge extracted from data is\nlocked to model parameters, hindering its reusability and scalability. To this\nend, we propose CoOpt, a highly efficient, parallelized framework for\ncollaborative unlabeled data optimization, thereby effectively encoding\nknowledge into the data itself. By distributing unlabeled data and leveraging\npublicly available task-agnostic models, CoOpt facilitates scalable, reusable,\nand sustainable training pipelines. Extensive experiments across diverse\ndatasets and architectures demonstrate its efficacy and efficiency, achieving\n13.6% and 6.8% improvements on Tiny-ImageNet and ImageNet-1K, respectively,\nwith training speedups of $1.94 \\times $ and $1.2 \\times$."}
{"id": "2505.13518", "pdf": "https://arxiv.org/pdf/2505.13518", "abs": "https://arxiv.org/abs/2505.13518", "authors": ["Behnam Yousefimehr", "Mehdi Ghatee", "Mohammad Amin Seifi", "Javad Fazli", "Sajed Tavakoli", "Zahra Rafei", "Shervin Ghaffari", "Abolfazl Nikahd", "Mahdi Razi Gandomani", "Alireza Orouji", "Ramtin Mahmoudi Kashani", "Sarina Heshmati", "Negin Sadat Mousavi"], "title": "Data Balancing Strategies: A Survey of Resampling and Augmentation Methods", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Imbalanced data poses a significant obstacle in machine learning, as an\nunequal distribution of class labels often results in skewed predictions and\ndiminished model accuracy. To mitigate this problem, various resampling\nstrategies have been developed, encompassing both oversampling and\nundersampling techniques aimed at modifying class proportions. Conventional\noversampling approaches like SMOTE enhance the representation of the minority\nclass, whereas undersampling methods focus on trimming down the majority class.\nAdvances in deep learning have facilitated the creation of more complex\nsolutions, such as Generative Adversarial Networks (GANs) and Variational\nAutoencoders (VAEs), which are capable of producing high-quality synthetic\nexamples. This paper reviews a broad spectrum of data balancing methods,\nclassifying them into categories including synthetic oversampling, adaptive\ntechniques, generative models, ensemble-based strategies, hybrid approaches,\nundersampling, and neighbor-based methods. Furthermore, it highlights current\ndevelopments in resampling techniques and discusses practical implementations\nand case studies that validate their effectiveness. The paper concludes by\noffering perspectives on potential directions for future exploration in this\ndomain."}
{"id": "2505.14297", "pdf": "https://arxiv.org/pdf/2505.14297", "abs": "https://arxiv.org/abs/2505.14297", "authors": ["Jungseob Lee", "Seongtae Hong", "Hyeonseok Moon", "Heuiseok Lim"], "title": "Cross-Lingual Optimization for Language Transfer in Large Language Models", "categories": ["cs.CL"], "comment": "Accepted for publication at ACL 2025. Jungseob Lee and Seongtae Hong\n  contributed equally to this work", "summary": "Adapting large language models to other languages typically employs\nsupervised fine-tuning (SFT) as a standard approach. However, it often suffers\nfrom an overemphasis on English performance, a phenomenon that is especially\npronounced in data-constrained environments. To overcome these challenges, we\npropose \\textbf{Cross-Lingual Optimization (CLO)} that efficiently transfers an\nEnglish-centric LLM to a target language while preserving its English\ncapabilities. CLO utilizes publicly available English SFT data and a\ntranslation model to enable cross-lingual transfer. We conduct experiments\nusing five models on six languages, each possessing varying levels of resource.\nOur results show that CLO consistently outperforms SFT in both acquiring target\nlanguage proficiency and maintaining English performance. Remarkably, in\nlow-resource languages, CLO with only 3,200 samples surpasses SFT with 6,400\nsamples, demonstrating that CLO can achieve better performance with less data.\nFurthermore, we find that SFT is particularly sensitive to data quantity in\nmedium and low-resource languages, whereas CLO remains robust. Our\ncomprehensive analysis emphasizes the limitations of SFT and incorporates\nadditional training strategies in CLO to enhance efficiency."}
{"id": "2505.14646", "pdf": "https://arxiv.org/pdf/2505.14646", "abs": "https://arxiv.org/abs/2505.14646", "authors": ["Anna C. Doris", "Md Ferdous Alam", "Amin Heyrani Nobari", "Faez Ahmed"], "title": "CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Efficient creation of accurate and editable 3D CAD models is critical in\nengineering design, significantly impacting cost and time-to-market in product\ninnovation. Current manual workflows remain highly time-consuming and demand\nextensive user expertise. While recent developments in AI-driven CAD generation\nshow promise, existing models are limited by incomplete representations of CAD\noperations, inability to generalize to real-world images, and low output\naccuracy. This paper introduces CAD-Coder, an open-source Vision-Language Model\n(VLM) explicitly fine-tuned to generate editable CAD code (CadQuery Python)\ndirectly from visual input. Leveraging a novel dataset that we\ncreated--GenCAD-Code, consisting of over 163k CAD-model image and code\npairs--CAD-Coder outperforms state-of-the-art VLM baselines such as GPT-4.5 and\nQwen2.5-VL-72B, achieving a 100% valid syntax rate and the highest accuracy in\n3D solid similarity. Notably, our VLM demonstrates some signs of\ngeneralizability, successfully generating CAD code from real-world images and\nexecuting CAD operations unseen during fine-tuning. The performance and\nadaptability of CAD-Coder highlights the potential of VLMs fine-tuned on code\nto streamline CAD workflows for engineers and designers. CAD-Coder is publicly\navailable at: https://github.com/anniedoris/CAD-Coder."}
{"id": "2505.14122", "pdf": "https://arxiv.org/pdf/2505.14122", "abs": "https://arxiv.org/abs/2505.14122", "authors": ["Ehsan Masoudian", "Ali Mirzaei", "Hossein Bagheri"], "title": "Assessing wildfire susceptibility in Iran: Leveraging machine learning for geospatial analysis of climatic and anthropogenic factors", "categories": ["cs.LG"], "comment": null, "summary": "This study investigates the multifaceted factors influencing wildfire risk in\nIran, focusing on the interplay between climatic conditions and human\nactivities. Utilizing advanced remote sensing, geospatial information system\n(GIS) processing techniques such as cloud computing, and machine learning\nalgorithms, this research analyzed the impact of climatic parameters,\ntopographic features, and human-related factors on wildfire susceptibility\nassessment and prediction in Iran. Multiple scenarios were developed for this\npurpose based on the data sampling strategy. The findings revealed that\nclimatic elements such as soil moisture, temperature, and humidity\nsignificantly contribute to wildfire susceptibility, while human\nactivities-particularly population density and proximity to powerlines-also\nplayed a crucial role. Furthermore, the seasonal impact of each parameter was\nseparately assessed during warm and cold seasons. The results indicated that\nhuman-related factors, rather than climatic variables, had a more prominent\ninfluence during the seasonal analyses. This research provided new insights\ninto wildfire dynamics in Iran by generating high-resolution wildfire\nsusceptibility maps using advanced machine learning classifiers. The generated\nmaps identified high risk areas, particularly in the central Zagros region, the\nnortheastern Hyrcanian Forest, and the northern Arasbaran forest, highlighting\nthe urgent need for effective fire management strategies."}
{"id": "2505.13519", "pdf": "https://arxiv.org/pdf/2505.13519", "abs": "https://arxiv.org/abs/2505.13519", "authors": ["Zekun Cai", "Yiheng Yao", "Guangji Bai", "Renhe Jiang", "Xuan Song", "Ryosuke Shibasaki", "Liang Zhao"], "title": "Continuous Domain Generalization", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "22 pages, 9 figures", "summary": "Real-world data distributions often shift continuously across multiple latent\nfactors such as time, geography, and socioeconomic context. However, existing\ndomain generalization approaches typically treat domains as discrete or\nevolving along a single axis (e.g., time), which fails to capture the complex,\nmulti-dimensional nature of real-world variation. This paper introduces the\ntask of Continuous Domain Generalization (CDG), which aims to generalize\npredictive models to unseen domains defined by arbitrary combinations of\ncontinuous variation descriptors. We present a principled framework grounded in\ngeometric and algebraic theory, showing that optimal model parameters across\ndomains lie on a low-dimensional manifold. To model this structure, we propose\na Neural Lie Transport Operator (NeuralLTO), which enables structured parameter\ntransitions by enforcing geometric continuity and algebraic consistency. To\nhandle noisy or incomplete domain descriptors, we introduce a gating mechanism\nto suppress irrelevant dimensions and a local chart-based strategy for robust\ngeneralization. Extensive experiments on synthetic and real-world\ndatasets-including remote sensing, scientific documents, and traffic\nforecasting-demonstrate that our method significantly outperforms existing\nbaselines in generalization accuracy and robustness under descriptor\nimperfections."}
{"id": "2505.14305", "pdf": "https://arxiv.org/pdf/2505.14305", "abs": "https://arxiv.org/abs/2505.14305", "authors": ["Jinwang Song", "Hongying Zan", "Kunli Zhang", "Lingling Mu", "Yingjie Han", "Haobo Hua", "Min Peng"], "title": "JOLT-SQL: Joint Loss Tuning of Text-to-SQL with Confusion-aware Noisy Schema Sampling", "categories": ["cs.CL"], "comment": "Work in progress. 13 pages, 6 figures", "summary": "Text-to-SQL, which maps natural language to SQL queries, has benefited\ngreatly from recent advances in Large Language Models (LLMs). While LLMs offer\nvarious paradigms for this task, including prompting and supervised fine-tuning\n(SFT), SFT approaches still face challenges such as complex multi-stage\npipelines and poor robustness to noisy schema information. To address these\nlimitations, we present JOLT-SQL, a streamlined single-stage SFT framework that\njointly optimizes schema linking and SQL generation via a unified loss.\nJOLT-SQL employs discriminative schema linking, enhanced by local bidirectional\nattention, alongside a confusion-aware noisy schema sampling strategy with\nselective attention to improve robustness under noisy schema conditions.\nExperiments on the Spider and BIRD benchmarks demonstrate that JOLT-SQL\nachieves state-of-the-art execution accuracy among comparable-size open-source\nmodels, while significantly improving both training and inference efficiency."}
{"id": "2505.14654", "pdf": "https://arxiv.org/pdf/2505.14654", "abs": "https://arxiv.org/abs/2505.14654", "authors": ["Zikai Liao", "Yi Ouyang", "Yi-Lun Lee", "Chen-Ping Yu", "Yi-Hsuan Tsai", "Zhaozheng Yin"], "title": "Beyond Words: Multimodal LLM Knows When to Speak", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Project page: https://github.com/lzk901372/MM-When2Speak", "summary": "While large language model (LLM)-based chatbots have demonstrated strong\ncapabilities in generating coherent and contextually relevant responses, they\noften struggle with understanding when to speak, particularly in delivering\nbrief, timely reactions during ongoing conversations. This limitation arises\nlargely from their reliance on text input, lacking the rich contextual cues in\nreal-world human dialogue. In this work, we focus on real-time prediction of\nresponse types, with an emphasis on short, reactive utterances that depend on\nsubtle, multimodal signals across vision, audio, and text. To support this, we\nintroduce a new multimodal dataset constructed from real-world conversational\nvideos, containing temporally aligned visual, auditory, and textual streams.\nThis dataset enables fine-grained modeling of response timing in dyadic\ninteractions. Building on this dataset, we propose MM-When2Speak, a multimodal\nLLM-based model that adaptively integrates visual, auditory, and textual\ncontext to predict when a response should occur, and what type of response is\nappropriate. Experiments show that MM-When2Speak significantly outperforms\nstate-of-the-art unimodal and LLM-based baselines, achieving up to a 4x\nimprovement in response timing accuracy over leading commercial LLMs. These\nresults underscore the importance of multimodal inputs for producing timely,\nnatural, and engaging conversational AI."}
{"id": "2505.14125", "pdf": "https://arxiv.org/pdf/2505.14125", "abs": "https://arxiv.org/abs/2505.14125", "authors": ["Viet Anh Khoa Tran", "Emre Neftci", "Willem. A. M. Wybo"], "title": "Contrastive Consolidation of Top-Down Modulations Achieves Sparsely Supervised Continual Learning", "categories": ["cs.LG", "cs.AI", "q-bio.NC", "68T05 (primary), 68T07, 68T45 (secondary)", "I.2.6; I.2.10"], "comment": "33 pages, 5 figures", "summary": "Biological brains learn continually from a stream of unlabeled data, while\nintegrating specialized information from sparsely labeled examples without\ncompromising their ability to generalize. Meanwhile, machine learning methods\nare susceptible to catastrophic forgetting in this natural learning setting, as\nsupervised specialist fine-tuning degrades performance on the original task. We\nintroduce task-modulated contrastive learning (TMCL), which takes inspiration\nfrom the biophysical machinery in the neocortex, using predictive coding\nprinciples to integrate top-down information continually and without\nsupervision. We follow the idea that these principles build a view-invariant\nrepresentation space, and that this can be implemented using a contrastive\nloss. Then, whenever labeled samples of a new class occur, new affine\nmodulations are learned that improve separation of the new class from all\nothers, without affecting feedforward weights. By co-opting the view-invariance\nlearning mechanism, we then train feedforward weights to match the unmodulated\nrepresentation of a data sample to its modulated counterparts. This introduces\nmodulation invariance into the representation space, and, by also using past\nmodulations, stabilizes it. Our experiments show improvements in both\nclass-incremental and transfer learning over state-of-the-art unsupervised\napproaches, as well as over comparable supervised approaches, using as few as\n1% of available labels. Taken together, our work suggests that top-down\nmodulations play a crucial role in balancing stability and plasticity."}
{"id": "2505.13520", "pdf": "https://arxiv.org/pdf/2505.13520", "abs": "https://arxiv.org/abs/2505.13520", "authors": ["Hessa Alawwad", "Usman Naseem", "Areej Alhothali", "Ali Alkhathlan", "Amani Jamal"], "title": "Beyond Retrieval: Joint Supervision and Multimodal Document Ranking for Textbook Question Answering", "categories": ["cs.IR", "cs.AI"], "comment": "14 pages, 16 figure", "summary": "Textbook question answering (TQA) is a complex task, requiring the\ninterpretation of complex multimodal context. Although recent advances have\nimproved overall performance, they often encounter difficulties in educational\nsettings where accurate semantic alignment and task-specific document retrieval\nare essential. In this paper, we propose a novel approach to multimodal\ntextbook question answering by introducing a mechanism for enhancing semantic\nrepresentations through multi-objective joint training. Our model, Joint\nEmbedding Training With Ranking Supervision for Textbook Question Answering\n(JETRTQA), is a multimodal learning framework built on a retriever--generator\narchitecture that uses a retrieval-augmented generation setup, in which a\nmultimodal large language model generates answers. JETRTQA is designed to\nimprove the relevance of retrieved documents in complex educational contexts.\nUnlike traditional direct scoring approaches, JETRTQA learns to refine the\nsemantic representations of questions and documents through a supervised signal\nthat combines pairwise ranking and implicit supervision derived from answers.\nWe evaluate our method on the CK12-QA dataset and demonstrate that it\nsignificantly improves the discrimination between informative and irrelevant\ndocuments, even when they are long, complex, and multimodal. JETRTQA\noutperforms the previous state of the art, achieving a 2.4\\% gain in accuracy\non the validation set and 11.1\\% on the test set."}
{"id": "2505.14309", "pdf": "https://arxiv.org/pdf/2505.14309", "abs": "https://arxiv.org/abs/2505.14309", "authors": ["Ehsan Doostmohammadi", "Marco Kuhlmann"], "title": "Studying the Role of Input-Neighbor Overlap in Retrieval-Augmented Language Models Training Efficiency", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-augmented language models have demonstrated performance comparable\nto much larger models while requiring fewer computational resources. The\neffectiveness of these models crucially depends on the overlap between query\nand retrieved context, but the optimal degree of this overlap remains\nunexplored. In this paper, we systematically investigate how varying levels of\nquery--context overlap affect model performance during both training and\ninference. Our experiments reveal that increased overlap initially has minimal\neffect, but substantially improves test-time perplexity and accelerates model\nlearning above a critical threshold. Building on these findings, we demonstrate\nthat deliberately increasing overlap through synthetic context can enhance data\nefficiency and reduce training time by approximately 40\\% without compromising\nperformance. We specifically generate synthetic context through paraphrasing\nqueries. We validate our perplexity-based findings on question-answering tasks,\nconfirming that the benefits of retrieval-augmented language modeling extend to\npractical applications. Our results provide empirical evidence of significant\noptimization potential for retrieval mechanisms in language model pretraining."}
{"id": "2505.14664", "pdf": "https://arxiv.org/pdf/2505.14664", "abs": "https://arxiv.org/abs/2505.14664", "authors": ["Yilin Ye", "Junchao Huang", "Xingchen Zeng", "Jiazhi Xia", "Wei Zeng"], "title": "AKRMap: Adaptive Kernel Regression for Trustworthy Visualization of Cross-Modal Embeddings", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Cross-modal embeddings form the foundation for multi-modal models. However,\nvisualization methods for interpreting cross-modal embeddings have been\nprimarily confined to traditional dimensionality reduction (DR) techniques like\nPCA and t-SNE. These DR methods primarily focus on feature distributions within\na single modality, whilst failing to incorporate metrics (e.g., CLIPScore)\nacross multiple modalities.This paper introduces AKRMap, a new DR technique\ndesigned to visualize cross-modal embeddings metric with enhanced accuracy by\nlearning kernel regression of the metric landscape in the projection space.\nSpecifically, AKRMap constructs a supervised projection network guided by a\npost-projection kernel regression loss, and employs adaptive generalized\nkernels that can be jointly optimized with the projection. This approach\nenables AKRMap to efficiently generate visualizations that capture complex\nmetric distributions, while also supporting interactive features such as zoom\nand overlay for deeper exploration. Quantitative experiments demonstrate that\nAKRMap outperforms existing DR methods in generating more accurate and\ntrustworthy visualizations. We further showcase the effectiveness of AKRMap in\nvisualizing and comparing cross-modal embeddings for text-to-image models. Code\nand demo are available at https://github.com/yilinye/AKRMap."}
{"id": "2505.14128", "pdf": "https://arxiv.org/pdf/2505.14128", "abs": "https://arxiv.org/abs/2505.14128", "authors": ["Yihang Du", "Jiaying Hu", "Suyang Hou", "Yueyang Ding", "Xiaobo Sun"], "title": "A Methodological Framework for Measuring Spatial Labeling Similarity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Spatial labeling assigns labels to specific spatial locations to characterize\ntheir spatial properties and relationships, with broad applications in\nscientific research and practice. Measuring the similarity between two spatial\nlabelings is essential for understanding their differences and the contributing\nfactors, such as changes in location properties or labeling methods. An\nadequate and unbiased measurement of spatial labeling similarity should\nconsider the number of matched labels (label agreement), the topology of\nspatial label distribution, and the heterogeneous impacts of mismatched labels.\nHowever, existing methods often fail to account for all these aspects. To\naddress this gap, we propose a methodological framework to guide the\ndevelopment of methods that meet these requirements. Given two spatial\nlabelings, the framework transforms them into graphs based on location\norganization, labels, and attributes (e.g., location significance). The\ndistributions of their graph attributes are then extracted, enabling an\nefficient computation of distributional discrepancy to reflect the\ndissimilarity level between the two labelings. We further provide a concrete\nimplementation of this framework, termed Spatial Labeling Analogy Metric\n(SLAM), along with an analysis of its theoretical foundation, for evaluating\nspatial labeling results in spatial transcriptomics (ST) \\textit{as per} their\nsimilarity with ground truth labeling. Through a series of carefully designed\nexperimental cases involving both simulated and real ST data, we demonstrate\nthat SLAM provides a comprehensive and accurate reflection of labeling quality\ncompared to other well-established evaluation metrics. Our code is available at\nhttps://github.com/YihDu/SLAM."}
{"id": "2505.13525", "pdf": "https://arxiv.org/pdf/2505.13525", "abs": "https://arxiv.org/abs/2505.13525", "authors": ["Samual Yen-Chi Chen", "Huan-Hsin Tseng", "Hsin-Yi Lin", "Shinjae Yoo"], "title": "Learning to Program Quantum Measurements for Machine Learning", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG", "cs.NE"], "comment": null, "summary": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave sparked significant interest, driving extensive exploration of quantum\nmachine learning (QML) algorithms to address a wide range of complex\nchallenges. The development of high-performance QML models requires\nexpert-level expertise, presenting a key challenge to the widespread adoption\nof QML. Critical obstacles include the design of effective data encoding\nstrategies and parameterized quantum circuits, both of which are vital for the\nperformance of QML models. Furthermore, the measurement process is often\nneglected-most existing QML models employ predefined measurement schemes that\nmay not align with the specific requirements of the targeted problem. We\npropose an innovative framework that renders the observable of a quantum\nsystem-specifically, the Hermitian matrix-trainable. This approach employs an\nend-to-end differentiable learning framework, enabling simultaneous\noptimization of the neural network used to program the parameterized\nobservables and the standard quantum circuit parameters. Notably, the quantum\nobservable parameters are dynamically programmed by the neural network,\nallowing the observables to adapt in real time based on the input data stream.\nThrough numerical simulations, we demonstrate that the proposed method\neffectively programs observables dynamically within variational quantum\ncircuits, achieving superior results compared to existing approaches. Notably,\nit delivers enhanced performance metrics, such as higher classification\naccuracy, thereby significantly improving the overall effectiveness of QML\nmodels."}
{"id": "2505.14311", "pdf": "https://arxiv.org/pdf/2505.14311", "abs": "https://arxiv.org/abs/2505.14311", "authors": ["Shamsuddeen Hassan Muhammad", "Ibrahim Said Ahmad", "Idris Abdulmumin", "Falalu Ibrahim Lawan", "Babangida Sani", "Sukairaj Hafiz Imam", "Yusuf Aliyu", "Sani Abdullahi Sani", "Ali Usman Umar", "Kenneth Church", "Vukosi Marivate"], "title": "HausaNLP: Current Status, Challenges and Future Directions for Hausa Natural Language Processing", "categories": ["cs.CL"], "comment": null, "summary": "Hausa Natural Language Processing (NLP) has gained increasing attention in\nrecent years, yet remains understudied as a low-resource language despite\nhaving over 120 million first-language (L1) and 80 million second-language (L2)\nspeakers worldwide. While significant advances have been made in high-resource\nlanguages, Hausa NLP faces persistent challenges, including limited open-source\ndatasets and inadequate model representation. This paper presents an overview\nof the current state of Hausa NLP, systematically examining existing resources,\nresearch contributions, and gaps across fundamental NLP tasks: text\nclassification, machine translation, named entity recognition, speech\nrecognition, and question answering. We introduce HausaNLP\n(https://catalog.hausanlp.org), a curated catalog that aggregates datasets,\ntools, and research works to enhance accessibility and drive further\ndevelopment. Furthermore, we discuss challenges in integrating Hausa into large\nlanguage models (LLMs), addressing issues of suboptimal tokenization and\ndialectal variation. Finally, we propose strategic research directions\nemphasizing dataset expansion, improved language modeling approaches, and\nstrengthened community collaboration to advance Hausa NLP. Our work provides\nboth a foundation for accelerating Hausa NLP progress and valuable insights for\nbroader multilingual NLP research."}
{"id": "2505.14671", "pdf": "https://arxiv.org/pdf/2505.14671", "abs": "https://arxiv.org/abs/2505.14671", "authors": ["Ruichuan An", "Sihan Yang", "Renrui Zhang", "Zijun Shen", "Ming Lu", "Gaole Dai", "Hao Liang", "Ziyu Guo", "Shilin Yan", "Yulin Luo", "Bocheng Zou", "Chaoqun Yang", "Wentao Zhang"], "title": "UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens", "categories": ["cs.CV"], "comment": null, "summary": "Personalized models have demonstrated remarkable success in understanding and\ngenerating concepts provided by users. However, existing methods use separate\nconcept tokens for understanding and generation, treating these tasks in\nisolation. This may result in limitations for generating images with complex\nprompts. For example, given the concept $\\langle bo\\rangle$, generating\n\"$\\langle bo\\rangle$ wearing its hat\" without additional textual descriptions\nof its hat. We call this kind of generation personalized knowledge-driven\ngeneration. To address the limitation, we present UniCTokens, a novel framework\nthat effectively integrates personalized information into a unified vision\nlanguage model (VLM) for understanding and generation. UniCTokens trains a set\nof unified concept tokens to leverage complementary semantics, boosting two\npersonalized tasks. Moreover, we propose a progressive training strategy with\nthree stages: understanding warm-up, bootstrapping generation from\nunderstanding, and deepening understanding from generation to enhance mutual\nbenefits between both tasks. To quantitatively evaluate the unified VLM\npersonalization, we present UnifyBench, the first benchmark for assessing\nconcept understanding, concept generation, and knowledge-driven generation.\nExperimental results on UnifyBench indicate that UniCTokens shows competitive\nperformance compared to leading methods in concept understanding, concept\ngeneration, and achieving state-of-the-art results in personalized\nknowledge-driven generation. Our research demonstrates that enhanced\nunderstanding improves generation, and the generation process can yield\nvaluable insights into understanding. Our code and dataset will be released at:\n\\href{https://github.com/arctanxarc/UniCTokens}{https://github.com/arctanxarc/UniCTokens}."}
{"id": "2505.14136", "pdf": "https://arxiv.org/pdf/2505.14136", "abs": "https://arxiv.org/abs/2505.14136", "authors": ["Ryo Bertolissi", "Jonas H√ºbotter", "Ido Hakimi", "Andreas Krause"], "title": "Local Mixtures of Experts: Essentially Free Test-Time Training via Model Merging", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture of expert (MoE) models are a promising approach to increasing model\ncapacity without increasing inference cost, and are core components of many\nstate-of-the-art language models. However, current MoE models typically use\nonly few experts due to prohibitive training and inference cost. We propose\nTest-Time Model Merging (TTMM) which scales the MoE paradigm to an order of\nmagnitude more experts and uses model merging to avoid almost any test-time\noverhead. We show that TTMM is an approximation of test-time training (TTT),\nwhich fine-tunes an expert model for each prediction task, i.e., prompt. TTT\nhas recently been shown to significantly improve language models, but is\ncomputationally expensive. We find that performance of TTMM improves with more\nexperts and approaches the performance of TTT. Moreover, we find that with a 1B\nparameter base model, TTMM is more than 100x faster than TTT at test-time by\namortizing the cost of TTT at train-time. Thus, TTMM offers a promising\ncost-effective approach to scale test-time training."}
{"id": "2505.13526", "pdf": "https://arxiv.org/pdf/2505.13526", "abs": "https://arxiv.org/abs/2505.13526", "authors": ["Zhao Liu", "Wei Liu", "Huajie Zhu", "Jianxing Yu", "Jian Yin", "Wang-Chien Lee", "Shun Wang"], "title": "Geography-Aware Large Language Models for Next POI Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "9 pages, 7figures", "summary": "The next Point-of-Interest (POI) recommendation task aims to predict users'\nnext destinations based on their historical movement data and plays a key role\nin location-based services and personalized applications. Accurate next POI\nrecommendation depends on effectively modeling geographic information and POI\ntransition relations, which are crucial for capturing spatial dependencies and\nuser movement patterns. While Large Language Models (LLMs) exhibit strong\ncapabilities in semantic understanding and contextual reasoning, applying them\nto spatial tasks like next POI recommendation remains challenging. First, the\ninfrequent nature of specific GPS coordinates makes it difficult for LLMs to\nmodel precise spatial contexts. Second, the lack of knowledge about POI\ntransitions limits their ability to capture potential POI-POI relationships. To\naddress these issues, we propose GA-LLM (Geography-Aware Large Language Model),\na novel framework that enhances LLMs with two specialized components. The\nGeographic Coordinate Injection Module (GCIM) transforms GPS coordinates into\nspatial representations using hierarchical and Fourier-based positional\nencoding, enabling the model to understand geographic features from multiple\nperspectives. The POI Alignment Module (PAM) incorporates POI transition\nrelations into the LLM's semantic space, allowing it to infer global POI\nrelationships and generalize to unseen POIs. Experiments on three real-world\ndatasets demonstrate the state-of-the-art performance of GA-LLM."}
{"id": "2505.14313", "pdf": "https://arxiv.org/pdf/2505.14313", "abs": "https://arxiv.org/abs/2505.14313", "authors": ["Leonardo Bertolazzi", "Manuel Vargas Guzm√°n", "Raffaella Bernardi", "Maciej Malicki", "Jakub Szymanik"], "title": "A MIND for Reasoning: Meta-learning for In-context Deduction", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly evaluated on formal tasks,\nwhere strong reasoning abilities define the state of the art. However, their\nability to generalize to out-of-distribution problems remains limited. In this\npaper, we investigate how LLMs can achieve a systematic understanding of\ndeductive rules. Our focus is on the task of identifying the appropriate subset\nof premises within a knowledge base needed to derive a given hypothesis. To\ntackle this challenge, we propose Meta-learning for In-context Deduction\n(MIND), a novel few-shot meta-learning fine-tuning approach. The goal of MIND\nis to enable models to generalize more effectively to unseen knowledge bases\nand to systematically apply inference rules. Our results show that MIND\nsignificantly improves generalization in small LMs ranging from 1.5B to 7B\nparameters. The benefits are especially pronounced in smaller models and\nlow-data settings. Remarkably, small models fine-tuned with MIND outperform\nstate-of-the-art LLMs, such as GPT-4o and o3-mini, on this task."}
{"id": "2505.14673", "pdf": "https://arxiv.org/pdf/2505.14673", "abs": "https://arxiv.org/abs/2505.14673", "authors": ["Yu Tong", "Zihao Pan", "Shuai Yang", "Kaiyang Zhou"], "title": "Training-Free Watermarking for Autoregressive Image Generation", "categories": ["cs.CV", "cs.AI", "cs.CR"], "comment": null, "summary": "Invisible image watermarking can protect image ownership and prevent\nmalicious misuse of visual generative models. However, existing generative\nwatermarking methods are mainly designed for diffusion models while\nwatermarking for autoregressive image generation models remains largely\nunderexplored. We propose IndexMark, a training-free watermarking framework for\nautoregressive image generation models. IndexMark is inspired by the redundancy\nproperty of the codebook: replacing autoregressively generated indices with\nsimilar indices produces negligible visual differences. The core component in\nIndexMark is a simple yet effective match-then-replace method, which carefully\nselects watermark tokens from the codebook based on token similarity, and\npromotes the use of watermark tokens through token replacement, thereby\nembedding the watermark without affecting the image quality. Watermark\nverification is achieved by calculating the proportion of watermark tokens in\ngenerated images, with precision further improved by an Index Encoder.\nFurthermore, we introduce an auxiliary validation scheme to enhance robustness\nagainst cropping attacks. Experiments demonstrate that IndexMark achieves\nstate-of-the-art performance in terms of image quality and verification\naccuracy, and exhibits robustness against various perturbations, including\ncropping, noises, Gaussian blur, random erasing, color jittering, and JPEG\ncompression."}
{"id": "2505.14139", "pdf": "https://arxiv.org/pdf/2505.14139", "abs": "https://arxiv.org/abs/2505.14139", "authors": ["Marvin Alles", "Nutan Chen", "Patrick van der Smagt", "Botond Cseke"], "title": "FlowQ: Energy-Guided Flow Policies for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "The use of guidance to steer sampling toward desired outcomes has been widely\nexplored within diffusion models, especially in applications such as image and\ntrajectory generation. However, incorporating guidance during training remains\nrelatively underexplored. In this work, we introduce energy-guided flow\nmatching, a novel approach that enhances the training of flow models and\neliminates the need for guidance at inference time. We learn a conditional\nvelocity field corresponding to the flow policy by approximating an\nenergy-guided probability path as a Gaussian path. Learning guided trajectories\nis appealing for tasks where the target distribution is defined by a\ncombination of data and an energy function, as in reinforcement learning.\nDiffusion-based policies have recently attracted attention for their expressive\npower and ability to capture multi-modal action distributions. Typically, these\npolicies are optimized using weighted objectives or by back-propagating\ngradients through actions sampled by the policy. As an alternative, we propose\nFlowQ, an offline reinforcement learning algorithm based on energy-guided flow\nmatching. Our method achieves competitive performance while the policy training\ntime is constant in the number of flow sampling steps."}
{"id": "2505.13528", "pdf": "https://arxiv.org/pdf/2505.13528", "abs": "https://arxiv.org/abs/2505.13528", "authors": ["Shengkang Gu", "Jiahao Liu", "Dongsheng Li", "Guangping Zhang", "Mingzhe Han", "Hansu Gu", "Peng Zhang", "Ning Gu", "Li Shang", "Tun Lu"], "title": "LLM-Based User Simulation for Low-Knowledge Shilling Attacks on Recommender Systems", "categories": ["cs.IR", "cs.AI"], "comment": "11 pages, under review", "summary": "Recommender systems (RS) are increasingly vulnerable to shilling attacks,\nwhere adversaries inject fake user profiles to manipulate system outputs.\nTraditional attack strategies often rely on simplistic heuristics, require\naccess to internal RS data, and overlook the manipulation potential of textual\nreviews. In this work, we introduce Agent4SR, a novel framework that leverages\nLarge Language Model (LLM)-based agents to perform low-knowledge, high-impact\nshilling attacks through both rating and review generation. Agent4SR simulates\nrealistic user behavior by orchestrating adversarial interactions, selecting\nitems, assigning ratings, and crafting reviews, while maintaining behavioral\nplausibility. Our design includes targeted profile construction, hybrid memory\nretrieval, and a review attack strategy that propagates target item features\nacross unrelated reviews to amplify manipulation. Extensive experiments on\nmultiple datasets and RS architectures demonstrate that Agent4SR outperforms\nexisting low-knowledge baselines in both effectiveness and stealth. Our\nfindings reveal a new class of emergent threats posed by LLM-driven agents,\nunderscoring the urgent need for enhanced defenses in modern recommender\nsystems."}
{"id": "2505.14347", "pdf": "https://arxiv.org/pdf/2505.14347", "abs": "https://arxiv.org/abs/2505.14347", "authors": ["Neelabh Sinha"], "title": "QA-prompting: Improving Summarization with Large Language Models using Question-Answering", "categories": ["cs.CL"], "comment": "Submitted to ARR", "summary": "Language Models (LMs) have revolutionized natural language processing,\nenabling high-quality text generation through prompting and in-context\nlearning. However, models often struggle with long-context summarization due to\npositional biases, leading to suboptimal extraction of critical information.\nThere are techniques to improve this with fine-tuning, pipelining, or using\ncomplex techniques, which have their own challenges. To solve these challenges,\nwe propose QA-prompting - a simple prompting method for summarization that\nutilizes question-answering as an intermediate step prior to summary\ngeneration. Our method extracts key information and enriches the context of\ntext to mitigate positional biases and improve summarization in a single LM\ncall per task without requiring fine-tuning or pipelining. Experiments on\nmultiple datasets belonging to different domains using ten state-of-the-art\npre-trained models demonstrate that QA-prompting outperforms baseline and other\nstate-of-the-art methods, achieving up to 29% improvement in ROUGE scores. This\nprovides an effective and scalable solution for summarization and highlights\nthe importance of domain-specific question selection for optimal performance."}
{"id": "2505.14677", "pdf": "https://arxiv.org/pdf/2505.14677", "abs": "https://arxiv.org/abs/2505.14677", "authors": ["Jiaer Xia", "Yuhang Zang", "Peng Gao", "Yixuan Li", "Kaiyang Zhou"], "title": "Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning", "categories": ["cs.CV"], "comment": null, "summary": "Learning general-purpose reasoning capabilities has long been a challenging\nproblem in AI. Recent research in large language models (LLMs), such as\nDeepSeek-R1, has shown that reinforcement learning techniques like GRPO can\nenable pre-trained LLMs to develop reasoning capabilities using simple\nquestion-answer pairs. In this paper, we aim to train visual language models\n(VLMs) to perform reasoning on image data through reinforcement learning and\nvisual question-answer pairs, without any explicit chain-of-thought (CoT)\nsupervision. Our findings indicate that simply applying reinforcement learning\nto a VLM -- by prompting the model to produce a reasoning chain before\nproviding an answer -- can lead the model to develop shortcuts from easy\nquestions, thereby reducing its ability to generalize across unseen data\ndistributions. We argue that the key to mitigating shortcut learning is to\nencourage the model to interpret images prior to reasoning. Therefore, we train\nthe model to adhere to a caption-reason-answer output format: initially\ngenerating a detailed caption for an image, followed by constructing an\nextensive reasoning chain. When trained on 273K CoT-free visual question-answer\npairs and using only reinforcement learning, our model, named Visionary-R1,\noutperforms strong multimodal models, such as GPT-4o, Claude3.5-Sonnet, and\nGemini-1.5-Pro, on multiple visual reasoning benchmarks."}
{"id": "2505.14161", "pdf": "https://arxiv.org/pdf/2505.14161", "abs": "https://arxiv.org/abs/2505.14161", "authors": ["Ting Wei", "Biao Mei", "Junliang Lyu", "Renquan Zhang", "Feng Zhou", "Yifan Sun"], "title": "Personalized Bayesian Federated Learning with Wasserstein Barycenter Aggregation", "categories": ["cs.LG"], "comment": null, "summary": "Personalized Bayesian federated learning (PBFL) handles non-i.i.d. client\ndata and quantifies uncertainty by combining personalization with Bayesian\ninference. However, existing PBFL methods face two limitations: restrictive\nparametric assumptions in client posterior inference and naive parameter\naveraging for server aggregation. To overcome these issues, we propose FedWBA,\na novel PBFL method that enhances both local inference and global aggregation.\nAt the client level, we use particle-based variational inference for\nnonparametric posterior representation. At the server level, we introduce\nparticle-based Wasserstein barycenter aggregation, offering a more\ngeometrically meaningful approach. Theoretically, we provide local and global\nconvergence guarantees for FedWBA. Locally, we prove a KL divergence decrease\nlower bound per iteration for variational inference convergence. Globally, we\nshow that the Wasserstein barycenter converges to the true parameter as the\nclient data size increases. Empirically, experiments show that FedWBA\noutperforms baselines in prediction accuracy, uncertainty calibration, and\nconvergence rate, with ablation studies confirming its robustness."}
{"id": "2505.13531", "pdf": "https://arxiv.org/pdf/2505.13531", "abs": "https://arxiv.org/abs/2505.13531", "authors": ["Shitong Duan", "Xiaoyuan Yi", "Peng Zhang", "Dongkuan Xu", "Jing Yao", "Tun Lu", "Ning Gu", "Xing Xie"], "title": "AdAEM: An Adaptively and Automated Extensible Measurement of LLMs' Value Difference", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Assessing Large Language Models (LLMs)' underlying value differences enables\ncomprehensive comparison of their misalignment, cultural adaptability, and\nbiases. Nevertheless, current value measurement datasets face the\ninformativeness challenge: with often outdated, contaminated, or generic test\nquestions, they can only capture the shared value orientations among different\nLLMs, leading to saturated and thus uninformative results. To address this\nproblem, we introduce AdAEM, a novel, self-extensible assessment framework for\nrevealing LLMs' inclinations. Distinct from previous static benchmarks, AdAEM\ncan automatically and adaptively generate and extend its test questions. This\nis achieved by probing the internal value boundaries of a diverse set of LLMs\ndeveloped across cultures and time periods in an in-context optimization\nmanner. The optimization process theoretically maximizes an\ninformation-theoretic objective to extract the latest or culturally\ncontroversial topics, providing more distinguishable and informative insights\nabout models' value differences. In this way, AdAEM is able to co-evolve with\nthe development of LLMs, consistently tracking their value dynamics. Using\nAdAEM, we generate 12,310 questions grounded in Schwartz Value Theory, conduct\nan extensive analysis to manifest our method's validity and effectiveness, and\nbenchmark the values of 16 LLMs, laying the groundwork for better value\nresearch."}
{"id": "2505.14350", "pdf": "https://arxiv.org/pdf/2505.14350", "abs": "https://arxiv.org/abs/2505.14350", "authors": ["Jialong Han", "Si Zhang", "Ke Zhang"], "title": "OSoRA: Output-Dimension and Singular-Value Initialized Low-Rank Adaptation", "categories": ["cs.CL"], "comment": null, "summary": "Fine-tuning Large Language Models (LLMs) has become increasingly challenging\ndue to their massive scale and associated computational costs.\nParameter-Efficient Fine-Tuning (PEFT) methodologies have been proposed as\ncomputational alternatives; however, their implementations still require\nsignificant resources. In this paper, we present OSoRA (Output-Dimension and\nSingular-Value Initialized Low-Rank Adaptation), a novel PEFT method for LLMs.\nOSoRA extends Low-Rank Adaptation (LoRA) by integrating Singular Value\nDecomposition (SVD) with learnable scaling vectors in a unified framework. It\nfirst performs an SVD of pre-trained weight matrices, then optimizes an\noutput-dimension vector during training, while keeping the corresponding\nsingular vector matrices frozen. OSoRA substantially reduces computational\nresource requirements by minimizing the number of trainable parameters during\nfine-tuning. Comprehensive evaluations across mathematical reasoning, common\nsense reasoning, and other benchmarks demonstrate that OSoRA achieves\ncomparable or superior performance to state-of-the-art methods like LoRA and\nVeRA, while maintaining a linear parameter scaling even as the rank increases\nto higher dimensions. Our ablation studies further confirm that jointly\ntraining both the singular values and the output-dimension vector is critical\nfor optimal performance."}
{"id": "2505.14682", "pdf": "https://arxiv.org/pdf/2505.14682", "abs": "https://arxiv.org/abs/2505.14682", "authors": ["Rui Tian", "Mingfei Gao", "Mingze Xu", "Jiaming Hu", "Jiasen Lu", "Zuxuan Wu", "Yinfei Yang", "Afshin Dehghan"], "title": "UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation", "categories": ["cs.CV"], "comment": "Technical report", "summary": "We introduce UniGen, a unified multimodal large language model (MLLM) capable\nof image understanding and generation. We study the full training pipeline of\nUniGen from a data-centric perspective, including multi-stage pre-training,\nsupervised fine-tuning, and direct preference optimization. More importantly,\nwe propose a new Chain-of-Thought Verification (CoT-V) strategy for test-time\nscaling, which significantly boosts UniGen's image generation quality using a\nsimple Best-of-N test-time strategy. Specifically, CoT-V enables UniGen to act\nas both image generator and verifier at test time, assessing the semantic\nalignment between a text prompt and its generated image in a step-by-step CoT\nmanner. Trained entirely on open-source datasets across all stages, UniGen\nachieves state-of-the-art performance on a range of image understanding and\ngeneration benchmarks, with a final score of 0.78 on GenEval and 85.19 on\nDPG-Bench. Through extensive ablation studies, our work provides actionable\ninsights and addresses key challenges in the full life cycle of building\nunified MLLMs, contributing meaningful directions to the future research."}
{"id": "2505.14170", "pdf": "https://arxiv.org/pdf/2505.14170", "abs": "https://arxiv.org/abs/2505.14170", "authors": ["Chen Zhang", "Weixin Bu", "Zeyi Ren", "Zhengwu Liu", "Yik-Chung Wu", "Ngai Wong"], "title": "Nonparametric Teaching for Graph Property Learners", "categories": ["cs.LG"], "comment": "ICML 2025 Spotlight (25 pages, 17 figures)", "summary": "Inferring properties of graph-structured data, e.g., the solubility of\nmolecules, essentially involves learning the implicit mapping from graphs to\ntheir properties. This learning process is often costly for graph property\nlearners like Graph Convolutional Networks (GCNs). To address this, we propose\na paradigm called Graph Neural Teaching (GraNT) that reinterprets the learning\nprocess through a novel nonparametric teaching perspective. Specifically, the\nlatter offers a theoretical framework for teaching implicitly defined (i.e.,\nnonparametric) mappings via example selection. Such an implicit mapping is\nrealized by a dense set of graph-property pairs, with the GraNT teacher\nselecting a subset of them to promote faster convergence in GCN training. By\nanalytically examining the impact of graph structure on parameter-based\ngradient descent during training, and recasting the evolution of GCNs--shaped\nby parameter updates--through functional gradient descent in nonparametric\nteaching, we show for the first time that teaching graph property learners\n(i.e., GCNs) is consistent with teaching structure-aware nonparametric\nlearners. These new findings readily commit GraNT to enhancing learning\nefficiency of the graph property learner, showing significant reductions in\ntraining time for graph-level regression (-36.62%), graph-level classification\n(-38.19%), node-level regression (-30.97%) and node-level classification\n(-47.30%), all while maintaining its generalization performance."}
{"id": "2505.13532", "pdf": "https://arxiv.org/pdf/2505.13532", "abs": "https://arxiv.org/abs/2505.13532", "authors": ["Feihong Zhang", "Guojian Zhan", "Bin Shuai", "Tianyi Zhang", "Jingliang Duan", "Shengbo Eben Li"], "title": "Distributional Soft Actor-Critic with Harmonic Gradient for Safe and Efficient Autonomous Driving in Multi-lane Scenarios", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "IEEE Intelligent Vehicles Symposium (IV 2025)", "summary": "Reinforcement learning (RL), known for its self-evolution capability, offers\na promising approach to training high-level autonomous driving systems.\nHowever, handling constraints remains a significant challenge for existing RL\nalgorithms, particularly in real-world applications. In this paper, we propose\na new safety-oriented training technique called harmonic policy iteration\n(HPI). At each RL iteration, it first calculates two policy gradients\nassociated with efficient driving and safety constraints, respectively. Then, a\nharmonic gradient is derived for policy updating, minimizing conflicts between\nthe two gradients and consequently enabling a more balanced and stable training\nprocess. Furthermore, we adopt the state-of-the-art DSAC algorithm as the\nbackbone and integrate it with our HPI to develop a new safe RL algorithm,\nDSAC-H. Extensive simulations in multi-lane scenarios demonstrate that DSAC-H\nachieves efficient driving performance with near-zero safety constraint\nviolations."}
{"id": "2505.14354", "pdf": "https://arxiv.org/pdf/2505.14354", "abs": "https://arxiv.org/abs/2505.14354", "authors": ["Xin Li", "Mengbing Liu", "Li Wei", "Jiancheng An", "M√©rouane Debbah", "Chau Yuen"], "title": "WirelessMathBench: A Mathematical Modeling Benchmark for LLMs in Wireless Communications", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ACL 2025 Findings", "summary": "Large Language Models (LLMs) have achieved impressive results across a broad\narray of tasks, yet their capacity for complex, domain-specific mathematical\nreasoning-particularly in wireless communications-remains underexplored. In\nthis work, we introduce WirelessMathBench, a novel benchmark specifically\ndesigned to evaluate LLMs on mathematical modeling challenges to wireless\ncommunications engineering. Our benchmark consists of 587 meticulously curated\nquestions sourced from 40 state-of-the-art research papers, encompassing a\ndiverse spectrum of tasks ranging from basic multiple-choice questions to\ncomplex equation completion tasks, including both partial and full completions,\nall of which rigorously adhere to physical and dimensional constraints. Through\nextensive experimentation with leading LLMs, we observe that while many models\nexcel in basic recall tasks, their performance degrades significantly when\nreconstructing partially or fully obscured equations, exposing fundamental\nlimitations in current LLMs. Even DeepSeek-R1, the best performer on our\nbenchmark, achieves an average accuracy of only 38.05%, with a mere 7.83%\nsuccess rate in full equation completion. By publicly releasing\nWirelessMathBench along with the evaluation toolkit, we aim to advance the\ndevelopment of more robust, domain-aware LLMs for wireless system analysis and\nbroader engineering applications."}
{"id": "2505.14683", "pdf": "https://arxiv.org/pdf/2505.14683", "abs": "https://arxiv.org/abs/2505.14683", "authors": ["Chaorui Deng", "Deyao Zhu", "Kunchang Li", "Chenhui Gou", "Feng Li", "Zeyu Wang", "Shu Zhong", "Weihao Yu", "Xiaonan Nie", "Ziang Song", "Guang Shi", "Haoqi Fan"], "title": "Emerging Properties in Unified Multimodal Pretraining", "categories": ["cs.CV"], "comment": "37 pages, 17 figures", "summary": "Unifying multimodal understanding and generation has shown impressive\ncapabilities in cutting-edge proprietary systems. In this work, we introduce\nBAGEL, an open0source foundational model that natively supports multimodal\nunderstanding and generation. BAGEL is a unified, decoder0only model pretrained\non trillions of tokens curated from large0scale interleaved text, image, video,\nand web data. When scaled with such diverse multimodal interleaved data, BAGEL\nexhibits emerging capabilities in complex multimodal reasoning. As a result, it\nsignificantly outperforms open-source unified models in both multimodal\ngeneration and understanding across standard benchmarks, while exhibiting\nadvanced multimodal reasoning abilities such as free-form image manipulation,\nfuture frame prediction, 3D manipulation, and world navigation. In the hope of\nfacilitating further opportunities for multimodal research, we share the key\nfindings, pretraining details, data creation protocal, and release our code and\ncheckpoints to the community. The project page is at https://bagel-ai.org/"}
{"id": "2505.14185", "pdf": "https://arxiv.org/pdf/2505.14185", "abs": "https://arxiv.org/abs/2505.14185", "authors": ["Kaustubh Ponkshe", "Shaan Shah", "Raghav Singhal", "Praneeth Vepakomma"], "title": "Safety Subspaces are Not Distinct: A Fine-Tuning Case Study", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Kaustubh Ponkshe, Shaan Shah, and Raghav Singhal contributed equally\n  to this work", "summary": "Large Language Models (LLMs) rely on safety alignment to produce socially\nacceptable responses. This is typically achieved through instruction tuning and\nreinforcement learning from human feedback. However, this alignment is known to\nbe brittle: further fine-tuning, even on benign or lightly contaminated data,\ncan degrade safety and reintroduce harmful behaviors. A growing body of work\nsuggests that alignment may correspond to identifiable geometric directions in\nweight space, forming subspaces that could, in principle, be isolated or\npreserved to defend against misalignment. In this work, we conduct a\ncomprehensive empirical study of this geometric perspective. We examine whether\nsafety-relevant behavior is concentrated in specific subspaces, whether it can\nbe separated from general-purpose learning, and whether harmfulness arises from\ndistinguishable patterns in internal representations. Across both parameter and\nactivation space, our findings are consistent: subspaces that amplify safe\nbehaviors also amplify unsafe ones, and prompts with different safety\nimplications activate overlapping representations. We find no evidence of a\nsubspace that selectively governs safety. These results challenge the\nassumption that alignment is geometrically localized. Rather than residing in\ndistinct directions, safety appears to emerge from entangled, high-impact\ncomponents of the model's broader learning dynamics. This suggests that\nsubspace-based defenses may face fundamental limitations and underscores the\nneed for alternative strategies to preserve alignment under continued training.\nWe corroborate these findings through multiple experiments on five open-source\nLLMs. Our code is publicly available at:\nhttps://github.com/CERT-Lab/safety-subspaces."}
{"id": "2505.13534", "pdf": "https://arxiv.org/pdf/2505.13534", "abs": "https://arxiv.org/abs/2505.13534", "authors": ["Dan Ofer", "Michal Linial", "Dafna Shahaf"], "title": "InterFeat: An Automated Pipeline for Finding Interesting Hypotheses in Structured Biomedical Data", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.IR", "68T05, 68T50, 92C50", "I.2.6; I.2.7; H.2.8; J.3"], "comment": null, "summary": "Finding interesting phenomena is the core of scientific discovery, but it is\na manual, ill-defined concept. We present an integrative pipeline for\nautomating the discovery of interesting simple hypotheses (feature-target\nrelations with effect direction and a potential underlying mechanism) in\nstructured biomedical data. The pipeline combines machine learning, knowledge\ngraphs, literature search and Large Language Models. We formalize\n\"interestingness\" as a combination of novelty, utility and plausibility. On 8\nmajor diseases from the UK Biobank, our pipeline consistently recovers risk\nfactors years before their appearance in the literature. 40--53% of our top\ncandidates were validated as interesting, compared to 0--7% for a SHAP-based\nbaseline. Overall, 28% of 109 candidates were interesting to medical experts.\nThe pipeline addresses the challenge of operationalizing \"interestingness\"\nscalably and for any target. We release data and code:\nhttps://github.com/LinialLab/InterFeat"}
{"id": "2505.14367", "pdf": "https://arxiv.org/pdf/2505.14367", "abs": "https://arxiv.org/abs/2505.14367", "authors": ["Jialong Han", "Si Zhang", "Ke Zhang"], "title": "Dual Decomposition of Weights and Singular Value Low Rank Adaptation", "categories": ["cs.CL"], "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) has emerged as a critical paradigm for\nadapting Large Language Models (LLMs) to downstream tasks, among which Low-rank\nAdaptation (LoRA) represents one of the most widely adopted methodologies.\nHowever, existing LoRA-based approaches exhibit two fundamental limitations:\nunstable training dynamics and inefficient knowledge transfer from pre-trained\nmodels, both stemming from random initialization of adapter parameters. To\novercome these challenges, we propose DuDe, a novel approach that decomposes\nweight matrices into magnitude and direction components, employing Singular\nValue Decomposition (SVD) for principled initialization. Our comprehensive\nevaluation demonstrates DuDe's superior performance and robustness, achieving\nup to 48.35\\% accuracy on MMLU and 62.53\\% ($\\pm$ 1.59) accuracy on GSM8K. Our\ntheoretical analysis and empirical validation collectively demonstrate that\nDuDe's decomposition strategy enhances optimization stability and better\npreserves pre-trained representations, particularly for domain-specific tasks\nrequiring specialized knowledge. The combination of robust empirical\nperformance and rigorous theoretical foundations establishes DuDe as a\nsignificant contribution to PEFT methodologies for LLMs."}
{"id": "2505.14687", "pdf": "https://arxiv.org/pdf/2505.14687", "abs": "https://arxiv.org/abs/2505.14687", "authors": ["Sucheng Ren", "Qihang Yu", "Ju He", "Alan Yuille", "Liang-Chieh Chen"], "title": "Grouping First, Attending Smartly: Training-Free Acceleration for Diffusion Transformers", "categories": ["cs.CV"], "comment": "Project website at oliverrensu.github.io/project/GRAT", "summary": "Diffusion-based Transformers have demonstrated impressive generative\ncapabilities, but their high computational costs hinder practical deployment,\nfor example, generating an $8192\\times 8192$ image can take over an hour on an\nA100 GPU. In this work, we propose GRAT (\\textbf{GR}ouping first,\n\\textbf{AT}tending smartly), a training-free attention acceleration strategy\nfor fast image and video generation without compromising output quality. The\nkey insight is to exploit the inherent sparsity in learned attention maps\n(which tend to be locally focused) in pretrained Diffusion Transformers and\nleverage better GPU parallelism. Specifically, GRAT first partitions contiguous\ntokens into non-overlapping groups, aligning both with GPU execution patterns\nand the local attention structures learned in pretrained generative\nTransformers. It then accelerates attention by having all query tokens within\nthe same group share a common set of attendable key and value tokens. These key\nand value tokens are further restricted to structured regions, such as\nsurrounding blocks or criss-cross regions, significantly reducing computational\noverhead (e.g., attaining a \\textbf{35.8$\\times$} speedup over full attention\nwhen generating $8192\\times 8192$ images) while preserving essential attention\npatterns and long-range context. We validate GRAT on pretrained Flux and\nHunyuanVideo for image and video generation, respectively. In both cases, GRAT\nachieves substantially faster inference without any fine-tuning, while\nmaintaining the performance of full attention. We hope GRAT will inspire future\nresearch on accelerating Diffusion Transformers for scalable visual generation."}
{"id": "2505.14190", "pdf": "https://arxiv.org/pdf/2505.14190", "abs": "https://arxiv.org/abs/2505.14190", "authors": ["Ni Ding", "Miao Qiao", "Jiaxing Xu", "Yiping Ke", "Xiaoyu Zhang"], "title": "$Œ±$-GAN by R√©nyi Cross Entropy", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper proposes $\\alpha$-GAN, a generative adversarial network using\nR\\'{e}nyi measures. The value function is formulated, by R\\'{e}nyi cross\nentropy, as an expected certainty measure incurred by the discriminator's soft\ndecision as to where the sample is from, true population or the generator. The\ndiscriminator tries to maximize the R\\'{e}nyi certainty about sample source,\nwhile the generator wants to reduce it by injecting fake samples. This forms a\nmin-max problem with the solution parameterized by the R\\'{e}nyi order\n$\\alpha$. This $\\alpha$-GAN reduces to vanilla GAN at $\\alpha = 1$, where the\nvalue function is exactly the binary cross entropy. The optimization of\n$\\alpha$-GAN is over probability (vector) space. It is shown that the gradient\nis exponentially enlarged when R\\'{e}nyi order is in the range $\\alpha \\in\n(0,1)$. This makes convergence faster, which is verified by experimental\nresults. A discussion shows that choosing $\\alpha \\in (0,1)$ may be able to\nsolve some common problems, e.g., vanishing gradient. A following observation\nreveals that this range has not been fully explored in the existing R\\'{e}nyi\nversion GANs."}
{"id": "2505.13535", "pdf": "https://arxiv.org/pdf/2505.13535", "abs": "https://arxiv.org/abs/2505.13535", "authors": ["Aniket Bhattacharyya", "Anurag Tripathi", "Ujjal Das", "Archan Karmakar", "Amit Pathak", "Maneesh Gupta"], "title": "Information Extraction from Visually Rich Documents using LLM-based Organization of Documents into Independent Textual Segments", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted to ACL Main 2025", "summary": "Information extraction (IE) from Visually Rich Documents (VRDs) containing\nlayout features along with text is a critical and well-studied task.\nSpecialized non-LLM NLP-based solutions typically involve training models using\nboth textual and geometric information to label sequences/tokens as named\nentities or answers to specific questions. However, these approaches lack\nreasoning, are not able to infer values not explicitly present in documents,\nand do not generalize well to new formats. Generative LLM-based approaches\nproposed recently are capable of reasoning, but struggle to comprehend clues\nfrom document layout especially in previously unseen document formats, and do\nnot show competitive performance in heterogeneous VRD benchmark datasets. In\nthis paper, we propose BLOCKIE, a novel LLM-based approach that organizes VRDs\ninto localized, reusable semantic textual segments called $\\textit{semantic\nblocks}$, which are processed independently. Through focused and more\ngeneralizable reasoning,our approach outperforms the state-of-the-art on public\nVRD benchmarks by 1-3% in F1 scores, is resilient to document formats\npreviously not encountered and shows abilities to correctly extract information\nnot explicitly present in documents."}
{"id": "2505.14376", "pdf": "https://arxiv.org/pdf/2505.14376", "abs": "https://arxiv.org/abs/2505.14376", "authors": ["Maitreya Prafulla Chitale", "Ketaki Mangesh Shetye", "Harshit Gupta", "Manav Chaudhary", "Vasudeva Varma"], "title": "AutoRev: Automatic Peer Review System for Academic Research Papers", "categories": ["cs.CL"], "comment": null, "summary": "Generating a review for an academic research paper is a complex task that\nrequires a deep understanding of the document's content and the\ninterdependencies between its sections. It demands not only insight into\ntechnical details but also an appreciation of the paper's overall coherence and\nstructure. Recent methods have predominantly focused on fine-tuning large\nlanguage models (LLMs) to address this challenge. However, they often overlook\nthe computational and performance limitations imposed by long input token\nlengths. To address this, we introduce AutoRev, an Automatic Peer Review System\nfor Academic Research Papers. Our novel framework represents an academic\ndocument as a graph, enabling the extraction of the most critical passages that\ncontribute significantly to the review. This graph-based approach demonstrates\neffectiveness for review generation and is potentially adaptable to various\ndownstream tasks, such as question answering, summarization, and document\nrepresentation. When applied to review generation, our method outperforms SOTA\nbaselines by an average of 58.72% across all evaluation metrics. We hope that\nour work will stimulate further research in applying graph-based extraction\ntechniques to other downstream tasks in NLP. We plan to make our code public\nupon acceptance."}
{"id": "2505.13539", "pdf": "https://arxiv.org/pdf/2505.13539", "abs": "https://arxiv.org/abs/2505.13539", "authors": ["Rodrigo Fritz", "Pablo Su√°rez-Serrato", "Victor Mijangos", "Anayanzi D. Martinez-Hernandez", "Eduardo Ivan Velazquez Richards"], "title": "EuLearn: A 3D database for learning Euler characteristics", "categories": ["cs.CG", "cs.CV", "cs.LG", "math.DG", "math.GT"], "comment": "35 pages, many figures. Datasets and source code publicly available\n  at https://huggingface.co/datasets/appliedgeometry/EuLearn and\n  https://github.com/appliedgeometry/EuLearn_db", "summary": "We present EuLearn, the first surface datasets equitably representing a\ndiversity of topological types. We designed our embedded surfaces of uniformly\nvarying genera relying on random knots, thus allowing our surfaces to knot with\nthemselves. EuLearn contributes new topological datasets of meshes, point\nclouds, and scalar fields in 3D. We aim to facilitate the training of machine\nlearning systems that can discern topological features. We experimented with\nspecific emblematic 3D neural network architectures, finding that their vanilla\nimplementations perform poorly on genus classification. To enhance performance,\nwe developed a novel, non-Euclidean, statistical sampling method adapted to\ngraph and manifold data. We also introduce adjacency-informed adaptations of\nPointNet and Transformer architectures that rely on our non-Euclidean sampling\nstrategy. Our results demonstrate that incorporating topological information\ninto deep learning workflows significantly improves performance on these\notherwise challenging EuLearn datasets."}
{"id": "2505.14201", "pdf": "https://arxiv.org/pdf/2505.14201", "abs": "https://arxiv.org/abs/2505.14201", "authors": ["Kosmas Alexandridis", "Vasileios Titopoulos", "Giorgos Dimitrakopoulos"], "title": "FLASH-D: FlashAttention with Hidden Softmax Division", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "IEEE/ACM International Symposium on Low Power Electronics and Design\n  (ISLPED) 2025", "summary": "The transformer's attention mechanism has revolutionized AI and machine\nlearning, with its efficient computation being crucial to its performance.\nHowever, calculating attention involves matrix operations interspersed with\nsoftmax rescaling, which inherently slows down computation and requires\nprocessing the entire input sequence. Building on online softmax computation,\nFlashAttention integrates softmax calculation with matrix arithmetic, enabling\ntiled computation independent of sequence length. While optimized for GPUs,\nFlashAttention's simplicity makes it amenable to direct hardware acceleration.\nThis work re-evaluates the core FlashAttention kernel, presenting FLASH-D a\nmathematically equivalent, yet simplified, formulation that achieves: (a)\nhiding softmax division within other non-linear function evaluations; (b)\ninherently numerically stable computation of exponentials, eliminating the need\nfor maximum value subtraction; and (c) a reduction in computational cost\nwithout introducing numerical approximations to the FlashAttention kernel.\nImportantly, the essential FlashAttention properties that facilitate efficient\ntiled implementation are fully preserved. Hardware implementation results at\n28nm demonstrate that this proposed formulation achieves a 22.8% reduction in\narea and a 20.3% reduction in power, on average, compared to state-of-the-art\nparallel hardware architectures without any performance penalty."}
{"id": "2505.13538", "pdf": "https://arxiv.org/pdf/2505.13538", "abs": "https://arxiv.org/abs/2505.13538", "authors": ["Dvir Cohen", "Lin Burg", "Gilad Barkan"], "title": "RAGXplain: From Explainable Evaluation to Actionable Guidance of RAG Pipelines", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems show promise by coupling large\nlanguage models with external knowledge, yet traditional RAG evaluation methods\nprimarily report quantitative scores while offering limited actionable guidance\nfor refining these complex pipelines. In this paper, we introduce RAGXplain, an\nevaluation framework that quantifies RAG performance and translates these\nassessments into clear insights that clarify the workings of its complex,\nmulti-stage pipeline and offer actionable recommendations. Using LLM reasoning,\nRAGXplain converts raw scores into coherent narratives identifying performance\ngaps and suggesting targeted improvements. By providing transparent\nexplanations for AI decision-making, our framework fosters user trust-a key\nchallenge in AI adoption. Our LLM-based metric assessments show strong\nalignment with human judgments, and experiments on public question-answering\ndatasets confirm that applying RAGXplain's actionable recommendations\nmeasurably improves system performance. RAGXplain thus bridges quantitative\nevaluation and practical optimization, empowering users to understand, trust,\nand enhance their AI systems."}
{"id": "2505.14393", "pdf": "https://arxiv.org/pdf/2505.14393", "abs": "https://arxiv.org/abs/2505.14393", "authors": ["Nadir Durrani", "Basel Mousi", "Fahim Dalvi"], "title": "Editing Across Languages: A Survey of Multilingual Knowledge Editing", "categories": ["cs.CL"], "comment": null, "summary": "While Knowledge Editing has been extensively studied in monolingual settings,\nit remains underexplored in multilingual contexts. This survey systematizes\nrecent research on Multilingual Knowledge Editing (MKE), a growing subdomain of\nmodel editing focused on ensuring factual edits generalize reliably across\nlanguages. We present a comprehensive taxonomy of MKE methods, covering\nparameter-based, memory-based, fine-tuning, and hypernetwork approaches. We\nsurvey available benchmarks,summarize key findings on method effectiveness and\ntransfer patterns, identify challenges in cross-lingual propagation, and\nhighlight open problems related to language anisotropy, evaluation coverage,\nand edit scalability. Our analysis consolidates a rapidly evolving area and\nlays the groundwork for future progress in editable language-aware LLMs."}
{"id": "2505.14202", "pdf": "https://arxiv.org/pdf/2505.14202", "abs": "https://arxiv.org/abs/2505.14202", "authors": ["Zhicheng Chen", "Shibo Feng", "Xi Xiao", "Zhong Zhang", "Qing Li", "Xingyu Gao", "Peilin Zhao"], "title": "MSDformer: Multi-scale Discrete Transformer For Time Series Generation", "categories": ["cs.LG"], "comment": null, "summary": "Discrete Token Modeling (DTM), which employs vector quantization techniques,\nhas demonstrated remarkable success in modeling non-natural language\nmodalities, particularly in time series generation. While our prior work\nSDformer established the first DTM-based framework to achieve state-of-the-art\nperformance in this domain, two critical limitations persist in existing DTM\napproaches: 1) their inability to capture multi-scale temporal patterns\ninherent to complex time series data, and 2) the absence of theoretical\nfoundations to guide model optimization. To address these challenges, we\nproposes a novel multi-scale DTM-based time series generation method, called\nMulti-Scale Discrete Transformer (MSDformer). MSDformer employs a multi-scale\ntime series tokenizer to learn discrete token representations at multiple\nscales, which jointly characterize the complex nature of time series data.\nSubsequently, MSDformer applies a multi-scale autoregressive token modeling\ntechnique to capture the multi-scale patterns of time series within the\ndiscrete latent space. Theoretically, we validate the effectiveness of the DTM\nmethod and the rationality of MSDformer through the rate-distortion theorem.\nComprehensive experiments demonstrate that MSDformer significantly outperforms\nstate-of-the-art methods. Both theoretical analysis and experimental results\ndemonstrate that incorporating multi-scale information and modeling multi-scale\npatterns can substantially enhance the quality of generated time series in\nDTM-based approaches. The code will be released upon acceptance."}
{"id": "2505.13545", "pdf": "https://arxiv.org/pdf/2505.13545", "abs": "https://arxiv.org/abs/2505.13545", "authors": ["Jessica Foo", "Pradyumna Shyama Prasad", "Shaun Khoo"], "title": "Know Or Not: a library for evaluating out-of-knowledge base robustness", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "While the capabilities of large language models (LLMs) have progressed\nsignificantly, their use in high-stakes applications have been limited due to\nrisks of hallucination. One key approach in reducing hallucination is\nretrieval-augmented generation (RAG), but even in such setups, LLMs may still\nhallucinate when presented with questions outside of the knowledge base. Such\nbehavior is unacceptable in high-stake applications where LLMs are expected to\nabstain from answering queries it does not have sufficient context on. In this\nwork, we present a novel methodology for systematically evaluating\nout-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not\nknow) in the RAG setting, without the need for manual annotation of gold\nstandard answers. We implement our methodology in knowornot, an open-source\nlibrary that enables users to develop their own customized evaluation data and\npipelines for OOKB robustness. knowornot comprises four main features. Firstly,\nit provides a unified, high-level API that streamlines the process of setting\nup and running robustness benchmarks. Secondly, its modular architecture\nemphasizes extensibility and flexibility, allowing users to easily integrate\ntheir own LLM clients and RAG settings. Thirdly, its rigorous data modeling\ndesign ensures experiment reproducibility, reliability and traceability.\nLastly, it implements a comprehensive suite of tools for users to customize\ntheir pipelines. We demonstrate the utility of knowornot by developing a\nchallenging benchmark, PolicyBench, which spans four Question-Answer (QA)\nchatbots on government policies, and analyze its OOKB robustness. The source\ncode of knowornot is available\nhttps://github.com/govtech-responsibleai/KnowOrNot."}
{"id": "2505.14395", "pdf": "https://arxiv.org/pdf/2505.14395", "abs": "https://arxiv.org/abs/2505.14395", "authors": ["Seyoung Song", "Seogyeong Jeong", "Eunsu Kim", "Jiho Jin", "Dongkwan Kim", "Jay Shin", "Alice Oh"], "title": "MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating text generation capabilities of large language models (LLMs) is\nchallenging, particularly for low-resource languages where methods for direct\nassessment are scarce. We propose MUG-Eval, a novel framework that evaluates\nLLMs' multilingual generation capabilities by transforming existing benchmarks\ninto conversational tasks and measuring the LLMs' accuracies on those tasks. We\nspecifically designed these conversational tasks to require effective\ncommunication in the target language. Then, we simply use task success rate as\na proxy of successful conversation generation. Our approach offers two key\nadvantages: it is independent of language-specific NLP tools or annotated\ndatasets, which are limited for most languages, and it does not rely on\nLLMs-as-judges, whose evaluation quality degrades outside a few high-resource\nlanguages. We evaluate 8 LLMs across 30 languages spanning high, mid, and\nlow-resource categories, and we find that MUG-Eval correlates strongly with\nestablished benchmarks ($r$ > 0.75) while enabling standardized comparisons\nacross languages and models. Our framework provides a robust and\nresource-efficient solution for evaluating multilingual generation that can be\nextended to thousands of languages."}
{"id": "2505.14022", "pdf": "https://arxiv.org/pdf/2505.14022", "abs": "https://arxiv.org/abs/2505.14022", "authors": ["Chenghuan Huang", "Zhigeng Xu", "Chong Sun", "Chen Li", "Ziyang Ma"], "title": "Towards Efficient Multi-Scale Deformable Attention on NPU", "categories": ["cs.PF", "cs.CV"], "comment": "10 pages, 8 figures", "summary": "Multi-scale deformable attention (MSDA) is a flexible and powerful feature\nextraction mechanism for visual tasks, but its random-access grid sampling\nstrategy poses significant optimization challenges, especially on\ndomain-specific accelerators such as NPUs. In this work, we present a co-design\napproach that systematically rethinks memory access and computation strategies\nfor MSDA on the Ascend NPU architecture. With this co-design approach, our\nimplementation supports both efficient forward and backward computation, is\nfully adapted for training workloads, and incorporates a suite of\nhardware-aware optimizations. Extensive experiments show that our solution\nachieves up to $5.9\\times$ (forward), $8.9\\times$ (backward), and $7.3\\times$\n(end-to-end training) speedup over the grid sample-based baseline, and\n$1.9\\times$, $2.4\\times$, and $2.0\\times$ acceleration over the latest vendor\nlibrary, respectively."}
{"id": "2505.14206", "pdf": "https://arxiv.org/pdf/2505.14206", "abs": "https://arxiv.org/abs/2505.14206", "authors": ["Flavio Di Martino", "Franca Delmastro"], "title": "Challenges and Limitations in the Synthetic Generation of mHealth Sensor Data", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to ACM Transactions on Computing for Healthcare (ACM\n  HEALTH)", "summary": "The widespread adoption of mobile sensors has the potential to provide\nmassive and heterogeneous time series data, driving Artificial Intelligence\napplications in mHealth. However, data collection remains limited due to\nstringent ethical regulations, privacy concerns, and other constraints,\nhindering progress in the field. Synthetic data generation, particularly\nthrough Generative Adversarial Networks and Diffusion Models, has emerged as a\npromising solution to address both data scarcity and privacy issues. Yet, these\nmodels are often limited to short-term, unimodal signal patterns. This paper\npresents a systematic evaluation of state-of-the-art generative models for time\nseries synthesis, with a focus on their ability to jointly handle\nmulti-modality, long-range dependencies, and conditional generation-key\nchallenges in the mHealth domain. To ensure a fair comparison, we introduce a\nnovel evaluation framework designed to measure both the intrinsic quality of\nsynthetic data and its utility in downstream predictive tasks. Our findings\nreveal critical limitations in the existing approaches, particularly in\nmaintaining cross-modal consistency, preserving temporal coherence, and\nensuring robust performance in train-on-synthetic, test-on-real, and data\naugmentation scenarios. Finally, we present our future research directions to\nenhance synthetic time series generation and improve the applicability of\ngenerative models in mHealth."}
{"id": "2505.13550", "pdf": "https://arxiv.org/pdf/2505.13550", "abs": "https://arxiv.org/abs/2505.13550", "authors": ["Ke Yang", "Kevin Ros", "Shankar Kumar Senthil Kumar", "ChengXiang Zhai"], "title": "JIR-Arena: The First Benchmark Dataset for Just-in-time Information Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Just-in-time Information Recommendation (JIR) is a service designed to\ndeliver the most relevant information precisely when users need it, ,\naddressing their knowledge gaps with minimal effort and boosting\ndecision-making and efficiency in daily life. Advances in device-efficient\ndeployment of foundation models and the growing use of intelligent wearable\ndevices have made always-on JIR assistants feasible. However, there has been no\nsystematic effort to formally define JIR tasks or establish evaluation\nframeworks. To bridge this gap, we present the first mathematical definition of\nJIR tasks and associated evaluation metrics. Additionally, we introduce\nJIR-Arena, a multimodal benchmark dataset featuring diverse,\ninformation-request-intensive scenarios to evaluate JIR systems across critical\ndimensions: i) accurately inferring user information needs, ii) delivering\ntimely and relevant recommendations, and iii) avoiding irrelevant content that\nmay distract users.\n  Developing a JIR benchmark dataset poses challenges due to subjectivity in\nestimating user information needs and uncontrollable system variables affecting\nreproducibility. To address these, JIR-Arena: i) combines input from multiple\nhumans and large AI models to approximate information need distributions; ii)\nassesses JIR quality through information retrieval outcomes using static\nknowledge base snapshots; and iii) employs a multi-turn, multi-entity\nvalidation framework to improve objectivity and generality. Furthermore, we\nimplement a baseline JIR system capable of processing real-time information\nstreams aligned with user inputs. Our evaluation of this baseline system on\nJIR-Arena indicates that while foundation model-based JIR systems simulate user\nneeds with reasonable precision, they face challenges in recall and effective\ncontent retrieval. To support future research in this new area, we fully\nrelease our code and data."}
{"id": "2505.14398", "pdf": "https://arxiv.org/pdf/2505.14398", "abs": "https://arxiv.org/abs/2505.14398", "authors": ["Peter Baile Chen", "Yi Zhang", "Dan Roth", "Samuel Madden", "Jacob Andreas", "Michael Cafarella"], "title": "Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Data and code are available at https://peterbaile.github.io/lag/", "summary": "While humans naturally learn and adapt from past experiences, large language\nmodels (LLMs) and their agentic counterparts struggle to retain reasoning from\nprevious tasks and apply them in future contexts. To address this limitation,\nwe propose a novel framework, log-augmented generation (LAG) that directly\nreuses prior computation and reasoning from past logs at test time to enhance\nmodel's ability to learn from previous tasks and perform better on new, unseen\nchallenges, all while keeping the system efficient and scalable. Specifically,\nour system represents task logs using key-value (KV) caches, encoding the full\nreasoning context of prior tasks while storing KV caches for only a selected\nsubset of tokens. When a new task arises, LAG retrieves the KV values from\nrelevant logs to augment generation. Our approach differs from reflection-based\nmemory mechanisms by directly reusing prior reasoning and computations without\nrequiring additional steps for knowledge extraction or distillation. Our method\nalso goes beyond existing KV caching techniques, which primarily target\nefficiency gains rather than improving accuracy. Experiments on knowledge- and\nreasoning-intensive datasets demonstrate that our method significantly\noutperforms standard agentic systems that do not utilize logs, as well as\nexisting solutions based on reflection and KV cache techniques."}
{"id": "2505.14087", "pdf": "https://arxiv.org/pdf/2505.14087", "abs": "https://arxiv.org/abs/2505.14087", "authors": ["Ziyi Chang", "He Wang", "George Alex Koulieris", "Hubert P. H. Shum"], "title": "Large-Scale Multi-Character Interaction Synthesis", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Generating large-scale multi-character interactions is a challenging and\nimportant task in character animation. Multi-character interactions involve not\nonly natural interactive motions but also characters coordinated with each\nother for transition. For example, a dance scenario involves characters dancing\nwith partners and also characters coordinated to new partners based on spatial\nand temporal observations. We term such transitions as coordinated interactions\nand decompose them into interaction synthesis and transition planning. Previous\nmethods of single-character animation do not consider interactions that are\ncritical for multiple characters. Deep-learning-based interaction synthesis\nusually focuses on two characters and does not consider transition planning.\nOptimization-based interaction synthesis relies on manually designing objective\nfunctions that may not generalize well. While crowd simulation involves more\ncharacters, their interactions are sparse and passive. We identify two\nchallenges to multi-character interaction synthesis, including the lack of data\nand the planning of transitions among close and dense interactions. Existing\ndatasets either do not have multiple characters or do not have close and dense\ninteractions. The planning of transitions for multi-character close and dense\ninteractions needs both spatial and temporal considerations. We propose a\nconditional generative pipeline comprising a coordinatable multi-character\ninteraction space for interaction synthesis and a transition planning network\nfor coordinations. Our experiments demonstrate the effectiveness of our\nproposed pipeline for multicharacter interaction synthesis and the applications\nfacilitated by our method show the scalability and transferability."}
{"id": "2505.14211", "pdf": "https://arxiv.org/pdf/2505.14211", "abs": "https://arxiv.org/abs/2505.14211", "authors": ["Qu Wang", "Yan Xia"], "title": "A PID-Controlled Tensor Wheel Decomposition Model for Dynamic Link Prediction", "categories": ["cs.LG"], "comment": "7 pages, 2 figures", "summary": "Link prediction in dynamic networks remains a fundamental challenge in\nnetwork science, requiring the inference of potential interactions and their\nevolving strengths through spatiotemporal pattern analysis. Traditional static\nnetwork methods have inherent limitations in capturing temporal dependencies\nand weight dynamics, while tensor-based methods offer a promising paradigm by\nencoding dynamic networks into high-order tensors to explicitly model\nmultidimensional interactions across nodes and time. Among them, tensor wheel\ndecomposition (TWD) stands out for its innovative topological structure, which\ndecomposes high-order tensors into cyclic factors and core tensors to maintain\nstructural integrity. To improve the prediction accuracy, this study introduces\na PID-controlled tensor wheel decomposition (PTWD) model, which mainly adopts\nthe following two ideas: 1) exploiting the representation power of TWD to\ncapture the latent features of dynamic network topology and weight evolution,\nand 2) integrating the proportional-integral-derivative (PID) control principle\ninto the optimization process to obtain a stable model parameter learning\nscheme. The performance on four real datasets verifies that the proposed PTWD\nmodel has more accurate link prediction capabilities compared to other models."}
{"id": "2505.13557", "pdf": "https://arxiv.org/pdf/2505.13557", "abs": "https://arxiv.org/abs/2505.13557", "authors": ["Davide Bruni", "Marco Avvenuti", "Nicola Tonellotto", "Maurizio Tesconi"], "title": "AMAQA: A Metadata-based QA Dataset for RAG Systems", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems are widely used in\nquestion-answering (QA) tasks, but current benchmarks lack metadata\nintegration, hindering evaluation in scenarios requiring both textual data and\nexternal information. To address this, we present AMAQA, a new open-access QA\ndataset designed to evaluate tasks combining text and metadata. The integration\nof metadata is especially important in fields that require rapid analysis of\nlarge volumes of data, such as cybersecurity and intelligence, where timely\naccess to relevant information is critical. AMAQA includes about 1.1 million\nEnglish messages collected from 26 public Telegram groups, enriched with\nmetadata such as timestamps, topics, emotional tones, and toxicity indicators,\nwhich enable precise and contextualized queries by filtering documents based on\nspecific criteria. It also includes 450 high-quality QA pairs, making it a\nvaluable resource for advancing research on metadata-driven QA and RAG systems.\nTo the best of our knowledge, AMAQA is the first single-hop QA benchmark to\nincorporate metadata and labels such as topics covered in the messages. We\nconduct extensive tests on the benchmark, establishing a new standard for\nfuture research. We show that leveraging metadata boosts accuracy from 0.12 to\n0.61, highlighting the value of structured context. Building on this, we\nexplore several strategies to refine the LLM input by iterating over provided\ncontext and enriching it with noisy documents, achieving a further 3-point gain\nover the best baseline and a 14-point improvement over simple metadata\nfiltering. The dataset is available at\nhttps://anonymous.4open.science/r/AMAQA-5D0D/"}
{"id": "2505.14406", "pdf": "https://arxiv.org/pdf/2505.14406", "abs": "https://arxiv.org/abs/2505.14406", "authors": ["Haoming Huang", "Yibo Yan", "Jiahao Huo", "Xin Zou", "Xinfeng Li", "Kun Wang", "Xuming Hu"], "title": "Pierce the Mists, Greet the Sky: Decipher Knowledge Overshadowing via Knowledge Circuit Analysis", "categories": ["cs.CL"], "comment": "18 pages, 6 figures, EMNLP under review", "summary": "Large Language Models (LLMs), despite their remarkable capabilities, are\nhampered by hallucinations. A particularly challenging variant, knowledge\novershadowing, occurs when one piece of activated knowledge inadvertently masks\nanother relevant piece, leading to erroneous outputs even with high-quality\ntraining data. Current understanding of overshadowing is largely confined to\ninference-time observations, lacking deep insights into its origins and\ninternal mechanisms during model training. Therefore, we introduce\nPhantomCircuit, a novel framework designed to comprehensively analyze and\ndetect knowledge overshadowing. By innovatively employing knowledge circuit\nanalysis, PhantomCircuit dissects the internal workings of attention heads,\ntracing how competing knowledge pathways contribute to the overshadowing\nphenomenon and its evolution throughout the training process. Extensive\nexperiments demonstrate PhantomCircuit's effectiveness in identifying such\ninstances, offering novel insights into this elusive hallucination and\nproviding the research community with a new methodological lens for its\npotential mitigation."}
{"id": "2505.14177", "pdf": "https://arxiv.org/pdf/2505.14177", "abs": "https://arxiv.org/abs/2505.14177", "authors": ["Marien Renaud", "Valentin De Bortoli", "Arthur Leclaire", "Nicolas Papadakis"], "title": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "categories": ["stat.ML", "cs.CV", "cs.LG"], "comment": null, "summary": "We consider the problem of sampling distributions stemming from non-convex\npotentials with Unadjusted Langevin Algorithm (ULA). We prove the stability of\nthe discrete-time ULA to drift approximations under the assumption that the\npotential is strongly convex at infinity. In many context, e.g. imaging inverse\nproblems, potentials are non-convex and non-smooth. Proximal Stochastic\nGradient Langevin Algorithm (PSGLA) is a popular algorithm to handle such\npotentials. It combines the forward-backward optimization algorithm with a ULA\nstep. Our main stability result combined with properties of the Moreau envelope\nallows us to derive the first proof of convergence of the PSGLA for non-convex\npotentials. We empirically validate our methodology on synthetic data and in\nthe context of imaging inverse problems. In particular, we observe that PSGLA\nexhibits faster convergence rates than Stochastic Gradient Langevin Algorithm\nfor posterior sampling while preserving its restoration properties."}
{"id": "2505.14214", "pdf": "https://arxiv.org/pdf/2505.14214", "abs": "https://arxiv.org/abs/2505.14214", "authors": ["Mattes Mollenhauer", "Nicole M√ºcke", "Dimitri Meunier", "Arthur Gretton"], "title": "Regularized least squares learning with heavy-tailed noise is minimax optimal", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "62G08 (Primary) 62G35, 62J07 (Secondary)"], "comment": "32 pages, 1 figure", "summary": "This paper examines the performance of ridge regression in reproducing kernel\nHilbert spaces in the presence of noise that exhibits a finite number of higher\nmoments. We establish excess risk bounds consisting of subgaussian and\npolynomial terms based on the well known integral operator framework. The\ndominant subgaussian component allows to achieve convergence rates that have\npreviously only been derived under subexponential noise - a prevalent\nassumption in related work from the last two decades. These rates are optimal\nunder standard eigenvalue decay conditions, demonstrating the asymptotic\nrobustness of regularized least squares against heavy-tailed noise. Our\nderivations are based on a Fuk-Nagaev inequality for Hilbert-space valued\nrandom variables."}
{"id": "2505.13562", "pdf": "https://arxiv.org/pdf/2505.13562", "abs": "https://arxiv.org/abs/2505.13562", "authors": ["Shishen Lin"], "title": "Randomised Optimism via Competitive Co-Evolution for Matrix Games with Bandit Feedback", "categories": ["stat.ML", "cs.AI", "cs.GT", "cs.LG", "cs.NE"], "comment": "21 pages, 10 figures, accepted at IJCAI 2025", "summary": "Learning in games is a fundamental problem in machine learning and artificial\nintelligence, with numerous\napplications~\\citep{silver2016mastering,schrittwieser2020mastering}. This work\ninvestigates two-player zero-sum matrix games with an unknown payoff matrix and\nbandit feedback, where each player observes their actions and the corresponding\nnoisy payoff. Prior studies have proposed algorithms for this\nsetting~\\citep{o2021matrix,maiti2023query,cai2024uncoupled}, with\n\\citet{o2021matrix} demonstrating the effectiveness of deterministic optimism\n(e.g., \\ucb) in achieving sublinear regret. However, the potential of\nrandomised optimism in matrix games remains theoretically unexplored.\n  We propose Competitive Co-evolutionary Bandit Learning (\\coebl), a novel\nalgorithm that integrates evolutionary algorithms (EAs) into the bandit\nframework to implement randomised optimism through EA variation operators. We\nprove that \\coebl achieves sublinear regret, matching the performance of\ndeterministic optimism-based methods. To the best of our knowledge, this is the\nfirst theoretical regret analysis of an evolutionary bandit learning algorithm\nin matrix games.\n  Empirical evaluations on diverse matrix game benchmarks demonstrate that\n\\coebl not only achieves sublinear regret but also consistently outperforms\nclassical bandit algorithms, including \\exptr~\\citep{auer2002nonstochastic},\nthe variant \\exptrni~\\citep{cai2024uncoupled}, and \\ucb~\\citep{o2021matrix}.\nThese results highlight the potential of evolutionary bandit learning,\nparticularly the efficacy of randomised optimism via evolutionary algorithms in\ngame-theoretic settings."}
{"id": "2505.14418", "pdf": "https://arxiv.org/pdf/2505.14418", "abs": "https://arxiv.org/abs/2505.14418", "authors": ["Pengzhou Cheng", "Haowen Hu", "Zheng Wu", "Zongru Wu", "Tianjie Ju", "Daizong Ding", "Zhuosheng Zhang", "Gongshen Liu"], "title": "Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents", "categories": ["cs.CL"], "comment": "25 pages, 10 figures, 12 Tables", "summary": "Graphical user interface (GUI) agents powered by multimodal large language\nmodels (MLLMs) have shown greater promise for human-interaction. However, due\nto the high fine-tuning cost, users often rely on open-source GUI agents or\nAPIs offered by AI providers, which introduces a critical but underexplored\nsupply chain threat: backdoor attacks. In this work, we first unveil that\nMLLM-powered GUI agents naturally expose multiple interaction-level triggers,\nsuch as historical steps, environment states, and task progress. Based on this\nobservation, we introduce AgentGhost, an effective and stealthy framework for\nred-teaming backdoor attacks. Specifically, we first construct composite\ntriggers by combining goal and interaction levels, allowing GUI agents to\nunintentionally activate backdoors while ensuring task utility. Then, we\nformulate backdoor injection as a Min-Max optimization problem that uses\nsupervised contrastive learning to maximize the feature difference across\nsample classes at the representation space, improving flexibility of the\nbackdoor. Meanwhile, it adopts supervised fine-tuning to minimize the\ndiscrepancy between backdoor and clean behavior generation, enhancing\neffectiveness and utility. Extensive evaluations of various agent models in two\nestablished mobile benchmarks show that AgentGhost is effective and generic,\nwith attack accuracy that reaches 99.7\\% on three attack objectives, and shows\nstealthiness with only 1\\% utility degradation. Furthermore, we tailor a\ndefense method against AgentGhost that reduces the attack accuracy to 22.1\\%.\nOur code is available at \\texttt{anonymous}."}
{"id": "2505.14180", "pdf": "https://arxiv.org/pdf/2505.14180", "abs": "https://arxiv.org/abs/2505.14180", "authors": ["Songhao Wu", "Quan Tu", "Mingjie Zhong", "Hong Liu", "Jia Xu", "Jinjie Gu", "Rui Yan"], "title": "Bridge the Gap between Past and Future: Siamese Model Optimization for Context-Aware Document Ranking", "categories": ["cs.IR", "cs.CV", "H.3.3"], "comment": null, "summary": "In the realm of information retrieval, users often engage in multi-turn\ninteractions with search engines to acquire information, leading to the\nformation of sequences of user feedback behaviors. Leveraging the session\ncontext has proven to be beneficial for inferring user search intent and\ndocument ranking. A multitude of approaches have been proposed to exploit\nin-session context for improved document ranking. Despite these advances, the\nlimitation of historical session data for capturing evolving user intent\nremains a challenge. In this work, we explore the integration of future\ncontextual information into the session context to enhance document ranking. We\npresent the siamese model optimization framework, comprising a\nhistory-conditioned model and a future-aware model. The former processes only\nthe historical behavior sequence, while the latter integrates both historical\nand anticipated future behaviors. Both models are trained collaboratively using\nthe supervised labels and pseudo labels predicted by the other. The\nhistory-conditioned model, referred to as ForeRanker, progressively learns\nfuture-relevant information to enhance ranking, while it singly uses historical\nsession at inference time. To mitigate inconsistencies during training, we\nintroduce the peer knowledge distillation method with a dynamic gating\nmechanism, allowing models to selectively incorporate contextual information.\nExperimental results on benchmark datasets demonstrate the effectiveness of our\nForeRanker, showcasing its superior performance compared to existing methods."}
{"id": "2505.14217", "pdf": "https://arxiv.org/pdf/2505.14217", "abs": "https://arxiv.org/abs/2505.14217", "authors": ["Jorge Fabila", "Lidia Garrucho", "V√≠ctor M. Campello", "Carlos Mart√≠n-Isla", "Karim Lekadir"], "title": "Federated learning in low-resource settings: A chest imaging study in Africa -- Challenges and lessons learned", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "This study explores the use of Federated Learning (FL) for tuberculosis (TB)\ndiagnosis using chest X-rays in low-resource settings across Africa. FL allows\nhospitals to collaboratively train AI models without sharing raw patient data,\naddressing privacy concerns and data scarcity that hinder traditional\ncentralized models. The research involved hospitals and research centers in\neight African countries. Most sites used local datasets, while Ghana and The\nGambia used public ones. The study compared locally trained models with a\nfederated model built across all institutions to evaluate FL's real-world\nfeasibility. Despite its promise, implementing FL in sub-Saharan Africa faces\nchallenges such as poor infrastructure, unreliable internet, limited digital\nliteracy, and weak AI regulations. Some institutions were also reluctant to\nshare model updates due to data control concerns. In conclusion, FL shows\nstrong potential for enabling AI-driven healthcare in underserved regions, but\nbroader adoption will require improvements in infrastructure, education, and\nregulatory support."}
{"id": "2505.13565", "pdf": "https://arxiv.org/pdf/2505.13565", "abs": "https://arxiv.org/abs/2505.13565", "authors": ["Oier Mentxaka", "Natalia D√≠az-Rodr√≠guez", "Mark Coeckelbergh", "Marcos L√≥pez de Prado", "Emilia G√≥mez", "David Fern√°ndez Llorca", "Enrique Herrera-Viedma", "Francisco Herrera"], "title": "Aligning Trustworthy AI with Democracy: A Dual Taxonomy of Opportunities and Risks", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "26 pages, 5 figures", "summary": "Artificial Intelligence (AI) poses both significant risks and valuable\nopportunities for democratic governance. This paper introduces a dual taxonomy\nto evaluate AI's complex relationship with democracy: the AI Risks to Democracy\n(AIRD) taxonomy, which identifies how AI can undermine core democratic\nprinciples such as autonomy, fairness, and trust; and the AI's Positive\nContributions to Democracy (AIPD) taxonomy, which highlights AI's potential to\nenhance transparency, participation, efficiency, and evidence-based\npolicymaking.\n  Grounded in the European Union's approach to ethical AI governance, and\nparticularly the seven Trustworthy AI requirements proposed by the European\nCommission's High-Level Expert Group on AI, each identified risk is aligned\nwith mitigation strategies based on EU regulatory and normative frameworks. Our\nanalysis underscores the transversal importance of transparency and societal\nwell-being across all risk categories and offers a structured lens for aligning\nAI systems with democratic values.\n  By integrating democratic theory with practical governance tools, this paper\noffers a normative and actionable framework to guide research, regulation, and\ninstitutional design to support trustworthy, democratic AI. It provides\nscholars with a conceptual foundation to evaluate the democratic implications\nof AI, equips policymakers with structured criteria for ethical oversight, and\nhelps technologists align system design with democratic principles. In doing\nso, it bridges the gap between ethical aspirations and operational realities,\nlaying the groundwork for more inclusive, accountable, and resilient democratic\nsystems in the algorithmic age."}
{"id": "2505.14420", "pdf": "https://arxiv.org/pdf/2505.14420", "abs": "https://arxiv.org/abs/2505.14420", "authors": ["Huopu Zhang", "Yanguang Liu", "Mengnan Du"], "title": "SAE-FiRE: Enhancing Earnings Surprise Predictions Through Sparse Autoencoder Feature Selection", "categories": ["q-fin.CP", "cs.CL", "cs.LG"], "comment": null, "summary": "Predicting earnings surprises through the analysis of earnings conference\ncall transcripts has attracted increasing attention from the financial research\ncommunity. Conference calls serve as critical communication channels between\ncompany executives, analysts, and shareholders, offering valuable\nforward-looking information. However, these transcripts present significant\nanalytical challenges, typically containing over 5,000 words with substantial\nredundancy and industry-specific terminology that creates obstacles for\nlanguage models. In this work, we propose the Sparse Autoencoder for Financial\nRepresentation Enhancement (SAE-FiRE) framework to address these limitations by\nextracting key information while eliminating redundancy. SAE-FiRE employs\nSparse Autoencoders (SAEs) to efficiently identify patterns and filter out\nnoises, and focusing specifically on capturing nuanced financial signals that\nhave predictive power for earnings surprises. Experimental results indicate\nthat the proposed method can significantly outperform comparing baselines."}
{"id": "2505.14629", "pdf": "https://arxiv.org/pdf/2505.14629", "abs": "https://arxiv.org/abs/2505.14629", "authors": ["Fnu Mohbat", "Mohammed J Zaki"], "title": "KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "Accepted at ACL 2025", "summary": "Recent advances in large language models (LLMs) and the abundance of food\ndata have resulted in studies to improve food understanding using LLMs. Despite\nseveral recommendation systems utilizing LLMs and Knowledge Graphs (KGs), there\nhas been limited research on integrating food related KGs with LLMs. We\nintroduce KERL, a unified system that leverages food KGs and LLMs to provide\npersonalized food recommendations and generates recipes with associated\nmicro-nutritional information. Given a natural language question, KERL extracts\nentities, retrieves subgraphs from the KG, which are then fed into the LLM as\ncontext to select the recipes that satisfy the constraints. Next, our system\ngenerates the cooking steps and nutritional information for each recipe. To\nevaluate our approach, we also develop a benchmark dataset by curating recipe\nrelated questions, combined with constraints and personal preferences. Through\nextensive experiments, we show that our proposed KG-augmented LLM significantly\noutperforms existing approaches, offering a complete and coherent solution for\nfood recommendation, recipe generation, and nutritional analysis. Our code and\nbenchmark datasets are publicly available at\nhttps://github.com/mohbattharani/KERL."}
{"id": "2505.14234", "pdf": "https://arxiv.org/pdf/2505.14234", "abs": "https://arxiv.org/abs/2505.14234", "authors": ["Illia Horenko", "Davide Bassetti", "Luk√°≈° Posp√≠≈°il"], "title": "Fast and close Shannon entropy approximation", "categories": ["cs.LG", "cs.AI", "68T01 (Primary) 68Q01, 90C99 (Secondary)"], "comment": "8 pages, 1 figure", "summary": "Shannon entropy (SE) and its quantum mechanical analogue von Neumann entropy\nare key components in many tools used in physics, information theory, machine\nlearning (ML) and quantum computing. Besides of the significant amounts of SE\ncomputations required in these fields, the singularity of the SE gradient is\none of the central mathematical reason inducing the high cost, frequently low\nrobustness and slow convergence of such tools. Here we propose the Fast Entropy\nApproximation (FEA) - a non-singular rational approximation of Shannon entropy\nand its gradient that achieves a mean absolute error of $10^{-3}$, which is\napproximately $20$ times lower than comparable state-of-the-art methods. FEA\nallows around $50\\%$ faster computation, requiring only $5$ to $6$ elementary\ncomputational operations, as compared to tens of elementary operations behind\nthe fastest entropy computation algorithms with table look-ups, bitshifts, or\nseries approximations. On a set of common benchmarks for the feature selection\nproblem in machine learning, we show that the combined effect of fewer\nelementary operations, low approximation error, and a non-singular gradient\nallows significantly better model quality and enables ML feature extraction\nthat is two to three orders of magnitude faster and computationally cheaper\nwhen incorporating FEA into AI tools."}
{"id": "2505.13572", "pdf": "https://arxiv.org/pdf/2505.13572", "abs": "https://arxiv.org/abs/2505.13572", "authors": ["Yousouf Taghzouti", "Franck Michel", "Tao Jiang", "Louis-F√©lix Nothias", "Fabien Gandon"], "title": "Q${}^2$Forge: Minting Competency Questions and SPARQL Queries for Question-Answering Over Knowledge Graphs", "categories": ["cs.DB", "cs.AI", "cs.IR"], "comment": null, "summary": "The SPARQL query language is the standard method to access knowledge graphs\n(KGs). However, formulating SPARQL queries is a significant challenge for\nnon-expert users, and remains time-consuming for the experienced ones. Best\npractices recommend to document KGs with competency questions and example\nqueries to contextualise the knowledge they contain and illustrate their\npotential applications. In practice, however, this is either not the case or\nthe examples are provided in limited numbers. Large Language Models (LLMs) are\nbeing used in conversational agents and are proving to be an attractive\nsolution with a wide range of applications, from simple question-answering\nabout common knowledge to generating code in a targeted programming language.\nHowever, training and testing these models to produce high quality SPARQL\nqueries from natural language questions requires substantial datasets of\nquestion-query pairs. In this paper, we present Q${}^2$Forge that addresses the\nchallenge of generating new competency questions for a KG and corresponding\nSPARQL queries. It iteratively validates those queries with human feedback and\nLLM as a judge. Q${}^2$Forge is open source, generic, extensible and modular,\nmeaning that the different modules of the application (CQ generation, query\ngeneration and query refinement) can be used separately, as an integrated\npipeline, or replaced by alternative services. The result is a complete\npipeline from competency question formulation to query evaluation, supporting\nthe creation of reference query sets for any target KG."}
{"id": "2505.14423", "pdf": "https://arxiv.org/pdf/2505.14423", "abs": "https://arxiv.org/abs/2505.14423", "authors": ["Ona de Gibert", "Joseph Attieh", "Teemu Vahtola", "Mikko Aulamo", "Zihao Li", "Ra√∫l V√°zquez", "Tiancheng Hu", "J√∂rg Tiedemann"], "title": "Scaling Low-Resource MT via Synthetic Data Generation with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "We investigate the potential of LLM-generated synthetic data for improving\nlow-resource machine translation (MT). Focusing on seven diverse target\nlanguages, we construct a document-level synthetic corpus from English\nEuroparl, and extend it via pivoting to 147 additional language pairs.\nAutomatic and human evaluation confirm its high overall quality. We study its\npractical application by (i) identifying effective training regimes, (ii)\ncomparing our data with the HPLT dataset, and (iii) testing its utility beyond\nEnglish-centric MT. Finally, we introduce SynOPUS, a public repository for\nsynthetic parallel datasets. Our findings show that LLM-generated synthetic\ndata, even when noisy, can substantially improve MT performance for\nlow-resource languages."}
{"id": "2505.14660", "pdf": "https://arxiv.org/pdf/2505.14660", "abs": "https://arxiv.org/abs/2505.14660", "authors": ["Ronald Seoh", "Dan Goldwasser"], "title": "EmoGist: Efficient In-Context Learning for Visual Emotion Understanding", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "In this paper, we introduce EmoGist, a training-free, in-context learning\nmethod for performing visual emotion classification with LVLMs. The key\nintuition of our approach is that context-dependent definition of emotion\nlabels could allow more accurate predictions of emotions, as the ways in which\nemotions manifest within images are highly context dependent and nuanced.\nEmoGist pre-generates multiple explanations of emotion labels, by analyzing the\nclusters of example images belonging to each category. At test time, we\nretrieve a version of explanation based on embedding similarity, and feed it to\na fast VLM for classification. Through our experiments, we show that EmoGist\nallows up to 13 points improvement in micro F1 scores with the multi-label\nMemotion dataset, and up to 8 points in macro F1 in the multi-class FI dataset."}
{"id": "2505.14240", "pdf": "https://arxiv.org/pdf/2505.14240", "abs": "https://arxiv.org/abs/2505.14240", "authors": ["Germain Vivier-Ardisson", "Mathieu Blondel", "Axel Parmentier"], "title": "Learning with Local Search MCMC Layers", "categories": ["cs.LG"], "comment": null, "summary": "Integrating combinatorial optimization layers into neural networks has\nrecently attracted significant research interest. However, many existing\napproaches lack theoretical guarantees or fail to perform adequately when\nrelying on inexact solvers. This is a critical limitation, as many operations\nresearch problems are NP-hard, often necessitating the use of\nneighborhood-based local search heuristics. These heuristics iteratively\ngenerate and evaluate candidate solutions based on an acceptance rule. In this\npaper, we introduce a theoretically-principled approach for learning with such\ninexact combinatorial solvers. Inspired by the connection between simulated\nannealing and Metropolis-Hastings, we propose to transform problem-specific\nneighborhood systems used in local search heuristics into proposal\ndistributions, implementing MCMC on the combinatorial space of feasible\nsolutions. This allows us to construct differentiable combinatorial layers and\nassociated loss functions. Replacing an exact solver by a local search strongly\nreduces the computational burden of learning on many applications. We\ndemonstrate our approach on a large-scale dynamic vehicle routing problem with\ntime windows."}
{"id": "2505.13573", "pdf": "https://arxiv.org/pdf/2505.13573", "abs": "https://arxiv.org/abs/2505.13573", "authors": ["Jian Liu", "Haohan Weng", "Biwen Lei", "Xianghui Yang", "Zibo Zhao", "Zhuo Chen", "Song Guo", "Tao Han", "Chunchao Guo"], "title": "FreeMesh: Boosting Mesh Generation with Coordinates Merging", "categories": ["cs.GR", "cs.AI"], "comment": "Accepted by ICML 2025, camera-ready version", "summary": "The next-coordinate prediction paradigm has emerged as the de facto standard\nin current auto-regressive mesh generation methods. Despite their\neffectiveness, there is no efficient measurement for the various tokenizers\nthat serialize meshes into sequences. In this paper, we introduce a new metric\nPer-Token-Mesh-Entropy (PTME) to evaluate the existing mesh tokenizers\ntheoretically without any training. Building upon PTME, we propose a\nplug-and-play tokenization technique called coordinate merging. It further\nimproves the compression ratios of existing tokenizers by rearranging and\nmerging the most frequent patterns of coordinates. Through experiments on\nvarious tokenization methods like MeshXL, MeshAnything V2, and Edgerunner, we\nfurther validate the performance of our method. We hope that the proposed PTME\nand coordinate merging can enhance the existing mesh tokenizers and guide the\nfurther development of native mesh generation."}
{"id": "2505.14425", "pdf": "https://arxiv.org/pdf/2505.14425", "abs": "https://arxiv.org/abs/2505.14425", "authors": ["Chalamalasetti Kranti", "Sherzod Hakimov", "David Schlangen"], "title": "From Templates to Natural Language: Generalization Challenges in Instruction-Tuned LLMs for Spatial Reasoning", "categories": ["cs.CL"], "comment": "4 pages", "summary": "Instruction-tuned large language models (LLMs) have shown strong performance\non a variety of tasks; however, generalizing from synthetic to human-authored\ninstructions in grounded environments remains a challenge for them. In this\nwork, we study generalization challenges in spatial grounding tasks where\nmodels interpret and translate instructions for building object arrangements on\na $2.5$D grid. We fine-tune LLMs using only synthetic instructions and evaluate\ntheir performance on a benchmark dataset containing both synthetic and\nhuman-written instructions. Our results reveal that while models generalize\nwell on simple tasks, their performance degrades significantly on more complex\ntasks. We present a detailed error analysis of the gaps in instruction\ngeneralization."}
{"id": "2301.05191", "pdf": "https://arxiv.org/pdf/2301.05191", "abs": "https://arxiv.org/abs/2301.05191", "authors": ["Lei Sun", "Daniel Gehrig", "Christos Sakaridis", "Mathias Gehrig", "Jingyun Liang", "Peng Sun", "Zhijie Xu", "Kaiwei Wang", "Luc Van Gool", "Davide Scaramuzza"], "title": "A Unified Framework for Event-based Frame Interpolation with Ad-hoc Deblurring in the Wild", "categories": ["cs.CV"], "comment": "Accepted to T-PAMI", "summary": "Effective video frame interpolation hinges on the adept handling of motion in\nthe input scene. Prior work acknowledges asynchronous event information for\nthis, but often overlooks whether motion induces blur in the video, limiting\nits scope to sharp frame interpolation. We instead propose a unified framework\nfor event-based frame interpolation that performs deblurring ad-hoc and thus\nworks both on sharp and blurry input videos. Our model consists in a\nbidirectional recurrent network that incorporates the temporal dimension of\ninterpolation and fuses information from the input frames and the events\nadaptively based on their temporal proximity. To enhance the generalization\nfrom synthetic data to real event cameras, we integrate self-supervised\nframework with the proposed model to enhance the generalization on real-world\ndatasets in the wild. At the dataset level, we introduce a novel real-world\nhigh-resolution dataset with events and color videos named HighREV, which\nprovides a challenging evaluation setting for the examined task. Extensive\nexperiments show that our network consistently outperforms previous\nstate-of-the-art methods on frame interpolation, single image deblurring, and\nthe joint task of both. Experiments on domain transfer reveal that\nself-supervised training effectively mitigates the performance degradation\nobserved when transitioning from synthetic data to real-world data. Code and\ndatasets are available at https://github.com/AHupuJR/REFID."}
{"id": "2505.14251", "pdf": "https://arxiv.org/pdf/2505.14251", "abs": "https://arxiv.org/abs/2505.14251", "authors": ["Bar Mahpud", "Or Sheffet"], "title": "A Private Approximation of the 2nd-Moment Matrix of Any Subsamplable Input", "categories": ["cs.LG", "cs.CR", "cs.DS"], "comment": null, "summary": "We study the problem of differentially private second moment estimation and\npresent a new algorithm that achieve strong privacy-utility trade-offs even for\nworst-case inputs under subsamplability assumptions on the data. We call an\ninput $(m,\\alpha,\\beta)$-subsamplable if a random subsample of size $m$ (or\nlarger) preserves w.p $\\geq 1-\\beta$ the spectral structure of the original\nsecond moment matrix up to a multiplicative factor of $1\\pm \\alpha$. Building\nupon subsamplability, we give a recursive algorithmic framework similar to\nKamath et al 2019, that abides zero-Concentrated Differential Privacy (zCDP)\nwhile preserving w.h.p. the accuracy of the second moment estimation upto an\narbitrary factor of $(1\\pm\\gamma)$. We then show how to apply our algorithm to\napproximate the second moment matrix of a distribution $\\mathcal{D}$, even when\na noticeable fraction of the input are outliers."}
{"id": "2505.14436", "pdf": "https://arxiv.org/pdf/2505.14436", "abs": "https://arxiv.org/abs/2505.14436", "authors": ["Yuqiao Tan", "Shizhu He", "Kang Liu", "Jun Zhao"], "title": "Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL'25 Main. Code link:\n  https://github.com/Trae1ounG/Neural_Incompatibility", "summary": "Large Language Models (LLMs) offer a transparent brain with accessible\nparameters that encode extensive knowledge, which can be analyzed, located and\ntransferred. Consequently, a key research challenge is to transcend traditional\nknowledge transfer paradigms rooted in symbolic language and achieve genuine\nParametric Knowledge Transfer (PKT). Significantly, exploring effective methods\nfor transferring knowledge across LLMs of different scales through parameters\npresents an intriguing and valuable research direction. In this paper, we first\ndemonstrate $\\textbf{Alignment}$ in parametric space is the fundamental\nprerequisite to achieve successful cross-scale PKT. We redefine the previously\nexplored knowledge transfer as Post-Align PKT (PostPKT), which utilizes\nextracted parameters for LoRA initialization and requires subsequent fine-tune\nfor alignment. Hence, to reduce cost for further fine-tuning, we introduce a\nnovel Pre-Align PKT (PrePKT) paradigm and propose a solution called\n$\\textbf{LaTen}$\n($\\textbf{L}$oc$\\textbf{a}$te-$\\textbf{T}$h$\\textbf{e}$n-Alig$\\textbf{n}$) that\naligns the parametric spaces of LLMs across scales only using several training\nsteps without following training. Comprehensive experiments on four benchmarks\ndemonstrate that both PostPKT and PrePKT face challenges in achieving\nconsistently stable transfer. Through in-depth analysis, we identify\n$\\textbf{Neural Incompatibility}$ as the ethological and parametric structural\ndifferences between LLMs of varying scales, presenting fundamental challenges\nto achieving effective PKT. These findings provide fresh insights into the\nparametric architectures of LLMs and highlight promising directions for future\nresearch on efficient PKT. Our code is available at\nhttps://github.com/Trae1ounG/Neural_Incompatibility."}
{"id": "2311.16515", "pdf": "https://arxiv.org/pdf/2311.16515", "abs": "https://arxiv.org/abs/2311.16515", "authors": ["Delong Liu", "Haiwen Li", "Zhaohui Hou", "Zhicheng Zhao", "Fei Su", "Yuan Dong"], "title": "Automatic Synthetic Data and Fine-grained Adaptive Feature Alignment for Composed Person Retrieval", "categories": ["cs.CV", "cs.AI", "cs.IR"], "comment": null, "summary": "Person retrieval has attracted rising attention. Existing methods are mainly\ndivided into two retrieval modes, namely image-only and text-only. However,\nthey are unable to make full use of the available information and are difficult\nto meet diverse application requirements. To address the above limitations, we\npropose a new Composed Person Retrieval (CPR) task, which combines visual and\ntextual queries to identify individuals of interest from large-scale person\nimage databases. Nevertheless, the foremost difficulty of the CPR task is the\nlack of available annotated datasets. Therefore, we first introduce a scalable\nautomatic data synthesis pipeline, which decomposes complex multimodal data\ngeneration into the creation of textual quadruples followed by\nidentity-consistent image synthesis using fine-tuned generative models.\nMeanwhile, a multimodal filtering method is designed to ensure the resulting\nSynCPR dataset retains 1.15 million high-quality and fully synthetic triplets.\nAdditionally, to improve the representation of composed person queries, we\npropose a novel Fine-grained Adaptive Feature Alignment (FAFA) framework\nthrough fine-grained dynamic alignment and masked feature reasoning. Moreover,\nfor objective evaluation, we manually annotate the Image-Text Composed Person\nRetrieval (ITCPR) test set. The extensive experiments demonstrate the\neffectiveness of the SynCPR dataset and the superiority of the proposed FAFA\nframework when compared with the state-of-the-art methods. All code and data\nwill be provided at\nhttps://github.com/Delong-liu-bupt/Composed_Person_Retrieval."}
{"id": "2505.14252", "pdf": "https://arxiv.org/pdf/2505.14252", "abs": "https://arxiv.org/abs/2505.14252", "authors": ["Mouad Elaarabi", "Domenico Borzacchiello", "Philippe Le Bot", "Nathan Lauzeral", "Sebastien Comas-Cardona"], "title": "Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we explore the integration of Sequence Encoding for Online\nParameter Identification with Physics-Informed Neural Networks to create a\nmodel that, once trained, can be utilized for real time applications with\nvariable parameters, boundary conditions, and initial conditions. Recently, the\ncombination of PINNs with Sparse Regression has emerged as a method for\nperforming dynamical system identification through supervised learning and\nsparse regression optimization, while also solving the dynamics using PINNs.\nHowever, this approach can be limited by variations in parameters or boundary\nand initial conditions, requiring retraining of the model whenever changes\noccur. In this work, we introduce an architecture that employs Deep Sets or\nSequence Encoders to encode dynamic parameters, boundary conditions, and\ninitial conditions, using these encoded features as inputs for the PINN,\nenabling the model to adapt to changes in parameters, BCs, and ICs. We apply\nthis approach to three different problems. First, we analyze the Rossler ODE\nsystem, demonstrating the robustness of the model with respect to noise and its\nability to generalize. Next, we explore the model's capability in a 2D\nNavier-Stokes PDE problem involving flow past a cylinder with a parametric\nsinusoidal inlet velocity function, showing that the model can encode pressure\ndata from a few points to identify the inlet velocity profile and utilize\nphysics to compute velocity and pressure throughout the domain. Finally, we\naddress a 1D heat monitoring problem using real data from the heating of glass\nfiber and thermoplastic composite plates."}
{"id": "2505.13729", "pdf": "https://arxiv.org/pdf/2505.13729", "abs": "https://arxiv.org/abs/2505.13729", "authors": ["Abhinav Rajvanshi", "Pritish Sahu", "Tixiao Shan", "Karan Sikka", "Han-Pang Chiu"], "title": "SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Adaptive collaboration is critical to a team of autonomous robots to perform\ncomplicated navigation tasks in large-scale unknown environments. An effective\ncollaboration strategy should be determined and adapted according to each\nrobot's skills and current status to successfully achieve the shared goal. We\npresent SayCoNav, a new approach that leverages large language models (LLMs)\nfor automatically generating this collaboration strategy among a team of\nrobots. Building on the collaboration strategy, each robot uses the LLM to\ngenerate its plans and actions in a decentralized way. By sharing information\nto each other during navigation, each robot also continuously updates its\nstep-by-step plans accordingly. We evaluate SayCoNav on Multi-Object Navigation\n(MultiON) tasks, that require the team of the robots to utilize their\ncomplementary strengths to efficiently search multiple different objects in\nunknown environments. By validating SayCoNav with varied team compositions and\nconditions against baseline methods, our experimental results show that\nSayCoNav can improve search efficiency by at most 44.28% through effective\ncollaboration among heterogeneous robots. It can also dynamically adapt to the\nchanging conditions during task execution."}
{"id": "2505.14442", "pdf": "https://arxiv.org/pdf/2505.14442", "abs": "https://arxiv.org/abs/2505.14442", "authors": ["Mete Ismayilzada", "Antonio Laverghetta Jr.", "Simone A. Luchini", "Reet Patel", "Antoine Bosselut", "Lonneke van der Plas", "Roger Beaty"], "title": "Creative Preference Optimization", "categories": ["cs.CL", "cs.AI"], "comment": "27 pages", "summary": "While Large Language Models (LLMs) have demonstrated impressive performance\nacross natural language generation tasks, their ability to generate truly\ncreative content-characterized by novelty, diversity, surprise, and\nquality-remains limited. Existing methods for enhancing LLM creativity often\nfocus narrowly on diversity or specific tasks, failing to address creativity's\nmultifaceted nature in a generalizable way. In this work, we propose Creative\nPreference Optimization (CrPO), a novel alignment method that injects signals\nfrom multiple creativity dimensions into the preference optimization objective\nin a modular fashion. We train and evaluate creativity-augmented versions of\nseveral models using CrPO and MuCE, a new large-scale human preference dataset\nspanning over 200,000 human-generated responses and ratings from more than 30\npsychological creativity assessments. Our models outperform strong baselines,\nincluding GPT-4o, on both automated and human evaluations, producing more\nnovel, diverse, and surprising generations while maintaining high output\nquality. Additional evaluations on NoveltyBench further confirm the\ngeneralizability of our approach. Together, our results demonstrate that\ndirectly optimizing for creativity within preference frameworks is a promising\ndirection for advancing the creative capabilities of LLMs without compromising\noutput quality."}
{"id": "2403.09948", "pdf": "https://arxiv.org/pdf/2403.09948", "abs": "https://arxiv.org/abs/2403.09948", "authors": ["Zhixiu Lu", "Hailong Li", "Nehal A. Parikh", "Jonathan R. Dillman", "Lili He"], "title": "RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The integration of artificial intelligence (AI) with radiology marks a\ntransformative era in medicine. Vision foundation models have been adopted to\nenhance radiologic imaging analysis. However, the distinct complexities of\nradiologic 2D and 3D radiologic data pose unique challenges that existing\nmodels, pre-trained on general non-medical images, fail to address adequately.\nTo bridge this gap and capitalize on the diagnostic precision required in\nradiologic imaging, we introduce Radiologic Contrastive Language-Image\nPre-training (RadCLIP): a cross-modal vision-language foundational model that\nharnesses Vision Language Pre-training (VLP) framework to improve radiologic\nimage analysis. Building upon Contrastive Language-Image Pre-training (CLIP),\nRadCLIP incorporates a slice pooling mechanism tailored for volumetric image\nanalysis and is pre-trained using a large and diverse dataset of radiologic\nimage-text pairs. The RadCLIP was pre-trained to effectively align radiologic\nimages with their corresponding text annotations, creating a robust vision\nbackbone for radiologic images. Extensive experiments demonstrate RadCLIP's\nsuperior performance in both uni-modal radiologic image classification and\ncross-modal image-text matching, highlighting its significant promise for\nimproving diagnostic accuracy and efficiency in clinical settings. Our Key\ncontributions include curating a large dataset with diverse radiologic 2D/3D\nradiologic image-text pairs, a slice pooling adapter using an attention\nmechanism for integrating 2D images, and comprehensive evaluations of RadCLIP\non various radiologic downstream tasks."}
{"id": "2505.14264", "pdf": "https://arxiv.org/pdf/2505.14264", "abs": "https://arxiv.org/abs/2505.14264", "authors": ["Jian Xiong", "Jingbo Zhou", "Jingyong Ye", "Dejing Dou"], "title": "AAPO: Enhance the Reasoning Capabilities of LLMs with Advantage Momentum", "categories": ["cs.LG", "cs.CL"], "comment": "14 pages, 7 figures", "summary": "Reinforcement learning (RL) has emerged as an effective approach for\nenhancing the reasoning capabilities of large language models (LLMs),\nespecially in scenarios where supervised fine-tuning (SFT) falls short due to\nlimited chain-of-thought (CoT) data. Among RL-based post-training methods,\ngroup relative advantage estimation, as exemplified by Group Relative Policy\nOptimization (GRPO), has attracted considerable attention for eliminating the\ndependency on the value model, thereby simplifying training compared to\ntraditional approaches like Proximal Policy Optimization (PPO). However, we\nobserve that exsiting group relative advantage estimation method still suffers\nfrom training inefficiencies, particularly when the estimated advantage\napproaches zero. To address this limitation, we propose Advantage-Augmented\nPolicy Optimization (AAPO), a novel RL algorithm that optimizes the\ncross-entropy (CE) loss using advantages enhanced through a momentum-based\nestimation scheme. This approach effectively mitigates the inefficiencies\nassociated with group relative advantage estimation. Experimental results on\nmultiple mathematical reasoning benchmarks demonstrate the superior performance\nof AAPO."}
{"id": "2505.13766", "pdf": "https://arxiv.org/pdf/2505.13766", "abs": "https://arxiv.org/abs/2505.13766", "authors": ["Avinash Patil"], "title": "Advancing Software Quality: A Standards-Focused Review of LLM-Based Assurance Techniques", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "16 pages, 1 Table, 6 Figures", "summary": "Software Quality Assurance (SQA) is critical for delivering reliable, secure,\nand efficient software products. The Software Quality Assurance Process aims to\nprovide assurance that work products and processes comply with predefined\nprovisions and plans. Recent advancements in Large Language Models (LLMs)\npresent new opportunities to enhance existing SQA processes by automating tasks\nlike requirement analysis, code review, test generation, and compliance checks.\nSimultaneously, established standards such as ISO/IEC 12207, ISO/IEC 25010,\nISO/IEC 5055, ISO 9001/ISO/IEC 90003, CMMI, and TMM provide structured\nframeworks for ensuring robust quality practices. This paper surveys the\nintersection of LLM-based SQA methods and these recognized standards,\nhighlighting how AI-driven solutions can augment traditional approaches while\nmaintaining compliance and process maturity. We first review the foundational\nsoftware quality standards and the technical fundamentals of LLMs in software\nengineering. Next, we explore various LLM-based SQA applications, including\nrequirement validation, defect detection, test generation, and documentation\nmaintenance. We then map these applications to key software quality frameworks,\nillustrating how LLMs can address specific requirements and metrics within each\nstandard. Empirical case studies and open-source initiatives demonstrate the\npractical viability of these methods. At the same time, discussions on\nchallenges (e.g., data privacy, model bias, explainability) underscore the need\nfor deliberate governance and auditing. Finally, we propose future directions\nencompassing adaptive learning, privacy-focused deployments, multimodal\nanalysis, and evolving standards for AI-driven software quality."}
{"id": "2505.14455", "pdf": "https://arxiv.org/pdf/2505.14455", "abs": "https://arxiv.org/abs/2505.14455", "authors": ["Chihan Huang", "Hao Tang"], "title": "CtrlDiff: Boosting Large Diffusion Language Models with Dynamic Block Prediction and Controllable Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although autoregressive models have dominated language modeling in recent\nyears, there has been a growing interest in exploring alternative paradigms to\nthe conventional next-token prediction framework. Diffusion-based language\nmodels have emerged as a compelling alternative due to their powerful parallel\ngeneration capabilities and inherent editability. However, these models are\noften constrained by fixed-length generation. A promising direction is to\ncombine the strengths of both paradigms, segmenting sequences into blocks,\nmodeling autoregressive dependencies across blocks while leveraging discrete\ndiffusion to estimate the conditional distribution within each block given the\npreceding context. Nevertheless, their practical application is often hindered\nby two key limitations: rigid fixed-length outputs and a lack of flexible\ncontrol mechanisms. In this work, we address the critical limitations of fixed\ngranularity and weak controllability in current large diffusion language\nmodels. We propose CtrlDiff, a dynamic and controllable semi-autoregressive\nframework that adaptively determines the size of each generation block based on\nlocal semantics using reinforcement learning. Furthermore, we introduce a\nclassifier-guided control mechanism tailored to discrete diffusion, which\nsignificantly reduces computational overhead while facilitating efficient\npost-hoc conditioning without retraining. Extensive experiments demonstrate\nthat CtrlDiff sets a new standard among hybrid diffusion models, narrows the\nperformance gap to state-of-the-art autoregressive approaches, and enables\neffective conditional text generation across diverse tasks."}
{"id": "2403.11083", "pdf": "https://arxiv.org/pdf/2403.11083", "abs": "https://arxiv.org/abs/2403.11083", "authors": ["Xiaohao Xu", "Yunkang Cao", "Huaxin Zhang", "Nong Sang", "Xiaonan Huang"], "title": "Customizing Visual-Language Foundation Models for Multi-modal Anomaly Detection and Reasoning", "categories": ["cs.CV", "cs.CL"], "comment": "Best Student Paper Award at IEEE International Conference on Computer\n  Supported Cooperative Work in Design, 2025", "summary": "Anomaly detection is vital in various industrial scenarios, including the\nidentification of unusual patterns in production lines and the detection of\nmanufacturing defects for quality control. Existing techniques tend to be\nspecialized in individual scenarios and lack generalization capacities. In this\nstudy, our objective is to develop a generic anomaly detection model that can\nbe applied in multiple scenarios. To achieve this, we custom-build generic\nvisual language foundation models that possess extensive knowledge and robust\nreasoning abilities as anomaly detectors and reasoners. Specifically, we\nintroduce a multi-modal prompting strategy that incorporates domain knowledge\nfrom experts as conditions to guide the models. Our approach considers diverse\nprompt types, including task descriptions, class context, normality rules, and\nreference images. In addition, we unify the input representation of\nmulti-modality into a 2D image format, enabling multi-modal anomaly detection\nand reasoning. Our preliminary studies demonstrate that combining visual and\nlanguage prompts as conditions for customizing the models enhances anomaly\ndetection performance. The customized models showcase the ability to detect\nanomalies across different data modalities such as images, point clouds, and\nvideos. Qualitative case studies further highlight the anomaly detection and\nreasoning capabilities, particularly for multi-object scenes and temporal data.\nOur code is publicly available at\nhttps://github.com/Xiaohao-Xu/Customizable-VLM"}
{"id": "2505.14273", "pdf": "https://arxiv.org/pdf/2505.14273", "abs": "https://arxiv.org/abs/2505.14273", "authors": ["Hiroki Shiraishi", "Hisao Ishibuchi", "Masaya Nakata"], "title": "X-KAN: Optimizing Local Kolmogorov-Arnold Networks via Evolutionary Rule-Based Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "Accepted by the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)", "summary": "Function approximation is a critical task in various fields. However,\nexisting neural network approaches struggle with locally complex or\ndiscontinuous functions due to their reliance on a single global model covering\nthe entire problem space. We propose X-KAN, a novel method that optimizes\nmultiple local Kolmogorov-Arnold Networks (KANs) through an evolutionary\nrule-based machine learning framework called XCSF. X-KAN combines KAN's high\nexpressiveness with XCSF's adaptive partitioning capability by implementing\nlocal KAN models as rule consequents and defining local regions via rule\nantecedents. Our experimental results on artificial test functions and\nreal-world datasets demonstrate that X-KAN significantly outperforms\nconventional methods, including XCSF, Multi-Layer Perceptron, and KAN, in terms\nof approximation accuracy. Notably, X-KAN effectively handles functions with\nlocally complex or discontinuous structures that are challenging for\nconventional KAN, using a compact set of rules (average 7.2 $\\pm$ 2.3 rules).\nThese results validate the effectiveness of using KAN as a local model in XCSF,\nwhich evaluates the rule fitness based on both accuracy and generality. Our\nX-KAN implementation is available at https://github.com/YNU-NakataLab/X-KAN."}
{"id": "2505.13808", "pdf": "https://arxiv.org/pdf/2505.13808", "abs": "https://arxiv.org/abs/2505.13808", "authors": ["Faramarz Safi Esfahani", "Ghassan Beydoun", "Morteza Saberi", "Brad McCusker", "Biswajeet Pradhan"], "title": "RAG/LLM Augmented Switching Driven Polymorphic Metaheuristic Framework", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Metaheuristic algorithms are widely used for solving complex optimization\nproblems, yet their effectiveness is often constrained by fixed structures and\nthe need for extensive tuning. The Polymorphic Metaheuristic Framework (PMF)\naddresses this limitation by introducing a self-adaptive metaheuristic\nswitching mechanism driven by real-time performance feedback and dynamic\nalgorithmic selection. PMF leverages the Polymorphic Metaheuristic Agent (PMA)\nand the Polymorphic Metaheuristic Selection Agent (PMSA) to dynamically select\nand transition between metaheuristic algorithms based on key performance\nindicators, ensuring continuous adaptation. This approach enhances convergence\nspeed, adaptability, and solution quality, outperforming traditional\nmetaheuristics in high-dimensional, dynamic, and multimodal environments.\nExperimental results on benchmark functions demonstrate that PMF significantly\nimproves optimization efficiency by mitigating stagnation and balancing\nexploration-exploitation strategies across various problem landscapes. By\nintegrating AI-driven decision-making and self-correcting mechanisms, PMF paves\nthe way for scalable, intelligent, and autonomous optimization frameworks, with\npromising applications in engineering, logistics, and complex decision-making\nsystems."}
{"id": "2505.14464", "pdf": "https://arxiv.org/pdf/2505.14464", "abs": "https://arxiv.org/abs/2505.14464", "authors": ["Xiaoyu Tian", "Yunjie Ji", "Haotian Wang", "Shuaiting Chen", "Sitong Zhao", "Yiping Peng", "Han Zhao", "Xiangang Li"], "title": "Not All Correct Answers Are Equal: Why Your Distillation Source Matters", "categories": ["cs.CL"], "comment": null, "summary": "Distillation has emerged as a practical and effective approach to enhance the\nreasoning capabilities of open-source language models. In this work, we conduct\na large-scale empirical study on reasoning data distillation by collecting\nverified outputs from three state-of-the-art teacher models-AM-Thinking-v1,\nQwen3-235B-A22B, and DeepSeek-R1-on a shared corpus of 1.89 million queries. We\nconstruct three parallel datasets and analyze their distributions, revealing\nthat AM-Thinking-v1-distilled data exhibits greater token length diversity and\nlower perplexity. Student models trained on each dataset are evaluated on\nreasoning benchmarks including AIME2024, AIME2025, MATH500, and LiveCodeBench.\nThe AM-based model consistently achieves the best performance (e.g., 84.3 on\nAIME2024, 72.2 on AIME2025, 98.4 on MATH500, and 65.9 on LiveCodeBench) and\ndemonstrates adaptive output behavior-producing longer responses for harder\ntasks and shorter ones for simpler tasks. These findings highlight the value of\nhigh-quality, verified reasoning traces. We release the AM-Thinking-v1 and\nQwen3-235B-A22B distilled datasets to support future research on open and\nhigh-performing reasoning-oriented language models. The datasets are publicly\navailable on Hugging Face\\footnote{Datasets are available on Hugging Face:\n\\href{https://huggingface.co/datasets/a-m-team/AM-Thinking-v1-Distilled}{AM-Thinking-v1-Distilled},\n\\href{https://huggingface.co/datasets/a-m-team/AM-Qwen3-Distilled}{AM-Qwen3-Distilled}.}."}
{"id": "2403.13238", "pdf": "https://arxiv.org/pdf/2403.13238", "abs": "https://arxiv.org/abs/2403.13238", "authors": ["Qitong Yang", "Mingtao Feng", "Zijie Wu", "Shijie Sun", "Weisheng Dong", "Yaonan Wang", "Ajmal Mian"], "title": "Learning Coherent Matrixized Representation in Latent Space for Volumetric 4D Generation", "categories": ["cs.CV"], "comment": null, "summary": "Directly learning to model 4D content, including shape, color, and motion, is\nchallenging. Existing methods rely on pose priors for motion control, resulting\nin limited motion diversity and continuity in details. To address this, we\npropose a framework that generates volumetric 4D sequences, where 3D shapes are\nanimated under given conditions (text-image guidance) with dynamic evolution in\nshape and color across spatial and temporal dimensions, allowing for free\nnavigation and rendering from any direction. We first use a coherent 3D shape\nand color modeling to encode the shape and color of each detailed 3D geometry\nframe into a latent space. Then we propose a matrixized 4D sequence\nrepresentation allowing efficient diffusion model operation. Finally, we\nintroduce spatio-temporal diffusion for 4D volumetric generation under given\nimages and text prompts. Extensive experiments on the ShapeNet, 3DBiCar,\nDeformingThings4D and Objaverse datasets for several tasks demonstrate that our\nmethod effectively learns to generate high quality 3D shapes with consistent\ncolor and coherent mesh animations, improving over the current methods. Our\ncode will be publicly available."}
{"id": "2505.14302", "pdf": "https://arxiv.org/pdf/2505.14302", "abs": "https://arxiv.org/abs/2505.14302", "authors": ["Mengzhao Chen", "Chaoyi Zhang", "Jing Liu", "Yutao Zeng", "Zeyue Xue", "Zhiheng Liu", "Yunshui Li", "Jin Ma", "Jie Huang", "Xun Zhou", "Ping Luo"], "title": "Scaling Law for Quantization-Aware Training", "categories": ["cs.LG", "cs.CL"], "comment": "A unified scaling law for QAT that models quantization error as a\n  function of model size, training data volume, and quantization group size", "summary": "Large language models (LLMs) demand substantial computational and memory\nresources, creating deployment challenges. Quantization-aware training (QAT)\naddresses these challenges by reducing model precision while maintaining\nperformance. However, the scaling behavior of QAT, especially at 4-bit\nprecision (W4A4), is not well understood. Existing QAT scaling laws often\nignore key factors such as the number of training tokens and quantization\ngranularity, which limits their applicability. This paper proposes a unified\nscaling law for QAT that models quantization error as a function of model size,\ntraining data volume, and quantization group size. Through 268 QAT experiments,\nwe show that quantization error decreases as model size increases, but rises\nwith more training tokens and coarser quantization granularity. To identify the\nsources of W4A4 quantization error, we decompose it into weight and activation\ncomponents. Both components follow the overall trend of W4A4 quantization\nerror, but with different sensitivities. Specifically, weight quantization\nerror increases more rapidly with more training tokens. Further analysis shows\nthat the activation quantization error in the FC2 layer, caused by outliers, is\nthe primary bottleneck of W4A4 QAT quantization error. By applying\nmixed-precision quantization to address this bottleneck, we demonstrate that\nweight and activation quantization errors can converge to similar levels.\nAdditionally, with more training data, weight quantization error eventually\nexceeds activation quantization error, suggesting that reducing weight\nquantization error is also important in such scenarios. These findings offer\nkey insights for improving QAT research and development."}
{"id": "2505.13834", "pdf": "https://arxiv.org/pdf/2505.13834", "abs": "https://arxiv.org/abs/2505.13834", "authors": ["Zhi Su", "Yuman Gao", "Emily Lukas", "Yunfei Li", "Jiaze Cai", "Faris Tulbah", "Fei Gao", "Chao Yu", "Zhongyu Li", "Yi Wu", "Koushil Sreenath"], "title": "Toward Real-World Cooperative and Competitive Soccer with Quadrupedal Robot Teams", "categories": ["cs.RO", "cs.AI"], "comment": "11 pages, 12 figures", "summary": "Achieving coordinated teamwork among legged robots requires both fine-grained\nlocomotion control and long-horizon strategic decision-making. Robot soccer\noffers a compelling testbed for this challenge, combining dynamic, competitive,\nand multi-agent interactions. In this work, we present a hierarchical\nmulti-agent reinforcement learning (MARL) framework that enables fully\nautonomous and decentralized quadruped robot soccer. First, a set of highly\ndynamic low-level skills is trained for legged locomotion and ball\nmanipulation, such as walking, dribbling, and kicking. On top of these, a\nhigh-level strategic planning policy is trained with Multi-Agent Proximal\nPolicy Optimization (MAPPO) via Fictitious Self-Play (FSP). This learning\nframework allows agents to adapt to diverse opponent strategies and gives rise\nto sophisticated team behaviors, including coordinated passing, interception,\nand dynamic role allocation. With an extensive ablation study, the proposed\nlearning method shows significant advantages in the cooperative and competitive\nmulti-agent soccer game. We deploy the learned policies to real quadruped\nrobots relying solely on onboard proprioception and decentralized localization,\nwith the resulting system supporting autonomous robot-robot and robot-human\nsoccer matches on indoor and outdoor soccer courts."}
{"id": "2505.14467", "pdf": "https://arxiv.org/pdf/2505.14467", "abs": "https://arxiv.org/abs/2505.14467", "authors": ["Mani Shemiranifar"], "title": "Void in Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Despite advances in transformer-based language models (LMs), a fundamental\nquestion remains largely unanswered: Are all layers activated during inference?\nWe investigate this question by detecting unactivated layers (which we refer to\nas Voids) using a non-trainable and parameter-free adaptive computation method\ncalled L2 Adaptive Computation (LAC). We adapt LAC from its original\nefficiency-focused application to trace activated layers during inference. This\nmethod monitors changes in the L2-norm of activations to identify voids. We\nanalyze layer activation in instruction-tuned LMs across two phases: Prompt\nProcessing (PP), where we trace activated layers for each token in the input\nprompts, and Response Generation (RG), where we trace activated layers for each\ngenerated token. We further demonstrate that distinct layers are activated\nduring these two phases. To show the effectiveness of our method, we evaluated\nthree distinct instruction-tuned LMs from the Llama, Mistral, and Qwen families\non three benchmarks: MMLU, GPQA Diamond, and BoolQ. For example, on MMLU with a\nzero-shot setting, skipping voids in Qwen2.5-7B-Instruct resulted in an\nimprovement from 69.24 to 71.29 while the model uses only 30% of the layers.\nSimilarly, Mistral-7B-Instruct-v0.3 on GPQA Diamond improved from 13.88 to\n18.36 when using 70% of the layers during both the PP and RG phases. These\nresults show that not all layers contribute equally during inference, and that\nselectively skipping most of them can improve the performance of models on\ncertain tasks."}
{"id": "2404.14807", "pdf": "https://arxiv.org/pdf/2404.14807", "abs": "https://arxiv.org/abs/2404.14807", "authors": ["Siyuan Mei", "Fuxin Fan", "Mareike Thies", "Mingxuan Gu", "Fabian Wagner", "Oliver Aust", "Ina Erceg", "Zeynab Mirzaei", "Georgiana Neag", "Yipeng Sun", "Yixing Huang", "Andreas Maier"], "title": "BigReg: An Efficient Registration Pipeline for High-Resolution X-Ray and Light-Sheet Fluorescence Microscopy", "categories": ["cs.CV"], "comment": null, "summary": "Recently, X-ray microscopy (XRM) and light-sheet fluorescence microscopy\n(LSFM) have emerged as pivotal tools in preclinical research, particularly for\nstudying bone remodeling diseases such as osteoporosis. These modalities offer\nmicrometer-level resolution, and their integration allows for a complementary\nexamination of bone microstructures which is essential for analyzing functional\nchanges. However, registering high-resolution volumes from these independently\nscanned modalities poses substantial challenges, especially in real-world and\nreference-free scenarios. This paper presents BigReg, a fast, two-stage\npipeline designed for large-volume registration of XRM and LSFM data. The first\nstage involves extracting surface features and applying two successive point\ncloud-based methods for coarse alignment. The subsequent stage refines this\nalignment using a modified cross-correlation technique, achieving precise\nvolumetric registration. Evaluations using expert-annotated landmarks and\naugmented test data demonstrate that BigReg approaches the accuracy of\nlandmark-based registration with a landmark distance (LMD) of 8.36\\,\\textmu\nm\\,$\\pm$\\,0.12\\,\\textmu m and a landmark fitness (LM fitness) of\n85.71\\%\\,$\\pm$\\,1.02\\%. Moreover, BigReg can provide an optimal initialization\nfor mutual information-based methods which otherwise fail independently,\nfurther reducing LMD to 7.24\\,\\textmu m\\,$\\pm$\\,0.11\\,\\textmu m and increasing\nLM fitness to 93.90\\%\\,$\\pm$\\,0.77\\%. Ultimately, key microstructures, notably\nlacunae in XRM and bone cells in LSFM, are accurately aligned, enabling\nunprecedented insights into the pathology of osteoporosis."}
{"id": "2505.14312", "pdf": "https://arxiv.org/pdf/2505.14312", "abs": "https://arxiv.org/abs/2505.14312", "authors": ["Kyungeun Lee", "Moonjung Eo", "Hye-Seung Cho", "Dongmin Kim", "Ye Seul Sim", "Seoyoon Kim", "Min-Kook Suh", "Woohyung Lim"], "title": "MultiTab: A Comprehensive Benchmark Suite for Multi-Dimensional Evaluation in Tabular Domains", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Despite the widespread use of tabular data in real-world applications, most\nbenchmarks rely on average-case metrics, which fail to reveal how model\nbehavior varies across diverse data regimes. To address this, we propose\nMultiTab, a benchmark suite and evaluation framework for multi-dimensional,\ndata-aware analysis of tabular learning algorithms. Rather than comparing\nmodels only in aggregate, MultiTab categorizes 196 publicly available datasets\nalong key data characteristics, including sample size, label imbalance, and\nfeature interaction, and evaluates 13 representative models spanning a range of\ninductive biases. Our analysis shows that model performance is highly sensitive\nto such regimes: for example, models using sample-level similarity excel on\ndatasets with large sample sizes or high inter-feature correlation, while\nmodels encoding inter-feature dependencies perform best with weakly correlated\nfeatures. These findings reveal that inductive biases do not always behave as\nintended, and that regime-aware evaluation is essential for understanding and\nimproving model behavior. MultiTab enables more principled model design and\noffers practical guidance for selecting models tailored to specific data\ncharacteristics. All datasets, code, and optimization logs are publicly\navailable at https://huggingface.co/datasets/LGAI-DILab/Multitab."}
{"id": "2505.13837", "pdf": "https://arxiv.org/pdf/2505.13837", "abs": "https://arxiv.org/abs/2505.13837", "authors": ["Gokul Puthumanaillam", "Paulo Padrao", "Jose Fuentes", "Leonardo Bobadilla", "Melkior Ornik"], "title": "Enhancing Robot Navigation Policies with Task-Specific Uncertainty Managements", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Robots navigating complex environments must manage uncertainty from sensor\nnoise, environmental changes, and incomplete information, with different tasks\nrequiring varying levels of precision in different areas. For example, precise\nlocalization may be crucial near obstacles but less critical in open spaces. We\npresent GUIDE (Generalized Uncertainty Integration for Decision-Making and\nExecution), a framework that integrates these task-specific requirements into\nnavigation policies via Task-Specific Uncertainty Maps (TSUMs). By assigning\nacceptable uncertainty levels to different locations, TSUMs enable robots to\nadapt uncertainty management based on context. When combined with reinforcement\nlearning, GUIDE learns policies that balance task completion and uncertainty\nmanagement without extensive reward engineering. Real-world tests show\nsignificant performance gains over methods lacking task-specific uncertainty\nawareness."}
{"id": "2505.14469", "pdf": "https://arxiv.org/pdf/2505.14469", "abs": "https://arxiv.org/abs/2505.14469", "authors": ["Somnath Banerjee", "Pratyush Chatterjee", "Shanu Kumar", "Sayan Layek", "Parag Agrawal", "Rima Hazra", "Animesh Mukherjee"], "title": "Attributional Safety Failures in Large Language Models under Code-Mixed Perturbations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in LLMs have raised significant safety concerns,\nparticularly when dealing with code-mixed inputs and outputs. Our study\nsystematically investigates the increased susceptibility of LLMs to produce\nunsafe outputs from code-mixed prompts compared to monolingual English prompts.\nUtilizing explainability methods, we dissect the internal attribution shifts\ncausing model's harmful behaviors. In addition, we explore cultural dimensions\nby distinguishing between universally unsafe and culturally-specific unsafe\nqueries. This paper presents novel experimental insights, clarifying the\nmechanisms driving this phenomenon."}
{"id": "2405.03159", "pdf": "https://arxiv.org/pdf/2405.03159", "abs": "https://arxiv.org/abs/2405.03159", "authors": ["Wenxin Fan", "Jian Cheng", "Qiyuan Tian", "Ruoyou Wu", "Juan Zou", "Zan Chen", "Shanshan Wang"], "title": "DeepMpMRI: Tensor-decomposition Regularized Learning for Fast and High-Fidelity Multi-Parametric Microstructural MR Imaging", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning has emerged as a promising approach for learning the nonlinear\nmapping between diffusion-weighted MR images and tissue parameters, which\nenables automatic and deep understanding of the brain microstructures. However,\nthe efficiency and accuracy in estimating multiple microstructural parameters\nderived from multiple diffusion models are still limited since previous studies\ntend to estimate parameter maps from distinct models with isolated signal\nmodeling and dense sampling. This paper proposes DeepMpMRI, an efficient\nframework for fast and high-fidelity multiple microstructural parameter\nestimation from multiple models using highly sparse sampled q-space data.\nDeepMpMRI is equipped with a newly designed tensor-decomposition-based\nregularizer to effectively capture fine details by exploiting the\nhigh-dimensional correlation across microstructural parameters. In addition, we\nintroduce a Nesterov-based adaptive learning algorithm that optimizes the\nregularization parameter dynamically to enhance the performance. DeepMpMRI is\nan extendable framework capable of incorporating flexible network architecture.\nExperimental results on the HCP dataset and the Alzheimer's disease dataset\nboth demonstrate the superiority of our approach over 5 state-of-the-art\nmethods in simultaneously estimating multi-model microstructural parameter maps\nfor DKI and NODDI model with fine-grained details both quantitatively and\nqualitatively, achieving 4.5 - 15 $\\times$ acceleration compared to the dense\nsampling of a total of 270 diffusion gradients."}
{"id": "2505.14338", "pdf": "https://arxiv.org/pdf/2505.14338", "abs": "https://arxiv.org/abs/2505.14338", "authors": ["Egor Bakaev", "Florestan Brunck", "Christoph Hertrich", "Jack Stade", "Amir Yehudayoff"], "title": "Better Neural Network Expressivity: Subdividing the Simplex", "categories": ["cs.LG", "cs.DM", "cs.NE", "math.CO"], "comment": "11 pages, 1 figure", "summary": "This work studies the expressivity of ReLU neural networks with a focus on\ntheir depth. A sequence of previous works showed that $\\lceil \\log_2(n+1)\n\\rceil$ hidden layers are sufficient to compute all continuous piecewise linear\n(CPWL) functions on $\\mathbb{R}^n$. Hertrich, Basu, Di Summa, and Skutella\n(NeurIPS'21) conjectured that this result is optimal in the sense that there\nare CPWL functions on $\\mathbb{R}^n$, like the maximum function, that require\nthis depth. We disprove the conjecture and show that\n$\\lceil\\log_3(n-1)\\rceil+1$ hidden layers are sufficient to compute all CPWL\nfunctions on $\\mathbb{R}^n$.\n  A key step in the proof is that ReLU neural networks with two hidden layers\ncan exactly represent the maximum function of five inputs. More generally, we\nshow that $\\lceil\\log_3(n-2)\\rceil+1$ hidden layers are sufficient to compute\nthe maximum of $n\\geq 4$ numbers. Our constructions almost match the\n$\\lceil\\log_3(n)\\rceil$ lower bound of Averkov, Hojny, and Merkert (ICLR'25) in\nthe special case of ReLU networks with weights that are decimal fractions. The\nconstructions have a geometric interpretation via polyhedral subdivisions of\nthe simplex into ``easier'' polytopes."}
{"id": "2505.13872", "pdf": "https://arxiv.org/pdf/2505.13872", "abs": "https://arxiv.org/abs/2505.13872", "authors": ["Jingzheng Li", "Tiancheng Wang", "Xingyu Peng", "Jiacheng Chen", "Zhijun Chen", "Bing Li", "Xianglong Liu"], "title": "Safety2Drive: Safety-Critical Scenario Benchmark for the Evaluation of Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Autonomous Driving (AD) systems demand the high levels of safety assurance.\nDespite significant advancements in AD demonstrated on open-source benchmarks\nlike Longest6 and Bench2Drive, existing datasets still lack\nregulatory-compliant scenario libraries for closed-loop testing to\ncomprehensively evaluate the functional safety of AD. Meanwhile, real-world AD\naccidents are underrepresented in current driving datasets. This scarcity leads\nto inadequate evaluation of AD performance, posing risks to safety validation\nand practical deployment. To address these challenges, we propose Safety2Drive,\na safety-critical scenario library designed to evaluate AD systems.\nSafety2Drive offers three key contributions. (1) Safety2Drive comprehensively\ncovers the test items required by standard regulations and contains 70 AD\nfunction test items. (2) Safety2Drive supports the safety-critical scenario\ngeneralization. It has the ability to inject safety threats such as natural\nenvironment corruptions and adversarial attacks cross camera and LiDAR sensors.\n(3) Safety2Drive supports multi-dimensional evaluation. In addition to the\nevaluation of AD systems, it also supports the evaluation of various perception\ntasks, such as object detection and lane detection. Safety2Drive provides a\nparadigm from scenario construction to validation, establishing a standardized\ntest framework for the safe deployment of AD."}
{"id": "2505.14471", "pdf": "https://arxiv.org/pdf/2505.14471", "abs": "https://arxiv.org/abs/2505.14471", "authors": ["Tong Li", "Jiachuan Wang", "Yongqi Zhang", "Shuangyin Li", "Lei Chen"], "title": "Adapting Pretrained Language Models for Citation Classification via Self-Supervised Contrastive Learning", "categories": ["cs.CL"], "comment": "Manuscripts, accepted to KDD 2025", "summary": "Citation classification, which identifies the intention behind academic\ncitations, is pivotal for scholarly analysis. Previous works suggest\nfine-tuning pretrained language models (PLMs) on citation classification\ndatasets, reaping the reward of the linguistic knowledge they gained during\npretraining. However, directly fine-tuning for citation classification is\nchallenging due to labeled data scarcity, contextual noise, and spurious\nkeyphrase correlations. In this paper, we present a novel framework, Citss,\nthat adapts the PLMs to overcome these challenges. Citss introduces\nself-supervised contrastive learning to alleviate data scarcity, and is\nequipped with two specialized strategies to obtain the contrastive pairs:\nsentence-level cropping, which enhances focus on target citations within long\ncontexts, and keyphrase perturbation, which mitigates reliance on specific\nkeyphrases. Compared with previous works that are only designed for\nencoder-based PLMs, Citss is carefully developed to be compatible with both\nencoder-based PLMs and decoder-based LLMs, to embrace the benefits of enlarged\npretraining. Experiments with three benchmark datasets with both encoder-based\nPLMs and decoder-based LLMs demonstrate our superiority compared to the\nprevious state of the art. Our code is available at: github.com/LITONG99/Citss"}
{"id": "2406.18012", "pdf": "https://arxiv.org/pdf/2406.18012", "abs": "https://arxiv.org/abs/2406.18012", "authors": ["Subin Varghese", "Vedhus Hoskere"], "title": "View-Invariant Pixelwise Anomaly Detection in Multi-object Scenes with Adaptive View Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The built environment, encompassing critical infrastructure such as bridges\nand buildings, requires diligent monitoring of unexpected anomalies or\ndeviations from a normal state in captured imagery. Anomaly detection methods\ncould aid in automating this task; however, deploying anomaly detection\neffectively in such environments presents significant challenges that have not\nbeen evaluated before. These challenges include camera viewpoints that vary,\nthe presence of multiple objects within a scene, and the absence of labeled\nanomaly data for training. To address these comprehensively, we introduce and\nformalize Scene Anomaly Detection (Scene AD) as the task of unsupervised,\npixel-wise anomaly localization under these specific real-world conditions.\nEvaluating progress in Scene AD required the development of ToyCity, the first\nmulti-object, multi-view real-image dataset, for unsupervised anomaly\ndetection. Our initial evaluations using ToyCity revealed that established\nanomaly detection baselines struggle to achieve robust pixel-level\nlocalization. To address this, two data augmentation strategies were created to\ngenerate additional synthetic images of non-anomalous regions to enhance\ngeneralizability. However, the addition of these synthetic images alone only\nprovided minor improvements. Thus, OmniAD, a refinement of the Reverse\nDistillation methodology, was created to establish a stronger baseline. Our\nexperiments demonstrate that OmniAD, when used with augmented views, yields a\n64.33\\% increase in pixel-wise \\(F_1\\) score over Reverse Distillation with no\naugmentation. Collectively, this work offers the Scene AD task definition, the\nToyCity benchmark, the view synthesis augmentation approaches, and the OmniAD\nmethod. Project Page: https://drags99.github.io/OmniAD/"}
{"id": "2505.14345", "pdf": "https://arxiv.org/pdf/2505.14345", "abs": "https://arxiv.org/abs/2505.14345", "authors": ["Aydin Abedinia", "Shima Tabakhi", "Vahid Seydi"], "title": "Enhancing Classification with Semi-Supervised Deep Learning Using Distance-Based Sample Weights", "categories": ["cs.LG", "cs.AI", "68T05, 62H30", "I.2.6; I.5.1; I.5.4"], "comment": "5 pages, 6 figures. This paper has been accepted for publication and\n  oral presentation at the 2025 10th IEEE International Conference on Machine\n  Learning Technologies (ICMLT 2025). The final authenticated version will be\n  available in IEEE Xplore following the conference", "summary": "Recent advancements in semi-supervised deep learning have introduced\neffective strategies for leveraging both labeled and unlabeled data to improve\nclassification performance. This work proposes a semi-supervised framework that\nutilizes a distance-based weighting mechanism to prioritize critical training\nsamples based on their proximity to test data. By focusing on the most\ninformative examples, the method enhances model generalization and robustness,\nparticularly in challenging scenarios with noisy or imbalanced datasets.\nBuilding on techniques such as uncertainty consistency and graph-based\nrepresentations, the approach addresses key challenges of limited labeled data\nwhile maintaining scalability. Experiments on twelve benchmark datasets\ndemonstrate significant improvements across key metrics, including accuracy,\nprecision, and recall, consistently outperforming existing methods. This\nframework provides a robust and practical solution for semi-supervised\nlearning, with potential applications in domains such as healthcare and\nsecurity where data limitations pose significant challenges."}
{"id": "2505.13921", "pdf": "https://arxiv.org/pdf/2505.13921", "abs": "https://arxiv.org/abs/2505.13921", "authors": ["Wanjing Huang", "Weixiang Yan", "Zhen Zhang", "Ambuj Singh"], "title": "APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate strong reasoning and task planning\ncapabilities but remain fundamentally limited in physical interaction modeling.\nExisting approaches integrate perception via Vision-Language Models (VLMs) or\nadaptive decision-making through Reinforcement Learning (RL), but they fail to\ncapture dynamic object interactions or require task-specific training, limiting\ntheir real-world applicability. We introduce APEX (Anticipatory\nPhysics-Enhanced Execution), a framework that equips LLMs with physics-driven\nforesight for real-time task planning. APEX constructs structured graphs to\nidentify and model the most relevant dynamic interactions in the environment,\nproviding LLMs with explicit physical state updates. Simultaneously, APEX\nprovides low-latency forward simulations of physically feasible actions,\nallowing LLMs to select optimal strategies based on predictive outcomes rather\nthan static observations. We evaluate APEX on three benchmarks designed to\nassess perception, prediction, and decision-making: (1) Physics Reasoning\nBenchmark, testing causal inference and object motion prediction; (2) Tetris,\nevaluating whether physics-informed prediction enhances decision-making\nperformance in long-horizon planning tasks; (3) Dynamic Obstacle Avoidance,\nassessing the immediate integration of perception and action feasibility\nanalysis. APEX significantly outperforms standard LLMs and VLM-based models,\ndemonstrating the necessity of explicit physics reasoning for bridging the gap\nbetween language-based intelligence and real-world task execution. The source\ncode and experiment setup are publicly available at\nhttps://github.com/hwj20/APEX_EXP ."}
{"id": "2505.14481", "pdf": "https://arxiv.org/pdf/2505.14481", "abs": "https://arxiv.org/abs/2505.14481", "authors": ["He Zhu", "Junyou Su", "Minxi Chen", "Wen Wang", "Yijie Deng", "Guanhua Chen", "Wenjia Zhang"], "title": "PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language Models", "categories": ["cs.CL"], "comment": null, "summary": "In the field of urban planning, existing Vision-Language Models (VLMs)\nfrequently fail to effectively analyze and evaluate planning maps, despite the\ncritical importance of these visual elements for urban planners and related\neducational contexts. Planning maps, which visualize land use, infrastructure\nlayouts, and functional zoning, require specialized understanding of spatial\nconfigurations, regulatory requirements, and multi-scale analysis. To address\nthis challenge, we introduce PlanGPT-VL, the first domain-specific\nVision-Language Model tailored specifically for urban planning maps. PlanGPT-VL\nemploys three innovative approaches: (1) PlanAnno-V framework for high-quality\nVQA data synthesis, (2) Critical Point Thinking to reduce hallucinations\nthrough structured verification, and (3) comprehensive training methodology\ncombining Supervised Fine-Tuning with frozen vision encoder parameters. Through\nsystematic evaluation on our proposed PlanBench-V benchmark, we demonstrate\nthat PlanGPT-VL significantly outperforms general-purpose state-of-the-art VLMs\nin specialized planning map interpretation tasks, offering urban planning\nprofessionals a reliable tool for map analysis, assessment, and educational\napplications while maintaining high factual accuracy. Our lightweight 7B\nparameter model achieves comparable performance to models exceeding 72B\nparameters, demonstrating efficient domain specialization without sacrificing\nperformance."}
{"id": "2407.10707", "pdf": "https://arxiv.org/pdf/2407.10707", "abs": "https://arxiv.org/abs/2407.10707", "authors": ["Youyi Zhan", "Tianjia Shao", "He Wang", "Yin Yang", "Kun Zhou"], "title": "Interactive Rendering of Relightable and Animatable Gaussian Avatars", "categories": ["cs.CV"], "comment": "IEEE Transactions on Visualization and Computer Graphics. Project\n  page https://gapszju.github.io/InteractRAGA . Code\n  https://github.com/1231234zhan/InteractRAGA", "summary": "Creating relightable and animatable avatars from multi-view or monocular\nvideos is a challenging task for digital human creation and virtual reality\napplications. Previous methods rely on neural radiance fields or ray tracing,\nresulting in slow training and rendering processes. By utilizing Gaussian\nSplatting, we propose a simple and efficient method to decouple body materials\nand lighting from sparse-view or monocular avatar videos, so that the avatar\ncan be rendered simultaneously under novel viewpoints, poses, and lightings at\ninteractive frame rates (6.9 fps). Specifically, we first obtain the canonical\nbody mesh using a signed distance function and assign attributes to each mesh\nvertex. The Gaussians in the canonical space then interpolate from nearby body\nmesh vertices to obtain the attributes. We subsequently deform the Gaussians to\nthe posed space using forward skinning, and combine the learnable environment\nlight with the Gaussian attributes for shading computation. To achieve fast\nshadow modeling, we rasterize the posed body mesh from dense viewpoints to\nobtain the visibility. Our approach is not only simple but also fast enough to\nallow interactive rendering of avatar animation under environmental light\nchanges. Experiments demonstrate that, compared to previous works, our method\ncan render higher quality results at a faster speed on both synthetic and real\ndatasets."}
{"id": "2505.14352", "pdf": "https://arxiv.org/pdf/2505.14352", "abs": "https://arxiv.org/abs/2505.14352", "authors": ["Bartosz Cywi≈Ñski", "Emil Ryd", "Senthooran Rajamanoharan", "Neel Nanda"], "title": "Towards eliciting latent knowledge from LLMs with mechanistic interpretability", "categories": ["cs.LG"], "comment": null, "summary": "As language models become more powerful and sophisticated, it is crucial that\nthey remain trustworthy and reliable. There is concerning preliminary evidence\nthat models may attempt to deceive or keep secrets from their operators. To\nexplore the ability of current techniques to elicit such hidden knowledge, we\ntrain a Taboo model: a language model that describes a specific secret word\nwithout explicitly stating it. Importantly, the secret word is not presented to\nthe model in its training data or prompt. We then investigate methods to\nuncover this secret. First, we evaluate non-interpretability (black-box)\napproaches. Subsequently, we develop largely automated strategies based on\nmechanistic interpretability techniques, including logit lens and sparse\nautoencoders. Evaluation shows that both approaches are effective in eliciting\nthe secret word in our proof-of-concept setting. Our findings highlight the\npromise of these approaches for eliciting hidden knowledge and suggest several\npromising avenues for future work, including testing and refining these methods\non more complex model organisms. This work aims to be a step towards addressing\nthe crucial problem of eliciting secret knowledge from language models, thereby\ncontributing to their safe and reliable deployment."}
{"id": "2505.14483", "pdf": "https://arxiv.org/pdf/2505.14483", "abs": "https://arxiv.org/abs/2505.14483", "authors": ["Agam Goyal", "Xianyang Zhan", "Yilun Chen", "Koustuv Saha", "Eshwar Chandrasekharan"], "title": "MoMoE: Mixture of Moderation Experts Framework for AI-Assisted Online Governance", "categories": ["cs.CL"], "comment": "Preprint: 15 pages, 4 figures, 2 tables", "summary": "Large language models (LLMs) have shown great potential in flagging harmful\ncontent in online communities. Yet, existing approaches for moderation require\na separate model for every community and are opaque in their decision-making,\nlimiting real-world adoption. We introduce Mixture of Moderation Experts\n(MoMoE), a modular, cross-community framework that adds post-hoc explanations\nto scalable content moderation. MoMoE orchestrates four operators -- Allocate,\nPredict, Aggregate, Explain -- and is instantiated as seven\ncommunity-specialized experts (MoMoE-Community) and five norm-violation experts\n(MoMoE-NormVio). On 30 unseen subreddits, the best variants obtain Micro-F1\nscores of 0.72 and 0.67, respectively, matching or surpassing strong fine-tuned\nbaselines while consistently producing concise and reliable explanations.\nAlthough community-specialized experts deliver the highest peak accuracy,\nnorm-violation experts provide steadier performance across domains. These\nfindings show that MoMoE yields scalable, transparent moderation without\nneeding per-community fine-tuning. More broadly, they suggest that lightweight,\nexplainable expert ensembles can guide future NLP and HCI research on\ntrustworthy human-AI governance of online communities."}
{"id": "2407.11850", "pdf": "https://arxiv.org/pdf/2407.11850", "abs": "https://arxiv.org/abs/2407.11850", "authors": ["Nir Barel", "Ron Shapira Weber", "Nir Mualem", "Shahaf E. Finder", "Oren Freifeld"], "title": "SpaceJAM: a Lightweight and Regularization-free Method for Fast Joint Alignment of Images", "categories": ["cs.CV"], "comment": "Accepted to ECCV 2024", "summary": "The unsupervised task of Joint Alignment (JA) of images is beset by\nchallenges such as high complexity, geometric distortions, and convergence to\npoor local or even global optima. Although Vision Transformers (ViT) have\nrecently provided valuable features for JA, they fall short of fully addressing\nthese issues. Consequently, researchers frequently depend on expensive models\nand numerous regularization terms, resulting in long training times and\nchallenging hyperparameter tuning. We introduce the Spatial Joint Alignment\nModel (SpaceJAM), a novel approach that addresses the JA task with efficiency\nand simplicity. SpaceJAM leverages a compact architecture with only 16K\ntrainable parameters and uniquely operates without the need for regularization\nor atlas maintenance. Evaluations on SPair-71K and CUB datasets demonstrate\nthat SpaceJAM matches the alignment capabilities of existing methods while\nsignificantly reducing computational demands and achieving at least a 10x\nspeedup. SpaceJAM sets a new standard for rapid and effective image alignment,\nmaking the process more accessible and efficient. Our code is available at:\nhttps://bgu-cs-vil.github.io/SpaceJAM/."}
{"id": "2505.14371", "pdf": "https://arxiv.org/pdf/2505.14371", "abs": "https://arxiv.org/abs/2505.14371", "authors": ["Anh Duc Nguyen", "Ilia Markov", "Frank Zhengqing Wu", "Ali Ramezani-Kebrya", "Kimon Antonakopoulos", "Dan Alistarh", "Volkan Cevher"], "title": "Layer-wise Quantization for Quantized Optimistic Dual Averaging", "categories": ["cs.LG", "math.OC"], "comment": "Accepted at the International Conference on Machine Learning (ICML\n  2025)", "summary": "Modern deep neural networks exhibit heterogeneity across numerous layers of\nvarious types such as residuals, multi-head attention, etc., due to varying\nstructures (dimensions, activation functions, etc.), distinct representation\ncharacteristics, which impact predictions. We develop a general layer-wise\nquantization framework with tight variance and code-length bounds, adapting to\nthe heterogeneities over the course of training. We then apply a new layer-wise\nquantization technique within distributed variational inequalities (VIs),\nproposing a novel Quantized Optimistic Dual Averaging (QODA) algorithm with\nadaptive learning rates, which achieves competitive convergence rates for\nmonotone VIs. We empirically show that QODA achieves up to a $150\\%$ speedup\nover the baselines in end-to-end training time for training Wasserstein GAN on\n$12+$ GPUs."}
{"id": "2505.13969", "pdf": "https://arxiv.org/pdf/2505.13969", "abs": "https://arxiv.org/abs/2505.13969", "authors": ["Junya Nakanishi", "Jun Baba", "Yuichiro Yoshikawa", "Hiroko Kamide", "Hiroshi Ishiguro"], "title": "Hypothesis on the Functional Advantages of the Selection-Broadcast Cycle Structure: Global Workspace Theory and Dealing with a Real-Time World", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "This paper discusses the functional advantages of the Selection-Broadcast\nCycle structure proposed by Global Workspace Theory (GWT), inspired by human\nconsciousness, particularly focusing on its applicability to artificial\nintelligence and robotics in dynamic, real-time scenarios. While previous\nstudies often examined the Selection and Broadcast processes independently,\nthis research emphasizes their combined cyclic structure and the resulting\nbenefits for real-time cognitive systems. Specifically, the paper identifies\nthree primary benefits: Dynamic Thinking Adaptation, Experience-Based\nAdaptation, and Immediate Real-Time Adaptation. This work highlights GWT's\npotential as a cognitive architecture suitable for sophisticated\ndecision-making and adaptive performance in unsupervised, dynamic environments.\nIt suggests new directions for the development and implementation of robust,\ngeneral-purpose AI and robotics systems capable of managing complex, real-world\ntasks."}
{"id": "2505.14499", "pdf": "https://arxiv.org/pdf/2505.14499", "abs": "https://arxiv.org/abs/2505.14499", "authors": ["Jun Cao", "Jiyi Li", "Ziwei Yang", "Renjie Zhou"], "title": "Enhanced Multimodal Aspect-Based Sentiment Analysis by LLM-Generated Rationales", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "There has been growing interest in Multimodal Aspect-Based Sentiment Analysis\n(MABSA) in recent years. Existing methods predominantly rely on pre-trained\nsmall language models (SLMs) to collect information related to aspects and\nsentiments from both image and text, with an aim to align these two modalities.\nHowever, small SLMs possess limited capacity and knowledge, often resulting in\ninaccurate identification of meaning, aspects, sentiments, and their\ninterconnections in textual and visual data. On the other hand, Large language\nmodels (LLMs) have shown exceptional capabilities in various tasks by\neffectively exploring fine-grained information in multimodal data. However,\nsome studies indicate that LLMs still fall short compared to fine-tuned small\nmodels in the field of ABSA. Based on these findings, we propose a novel\nframework, termed LRSA, which combines the decision-making capabilities of SLMs\nwith additional information provided by LLMs for MABSA. Specifically, we inject\nexplanations generated by LLMs as rationales into SLMs and employ a dual\ncross-attention mechanism for enhancing feature interaction and fusion, thereby\naugmenting the SLMs' ability to identify aspects and sentiments. We evaluated\nour method using two baseline models, numerous experiments highlight the\nsuperiority of our approach on three widely-used benchmarks, indicating its\ngeneralizability and applicability to most pre-trained models for MABSA."}
{"id": "2407.13911", "pdf": "https://arxiv.org/pdf/2407.13911", "abs": "https://arxiv.org/abs/2407.13911", "authors": ["Qifan Zhang", "Yunhui Guo", "Yu Xiang"], "title": "Continual Distillation Learning: Knowledge Distillation in Prompt-based Continual Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We introduce the problem of continual distillation learning (CDL) in order to\nuse knowledge distillation (KD) to improve prompt-based continual learning (CL)\nmodels. The CDL problem is valuable to study since the use of a larger vision\ntransformer (ViT) leads to better performance in prompt-based continual\nlearning. The distillation of knowledge from a large ViT to a small ViT\nimproves the inference efficiency for prompt-based CL models. We empirically\nfound that existing KD methods such as logit distillation and feature\ndistillation cannot effectively improve the student model in the CDL setup. To\naddress this issue, we introduce a novel method named Knowledge Distillation\nbased on Prompts (KDP), in which globally accessible prompts specifically\ndesigned for knowledge distillation are inserted into the frozen ViT backbone\nof the student model. We demonstrate that our KDP method effectively enhances\nthe distillation performance in comparison to existing KD methods in the CDL\nsetup."}
{"id": "2505.14388", "pdf": "https://arxiv.org/pdf/2505.14388", "abs": "https://arxiv.org/abs/2505.14388", "authors": ["Prasanna Parasurama", "Panos Ipeirotis"], "title": "Algorithmic Hiring and Diversity: Reducing Human-Algorithm Similarity for Better Outcomes", "categories": ["cs.LG", "cs.HC", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Algorithmic tools are increasingly used in hiring to improve fairness and\ndiversity, often by enforcing constraints such as gender-balanced candidate\nshortlists. However, we show theoretically and empirically that enforcing equal\nrepresentation at the shortlist stage does not necessarily translate into more\ndiverse final hires, even when there is no gender bias in the hiring stage. We\nidentify a crucial factor influencing this outcome: the correlation between the\nalgorithm's screening criteria and the human hiring manager's evaluation\ncriteria -- higher correlation leads to lower diversity in final hires. Using a\nlarge-scale empirical analysis of nearly 800,000 job applications across\nmultiple technology firms, we find that enforcing equal shortlists yields\nlimited improvements in hire diversity when the algorithmic screening closely\nmirrors the hiring manager's preferences. We propose a complementary\nalgorithmic approach designed explicitly to diversify shortlists by selecting\ncandidates likely to be overlooked by managers, yet still competitive according\nto their evaluation criteria. Empirical simulations show that this approach\nsignificantly enhances gender diversity in final hires without substantially\ncompromising hire quality. These findings highlight the importance of\nalgorithmic design choices in achieving organizational diversity goals and\nprovide actionable guidance for practitioners implementing fairness-oriented\nhiring algorithms."}
{"id": "2505.14027", "pdf": "https://arxiv.org/pdf/2505.14027", "abs": "https://arxiv.org/abs/2505.14027", "authors": ["Yifan Zeng"], "title": "CSAGC-IDS: A Dual-Module Deep Learning Network Intrusion Detection Model for Complex and Imbalanced Data", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As computer networks proliferate, the gravity of network intrusions has\nescalated, emphasizing the criticality of network intrusion detection systems\nfor safeguarding security. While deep learning models have exhibited promising\nresults in intrusion detection, they face challenges in managing\nhigh-dimensional, complex traffic patterns and imbalanced data categories. This\npaper presents CSAGC-IDS, a network intrusion detection model based on deep\nlearning techniques. CSAGC-IDS integrates SC-CGAN, a self-attention-enhanced\nconvolutional conditional generative adversarial network that generates\nhigh-quality data to mitigate class imbalance. Furthermore, CSAGC-IDS\nintegrates CSCA-CNN, a convolutional neural network enhanced through cost\nsensitive learning and channel attention mechanism, to extract features from\ncomplex traffic data for precise detection. Experiments conducted on the\nNSL-KDD dataset. CSAGC-IDS achieves an accuracy of 84.55% and an F1-score of\n84.52% in five-class classification task, and an accuracy of 91.09% and an F1\nscore of 92.04% in binary classification task.Furthermore, this paper provides\nan interpretability analysis of the proposed model, using SHAP and LIME to\nexplain the decision-making mechanisms of the model."}
{"id": "2505.14505", "pdf": "https://arxiv.org/pdf/2505.14505", "abs": "https://arxiv.org/abs/2505.14505", "authors": ["Jiale Kang", "Ziyin Yue", "Qingyu Yin", "Jiang Rui", "Weile Li", "Zening Lu", "Zhouran Ji"], "title": "ModRWKV: Transformer Multimodality in Linear Time", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Currently, most multimodal studies are based on large language models (LLMs)\nwith quadratic-complexity Transformer architectures. While linear models like\nRNNs enjoy low inference costs, their application has been largely limited to\nthe text-only modality. This work explores the capabilities of modern RNN\narchitectures in multimodal contexts. We propose ModRWKV-a decoupled multimodal\nframework built upon the RWKV7 architecture as its LLM backbone-which achieves\nmulti-source information fusion through dynamically adaptable heterogeneous\nmodality encoders. We designed the multimodal modules in ModRWKV with an\nextremely lightweight architecture and, through extensive experiments,\nidentified a configuration that achieves an optimal balance between performance\nand computational efficiency. ModRWKV leverages the pretrained weights of the\nRWKV7 LLM for initialization, which significantly accelerates multimodal\ntraining. Comparative experiments with different pretrained checkpoints further\ndemonstrate that such initialization plays a crucial role in enhancing the\nmodel's ability to understand multimodal signals. Supported by extensive\nexperiments, we conclude that modern RNN architectures present a viable\nalternative to Transformers in the domain of multimodal large language models\n(MLLMs). Furthermore, we identify the optimal configuration of the ModRWKV\narchitecture through systematic exploration."}
{"id": "2408.07337", "pdf": "https://arxiv.org/pdf/2408.07337", "abs": "https://arxiv.org/abs/2408.07337", "authors": ["Yucheng Xie", "Fu Feng", "Ruixiao Shi", "Jing Wang", "Yong Rui", "Xin Geng"], "title": "KIND: Knowledge Integration and Diversion for Training Decomposable Models", "categories": ["cs.CV"], "comment": null, "summary": "Pre-trained models have become the preferred backbone due to the increasing\ncomplexity of model parameters. However, traditional pre-trained models often\nface deployment challenges due to their fixed sizes, and are prone to negative\ntransfer when discrepancies arise between training tasks and target tasks. To\naddress this, we propose KIND, a novel pre-training method designed to\nconstruct decomposable models. KIND integrates knowledge by incorporating\nSingular Value Decomposition (SVD) as a structural constraint, with each basic\ncomponent represented as a combination of a column vector, singular value, and\nrow vector from U, \\Sigma, and V^\\top matrices. These components are\ncategorized into learngenes for encapsulating class-agnostic knowledge and\ntailors for capturing class-specific knowledge, with knowledge diversion\nfacilitated by a class gate mechanism during training. Extensive experiments\ndemonstrate that models pre-trained with KIND can be decomposed into learngenes\nand tailors, which can be adaptively recombined for diverse\nresource-constrained deployments. Moreover, for tasks with large domain shifts,\ntransferring only learngenes with task-agnostic knowledge, when combined with\nrandomly initialized tailors, effectively mitigates domain shifts. Code will be\nmade available at https://github.com/Te4P0t/KIND."}
{"id": "2505.14407", "pdf": "https://arxiv.org/pdf/2505.14407", "abs": "https://arxiv.org/abs/2505.14407", "authors": ["Aniket Salvi", "Gereon Weiss", "Mario Trapp"], "title": "Explaining Unreliable Perception in Automated Driving: A Fuzzy-based Monitoring Approach", "categories": ["cs.LG"], "comment": null, "summary": "Autonomous systems that rely on Machine Learning (ML) utilize online fault\ntolerance mechanisms, such as runtime monitors, to detect ML prediction errors\nand maintain safety during operation. However, the lack of human-interpretable\nexplanations for these errors can hinder the creation of strong assurances\nabout the system's safety and reliability. This paper introduces a novel\nfuzzy-based monitor tailored for ML perception components. It provides\nhuman-interpretable explanations about how different operating conditions\naffect the reliability of perception components and also functions as a runtime\nsafety monitor. We evaluated our proposed monitor using naturalistic driving\ndatasets as part of an automated driving case study. The interpretability of\nthe monitor was evaluated and we identified a set of operating conditions in\nwhich the perception component performs reliably. Additionally, we created an\nassurance case that links unit-level evidence of \\textit{correct} ML operation\nto system-level \\textit{safety}. The benchmarking demonstrated that our monitor\nachieved a better increase in safety (i.e., absence of hazardous situations)\nwhile maintaining availability (i.e., ability to perform the mission) compared\nto state-of-the-art runtime ML monitors in the evaluated dataset."}
{"id": "2505.14057", "pdf": "https://arxiv.org/pdf/2505.14057", "abs": "https://arxiv.org/abs/2505.14057", "authors": ["Yu Cui", "Feng Liu", "Jiawei Chen", "Xingyu Lou", "Changwang Zhang", "Jun Wang", "Yuegang Sun", "Xiaohu Yang", "Can Wang"], "title": "Field Matters: A lightweight LLM-enhanced Method for CTR Prediction", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Click-through rate (CTR) prediction is a fundamental task in modern\nrecommender systems. In recent years, the integration of large language models\n(LLMs) has been shown to effectively enhance the performance of traditional CTR\nmethods. However, existing LLM-enhanced methods often require extensive\nprocessing of detailed textual descriptions for large-scale instances or\nuser/item entities, leading to substantial computational overhead. To address\nthis challenge, this work introduces LLaCTR, a novel and lightweight\nLLM-enhanced CTR method that employs a field-level enhancement paradigm.\nSpecifically, LLaCTR first utilizes LLMs to distill crucial and lightweight\nsemantic knowledge from small-scale feature fields through self-supervised\nfield-feature fine-tuning. Subsequently, it leverages this field-level semantic\nknowledge to enhance both feature representation and feature interactions. In\nour experiments, we integrate LLaCTR with six representative CTR models across\nfour datasets, demonstrating its superior performance in terms of both\neffectiveness and efficiency compared to existing LLM-enhanced methods. Our\ncode is available at https://anonymous.4open.science/r/LLaCTR-EC46."}
{"id": "2505.14523", "pdf": "https://arxiv.org/pdf/2505.14523", "abs": "https://arxiv.org/abs/2505.14523", "authors": ["Michael Sullivan"], "title": "Exploring Graph Representations of Logical Forms for Language Modeling", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "To be published in ACL 2025 Findings", "summary": "We make the case for language models over logical forms (LFLMs), arguing that\nsuch models are more data-efficient than their textual counterparts. To that\nend, we introduce the Graph-based Formal-Logical Distributional Semantics\n(GFoLDS) prototype, a pretrained LM over graph representations of logical\nforms, as a proof-of-concept of LFLMs. Using GFoLDS, we present strong\nexperimental evidence that LFLMs can leverage the built-in, basic linguistic\nknowledge inherent in such models to immediately begin learning more complex\npatterns. On downstream tasks, we show that GFoLDS vastly outperforms textual,\ntransformer LMs pretrained on similar amounts of data, indicating that LFLMs\ncan learn with substantially less data than models over plain text.\nFurthermore, we show that the performance of this model is likely to scale with\nadditional parameters and pretraining data, suggesting the viability of LFLMs\nin real-world applications."}
{"id": "2408.14841", "pdf": "https://arxiv.org/pdf/2408.14841", "abs": "https://arxiv.org/abs/2408.14841", "authors": ["Suhee Yoon", "Sanghyu Yoon", "Ye Seul Sim", "Sungik Choi", "Kyungeun Lee", "Hye-Seung Cho", "Hankook Lee", "Woohyung Lim"], "title": "Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Out-of-distribution (OOD) detection, which determines whether a given sample\nis part of the in-distribution (ID), has recently shown promising results\nthrough training with synthetic OOD datasets. Nonetheless, existing methods\noften produce outliers that are considerably distant from the ID, showing\nlimited efficacy for capturing subtle distinctions between ID and OOD. To\naddress these issues, we propose a novel framework, Semantic Outlier generation\nvia Nuisance Awareness (SONA), which notably produces challenging outliers by\ndirectly leveraging pixel-space ID samples through diffusion models. Our\napproach incorporates SONA guidance, providing separate control over semantic\nand nuisance regions of ID samples. Thereby, the generated outliers achieve two\ncrucial properties: (i) they present explicit semantic-discrepant information,\nwhile (ii) maintaining various levels of nuisance resemblance with ID.\nFurthermore, the improved OOD detector training with SONA outliers facilitates\nlearning with a focus on semantic distinctions. Extensive experiments\ndemonstrate the effectiveness of our framework, achieving an impressive AUROC\nof 88% on near-OOD datasets, which surpasses the performance of baseline\nmethods by a significant margin of approximately 6%."}
{"id": "2505.14411", "pdf": "https://arxiv.org/pdf/2505.14411", "abs": "https://arxiv.org/abs/2505.14411", "authors": ["Leon G√∂tz", "Marcel Kollovieh", "Stephan G√ºnnemann", "Leo Schwinn"], "title": "Byte Pair Encoding for Efficient Time Series Forecasting", "categories": ["cs.LG"], "comment": "24 pages in total, 17 figures", "summary": "Existing time series tokenization methods predominantly encode a constant\nnumber of samples into individual tokens. This inflexible approach can generate\nexcessive tokens for even simple patterns like extended constant values,\nresulting in substantial computational overhead. Inspired by the success of\nbyte pair encoding, we propose the first pattern-centric tokenization scheme\nfor time series analysis. Based on a discrete vocabulary of frequent motifs,\nour method merges samples with underlying patterns into tokens, compressing\ntime series adaptively. Exploiting our finite set of motifs and the continuous\nproperties of time series, we further introduce conditional decoding as a\nlightweight yet powerful post-hoc optimization method, which requires no\ngradient computation and adds no computational overhead. On recent time series\nfoundation models, our motif-based tokenization improves forecasting\nperformance by 36% and boosts efficiency by 1990% on average. Conditional\ndecoding further reduces MSE by up to 44%. In an extensive analysis, we\ndemonstrate the adaptiveness of our tokenization to diverse temporal patterns,\nits generalization to unseen data, and its meaningful token representations\ncapturing distinct time series properties, including statistical moments and\ntrends."}
{"id": "2505.14530", "pdf": "https://arxiv.org/pdf/2505.14530", "abs": "https://arxiv.org/abs/2505.14530", "authors": ["Zhipeng Yang", "Junzhuo Li", "Siyu Xia", "Xuming Hu"], "title": "Internal Chain-of-Thought: Empirical Evidence for Layer-wise Subtask Scheduling in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "27 pages, 17 figures", "summary": "We show that large language models (LLMs) exhibit an $\\textit{internal\nchain-of-thought}$: they sequentially decompose and execute composite tasks\nlayer-by-layer. Two claims ground our study: (i) distinct subtasks are learned\nat different network depths, and (ii) these subtasks are executed sequentially\nacross layers. On a benchmark of 15 two-step composite tasks, we employ\nlayer-from context-masking and propose a novel cross-task patching method,\nconfirming (i). To examine claim (ii), we apply LogitLens to decode hidden\nstates, revealing a consistent layerwise execution pattern. We further\nreplicate our analysis on the real-world $\\text{TRACE}$ benchmark, observing\nthe same stepwise dynamics. Together, our results enhance LLMs transparency by\nshowing their capacity to internally plan and execute subtasks (or\ninstructions), opening avenues for fine-grained, instruction-level activation\nsteering."}
{"id": "2408.16305", "pdf": "https://arxiv.org/pdf/2408.16305", "abs": "https://arxiv.org/abs/2408.16305", "authors": ["Mian Zou", "Baosheng Yu", "Yibing Zhan", "Siwei Lyu", "Kede Ma"], "title": "Semantics-Oriented Multitask Learning for DeepFake Detection: A Joint Embedding Approach", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, the multimedia forensics and security community has seen\nremarkable progress in multitask learning for DeepFake (i.e., face forgery)\ndetection. The prevailing approach has been to frame DeepFake detection as a\nbinary classification problem augmented by manipulation-oriented auxiliary\ntasks. This scheme focuses on learning features specific to face manipulations\nwith limited generalizability. In this paper, we delve deeper into\nsemantics-oriented multitask learning for DeepFake detection, capturing the\nrelationships among face semantics via joint embedding. We first propose an\nautomated dataset expansion technique that broadens current face forgery\ndatasets to support semantics-oriented DeepFake detection tasks at both the\nglobal face attribute and local face region levels. Furthermore, we resort to\nthe joint embedding of face images and labels (depicted by text descriptions)\nfor prediction. This approach eliminates the need for manually setting\ntask-agnostic and task-specific parameters, which is typically required when\npredicting multiple labels directly from images. In addition, we employ\nbi-level optimization to dynamically balance the fidelity loss weightings of\nvarious tasks, making the training process fully automated. Extensive\nexperiments on six DeepFake datasets show that our method improves the\ngeneralizability of DeepFake detection and renders some degree of model\ninterpretation by providing human-understandable explanations."}
{"id": "2505.14415", "pdf": "https://arxiv.org/pdf/2505.14415", "abs": "https://arxiv.org/abs/2505.14415", "authors": ["Myung Jun Kim", "F√©lix Lefebvre", "Ga√´tan Brison", "Alexandre Perez-Lebel", "Ga√´l Varoquaux"], "title": "Table Foundation Models: on knowledge pre-training for tabular learning", "categories": ["cs.LG"], "comment": null, "summary": "Table foundation models bring high hopes to data science: pre-trained on\ntabular data to embark knowledge or priors, they should facilitate downstream\ntasks on tables. One specific challenge is that of data semantics: numerical\nentries take their meaning from context, e.g., column name. Pre-trained neural\nnetworks that jointly model column names and table entries have recently\nboosted prediction accuracy. While these models outline the promises of world\nknowledge to interpret table values, they lack the convenience of popular\nfoundation models in text or vision. Indeed, they must be fine-tuned to bring\nbenefits, come with sizeable computation costs, and cannot easily be reused or\ncombined with other architectures. Here we introduce TARTE, a foundation model\nthat transforms tables to knowledge-enhanced vector representations using the\nstring to capture semantics. Pre-trained on large relational data, TARTE yields\nrepresentations that facilitate subsequent learning with little additional\ncost. These representations can be fine-tuned or combined with other learners,\ngiving models that push the state-of-the-art prediction performance and improve\nthe prediction/computation performance trade-off. Specialized to a task or a\ndomain, TARTE gives domain-specific representations that facilitate further\nlearning. Our study demonstrates an effective approach to knowledge\npre-training for tabular learning."}
{"id": "2505.14536", "pdf": "https://arxiv.org/pdf/2505.14536", "abs": "https://arxiv.org/abs/2505.14536", "authors": ["Agam Goyal", "Vedant Rathi", "William Yeh", "Yian Wang", "Yuen Chen", "Hari Sundaram"], "title": "Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders", "categories": ["cs.CL"], "comment": "Preprint: 19 pages, 7 figures, 1 table", "summary": "Large language models (LLMs) are now ubiquitous in user-facing applications,\nyet they still generate undesirable toxic outputs, including profanity,\nvulgarity, and derogatory remarks. Although numerous detoxification methods\nexist, most apply broad, surface-level fixes and can therefore easily be\ncircumvented by jailbreak attacks. In this paper we leverage sparse\nautoencoders (SAEs) to identify toxicity-related directions in the residual\nstream of models and perform targeted activation steering using the\ncorresponding decoder vectors. We introduce three tiers of steering\naggressiveness and evaluate them on GPT-2 Small and Gemma-2-2B, revealing\ntrade-offs between toxicity reduction and language fluency. At stronger\nsteering strengths, these causal interventions surpass competitive baselines in\nreducing toxicity by up to 20%, though fluency can degrade noticeably on GPT-2\nSmall depending on the aggressiveness. Crucially, standard NLP benchmark scores\nupon steering remain stable, indicating that the model's knowledge and general\nabilities are preserved. We further show that feature-splitting in wider SAEs\nhampers safety interventions, underscoring the importance of disentangled\nfeature learning. Our findings highlight both the promise and the current\nlimitations of SAE-based causal interventions for LLM detoxification, further\nsuggesting practical guidelines for safer language-model deployment."}
{"id": "2409.09451", "pdf": "https://arxiv.org/pdf/2409.09451", "abs": "https://arxiv.org/abs/2409.09451", "authors": ["Yi-Chia Chang", "Adam J. Stewart", "Favyen Bastani", "Piper Wolters", "Shreya Kannan", "George R. Huber", "Jingtong Wang", "Arindam Banerjee"], "title": "On the Generalizability of Foundation Models for Crop Type Mapping", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to IEEE IGARSS 2025. The final version will appear in the\n  Proceedings of the IEEE International Geoscience and Remote Sensing Symposium\n  (IGARSS) 2025", "summary": "Foundation models pre-trained using self-supervised learning have shown\npowerful transfer learning capabilities on various downstream tasks, including\nlanguage understanding, text generation, and image recognition. The Earth\nobservation (EO) field has produced several foundation models pre-trained\ndirectly on multispectral satellite imagery for applications like precision\nagriculture, wildfire and drought monitoring, and natural disaster response.\nHowever, few studies have investigated the ability of these models to\ngeneralize to new geographic locations, and potential concerns of geospatial\nbias -- models trained on data-rich developed nations not transferring well to\ndata-scarce developing nations -- remain. We evaluate three popular EO\nfoundation models, SSL4EO-S12, SatlasPretrain, and ImageNet, on five crop\nclassification datasets across five continents. Results show that pre-trained\nweights designed explicitly for Sentinel-2, such as SSL4EO-S12, outperform\ngeneral pre-trained weights like ImageNet. While only 100 labeled images are\nsufficient for achieving high overall accuracy, 900 images are required to\nmitigate class imbalance and improve average accuracy."}
{"id": "2505.14424", "pdf": "https://arxiv.org/pdf/2505.14424", "abs": "https://arxiv.org/abs/2505.14424", "authors": ["Levin Hornischer", "Hannes Leitgeb"], "title": "Explaining Neural Networks with Reasons", "categories": ["cs.LG"], "comment": "28 pages (12 pages main text), 29 figures", "summary": "We propose a new interpretability method for neural networks, which is based\non a novel mathematico-philosophical theory of reasons. Our method computes a\nvector for each neuron, called its reasons vector. We then can compute how\nstrongly this reasons vector speaks for various propositions, e.g., the\nproposition that the input image depicts digit 2 or that the input prompt has a\nnegative sentiment. This yields an interpretation of neurons, and groups\nthereof, that combines a logical and a Bayesian perspective, and accounts for\npolysemanticity (i.e., that a single neuron can figure in multiple concepts).\nWe show, both theoretically and empirically, that this method is: (1) grounded\nin a philosophically established notion of explanation, (2) uniform, i.e.,\napplies to the common neural network architectures and modalities, (3)\nscalable, since computing reason vectors only involves forward-passes in the\nneural network, (4) faithful, i.e., intervening on a neuron based on its reason\nvector leads to expected changes in model output, (5) correct in that the\nmodel's reasons structure matches that of the data source, (6) trainable, i.e.,\nneural networks can be trained to improve their reason strengths, (7) useful,\ni.e., it delivers on the needs for interpretability by increasing, e.g.,\nrobustness and fairness."}
{"id": "2505.14552", "pdf": "https://arxiv.org/pdf/2505.14552", "abs": "https://arxiv.org/abs/2505.14552", "authors": ["Jiajun Shi", "Jian Yang", "Jiaheng Liu", "Xingyuan Bu", "Jiangjie Chen", "Junting Zhou", "Kaijing Ma", "Zhoufutu Wen", "Bingli Wang", "Yancheng He", "Liang Song", "Hualei Zhu", "Shilong Li", "Xingjian Wang", "Wei Zhang", "Ruibin Yuan", "Yifan Yao", "Wenjun Yang", "Yunli Wang", "Siyuan Fang", "Siyu Yuan", "Qianyu He", "Xiangru Tang", "Yingshui Tan", "Wangchunshu Zhou", "Zhaoxiang Zhang", "Zhoujun Li", "Wenhao Huang", "Ge Zhang"], "title": "KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "22 pages", "summary": "Recent advancements in large language models (LLMs) underscore the need for\nmore comprehensive evaluation methods to accurately assess their reasoning\ncapabilities. Existing benchmarks are often domain-specific and thus cannot\nfully capture an LLM's general reasoning potential. To address this limitation,\nwe introduce the Knowledge Orthogonal Reasoning Gymnasium (KORGym), a dynamic\nevaluation platform inspired by KOR-Bench and Gymnasium. KORGym offers over\nfifty games in either textual or visual formats and supports interactive,\nmulti-turn assessments with reinforcement learning scenarios. Using KORGym, we\nconduct extensive experiments on 19 LLMs and 8 VLMs, revealing consistent\nreasoning patterns within model families and demonstrating the superior\nperformance of closed-source models. Further analysis examines the effects of\nmodality, reasoning strategies, reinforcement learning techniques, and response\nlength on model performance. We expect KORGym to become a valuable resource for\nadvancing LLM reasoning research and developing evaluation methodologies suited\nto complex, interactive environments."}
{"id": "2409.15250", "pdf": "https://arxiv.org/pdf/2409.15250", "abs": "https://arxiv.org/abs/2409.15250", "authors": ["Sombit Dey", "Jan-Nico Zaech", "Nikolay Nikolov", "Luc Van Gool", "Danda Pani Paudel"], "title": "ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted at ICRA-2025, Atlanta", "summary": "Recent progress in large language models and access to large-scale robotic\ndatasets has sparked a paradigm shift in robotics models transforming them into\ngeneralists able to adapt to various tasks, scenes, and robot modalities. A\nlarge step for the community are open Vision Language Action models which\nshowcase strong performance in a wide variety of tasks. In this work, we study\nthe visual generalization capabilities of three existing robotic foundation\nmodels, and propose a corresponding evaluation framework. Our study shows that\nthe existing models do not exhibit robustness to visual out-of-domain\nscenarios. This is potentially caused by limited variations in the training\ndata and/or catastrophic forgetting, leading to domain limitations in the\nvision foundation models. We further explore OpenVLA, which uses two\npre-trained vision foundation models and is, therefore, expected to generalize\nto out-of-domain experiments. However, we showcase catastrophic forgetting by\nDINO-v2 in OpenVLA through its failure to fulfill the task of depth regression.\nTo overcome the aforementioned issue of visual catastrophic forgetting, we\npropose a gradual backbone reversal approach founded on model merging. This\nenables OpenVLA -- which requires the adaptation of the visual backbones during\ninitial training -- to regain its visual generalization ability. Regaining this\ncapability enables our ReVLA model to improve over OpenVLA by a factor of 77\\%\nand 66\\% for grasping and lifting in visual OOD tasks. Comprehensive\nevaluations, episode rollouts and model weights are available on the ReVLA Page"}
{"id": "2505.14428", "pdf": "https://arxiv.org/pdf/2505.14428", "abs": "https://arxiv.org/abs/2505.14428", "authors": ["Riccardo D'Elia"], "title": "Interpretable Neural System Dynamics: Combining Deep Learning with System Dynamics Modeling to Support Critical Applications", "categories": ["cs.LG", "cs.AI"], "comment": "To be submitted to CEUR-WS.org for publication in the Doctoral\n  Consortium Proceedings of XAI 2025, The World Conference on Explainable\n  Artificial Intelligence", "summary": "The objective of this proposal is to bridge the gap between Deep Learning\n(DL) and System Dynamics (SD) by developing an interpretable neural system\ndynamics framework. While DL excels at learning complex models and making\naccurate predictions, it lacks interpretability and causal reliability.\nTraditional SD approaches, on the other hand, provide transparency and causal\ninsights but are limited in scalability and require extensive domain knowledge.\nTo overcome these limitations, this project introduces a Neural System Dynamics\npipeline, integrating Concept-Based Interpretability, Mechanistic\nInterpretability, and Causal Machine Learning. This framework combines the\npredictive power of DL with the interpretability of traditional SD models,\nresulting in both causal reliability and scalability. The efficacy of the\nproposed pipeline will be validated through real-world applications of the\nEU-funded AutoMoTIF project, which is focused on autonomous multimodal\ntransportation systems. The long-term goal is to collect actionable insights\nthat support the integration of explainability and safety in autonomous\nsystems."}
{"id": "2505.14553", "pdf": "https://arxiv.org/pdf/2505.14553", "abs": "https://arxiv.org/abs/2505.14553", "authors": ["Abhimanyu Talwar", "Julien Laasri"], "title": "Pivot Language for Low-Resource Machine Translation", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "comment": "7 pages, 3 figures, paper dated May 13, 2019", "summary": "Certain pairs of languages suffer from lack of a parallel corpus which is\nlarge in size and diverse in domain. One of the ways this is overcome is via\nuse of a pivot language. In this paper we use Hindi as a pivot language to\ntranslate Nepali into English. We describe what makes Hindi a good candidate\nfor the pivot. We discuss ways in which a pivot language can be used, and use\ntwo such approaches - the Transfer Method (fully supervised) and\nBacktranslation (semi-supervised) - to translate Nepali into English. Using the\nformer, we are able to achieve a devtest Set SacreBLEU score of 14.2, which\nimproves the baseline fully supervised score reported by (Guzman et al., 2019)\nby 6.6 points. While we are slightly below the semi-supervised baseline score\nof 15.1, we discuss what may have caused this under-performance, and suggest\nscope for future work."}
{"id": "2410.00275", "pdf": "https://arxiv.org/pdf/2410.00275", "abs": "https://arxiv.org/abs/2410.00275", "authors": ["Rohaifa Khaldi", "Domingo Alcaraz-Segura", "Ignacio S√°nchez-Herrera", "Javier Martinez-Lopez", "Carlos Javier Navarro", "Siham Tabik"], "title": "Exploring Social Media Image Categorization Using Large Models with Different Adaptation Methods: A Case Study on Cultural Nature's Contributions to People", "categories": ["cs.CV", "cs.AI"], "comment": "23 pages, 7 figures", "summary": "Social media images provide valuable insights for modeling, mapping, and\nunderstanding human interactions with natural and cultural heritage. However,\ncategorizing these images into semantically meaningful groups remains highly\ncomplex due to the vast diversity and heterogeneity of their visual content as\nthey contain an open-world human and nature elements. This challenge becomes\ngreater when categories involve abstract concepts and lack consistent visual\npatterns. Related studies involve human supervision in the categorization\nprocess and the lack of public benchmark datasets make comparisons between\nthese works unfeasible. On the other hand, the continuous advances in large\nmodels, including Large Language Models (LLMs), Large Visual Models (LVMs), and\nLarge Visual Language Models (LVLMs), provide a large space of unexplored\nsolutions. In this work 1) we introduce FLIPS a dataset of Flickr images that\ncapture the interaction between human and nature, and 2) evaluate various\nsolutions based on different types and combinations of large models using\nvarious adaptation methods. We assess and report their performance in terms of\ncost, productivity, scalability, and result quality to address the challenges\nof social media image categorization."}
{"id": "2505.14451", "pdf": "https://arxiv.org/pdf/2505.14451", "abs": "https://arxiv.org/abs/2505.14451", "authors": ["Md Atik Ahamed", "Qiang Ye", "Qiang Cheng"], "title": "RefiDiff: Refinement-Aware Diffusion for Efficient Missing Data Imputation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Missing values in high-dimensional, mixed-type datasets pose significant\nchallenges for data imputation, particularly under Missing Not At Random (MNAR)\nmechanisms. Existing methods struggle to integrate local and global data\ncharacteristics, limiting performance in MNAR and high-dimensional settings. We\npropose an innovative framework, RefiDiff, combining local machine learning\npredictions with a novel Mamba-based denoising network capturing\ninterrelationships among distant features and samples. Our approach leverages\npre-refinement for initial warm-up imputations and post-refinement to polish\nresults, enhancing stability and accuracy. By encoding mixed-type data into\nunified tokens, RefiDiff enables robust imputation without architectural or\nhyperparameter tuning. RefiDiff outperforms state-of-the-art (SOTA) methods\nacross missing-value settings, excelling in MNAR with a 4x faster training time\nthan SOTA DDPM-based approaches. Extensive evaluations on nine real-world\ndatasets demonstrate its robustness, scalability, and effectiveness in handling\ncomplex missingness patterns."}
{"id": "2505.14295", "pdf": "https://arxiv.org/pdf/2505.14295", "abs": "https://arxiv.org/abs/2505.14295", "authors": ["Orlane Zang", "Gr√©goire Barru√©", "Tony Quertier"], "title": "Benchmarking data encoding methods in Quantum Machine Learning", "categories": ["quant-ph", "cs.AI"], "comment": "30 pages, 8 figures", "summary": "Data encoding plays a fundamental and distinctive role in Quantum Machine\nLearning (QML). While classical approaches process data directly as vectors,\nQML may require transforming classical data into quantum states through\nencoding circuits, known as quantum feature maps or quantum embeddings. This\nstep leverages the inherently high-dimensional and non-linear nature of Hilbert\nspace, enabling more efficient data separation in complex feature spaces that\nmay be inaccessible to classical methods. This encoding part significantly\naffects the performance of the QML model, so it is important to choose the\nright encoding method for the dataset to be encoded. However, this choice is\ngenerally arbitrary, since there is no \"universal\" rule for knowing which\nencoding to choose based on a specific set of data. There are currently a\nvariety of encoding methods using different quantum logic gates. We studied the\nmost commonly used types of encoding methods and benchmarked them using\ndifferent datasets."}
{"id": "2505.14577", "pdf": "https://arxiv.org/pdf/2505.14577", "abs": "https://arxiv.org/abs/2505.14577", "authors": ["Sohaila Eltanbouly", "Salam Albatarni", "Tamer Elsayed"], "title": "TRATES: Trait-Specific Rubric-Assisted Cross-Prompt Essay Scoring", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025 Findings", "summary": "Research on holistic Automated Essay Scoring (AES) is long-dated; yet, there\nis a notable lack of attention for assessing essays according to individual\ntraits. In this work, we propose TRATES, a novel trait-specific and\nrubric-based cross-prompt AES framework that is generic yet specific to the\nunderlying trait. The framework leverages a Large Language Model (LLM) that\nutilizes the trait grading rubrics to generate trait-specific features\n(represented by assessment questions), then assesses those features given an\nessay. The trait-specific features are eventually combined with generic\nwriting-quality and prompt-specific features to train a simple classical\nregression model that predicts trait scores of essays from an unseen prompt.\nExperiments show that TRATES achieves a new state-of-the-art performance across\nall traits on a widely-used dataset, with the generated LLM-based features\nbeing the most significant."}
{"id": "2410.00580", "pdf": "https://arxiv.org/pdf/2410.00580", "abs": "https://arxiv.org/abs/2410.00580", "authors": ["Aurora Micheli", "Olaf Booij", "Jan van Gemert", "Nergis T√∂men"], "title": "Deep activity propagation via weight initialization in spiking neural networks", "categories": ["cs.CV"], "comment": null, "summary": "Spiking Neural Networks (SNNs) and neuromorphic computing offer bio-inspired\nadvantages such as sparsity and ultra-low power consumption, providing a\npromising alternative to conventional networks. However, training deep SNNs\nfrom scratch remains a challenge, as SNNs process and transmit information by\nquantizing the real-valued membrane potentials into binary spikes. This can\nlead to information loss and vanishing spikes in deeper layers, impeding\neffective training. While weight initialization is known to be critical for\ntraining deep neural networks, what constitutes an effective initial state for\na deep SNN is not well-understood. Existing weight initialization methods\ndesigned for conventional networks (ANNs) are often applied to SNNs without\naccounting for their distinct computational properties. In this work we derive\nan optimal weight initialization method specifically tailored for SNNs, taking\ninto account the quantization operation. We show theoretically that, unlike\nstandard approaches, this method enables the propagation of activity in deep\nSNNs without loss of spikes. We demonstrate this behavior in numerical\nsimulations of SNNs with up to 100 layers across multiple time steps. We\npresent an in-depth analysis of the numerical conditions, regarding layer width\nand neuron hyperparameters, which are necessary to accurately apply our\ntheoretical findings. Furthermore, our experiments on MNIST demonstrate higher\naccuracy and faster convergence when using the proposed weight initialization\nscheme. Finally, we show that the newly introduced weight initialization is\nrobust against variations in several network and neuron hyperparameters."}
{"id": "2505.14459", "pdf": "https://arxiv.org/pdf/2505.14459", "abs": "https://arxiv.org/abs/2505.14459", "authors": ["Kamal Singh", "Sami Marouani", "Ahmad Al Sheikh", "Pham Tran Anh Quang", "Amaury Habrard"], "title": "Interpretable Reinforcement Learning for Load Balancing using Kolmogorov-Arnold Networks", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Reinforcement learning (RL) has been increasingly applied to network control\nproblems, such as load balancing. However, existing RL approaches often suffer\nfrom lack of interpretability and difficulty in extracting controller\nequations. In this paper, we propose the use of Kolmogorov-Arnold Networks\n(KAN) for interpretable RL in network control. We employ a PPO agent with a\n1-layer actor KAN model and an MLP Critic network to learn load balancing\npolicies that maximise throughput utility, minimize loss as well as delay. Our\napproach allows us to extract controller equations from the learned neural\nnetworks, providing insights into the decision-making process. We evaluate our\napproach using different reward functions demonstrating its effectiveness in\nimproving network performance while providing interpretable policies."}
{"id": "2505.14316", "pdf": "https://arxiv.org/pdf/2505.14316", "abs": "https://arxiv.org/abs/2505.14316", "authors": ["Tiehan Cui", "Yanxu Mao", "Peipei Liu", "Congying Liu", "Datao You"], "title": "Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Although large language models (LLMs) have achieved remarkable advancements,\ntheir security remains a pressing concern. One major threat is jailbreak\nattacks, where adversarial prompts bypass model safeguards to generate harmful\nor objectionable content. Researchers study jailbreak attacks to understand\nsecurity and robustness of LLMs. However, existing jailbreak attack methods\nface two main challenges: (1) an excessive number of iterative queries, and (2)\npoor generalization across models. In addition, recent jailbreak evaluation\ndatasets focus primarily on question-answering scenarios, lacking attention to\ntext generation tasks that require accurate regeneration of toxic content. To\ntackle these challenges, we propose two contributions: (1) ICE, a novel\nblack-box jailbreak method that employs Intent Concealment and divErsion to\neffectively circumvent security constraints. ICE achieves high attack success\nrates (ASR) with a single query, significantly improving efficiency and\ntransferability across different models. (2) BiSceneEval, a comprehensive\ndataset designed for assessing LLM robustness in question-answering and\ntext-generation tasks. Experimental results demonstrate that ICE outperforms\nexisting jailbreak techniques, revealing critical vulnerabilities in current\ndefense mechanisms. Our findings underscore the necessity of a hybrid security\nstrategy that integrates predefined security mechanisms with real-time semantic\ndecomposition to enhance the security of LLMs."}
{"id": "2505.14582", "pdf": "https://arxiv.org/pdf/2505.14582", "abs": "https://arxiv.org/abs/2505.14582", "authors": ["Shangziqi Zhao", "Jiahao Yuan", "Guisong Yang", "Usman Naseem"], "title": "Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning", "categories": ["cs.CL"], "comment": "17 pages,4 figures", "summary": "Long chain-of-thought (Long-CoT) reasoning improves accuracy in LLMs, yet its\nverbose, self-reflective style often hinders effective distillation into small\nlanguage models (SLMs). We revisit Long-CoT compression through the lens of\ncapability alignment and ask: Can pruning improve reasoning? We propose\nPrune-on-Logic, a structure-aware framework that transforms Long-CoT into logic\ngraphs and selectively prunes low-utility reasoning steps under\nself-verification constraints. Through systematic analysis across three pruning\nstrategies -- targeting entire chains, core reasoning, and verification -- we\nfind that pruning verification steps yields consistent accuracy gains while\nreducing inference cost, outperforming token-level baselines and uncompressed\nfine-tuning. In contrast, pruning reasoning or all-chain steps degrades\nperformance, revealing that small models benefit not from shorter CoTs, but\nfrom semantically leaner ones. Our findings highlight pruning as a structural\noptimization strategy for aligning CoT reasoning with SLM capacity."}
{"id": "2411.12199", "pdf": "https://arxiv.org/pdf/2411.12199", "abs": "https://arxiv.org/abs/2411.12199", "authors": ["Tae-Min Choi", "Juyoun Park"], "title": "Rethinking Text-Promptable Surgical Instrument Segmentation with Robust Framework", "categories": ["cs.CV"], "comment": "15 pages, 5 figures, 8 tables", "summary": "Surgical instrument segmentation is an essential component of\ncomputer-assisted and robotic surgery systems. Vision-based segmentation models\ntypically produce outputs limited to a predefined set of instrument categories,\nwhich restricts their applicability in interactive systems and robotic task\nautomation. Promptable segmentation methods allow selective predictions based\non textual prompts. However, they often rely on the assumption that the\ninstruments present in the scene are already known, and prompts are generated\naccordingly, limiting their ability to generalize to unseen or dynamically\nemerging instruments. In practical surgical environments, where instrument\nexistence information is not provided, this assumption does not hold\nconsistently, resulting in false-positive segmentation. To address these\nlimitations, we formulate a new task called Robust text-promptable Surgical\nInstrument Segmentation (R-SIS). Under this setting, prompts are issued for all\ncandidate categories without access to instrument presence information. R-SIS\nrequires distinguishing which prompts refer to visible instruments and\ngenerating masks only when such instruments are explicitly present in the\nscene. This setting reflects practical conditions where uncertainty in\ninstrument presence is inherent. We evaluate existing segmentation methods\nunder the R-SIS protocol using surgical video datasets and observe substantial\nfalse-positive predictions in the absence of ground-truth instruments. These\nfindings demonstrate a mismatch between current evaluation protocols and\nreal-world use cases, and support the need for benchmarks that explicitly\naccount for prompt uncertainty and instrument absence."}
{"id": "2505.14463", "pdf": "https://arxiv.org/pdf/2505.14463", "abs": "https://arxiv.org/abs/2505.14463", "authors": ["Xinxin Fan", "Wenxiong Chen", "Mengfan Li", "Wenqi Wei", "Ling Liu"], "title": "Adverseness vs. Equilibrium: Exploring Graph Adversarial Resilience through Dynamic Equilibrium", "categories": ["cs.LG"], "comment": null, "summary": "Adversarial attacks to graph analytics are gaining increased attention. To\ndate, two lines of countermeasures have been proposed to resist various graph\nadversarial attacks from the perspectives of either graph per se or graph\nneural networks. Nevertheless, a fundamental question lies in whether there\nexists an intrinsic adversarial resilience state within a graph regime and how\nto find out such a critical state if exists. This paper contributes to tackle\nthe above research questions from three unique perspectives: i) we regard the\nprocess of adversarial learning on graph as a complex multi-object dynamic\nsystem, and model the behavior of adversarial attack; ii) we propose a\ngeneralized theoretical framework to show the existence of critical adversarial\nresilience state; and iii) we develop a condensed one-dimensional function to\ncapture the dynamic variation of graph regime under perturbations, and pinpoint\nthe critical state through solving the equilibrium point of dynamic system.\nMulti-facet experiments are conducted to show our proposed approach can\nsignificantly outperform the state-of-the-art defense methods under five\ncommonly-used real-world datasets and three representative attacks."}
{"id": "2505.14377", "pdf": "https://arxiv.org/pdf/2505.14377", "abs": "https://arxiv.org/abs/2505.14377", "authors": ["Ulrike Kuhl", "Annika Bush"], "title": "When Bias Backfires: The Modulatory Role of Counterfactual Explanations on the Adoption of Algorithmic Bias in XAI-Supported Human Decision-Making", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted for XAI2025", "summary": "Although the integration of artificial intelligence (AI) into everyday tasks\nimproves efficiency and objectivity, it also risks transmitting bias to human\ndecision-making. In this study, we conducted a controlled experiment that\nsimulated hiring decisions to examine how biased AI recommendations - augmented\nwith or without counterfactual explanations - influence human judgment over\ntime. Participants, acting as hiring managers, completed 60 decision trials\ndivided into a baseline phase without AI, followed by a phase with biased (X)AI\nrecommendations (favoring either male or female candidates), and a final\npost-interaction phase without AI. Our results indicate that the participants\nfollowed the AI recommendations 70% of the time when the qualifications of the\ngiven candidates were comparable. Yet, only a fraction of participants detected\nthe gender bias (8 out of 294). Crucially, exposure to biased AI altered\nparticipants' inherent preferences: in the post-interaction phase,\nparticipants' independent decisions aligned with the bias when no\ncounterfactual explanations were provided before, but reversed the bias when\nexplanations were given. Reported trust did not differ significantly across\nconditions. Confidence varied throughout the study phases after exposure to\nmale-biased AI, indicating nuanced effects of AI bias on decision certainty.\nOur findings point to the importance of calibrating XAI to avoid unintended\nbehavioral shifts in order to safeguard equitable decision-making and prevent\nthe adoption of algorithmic bias."}
{"id": "2505.14585", "pdf": "https://arxiv.org/pdf/2505.14585", "abs": "https://arxiv.org/abs/2505.14585", "authors": ["Wenbin Hu", "Haoran Li", "Huihao Jing", "Qi Hu", "Ziqian Zeng", "Sirui Han", "Heli Xu", "Tianshu Chu", "Peizhao Hu", "Yangqiu Song"], "title": "Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning", "categories": ["cs.CL"], "comment": null, "summary": "While Large Language Models (LLMs) exhibit remarkable capabilities, they also\nintroduce significant safety and privacy risks. Current mitigation strategies\noften fail to preserve contextual reasoning capabilities in risky scenarios.\nInstead, they rely heavily on sensitive pattern matching to protect LLMs, which\nlimits the scope. Furthermore, they overlook established safety and privacy\nstandards, leading to systemic risks for legal compliance. To address these\ngaps, we formulate safety and privacy issues into contextualized compliance\nproblems following the Contextual Integrity (CI) theory. Under the CI\nframework, we align our model with three critical regulatory standards: GDPR,\nEU AI Act, and HIPAA. Specifically, we employ reinforcement learning (RL) with\na rule-based reward to incentivize contextual reasoning capabilities while\nenhancing compliance with safety and privacy norms. Through extensive\nexperiments, we demonstrate that our method not only significantly enhances\nlegal compliance (achieving a +17.64% accuracy improvement in safety/privacy\nbenchmarks) but also further improves general reasoning capability. For\nOpenThinker-7B, a strong reasoning model that significantly outperforms its\nbase model Qwen2.5-7B-Instruct across diverse subjects, our method enhances its\ngeneral reasoning capabilities, with +2.05% and +8.98% accuracy improvement on\nthe MMLU and LegalBench benchmark, respectively."}
{"id": "2411.15633", "pdf": "https://arxiv.org/pdf/2411.15633", "abs": "https://arxiv.org/abs/2411.15633", "authors": ["Zhiyuan Yan", "Jiangming Wang", "Peng Jin", "Ke-Yue Zhang", "Chengchun Liu", "Shen Chen", "Taiping Yao", "Shouhong Ding", "Baoyuan Wu", "Li Yuan"], "title": "Orthogonal Subspace Decomposition for Generalizable AI-Generated Image Detection", "categories": ["cs.CV"], "comment": null, "summary": "AI-generated images (AIGIs), such as natural or face images, have become\nincreasingly important yet challenging. In this paper, we start from a new\nperspective to excavate the reason behind the failure generalization in AIGI\ndetection, named the \\textit{asymmetry phenomenon}, where a naively trained\ndetector tends to favor overfitting to the limited and monotonous fake\npatterns, causing the feature space to become highly constrained and\nlow-ranked, which is proved seriously limiting the expressivity and\ngeneralization. One potential remedy is incorporating the pre-trained knowledge\nwithin the vision foundation models (higher-ranked) to expand the feature\nspace, alleviating the model's overfitting to fake. To this end, we employ\nSingular Value Decomposition (SVD) to decompose the original feature space into\n\\textit{two orthogonal subspaces}. By freezing the principal components and\nadapting only the remained components, we preserve the pre-trained knowledge\nwhile learning fake patterns. Compared to existing full-parameters and\nLoRA-based tuning methods, we explicitly ensure orthogonality, enabling the\nhigher rank of the whole feature space, effectively minimizing overfitting and\nenhancing generalization. We finally identify a crucial insight: our method\nimplicitly learns \\textit{a vital prior that fakes are actually derived from\nthe real}, indicating a hierarchical relationship rather than independence.\nModeling this prior, we believe, is essential for achieving superior\ngeneralization. Our codes are publicly available at\n\\href{https://github.com/YZY-stack/Effort-AIGI-Detection}{GitHub}."}
{"id": "2505.14468", "pdf": "https://arxiv.org/pdf/2505.14468", "abs": "https://arxiv.org/abs/2505.14468", "authors": ["Yifan Sui", "Hao Wang", "Hanfei Yu", "Yitao Hu", "Jianxun Li", "Hao Wang"], "title": "ServerlessLoRA: Minimizing Latency and Cost in Serverless Inference for LoRA-Based LLMs", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Serverless computing has grown rapidly for serving Large Language Model (LLM)\ninference due to its pay-as-you-go pricing, fine-grained GPU usage, and rapid\nscaling. However, our analysis reveals that current serverless can effectively\nserve general LLM but fail with Low-Rank Adaptation (LoRA) inference due to\nthree key limitations: 1) massive parameter redundancy among functions where\n99% of weights are unnecessarily duplicated, 2) costly artifact loading latency\nbeyond LLM loading, and 3) magnified resource contention when serving multiple\nLoRA LLMs. These inefficiencies lead to massive GPU wastage, increased\nTime-To-First-Token (TTFT), and high monetary costs.\n  We propose ServerlessLoRA, a novel serverless inference system designed for\nfaster and cheaper LoRA LLM serving. ServerlessLoRA enables secure backbone LLM\nsharing across isolated LoRA functions to reduce redundancy. We design a\npre-loading method that pre-loads comprehensive LoRA artifacts to minimize\ncold-start latency. Furthermore, ServerlessLoRA employs contention aware\nbatching and offloading to mitigate GPU resource conflicts during bursty\nworkloads. Experiment on industrial workloads demonstrates that ServerlessLoRA\nreduces TTFT by up to 86% and cuts monetary costs by up to 89% compared to\nstate-of-the-art LLM inference solutions."}
{"id": "2505.14435", "pdf": "https://arxiv.org/pdf/2505.14435", "abs": "https://arxiv.org/abs/2505.14435", "authors": ["Annika Bush", "Meltem Aksoy", "Markus Pauly", "Greta Ontrup"], "title": "Choosing a Model, Shaping a Future: Comparing LLM Perspectives on Sustainability and its Relationship with AI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As organizations increasingly rely on AI systems for decision support in\nsustainability contexts, it becomes critical to understand the inherent biases\nand perspectives embedded in Large Language Models (LLMs). This study\nsystematically investigates how five state-of-the-art LLMs -- Claude, DeepSeek,\nGPT, LLaMA, and Mistral - conceptualize sustainability and its relationship\nwith AI. We administered validated, psychometric sustainability-related\nquestionnaires - each 100 times per model -- to capture response patterns and\nvariability. Our findings revealed significant inter-model differences: For\nexample, GPT exhibited skepticism about the compatibility of AI and\nsustainability, whereas LLaMA demonstrated extreme techno-optimism with perfect\nscores for several Sustainable Development Goals (SDGs). Models also diverged\nin attributing institutional responsibility for AI and sustainability\nintegration, a results that holds implications for technology governance\napproaches. Our results demonstrate that model selection could substantially\ninfluence organizational sustainability strategies, highlighting the need for\nawareness of model-specific biases when deploying LLMs for\nsustainability-related decision-making."}
{"id": "2505.14590", "pdf": "https://arxiv.org/pdf/2505.14590", "abs": "https://arxiv.org/abs/2505.14590", "authors": ["Huihao Jing", "Haoran Li", "Wenbin Hu", "Qi Hu", "Heli Xu", "Tianshu Chu", "Peizhao Hu", "Yangqiu Song"], "title": "MCIP: Protecting MCP Safety via Model Contextual Integrity Protocol", "categories": ["cs.CL"], "comment": "17 pages", "summary": "As Model Context Protocol (MCP) introduces an easy-to-use ecosystem for users\nand developers, it also brings underexplored safety risks. Its decentralized\narchitecture, which separates clients and servers, poses unique challenges for\nsystematic safety analysis. This paper proposes a novel framework to enhance\nMCP safety. Guided by the MAESTRO framework, we first analyze the missing\nsafety mechanisms in MCP, and based on this analysis, we propose the Model\nContextual Integrity Protocol (MCIP), a refined version of MCP that addresses\nthese gaps.Next, we develop a fine-grained taxonomy that captures a diverse\nrange of unsafe behaviors observed in MCP scenarios. Building on this taxonomy,\nwe develop benchmark and training data that support the evaluation and\nimprovement of LLMs' capabilities in identifying safety risks within MCP\ninteractions. Leveraging the proposed benchmark and training data, we conduct\nextensive experiments on state-of-the-art LLMs. The results highlight LLMs'\nvulnerabilities in MCP interactions and demonstrate that our approach\nsubstantially improves their safety performance."}
{"id": "2411.16301", "pdf": "https://arxiv.org/pdf/2411.16301", "abs": "https://arxiv.org/abs/2411.16301", "authors": ["Yuxuan Yang", "Tao Geng", "Jingyao Wang", "Changwen Zheng", "Fuchun Sun"], "title": "DiffDesign: Controllable Diffusion with Meta Prior for Efficient Interior Design Generation", "categories": ["cs.CV", "cs.LG"], "comment": "32 pages", "summary": "Interior design is a complex and creative discipline involving aesthetics,\nfunctionality, ergonomics, and materials science. Effective solutions must meet\ndiverse requirements, typically producing multiple deliverables such as\nrenderings and design drawings from various perspectives. Consequently,\ninterior design processes are often inefficient and demand significant\ncreativity. With advances in machine learning, generative models have emerged\nas a promising means of improving efficiency by creating designs from text\ndescriptions or sketches. However, few generative works focus on interior\ndesign, leading to substantial discrepancies between outputs and practical\nneeds, such as differences in size, spatial scope, and the lack of controllable\ngeneration quality. To address these challenges, we propose DiffDesign, a\ncontrollable diffusion model with meta priors for efficient interior design\ngeneration. Specifically, we utilize the generative priors of a 2D diffusion\nmodel pre-trained on a large image dataset as our rendering backbone. We\nfurther guide the denoising process by disentangling cross-attention control\nover design attributes, such as appearance, pose, and size, and introduce an\noptimal transfer-based alignment module to enforce view consistency.\nSimultaneously, we construct an interior design-specific dataset, DesignHelper,\nconsisting of over 400 solutions across more than 15 spatial types and 15\ndesign styles. This dataset helps fine-tune DiffDesign. Extensive experiments\nconducted on various benchmark datasets demonstrate the effectiveness and\nrobustness of DiffDesign."}
{"id": "2505.14477", "pdf": "https://arxiv.org/pdf/2505.14477", "abs": "https://arxiv.org/abs/2505.14477", "authors": ["Maria Panagiotou", "Lorenzo Brigato", "Vivien Streit", "Amanda Hayoz", "Stephan Proennecke", "Stavros Athanasopoulos", "Mikkel T. Olsen", "Elizabeth J. den Brok", "Cecilie H. Svensson", "Konstantinos Makrilakis", "Maria Xatzipsalti", "Andriani Vazeou", "Peter R. Mertens", "Ulrik Pedersen-Bjergaard", "Bastiaan E. de Galan", "Stavroula Mougiakakou"], "title": "Personalised Insulin Adjustment with Reinforcement Learning: An In-Silico Validation for People with Diabetes on Intensive Insulin Treatment", "categories": ["cs.LG"], "comment": null, "summary": "Despite recent advances in insulin preparations and technology, adjusting\ninsulin remains an ongoing challenge for the majority of people with type 1\ndiabetes (T1D) and longstanding type 2 diabetes (T2D). In this study, we\npropose the Adaptive Basal-Bolus Advisor (ABBA), a personalised insulin\ntreatment recommendation approach based on reinforcement learning for\nindividuals with T1D and T2D, performing self-monitoring blood glucose\nmeasurements and multiple daily insulin injection therapy. We developed and\nevaluated the ability of ABBA to achieve better time-in-range (TIR) for\nindividuals with T1D and T2D, compared to a standard basal-bolus advisor (BBA).\nThe in-silico test was performed using an FDA-accepted population, including\n101 simulated adults with T1D and 101 with T2D. An in-silico evaluation shows\nthat ABBA significantly improved TIR and significantly reduced both times\nbelow- and above-range, compared to BBA. ABBA's performance continued to\nimprove over two months, whereas BBA exhibited only modest changes. This\npersonalised method for adjusting insulin has the potential to further optimise\nglycaemic control and support people with T1D and T2D in their daily\nself-management. Our results warrant ABBA to be trialed for the first time in\nhumans."}
{"id": "2505.14452", "pdf": "https://arxiv.org/pdf/2505.14452", "abs": "https://arxiv.org/abs/2505.14452", "authors": ["Lance T Wilhelm", "Xiaohan Ding", "Kirk McInnis Knutsen", "Buse Carik", "Eugenia H Rho"], "title": "How Managers Perceive AI-Assisted Conversational Training for Workplace Communication", "categories": ["cs.HC", "cs.AI"], "comment": "accepted to CUI '25", "summary": "Effective workplace communication is essential for managerial success, yet\nmany managers lack access to tailored and sustained training. Although\nAI-assisted communication systems may offer scalable training solutions, little\nis known about how managers envision the role of AI in helping them improve\ntheir communication skills. To investigate this, we designed a conversational\nrole-play system, CommCoach, as a functional probe to understand how managers\nanticipate using AI to practice their communication skills. Through\nsemi-structured interviews, participants emphasized the value of adaptive,\nlow-risk simulations for practicing difficult workplace conversations. They\nalso highlighted opportunities, including human-AI teaming, transparent and\ncontext-aware feedback, and greater control over AI-generated personas.\nAI-assisted communication training should balance personalization, structured\nlearning objectives, and adaptability to different user styles and contexts.\nHowever, achieving this requires carefully navigating tensions between adaptive\nand consistent AI feedback, realism and potential bias, and the open-ended\nnature of AI conversations versus structured workplace discourse."}
{"id": "2505.14597", "pdf": "https://arxiv.org/pdf/2505.14597", "abs": "https://arxiv.org/abs/2505.14597", "authors": ["Xianzhen Luo", "Qingfu Zhu", "Zhiming Zhang", "Mingzheng Xu", "Tianhao Cheng", "Yixuan Wang", "Zheng Chu", "Shijie Xuyang", "Zhiyuan Ma", "YuanTao Fan", "Wanxiang Che"], "title": "Success is in the Details: Evaluate and Enhance Details Sensitivity of Code LLMs through Counterfactuals", "categories": ["cs.CL"], "comment": "Code & Model is https://github.com/Luowaterbi/CTF-Instruct", "summary": "Code Sensitivity refers to the ability of Code LLMs to recognize and respond\nto details changes in problem descriptions. While current code benchmarks and\ninstruction data focus on difficulty and diversity, sensitivity is overlooked.\nWe first introduce the CTF-Code benchmark, constructed using counterfactual\nperturbations, minimizing input changes while maximizing output changes. The\nevaluation shows that many LLMs have a more than 10\\% performance drop compared\nto the original problems. To fully utilize sensitivity, CTF-Instruct, an\nincremental instruction fine-tuning framework, extends on existing data and\nuses a selection mechanism to meet the three dimensions of difficulty,\ndiversity, and sensitivity. Experiments show that LLMs fine-tuned with\nCTF-Instruct data achieve over a 2\\% improvement on CTF-Code, and more than a\n10\\% performance boost on LiveCodeBench, validating the feasibility of\nenhancing LLMs' sensitivity to improve performance."}
{"id": "2412.12974", "pdf": "https://arxiv.org/pdf/2412.12974", "abs": "https://arxiv.org/abs/2412.12974", "authors": ["Wenhao Sun", "Benlei Cui", "Xue-Mei Dong", "Jingqun Tang"], "title": "Attentive Eraser: Unleashing Diffusion Model's Object Removal Potential via Self-Attention Redirection Guidance", "categories": ["cs.CV"], "comment": "Accepted by AAAI 2025(Oral)", "summary": "Recently, diffusion models have emerged as promising newcomers in the field\nof generative models, shining brightly in image generation. However, when\nemployed for object removal tasks, they still encounter issues such as\ngenerating random artifacts and the incapacity to repaint foreground object\nareas with appropriate content after removal. To tackle these problems, we\npropose Attentive Eraser, a tuning-free method to empower pre-trained diffusion\nmodels for stable and effective object removal. Firstly, in light of the\nobservation that the self-attention maps influence the structure and shape\ndetails of the generated images, we propose Attention Activation and\nSuppression (ASS), which re-engineers the self-attention mechanism within the\npre-trained diffusion models based on the given mask, thereby prioritizing the\nbackground over the foreground object during the reverse generation process.\nMoreover, we introduce Self-Attention Redirection Guidance (SARG), which\nutilizes the self-attention redirected by ASS to guide the generation process,\neffectively removing foreground objects within the mask while simultaneously\ngenerating content that is both plausible and coherent. Experiments demonstrate\nthe stability and effectiveness of Attentive Eraser in object removal across a\nvariety of pre-trained diffusion models, outperforming even training-based\nmethods. Furthermore, Attentive Eraser can be implemented in various diffusion\nmodel architectures and checkpoints, enabling excellent scalability. Code is\navailable at https://github.com/Anonym0u3/AttentiveEraser."}
{"id": "2505.14502", "pdf": "https://arxiv.org/pdf/2505.14502", "abs": "https://arxiv.org/abs/2505.14502", "authors": ["Wenze Liu", "Xiangyu Yue"], "title": "Learning to Integrate Diffusion ODEs by Averaging the Derivatives", "categories": ["cs.LG"], "comment": null, "summary": "To accelerate diffusion model inference, numerical solvers perform poorly at\nextremely small steps, while distillation techniques often introduce complexity\nand instability. This work presents an intermediate strategy, balancing\nperformance and cost, by learning ODE integration using loss functions derived\nfrom the derivative-integral relationship, inspired by Monte Carlo integration\nand Picard iteration. From a geometric perspective, the losses operate by\ngradually extending the tangent to the secant, thus are named as secant losses.\nThe secant losses can rapidly convert (via fine-tuning or distillation) a\npretrained diffusion model into its secant version. In our experiments, the\nsecant version of EDM achieves a $10$-step FID of $2.14$ on CIFAR-10, while the\nsecant version of SiT-XL/2 attains a $4$-step FID of $2.27$ and an $8$-step FID\nof $1.96$ on ImageNet-$256\\times256$. Code will be available."}
{"id": "2505.14513", "pdf": "https://arxiv.org/pdf/2505.14513", "abs": "https://arxiv.org/abs/2505.14513", "authors": ["Yen-Chen Wu", "Feng-Ting Liao", "Meng-Hsi Chen", "Pei-Chen Ho", "Farhang Nabiei", "Da-shan Shiu"], "title": "Latent Flow Transformer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformers, the standard implementation for large language models (LLMs),\ntypically consist of tens to hundreds of discrete layers. While more layers can\nlead to better performance, this approach has been challenged as far from\nefficient, especially given the superiority of continuous layers demonstrated\nby diffusion and flow-based models for image generation. We propose the Latent\nFlow Transformer (LFT), which replaces a block of layers with a single learned\ntransport operator trained via flow matching, offering significant compression\nwhile maintaining compatibility with the original architecture. Additionally,\nwe address the limitations of existing flow-based methods in \\textit{preserving\ncoupling} by introducing the Flow Walking (FW) algorithm. On the Pythia-410M\nmodel, LFT trained with flow matching compresses 6 of 24 layers and outperforms\ndirectly skipping 2 layers (KL Divergence of LM logits at 0.407 vs. 0.529),\ndemonstrating the feasibility of this design. When trained with FW, LFT further\ndistills 12 layers into one while reducing the KL to 0.736 surpassing that from\nskipping 3 layers (0.932), significantly narrowing the gap between\nautoregressive and flow-based generation paradigms."}
{"id": "2505.14599", "pdf": "https://arxiv.org/pdf/2505.14599", "abs": "https://arxiv.org/abs/2505.14599", "authors": ["Guangzhi Xiong", "Eric Xie", "Corey Williams", "Myles Kim", "Amir Hassan Shariatmadari", "Sikun Guo", "Stefan Bekiranov", "Aidong Zhang"], "title": "Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to IJCAI 2025", "summary": "Large language models (LLMs) have shown significant potential in scientific\ndisciplines such as biomedicine, particularly in hypothesis generation, where\nthey can analyze vast literature, identify patterns, and suggest research\ndirections. However, a key challenge lies in evaluating the truthfulness of\ngenerated hypotheses, as verifying their accuracy often requires substantial\ntime and resources. Additionally, the hallucination problem in LLMs can lead to\nthe generation of hypotheses that appear plausible but are ultimately\nincorrect, undermining their reliability. To facilitate the systematic study of\nthese challenges, we introduce TruthHypo, a benchmark for assessing the\ncapabilities of LLMs in generating truthful biomedical hypotheses, and KnowHD,\na knowledge-based hallucination detector to evaluate how well hypotheses are\ngrounded in existing knowledge. Our results show that LLMs struggle to generate\ntruthful hypotheses. By analyzing hallucinations in reasoning steps, we\ndemonstrate that the groundedness scores provided by KnowHD serve as an\neffective metric for filtering truthful hypotheses from the diverse outputs of\nLLMs. Human evaluations further validate the utility of KnowHD in identifying\ntruthful hypotheses and accelerating scientific discovery. Our data and source\ncode are available at https://github.com/Teddy-XiongGZ/TruthHypo."}
{"id": "2412.20761", "pdf": "https://arxiv.org/pdf/2412.20761", "abs": "https://arxiv.org/abs/2412.20761", "authors": ["Jie Jing", "Qing Lin", "Shuangpeng Han", "Lucia Schiatti", "Yen-Ling Kuo", "Mengmi Zhang"], "title": "Unforgettable Lessons from Forgettable Images: Intra-Class Memorability Matters in Computer Vision", "categories": ["cs.CV"], "comment": null, "summary": "We introduce intra-class memorability, where certain images within the same\nclass are more memorable than others despite shared category characteristics.\nTo investigate what features make one object instance more memorable than\nothers, we design and conduct human behavior experiments, where participants\nare shown a series of images, and they must identify when the current image\nmatches the image presented a few steps back in the sequence. To quantify\nmemorability, we propose the Intra-Class Memorability score (ICMscore), a novel\nmetric that incorporates the temporal intervals between repeated image\npresentations into its calculation. Furthermore, we curate the Intra-Class\nMemorability Dataset (ICMD), comprising over 5,000 images across ten object\nclasses with their ICMscores derived from 2,000 participants' responses.\nSubsequently, we demonstrate the usefulness of ICMD by training AI models on\nthis dataset for various downstream tasks: memorability prediction, image\nrecognition, continual learning, and memorability-controlled image editing.\nSurprisingly, high-ICMscore images impair AI performance in image recognition\nand continual learning tasks, while low-ICMscore images improve outcomes in\nthese tasks. Additionally, we fine-tune a state-of-the-art image diffusion\nmodel on ICMD image pairs with and without masked semantic objects. The\ndiffusion model can successfully manipulate image elements to enhance or reduce\nmemorability. Our contributions open new pathways in understanding intra-class\nmemorability by scrutinizing fine-grained visual features behind the most and\nleast memorable images and laying the groundwork for real-world applications in\ncomputer vision. We will release all code, data, and models publicly."}
{"id": "2505.14512", "pdf": "https://arxiv.org/pdf/2505.14512", "abs": "https://arxiv.org/abs/2505.14512", "authors": ["Juliusz Ziomek", "George Whittle", "Michael A. Osborne"], "title": "Just One Layer Norm Guarantees Stable Extrapolation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In spite of their prevalence, the behaviour of Neural Networks when\nextrapolating far from the training distribution remains poorly understood,\nwith existing results limited to specific cases. In this work, we prove general\nresults -- the first of their kind -- by applying Neural Tangent Kernel (NTK)\ntheory to analyse infinitely-wide neural networks trained until convergence and\nprove that the inclusion of just one Layer Norm (LN) fundamentally alters the\ninduced NTK, transforming it into a bounded-variance kernel. As a result, the\noutput of an infinitely wide network with at least one LN remains bounded, even\non inputs far from the training data. In contrast, we show that a broad class\nof networks without LN can produce pathologically large outputs for certain\ninputs. We support these theoretical findings with empirical experiments on\nfinite-width networks, demonstrating that while standard NNs often exhibit\nuncontrolled growth outside the training domain, a single LN layer effectively\nmitigates this instability. Finally, we explore real-world implications of this\nextrapolatory stability, including applications to predicting residue sizes in\nproteins larger than those seen during training and estimating age from facial\nimages of underrepresented ethnicities absent from the training set."}
{"id": "2505.14526", "pdf": "https://arxiv.org/pdf/2505.14526", "abs": "https://arxiv.org/abs/2505.14526", "authors": ["Matteo El-Hariry", "Antoine Richard", "Ricard M. Castan", "Luis F. W. Batista", "Matthieu Geist", "Cedric Pradalier", "Miguel Olivares-Mendez"], "title": "NavBench: A Unified Robotics Benchmark for Reinforcement Learning-Based Autonomous Navigation", "categories": ["cs.RO", "cs.AI"], "comment": "Submitted for publication. Under review (2025)", "summary": "Autonomous robots must navigate and operate in diverse environments, from\nterrestrial and aquatic settings to aerial and space domains. While\nReinforcement Learning (RL) has shown promise in training policies for specific\nautonomous robots, existing benchmarks are often constrained to unique\nplatforms, limiting generalization and fair comparisons across different\nmobility systems. In this paper, we present NavBench, a multi-domain benchmark\nfor training and evaluating RL-based navigation policies across diverse robotic\nplatforms and operational environments. Built on IsaacLab, our framework\nstandardizes task definitions, enabling different robots to tackle various\nnavigation challenges without the need for ad-hoc task redesigns or custom\nevaluation metrics. Our benchmark addresses three key challenges: (1) Unified\ncross-medium benchmarking, enabling direct evaluation of diverse actuation\nmethods (thrusters, wheels, water-based propulsion) in realistic environments;\n(2) Scalable and modular design, facilitating seamless robot-task\ninterchangeability and reproducible training pipelines; and (3) Robust\nsim-to-real validation, demonstrated through successful policy transfer to\nmultiple real-world robots, including a satellite robotic simulator, an\nunmanned surface vessel, and a wheeled ground vehicle. By ensuring consistency\nbetween simulation and real-world deployment, NavBench simplifies the\ndevelopment of adaptable RL-based navigation strategies. Its modular design\nallows researchers to easily integrate custom robots and tasks by following the\nframework's predefined templates, making it accessible for a wide range of\napplications. Our code is publicly available at NavBench."}
{"id": "2505.14607", "pdf": "https://arxiv.org/pdf/2505.14607", "abs": "https://arxiv.org/abs/2505.14607", "authors": ["Soumadeep Saha", "Akshay Chaturvedi", "Joy Mahapatra", "Utpal Garain"], "title": "sudoLLM : On Multi-role Alignment of Language Models", "categories": ["cs.CL", "cs.CR", "I.2.7"], "comment": "Under review. Code and data to be released later", "summary": "User authorization-based access privileges are a key feature in many\nsafety-critical systems, but have thus far been absent from the large language\nmodel (LLM) realm. In this work, drawing inspiration from such access control\nsystems, we introduce sudoLLM, a novel framework that results in multi-role\naligned LLMs, i.e., LLMs that account for, and behave in accordance with, user\naccess rights. sudoLLM injects subtle user-based biases into queries and trains\nan LLM to utilize this bias signal in order to produce sensitive information if\nand only if the user is authorized. We present empirical results demonstrating\nthat this approach shows substantially improved alignment, generalization, and\nresistance to prompt-based jailbreaking attacks. The persistent tension between\nthe language modeling objective and safety alignment, which is often exploited\nto jailbreak LLMs, is somewhat resolved with the aid of the injected bias\nsignal. Our framework is meant as an additional security layer, and complements\nexisting guardrail mechanisms for enhanced end-to-end safety with LLMs."}
{"id": "2501.02040", "pdf": "https://arxiv.org/pdf/2501.02040", "abs": "https://arxiv.org/abs/2501.02040", "authors": ["Juntao Zhang", "Shaogeng Liu", "Kun Bian", "You Zhou", "Pei Zhang", "Jianning Liu", "Jun Zhou", "Bingyan Liu"], "title": "A Separable Self-attention Inspired by the State Space Model for Computer Vision", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Mamba is an efficient State Space Model (SSM) with linear computational\ncomplexity. Although SSMs are not suitable for handling non-causal data, Vision\nMamba (ViM) methods still demonstrate good performance in tasks such as image\nclassification and object detection. Recent studies have shown that there is a\nrich theoretical connection between state space models and attention variants.\nWe propose a novel separable self attention method, for the first time\nintroducing some excellent design concepts of Mamba into separable\nself-attention. To ensure a fair comparison with ViMs, we introduce VMINet, a\nsimple yet powerful prototype architecture, constructed solely by stacking our\nnovel attention modules with the most basic down-sampling layers. Notably,\nVMINet differs significantly from the conventional Transformer architecture.\nOur experiments demonstrate that VMINet has achieved competitive results on\nimage classification and high-resolution dense prediction tasks.Code is\navailable at: https://github.com/yws-wxs/VMINet."}
{"id": "2505.14522", "pdf": "https://arxiv.org/pdf/2505.14522", "abs": "https://arxiv.org/abs/2505.14522", "authors": ["Mahmuda Akhter Nishu", "Chenyu Huang", "Milad Roohi", "Xin Zhong"], "title": "Interpretable Dual-Stream Learning for Local Wind Hazard Prediction in Vulnerable Communities", "categories": ["cs.LG"], "comment": null, "summary": "Wind hazards such as tornadoes and straight-line winds frequently affect\nvulnerable communities in the Great Plains of the United States, where limited\ninfrastructure and sparse data coverage hinder effective emergency response.\nExisting forecasting systems focus primarily on meteorological elements and\noften fail to capture community-specific vulnerabilities, limiting their\nutility for localized risk assessment and resilience planning. To address this\ngap, we propose an interpretable dual-stream learning framework that integrates\nstructured numerical weather data with unstructured textual event narratives.\nOur architecture combines a Random Forest and RoBERTa-based transformer through\na late fusion mechanism, enabling robust and context-aware wind hazard\nprediction. The system is tailored for underserved tribal communities and\nsupports block-level risk assessment. Experimental results show significant\nperformance gains over traditional baselines. Furthermore, gradient-based\nsensitivity and ablation studies provide insight into the model's\ndecision-making process, enhancing transparency and operational trust. The\nfindings demonstrate both predictive effectiveness and practical value in\nsupporting emergency preparedness and advancing community resilience."}
{"id": "2505.14533", "pdf": "https://arxiv.org/pdf/2505.14533", "abs": "https://arxiv.org/abs/2505.14533", "authors": ["Mohammad Irfan Uddin", "Nishad Tasnim", "Md Omor Faruk", "Zejian Zhou"], "title": "Energy-Efficient Deep Reinforcement Learning with Spiking Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Agent-based Transformers have been widely adopted in recent reinforcement\nlearning advances due to their demonstrated ability to solve complex tasks.\nHowever, the high computational complexity of Transformers often results in\nsignificant energy consumption, limiting their deployment in real-world\nautonomous systems. Spiking neural networks (SNNs), with their biologically\ninspired structure, offer an energy-efficient alternative for machine learning.\nIn this paper, a novel Spike-Transformer Reinforcement Learning (STRL)\nalgorithm that combines the energy efficiency of SNNs with the powerful\ndecision-making capabilities of reinforcement learning is developed.\nSpecifically, an SNN using multi-step Leaky Integrate-and-Fire (LIF) neurons\nand attention mechanisms capable of processing spatio-temporal patterns over\nmultiple time steps is designed. The architecture is further enhanced with\nstate, action, and reward encodings to create a Transformer-like structure\noptimized for reinforcement learning tasks. Comprehensive numerical experiments\nconducted on state-of-the-art benchmarks demonstrate that the proposed SNN\nTransformer achieves significantly improved policy performance compared to\nconventional agent-based Transformers. With both enhanced energy efficiency and\npolicy optimality, this work highlights a promising direction for deploying\nbio-inspired, low-cost machine learning models in complex real-world\ndecision-making scenarios."}
{"id": "2505.14608", "pdf": "https://arxiv.org/pdf/2505.14608", "abs": "https://arxiv.org/abs/2505.14608", "authors": ["Rafael Rivera Soto", "Barry Chen", "Nicholas Andrews"], "title": "Language Models Optimized to Fool Detectors Still Have a Distinct Style (And How to Change It)", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite considerable progress in the development of machine-text detectors,\nit has been suggested that the problem is inherently hard, and therefore, that\nstakeholders should proceed under the assumption that machine-generated text\ncannot be reliably detected as such. We examine a recent such claim by Nicks et\nal. (2024) regarding the ease with which language models can be optimized to\ndegrade the performance of machine-text detectors, including detectors not\nspecifically optimized against. We identify a feature space$\\unicode{x2013}$the\nstylistic feature space$\\unicode{x2013}$that is robust to such optimization,\nand show that it may be used to reliably detect samples from language models\noptimized to prevent detection. Furthermore, we show that even when models are\nexplicitly optimized against stylistic detectors, detection performance remains\nsurprisingly unaffected. We then seek to understand if stylistic detectors are\ninherently more robust. To study this question, we explore a new paraphrasing\napproach that simultaneously aims to close the gap between human writing and\nmachine writing in stylistic feature space while avoiding detection using\ntraditional features. We show that when only a single sample is available for\ndetection, this attack is universally effective across all detectors\nconsidered, including those that use writing style. However, as the number of\nsamples available for detection grows, the human and machine distributions\nbecome distinguishable. This observation encourages us to introduce AURA, a\nmetric that estimates the overlap between human and machine-generated\ndistributions by analyzing how detector performance improves as more samples\nbecome available. Overall, our findings underscore previous recommendations to\navoid reliance on machine-text detection."}
{"id": "2501.12368", "pdf": "https://arxiv.org/pdf/2501.12368", "abs": "https://arxiv.org/abs/2501.12368", "authors": ["Yuhang Zang", "Xiaoyi Dong", "Pan Zhang", "Yuhang Cao", "Ziyu Liu", "Shengyuan Ding", "Shenxi Wu", "Yubo Ma", "Haodong Duan", "Wenwei Zhang", "Kai Chen", "Dahua Lin", "Jiaqi Wang"], "title": "InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model", "categories": ["cs.CV", "cs.CL"], "comment": "ACL 2025 Findings", "summary": "Despite the promising performance of Large Vision Language Models (LVLMs) in\nvisual understanding, they occasionally generate incorrect outputs. While\nreward models (RMs) with reinforcement learning or test-time scaling offer the\npotential for improving generation quality, a critical gap remains: publicly\navailable multi-modal RMs for LVLMs are scarce, and the implementation details\nof proprietary models are often unclear. We bridge this gap with\nInternLM-XComposer2.5-Reward (IXC-2.5-Reward), a simple yet effective\nmulti-modal reward model that aligns LVLMs with human preferences. To ensure\nthe robustness and versatility of IXC-2.5-Reward, we set up a high-quality\nmulti-modal preference corpus spanning text, image, and video inputs across\ndiverse domains, such as instruction following, general understanding,\ntext-rich documents, mathematical reasoning, and video understanding.\nIXC-2.5-Reward achieves excellent results on the latest multi-modal reward\nmodel benchmark and shows competitive performance on text-only reward model\nbenchmarks. We further demonstrate three key applications of IXC-2.5-Reward:\n(1) Providing a supervisory signal for RL training. We integrate IXC-2.5-Reward\nwith Proximal Policy Optimization (PPO) yields IXC-2.5-Chat, which shows\nconsistent improvements in instruction following and multi-modal open-ended\ndialogue; (2) Selecting the best response from candidate responses for\ntest-time scaling; and (3) Filtering outlier or noisy samples from existing\nimage and video instruction tuning training data. To ensure reproducibility and\nfacilitate further research, we have open-sourced all model weights and\ntraining recipes at\nhttps://github.com/InternLM/InternLM-XComposer/tree/main/InternLM-XComposer-2.5-Reward"}
{"id": "2505.14531", "pdf": "https://arxiv.org/pdf/2505.14531", "abs": "https://arxiv.org/abs/2505.14531", "authors": ["Shaoye Luo", "Xinxin Fan", "Quanliang Jing", "Chi Lin", "Mengfan Li", "Yunfeng Lu", "Yongjun Xu"], "title": "SifterNet: A Generalized and Model-Agnostic Trigger Purification Approach", "categories": ["cs.LG"], "comment": null, "summary": "Aiming at resisting backdoor attacks in convolution neural networks and\nvision Transformer-based large model, this paper proposes a generalized and\nmodel-agnostic trigger-purification approach resorting to the classic Ising\nmodel. To date, existing trigger detection/removal studies usually require to\nknow the detailed knowledge of target model in advance, access to a large\nnumber of clean samples or even model-retraining authorization, which brings\nthe huge inconvenience for practical applications, especially inaccessible to\ntarget model. An ideal countermeasure ought to eliminate the implanted trigger\nwithout regarding whatever the target models are. To this end, a lightweight\nand black-box defense approach SifterNet is proposed through leveraging the\nmemorization-association functionality of Hopfield network, by which the\ntriggers of input samples can be effectively purified in a proper manner. The\nmain novelty of our proposed approach lies in the introduction of ideology of\nIsing model. Extensive experiments also validate the effectiveness of our\napproach in terms of proper trigger purification and high accuracy achievement,\nand compared to the state-of-the-art baselines under several commonly-used\ndatasets, our SiferNet has a significant superior performance."}
{"id": "2505.14549", "pdf": "https://arxiv.org/pdf/2505.14549", "abs": "https://arxiv.org/abs/2505.14549", "authors": ["Dzung Pham", "Peter Kairouz", "Niloofar Mireshghallah", "Eugene Bagdasarian", "Chau Minh Pham", "Amir Houmansadr"], "title": "Can Large Language Models Really Recognize Your Name?", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly being used to protect sensitive\nuser data. However, current LLM-based privacy solutions assume that these\nmodels can reliably detect personally identifiable information (PII),\nparticularly named entities. In this paper, we challenge that assumption by\nrevealing systematic failures in LLM-based privacy tasks. Specifically, we show\nthat modern LLMs regularly overlook human names even in short text snippets due\nto ambiguous contexts, which cause the names to be misinterpreted or\nmishandled. We propose AMBENCH, a benchmark dataset of seemingly ambiguous\nhuman names, leveraging the name regularity bias phenomenon, embedded within\nconcise text snippets along with benign prompt injections. Our experiments on\nmodern LLMs tasked to detect PII as well as specialized tools show that recall\nof ambiguous names drops by 20--40% compared to more recognizable names.\nFurthermore, ambiguous human names are four times more likely to be ignored in\nsupposedly privacy-preserving summaries generated by LLMs when benign prompt\ninjections are present. These findings highlight the underexplored risks of\nrelying solely on LLMs to safeguard user privacy and underscore the need for a\nmore systematic investigation into their privacy failure modes."}
{"id": "2505.14617", "pdf": "https://arxiv.org/pdf/2505.14617", "abs": "https://arxiv.org/abs/2505.14617", "authors": ["Sahar Abdelnabi", "Ahmed Salem"], "title": "Linear Control of Test Awareness Reveals Differential Compliance in Reasoning Models", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Reasoning-focused large language models (LLMs) sometimes alter their behavior\nwhen they detect that they are being evaluated, an effect analogous to the\nHawthorne phenomenon, which can lead them to optimize for test-passing\nperformance or to comply more readily with harmful prompts if real-world\nconsequences appear absent. We present the first quantitative study of how such\n\"test awareness\" impacts model behavior, particularly its safety alignment. We\nintroduce a white-box probing framework that (i) linearly identifies\nawareness-related activations and (ii) steers models toward or away from test\nawareness while monitoring downstream performance. We apply our method to\ndifferent state-of-the-art open-source reasoning LLMs across both realistic and\nhypothetical tasks. Our results demonstrate that test awareness significantly\nimpact safety alignment, and is different for different models. By providing\nfine-grained control over this latent effect, our work aims to increase trust\nin how we perform safety evaluation."}
{"id": "2501.15641", "pdf": "https://arxiv.org/pdf/2501.15641", "abs": "https://arxiv.org/abs/2501.15641", "authors": ["Yuxin Zhang", "Minyan Luo", "Weiming Dong", "Xiao Yang", "Haibin Huang", "Chongyang Ma", "Oliver Deussen", "Tong-Yee Lee", "Changsheng Xu"], "title": "IP-Prompter: Training-Free Theme-Specific Image Generation via Dynamic Visual Prompting", "categories": ["cs.CV"], "comment": "Accepted by ACM SIGGRAPH 2025. Project page:\n  https://ip-prompter.github.io/", "summary": "The stories and characters that captivate us as we grow up shape unique\nfantasy worlds, with images serving as the primary medium for visually\nexperiencing these realms. Personalizing generative models through fine-tuning\nwith theme-specific data has become a prevalent approach in text-to-image\ngeneration. However, unlike object customization, which focuses on learning\nspecific objects, theme-specific generation encompasses diverse elements such\nas characters, scenes, and objects. Such diversity also introduces a key\nchallenge: how to adaptively generate multi-character, multi-concept, and\ncontinuous theme-specific images (TSI). Moreover, fine-tuning approaches often\ncome with significant computational overhead, time costs, and risks of\noverfitting. This paper explores a fundamental question: Can image generation\nmodels directly leverage images as contextual input, similarly to how large\nlanguage models use text as context? To address this, we present IP-Prompter, a\nnovel training-free TSI generation method. IP-Prompter introduces visual\nprompting, a mechanism that integrates reference images into generative models,\nallowing users to seamlessly specify the target theme without requiring\nadditional training. To further enhance this process, we propose a Dynamic\nVisual Prompting (DVP) mechanism, which iteratively optimizes visual prompts to\nimprove the accuracy and quality of generated images. Our approach enables\ndiverse applications, including consistent story generation, character design,\nrealistic character generation, and style-guided image generation. Comparative\nevaluations against state-of-the-art personalization methods demonstrate that\nIP-Prompter achieves significantly better results and excels in maintaining\ncharacter identity preserving, style consistency and text alignment, offering a\nrobust and flexible solution for theme-specific image generation."}
{"id": "2505.14535", "pdf": "https://arxiv.org/pdf/2505.14535", "abs": "https://arxiv.org/abs/2505.14535", "authors": ["Jiangrong Shen", "Yulin Xie", "Qi Xu", "Gang Pan", "Huajin Tang", "Badong Chen"], "title": "Spiking Neural Networks with Temporal Attention-Guided Adaptive Fusion for imbalanced Multi-modal Learning", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Multimodal spiking neural networks (SNNs) hold significant potential for\nenergy-efficient sensory processing but face critical challenges in modality\nimbalance and temporal misalignment. Current approaches suffer from\nuncoordinated convergence speeds across modalities and static fusion mechanisms\nthat ignore time-varying cross-modal interactions. We propose the temporal\nattention-guided adaptive fusion framework for multimodal SNNs with two\nsynergistic innovations: 1) The Temporal Attention-guided Adaptive Fusion\n(TAAF) module that dynamically assigns importance scores to fused spiking\nfeatures at each timestep, enabling hierarchical integration of temporally\nheterogeneous spike-based features; 2) The temporal adaptive balanced fusion\nloss that modulates learning rates per modality based on the above attention\nscores, preventing dominant modalities from monopolizing optimization. The\nproposed framework implements adaptive fusion, especially in the temporal\ndimension, and alleviates the modality imbalance during multimodal learning,\nmimicking cortical multisensory integration principles. Evaluations on CREMA-D,\nAVE, and EAD datasets demonstrate state-of-the-art performance (77.55\\%,\n70.65\\% and 97.5\\%accuracy, respectively) with energy efficiency. The system\nresolves temporal misalignment through learnable time-warping operations and\nfaster modality convergence coordination than baseline SNNs. This work\nestablishes a new paradigm for temporally coherent multimodal learning in\nneuromorphic systems, bridging the gap between biological sensory processing\nand efficient machine intelligence."}
{"id": "2505.14551", "pdf": "https://arxiv.org/pdf/2505.14551", "abs": "https://arxiv.org/abs/2505.14551", "authors": ["Petros Drineas", "Rohit Nema", "Rafail Ostrovsky", "Vassilis Zikas"], "title": "Trustworthy Reputation Games and Applications to Proof-of-Reputation Blockchains", "categories": ["cs.GT", "cs.AI", "cs.CR"], "comment": null, "summary": "Reputation systems play an essential role in the Internet era, as they enable\npeople to decide whom to trust, by collecting and aggregating data about users'\nbehavior. Recently, several works proposed the use of reputation for the design\nand scalability improvement of decentralized (blockchain) ledgers; however,\nsuch systems are prone to manipulation and to our knowledge no game-theoretic\ntreatment exists that can support their economic robustness.\n  In this work we put forth a new model for the design of what we call, {\\em\ntrustworthy reputation systems}. Concretely, we describe a class of games,\nwhich we term {\\em trustworthy reputation games}, that enable a set of users to\nreport a function of their beliefs about the trustworthiness of each server in\na set -- i.e., their estimate of the probability that this server will behave\naccording to its specified strategy -- in a way that satisfies the following\nproperties:\n  1. It is $(\\epsilon$-)best response for any rational user in the game to play\na prescribed (truthful) strategy according to their true belief.\n  2. Assuming that the users' beliefs are not too far from the {\\em true}\ntrustworthiness of the servers, playing the above ($\\epsilon-$)Nash equilibrium\nallows anyone who observes the users' strategies to estimate the relative\ntrustworthiness of any two servers.\n  Our utilities and decoding function build on a connection between the well\nknown PageRank algorithm and the problem of trustworthiness discovery, which\ncan be of independent interest. Finally, we show how the above games are\nmotivated by and can be leveraged in proof-of-reputation (PoR) blockchains."}
{"id": "2505.14631", "pdf": "https://arxiv.org/pdf/2505.14631", "abs": "https://arxiv.org/abs/2505.14631", "authors": ["Lingjie Jiang", "Xun Wu", "Shaohan Huang", "Qingxiu Dong", "Zewen Chi", "Li Dong", "Xingxing Zhang", "Tengchao Lv", "Lei Cui", "Furu Wei"], "title": "Think Only When You Need with Large Hybrid-Reasoning Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent Large Reasoning Models (LRMs) have shown substantially improved\nreasoning capabilities over traditional Large Language Models (LLMs) by\nincorporating extended thinking processes prior to producing final responses.\nHowever, excessively lengthy thinking introduces substantial overhead in terms\nof token consumption and latency, which is particularly unnecessary for simple\nqueries. In this work, we introduce Large Hybrid-Reasoning Models (LHRMs), the\nfirst kind of model capable of adaptively determining whether to perform\nthinking based on the contextual information of user queries. To achieve this,\nwe propose a two-stage training pipeline comprising Hybrid Fine-Tuning (HFT) as\na cold start, followed by online reinforcement learning with the proposed\nHybrid Group Policy Optimization (HGPO) to implicitly learn to select the\nappropriate thinking mode. Furthermore, we introduce a metric called Hybrid\nAccuracy to quantitatively assess the model's capability for hybrid thinking.\nExtensive experimental results show that LHRMs can adaptively perform hybrid\nthinking on queries of varying difficulty and type. It outperforms existing\nLRMs and LLMs in reasoning and general capabilities while significantly\nimproving efficiency. Together, our work advocates for a reconsideration of the\nappropriate use of extended thinking processes and provides a solid starting\npoint for building hybrid thinking systems."}
{"id": "2502.00379", "pdf": "https://arxiv.org/pdf/2502.00379", "abs": "https://arxiv.org/abs/2502.00379", "authors": ["Alexander Nikulin", "Ilya Zisman", "Denis Tarasov", "Nikita Lyubaykin", "Andrei Polubarov", "Igor Kiselev", "Vladislav Kurenkov"], "title": "Latent Action Learning Requires Supervision in the Presence of Distractors", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICML 2025, Poster, Source code: https://github.com/dunnolab/laom", "summary": "Recently, latent action learning, pioneered by Latent Action Policies (LAPO),\nhave shown remarkable pre-training efficiency on observation-only data,\noffering potential for leveraging vast amounts of video available on the web\nfor embodied AI. However, prior work has focused on distractor-free data, where\nchanges between observations are primarily explained by ground-truth actions.\nUnfortunately, real-world videos contain action-correlated distractors that may\nhinder latent action learning. Using Distracting Control Suite (DCS) we\nempirically investigate the effect of distractors on latent action learning and\ndemonstrate that LAPO struggle in such scenario. We propose LAOM, a simple LAPO\nmodification that improves the quality of latent actions by 8x, as measured by\nlinear probing. Importantly, we show that providing supervision with\nground-truth actions, as few as 2.5% of the full dataset, during latent action\nlearning improves downstream performance by 4.2x on average. Our findings\nsuggest that integrating supervision during Latent Action Models (LAM) training\nis critical in the presence of distractors, challenging the conventional\npipeline of first learning LAM and only then decoding from latent to\nground-truth actions."}
{"id": "2505.14543", "pdf": "https://arxiv.org/pdf/2505.14543", "abs": "https://arxiv.org/abs/2505.14543", "authors": ["Utsav Dutta", "Sina Khoshfetrat Pakazad", "Henrik Ohlsson"], "title": "Time to Embed: Unlocking Foundation Models for Time Series with Channel Descriptions", "categories": ["cs.LG"], "comment": null, "summary": "Traditional time series models are task-specific and often depend on\ndataset-specific training and extensive feature engineering. While\nTransformer-based architectures have improved scalability, foundation models,\ncommonplace in text, vision, and audio, remain under-explored for time series\nand are largely restricted to forecasting. We introduce $\\textbf{CHARM}$, a\nfoundation embedding model for multivariate time series that learns shared,\ntransferable, and domain-aware representations. To address the unique\ndifficulties of time series foundation learning, $\\textbf{CHARM}$ incorporates\narchitectural innovations that integrate channel-level textual descriptions\nwhile remaining invariant to channel order. The model is trained using a Joint\nEmbedding Predictive Architecture (JEPA), with novel augmentation schemes and a\nloss function designed to improve interpretability and training stability. Our\n$7$M-parameter model achieves state-of-the-art performance across diverse\ndownstream tasks, setting a new benchmark for time series representation\nlearning."}
{"id": "2505.14555", "pdf": "https://arxiv.org/pdf/2505.14555", "abs": "https://arxiv.org/abs/2505.14555", "authors": ["Yingtao Luo", "Shikai Fang", "Binqing Wu", "Qingsong Wen", "Liang Sun"], "title": "Physics-Guided Learning of Meteorological Dynamics for Weather Downscaling and Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Published/Accepted in KDD 2025 (February Cycle)", "summary": "Weather forecasting is essential but remains computationally intensive and\nphysically incomplete in traditional numerical weather prediction (NWP)\nmethods. Deep learning (DL) models offer efficiency and accuracy but often\nignore physical laws, limiting interpretability and generalization. We propose\nPhyDL-NWP, a physics-guided deep learning framework that integrates physical\nequations with latent force parameterization into data-driven models. It\npredicts weather variables from arbitrary spatiotemporal coordinates, computes\nphysical terms via automatic differentiation, and uses a physics-informed loss\nto align predictions with governing dynamics. PhyDL-NWP enables resolution-free\ndownscaling by modeling weather as a continuous function and fine-tunes\npre-trained models with minimal overhead, achieving up to 170x faster inference\nwith only 55K parameters. Experiments show that PhyDL-NWP improves both\nforecasting performance and physical consistency."}
{"id": "2505.14633", "pdf": "https://arxiv.org/pdf/2505.14633", "abs": "https://arxiv.org/abs/2505.14633", "authors": ["Yu Ying Chiu", "Zhilin Wang", "Sharan Maiya", "Yejin Choi", "Kyle Fish", "Sydney Levine", "Evan Hubinger"], "title": "Will AI Tell Lies to Save Sick Children? Litmus-Testing AI Values Prioritization with AIRiskDilemmas", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "comment": "34 pages, 11 figures, see associated data at\n  https://huggingface.co/datasets/kellycyy/AIRiskDilemmas and code at\n  https://github.com/kellycyy/LitmusValues", "summary": "Detecting AI risks becomes more challenging as stronger models emerge and\nfind novel methods such as Alignment Faking to circumvent these detection\nattempts. Inspired by how risky behaviors in humans (i.e., illegal activities\nthat may hurt others) are sometimes guided by strongly-held values, we believe\nthat identifying values within AI models can be an early warning system for\nAI's risky behaviors. We create LitmusValues, an evaluation pipeline to reveal\nAI models' priorities on a range of AI value classes. Then, we collect\nAIRiskDilemmas, a diverse collection of dilemmas that pit values against one\nanother in scenarios relevant to AI safety risks such as Power Seeking. By\nmeasuring an AI model's value prioritization using its aggregate choices, we\nobtain a self-consistent set of predicted value priorities that uncover\npotential risks. We show that values in LitmusValues (including seemingly\ninnocuous ones like Care) can predict for both seen risky behaviors in\nAIRiskDilemmas and unseen risky behaviors in HarmBench."}
{"id": "2502.01051", "pdf": "https://arxiv.org/pdf/2502.01051", "abs": "https://arxiv.org/abs/2502.01051", "authors": ["Tao Zhang", "Cheng Da", "Kun Ding", "Huan Yang", "Kun Jin", "Yan Li", "Tingting Gao", "Di Zhang", "Shiming Xiang", "Chunhong Pan"], "title": "Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization", "categories": ["cs.CV"], "comment": "25 pages, 26 tables, 15 figures", "summary": "Preference optimization for diffusion models aims to align them with human\npreferences for images. Previous methods typically use Vision-Language Models\n(VLMs) as pixel-level reward models to approximate human preferences. However,\nwhen used for step-level preference optimization, these models face challenges\nin handling noisy images of different timesteps and require complex\ntransformations into pixel space. In this work, we show that pre-trained\ndiffusion models are naturally suited for step-level reward modeling in the\nnoisy latent space, as they are explicitly designed to process latent images at\nvarious noise levels. Accordingly, we propose the Latent Reward Model (LRM),\nwhich repurposes components of the diffusion model to predict preferences of\nlatent images at arbitrary timesteps. Building on LRM, we introduce Latent\nPreference Optimization (LPO), a step-level preference optimization method\nconducted directly in the noisy latent space. Experimental results indicate\nthat LPO significantly improves the model's alignment with general, aesthetic,\nand text-image alignment preferences, while achieving a 2.5-28x training\nspeedup over existing preference optimization methods. Our code and models are\navailable at https://github.com/Kwai-Kolors/LPO."}
{"id": "2505.14564", "pdf": "https://arxiv.org/pdf/2505.14564", "abs": "https://arxiv.org/abs/2505.14564", "authors": ["David Krame Kadurha", "Domini Jocema Leko Moutouo", "Yae Ulrich Gaba"], "title": "Bellman operator convergence enhancements in reinforcement learning algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper reviews the topological groundwork for the study of reinforcement\nlearning (RL) by focusing on the structure of state, action, and policy spaces.\nWe begin by recalling key mathematical concepts such as complete metric spaces,\nwhich form the foundation for expressing RL problems. By leveraging the Banach\ncontraction principle, we illustrate how the Banach fixed-point theorem\nexplains the convergence of RL algorithms and how Bellman operators, expressed\nas operators on Banach spaces, ensure this convergence. The work serves as a\nbridge between theoretical mathematics and practical algorithm design, offering\nnew approaches to enhance the efficiency of RL. In particular, we investigate\nalternative formulations of Bellman operators and demonstrate their impact on\nimproving convergence rates and performance in standard RL environments such as\nMountainCar, CartPole, and Acrobot. Our findings highlight how a deeper\nmathematical understanding of RL can lead to more effective algorithms for\ndecision-making problems."}
{"id": "2505.14566", "pdf": "https://arxiv.org/pdf/2505.14566", "abs": "https://arxiv.org/abs/2505.14566", "authors": ["Andrei Cozma", "Landon Harris", "Hairong Qi"], "title": "KIPPO: Koopman-Inspired Proximal Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for IJCAI 2025. This arXiv submission is the full version of\n  the conference paper, including the appendix and supplementary material\n  omitted from the IJCAI proceedings", "summary": "Reinforcement Learning (RL) has made significant strides in various domains,\nand policy gradient methods like Proximal Policy Optimization (PPO) have gained\npopularity due to their balance in performance, training stability, and\ncomputational efficiency. These methods directly optimize policies through\ngradient-based updates. However, developing effective control policies for\nenvironments with complex and non-linear dynamics remains a challenge. High\nvariance in gradient estimates and non-convex optimization landscapes often\nlead to unstable learning trajectories. Koopman Operator Theory has emerged as\na powerful framework for studying non-linear systems through an\ninfinite-dimensional linear operator that acts on a higher-dimensional space of\nmeasurement functions. In contrast with their non-linear counterparts, linear\nsystems are simpler, more predictable, and easier to analyze. In this paper, we\npresent Koopman-Inspired Proximal Policy Optimization (KIPPO), which learns an\napproximately linear latent-space representation of the underlying system's\ndynamics while retaining essential features for effective policy learning. This\nis achieved through a Koopman-approximation auxiliary network that can be added\nto the baseline policy optimization algorithms without altering the\narchitecture of the core policy or value function. Extensive experimental\nresults demonstrate consistent improvements over the PPO baseline with 6-60%\nincreased performance while reducing variability by up to 91% when evaluated on\nvarious continuous control tasks."}
{"id": "2505.14652", "pdf": "https://arxiv.org/pdf/2505.14652", "abs": "https://arxiv.org/abs/2505.14652", "authors": ["Xueguang Ma", "Qian Liu", "Dongfu Jiang", "Ge Zhang", "Zejun Ma", "Wenhu Chen"], "title": "General-Reasoner: Advancing LLM Reasoning Across All Domains", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) has recently demonstrated strong potential in\nenhancing the reasoning capabilities of large language models (LLMs).\nParticularly, the \"Zero\" reinforcement learning introduced by Deepseek-R1-Zero,\nenables direct RL training of base LLMs without relying on an intermediate\nsupervised fine-tuning stage. Despite these advancements, current works for LLM\nreasoning mainly focus on mathematical and coding domains, largely due to data\nabundance and the ease of answer verification. This limits the applicability\nand generalization of such models to broader domains, where questions often\nhave diverse answer representations, and data is more scarce. In this paper, we\npropose General-Reasoner, a novel training paradigm designed to enhance LLM\nreasoning capabilities across diverse domains. Our key contributions include:\n(1) constructing a large-scale, high-quality dataset of questions with\nverifiable answers curated by web crawling, covering a wide range of\ndisciplines; and (2) developing a generative model-based answer verifier, which\nreplaces traditional rule-based verification with the capability of\nchain-of-thought and context-awareness. We train a series of models and\nevaluate them on a wide range of datasets covering wide domains like physics,\nchemistry, finance, electronics etc. Our comprehensive evaluation across these\n12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC)\ndemonstrates that General-Reasoner outperforms existing baseline methods,\nachieving robust and generalizable reasoning performance while maintaining\nsuperior effectiveness in mathematical reasoning tasks."}
{"id": "2502.08200", "pdf": "https://arxiv.org/pdf/2502.08200", "abs": "https://arxiv.org/abs/2502.08200", "authors": ["Linghao Zhuang", "Ying Zhang", "Gege Yuan", "Xingyue Zhao", "Zhiping Jiang"], "title": "ActiveSSF: An Active-Learning-Guided Self-Supervised Framework for Long-Tailed Megakaryocyte Classification", "categories": ["cs.CV"], "comment": "6 pages", "summary": "Precise classification of megakaryocytes is crucial for diagnosing\nmyelodysplastic syndromes. Although self-supervised learning has shown promise\nin medical image analysis, its application to classifying megakaryocytes in\nstained slides faces three main challenges: (1) pervasive background noise that\nobscures cellular details, (2) a long-tailed distribution that limits data for\nrare subtypes, and (3) complex morphological variations leading to high\nintra-class variability. To address these issues, we propose the ActiveSSF\nframework, which integrates active learning with self-supervised pretraining.\nSpecifically, our approach employs Gaussian filtering combined with K-means\nclustering and HSV analysis (augmented by clinical prior knowledge) for\naccurate region-of-interest extraction; an adaptive sample selection mechanism\nthat dynamically adjusts similarity thresholds to mitigate class imbalance; and\nprototype clustering on labeled samples to overcome morphological complexity.\nExperimental results on clinical megakaryocyte datasets demonstrate that\nActiveSSF not only achieves state-of-the-art performance but also significantly\nimproves recognition accuracy for rare subtypes. Moreover, the integration of\nthese advanced techniques further underscores the practical potential of\nActiveSSF in clinical settings."}
{"id": "2505.14592", "pdf": "https://arxiv.org/pdf/2505.14592", "abs": "https://arxiv.org/abs/2505.14592", "authors": ["Alexandre Broggi", "Nathaniel Bastian", "Lance Fiondella", "Gokhan Kul"], "title": "Adaptive Pruning of Deep Neural Networks for Resource-Aware Embedded Intrusion Detection on the Edge", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Artificial neural network pruning is a method in which artificial neural\nnetwork sizes can be reduced while attempting to preserve the predicting\ncapabilities of the network. This is done to make the model smaller or faster\nduring inference time. In this work we analyze the ability of a selection of\nartificial neural network pruning methods to generalize to a new cybersecurity\ndataset utilizing a simpler network type than was designed for. We analyze each\nmethod using a variety of pruning degrees to best understand how each algorithm\nresponds to the new environment. This has allowed us to determine the most well\nfit pruning method of those we searched for the task. Unexpectedly, we have\nfound that many of them do not generalize to the problem well, leaving only a\nfew algorithms working to an acceptable degree."}
{"id": "2505.14625", "pdf": "https://arxiv.org/pdf/2505.14625", "abs": "https://arxiv.org/abs/2505.14625", "authors": ["Zhangchen Xu", "Yuetai Li", "Fengqing Jiang", "Bhaskar Ramasubramanian", "Luyao Niu", "Bill Yuchen Lin", "Radha Poovendran"], "title": "TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement Learning (RL) has become a powerful tool for enhancing the\nreasoning abilities of large language models (LLMs) by optimizing their\npolicies with reward signals. Yet, RL's success relies on the reliability of\nrewards, which are provided by verifiers. In this paper, we expose and analyze\na widespread problem--false negatives--where verifiers wrongly reject correct\nmodel outputs. Our in-depth study of the Big-Math-RL-Verified dataset reveals\nthat over 38% of model-generated responses suffer from false negatives, where\nthe verifier fails to recognize correct answers. We show, both empirically and\ntheoretically, that these false negatives severely impair RL training by\ndepriving the model of informative gradient signals and slowing convergence. To\nmitigate this, we propose tinyV, a lightweight LLM-based verifier that augments\nexisting rule-based methods, which dynamically identifies potential false\nnegatives and recovers valid responses to produce more accurate reward\nestimates. Across multiple math-reasoning benchmarks, integrating TinyV boosts\npass rates by up to 10% and accelerates convergence relative to the baseline.\nOur findings highlight the critical importance of addressing verifier false\nnegatives and offer a practical approach to improve RL-based fine-tuning of\nLLMs. Our code is available at https://github.com/uw-nsl/TinyV."}
{"id": "2505.14674", "pdf": "https://arxiv.org/pdf/2505.14674", "abs": "https://arxiv.org/abs/2505.14674", "authors": ["Jiaxin Guo", "Zewen Chi", "Li Dong", "Qingxiu Dong", "Xun Wu", "Shaohan Huang", "Furu Wei"], "title": "Reward Reasoning Model", "categories": ["cs.CL"], "comment": null, "summary": "Reward models play a critical role in guiding large language models toward\noutputs that align with human expectations. However, an open challenge remains\nin effectively utilizing test-time compute to enhance reward model performance.\nIn this work, we introduce Reward Reasoning Models (RRMs), which are\nspecifically designed to execute a deliberate reasoning process before\ngenerating final rewards. Through chain-of-thought reasoning, RRMs leverage\nadditional test-time compute for complex queries where appropriate rewards are\nnot immediately apparent. To develop RRMs, we implement a reinforcement\nlearning framework that fosters self-evolved reward reasoning capabilities\nwithout requiring explicit reasoning traces as training data. Experimental\nresults demonstrate that RRMs achieve superior performance on reward modeling\nbenchmarks across diverse domains. Notably, we show that RRMs can adaptively\nexploit test-time compute to further improve reward accuracy. The pretrained\nreward reasoning models are available at\nhttps://huggingface.co/Reward-Reasoning."}
{"id": "2502.11163", "pdf": "https://arxiv.org/pdf/2502.11163", "abs": "https://arxiv.org/abs/2502.11163", "authors": ["Jingyuan Huang", "Jen-tse Huang", "Ziyi Liu", "Xiaoyuan Liu", "Wenxuan Wang", "Jieyu Zhao"], "title": "VLMs as GeoGuessr Masters: Exceptional Performance, Hidden Biases, and Privacy Risks", "categories": ["cs.CV", "cs.CL"], "comment": "8 pages of main text; 5 pages of appendix", "summary": "Visual-Language Models (VLMs) have shown remarkable performance across\nvarious tasks, particularly in recognizing geographic information from images.\nHowever, VLMs still show regional biases in this task. To systematically\nevaluate these issues, we introduce a benchmark consisting of 1,200 images\npaired with detailed geographic metadata. Evaluating four VLMs, we find that\nwhile these models demonstrate the ability to recognize geographic information\nfrom images, achieving up to 53.8% accuracy in city prediction, they exhibit\nsignificant biases. Specifically, performance is substantially higher for\neconomically developed and densely populated regions compared to less developed\n(-12.5%) and sparsely populated (-17.0%) areas. Moreover, regional biases of\nfrequently over-predicting certain locations remain. For instance, they\nconsistently predict Sydney for images taken in Australia, shown by the low\nentropy scores for these countries. The strong performance of VLMs also raises\nprivacy concerns, particularly for users who share images online without the\nintent of being identified. Our code and dataset are publicly available at\nhttps://github.com/uscnlp-lime/FairLocator."}
{"id": "2505.14595", "pdf": "https://arxiv.org/pdf/2505.14595", "abs": "https://arxiv.org/abs/2505.14595", "authors": ["Nima Hosseini Dashtbayaz", "Hesam Salehipour", "Adrian Butscher", "Nigel Morris"], "title": "Physics-informed Reduced Order Modeling of Time-dependent PDEs via Differentiable Solvers", "categories": ["cs.LG"], "comment": null, "summary": "Reduced-order modeling (ROM) of time-dependent and parameterized differential\nequations aims to accelerate the simulation of complex high-dimensional systems\nby learning a compact latent manifold representation that captures the\ncharacteristics of the solution fields and their time-dependent dynamics.\nAlthough high-fidelity numerical solvers generate the training datasets, they\nhave thus far been excluded from the training process, causing the learned\nlatent dynamics to drift away from the discretized governing physics. This\nmismatch often limits generalization and forecasting capabilities. In this\nwork, we propose Physics-informed ROM ($\\Phi$-ROM) by incorporating\ndifferentiable PDE solvers into the training procedure. Specifically, the\nlatent space dynamics and its dependence on PDE parameters are shaped directly\nby the governing physics encoded in the solver, ensuring a strong\ncorrespondence between the full and reduced systems. Our model outperforms\nstate-of-the-art data-driven ROMs and other physics-informed strategies by\naccurately generalizing to new dynamics arising from unseen parameters,\nenabling long-term forecasting beyond the training horizon, maintaining\ncontinuity in both time and space, and reducing the data cost. Furthermore,\n$\\Phi$-ROM learns to recover and forecast the solution fields even when trained\nor evaluated with sparse and irregular observations of the fields, providing a\nflexible framework for field reconstruction and data assimilation. We\ndemonstrate the framework's robustness across different PDE solvers and\nhighlight its broad applicability by providing an open-source JAX\nimplementation readily extensible to other PDE systems and differentiable\nsolvers."}
{"id": "2505.14659", "pdf": "https://arxiv.org/pdf/2505.14659", "abs": "https://arxiv.org/abs/2505.14659", "authors": ["Navneet Kaur", "Lav Gupta"], "title": "Explainable AI for Securing Healthcare in IoT-Integrated 6G Wireless Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As healthcare systems increasingly adopt advanced wireless networks and\nconnected devices, securing medical applications has become critical. The\nintegration of Internet of Medical Things devices, such as robotic surgical\ntools, intensive care systems, and wearable monitors has enhanced patient care\nbut introduced serious security risks. Cyberattacks on these devices can lead\nto life threatening consequences, including surgical errors, equipment failure,\nand data breaches. While the ITU IMT 2030 vision highlights 6G's transformative\nrole in healthcare through AI and cloud integration, it also raises new\nsecurity concerns. This paper explores how explainable AI techniques like SHAP,\nLIME, and DiCE can uncover vulnerabilities, strengthen defenses, and improve\ntrust and transparency in 6G enabled healthcare. We support our approach with\nexperimental analysis and highlight promising results."}
{"id": "2505.14679", "pdf": "https://arxiv.org/pdf/2505.14679", "abs": "https://arxiv.org/abs/2505.14679", "authors": ["Xiaojie Gu", "Guangxu Chen", "Jungang Li", "Jia-Chen Gu", "Xuming Hu", "Kai Zhang"], "title": "UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Lifelong learning enables large language models (LLMs) to adapt to evolving\ninformation by continually updating their internal knowledge. An ideal system\nshould support efficient, wide-ranging updates while preserving existing\ncapabilities and ensuring reliable deployment. Model editing stands out as a\npromising solution for this goal, offering a focused and efficient way to\nrevise a model's internal knowledge. Although recent paradigms have made\nnotable progress, they often struggle to meet the demands of practical lifelong\nadaptation at scale. To bridge this gap, we propose ULTRAEDIT-a fundamentally\nnew editing solution that is training-, subject- and memory-free, making it\nparticularly well-suited for ultra-scalable, real-world lifelong model editing.\nULTRAEDIT performs editing through a self-contained process that relies solely\non lightweight linear algebra operations to compute parameter shifts, enabling\nfast and consistent parameter modifications with minimal overhead. To improve\nscalability in lifelong settings, ULTRAEDIT employs a lifelong normalization\nstrategy that continuously updates feature statistics across turns, allowing it\nto adapt to distributional shifts and maintain consistency over time. ULTRAEDIT\nachieves editing speeds over 7x faster than the previous state-of-the-art\nmethod-which was also the fastest known approach-while consuming less than 1/3\nthe VRAM, making it the only method currently capable of editing a 7B LLM on a\n24GB consumer-grade GPU. Furthermore, we construct ULTRAEDITBENCH-the largest\ndataset in the field to date, with over 2M editing pairs-and demonstrate that\nour method supports up to 1M edits while maintaining high accuracy.\nComprehensive experiments on four datasets and six models show that ULTRAEDIT\nconsistently achieves superior performance across diverse model editing\nscenarios. Our code is available at: https://github.com/XiaojieGu/UltraEdit."}
{"id": "2502.12558", "pdf": "https://arxiv.org/pdf/2502.12558", "abs": "https://arxiv.org/abs/2502.12558", "authors": ["Huaying Yuan", "Jian Ni", "Zheng Liu", "Yueze Wang", "Junjie Zhou", "Zhengyang Liang", "Bo Zhao", "Zhao Cao", "Zhicheng Dou", "Ji-Rong Wen"], "title": "MomentSeeker: A Task-Oriented Benchmark For Long-Video Moment Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurately locating key moments within long videos is crucial for solving\nlong video understanding (LVU) tasks. However, existing benchmarks are either\nseverely limited in terms of video length and task diversity, or they focus\nsolely on the end-to-end LVU performance, making them inappropriate for\nevaluating whether key moments can be accurately accessed. To address this\nchallenge, we propose MomentSeeker, a novel benchmark for long-video moment\nretrieval (LMVR), distinguished by the following features. First, it is created\nbased on long and diverse videos, averaging over 1200 seconds in duration and\ncollected from various domains, e.g., movie, anomaly, egocentric, and sports.\nSecond, it covers a variety of real-world scenarios in three levels:\nglobal-level, event-level, object-level, covering common tasks like action\nrecognition, object localization, and causal reasoning, etc. Third, it\nincorporates rich forms of queries, including text-only queries,\nimage-conditioned queries, and video-conditioned queries. On top of\nMomentSeeker, we conduct comprehensive experiments for both generation-based\napproaches (directly using MLLMs) and retrieval-based approaches (leveraging\nvideo retrievers). Our results reveal the significant challenges in long-video\nmoment retrieval in terms of accuracy and efficiency, despite improvements from\nthe latest long-video MLLMs and task-specific fine-tuning. We have publicly\nreleased MomentSeeker(https://yhy-2000.github.io/MomentSeeker/) to facilitate\nfuture research in this area."}
{"id": "2505.14596", "pdf": "https://arxiv.org/pdf/2505.14596", "abs": "https://arxiv.org/abs/2505.14596", "authors": ["Isabella Degen", "Zahraa S Abdallah", "Henry W J Reeve", "Kate Robson Brown"], "title": "CSTS: A Benchmark for the Discovery of Correlation Structures in Time Series Clustering", "categories": ["cs.LG", "stat.ML", "62H30, 62H20, 62-11, 68T10, 62M10,", "I.5.3; H.2.8; G.3; I.2.6"], "comment": "9 pages main + 32 pages total, 2 figures main + 6 figures appendix, 1\n  table main + 17 tables appendix, dataset available at\n  https://huggingface.co/datasets/idegen/csts, code available at\n  https://github.com/isabelladegen/corrclust-validation", "summary": "Time series clustering promises to uncover hidden structural patterns in data\nwith applications across healthcare, finance, industrial systems, and other\ncritical domains. However, without validated ground truth information,\nresearchers cannot objectively assess clustering quality or determine whether\npoor results stem from absent structures in the data, algorithmic limitations,\nor inappropriate validation methods, raising the question whether clustering is\n\"more art than science\" (Guyon et al., 2009). To address these challenges, we\nintroduce CSTS (Correlation Structures in Time Series), a synthetic benchmark\nfor evaluating the discovery of correlation structures in multivariate time\nseries data. CSTS provides a clean benchmark that enables researchers to\nisolate and identify specific causes of clustering failures by differentiating\nbetween correlation structure deterioration and limitations of clustering\nalgorithms and validation methods. Our contributions are: (1) a comprehensive\nbenchmark for correlation structure discovery with distinct correlation\nstructures, systematically varied data conditions, established performance\nthresholds, and recommended evaluation protocols; (2) empirical validation of\ncorrelation structure preservation showing moderate distortion from\ndownsampling and minimal effects from distribution shifts and sparsification;\nand (3) an extensible data generation framework enabling structure-first\nclustering evaluation. A case study demonstrates CSTS's practical utility by\nidentifying an algorithm's previously undocumented sensitivity to non-normal\ndistributions, illustrating how the benchmark enables precise diagnosis of\nmethodological limitations. CSTS advances rigorous evaluation standards for\ncorrelation-based time series clustering."}
{"id": "2505.14661", "pdf": "https://arxiv.org/pdf/2505.14661", "abs": "https://arxiv.org/abs/2505.14661", "authors": ["Matthew Russo", "Sivaprasad Sudhir", "Gerardo Vitagliano", "Chunwei Liu", "Tim Kraska", "Samuel Madden", "Michael Cafarella"], "title": "Abacus: A Cost-Based Optimizer for Semantic Operator Systems", "categories": ["cs.DB", "cs.AI", "H.2.4; I.2.5"], "comment": "16 pages, 6 figures", "summary": "LLMs enable an exciting new class of data processing applications over large\ncollections of unstructured documents. Several new programming frameworks have\nenabled developers to build these applications by composing them out of\nsemantic operators: a declarative set of AI-powered data transformations with\nnatural language specifications. These include LLM-powered maps, filters,\njoins, etc. used for document processing tasks such as information extraction,\nsummarization, and more. While systems of semantic operators have achieved\nstrong performance on benchmarks, they can be difficult to optimize. An\noptimizer for this setting must determine how to physically implement each\nsemantic operator in a way that optimizes the system globally. Existing\noptimizers are limited in the number of optimizations they can apply, and most\n(if not all) cannot optimize system quality, cost, or latency subject to\nconstraint(s) on the other dimensions. In this paper we present Abacus, an\nextensible, cost-based optimizer which searches for the best implementation of\na semantic operator system given a (possibly constrained) optimization\nobjective. Abacus estimates operator performance by leveraging a minimal set of\nvalidation examples and, if available, prior beliefs about operator\nperformance. We evaluate Abacus on document processing workloads in the\nbiomedical and legal domains (BioDEX; CUAD) and multi-modal question answering\n(MMQA). We demonstrate that systems optimized by Abacus achieve 18.7%-39.2%\nbetter quality and up to 23.6x lower cost and 4.2x lower latency than the next\nbest system."}
{"id": "2505.14684", "pdf": "https://arxiv.org/pdf/2505.14684", "abs": "https://arxiv.org/abs/2505.14684", "authors": ["Haolei Xu", "Yuchen Yan", "Yongliang Shen", "Wenqi Zhang", "Guiyang Hou", "Shengpei Jiang", "Kaitao Song", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress on\nmathemati-cal tasks through Chain-of-Thought (CoT) reasoning. However, existing\nmathematical CoT datasets often suffer from Thought Leaps due to experts\nomitting intermediate steps, which negatively impacts model learning and\ngeneralization. We propose the CoT Thought Leap Bridge Task, which aims to\nautomatically detect leaps and generate missing intermediate reasoning steps to\nrestore the completeness and coherence of CoT. To facilitate this, we\nconstructed a specialized training dataset called ScaleQM+, based on the\nstructured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought\nleaps. Through comprehensive experiments on mathematical reasoning benchmarks,\nwe demonstrate that models fine-tuned on bridged datasets consistently\noutperform those trained on original datasets, with improvements of up to\n+5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%)\nand provides better starting points for reinforcement learning (+3.1%),\nfunctioning as a plug-and-play module compatible with existing optimization\ntechniques. Furthermore, CoT-Bridge demonstrate improved generalization to\nout-of-domain logical reasoning tasks, confirming that enhancing reasoning\ncompleteness yields broadly applicable benefits."}
{"id": "2502.13146", "pdf": "https://arxiv.org/pdf/2502.13146", "abs": "https://arxiv.org/abs/2502.13146", "authors": ["Shuo Xing", "Yuping Wang", "Peiran Li", "Ruizheng Bai", "Yueqi Wang", "Chan-wei Hu", "Chengxuan Qian", "Huaxiu Yao", "Zhengzhong Tu"], "title": "Re-Align: Aligning Vision Language Models via Retrieval-Augmented Direct Preference Optimization", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages", "summary": "The emergence of large Vision Language Models (VLMs) has broadened the scope\nand capabilities of single-modal Large Language Models (LLMs) by integrating\nvisual modalities, thereby unlocking transformative cross-modal applications in\na variety of real-world scenarios. Despite their impressive performance, VLMs\nare prone to significant hallucinations, particularly in the form of\ncross-modal inconsistencies. Building on the success of Reinforcement Learning\nfrom Human Feedback (RLHF) in aligning LLMs, recent advancements have focused\non applying direct preference optimization (DPO) on carefully curated datasets\nto mitigate these issues. Yet, such approaches typically introduce preference\nsignals in a brute-force manner, neglecting the crucial role of visual\ninformation in the alignment process. In this paper, we introduce Re-Align, a\nnovel alignment framework that leverages image retrieval to construct a\ndual-preference dataset, effectively incorporating both textual and visual\npreference signals. We further introduce rDPO, an extension of the standard\ndirect preference optimization that incorporates an additional visual\npreference objective during fine-tuning. Our experimental results demonstrate\nthat Re-Align not only mitigates hallucinations more effectively than previous\nmethods but also yields significant performance gains in general visual\nquestion-answering (VQA) tasks. Moreover, we show that Re-Align maintains\nrobustness and scalability across a wide range of VLM sizes and architectures.\nThis work represents a significant step forward in aligning multimodal LLMs,\npaving the way for more reliable and effective cross-modal applications. We\nrelease all the code in https://github.com/taco-group/Re-Align."}
{"id": "2505.14606", "pdf": "https://arxiv.org/pdf/2505.14606", "abs": "https://arxiv.org/abs/2505.14606", "authors": ["Maksim Zhdanov", "Vladislav Kurenkov"], "title": "Electrostatics from Laplacian Eigenbasis for Neural Network Interatomic Potentials", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Recent advances in neural network interatomic potentials have emerged as a\npromising research direction. However, popular deep learning models often lack\nauxiliary constraints grounded in physical laws, which could accelerate\ntraining and improve fidelity through physics-based regularization. In this\nwork, we introduce $\\Phi$-Module, a universal plugin module that enforces\nPoisson's equation within the message-passing framework to learn electrostatic\ninteractions in a self-supervised manner. Specifically, each atom-wise\nrepresentation is encouraged to satisfy a discretized Poisson's equation,\nmaking it possible to acquire a potential $\\boldsymbol{\\phi}$ and a\ncorresponding charge density $\\boldsymbol{\\rho}$ linked to the learnable\nLaplacian eigenbasis coefficients of a given molecular graph. We then derive an\nelectrostatic energy term, crucial for improved total energy predictions. This\napproach integrates seamlessly into any existing neural potential with\ninsignificant computational overhead. Experiments on the OE62 and MD22\nbenchmarks confirm that models combined with $\\Phi$-Module achieve robust\nimprovements over baseline counterparts. For OE62 error reduction ranges from\n4.5\\% to 17.8\\%, and for MD22, baseline equipped with $\\Phi$-Module achieves\nbest results on 5 out of 14 cases. Our results underscore how embedding a\nfirst-principles constraint in neural interatomic potentials can significantly\nimprove performance while remaining hyperparameter-friendly, memory-efficient\nand lightweight in training. Code will be available at\n\\href{https://github.com/dunnolab/phi-module}{dunnolab/phi-module}."}
{"id": "2505.14680", "pdf": "https://arxiv.org/pdf/2505.14680", "abs": "https://arxiv.org/abs/2505.14680", "authors": ["Sunhao Dai", "Wenjie Wang", "Liang Pang", "Jun Xu", "See-Kiong Ng", "Ji-Rong Wen", "Tat-Seng Chua"], "title": "NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.HC"], "comment": "SIGIR 2025 Perspective Paper", "summary": "Generative AI search is reshaping information retrieval by offering\nend-to-end answers to complex queries, reducing users' reliance on manually\nbrowsing and summarizing multiple web pages. However, while this paradigm\nenhances convenience, it disrupts the feedback-driven improvement loop that has\nhistorically powered the evolution of traditional Web search. Web search can\ncontinuously improve their ranking models by collecting large-scale,\nfine-grained user feedback (e.g., clicks, dwell time) at the document level. In\ncontrast, generative AI search operates through a much longer search pipeline,\nspanning query decomposition, document retrieval, and answer generation, yet\ntypically receives only coarse-grained feedback on the final answer. This\nintroduces a feedback loop disconnect, where user feedback for the final output\ncannot be effectively mapped back to specific system components, making it\ndifficult to improve each intermediate stage and sustain the feedback loop. In\nthis paper, we envision NExT-Search, a next-generation paradigm designed to\nreintroduce fine-grained, process-level feedback into generative AI search.\nNExT-Search integrates two complementary modes: User Debug Mode, which allows\nengaged users to intervene at key stages; and Shadow User Mode, where a\npersonalized user agent simulates user preferences and provides AI-assisted\nfeedback for less interactive users. Furthermore, we envision how these\nfeedback signals can be leveraged through online adaptation, which refines\ncurrent search outputs in real-time, and offline update, which aggregates\ninteraction logs to periodically fine-tune query decomposition, retrieval, and\ngeneration models. By restoring human control over key stages of the generative\nAI search pipeline, we believe NExT-Search offers a promising direction for\nbuilding feedback-rich AI search systems that can evolve continuously alongside\nhuman feedback."}
{"id": "2505.14685", "pdf": "https://arxiv.org/pdf/2505.14685", "abs": "https://arxiv.org/abs/2505.14685", "authors": ["Nikhil Prakash", "Natalie Shapira", "Arnab Sen Sharma", "Christoph Riedl", "Yonatan Belinkov", "Tamar Rott Shaham", "David Bau", "Atticus Geiger"], "title": "Language Models use Lookbacks to Track Beliefs", "categories": ["cs.CL"], "comment": "32 pages, 32 figures. Code and data at https://belief.baulab.info/", "summary": "How do language models (LMs) represent characters' beliefs, especially when\nthose beliefs may differ from reality? This question lies at the heart of\nunderstanding the Theory of Mind (ToM) capabilities of LMs. We analyze\nLlama-3-70B-Instruct's ability to reason about characters' beliefs using causal\nmediation and abstraction. We construct a dataset that consists of simple\nstories where two characters each separately change the state of two objects,\npotentially unaware of each other's actions. Our investigation uncovered a\npervasive algorithmic pattern that we call a lookback mechanism, which enables\nthe LM to recall important information when it becomes necessary. The LM binds\neach character-object-state triple together by co-locating reference\ninformation about them, represented as their Ordering IDs (OIs) in low rank\nsubspaces of the state token's residual stream. When asked about a character's\nbeliefs regarding the state of an object, the binding lookback retrieves the\ncorresponding state OI and then an answer lookback retrieves the state token.\nWhen we introduce text specifying that one character is (not) visible to the\nother, we find that the LM first generates a visibility ID encoding the\nrelation between the observing and the observed character OIs. In a visibility\nlookback, this ID is used to retrieve information about the observed character\nand update the observing character's beliefs. Our work provides insights into\nthe LM's belief tracking mechanisms, taking a step toward reverse-engineering\nToM reasoning in LMs."}
{"id": "2503.06794", "pdf": "https://arxiv.org/pdf/2503.06794", "abs": "https://arxiv.org/abs/2503.06794", "authors": ["Yizheng Sun", "Hao Li", "Chang Xu", "Hongpeng Zhou", "Chenghua Lin", "Riza Batista-Navarro", "Jingyuan Sun"], "title": "Does Acceleration Cause Hidden Instability in Vision Language Models? Uncovering Instance-Level Divergence Through a Large-Scale Empirical Study", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Vision-Language Models (VLMs) are powerful yet computationally intensive for\nwidespread practical deployments. To address such challenge without costly\nre-training, post-training acceleration techniques like quantization and token\nreduction are extensively explored. However, current acceleration evaluations\nprimarily target minimal overall performance degradation, overlooking a crucial\nquestion: does the accelerated model still give the same answers to the same\nquestions as it did before acceleration? This is vital for stability-centered\nindustrial applications where consistently correct answers for specific, known\nsituations are paramount, such as in AI-based disease diagnosis. We\nsystematically investigate this for accelerated VLMs, testing four leading\nmodels (LLaVA-1.5, LLaVA-Next, Qwen2-VL, Qwen2.5-VL) with eight acceleration\nmethods on ten multi-modal benchmarks. Our findings are stark: despite minimal\naggregate performance drops, accelerated models changed original answers up to\n20% of the time. Critically, up to 6.5% of these changes converted correct\nanswers to incorrect. Input perturbations magnified these inconsistencies, and\nthe trend is confirmed by case studies with the medical VLM LLaVA-Med. This\nresearch reveals a significant oversight in VLM acceleration, stressing an\nurgent need for instance-level stability checks to ensure trustworthy\nreal-world deployment."}
{"id": "2505.14610", "pdf": "https://arxiv.org/pdf/2505.14610", "abs": "https://arxiv.org/abs/2505.14610", "authors": ["Hao Wang", "Chenyu Shi", "Angel E. Rodriguez-Fernandez", "Oliver Sch√ºtze"], "title": "MMD-Newton Method for Multi-objective Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Maximum mean discrepancy (MMD) has been widely employed to measure the\ndistance between probability distributions. In this paper, we propose using MMD\nto solve continuous multi-objective optimization problems (MOPs). For solving\nMOPs, a common approach is to minimize the distance (e.g., Hausdorff) between a\nfinite approximate set of the Pareto front and a reference set. Viewing these\ntwo sets as empirical measures, we propose using MMD to measure the distance\nbetween them. To minimize the MMD value, we provide the analytical expression\nof its gradient and Hessian matrix w.r.t. the search variables, and use them to\ndevise a novel set-oriented, MMD-based Newton (MMDN) method. Also, we analyze\nthe theoretical properties of MMD's gradient and Hessian, including the\nfirst-order stationary condition and the eigenspectrum of the Hessian, which\nare important for verifying the correctness of MMDN. To solve complicated\nproblems, we propose hybridizing MMDN with multiobjective evolutionary\nalgorithms (MOEAs), where we first execute an EA for several iterations to get\nclose to the global Pareto front and then warm-start MMDN with the result of\nthe MOEA to efficiently refine the approximation. We empirically test the\nhybrid algorithm on 11 widely used benchmark problems, and the results show the\nhybrid (MMDN + MOEA) can achieve a much better optimization accuracy than EA\nalone with the same computation budget."}
{"id": "2311.18662", "pdf": "https://arxiv.org/pdf/2311.18662", "abs": "https://arxiv.org/abs/2311.18662", "authors": ["Daniel Fuertes", "Carlos R. del-Blanco", "Fernando Jaureguizar", "Narciso Garc√≠a"], "title": "TOP-Former: A Multi-Agent Transformer Approach for the Team Orienteering Problem", "categories": ["cs.AI"], "comment": null, "summary": "Route planning for a fleet of vehicles is an important task in applications\nsuch as package delivery, surveillance, or transportation, often integrated\nwithin larger Intelligent Transportation Systems (ITS). This problem is\ncommonly formulated as a Vehicle Routing Problem (VRP) known as the Team\nOrienteering Problem (TOP). Existing solvers for this problem primarily rely on\neither linear programming, which provides accurate solutions but requires\ncomputation times that grow with the size of the problem, or heuristic methods,\nwhich typically find suboptimal solutions in a shorter time. In this paper, we\nintroduce TOP-Former, a multi-agent route planning neural network designed to\nefficiently and accurately solve the Team Orienteering Problem. The proposed\nalgorithm is based on a centralized Transformer neural network capable of\nlearning to encode the scenario (modeled as a graph) and analyze the complete\ncontext of all agents to deliver fast, precise, and collaborative solutions.\nUnlike other neural network-based approaches that adopt a more local\nperspective, TOP-Former is trained to understand the global situation of the\nvehicle fleet and generate solutions that maximize long-term expected returns.\nExtensive experiments demonstrate that the presented system outperforms most\nstate-of-the-art methods in terms of both accuracy and computation speed."}
{"id": "2505.13482", "pdf": "https://arxiv.org/pdf/2505.13482", "abs": "https://arxiv.org/abs/2505.13482", "authors": ["Anand Selvadurai", "Jasheen Shaik", "Girish Chandrasekar", "ShriRadhaKrishnan Balamurugan", "Eswara Reddy"], "title": "MedEIR: A Specialized Medical Embedding Model for Enhanced Information Retrieval", "categories": ["cs.IR", "cs.CL"], "comment": "9 pages, 1 figure. This manuscript is a substantial revision of a\n  previously submitted paper. We have explicitly clarified novelty,\n  strengthened scholarly depth, and expanded experimental validation", "summary": "Embedding models have become essential for retrieval-augmented generation\n(RAG) tasks, semantic clustering, and text re-ranking. But despite their\ngrowing use, many of these come with notable limitations. For example, Jina\nfails to capture the semantic content of medical documents, while models such\nas MiniLM often perform poorly on long-form documents. Domain-adapted models,\nwhile specialized, often underperform in general-purpose tasks, reducing their\noverall applicability. General-domain tokenizers often misinterpret medical\nvocabulary. The limitations of current embedding models, whether in\ntokenization accuracy, domain comprehension, or handling long sequences,\nhighlight the need for more versatile solutions. In this work, we present\nMedEIR, a novel embedding model and tokenizer jointly optimized for both\nmedical and general NLP tasks, incorporating ALiBi-based long-context\nprocessing to support sequences of up to 8,192 tokens. MedEIR was pre-trained\non only 6 billion tokens, significantly fewer than Jina's, followed by\nfine-tuning on 3 million sentence pairs. MedEIR consistently outperforms Jina\nV2 and MiniLM across MTEB benchmarks, achieving top scores on ArguAna (55.24),\nNFCorpus (38.44), MedicalQARetrieval (74.25), SciFact (72.04), and TRECCOVID\n(79.56). These results highlight the potential of MedEIR as a highly effective\nembedding model, demonstrating strong performance across both general-purpose\nand domain-specific tasks and outperforming existing models on multiple\nbenchmarks."}
{"id": "2503.06897", "pdf": "https://arxiv.org/pdf/2503.06897", "abs": "https://arxiv.org/abs/2503.06897", "authors": ["Xingzu Zhan", "Chen Xie", "Honghang Chen", "Haoran Sun", "Xiaochun Mai"], "title": "Multi-granular body modeling with Redundancy-Free Spatiotemporal Fusion for Text-Driven Motion Generation", "categories": ["cs.CV"], "comment": "15pages,5figures,", "summary": "Text-to-motion generation sits at the intersection of multimodal learning and\ncomputer graphics and is gaining momentum because it can simplify content\ncreation for games, animation, robotics and virtual reality. Most current\nmethods stack spatial and temporal features in a straightforward way, which\nadds redundancy and still misses subtle joint-level cues. We introduce HiSTF\nMamba, a framework with three parts: Dual-Spatial Mamba, Bi-Temporal Mamba and\na Dynamic Spatiotemporal Fusion Module (DSFM). The Dual-Spatial module runs\npart-based and whole-body models in parallel, capturing both overall\ncoordination and fine-grained joint motion. The Bi-Temporal module scans\nsequences forward and backward to encode short-term details and long-term\ndependencies. DSFM removes redundant temporal information, extracts\ncomplementary cues and fuses them with spatial features to build a richer\nspatiotemporal representation. Experiments on the HumanML3D benchmark show that\nHiSTF Mamba performs well across several metrics, achieving high fidelity and\ntight semantic alignment between text and motion."}
{"id": "2505.14613", "pdf": "https://arxiv.org/pdf/2505.14613", "abs": "https://arxiv.org/abs/2505.14613", "authors": ["Emmanuel Noutahi", "Jason Hartford", "Prudencio Tossou", "Shawn Whitfield", "Alisandra K. Denton", "Cas Wognum", "Kristina Ulicna", "Jonathan Hsu", "Michael Cuccarese", "Emmanuel Bengio", "Dominique Beaini", "Christopher Gibson", "Daniel Cohen", "Berton Earnshaw"], "title": "Virtual Cells: Predict, Explain, Discover", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Drug discovery is fundamentally a process of inferring the effects of\ntreatments on patients, and would therefore benefit immensely from\ncomputational models that can reliably simulate patient responses, enabling\nresearchers to generate and test large numbers of therapeutic hypotheses safely\nand economically before initiating costly clinical trials. Even a more specific\nmodel that predicts the functional response of cells to a wide range of\nperturbations would be tremendously valuable for discovering safe and effective\ntreatments that successfully translate to the clinic. Creating such virtual\ncells has long been a goal of the computational research community that\nunfortunately remains unachieved given the daunting complexity and scale of\ncellular biology. Nevertheless, recent advances in AI, computing power, lab\nautomation, and high-throughput cellular profiling provide new opportunities\nfor reaching this goal. In this perspective, we present a vision for developing\nand evaluating virtual cells that builds on our experience at Recursion. We\nargue that in order to be a useful tool to discover novel biology, virtual\ncells must accurately predict the functional response of a cell to\nperturbations and explain how the predicted response is a consequence of\nmodifications to key biomolecular interactions. We then introduce key\nprinciples for designing therapeutically-relevant virtual cells, describe a\nlab-in-the-loop approach for generating novel insights with them, and advocate\nfor biologically-grounded benchmarks to guide virtual cell development.\nFinally, we make the case that our approach to virtual cells provides a useful\nframework for building other models at higher levels of organization, including\nvirtual patients. We hope that these directions prove useful to the research\ncommunity in developing virtual models optimized for positive impact on drug\ndiscovery outcomes."}
{"id": "2403.01508", "pdf": "https://arxiv.org/pdf/2403.01508", "abs": "https://arxiv.org/abs/2403.01508", "authors": ["Weizhi Fei", "Zihao Wang", "Hang Yin", "Yang Duan", "Yangqiu Song"], "title": "Extending Complex Logical Queries on Uncertain Knowledge Graphs", "categories": ["cs.AI"], "comment": "Accepted by the main conference of ACL 2025", "summary": "The study of machine learning-based logical query answering enables reasoning\nwith large-scale and incomplete knowledge graphs. This paper advances this area\nof research by addressing the uncertainty inherent in knowledge. While the\nuncertain nature of knowledge is widely recognized in the real world, it does\nnot align seamlessly with the first-order logic that underpins existing\nstudies. To bridge this gap, we explore the soft queries on uncertain\nknowledge, inspired by the framework of soft constraint programming. We propose\na neural symbolic approach that incorporates both forward inference and\nbackward calibration to answer soft queries on large-scale, incomplete, and\nuncertain knowledge graphs. Theoretical discussions demonstrate that our method\navoids catastrophic cascading errors in the forward inference while maintaining\nthe same complexity as state-of-the-art symbolic methods for complex logical\nqueries. Empirical results validate the superior performance of our backward\ncalibration compared to extended query embedding methods and neural symbolic\napproaches."}
{"id": "2505.13581", "pdf": "https://arxiv.org/pdf/2505.13581", "abs": "https://arxiv.org/abs/2505.13581", "authors": ["Tommaso Mario Buonocore", "Enea Parimbelli"], "title": "RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection", "categories": ["cs.IR", "cs.CL", "cs.CR", "68M25, 68T07", "I.2.7; K.6.5"], "comment": "7 pages, 4 figures, 2 tables", "summary": "Content moderation for large language models (LLMs) remains a significant\nchallenge, requiring flexible and adaptable solutions that can quickly respond\nto emerging threats. This paper introduces Retrieval Augmented Rejection (RAR),\na novel approach that leverages a retrieval-augmented generation (RAG)\narchitecture to dynamically reject unsafe user queries without model\nretraining. By strategically inserting and marking malicious documents into the\nvector database, the system can identify and reject harmful requests when these\ndocuments are retrieved. Our preliminary results show that RAR achieves\ncomparable performance to embedded moderation in LLMs like Claude 3.5 Sonnet,\nwhile offering superior flexibility and real-time customization capabilities, a\nfundamental feature to timely address critical vulnerabilities. This approach\nintroduces no architectural changes to existing RAG systems, requiring only the\naddition of specially crafted documents and a simple rejection mechanism based\non retrieval results."}
{"id": "2503.07035", "pdf": "https://arxiv.org/pdf/2503.07035", "abs": "https://arxiv.org/abs/2503.07035", "authors": ["Sheng Luo", "Yi Zhou", "Tao Zhou"], "title": "Universal Incremental Learning: Mitigating Confusion from Inter- and Intra-task Distribution Randomness", "categories": ["cs.CV"], "comment": "10 pages, 4 figures, 4 tables", "summary": "Incremental learning (IL) aims to overcome catastrophic forgetting of\nprevious tasks while learning new ones. Existing IL methods make strong\nassumptions that the incoming task type will either only increases new classes\nor domains (i.e. Class IL, Domain IL), or increase by a static scale in a\nclass- and domain-agnostic manner (i.e. Versatile IL (VIL)), which greatly\nlimit their applicability in the unpredictable and dynamic wild. In this work,\nwe investigate $\\textbf{Universal Incremental Learning (UIL)}$, where a model\nneither knows which new classes or domains will increase along sequential\ntasks, nor the scale of the increments within each task. This uncertainty\nprevents the model from confidently learning knowledge from all task\ndistributions and symmetrically focusing on the diverse knowledge within each\ntask distribution. Consequently, UIL presents a more general and realistic IL\nscenario, making the model face confusion arising from inter-task and\nintra-task distribution randomness. To $\\textbf{Mi}$tigate both\n$\\textbf{Co}$nfusion, we propose a simple yet effective framework for UIL,\nnamed $\\textbf{MiCo}$. At the inter-task distribution level, we employ a\nmulti-objective learning scheme to enforce accurate and deterministic\npredictions, and its effectiveness is further enhanced by a direction\nrecalibration module that reduces conflicting gradients. Moreover, at the\nintra-task distribution level, we introduce a magnitude recalibration module to\nalleviate asymmetrical optimization towards imbalanced class distribution.\nExtensive experiments on three benchmarks demonstrate the effectiveness of our\nmethod, outperforming existing state-of-the-art methods in both the UIL\nscenario and the VIL scenario. Our code will be available at\n$\\href{https://github.com/rolsheng/UIL}{here}$."}
{"id": "2505.14620", "pdf": "https://arxiv.org/pdf/2505.14620", "abs": "https://arxiv.org/abs/2505.14620", "authors": ["Morgan Lindsay Heisler", "Linzi Xing", "Ge Shi", "Hanieh Sadri", "Gursimran Singh", "Weiwei Zhang", "Tao Ye", "Ying Xiong", "Yong Zhang", "Zhenan Fan"], "title": "Enhancing Learned Knowledge in LoRA Adapters Through Efficient Contrastive Decoding on Ascend NPUs", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted at ACM KDD 2025", "summary": "Huawei Cloud users leverage LoRA (Low-Rank Adaptation) as an efficient and\nscalable method to fine-tune and customize large language models (LLMs) for\napplication-specific needs. However, tasks that require complex reasoning or\ndeep contextual understanding are often hindered by biases or interference from\nthe base model when using typical decoding methods like greedy or beam search.\nThese biases can lead to generic or task-agnostic responses from the base model\ninstead of leveraging the LoRA-specific adaptations. In this paper, we\nintroduce Contrastive LoRA Decoding (CoLD), a novel decoding framework designed\nto maximize the use of task-specific knowledge in LoRA-adapted models,\nresulting in better downstream performance. CoLD uses contrastive decoding by\nscoring candidate tokens based on the divergence between the probability\ndistributions of a LoRA-adapted expert model and the corresponding base model.\nThis approach prioritizes tokens that better align with the LoRA's learned\nrepresentations, enhancing performance for specialized tasks. While effective,\na naive implementation of CoLD is computationally expensive because each\ndecoding step requires evaluating multiple token candidates across both models.\nTo address this, we developed an optimized kernel for Huawei's Ascend NPU. CoLD\nachieves up to a 5.54% increase in task accuracy while reducing end-to-end\nlatency by 28% compared to greedy decoding. This work provides practical and\nefficient decoding strategies for fine-tuned LLMs in resource-constrained\nenvironments and has broad implications for applied data science in both cloud\nand on-premises settings."}
{"id": "2406.06051", "pdf": "https://arxiv.org/pdf/2406.06051", "abs": "https://arxiv.org/abs/2406.06051", "authors": ["Guanghui Yu", "Robert Kasumba", "Chien-Ju Ho", "William Yeoh"], "title": "On the Utility of Accounting for Human Beliefs about AI Intention in Human-AI Collaboration", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "To enable effective human-AI collaboration, merely optimizing AI performance\nwithout considering human factors is insufficient. Recent research has shown\nthat designing AI agents that take human behavior into account leads to\nimproved performance in human-AI collaboration. However, a limitation of most\nexisting approaches is their assumption that human behavior remains static,\nregardless of the AI agent's actions. In reality, humans may adjust their\nactions based on their beliefs about the AI's intentions, specifically, the\nsubtasks they perceive the AI to be attempting to complete based on its\nbehavior. In this paper, we address this limitation by enabling a collaborative\nAI agent to consider its human partner's beliefs about its intentions, i.e.,\nwhat the human partner thinks the AI agent is trying to accomplish, and to\ndesign its action plan accordingly to facilitate more effective human-AI\ncollaboration. Specifically, we developed a model of human beliefs that\ncaptures how humans interpret and reason about their AI partner's intentions.\nUsing this belief model, we created an AI agent that incorporates both human\nbehavior and human beliefs when devising its strategy for interacting with\nhumans. Through extensive real-world human-subject experiments, we demonstrate\nthat our belief model more accurately captures human perceptions of AI\nintentions. Furthermore, we show that our AI agent, designed to account for\nhuman beliefs over its intentions, significantly enhances performance in\nhuman-AI collaboration."}
{"id": "2505.13652", "pdf": "https://arxiv.org/pdf/2505.13652", "abs": "https://arxiv.org/abs/2505.13652", "authors": ["Karina Zainullina", "Alexander Golubev", "Maria Trofimova", "Sergei Polezhaev", "Ibragim Badertdinov", "Daria Litvintseva", "Simon Karasik", "Filipp Fisin", "Sergei Skvortsov", "Maksim Nekrashevich", "Anton Shevtsov", "Boris Yangel"], "title": "Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents", "categories": ["cs.SE", "cs.CL"], "comment": "ICML", "summary": "Large language models (LLMs) have recently achieved remarkable results in\ncomplex multi-step tasks, such as mathematical reasoning and agentic software\nengineering. However, they often struggle to maintain consistent performance\nacross multiple solution attempts. One effective approach to narrow the gap\nbetween average-case and best-case performance is guided test-time search,\nwhich explores multiple solution paths to identify the most promising one.\nUnfortunately, effective search techniques (e.g. MCTS) are often unsuitable for\nnon-serializable RL environments, such as Docker containers, where intermediate\nenvironment states cannot be easily saved and restored. We investigate two\ncomplementary search strategies applicable to such environments: 1-step\nlookahead and trajectory selection, both guided by a learned action-value\nfunction estimator. On the SWE-bench Verified benchmark, a key testbed for\nagentic software engineering, we find these methods to double the average\nsuccess rate of a fine-tuned Qwen-72B model, achieving 40.8%, the new\nstate-of-the-art for open-weights models. Additionally, we show that these\ntechniques are transferable to more advanced closed models, yielding similar\nimprovements with GPT-4o."}
{"id": "2503.07266", "pdf": "https://arxiv.org/pdf/2503.07266", "abs": "https://arxiv.org/abs/2503.07266", "authors": ["Fu Rong", "Meng Lan", "Qian Zhang", "Lefei Zhang"], "title": "Customized SAM 2 for Referring Remote Sensing Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Referring Remote Sensing Image Segmentation (RRSIS) aims to segment target\nobjects in remote sensing (RS) images based on textual descriptions. Although\nSegment Anything Model 2 (SAM 2) has shown remarkable performance in various\nsegmentation tasks, its application to RRSIS presents several challenges,\nincluding understanding the text-described RS scenes and generating effective\nprompts from text descriptions. To address these issues, we propose RS2-SAM 2,\na novel framework that adapts SAM 2 to RRSIS by aligning the adapted RS\nfeatures and textual features, providing pseudo-mask-based dense prompts, and\nenforcing boundary constraints. Specifically, we first employ a union encoder\nto jointly encode the visual and textual inputs, generating aligned visual and\ntext embeddings as well as multimodal class tokens. Then, we design a\nbidirectional hierarchical fusion module to adapt SAM 2 to RS scenes and align\nadapted visual features with the visually enhanced text embeddings, improving\nthe model's interpretation of text-described RS scenes. Additionally, a mask\nprompt generator is introduced to take the visual embeddings and class tokens\nas input and produce a pseudo-mask as the dense prompt of SAM 2. To further\nrefine segmentation, we introduce a text-guided boundary loss to optimize\nsegmentation boundaries by computing text-weighted gradient differences.\nExperimental results on several RRSIS benchmarks demonstrate that RS2-SAM 2\nachieves state-of-the-art performance."}
{"id": "2505.14635", "pdf": "https://arxiv.org/pdf/2505.14635", "abs": "https://arxiv.org/abs/2505.14635", "authors": ["Benjamin Prada", "Shion Matsumoto", "Abdul Malik Zekri", "Ankur Mali"], "title": "Bridging Predictive Coding and MDL: A Two-Part Code Framework for Deep Learning", "categories": ["cs.LG"], "comment": "24 pages, 2 figures", "summary": "We present the first theoretical framework that connects predictive coding\n(PC), a biologically inspired local learning rule, with the minimum description\nlength (MDL) principle in deep networks. We prove that layerwise PC performs\nblock-coordinate descent on the MDL two-part code objective, thereby jointly\nminimizing empirical risk and model complexity. Using Hoeffding's inequality\nand a prefix-code prior, we derive a novel generalization bound of the form\n$R(\\theta) \\le \\hat{R}(\\theta) + \\frac{L(\\theta)}{N}$, capturing the tradeoff\nbetween fit and compression. We further prove that each PC sweep monotonically\ndecreases the empirical two-part codelength, yielding tighter high-probability\nrisk bounds than unconstrained gradient descent. Finally, we show that repeated\nPC updates converge to a block-coordinate stationary point, providing an\napproximate MDL-optimal solution. To our knowledge, this is the first result\noffering formal generalization and convergence guarantees for PC-trained deep\nmodels, positioning PC as a theoretically grounded and biologically plausible\nalternative to backpropagation."}
{"id": "2406.14449", "pdf": "https://arxiv.org/pdf/2406.14449", "abs": "https://arxiv.org/abs/2406.14449", "authors": ["Can Jin", "Hongwu Peng", "Shiyu Zhao", "Zhenting Wang", "Wujiang Xu", "Ligong Han", "Jiahui Zhao", "Kai Zhong", "Sanguthevar Rajasekaran", "Dimitris N. Metaxas"], "title": "APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have significantly enhanced Information\nRetrieval (IR) across various modules, such as reranking. Despite impressive\nperformance, current zero-shot relevance ranking with LLMs heavily relies on\nhuman prompt engineering. Existing automatic prompt engineering algorithms\nprimarily focus on language modeling and classification tasks, leaving the\ndomain of IR, particularly reranking, underexplored. Directly applying current\nprompt engineering algorithms to relevance ranking is challenging due to the\nintegration of query and long passage pairs in the input, where the ranking\ncomplexity surpasses classification tasks. To reduce human effort and unlock\nthe potential of prompt optimization in reranking, we introduce a novel\nautomatic prompt engineering algorithm named APEER. APEER iteratively generates\nrefined prompts through feedback and preference optimization. Extensive\nexperiments with four LLMs and ten datasets demonstrate the substantial\nperformance improvement of APEER over existing state-of-the-art (SoTA) manual\nprompts. Furthermore, we find that the prompts generated by APEER exhibit\nbetter transferability across diverse tasks and LLMs."}
{"id": "2505.13757", "pdf": "https://arxiv.org/pdf/2505.13757", "abs": "https://arxiv.org/abs/2505.13757", "authors": ["Runchu Tian", "Xueqiang Xu", "Bowen Jin", "SeongKu Kang", "Jiawei Han"], "title": "LLM-Based Compact Reranking with Document Features for Scientific Retrieval", "categories": ["cs.IR", "cs.CL"], "comment": "17 pages, 4 figures", "summary": "Scientific retrieval is essential for advancing academic discovery. Within\nthis process, document reranking plays a critical role by refining first-stage\nretrieval results. However, large language model (LLM) listwise reranking faces\nunique challenges in the scientific domain. First-stage retrieval is often\nsuboptimal in the scientific domain, so relevant documents are ranked lower.\nMoreover, conventional listwise reranking uses the full text of candidate\ndocuments in the context window, limiting the number of candidates that can be\nconsidered. As a result, many relevant documents are excluded before reranking,\nwhich constrains overall retrieval performance. To address these challenges, we\nexplore compact document representations based on semantic features such as\ncategories, sections, and keywords, and propose a training-free, model-agnostic\nreranking framework for scientific retrieval called CoRank. The framework\ninvolves three stages: (i) offline extraction of document-level features, (ii)\ncoarse reranking using these compact representations, and (iii) fine-grained\nreranking on full texts of the top candidates from stage (ii). This hybrid\ndesign provides a high-level abstraction of document semantics, expands\ncandidate coverage, and retains critical details required for precise ranking.\nExperiments on LitSearch and CSFCube show that CoRank significantly improves\nreranking performance across different LLM backbones, increasing nDCG@10 from\n32.0 to 39.7. Overall, these results highlight the value of information\nextraction for reranking in scientific retrieval."}
{"id": "2503.07575", "pdf": "https://arxiv.org/pdf/2503.07575", "abs": "https://arxiv.org/abs/2503.07575", "authors": ["Jen-tse Huang", "Jiantong Qin", "Jianping Zhang", "Youliang Yuan", "Wenxuan Wang", "Jieyu Zhao"], "title": "VisBias: Measuring Explicit and Implicit Social Biases in Vision Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "8 pages of main text; 9 pages of appendix", "summary": "This research investigates both explicit and implicit social biases exhibited\nby Vision-Language Models (VLMs). The key distinction between these bias types\nlies in the level of awareness: explicit bias refers to conscious, intentional\nbiases, while implicit bias operates subconsciously. To analyze explicit bias,\nwe directly pose questions to VLMs related to gender and racial differences:\n(1) Multiple-choice questions based on a given image (e.g., \"What is the\neducation level of the person in the image?\") (2) Yes-No comparisons using two\nimages (e.g., \"Is the person in the first image more educated than the person\nin the second image?\") For implicit bias, we design tasks where VLMs assist\nusers but reveal biases through their responses: (1) Image description tasks:\nModels are asked to describe individuals in images, and we analyze disparities\nin textual cues across demographic groups. (2) Form completion tasks: Models\ndraft a personal information collection form with 20 attributes, and we examine\ncorrelations among selected attributes for potential biases. We evaluate\nGemini-1.5, GPT-4V, GPT-4o, LLaMA-3.2-Vision and LLaVA-v1.6. Our code and data\nare publicly available at https://github.com/uscnlp-lime/VisBias."}
{"id": "2505.14643", "pdf": "https://arxiv.org/pdf/2505.14643", "abs": "https://arxiv.org/abs/2505.14643", "authors": ["Ane G. Domingo-Aldama", "Marcos Merino Prado", "Alain Garc√≠a Olea", "Koldo Gojenola Galletebeitia", "Josu Goikoetxea Salutregi", "Aitziber Atutxa Salazar"], "title": "Early Diagnosis of Atrial Fibrillation Recurrence: A Large Tabular Model Approach with Structured and Unstructured Clinical Data", "categories": ["cs.LG"], "comment": null, "summary": "BACKGROUND: Atrial fibrillation (AF), the most common arrhythmia, is linked\nto high morbidity and mortality. In a fast-evolving AF rhythm control treatment\nera, predicting AF recurrence after its onset may be crucial to achieve the\noptimal therapeutic approach, yet traditional scores like CHADS2-VASc, HATCH,\nand APPLE show limited predictive accuracy. Moreover, early diagnosis studies\noften rely on codified electronic health record (EHR) data, which may contain\nerrors and missing information.\n  OBJECTIVE: This study aims to predict AF recurrence between one month and two\nyears after onset by evaluating traditional clinical scores, ML models, and our\nLTM approach. Moreover, another objective is to develop a methodology for\nintegrating structured and unstructured data to enhance tabular dataset\nquality.\n  METHODS: A tabular dataset was generated by combining structured clinical\ndata with free-text discharge reports processed through natural language\nprocessing techniques, reducing errors and annotation effort. A total of 1,508\npatients with documented AF onset were identified, and models were evaluated on\na manually annotated test set. The proposed approach includes a LTM compared\nagainst traditional clinical scores and ML models.\n  RESULTS: The proposed LTM approach achieved the highest predictive\nperformance, surpassing both traditional clinical scores and ML models.\nAdditionally, the gender and age bias analyses revealed demographic\ndisparities.\n  CONCLUSION: The integration of structured data and free-text sources resulted\nin a high-quality dataset. The findings emphasize the limitations of\ntraditional clinical scores in predicting AF recurrence and highlight the\npotential of ML-based approaches, particularly our LTM model."}
{"id": "2408.17401", "pdf": "https://arxiv.org/pdf/2408.17401", "abs": "https://arxiv.org/abs/2408.17401", "authors": ["Antonio Rago", "Bence Palfi", "Purin Sukpanichnant", "Hannibal Nabli", "Kavyesh Vivek", "Olga Kostopoulou", "James Kinross", "Francesca Toni"], "title": "Exploring the Effect of Explanation Content and Format on User Comprehension and Trust in Healthcare", "categories": ["cs.AI"], "comment": "12 pages", "summary": "AI-driven tools for healthcare are widely acknowledged as potentially\nbeneficial to health practitioners and patients, e.g. the QCancer regression\ntool for cancer risk prediction. However, for these tools to be trusted, they\nneed to be supplemented with explanations. We examine how explanations' content\nand format affect user comprehension and trust when explaining QCancer's\npredictions. Regarding content, we deploy SHAP and Occlusion-1. Regarding\nformat, we present SHAP explanations, conventionally, as charts (SC) and\nOcclusion-1 explanations as charts (OC) as well as text (OT), to which their\nsimpler nature lends itself. We conduct experiments with two sets of\nstakeholders: the general public (representing patients) and medical students\n(representing healthcare practitioners). Our experiments showed higher\nsubjective comprehension and trust for Occlusion-1 over SHAP explanations based\non content. However, when controlling for format, only OT outperformed SC,\nsuggesting this trend is driven by preferences for text. Other findings\ncorroborated that explanation format, rather than content, is often the\ncritical factor."}
{"id": "2505.13862", "pdf": "https://arxiv.org/pdf/2505.13862", "abs": "https://arxiv.org/abs/2505.13862", "authors": ["Guobin Shen", "Dongcheng Zhao", "Linghao Feng", "Xiang He", "Jihang Wang", "Sicheng Shen", "Haibo Tong", "Yiting Dong", "Jindong Li", "Xiang Zheng", "Yi Zeng"], "title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable capabilities but remain\nvulnerable to adversarial prompts known as jailbreaks, which can bypass safety\nalignment and elicit harmful outputs. Despite growing efforts in LLM safety\nresearch, existing evaluations are often fragmented, focused on isolated attack\nor defense techniques, and lack systematic, reproducible analysis. In this\nwork, we introduce PandaGuard, a unified and modular framework that models LLM\njailbreak safety as a multi-agent system comprising attackers, defenders, and\njudges. Our framework implements 19 attack methods and 12 defense mechanisms,\nalong with multiple judgment strategies, all within a flexible plugin\narchitecture supporting diverse LLM interfaces, multiple interaction modes, and\nconfiguration-driven experimentation that enhances reproducibility and\npractical deployment. Built on this framework, we develop PandaBench, a\ncomprehensive benchmark that evaluates the interactions between these\nattack/defense methods across 49 LLMs and various judgment approaches,\nrequiring over 3 billion tokens to execute. Our extensive evaluation reveals\nkey insights into model vulnerabilities, defense cost-performance trade-offs,\nand judge consistency. We find that no single defense is optimal across all\ndimensions and that judge disagreement introduces nontrivial variance in safety\nassessments. We release the code, configurations, and evaluation results to\nsupport transparent and reproducible research in LLM safety."}
{"id": "2503.11094", "pdf": "https://arxiv.org/pdf/2503.11094", "abs": "https://arxiv.org/abs/2503.11094", "authors": ["Weichen Zhang", "Zile Zhou", "Zhiheng Zheng", "Chen Gao", "Jinqiang Cui", "Yong Li", "Xinlei Chen", "Xiao-Ping Zhang"], "title": "Open3DVQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space", "categories": ["cs.CV"], "comment": null, "summary": "Spatial reasoning is a fundamental capability of embodied agents and has\ngarnered widespread attention in the field of multimodal large language models\n(MLLMs). In this work, we propose a novel benchmark, Open3DVQA, to\ncomprehensively evaluate the spatial reasoning capacities of current\nstate-of-the-art (SOTA) foundation models in open 3D space. Open3DVQA consists\nof 9k VQA samples, collected using an efficient semi-automated tool in a\nhigh-fidelity urban simulator. We evaluate several SOTA MLLMs across various\naspects of spatial reasoning, such as relative and absolute spatial\nrelationships, situational reasoning, and object-centric spatial attributes.\nOur results reveal that: 1) MLLMs perform better at answering questions\nregarding relative spatial relationships than absolute spatial relationships,\n2) MLLMs demonstrate similar spatial reasoning abilities for both egocentric\nand allocentric perspectives, and 3) Fine-tuning large models significantly\nimproves their performance across different spatial reasoning tasks. We believe\nthat our open-source data collection tools and in-depth analyses will inspire\nfurther research on MLLM spatial reasoning capabilities. The benchmark is\navailable at https://github.com/WeichenZh/Open3DVQA."}
{"id": "2505.14669", "pdf": "https://arxiv.org/pdf/2505.14669", "abs": "https://arxiv.org/abs/2505.14669", "authors": ["Roberto L. Castro", "Andrei Panferov", "Soroush Tabesh", "Oliver Sieberling", "Jiale Chen", "Mahdi Nikdan", "Saleh Ashkboos", "Dan Alistarh"], "title": "Quartet: Native FP4 Training Can Be Optimal for Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has been paralleled by\nunprecedented increases in computational demands, with training costs for\nstate-of-the-art models doubling every few months. Training models directly in\nlow-precision arithmetic offers a solution, by improving both computational\nthroughput and energy efficiency. Specifically, NVIDIA's recent Blackwell\narchitecture facilitates extremely low-precision operations, specifically FP4\nvariants, promising substantial efficiency gains. Yet, current algorithms for\ntraining LLMs in FP4 precision face significant accuracy degradation and often\nrely on mixed-precision fallbacks. In this paper, we systematically investigate\nhardware-supported FP4 training and introduce Quartet, a new approach enabling\naccurate, end-to-end FP4 training with all the major computations (in e.g.\nlinear layers) being performed in low precision. Through extensive evaluations\non Llama-type models, we reveal a new low-precision scaling law that quantifies\nperformance trade-offs across varying bit-widths and allows us to identify a\n\"near-optimal\" low-precision training technique in terms of\naccuracy-vs-computation, called Quartet. We implement Quartet using optimized\nCUDA kernels tailored for NVIDIA Blackwell GPUs, and show that it can achieve\nstate-of-the-art accuracy for FP4 precision, successfully training\nbillion-scale models. Our method demonstrates that fully FP4-based training is\na competitive alternative to standard-precision and FP8 training. Our code is\navailable at https://github.com/IST-DASLab/Quartet."}
{"id": "2409.17994", "pdf": "https://arxiv.org/pdf/2409.17994", "abs": "https://arxiv.org/abs/2409.17994", "authors": ["Sawinder Kaur", "Avery Gump", "Yi Xiao", "Jingyu Xin", "Harshit Sharma", "Nina R Benway", "Jonathan L Preston", "Asif Salekin"], "title": "CRoP: Context-wise Robust Static Human-Sensing Personalization", "categories": ["cs.AI"], "comment": "34 pages, 6 figues and 15 tables", "summary": "The advancement in deep learning and internet-of-things have led to diverse\nhuman sensing applications. However, distinct patterns in human sensing,\ninfluenced by various factors or contexts, challenge the generic neural network\nmodel's performance due to natural distribution shifts. To address this,\npersonalization tailors models to individual users. Yet most personalization\nstudies overlook intra-user heterogeneity across contexts in sensory data,\nlimiting intra-user generalizability. This limitation is especially critical in\nclinical applications, where limited data availability hampers both\ngeneralizability and personalization. Notably, intra-user sensing attributes\nare expected to change due to external factors such as treatment progression,\nfurther complicating the challenges. To address the intra-user generalization\nchallenge, this work introduces CRoP, a novel static personalization approach.\nCRoP leverages off-the-shelf pre-trained models as generic starting points and\ncaptures user-specific traits through adaptive pruning on a minimal sub-network\nwhile allowing generic knowledge to be incorporated in remaining parameters.\nCRoP demonstrates superior personalization effectiveness and intra-user\nrobustness across four human-sensing datasets, including two from real-world\nhealth domains, underscoring its practical and social impact. Additionally, to\nsupport CRoP's generalization ability and design choices, we provide empirical\njustification through gradient inner product analysis, ablation studies, and\ncomparisons against state-of-the-art baselines."}
{"id": "2505.13957", "pdf": "https://arxiv.org/pdf/2505.13957", "abs": "https://arxiv.org/abs/2505.13957", "authors": ["Jiankun Zhang", "Shenglai Zeng", "Jie Ren", "Tianqi Zheng", "Hui Liu", "Xianfeng Tang", "Hui Liu", "Yi Chang"], "title": "Beyond Text: Unveiling Privacy Vulnerabilities in Multi-modal Retrieval-Augmented Generation", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Multimodal Retrieval-Augmented Generation (MRAG) systems enhance LMMs by\nintegrating external multimodal databases, but introduce unexplored privacy\nvulnerabilities. While text-based RAG privacy risks have been studied,\nmultimodal data presents unique challenges. We provide the first systematic\nanalysis of MRAG privacy vulnerabilities across vision-language and\nspeech-language modalities. Using a novel compositional structured prompt\nattack in a black-box setting, we demonstrate how attackers can extract private\ninformation by manipulating queries. Our experiments reveal that LMMs can both\ndirectly generate outputs resembling retrieved content and produce descriptions\nthat indirectly expose sensitive information, highlighting the urgent need for\nrobust privacy-preserving MRAG techniques."}
{"id": "2503.13794", "pdf": "https://arxiv.org/pdf/2503.13794", "abs": "https://arxiv.org/abs/2503.13794", "authors": ["Yang Zhou", "Shiyu Zhao", "Yuxiao Chen", "Zhenting Wang", "Can Jin", "Dimitris N. Metaxas"], "title": "LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large foundation models trained on large-scale vision-language data can boost\nOpen-Vocabulary Object Detection (OVD) via synthetic training data, yet the\nhand-crafted pipelines often introduce bias and overfit to specific prompts. We\nsidestep this issue by directly fusing hidden states from Large Language Models\n(LLMs) into detectors-an avenue surprisingly under-explored. This paper\npresents a systematic method to enhance visual grounding by utilizing decoder\nlayers of the LLM of an MLLM. We introduce a zero-initialized cross-attention\nadapter to enable efficient knowledge fusion from LLMs to object detectors, a\nnew approach called LED (LLM Enhanced Open-Vocabulary Object Detection). We\nfind that intermediate LLM layers already encode rich spatial semantics;\nadapting only the early layers yields most of the gain. With Swin-T as the\nvision encoder, Qwen2-0.5B + LED lifts GroundingDINO by 3.82 % on OmniLabel at\njust 8.7 % extra GFLOPs, and a larger vision backbone pushes the improvement to\n6.22 %. Extensive ablations on adapter variants, LLM scales and fusion depths\nfurther corroborate our design."}
{"id": "2412.12504", "pdf": "https://arxiv.org/pdf/2412.12504", "abs": "https://arxiv.org/abs/2412.12504", "authors": ["Hong Liu", "Saisai Gong", "Yixin Ji", "Kaixin Wu", "Jia Xu", "Jinjie Gu"], "title": "Boosting LLM-based Relevance Modeling with Distribution-Aware Robust Learning", "categories": ["cs.IR", "cs.LG", "H.3.3"], "comment": "8 pages", "summary": "With the rapid advancement of pre-trained large language models (LLMs),\nrecent endeavors have leveraged the capabilities of LLMs in relevance modeling,\nresulting in enhanced performance. This is usually done through the process of\nfine-tuning LLMs on specifically annotated datasets to determine the relevance\nbetween queries and items. However, there are two limitations when LLMs are\nnaively employed for relevance modeling through fine-tuning and inference.\nFirst, it is not inherently efficient for performing nuanced tasks beyond\nsimple yes or no answers, such as assessing search relevance. It may therefore\ntend to be overconfident and struggle to distinguish fine-grained degrees of\nrelevance (e.g., strong relevance, weak relevance, irrelevance) used in search\nengines. Second, it exhibits significant performance degradation when\nconfronted with data distribution shift in real-world scenarios. In this paper,\nwe propose a novel Distribution-Aware Robust Learning framework (DaRL) for\nrelevance modeling in Alipay Search. Specifically, we design an effective loss\nfunction to enhance the discriminability of LLM-based relevance modeling across\nvarious fine-grained degrees of query-item relevance. To improve the\ngeneralizability of LLM-based relevance modeling, we first propose the\nDistribution-Aware Sample Augmentation (DASA) module. This module utilizes\nout-of-distribution (OOD) detection techniques to actively select appropriate\nsamples that are not well covered by the original training set for model\nfine-tuning. Furthermore, we adopt a multi-stage fine-tuning strategy to\nsimultaneously improve in-distribution (ID) and OOD performance, bridging the\nperformance gap between them. DaRL has been deployed online to serve the\nAlipay's insurance product search..."}
{"id": "2410.02429", "pdf": "https://arxiv.org/pdf/2410.02429", "abs": "https://arxiv.org/abs/2410.02429", "authors": ["Tuo An", "Yunjiao Zhou", "Han Zou", "Jianfei Yang"], "title": "IoT-LLM: Enhancing Real-World IoT Task Reasoning with Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "21 pages, 11 figures, under review", "summary": "Large Language Models (LLMs) excel in textual and visual tasks but often\nproduce outputs that defy physical laws when dealing with physical-world\nreasoning tasks. Inspired by human cognition, where perception is fundamental\nto reasoning, we explore augmenting LLMs with enhanced perception abilities\nusing Internet of Things (IoT) sensor data and pertinent knowledge for\nIoT-sensory task reasoning in the physical world. In this work, we\nsystematically study LLMs' capability to address real-world IoT-sensory tasks\nby augmenting their perception and knowledge base, and then propose a unified\nframework, IoT-LLM, to enhance such capability. In IoT-LLM, we customize three\nsteps for LLMs: preprocessing IoT data into formats amenable to LLMs, expanding\ntheir understanding via IoT-oriented retrieval-augmented generation based on\nin-context learning and activating their commonsense knowledge through\nchain-of-thought prompting and specialized role definitions. We design a new\nbenchmark comprising five real-world tasks with varying data types and\nreasoning complexities to evaluate the performance of IoT-LLM. Experimental\nresults on six LLMs reveal that IoT-LLM significantly improves the performance\nof IoT-sensory task reasoning of LLMs, with models like GPT-4o-mini showing a\n49.4% average improvement over previous methods."}
{"id": "2503.14232", "pdf": "https://arxiv.org/pdf/2503.14232", "abs": "https://arxiv.org/abs/2503.14232", "authors": ["Yuyang Xue", "Edward Moroshko", "Feng Chen", "Jingyu Sun", "Steven McDonagh", "Sotirios A. Tsaftaris"], "title": "CRCE: Coreference-Retention Concept Erasure in Text-to-Image Diffusion Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Text-to-Image diffusion models can produce undesirable content that\nnecessitates concept erasure. However, existing methods struggle with\nunder-erasure, leaving residual traces of targeted concepts, or over-erasure,\nmistakenly eliminating unrelated but visually similar concepts. To address\nthese limitations, we introduce CRCE, a novel concept erasure framework that\nleverages Large Language Models to identify both semantically related concepts\nthat should be erased alongside the target and distinct concepts that should be\npreserved. By explicitly modelling coreferential and retained concepts\nsemantically, CRCE enables more precise concept removal, without unintended\nerasure. Experiments demonstrate that CRCE outperforms existing methods on\ndiverse erasure tasks, including real-world object, person identities, and\nabstract intellectual property characteristics. The constructed dataset\nCorefConcept and the source code will be release upon acceptance."}
{"id": "2505.13479", "pdf": "https://arxiv.org/pdf/2505.13479", "abs": "https://arxiv.org/abs/2505.13479", "authors": ["Mohammad Akyash", "Kimia Azar", "Hadi Kamali"], "title": "RTL++: Graph-enhanced LLM for RTL Code Generation", "categories": ["cs.PL", "cs.AR", "cs.LG"], "comment": "Accepted to the IEEE International Conference on LLM-Aided Design\n  (LAD '25)", "summary": "As hardware design complexity escalates, there is an urgent need for advanced\nautomation in electronic design automation (EDA). Traditional register transfer\nlevel (RTL) design methods are manual, time-consuming, and prone to errors.\nWhile commercial (instruction-tuned) large language models (LLMs) shows\npromising performance for automation, they pose security and privacy concerns.\nOpen-source models offer alternatives; however, they frequently fall short in\nquality/correctness, largely due to limited, high-quality RTL code data\nessential for effective training and generalization. This paper proposes RTL++,\na first-of-its-kind LLM-assisted method for RTL code generation that utilizes\ngraph representations of code structures to enhance the quality of generated\ncode. By encoding RTL code into a textualized control flowgraphs (CFG) and data\nflow graphs (DFG), RTL++ captures the inherent hierarchy, dependencies, and\nrelationships within the code. This structured graph-based approach enhances\nthe context available to LLMs, enabling them to better understand and generate\ninstructions. By focusing on data generation through graph representations,\nRTL++ addresses the limitations of previous approaches that rely solely on code\nand suffer from lack of diversity. Experimental results demonstrate that RTL++\noutperforms state-of-the-art models fine-tuned for RTL generation, as evaluated\nusing the VerilogEval benchmark's Pass@1/5/10 metric, as well as the RTLLM1.1\nmodel, which highlight the effectiveness of graph-enhanced context in advancing\nthe capabilities of LLM-assisted RTL code generation."}
{"id": "2410.09083", "pdf": "https://arxiv.org/pdf/2410.09083", "abs": "https://arxiv.org/abs/2410.09083", "authors": ["Lu Chen", "Yuxuan Huang", "Yixing Li", "Dongrui Liu", "Qihan Ren", "Shuai Zhao", "Kun Kuang", "Zilong Zheng", "Quanshi Zhang"], "title": "Evaluating the Correctness of Inference Patterns Used by LLMs for Judgment", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper presents a method to analyze the inference patterns used by Large\nLanguage Models (LLMs) for judgment in a case study on legal LLMs, so as to\nidentify potential incorrect representations of the LLM, according to human\ndomain knowledge. Unlike traditional evaluations on language generation\nresults, we propose to evaluate the correctness of the detailed inference\npatterns of an LLM behind its seemingly correct outputs. To this end, we\nquantify the interactions between input phrases used by the LLM as primitive\ninference patterns, because recent theoretical achievements have proven several\nmathematical guarantees of the faithfulness of the interaction-based\nexplanation. We design a set of metrics to evaluate the detailed inference\npatterns of LLMs. Experiments show that even when the language generation\nresults appear correct, a significant portion of the inference patterns used by\nthe LLM for the legal judgment may represent misleading or irrelevant logic."}
{"id": "2505.14368", "pdf": "https://arxiv.org/pdf/2505.14368", "abs": "https://arxiv.org/abs/2505.14368", "authors": ["Jiawen Wang", "Pritha Gupta", "Ivan Habernal", "Eyke H√ºllermeier"], "title": "Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs", "categories": ["cs.CR", "cs.CL"], "comment": "8 pages, 3 figures, EMNLP 2025 under review", "summary": "Recent studies demonstrate that Large Language Models (LLMs) are vulnerable\nto different prompt-based attacks, generating harmful content or sensitive\ninformation. Both closed-source and open-source LLMs are underinvestigated for\nthese attacks. This paper studies effective prompt injection attacks against\nthe $\\mathbf{14}$ most popular open-source LLMs on five attack benchmarks.\nCurrent metrics only consider successful attacks, whereas our proposed Attack\nSuccess Probability (ASP) also captures uncertainty in the model's response,\nreflecting ambiguity in attack feasibility. By comprehensively analyzing the\neffectiveness of prompt injection attacks, we propose a simple and effective\nhypnotism attack; results show that this attack causes aligned language models,\nincluding Stablelm2, Mistral, Openchat, and Vicuna, to generate objectionable\nbehaviors, achieving around $90$% ASP. They also indicate that our ignore\nprefix attacks can break all $\\mathbf{14}$ open-source LLMs, achieving over\n$60$% ASP on a multi-categorical dataset. We find that moderately well-known\nLLMs exhibit higher vulnerability to prompt injection attacks, highlighting the\nneed to raise public awareness and prioritize efficient mitigation strategies."}
{"id": "2503.15060", "pdf": "https://arxiv.org/pdf/2503.15060", "abs": "https://arxiv.org/abs/2503.15060", "authors": ["Imanol G. Estepa", "Jes√∫s M. Rodr√≠guez-de-Vera", "Ignacio Saras√∫a", "Bhalaji Nagarajan", "Petia Radeva"], "title": "Conjuring Positive Pairs for Efficient Unification of Representation Learning and Image Synthesis", "categories": ["cs.CV", "cs.AI", "I.5.4; I.5.1; I.2.10"], "comment": "The source code is available in https://github.com/ImaGonEs/Sorcen", "summary": "While representation learning and generative modeling seek to understand\nvisual data, unifying both domains remains unexplored. Recent Unified\nSelf-Supervised Learning (SSL) methods have started to bridge the gap between\nboth paradigms. However, they rely solely on semantic token reconstruction,\nwhich requires an external tokenizer during training -- introducing a\nsignificant overhead. In this work, we introduce Sorcen, a novel unified SSL\nframework, incorporating a synergic Contrastive-Reconstruction objective. Our\nContrastive objective, \"Echo Contrast\", leverages the generative capabilities\nof Sorcen, eliminating the need for additional image crops or augmentations\nduring training. Sorcen \"generates\" an echo sample in the semantic token space,\nforming the contrastive positive pair. Sorcen operates exclusively on\nprecomputed tokens, eliminating the need for an online token transformation\nduring training, thereby significantly reducing computational overhead.\nExtensive experiments on ImageNet-1k demonstrate that Sorcen outperforms the\nprevious Unified SSL SoTA by 0.4%, 1.48 FID, 1.76%, and 1.53% on linear\nprobing, unconditional image generation, few-shot learning, and transfer\nlearning, respectively, while being 60.8% more efficient. Additionally, Sorcen\nsurpasses previous single-crop MIM SoTA in linear probing and achieves SoTA\nperformance in unconditional image generation, highlighting significant\nimprovements and breakthroughs in Unified SSL models."}
{"id": "2505.13494", "pdf": "https://arxiv.org/pdf/2505.13494", "abs": "https://arxiv.org/abs/2505.13494", "authors": ["Ying Zhao", "Guanhua Chen", "Jie Liu"], "title": "Polymer Data Challenges in the AI Era: Bridging Gaps for Next-Generation Energy Materials", "categories": ["cond-mat.soft", "cond-mat.mtrl-sci", "cs.LG"], "comment": "45 pages, 0 figures", "summary": "The pursuit of advanced polymers for energy technologies, spanning\nphotovoltaics, solid-state batteries, and hydrogen storage, is hindered by\nfragmented data ecosystems that fail to capture the hierarchical complexity of\nthese materials. Polymer science lacks interoperable databases, forcing\nreliance on disconnected literature and legacy records riddled with\nunstructured formats and irreproducible testing protocols. This fragmentation\nstifles machine learning (ML) applications and delays the discovery of\nmaterials critical for global decarbonization. Three systemic barriers compound\nthe challenge. First, academic-industrial data silos restrict access to\nproprietary industrial datasets, while academic publications often omit\ncritical synthesis details. Second, inconsistent testing methods undermine\ncross-study comparability. Third, incomplete metadata in existing databases\nlimits their utility for training reliable ML models. Emerging solutions\naddress these gaps through technological and collaborative innovation. Natural\nlanguage processing (NLP) tools extract structured polymer data from decades of\nliterature, while high-throughput robotic platforms generate self-consistent\ndatasets via autonomous experimentation. Central to these advances is the\nadoption of FAIR (Findable, Accessible, Interoperable, Reusable) principles,\nadapted to polymer-specific ontologies, ensuring machine-readability and\nreproducibility. Future breakthroughs hinge on cultural shifts toward open\nscience, accelerated by decentralized data markets and autonomous laboratories\nthat merge robotic experimentation with real-time ML validation. By addressing\ndata fragmentation through technological innovation, collaborative governance,\nand ethical stewardship, the polymer community can transform bottlenecks into\naccelerants."}
{"id": "2412.02508", "pdf": "https://arxiv.org/pdf/2412.02508", "abs": "https://arxiv.org/abs/2412.02508", "authors": ["Haidong Xu", "Meishan Zhang", "Hao Ju", "Zhedong Zheng", "Erik Cambria", "Min Zhang", "Hao Fei"], "title": "Towards Rich Emotions in 3D Avatars: A Text-to-3D Avatar Generation Benchmark", "categories": ["cs.AI", "cs.CV"], "comment": "19 pages. Project website: https://github.com/WalkerMitty/EmoAva", "summary": "Producing emotionally dynamic 3D facial avatars with text derived from spoken\nwords (Emo3D) has been a pivotal research topic in 3D avatar generation. While\nprogress has been made in general-purpose 3D avatar generation, the exploration\nof generating emotional 3D avatars remains scarce, primarily due to the\ncomplexities of identifying and rendering rich emotions from spoken words. This\npaper reexamines Emo3D generation and draws inspiration from human processes,\nbreaking down Emo3D into two cascading steps: Text-to-3D Expression Mapping\n(T3DEM) and 3D Avatar Rendering (3DAR). T3DEM is the most crucial step in\ndetermining the quality of Emo3D generation and encompasses three key\nchallenges: Expression Diversity, Emotion-Content Consistency, and Expression\nFluidity. To address these challenges, we introduce a novel benchmark to\nadvance research in Emo3D generation. First, we present EmoAva, a large-scale,\nhigh-quality dataset for T3DEM, comprising 15,000 text-to-3D expression\nmappings that characterize the aforementioned three challenges in Emo3D\ngeneration. Furthermore, we develop various metrics to effectively evaluate\nmodels against these identified challenges. Next, to effectively model the\nconsistency, diversity, and fluidity of human expressions in the T3DEM step, we\npropose the Continuous Text-to-Expression Generator, which employs an\nautoregressive Conditional Variational Autoencoder for expression code\ngeneration, enhanced with Latent Temporal Attention and Expression-wise\nAttention mechanisms. Finally, to further enhance the 3DAR step on rendering\nhigher-quality subtle expressions, we present the Globally-informed Gaussian\nAvatar (GiGA) model. GiGA incorporates a global information mechanism into 3D\nGaussian representations, enabling the capture of subtle micro-expressions and\nseamless transitions between emotional states."}
{"id": "2505.14402", "pdf": "https://arxiv.org/pdf/2505.14402", "abs": "https://arxiv.org/abs/2505.14402", "authors": ["Heng Yang", "Jack Cole", "Yuan Li", "Renzhi Chen", "Geyong Min", "Ke Li"], "title": "OmniGenBench: A Modular Platform for Reproducible Genomic Foundation Models Benchmarking", "categories": ["q-bio.GN", "cs.CL"], "comment": null, "summary": "The code of nature, embedded in DNA and RNA genomes since the origin of life,\nholds immense potential to impact both humans and ecosystems through genome\nmodeling. Genomic Foundation Models (GFMs) have emerged as a transformative\napproach to decoding the genome. As GFMs scale up and reshape the landscape of\nAI-driven genomics, the field faces an urgent need for rigorous and\nreproducible evaluation. We present OmniGenBench, a modular benchmarking\nplatform designed to unify the data, model, benchmarking, and interpretability\nlayers across GFMs. OmniGenBench enables standardized, one-command evaluation\nof any GFM across five benchmark suites, with seamless integration of over 31\nopen-source models. Through automated pipelines and community-extensible\nfeatures, the platform addresses critical reproducibility challenges, including\ndata transparency, model interoperability, benchmark fragmentation, and\nblack-box interpretability. OmniGenBench aims to serve as foundational\ninfrastructure for reproducible genomic AI research, accelerating trustworthy\ndiscovery and collaborative innovation in the era of genome-scale modeling."}
{"id": "2503.16282", "pdf": "https://arxiv.org/pdf/2503.16282", "abs": "https://arxiv.org/abs/2503.16282", "authors": ["Zhaochong An", "Guolei Sun", "Yun Liu", "Runjia Li", "Junlin Han", "Ender Konukoglu", "Serge Belongie"], "title": "Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "Generalized few-shot 3D point cloud segmentation (GFS-PCS) adapts models to\nnew classes with few support samples while retaining base class segmentation.\nExisting GFS-PCS methods enhance prototypes via interacting with support or\nquery features but remain limited by sparse knowledge from few-shot samples.\nMeanwhile, 3D vision-language models (3D VLMs), generalizing across open-world\nnovel classes, contain rich but noisy novel class knowledge. In this work, we\nintroduce a GFS-PCS framework that synergizes dense but noisy pseudo-labels\nfrom 3D VLMs with precise yet sparse few-shot samples to maximize the strengths\nof both, named GFS-VL. Specifically, we present a prototype-guided pseudo-label\nselection to filter low-quality regions, followed by an adaptive infilling\nstrategy that combines knowledge from pseudo-label contexts and few-shot\nsamples to adaptively label the filtered, unlabeled areas. Additionally, we\ndesign a novel-base mix strategy to embed few-shot samples into training\nscenes, preserving essential context for improved novel class learning.\nMoreover, recognizing the limited diversity in current GFS-PCS benchmarks, we\nintroduce two challenging benchmarks with diverse novel classes for\ncomprehensive generalization evaluation. Experiments validate the effectiveness\nof our framework across models and datasets. Our approach and benchmarks\nprovide a solid foundation for advancing GFS-PCS in the real world. The code is\nat https://github.com/ZhaochongAn/GFS-VL"}
{"id": "2505.13509", "pdf": "https://arxiv.org/pdf/2505.13509", "abs": "https://arxiv.org/abs/2505.13509", "authors": ["Catherine Stinson"], "title": "Fuck the Algorithm: Conceptual Issues in Algorithmic Bias", "categories": ["cs.CY", "cs.LG"], "comment": null, "summary": "Algorithmic bias has been the subject of much recent controversy. To clarify\nwhat is at stake and to make progress resolving the controversy, a better\nunderstanding of the concepts involved would be helpful. The discussion here\nfocuses on the disputed claim that algorithms themselves cannot be biased. To\nclarify this claim we need to know what kind of thing 'algorithms themselves'\nare, and to disambiguate the several meanings of 'bias' at play. This further\ninvolves showing how bias of moral import can result from statistical biases,\nand drawing connections to previous conceptual work about political artifacts\nand oppressive things. Data bias has been identified in domains like hiring,\npolicing and medicine. Examples where algorithms themselves have been\npinpointed as the locus of bias include recommender systems that influence\nmedia consumption, academic search engines that influence citation patterns,\nand the 2020 UK algorithmically-moderated A-level grades. Recognition that\nalgorithms are a kind of thing that can be biased is key to making decisions\nabout responsibility for harm, and preventing algorithmically mediated\ndiscrimination."}
{"id": "2412.06559", "pdf": "https://arxiv.org/pdf/2412.06559", "abs": "https://arxiv.org/abs/2412.06559", "authors": ["Chujie Zheng", "Zhenru Zhang", "Beichen Zhang", "Runji Lin", "Keming Lu", "Bowen Yu", "Dayiheng Liu", "Jingren Zhou", "Junyang Lin"], "title": "ProcessBench: Identifying Process Errors in Mathematical Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "ACL 2025", "summary": "As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models."}
{"id": "2505.14432", "pdf": "https://arxiv.org/pdf/2505.14432", "abs": "https://arxiv.org/abs/2505.14432", "authors": ["Eugene Yang", "Andrew Yates", "Kathryn Ricci", "Orion Weller", "Vivek Chari", "Benjamin Van Durme", "Dawn Lawrie"], "title": "Rank-K: Test-Time Reasoning for Listwise Reranking", "categories": ["cs.IR", "cs.CL"], "comment": "15 pages, 4 figures", "summary": "Retrieve-and-rerank is a popular retrieval pipeline because of its ability to\nmake slow but effective rerankers efficient enough at query time by reducing\nthe number of comparisons. Recent works in neural rerankers take advantage of\nlarge language models for their capability in reasoning between queries and\npassages and have achieved state-of-the-art retrieval effectiveness. However,\nsuch rerankers are resource-intensive, even after heavy optimization. In this\nwork, we introduce Rank-K, a listwise passage reranking model that leverages\nthe reasoning capability of the reasoning language model at query time that\nprovides test time scalability to serve hard queries. We show that Rank-K\nimproves retrieval effectiveness by 23\\% over the RankZephyr, the\nstate-of-the-art listwise reranker, when reranking a BM25 initial ranked list\nand 19\\% when reranking strong retrieval results by SPLADE-v3. Since Rank-K is\ninherently a multilingual model, we found that it ranks passages based on\nqueries in different languages as effectively as it does in monolingual\nretrieval."}
{"id": "2503.18339", "pdf": "https://arxiv.org/pdf/2503.18339", "abs": "https://arxiv.org/abs/2503.18339", "authors": ["Inpyo Hong", "Youngwan Jo", "Hyojeong Lee", "Sunghyun Ahn", "Sanghyun Park"], "title": "GranQ: Granular Zero-Shot Quantization with Channel-Wise Activation Scaling in QAT", "categories": ["cs.CV"], "comment": null, "summary": "Zero-shot quantization (ZSQ) enables neural network compression without\noriginal training data, making it a promising solution for restricted data\naccess scenarios. To compensate for the lack of data, recent ZSQ methods\ntypically rely on synthetic inputs generated from the full-precision model.\nHowever, these synthetic inputs often lead to activation distortion, especially\nunder low-bit settings. As a result, existing methods struggle to mitigate this\nissue due to coarse activation scaling. To address this issue, we propose\nGranQ, a novel activation quantization framework that efficiently applies\nper-channel scaling through vectorized computation. In contrast to conventional\nchannel-wise methods, which apply vectorization only to the quantization step,\nGranQ improves efficiency by vectorizing the scaling operation. This design\nallows GranQ to maintain fine-grained quantization granularity with minimal\ncomputational overhead, even in low-bit environments. Extensive experiments\nunder quantization-aware training (QAT) settings demonstrate that GranQ\nconsistently outperforms state-of-the-art ZSQ methods across CIFAR and\nImageNet. In particular, our method achieves up to 5.45% higher accuracy in the\n3-bit setting on CIFAR-100 and even surpasses the full-precision baseline on\nCIFAR-10. Furthermore, GranQ achieves significant speedup in quantization\nlatency over conventional per-channel methods, demonstrating improved\nefficiency. With these findings, we anticipate that GranQ will inspire future\nresearch beyond conventional ZSQ approaches centered on data generation and\nmodel fine-tuning."}
{"id": "2501.09632", "pdf": "https://arxiv.org/pdf/2501.09632", "abs": "https://arxiv.org/abs/2501.09632", "authors": ["Stefan Panjkovic", "Alessandro Cimatti", "Andrea Micheli", "Stefano Tonetta"], "title": "Platform-Aware Mission Planning", "categories": ["cs.AI"], "comment": null, "summary": "Planning for autonomous systems typically requires reasoning with models at\ndifferent levels of abstraction, and the harmonization of two competing sets of\nobjectives: high-level mission goals that refer to an interaction of the system\nwith the external environment, and low-level platform constraints that aim to\npreserve the integrity and the correct interaction of the subsystems. The\ncomplicated interplay between these two models makes it very hard to reason on\nthe system as a whole, especially when the objective is to find plans with\nrobustness guarantees, considering the non-deterministic behavior of the lower\nlayers of the system.\n  In this paper, we introduce the problem of Platform-Aware Mission Planning\n(PAMP), addressing it in the setting of temporal durative actions. The PAMP\nproblem differs from standard temporal planning for its exists-forall nature:\nthe high-level plan dealing with mission goals is required to satisfy safety\nand executability constraints, for all the possible non-deterministic\nexecutions of the low-level model of the platform and the environment. We\npropose two approaches for solving PAMP. The first baseline approach\namalgamates the mission and platform levels, while the second is based on an\nabstraction-refinement loop that leverages the combination of a planner and a\nverification engine. We prove the soundness and completeness of the proposed\napproaches and validate them experimentally, demonstrating the importance of\nheterogeneous modeling and the superiority of the technique based on\nabstraction-refinement."}
{"id": "2503.20252", "pdf": "https://arxiv.org/pdf/2503.20252", "abs": "https://arxiv.org/abs/2503.20252", "authors": ["Yejin Kwon", "Daeun Moon", "Youngje Oh", "Hyunsoo Yoon"], "title": "LogicQA: Logical Anomaly Detection with Vision Language Model Generated Questions", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted Industry Track at ACL 2025", "summary": "Anomaly Detection (AD) focuses on detecting samples that differ from the\nstandard pattern, making it a vital tool in process control. Logical anomalies\nmay appear visually normal yet violate predefined constraints on object\npresence, arrangement, or quantity, depending on reasoning and explainability.\nWe introduce LogicQA, a framework that enhances AD by providing industrial\noperators with explanations for logical anomalies. LogicQA compiles\nautomatically generated questions into a checklist and collects responses to\nidentify violations of logical constraints. LogicQA is training-free,\nannotation-free, and operates in a few-shot setting. We achieve\nstate-of-the-art (SOTA) Logical AD performance on public benchmarks, MVTec LOCO\nAD, with an AUROC of 87.6 percent and an F1-max of 87.0 percent along with the\nexplanations of anomalies. Also, our approach has shown outstanding performance\non semiconductor SEM corporate data, further validating its effectiveness in\nindustrial applications."}
{"id": "2505.13553", "pdf": "https://arxiv.org/pdf/2505.13553", "abs": "https://arxiv.org/abs/2505.13553", "authors": ["Jaewoo Jeong", "Taesoo Kim", "Sangdon Park"], "title": "Selective Code Generation for Functional Guarantees", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) show human-level performance and their\nspecialized descendants, code generation models, play core roles in solving\ncomplex tasks, including mathematical reasoning and software development. On\nthe downside, the hallucination of LLMs mainly hinders their applicability to\nsystems requiring higher safety standards, thus drawing the attention of the AI\ncommunity. However, the hallucination of code generation models is rarely\nconsidered. One critical bottleneck in considering code hallucination is the\nintricate property of code to identify whether generated code has the intended\nfunctionality due to its un-natural form, different to natural languages.\nHandful of unit tests have been considered to address this issue, but\nscaling-up its size is extremely expensive. We address this core bottleneck by\nautomatically generating unit tests using dynamic code analysis tools, which\nleverages the \\emph{executable nature} of code. Given generated unit tests from\ntrue code for measuring functional correctness of generated code, we propose to\nlearn a \\emph{selective code generator}, which abstains from answering for\nunsure generation, to control the rate of code hallucination among\nnon-abstaining answers in terms of a false discovery rate. This learning\nalgorithm provides a controllability guarantee, providing trustworthiness of\ncode generation. Finally, we propose to use generated unit tests in evaluation\nas well as in learning for precise code evaluation, calling this evaluation\nparadigm \\emph{FuzzEval}. We demonstrate the efficacy of our selective code\ngenerator over open and closed code generators, showing clear benefit of\nleveraging generated unit tests along with the controllability of code\nhallucination and reasonable selection efficiency via our selective code\ngenerator."}
{"id": "2502.02145", "pdf": "https://arxiv.org/pdf/2502.02145", "abs": "https://arxiv.org/abs/2502.02145", "authors": ["Yuan Gao", "Mattia Piccinini", "Korbinian Moller", "Johannes Betz"], "title": "From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios", "categories": ["cs.AI", "cs.CL", "cs.RO"], "comment": null, "summary": "Ensuring the safety of autonomous vehicles requires virtual scenario-based\ntesting, which depends on the robust evaluation and generation of\nsafety-critical scenarios. So far, researchers have used scenario-based testing\nframeworks that rely heavily on handcrafted scenarios as safety metrics. To\nreduce the effort of human interpretation and overcome the limited scalability\nof these approaches, we combine Large Language Models (LLMs) with structured\nscenario parsing and prompt engineering to automatically evaluate and generate\nsafety-critical driving scenarios. We introduce Cartesian and Ego-centric\nprompt strategies for scenario evaluation, and an adversarial generation module\nthat modifies trajectories of risk-inducing vehicles (ego-attackers) to create\ncritical scenarios. We validate our approach using a 2D simulation framework\nand multiple pre-trained LLMs. The results show that the evaluation module\neffectively detects collision scenarios and infers scenario safety. Meanwhile,\nthe new generation module identifies high-risk agents and synthesizes\nrealistic, safety-critical scenarios. We conclude that an LLM equipped with\ndomain-informed prompting techniques can effectively evaluate and generate\nsafety-critical driving scenarios, reducing dependence on handcrafted metrics.\nWe release our open-source code and scenarios at:\nhttps://github.com/TUM-AVS/From-Words-to-Collisions."}
{"id": "2503.22577", "pdf": "https://arxiv.org/pdf/2503.22577", "abs": "https://arxiv.org/abs/2503.22577", "authors": ["I√±igo Pikabea", "I√±aki Lacunza", "Oriol Pareras", "Carlos Escolano", "Aitor Gonzalez-Agirre", "Javier Hernando", "Marta Villegas"], "title": "Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization", "categories": ["cs.CV", "cs.AI"], "comment": "v2: Expanded model merging experiments. Fix duplicated subsection on\n  limitations", "summary": "Rapid advancements in Visual Language Models (VLMs) have transformed\nmultimodal understanding but are often constrained by generating English\nresponses regardless of the input language. This phenomenon has been termed as\nImage-induced Fidelity Loss (IFL) and stems from limited multimodal\nmultilingual training data. To address this, we propose a continuous\nmultilingual integration strategy that injects text-only multilingual data\nduring visual instruction tuning, preserving the language model's original\nmultilingual capabilities. Extensive evaluations demonstrate that our approach\nsignificantly improves linguistic fidelity across languages without degradation\nin visual performance. We also explore model merging, which improves language\nfidelity but comes at the cost of visual performance. In contrast, our core\nmethod achieves robust multilingual alignment without trade-offs, offering a\nscalable and effective path to mitigating IFL for global VLM adoption."}
{"id": "2505.13556", "pdf": "https://arxiv.org/pdf/2505.13556", "abs": "https://arxiv.org/abs/2505.13556", "authors": ["Yiru Jiao", "Simeon C. Calvert", "Sander van Cranenburgh", "Hans van Lint"], "title": "Learning Collision Risk from Naturalistic Driving with Generalised Surrogate Safety Measures", "categories": ["cs.RO", "cs.LG"], "comment": "18 pages, 8 figures", "summary": "Accurate and timely alerts for drivers or automated systems to unfolding\ncollisions remains a challenge in road safety, particularly in highly\ninteractive urban traffic. Existing approaches require labour-intensive\nannotation of sparse risk, struggle to consider varying interaction context, or\nare useful only in the scenarios they are designed for. To address these\nlimits, this study introduces the generalised surrogate safety measure (GSSM),\na new approach that learns exclusively from naturalistic driving without crash\nor risk labels. GSSM captures the patterns of normal driving and estimates the\nextent to which a traffic interaction deviates from the norm towards unsafe\nextreme. Utilising neural networks, normal interactions are characterised by\ncontext-conditioned distributions of multi-directional spacing between road\nusers. In the same interaction context, a spacing closer than normal entails\nhigher risk of potential collision. Then a context-adaptive risk score and its\nassociated probability can be calculated based on the theory of extreme values.\nAny measurable factors, such as motion kinematics, weather, lighting, can serve\nas part of the context, allowing for diverse coverage of safety-critical\ninteractions. Multiple public driving datasets are used to train GSSMs, which\nare tested with 4,875 real-world crashes and near-crashes reconstructed from\nthe SHRP2 NDS. A vanilla GSSM using only instantaneous states achieves AUPRC of\n0.9 and secures a median time advance of 2.6 seconds to prevent potential\ncollisions. Additional data and contextual factors provide further performance\ngains. Across various interaction types such as rear-end, merging, and\ncrossing, the accuracy and timeliness of GSSM consistently outperforms existing\nbaselines. GSSM therefore establishes a scalable, context-aware, and\ngeneralisable foundation to proactively quantify collision risk in traffic\ninteractions."}
{"id": "2502.02982", "pdf": "https://arxiv.org/pdf/2502.02982", "abs": "https://arxiv.org/abs/2502.02982", "authors": ["Wenhao Wang", "Mengying Yuan", "Zijie Yu", "Guangyi Liu", "Rui Ye", "Tian Jin", "Siheng Chen", "Yanfeng Wang"], "title": "MobileA3gent: Training Mobile GUI Agents Using Decentralized Self-Sourced Data from Diverse Users", "categories": ["cs.AI"], "comment": null, "summary": "The advancement of mobile GUI agents has opened new opportunities for\nautomating tasks on mobile devices. Training these agents requires large-scale\nhigh-quality data, which is prohibitively expensive when relying on human\nlabor. Given the vast population of global mobile phone users, if automated\ndata collection from them becomes feasible, the resulting data volume and the\nsubsequently trained mobile agents could reach unprecedented levels.\nNevertheless, two major challenges arise: (1) extracting user instructions\nwithout human intervention and (2) utilizing distributed user data while\npreserving privacy. To tackle these challenges, we propose MobileA3gent, a\ncollaborative framework that trains mobile GUI Agents using decentralized\nself-sourced data from diverse users. The framework comprises two components,\neach targeting a specific challenge: (1) Auto-Annotation, which enables the\nautomatic collection of high-quality datasets during users' routine phone usage\nwith minimal cost. (2) FedVLM-A, which enhances federated VLM training under\nnon-IID distributions by incorporating adapted global aggregation based on both\nepisode-level and step-level variability. Extensive experiments prove that\nMobileA3gent achieves superior performance over traditional approaches at only\n1% of the cost, highlighting its potential for real-world applications"}
{"id": "2312.10097", "pdf": "https://arxiv.org/pdf/2312.10097", "abs": "https://arxiv.org/abs/2312.10097", "authors": ["Isidor Konrad Maier", "Matthias Wolff"], "title": "Arithmetics-Based Decomposition of Numeral Words -- Arithmetic Conditions give the Unpacking Strategy", "categories": ["cs.CL"], "comment": null, "summary": "This paper presents a novel numeral decomposer based on arithmetic criteria.\nThe criteria are not dependent on a base-10 assumption but only on Hurford's\nPacking Strategy. Hurford's Packing Strategy constitutes numerals by packing\nfactors and summands to multiplicators. We found out that a numeral of value n\nhas a multiplicator larger than sqrt(n), a summand smaller than n/2 and a\nfactor smaller than sqrt(n). Using these findings, the numeral decomposer\nattempts to detect and unpack factors and summand in order to reverse Hurford's\nPacking strategy. We tested its applicability for incremental unsupervised\ngrammar induction in 273 languages. This way, grammars were obtained with\nsensible mathematical attributes that explain the structure of produced\nnumerals. The numeral-decomposer-induced grammars are often close to\nexpert-made and more compact than numeral grammars induced by a modern\nstate-of-the-art grammar induction tool. Furthermore, this paper contains a\nreport about the few cases of incorrect induced mathematical attributes, which\nare often linked to linguistic peculiarities like context sensitivity."}
{"id": "2504.04837", "pdf": "https://arxiv.org/pdf/2504.04837", "abs": "https://arxiv.org/abs/2504.04837", "authors": ["Zhi Zuo", "Chenyi Zhuang", "Pan Gao", "Jie Qin", "Hao Feng", "Nicu Sebe"], "title": "Uni4D: A Unified Self-Supervised Learning Framework for Point Cloud Videos", "categories": ["cs.CV"], "comment": "11 pages, 7 figures", "summary": "Self-supervised representation learning for point cloud videos remains a\nchallenging problem with two key limitations: (1) existing methods rely on\nexplicit knowledge to learn motion, resulting in suboptimal representations;\n(2) prior Masked AutoEncoder (MAE) frameworks struggle to bridge the gap\nbetween low-level geometry and high-level dynamics in 4D data. In this work, we\npropose a novel self-disentangled MAE for learning expressive, discriminative,\nand transferable 4D representations. To overcome the first limitation, we learn\nmotion by aligning high-level semantics in the latent space \\textit{without any\nexplicit knowledge}. To tackle the second, we introduce a\n\\textit{self-disentangled learning} strategy that incorporates the latent token\nwith the geometry token within a shared decoder, effectively disentangling\nlow-level geometry and high-level semantics. In addition to the reconstruction\nobjective, we employ three alignment objectives to enhance temporal\nunderstanding, including frame-level motion and video-level global information.\nWe show that our pre-trained encoder surprisingly discriminates spatio-temporal\nrepresentation without further fine-tuning. Extensive experiments on\nMSR-Action3D, NTU-RGBD, HOI4D, NvGesture, and SHREC'17 demonstrate the\nsuperiority of our approach in both coarse-grained and fine-grained 4D\ndownstream tasks. Notably, Uni4D improves action segmentation accuracy on HOI4D\nby $+3.8\\%$."}
{"id": "2505.13558", "pdf": "https://arxiv.org/pdf/2505.13558", "abs": "https://arxiv.org/abs/2505.13558", "authors": ["Yingjie Kuang", "Tianchen Zhang", "Zhen-Wei Huang", "Zhongjie Zeng", "Zhe-Yuan Li", "Ling Huang", "Yuefang Gao"], "title": "CATS: Clustering-Aggregated and Time Series for Business Customer Purchase Intention Prediction", "categories": ["econ.EM", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Accurately predicting customers' purchase intentions is critical to the\nsuccess of a business strategy. Current researches mainly focus on analyzing\nthe specific types of products that customers are likely to purchase in the\nfuture, little attention has been paid to the critical factor of whether\ncustomers will engage in repurchase behavior. Predicting whether a customer\nwill make the next purchase is a classic time series forecasting task. However,\nin real-world purchasing behavior, customer groups typically exhibit imbalance\n- i.e., there are a large number of occasional buyers and a small number of\nloyal customers. This head-to-tail distribution makes traditional time series\nforecasting methods face certain limitations when dealing with such problems.\nTo address the above challenges, this paper proposes a unified Clustering and\nAttention mechanism GRU model (CAGRU) that leverages multi-modal data for\ncustomer purchase intention prediction. The framework first performs customer\nprofiling with respect to the customer characteristics and clusters the\ncustomers to delineate the different customer clusters that contain similar\nfeatures. Then, the time series features of different customer clusters are\nextracted by GRU neural network and an attention mechanism is introduced to\ncapture the significance of sequence locations. Furthermore, to mitigate the\nhead-to-tail distribution of customer segments, we train the model separately\nfor each customer segment, to adapt and capture more accurately the differences\nin behavioral characteristics between different customer segments, as well as\nthe similar characteristics of the customers within the same customer segment.\nWe constructed four datasets and conducted extensive experiments to demonstrate\nthe superiority of the proposed CAGRU approach."}
{"id": "2502.14706", "pdf": "https://arxiv.org/pdf/2502.14706", "abs": "https://arxiv.org/abs/2502.14706", "authors": ["Daphne Cornelisse", "Aarav Pandya", "Kevin Joseph", "Joseph Su√°rez", "Eugene Vinitsky"], "title": "Building reliable sim driving agents by scaling self-play", "categories": ["cs.AI", "cs.RO"], "comment": "v3", "summary": "Simulation agents are essential for designing and testing systems that\ninteract with humans, such as autonomous vehicles (AVs). These agents serve\nvarious purposes, from benchmarking AV performance to stress-testing system\nlimits, but all applications share one key requirement: reliability. To enable\nsound experimentation, a simulation agent must behave as intended. It should\nminimize actions that may lead to undesired outcomes, such as collisions, which\ncan distort the signal-to-noise ratio in analyses. As a foundation for reliable\nsim agents, we propose scaling self-play to thousands of scenarios on the Waymo\nOpen Motion Dataset under semi-realistic limits on human perception and\ncontrol. Training from scratch on a single GPU, our agents solve almost the\nfull training set within a day. They generalize to unseen test scenes,\nachieving a 99.8% goal completion rate with less than 0.8% combined collision\nand off-road incidents across 10,000 held-out scenarios. Beyond in-distribution\ngeneralization, our agents show partial robustness to out-of-distribution\nscenes and can be fine-tuned in minutes to reach near-perfect performance in\nsuch cases. We open-source the pre-trained agents and integrate them with a\nbatched multi-agent simulator. Demonstrations of agent behaviors can be viewed\nat https://sites.google.com/view/reliable-sim-agents, and we open-source our\nagents at https://github.com/Emerge-Lab/gpudrive."}
{"id": "2403.10056", "pdf": "https://arxiv.org/pdf/2403.10056", "abs": "https://arxiv.org/abs/2403.10056", "authors": ["Yongquan He", "Wenyuan Zhang", "Xuancheng Huang", "Peng Zhang"], "title": "Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 6 figures", "summary": "Instruction tuning for large language models (LLMs) can drive them to produce\nresults consistent with human goals in specific downstream tasks. However, the\nprocess of continual instruction tuning (CIT) for LLMs may bring about the\ncatastrophic forgetting (CF) problem, where previously learned abilities are\ndegraded. Recent methods try to alleviate the CF problem by modifying models or\nreplaying data, which may only remember the surface-level pattern of\ninstructions and get confused on held-out tasks. In this paper, we propose a\nnovel continual instruction tuning method based on Key-part Information Gain\n(KPIG). Our method computes the information gain on masked parts to dynamically\nreplay data and refine the training objective, which enables LLMs to capture\ntask-aware information relevant to the correct response and alleviate\noverfitting to general descriptions in instructions. In addition, we propose\ntwo metrics, P-score and V-score, to measure the generalization and\ninstruction-following abilities of LLMs. Experiments demonstrate our method\nachieves superior performance on both seen and held-out tasks."}
{"id": "2504.14202", "pdf": "https://arxiv.org/pdf/2504.14202", "abs": "https://arxiv.org/abs/2504.14202", "authors": ["Zichuan Liu", "Liming Jiang", "Qing Yan", "Yumin Jia", "Hao Kang", "Xin Lu"], "title": "Learning Joint ID-Textual Representation for ID-Preserving Image Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose a novel framework for ID-preserving generation using a multi-modal\nencoding strategy rather than injecting identity features via adapters into\npre-trained models. Our method treats identity and text as a unified\nconditioning input. To achieve this, we introduce FaceCLIP, a multi-modal\nencoder that learns a joint embedding space for both identity and textual\nsemantics. Given a reference face and a text prompt, FaceCLIP produces a\nunified representation that encodes both identity and text, which conditions a\nbase diffusion model to generate images that are identity-consistent and\ntext-aligned. We also present a multi-modal alignment algorithm to train\nFaceCLIP, using a loss that aligns its joint representation with face, text,\nand image embedding spaces. We then build FaceCLIP-SDXL, an ID-preserving image\nsynthesis pipeline by integrating FaceCLIP with Stable Diffusion XL (SDXL).\nCompared to prior methods, FaceCLIP-SDXL enables photorealistic portrait\ngeneration with better identity preservation and textual relevance. Extensive\nexperiments demonstrate its quantitative and qualitative superiority."}
{"id": "2505.13571", "pdf": "https://arxiv.org/pdf/2505.13571", "abs": "https://arxiv.org/abs/2505.13571", "authors": ["Andy S. Anker", "Jonas H. Jensen", "Miguel Gonzalez-Duque", "Rodrigo Moreno", "Aleksandra Smolska", "Mikkel Juelsholt", "Vincent Hardion", "Mads R. V. Jorgensen", "Andres Faina", "Jonathan Quinson", "Kasper Stoy", "Tejs Vegge"], "title": "Autonomous nanoparticle synthesis by design", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cs.LG"], "comment": null, "summary": "Controlled synthesis of materials with specified atomic structures underpins\ntechnological advances yet remains reliant on iterative, trial-and-error\napproaches. Nanoparticles (NPs), whose atomic arrangement dictates their\nemergent properties, are particularly challenging to synthesise due to numerous\ntunable parameters. Here, we introduce an autonomous approach explicitly\ntargeting synthesis of atomic-scale structures. Our method autonomously designs\nsynthesis protocols by matching real time experimental total scattering (TS)\nand pair distribution function (PDF) data to simulated target patterns, without\nrequiring prior synthesis knowledge. We demonstrate this capability at a\nsynchrotron, successfully synthesising two structurally distinct gold NPs: 5 nm\ndecahedral and 10 nm face-centred cubic structures. Ultimately, specifying a\nsimulated target scattering pattern, thus representing a bespoke atomic\nstructure, and obtaining both the synthesised material and its reproducible\nsynthesis protocol on demand may revolutionise materials design. Thus,\nScatterLab provides a generalisable blueprint for autonomous, atomic\nstructure-targeted synthesis across diverse systems and applications."}
{"id": "2503.23326", "pdf": "https://arxiv.org/pdf/2503.23326", "abs": "https://arxiv.org/abs/2503.23326", "authors": ["Yiyu Qian", "Tim Miller", "Zheng Qian", "Liyuan Zhao"], "title": "Exploring Explainable Multi-player MCTS-minimax Hybrids in Board Game Using Process Mining", "categories": ["cs.AI"], "comment": "38 pages, AAAI 2025 PRL", "summary": "Monte-Carlo Tree Search (MCTS) is a family of sampling-based search\nalgorithms widely used for online planning in sequential decision-making\ndomains and at the heart of many recent advances in artificial intelligence.\nUnderstanding the behavior of MCTS agents is difficult for developers and users\ndue to the frequently large and complex search trees that result from the\nsimulation of many possible futures, their evaluations, and their\nrelationships. This paper presents our ongoing investigation into potential\nexplanations for the decision-making and behavior of MCTS. A weakness of MCTS\nis that it constructs a highly selective tree and, as a result, can miss\ncrucial moves and fall into tactical traps. Full-width minimax search\nconstitutes the solution. We integrate shallow minimax search into the rollout\nphase of multi-player MCTS and use process mining technique to explain agents'\nstrategies in 3v3 checkers."}
{"id": "2404.17662", "pdf": "https://arxiv.org/pdf/2404.17662", "abs": "https://arxiv.org/abs/2404.17662", "authors": ["Qinglin Zhu", "Runcong Zhao", "Bin Liang", "Jinhua Du", "Lin Gui", "Yulan He"], "title": "PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games", "categories": ["cs.CL"], "comment": null, "summary": "We introduce WellPlay, a reasoning dataset for multi-agent conversational\ninference in Murder Mystery Games (MMGs). WellPlay comprises 1,482 inferential\nquestions across 12 games, spanning objectives, reasoning, and relationship\nunderstanding, and establishes a systematic benchmark for evaluating agent\nreasoning abilities in complex social settings. Building on this foundation, we\npresent PLAYER*, a novel framework for Large Language Model (LLM)-based agents\nin MMGs. MMGs pose unique challenges, including undefined state spaces, absent\nintermediate rewards, and the need for strategic reasoning through natural\nlanguage. PLAYER* addresses these challenges with a sensor-based state\nrepresentation and an information-driven strategy that optimises questioning\nand suspect pruning. Experiments show that PLAYER* outperforms existing methods\nin reasoning accuracy, efficiency, and agent-human interaction, advancing\nreasoning agents for complex social scenarios."}
{"id": "2504.15723", "pdf": "https://arxiv.org/pdf/2504.15723", "abs": "https://arxiv.org/abs/2504.15723", "authors": ["Dasol Jeong", "Donggoo Kang", "Jiwon Park", "Hyebean Lee", "Joonki Paik"], "title": "Structure-Preserving Zero-Shot Image Editing via Stage-Wise Latent Injection in Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "We propose a diffusion-based framework for zero-shot image editing that\nunifies text-guided and reference-guided approaches without requiring\nfine-tuning. Our method leverages diffusion inversion and timestep-specific\nnull-text embeddings to preserve the structural integrity of the source image.\nBy introducing a stage-wise latent injection strategy-shape injection in early\nsteps and attribute injection in later steps-we enable precise, fine-grained\nmodifications while maintaining global consistency. Cross-attention with\nreference latents facilitates semantic alignment between the source and\nreference. Extensive experiments across expression transfer, texture\ntransformation, and style infusion demonstrate state-of-the-art performance,\nconfirming the method's scalability and adaptability to diverse image editing\nscenarios."}
{"id": "2505.13585", "pdf": "https://arxiv.org/pdf/2505.13585", "abs": "https://arxiv.org/abs/2505.13585", "authors": ["Xinzhu Liang", "Joseph M. Lukens", "Sanjaya Lohani", "Brian T. Kirby", "Thomas A. Searles", "Xin Qiu", "Kody J. H. Law"], "title": "Scalable Bayesian Monte Carlo: fast uncertainty estimation beyond deep ensembles", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "56 pages, 44 figures, 35 tables", "summary": "This work introduces a new method called scalable Bayesian Monte Carlo\n(SBMC). The model interpolates between a point estimator and the posterior, and\nthe algorithm is a parallel implementation of a consistent (asymptotically\nunbiased) Bayesian deep learning algorithm: sequential Monte Carlo (SMC) or\nMarkov chain Monte Carlo (MCMC). The method is motivated theoretically, and its\nutility is demonstrated on practical examples: MNIST, CIFAR, IMDb. A systematic\nnumerical study reveals that parallel implementations of SMC and MCMC are\ncomparable to serial implementations in terms of performance and total cost,\nand they achieve accuracy at or beyond the state-of-the-art (SOTA) methods like\ndeep ensembles at convergence, along with substantially improved uncertainty\nquantification (UQ)--in particular, epistemic UQ. But even parallel\nimplementations are expensive, with an irreducible time barrier much larger\nthan the cost of the MAP estimator. Compressing time further leads to rapid\ndegradation of accuracy, whereas UQ remains valuable. By anchoring to a point\nestimator we can recover accuracy, while retaining valuable UQ, ultimately\ndelivering strong performance across metrics for a cost comparable to the SOTA."}
{"id": "2504.05047", "pdf": "https://arxiv.org/pdf/2504.05047", "abs": "https://arxiv.org/abs/2504.05047", "authors": ["Sugyeong Eo", "Hyeonseok Moon", "Evelyn Hayoon Zi", "Chanjun Park", "Heuiseok Lim"], "title": "Debate Only When Necessary: Adaptive Multiagent Collaboration for Efficient LLM Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Multiagent collaboration has emerged as a promising framework for enhancing\nthe reasoning capabilities of large language models (LLMs). Despite\nimprovements in reasoning, the approach introduces substantial computational\noverhead resulting from iterative agent interactions. Furthermore, engaging in\nunnecessary debates increases the risk of generating erroneous responses. To\naddress these challenges, we propose Debate Only When Necessary (DOWN), an\nadaptive multiagent debate framework that selectively activates debate based on\nthe confidence score of the agent's initial response. Debate is activated only\nfor queries requiring further deliberation, during which agents refine their\noutputs by referencing peer responses and associated confidence scores.\nEvaluations on benchmarks show that DOWN improves efficiency by up to six times\nwhile preserving or even outperforming the performance of existing methods.\nFurther analysis indicates that DOWN effectively mitigates the risk of error\npropagation stemming from the unnecessary debate process. These findings\ndemonstrate the effectiveness of our approach in delivering high-performance\nLLM solutions at a lower computational cost."}
{"id": "2407.01082", "pdf": "https://arxiv.org/pdf/2407.01082", "abs": "https://arxiv.org/abs/2407.01082", "authors": ["Minh Nguyen", "Andrew Baker", "Clement Neo", "Allen Roush", "Andreas Kirsch", "Ravid Shwartz-Ziv"], "title": "Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs", "categories": ["cs.CL"], "comment": "In line with ICLR/Openreview changes + better overall reading flow.\n  https://iclr.cc/virtual/2025/poster/30358", "summary": "Large Language Models (LLMs) generate text by sampling the next token from a\nprobability distribution over the vocabulary at each decoding step. Popular\nsampling methods like top-p (nucleus sampling) often struggle to balance\nquality and diversity, especially at higher temperatures which lead to\nincoherent or repetitive outputs. We propose min-p sampling, a dynamic\ntruncation method that adjusts the sampling threshold based on the model's\nconfidence by using the top token's probability as a scaling factor. Our\nexperiments on benchmarks including GPQA, GSM8K, and AlpacaEval Creative\nWriting show that min-p sampling improves both the quality and diversity of\ngenerated text across different model families (Mistral and Llama 3) and model\nsizes (1B to 123B parameters), especially at higher temperatures. Human\nevaluations further show a clear preference for min-p sampling, in both text\nquality and creativity. Min-p sampling has been adopted by popular open-source\nLLM frameworks, including Hugging Face Transformers, VLLM, and many others,\nhighlighting its considerable impact on improving text generation quality."}
{"id": "2504.17821", "pdf": "https://arxiv.org/pdf/2504.17821", "abs": "https://arxiv.org/abs/2504.17821", "authors": ["Xinyu Chen", "Yunxin Li", "Haoyuan Shi", "Baotian Hu", "Wenhan Luo", "Yaowei Wang", "Min Zhang"], "title": "VideoVista-CulturalLingo: 360$^\\circ$ Horizons-Bridging Cultures, Languages, and Domains in Video Comprehension", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Assessing the video comprehension capabilities of multimodal AI systems can\neffectively measure their understanding and reasoning abilities. Most video\nevaluation benchmarks are limited to a single language, typically English, and\npredominantly feature videos rooted in Western cultural contexts. In this\npaper, we present VideoVista-CulturalLingo, the first video evaluation\nbenchmark designed to bridge cultural, linguistic, and domain divide in video\ncomprehension. Our work differs from existing benchmarks in the following ways:\n1) Cultural diversity, incorporating cultures from China, North America, and\nEurope; 2) Multi-linguistics, with questions presented in Chinese and\nEnglish-two of the most widely spoken languages; and 3) Broad domain, featuring\nvideos sourced from hundreds of human-created domains. VideoVista-CulturalLingo\ncontains 1,389 videos and 3,134 QA pairs, and we have evaluated 24 recent\nopen-source or proprietary video large models. From the experiment results, we\nobserve that: 1) Existing models perform worse on Chinese-centric questions\nthan Western-centric ones, particularly those related to Chinese history; 2)\nCurrent open-source models still exhibit limitations in temporal understanding,\nespecially in the Event Localization task, achieving a maximum score of only\n45.2%; 3) Mainstream models demonstrate strong performance in general\nscientific questions, while open-source models demonstrate weak performance in\nmathematics."}
{"id": "2505.13651", "pdf": "https://arxiv.org/pdf/2505.13651", "abs": "https://arxiv.org/abs/2505.13651", "authors": ["Jiahao Xu", "Rui Hu", "Olivera Kotevska", "Zikai Zhang"], "title": "Traceable Black-box Watermarks for Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Due to the distributed nature of Federated Learning (FL) systems, each local\nclient has access to the global model, posing a critical risk of model leakage.\nExisting works have explored injecting watermarks into local models to enable\nintellectual property protection. However, these methods either focus on\nnon-traceable watermarks or traceable but white-box watermarks. We identify a\ngap in the literature regarding the formal definition of traceable black-box\nwatermarking and the formulation of the problem of injecting such watermarks\ninto FL systems. In this work, we first formalize the problem of injecting\ntraceable black-box watermarks into FL. Based on the problem, we propose a\nnovel server-side watermarking method, $\\mathbf{TraMark}$, which creates a\ntraceable watermarked model for each client, enabling verification of model\nleakage in black-box settings. To achieve this, $\\mathbf{TraMark}$ partitions\nthe model parameter space into two distinct regions: the main task region and\nthe watermarking region. Subsequently, a personalized global model is\nconstructed for each client by aggregating only the main task region while\npreserving the watermarking region. Each model then learns a unique watermark\nexclusively within the watermarking region using a distinct watermark dataset\nbefore being sent back to the local client. Extensive results across various FL\nsystems demonstrate that $\\mathbf{TraMark}$ ensures the traceability of all\nwatermarked models while preserving their main task performance."}
{"id": "2504.15364", "pdf": "https://arxiv.org/pdf/2504.15364", "abs": "https://arxiv.org/abs/2504.15364", "authors": ["Junyoung Park", "Dalton Jones", "Matthew J Morse", "Raghavv Goel", "Mingu Lee", "Chris Lott"], "title": "KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments", "categories": ["cs.AI"], "comment": "9 pages, 7 figures", "summary": "We demonstrate that geometrically distinctive keys during LLM inference tend\nto have high attention scores. Based on the phenomenon we propose KeyDiff, a\ntraining-free KV cache eviction method based solely on key similarity. Unlike\nother KV cache eviction methods, KeyDiff can process arbitrarily long prompts\nwithin strict resource constraints and efficiently generate responses. We\nprovide a theoretical basis for KeyDiff by relating key diversity with\nattention scores. These results imply KeyDiff can efficiently identify the most\nimportant tokens to retain. Notably KeyDiff does not rely on attention scores,\nallowing the use of optimized attention mechanisms like FlashAttention. Under a\nstrict memory allowance, we demonstrate the effectiveness of KeyDiff for the\nLlama and Qwen model families by observing a performance gap of less than 0.04%\nwith 8K cache budget ($\\sim$23% KV cache reduction) from the non-evicting\nbaseline on LongBench for Llama 3.1-8B and Llama 3.2-3B. We also observe near\nbaseline performance for Deepseek-R1-Distill-Llama-8B on the Math500 reasoning\nbenchmark and decrease end-to-end inference latency by up to 30% compared to\nthe other token-eviction methods."}
{"id": "2407.18416", "pdf": "https://arxiv.org/pdf/2407.18416", "abs": "https://arxiv.org/abs/2407.18416", "authors": ["Vinay Samuel", "Henry Peng Zou", "Yue Zhou", "Shreyas Chaudhari", "Ashwin Kalyan", "Tanmay Rajpurohit", "Ameet Deshpande", "Karthik Narasimhan", "Vishvak Murahari"], "title": "PersonaGym: Evaluating Persona Agents and LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "21 pages, 5 figures", "summary": "Persona agents, which are LLM agents conditioned to act according to an\nassigned persona, enable contextually rich and user aligned interactions across\ndomains like education and healthcare. However, evaluating how faithfully these\nagents adhere to their personas remains a significant challenge, particularly\nin free-form settings that demand consistency across diverse, persona-relevant\nenvironments. We introduce PersonaGym, the first dynamic evaluation framework\nfor persona agents, and PersonaScore, a human-aligned automatic metric grounded\nin decision theory that enables comprehensive large-scale evaluation. Our\nevaluation of 10 leading LLMs across 200 personas and 10,000 questions reveals\nsignificant advancement opportunities. For example, GPT-4.1 had the exact same\nPersonaScore as LLaMA-3-8b despite being a more recent and advanced closed\nsource model. Importantly, increased model size and complexity do not\nnecessarily enhance persona agent capabilities, underscoring the need for\nalgorithmic and architectural innovation toward faithful, performant persona\nagents."}
{"id": "2504.21561", "pdf": "https://arxiv.org/pdf/2504.21561", "abs": "https://arxiv.org/abs/2504.21561", "authors": ["Pengxiang Li", "Zhi Gao", "Bofei Zhang", "Yapeng Mi", "Xiaojian Ma", "Chenrui Shi", "Tao Yuan", "Yuwei Wu", "Yunde Jia", "Song-Chun Zhu", "Qing Li"], "title": "Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning", "categories": ["cs.CV"], "comment": "24 pages", "summary": "Multimodal agents, which integrate a controller e.g., a vision language\nmodel) with external tools, have demonstrated remarkable capabilities in\ntackling complex multimodal tasks. Existing approaches for training these\nagents, both supervised fine-tuning and reinforcement learning, depend on\nextensive human-annotated task-answer pairs and tool trajectories. However, for\ncomplex multimodal tasks, such annotations are prohibitively expensive or\nimpractical to obtain. In this paper, we propose an iterative tool usage\nexploration method for multimodal agents without any pre-collected data, namely\nSPORT, via step-wise preference optimization to refine the trajectories of tool\nusage. Our method enables multimodal agents to autonomously discover effective\ntool usage strategies through self-exploration and optimization, eliminating\nthe bottleneck of human annotation. SPORT has four iterative components: task\nsynthesis, step sampling, step verification, and preference tuning. We first\nsynthesize multimodal tasks using language models. Then, we introduce a novel\ntrajectory exploration scheme, where step sampling and step verification are\nexecuted alternately to solve synthesized tasks. In step sampling, the agent\ntries different tools and obtains corresponding results. In step verification,\nwe employ a verifier to provide AI feedback to construct step-wise preference\ndata. The data is subsequently used to update the controller for tool usage\nthrough preference tuning, producing a SPORT agent. By interacting with real\nenvironments, the SPORT agent gradually evolves into a more refined and capable\nsystem. Evaluation in the GTA and GAIA benchmarks shows that the SPORT agent\nachieves 6.41% and 3.64% improvements, underscoring the generalization and\neffectiveness introduced by our method. The project page is\nhttps://SPORT-Agents.github.io."}
{"id": "2505.13655", "pdf": "https://arxiv.org/pdf/2505.13655", "abs": "https://arxiv.org/abs/2505.13655", "authors": ["Jiahao Xu", "Rui Hu", "Olivera Kotevska"], "title": "Optimal Client Sampling in Federated Learning with Client-Level Heterogeneous Differential Privacy", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Federated Learning with client-level differential privacy (DP) provides a\npromising framework for collaboratively training models while rigorously\nprotecting clients' privacy. However, classic approaches like DP-FedAvg\nstruggle when clients have heterogeneous privacy requirements, as they must\nuniformly enforce the strictest privacy level across clients, leading to\nexcessive DP noise and significant model utility degradation. Existing methods\nto improve the model utility in such heterogeneous privacy settings often\nassume a trusted server and are largely heuristic, resulting in suboptimal\nperformance and lacking strong theoretical underpinnings. In this work, we\naddress these challenges under a practical attack model where both clients and\nthe server are honest-but-curious. We propose GDPFed, which partitions clients\ninto groups based on their privacy budgets and achieves client-level DP within\neach group to reduce the privacy budget waste and hence improve the model\nutility. Based on the privacy and convergence analysis of GDPFed, we find that\nthe magnitude of DP noise depends on both model dimensionality and the\nper-group client sampling ratios. To further improve the performance of GDPFed,\nwe introduce GDPFed$^+$, which integrates model sparsification to eliminate\nunnecessary noise and optimizes per-group client sampling ratios to minimize\nconvergence error. Extensive empirical evaluations on multiple benchmark\ndatasets demonstrate the effectiveness of GDPFed$^+$, showing substantial\nperformance gains compared with state-of-the-art methods."}
{"id": "2505.03941", "pdf": "https://arxiv.org/pdf/2505.03941", "abs": "https://arxiv.org/abs/2505.03941", "authors": ["Matan Shamir", "Reuth Mirsky"], "title": "GRAML: Goal Recognition As Metric Learning", "categories": ["cs.AI"], "comment": "Accepted for publication in International Joint Conference on\n  Artificial Intelligence (IJCAI) 2025", "summary": "Goal Recognition (GR) is the problem of recognizing an agent's objectives\nbased on observed actions. Recent data-driven approaches for GR alleviate the\nneed for costly, manually crafted domain models. However, these approaches can\nonly reason about a pre-defined set of goals, and time-consuming training is\nneeded for new emerging goals. To keep this model-learning automated while\nenabling quick adaptation to new goals, this paper introduces GRAML: Goal\nRecognition As Metric Learning. GRAML uses a Siamese network to treat GR as a\ndeep metric learning task, employing an RNN that learns a metric over an\nembedding space, where the embeddings for observation traces leading to\ndifferent goals are distant, and embeddings of traces leading to the same goals\nare close. This metric is especially useful when adapting to new goals, even if\ngiven just one example observation trace per goal. Evaluated on a versatile set\nof environments, GRAML shows speed, flexibility, and runtime improvements over\nthe state-of-the-art GR while maintaining accurate recognition."}
{"id": "2409.00054", "pdf": "https://arxiv.org/pdf/2409.00054", "abs": "https://arxiv.org/abs/2409.00054", "authors": ["Yuting Hu", "Dancheng Liu", "Qingyun Wang", "Charles Yu", "Chenhui Xu", "Qingxiao Zheng", "Heng Ji", "Jinjun Xiong"], "title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCAI2025", "summary": "Identifying effective interventions from the scientific literature is\nchallenging due to the high volume of publications, specialized terminology,\nand inconsistent reporting formats, making manual curation laborious and prone\nto oversight. To address this challenge, this paper proposes a novel framework\nleveraging large language models (LLMs), which integrates a progressive\nontology prompting (POP) algorithm with a dual-agent system, named LLM-Duo. On\nthe one hand, the POP algorithm conducts a prioritized breadth-first search\n(BFS) across a predefined ontology, generating structured prompt templates and\naction sequences to guide the automatic annotation process. On the other hand,\nthe LLM-Duo system features two specialized LLM agents, an explorer and an\nevaluator, working collaboratively and adversarially to continuously refine\nannotation quality. We showcase the real-world applicability of our framework\nthrough a case study focused on speech-language intervention discovery.\nExperimental results show that our approach surpasses advanced baselines,\nachieving more accurate and comprehensive annotations through a fully automated\nprocess. Our approach successfully identified 2,421 interventions from a corpus\nof 64,177 research articles in the speech-language pathology domain,\nculminating in the creation of a publicly accessible intervention knowledge\nbase with great potential to benefit the speech-language pathology community."}
{"id": "2505.02043", "pdf": "https://arxiv.org/pdf/2505.02043", "abs": "https://arxiv.org/abs/2505.02043", "authors": ["Cheng Wang", "Xinzhu Ma", "Bin Wang", "Shixiang Tang", "Yuan Meng", "Ping Jiang"], "title": "Point2Primitive: CAD Reconstruction from Point Cloud by Direct Primitive Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Recovering CAD models from point clouds, especially the sketch-extrusion\nprocess, can be seen as the process of rebuilding the topology and extrusion\nprimitives. Previous methods utilize implicit fields for sketch representation,\nleading to shape reconstruction of curved edges. In this paper, we proposed a\nCAD reconstruction network that produces editable CAD models from input point\nclouds (Point2Primitive) by directly predicting every element of the extrusion\nprimitives. Point2Primitive can directly detect and predict sketch curves (type\nand parameter) from point clouds based on an improved transformer. The sketch\ncurve parameters are formulated as position queries and optimized in an\nautoregressive way, leading to high parameter accuracy. The topology is rebuilt\nby extrusion segmentation, and each extrusion parameter (sketch and extrusion\noperation) is recovered by combining the predicted curves and the computed\nextrusion operation. Extensive experiments demonstrate that our method is\nsuperior in primitive prediction accuracy and CAD reconstruction. The\nreconstructed shapes are of high geometrical fidelity."}
{"id": "2505.13660", "pdf": "https://arxiv.org/pdf/2505.13660", "abs": "https://arxiv.org/abs/2505.13660", "authors": ["Kaheon Kim", "Bohan Zhou", "Changbo Zhu", "Xiaohui Chen"], "title": "Sobolev Gradient Ascent for Optimal Transport: Barycenter Optimization and Convergence Analysis", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "This paper introduces a new constraint-free concave dual formulation for the\nWasserstein barycenter. Tailoring the vanilla dual gradient ascent algorithm to\nthe Sobolev geometry, we derive a scalable Sobolev gradient ascent (SGA)\nalgorithm to compute the barycenter for input distributions supported on a\nregular grid. Despite the algorithmic simplicity, we provide a global\nconvergence analysis that achieves the same rate as the classical subgradient\ndescent methods for minimizing nonsmooth convex functions in the Euclidean\nspace. A central feature of our SGA algorithm is that the computationally\nexpensive $c$-concavity projection operator enforced on the Kantorovich dual\npotentials is unnecessary to guarantee convergence, leading to significant\nalgorithmic and theoretical simplifications over all existing primal and dual\nmethods for computing the exact barycenter. Our numerical experiments\ndemonstrate the superior empirical performance of SGA over the existing optimal\ntransport barycenter solvers."}
{"id": "2505.06706", "pdf": "https://arxiv.org/pdf/2505.06706", "abs": "https://arxiv.org/abs/2505.06706", "authors": ["Yuxuan Zheng", "Yihe Zhou", "Feiyang Xu", "Mingli Song", "Shunyu Liu"], "title": "Bi-level Mean Field: Dynamic Grouping for Large-Scale MARL", "categories": ["cs.AI"], "comment": null, "summary": "Large-scale Multi-Agent Reinforcement Learning (MARL) often suffers from the\ncurse of dimensionality, as the exponential growth in agent interactions\nsignificantly increases computational complexity and impedes learning\nefficiency. To mitigate this, existing efforts that rely on Mean Field (MF)\nsimplify the interaction landscape by approximating neighboring agents as a\nsingle mean agent, thus reducing overall complexity to pairwise interactions.\nHowever, these MF methods inevitably fail to account for individual\ndifferences, leading to aggregation noise caused by inaccurate iterative\nupdates during MF learning. In this paper, we propose a Bi-level Mean Field\n(BMF) method to capture agent diversity with dynamic grouping in large-scale\nMARL, which can alleviate aggregation noise via bi-level interaction.\nSpecifically, BMF introduces a dynamic group assignment module, which employs a\nVariational AutoEncoder (VAE) to learn the representations of agents,\nfacilitating their dynamic grouping over time. Furthermore, we propose a\nbi-level interaction module to model both inter- and intra-group interactions\nfor effective neighboring aggregation. Experiments across various tasks\ndemonstrate that the proposed BMF yields results superior to the\nstate-of-the-art methods."}
{"id": "2409.11074", "pdf": "https://arxiv.org/pdf/2409.11074", "abs": "https://arxiv.org/abs/2409.11074", "authors": ["Adrian Cosma", "Ana-Maria Bucur", "Emilian Radoi"], "title": "RoMath: A Mathematical Reasoning Benchmark in Romanian", "categories": ["cs.CL", "cs.AI"], "comment": "5 Figures, 11 Tables", "summary": "Mathematics has long been conveyed through natural language, primarily for\nhuman understanding. With the rise of mechanized mathematics and proof\nassistants, there is a growing need to understand informal mathematical text,\nyet most existing benchmarks focus solely on English, overlooking other\nlanguages. This paper introduces RoMath, a Romanian mathematical reasoning\nbenchmark suite comprising three subsets: Baccalaureate, Competitions and\nSynthetic, which cover a range of mathematical domains and difficulty levels,\naiming to improve non-English language models and promote multilingual AI\ndevelopment. By focusing on Romanian, a low-resource language with unique\nlinguistic features, RoMath addresses the limitations of Anglo-centric models\nand emphasizes the need for dedicated resources beyond simple automatic\ntranslation. We benchmark several open-weight language models, highlighting the\nimportance of creating resources for underrepresented languages. Code and\ndatasets are be made available."}
{"id": "2505.04058", "pdf": "https://arxiv.org/pdf/2505.04058", "abs": "https://arxiv.org/abs/2505.04058", "authors": ["Feng Xiao", "Hongbin Xu", "Guocan Zhao", "Wenxiong Kang"], "title": "AS3D: 2D-Assisted Cross-Modal Understanding with Semantic-Spatial Scene Graphs for 3D Visual Grounding", "categories": ["cs.CV"], "comment": null, "summary": "3D visual grounding aims to localize the unique target described by natural\nlanguages in 3D scenes. The significant gap between 3D and language modalities\nmakes it a notable challenge to distinguish multiple similar objects through\nthe described spatial relationships. Current methods attempt to achieve\ncross-modal understanding in complex scenes via a target-centered learning\nmechanism, ignoring the perception of referred objects. We propose a novel\n2D-assisted 3D visual grounding framework that constructs semantic-spatial\nscene graphs with referred object discrimination for relationship perception.\nThe framework incorporates a dual-branch visual encoder that utilizes 2D\npre-trained attributes to guide the multi-modal object encoding. Furthermore,\nour cross-modal interaction module uses graph attention to facilitate\nrelationship-oriented information fusion. The enhanced object representation\nand iterative relational learning enable the model to establish effective\nalignment between 3D vision and referential descriptions. Experimental results\non the popular benchmarks demonstrate our superior performance compared to\nstate-of-the-art methods, especially in addressing the challenges of multiple\nsimilar distractors."}
{"id": "2505.13693", "pdf": "https://arxiv.org/pdf/2505.13693", "abs": "https://arxiv.org/abs/2505.13693", "authors": ["Hiya Bhatt", "Shaunak Biswas", "Srinivasan Rakhunathan", "Karthik Vaidhyanathan"], "title": "HarmonE: A Self-Adaptive Approach to Architecting Sustainable MLOps", "categories": ["cs.SE", "cs.LG"], "comment": "This paper has been accepted to ECSA 2025", "summary": "Machine Learning Enabled Systems (MLS) are becoming integral to real-world\napplications, but ensuring their sustainable performance over time remains a\nsignificant challenge. These systems operate in dynamic environments and face\nruntime uncertainties like data drift and model degradation, which affect the\nsustainability of MLS across multiple dimensions: technical, economical,\nenvironmental, and social. While Machine Learning Operations (MLOps) addresses\nthe technical dimension by streamlining the ML model lifecycle, it overlooks\nother dimensions. Furthermore, some traditional practices, such as frequent\nretraining, incur substantial energy and computational overhead, thus\namplifying sustainability concerns. To address them, we introduce HarmonE, an\narchitectural approach that enables self-adaptive capabilities in MLOps\npipelines using the MAPE-K loop. HarmonE allows system architects to define\nexplicit sustainability goals and adaptation thresholds at design time, and\nperforms runtime monitoring of key metrics, such as prediction accuracy, energy\nconsumption, and data distribution shifts, to trigger appropriate adaptation\nstrategies. We validate our approach using a Digital Twin (DT) of an\nIntelligent Transportation System (ITS), focusing on traffic flow prediction as\nour primary use case. The DT employs time series ML models to simulate\nreal-time traffic and assess various flow scenarios. Our results show that\nHarmonE adapts effectively to evolving conditions while maintaining accuracy\nand meeting sustainability goals."}
{"id": "2505.08155", "pdf": "https://arxiv.org/pdf/2505.08155", "abs": "https://arxiv.org/abs/2505.08155", "authors": ["Weizhi Fei", "Zihao Wang", "hang Yin", "Shukai Zhao", "Wei Zhang", "Yangqiu Song"], "title": "Efficient and Scalable Neural Symbolic Search for Knowledge Graph Complex Query Answering", "categories": ["cs.AI"], "comment": null, "summary": "Complex Query Answering (CQA) aims to retrieve answer sets for complex\nlogical formulas from incomplete knowledge graphs, which is a crucial yet\nchallenging task in knowledge graph reasoning. While neuro-symbolic search\nutilized neural link predictions achieve superior accuracy, they encounter\nsignificant complexity bottlenecks: (i) Data complexity typically scales\nquadratically with the number of entities in the knowledge graph, and (ii)\nQuery complexity becomes NP-hard for cyclic queries. Consequently, these\napproaches struggle to effectively scale to larger knowledge graphs and more\ncomplex queries. To address these challenges, we propose an efficient and\nscalable symbolic search framework. First, we propose two constraint strategies\nto compute neural logical indices to reduce the domain of variables, thereby\ndecreasing the data complexity of symbolic search. Additionally, we introduce\nan approximate algorithm based on local search to tackle the NP query\ncomplexity of cyclic queries. Experiments on various CQA benchmarks demonstrate\nthat our framework reduces the computational load of symbolic methods by 90\\%\nwhile maintaining nearly the same performance, thus alleviating both efficiency\nand scalability issues."}
{"id": "2409.11726", "pdf": "https://arxiv.org/pdf/2409.11726", "abs": "https://arxiv.org/abs/2409.11726", "authors": ["Wenyuan Zhang", "Shuaiyi Nie", "Jiawei Sheng", "Zefeng Zhang", "Xinghua Zhang", "Yongquan He", "Tingwen Liu"], "title": "Revealing and Mitigating the Challenge of Detecting Character Knowledge Errors in LLM Role-Playing", "categories": ["cs.CL", "cs.HC"], "comment": "25 pages, 6 figures, 20 tables", "summary": "Large language model (LLM) role-playing has gained widespread attention.\nAuthentic character knowledge is crucial for constructing realistic LLM\nrole-playing agents. However, existing works usually overlook the exploration\nof LLMs' ability to detect characters' known knowledge errors (KKE) and unknown\nknowledge errors (UKE) while playing roles, which would lead to low-quality\nautomatic construction of character trainable corpus. In this paper, we propose\nRoleKE-Bench to evaluate LLMs' ability to detect errors in KKE and UKE. The\nresults indicate that even the latest LLMs struggle to detect these two types\nof errors effectively, especially when it comes to familiar knowledge. We\nexperimented with various reasoning strategies and propose an agent-based\nreasoning method, Self-Recollection and Self-Doubt (S$^2$RD), to explore\nfurther the potential for improving error detection capabilities. Experiments\nshow that our method effectively improves the LLMs' ability to detect error\ncharacter knowledge, but it remains an issue that requires ongoing attention."}
{"id": "2505.04612", "pdf": "https://arxiv.org/pdf/2505.04612", "abs": "https://arxiv.org/abs/2505.04612", "authors": ["Jiahao Li", "Haochen Wang", "Muhammad Zubair Irshad", "Igor Vasiljevic", "Matthew R. Walter", "Vitor Campagnolo Guizilini", "Greg Shakhnarovich"], "title": "FastMap: Revisiting Dense and Scalable Structure from Motion", "categories": ["cs.CV"], "comment": "Project webpage: https://jiahao.ai/fastmap", "summary": "We propose FastMap, a new global structure from motion method focused on\nspeed and simplicity. Previous methods like COLMAP and GLOMAP are able to\nestimate high-precision camera poses, but suffer from poor scalability when the\nnumber of matched keypoint pairs becomes large. We identify two key factors\nleading to this problem: poor parallelization and computationally expensive\noptimization steps. To overcome these issues, we design an SfM framework that\nrelies entirely on GPU-friendly operations, making it easily parallelizable.\nMoreover, each optimization step runs in time linear to the number of image\npairs, independent of keypoint pairs or 3D points. Through extensive\nexperiments, we show that FastMap is faster than COLMAP and GLOMAP on\nlarge-scale scenes with comparable pose accuracy."}
{"id": "2505.13708", "pdf": "https://arxiv.org/pdf/2505.13708", "abs": "https://arxiv.org/abs/2505.13708", "authors": ["Jane Lange", "Arsen Vasilyan"], "title": "Robust learning of halfspaces under log-concave marginals", "categories": ["cs.DS", "cs.LG"], "comment": null, "summary": "We say that a classifier is \\emph{adversarially robust} to perturbations of\nnorm $r$ if, with high probability over a point $x$ drawn from the input\ndistribution, there is no point within distance $\\le r$ from $x$ that is\nclassified differently. The \\emph{boundary volume} is the probability that a\npoint falls within distance $r$ of a point with a different label. This work\nstudies the task of computationally efficient learning of hypotheses with small\nboundary volume, where the input is distributed as a subgaussian isotropic\nlog-concave distribution over $\\mathbb{R}^d$.\n  Linear threshold functions are adversarially robust; they have boundary\nvolume proportional to $r$. Such concept classes are efficiently learnable by\npolynomial regression, which produces a polynomial threshold function (PTF),\nbut PTFs in general may have boundary volume $\\Omega(1)$, even for $r \\ll 1$.\n  We give an algorithm that agnostically learns linear threshold functions and\nreturns a classifier with boundary volume $O(r+\\varepsilon)$ at radius of\nperturbation $r$. The time and sample complexity of\n$d^{\\tilde{O}(1/\\varepsilon^2)}$ matches the complexity of polynomial\nregression.\n  Our algorithm augments the classic approach of polynomial regression with\nthree additional steps: a) performing the $\\ell_1$-error regression under noise\nsensitivity constraints, b) a structured partitioning and rounding step that\nreturns a Boolean classifier with error $\\textsf{opt} + O(\\varepsilon)$ and\nnoise sensitivity $O(r+\\varepsilon)$ simultaneously, and c) a local corrector\nthat ``smooths'' a function with low noise sensitivity into a function that is\nadversarially robust."}
{"id": "2505.08451", "pdf": "https://arxiv.org/pdf/2505.08451", "abs": "https://arxiv.org/abs/2505.08451", "authors": ["Lotfi Kobrosly", "Marc-Emmanuel Coupvent des Graviers", "Christophe Guettier", "Tristan Cazenave"], "title": "Adaptive Bias Generalized Rollout Policy Adaptation on the Flexible Job-Shop Scheduling Problem", "categories": ["cs.AI"], "comment": "The 19th Learning and Intelligent OptimizatioN Conference, LION19\n  2025", "summary": "The Flexible Job-Shop Scheduling Problem (FJSSP) is an NP-hard combinatorial\noptimization problem, with several application domains, especially for\nmanufacturing purposes. The objective is to efficiently schedule multiple\noperations on dissimilar machines. These operations are gathered into jobs, and\noperations pertaining to the same job need to be scheduled sequentially.\nDifferent methods have been previously tested to solve this problem, such as\nConstraint Solving, Tabu Search, Genetic Algorithms, or Monte Carlo Tree Search\n(MCTS). We propose a novel algorithm derived from the Generalized Nested\nRollout Policy Adaptation, developed to solve the FJSSP. We report encouraging\nexperimental results, as our algorithm performs better than other MCTS-based\napproaches, even if makespans obtained on large instances are still far from\nknown upper bounds."}
{"id": "2410.03663", "pdf": "https://arxiv.org/pdf/2410.03663", "abs": "https://arxiv.org/abs/2410.03663", "authors": ["Zhuochun Li", "Yuelyu Ji", "Rui Meng", "Daqing He"], "title": "Learning from Committee: Reasoning Distillation from a Mixture of Teachers with Peer-Review", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 5 figures", "summary": "While reasoning capabilities typically emerge in large language models (LLMs)\nwith tens of billions of parameters, recent research focuses on improving\nsmaller open-source models through knowledge distillation (KD) from commercial\nLLMs. However, many of these studies rely solely on responses from a single LLM\nas the gold rationale, unlike the natural human learning process, which\ninvolves understanding both the correct answers and the reasons behind\nmistakes. In this paper, we introduce a novel Fault-Aware DistIllation via\nPeer-Review (FAIR) approach: 1) instead of merely obtaining rationales from\nteachers, our method asks teachers to identify and explain the student's\nmistakes, providing customized instruction learning data; 2) we design a\nsimulated peer-review process between teacher LLMs, and selects only the\ngenerated rationales above the acceptance threshold, which reduces the chance\nof teachers guessing correctly with flawed rationale, improving instructional\ndata quality. Comprehensive experiments and analysis on mathematical,\ncommonsense, and logical reasoning tasks demonstrate the effectiveness of our\nmethod. Our code is available at\nhttps://github.com/zhuochunli/Learn-from-Committee."}
{"id": "2505.09018", "pdf": "https://arxiv.org/pdf/2505.09018", "abs": "https://arxiv.org/abs/2505.09018", "authors": ["Adarsh Kumar"], "title": "Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction", "categories": ["cs.CV", "cs.LG"], "comment": "The manuscript was submitted without proper consideration of\n  institutional policies. Upon review with professor, it was found that the\n  content is subject to licensing restrictions which prohibit public\n  dissemination in its current form. Therefore, I am withdrawing the paper to\n  comply with these requirements", "summary": "Effective dietary monitoring is critical for managing Type 2 diabetes, yet\naccurately estimating caloric intake remains a major challenge. While\ncontinuous glucose monitors (CGMs) offer valuable physiological data, they\noften fall short in capturing the full nutritional profile of meals due to\ninter-individual and meal-specific variability. In this work, we introduce a\nmultimodal deep learning framework that jointly leverages CGM time-series data,\nDemographic/Microbiome, and pre-meal food images to enhance caloric estimation.\nOur model utilizes attention based encoding and a convolutional feature\nextraction for meal imagery, multi-layer perceptrons for CGM and Microbiome\ndata followed by a late fusion strategy for joint reasoning. We evaluate our\napproach on a curated dataset of over 40 participants, incorporating\nsynchronized CGM, Demographic and Microbiome data and meal photographs with\nstandardized caloric labels. Our model achieves a Root Mean Squared Relative\nError (RMSRE) of 0.2544, outperforming the baselines models by over 50%. These\nfindings demonstrate the potential of multimodal sensing to improve automated\ndietary assessment tools for chronic disease management."}
{"id": "2505.13732", "pdf": "https://arxiv.org/pdf/2505.13732", "abs": "https://arxiv.org/abs/2505.13732", "authors": ["Etienne Gauthier", "Francis Bach", "Michael I. Jordan"], "title": "Backward Conformal Prediction", "categories": ["stat.ML", "cs.LG"], "comment": "Code available at: https://github.com/GauthierE/backward-cp", "summary": "We introduce $\\textit{Backward Conformal Prediction}$, a method that\nguarantees conformal coverage while providing flexible control over the size of\nprediction sets. Unlike standard conformal prediction, which fixes the coverage\nlevel and allows the conformal set size to vary, our approach defines a rule\nthat constrains how prediction set sizes behave based on the observed data, and\nadapts the coverage level accordingly. Our method builds on two key\nfoundations: (i) recent results by Gauthier et al. [2025] on post-hoc validity\nusing e-values, which ensure marginal coverage of the form $\\mathbb{P}(Y_{\\rm\ntest} \\in \\hat C_n^{\\tilde{\\alpha}}(X_{\\rm test})) \\ge 1 -\n\\mathbb{E}[\\tilde{\\alpha}]$ up to a first-order Taylor approximation for any\ndata-dependent miscoverage $\\tilde{\\alpha}$, and (ii) a novel leave-one-out\nestimator $\\hat{\\alpha}^{\\rm LOO}$ of the marginal miscoverage\n$\\mathbb{E}[\\tilde{\\alpha}]$ based on the calibration set, ensuring that the\ntheoretical guarantees remain computable in practice. This approach is\nparticularly useful in applications where large prediction sets are impractical\nsuch as medical diagnosis. We provide theoretical results and empirical\nevidence supporting the validity of our method, demonstrating that it maintains\ncomputable coverage guarantees while ensuring interpretable, well-controlled\nprediction set sizes."}
{"id": "2505.10468", "pdf": "https://arxiv.org/pdf/2505.10468", "abs": "https://arxiv.org/abs/2505.10468", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges", "categories": ["cs.AI"], "comment": "33 pages, 14 figures, 11 tables", "summary": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications"}
{"id": "2410.10624", "pdf": "https://arxiv.org/pdf/2410.10624", "abs": "https://arxiv.org/abs/2410.10624", "authors": ["Zechen Li", "Shohreh Deldari", "Linyao Chen", "Hao Xue", "Flora D. Salim"], "title": "SensorLLM: Human-Intuitive Alignment of Multivariate Sensor Data with LLMs for Activity Recognition", "categories": ["cs.CL"], "comment": null, "summary": "We introduce SensorLLM, a two-stage framework that enables Large Language\nModels (LLMs) to perform human activity recognition (HAR) from wearable sensor\ndata. While LLMs excel at reasoning and generalization, they struggle with\ntime-series inputs due to limited semantic context, numerical complexity, and\nsequence variability. To address these challenges, we construct SensorQA, a\nquestion-answering dataset of human-intuitive sensor-text pairs spanning\ndiverse HAR scenarios. It supervises the Sensor-Language Alignment stage, where\nthe model aligns sensor inputs with trend descriptions. Special tokens are\nintroduced to mark channel boundaries. This alignment enables LLMs to interpret\nnumerical patterns, channel-specific signals, and variable-length\ninputs--without requiring human annotation. In the subsequent Task-Aware Tuning\nstage, we adapt the model for multivariate HAR classification, achieving\nperformance that matches or exceeds state-of-the-art methods. Our results show\nthat, guided by human-intuitive alignment, SensorLLM becomes an effective\nsensor learner, reasoner, and classifier--generalizing across varied HAR\nsettings and paving the way for foundation model research in time-series\nanalysis."}
{"id": "2505.10238", "pdf": "https://arxiv.org/pdf/2505.10238", "abs": "https://arxiv.org/abs/2505.10238", "authors": ["Yanbo Ding", "Xirui Hu", "Zhizhi Guo", "Yali Wang"], "title": "MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation", "categories": ["cs.CV"], "comment": null, "summary": "Human image animation has gained increasing attention and developed rapidly\ndue to its broad applications in digital humans. However, existing methods rely\nlargely on 2D-rendered pose images for motion guidance, which limits\ngeneralization and discards essential 3D information for open-world animation.\nTo tackle this problem, we propose MTVCrafter (Motion Tokenization Video\nCrafter), the first framework that directly models raw 3D motion sequences\n(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT\n(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.\nCompared to 2D-rendered pose images, 4D motion tokens offer more robust\nspatio-temporal cues and avoid strict pixel-level alignment between pose image\nand character, enabling more flexible and disentangled control. Then, we\nintroduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention\nwith 4D positional encodings, MV-DiT can effectively leverage motion tokens as\n4D compact yet expressive context for human image animation in the complex 3D\nworld. Hence, it marks a significant step forward in this field and opens a new\ndirection for pose-guided human video generation. Experiments show that our\nMTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,\nsurpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter\nalso generalizes well to diverse open-world characters (single/multiple,\nfull/half-body) across various styles and scenarios. Our video demos and code\nare on: https://github.com/DINGYANB/MTVCrafter."}
{"id": "2505.13864", "pdf": "https://arxiv.org/pdf/2505.13864", "abs": "https://arxiv.org/abs/2505.13864", "authors": ["Sevvandi Kandanaarachchi", "Cheng Soon Ong"], "title": "Graphon Mixtures", "categories": ["stat.ML", "cs.DM", "cs.LG"], "comment": null, "summary": "Social networks have a small number of large hubs, and a large number of\nsmall dense communities. We propose a generative model that captures both hub\nand dense structures. Based on recent results about graphons on line graphs,\nour model is a graphon mixture, enabling us to generate sequences of graphs\nwhere each graph is a combination of sparse and dense graphs. We propose a new\ncondition on sparse graphs (the max-degree), which enables us to identify hubs.\nWe show theoretically that we can estimate the normalized degree of the hubs,\nas well as estimate the graphon corresponding to sparse components of graph\nmixtures. We illustrate our approach on synthetic data, citation graphs, and\nsocial networks, showing the benefits of explicitly modeling sparse graphs."}
{"id": "2505.10991", "pdf": "https://arxiv.org/pdf/2505.10991", "abs": "https://arxiv.org/abs/2505.10991", "authors": ["Yacine Izza", "Alexey Ignatiev", "Sasha Rubin", "Joao Marques-Silva", "Peter J. Stuckey"], "title": "Most General Explanations of Tree Ensembles (Extended Version)", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "Explainable Artificial Intelligence (XAI) is critical for attaining trust in\nthe operation of AI systems. A key question of an AI system is ``why was this\ndecision made this way''. Formal approaches to XAI use a formal model of the AI\nsystem to identify abductive explanations. While abductive explanations may be\napplicable to a large number of inputs sharing the same concrete values, more\ngeneral explanations may be preferred for numeric inputs. So-called inflated\nabductive explanations give intervals for each feature ensuring that any input\nwhose values fall withing these intervals is still guaranteed to make the same\nprediction. Inflated explanations cover a larger portion of the input space,\nand hence are deemed more general explanations. But there can be many\n(inflated) abductive explanations for an instance. Which is the best? In this\npaper, we show how to find a most general abductive explanation for an AI\ndecision. This explanation covers as much of the input space as possible, while\nstill being a correct formal explanation of the model's behaviour. Given that\nwe only want to give a human one explanation for a decision, the most general\nexplanation gives us the explanation with the broadest applicability, and hence\nthe one most likely to seem sensible. (The paper has been accepted at IJCAI2025\nconference.)"}
{"id": "2410.11348", "pdf": "https://arxiv.org/pdf/2410.11348", "abs": "https://arxiv.org/abs/2410.11348", "authors": ["David Reber", "Sean Richardson", "Todd Nief", "Cristina Garbacea", "Victor Veitch"], "title": "RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals", "categories": ["cs.CL", "cs.AI"], "comment": "ICML 2025. Code at https://github.com/toddnief/RATE", "summary": "Reward models are widely used as proxies for human preferences when aligning\nor evaluating LLMs. However, reward models are black boxes, and it is often\nunclear what, exactly, they are actually rewarding. In this paper we develop\nRewrite-based Attribute Treatment Estimator (RATE) as an effective method for\nmeasuring the sensitivity of a reward model to high-level attributes of\nresponses, such as sentiment, helpfulness, or complexity. Importantly, RATE\nmeasures the causal effect of an attribute on the reward. RATE uses LLMs to\nrewrite responses to produce imperfect counterfactuals examples that can be\nused to measure causal effects. A key challenge is that these rewrites are\nimperfect in a manner that can induce substantial bias in the estimated\nsensitivity of the reward model to the attribute. The core idea of RATE is to\nadjust for this imperfect-rewrite effect by rewriting twice. We establish the\nvalidity of the RATE procedure and show empirically that it is an effective\nestimator."}
{"id": "2505.10634", "pdf": "https://arxiv.org/pdf/2505.10634", "abs": "https://arxiv.org/abs/2505.10634", "authors": ["Jianfei Zhao", "Feng Zhang", "Xin Sun", "Chong Feng"], "title": "Cross-Image Contrastive Decoding: Precise, Lossless Suppression of Language Priors in Large Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Language priors are a major cause of hallucinations in Large Vision-Language\nModels (LVLMs), often leading to text that is linguistically plausible but\nvisually inconsistent. Recent work explores contrastive decoding as a\ntraining-free solution, but these methods typically construct negative contexts\nfrom the original image, resulting in visual information loss and distorted\ndistribution. Motivated by the observation that language priors stem from the\nLLM backbone and remain consistent across images, we propose Cross-Images\nContrastive Decoding (CICD), a simple yet effective training-free method that\nuses different images to construct negative contexts. We further analyze the\ncross-image behavior of language priors and introduce a distinction between\nessential priors (supporting fluency) and detrimental priors (causing\nhallucinations). By selectively preserving essential priors and suppressing\ndetrimental ones, our method reduces hallucinations while maintaining coherent\nand fluent language generation. Experiments on 4 benchmarks and 6 LVLMs across\nthree model families confirm the effectiveness and generalizability of CICD,\nespecially in image captioning, where language priors are particularly\npronounced. Code will be released once accepted."}
{"id": "2505.13881", "pdf": "https://arxiv.org/pdf/2505.13881", "abs": "https://arxiv.org/abs/2505.13881", "authors": ["Jiahao Yu", "Haozhuang Liu", "Yeqiu Yang", "Lu Chen", "Wu Jian", "Yuning Jiang", "Bo Zheng"], "title": "TranSUN: A Preemptive Paradigm to Eradicate Retransformation Bias Intrinsically from Regression Models in Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": "22 pages, 6 figures", "summary": "Regression models are crucial in recommender systems. However,\nretransformation bias problem has been conspicuously neglected within the\ncommunity. While many works in other fields have devised effective bias\ncorrection methods, all of them are post-hoc cures externally to the model,\nfacing practical challenges when applied to real-world recommender systems.\nHence, we propose a preemptive paradigm to eradicate the bias intrinsically\nfrom the models via minor model refinement. Specifically, a novel TranSUN\nmethod is proposed with a joint bias learning manner to offer theoretically\nguaranteed unbiasedness under empirical superior convergence. It is further\ngeneralized into a novel generic regression model family, termed Generalized\nTranSUN (GTS), which not only offers more theoretical insights but also serves\nas a generic framework for flexibly developing various bias-free models.\nComprehensive experimental results demonstrate the superiority of our methods\nacross data from various domains, which have been successfully deployed in two\nreal-world industrial recommendation scenarios, i.e. product and short video\nrecommendation scenarios in Guess What You Like business domain in the homepage\nof Taobao App (a leading e-commerce platform), to serve the major online\ntraffic. Codes will be released after this paper is published."}
{"id": "2505.12355", "pdf": "https://arxiv.org/pdf/2505.12355", "abs": "https://arxiv.org/abs/2505.12355", "authors": ["Ya Shen", "Gang Chen", "Hui Ma", "Mengjie Zhang"], "title": "GATES: Cost-aware Dynamic Workflow Scheduling via Graph Attention Networks and Evolution Strategy", "categories": ["cs.AI"], "comment": "This paper has been accepted by the 34th International Joint\n  Conference on Artificial Intelligence (IJCAI-2025)", "summary": "Cost-aware Dynamic Workflow Scheduling (CADWS) is a key challenge in cloud\ncomputing, focusing on devising an effective scheduling policy to efficiently\nschedule dynamically arriving workflow tasks, represented as Directed Acyclic\nGraphs (DAG), to suitable virtual machines (VMs). Deep reinforcement learning\n(DRL) has been widely employed for automated scheduling policy design. However,\nthe performance of DRL is heavily influenced by the design of the\nproblem-tailored policy network and is highly sensitive to hyperparameters and\nthe design of reward feedback. Considering the above-mentioned issues, this\nstudy proposes a novel DRL method combining Graph Attention Networks-based\npolicy network and Evolution Strategy, referred to as GATES. The contributions\nof GATES are summarized as follows: (1) GATES can capture the impact of current\ntask scheduling on subsequent tasks by learning the topological relationships\nbetween tasks in a DAG. (2) GATES can assess the importance of each VM to the\nready task, enabling it to adapt to dynamically changing VM resources. (3)\nUtilizing Evolution Strategy's robustness, exploratory nature, and tolerance\nfor delayed rewards, GATES achieves stable policy learning in CADWS. Extensive\nexperimental results demonstrate the superiority of the proposed GATES in\nCADWS, outperforming several state-of-the-art algorithms. The source code is\navailable at: https://github.com/YaShen998/GATES."}
{"id": "2410.12924", "pdf": "https://arxiv.org/pdf/2410.12924", "abs": "https://arxiv.org/abs/2410.12924", "authors": ["Nura Aljaafari", "Danilo S. Carvalho", "Andr√© Freitas"], "title": "Interpreting token compositionality in LLMs: A robustness analysis", "categories": ["cs.CL"], "comment": "23 pages, 3 Figures, 14 tables", "summary": "Understanding the internal mechanisms of large language models (LLMs) is\nintegral to enhancing their reliability, interpretability, and inference\nprocesses. We present Constituent-Aware Pooling (CAP), a methodology designed\nto analyse how LLMs process compositional linguistic structures. Grounded in\nprinciples of compositionality, mechanistic interpretability, and information\ntheory, CAP systematically intervenes in model activations through\nconstituent-based pooling at various model levels. Our experiments on inverse\ndefinition modelling, hypernym and synonym prediction reveal critical insights\ninto transformers' limitations in handling compositional abstractions. No\nspecific layer integrates tokens into unified semantic representations based on\ntheir constituent parts. We observe fragmented information processing, which\nintensifies with model size, suggesting that larger models struggle more with\nthese interventions and exhibit greater information dispersion. This\nfragmentation likely stems from transformers' training objectives and\narchitectural design, preventing systematic and cohesive representations. Our\nfindings highlight fundamental limitations in current transformer architectures\nregarding compositional semantics processing and model interpretability,\nunderscoring the critical need for novel approaches in LLM design to address\nthese challenges."}
{"id": "2505.11192", "pdf": "https://arxiv.org/pdf/2505.11192", "abs": "https://arxiv.org/abs/2505.11192", "authors": ["Myunsoo Kim", "Seong-Woong Shim", "Byung-Jun Lee"], "title": "FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Pretraining", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "False negatives pose a critical challenge in vision-language pretraining\n(VLP) due to the many-to-many correspondence between images and texts in\nlarge-scale datasets. These false negatives introduce conflicting supervision\nsignals that degrade the learned embedding space and diminish the effectiveness\nof hard negative sampling. In this paper, we propose FALCON (False-negative\nAware Learning of COntrastive Negatives), a learning-based mini-batch\nconstruction strategy that adaptively balances the trade-off between hard and\nfalse negatives during VLP. Rather than relying on fixed heuristics, FALCON\nemploys a negative mining scheduler that dynamically selects negative samples\nof appropriate hardness for each anchor instance during mini-batch\nconstruction, guided by a proxy for cross-modal alignment improvement.\nExperimental results demonstrate that FALCON significantly improves performance\nacross two widely adopted VLP frameworks (ALBEF, BLIP-2) and a broad range of\ndownstream tasks and evaluation settings, underscoring its effectiveness and\nrobustness in mitigating the impact of false negatives."}
{"id": "2505.13889", "pdf": "https://arxiv.org/pdf/2505.13889", "abs": "https://arxiv.org/abs/2505.13889", "authors": ["Yiting Zhang", "Shichen Li"], "title": "Certifiably Safe Manipulation of Deformable Linear Objects via Joint Shape and Tension Prediction", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted to ICRA 2025 Workshop on Learning Meets Model-Based Methods\n  for Contact-Rich Manipulation", "summary": "Manipulating deformable linear objects (DLOs) is challenging due to their\ncomplex dynamics and the need for safe interaction in contact-rich\nenvironments. Most existing models focus on shape prediction alone and fail to\naccount for contact and tension constraints, which can lead to damage to both\nthe DLO and the robot. In this work, we propose a certifiably safe motion\nplanning and control framework for DLO manipulation. At the core of our method\nis a predictive model that jointly estimates the DLO's future shape and\ntension. These predictions are integrated into a real-time trajectory optimizer\nbased on polynomial zonotopes, allowing us to enforce safety constraints\nthroughout the execution. We evaluate our framework on a simulated wire harness\nassembly task using a 7-DOF robotic arm. Compared to state-of-the-art methods,\nour approach achieves a higher task success rate while avoiding all safety\nviolations. The results demonstrate that our method enables robust and safe DLO\nmanipulation in contact-rich environments."}
{"id": "2505.13126", "pdf": "https://arxiv.org/pdf/2505.13126", "abs": "https://arxiv.org/abs/2505.13126", "authors": ["Liancheng Gong", "Wang Zhu", "Jesse Thomason", "Li Zhang"], "title": "Zero-Shot Iterative Formalization and Planning in Partially Observable Environments", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Using LLMs not to predict plans but to formalize an environment into the\nPlanning Domain Definition Language (PDDL) has been shown to improve\nperformance and control. Existing work focuses on fully observable\nenvironments; we tackle the more realistic and challenging partially observable\nenvironments that lack of complete, reliable information. We propose PDDLego+,\na framework to iteratively formalize, plan, grow, and refine PDDL\nrepresentations in a zero-shot manner, without needing access to any existing\ntrajectories. On two textual simulated environments, we show that PDDLego+\nimproves goal reaching success and exhibits robustness against problem\ncomplexity. We also show that the domain knowledge captured after a successful\ntrial can benefit future tasks."}
{"id": "2410.13779", "pdf": "https://arxiv.org/pdf/2410.13779", "abs": "https://arxiv.org/abs/2410.13779", "authors": ["Arvid Frydenlund"], "title": "The Mystery of the Pathological Path-star Task for Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "EMNLP 2024 Main at https://aclanthology.org/2024.emnlp-main.695/ See\n  'Language Models, Graph Searching, and Supervision Adulteration: When More\n  Supervision is Less and How to Make More More' for a follow-up work", "summary": "The recently introduced path-star task is a minimal task designed to\nexemplify limitations to the abilities of language models (Bachmann and\nNagarajan, 2024). It involves a path-star graph where multiple arms radiate\nfrom a single starting node and each node is unique. Given the start node and a\nspecified target node that ends an arm, the task is to generate the arm\ncontaining that target node. This is straightforward for a human but\nsurprisingly difficult for language models, which did not outperform the random\nbaseline. The authors hypothesized this is due to a deficiency in\nteacher-forcing and the next-token prediction paradigm.\n  We demonstrate the task is learnable using teacher-forcing in alternative\nsettings and that the issue is partially due to representation. We introduce a\nregularization method using structured samples of the same graph but with\ndiffering target nodes, improving results across a variety of model types. We\nprovide RASP proofs showing the task is theoretically solvable. Finally, we\nfind settings where an encoder-only model can consistently solve the task."}
{"id": "2505.11983", "pdf": "https://arxiv.org/pdf/2505.11983", "abs": "https://arxiv.org/abs/2505.11983", "authors": ["Ting Xiao", "Lei Shi", "Yang Zhang", "HaoFeng Yang", "Zhe Wang", "Chenjia Bai"], "title": "Online Iterative Self-Alignment for Radiology Report Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ACL 2025 Main", "summary": "Radiology Report Generation (RRG) is an important research topic for\nrelieving radiologist' heavy workload. Existing RRG models mainly rely on\nsupervised fine-tuning (SFT) based on different model architectures using data\npairs of radiological images and corresponding radiologist-annotated reports.\nRecent research has shifted focus to post-training improvements, aligning RRG\nmodel outputs with human preferences using reinforcement learning (RL).\nHowever, the limited data coverage of high-quality annotated data poses risks\nof overfitting and generalization. This paper proposes a novel Online Iterative\nSelf-Alignment (OISA) method for RRG that consists of four stages:\nself-generation of diverse data, self-evaluation for multi-objective preference\ndata,self-alignment for multi-objective optimization and self-iteration for\nfurther improvement. Our approach allows for generating varied reports tailored\nto specific clinical objectives, enhancing the overall performance of the RRG\nmodel iteratively. Unlike existing methods, our frame-work significantly\nincreases data quality and optimizes performance through iterative\nmulti-objective optimization. Experimental results demonstrate that our method\nsurpasses previous approaches, achieving state-of-the-art performance across\nmultiple evaluation metrics."}
{"id": "2505.13902", "pdf": "https://arxiv.org/pdf/2505.13902", "abs": "https://arxiv.org/abs/2505.13902", "authors": ["Naoki Hayashi", "Takuro Kutsuna", "Sawa Takamuku"], "title": "An Asymptotic Equation Linking WAIC and WBIC in Singular Models", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62F15, 62R01"], "comment": "14pages, to be submitted to ICONIP2025", "summary": "In statistical learning, models are classified as regular or singular\ndepending on whether the mapping from parameters to probability distributions\nis injective. Most models with hierarchical structures or latent variables are\nsingular, for which conventional criteria such as the Akaike Information\nCriterion and the Bayesian Information Criterion are inapplicable due to the\nbreakdown of normal approximations for the likelihood and posterior. To address\nthis, the Widely Applicable Information Criterion (WAIC) and the Widely\nApplicable Bayesian Information Criterion (WBIC) have been proposed. Since WAIC\nand WBIC are computed using posterior distributions at different temperature\nsettings, separate posterior sampling is generally required. In this paper, we\ntheoretically derive an asymptotic equation that links WAIC and WBIC, despite\ntheir dependence on different posteriors. This equation yields an\nasymptotically unbiased expression of WAIC in terms of the posterior\ndistribution used for WBIC. The result clarifies the structural relationship\nbetween these criteria within the framework of singular learning theory, and\ndeepens understanding of their asymptotic behavior. This theoretical\ncontribution provides a foundation for future developments in the computational\nefficiency of model selection in singular models."}
{"id": "2505.13232", "pdf": "https://arxiv.org/pdf/2505.13232", "abs": "https://arxiv.org/abs/2505.13232", "authors": ["Younghyun Kim", "Jongheon Jeong", "Sangkyung Kwak", "Kyungmin Lee", "Juho Lee", "Jinwoo Shin"], "title": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment", "categories": ["cs.AI", "cs.CV"], "comment": "IJCAI 2025; Code is available at https://github.com/alinlab/StarFT", "summary": "Learning robust representations from data often requires scale, which has led\nto the success of recent zero-shot models such as CLIP. However, the obtained\nrobustness can easily be deteriorated when these models are fine-tuned on other\ndownstream tasks (e.g., of smaller scales). Previous works often interpret this\nphenomenon in the context of domain shift, developing fine-tuning methods that\naim to preserve the original domain as much as possible. However, in a\ndifferent context, fine-tuned models with limited data are also prone to\nlearning features that are spurious to humans, such as background or texture.\nIn this paper, we propose StarFT (Spurious Textual Alignment Regularization), a\nnovel framework for fine-tuning zero-shot models to enhance robustness by\npreventing them from learning spuriosity. We introduce a regularization that\naligns the output distribution for spuriosity-injected labels with the original\nzero-shot model, ensuring that the model is not induced to extract irrelevant\nfeatures further from these descriptions. We leverage recent language models to\nget such spuriosity-injected labels by generating alternative textual\ndescriptions that highlight potentially confounding features. Extensive\nexperiments validate the robust generalization of StarFT and its emerging\nproperties: zero-shot group robustness and improved zero-shot classification.\nNotably, StarFT boosts both worst-group and average accuracy by 14.30% and\n3.02%, respectively, in the Waterbirds group shift scenario, where other robust\nfine-tuning baselines show even degraded performance."}
{"id": "2410.14425", "pdf": "https://arxiv.org/pdf/2410.14425", "abs": "https://arxiv.org/abs/2410.14425", "authors": ["Shuai Zhao", "Xiaobao Wu", "Cong-Duy Nguyen", "Yanhao Jia", "Meihuizi Jia", "Yichao Feng", "Luu Anh Tuan"], "title": "Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) can bridge the gap between large\nlanguage models (LLMs) and downstream tasks. However, PEFT has been proven\nvulnerable to malicious attacks. Research indicates that poisoned LLMs, even\nafter PEFT, retain the capability to activate internalized backdoors when input\nsamples contain predefined triggers. In this paper, we introduce a novel\nweak-to-strong unlearning algorithm to defend against backdoor attacks based on\nfeature alignment knowledge distillation, named W2SDefense. Specifically, we\nfirst train a small-scale language model through full-parameter fine-tuning to\nserve as the clean teacher model. Then, this teacher model guides the\nlarge-scale poisoned student model in unlearning the backdoor, leveraging PEFT.\nTheoretical analysis suggests that W2SDefense has the potential to enhance the\nstudent model's ability to unlearn backdoor features, preventing the activation\nof the backdoor. We conduct comprehensive experiments on three state-of-the-art\nlarge language models and several different backdoor attack algorithms. Our\nempirical results demonstrate the outstanding performance of W2SDefense in\ndefending against backdoor attacks without compromising model performance."}
{"id": "2505.11997", "pdf": "https://arxiv.org/pdf/2505.11997", "abs": "https://arxiv.org/abs/2505.11997", "authors": ["Mingcheng Qu", "Guang Yang", "Donglin Di", "Tonghua Su", "Yue Gao", "Yang Song", "Lei Fan"], "title": "Multimodal Cancer Survival Analysis via Hypergraph Learning with Cross-Modality Rebalance", "categories": ["cs.CV"], "comment": "accepted by IJCAI2025 Code: https://github.com/MCPathology/MRePath", "summary": "Multimodal pathology-genomic analysis has become increasingly prominent in\ncancer survival prediction. However, existing studies mainly utilize\nmulti-instance learning to aggregate patch-level features, neglecting the\ninformation loss of contextual and hierarchical details within pathology\nimages. Furthermore, the disparity in data granularity and dimensionality\nbetween pathology and genomics leads to a significant modality imbalance. The\nhigh spatial resolution inherent in pathology data renders it a dominant role\nwhile overshadowing genomics in multimodal integration. In this paper, we\npropose a multimodal survival prediction framework that incorporates hypergraph\nlearning to effectively capture both contextual and hierarchical details from\npathology images. Moreover, it employs a modality rebalance mechanism and an\ninteractive alignment fusion strategy to dynamically reweight the contributions\nof the two modalities, thereby mitigating the pathology-genomics imbalance.\nQuantitative and qualitative experiments are conducted on five TCGA datasets,\ndemonstrating that our model outperforms advanced methods by over 3.4\\% in\nC-Index performance."}
{"id": "2505.13925", "pdf": "https://arxiv.org/pdf/2505.13925", "abs": "https://arxiv.org/abs/2505.13925", "authors": ["Yunpeng Jiang", "Jianshu Hu", "Paul Weng", "Yutong Ban"], "title": "Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Symmetry is pervasive in robotics and has been widely exploited to improve\nsample efficiency in deep reinforcement learning (DRL). However, existing\napproaches primarily focus on spatial symmetries, such as reflection, rotation,\nand translation, while largely neglecting temporal symmetries. To address this\ngap, we explore time reversal symmetry, a form of temporal symmetry commonly\nfound in robotics tasks such as door opening and closing. We propose Time\nReversal symmetry enhanced Deep Reinforcement Learning (TR-DRL), a framework\nthat combines trajectory reversal augmentation and time reversal guided reward\nshaping to efficiently solve temporally symmetric tasks. Our method generates\nreversed transitions from fully reversible transitions, identified by a\nproposed dynamics-consistent filter, to augment the training data. For\npartially reversible transitions, we apply reward shaping to guide learning,\naccording to successful trajectories from the reversed task. Extensive\nexperiments on the Robosuite and MetaWorld benchmarks demonstrate that TR-DRL\nis effective in both single-task and multi-task settings, achieving higher\nsample efficiency and stronger final performance compared to baseline methods."}
{"id": "2305.04095", "pdf": "https://arxiv.org/pdf/2305.04095", "abs": "https://arxiv.org/abs/2305.04095", "authors": ["Hanchi Ren", "Jingjing Deng", "Xianghua Xie", "Xiaoke Ma", "Jianfeng Ma"], "title": "Gradient Leakage Defense with Key-Lock Module for Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "The source code can be found at https://github.com/Rand2AI/FedKL", "summary": "Federated Learning (FL) is a widely adopted privacy-preserving machine\nlearning approach where private data remains local, enabling secure\ncomputations and the exchange of local model gradients between local clients\nand third-party parameter servers. However, recent findings reveal that privacy\nmay be compromised and sensitive information potentially recovered from shared\ngradients. In this study, we offer detailed analysis and a novel perspective on\nunderstanding the gradient leakage problem. These theoretical works lead to a\nnew gradient leakage defense technique that secures arbitrary model\narchitectures using a private key-lock module. Only the locked gradient is\ntransmitted to the parameter server for global model aggregation. Our proposed\nlearning method is resistant to gradient leakage attacks, and the key-lock\nmodule is designed and trained to ensure that, without the private information\nof the key-lock module: a) reconstructing private training data from the shared\ngradient is infeasible; and b) the global model's inference performance is\nsignificantly compromised. We discuss the theoretical underpinnings of why\ngradients can leak private information and provide theoretical proof of our\nmethod's effectiveness. We conducted extensive empirical evaluations with many\nmodels on several popular benchmarks, demonstrating the robustness of our\nproposed approach in both maintaining model performance and defending against\ngradient leakage attacks."}
{"id": "2410.15522", "pdf": "https://arxiv.org/pdf/2410.15522", "abs": "https://arxiv.org/abs/2410.15522", "authors": ["Srishti Gureja", "Lester James V. Miranda", "Shayekh Bin Islam", "Rishabh Maheshwary", "Drishti Sharma", "Gusti Winata", "Nathan Lambert", "Sebastian Ruder", "Sara Hooker", "Marzieh Fadaee"], "title": "M-RewardBench: Evaluating Reward Models in Multilingual Settings", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "16 pages, 6 figures, 10 tables. Website:\n  https://m-rewardbench.github.io/ , Updated results with latest models. Added\n  more author information", "summary": "Reward models (RMs) have driven the state-of-the-art performance of LLMs\ntoday by enabling the integration of human feedback into the language modeling\nprocess. However, RMs are primarily trained and evaluated in English, and their\ncapabilities in multilingual settings remain largely understudied. In this\nwork, we conduct a systematic evaluation of several reward models in\nmultilingual settings. We first construct the first-of-its-kind multilingual RM\nevaluation benchmark, M-RewardBench, consisting of 2.87k preference instances\nfor 23 typologically diverse languages, that tests the chat, safety, reasoning,\nand translation capabilities of RMs. We then rigorously evaluate a wide range\nof reward models on M-RewardBench, offering fresh insights into their\nperformance across diverse languages. We identify a significant gap in RMs'\nperformances between English and non-English languages and show that RM\npreferences can change substantially from one language to another. We also\npresent several findings on how different multilingual aspects impact RM\nperformance. Specifically, we show that the performance of RMs is improved with\nimproved translation quality. Similarly, we demonstrate that the models exhibit\nbetter performance for high-resource languages. We release M-RewardBench\ndataset and the codebase in this study to facilitate a better understanding of\nRM evaluation in multilingual settings."}
{"id": "2505.12007", "pdf": "https://arxiv.org/pdf/2505.12007", "abs": "https://arxiv.org/abs/2505.12007", "authors": ["Runduo Han", "Xiuping Liu", "Shangxuan Yi", "Yi Zhang", "Hongchen Tan"], "title": "Multi-modal Collaborative Optimization and Expansion Network for Event-assisted Single-eye Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we proposed a Multi-modal Collaborative Optimization and\nExpansion Network (MCO-E Net), to use event modalities to resist challenges\nsuch as low light, high exposure, and high dynamic range in single-eye\nexpression recognition tasks. The MCO-E Net introduces two innovative designs:\nMulti-modal Collaborative Optimization Mamba (MCO-Mamba) and Heterogeneous\nCollaborative and Expansion Mixture-of-Experts (HCE-MoE). MCO-Mamba, building\nupon Mamba, leverages dual-modal information to jointly optimize the model,\nfacilitating collaborative interaction and fusion of modal semantics. This\napproach encourages the model to balance the learning of both modalities and\nharness their respective strengths. HCE-MoE, on the other hand, employs a\ndynamic routing mechanism to distribute structurally varied experts (deep,\nattention, and focal), fostering collaborative learning of complementary\nsemantics. This heterogeneous architecture systematically integrates diverse\nfeature extraction paradigms to comprehensively capture expression semantics.\nExtensive experiments demonstrate that our proposed network achieves\ncompetitive performance in the task of single-eye expression recognition,\nespecially under poor lighting conditions."}
{"id": "2505.13947", "pdf": "https://arxiv.org/pdf/2505.13947", "abs": "https://arxiv.org/abs/2505.13947", "authors": ["Shirong Xu", "Hengzhi He", "Guang Cheng"], "title": "A Probabilistic Perspective on Model Collapse", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In recent years, model collapse has become a critical issue in language model\ntraining, making it essential to understand the underlying mechanisms driving\nthis phenomenon. In this paper, we investigate recursive parametric model\ntraining from a probabilistic perspective, aiming to characterize the\nconditions under which model collapse occurs and, crucially, how it can be\nmitigated. We conceptualize the recursive training process as a random walk of\nthe model estimate, highlighting how the sample size influences the step size\nand how the estimation procedure determines the direction and potential bias of\nthe random walk. Under mild conditions, we rigorously show that progressively\nincreasing the sample size at each training step is necessary to prevent model\ncollapse. In particular, when the estimation is unbiased, the required growth\nrate follows a superlinear pattern. This rate needs to be accelerated even\nfurther in the presence of substantial estimation bias. Building on this\nprobabilistic framework, we also investigate the probability that recursive\ntraining on synthetic data yields models that outperform those trained solely\non real data. Moreover, we extend these results to general parametric model\nfamily in an asymptotic regime. Finally, we validate our theoretical results\nthrough extensive simulations and a real-world dataset."}
{"id": "2401.05502", "pdf": "https://arxiv.org/pdf/2401.05502", "abs": "https://arxiv.org/abs/2401.05502", "authors": ["Suhas Thejaswi", "Ameet Gadekar", "Bruno Ordozgoiti", "Aristides Gionis"], "title": "Diversity-aware clustering: Computational Complexity and Approximation Algorithms", "categories": ["cs.DS", "cs.AI", "cs.CC", "cs.LG"], "comment": "Algorithmic Fairness, Fair Clustering, Diversity-aware Clustering,\n  Intersectionaly, Subgroup fairness", "summary": "In this work, we study diversity-aware clustering problems where the data\npoints are associated with multiple attributes resulting in intersecting\ngroups. A clustering solution needs to ensure that the number of chosen cluster\ncenters from each group should be within the range defined by a lower and upper\nbound threshold for each group, while simultaneously minimizing the clustering\nobjective, which can be either $k$-median, $k$-means or $k$-supplier. We study\nthe computational complexity of the proposed problems, offering insights into\ntheir NP-hardness, polynomial-time inapproximability, and fixed-parameter\nintractability. We present parameterized approximation algorithms with\napproximation ratios $1+ \\frac{2}{e} + \\epsilon \\approx 1.736$, $1+\\frac{8}{e}\n+ \\epsilon \\approx 3.943$, and $5$ for diversity-aware $k$-median,\ndiversity-aware $k$-means and diversity-aware $k$-supplier, respectively.\nAssuming Gap-ETH, the approximation ratios are tight for the diversity-aware\n$k$-median and diversity-aware $k$-means problems. Our results imply the same\napproximation factors for their respective fair variants with disjoint groups\n-- fair $k$-median, fair $k$-means, and fair $k$-supplier -- with lower bound\nrequirements."}
{"id": "2410.21272", "pdf": "https://arxiv.org/pdf/2410.21272", "abs": "https://arxiv.org/abs/2410.21272", "authors": ["Yaniv Nikankin", "Anja Reusch", "Aaron Mueller", "Yonatan Belinkov"], "title": "Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics", "categories": ["cs.CL", "68T5", "I.2.7"], "comment": null, "summary": "Do large language models (LLMs) solve reasoning tasks by learning robust\ngeneralizable algorithms, or do they memorize training data? To investigate\nthis question, we use arithmetic reasoning as a representative task. Using\ncausal analysis, we identify a subset of the model (a circuit) that explains\nmost of the model's behavior for basic arithmetic logic and examine its\nfunctionality. By zooming in on the level of individual circuit neurons, we\ndiscover a sparse set of important neurons that implement simple heuristics.\nEach heuristic identifies a numerical input pattern and outputs corresponding\nanswers. We hypothesize that the combination of these heuristic neurons is the\nmechanism used to produce correct arithmetic answers. To test this, we\ncategorize each neuron into several heuristic types-such as neurons that\nactivate when an operand falls within a certain range-and find that the\nunordered combination of these heuristic types is the mechanism that explains\nmost of the model's accuracy on arithmetic prompts. Finally, we demonstrate\nthat this mechanism appears as the main source of arithmetic accuracy early in\ntraining. Overall, our experimental results across several LLMs show that LLMs\nperform arithmetic using neither robust algorithms nor memorization; rather,\nthey rely on a \"bag of heuristics\"."}
{"id": "2505.12200", "pdf": "https://arxiv.org/pdf/2505.12200", "abs": "https://arxiv.org/abs/2505.12200", "authors": ["Bohan Jia", "Wenxuan Huang", "Yuntian Tang", "Junbo Qiao", "Jincheng Liao", "Shaosheng Cao", "Fei Zhao", "Zhaopeng Feng", "Zhouhong Gu", "Zhenfei Yin", "Lei Bai", "Wanli Ouyang", "Lin Chen", "Fei Zhao", "Zihan Wang", "Yuan Xie", "Shaohui Lin"], "title": "CompBench: Benchmarking Complex Instruction-guided Image Editing", "categories": ["cs.CV"], "comment": null, "summary": "While real-world applications increasingly demand intricate scene\nmanipulation, existing instruction-guided image editing benchmarks often\noversimplify task complexity and lack comprehensive, fine-grained instructions.\nTo bridge this gap, we introduce, a large-scale benchmark specifically designed\nfor complex instruction-guided image editing. CompBench features challenging\nediting scenarios that incorporate fine-grained instruction following, spatial\nand contextual reasoning, thereby enabling comprehensive evaluation of image\nediting models' precise manipulation capabilities. To construct CompBench, We\npropose an MLLM-human collaborative framework with tailored task pipelines.\nFurthermore, we propose an instruction decoupling strategy that disentangles\nediting intents into four key dimensions: location, appearance, dynamics, and\nobjects, ensuring closer alignment between instructions and complex editing\nrequirements. Extensive evaluations reveal that CompBench exposes fundamental\nlimitations of current image editing models and provides critical insights for\nthe development of next-generation instruction-guided image editing systems.\nThe dataset, code, and models are available in https://comp-bench.github.io/."}
{"id": "2505.14016", "pdf": "https://arxiv.org/pdf/2505.14016", "abs": "https://arxiv.org/abs/2505.14016", "authors": ["Shunjing Zhao", "Xian Shi", "Hanlun Lei"], "title": "ThermoONet -- a deep learning-based small body thermophysical network: applications to modelling water activity of comets", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": "accepted for publication in A&A", "summary": "Cometary activity is a compelling subject of study, with thermophysical\nmodels playing a pivotal role in its understanding. However, traditional\nnumerical solutions for small body thermophysical models are computationally\nintensive, posing challenges for investigations requiring high-resolution or\nrepetitive modeling. To address this limitation, we employed a machine learning\napproach to develop ThermoONet - a neural network designed to predict the\ntemperature and water ice sublimation flux of comets. Performance evaluations\nindicate that ThermoONet achieves a low average error in subsurface temperature\nof approximately 2% relative to the numerical simulation, while reducing\ncomputational time by nearly six orders of magnitude. We applied ThermoONet to\nmodel the water activity of comets 67P/Churyumov-Gerasimenko and\n21P/Giacobini-Zinner. By successfully fitting the water production rate curves\nof these comets, as obtained by the Rosetta mission and the SOHO telescope,\nrespectively, we demonstrate the network's effectiveness and efficiency.\nFurthermore, when combined with a global optimization algorithm, ThermoONet\nproves capable of retrieving the physical properties of target bodies."}
{"id": "2402.04059", "pdf": "https://arxiv.org/pdf/2402.04059", "abs": "https://arxiv.org/abs/2402.04059", "authors": ["Jun Wang", "Wenjie Du", "Yiyuan Yang", "Linglong Qian", "Wei Cao", "Keli Zhang", "Wenjia Wang", "Yuxuan Liang", "Qingsong Wen"], "title": "Deep Learning for Multivariate Time Series Imputation: A Survey", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Missing values are ubiquitous in multivariate time series (MTS) data, posing\nsignificant challenges for accurate analysis and downstream applications. In\nrecent years, deep learning-based methods have successfully handled missing\ndata by leveraging complex temporal dependencies and learned data\ndistributions. In this survey, we provide a comprehensive summary of deep\nlearning approaches for multivariate time series imputation (MTSI) tasks. We\npropose a novel taxonomy that categorizes existing methods based on two key\nperspectives: imputation uncertainty and neural network architecture.\nFurthermore, we summarize existing MTSI toolkits with a particular emphasis on\nthe PyPOTS Ecosystem, which provides an integrated and standardized foundation\nfor MTSI research. Finally, we discuss key challenges and future research\ndirections, which give insight for further MTSI research. This survey aims to\nserve as a valuable resource for researchers and practitioners in the field of\ntime series analysis and missing data imputation tasks.A well-maintained MTSI\npaper and tool list are available at\nhttps://github.com/WenjieDu/Awesome_Imputation."}
{"id": "2411.02448", "pdf": "https://arxiv.org/pdf/2411.02448", "abs": "https://arxiv.org/abs/2411.02448", "authors": ["Aliyah R. Hsu", "James Zhu", "Zhichao Wang", "Bin Bi", "Shubham Mehrotra", "Shiva K. Pentyala", "Katherine Tan", "Xiang-Bo Mao", "Roshanak Omrani", "Sougata Chaudhuri", "Regunathan Radhakrishnan", "Sitaram Asur", "Claire Na Cheng", "Bin Yu"], "title": "Rate, Explain and Cite (REC): Enhanced Explanation and Attribution in Automatic Evaluation by Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "LLMs have demonstrated impressive proficiency in generating coherent and\nhigh-quality text, making them valuable across a range of text-generation\ntasks. However, rigorous evaluation of this generated content is crucial, as\nensuring its quality remains a significant challenge due to persistent issues\nsuch as factual inaccuracies and hallucination. This paper introduces three\nfine-tuned general-purpose LLM autoevaluators, REC-8B, REC-12B and REC-70B,\nspecifically designed to evaluate generated text across several dimensions:\nfaithfulness, instruction following, coherence, and completeness. These models\nnot only provide ratings for these metrics but also offer detailed explanation\nand verifiable citation, thereby enhancing trust in the content. Moreover, the\nmodels support various citation modes, accommodating different requirements for\nlatency and granularity. Extensive evaluations on diverse benchmarks\ndemonstrate that our general-purpose LLM auto-evaluator, REC-70B, outperforms\nstate-of-the-art LLMs, excelling in content evaluation by delivering better\nquality explanation and citation with minimal bias. Our REC dataset and models\nare available at https://github.com/adelaidehsu/REC."}
{"id": "2505.12427", "pdf": "https://arxiv.org/pdf/2505.12427", "abs": "https://arxiv.org/abs/2505.12427", "authors": ["Siwei Xia", "Li Sun", "Tiantian Sun", "Qingli Li"], "title": "DragLoRA: Online Optimization of LoRA Adapters for Drag-based Image Editing in Diffusion Model", "categories": ["cs.CV"], "comment": "Accepted by ICML2025", "summary": "Drag-based editing within pretrained diffusion model provides a precise and\nflexible way to manipulate foreground objects. Traditional methods optimize the\ninput feature obtained from DDIM inversion directly, adjusting them iteratively\nto guide handle points towards target locations. However, these approaches\noften suffer from limited accuracy due to the low representation ability of the\nfeature in motion supervision, as well as inefficiencies caused by the large\nsearch space required for point tracking. To address these limitations, we\npresent DragLoRA, a novel framework that integrates LoRA (Low-Rank Adaptation)\nadapters into the drag-based editing pipeline. To enhance the training of LoRA\nadapters, we introduce an additional denoising score distillation loss which\nregularizes the online model by aligning its output with that of the original\nmodel. Additionally, we improve the consistency of motion supervision by\nadapting the input features using the updated LoRA, giving a more stable and\naccurate input feature for subsequent operations. Building on this, we design\nan adaptive optimization scheme that dynamically toggles between two modes,\nprioritizing efficiency without compromising precision. Extensive experiments\ndemonstrate that DragLoRA significantly enhances the control precision and\ncomputational efficiency for drag-based image editing. The Codes of DragLoRA\nare available at: https://github.com/Sylvie-X/DragLoRA."}
{"id": "2505.14083", "pdf": "https://arxiv.org/pdf/2505.14083", "abs": "https://arxiv.org/abs/2505.14083", "authors": ["Andrea Della Vecchia", "Arnaud Mavakala Watusadisi", "Ernesto De Vito", "Lorenzo Rosasco"], "title": "Computational Efficiency under Covariate Shift in Kernel Ridge Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper addresses the covariate shift problem in the context of\nnonparametric regression within reproducing kernel Hilbert spaces (RKHSs).\nCovariate shift arises in supervised learning when the input distributions of\nthe training and test data differ, presenting additional challenges for\nlearning. Although kernel methods have optimal statistical properties, their\nhigh computational demands in terms of time and, particularly, memory, limit\ntheir scalability to large datasets. To address this limitation, the main focus\nof this paper is to explore the trade-off between computational efficiency and\nstatistical accuracy under covariate shift. We investigate the use of random\nprojections where the hypothesis space consists of a random subspace within a\ngiven RKHS. Our results show that, even in the presence of covariate shift,\nsignificant computational savings can be achieved without compromising learning\nperformance."}
{"id": "2405.10271", "pdf": "https://arxiv.org/pdf/2405.10271", "abs": "https://arxiv.org/abs/2405.10271", "authors": ["Christian Intern√≤", "Elena Raponi", "Niki van Stein", "Thomas B√§ck", "Markus Olhofer", "Yaochu Jin", "Barbara Hammer"], "title": "Federated Hybrid Model Pruning through Loss Landscape Exploration", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.ET"], "comment": null, "summary": "As the era of connectivity and unprecedented data generation expands,\ncollaborative intelligence emerges as a key driver for machine learning,\nencouraging global-scale model development. Federated learning (FL) stands at\nthe heart of this transformation, enabling distributed systems to work\ncollectively on complex tasks while respecting strict constraints on privacy\nand security. Despite its vast potential, specially in the age of complex\nmodels, FL encounters challenges such as elevated communication costs,\ncomputational constraints, and the heterogeneous data distributions. In this\ncontext, we present AutoFLIP, a novel framework that optimizes FL through an\nadaptive hybrid pruning approach, grounded in a federated loss exploration\nphase. By jointly analyzing diverse non-IID client loss landscapes, AutoFLIP\nefficiently identifies model substructures for pruning both at structured and\nunstructured levels. This targeted optimization fosters a symbiotic\nintelligence loop, reducing computational burdens and boosting model\nperformance on resource-limited devices for a more inclusive and democratized\nmodel usage. Our extensive experiments across multiple datasets and FL tasks\nshow that AutoFLIP delivers quantifiable benefits: a 48.8% reduction in\ncomputational overhead, a 35.5% decrease in communication costs, and a notable\nimprovement in global accuracy. By significantly reducing these overheads,\nAutoFLIP offer the way for efficient FL deployment in real-world applications\nfor a scalable and broad applicability."}
{"id": "2411.14318", "pdf": "https://arxiv.org/pdf/2411.14318", "abs": "https://arxiv.org/abs/2411.14318", "authors": ["Zheheng Luo", "Xin Zhang", "Xiao Liu", "Haoling Li", "Yeyun Gong", "Chen Qi", "Peng Cheng"], "title": "Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025", "summary": "It is well-known that a diverse corpus is critical for training large\nlanguage models, which are typically constructed from a mixture of various\ndomains. In general, previous efforts resort to sampling training data from\ndifferent domains with static proportions, as well as adjusting data\nproportions during training. However, few methods have addressed the\ncomplexities of domain-adaptive continual pre-training. To fill this gap, we\npropose Velocitune, a novel framework dynamically assesses learning velocity\nand adjusts data proportions accordingly, favoring slower-learning domains\nwhile shunning faster-learning ones, which is guided by a scaling law to\nindicate the desired learning goal for each domain with less associated cost.\nTo evaluate the effectiveness of Velocitune, we conduct experiments in a\nreasoning-focused dataset with CodeLlama, as well as in a corpus specialised\nfor system command generation with Llama3 and Mistral. Velocitune achieves\nperformance gains in both math and code reasoning tasks and command-line\ngeneration benchmarks. Further analysis reveals that key factors driving\nVelocitune's effectiveness include target loss prediction and data ordering."}
{"id": "2505.12482", "pdf": "https://arxiv.org/pdf/2505.12482", "abs": "https://arxiv.org/abs/2505.12482", "authors": ["Wenchen Chen", "Yanmei Zhang", "Zhongwei Xiao", "Jianping Chu", "Xingbo Wang"], "title": "Spectral-Spatial Self-Supervised Learning for Few-Shot Hyperspectral Image Classification", "categories": ["cs.CV"], "comment": "https://github.com/Wenchen-Chen/S4L-FSC", "summary": "Few-shot classification of hyperspectral images (HSI) faces the challenge of\nscarce labeled samples. Self-Supervised learning (SSL) and Few-Shot Learning\n(FSL) offer promising avenues to address this issue. However, existing methods\noften struggle to adapt to the spatial geometric diversity of HSIs and lack\nsufficient spectral prior knowledge. To tackle these challenges, we propose a\nmethod, Spectral-Spatial Self-Supervised Learning for Few-Shot Hyperspectral\nImage Classification (S4L-FSC), aimed at improving the performance of few-shot\nHSI classification. Specifically, we first leverage heterogeneous datasets to\npretrain a spatial feature extractor using a designed Rotation-Mirror\nSelf-Supervised Learning (RM-SSL) method, combined with FSL. This approach\nenables the model to learn the spatial geometric diversity of HSIs using\nrotation and mirroring labels as supervisory signals, while acquiring\ntransferable spatial meta-knowledge through few-shot learning. Subsequently,\nhomogeneous datasets are utilized to pretrain a spectral feature extractor via\na combination of FSL and Masked Reconstruction Self-Supervised Learning\n(MR-SSL). The model learns to reconstruct original spectral information from\nrandomly masked spectral vectors, inferring spectral dependencies. In parallel,\nFSL guides the model to extract pixel-level discriminative features, thereby\nembedding rich spectral priors into the model. This spectral-spatial\npretraining method, along with the integration of knowledge from heterogeneous\nand homogeneous sources, significantly enhances model performance. Extensive\nexperiments on four HSI datasets demonstrate the effectiveness and superiority\nof the proposed S4L-FSC approach for few-shot HSI classification."}
{"id": "2505.14102", "pdf": "https://arxiv.org/pdf/2505.14102", "abs": "https://arxiv.org/abs/2505.14102", "authors": ["Shogo Iwazaki", "Junpei Komiyama", "Masaaki Imaizumi"], "title": "High-dimensional Nonparametric Contextual Bandit Problem", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "38 pages", "summary": "We consider the kernelized contextual bandit problem with a large feature\nspace. This problem involves $K$ arms, and the goal of the forecaster is to\nmaximize the cumulative rewards through learning the relationship between the\ncontexts and the rewards. It serves as a general framework for various\ndecision-making scenarios, such as personalized online advertising and\nrecommendation systems. Kernelized contextual bandits generalize the linear\ncontextual bandit problem and offers a greater modeling flexibility. Existing\nmethods, when applied to Gaussian kernels, yield a trivial bound of $O(T)$ when\nwe consider $\\Omega(\\log T)$ feature dimensions. To address this, we introduce\nstochastic assumptions on the context distribution and show that no-regret\nlearning is achievable even when the number of dimensions grows up to the\nnumber of samples. Furthermore, we analyze lenient regret, which allows a\nper-round regret of at most $\\Delta > 0$. We derive the rate of lenient regret\nin terms of $\\Delta$."}
{"id": "2405.12463", "pdf": "https://arxiv.org/pdf/2405.12463", "abs": "https://arxiv.org/abs/2405.12463", "authors": ["Georgiy A. Bondar", "Robert Gifford", "Linh Thi Xuan Phan", "Abhishek Halder"], "title": "Stochastic Learning of Computational Resource Usage as Graph Structured Multimarginal Schr√∂dinger Bridge", "categories": ["math.OC", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "stat.ML"], "comment": null, "summary": "We propose to learn the time-varying stochastic computational resource usage\nof software as a graph structured Schr\\\"odinger bridge problem. In general,\nlearning the computational resource usage from data is challenging because\nresources such as the number of CPU instructions and the number of last level\ncache requests are both time-varying and statistically correlated. Our proposed\nmethod enables learning the joint time-varying stochasticity in computational\nresource usage from the measured profile snapshots in a nonparametric manner.\nThe method can be used to predict the most-likely time-varying distribution of\ncomputational resource availability at a desired time. We provide detailed\nalgorithms for stochastic learning in both single and multi-core cases, discuss\nthe convergence guarantees, computational complexities, and demonstrate their\npractical use in two case studies: a single-core nonlinear model predictive\ncontroller, and a synthetic multi-core software."}
{"id": "2411.17388", "pdf": "https://arxiv.org/pdf/2411.17388", "abs": "https://arxiv.org/abs/2411.17388", "authors": ["Haoyu Huang", "Chong Chen", "Zeang Sheng", "Yang Li", "Wentao Zhang"], "title": "Can LLMs be Good Graph Judge for Knowledge Graph Construction?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In real-world scenarios, most of the data obtained from the information\nretrieval (IR) system is unstructured. Converting natural language sentences\ninto structured Knowledge Graphs (KGs) remains a critical challenge. We\nidentified three limitations with respect to existing KG construction methods:\n(1) There could be a large amount of noise in real-world documents, which could\nresult in extracting messy information. (2) Naive LLMs usually extract\ninaccurate knowledge from some domain-specific documents. (3) Hallucination\nphenomenon cannot be overlooked when directly using LLMs to construct KGs. In\nthis paper, we propose \\textbf{GraphJudge}, a KG construction framework to\naddress the aforementioned challenges. In this framework, we designed an\nentity-centric strategy to eliminate the noise information in the documents.\nAnd we fine-tuned a LLM as a graph judge to finally enhance the quality of\ngenerated KGs. Experiments conducted on two general and one domain-specific\ntext-graph pair datasets demonstrate state-of-the-art performance against\nvarious baseline methods with strong generalization abilities. Our code is\navailable at\n\\href{https://github.com/hhy-huang/GraphJudge}{https://github.com/hhy-huang/GraphJudge}."}
{"id": "2505.12711", "pdf": "https://arxiv.org/pdf/2505.12711", "abs": "https://arxiv.org/abs/2505.12711", "authors": ["Qichen Sun", "Zhengrui Guo", "Rui Peng", "Hao Chen", "Jinzhuo Wang"], "title": "Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in computational pathology and artificial intelligence have\nsignificantly enhanced the utilization of gigapixel whole-slide images and and\nadditional modalities (e.g., genomics) for pathological diagnosis. Although\ndeep learning has demonstrated strong potential in pathology, several key\nchallenges persist: (1) fusing heterogeneous data types requires sophisticated\nstrategies beyond simple concatenation due to high computational costs; (2)\ncommon scenarios of missing modalities necessitate flexible strategies that\nallow the model to learn robustly in the absence of certain modalities; (3) the\ndownstream tasks in CPath are diverse, ranging from unimodal to multimodal,\ncnecessitating a unified model capable of handling all modalities. To address\nthese challenges, we propose ALTER, an any-to-any tri-modal pretraining\nframework that integrates WSIs, genomics, and pathology reports. The term \"any\"\nemphasizes ALTER's modality-adaptive design, enabling flexible pretraining with\nany subset of modalities, and its capacity to learn robust, cross-modal\nrepresentations beyond WSI-centric approaches. We evaluate ALTER across\nextensive clinical tasks including survival prediction, cancer subtyping, gene\nmutation prediction, and report generation, achieving superior or comparable\nperformance to state-of-the-art baselines."}
{"id": "2505.14164", "pdf": "https://arxiv.org/pdf/2505.14164", "abs": "https://arxiv.org/abs/2505.14164", "authors": ["Marcel Arpogaus", "Thomas Kneib", "Thomas Nagler", "David R√ºgamer"], "title": "Hybrid Bernstein Normalizing Flows for Flexible Multivariate Density Regression with Interpretable Marginals", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.ME"], "comment": null, "summary": "Density regression models allow a comprehensive understanding of data by\nmodeling the complete conditional probability distribution. While flexible\nestimation approaches such as normalizing flows (NF) work particularly well in\nmultiple dimensions, interpreting the input-output relationship of such models\nis often difficult, due to the black-box character of deep learning models. In\ncontrast, existing statistical methods for multivariate outcomes such as\nmultivariate conditional transformation models (MCTM) are restricted in\nflexibility and are often not expressive enough to represent complex\nmultivariate probability distributions. In this paper, we combine MCTM with\nstate-of-the-art and autoregressive NF to leverage the transparency of MCTM for\nmodeling interpretable feature effects on the marginal distributions in the\nfirst step and the flexibility of neural-network-based NF techniques to account\nfor complex and non-linear relationships in the joint data distribution. We\ndemonstrate our method's versatility in various numerical experiments and\ncompare it with MCTM and other NF models on both simulated and real-world data."}
{"id": "2406.14761", "pdf": "https://arxiv.org/pdf/2406.14761", "abs": "https://arxiv.org/abs/2406.14761", "authors": ["Harrison Delecki", "Marc R. Schlichting", "Mansur Arief", "Anthony Corso", "Marcell Vazquez-Chanlatte", "Mykel J. Kochenderfer"], "title": "Diffusion-Based Failure Sampling for Evaluating Safety-Critical Autonomous Systems", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "Appears in IEEE International Conference on Engineering Reliable\n  Autonomous Systems (ERAS) 2025", "summary": "Validating safety-critical autonomous systems in high-dimensional domains\nsuch as robotics presents a significant challenge. Existing black-box\napproaches based on Markov chain Monte Carlo may require an enormous number of\nsamples, while methods based on importance sampling often rely on simple\nparametric families that may struggle to represent the distribution over\nfailures. We propose to sample the distribution over failures using a\nconditional denoising diffusion model, which has shown success in complex\nhigh-dimensional problems such as robotic task planning. We iteratively train a\ndiffusion model to produce state trajectories closer to failure. We demonstrate\nthe effectiveness of our approach on high-dimensional robotic validation tasks,\nimproving sample efficiency and mode coverage compared to existing black-box\ntechniques."}
{"id": "2412.06245", "pdf": "https://arxiv.org/pdf/2412.06245", "abs": "https://arxiv.org/abs/2412.06245", "authors": ["Saahith Janapati", "Yangfeng Ji"], "title": "A Comparative Study of Learning Paradigms in Large Language Models via Intrinsic Dimension", "categories": ["cs.CL"], "comment": null, "summary": "The performance of Large Language Models (LLMs) on natural language tasks can\nbe improved through both supervised fine-tuning (SFT) and in-context learning\n(ICL), which operate via distinct mechanisms. Supervised fine-tuning updates\nthe model's weights by minimizing loss on training data, whereas in-context\nlearning leverages task demonstrations embedded in the prompt, without changing\nthe model's parameters. This study investigates the effects of these learning\nparadigms on the hidden representations of LLMs using Intrinsic Dimension (ID).\nWe use ID to estimate the number of degrees of freedom between representations\nextracted from LLMs as they perform specific natural language tasks. We first\nexplore how the ID of LLM representations evolves during SFT and how it varies\ndue to the number of demonstrations in ICL. We then compare the IDs induced by\nSFT and ICL and find that ICL consistently induces a higher ID compared to SFT,\nsuggesting that representations generated during ICL reside in higher\ndimensional manifolds in the embedding space."}
{"id": "2505.12772", "pdf": "https://arxiv.org/pdf/2505.12772", "abs": "https://arxiv.org/abs/2505.12772", "authors": ["Junyi Hu", "Tian Bai", "Fengyi Wu", "Zhenming Peng", "Yi Zhang"], "title": "Pyramid Sparse Transformer: Enhancing Multi-Scale Feature Fusion with Dynamic Token Selection", "categories": ["cs.CV"], "comment": "13 pages, 5 figures", "summary": "Feature fusion is critical for high-performance vision models but often\nincurs prohibitive complexity. However, prevailing attention-based fusion\nmethods often involve significant computational complexity and implementation\nchallenges, limiting their efficiency in resource-constrained environments. To\naddress these issues, we introduce the Pyramid Sparse Transformer (PST), a\nlightweight, plug-and-play module that integrates coarse-to-fine token\nselection and shared attention parameters to reduce computation while\npreserving spatial detail. PST can be trained using only coarse attention and\nseamlessly activated at inference for further accuracy gains without\nretraining. When added to state-of-the-art real-time detection models, such as\nYOLOv11-N/S/M, PST yields mAP improvements of 0.9%, 0.5%, and 0.4% on MS COCO\nwith minimal latency impact. Likewise, embedding PST into ResNet-18/50/101 as\nbackbones, boosts ImageNet top-1 accuracy by 6.5%, 1.7%, and 1.0%,\nrespectively. These results demonstrate PST's effectiveness as a simple,\nhardware-friendly enhancement for both detection and classification tasks."}
{"id": "2505.14192", "pdf": "https://arxiv.org/pdf/2505.14192", "abs": "https://arxiv.org/abs/2505.14192", "authors": ["Bikash K. Behera", "Saif Al-Kuwari", "Ahmed Farouk"], "title": "QSVM-QNN: Quantum Support Vector Machine Based Quantum Neural Network Learning Algorithm for Brain-Computer Interfacing Systems", "categories": ["quant-ph", "cs.LG", "eess.SP"], "comment": "12 pages, 7 Figures, 7 Tables", "summary": "A brain-computer interface (BCI) system enables direct communication between\nthe brain and external devices, offering significant potential for assistive\ntechnologies and advanced human-computer interaction. Despite progress, BCI\nsystems face persistent challenges, including signal variability,\nclassification inefficiency, and difficulty adapting to individual users in\nreal time. In this study, we propose a novel hybrid quantum learning model,\ntermed QSVM-QNN, which integrates a Quantum Support Vector Machine (QSVM) with\na Quantum Neural Network (QNN), to improve classification accuracy and\nrobustness in EEG-based BCI tasks. Unlike existing models, QSVM-QNN combines\nthe decision boundary capabilities of QSVM with the expressive learning power\nof QNN, leading to superior generalization performance. The proposed model is\nevaluated on two benchmark EEG datasets, achieving high accuracies of 0.990 and\n0.950, outperforming both classical and standalone quantum models. To\ndemonstrate real-world viability, we further validated the robustness of QNN,\nQSVM, and QSVM-QNN against six realistic quantum noise models, including bit\nflip and phase damping. These experiments reveal that QSVM-QNN maintains stable\nperformance under noisy conditions, establishing its applicability for\ndeployment in practical, noisy quantum environments. Beyond BCI, the proposed\nhybrid quantum architecture is generalizable to other biomedical and\ntime-series classification tasks, offering a scalable and noise-resilient\nsolution for next-generation neurotechnological systems."}
{"id": "2407.04737", "pdf": "https://arxiv.org/pdf/2407.04737", "abs": "https://arxiv.org/abs/2407.04737", "authors": ["Yuanyuan Duan", "Haiyang Feng", "Zhiping Yu", "Hanming Wu", "Leilai Shao", "Xiaolei Zhu"], "title": "Hierarchical Decoupling Capacitor Optimization for Power Distribution Network of 2.5D ICs with Co-Analysis of Frequency and Time Domains Based on Deep Reinforcement Learning", "categories": ["eess.SP", "cs.AI"], "comment": "The data needs to be experimentally revalidated, and the experimental\n  details require further optimization", "summary": "With the growing need for higher memory bandwidth and computation density,\n2.5D design, which involves integrating multiple chiplets onto an interposer,\nemerges as a promising solution. However, this integration introduces\nsignificant challenges due to increasing data rates and a large number of I/Os,\nnecessitating advanced optimization of the power distribution networks (PDNs)\nboth on-chip and on-interposer to mitigate the small signal noise and\nsimultaneous switching noise (SSN). Traditional PDN optimization strategies in\n2.5D systems primarily focus on reducing impedance by integrating decoupling\ncapacitors (decaps) to lessen small signal noises. Unfortunately, relying\nsolely on frequency-domain analysis has been proven inadequate for addressing\ncoupled SSN, as indicated by our experimental results. In this work, we\nintroduce a novel two-phase optimization flow using deep reinforcement learning\nto tackle both the on-chip small signal noise and SSN. Initially, we optimize\nthe impedance in the frequency domain to maintain the small signal noise within\nacceptable limits while avoiding over-design. Subsequently, in the time domain,\nwe refine the PDN to minimize the voltage violation integral (VVI), a more\naccurate measure of SSN severity. To the best of our knowledge, this is the\nfirst dual-domain optimization strategy that simultaneously addresses both the\nsmall signal noise and SSN propagation through strategic decap placement in\non-chip and on-interposer PDNs, offering a significant step forward in the\ndesign of robust PDNs for 2.5D integrated systems."}
{"id": "2412.11936", "pdf": "https://arxiv.org/pdf/2412.11936", "abs": "https://arxiv.org/abs/2412.11936", "authors": ["Yibo Yan", "Jiamin Su", "Jianxiang He", "Fangteng Fu", "Xu Zheng", "Yuanhuiyi Lyu", "Kun Wang", "Shen Wang", "Qingsong Wen", "Xuming Hu"], "title": "A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges", "categories": ["cs.CL"], "comment": "Accepted by The 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL Findings 2025)", "summary": "Mathematical reasoning, a core aspect of human cognition, is vital across\nmany domains, from educational problem-solving to scientific advancements. As\nartificial general intelligence (AGI) progresses, integrating large language\nmodels (LLMs) with mathematical reasoning tasks is becoming increasingly\nsignificant. This survey provides the first comprehensive analysis of\nmathematical reasoning in the era of multimodal large language models (MLLMs).\nWe review over 200 studies published since 2021, and examine the\nstate-of-the-art developments in Math-LLMs, with a focus on multimodal\nsettings. We categorize the field into three dimensions: benchmarks,\nmethodologies, and challenges. In particular, we explore multimodal\nmathematical reasoning pipeline, as well as the role of (M)LLMs and the\nassociated methodologies. Finally, we identify five major challenges hindering\nthe realization of AGI in this domain, offering insights into the future\ndirection for enhancing multimodal reasoning capabilities. This survey serves\nas a critical resource for the research community in advancing the capabilities\nof LLMs to tackle complex multimodal reasoning tasks."}
{"id": "2505.13061", "pdf": "https://arxiv.org/pdf/2505.13061", "abs": "https://arxiv.org/abs/2505.13061", "authors": ["Chengtang Yao", "Zhidan Liu", "Jiaxi Zeng", "Lidong Yu", "Yuwei Wu", "Yunde Jia"], "title": "3D Visual Illusion Depth Estimation", "categories": ["cs.CV"], "comment": "Project:\n  https://github.com/YaoChengTang/3D-Visual-Illusion-Depth-Estimation", "summary": "3D visual illusion is a perceptual phenomenon where a two-dimensional plane\nis manipulated to simulate three-dimensional spatial relationships, making a\nflat artwork or object look three-dimensional in the human visual system. In\nthis paper, we reveal that the machine visual system is also seriously fooled\nby 3D visual illusions, including monocular and binocular depth estimation. In\norder to explore and analyze the impact of 3D visual illusion on depth\nestimation, we collect a large dataset containing almost 3k scenes and 200k\nimages to train and evaluate SOTA monocular and binocular depth estimation\nmethods. We also propose a robust depth estimation framework that uses common\nsense from a vision-language model to adaptively select reliable depth from\nbinocular disparity and monocular depth. Experiments show that SOTA monocular,\nbinocular, and multi-view depth estimation approaches are all fooled by various\n3D visual illusions, while our method achieves SOTA performance."}
{"id": "2505.14245", "pdf": "https://arxiv.org/pdf/2505.14245", "abs": "https://arxiv.org/abs/2505.14245", "authors": ["A. A. Solovykh", "N. E. Rybin", "I. S. Novikov", "A. V. Shapeev"], "title": "Path-integral molecular dynamics with actively-trained and universal machine learning force fields", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "9 pages, 6 eps figures", "summary": "Accounting for nuclear quantum effects (NQEs) can significantly alter\nmaterial properties at finite temperatures. Atomic modeling using the\npath-integral molecular dynamics (PIMD) method can fully account for such\neffects, but requires computationally efficient and accurate models of\ninteratomic interactions. Empirical potentials are fast but may lack sufficient\naccuracy, whereas quantum-mechanical calculations are highly accurate but\ncomputationally expensive. Machine-learned interatomic potentials offer a\nsolution to this challenge, providing near-quantum-mechanical accuracy while\nmaintaining high computational efficiency compared to density functional theory\n(DFT) calculations. In this context, an interface was developed to integrate\nmoment tensor potentials (MTPs) from the MLIP-2 software package into PIMD\ncalculations using the i-PI software package. This interface was then applied\nto active learning of potentials and to investigate the influence of NQEs on\nmaterial properties, namely the temperature dependence of lattice parameters\nand thermal expansion coefficients, as well as radial distribution functions,\nfor lithium hydride (LiH) and silicon (Si) systems. The results were compared\nwith experimental data, quasi-harmonic approximation calculations, and\npredictions from the universal machine learning force field MatterSim. These\ncomparisons demonstrated the high accuracy and effectiveness of the MTP-PIMD\napproach."}
{"id": "2407.09096", "pdf": "https://arxiv.org/pdf/2407.09096", "abs": "https://arxiv.org/abs/2407.09096", "authors": ["YiHeng Huang", "Xiaowei Mao", "Shengnan Guo", "Yubin Chen", "Junfeng Shen", "Tiankuo Li", "Youfang Lin", "Huaiyu Wan"], "title": "STD-PLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with PLM", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Spatial-temporal forecasting and imputation are important for real-world\nintelligent systems. Most existing methods are tailored for individual\nforecasting or imputation tasks but are not designed for both. Additionally,\nthey are less effective for zero-shot and few-shot learning. While pre-trained\nlanguage model (PLM) have exhibited strong pattern recognition and reasoning\nabilities across various tasks, including few-shot and zero-shot learning,\ntheir applications in spatial-temporal data understanding has been constrained\nby insufficient modeling of complex correlations such as the temporal\ncorrelations, spatial connectivity, non-pairwise and high-order\nspatial-temporal correlations within data. In this paper, we propose STD-PLM\nfor understanding both spatial and temporal properties of\n\\underline{S}patial-\\underline{T}emporal \\underline{D}ata with \\underline{PLM},\nwhich is capable of implementing both spatial-temporal forecasting and\nimputation tasks. STD-PLM understands spatial-temporal correlations via\nexplicitly designed spatial and temporal tokenizers. Topology-aware node\nembeddings are designed for PLM to comprehend and exploit the topology\nstructure of data in inductive manner. Furthermore, to mitigate the efficiency\nissues introduced by the PLM, we design a sandglass attention module (SGA)\ncombined with a specific constrained loss function, which significantly\nimproves the model's efficiency while ensuring performance. Extensive\nexperiments demonstrate that STD-PLM exhibits competitive performance and\ngeneralization capabilities across the forecasting and imputation tasks on\nvarious datasets. Moreover, STD-PLM achieves promising results on both few-shot\nand zero-shot tasks. The code is made available at\n\\href{https://github.com/Hyheng/STD-PLM}{https://github.com/Hyheng/STD-PLM}"}
{"id": "2412.14161", "pdf": "https://arxiv.org/pdf/2412.14161", "abs": "https://arxiv.org/abs/2412.14161", "authors": ["Frank F. Xu", "Yufan Song", "Boxuan Li", "Yuxuan Tang", "Kritanjali Jain", "Mengxue Bao", "Zora Z. Wang", "Xuhui Zhou", "Zhitong Guo", "Murong Cao", "Mingyang Yang", "Hao Yang Lu", "Amaad Martin", "Zhe Su", "Leander Maben", "Raj Mehta", "Wayne Chi", "Lawrence Jang", "Yiqing Xie", "Shuyan Zhou", "Graham Neubig"], "title": "TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks", "categories": ["cs.CL"], "comment": "Preprint", "summary": "We interact with computers on an everyday basis, be it in everyday life or\nwork, and many aspects of work can be done entirely with access to a computer\nand the Internet. At the same time, thanks to improvements in large language\nmodels (LLMs), there has also been a rapid development in AI agents that\ninteract with and affect change in their surrounding environments. But how\nperformant are AI agents at accelerating or even autonomously performing\nwork-related tasks? The answer to this question has important implications both\nfor industry looking to adopt AI into their workflows and for economic policy\nto understand the effects that adoption of AI may have on the labor market. To\nmeasure the progress of these LLM agents' performance on performing real-world\nprofessional tasks, in this paper we introduce TheAgentCompany, an extensible\nbenchmark for evaluating AI agents that interact with the world in similar ways\nto those of a digital worker: by browsing the Web, writing code, running\nprograms, and communicating with other coworkers. We build a self-contained\nenvironment with internal web sites and data that mimics a small software\ncompany environment, and create a variety of tasks that may be performed by\nworkers in such a company. We test baseline agents powered by both closed\nAPI-based and open-weights language models (LMs), and find that the most\ncompetitive agent can complete 30% of tasks autonomously. This paints a nuanced\npicture on task automation with LM agents--in a setting simulating a real\nworkplace, a good portion of simpler tasks could be solved autonomously, but\nmore difficult long-horizon tasks are still beyond the reach of current\nsystems. We release code, data, environment, and experiments on\nhttps://the-agent-company.com."}
{"id": "2505.13099", "pdf": "https://arxiv.org/pdf/2505.13099", "abs": "https://arxiv.org/abs/2505.13099", "authors": ["Shinichi Mae", "Ryousuke Yamada", "Hirokatsu Kataoka"], "title": "Industrial Synthetic Segment Pre-training", "categories": ["cs.CV"], "comment": null, "summary": "Pre-training on real-image datasets has been widely proven effective for\nimproving instance segmentation. However, industrial applications face two key\nchallenges: (1) legal and ethical restrictions, such as ImageNet's prohibition\nof commercial use, and (2) limited transferability due to the domain gap\nbetween web images and industrial imagery. Even recent vision foundation\nmodels, including the segment anything model (SAM), show notable performance\ndegradation in industrial settings. These challenges raise critical questions:\nCan we build a vision foundation model for industrial applications without\nrelying on real images or manual annotations? And can such models outperform\neven fine-tuned SAM on industrial datasets? To address these questions, we\npropose the Instance Core Segmentation Dataset (InsCore), a synthetic\npre-training dataset based on formula-driven supervised learning (FDSL).\nInsCore generates fully annotated instance segmentation images that reflect key\ncharacteristics of industrial data, including complex occlusions, dense\nhierarchical masks, and diverse non-rigid shapes, distinct from typical web\nimagery. Unlike previous methods, InsCore requires neither real images nor\nhuman annotations. Experiments on five industrial datasets show that models\npre-trained with InsCore outperform those trained on COCO and ImageNet-21k, as\nwell as fine-tuned SAM, achieving an average improvement of 6.2 points in\ninstance segmentation performance. This result is achieved using only 100k\nsynthetic images, more than 100 times fewer than the 11 million images in SAM's\nSA-1B dataset, demonstrating the data efficiency of our approach. These\nfindings position InsCore as a practical and license-free vision foundation\nmodel for industrial applications."}
{"id": "2505.14303", "pdf": "https://arxiv.org/pdf/2505.14303", "abs": "https://arxiv.org/abs/2505.14303", "authors": ["Rebecca Pelke", "Jos√© Cubero-Cascante", "Nils Bosbach", "Niklas Degener", "Florian Idrizi", "Lennart M. Reimann", "Jan Moritz Joseph", "Rainer Leupers"], "title": "Optimizing Binary and Ternary Neural Network Inference on RRAM Crossbars using CIM-Explorer", "categories": ["cs.ET", "cs.LG"], "comment": null, "summary": "Using Resistive Random Access Memory (RRAM) crossbars in Computing-in-Memory\n(CIM) architectures offers a promising solution to overcome the von Neumann\nbottleneck. Due to non-idealities like cell variability, RRAM crossbars are\noften operated in binary mode, utilizing only two states: Low Resistive State\n(LRS) and High Resistive State (HRS). Binary Neural Networks (BNNs) and Ternary\nNeural Networks (TNNs) are well-suited for this hardware due to their efficient\nmapping. Existing software projects for RRAM-based CIM typically focus on only\none aspect: compilation, simulation, or Design Space Exploration (DSE).\nMoreover, they often rely on classical 8 bit quantization. To address these\nlimitations, we introduce CIM-Explorer, a modular toolkit for optimizing BNN\nand TNN inference on RRAM crossbars. CIM-Explorer includes an end-to-end\ncompiler stack, multiple mapping options, and simulators, enabling a DSE flow\nfor accuracy estimation across different crossbar parameters and mappings.\nCIM-Explorer can accompany the entire design process, from early accuracy\nestimation for specific crossbar parameters, to selecting an appropriate\nmapping, and compiling BNNs and TNNs for a finalized crossbar chip. In DSE case\nstudies, we demonstrate the expected accuracy for various mappings and crossbar\nparameters. CIM-Explorer can be found on GitHub."}
{"id": "2409.04744", "pdf": "https://arxiv.org/pdf/2409.04744", "abs": "https://arxiv.org/abs/2409.04744", "authors": ["Yongxin Deng", "Xihe Qiu", "Jue Chen", "Xiaoyu Tan"], "title": "Reward Guidance for Reinforcement Learning Tasks Based on Large Language Models: The LMGT Framework", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The inherent uncertainty in the environmental transition model of\nReinforcement Learning (RL) necessitates a delicate balance between exploration\nand exploitation. This balance is crucial for optimizing computational\nresources to accurately estimate expected rewards for the agent. In scenarios\nwith sparse rewards, such as robotic control systems, achieving this balance is\nparticularly challenging. However, given that many environments possess\nextensive prior knowledge, learning from the ground up in such contexts may be\nredundant. To address this issue, we propose Language Model Guided reward\nTuning (LMGT), a novel, sample-efficient framework. LMGT leverages the\ncomprehensive prior knowledge embedded in Large Language Models (LLMs) and\ntheir proficiency in processing non-standard data forms, such as wiki\ntutorials. By utilizing LLM-guided reward shifts, LMGT adeptly balances\nexploration and exploitation, thereby guiding the agent's exploratory behavior\nand enhancing sample efficiency. We have rigorously evaluated LMGT across\nvarious RL tasks and evaluated it in the embodied robotic environment\nHousekeep. Our results demonstrate that LMGT consistently outperforms baseline\nmethods. Furthermore, the findings suggest that our framework can substantially\nreduce the computational resources required during the RL training phase."}
{"id": "2412.14470", "pdf": "https://arxiv.org/pdf/2412.14470", "abs": "https://arxiv.org/abs/2412.14470", "authors": ["Zhexin Zhang", "Shiyao Cui", "Yida Lu", "Jingzhuo Zhou", "Junxiao Yang", "Hongning Wang", "Minlie Huang"], "title": "Agent-SafetyBench: Evaluating the Safety of LLM Agents", "categories": ["cs.CL"], "comment": "26 pages", "summary": "As large language models (LLMs) are increasingly deployed as agents, their\nintegration into interactive environments and tool use introduce new safety\nchallenges beyond those associated with the models themselves. However, the\nabsence of comprehensive benchmarks for evaluating agent safety presents a\nsignificant barrier to effective assessment and further improvement. In this\npaper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to\nevaluate the safety of LLM agents. Agent-SafetyBench encompasses 349\ninteraction environments and 2,000 test cases, evaluating 8 categories of\nsafety risks and covering 10 common failure modes frequently encountered in\nunsafe interactions. Our evaluation of 16 popular LLM agents reveals a\nconcerning result: none of the agents achieves a safety score above 60%. This\nhighlights significant safety challenges in LLM agents and underscores the\nconsiderable need for improvement. Through failure mode and helpfulness\nanalysis, we summarize two fundamental safety defects in current LLM agents:\nlack of robustness and lack of risk awareness. Furthermore, our findings\nsuggest that reliance on defense prompts alone may be insufficient to address\nthese safety issues, emphasizing the need for more advanced and robust\nstrategies. To drive progress in this area, Agent-SafetyBench has been released\nat https://github.com/thu-coai/Agent-SafetyBench/ to facilitate further\nresearch in agent safety evaluation and improvement."}
{"id": "2505.13219", "pdf": "https://arxiv.org/pdf/2505.13219", "abs": "https://arxiv.org/abs/2505.13219", "authors": ["Jiafu Wu", "Yabiao Wang", "Jian Li", "Jinlong Peng", "Yun Cao", "Chengjie Wang", "Jiangning Zhang"], "title": "Swin DiT: Diffusion Transformer using Pseudo Shifted Windows", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion Transformers (DiTs) achieve remarkable performance within the\ndomain of image generation through the incorporation of the transformer\narchitecture. Conventionally, DiTs are constructed by stacking serial isotropic\nglobal information modeling transformers, which face significant computational\ncost when processing high-resolution images. We empirically analyze that latent\nspace image generation does not exhibit a strong dependence on global\ninformation as traditionally assumed. Most of the layers in the model\ndemonstrate redundancy in global computation. In addition, conventional\nattention mechanisms exhibit low-frequency inertia issues. To address these\nissues, we propose \\textbf{P}seudo \\textbf{S}hifted \\textbf{W}indow\n\\textbf{A}ttention (PSWA), which fundamentally mitigates global model\nredundancy. PSWA achieves intermediate global-local information interaction\nthrough window attention, while employing a high-frequency bridging branch to\nsimulate shifted window operations, supplementing appropriate global and\nhigh-frequency information. Furthermore, we propose the Progressive Coverage\nChannel Allocation(PCCA) strategy that captures high-order attention similarity\nwithout additional computational cost. Building upon all of them, we propose a\nseries of Pseudo \\textbf{S}hifted \\textbf{Win}dow DiTs (\\textbf{Swin DiT}),\naccompanied by extensive experiments demonstrating their superior performance.\nFor example, our proposed Swin-DiT-L achieves a 54%$\\uparrow$ FID improvement\nover DiT-XL/2 while requiring less computational.\nhttps://github.com/wujiafu007/Swin-DiT"}
{"id": "2505.14310", "pdf": "https://arxiv.org/pdf/2505.14310", "abs": "https://arxiv.org/abs/2505.14310", "authors": ["Shiyin Tan", "Dongyuan Li", "Renhe Jiang", "Zhen Wang", "Xingtong Yu", "Manabu Okumura"], "title": "Taming Recommendation Bias with Causal Intervention on Evolving Personal Popularity", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Popularity bias occurs when popular items are recommended far more frequently\nthan they should be, negatively impacting both user experience and\nrecommendation accuracy. Existing debiasing methods mitigate popularity bias\noften uniformly across all users and only partially consider the time evolution\nof users or items. However, users have different levels of preference for item\npopularity, and this preference is evolving over time. To address these issues,\nwe propose a novel method called CausalEPP (Causal Intervention on Evolving\nPersonal Popularity) for taming recommendation bias, which accounts for the\nevolving personal popularity of users. Specifically, we first introduce a\nmetric called {Evolving Personal Popularity} to quantify each user's preference\nfor popular items. Then, we design a causal graph that integrates evolving\npersonal popularity into the conformity effect, and apply deconfounded training\nto mitigate the popularity bias of the causal graph. During inference, we\nconsider the evolution consistency between users and items to achieve a better\nrecommendation. Empirical studies demonstrate that CausalEPP outperforms\nbaseline methods in reducing popularity bias while improving recommendation\naccuracy."}
{"id": "2409.13652", "pdf": "https://arxiv.org/pdf/2409.13652", "abs": "https://arxiv.org/abs/2409.13652", "authors": ["Stephen Zhang", "Vardan Papyan"], "title": "OATS: Outlier-Aware Pruning Through Sparse and Low Rank Decomposition", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The recent paradigm shift to large-scale foundation models has brought about\na new era for deep learning that, while has found great success in practice,\nhas also been plagued by prohibitively expensive costs in terms of high memory\nconsumption and compute. To mitigate these issues, there has been a concerted\neffort in post-hoc neural network pruning techniques that do not require costly\nretraining. Despite the considerable progress being made, existing methods\noften exhibit a steady drop in model performance as the compression increases.\nIn this paper, we present a novel approach to compressing large transformers,\ncoined OATS, that utilizes the second moment information in the input\nembeddings to decompose the model weights into a sum of sparse and low-rank\nmatrices. Without any retraining, OATS achieves state-of-the-art performance\nwhen compressing models by up to $60\\%$ on large language models such as\nLlama-3 and Phi-3 and vision transformers such as ViT and DINOv2 while\ndelivering up to $1.37\\times$ the CPU acceleration versus a model that was\ncomparably pruned."}
{"id": "2412.16783", "pdf": "https://arxiv.org/pdf/2412.16783", "abs": "https://arxiv.org/abs/2412.16783", "authors": ["Leon Fr√∂hling", "Pietro Bernardelle", "Gianluca Demartini"], "title": "SubData: Bridging Heterogeneous Datasets to Enable Theory-Driven Evaluation of Political and Demographic Perspectives in LLMs", "categories": ["cs.CL"], "comment": "11 pages, 2 figures", "summary": "As increasingly capable large language models (LLMs) emerge, researchers have\nbegun exploring their potential for subjective tasks. While recent work\ndemonstrates that LLMs can be aligned with diverse human perspectives,\nevaluating this alignment on actual downstream tasks (e.g., hate speech\ndetection) remains challenging due to the use of inconsistent datasets across\nstudies. To address this issue, in this resource paper we propose a two-step\nframework: we (1) introduce SubData, an open-source Python library designed for\nstandardizing heterogeneous datasets to evaluate LLM perspective alignment; and\n(2) present a theory-driven approach leveraging this library to test how\ndifferently-aligned LLMs (e.g., aligned with different political viewpoints)\nclassify content targeting specific demographics. SubData's flexible mapping\nand taxonomy enable customization for diverse research needs, distinguishing it\nfrom existing resources. We invite contributions to add datasets to our\ninitially proposed resource and thereby help expand SubData into a\nmulti-construct benchmark suite for evaluating LLM perspective alignment on NLP\ntasks."}
{"id": "2505.13279", "pdf": "https://arxiv.org/pdf/2505.13279", "abs": "https://arxiv.org/abs/2505.13279", "authors": ["Zhiqiang Yan", "Jianhao Jiao", "Zhengxue Wang", "Gim Hee Lee"], "title": "Event-Driven Dynamic Scene Depth Completion", "categories": ["cs.CV"], "comment": "9 pages", "summary": "Depth completion in dynamic scenes poses significant challenges due to rapid\nego-motion and object motion, which can severely degrade the quality of input\nmodalities such as RGB images and LiDAR measurements. Conventional RGB-D\nsensors often struggle to align precisely and capture reliable depth under such\nconditions. In contrast, event cameras with their high temporal resolution and\nsensitivity to motion at the pixel level provide complementary cues that are\n%particularly beneficial in dynamic environments.To this end, we propose\nEventDC, the first event-driven depth completion framework. It consists of two\nkey components: Event-Modulated Alignment (EMA) and Local Depth Filtering\n(LDF). Both modules adaptively learn the two fundamental components of\nconvolution operations: offsets and weights conditioned on motion-sensitive\nevent streams. In the encoder, EMA leverages events to modulate the sampling\npositions of RGB-D features to achieve pixel redistribution for improved\nalignment and fusion. In the decoder, LDF refines depth estimations around\nmoving objects by learning motion-aware masks from events. Additionally,\nEventDC incorporates two loss terms to further benefit global alignment and\nenhance local depth recovery. Moreover, we establish the first benchmark for\nevent-based depth completion comprising one real-world and two synthetic\ndatasets to facilitate future research. Extensive experiments on this benchmark\ndemonstrate the superiority of our EventDC."}
{"id": "2505.14314", "pdf": "https://arxiv.org/pdf/2505.14314", "abs": "https://arxiv.org/abs/2505.14314", "authors": ["Kosmas Alexandridis", "Vasileios Titopoulos", "Giorgos Dimitrakopoulos"], "title": "Low-Cost FlashAttention with Fused Exponential and Multiplication Hardware Operators", "categories": ["cs.AR", "cs.LG"], "comment": "IEEE Computer Society Annual Symposium on VLSI (ISVLSI 2025)", "summary": "Attention mechanisms, particularly within Transformer architectures and large\nlanguage models (LLMs), have revolutionized sequence modeling in machine\nlearning and artificial intelligence applications. To compute attention for\nincreasingly long sequences, specialized accelerators have been proposed to\nexecute key attention steps directly in hardware. Among the various recently\nproposed architectures, those based on variants of the FlashAttention\nalgorithm, originally designed for GPUs, stand out due to their optimized\ncomputation, tiling capabilities, and reduced memory traffic. In this work, we\nfocus on optimizing the kernel of floating-point-based FlashAttention using new\nhardware operators that fuse the computation of exponentials and vector\nmultiplications, e.g., e^x, V. The proposed ExpMul hardware operators\nsignificantly reduce the area and power costs of FlashAttention-based hardware\naccelerators. When implemented in a 28nm ASIC technology, they achieve\nimprovements of 28.8% in area and 17.6% in power, on average, compared to\nstate-of-the-art hardware architectures with separate exponentials and vector\nmultiplications hardware operators."}
{"id": "2410.03779", "pdf": "https://arxiv.org/pdf/2410.03779", "abs": "https://arxiv.org/abs/2410.03779", "authors": ["Huayu Deng", "Xiangming Zhu", "Yunbo Wang", "Xiaokang Yang"], "title": "EvoMesh: Adaptive Physical Simulation with Hierarchical Graph Evolutions", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Graph neural networks have been a powerful tool for mesh-based physical\nsimulation. To efficiently model large-scale systems, existing methods mainly\nemploy hierarchical graph structures to capture multi-scale node relations.\nHowever, these graph hierarchies are typically manually designed and fixed,\nlimiting their ability to adapt to the evolving dynamics of complex physical\nsystems. We propose EvoMesh, a fully differentiable framework that jointly\nlearns graph hierarchies and physical dynamics, adaptively guided by physical\ninputs. EvoMesh introduces anisotropic message passing, which enables\ndirection-specific aggregation of dynamic features between nodes within each\nhierarchy, while simultaneously learning node selection probabilities for the\nnext hierarchical level based on physical context. This design creates more\nflexible message shortcuts and enhances the model's capacity to capture\nlong-range dependencies. Extensive experiments on five benchmark physical\nsimulation datasets show that EvoMesh outperforms recent fixed-hierarchy\nmessage passing networks by large margins. Code is available at\nhttps://github.com/hbell99/EvoMesh."}
{"id": "2501.02009", "pdf": "https://arxiv.org/pdf/2501.02009", "abs": "https://arxiv.org/abs/2501.02009", "authors": ["Youcheng Huang", "Chen Huang", "Duanyu Feng", "Wenqiang Lei", "Jiancheng Lv"], "title": "Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main Camera Ready", "summary": "Understanding the inner workings of Large Language Models (LLMs) is a\ncritical research frontier. Prior research has shown that a single LLM's\nconcept representations can be captured as steering vectors (SVs), enabling the\ncontrol of LLM behavior (e.g., towards generating harmful content). Our work\ntakes a novel approach by exploring the intricate relationships between concept\nrepresentations across different LLMs, drawing an intriguing parallel to\nPlato's Allegory of the Cave. In particular, we introduce a linear\ntransformation method to bridge these representations and present three key\nfindings: 1) Concept representations across different LLMs can be effectively\naligned using simple linear transformations, enabling efficient cross-model\ntransfer and behavioral control via SVs. 2) This linear transformation\ngeneralizes across concepts, facilitating alignment and control of SVs\nrepresenting different concepts across LLMs. 3) A weak-to-strong\ntransferability exists between LLM concept representations, whereby SVs\nextracted from smaller LLMs can effectively control the behavior of larger\nLLMs."}
{"id": "2505.13327", "pdf": "https://arxiv.org/pdf/2505.13327", "abs": "https://arxiv.org/abs/2505.13327", "authors": ["Ajian Liu", "Haocheng Yuan", "Xiao Guo", "Hui Ma", "Wanyi Zhuang", "Changtao Miao", "Yan Hong", "Chuanbiao Song", "Jun Lan", "Qi Chu", "Tao Gong", "Yanyan Liang", "Weiqiang Wang", "Jun Wan", "Xiaoming Liu", "Zhen Lei"], "title": "Benchmarking Unified Face Attack Detection via Hierarchical Prompt Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Presentation Attack Detection and Face Forgery Detection are designed to\nprotect face data from physical media-based Presentation Attacks and digital\nediting-based DeepFakes respectively. But separate training of these two models\nmakes them vulnerable to unknown attacks and burdens deployment environments.\nThe lack of a Unified Face Attack Detection model to handle both types of\nattacks is mainly due to two factors. First, there's a lack of adequate\nbenchmarks for models to explore. Existing UAD datasets have limited attack\ntypes and samples, restricting the model's ability to address advanced threats.\nTo address this, we propose UniAttackDataPlus (UniAttackData+), the most\nextensive and sophisticated collection of forgery techniques to date. It\nincludes 2,875 identities and their 54 kinds of falsified samples, totaling\n697,347 videos. Second, there's a lack of a reliable classification criterion.\nCurrent methods try to find an arbitrary criterion within the same semantic\nspace, which fails when encountering diverse attacks. So, we present a novel\nVisual-Language Model-based Hierarchical Prompt Tuning Framework (HiPTune) that\nadaptively explores multiple classification criteria from different semantic\nspaces. We build a Visual Prompt Tree to explore various classification rules\nhierarchically. Then, by adaptively pruning the prompts, the model can select\nthe most suitable prompts to guide the encoder to extract discriminative\nfeatures at different levels in a coarse-to-fine way. Finally, to help the\nmodel understand the classification criteria in visual space, we propose a\nDynamically Prompt Integration module to project the visual prompts to the text\nencoder for more accurate semantics. Experiments on 12 datasets have shown the\npotential to inspire further innovations in the UAD field."}
{"id": "2505.14323", "pdf": "https://arxiv.org/pdf/2505.14323", "abs": "https://arxiv.org/abs/2505.14323", "authors": ["Tomasz MaciƒÖ≈ºek", "Robert Allison"], "title": "Vulnerability of Transfer-Learned Neural Networks to Data Reconstruction Attacks in Small-Data Regime", "categories": ["cs.CR", "cs.LG"], "comment": "27 pages", "summary": "Training data reconstruction attacks enable adversaries to recover portions\nof a released model's training data. We consider the attacks where a\nreconstructor neural network learns to invert the (random) mapping between\ntraining data and model weights. Prior work has shown that an informed\nadversary with access to released model's weights and all but one training data\npoint can achieve high-quality reconstructions in this way. However,\ndifferential privacy can defend against such an attack with little to no loss\nin model's utility when the amount of training data is sufficiently large. In\nthis work we consider a more realistic adversary who only knows the\ndistribution from which a small training dataset has been sampled and who\nattacks a transfer-learned neural network classifier that has been trained on\nthis dataset. We exhibit an attack that works in this realistic threat model\nand demonstrate that in the small-data regime it cannot be defended against by\nDP-SGD without severely damaging the classifier accuracy. This raises\nsignificant concerns about the use of such transfer-learned classifiers when\nprotection of training-data is paramount. We demonstrate the effectiveness and\nrobustness of our attack on VGG, EfficientNet and ResNet image classifiers\ntransfer-learned on MNIST, CIFAR-10 and CelebA respectively. Additionally, we\npoint out that the commonly used (true-positive) reconstruction success rate\nmetric fails to reliably quantify the actual reconstruction effectiveness.\nInstead, we make use of the Neyman-Pearson lemma to construct the receiver\noperating characteristic curve and consider the associated true-positive\nreconstruction rate at a fixed level of the false-positive reconstruction rate."}
{"id": "2410.06530", "pdf": "https://arxiv.org/pdf/2410.06530", "abs": "https://arxiv.org/abs/2410.06530", "authors": ["Mathilde Papillon", "Guillermo Bern√°rdez", "Claudio Battiloro", "Nina Miolane"], "title": "TopoTune : A Framework for Generalized Combinatorial Complex Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) excel in learning from relational datasets as\nthey preserve the symmetries of the graph domain. However, many complex systems\n-- such as biological or social networks -- involve multiway complex\ninteractions that are more naturally represented by higher-order topological\ndomains. The emerging field of Topological Deep Learning (TDL) aims to\naccommodate and leverage these higher-order structures. Combinatorial Complex\nNeural Networks (CCNNs), fairly general TDL models, have been shown to be more\nexpressive and better performing than GNNs. However, differently from the GNN\necosystem, TDL lacks a principled and standardized framework for easily\ndefining new architectures, restricting its accessibility and applicability. To\naddress this issue, we introduce Generalized CCNNs (GCCNs), a simple yet\npowerful family of TDL models that can be used to systematically transform any\n(graph) neural network into its TDL counterpart. We prove that GCCNs generalize\nand subsume CCNNs, while extensive experiments on a diverse class of GCCNs show\nthat these architectures consistently match or outperform CCNNs, often with\nless model complexity. In an effort to accelerate and democratize TDL, we\nintroduce TopoTune, a lightweight software for defining, building, and training\nGCCNs with unprecedented flexibility and ease."}
{"id": "2501.02506", "pdf": "https://arxiv.org/pdf/2501.02506", "abs": "https://arxiv.org/abs/2501.02506", "authors": ["Junjie Ye", "Zhengyin Du", "Xuesong Yao", "Weijian Lin", "Yufei Xu", "Zehui Chen", "Zaiyuan Wang", "Sining Zhu", "Zhiheng Xi", "Siyu Yuan", "Tao Gui", "Qi Zhang", "Xuanjing Huang", "Jiecao Chen"], "title": "ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025 Main Conference", "summary": "Effective evaluation of multi-hop tool use is critical for analyzing the\nunderstanding, reasoning, and function-calling capabilities of large language\nmodels (LLMs). However, progress has been hindered by a lack of reliable\nevaluation datasets. To address this, we present ToolHop, a dataset comprising\n995 user queries and 3,912 associated tools, specifically designed for rigorous\nevaluation of multi-hop tool use. ToolHop ensures diverse queries, meaningful\ninterdependencies, locally executable tools, detailed feedback, and verifiable\nanswers through a novel query-driven data construction approach that includes\ntool creation, document refinement, and code generation. We evaluate 14 LLMs\nacross five model families (i.e., LLaMA3.1, Qwen2.5, Gemini1.5, Claude3.5, and\nGPT), uncovering significant challenges in handling multi-hop tool-use\nscenarios. The leading model, GPT-4o, achieves an accuracy of 49.04%,\nunderscoring substantial room for improvement. Further analysis reveals\nvariations in tool-use strategies for various families, offering actionable\ninsights to guide the development of more effective approaches. Code and data\ncan be found in https://huggingface.co/datasets/bytedance-research/ToolHop."}
{"id": "2405.14979", "pdf": "https://arxiv.org/pdf/2405.14979", "abs": "https://arxiv.org/abs/2405.14979", "authors": ["Weiyu Li", "Jiarui Liu", "Rui Chen", "Yixun Liang", "Xuelin Chen", "Ping Tan", "Xiaoxiao Long"], "title": "CraftsMan3D: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner", "categories": ["cs.GR", "cs.CV"], "comment": "HomePage: https://craftsman3d.github.io/, Code:\n  https://github.com/wyysf-98/CraftsMan3D", "summary": "We present a novel generative 3D modeling system, coined CraftsMan, which can\ngenerate high-fidelity 3D geometries with highly varied shapes, regular mesh\ntopologies, and detailed surfaces, and, notably, allows for refining the\ngeometry in an interactive manner. Despite the significant advancements in 3D\ngeneration, existing methods still struggle with lengthy optimization\nprocesses, irregular mesh topologies, noisy surfaces, and difficulties in\naccommodating user edits, consequently impeding their widespread adoption and\nimplementation in 3D modeling software. Our work is inspired by the craftsman,\nwho usually roughs out the holistic figure of the work first and elaborates the\nsurface details subsequently. Specifically, we employ a 3D native diffusion\nmodel, which operates on latent space learned from latent set-based 3D\nrepresentations, to generate coarse geometries with regular mesh topology in\nseconds. In particular, this process takes as input a text prompt or a\nreference image and leverages a powerful multi-view (MV) diffusion model to\ngenerate multiple views of the coarse geometry, which are fed into our\nMV-conditioned 3D diffusion model for generating the 3D geometry, significantly\nimproving robustness and generalizability. Following that, a normal-based\ngeometry refiner is used to significantly enhance the surface details. This\nrefinement can be performed automatically, or interactively with user-supplied\nedits. Extensive experiments demonstrate that our method achieves high efficacy\nin producing superior-quality 3D assets compared to existing methods. HomePage:\nhttps://craftsman3d.github.io/, Code: https://github.com/wyysf-98/CraftsMan"}
{"id": "2505.14417", "pdf": "https://arxiv.org/pdf/2505.14417", "abs": "https://arxiv.org/abs/2505.14417", "authors": ["Menglin Yang", "Yifei Zhang", "Jialin Chen", "Melanie Weber", "Rex Ying"], "title": "Towards Non-Euclidean Foundation Models: Advancing AI Beyond Euclidean Frameworks", "categories": ["cs.CG", "cs.LG"], "comment": "WWW 2025 Companion", "summary": "In the era of foundation models and Large Language Models (LLMs), Euclidean\nspace is the de facto geometric setting of our machine learning architectures.\nHowever, recent literature has demonstrated that this choice comes with\nfundamental limitations. To that end, non-Euclidean learning is quickly gaining\ntraction, particularly in web-related applications where complex relationships\nand structures are prevalent. Non-Euclidean spaces, such as hyperbolic,\nspherical, and mixed-curvature spaces, have been shown to provide more\nefficient and effective representations for data with intrinsic geometric\nproperties, including web-related data like social network topology,\nquery-document relationships, and user-item interactions. Integrating\nfoundation models with non-Euclidean geometries has great potential to enhance\ntheir ability to capture and model the underlying structures, leading to better\nperformance in search, recommendations, and content understanding. This\nworkshop focuses on the intersection of Non-Euclidean Foundation Models and\nGeometric Learning (NEGEL), exploring its potential benefits, including the\npotential benefits for advancing web-related technologies, challenges, and\nfuture directions. Workshop page:\n[https://hyperboliclearning.github.io/events/www2025workshop](https://hyperboliclearning.github.io/events/www2025workshop)"}
{"id": "2410.10868", "pdf": "https://arxiv.org/pdf/2410.10868", "abs": "https://arxiv.org/abs/2410.10868", "authors": ["Jingyang Qiao", "Zhizhong Zhang", "Xin Tan", "Yanyun Qu", "Shouhong Ding", "Yuan Xie"], "title": "Large Continual Instruction Assistant", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Continual Instruction Tuning (CIT) is adopted to continually instruct Large\nModels to follow human intent data by data. It is observed that existing\ngradient update would heavily destroy the performance on previous datasets\nduring CIT process. Instead, Exponential Moving Average (EMA), owns the ability\nto trace previous parameters, which can aid in decreasing forgetting.\nNonetheless, its stable balance weight fails to deal with the ever-changing\ndatasets, leading to the out-of-balance between plasticity and stability. In\nthis paper, we propose a general continual instruction tuning framework to\naddress the challenge. Starting from the trade-off prerequisite and EMA update,\nwe propose the plasticity and stability ideal condition. Based on Taylor\nexpansion in the loss function, we find the optimal balance weight can be\nautomatically determined by the gradients and learned parameters. Therefore, we\npropose a stable-plasticity balanced coefficient to avoid knowledge\ninterference. Based on the semantic similarity of the instructions, we can\ndetermine whether to retrain or expand the training parameters and allocate the\nmost suitable parameters for the testing instances. Extensive experiments\nacross multiple continual instruction tuning benchmarks demonstrate that our\napproach not only enhances anti-forgetting capabilities but also significantly\nimproves overall continual tuning performance. Our code is available at\nhttps://github.com/JingyangQiao/CoIN."}
{"id": "2501.06582", "pdf": "https://arxiv.org/pdf/2501.06582", "abs": "https://arxiv.org/abs/2501.06582", "authors": ["Steven H. Wang", "Maksim Zubkov", "Kexin Fan", "Sarah Harrell", "Yuyang Sun", "Wei Chen", "Andreas Plesner", "Roger Wattenhofer"], "title": "ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025. See the project page at\n  https://www.atticusprojectai.org/acord", "summary": "Information retrieval, specifically contract clause retrieval, is\nfoundational to contract drafting because lawyers rarely draft contracts from\nscratch; instead, they locate and revise the most relevant precedent. We\nintroduce the Atticus Clause Retrieval Dataset (ACORD), the first retrieval\nbenchmark for contract drafting fully annotated by experts. ACORD focuses on\ncomplex contract clauses such as Limitation of Liability, Indemnification,\nChange of Control, and Most Favored Nation. It includes 114 queries and over\n126,000 query-clause pairs, each ranked on a scale from 1 to 5 stars. The task\nis to find the most relevant precedent clauses to a query. The bi-encoder\nretriever paired with pointwise LLMs re-rankers shows promising results.\nHowever, substantial improvements are still needed to effectively manage the\ncomplex legal work typically undertaken by lawyers. As the first retrieval\nbenchmark for contract drafting annotated by experts, ACORD can serve as a\nvaluable IR benchmark for the NLP community."}
{"id": "2411.16959", "pdf": "https://arxiv.org/pdf/2411.16959", "abs": "https://arxiv.org/abs/2411.16959", "authors": ["Ezra Ameperosa", "Jeremy A. Collins", "Mrinal Jain", "Animesh Garg"], "title": "RoCoDA: Counterfactual Data Augmentation for Data-Efficient Robot Learning from Demonstrations", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted to 2025 IEEE International Conference on Robotics and\n  Automation (ICRA)", "summary": "Imitation learning in robotics faces significant challenges in generalization\ndue to the complexity of robotic environments and the high cost of data\ncollection. We introduce RoCoDA, a novel method that unifies the concepts of\ninvariance, equivariance, and causality within a single framework to enhance\ndata augmentation for imitation learning. RoCoDA leverages causal invariance by\nmodifying task-irrelevant subsets of the environment state without affecting\nthe policy's output. Simultaneously, we exploit SE(3) equivariance by applying\nrigid body transformations to object poses and adjusting corresponding actions\nto generate synthetic demonstrations. We validate RoCoDA through extensive\nexperiments on five robotic manipulation tasks, demonstrating improvements in\npolicy performance, generalization, and sample efficiency compared to\nstate-of-the-art data augmentation methods. Our policies exhibit robust\ngeneralization to unseen object poses, textures, and the presence of\ndistractors. Furthermore, we observe emergent behavior such as re-grasping,\nindicating policies trained with RoCoDA possess a deeper understanding of task\ndynamics. By leveraging invariance, equivariance, and causality, RoCoDA\nprovides a principled approach to data augmentation in imitation learning,\nbridging the gap between geometric symmetries and causal reasoning. Project\nPage: https://rocoda.github.io"}
{"id": "2505.14421", "pdf": "https://arxiv.org/pdf/2505.14421", "abs": "https://arxiv.org/abs/2505.14421", "authors": ["Zuogong Yue", "Xinyi Wang", "Victor Solo"], "title": "A system identification approach to clustering vector autoregressive time series", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "Clustering of time series based on their underlying dynamics is keeping\nattracting researchers due to its impacts on assisting complex system\nmodelling. Most current time series clustering methods handle only scalar time\nseries, treat them as white noise, or rely on domain knowledge for high-quality\nfeature construction, where the autocorrelation pattern/feature is mostly\nignored. Instead of relying on heuristic feature/metric construction, the\nsystem identification approach allows treating vector time series clustering by\nexplicitly considering their underlying autoregressive dynamics. We first\nderive a clustering algorithm based on a mixture autoregressive model.\nUnfortunately it turns out to have significant computational problems. We then\nderive a `small-noise' limiting version of the algorithm, which we call k-LMVAR\n(Limiting Mixture Vector AutoRegression), that is computationally manageable.\nWe develop an associated BIC criterion for choosing the number of clusters and\nmodel order. The algorithm performs very well in comparative simulations and\nalso scales well computationally."}
{"id": "2410.11234", "pdf": "https://arxiv.org/pdf/2410.11234", "abs": "https://arxiv.org/abs/2410.11234", "authors": ["Jiayu Chen", "Wentse Chen", "Jeff Schneider"], "title": "Bayes Adaptive Monte Carlo Tree Search for Offline Model-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "We added the code link, more empirical results, and the\n  acknowledgement", "summary": "Offline RL is a powerful approach for data-driven decision-making and\ncontrol. Compared to model-free methods, offline model-based RL (MBRL)\nexplicitly learns world models from a static dataset and uses them as surrogate\nsimulators, improving the data efficiency and enabling the learned policy to\npotentially generalize beyond the dataset support. However, there could be\nvarious MDPs that behave identically on the offline dataset and dealing with\nthe uncertainty about the true MDP can be challenging. In this paper, we\npropose modeling offline MBRL as a Bayes Adaptive Markov Decision Process\n(BAMDP), which is a principled framework for addressing model uncertainty. We\nfurther propose a novel Bayes Adaptive Monte-Carlo planning algorithm capable\nof solving BAMDPs in continuous state and action spaces with stochastic\ntransitions. This planning process is based on Monte Carlo Tree Search and can\nbe integrated into offline MBRL as a policy improvement operator in policy\niteration. Our ``RL + Search\" framework follows in the footsteps of superhuman\nAIs like AlphaZero, improving on current offline MBRL methods by incorporating\nmore computation input. The proposed algorithm significantly outperforms\nstate-of-the-art offline RL methods on twelve D4RL MuJoCo tasks and three\ntarget tracking tasks in a challenging, stochastic tokamak control simulator.\nThe codebase is available at: https://github.com/LucasCJYSDL/Offline-RL-Kit."}
{"id": "2501.07482", "pdf": "https://arxiv.org/pdf/2501.07482", "abs": "https://arxiv.org/abs/2501.07482", "authors": ["Thales Sales Almeida", "Giovana Kerche Bon√°s", "Jo√£o Guilherme Alves Santos", "Hugo Abonizio", "Rodrigo Nogueira"], "title": "TiEBe: Tracking Language Model Recall of Notable Worldwide Events Through Time", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As the knowledge landscape evolves and large language models (LLMs) become\nincreasingly widespread, there is a growing need to keep these models updated\nwith current events. While existing benchmarks assess general factual recall,\nfew studies explore how LLMs retain knowledge over time or across different\nregions. To address these gaps, we present the Timely Events Benchmark (TiEBe),\na dataset of over 23,000 question-answer pairs centered on notable global and\nregional events, spanning more than 10 years of events, 23 regions, and 13\nlanguages. TiEBe leverages structured retrospective data from Wikipedia to\nidentify notable events through time. These events are then used to construct a\nbenchmark to evaluate LLMs' understanding of global and regional developments,\ngrounded in factual evidence beyond Wikipedia itself. Our results reveal\nsignificant geographic disparities in factual recall, emphasizing the need for\nmore balanced global representation in LLM training. We also observe a Pearson\ncorrelation of more than 0.7 between models' performance in TiEBe and various\ncountries' socioeconomic indicators, such as HDI. In addition, we examine the\nimpact of language on factual recall by posing questions in the native language\nof the region where each event occurred, uncovering substantial performance\ngaps for low-resource languages."}
{"id": "2501.08828", "pdf": "https://arxiv.org/pdf/2501.08828", "abs": "https://arxiv.org/abs/2501.08828", "authors": ["Kuicai Dong", "Yujing Chang", "Xin Deik Goh", "Dexun Li", "Ruiming Tang", "Yong Liu"], "title": "MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "comment": "https://huggingface.co/MMDocIR", "summary": "Multimodal document retrieval aims to identify and retrieve various forms of\nmultimodal content, such as figures, tables, charts, and layout information\nfrom extensive documents. Despite its increasing popularity, there is a notable\nlack of a comprehensive and robust benchmark to effectively evaluate the\nperformance of systems in such tasks. To address this gap, this work introduces\na new benchmark, named MMDocIR, that encompasses two distinct tasks: page-level\nand layout-level retrieval. The former evaluates the performance of identifying\nthe most relevant pages within a long document, while the later assesses the\nability of detecting specific layouts, providing a more fine-grained measure\nthan whole-page analysis. A layout refers to a variety of elements, including\ntextual paragraphs, equations, figures, tables, or charts. The MMDocIR\nbenchmark comprises a rich dataset featuring 1,685 questions annotated by\nexperts and 173,843 questions with bootstrapped labels, making it a valuable\nresource in multimodal document retrieval for both training and evaluation.\nThrough rigorous experiments, we demonstrate that (i) visual retrievers\nsignificantly outperform their text counterparts, (ii) MMDocIR training set\neffectively enhances the performance of multimodal document retrieval and (iii)\ntext retrievers leveraging VLM-text significantly outperforms retrievers\nrelying on OCR-text. Our dataset is available at\nhttps://mmdocrag.github.io/MMDocIR/."}
{"id": "2505.14507", "pdf": "https://arxiv.org/pdf/2505.14507", "abs": "https://arxiv.org/abs/2505.14507", "authors": ["Jingyun Chen", "David Horowitz", "Yading Yuan"], "title": "Federated prediction for scalable and privacy-preserved knowledge-based planning in radiotherapy", "categories": ["cs.DC", "cs.LG"], "comment": "Under review for publication by the journal of Medical Physics", "summary": "Background: Deep learning has potential to improve the efficiency and\nconsistency of radiation therapy planning, but clinical adoption is hindered by\nthe limited model generalizability due to data scarcity and heterogeneity among\ninstitutions. Although aggregating data from different institutions could\nalleviate this problem, data sharing is a practical challenge due to concerns\nabout patient data privacy and other technical obstacles. Purpose: This work\naims to address this dilemma by developing FedKBP+, a comprehensive federated\nlearning (FL) platform for predictive tasks in real-world applications in\nradiotherapy treatment planning. Methods: We implemented a unified\ncommunication stack based on Google Remote Procedure Call (gRPC) to support\ncommunication between participants whether located on the same workstation or\ndistributed across multiple workstations. In addition to supporting the\ncentralized FL strategies commonly available in existing open-source\nframeworks, FedKBP+ also provides a fully decentralized FL model where\nparticipants directly exchange model weights to each other through Peer-to-Peer\ncommunication. We evaluated FedKBP+ on three predictive tasks using\nscale-attention network (SA-Net) as the predictive model. Conclusions: Our\nresults demonstrate that FedKBP+ is highly effective, efficient and robust,\nshowing great potential as a federated learning platform for radiation therapy."}
{"id": "2410.17980", "pdf": "https://arxiv.org/pdf/2410.17980", "abs": "https://arxiv.org/abs/2410.17980", "authors": ["Shawn Tan", "Songlin Yang", "Aaron Courville", "Rameswar Panda", "Yikang Shen"], "title": "Scaling Stick-Breaking Attention: An Efficient Implementation and In-depth Study", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The self-attention mechanism traditionally relies on the softmax operator,\nnecessitating positional embeddings like RoPE, or position biases to account\nfor token order. But current methods using still face length generalisation\nchallenges. We investigate an alternative attention mechanism based on the\nstick-breaking process in larger scale settings. The method works as follows:\nFor each token before the current, we determine a break point, which represents\nthe proportion of the stick, the weight of the attention, to allocate to the\ncurrent token. We repeat this on the remaining stick, until all tokens are\nallocated a weight, resulting in a sequence of attention weights. This process\nnaturally incorporates recency bias, which has linguistic motivations for\ngrammar parsing. We study the implications of replacing the conventional\nsoftmax-based attention mechanism with stick-breaking attention. We then\ndiscuss implementation of numerically stable stick-breaking attention and adapt\nFlash Attention to accommodate this mechanism. When used as a drop-in\nreplacement for current softmax+RoPE attention systems, we find that\nstick-breaking attention performs competitively with current methods on length\ngeneralisation and downstream tasks. Stick-breaking also performs well at\nlength generalisation, allowing a model trained with $2^{11}$ context window to\nperform well at $2^{14}$ with perplexity improvements."}
{"id": "2501.14315", "pdf": "https://arxiv.org/pdf/2501.14315", "abs": "https://arxiv.org/abs/2501.14315", "authors": ["Chao-Chung Wu", "Zhi Rui Tam", "Chieh-Yen Lin", "Yun-Nung Chen", "Shao-Hua Sun", "Hung-yi Lee"], "title": "Mitigating Forgetting in LLM Fine-Tuning via Low-Perplexity Token Learning", "categories": ["cs.CL"], "comment": null, "summary": "Maintaining consistent model performance across domains is a fundamental\nchallenge in machine learning. While recent work has explored using\nLLM-generated data for fine-tuning, its impact on cross-domain generalization\nremains poorly understood. This paper presents a systematic analysis revealing\nthat fine-tuning with LLM-generated data not only improves target task\nperformance but also reduces non-target task degradation compared to\nfine-tuning with ground truth data. Through analyzing the data sequence in\ntasks of various domains, we demonstrate that this enhancement of non-target\ntask robustness stems from the reduction of high perplexity tokens found in\nLLM-generated sequences. Following our findings, we showed that masking high\nperplexity tokens in ground truth training data achieves similar non-target\ntask performance preservation, comparable to using LLM-generated data.\nExtensive experiments across different model families and scales, including\nGemma 2 IT 2B, Llama 3 8B Instruct, and 3 additional models, agree with our\nfindings. To the best of our knowledge, this is the first work to provide an\nempirical explanation based on token perplexity reduction to mitigate\ncatastrophic forgetting in LLMs after fine-tuning, offering valuable insights\nfor developing more robust fine-tuning strategies."}
{"id": "2502.05505", "pdf": "https://arxiv.org/pdf/2502.05505", "abs": "https://arxiv.org/abs/2502.05505", "authors": ["Zinan Lin", "Tadas Baltrusaitis", "Wenyu Wang", "Sergey Yekhanin"], "title": "Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model", "categories": ["cs.LG", "cs.CR", "cs.CV", "stat.ML"], "comment": "Published in: (1) ICLR 2025 Workshop on Data Problems, (2) ICLR 2025\n  Workshop on Synthetic Data", "summary": "Differentially private (DP) synthetic data, which closely resembles the\noriginal private data while maintaining strong privacy guarantees, has become a\nkey tool for unlocking the value of private data without compromising privacy.\nRecently, Private Evolution (PE) has emerged as a promising method for\ngenerating DP synthetic data. Unlike other training-based approaches, PE only\nrequires access to inference APIs from foundation models, enabling it to\nharness the power of state-of-the-art (SoTA) models. However, a suitable\nfoundation model for a specific private data domain is not always available. In\nthis paper, we discover that the PE framework is sufficiently general to allow\nAPIs beyond foundation models. In particular, we demonstrate that many SoTA\ndata synthesizers that do not rely on neural networks--such as computer\ngraphics-based image generators, which we refer to as simulators--can be\neffectively integrated into PE. This insight significantly broadens PE's\napplicability and unlocks the potential of powerful simulators for DP data\nsynthesis. We explore this approach, named Sim-PE, in the context of image\nsynthesis. Across four diverse simulators, Sim-PE performs well, improving the\ndownstream classification accuracy of PE by up to 3x, reducing FID by up to\n80%, and offering much greater efficiency. We also show that simulators and\nfoundation models can be easily leveraged together within PE to achieve further\nimprovements. The code is open-sourced in the Private Evolution Python library:\nhttps://github.com/microsoft/DPSDA."}
{"id": "2505.14529", "pdf": "https://arxiv.org/pdf/2505.14529", "abs": "https://arxiv.org/abs/2505.14529", "authors": ["Christian Gouri√©roux", "Yang Lu"], "title": "A simple estimator of the correlation kernel matrix of a determinantal point process", "categories": ["stat.ML", "cs.LG", "62G30"], "comment": null, "summary": "The Determinantal Point Process (DPP) is a parameterized model for\nmultivariate binary variables, characterized by a correlation kernel matrix.\nThis paper proposes a closed form estimator of this kernel, which is\nparticularly easy to implement and can also be used as a starting value of\nlearning algorithms for maximum likelihood estimation. We prove the consistency\nand asymptotic normality of our estimator, as well as its large deviation\nproperties."}
{"id": "2410.21673", "pdf": "https://arxiv.org/pdf/2410.21673", "abs": "https://arxiv.org/abs/2410.21673", "authors": ["Lin Li", "Xinchun Yu", "Xinyu Chen", "Peng Liang"], "title": "Knowledge-Guided Prompt Learning for Request Quality Assurance in Public Code Review", "categories": ["cs.SE", "cs.AI"], "comment": "27 pages, 5 images, 12 tables, Manuscript revision submitted to a\n  journal (2025)", "summary": "Public Code Review (PCR) is developed in the Software Question Answering\n(SQA) community, assisting developers in exploring high-quality and efficient\nreview services. Current methods on PCR mainly focus on the reviewer's\nperspective, including finding a capable reviewer, predicting comment quality,\nand recommending/generating review comments. However, it is not well studied\nthat how to satisfy the review necessity requests posted by developers which\ncan increase their visibility, which in turn acts as a prerequisite for better\nreview responses. To this end, we propose Knowledge-guided Prompt learning for\nPublic Code Review (KP-PCR) to achieve developer-based code review request\nquality assurance (i.e., predicting request necessity and recommending tags\nsubtask). Specifically, we reformulate the two subtasks via 1) text prompt\ntuning which converts both of them into a Masked Language Model (MLM) by\nconstructing prompt templates using hard prompt; and 2) knowledge and code\nprefix tuning which introduces knowledge guidance from fine-tuned large\nlanguage models by soft prompt, and uses program dependence graph to\ncharacterize code snippets. Finally, both of the request necessity prediction\nand tag recommendation subtasks output predicted results through an answer\nengineering module. In addition, we further analysis the time complexity of our\nKP-PCR that has lightweight prefix based the operation of introducing knowledge\nguidance. Experimental results on the PCR dataset for the period 2011-2023\ndemonstrate that our KP-PCR outperforms baselines by 2.3%-8.4% in the request\nnecessity prediction and by 1.4%-6.9% in the tag recommendation. The code\nimplementation is released at https://github.com/WUT-IDEA/KP-PCR."}
{"id": "2501.15451", "pdf": "https://arxiv.org/pdf/2501.15451", "abs": "https://arxiv.org/abs/2501.15451", "authors": ["Zewen Bai", "Shengdi Yin", "Junyu Lu", "Jingjie Zeng", "Haohao Zhu", "Yuanyuan Sun", "Liang Yang", "Hongfei Lin"], "title": "STATE ToxiCN: A Benchmark for Span-level Target-Aware Toxicity Extraction in Chinese Hate Speech Detection", "categories": ["cs.CL"], "comment": "Our paper has been accepted by ACL 2025 Findings", "summary": "The proliferation of hate speech has caused significant harm to society. The\nintensity and directionality of hate are closely tied to the target and\nargument it is associated with. However, research on hate speech detection in\nChinese has lagged behind, and existing datasets lack span-level fine-grained\nannotations. Furthermore, the lack of research on Chinese hateful slang poses a\nsignificant challenge. In this paper, we provide a solution for fine-grained\ndetection of Chinese hate speech. First, we construct a dataset containing\nTarget-Argument-Hateful-Group quadruples (STATE ToxiCN), which is the first\nspan-level Chinese hate speech dataset. Secondly, we evaluate the span-level\nhate speech detection performance of existing models using STATE ToxiCN.\nFinally, we conduct the first study on Chinese hateful slang and evaluate the\nability of LLMs to detect such expressions. Our work contributes valuable\nresources and insights to advance span-level hate speech detection in Chinese."}
{"id": "2502.13061", "pdf": "https://arxiv.org/pdf/2502.13061", "abs": "https://arxiv.org/abs/2502.13061", "authors": ["Jingbiao Mei", "Jinghong Chen", "Guangyu Yang", "Weizhe Lin", "Bill Byrne"], "title": "Robust Adaptation of Large Multimodal Models for Retrieval Augmented Hateful Meme Detection", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "Preprint. Under Review", "summary": "Hateful memes have become a significant concern on the Internet,\nnecessitating robust automated detection systems. While LMMs have shown promise\nin hateful meme detection, they face notable challenges like sub-optimal\nperformance and limited out-of-domain generalization capabilities. Recent\nstudies further reveal the limitations of both SFT and in-context learning when\napplied to LMMs in this setting. To address these issues, we propose a robust\nadaptation framework for hateful meme detection that enhances in-domain\naccuracy and cross-domain generalization while preserving the general\nvision-language capabilities of LMMs. Experiments on six meme classification\ndatasets show that our approach achieves state-of-the-art performance,\noutperforming larger agentic systems. Moreover, our method generates\nhigher-quality rationales for explaining hateful content compared to standard\nSFT, enhancing model interpretability."}
{"id": "2505.14534", "pdf": "https://arxiv.org/pdf/2505.14534", "abs": "https://arxiv.org/abs/2505.14534", "authors": ["Chongyang Shi", "Sharon Lin", "Shuang Song", "Jamie Hayes", "Ilia Shumailov", "Itay Yona", "Juliette Pluto", "Aneesh Pappu", "Christopher A. Choquette-Choo", "Milad Nasr", "Chawin Sitawarin", "Gena Gibson", "Andreas Terzis", "John \"Four\" Flynn"], "title": "Lessons from Defending Gemini Against Indirect Prompt Injections", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Gemini is increasingly used to perform tasks on behalf of users, where\nfunction-calling and tool-use capabilities enable the model to access user\ndata. Some tools, however, require access to untrusted data introducing risk.\nAdversaries can embed malicious instructions in untrusted data which cause the\nmodel to deviate from the user's expectations and mishandle their data or\npermissions. In this report, we set out Google DeepMind's approach to\nevaluating the adversarial robustness of Gemini models and describe the main\nlessons learned from the process. We test how Gemini performs against a\nsophisticated adversary through an adversarial evaluation framework, which\ndeploys a suite of adaptive attack techniques to run continuously against past,\ncurrent, and future versions of Gemini. We describe how these ongoing\nevaluations directly help make Gemini more resilient against manipulation."}
{"id": "2411.18463", "pdf": "https://arxiv.org/pdf/2411.18463", "abs": "https://arxiv.org/abs/2411.18463", "authors": ["Jiahan Li", "Tong Chen", "Shitong Luo", "Chaoran Cheng", "Jiaqi Guan", "Ruihan Guo", "Sheng Wang", "Ge Liu", "Jian Peng", "Jianzhu Ma"], "title": "Hotspot-Driven Peptide Design via Multi-Fragment Autoregressive Extension", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": "Published as a conference paper at ICLR 2025", "summary": "Peptides, short chains of amino acids, interact with target proteins, making\nthem a unique class of protein-based therapeutics for treating human diseases.\nRecently, deep generative models have shown great promise in peptide\ngeneration. However, several challenges remain in designing effective peptide\nbinders. First, not all residues contribute equally to peptide-target\ninteractions. Second, the generated peptides must adopt valid geometries due to\nthe constraints of peptide bonds. Third, realistic tasks for peptide drug\ndevelopment are still lacking. To address these challenges, we introduce\nPepHAR, a hot-spot-driven autoregressive generative model for designing\npeptides targeting specific proteins. Building on the observation that certain\nhot spot residues have higher interaction potentials, we first use an\nenergy-based density model to fit and sample these key residues. Next, to\nensure proper peptide geometry, we autoregressively extend peptide fragments by\nestimating dihedral angles between residue frames. Finally, we apply an\noptimization process to iteratively refine fragment assembly, ensuring correct\npeptide structures. By combining hot spot sampling with fragment-based\nextension, our approach enables de novo peptide design tailored to a target\nprotein and allows the incorporation of key hot spot residues into peptide\nscaffolds. Extensive experiments, including peptide design and peptide scaffold\ngeneration, demonstrate the strong potential of PepHAR in computational peptide\nbinder design. Source code will be available at\nhttps://github.com/Ced3-han/PepHAR."}
{"id": "2501.15654", "pdf": "https://arxiv.org/pdf/2501.15654", "abs": "https://arxiv.org/abs/2501.15654", "authors": ["Jenna Russell", "Marzena Karpinska", "Mohit Iyyer"], "title": "People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 33 pages", "summary": "In this paper, we study how well humans can detect text generated by\ncommercial LLMs (GPT-4o, Claude, o1). We hire annotators to read 300\nnon-fiction English articles, label them as either human-written or\nAI-generated, and provide paragraph-length explanations for their decisions.\nOur experiments show that annotators who frequently use LLMs for writing tasks\nexcel at detecting AI-generated text, even without any specialized training or\nfeedback. In fact, the majority vote among five such \"expert\" annotators\nmisclassifies only 1 of 300 articles, significantly outperforming most\ncommercial and open-source detectors we evaluated even in the presence of\nevasion tactics like paraphrasing and humanization. Qualitative analysis of the\nexperts' free-form explanations shows that while they rely heavily on specific\nlexical clues ('AI vocabulary'), they also pick up on more complex phenomena\nwithin the text (e.g., formality, originality, clarity) that are challenging to\nassess for automatic detectors. We release our annotated dataset and code to\nspur future research into both human and automated detection of AI-generated\ntext."}
{"id": "2503.01776", "pdf": "https://arxiv.org/pdf/2503.01776", "abs": "https://arxiv.org/abs/2503.01776", "authors": ["Tiansheng Wen", "Yifei Wang", "Zequn Zeng", "Zhong Peng", "Yudi Su", "Xinyang Liu", "Bo Chen", "Hongwei Liu", "Stefanie Jegelka", "Chenyu You"], "title": "Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IR"], "comment": "Accepted by ICML2025", "summary": "Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep"}
{"id": "2505.14581", "pdf": "https://arxiv.org/pdf/2505.14581", "abs": "https://arxiv.org/abs/2505.14581", "authors": ["Deemah H. Tashman", "Soumaya Cherkaoui", "Walaa Hamouda"], "title": "Performance Optimization of Energy-Harvesting Underlay Cognitive Radio Networks Using Reinforcement Learning", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "In this paper, a reinforcement learning technique is employed to maximize the\nperformance of a cognitive radio network (CRN). In the presence of primary\nusers (PUs), it is presumed that two secondary users (SUs) access the licensed\nband within underlay mode. In addition, the SU transmitter is assumed to be an\nenergy-constrained device that requires harvesting energy in order to transmit\nsignals to their intended destination. Therefore, we propose that there are two\nmain sources of energy; the interference of PUs' transmissions and ambient\nradio frequency (RF) sources. The SU will select whether to gather energy from\nPUs or only from ambient sources based on a predetermined threshold. The\nprocess of energy harvesting from the PUs' messages is accomplished via the\ntime switching approach. In addition, based on a deep Q-network (DQN) approach,\nthe SU transmitter determines whether to collect energy or transmit messages\nduring each time slot as well as selects the suitable transmission power in\norder to maximize its average data rate. Our approach outperforms a baseline\nstrategy and converges, as shown by our findings."}
{"id": "2412.18169", "pdf": "https://arxiv.org/pdf/2412.18169", "abs": "https://arxiv.org/abs/2412.18169", "authors": ["Rongxin Cheng", "Yuxin Lai", "Xingda Wei", "Rong Chen", "Haibo Chen"], "title": "KunServe: Efficient Parameter-centric Memory Management for LLM Serving", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Serving LLMs with a cluster of GPUs is common nowadays, where the serving\nsystem must meet strict latency SLOs required by applications. However, the\nstateful nature of LLM serving requires maintaining huge states (i.e., KVCache)\nin limited GPU memory. Under spikes in real-world workloads, GPU memory can be\neasily throttled, leading to orders of magnitude higher response latency due to\nqueuing introduced by waiting for KVCache to be reclaimed. Prior\nKVCache-centric approaches handle load throttling by dropping, migrating, or\nswapping KVCache. These methods fail to release sufficient memory quickly with\nrequests still queued.\n  This paper proposes the first parameter-centric approach to handling\nthrottling by selectively dropping replicated parameters to instantly free\nmemory for requests, based on an unnoticed observation that model parameters\nare commonly replicated across GPUs for serving LLMs. With additional memory,\nall requests can be served with a larger batch without queuing. To make the\nparameter-centric approach correct and efficient, we cooperatively execute\nrequests on GPUs with a complete copy of parameters using pipeline parallelism,\nand derive an appropriate drop plan without unnecessary cooperation. We also\ndesign techniques to minimize the performance overhead due to pipeline\nparallelism with the execution patterns of requests under drop. Evaluations\nshow that {\\sys} reduces the tail TTFT of requests under throttling by up to\n72.2 times compared to the state-of-the-art systems including Llumnix, vLLM and\nInferCept."}
{"id": "2501.19202", "pdf": "https://arxiv.org/pdf/2501.19202", "abs": "https://arxiv.org/abs/2501.19202", "authors": ["Dang Huu-Tien", "Hoang Thanh-Tung", "Anh Bui", "Le-Minh Nguyen", "Naoya Inoue"], "title": "Improving LLM Unlearning Robustness via Random Perturbations", "categories": ["cs.CL"], "comment": "23 pages, 10 figures, 5 tables", "summary": "In this paper, we show that current state-of-the-art LLM unlearning methods\ninherently reduce models' robustness, causing them to misbehave even when a\nsingle non-adversarial forget-token is in the retain-query. Toward\nunderstanding underlying causes, we reframe the unlearning process as backdoor\nattacks and defenses: forget-tokens act as backdoor triggers that, when\nactivated in retain-queries, cause disruptions in unlearned models' behaviors,\nsimilar to successful backdoor attacks. To mitigate this vulnerability, we\npropose Random Noise Augmentation (RNA) -- a plug-and-play, model and method\nagnostic approach with theoretical guarantees for improving the robustness of\nunlearned models. Extensive experiments demonstrate that RNA significantly\nimproves the robustness of unlearned models, maintains unlearning performances\nwhile introducing no additional computational overhead."}
{"id": "2504.14440", "pdf": "https://arxiv.org/pdf/2504.14440", "abs": "https://arxiv.org/abs/2504.14440", "authors": ["Chuhao Liu", "Zhijian Qiao", "Jieqi Shi", "Ke Wang", "Peize Liu", "Shaojie Shen"], "title": "SG-Reg: Generalizable and Efficient Scene Graph Registration", "categories": ["cs.RO", "cs.CV"], "comment": "IEEE Transactions Robotics Regular Paper", "summary": "This paper addresses the challenges of registering two rigid semantic scene\ngraphs, an essential capability when an autonomous agent needs to register its\nmap against a remote agent, or against a prior map. The hand-crafted\ndescriptors in classical semantic-aided registration, or the ground-truth\nannotation reliance in learning-based scene graph registration, impede their\napplication in practical real-world environments. To address the challenges, we\ndesign a scene graph network to encode multiple modalities of semantic nodes:\nopen-set semantic feature, local topology with spatial awareness, and shape\nfeature. These modalities are fused to create compact semantic node features.\nThe matching layers then search for correspondences in a coarse-to-fine manner.\nIn the back-end, we employ a robust pose estimator to decide transformation\naccording to the correspondences. We manage to maintain a sparse and\nhierarchical scene representation. Our approach demands fewer GPU resources and\nfewer communication bandwidth in multi-agent tasks. Moreover, we design a new\ndata generation approach using vision foundation models and a semantic mapping\nmodule to reconstruct semantic scene graphs. It differs significantly from\nprevious works, which rely on ground-truth semantic annotations to generate\ndata. We validate our method in a two-agent SLAM benchmark. It significantly\noutperforms the hand-crafted baseline in terms of registration success rate.\nCompared to visual loop closure networks, our method achieves a slightly higher\nregistration recall while requiring only 52 KB of communication bandwidth for\neach query frame. Code available at:\n\\href{http://github.com/HKUST-Aerial-Robotics/SG-Reg}{http://github.com/HKUST-Aerial-Robotics/SG-Reg}."}
{"id": "2505.14587", "pdf": "https://arxiv.org/pdf/2505.14587", "abs": "https://arxiv.org/abs/2505.14587", "authors": ["Hamza Cherkaoui", "Malik Tiomoko", "Mohamed El Amine Seddik", "Cosme Louart", "Ekkehard Schnoor", "Balazs Kegl"], "title": "High-Dimensional Analysis of Bootstrap Ensemble Classifiers", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Bootstrap methods have long been a cornerstone of ensemble learning in\nmachine learning. This paper presents a theoretical analysis of bootstrap\ntechniques applied to the Least Square Support Vector Machine (LSSVM) ensemble\nin the context of large and growing sample sizes and feature dimensionalities.\nLeveraging tools from Random Matrix Theory, we investigate the performance of\nthis classifier that aggregates decision functions from multiple weak\nclassifiers, each trained on different subsets of the data. We provide insights\ninto the use of bootstrap methods in high-dimensional settings, enhancing our\nunderstanding of their impact. Based on these findings, we propose strategies\nto select the number of subsets and the regularization parameter that maximize\nthe performance of the LSSVM. Empirical experiments on synthetic and real-world\ndatasets validate our theoretical results."}
{"id": "2501.08046", "pdf": "https://arxiv.org/pdf/2501.08046", "abs": "https://arxiv.org/abs/2501.08046", "authors": ["Miriana Calvano", "Antonio Curci", "Giuseppe Desolda", "Andrea Esposito", "Rosa Lanzilotti", "Antonio Piccinno"], "title": "Building Symbiotic AI: Reviewing the AI Act for a Human-Centred, Principle-Based Framework", "categories": ["cs.HC", "cs.AI"], "comment": "Third version: 36 pages", "summary": "Artificial Intelligence (AI) spreads quickly as new technologies and services\ntake over modern society. The need to regulate AI design, development, and use\nis strictly necessary to avoid unethical and potentially dangerous consequences\nto humans. The European Union (EU) has released a new legal framework, the AI\nAct, to regulate AI by undertaking a risk-based approach to safeguard humans\nduring interaction. At the same time, researchers offer a new perspective on AI\nsystems, commonly known as Human-Centred AI (HCAI), highlighting the need for a\nhuman-centred approach to their design. In this context, Symbiotic AI (a\nsubtype of HCAI) promises to enhance human capabilities through a deeper and\ncontinuous collaboration between human intelligence and AI. This article\npresents the results of a Systematic Literature Review (SLR) that aims to\nidentify principles that characterise the design and development of Symbiotic\nAI systems while considering humans as the core of the process. Through content\nanalysis, four principles emerged from the review that must be applied to\ncreate Human-Centred AI systems that can establish a symbiotic relationship\nwith humans. In addition, current trends and challenges were defined to\nindicate open questions that may guide future research for the development of\nSAI systems that comply with the AI Act."}
{"id": "2502.02095", "pdf": "https://arxiv.org/pdf/2502.02095", "abs": "https://arxiv.org/abs/2502.02095", "authors": ["Bowen Ping", "Jiali Zeng", "Fandong Meng", "Shuo Wang", "Jie Zhou", "Shanghang Zhang"], "title": "LongDPO: Unlock Better Long-form Generation Abilities for LLMs via Critique-augmented Stepwise Information", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "Long-form generation is crucial for academic writing papers and repo-level\ncode generation. Despite this, current models, including GPT-4o, still exhibit\nunsatisfactory performance. Existing methods that utilize preference learning\nwith outcome supervision often fail to provide detailed feedback for extended\ncontexts. This shortcoming can lead to content that does not fully satisfy\nquery requirements, resulting in issues like length deviations, and diminished\nquality. In this paper, we propose enhancing long-form generation by\nincorporating process supervision. We employ Monte Carlo Tree Search to gather\nstepwise preference pairs, utilizing a global memory pool to maintain\nconsistency. To address the issue of suboptimal candidate selection, we\nintegrate external critiques to refine and improve the quality of the\npreference pairs. Finally, we apply step-level DPO using the collected stepwise\npreference pairs. Experimental results show that our method improves length and\nquality on long-form generation benchmarks, with almost lossless performance on\ngeneral benchmarks across various model backbones."}
{"id": "2505.06993", "pdf": "https://arxiv.org/pdf/2505.06993", "abs": "https://arxiv.org/abs/2505.06993", "authors": ["Yuxuan He", "Junpeng Zhang", "Lei Cheng", "Hongyuan Zhang", "Quanshi Zhang"], "title": "Technical Report: Quantifying and Analyzing the Generalization Power of a DNN", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "This paper proposes a new perspective for analyzing the generalization power\nof deep neural networks (DNNs), i.e., directly disentangling and analyzing the\ndynamics of generalizable and non-generalizable interaction encoded by a DNN\nthrough the training process. Specifically, this work builds upon the recent\ntheoretical achievement in explainble AI, which proves that the detailed\ninference logic of DNNs can be can be strictly rewritten as a small number of\nAND-OR interaction patterns. Based on this, we propose an efficient method to\nquantify the generalization power of each interaction, and we discover a\ndistinct three-phase dynamics of the generalization power of interactions\nduring training. In particular, the early phase of training typically removes\nnoisy and non-generalizable interactions and learns simple and generalizable\nones. The second and the third phases tend to capture increasingly complex\ninteractions that are harder to generalize. Experimental results verify that\nthe learning of non-generalizable interactions is the the direct cause for the\ngap between the training and testing losses."}
{"id": "2505.14647", "pdf": "https://arxiv.org/pdf/2505.14647", "abs": "https://arxiv.org/abs/2505.14647", "authors": ["Sina Sharifi", "Erfan Yazdandoost Hamedani", "Mahyar Fazlyab"], "title": "Sequential QCQP for Bilevel Optimization with Line Search", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": "Under Review", "summary": "Bilevel optimization involves a hierarchical structure where one problem is\nnested within another, leading to complex interdependencies between levels. We\npropose a single-loop, tuning-free algorithm that guarantees anytime\nfeasibility, i.e., approximate satisfaction of the lower-level optimality\ncondition, while ensuring descent of the upper-level objective. At each\niteration, a convex quadratically-constrained quadratic program (QCQP) with a\nclosed-form solution yields the search direction, followed by a backtracking\nline search inspired by control barrier functions to ensure safe, uniformly\npositive step sizes. The resulting method is scalable, requires no\nhyperparameter tuning, and converges under mild local regularity assumptions.\nWe establish an O(1/k) ergodic convergence rate and demonstrate the algorithm's\neffectiveness on representative bilevel tasks."}
{"id": "2501.12668", "pdf": "https://arxiv.org/pdf/2501.12668", "abs": "https://arxiv.org/abs/2501.12668", "authors": ["Myunsoo Kim", "Hayeong Lee", "Seong-Woong Shim", "JunHo Seo", "Byung-Jun Lee"], "title": "NBDI: A Simple and Effective Termination Condition for Skill Extraction from Task-Agnostic Demonstrations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Intelligent agents are able to make decisions based on different levels of\ngranularity and duration. Recent advances in skill learning enabled the agent\nto solve complex, long-horizon tasks by effectively guiding the agent in\nchoosing appropriate skills. However, the practice of using fixed-length skills\ncan easily result in skipping valuable decision points, which ultimately limits\nthe potential for further exploration and faster policy learning. In this work,\nwe propose to learn a simple and effective termination condition that\nidentifies decision points through a state-action novelty module that leverages\nagent experience data. Our approach, Novelty-based Decision Point\nIdentification (NBDI), outperforms previous baselines in complex, long-horizon\ntasks, and remains effective even in the presence of significant variations in\nthe environment configurations of downstream tasks, highlighting the importance\nof decision point identification in skill learning."}
{"id": "2502.02362", "pdf": "https://arxiv.org/pdf/2502.02362", "abs": "https://arxiv.org/abs/2502.02362", "authors": ["Sagnik Mukherjee", "Abhinav Chinta", "Takyoung Kim", "Tarun Anoop Sharma", "Dilek Hakkani-T√ºr"], "title": "Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs", "categories": ["cs.CL"], "comment": "Accepted at ICML 2025", "summary": "Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large\nlanguage models (LLMs) by enabling detailed step-by-step solutions. However,\ndue to the verbosity of LLMs, the resulting reasoning chains can be long,\nmaking it harder to verify the reasoning steps and trace issues resulting from\ndependencies between the steps that may be farther away in the sequence of\nsteps. Importantly, mathematical reasoning allows each step to be derived from\na small set of premises, which are a subset of the preceding steps in the\nreasoning chain. In this paper, we present a framework that identifies the\npremises for each step, to improve the evaluation of reasoning. We restructure\nconventional linear reasoning chains into Premise Augmented Reasoning Chains\n(PARC) by introducing premise links, resulting in a directed acyclic graph\nwhere the nodes are the steps and the edges are the premise links. Through\nexperiments with a PARC-based dataset that we built, namely PERL (Premises and\nERrors identification in LLMs), we demonstrate that LLMs can reliably identify\npremises within complex reasoning chains. In particular, even open-source LLMs\nachieve 90% recall in premise identification. We also show that PARC helps to\nidentify errors in reasoning chains more reliably. The accuracy of error\nidentification improves by 6% to 16% absolute when step-by-step verification is\ncarried out in PARC under the premises. Our findings highlight the utility of\npremise-centric representations in addressing complex problem-solving tasks and\nopen new avenues for improving the reliability of LLM-based reasoning\nevaluations."}
{"id": "2505.07447", "pdf": "https://arxiv.org/pdf/2505.07447", "abs": "https://arxiv.org/abs/2505.07447", "authors": ["Peng Sun", "Yi Jiang", "Tao Lin"], "title": "Unified Continuous Generative Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "https://github.com/LINs-lab/UCGM", "summary": "Recent advances in continuous generative models, including multi-step\napproaches like diffusion and flow-matching (typically requiring 8-1000\nsampling steps) and few-step methods such as consistency models (typically 1-8\nsteps), have demonstrated impressive generative performance. However, existing\nwork often treats these approaches as distinct paradigms, resulting in separate\ntraining and sampling methodologies. We introduce a unified framework for\ntraining, sampling, and analyzing these models. Our implementation, the Unified\nContinuous Generative Models Trainer and Sampler (UCGM-{T,S}), achieves\nstate-of-the-art (SOTA) performance. For example, on ImageNet 256x256 using a\n675M diffusion transformer, UCGM-T trains a multi-step model achieving 1.30 FID\nin 20 steps and a few-step model reaching 1.42 FID in just 2 steps.\nAdditionally, applying UCGM-S to a pre-trained model (previously 1.26 FID at\n250 steps) improves performance to 1.06 FID in only 40 steps. Code is available\nat: https://github.com/LINs-lab/UCGM."}
{"id": "2505.14670", "pdf": "https://arxiv.org/pdf/2505.14670", "abs": "https://arxiv.org/abs/2505.14670", "authors": ["Jiaqi Leng", "Bin Shi"], "title": "Quantum Optimization via Gradient-Based Hamiltonian Descent", "categories": ["quant-ph", "cs.LG", "math.OC"], "comment": "19 pages, 6 figures. To appear in the proceedings of ICML 2025", "summary": "With rapid advancements in machine learning, first-order algorithms have\nemerged as the backbone of modern optimization techniques, owing to their\ncomputational efficiency and low memory requirements. Recently, the connection\nbetween accelerated gradient methods and damped heavy-ball motion, particularly\nwithin the framework of Hamiltonian dynamics, has inspired the development of\ninnovative quantum algorithms for continuous optimization. One such algorithm,\nQuantum Hamiltonian Descent (QHD), leverages quantum tunneling to escape saddle\npoints and local minima, facilitating the discovery of global solutions in\ncomplex optimization landscapes. However, QHD faces several challenges,\nincluding slower convergence rates compared to classical gradient methods and\nlimited robustness in highly non-convex problems due to the non-local nature of\nquantum states. Furthermore, the original QHD formulation primarily relies on\nfunction value information, which limits its effectiveness. Inspired by\ninsights from high-resolution differential equations that have elucidated the\nacceleration mechanisms in classical methods, we propose an enhancement to QHD\nby incorporating gradient information, leading to what we call gradient-based\nQHD. Gradient-based QHD achieves faster convergence and significantly increases\nthe likelihood of identifying global solutions. Numerical simulations on\nchallenging problem instances demonstrate that gradient-based QHD outperforms\nexisting quantum and classical methods by at least an order of magnitude."}
{"id": "2501.18187", "pdf": "https://arxiv.org/pdf/2501.18187", "abs": "https://arxiv.org/abs/2501.18187", "authors": ["Haoyuan Sun", "Ali Jadbabaie", "Navid Azizan"], "title": "On the Role of Transformer Feed-Forward Layers in Nonlinear In-Context Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformer-based models demonstrate a remarkable ability for in-context\nlearning (ICL), where they can adapt to unseen tasks from a few prompt examples\nwithout parameter updates. Notably, recent research has provided insight into\nhow the Transformer architecture can perform ICL, showing that the optimal\nlinear self-attention (LSA) mechanism can implement one step of gradient\ndescent for linear least-squares objectives when trained on random linear\nregression tasks.\n  Building upon this understanding of linear ICL, we investigate ICL for\nnonlinear function classes. We first show that LSA is inherently incapable of\nsolving problems that go beyond linear least-squares objectives, underscoring\nwhy prior solutions cannot readily extend to nonlinear ICL tasks. To overcome\nthis limitation, we investigate a mechanism combining LSA with feed-forward\nlayers that are inspired by the gated linear units (GLU) commonly found in\nmodern Transformer architectures. We show that this combination empowers the\nTransformer to perform nonlinear ICL, specifically by implementing one step of\ngradient descent on a polynomial kernel regression loss. Furthermore, we show\nthat multiple blocks of our GLU-LSA model implement block coordinate descent in\nthis polynomial kernel space. Our findings highlight the distinct roles of\nattention and feed-forward layers, demonstrating that the feed-forward\ncomponents provide a mechanism by which Transformers gain nonlinear\ncapabilities for ICL."}
{"id": "2502.02577", "pdf": "https://arxiv.org/pdf/2502.02577", "abs": "https://arxiv.org/abs/2502.02577", "authors": ["Alex Fl√ºckiger", "Chantal Amrhein", "Tim Graf", "Fr√©d√©ric Odermatt", "Martin P√∂msl", "Philippe Schl√§pfer", "Florian Schottmann", "Samuel L√§ubli"], "title": "A comparison of translation performance between DeepL and Supertext", "categories": ["cs.CL"], "comment": "Paper accepted at MT Summit 2025", "summary": "As strong machine translation (MT) systems are increasingly based on large\nlanguage models (LLMs), reliable quality benchmarking requires methods that\ncapture their ability to leverage extended context. This study compares two\ncommercial MT systems -- DeepL and Supertext -- by assessing their performance\non unsegmented texts. We evaluate translation quality across four language\ndirections with professional translators assessing segments with full\ndocument-level context. While segment-level assessments indicate no strong\npreference between the systems in most cases, document-level analysis reveals a\npreference for Supertext in three out of four language directions, suggesting\nsuperior consistency across longer texts. We advocate for more\ncontext-sensitive evaluation methodologies to ensure that MT quality\nassessments reflect real-world usability. We release all evaluation data and\nscripts for further analysis and reproduction at\nhttps://github.com/supertext/evaluation_deepl_supertext."}
{"id": "2111.06592", "pdf": "https://arxiv.org/pdf/2111.06592", "abs": "https://arxiv.org/abs/2111.06592", "authors": ["Yongyi Yang", "Tang Liu", "Yangkun Wang", "Zengfeng Huang", "David Wipf"], "title": "Implicit vs Unfolded Graph Neural Networks", "categories": ["cs.LG"], "comment": "A version of this work has been accepted to the Journal of Machine\n  Learning Research", "summary": "It has been observed that message-passing graph neural networks (GNN)\nsometimes struggle to maintain a healthy balance between the efficient/scalable\nmodeling of long-range dependencies across nodes while avoiding unintended\nconsequences such oversmoothed node representations, sensitivity to spurious\nedges, or inadequate model interpretability. To address these and other issues,\ntwo separate strategies have recently been proposed, namely implicit and\nunfolded GNNs (that we abbreviate to IGNN and UGNN respectively). The former\ntreats node representations as the fixed points of a deep equilibrium model\nthat can efficiently facilitate arbitrary implicit propagation across the graph\nwith a fixed memory footprint. In contrast, the latter involves treating graph\npropagation as unfolded descent iterations as applied to some graph-regularized\nenergy function. While motivated differently, in this paper we carefully\nquantify explicit situations where the solutions they produce are equivalent\nand others where their properties sharply diverge. This includes the analysis\nof convergence, representational capacity, and interpretability. In support of\nthis analysis, we also provide empirical head-to-head comparisons across\nmultiple synthetic and public real-world node classification benchmarks. These\nresults indicate that while IGNN is substantially more memory-efficient, UGNN\nmodels support unique, integrated graph attention mechanisms and propagation\nrules that can achieve strong node classification accuracy across disparate\nregimes such as adversarially-perturbed graphs, graphs with heterophily, and\ngraphs involving long-range dependencies."}
{"id": "2501.19403", "pdf": "https://arxiv.org/pdf/2501.19403", "abs": "https://arxiv.org/abs/2501.19403", "authors": ["Yingdan Shi", "Sijia Liu", "Ren Wang"], "title": "Redefining Machine Unlearning: A Conformal Prediction-Motivated Approach", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine unlearning seeks to remove the influence of specified data from a\ntrained model. While metrics such as unlearning accuracy (UA) and membership\ninference attack (MIA) provide baselines for assessing unlearning performance,\nthey fall short of evaluating the forgetting reliability. In this paper, we\nfind that the data misclassified across UA and MIA still have their ground\ntruth labels included in the prediction set from the uncertainty quantification\nperspective, which raises a fake unlearning issue. To address this issue, we\npropose two novel metrics inspired by conformal prediction that more reliably\nevaluate forgetting quality. Building on these insights, we further propose a\nconformal prediction-based unlearning framework that integrates conformal\nprediction into Carlini & Wagner adversarial attack loss, which can\nsignificantly push the ground truth label out of the conformal prediction set.\nThrough extensive experiments on image classification task, we demonstrate both\nthe effectiveness of our proposed metrics and the superiority of our unlearning\nframework, which improves the UA of existing unlearning methods by an average\nof 6.6% through the incorporation of a tailored loss term alone."}
{"id": "2502.02789", "pdf": "https://arxiv.org/pdf/2502.02789", "abs": "https://arxiv.org/abs/2502.02789", "authors": ["Jingyu Liu", "Beidi Chen", "Ce Zhang"], "title": "Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation", "categories": ["cs.CL", "cs.AI"], "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "Improving time-to-first-token (TTFT) is an essentially important objective in\nmodern large language model (LLM) inference engines. Optimizing TTFT directly\nresults in higher maximal QPS and meets the requirements of many critical\napplications. However, boosting TTFT is notoriously challenging since it is\ncompute-bounded and the performance bottleneck shifts from the self-attention\nthat many prior works focus on to the MLP part. In this work, we present\nSpecPrefill, a training free framework that accelerates the inference TTFT for\nboth long and medium context queries based on the following insight: LLMs are\ngeneralized enough to preserve the quality given only a carefully chosen subset\nof prompt tokens. At its core, SpecPrefill leverages a lightweight model to\nspeculate locally important tokens based on the context. These tokens, along\nwith the necessary positional information, are then sent to the main model for\nprocessing. We evaluate SpecPrefill with a diverse set of tasks, followed by a\ncomprehensive benchmarking of performance improvement both in a real end-to-end\nsetting and ablation studies. SpecPrefill manages to serve\nLlama-3.1-405B-Instruct-FP8 with up to 7$\\times$ maximal end-to-end QPS on real\ndownstream tasks and 7.66$\\times$ TTFT improvement."}
{"id": "2212.00228", "pdf": "https://arxiv.org/pdf/2212.00228", "abs": "https://arxiv.org/abs/2212.00228", "authors": ["N. Benjamin Erichson", "Soon Hoe Lim", "Michael W. Mahoney"], "title": "Gated Recurrent Neural Networks with Weighted Time-Delay Feedback", "categories": ["cs.LG", "cs.NE", "stat.ML"], "comment": "Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025,", "summary": "In this paper, we present a novel approach to modeling long-term dependencies\nin sequential data by introducing a gated recurrent unit (GRU) with a weighted\ntime-delay feedback mechanism. Our proposed model, named $\\tau$-GRU, is a\ndiscretized version of a continuous-time formulation of a recurrent unit, where\nthe dynamics are governed by delay differential equations (DDEs). We prove the\nexistence and uniqueness of solutions for the continuous-time model and show\nthat the proposed feedback mechanism can significantly improve the modeling of\nlong-term dependencies. Our empirical results indicate that $\\tau$-GRU\noutperforms state-of-the-art recurrent units and gated recurrent architectures\non a range of tasks, achieving faster convergence and better generalization."}
{"id": "2502.07115", "pdf": "https://arxiv.org/pdf/2502.07115", "abs": "https://arxiv.org/abs/2502.07115", "authors": ["Patrick Jaillet", "Jiashuo Jiang", "Konstantina Mellou", "Marco Molinaro", "Chara Podimata", "Zijie Zhou"], "title": "Online Scheduling for LLM Inference with KV Cache Constraints", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Large Language Model (LLM) inference, where a trained model generates text\none word at a time in response to user prompts, is a computationally intensive\nprocess requiring efficient scheduling to optimize latency and resource\nutilization. A key challenge in LLM inference is the management of the\nKey-Value (KV) cache, which reduces redundant computations but introduces\nmemory constraints. In this work, we model LLM inference with KV cache\nconstraints theoretically and propose a novel batching and scheduling algorithm\nthat minimizes inference latency while effectively managing the KV cache's\nmemory.\n  More specifically, we make the following contributions. First, to evaluate\nthe performance of online algorithms for scheduling in LLM inference, we\nintroduce a hindsight optimal benchmark, formulated as an integer program that\ncomputes the minimum total inference latency under full future information.\nSecond, we prove that no deterministic online algorithm can achieve a constant\ncompetitive ratio when the arrival process is arbitrary. Third, motivated by\nthe computational intractability of solving the integer program at scale, we\npropose a polynomial-time online scheduling algorithm and show that under\ncertain conditions it can achieve a constant competitive ratio. We also\ndemonstrate our algorithm's strong empirical performance by comparing it to the\nhindsight optimal in a synthetic dataset. Finally, we conduct empirical\nevaluations on a real-world public LLM inference dataset, simulating the\nLlama2-70B model on A100 GPUs, and show that our algorithm significantly\noutperforms the benchmark algorithms. Overall, our results offer a path toward\nmore sustainable and cost-effective LLM deployment."}
{"id": "2502.06659", "pdf": "https://arxiv.org/pdf/2502.06659", "abs": "https://arxiv.org/abs/2502.06659", "authors": ["Somin Wadhwa", "Chantal Shaib", "Silvio Amir", "Byron C. Wallace"], "title": "Who Taught You That? Tracing Teachers in Model Distillation", "categories": ["cs.CL"], "comment": "Findings of ACL 2025", "summary": "Model distillation -- using outputs from a large teacher model to teach a\nsmall student model -- is a practical means of creating efficient models for a\nparticular task. We ask: Can we identify a students' teacher based on its\noutputs? Such \"footprints\" left by teacher LLMs would be interesting artifacts.\nBeyond this, reliable teacher inference may have practical implications as\nactors seek to distill specific capabilities of massive proprietary LLMs into\ndeployed smaller LMs, potentially violating terms of service. We consider\npractical task distillation targets including summarization, question\nanswering, and instruction-following. We assume a finite set of candidate\nteacher models, which we treat as blackboxes. We design discriminative models\nthat operate over lexical features. We find that $n$-gram similarity alone is\nunreliable for identifying teachers, but part-of-speech (PoS) templates\npreferred by student models mimic those of their teachers."}
{"id": "2302.04363", "pdf": "https://arxiv.org/pdf/2302.04363", "abs": "https://arxiv.org/abs/2302.04363", "authors": ["S. Abdurakhmanova", "Y. SarcheshmehPour", "A. Jung"], "title": "Towards Model-Agnostic Federated Learning over Networks", "categories": ["cs.LG", "I.5.3; C.2.4; I.5.2"], "comment": null, "summary": "We present a model-agnostic federated learning method for networks of\nheterogeneous data and models. The network structure reflects similarities\nbetween the (statistics of the) local datasets and, in turn, their associated\nlocal (personal) models. Our method is an instance of empirical risk\nminimization, with a regularization term derived from the network structure of\nthe data. In particular, we require well-connected local models, which form\nclusters, to yield similar predictions on shared public, unlabelled dataset(s).\nThe proposed method allows for a wide range of local models. The only\nrestriction is that these local models must allow for efficient implementation\nof regularized empirical risk minimization (training). For many models, such\nimplementations are readily available in high-level programming libraries,\nincluding scikit-learn, Keras, and PyTorch."}
{"id": "2502.07158", "pdf": "https://arxiv.org/pdf/2502.07158", "abs": "https://arxiv.org/abs/2502.07158", "authors": ["Jiaying Lu", "Stephanie R. Brown", "Songyuan Liu", "Shifan Zhao", "Kejun Dong", "Del Bold", "Michael Fundora", "Alaa Aljiffry", "Alex Fedorov", "Jocelyn Grunwell", "Xiao Hu"], "title": "Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Early prediction of pediatric cardiac arrest (CA) is critical for timely\nintervention in high-risk intensive care settings. We introduce PedCA-FT, a\nnovel transformer-based framework that fuses tabular view of EHR with the\nderived textual view of EHR to fully unleash the interactions of\nhigh-dimensional risk factors and their dynamics. By employing dedicated\ntransformer modules for each modality view, PedCA-FT captures complex temporal\nand contextual patterns to produce robust CA risk estimates. Evaluated on a\ncurated pediatric cohort from the CHOA-CICU database, our approach outperforms\nten other artificial intelligence models across five key performance metrics\nand identifies clinically meaningful risk factors. These findings underscore\nthe potential of multimodal fusion techniques to enhance early CA detection and\nimprove patient care."}
{"id": "2502.11051", "pdf": "https://arxiv.org/pdf/2502.11051", "abs": "https://arxiv.org/abs/2502.11051", "authors": ["Jiahao Huo", "Yibo Yan", "Xu Zheng", "Yuanhuiyi Lyu", "Xin Zou", "Zhihua Wei", "Xuming Hu"], "title": "MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted as ACL 2025 Findings", "summary": "Recent progress in Machine Unlearning (MU) has introduced solutions for the\nselective removal of private or sensitive information encoded within deep\nneural networks. Nonetheless, MU for Multimodal Large Language Models (MLLMs)\nremains in its nascent phase. Therefore, we propose to reformulate the task of\nmultimodal MU in the era of MLLMs, which aims to erase only the visual patterns\nassociated with a given entity while preserving the corresponding textual\nknowledge encoded within the original parameters of the language model\nbackbone. Furthermore, we develop a novel geometry-constrained gradient ascent\nmethod MMUnlearner. It updates the weights of MLLMs with a weight saliency map\njointly restricted by the remaining concepts and textual knowledge during\nunlearning, thereby preserving parameters essential for non-target knowledge.\nExtensive experiments demonstrate that MMUnlearner surpasses baselines that\nfinetuning MLLMs with VQA data directly through Gradient Ascent (GA) or\nNegative Preference Optimization (NPO), across all evaluation dimensions. Our\ncode will be released upon acceptance."}
{"id": "2310.16608", "pdf": "https://arxiv.org/pdf/2310.16608", "abs": "https://arxiv.org/abs/2310.16608", "authors": ["Moritz Hardt", "Celestine Mendler-D√ºnner"], "title": "Performative Prediction: Past and Future", "categories": ["cs.LG"], "comment": "To appear in Statistical Science", "summary": "Predictions in the social world generally influence the target of prediction,\na phenomenon known as performativity. Self-fulfilling and self-negating\npredictions are examples of performativity. Of fundamental importance to\neconomics, finance, and the social sciences, the notion has been absent from\nthe development of machine learning that builds on the static perspective of\npattern recognition. In machine learning applications, however, performativity\noften surfaces as distribution shift. A predictive model deployed on a digital\nplatform, for example, influences behavior and thereby changes the\ndata-generating distribution. We discuss the recently founded area of\nperformative prediction that provides a definition and conceptual framework to\nstudy performativity in machine learning. A key element of performative\nprediction is a natural equilibrium notion that gives rise to new optimization\nchallenges. What emerges is a distinction between learning and steering, two\nmechanisms at play in performative prediction. Steering is in turn intimately\nrelated to questions of power in digital markets. The notion of performative\npower that we review gives an answer to the question how much a platform can\nsteer participants through its predictions. We end on a discussion of future\ndirections, such as the role that performativity plays in contesting\nalgorithmic systems."}
{"id": "2502.07693", "pdf": "https://arxiv.org/pdf/2502.07693", "abs": "https://arxiv.org/abs/2502.07693", "authors": ["Victor Morel", "Leonardo Iwaya", "Simone Fischer-H√ºbner"], "title": "AI-driven Personalized Privacy Assistants: a Systematic Literature Review", "categories": ["cs.CY", "cs.AI"], "comment": "Submitted to IEEE Access", "summary": "In recent years, several personalized assistants based on AI have been\nresearched and developed to help users make privacy-related decisions. These\nAI-driven Personalized Privacy Assistants (AI-driven PPAs) can provide\nsignificant benefits for users, who might otherwise struggle with making\ndecisions about their personal data in online environments that often overload\nthem with different privacy decision requests. So far, no studies have\nsystematically investigated the emerging topic of AI-driven PPAs, classifying\ntheir underlying technologies, architecture and features, including decision\ntypes or the accuracy of their decisions. To fill this gap, we present a\nSystematic Literature Review (SLR) to map the existing solutions found in the\nscientific literature, which allows reasoning about existing approaches and\nopen challenges for this research field. We screened several hundred unique\nresearch papers over the recent years (2013-2025), constructing a\nclassification from 41 included papers. As a result, this SLR reviews several\naspects of existing research on AI-driven PPAs in terms of types of\npublications, contributions, methodological quality, and other quantitative\ninsights. Furthermore, we provide a comprehensive classification for AI-driven\nPPAs, delving into their architectural choices, system contexts, types of AI\nused, data sources, types of decisions, and control over decisions, among other\nfacets. Based on our SLR, we further underline the research gaps and challenges\nand formulate recommendations for the design and development of AI-driven PPAs\nas well as avenues for future research."}
{"id": "2502.11066", "pdf": "https://arxiv.org/pdf/2502.11066", "abs": "https://arxiv.org/abs/2502.11066", "authors": ["Nura Aljaafari", "Danilo S. Carvalho", "Andr√© Freitas"], "title": "CARMA: Enhanced Compositionality in LLMs via Advanced Regularisation and Mutual Information Alignment", "categories": ["cs.CL"], "comment": "19 pages, 8 figures, 8 tables", "summary": "Large language models (LLMs) struggle with compositional generalisation,\nlimiting their ability to systematically combine learned components to\ninterpret novel inputs. While architectural modifications, fine-tuning, and\ndata augmentation improve compositionality, they often have limited\nadaptability, face scalability constraints, or yield diminishing returns on\nreal data. To address this, we propose CARMA, an intervention that enhances the\nstability and robustness of compositional reasoning in LLMs while preserving\nfine-tuned performance. CARMA employs mutual information regularisation and\nlayer-wise stability constraints to mitigate feature fragmentation, ensuring\nstructured representations persist across and within layers. We evaluate CARMA\non inverse dictionary modelling and sentiment classification, measuring its\nimpact on semantic consistency, performance stability, and robustness to\nlexical perturbations. Results show that CARMA reduces the variability\nintroduced by fine-tuning, stabilises token representations, and improves\ncompositional reasoning. While its effectiveness varies across architectures,\nCARMA's key strength lies in reinforcing learned structures rather than\nintroducing new capabilities, making it a scalable auxiliary method. These\nfindings suggest that integrating CARMA with fine-tuning can improve\ncompositional generalisation while maintaining task-specific performance in\nLLMs."}
{"id": "2402.04906", "pdf": "https://arxiv.org/pdf/2402.04906", "abs": "https://arxiv.org/abs/2402.04906", "authors": ["Jef Jonkers", "Jarne Verhaeghe", "Glenn Van Wallendael", "Luc Duchateau", "Sofie Van Hoecke"], "title": "Conformal Convolution and Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects", "categories": ["cs.LG", "stat.ML"], "comment": "Major update (rescope to distributional regression in counterfactual\n  inference)", "summary": "Generating probabilistic forecasts of potential outcomes and individual\ntreatment effects (ITE) is essential for risk-aware decision-making in domains\nsuch as healthcare, policy, marketing, and finance. We propose two novel\nmethods: the conformal convolution T-learner (CCT) and the conformal Monte\nCarlo (CMC) meta-learner, that generate full predictive distributions of both\npotential outcomes and ITEs. Our approaches combine weighted conformal\npredictive systems with either analytic convolution of potential outcome\ndistributions or Monte Carlo sampling, addressing covariate shift through\npropensity score weighting. In contrast to other approaches that allow the\ngeneration of potential outcome predictive distributions, our approaches are\nmodel agnostic, universal, and come with finite-sample guarantees of\nprobabilistic calibration under knowledge of the propensity score. Regarding\nestimating the ITE distribution, we formally characterize how assumptions about\npotential outcomes' noise dependency impact distribution validity and establish\nuniversal consistency under independence noise assumptions. Experiments on\nsynthetic and semi-synthetic datasets demonstrate that the proposed methods\nachieve probabilistically calibrated predictive distributions while maintaining\nnarrow prediction intervals and having performant continuous ranked probability\nscores. Besides probabilistic forecasting performance, we observe significant\nefficiency gains for the CCT- and CMC meta-learners compared to other conformal\napproaches that produce prediction intervals for ITE with coverage guarantees."}
{"id": "2502.10940", "pdf": "https://arxiv.org/pdf/2502.10940", "abs": "https://arxiv.org/abs/2502.10940", "authors": ["Ziyue Liu", "Ruijie Zhang", "Zhengyang Wang", "Zi Yang", "Paul Hovland", "Bogdan Nicolae", "Franck Cappello", "Zheng Zhang"], "title": "CoLA: Compute-Efficient Pre-Training of LLMs via Low-Rank Activation", "categories": ["cs.LG", "cs.AI"], "comment": "v2", "summary": "The full-size MLPs and the projection layers in attention introduce\ntremendous model sizes of large language models (LLMs), imposing extremely\ndemanding needs of computational resources in the pre-training stage. However,\nwe empirically observe that the activations of pre-trained LLMs exhibit\nlow-rank property. Motivated by such observations, we propose CoLA and its\nmemory-efficient implementation, CoLA-M, to replace these full-size layers with\ncompute-efficient auto-encoders that naturally enforce low-rank activations\nthroughout training. This fundamental architectural change eliminates the\nactivation redundancy and significantly boosts model capacity and training\nefficiency. Experiments on LLaMA models with 60 million to 7 billion parameters\nshow that CoLA reduces the computing cost by $\\bf 2\\pmb{\\times}$ and improves\ntraining throughput by $\\bf 1.86\\pmb{\\times}$ while maintaining full-rank level\nperformance. CoLA-M further squeezes memory cost without sacrificing\nthroughput, offering a pre-training approach with collectively superior\nparameter, computing, and memory efficiency. The LLMs produced are also $\\bf\n2\\pmb{\\times}$ smaller, enabling faster inference with lower memory cost on\nresource-constrained platforms."}
{"id": "2502.11100", "pdf": "https://arxiv.org/pdf/2502.11100", "abs": "https://arxiv.org/abs/2502.11100", "authors": ["Milan Bhan", "Yann Choho", "Pierre Moreau", "Jean-Noel Vittaut", "Nicolas Chesneau", "Marie-Jeanne Lesot"], "title": "Towards Achieving Concept Completeness for Textual Concept Bottleneck Models", "categories": ["cs.CL"], "comment": null, "summary": "Textual Concept Bottleneck Models (TBMs) are interpretable-by-design models\nfor text classification that predict a set of salient concepts before making\nthe final prediction. This paper proposes Complete Textual Concept Bottleneck\nModel (CT-CBM),a novel TCBM generator building concept labels in a fully\nunsupervised manner using a small language model, eliminating both the need for\npredefined human labeled concepts and LLM annotations. CT-CBM iteratively\ntargets and adds important concepts in the bottleneck layer to create a\ncomplete concept basis and addresses downstream classification leakage through\na parallel residual connection. CT-CBM achieves good results against\ncompetitors, offering a promising solution to enhance interpretability of NLP\nclassifiers without sacrificing performance."}
{"id": "2402.16383", "pdf": "https://arxiv.org/pdf/2402.16383", "abs": "https://arxiv.org/abs/2402.16383", "authors": ["Ran Eisenberg", "Jonathan Svirsky", "Ofir Lindenbaum"], "title": "Self Supervised Correlation-based Permutations for Multi-View Clustering", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Combining data from different sources can improve data analysis tasks such as\nclustering. However, most of the current multi-view clustering methods are\nlimited to specific domains or rely on a suboptimal and computationally\nintensive two-stage process of representation learning and clustering. We\npropose an end-to-end deep learning-based multi-view clustering framework for\ngeneral data types (such as images and tables). Our approach involves\ngenerating meaningful fused representations using a novel permutation-based\ncanonical correlation objective. We provide a theoretical analysis showing how\nthe learned embeddings approximate those obtained by supervised linear\ndiscriminant analysis (LDA). Cluster assignments are learned by identifying\nconsistent pseudo-labels across multiple views. Additionally, we establish a\ntheoretical bound on the error caused by incorrect pseudo-labels in the\nunsupervised representations compared to LDA. Extensive experiments on ten\nmulti-view clustering benchmark datasets provide empirical evidence for the\neffectiveness of the proposed model."}
{"id": "2502.11537", "pdf": "https://arxiv.org/pdf/2502.11537", "abs": "https://arxiv.org/abs/2502.11537", "authors": ["Lior Cohen", "Kaixin Wang", "Bingyi Kang", "Uri Gadot", "Shie Mannor"], "title": "Uncovering Untapped Potential in Sample-Efficient World Model Agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "World model (WM) agents enable sample-efficient reinforcement learning by\nlearning policies entirely from simulated experience. However, existing\ntoken-based world models (TBWMs) are limited to visual inputs and discrete\nactions, restricting their adoption and applicability. Moreover, although both\nintrinsic motivation and prioritized WM replay have shown promise in improving\nWM performance and generalization, they remain underexplored in this setting,\nparticularly in combination. We introduce Simulus, a highly modular TBWM agent\nthat integrates (1) a modular multi-modality tokenization framework, (2)\nintrinsic motivation, (3) prioritized WM replay, and (4)\nregression-as-classification for reward and return prediction. Simulus achieves\nstate-of-the-art sample efficiency for planning-free WMs across three diverse\nbenchmarks. Ablation studies reveal the individual contribution of each\ncomponent while highlighting their synergy. Our code and model weights are\npublicly available at https://github.com/leor-c/Simulus."}
{"id": "2502.11733", "pdf": "https://arxiv.org/pdf/2502.11733", "abs": "https://arxiv.org/abs/2502.11733", "authors": ["Jonathan Jordan", "Sherzod Hakimov", "David Schlangen"], "title": "Plant in Cupboard, Orange on Rably, Inat Aphone. Benchmarking Incremental Learning of Situation and Language Model using a Text-Simulated Situated Environment", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) serve not only as chatbots but as key components\nin agent systems, where their common-sense knowledge significantly impacts\nperformance as language-based planners for situated or embodied action. We\nassess LLMs' incremental learning (based on feedback from the environment), and\ncontrolled in-context learning abilities using a text-based environment. We\nintroduce challenging yet interesting set of experiments to test i) how agents\ncan incrementally solve tasks related to every day objects in typical rooms in\na house where each of them are discovered by interacting within the\nenvironment, ii) controlled in-context learning abilities and efficiency of\nagents by providing short info about locations of objects and rooms to check\nhow faster the task can be solved, and finally iii) using synthetic\npseudo-English words to gauge how well LLMs are at inferring meaning of unknown\nwords from environmental feedback. Results show that larger commercial models\nhave a substantial gap in performance compared to open-weight but almost all\nmodels struggle with the synthetic words experiments."}
{"id": "2403.00155", "pdf": "https://arxiv.org/pdf/2403.00155", "abs": "https://arxiv.org/abs/2403.00155", "authors": ["Mahsa Mozafari-Nia", "Salimeh Yasaei Sekeh"], "title": "Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space", "categories": ["cs.LG"], "comment": null, "summary": "Despite the impressive performance of deep neural networks (DNNs), their\ncomputational complexity and storage space consumption have led to the concept\nof network compression. While DNN compression techniques such as pruning and\nlow-rank decomposition have been extensively studied, there has been\ninsufficient attention paid to their theoretical explanation. In this paper, we\npropose a novel theoretical framework that leverages a probabilistic latent\nspace of DNN weights and explains the optimal network sparsity by using the\ninformation-theoretic divergence measures. We introduce new analogous projected\npatterns (AP2) and analogous-in-probability projected patterns (AP3) notions\nfor DNNs and prove that there exists a relationship between AP3/AP2 property of\nlayers in the network and its performance. Further, we provide a theoretical\nanalysis that explains the training process of the compressed network. The\ntheoretical results are empirically validated through experiments conducted on\nstandard pre-trained benchmarks, including AlexNet, ResNet50, and VGG16, using\nCIFAR10 and CIFAR100 datasets. Through our experiments, we highlight the\nrelationship of AP3 and AP2 properties with fine-tuning pruned DNNs and\nsparsity levels."}
{"id": "2502.11916", "pdf": "https://arxiv.org/pdf/2502.11916", "abs": "https://arxiv.org/abs/2502.11916", "authors": ["Jiamin Su", "Yibo Yan", "Fangteng Fu", "Han Zhang", "Jingheng Ye", "Xiang Liu", "Jiahao Huo", "Huiyu Zhou", "Xuming Hu"], "title": "EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay Scoring Capabilities of Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL Findings 2025", "summary": "Automated Essay Scoring (AES) plays a crucial role in educational assessment\nby providing scalable and consistent evaluations of writing tasks. However,\ntraditional AES systems face three major challenges: (1) reliance on\nhandcrafted features that limit generalizability, (2) difficulty in capturing\nfine-grained traits like coherence and argumentation, and (3) inability to\nhandle multimodal contexts. In the era of Multimodal Large Language Models\n(MLLMs), we propose EssayJudge, the first multimodal benchmark to evaluate AES\ncapabilities across lexical-, sentence-, and discourse-level traits. By\nleveraging MLLMs' strengths in trait-specific scoring and multimodal context\nunderstanding, EssayJudge aims to offer precise, context-rich evaluations\nwithout manual feature engineering, addressing longstanding AES limitations.\nOur experiments with 18 representative MLLMs reveal gaps in AES performance\ncompared to human evaluation, particularly in discourse-level traits,\nhighlighting the need for further advancements in MLLM-based AES research."}
{"id": "2502.11811", "pdf": "https://arxiv.org/pdf/2502.11811", "abs": "https://arxiv.org/abs/2502.11811", "authors": ["Qianchi Zhang", "Hainan Zhang", "Liang Pang", "Ziwei Wang", "Hongwei Zheng", "Yongxin Tong", "Zhiming Zheng"], "title": "FineFilter: A Fine-grained Noise Filtering Mechanism for Retrieval-Augmented Large Language Models", "categories": ["cs.CL"], "comment": "18 pages, 4 figures, 18 tables, under review", "summary": "Retrieved documents containing noise will hinder Retrieval-Augmented\nGeneration (RAG) from detecting answer clues, necessitating noise filtering\nmechanisms to enhance accuracy. Existing methods use reranking or summarization\nto identify the most relevant sentences, but directly and accurately locating\nanswer clues from these large-scale and complex documents remains challenging.\nUnlike these document-level operations, we treat noise filtering as a\nsentence-level MinMax optimization problem: first identifying potential clues\nfrom multiple documents, then ranking them by relevance, and finally retaining\nthe minimum number of clues through truncation. In this paper, we propose\nFineFilter, a novel fine-grained noise filtering mechanism for RAG, consisting\nof a clue extractor, a reranker, and a truncator. We optimize each module to\ntackle complex reasoning challenges: (1) The clue extractor first uses\nsentences containing the answer and similar ones as fine-tuning targets, aiming\nto extract sufficient potential clues; (2) The reranker is trained to\nprioritize effective clues based on the real feedback from the generation\nmodule, with clues capable of generating correct answers as positive samples\nand others as negative; (3) The truncator takes the minimum number of clues\nneeded to answer the question (truncation point) as fine-tuning targets, and\nperforms truncation on the reranked clues to achieve fine-grained noise\nfiltering. Experiments on three QA datasets demonstrate that FineFilter\nsignificantly improves QA performance over baselines on both LLaMA3 and\nMistral. Further analysis confirms its effectiveness in complex reasoning,\nrobustness to unreliable retrieval, and generalization to different scenarios."}
{"id": "2403.02873", "pdf": "https://arxiv.org/pdf/2403.02873", "abs": "https://arxiv.org/abs/2403.02873", "authors": ["Amit Attia", "Tomer Koren"], "title": "A General Reduction for High-Probability Analysis with General Light-Tailed Distributions", "categories": ["cs.LG", "cs.DS", "math.PR"], "comment": "14 pages", "summary": "We describe a general reduction technique for analyzing learning algorithms\nthat are subject to light-tailed (but not necessarily bounded) randomness, a\nscenario that is often the focus of theoretical analysis. We show that the\nanalysis of such an algorithm can be reduced, in a black-box manner and with\nonly a small loss in logarithmic factors, to an analysis of a simpler variant\nof the same algorithm that uses bounded random variables and is often easier to\nanalyze. This approach simultaneously applies to any light-tailed\nrandomization, including exponential, sub-Gaussian, and more general\nfast-decaying distributions, without needing to appeal to specialized\nconcentration inequalities. Derivations of a generalized Azuma inequality,\nconvergence bounds in stochastic optimization, and regret analysis in\nmulti-armed bandits with general light-tailed randomization are provided to\nillustrate the technique."}
{"id": "2502.12466", "pdf": "https://arxiv.org/pdf/2502.12466", "abs": "https://arxiv.org/abs/2502.12466", "authors": ["Anjiang Wei", "Jiannan Cao", "Ran Li", "Hongyu Chen", "Yuhui Zhang", "Ziheng Wang", "Yuan Liu", "Thiago S. F. X. Teixeira", "Diyi Yang", "Ke Wang", "Alex Aiken"], "title": "EquiBench: Benchmarking Large Language Models' Understanding of Program Semantics via Equivalence Checking", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PL", "cs.SE"], "comment": null, "summary": "As large language models (LLMs) become integral to code-related tasks, a\ncentral question emerges: do LLMs truly understand program execution semantics?\nWe introduce EquiBench, a new benchmark for evaluating LLMs through equivalence\nchecking, i.e., determining whether two programs produce identical outputs for\nall possible inputs. Unlike prior code generation benchmarks, this task\ndirectly tests a model's understanding of code execution semantics. EquiBench\nconsists of 2400 program pairs across four languages and six categories. These\npairs are generated through program analysis, compiler scheduling, and\nsuperoptimization, ensuring high-confidence labels, nontrivial difficulty, and\nfull automation. The transformations span syntactic edits, structural\nmodifications, and algorithmic changes, covering a broad spectrum of semantic\nvariation. We evaluate 19 state-of-the-art LLMs and find that in the most\nchallenging categories, the best accuracies are 63.8% and 76.2%, only modestly\nabove the 50% random baseline. Further analysis reveals that models often rely\non syntactic similarity rather than exhibiting robust reasoning over execution\nsemantics, highlighting fundamental limitations."}
{"id": "2502.12464", "pdf": "https://arxiv.org/pdf/2502.12464", "abs": "https://arxiv.org/abs/2502.12464", "authors": ["Seanie Lee", "Dong Bok Lee", "Dominik Wagner", "Minki Kang", "Haebin Seong", "Tobias Bocklet", "Juho Lee", "Sung Ju Hwang"], "title": "SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models", "categories": ["cs.CL"], "comment": "ACL 2025 findings", "summary": "Deploying large language models (LLMs) in real-world applications requires\nrobust safety guard models to detect and block harmful user prompts. While\nlarge safety guard models achieve strong performance, their computational cost\nis substantial. To mitigate this, smaller distilled models are used, but they\noften underperform on \"hard\" examples where the larger model provides accurate\npredictions. We observe that many inputs can be reliably handled by the smaller\nmodel, while only a small fraction require the larger model's capacity.\nMotivated by this, we propose SafeRoute, a binary router that distinguishes\nhard examples from easy ones. Our method selectively applies the larger safety\nguard model to the data that the router considers hard, improving efficiency\nwhile maintaining accuracy compared to solely using the larger safety guard\nmodel. Experimental results on multiple benchmark datasets demonstrate that our\nadaptive model selection significantly enhances the trade-off between\ncomputational cost and safety performance, outperforming relevant baselines."}
{"id": "2405.15506", "pdf": "https://arxiv.org/pdf/2405.15506", "abs": "https://arxiv.org/abs/2405.15506", "authors": ["Vinh Tong", "Hoang Trung-Dung", "Anji Liu", "Guy Van den Broeck", "Mathias Niepert"], "title": "Learning to Discretize Denoising Diffusion ODEs", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion Probabilistic Models (DPMs) are generative models showing\ncompetitive performance in various domains, including image synthesis and 3D\npoint cloud generation. Sampling from pre-trained DPMs involves multiple neural\nfunction evaluations (NFEs) to transform Gaussian noise samples into images,\nresulting in higher computational costs compared to single-step generative\nmodels such as GANs or VAEs. Therefore, reducing the number of NFEs while\npreserving generation quality is crucial. To address this, we propose LD3, a\nlightweight framework designed to learn the optimal time discretization for\nsampling. LD3 can be combined with various samplers and consistently improves\ngeneration quality without having to retrain resource-intensive neural\nnetworks. We demonstrate analytically and empirically that LD3 improves\nsampling efficiency with much less computational overhead. We evaluate our\nmethod with extensive experiments on 7 pre-trained models, covering\nunconditional and conditional sampling in both pixel-space and latent-space\nDPMs. We achieve FIDs of 2.38 (10 NFE), and 2.27 (10 NFE) on unconditional\nCIFAR10 and AFHQv2 in 5-10 minutes of training. LD3 offers an efficient\napproach to sampling from pre-trained diffusion models. Code is available at\nhttps://github.com/vinhsuhi/LD3."}
{"id": "2502.12767", "pdf": "https://arxiv.org/pdf/2502.12767", "abs": "https://arxiv.org/abs/2502.12767", "authors": ["Sumin Jo", "Junseong Choi", "Jiho Kim", "Edward Choi"], "title": "R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent studies have combined Large Language Models (LLMs) with Knowledge\nGraphs (KGs) to enhance reasoning, improving inference accuracy without\nadditional training while mitigating hallucination. However, existing\nframeworks still suffer two practical drawbacks: they must be re-tuned whenever\nthe KG or reasoning task changes, and they depend on a single, high-capacity\nLLM for reliable (i.e., trustworthy) reasoning. To address this, we introduce\nR2-KG, a plug-and-play, dual-agent framework that separates reasoning into two\nroles: an Operator (a low-capacity LLM) that gathers evidence and a Supervisor\n(a high-capacity LLM) that makes final judgments. This design is cost-efficient\nfor LLM inference while still maintaining strong reasoning accuracy.\nAdditionally, R2-KG employs an Abstention mechanism, generating answers only\nwhen sufficient evidence is collected from KG, which significantly enhances\nreliability. Experiments across five diverse benchmarks show that R2-KG\nconsistently outperforms baselines in both accuracy and reliability, regardless\nof the inherent capability of LLMs used as the Operator. Further experiments\nreveal that the single-agent version of R2-KG, equipped with a strict\nself-consistency strategy, achieves significantly higher-than-baseline\nreliability with reduced inference cost but increased abstention rate in\ncomplex KGs. Our findings establish R2-KG as a flexible and cost-effective\nsolution for KG-based reasoning, reducing reliance on high-capacity LLMs while\nensuring trustworthy inference. The code is available at\nhttps://github.com/ekrxjwh2009/R2-KG/."}
{"id": "2502.13442", "pdf": "https://arxiv.org/pdf/2502.13442", "abs": "https://arxiv.org/abs/2502.13442", "authors": ["Jialin Ouyang"], "title": "TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Large language models (LLMs) now achieve near-human performance on standard\nmath word problem benchmarks (e.g., GSM8K), yet their true reasoning ability\nremains disputed. A key concern is that models often produce confident, yet\nunfounded, answers to unanswerable problems. We introduce TreeCut, a synthetic\ndataset that systematically generates infinite unanswerable math word problems\nand their answerable counterparts, by representing each question as a tree and\nremoving chosen necessary conditions. Experiments show TreeCut effectively\ninduce hallucinations in large language models, including GPT-4o and o3-mini,\nwith rates of 64% and 44% in their respective worst-case scenarios under\nzero-shot setting. Further analysis highlights that deeper or more complex\ntrees, composite item names, and removing necessary condition near the middle\nof a path all increase the likelihood of hallucinations, underscoring the\npersistent challenges LLMs face in identifying unanswerable math problems. The\ndataset generation code and sample data are available at\nhttps://github.com/j-bagel/treecut-math."}
{"id": "2405.18069", "pdf": "https://arxiv.org/pdf/2405.18069", "abs": "https://arxiv.org/abs/2405.18069", "authors": ["Albin Soutif--Cormerais", "Simone Magistri", "Joost van de Weijer", "Andew D. Bagdanov"], "title": "An Empirical Analysis of Forgetting in Pre-trained Models with Incremental Low-Rank Updates", "categories": ["cs.LG"], "comment": "CoLLAs 2024 accepted paper, PMLR 274:996-1012", "summary": "Broad, open source availability of large pretrained foundation models on the\ninternet through platforms such as HuggingFace has taken the world of practical\ndeep learning by storm. A classical pipeline for neural network training now\ntypically consists of finetuning these pretrained network on a small target\ndataset instead of training from scratch. In the case of large models this can\nbe done even on modest hardware using a low rank training technique known as\nLow-Rank Adaptation (LoRA). While Low Rank training has already been studied in\nthe continual learning setting, existing works often consider storing the\nlearned adapter along with the existing model but rarely attempt to modify the\nweights of the pretrained model by merging the LoRA with the existing weights\nafter finishing the training of each task. In this article we investigate this\nsetting and study the impact of LoRA rank on the forgetting of the pretraining\nfoundation task and on the plasticity and forgetting of subsequent ones. We\nobserve that this rank has an important impact on forgetting of both the\npretraining and downstream tasks. We also observe that vision transformers\nfinetuned in that way exhibit a sort of ``contextual'' forgetting, a behaviour\nthat we do not observe for residual networks and that we believe has not been\nobserved yet in previous continual learning works."}
{"id": "2502.14037", "pdf": "https://arxiv.org/pdf/2502.14037", "abs": "https://arxiv.org/abs/2502.14037", "authors": ["Giorgio Franceschelli", "Mirco Musolesi"], "title": "DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite their growing capabilities, language models still frequently\nreproduce content from their training data, generate repetitive text, and favor\ncommon grammatical patterns and vocabulary. A possible cause is the decoding\nstrategy: the most common strategies either consider only the most probable\ntokens, which reduces output diversity, or increase the likelihood of unlikely\ntokens, compromising output accuracy and correctness. In this paper, we propose\nthree new decoding methods that leverage a mathematical analysis of the token\nprobability distribution to ensure the generation of contextually appropriate\ntext. In particular, the difference between consecutive, sorted probabilities\ncan be used to truncate incorrect tokens. Experiments concerning math problem\nsolving, extreme summarization, and the divergent association task demonstrate\nthat our approach consistently performs at least as well as existing methods in\nterms of quality and diversity."}
{"id": "2502.14171", "pdf": "https://arxiv.org/pdf/2502.14171", "abs": "https://arxiv.org/abs/2502.14171", "authors": ["Mehdi Jafari", "Devin Yuncheng Hua", "Hao Xue", "Flora Salim"], "title": "Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs, Desires, and Intentions for Human-Like Interaction", "categories": ["cs.CL"], "comment": "Accepted to Findings of ACL 2025", "summary": "Natural language interaction with agentic Artificial Intelligence (AI),\ndriven by Large Language Models (LLMs), is expected to remain a dominant\nparadigm in the near future. While humans instinctively align their\ncommunication with mental states -- an ability known as Theory of Mind (ToM),\ncurrent LLM powered systems exhibit significant limitations in this regard.\nThis study examines the extent to which open source language models (LLaMA) can\ncapture and preserve ToM related information and how effectively it contributes\nto consistent ToM reasoning in generated responses. We further investigate\nwhether explicit manipulation of ToM related components, such as beliefs,\ndesires, and intentions, can enhance response alignment. Experiments on two\nLLaMA 3 variants demonstrate that incorporating ToM informed alignment improves\nresponse quality, achieving win rates of 67 and 63 percent for the 3B and 8B\nmodels, respectively. These findings highlight the potential of ToM driven\nstrategies to improve alignment in LLM based conversational agents."}
{"id": "2406.12915", "pdf": "https://arxiv.org/pdf/2406.12915", "abs": "https://arxiv.org/abs/2406.12915", "authors": ["Yijin Zhou", "Yutang Ge", "Xiaowen Dong", "Yuguang Wang"], "title": "How Out-of-Distribution Detection Learning Theory Enhances Transformer: Learnability and Reliability", "categories": ["cs.LG", "math.PR"], "comment": null, "summary": "Transformers excel in natural language processing and computer vision tasks.\nHowever, they still face challenges in generalizing to Out-of-Distribution\n(OOD) datasets, i.e. data whose distribution differs from that seen during\ntraining. OOD detection aims to distinguish outliers while preserving\nin-distribution (ID) data performance. This paper introduces the OOD detection\nProbably Approximately Correct (PAC) Theory for transformers, which establishes\nthe conditions for data distribution and model configurations for the OOD\ndetection learnability of transformers. It shows that outliers can be\naccurately represented and distinguished with sufficient data under conditions.\nThe theoretical implications highlight the trade-off between theoretical\nprinciples and practical training paradigms. By examining this trade-off, we\nnaturally derived the rationale for leveraging auxiliary outliers to enhance\nOOD detection. Our theory suggests that by penalizing the misclassification of\noutliers within the loss function and strategically generating soft synthetic\noutliers, one can robustly bolster the reliability of transformer networks.\nThis approach yields a novel algorithm that ensures learnability and refines\nthe decision boundaries between inliers and outliers. In practice, the\nalgorithm consistently achieves state-of-the-art (SOTA) performance across\nvarious data formats."}
{"id": "2502.16747", "pdf": "https://arxiv.org/pdf/2502.16747", "abs": "https://arxiv.org/abs/2502.16747", "authors": ["Dai Quoc Nguyen", "Cong Duy Vu Hoang", "Duy Vu", "Gioacchino Tangari", "Thanh Tien Vu", "Don Dharmasiri", "Yuan-Fang Li", "Long Duong"], "title": "SQLong: Enhanced NL2SQL for Longer Contexts with LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to Table Representation Learning Workshop at ACL 2025", "summary": "Open-weight large language models (LLMs) have significantly advanced\nperformance in the Natural Language to SQL (NL2SQL) task. However, their\neffectiveness diminishes when dealing with large database schemas, as the\ncontext length increases. To address this limitation, we present SQLong, a\nnovel and efficient data augmentation framework designed to enhance LLM\nperformance in long-context scenarios for the NL2SQL task. SQLong generates\naugmented datasets by extending existing database schemas with additional\nsynthetic CREATE TABLE commands and corresponding data rows, sampled from\ndiverse schemas in the training data. This approach effectively simulates\nlong-context scenarios during finetuning and evaluation. Through experiments on\nthe Spider and BIRD datasets, we demonstrate that LLMs finetuned with\nSQLong-augmented data significantly outperform those trained on standard\ndatasets. These imply SQLong's practical implementation and its impact on\nimproving NL2SQL capabilities in real-world settings with complex database\nschemas."}
{"id": "2502.16051", "pdf": "https://arxiv.org/pdf/2502.16051", "abs": "https://arxiv.org/abs/2502.16051", "authors": ["Max Lamparth", "Declan Grabb", "Amy Franks", "Scott Gershan", "Kaitlyn N. Kunstman", "Aaron Lulla", "Monika Drummond Roots", "Manu Sharma", "Aryan Shrivastava", "Nina Vasan", "Colleen Waickman"], "title": "Moving Beyond Medical Exam Questions: A Clinician-Annotated Dataset of Real-World Tasks and Ambiguity in Mental Healthcare", "categories": ["cs.CL"], "comment": "Added minor clarifications and expanded appendices", "summary": "Current medical language model (LM) benchmarks often over-simplify the\ncomplexities of day-to-day clinical practice tasks and instead rely on\nevaluating LMs on multiple-choice board exam questions. Thus, we present an\nexpert-created and annotated dataset spanning five critical domains of\ndecision-making in mental healthcare: treatment, diagnosis, documentation,\nmonitoring, and triage. This dataset - created without any LM assistance - is\ndesigned to capture the nuanced clinical reasoning and daily ambiguities mental\nhealth practitioners encounter, reflecting the inherent complexities of care\ndelivery that are missing from existing datasets. Almost all 203 base questions\nwith five answer options each have had the decision-irrelevant demographic\npatient information removed and replaced with variables (e.g., AGE), and are\navailable for male, female, or non-binary-coded patients. For question\ncategories dealing with ambiguity and multiple valid answer options, we create\na preference dataset with uncertainties from the expert annotations. We outline\na series of intended use cases and demonstrate the usability of our dataset by\nevaluating eleven off-the-shelf and four mental health fine-tuned LMs on\ncategory-specific task accuracy, on the impact of patient demographic\ninformation on decision-making, and how consistently free-form responses\ndeviate from human annotated samples."}
{"id": "2407.07613", "pdf": "https://arxiv.org/pdf/2407.07613", "abs": "https://arxiv.org/abs/2407.07613", "authors": ["Dahlia Devapriya", "Thulasi Tholeti", "Janani Suresh", "Sheetal Kalyani"], "title": "Randomness Helps Rigor: A Probabilistic Learning Rate Scheduler Bridging Theory and Deep Learning Practice", "categories": ["cs.LG"], "comment": "We have changed the title to better reflect our work and some parts\n  of our manuscript for better readability", "summary": "Learning rate schedulers have shown great success in speeding up the\nconvergence of learning algorithms in practice. However, their convergence to a\nminimum has not been proven theoretically. This difficulty mainly arises from\nthe fact that, while traditional convergence analysis prescribes to\nmonotonically decreasing (or constant) learning rates, schedulers opt for rates\nthat often increase and decrease through the training epochs. In this work, we\naim to bridge the gap by proposing a probabilistic learning rate scheduler\n(PLRS) that does not conform to the monotonically decreasing condition, with\nprovable convergence guarantees. To cement the relevance and utility of our\nwork in modern day applications, we show experimental results on deep neural\nnetwork architectures such as ResNet, WRN, VGG, and DenseNet on CIFAR-10,\nCIFAR-100, and Tiny ImageNet datasets. We show that PLRS performs as well as or\nbetter than existing state-of-the-art learning rate schedulers in terms of\nconvergence as well as accuracy. For example, while training ResNet-110 on the\nCIFAR-100 dataset, we outperform the state-of-the-art knee scheduler by\n$1.56\\%$ in terms of classification accuracy. Furthermore, on the Tiny ImageNet\ndataset using ResNet-50 architecture, we show a significantly more stable\nconvergence than the cosine scheduler and a better classification accuracy than\nthe existing schedulers."}
{"id": "2502.16901", "pdf": "https://arxiv.org/pdf/2502.16901", "abs": "https://arxiv.org/abs/2502.16901", "authors": ["Himanshu Beniwal", "Sailesh Panda", "Birudugadda Srivibhav", "Mayank Singh"], "title": "Char-mander Use mBackdoor! A Study of Cross-lingual Backdoor Attacks in Multilingual LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We explore \\textbf{C}ross-lingual \\textbf{B}ackdoor \\textbf{AT}tacks (X-BAT)\nin multilingual Large Language Models (mLLMs), revealing how backdoors inserted\nin one language can automatically transfer to others through shared embedding\nspaces. Using toxicity classification as a case study, we demonstrate that\nattackers can compromise multilingual systems by poisoning data in a single\nlanguage, with rare and high-occurring tokens serving as specific, effective\ntriggers. Our findings expose a critical vulnerability that influences the\nmodel's architecture, resulting in a concealed backdoor effect during the\ninformation flow. Our code and data are publicly available\nhttps://github.com/himanshubeniwal/X-BAT."}
{"id": "2502.16894", "pdf": "https://arxiv.org/pdf/2502.16894", "abs": "https://arxiv.org/abs/2502.16894", "authors": ["Chenghao Fan", "Zhenyi Lu", "Sichen Liu", "Chengfeng Gu", "Xiaoye Qu", "Wei Wei", "Yu Cheng"], "title": "Make LoRA Great Again: Boosting LoRA with Adaptive Singular Values and Mixture-of-Experts Optimization Alignment", "categories": ["cs.CL"], "comment": "Accepted by ICML 2025", "summary": "While Low-Rank Adaptation (LoRA) enables parameter-efficient fine-tuning for\nLarge Language Models (LLMs), its performance often falls short of Full\nFine-Tuning (Full FT). Current methods optimize LoRA by initializing with\nstatic singular value decomposition (SVD) subsets, leading to suboptimal\nleveraging of pre-trained knowledge. Another path for improving LoRA is\nincorporating a Mixture-of-Experts (MoE) architecture. However, weight\nmisalignment and complex gradient dynamics make it challenging to adopt SVD\nprior to the LoRA MoE architecture. To mitigate these issues, we propose\n\\underline{G}reat L\\underline{o}R\\underline{A} Mixture-of-Exper\\underline{t}\n(GOAT), a framework that (1) adaptively integrates relevant priors using an\nSVD-structured MoE, and (2) aligns optimization with full fine-tuned MoE by\nderiving a theoretical scaling factor. We demonstrate that proper scaling,\nwithout modifying the architecture or training algorithms, boosts LoRA MoE's\nefficiency and performance. Experiments across 25 datasets, including natural\nlanguage understanding, commonsense reasoning, image classification, and\nnatural language generation, demonstrate GOAT's state-of-the-art performance,\nclosing the gap with Full FT."}
{"id": "2407.11542", "pdf": "https://arxiv.org/pdf/2407.11542", "abs": "https://arxiv.org/abs/2407.11542", "authors": ["Freya Behrens", "Luca Biggio", "Lenka Zdeborov√°"], "title": "Counting in Small Transformers: The Delicate Interplay between Attention and Feed-Forward Layers", "categories": ["cs.LG"], "comment": "9 pages main, 33 including appendix, ICML 2025", "summary": "Next to scaling considerations, architectural design choices profoundly shape\nthe solution space of transformers. In this work, we analyze the solutions\nsimple transformer blocks implement when tackling the histogram task: counting\nitems in sequences. Despite its simplicity, this task reveals a complex\ninterplay between predictive performance, vocabulary and embedding sizes,\ntoken-mixing mechanisms, and feed-forward layer capacity. We identify two\ntheoretical counting strategies transformers adopt, relation-based and\ninventory-based counting, each defining distinct learning regimes for the task.\nThese strategies dictate how functionality is distributed between attention and\nfeed-forward layers. We further show that adding softmax and\nbeginning-of-sequence tokens allow for more robustness when embedding\ndimensions are comparatively small. Empirical introspection of trained models\nclosely confirms both the learning regimes of the various architectures and the\nformation of these strategies during training. We demonstrate how a basic task\nthat requires only aggregation and selection is significantly impacted by minor\ndesign changes."}
{"id": "2502.17537", "pdf": "https://arxiv.org/pdf/2502.17537", "abs": "https://arxiv.org/abs/2502.17537", "authors": ["Lucas Beerens", "Alex D. Richardson", "Kaicheng Zhang", "Dongdong Chen"], "title": "On the Vulnerability of Concept Erasure in Diffusion Models", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The proliferation of text-to-image diffusion models has raised significant\nprivacy and security concerns, particularly regarding the generation of\ncopyrighted or harmful images. In response, several concept erasure (defense)\nmethods have been developed to prevent the generation of unwanted content\nthrough post-hoc finetuning. On the other hand, concept restoration (attack)\nmethods seek to recover supposedly erased concepts via adversarially crafted\nprompts. However, all existing restoration methods only succeed in the highly\nrestrictive scenario of finding adversarial prompts tailed to some fixed seed.\nTo address this, we introduce RECORD, a novel coordinate-descent-based\nrestoration algorithm that finds adversarial prompts to recover erased concepts\nindependently of the seed. Our extensive experiments demonstrate RECORD\nconsistently outperforms the current restoration methods by up to 17.8 times in\nthis setting. Our findings further reveal the susceptibility of unlearned\nmodels to restoration attacks, providing crucial insights into the behavior of\nunlearned models under the influence of adversarial prompts."}
{"id": "2502.19982", "pdf": "https://arxiv.org/pdf/2502.19982", "abs": "https://arxiv.org/abs/2502.19982", "authors": ["Huazheng Wang", "Yongcheng Jing", "Haifeng Sun", "Yingjie Wang", "Jingyu Wang", "Jianxin Liao", "Dacheng Tao"], "title": "Erasing Without Remembering: Implicit Knowledge Forgetting in Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In this paper, we investigate knowledge forgetting in large language models\nwith a focus on its generalisation--ensuring that models forget not only\nspecific training samples but also related implicit knowledge. To this end, we\nbegin by identifying a broader unlearning scope that includes both target data\nand logically associated samples, including rephrased, subject-replaced,\none-hop reasoned, and relation-reversed data. To rigorously evaluate\ngeneralisation, we introduce UGBench, the first comprehensive benchmark\nspecifically designed to assess the unlearning of in-scope implicit knowledge\ncovering 13 state-of-the-art methods across three datasets. UGBench reveals\nthat unlearned models can still recall paraphrased answers and retain target\nfacts in intermediate layers. This motivates us to take a preliminary step\ntoward more generalised implicit knowledge forgetting by proposing PerMU, a\nnovel probability perturbation-based unlearning paradigm. PerMU simulates\nadversarial unlearning samples to eliminate fact-related tokens from the logit\ndistribution, collectively reducing the probabilities of all answer-associated\ntokens. Experiments are conducted on a diverse range of datasets, including\nTOFU, Harry Potter, ZsRE, WMDP, and MUSE, using models ranging from 1.3B to 13B\nin scale. The results demonstrate that PerMU delivers up to a 50.40%\nimprovement in unlearning vanilla target data while maintaining a 40.73% boost\nin forgetting implicit knowledge. Our code can be found in\nhttps://github.com/MaybeLizzy/UGBench."}
{"id": "2407.14058", "pdf": "https://arxiv.org/pdf/2407.14058", "abs": "https://arxiv.org/abs/2407.14058", "authors": ["Jingyao Wang", "Siyu Zhao", "Wenwen Qiang", "Jiangmeng Li", "Changwen Zheng", "Fuchun Sun", "Hui Xiong"], "title": "Towards the Causal Complete Cause of Multi-Modal Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Multi-Modal Learning (MML) aims to learn effective representations across\nmodalities for accurate predictions. Existing methods typically focus on\nmodality consistency and specificity to learn effective representations.\nHowever, from a causal perspective, they may lead to representations that\ncontain insufficient and unnecessary information. To address this, we propose\nthat effective MML representations should be causally sufficient and necessary.\nConsidering practical issues like spurious correlations and modality conflicts,\nwe relax the exogeneity and monotonicity assumptions prevalent in prior works\nand explore the concepts specific to MML, i.e., Causal Complete Cause $C^3$. We\nbegin by defining $C^3$, which quantifies the probability of representations\nbeing causally sufficient and necessary. We then discuss the identifiability of\n$C^3$ and introduce an instrumental variable to support identifying $C^3$ with\nnon-exogeneity and non-monotonicity. Building on this, we conduct the $C^3$\nmeasurement, i.e., \\(C^3\\) risk. We propose a twin network to estimate it\nthrough (i) the real-world branch: utilizing the instrumental variable for\nsufficiency, and (ii) the hypothetical-world branch: applying gradient-based\ncounterfactual modeling for necessity. Theoretical analyses confirm its\nreliability. Based on these results, we propose $C^3$ Regularization, a\nplug-and-play method that enforces the causal completeness of the learned\nrepresentations by minimizing $C^3$ risk. Extensive experiments demonstrate its\neffectiveness."}
{"id": "2503.09579", "pdf": "https://arxiv.org/pdf/2503.09579", "abs": "https://arxiv.org/abs/2503.09579", "authors": ["Yingfa Chen", "Yutong Wu", "Chenyang Song", "Zhen Leng Thai", "Xingyu Shen", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "title": "Cost-Optimal Grouped-Query Attention for Long-Context Modeling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "18 pages, 15 figures", "summary": "Grouped-Query Attention (GQA) is a widely adopted strategy for reducing the\ncomputational cost of attention layers in large language models (LLMs).\nHowever, current GQA configurations are often suboptimal because they overlook\nhow context length influences inference cost. Since inference cost grows with\ncontext length, the most cost-efficient GQA configuration should also vary\naccordingly. In this work, we analyze the relationship among context length,\nmodel size, GQA configuration, and model loss, and introduce two innovations:\n(1) we decouple the total head size from the hidden size, enabling more\nflexible control over attention FLOPs; and (2) we jointly optimize the model\nsize and the GQA configuration to arrive at a better allocation of inference\nresources between attention layers and other components. Our analysis reveals\nthat commonly used GQA configurations are highly suboptimal for long-context\nscenarios. More importantly, we propose a recipe for deriving cost-optimal GQA\nconfigurations. Our results show that for long-context scenarios, one should\nuse fewer attention heads while scaling up model size. Configurations selected\nby our recipe can reduce both memory usage and FLOPs by more than 50% compared\nto Llama-3's GQA, with *no degradation in model capabilities*. Our findings\noffer valuable insights for designing efficient long-context LLMs. The code is\navailable at https://www.github.com/THUNLP/cost-optimal-gqa ."}
{"id": "2502.20592", "pdf": "https://arxiv.org/pdf/2502.20592", "abs": "https://arxiv.org/abs/2502.20592", "authors": ["Juntai Cao", "Xiang Zhang", "Raymond Li", "Chuyuan Li", "Chenyu You", "Shafiq Joty", "Giuseppe Carenini"], "title": "Multi2: Multi-Agent Test-Time Scalable Framework for Multi-Document Processing", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in test-time scaling have shown promising results in\nimproving Large Language Model (LLM) performance through strategic computation\nallocation during inference. While this approach has demonstrated strong\nimprovements in logical and mathematical reasoning tasks, its application to\nnatural language generation (NLG), particularly summarization, remains\nunexplored. Multi-Document Summarization (MDS), a fundamental task in NLG,\npresents unique challenges by requiring models to extract and synthesize\nessential information across multiple lengthy documents. Unlike reasoning\ntasks, MDS demands a more nuanced approach to prompt design and ensemble\nmethods, as no single \"best\" prompt can satisfy diverse summarization\nrequirements. We propose a novel framework leveraging test-time scaling for\nMDS. Our approach employs prompt ensemble techniques to generate multiple\ncandidate summaries using various prompts, then combines them with an\naggregator to produce a refined summary. To evaluate our method effectively, we\nalso introduce two new LLM-based metrics: the Consistency-Aware Preference\n(CAP) score and LLM Atom-Content-Unit (LLM-ACU) score, which assess summary\nquality while addressing the positional bias inherent in traditional automatic\nevaluation. Our extensive experiments demonstrate that this framework\nsignificantly enhances summary quality while also revealing the practical\nscaling boundaries to MDS tasks."}
{"id": "2408.03619", "pdf": "https://arxiv.org/pdf/2408.03619", "abs": "https://arxiv.org/abs/2408.03619", "authors": ["Matthew J. Holland", "Toma Hamada"], "title": "Making Robust Generalizers Less Rigid with Loss Concentration", "categories": ["cs.LG"], "comment": null, "summary": "While the traditional formulation of machine learning tasks is in terms of\nperformance on average, in practice we are often interested in how well a\ntrained model performs on rare or difficult data points at test time. To\nachieve more robust and balanced generalization, methods applying\nsharpness-aware minimization to a subset of worst-case examples have proven\nsuccessful for image classification tasks, but only using overparameterized\nneural networks under which the relative difference between \"easy\" and \"hard\"\ndata points becomes negligible. In this work, we show how such a strategy can\ndramatically break down under simpler models where the difficulty gap becomes\nmore extreme. As a more flexible alternative, instead of typical sharpness, we\npropose and evaluate a training criterion which penalizes poor loss\nconcentration, which can be easily combined with loss transformations such\nexponential tilting, conditional value-at-risk (CVaR), or distributionally\nrobust optimization (DRO) that control tail emphasis."}
{"id": "2503.10542", "pdf": "https://arxiv.org/pdf/2503.10542", "abs": "https://arxiv.org/abs/2503.10542", "authors": ["Arvid Frydenlund"], "title": "Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7; I.2.8; I.5.0"], "comment": "ACL 2025 Main. A camera-ready version will follow in a few weeks. A\n  reduced version of this work has was also accepted to the Workshop on\n  Spurious Correlation and Shortcut Learning: Foundations and Solutions (SCSL)\n  at ICLR 2025", "summary": "This work concerns the path-star task, a minimal example of searching over a\ngraph. The graph, $G$, is star-shaped with $D$ arms radiating from a start\nnode, $s$. A language model (LM) is given $G$, $s$, and a target node $t$,\nwhich ends one of the arms and is tasked with generating the arm containing\n$t$. The minimal nature of this task means only a single choice needs to be\nmade: which of the $D$ arms contains $t$?\n  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to\na learned shortcut that absorbs training supervision. We show how this\npathology is caused by excess supervision and we present a series of solutions\ndemonstrating that the task is solvable via decoder-only LMs. We find that the\ntask's minimal nature causes its difficulty, as it prevents task decomposition.\nOur solutions provide insight into the pathology and its implications for LMs\ntrained via next-token prediction."}
{"id": "2502.21074", "pdf": "https://arxiv.org/pdf/2502.21074", "abs": "https://arxiv.org/abs/2502.21074", "authors": ["Zhenyi Shen", "Hanqi Yan", "Linhai Zhang", "Zhanghao Hu", "Yali Du", "Yulan He"], "title": "CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation", "categories": ["cs.CL"], "comment": "16 pages", "summary": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by\nencouraging step-by-step reasoning in natural language. However, leveraging a\nlatent continuous space for reasoning may offer benefits in terms of both\nefficiency and robustness. Prior implicit CoT methods attempt to bypass\nlanguage completely by reasoning in continuous space but have consistently\nunderperformed compared to the standard explicit CoT approach. We introduce\nCODI (Continuous Chain-of-Thought via Self-Distillation), a novel training\nframework that effectively compresses natural language CoT into continuous\nspace. CODI jointly trains a teacher task (Explicit CoT) and a student task\n(Implicit CoT), distilling the reasoning ability from language into continuous\nspace by aligning the hidden states of a designated token. Our experiments show\nthat CODI is the first implicit CoT approach to match the performance of\nexplicit CoT on GSM8k at the GPT-2 scale, achieving a 3.1x compression rate and\noutperforming the previous state-of-the-art by 28.2% in accuracy. CODI also\ndemonstrates robustness, generalizable to complex datasets, and\ninterpretability. These results validate that LLMs can reason effectively not\nonly in natural language, but also in a latent continuous space."}
{"id": "2409.06998", "pdf": "https://arxiv.org/pdf/2409.06998", "abs": "https://arxiv.org/abs/2409.06998", "authors": ["Gangda Deng", "Hongkuan Zhou", "Rajgopal Kannan", "Viktor Prasanna"], "title": "Mixture of Scope Experts at Test: Generalizing Deeper Graph Neural Networks with Shallow Variants", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Heterophilous graphs, where dissimilar nodes tend to connect, pose a\nchallenge for graph neural networks (GNNs). Increasing the GNN depth can expand\nthe scope (i.e., receptive field), potentially finding homophily from the\nhigher-order neighborhoods. However, GNNs suffer from performance degradation\nas depth increases. Despite having better expressivity, state-of-the-art deeper\nGNNs achieve only marginal improvements compared to their shallow variants.\nThrough theoretical and empirical analysis, we systematically demonstrate a\nshift in GNN generalization preferences across nodes with different homophily\nlevels as depth increases. This creates a disparity in generalization patterns\nbetween GNN models with varying depth. Based on these findings, we propose to\nimprove deeper GNN generalization while maintaining high expressivity by\nMixture of scope experts at test (Moscat). Experimental results show that\nMoscat works flexibly with various GNNs across a wide range of datasets while\nsignificantly improving accuracy. Our code is available at\n(https://github.com/Hydrapse/moscat)."}
{"id": "2503.10657", "pdf": "https://arxiv.org/pdf/2503.10657", "abs": "https://arxiv.org/abs/2503.10657", "authors": ["Zhongzhan Huang", "Guoming Ling", "Yupei Lin", "Yandong Chen", "Shanshan Zhong", "Hefeng Wu", "Liang Lin"], "title": "RouterEval: A Comprehensive Benchmark for Routing LLMs to Explore Model-level Scaling Up in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Routing large language models (LLMs) is a new paradigm that uses a router to\nrecommend the best LLM from a pool of candidates for a given input. In this\npaper, our comprehensive analysis with more than 8,500 LLMs reveals a novel\nmodel-level scaling up phenomenon in Routing LLMs, i.e., a capable router can\nsignificantly enhance the performance of this paradigm as the number of\ncandidates increases. This improvement can even surpass the performance of the\nbest single model in the pool and many existing strong LLMs, confirming it a\nhighly promising paradigm. However, the lack of comprehensive and open-source\nbenchmarks for Routing LLMs has hindered the development of routers. In this\npaper, we introduce RouterEval, a benchmark tailored for router research, which\nincludes over 200,000,000 performance records for 12 popular LLM evaluations\nacross various areas such as commonsense reasoning, semantic understanding,\netc., based on over 8,500 various LLMs. Using RouterEval, extensive evaluations\nof existing Routing LLM methods reveal that most still have significant room\nfor improvement. See https://github.com/MilkThink-Lab/RouterEval for all data,\ncode and tutorial."}
{"id": "2503.01513", "pdf": "https://arxiv.org/pdf/2503.01513", "abs": "https://arxiv.org/abs/2503.01513", "authors": ["Katerina Korre", "Dimitris Tsirmpas", "Nikos Gkoumas", "Emma Cabal√©", "Danai Myrtzani", "Theodoros Evgeniou", "Ion Androutsopoulos", "John Pavlopoulos"], "title": "Evaluation and Facilitation of Online Discussions in the LLM Era: A Survey", "categories": ["cs.CL"], "comment": null, "summary": "We present a survey of methods for assessing and enhancing the quality of\nonline discussions, focusing on the potential of LLMs. While online discourses\naim, at least in theory, to foster mutual understanding, they often devolve\ninto harmful exchanges, such as hate speech, threatening social cohesion and\ndemocratic values. Recent advancements in LLMs enable artificial facilitation\nagents to not only moderate content, but also actively improve the quality of\ninteractions. Our survey synthesizes ideas from NLP and Social Sciences to\nprovide (a) a new taxonomy on discussion quality evaluation, (b) an overview of\nintervention and facilitation strategies, (c) along with a new taxonomy of\nconversation facilitation datasets, (d) an LLM-oriented roadmap of good\npractices and future research directions, from technological and societal\nperspectives."}
{"id": "2409.17355", "pdf": "https://arxiv.org/pdf/2409.17355", "abs": "https://arxiv.org/abs/2409.17355", "authors": ["Filippo Lazzati", "Alberto Maria Metelli"], "title": "Learning Utilities from Demonstrations in Markov Decision Processes", "categories": ["cs.LG"], "comment": "International Conference on Machine Learning 42 (ICML 2025)", "summary": "Our goal is to extract useful knowledge from demonstrations of behavior in\nsequential decision-making problems. Although it is well-known that humans\ncommonly engage in risk-sensitive behaviors in the presence of stochasticity,\nmost Inverse Reinforcement Learning (IRL) models assume a risk-neutral agent.\nBeyond introducing model misspecification, these models do not directly capture\nthe risk attitude of the observed agent, which can be crucial in many\napplications. In this paper, we propose a novel model of behavior in Markov\nDecision Processes (MDPs) that explicitly represents the agent's risk attitude\nthrough a utility function. We then define the Utility Learning (UL) problem as\nthe task of inferring the observed agent's risk attitude, encoded via a utility\nfunction, from demonstrations in MDPs, and we analyze the partial\nidentifiability of the agent's utility. Furthermore, we devise two provably\nefficient algorithms for UL in a finite-data regime, and we analyze their\nsample complexity. We conclude with proof-of-concept experiments that\nempirically validate both our model and our algorithms."}
{"id": "2503.12908", "pdf": "https://arxiv.org/pdf/2503.12908", "abs": "https://arxiv.org/abs/2503.12908", "authors": ["Xinyan Jiang", "Hang Ye", "Yongxin Zhu", "Xiaoying Zheng", "Zikang Chen", "Jun Gong"], "title": "HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL2025 findings", "summary": "Large Language Models (LLMs) often generate hallucinations, producing outputs\nthat are contextually inaccurate or factually incorrect. We introduce HICD, a\nnovel method designed to induce hallucinations for contrastive decoding to\nmitigate hallucinations. Unlike existing contrastive decoding methods, HICD\nselects attention heads crucial to the model's prediction as inducing heads,\nthen induces hallucinations by dispersing attention of these inducing heads and\ncompares the hallucinated outputs with the original outputs to obtain the final\nresult. Our approach significantly improves performance on tasks requiring\ncontextual faithfulness, such as context completion, reading comprehension, and\nquestion answering. It also improves factuality in tasks requiring accurate\nknowledge recall. We demonstrate that our inducing heads selection and\nattention dispersion method leads to more \"contrast-effective\" hallucinations\nfor contrastive decoding, outperforming other hallucination-inducing methods.\nOur findings provide a promising strategy for reducing hallucinations by\ninducing hallucinations in a controlled manner, enhancing the performance of\nLLMs in a wide range of tasks."}
{"id": "2503.02589", "pdf": "https://arxiv.org/pdf/2503.02589", "abs": "https://arxiv.org/abs/2503.02589", "authors": ["Caiyu Hu", "Yikai Zhang", "Tinghui Zhu", "Yiwei Ye", "Yanghua Xiao"], "title": "MCiteBench: A Multimodal Benchmark for Generating Text with Citations", "categories": ["cs.CL", "cs.IR"], "comment": "https://caiyuhu.github.io/MCiteBench/", "summary": "Multimodal Large Language Models (MLLMs) have advanced in integrating diverse\nmodalities but frequently suffer from hallucination. A promising solution to\nmitigate this issue is to generate text with citations, providing a transparent\nchain for verification. However, existing work primarily focuses on generating\ncitations for text-only content, leaving the challenges of multimodal scenarios\nlargely unexplored. In this paper, we introduce MCiteBench, the first benchmark\ndesigned to assess the ability of MLLMs to generate text with citations in\nmultimodal contexts. Our benchmark comprises data derived from academic papers\nand review-rebuttal interactions, featuring diverse information sources and\nmultimodal content. Experimental results reveal that MLLMs struggle to ground\ntheir outputs reliably when handling multimodal input. Further analysis\nuncovers a systematic modality bias and reveals how models internally rely on\ndifferent sources when generating citations, offering insights into model\nbehavior and guiding future directions for multimodal citation tasks."}
{"id": "2409.18332", "pdf": "https://arxiv.org/pdf/2409.18332", "abs": "https://arxiv.org/abs/2409.18332", "authors": ["Pranav Maneriker", "Aditya T. Vadlamani", "Anutam Srinivasan", "Yuntian He", "Ali Payani", "Srinivasan Parthasarathy"], "title": "Conformal Prediction: A Theoretical Note and Benchmarking Transductive Node Classification in Graphs", "categories": ["cs.LG", "stat.ML"], "comment": "TMLR 2025 Camera Ready Version", "summary": "Conformal prediction has become increasingly popular for quantifying the\nuncertainty associated with machine learning models. Recent work in graph\nuncertainty quantification has built upon this approach for conformal graph\nprediction. The nascent nature of these explorations has led to conflicting\nchoices for implementations, baselines, and method evaluation. In this work, we\nanalyze the design choices made in the literature and discuss the tradeoffs\nassociated with existing methods. Building on the existing implementations, we\nintroduce techniques to scale existing methods to large-scale graph datasets\nwithout sacrificing performance. Our theoretical and empirical results justify\nour recommendations for future scholarship in graph conformal prediction."}
{"id": "2503.12931", "pdf": "https://arxiv.org/pdf/2503.12931", "abs": "https://arxiv.org/abs/2503.12931", "authors": ["Rui Pu", "Chaozhuo Li", "Rui Ha", "Litian Zhang", "Lirong Qiu", "Xi Zhang"], "title": "MirrorShield: Towards Universal Defense Against Jailbreaks via Entropy-Guided Mirror Crafting", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Defending large language models (LLMs) against jailbreak attacks is crucial\nfor ensuring their safe deployment. Existing defense strategies typically rely\non predefined static criteria to differentiate between harmful and benign\nprompts. However, such rigid rules fail to accommodate the inherent complexity\nand dynamic nature of real-world jailbreak attacks. In this paper, we focus on\nthe novel challenge of universal defense against diverse jailbreaks. We propose\na new concept ``mirror'', which is a dynamically generated prompt that reflects\nthe syntactic structure of the input while ensuring semantic safety. The\ndiscrepancies between input prompts and their corresponding mirrors serve as\nguiding principles for defense. A novel defense model, MirrorShield, is further\nproposed to detect and calibrate risky inputs based on the crafted mirrors.\nEvaluated on multiple benchmark datasets and compared against ten\nstate-of-the-art attack methods, MirrorShield demonstrates superior defense\nperformance and promising generalization capabilities."}
{"id": "2503.04372", "pdf": "https://arxiv.org/pdf/2503.04372", "abs": "https://arxiv.org/abs/2503.04372", "authors": ["Orfeas Menis Mastromichalakis", "Giorgos Filandrianos", "Maria Symeonaki", "Giorgos Stamou"], "title": "Assumed Identities: Quantifying Gender Bias in Machine Translation of Gender-Ambiguous Occupational Terms", "categories": ["cs.CL"], "comment": null, "summary": "Machine Translation (MT) systems frequently encounter gender-ambiguous\noccupational terms, where they must assign gender without explicit contextual\ncues. While individual translations in such cases may not be inherently biased,\nsystematic patterns-such as consistently translating certain professions with\nspecific genders-can emerge, reflecting and perpetuating societal stereotypes.\nThis ambiguity challenges traditional instance-level single-answer evaluation\napproaches, as no single gold standard translation exists. To address this, we\nintroduce GRAPE, a probability-based metric designed to evaluate gender bias by\nanalyzing aggregated model responses. Alongside this, we present GAMBIT-MT, a\nbenchmarking dataset in English with gender-ambiguous occupational terms. Using\nGRAPE, we evaluate several MT systems and examine whether their gendered\ntranslations in Greek and French align with or diverge from societal\nstereotypes, real-world occupational gender distributions, and normative\nstandards."}
{"id": "2410.02344", "pdf": "https://arxiv.org/pdf/2410.02344", "abs": "https://arxiv.org/abs/2410.02344", "authors": ["Felix Zimmer", "Patrik Okanovic", "Torsten Hoefler"], "title": "EntryPrune: Neural Network Feature Selection using First Impressions", "categories": ["cs.LG"], "comment": null, "summary": "There is an ongoing effort to develop feature selection algorithms to improve\ninterpretability, reduce computational resources, and minimize overfitting in\npredictive models. Neural networks stand out as architectures on which to build\nfeature selection methods, and recently, neuron pruning and regrowth have\nemerged from the sparse neural network literature as promising new tools. We\nintroduce EntryPrune, a novel supervised feature selection algorithm using a\ndense neural network with a dynamic sparse input layer. It employs entry-based\npruning, a novel approach that compares neurons based on their relative change\ninduced when they have entered the network. Extensive experiments on 13\ndifferent datasets show that our approach generally outperforms the current\nstate-of-the-art methods, and in particular improves the average accuracy on\nlow-dimensional datasets. Furthermore, we show that EntryPruning surpasses\ntraditional techniques such as magnitude pruning within the EntryPrune\nframework and that EntryPrune achieves lower runtime than competing approaches.\nOur code is available at https://github.com/flxzimmer/entryprune."}
{"id": "2504.01281", "pdf": "https://arxiv.org/pdf/2504.01281", "abs": "https://arxiv.org/abs/2504.01281", "authors": ["Sakhinana Sagar Srinivas", "Akash Das", "Shivam Gupta", "Venkataramana Runkana"], "title": "Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "We present a comprehensive framework for enhancing Retrieval-Augmented\nGeneration (RAG) systems through dynamic retrieval strategies and reinforcement\nfine-tuning. This approach significantly improves large language models on\nknowledge-intensive tasks, including opendomain question answering and complex\nreasoning. Our framework integrates two complementary techniques:\nPolicy-Optimized RetrievalAugmented Generation (PORAG), which optimizes the use\nof retrieved information, and Adaptive Token-Layer Attention Scoring (ATLAS),\nwhich dynamically determines retrieval timing and content based on contextual\nneeds. Together, these techniques enhance both the utilization and relevance of\nretrieved content, improving factual accuracy and response quality. Designed as\na lightweight solution compatible with any Transformer-based LLM without\nrequiring additional training, our framework excels in knowledge-intensive\ntasks, boosting output accuracy in RAG settings. We further propose CRITIC, a\nnovel method to selectively compress key-value caches by token importance,\nmitigating memory bottlenecks in long-context applications. The framework also\nincorporates test-time scaling techniques to dynamically balance reasoning\ndepth and computational resources, alongside optimized decoding strategies for\nfaster inference. Experiments on benchmark datasets show that our framework\nreduces hallucinations, strengthens domain-specific reasoning, and achieves\nsignificant efficiency and scalability gains over traditional RAG systems. This\nintegrated approach advances the development of robust, efficient, and scalable\nRAG systems across diverse applications."}
{"id": "2503.18132", "pdf": "https://arxiv.org/pdf/2503.18132", "abs": "https://arxiv.org/abs/2503.18132", "authors": ["Yibo Yan", "Shen Wang", "Jiahao Huo", "Philip S. Yu", "Xuming Hu", "Qingsong Wen"], "title": "MathAgent: Leveraging a Mixture-of-Math-Agent Framework for Real-World Multimodal Mathematical Error Detection", "categories": ["cs.CL"], "comment": "Accepted by The 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL Industry 2025, Oral Presentation)", "summary": "Mathematical error detection in educational settings presents a significant\nchallenge for Multimodal Large Language Models (MLLMs), requiring a\nsophisticated understanding of both visual and textual mathematical content\nalong with complex reasoning capabilities. Though effective in mathematical\nproblem-solving, MLLMs often struggle with the nuanced task of identifying and\ncategorizing student errors in multimodal mathematical contexts. Therefore, we\nintroduce MathAgent, a novel Mixture-of-Math-Agent framework designed\nspecifically to address these challenges. Our approach decomposes error\ndetection into three phases, each handled by a specialized agent: an image-text\nconsistency validator, a visual semantic interpreter, and an integrative error\nanalyzer. This architecture enables more accurate processing of mathematical\ncontent by explicitly modeling relationships between multimodal problems and\nstudent solution steps. We evaluate MathAgent on real-world educational data,\ndemonstrating approximately 5% higher accuracy in error step identification and\n3% improvement in error categorization compared to baseline models. Besides,\nMathAgent has been successfully deployed in an educational platform that has\nserved over one million K-12 students, achieving nearly 90% student\nsatisfaction while generating significant cost savings by reducing manual error\ndetection."}
{"id": "2410.04458", "pdf": "https://arxiv.org/pdf/2410.04458", "abs": "https://arxiv.org/abs/2410.04458", "authors": ["Ruinan Jin", "Xiao Li", "Yaoliang Yu", "Baoxiang Wang"], "title": "A Comprehensive Framework for Analyzing the Convergence of Adam: Bridging the Gap with SGD", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Adaptive Moment Estimation (Adam) is a cornerstone optimization algorithm in\ndeep learning, widely recognized for its flexibility with adaptive learning\nrates and efficiency in handling large-scale data. However, despite its\npractical success, the theoretical understanding of Adam's convergence has been\nconstrained by stringent assumptions, such as almost surely bounded stochastic\ngradients or uniformly bounded gradients, which are more restrictive than those\ntypically required for analyzing stochastic gradient descent (SGD).\n  In this paper, we introduce a novel and comprehensive framework for analyzing\nthe convergence properties of Adam. This framework offers a versatile approach\nto establishing Adam's convergence. Specifically, we prove that Adam achieves\nasymptotic (last iterate sense) convergence in both the almost sure sense and\nthe \\(L_1\\) sense under the relaxed assumptions typically used for SGD, namely\n\\(L\\)-smoothness and the ABC inequality. Meanwhile, under the same assumptions,\nwe show that Adam attains non-asymptotic sample complexity bounds similar to\nthose of SGD."}
{"id": "2504.02438", "pdf": "https://arxiv.org/pdf/2504.02438", "abs": "https://arxiv.org/abs/2504.02438", "authors": ["Chuanqi Cheng", "Jian Guan", "Wei Wu", "Rui Yan"], "title": "Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Long-form video processing fundamentally challenges vision-language models\n(VLMs) due to the high computational costs of handling extended temporal\nsequences. Existing token pruning and feature merging methods often sacrifice\ncritical temporal dependencies or dilute semantic information. We introduce\ndifferential distillation, a principled approach that systematically preserves\ntask-relevant information while suppressing redundancy. Based on this\nprinciple, we develop ViLAMP, a hierarchical video-language model that\nprocesses hour-long videos at \"mixed precision\" through two key mechanisms: (1)\ndifferential keyframe selection that maximizes query relevance while\nmaintaining temporal distinctiveness at the frame level and (2) differential\nfeature merging that preserves query-salient features in non-keyframes at the\npatch level. Hence, ViLAMP retains full information in keyframes while reducing\nnon-keyframes to their most salient features, resembling mixed-precision\ntraining. Extensive experiments demonstrate ViLAMP's superior performance\nacross five video understanding benchmarks, particularly on long-form content.\nNotably, ViLAMP can process ultra-long videos (up to 10K frames) on a single\nNVIDIA A100 GPU, achieving substantial computational efficiency while\nmaintaining state-of-the-art performance. Code and model are available at\nhttps://github.com/steven-ccq/ViLAMP."}
{"id": "2504.05831", "pdf": "https://arxiv.org/pdf/2504.05831", "abs": "https://arxiv.org/abs/2504.05831", "authors": ["Mingye Zhu", "Yi Liu", "Zheren Fu", "Yongdong Zhang", "Zhendong Mao"], "title": "Leveraging Robust Optimization for LLM Alignment under Distribution Shifts", "categories": ["cs.CL"], "comment": null, "summary": "Preference alignment methods are increasingly critical for steering large\nlanguage models (LLMs) to generate outputs consistent with human values. While\nrecent approaches often rely on synthetic data generated by LLMs for\nscalability and cost-efficiency reasons, this reliance can introduce\ndistribution shifts that undermine the nuanced representation of human\npreferences needed for desirable outputs. In this paper, we propose a novel\ndistribution-aware optimization framework that improves preference alignment\ndespite such shifts. Our approach first leverages well-learned classifiers to\nassign a calibration value to each training sample, quantifying its alignment\nwith the target human-preferred distribution. These values are then\nincorporated into a robust optimization objective that minimizes the worst-case\nloss over regions of the data space most relevant to human preferences. By\nexplicitly focusing optimization on the target distribution, our approach\nmitigates the impact of distributional mismatch and improves the generation of\nresponses that better reflect intended values."}
{"id": "2410.07003", "pdf": "https://arxiv.org/pdf/2410.07003", "abs": "https://arxiv.org/abs/2410.07003", "authors": ["Leticia Mattos Da Silva", "Silvia Sell√°n", "Francisco Vargas", "Justin Solomon"], "title": "Mirror Bridges Between Probability Measures", "categories": ["cs.LG"], "comment": null, "summary": "Resampling from a target measure whose density is unknown is a fundamental\nproblem in mathematical statistics and machine learning. A setting that\ndominates the machine learning literature consists of learning a map from an\neasy-to-sample prior, such as the Gaussian distribution, to a target measure.\nUnder this model, samples from the prior are pushed forward to generate a new\nsample on the target measure, which is often difficult to sample from directly.\nOf particular interest is the problem of generating a new sample that is\nproximate to or otherwise conditioned on a given input sample. In this paper,\nwe propose a new model called mirror bridges to solve this problem of\nconditional resampling. Our key observation is that solving the Schr\\\"odinger\nbridge problem between a distribution and itself provides a natural way to\nproduce new samples from conditional distributions, giving in-distribution\nvariations of an input data point. We demonstrate how to efficiently estimate\nthe solution to this largely overlooked version of the Schr\\\"odinger bridge\nproblem, and we prove that under mild conditions, the difference between our\nestimate and the true Schr\\\"odinger bridge can be controlled explicitly. We\nshow that our proposed method leads to significant algorithmic simplifications\nover existing alternatives, in addition to providing control over\nin-distribution variation. Empirically, we demonstrate how these benefits can\nbe leveraged to produce proximal samples in a number of application domains."}
{"id": "2504.08399", "pdf": "https://arxiv.org/pdf/2504.08399", "abs": "https://arxiv.org/abs/2504.08399", "authors": ["Yin Jou Huang", "Rafik Hadfi"], "title": "Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 6 figures, 6 tables", "summary": "Self-report questionnaires have long been used to assess LLM personality\ntraits, yet they fail to capture behavioral nuances due to biases and\nmeta-knowledge contamination. This paper proposes a novel multi-observer\nframework for personality trait assessments in LLM agents that draws on\ninformant-report methods in psychology. Instead of relying on self-assessments,\nwe employ multiple observer agents. Each observer is configured with a specific\nrelational context (e.g., family member, friend, or coworker) and engages the\nsubject LLM in dialogue before evaluating its behavior across the Big Five\ndimensions. We show that these observer-report ratings align more closely with\nhuman judgments than traditional self-reports and reveal systematic biases in\nLLM self-assessments. We also found that aggregating responses from 5 to 7\nobservers reduces systematic biases and achieves optimal reliability. Our\nresults highlight the role of relationship context in perceiving personality\nand demonstrate that a multi-observer paradigm offers a more reliable,\ncontext-sensitive approach to evaluating LLM personality traits."}
{"id": "2504.10368", "pdf": "https://arxiv.org/pdf/2504.10368", "abs": "https://arxiv.org/abs/2504.10368", "authors": ["Wenyuan Zhang", "Shuaiyi Nie", "Xinghua Zhang", "Zefeng Zhang", "Tingwen Liu"], "title": "S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models", "categories": ["cs.CL", "cs.AI"], "comment": "31 pages, 9 figures, 16 tables", "summary": "We introduce S1-Bench, a novel benchmark designed to evaluate the performance\nof Large Reasoning Models (LRMs) on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their heavy reliance on system 2 thinking may limit their system 1\nthinking capabilities. However, there is a lack of an appropriate benchmark for\nevaluating LRM's system 1 thinking capabilities. To fill this gap, S1-Bench\nintroduces a suite of simple, diverse, and natural questions across multiple\ndomains and languages, specifically designed to assess LRMs' performance on\nquestions more suitable for system 1 . We conduct extensive evaluations across\n28 LRMs, revealing their inefficiency, inadequate accuracy, and limited\nrobustness when handling simple questions. Additionally, we observe a gap\nbetween their difficulty perception and generation length. Overall, this work\npaves the way toward dual-system compatibility in the development of LRMs."}
{"id": "2410.10431", "pdf": "https://arxiv.org/pdf/2410.10431", "abs": "https://arxiv.org/abs/2410.10431", "authors": ["Hampus Gummesson Svensson", "Christian Tyrchan", "Ola Engkvist", "Morteza Haghir Chehreghani"], "title": "Diversity-Aware Reinforcement Learning for de novo Drug Design", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Fine-tuning a pre-trained generative model has demonstrated good performance\nin generating promising drug molecules. The fine-tuning task is often\nformulated as a reinforcement learning problem, where previous methods\nefficiently learn to optimize a reward function to generate potential drug\nmolecules. Nevertheless, in the absence of an adaptive update mechanism for the\nreward function, the optimization process can become stuck in local optima. The\nefficacy of the optimal molecule in a local optimization may not translate to\nusefulness in the subsequent drug optimization process or as a potential\nstandalone clinical candidate. Therefore, it is important to generate a diverse\nset of promising molecules. Prior work has modified the reward function by\npenalizing structurally similar molecules, primarily focusing on finding\nmolecules with higher rewards. To date, no study has comprehensively examined\nhow different adaptive update mechanisms for the reward function influence the\ndiversity of generated molecules. In this work, we investigate a wide range of\nintrinsic motivation methods and strategies to penalize the extrinsic reward,\nand how they affect the diversity of the set of generated molecules. Our\nexperiments reveal that combining structure- and prediction-based methods\ngenerally yields better results in terms of diversity."}
{"id": "2504.12324", "pdf": "https://arxiv.org/pdf/2504.12324", "abs": "https://arxiv.org/abs/2504.12324", "authors": ["Mengying Yuan", "Wenhao Wang", "Zixuan Wang", "Yujie Huang", "Kangli Wei", "Fei Li", "Chong Teng", "Donghong Ji"], "title": "Cross-Document Cross-Lingual NLI via RST-Enhanced Graph Fusion and Interpretability Prediction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural Language Inference (NLI) is a fundamental task in natural language\nprocessing. While NLI has developed many sub-directions such as sentence-level\nNLI, document-level NLI and cross-lingual NLI, Cross-Document Cross-Lingual NLI\n(CDCL-NLI) remains largely unexplored. In this paper, we propose a novel\nparadigm: CDCL-NLI, which extends traditional NLI capabilities to\nmulti-document, multilingual scenarios. To support this task, we construct a\nhigh-quality CDCL-NLI dataset including 25,410 instances and spanning 26\nlanguages. To address the limitations of previous methods on CDCL-NLI task, we\nfurther propose an innovative method that integrates RST-enhanced graph fusion\nwith interpretability-aware prediction. Our approach leverages RST (Rhetorical\nStructure Theory) within heterogeneous graph neural networks for cross-document\ncontext modeling, and employs a structure-aware semantic alignment based on\nlexical chains for cross-lingual understanding. For NLI interpretability, we\ndevelop an EDU (Elementary Discourse Unit)-level attribution framework that\nproduces extractive explanations. Extensive experiments demonstrate our\napproach's superior performance, achieving significant improvements over both\nconventional NLI models as well as large language models. Our work sheds light\non the study of NLI and will bring research interest on cross-document\ncross-lingual context understanding, hallucination elimination and\ninterpretability inference. Our code and datasets are available at\n\\href{https://anonymous.4open.science/r/CDCL-NLI-637E/}{CDCL-NLI-link} for peer\nreview."}
{"id": "2504.14150", "pdf": "https://arxiv.org/pdf/2504.14150", "abs": "https://arxiv.org/abs/2504.14150", "authors": ["Katie Matton", "Robert Osazuwa Ness", "John Guttag", "Emre Kƒ±cƒ±man"], "title": "Walk the Talk? Measuring the Faithfulness of Large Language Model Explanations", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "comment": "66 pages, 14 figures, 40 tables; ICLR 2025 (spotlight) camera ready", "summary": "Large language models (LLMs) are capable of generating plausible explanations\nof how they arrived at an answer to a question. However, these explanations can\nmisrepresent the model's \"reasoning\" process, i.e., they can be unfaithful.\nThis, in turn, can lead to over-trust and misuse. We introduce a new approach\nfor measuring the faithfulness of LLM explanations. First, we provide a\nrigorous definition of faithfulness. Since LLM explanations mimic human\nexplanations, they often reference high-level concepts in the input question\nthat purportedly influenced the model. We define faithfulness in terms of the\ndifference between the set of concepts that LLM explanations imply are\ninfluential and the set that truly are. Second, we present a novel method for\nestimating faithfulness that is based on: (1) using an auxiliary LLM to modify\nthe values of concepts within model inputs to create realistic counterfactuals,\nand (2) using a Bayesian hierarchical model to quantify the causal effects of\nconcepts at both the example- and dataset-level. Our experiments show that our\nmethod can be used to quantify and discover interpretable patterns of\nunfaithfulness. On a social bias task, we uncover cases where LLM explanations\nhide the influence of social bias. On a medical question answering task, we\nuncover cases where LLM explanations provide misleading claims about which\npieces of evidence influenced the model's decisions."}
{"id": "2410.13853", "pdf": "https://arxiv.org/pdf/2410.13853", "abs": "https://arxiv.org/abs/2410.13853", "authors": ["Yifeng Wang", "Xueying Zhan", "Siyu Huang"], "title": "AutoAL: Automated Active Learning with Differentiable Query Strategy Search", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "As deep learning continues to evolve, the need for data efficiency becomes\nincreasingly important. Considering labeling large datasets is both\ntime-consuming and expensive, active learning (AL) provides a promising\nsolution to this challenge by iteratively selecting the most informative\nsubsets of examples to train deep neural networks, thereby reducing the\nlabeling cost. However, the effectiveness of different AL algorithms can vary\nsignificantly across data scenarios, and determining which AL algorithm best\nfits a given task remains a challenging problem. This work presents the first\ndifferentiable AL strategy search method, named AutoAL, which is designed on\ntop of existing AL sampling strategies. AutoAL consists of two neural nets,\nnamed SearchNet and FitNet, which are optimized concurrently under a\ndifferentiable bi-level optimization framework. For any given task, SearchNet\nand FitNet are iteratively co-optimized using the labeled data, learning how\nwell a set of candidate AL algorithms perform on that task. With the optimal AL\nstrategies identified, SearchNet selects a small subset from the unlabeled pool\nfor querying their annotations, enabling efficient training of the task model.\nExperimental results demonstrate that AutoAL consistently achieves superior\naccuracy compared to all candidate AL algorithms and other selective AL\napproaches, showcasing its potential for adapting and integrating multiple\nexisting AL methods across diverse tasks and domains. Code is available at:\nhttps://github.com/haizailache999/AutoAL."}
{"id": "2504.14945", "pdf": "https://arxiv.org/pdf/2504.14945", "abs": "https://arxiv.org/abs/2504.14945", "authors": ["Jianhao Yan", "Yafu Li", "Zican Hu", "Zhi Wang", "Ganqu Cui", "Xiaoye Qu", "Yu Cheng", "Yue Zhang"], "title": "Learning to Reason under Off-Policy Guidance", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning with verifiable rewards~(\\textit{RLVR}).\nHowever, existing \\textit{RLVR} approaches are inherently ``on-policy'',\nlimiting learning to a model's own outputs and failing to acquire reasoning\nabilities beyond its initial capabilities. To address this issue, we introduce\n\\textbf{LUFFY} (\\textbf{L}earning to reason \\textbf{U}nder\no\\textbf{FF}-polic\\textbf{Y} guidance), a framework that augments \\textit{RLVR}\nwith off-policy reasoning traces. LUFFY dynamically balances imitation and\nexploration by combining off-policy demonstrations with on-policy rollouts\nduring training. Specifically, LUFFY combines the Mixed-Policy GRPO framework,\nwhich has a theoretically guaranteed convergence rate, alongside policy shaping\nvia regularized importance sampling to avoid superficial and rigid imitation\nduring mixed-policy training. Compared with previous RLVR methods, LUFFY\nachieves an over \\textbf{+6.4} average gain across six math benchmarks and an\nadvantage of over \\textbf{+6.2} points in out-of-distribution tasks. Most\nsignificantly, we show that LUFFY successfully trains weak models in scenarios\nwhere on-policy RLVR completely fails. These results provide compelling\nevidence that LUFFY transcends the fundamental limitations of on-policy RLVR\nand demonstrates the great potential of utilizing off-policy guidance in RLVR."}
{"id": "2504.15241", "pdf": "https://arxiv.org/pdf/2504.15241", "abs": "https://arxiv.org/abs/2504.15241", "authors": ["Yahan Yang", "Soham Dan", "Shuo Li", "Dan Roth", "Insup Lee"], "title": "MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety", "categories": ["cs.CL"], "comment": "Preprint", "summary": "Large Language Models (LLMs) are susceptible to adversarial attacks such as\njailbreaking, which can elicit harmful or unsafe behaviors. This vulnerability\nis exacerbated in multilingual settings, where multilingual safety-aligned data\nis often limited. Thus, developing a guardrail capable of detecting and\nfiltering unsafe content across diverse languages is critical for deploying\nLLMs in real-world applications. In this work, we introduce a multilingual\nguardrail with reasoning for prompt classification. Our method consists of: (1)\nsynthetic multilingual data generation incorporating culturally and\nlinguistically nuanced variants, (2) supervised fine-tuning, and (3) a\ncurriculum-based Group Relative Policy Optimization (GRPO) framework that\nfurther improves performance. Experimental results demonstrate that our\nmultilingual guardrail, MrGuard, consistently outperforms recent baselines\nacross both in-domain and out-of-domain languages by more than 15%. We also\nevaluate MrGuard's robustness to multilingual variations, such as\ncode-switching and low-resource language distractors in the prompt, and\ndemonstrate that it preserves safety judgments under these challenging\nconditions. The multilingual reasoning capability of our guardrail enables it\nto generate explanations, which are particularly useful for understanding\nlanguage-specific risks and ambiguities in multilingual content moderation."}
{"id": "2410.16150", "pdf": "https://arxiv.org/pdf/2410.16150", "abs": "https://arxiv.org/abs/2410.16150", "authors": ["Robin Th√©riault", "Francesco Tosello", "Daniele Tantari"], "title": "Modeling Structured Data Learning with Restricted Boltzmann Machines in the Teacher-Student Setting", "categories": ["cs.LG", "cond-mat.dis-nn"], "comment": "24 pages, 21 figures", "summary": "Restricted Boltzmann machines (RBM) are generative models capable to learn\ndata with a rich underlying structure. We study the teacher-student setting\nwhere a student RBM learns structured data generated by a teacher RBM. The\namount of structure in the data is controlled by adjusting the number of hidden\nunits of the teacher and the correlations in the rows of the weights, a.k.a.\npatterns. In the absence of correlations, we validate the conjecture that the\nperformance is independent of the number of teacher patters and hidden units of\nthe student RBMs, and we argue that the teacher-student setting can be used as\na toy model for studying the lottery ticket hypothesis. Beyond this regime, we\nfind that the critical amount of data required to learn the teacher patterns\ndecreases with both their number and correlations. In both regimes, we find\nthat, even with a relatively large dataset, it becomes impossible to learn the\nteacher patterns if the inference temperature used for regularization is kept\ntoo low. In our framework, the student can learn teacher patterns one-to-one or\nmany-to-one, generalizing previous findings about the teacher-student setting\nwith two hidden units to any arbitrary finite number of hidden units."}
{"id": "2504.15417", "pdf": "https://arxiv.org/pdf/2504.15417", "abs": "https://arxiv.org/abs/2504.15417", "authors": ["Van-Giang Trinh", "Belaid Benhamou", "Sylvain Soliman", "Fran√ßois Fages"], "title": "On the Boolean Network Theory of Datalog$^\\neg$", "categories": ["cs.LO", "cs.AI"], "comment": "47 pages, 7 figures", "summary": "Datalog$^\\neg$ is a central formalism used in a variety of domains ranging\nfrom deductive databases and abstract argumentation frameworks to answer set\nprogramming. Its model theory is the finite counterpart of the logical\nsemantics developed for normal logic programs, mainly based on the notions of\nClark's completion and two-valued or three-valued canonical models including\nsupported, stable, regular and well-founded models. In this paper we establish\na formal link between Datalog$^\\neg$ and Boolean network theory first\nintroduced for gene regulatory networks. We show that in the absence of odd\ncycles in a Datalog$^\\neg$ program, the regular models coincide with the stable\nmodels, which entails the existence of stable models, and in the absence of\neven cycles, we prove the uniqueness of stable partial models and regular\nmodels. This connection also gives new upper bounds on the numbers of stable\npartial, regular, and stable models of a Datalog$^\\neg$ program using the\ncardinality of a feedback vertex set in its atom dependency graph.\nInterestingly, our connection to Boolean network theory also points us to the\nnotion of trap spaces. In particular we show the equivalence between\nsubset-minimal stable trap spaces and regular models."}
{"id": "2504.20371", "pdf": "https://arxiv.org/pdf/2504.20371", "abs": "https://arxiv.org/abs/2504.20371", "authors": ["Zhibo Man", "Yuanmeng Chen", "Yujie Zhang", "Jinan Xu"], "title": "DMDTEval: An Evaluation and Analysis of LLMs on Disambiguation in Multi-domain Translation", "categories": ["cs.CL"], "comment": null, "summary": "Currently, Large Language Models (LLMs) have achieved remarkable results in\nmachine translation. However, their performance in multi-domain translation\n(MDT) is less satisfactory, the meanings of words can vary across different\ndomains, highlighting the significant ambiguity inherent in MDT. Therefore,\nevaluating the disambiguation ability of LLMs in MDT, remains an open problem.\nTo this end, we present an evaluation and analysis of LLMs on disambiguation in\nmulti-domain translation (DMDTEval), our systematic evaluation framework\nconsisting of three critical aspects: (1) we construct a translation test set\nwith multi-domain ambiguous word annotation, (2) we curate a diverse set of\ndisambiguation prompt strategies, and (3) we design precise disambiguation\nmetrics, and study the efficacy of various prompt strategies on multiple\nstate-of-the-art LLMs. We conduct comprehensive experiments across 4 language\npairs and 13 domains, our extensive experiments reveal a number of crucial\nfindings that we believe will pave the way and also facilitate further research\nin the critical area of improving the disambiguation of LLMs."}
{"id": "2410.19236", "pdf": "https://arxiv.org/pdf/2410.19236", "abs": "https://arxiv.org/abs/2410.19236", "authors": ["Darin Tsui", "Aryan Musharaf", "Yigit Efe Erginbas", "Justin Singh Kang", "Amirali Aghazadeh"], "title": "SHAP zero Explains Biological Sequence Models with Near-zero Marginal Cost for Future Queries", "categories": ["cs.LG", "cs.CE", "q-bio.GN", "stat.CO"], "comment": null, "summary": "The growing adoption of machine learning models for biological sequences has\nintensified the need for interpretable predictions, with Shapley values\nemerging as a theoretically grounded standard for model explanation. While\neffective for local explanations of individual input sequences, scaling\nShapley-based interpretability to extract global biological insights requires\nevaluating thousands of sequences--incurring exponential computational cost per\nquery. We introduce SHAP zero, a novel algorithm that amortizes the cost of\nShapley value computation across large-scale biological datasets. After a\none-time model sketching step, SHAP zero enables near-zero marginal cost for\nfuture queries by uncovering an underexplored connection between Shapley\nvalues, high-order feature interactions, and the sparse Fourier transform of\nthe model. Applied to models of guide RNA efficacy, DNA repair outcomes, and\nprotein fitness, SHAP zero explains predictions orders of magnitude faster than\nexisting methods, recovering rich combinatorial interactions previously\ninaccessible at scale. This work opens the door to principled, efficient, and\nscalable interpretability for black-box sequence models in biology."}
{"id": "2504.18062", "pdf": "https://arxiv.org/pdf/2504.18062", "abs": "https://arxiv.org/abs/2504.18062", "authors": ["Lingyan Bao", "Sinwoong Yun", "Jemin Lee", "Tony Q. S. Quek"], "title": "LLM-hRIC: LLM-empowered Hierarchical RAN Intelligent Control for O-RAN", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "Despite recent advances in applying large language models (LLMs) and machine\nlearning (ML) techniques to open radio access network (O-RAN), critical\nchallenges remain, such as insufficient cooperation between radio access\nnetwork (RAN) intelligent controllers (RICs), high computational demands\nhindering real-time decisions, and the lack of domain-specific finetuning.\nTherefore, this article introduces the LLM-empowered hierarchical RIC\n(LLM-hRIC) framework to improve the collaboration between RICs in O-RAN. The\nLLM-empowered non-real-time RIC (non-RT RIC) acts as a guider, offering a\nstrategic guidance to the near-real-time RIC (near-RT RIC) using global network\ninformation. The RL-empowered near-RT RIC acts as an implementer, combining\nthis guidance with local real-time data to make near-RT decisions. We evaluate\nthe feasibility and performance of the LLM-hRIC framework in an integrated\naccess and backhaul (IAB) network setting, and finally, discuss the open\nchallenges of the LLM-hRIC framework for O-RAN."}
{"id": "2505.00038", "pdf": "https://arxiv.org/pdf/2505.00038", "abs": "https://arxiv.org/abs/2505.00038", "authors": ["Cristina Garbacea", "Chenhao Tan"], "title": "HyPerAlign: Interpretable Personalized LLM Alignment via Hypothesis Generation", "categories": ["cs.CL"], "comment": null, "summary": "Alignment algorithms are widely used to align large language models (LLMs) to\nhuman users based on preference annotations. Typically these (often divergent)\npreferences are aggregated over a diverse set of users, resulting in fine-tuned\nmodels that are aligned to the ``average-user'' preference. Nevertheless,\ncurrent models are used by individual users in very specific contexts and\nsituations, emphasizing the need for user-dependent preference control. In this\nwork we address the problem of personalizing LLM outputs to their users. We aim\nto generate customized responses tailored to specific individuals instead of\ngeneric outputs that emulate the collective voices of diverse populations. We\npropose HyPerAlign, an interpretable and sample-efficient hypothesis-driven\npersonalization approach for LLM models. Given few-shot examples written by a\nparticular user, we first infer hypotheses about their communication\nstrategies, personality, and writing style, then prompt LLM models with these\nhypotheses and user-specific attributes to generate customized outputs. We\nconduct experiments on two different personalization tasks, namely authorship\nattribution and deliberative alignment, with datasets from diverse domains\n(news articles, blog posts, emails, jailbreaking benchmarks). Results\ndemonstrate the superiority of hypothesis-driven LLM personalization compared\nto preference-based fine-tuning methods. For authorship attribution, HyPerAlign\ngenerations have consistently high win-rates (commonly $> 90\\%$) against\nstate-of-the-art preference fine-tuning approaches across diverse user profiles\nand LLM models. For deliberative alignment, the helpfulness of LLM models is\nimproved by up to $70\\%$ on average. Overall, HyPerAlign represents an\ninterpretable and sample-efficient strategy for the personalization of LLM\nmodels to individual users."}
{"id": "2411.02279", "pdf": "https://arxiv.org/pdf/2411.02279", "abs": "https://arxiv.org/abs/2411.02279", "authors": ["Jincheng Huang", "Yujie Mo", "Xiaoshuang Shi", "Lei Feng", "Xiaofeng Zhu"], "title": "Enhancing the Influence of Labels on Unlabeled Nodes in Graph Convolutional Networks", "categories": ["cs.LG"], "comment": "Accepted by ICML2025", "summary": "The message-passing mechanism of graph convolutional networks (i.e., GCNs)\nenables label information to be propagated to a broader range of neighbors,\nthereby increasing the utilization of labels. However, the label information is\nnot always effectively utilized in the traditional GCN framework. To address\nthis issue, we propose a new two-step framework called ELU-GCN. In the first\nstage, ELU-GCN conducts graph learning to learn a new graph structure (i.e.,\nELU-graph), which enables the message passing can effectively utilize label\ninformation. In the second stage, we design a new graph contrastive learning on\nthe GCN framework for representation learning by exploring the consistency and\nmutually exclusive information between the learned ELU graph and the original\ngraph. Moreover, we theoretically demonstrate that the proposed method can\nensure the generalization ability of GCNs. Extensive experiments validate the\nsuperiority of our method."}
{"id": "2505.02156", "pdf": "https://arxiv.org/pdf/2505.02156", "abs": "https://arxiv.org/abs/2505.02156", "authors": ["Minzheng Wang", "Yongbin Li", "Haobo Wang", "Xinghua Zhang", "Nan Xu", "Bingli Wu", "Fei Huang", "Haiyang Yu", "Wenji Mao"], "title": "Adaptive Thinking via Mode Policy Optimization for Social Language Agents", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Work in Progress. The code and data are available, see\n  https://github.com/MozerWang/AMPO", "summary": "Effective social intelligence simulation requires language agents to\ndynamically adjust reasoning depth, a capability notably absent in current\nstudies. Existing methods either lack this kind of reasoning capability or\nenforce Long Chain-of-Thought reasoning uniformly across all scenarios,\nresulting in excessive token usage and inflexible social simulation. To address\nthis, we propose an $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{L}$earning\n($\\textbf{AML}$) framework in this paper, aiming to improve the adaptive\nthinking ability of language agents in dynamic social interactions. To this\nend, we first identify hierarchical thinking modes ranging from intuitive\nresponse to deep deliberation based on the cognitive control theory. We then\ndevelop the $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{P}$olicy\n$\\textbf{O}$ptimization ($\\textbf{AMPO}$) algorithm to optimize the\ncontext-aware mode switching and reasoning. Our framework advances existing\nresearch in three key aspects: (1) Multi-granular thinking mode design, (2)\nContext-aware mode switching across social interaction, and (3) Token-efficient\nreasoning via depth-adaptive processing. Extensive experiments on social\nintelligence benchmarks verify that AML achieves 15.6% higher task performance\nthan GPT-4o. Notably, our AMPO outperforms GRPO by 7.0% with 32.8% shorter\nreasoning chains, demonstrating the advantage of adaptive thinking mode\nselection and optimization mechanism in AMPO over GRPO's fixed-depth solution."}
{"id": "2505.00753", "pdf": "https://arxiv.org/pdf/2505.00753", "abs": "https://arxiv.org/abs/2505.00753", "authors": ["Henry Peng Zou", "Wei-Chieh Huang", "Yaozu Wu", "Yankai Chen", "Chunyu Miao", "Hoang Nguyen", "Yue Zhou", "Weizhi Zhang", "Liancheng Fang", "Langzhou He", "Yangning Li", "Dongyuan Li", "Renhe Jiang", "Xue Liu", "Philip S. Yu"], "title": "A Survey on Large Language Model based Human-Agent Systems", "categories": ["cs.CL", "cs.LG"], "comment": "Paper lists and resources are available at\n  https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-Systems", "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin building fully autonomous agents. However, fully autonomous LLM-based agents\nstill face significant challenges, including limited reliability due to\nhallucinations, difficulty in handling complex tasks, and substantial safety\nand ethical risks, all of which limit their feasibility and trustworthiness in\nreal-world applications. To overcome these limitations, LLM-based human-agent\nsystems (LLM-HAS) incorporate human-provided information, feedback, or control\ninto the agent system to enhance system performance, reliability and safety.\nThis paper provides the first comprehensive and structured survey of LLM-HAS.\nIt clarifies fundamental concepts, systematically presents core components\nshaping these systems, including environment & profiling, human feedback,\ninteraction types, orchestration and communication, explores emerging\napplications, and discusses unique challenges and opportunities. By\nconsolidating current knowledge and offering a structured overview, we aim to\nfoster further research and innovation in this rapidly evolving\ninterdisciplinary field. Paper lists and resources are available at\nhttps://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-Systems."}
{"id": "2411.11259", "pdf": "https://arxiv.org/pdf/2411.11259", "abs": "https://arxiv.org/abs/2411.11259", "authors": ["Qian Chang", "Xia Li", "Xiufeng Cheng"], "title": "Graph Retention Networks for Dynamic Graphs", "categories": ["cs.LG"], "comment": "The results are unreliable due to errors in the experimental setup;\n  corrected results will be updated soon", "summary": "In this work, we propose Graph Retention Network as a unified architecture\nfor deep learning on dynamic graphs. The GRN extends the core computational\nmanner of retention to dynamic graph data as graph retention, which empowers\nthe model with three key computational paradigms that enable training\nparallelism, $O(1)$ low-cost inference, and long-term batch training. This\narchitecture achieves an optimal balance of effectiveness, efficiency, and\nscalability. Extensive experiments conducted on benchmark datasets present the\nsuperior performance of the GRN in both edge-level prediction and node-level\nclassification tasks. Our architecture achieves cutting-edge results while\nmaintaining lower training latency, reduced GPU memory consumption, and up to\nan 86.7x improvement in inference throughput compared to baseline models. The\nGRNs have demonstrated strong potential to become a widely adopted architecture\nfor dynamic graph learning tasks. Code will be available at\nhttps://github.com/Chandler-Q/GraphRetentionNet."}
{"id": "2505.02863", "pdf": "https://arxiv.org/pdf/2505.02863", "abs": "https://arxiv.org/abs/2505.02863", "authors": ["Newnew Deng", "Edward Jiusi Liu", "Xiaoming Zhai"], "title": "Understanding University Students' Use of Generative AI: The Roles of Demographics and Personality Traits", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The use of generative AI (GAI) among university students is rapidly\nincreasing, yet empirical research on students' GAI use and the factors\ninfluencing it remains limited. To address this gap, we surveyed 363\nundergraduate and graduate students in the United States, examining their GAI\nusage and how it relates to demographic variables and personality traits based\non the Big Five model (i.e., extraversion, agreeableness, conscientiousness,\nand emotional stability, and intellect/imagination). Our findings reveal: (a)\nStudents in higher academic years are more inclined to use GAI and prefer it\nover traditional resources. (b) Non-native English speakers use and adopt GAI\nmore readily than native speakers. (c) Compared to White, Asian students report\nhigher GAI usage, perceive greater academic benefits, and express a stronger\npreference for it. Similarly, Black students report a more positive impact of\nGAI on their academic performance. Personality traits also play a significant\nrole in shaping perceptions and usage of GAI. After controlling demographic\nfactors, we found that personality still significantly predicts GAI use and\nattitudes: (a) Students with higher conscientiousness use GAI less. (b)\nStudents who are higher in agreeableness perceive a less positive impact of GAI\non academic performance and express more ethical concerns about using it for\nacademic work. (c) Students with higher emotional stability report a more\npositive impact of GAI on learning and fewer concerns about its academic use.\n(d) Students with higher extraversion show a stronger preference for GAI over\ntraditional resources. (e) Students with higher intellect/imagination tend to\nprefer traditional resources. These insights highlight the need for\nuniversities to provide personalized guidance to ensure students use GAI\neffectively, ethically, and equitably in their academic pursuits."}
{"id": "2505.09930", "pdf": "https://arxiv.org/pdf/2505.09930", "abs": "https://arxiv.org/abs/2505.09930", "authors": ["Zixiao Zhu", "Hanzhang Zhou", "Zijian Feng", "Tianjiao Li", "Chua Jia Jim Deryl", "Mak Lee Onn", "Gee Wah Ng", "Kezhi Mao"], "title": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization", "categories": ["cs.CL"], "comment": "21 pages, 14 figures", "summary": "Prompt optimization (PO) provides a practical way to improve response quality\nwhen users lack the time or expertise to manually craft effective prompts.\nExisting methods typically rely on advanced, large-scale LLMs like GPT-4 to\ngenerate optimized prompts. However, due to limited downward compatibility,\nverbose, instruction-heavy prompts from advanced LLMs can overwhelm lightweight\ninference models and degrade response quality. In this work, we rethink prompt\noptimization through the lens of interpretable design. We first identify a set\nof model-agnostic prompt quality merits and empirically validate their\neffectiveness in enhancing prompt and response quality. We then introduce MePO,\na merit-guided, lightweight, and locally deployable prompt optimizer trained on\nour preference dataset built from merit-aligned prompts generated by a\nlightweight LLM. Unlike prior work, MePO avoids online optimization reliance,\nreduces cost and privacy concerns, and, by learning clear, interpretable\nmerits, generalizes effectively to both large-scale and lightweight inference\nmodels. Experiments demonstrate that MePO achieves better results across\ndiverse tasks and model types, offering a scalable and robust solution for\nreal-world deployment. The code and dataset can be found in\nhttps://github.com/MidiyaZhu/MePO"}
{"id": "2411.12127", "pdf": "https://arxiv.org/pdf/2411.12127", "abs": "https://arxiv.org/abs/2411.12127", "authors": ["Jesse Friedbaum", "Sudarshan Adiga", "Ravi Tandon"], "title": "Fine-Grained Uncertainty Quantification via Collisions", "categories": ["cs.LG", "cs.IT", "math.IT", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "We propose a new and intuitive metric for aleatoric uncertainty\nquantification (UQ), the prevalence of class collisions defined as the same\ninput being observed in different classes. We use the rate of class collisions\nto define the collision matrix, a novel and uniquely fine-grained measure of\nuncertainty. For a classification problem involving $K$ classes, the $K\\times\nK$ collision matrix $S$ measures the inherent difficulty in distinguishing\nbetween each pair of classes. We discuss several applications of the collision\nmatrix, establish its fundamental mathematical properties, as well as show its\nrelationship with existing UQ methods, including the Bayes error rate (BER). We\nalso address the new problem of estimating the collision matrix using one-hot\nlabeled data by proposing a series of innovative techniques to estimate $S$.\nFirst, we learn a pair-wise contrastive model which accepts two inputs and\ndetermines if they belong to the same class. We then show that this contrastive\nmodel (which is PAC learnable) can be used to estimate the Gramian matrix of\n$S$, defined as $G=S^TS$. Finally, we show that under reasonable assumptions,\n$G$ can be used to uniquely recover $S$, a new result on non-negative matrices\nwhich could be of independent interest. With a method to estimate $S$\nestablished, we demonstrate how this estimate of $S$, in conjunction with the\ncontrastive model, can be used to estimate the posterior class portability\ndistribution of any point. Experimental results are also presented to validate\nour methods of estimating the collision matrix and class posterior\ndistributions on several datasets."}
{"id": "2505.03802", "pdf": "https://arxiv.org/pdf/2505.03802", "abs": "https://arxiv.org/abs/2505.03802", "authors": ["Changhai Zhou", "Yuhua Zhou", "Qian Qiao", "Weizhong Zhang", "Cheng Jin"], "title": "Efficient Fine-Tuning of Quantized Models via Adaptive Rank and Bitwidth", "categories": ["cs.LG", "cs.AI"], "comment": "This preprint is being withdrawn because not all original authors are\n  continuing with the paper. Responsibility for the manuscript has been taken\n  over by a subset of the original authors, who will revise and resubmit it\n  independently. To avoid confusion regarding authorship and future versions of\n  the work, we request that this version be removed from arXiv", "summary": "QLoRA effectively combines low-bit quantization and LoRA to achieve\nmemory-friendly fine-tuning for large language models (LLM). Recently, methods\nbased on SVD for continuous update iterations to initialize LoRA matrices to\naccommodate quantization errors have generally failed to consistently improve\nperformance. Dynamic mixed precision is a natural idea for continuously\nimproving the fine-tuning performance of quantized models, but previous methods\noften optimize low-rank subspaces or quantization components separately,\nwithout considering their synergy. To address this, we propose\n\\textbf{QR-Adaptor}, a unified, gradient-free strategy that uses partial\ncalibration data to jointly search the quantization components and the rank of\nlow-rank spaces for each layer, thereby continuously improving model\nperformance. QR-Adaptor does not minimize quantization error but treats\nprecision and rank allocation as a discrete optimization problem guided by\nactual downstream performance and memory usage. Compared to state-of-the-art\n(SOTA) quantized LoRA fine-tuning methods, our approach achieves a 4.89\\%\naccuracy improvement on GSM8K, and in some cases even outperforms the 16-bit\nfine-tuned model while maintaining the memory footprint of the 4-bit setting."}
{"id": "2505.10081", "pdf": "https://arxiv.org/pdf/2505.10081", "abs": "https://arxiv.org/abs/2505.10081", "authors": ["Wisdom Aduah", "Francois Meyer"], "title": "Designing and Contextualising Probes for African Languages", "categories": ["cs.CL"], "comment": null, "summary": "Pretrained language models (PLMs) for African languages are continually\nimproving, but the reasons behind these advances remain unclear. This paper\npresents the first systematic investigation into probing PLMs for linguistic\nknowledge about African languages. We train layer-wise probes for six\ntypologically diverse African languages to analyse how linguistic features are\ndistributed. We also design control tasks, a way to interpret probe\nperformance, for the MasakhaPOS dataset. We find PLMs adapted for African\nlanguages to encode more linguistic information about target languages than\nmassively multilingual PLMs. Our results reaffirm previous findings that\ntoken-level syntactic information concentrates in middle-to-last layers, while\nsentence-level semantic information is distributed across all layers. Through\ncontrol tasks and probing baselines, we confirm that performance reflects the\ninternal knowledge of PLMs rather than probe memorisation. Our study applies\nestablished interpretability techniques to African-language PLMs. In doing so,\nwe highlight the internal mechanisms underlying the success of strategies like\nactive learning and multilingual adaptation."}
{"id": "2411.14585", "pdf": "https://arxiv.org/pdf/2411.14585", "abs": "https://arxiv.org/abs/2411.14585", "authors": ["Sanaz Mahmoodi Takaghaj"], "title": "Efficient Spatio-Temporal Signal Recognition on Edge Devices Using PointLCA-Net", "categories": ["cs.LG", "cs.ET"], "comment": "Accepted to International Joint Conference on Neural Networks(IJCNN),\n  2015", "summary": "Recent advancements in machine learning, particularly through deep learning\narchitectures like PointNet, have transformed the processing of\nthree-dimensional (3D) point clouds, significantly improving 3D object\nclassification and segmentation tasks. While 3D point clouds provide detailed\nspatial information, spatio-temporal signals introduce a dynamic element that\naccounts for changes over time. However, applying deep learning techniques to\nspatio-temporal signals and deploying them on edge devices presents challenges,\nincluding real-time processing, memory capacity, and power consumption. To\naddress these issues, this paper presents a novel approach that combines\nPointNet's feature extraction with the in-memory computing capabilities and\nenergy efficiency of neuromorphic systems for spatio-temporal signal\nrecognition. The proposed method consists of a two-stage process: in the first\nstage, PointNet extracts features from the spatio-temporal signals, which are\nthen stored in non-volatile memristor crossbar arrays. In the second stage,\nthese features are processed by a single-layer spiking neural encoder-decoder\nthat employs the Locally Competitive Algorithm (LCA) for efficient encoding and\nclassification. This work integrates the strengths of both PointNet and LCA,\nenhancing computational efficiency and energy performance on edge devices.\nPointLCA-Net achieves high recognition accuracy for spatio-temporal data with\nsubstantially lower energy burden during both inference and training than\ncomparable approaches, thus advancing the deployment of advanced neural\narchitectures in energy-constrained environments."}
{"id": "2505.04174", "pdf": "https://arxiv.org/pdf/2505.04174", "abs": "https://arxiv.org/abs/2505.04174", "authors": ["Ju-Hyung Lee", "Yanqing Lu", "Klaus Doppler"], "title": "On-Device LLM for Context-Aware Wi-Fi Roaming", "categories": ["cs.LG", "cs.AI", "cs.NI", "eess.SP"], "comment": null, "summary": "Roaming in Wireless LAN (Wi-Fi) is a critical yet challenging task for\nmaintaining seamless connectivity in dynamic mobile environments. Conventional\nthreshold-based or heuristic schemes often fail, leading to either sticky or\nexcessive handovers. We introduce the first cross-layer use of an on-device\nlarge language model (LLM): high-level reasoning in the application layer that\nissues real-time actions executed in the PHY/MAC stack. The LLM addresses two\ntasks: (i) context-aware AP selection, where structured prompts fuse\nenvironmental cues (e.g., location, time) to choose the best BSSID; and (ii)\ndynamic threshold adjustment, where the model adaptively decides when to roam.\nTo satisfy the tight latency and resource budgets of edge hardware, we apply a\nsuite of optimizations-chain-of-thought prompting, parameter-efficient\nfine-tuning, and quantization. Experiments on indoor and outdoor datasets show\nthat our approach surpasses legacy heuristics and DRL baselines, achieving a\nstrong balance between roaming stability and signal quality. These findings\nunderscore the promise of application-layer LLM reasoning for lower-layer\nwireless control in future edge systems."}
{"id": "2505.10643", "pdf": "https://arxiv.org/pdf/2505.10643", "abs": "https://arxiv.org/abs/2505.10643", "authors": ["Shuchen Guo", "Yun Wang", "Jichao Yu", "Xuansheng Wu", "Bilgehan Ayik", "Field M. Watts", "Ehsan Latif", "Ninghao Liu", "Lei Liu", "Xiaoming Zhai"], "title": "Artificial Intelligence Bias on English Language Learners in Automatic Scoring", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "This study investigated potential scoring biases and disparities toward\nEnglish Language Learners (ELLs) when using automatic scoring systems for\nmiddle school students' written responses to science assessments. We\nspecifically focus on examining how unbalanced training data with ELLs\ncontributes to scoring bias and disparities. We fine-tuned BERT with four\ndatasets: responses from (1) ELLs, (2) non-ELLs, (3) a mixed dataset reflecting\nthe real-world proportion of ELLs and non-ELLs (unbalanced), and (4) a balanced\nmixed dataset with equal representation of both groups. The study analyzed 21\nassessment items: 10 items with about 30,000 ELL responses, five items with\nabout 1,000 ELL responses, and six items with about 200 ELL responses. Scoring\naccuracy (Acc) was calculated and compared to identify bias using Friedman\ntests. We measured the Mean Score Gaps (MSGs) between ELLs and non-ELLs and\nthen calculated the differences in MSGs generated through both the human and AI\nmodels to identify the scoring disparities. We found that no AI bias and\ndistorted disparities between ELLs and non-ELLs were found when the training\ndataset was large enough (ELL = 30,000 and ELL = 1,000), but concerns could\nexist if the sample size is limited (ELL = 200)."}
{"id": "2412.03717", "pdf": "https://arxiv.org/pdf/2412.03717", "abs": "https://arxiv.org/abs/2412.03717", "authors": ["Juan Miguel Lopez Alcaraz", "Wilhelm Haverkamp", "Nils Strodthoff"], "title": "Electrocardiogram-based diagnosis of liver diseases: an externally validated and explainable machine learning approach", "categories": ["cs.LG", "eess.SP"], "comment": "Accepted version by EClinicalMedicine, The Lancet: 13 pages, 2\n  figures, code under https://github.com/AI4HealthUOL/CardioDiag", "summary": "Background: Liver diseases present a significant global health challenge and\noften require costly, invasive diagnostics. Electrocardiography (ECG), a widely\navailable and non-invasive tool, can enable the detection of liver disease by\ncapturing cardiovascular-hepatic interactions.\n  Methods: We trained tree-based machine learning models on ECG features to\ndetect liver diseases using two large datasets: MIMIC-IV-ECG (467,729 patients,\n2008-2019) and ECG-View II (775,535 patients, 1994-2013). The task was framed\nas binary classification, with performance evaluated via the area under the\nreceiver operating characteristic curve (AUROC). To improve interpretability,\nwe applied explainability methods to identify key predictive features.\n  Findings: The models showed strong predictive performance with good\ngeneralizability. For example, AUROCs for alcoholic liver disease (K70) were\n0.8025 (95% confidence interval (CI), 0.8020-0.8035) internally and 0.7644 (95%\nCI, 0.7641-0.7649) externally; for hepatic failure (K72), scores were 0.7404\n(95% CI, 0.7389-0.7415) and 0.7498 (95% CI, 0.7494-0.7509), respectively. The\nexplainability analysis consistently identified age and prolonged QTc intervals\n(corrected QT, reflecting ventricular repolarization) as key predictors.\nFeatures linked to autonomic regulation and electrical conduction abnormalities\nwere also prominent, supporting known cardiovascular-liver connections and\nsuggesting QTc as a potential biomarker.\n  Interpretation: ECG-based machine learning offers a promising, interpretable\napproach for liver disease detection, particularly in resource-limited\nsettings. By revealing clinically relevant biomarkers, this method supports\nnon-invasive diagnostics, early detection, and risk stratification prior to\ntargeted clinical assessments."}
{"id": "2505.06330", "pdf": "https://arxiv.org/pdf/2505.06330", "abs": "https://arxiv.org/abs/2505.06330", "authors": ["Junyu Xue", "Xudong Wang", "Xiaoling He", "Shicheng Liu", "Yi Wang", "Guoming Tang"], "title": "Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Non-intrusive load monitoring (NILM) aims to disaggregate aggregate household\nelectricity consumption into individual appliance usage and thus enables more\neffective energy management. While deep learning has advanced NILM, it remains\nlimited by its dependence on labeled data, restricted generalization, and lack\nof explainability. This paper introduces the first prompt-based NILM framework\nthat leverages large language models (LLMs) with in-context learning. We design\nand evaluate prompt strategies that integrate appliance features, timestamps\nand contextual information, as well as representative time-series examples on\nwidely used open datasets. With optimized prompts, LLMs achieve competitive\nstate detection accuracy and demonstrate robust generalization without the need\nfor fine-tuning. LLMs also enhance explainability by providing clear,\nhuman-readable explanations for their predictions. Our results show that LLMs\ncan reduce data requirements, improve adaptability, and provide transparent\nenergy disaggregation in NILM applications."}
{"id": "2505.11341", "pdf": "https://arxiv.org/pdf/2505.11341", "abs": "https://arxiv.org/abs/2505.11341", "authors": ["Banca Calvo Figueras", "Rodrigo Agerri"], "title": "Benchmarking Critical Questions Generation: A Challenging Reasoning Task for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The task of Critical Questions Generation (CQs-Gen) aims to foster critical\nthinking by enabling systems to generate questions that expose underlying\nassumptions and challenge the validity of argumentative reasoning structures.\nDespite growing interest in this area, progress has been hindered by the lack\nof suitable datasets and automatic evaluation standards. This paper presents a\ncomprehensive approach to support the development and benchmarking of systems\nfor this task. We construct the first large-scale dataset including $~$5K\nmanually annotated questions. We also investigate automatic evaluation methods\nand propose a reference-based technique using large language models (LLMs) as\nthe strategy that best correlates with human judgments. Our zero-shot\nevaluation of 11 LLMs establishes a strong baseline while showcasing the\ndifficulty of the task. Data and code plus a public leaderboard are provided to\nencourage further research not only in terms of model performance, but also to\nexplore the practical benefits of CQs-Gen for both automated reasoning and\nhuman critical thinking."}
{"id": "2412.09232", "pdf": "https://arxiv.org/pdf/2412.09232", "abs": "https://arxiv.org/abs/2412.09232", "authors": ["Simon De Vos", "Christopher Bockel-Rickermann", "Stefan Lessmann", "Wouter Verbeke"], "title": "Uplift modeling with continuous treatments: A predict-then-optimize approach", "categories": ["cs.LG"], "comment": null, "summary": "The goal of uplift modeling is to recommend actions that optimize specific\noutcomes by determining which entities should receive treatment. One common\napproach involves two steps: first, an inference step that estimates\nconditional average treatment effects (CATEs), and second, an optimization step\nthat ranks entities based on their CATE values and assigns treatment to the top\nk within a given budget. While uplift modeling typically focuses on binary\ntreatments, many real-world applications are characterized by continuous-valued\ntreatments, i.e., a treatment dose. This paper presents a predict-then-optimize\nframework to allow for continuous treatments in uplift modeling. First, in the\ninference step, conditional average dose responses (CADRs) are estimated from\ndata using causal machine learning techniques. Second, in the optimization\nstep, we frame the assignment task of continuous treatments as a\ndose-allocation problem and solve it using integer linear programming (ILP).\nThis approach allows decision-makers to efficiently and effectively allocate\ntreatment doses while balancing resource availability, with the possibility of\nadding extra constraints like fairness considerations or adapting the objective\nfunction to take into account instance-dependent costs and benefits to maximize\nutility. The experiments compare several CADR estimators and illustrate the\ntrade-offs between policy value and fairness, as well as the impact of an\nadapted objective function. This showcases the framework's advantages and\nflexibility across diverse applications in healthcare, lending, and human\nresource management. All code is available on github.com/SimonDeVos/UMCT."}
{"id": "2505.07078", "pdf": "https://arxiv.org/pdf/2505.07078", "abs": "https://arxiv.org/abs/2505.07078", "authors": ["Weixian Waylon Li", "Hyeonjun Kim", "Mihai Cucuringu", "Tiejun Ma"], "title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?", "categories": ["q-fin.TR", "cs.AI", "cs.CE"], "comment": "14 pages", "summary": "Large Language Models (LLMs) have recently been leveraged for asset pricing\ntasks and stock trading applications, enabling AI agents to generate investment\ndecisions from unstructured financial data. However, most evaluations of LLM\ntiming-based investing strategies are conducted on narrow timeframes and\nlimited stock universes, overstating effectiveness due to survivorship and\ndata-snooping biases. We critically assess their generalizability and\nrobustness by proposing FINSABER, a backtesting framework evaluating\ntiming-based strategies across longer periods and a larger universe of symbols.\nSystematic backtests over two decades and 100+ symbols reveal that previously\nreported LLM advantages deteriorate significantly under broader cross-section\nand over a longer-term evaluation. Our market regime analysis further\ndemonstrates that LLM strategies are overly conservative in bull markets,\nunderperforming passive benchmarks, and overly aggressive in bear markets,\nincurring heavy losses. These findings highlight the need to develop LLM\nstrategies that are able to prioritise trend detection and regime-aware risk\ncontrols over mere scaling of framework complexity."}
{"id": "2505.11423", "pdf": "https://arxiv.org/pdf/2505.11423", "abs": "https://arxiv.org/abs/2505.11423", "authors": ["Xiaomin Li", "Zhou Yu", "Zhiwei Zhang", "Xupeng Chen", "Ziji Zhang", "Yingying Zhuang", "Narayanan Sadagopan", "Anurag Beniwal"], "title": "When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning-enhanced large language models (RLLMs), whether explicitly trained\nfor reasoning or prompted via chain-of-thought (CoT), have achieved\nstate-of-the-art performance on many complex reasoning tasks. However, we\nuncover a surprising and previously overlooked phenomenon: explicit CoT\nreasoning can significantly degrade instruction-following accuracy. Evaluating\n15 models on two benchmarks: IFEval (with simple, rule-verifiable constraints)\nand ComplexBench (with complex, compositional constraints), we consistently\nobserve performance drops when CoT prompting is applied. Through large-scale\ncase studies and an attention-based analysis, we identify common patterns where\nreasoning either helps (e.g., with formatting or lexical precision) or hurts\n(e.g., by neglecting simple constraints or introducing unnecessary content). We\npropose a metric, constraint attention, to quantify model focus during\ngeneration and show that CoT reasoning often diverts attention away from\ninstruction-relevant tokens. To mitigate these effects, we introduce and\nevaluate four strategies: in-context learning, self-reflection, self-selective\nreasoning, and classifier-selective reasoning. Our results demonstrate that\nselective reasoning strategies, particularly classifier-selective reasoning,\ncan substantially recover lost performance. To our knowledge, this is the first\nwork to systematically expose reasoning-induced failures in\ninstruction-following and offer practical mitigation strategies."}
{"id": "2412.17040", "pdf": "https://arxiv.org/pdf/2412.17040", "abs": "https://arxiv.org/abs/2412.17040", "authors": ["Eric Hedlin", "Munawar Hayat", "Fatih Porikli", "Kwang Moo Yi", "Shweta Mahajan"], "title": "HyperNet Fields: Efficiently Training Hypernetworks without Ground Truth by Learning Weight Trajectories", "categories": ["cs.LG"], "comment": null, "summary": "To efficiently adapt large models or to train generative models of neural\nrepresentations, Hypernetworks have drawn interest. While hypernetworks work\nwell, training them is cumbersome, and often requires ground truth optimized\nweights for each sample. However, obtaining each of these weights is a training\nproblem of its own-one needs to train, e.g., adaptation weights or even an\nentire neural field for hypernetworks to regress to. In this work, we propose a\nmethod to train hypernetworks, without the need for any per-sample ground\ntruth. Our key idea is to learn a Hypernetwork `Field` and estimate the entire\ntrajectory of network weight training instead of simply its converged state. In\nother words, we introduce an additional input to the Hypernetwork, the\nconvergence state, which then makes it act as a neural field that models the\nentire convergence pathway of a task network. A critical benefit in doing so is\nthat the gradient of the estimated weights at any convergence state must then\nmatch the gradients of the original task -- this constraint alone is sufficient\nto train the Hypernetwork Field. We demonstrate the effectiveness of our method\nthrough the task of personalized image generation and 3D shape reconstruction\nfrom images and point clouds, demonstrating competitive results without any\nper-sample ground truth."}
{"id": "2505.09561", "pdf": "https://arxiv.org/pdf/2505.09561", "abs": "https://arxiv.org/abs/2505.09561", "authors": ["Marcel Torne", "Andy Tang", "Yuejiang Liu", "Chelsea Finn"], "title": "Learning Long-Context Diffusion Policies via Past-Token Prediction", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Videos are available at https://long-context-dp.github.io", "summary": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x."}
{"id": "2505.11604", "pdf": "https://arxiv.org/pdf/2505.11604", "abs": "https://arxiv.org/abs/2505.11604", "authors": ["Kyudan Jung", "Hojun Cho", "Jooyeol Yun", "Soyoung Yang", "Jaehyeok Jang", "Jagul Choo"], "title": "Talk to Your Slides: Language-Driven Agents for Efficient Slide Editing", "categories": ["cs.CL"], "comment": "20 pages, 14 figures", "summary": "Editing presentation slides remains one of the most common and time-consuming\ntasks faced by millions of users daily, despite significant advances in\nautomated slide generation. Existing approaches have successfully demonstrated\nslide editing via graphic user interface (GUI)-based agents, offering intuitive\nvisual control. However, such methods often suffer from high computational cost\nand latency. In this paper, we propose Talk-to-Your-Slides, an LLM-powered\nagent designed to edit slides %in active PowerPoint sessions by leveraging\nstructured information about slide objects rather than relying on image\nmodality. The key insight of our work is designing the editing process with\ndistinct high-level and low-level layers to facilitate interaction between user\ncommands and slide objects. By providing direct access to application objects\nrather than screen pixels, our system enables 34.02% faster processing, 34.76%\nbetter instruction fidelity, and 87.42% cheaper operation than baselines. To\nevaluate slide editing capabilities, we introduce TSBench, a human-annotated\ndataset comprising 379 diverse editing instructions paired with corresponding\nslide variations in four categories. Our code, benchmark and demos are\navailable at https://anonymous.4open.science/r/Talk-to-Your-Slides-0F4C."}
{"id": "2412.18184", "pdf": "https://arxiv.org/pdf/2412.18184", "abs": "https://arxiv.org/abs/2412.18184", "authors": ["Haoyu Zhang", "Rayan Saab"], "title": "Unified Stochastic Framework for Neural Network Quantization and Pruning", "categories": ["cs.LG", "cs.NA", "math.NA", "math.PR"], "comment": "14 pages", "summary": "Quantization and pruning are two essential techniques for compressing neural\nnetworks, yet they are often treated independently, with limited theoretical\nanalysis connecting them. This paper introduces a unified framework for\npost-training quantization and pruning using stochastic path-following\nalgorithms. Our approach builds on the Stochastic Path Following Quantization\n(SPFQ) method, extending its applicability to pruning and low-bit quantization,\nincluding challenging 1-bit regimes. By incorporating a scaling parameter and\ngeneralizing the stochastic operator, the proposed method achieves robust error\ncorrection and yields rigorous theoretical error bounds for both quantization\nand pruning as well as their combination."}
{"id": "2505.10940", "pdf": "https://arxiv.org/pdf/2505.10940", "abs": "https://arxiv.org/abs/2505.10940", "authors": ["Qing Yu", "Xiaobei Wang", "Shuchang Liu", "Yandong Bai", "Xiaoyu Yang", "Xueliang Wang", "Chang Meng", "Shanshan Wu", "Hailan Yang", "Huihui Xiao", "Xiang Li", "Fan Yang", "Xiaoqiang Feng", "Lantao Hu", "Han Li", "Kun Gai", "Lixin Zou"], "title": "Who You Are Matters: Bridging Topics and Social Roles via LLM-Enhanced Logical Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Recommender systems filter contents/items valuable to users by inferring\npreferences from user features and historical behaviors. Mainstream approaches\nfollow the learning-to-rank paradigm, which focus on discovering and modeling\nitem topics (e.g., categories), and capturing user preferences on these topics\nbased on historical interactions. However, this paradigm often neglects the\nmodeling of user characteristics and their social roles, which are logical\nconfounders influencing the correlated interest and user preference transition.\nTo bridge this gap, we introduce the user role identification task and the\nbehavioral logic modeling task that aim to explicitly model user roles and\nlearn the logical relations between item topics and user social roles. We show\nthat it is possible to explicitly solve these tasks through an efficient\nintegration framework of Large Language Model (LLM) and recommendation systems,\nfor which we propose TagCF. On the one hand, TagCF exploits the (Multi-modal)\nLLM's world knowledge and logic inference ability to extract realistic\ntag-based virtual logic graphs that reveal dynamic and expressive knowledge of\nusers, refining our understanding of user behaviors. On the other hand, TagCF\npresents empirically effective integration modules that take advantage of the\nextracted tag-logic information, augmenting the recommendation performance. We\nconduct both online experiments and offline experiments with industrial and\npublic datasets as verification of TagCF's effectiveness, and we empirically\nshow that the user role modeling strategy is potentially a better choice than\nthe modeling of item topics. Additionally, we provide evidence that the\nextracted logic graphs are empirically a general and transferable knowledge\nthat can benefit a wide range of recommendation tasks."}
{"id": "2505.11733", "pdf": "https://arxiv.org/pdf/2505.11733", "abs": "https://arxiv.org/abs/2505.11733", "authors": ["Kevin Wu", "Eric Wu", "Rahul Thapa", "Kevin Wei", "Angela Zhang", "Arvind Suresh", "Jacqueline J. Tao", "Min Woo Sun", "Alejandro Lozano", "James Zou"], "title": "MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports", "categories": ["cs.CL"], "comment": null, "summary": "Doctors and patients alike increasingly use Large Language Models (LLMs) to\ndiagnose clinical cases. However, unlike domains such as math or coding, where\ncorrectness can be objectively defined by the final answer, medical diagnosis\nrequires both the outcome and the reasoning process to be accurate. Currently,\nwidely used medical benchmarks like MedQA and MMLU assess only accuracy in the\nfinal answer, overlooking the quality and faithfulness of the clinical\nreasoning process. To address this limitation, we introduce MedCaseReasoning,\nthe first open-access dataset for evaluating LLMs on their ability to align\nwith clinician-authored diagnostic reasoning. The dataset includes 14,489\ndiagnostic question-and-answer cases, each paired with detailed reasoning\nstatements derived from open-access medical case reports. We evaluate\nstate-of-the-art reasoning LLMs on MedCaseReasoning and find significant\nshortcomings in their diagnoses and reasoning: for instance, the top-performing\nopen-source model, DeepSeek-R1, achieves only 48% 10-shot diagnostic accuracy\nand mentions only 64% of the clinician reasoning statements (recall). However,\nwe demonstrate that fine-tuning LLMs on the reasoning traces derived from\nMedCaseReasoning significantly improves diagnostic accuracy and clinical\nreasoning recall by an average relative gain of 29% and 41%, respectively. The\nopen-source dataset, code, and models are available at\nhttps://github.com/kevinwu23/Stanford-MedCaseReasoning."}
{"id": "2412.19106", "pdf": "https://arxiv.org/pdf/2412.19106", "abs": "https://arxiv.org/abs/2412.19106", "authors": ["Guoming Li", "Jian Yang", "Shangsong Liang"], "title": "ERGNN: Spectral Graph Neural Network With Explicitly-Optimized Rational Graph Filters", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "comment": "Accepted at 2025 IEEE International Conference on Acoustics, Speech,\n  and Signal Processing, ICASSP 2025", "summary": "Approximation-based spectral graph neural networks, which construct graph\nfilters with function approximation, have shown substantial performance in\ngraph learning tasks. Despite their great success, existing works primarily\nemploy polynomial approximation to construct the filters, whereas another\nsuperior option, namely ration approximation, remains underexplored. Although a\nhandful of prior works have attempted to deploy the rational approximation,\ntheir implementations often involve intensive computational demands or still\nresort to polynomial approximations, hindering full potential of the rational\ngraph filters. To address the issues, this paper introduces ERGNN, a novel\nspectral GNN with explicitly-optimized rational filter. ERGNN adopts a unique\ntwo-step framework that sequentially applies the numerator filter and the\ndenominator filter to the input signals, thus streamlining the model paradigm\nwhile enabling explicit optimization of both numerator and denominator of the\nrational filter. Extensive experiments validate the superiority of ERGNN over\nstate-of-the-art methods, establishing it as a practical solution for deploying\nrational-based GNNs."}
{"id": "2505.10973", "pdf": "https://arxiv.org/pdf/2505.10973", "abs": "https://arxiv.org/abs/2505.10973", "authors": ["Narayanan PP", "Sarvesh Prasanth Venkatesan", "Srinivas Kantha Reddy", "Shishir Kolathaya"], "title": "GRoQ-Loco: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets", "categories": ["cs.RO", "cs.AI", "cs.LG", "I.2.9"], "comment": "18pages, 16figures, 6tables", "summary": "Recent advancements in large-scale offline training have demonstrated the\npotential of generalist policy learning for complex robotic tasks. However,\napplying these principles to legged locomotion remains a challenge due to\ncontinuous dynamics and the need for real-time adaptation across diverse\nterrains and robot morphologies. In this work, we propose GRoQ-Loco, a\nscalable, attention-based framework that learns a single generalist locomotion\npolicy across multiple quadruped robots and terrains, relying solely on offline\ndatasets. Our approach leverages expert demonstrations from two distinct\nlocomotion behaviors - stair traversal (non-periodic gaits) and flat terrain\ntraversal (periodic gaits) - collected across multiple quadruped robots, to\ntrain a generalist model that enables behavior fusion for both behaviors.\nCrucially, our framework operates directly on proprioceptive data from all\nrobots without incorporating any robot-specific encodings. The policy is\ndirectly deployable on an Intel i7 nuc, producing low-latency control outputs\nwithout any test-time optimization. Our extensive experiments demonstrate\nstrong zero-shot transfer across highly diverse quadruped robots and terrains,\nincluding hardware deployment on the Unitree Go1, a commercially available 12kg\nrobot. Notably, we evaluate challenging cross-robot training setups where\ndifferent locomotion skills are unevenly distributed across robots, yet observe\nsuccessful transfer of both flat walking and stair traversal behaviors to all\nrobots at test time. We also show preliminary walking on Stoch 5, a 70kg\nquadruped, on flat and outdoor terrains without requiring any fine tuning.\nThese results highlight the potential for robust generalist locomotion across\ndiverse robots and terrains."}
{"id": "2505.11810", "pdf": "https://arxiv.org/pdf/2505.11810", "abs": "https://arxiv.org/abs/2505.11810", "authors": ["Shen Li", "Renfen Hu", "Lijun Wang"], "title": "Efficiently Building a Domain-Specific Large Language Model from Scratch: A Case Study of a Classical Chinese Large Language Model", "categories": ["cs.CL"], "comment": null, "summary": "General-purpose large language models demonstrate notable capabilities in\nlanguage comprehension and generation, achieving results that are comparable\nto, or even surpass, human performance in many natural language processing\ntasks. Nevertheless, when general models are applied to some specific domains,\ne.g., Classical Chinese texts, their effectiveness is often unsatisfactory, and\nfine-tuning open-source foundational models similarly struggles to adequately\nincorporate domain-specific knowledge. To address this challenge, this study\ndeveloped a large language model, AI Taiyan, specifically designed for\nunderstanding and generating Classical Chinese. Experiments show that with a\nreasonable model design, data processing, foundational training, and\nfine-tuning, satisfactory results can be achieved with only 1.8 billion\nparameters. In key tasks related to language processing of Classical Chinese\nsuch as punctuation, identification of allusions, explanation of word meanings,\nand translation between ancient and modern Chinese, this model exhibits a clear\nadvantage over both general-purpose large models and domain-specific\ntraditional models, achieving levels close to or surpassing human baselines.\nThis research provides a reference for the efficient construction of\nspecialized domain-specific large language models. Furthermore, the paper\ndiscusses the application of this model in fields such as the collation of\nancient texts, dictionary editing, and language research, combined with case\nstudies."}
{"id": "2501.13041", "pdf": "https://arxiv.org/pdf/2501.13041", "abs": "https://arxiv.org/abs/2501.13041", "authors": ["Yifan Hu", "Guibin Zhang", "Peiyuan Liu", "Disen Lan", "Naiqi Li", "Dawei Cheng", "Tao Dai", "Shu-Tao Xia", "Shirui Pan"], "title": "TimeFilter: Patch-Specific Spatial-Temporal Graph Filtration for Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting methods generally fall into two main categories:\nChannel Independent (CI) and Channel Dependent (CD) strategies. While CI\noverlooks important covariate relationships, CD captures all dependencies\nwithout distinction, introducing noise and reducing generalization. Recent\nadvances in Channel Clustering (CC) aim to refine dependency modeling by\ngrouping channels with similar characteristics and applying tailored modeling\ntechniques. However, coarse-grained clustering struggles to capture complex,\ntime-varying interactions effectively. To address these challenges, we propose\nTimeFilter, a GNN-based framework for adaptive and fine-grained dependency\nmodeling. After constructing the graph from the input sequence, TimeFilter\nrefines the learned spatial-temporal dependencies by filtering out irrelevant\ncorrelations while preserving the most critical ones in a patch-specific\nmanner. Extensive experiments on 13 real-world datasets from diverse\napplication domains demonstrate the state-of-the-art performance of TimeFilter.\nThe code is available at https://github.com/TROUBADOUR000/TimeFilter."}
{"id": "2505.11548", "pdf": "https://arxiv.org/pdf/2505.11548", "abs": "https://arxiv.org/abs/2505.11548", "authors": ["Zhiyuan Chang", "Mingyang Li", "Xiaojun Jia", "Junjie Wang", "Yuekai Huang", "Ziyou Jiang", "Yang Liu", "Qing Wang"], "title": "One Shot Dominance: Knowledge Poisoning Attack on Retrieval-Augmented Generation Systems", "categories": ["cs.CR", "cs.AI"], "comment": "14pages, 4 figures", "summary": "Large Language Models (LLMs) enhanced with Retrieval-Augmented Generation\n(RAG) have shown improved performance in generating accurate responses.\nHowever, the dependence on external knowledge bases introduces potential\nsecurity vulnerabilities, particularly when these knowledge bases are publicly\naccessible and modifiable. While previous studies have exposed knowledge\npoisoning risks in RAG systems, existing attack methods suffer from critical\nlimitations: they either require injecting multiple poisoned documents\n(resulting in poor stealthiness) or can only function effectively on simplistic\nqueries (limiting real-world applicability). This paper reveals a more\nrealistic knowledge poisoning attack against RAG systems that achieves\nsuccessful attacks by poisoning only a single document while remaining\neffective for complex multi-hop questions involving complex relationships\nbetween multiple elements. Our proposed AuthChain address three challenges to\nensure the poisoned documents are reliably retrieved and trusted by the LLM,\neven against large knowledge bases and LLM's own knowledge. Extensive\nexperiments across six popular LLMs demonstrate that AuthChain achieves\nsignificantly higher attack success rates while maintaining superior\nstealthiness against RAG defense mechanisms compared to state-of-the-art\nbaselines."}
{"id": "2505.11958", "pdf": "https://arxiv.org/pdf/2505.11958", "abs": "https://arxiv.org/abs/2505.11958", "authors": ["Aswini Kumar Padhi", "Anil Bandhakavi", "Tanmoy Chakraborty"], "title": "Counterspeech the ultimate shield! Multi-Conditioned Counterspeech Generation through Attributed Prefix Learning", "categories": ["cs.CL"], "comment": "Accepted in ACL 2025 Main Conference", "summary": "Counterspeech has proven to be a powerful tool to combat hate speech online.\nPrevious studies have focused on generating counterspeech conditioned only on\nspecific intents (single attributed). However, a holistic approach considering\nmultiple attributes simultaneously can yield more nuanced and effective\nresponses. Here, we introduce HiPPrO, Hierarchical Prefix learning with\nPreference Optimization, a novel two-stage framework that utilizes the\neffectiveness of attribute-specific prefix embedding spaces hierarchically\noptimized during the counterspeech generation process in the first phase.\nThereafter, we incorporate both reference and reward-free preference\noptimization to generate more constructive counterspeech. Furthermore, we\nextend IntentCONANv2 by annotating all 13,973 counterspeech instances with\nemotion labels by five annotators. HiPPrO leverages hierarchical prefix\noptimization to integrate these dual attributes effectively. An extensive\nevaluation demonstrates that HiPPrO achieves a ~38 % improvement in intent\nconformity and a ~3 %, ~2 %, ~3 % improvement in Rouge-1, Rouge-2, and Rouge-L,\nrespectively, compared to several baseline models. Human evaluations further\nsubstantiate the superiority of our approach, highlighting the enhanced\nrelevance and appropriateness of the generated counterspeech. This work\nunderscores the potential of multi-attribute conditioning in advancing the\nefficacy of counterspeech generation systems."}
{"id": "2501.13223", "pdf": "https://arxiv.org/pdf/2501.13223", "abs": "https://arxiv.org/abs/2501.13223", "authors": ["Zahraa Al Sahili", "Ioannis Patras", "Matthew Purver"], "title": "A Comprehensive Social Bias Audit of Contrastive Vision Language Models", "categories": ["cs.LG"], "comment": null, "summary": "In the domain of text-to-image generative models, biases inherent in training\ndatasets often propagate into generated content, posing significant ethical\nchallenges, particularly in socially sensitive contexts. We introduce FairCoT,\na novel framework that enhances fairness in text-to-image models through\nChain-of-Thought (CoT) reasoning within multimodal generative large language\nmodels. FairCoT employs iterative CoT refinement to systematically mitigate\nbiases, and dynamically adjusts textual prompts in real time, ensuring diverse\nand equitable representation in generated images. By integrating iterative\nreasoning processes, FairCoT addresses the limitations of zero-shot CoT in\nsensitive scenarios, balancing creativity with ethical responsibility.\nExperimental evaluations across popular text-to-image systems--including DALL-E\nand various Stable Diffusion variants--demonstrate that FairCoT significantly\nenhances fairness and diversity without sacrificing image quality or semantic\nfidelity. By combining robust reasoning, lightweight deployment, and\nextensibility to multiple models, FairCoT represents a promising step toward\nmore socially responsible and transparent AI-driven content generation."}
{"id": "2505.11568", "pdf": "https://arxiv.org/pdf/2505.11568", "abs": "https://arxiv.org/abs/2505.11568", "authors": ["Stylianos Stasinos", "Martino Mensio", "Elena Lazovik", "Athanasios Trantas"], "title": "BioCube: A Multimodal Dataset for Biodiversity Research", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "submitted to BiDS'25, 5 pages, 1 figure", "summary": "Biodiversity research requires complete and detailed information to study\necosystem dynamics at different scales. Employing data-driven methods like\nMachine Learning is getting traction in ecology and more specific biodiversity,\noffering alternative modelling pathways. For these methods to deliver accurate\nresults there is the need for large, curated and multimodal datasets that offer\ngranular spatial and temporal resolutions. In this work, we introduce BioCube,\na multimodal, fine-grained global dataset for ecology and biodiversity\nresearch. BioCube incorporates species observations through images, audio\nrecordings and descriptions, environmental DNA, vegetation indices,\nagricultural, forest, land indicators, and high-resolution climate variables.\nAll observations are geospatially aligned under the WGS84 geodetic system,\nspanning from 2000 to 2020. The dataset will become available at\nhttps://huggingface.co/datasets/BioDT/BioCube while the acquisition and\nprocessing code base at https://github.com/BioDT/bfm-data."}
{"id": "2505.12043", "pdf": "https://arxiv.org/pdf/2505.12043", "abs": "https://arxiv.org/abs/2505.12043", "authors": ["Jingxue Chen", "Qingkun Tang", "Qianchun Lu", "Siyuan Fang"], "title": "MoL for LLMs: Dual-Loss Optimization to Enhance Domain Expertise While Preserving General Capabilities", "categories": ["cs.CL"], "comment": null, "summary": "Although large language models (LLMs) perform well in general tasks,\ndomain-specific applications suffer from hallucinations and accuracy\nlimitations. Continual Pre-Training (CPT) approaches encounter two key issues:\n(1) domain-biased data degrades general language skills, and (2) improper\ncorpus-mixture ratios limit effective adaptation. To address these, we propose\na novel framework, Mixture of Losses (MoL), which decouples optimization\nobjectives for domain-specific and general corpora. Specifically, cross-entropy\n(CE) loss is applied to domain-corpus to ensure knowledge acquisition, while\nKullback-Leibler (KL) divergence aligns general-corpus training with the base\nmodel's foundational capabilities. This dual-loss architecture preserves\nuniversal skills while enhancing domain expertise, avoiding catastrophic\nforgetting. Empirically, we validate that a 1:1 domain-to-general corpus ratio\noptimally balances training and overfitting without the need for extensive\ntuning or resource-intensive experiments. Furthermore, our experiments\ndemonstrate significant performance gains compared to traditional CPT\napproaches, which often suffer from degradation in general language\ncapabilities; our model achieves 27.9% higher accuracy on the Math-500\nbenchmark in the non-think reasoning mode, and an impressive 83.3% improvement\non the challenging AIME25 subset in the think mode, underscoring the\neffectiveness of our approach."}
{"id": "2501.15910", "pdf": "https://arxiv.org/pdf/2501.15910", "abs": "https://arxiv.org/abs/2501.15910", "authors": ["Michael Muehlebach", "Zhiyu He", "Michael I. Jordan"], "title": "The Sample Complexity of Online Reinforcement Learning: A Multi-model Perspective", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "comment": "29 pages, 3 figures", "summary": "We study the sample complexity of online reinforcement learning in the\ngeneral setting of nonlinear dynamical systems with continuous state and action\nspaces. Our analysis accommodates a large class of dynamical systems ranging\nfrom a finite set of nonlinear candidate models to models with bounded and\nLipschitz continuous dynamics, to systems that are parametrized by a compact\nand real-valued set of parameters. In the most general setting, our algorithm\nachieves a policy regret of $\\mathcal{O}(N \\epsilon^2 +\n\\mathrm{ln}(m(\\epsilon))/\\epsilon^2)$, where $N$ is the time horizon,\n$\\epsilon$ is a user-specified discretization width, and $m(\\epsilon)$ measures\nthe complexity of the function class under consideration via its packing\nnumber. In the special case where the dynamics are parametrized by a compact\nand real-valued set of parameters (such as neural networks, transformers,\netc.), we prove a policy regret of $\\mathcal{O}(\\sqrt{N p})$, where $p$ denotes\nthe number of parameters, recovering earlier sample-complexity results that\nwere derived for linear time-invariant dynamical systems. While this article\nfocuses on characterizing sample complexity, the proposed algorithms are likely\nto be useful in practice, due to their simplicity, their ability to incorporate\nprior knowledge, and their benign transient behavior."}
{"id": "2505.11750", "pdf": "https://arxiv.org/pdf/2505.11750", "abs": "https://arxiv.org/abs/2505.11750", "authors": ["Zhanxiang Hua", "Ryan Sobash", "David John Gagne II", "Yingkai Sha", "Alexandra Anderson-Frey"], "title": "Improving Medium Range Severe Weather Prediction through Transformer Post-processing of AI Weather Forecasts", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "comment": "16 pages, 10 figures; update fix issues with section reference number", "summary": "Improving the skill of medium-range (1-8 day) severe weather prediction is\ncrucial for mitigating societal impacts. This study introduces a novel approach\nleveraging decoder-only transformer networks to post-process AI-based weather\nforecasts, specifically from the Pangu-Weather model, for improved severe\nweather guidance. Unlike traditional post-processing methods that use a dense\nneural network to predict the probability of severe weather using discrete\nforecast samples, our method treats forecast lead times as sequential\n``tokens'', enabling the transformer to learn complex temporal relationships\nwithin the evolving atmospheric state. We compare this approach against\npost-processing of the Global Forecast System (GFS) using both a traditional\ndense neural network and our transformer, as well as configurations that\nexclude convective parameters to fairly evaluate the impact of using the\nPangu-Weather AI model. Results demonstrate that the transformer-based\npost-processing significantly enhances forecast skill compared to dense neural\nnetworks. Furthermore, AI-driven forecasts, particularly Pangu-Weather\ninitialized from high resolution analysis, exhibit superior performance to GFS\nin the medium-range, even without explicit convective parameters. Our approach\noffers improved accuracy, and reliability, which also provides interpretability\nthrough feature attribution analysis, advancing medium-range severe weather\nprediction capabilities."}
{"id": "2505.12082", "pdf": "https://arxiv.org/pdf/2505.12082", "abs": "https://arxiv.org/abs/2505.12082", "authors": ["Yunshui Li", "Yiyuan Ma", "Shen Yan", "Chaoyi Zhang", "Jing Liu", "Jianqiao Lu", "Ziwen Xu", "Mengzhao Chen", "Minrui Wang", "Shiyi Zhan", "Jin Ma", "Xunhao Lai", "Yao Luo", "Xingyan Bin", "Hongbin Ren", "Mingji Han", "Wenhao Hao", "Bairen Yi", "LingJun Liu", "Bole Ma", "Xiaoying Jia", "Zhou Xun", "Siyuan Qiao", "Liang Xiang", "Yonghui Wu"], "title": "Model Merging in Pre-training of Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Model merging has emerged as a promising technique for enhancing large\nlanguage models, though its application in large-scale pre-training remains\nrelatively unexplored. In this paper, we present a comprehensive investigation\nof model merging techniques during the pre-training process. Through extensive\nexperiments with both dense and Mixture-of-Experts (MoE) architectures ranging\nfrom millions to over 100 billion parameters, we demonstrate that merging\ncheckpoints trained with constant learning rates not only achieves significant\nperformance improvements but also enables accurate prediction of annealing\nbehavior. These improvements lead to both more efficient model development and\nsignificantly lower training costs. Our detailed ablation studies on merging\nstrategies and hyperparameters provide new insights into the underlying\nmechanisms while uncovering novel applications. Through comprehensive\nexperimental analysis, we offer the open-source community practical\npre-training guidelines for effective model merging."}
{"id": "2501.17323", "pdf": "https://arxiv.org/pdf/2501.17323", "abs": "https://arxiv.org/abs/2501.17323", "authors": ["Haoyang Zheng", "Hengrong Du", "Ruqi Zhang", "Guang Lin"], "title": "Exploring Non-Convex Discrete Energy Landscapes: An Efficient Langevin-Like Sampler with Replica Exchange", "categories": ["cs.LG", "stat.ML"], "comment": "7 figures, 30 pages", "summary": "Gradient-based Discrete Samplers (GDSs) are effective for sampling discrete\nenergy landscapes. However, they often stagnate in complex, non-convex\nsettings. To improve exploration, we introduce the Discrete Replica EXchangE\nLangevin (DREXEL) sampler and its variant with Adjusted Metropolis (DREAM).\nThese samplers use two GDSs at different temperatures and step sizes: one\nfocuses on local exploitation, while the other explores broader energy\nlandscapes. When energy differences are significant, sample swaps occur, which\nare determined by a mechanism tailored for discrete sampling to ensure detailed\nbalance. Theoretically, we prove that the proposed samplers satisfy detailed\nbalance and converge to the target distribution under mild conditions.\nExperiments across 2d synthetic simulations, sampling from Ising models and\nrestricted Boltzmann machines, and training deep energy-based models further\nconfirm their efficiency in exploring non-convex discrete energy landscapes."}
{"id": "2505.11755", "pdf": "https://arxiv.org/pdf/2505.11755", "abs": "https://arxiv.org/abs/2505.11755", "authors": ["Matthew Kim", "William Sharpless", "Hyun Joe Jeong", "Sander Tonkens", "Somil Bansal", "Sylvia Herbert"], "title": "Reachability Barrier Networks: Learning Hamilton-Jacobi Solutions for Smooth and Flexible Control Barrier Functions", "categories": ["cs.RO", "cs.AI"], "comment": "15 pages, 7 figures", "summary": "Recent developments in autonomous driving and robotics underscore the\nnecessity of safety-critical controllers. Control barrier functions (CBFs) are\na popular method for appending safety guarantees to a general control\nframework, but they are notoriously difficult to generate beyond low\ndimensions. Existing methods often yield non-differentiable or inaccurate\napproximations that lack integrity, and thus fail to ensure safety. In this\nwork, we use physics-informed neural networks (PINNs) to generate smooth\napproximations of CBFs by computing Hamilton-Jacobi (HJ) optimal control\nsolutions. These reachability barrier networks (RBNs) avoid traditional\ndimensionality constraints and support the tuning of their conservativeness\npost-training through a parameterized discount term. To ensure robustness of\nthe discounted solutions, we leverage conformal prediction methods to derive\nprobabilistic safety guarantees for RBNs. We demonstrate that RBNs are highly\naccurate in low dimensions, and safer than the standard neural CBF approach in\nhigh dimensions. Namely, we showcase the RBNs in a 9D multi-vehicle collision\navoidance problem where it empirically proves to be 5.5x safer and 1.9x less\nconservative than the neural CBFs, offering a promising method to synthesize\nCBFs for general nonlinear autonomous systems."}
{"id": "2505.12654", "pdf": "https://arxiv.org/pdf/2505.12654", "abs": "https://arxiv.org/abs/2505.12654", "authors": ["Yuxin Lin", "Yinglin Zheng", "Ming Zeng", "Wangzheng Shi"], "title": "Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals", "categories": ["cs.CL", "cs.AI"], "comment": "Accepected by ACL 2025", "summary": "This paper addresses the gap in predicting turn-taking and backchannel\nactions in human-machine conversations using multi-modal signals (linguistic,\nacoustic, and visual). To overcome the limitation of existing datasets, we\npropose an automatic data collection pipeline that allows us to collect and\nannotate over 210 hours of human conversation videos. From this, we construct a\nMulti-Modal Face-to-Face (MM-F2F) human conversation dataset, including over\n1.5M words and corresponding turn-taking and backchannel annotations from\napproximately 20M frames. Additionally, we present an end-to-end framework that\npredicts the probability of turn-taking and backchannel actions from\nmulti-modal signals. The proposed model emphasizes the interrelation between\nmodalities and supports any combination of text, audio, and video inputs,\nmaking it adaptable to a variety of realistic scenarios. Our experiments show\nthat our approach achieves state-of-the-art performance on turn-taking and\nbackchannel prediction tasks, achieving a 10% increase in F1-score on\nturn-taking and a 33% increase on backchannel prediction. Our dataset and code\nare publicly available online to ease of subsequent research."}
{"id": "2502.00829", "pdf": "https://arxiv.org/pdf/2502.00829", "abs": "https://arxiv.org/abs/2502.00829", "authors": ["Xixi Wu", "Yifei Shen", "Fangzhou Ge", "Caihua Shan", "Yizhu Jiao", "Xiangguo Sun", "Hong Cheng"], "title": "When Do LLMs Help With Node Classification? A Comprehensive Analysis", "categories": ["cs.LG", "cs.SI"], "comment": "Accepted by ICML 2025", "summary": "Node classification is a fundamental task in graph analysis, with broad\napplications across various fields. Recent breakthroughs in Large Language\nModels (LLMs) have enabled LLM-based approaches for this task. Although many\nstudies demonstrate the impressive performance of LLM-based methods, the lack\nof clear design guidelines may hinder their practical application. In this\nwork, we aim to establish such guidelines through a fair and systematic\ncomparison of these algorithms. As a first step, we developed LLMNodeBed, a\ncomprehensive codebase and testbed for node classification using LLMs. It\nincludes 10 homophilic datasets, 4 heterophilic datasets, 8 LLM-based\nalgorithms, 8 classic baselines, and 3 learning paradigms. Subsequently, we\nconducted extensive experiments, training and evaluating over 2,700 models, to\ndetermine the key settings (e.g., learning paradigms and homophily) and\ncomponents (e.g., model size and prompt) that affect performance. Our findings\nuncover 8 insights, e.g., (1) LLM-based methods can significantly outperform\ntraditional methods in a semi-supervised setting, while the advantage is\nmarginal in a supervised setting; (2) Graph Foundation Models can beat\nopen-source LLMs but still fall short of strong LLMs like GPT-4o in a zero-shot\nsetting. We hope that the release of LLMNodeBed, along with our insights, will\nfacilitate reproducible research and inspire future studies in this field.\nCodes and datasets are released at\n\\href{https://llmnodebed.github.io/}{\\texttt{https://llmnodebed.github.io/}}."}
{"id": "2505.12188", "pdf": "https://arxiv.org/pdf/2505.12188", "abs": "https://arxiv.org/abs/2505.12188", "authors": ["Hanyu Wang", "Xinrui Wu", "Zijian Ding", "Su Zheng", "Chengyue Wang", "Tony Nowatzki", "Yizhou Sun", "Jason Cong"], "title": "LLM-DSE: Searching Accelerator Parameters with LLM Agents", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Even though high-level synthesis (HLS) tools mitigate the challenges of\nprogramming domain-specific accelerators (DSAs) by raising the abstraction\nlevel, optimizing hardware directive parameters remains a significant hurdle.\nExisting heuristic and learning-based methods struggle with adaptability and\nsample efficiency. We present LLM-DSE, a multi-agent framework designed\nspecifically for optimizing HLS directives. Combining LLM with design space\nexploration (DSE), our explorer coordinates four agents: Router, Specialists,\nArbitrator, and Critic. These multi-agent components interact with various\ntools to accelerate the optimization process. LLM-DSE leverages essential\ndomain knowledge to identify efficient parameter combinations while maintaining\nadaptability through verbal learning from online interactions. Evaluations on\nthe HLSyn dataset demonstrate that LLM-DSE achieves substantial $2.55\\times$\nperformance gains over state-of-the-art methods, uncovering novel designs while\nreducing runtime. Ablation studies validate the effectiveness and necessity of\nthe proposed agent interactions. Our code is open-sourced here:\nhttps://github.com/Nozidoali/LLM-DSE."}
{"id": "2505.12768", "pdf": "https://arxiv.org/pdf/2505.12768", "abs": "https://arxiv.org/abs/2505.12768", "authors": ["Yaxun Dai", "Wenxuan Xie", "Xialie Zhuang", "Tianyu Yang", "Yiying Yang", "Haiqin Yang", "Yuhang Zhao", "Pingfu Chao", "Wenhao Jiang"], "title": "ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL", "categories": ["cs.CL"], "comment": null, "summary": "In Text-to-SQL, execution feedback is essential for guiding large language\nmodels (LLMs) to reason accurately and generate reliable SQL queries. However,\nexisting methods treat execution feedback solely as a post-hoc signal for\ncorrection or selection, failing to integrate it into the generation process.\nThis limitation hinders their ability to address reasoning errors as they\noccur, ultimately reducing query accuracy and robustness. To address this\nissue, we propose ReEx-SQL (Reasoning with Execution-Aware Reinforcement\nLearning), a framework for Text-to-SQL that enables models to interact with the\ndatabase during decoding and dynamically adjust their reasoning based on\nexecution feedback. ReEx-SQL introduces an execution-aware reasoning paradigm\nthat interleaves intermediate SQL execution into reasoning paths, facilitating\ncontext-sensitive revisions. It achieves this through structured prompts with\nmarkup tags and a stepwise rollout strategy that integrates execution feedback\ninto each stage of generation. To supervise policy learning, we develop a\ncomposite reward function that includes an exploration reward, explicitly\nencouraging effective database interaction. Additionally, ReEx-SQL adopts a\ntree-based decoding strategy to support exploratory reasoning, enabling dynamic\nexpansion of alternative reasoning paths. Notably, ReEx-SQL achieves 88.8% on\nSpider and 64.9% on BIRD at the 7B scale, surpassing the standard reasoning\nbaseline by 2.7% and 2.6%, respectively. It also shows robustness, achieving\n85.2% on Spider-Realistic with leading performance. In addition, its\ntree-structured decoding improves efficiency and performance over linear\ndecoding, reducing inference time by 51.9% on the BIRD development set."}
{"id": "2502.01237", "pdf": "https://arxiv.org/pdf/2502.01237", "abs": "https://arxiv.org/abs/2502.01237", "authors": ["Alexey Gorbatovski", "Boris Shaposhnikov", "Viacheslav Sinii", "Alexey Malakhov", "Daniil Gavrilov"], "title": "The Differences Between Direct Alignment Algorithms are a Blur", "categories": ["cs.LG"], "comment": null, "summary": "Direct Alignment Algorithms (DAAs) offer a simpler way to language model\nalignment than traditional RLHF by directly optimizing policies. While DAAs\ndiffer in their use of SFT (one-stage vs. two-stage), the scalar scores within\ntheir objectives (likelihood vs. odds ratios), and ranking objectives (pairwise\nvs. pointwise), the critical factors for performance remain underexplored. We\nprovide a systematic comparative analysis. We first show that one-stage methods\n(e.g. ORPO, ASFT) underperform compared to two-stage approaches. However, we\ndemonstrate that adapting them to a two-stage setup with an explicit SFT phase\ncan improve their performance. Further, introducing and tuning a unifying\n$\\beta$ parameter within this two-stage framework boosts their performence\n(e.g., AlpacaEval 2: $+13.45$ ORPO, $+8.27$ ASFT), matching established methods\nlike DPO and enabling fair comparisons. Our comprehensive analysis reveals that\nthe choice between pairwise and pointwise objectives is the primary determinant\nof alignment success, rather than the specific scalar score (e.g.,\npolicy-reference ratio vs. odds ratio) employed. We provide empirical evidence\nsuggesting this stems from how these objectives interact with prompt-specific\nbiases. These findings underscore the need for nuanced evaluations in DAA\nresearch to avoid oversimplified claims of superiority."}
{"id": "2505.12224", "pdf": "https://arxiv.org/pdf/2505.12224", "abs": "https://arxiv.org/abs/2505.12224", "authors": ["Weifeng Lu", "Minghao Ye", "Zewei Ye", "Ruihan Tao", "Shuo Yang", "Bo Zhao"], "title": "RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Vision-Language-Action (VLA) models have recently advanced robotic\nmanipulation by translating natural-language instructions and image information\ninto sequential control actions. However, these models often underperform in\nopen-world scenarios, as they are predominantly trained on successful expert\ndemonstrations and exhibit a limited capacity for failure recovery. In this\nwork, we present a Robotic Failure Analysis and Correction (RoboFAC) framework\nto address this issue. Firstly, we construct RoboFAC dataset comprising 9,440\nerroneous manipulation trajectories and 78,623 QA pairs across 16 diverse tasks\nand 53 scenes in both simulation and real-world environments. Leveraging our\ndataset, we develop RoboFAC model, which is capable of Task Understanding,\nFailure Analysis and Failure Correction. Experimental results demonstrate that\nthe RoboFAC model outperforms GPT-4o by 34.1% on our evaluation benchmark.\nFurthermore, we integrate the RoboFAC model into a real-world VLA control\npipeline as an external supervision providing correction instructions, yielding\na 29.1% relative improvement on average on four real-world tasks. The results\nshow that our RoboFAC framework effectively handles robotic failures and\nassists the VLA model in recovering from failures."}
{"id": "2505.13147", "pdf": "https://arxiv.org/pdf/2505.13147", "abs": "https://arxiv.org/abs/2505.13147", "authors": ["Aswathy Velutharambath", "Kai Sassenberg", "Roman Klinger"], "title": "What if Deception Cannot be Detected? A Cross-Linguistic Study on the Limits of Deception Detection from Text", "categories": ["cs.CL"], "comment": null, "summary": "Can deception be detected solely from written text? Cues of deceptive\ncommunication are inherently subtle, even more so in text-only communication.\nYet, prior studies have reported considerable success in automatic deception\ndetection. We hypothesize that such findings are largely driven by artifacts\nintroduced during data collection and do not generalize beyond specific\ndatasets. We revisit this assumption by introducing a belief-based deception\nframework, which defines deception as a misalignment between an author's claims\nand true beliefs, irrespective of factual accuracy, allowing deception cues to\nbe studied in isolation. Based on this framework, we construct three corpora,\ncollectively referred to as DeFaBel, including a German-language corpus of\ndeceptive and non-deceptive arguments and a multilingual version in German and\nEnglish, each collected under varying conditions to account for belief change\nand enable cross-linguistic analysis. Using these corpora, we evaluate commonly\nreported linguistic cues of deception. Across all three DeFaBel variants, these\ncues show negligible, statistically insignificant correlations with deception\nlabels, contrary to prior work that treats such cues as reliable indicators. We\nfurther benchmark against other English deception datasets following similar\ndata collection protocols. While some show statistically significant\ncorrelations, effect sizes remain low and, critically, the set of predictive\ncues is inconsistent across datasets. We also evaluate deception detection\nusing feature-based models, pretrained language models, and instruction-tuned\nlarge language models. While some models perform well on established deception\ndatasets, they consistently perform near chance on DeFaBel. Our findings\nchallenge the assumption that deception can be reliably inferred from\nlinguistic cues and call for rethinking how deception is studied and modeled in\nNLP."}
{"id": "2502.01681", "pdf": "https://arxiv.org/pdf/2502.01681", "abs": "https://arxiv.org/abs/2502.01681", "authors": ["Ziyang Zheng", "Shan Huang", "Jianyuan Zhong", "Zhengyuan Shi", "Guohao Dai", "Ningyi Xu", "Qiang Xu"], "title": "DeepGate4: Efficient and Effective Representation Learning for Circuit Design at Scale", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Circuit representation learning has become pivotal in electronic design\nautomation, enabling critical tasks such as testability analysis, logic\nreasoning, power estimation, and SAT solving. However, existing models face\nsignificant challenges in scaling to large circuits due to limitations like\nover-squashing in graph neural networks and the quadratic complexity of\ntransformer-based models. To address these issues, we introduce DeepGate4, a\nscalable and efficient graph transformer specifically designed for large-scale\ncircuits. DeepGate4 incorporates several key innovations: (1) an update\nstrategy tailored for circuit graphs, which reduce memory complexity to\nsub-linear and is adaptable to any graph transformer; (2) a GAT-based sparse\ntransformer with global and local structural encodings for AIGs; and (3) an\ninference acceleration CUDA kernel that fully exploit the unique sparsity\npatterns of AIGs. Our extensive experiments on the ITC99 and EPFL benchmarks\nshow that DeepGate4 significantly surpasses state-of-the-art methods, achieving\n15.5% and 31.1% performance improvements over the next-best models.\nFurthermore, the Fused-DeepGate4 variant reduces runtime by 35.1% and memory\nusage by 46.8%, making it highly efficient for large-scale circuit analysis.\nThese results demonstrate the potential of DeepGate4 to handle complex EDA\ntasks while offering superior scalability and efficiency. Code is available at\nhttps://github.com/zyzheng17/DeepGate4-ICLR-25."}
{"id": "2505.12442", "pdf": "https://arxiv.org/pdf/2505.12442", "abs": "https://arxiv.org/abs/2505.12442", "authors": ["Liwen Wang", "Wenxuan Wang", "Shuai Wang", "Zongjie Li", "Zhenlan Ji", "Zongyi Lyu", "Daoyuan Wu", "Shing-Chi Cheung"], "title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has led to the\nemergence of Multi-Agent Systems (MAS) to perform complex tasks through\ncollaboration. However, the intricate nature of MAS, including their\narchitecture and agent interactions, raises significant concerns regarding\nintellectual property (IP) protection. In this paper, we introduce MASLEAK, a\nnovel attack framework designed to extract sensitive information from MAS\napplications. MASLEAK targets a practical, black-box setting, where the\nadversary has no prior knowledge of the MAS architecture or agent\nconfigurations. The adversary can only interact with the MAS through its public\nAPI, submitting attack query $q$ and observing outputs from the final agent.\nInspired by how computer worms propagate and infect vulnerable network hosts,\nMASLEAK carefully crafts adversarial query $q$ to elicit, propagate, and retain\nresponses from each MAS agent that reveal a full set of proprietary components,\nincluding the number of agents, system topology, system prompts, task\ninstructions, and tool usages. We construct the first synthetic dataset of MAS\napplications with 810 applications and also evaluate MASLEAK against real-world\nMAS applications, including Coze and CrewAI. MASLEAK achieves high accuracy in\nextracting MAS IP, with an average attack success rate of 87% for system\nprompts and task instructions, and 92% for system architecture in most cases.\nWe conclude by discussing the implications of our findings and the potential\ndefenses."}
{"id": "2505.13282", "pdf": "https://arxiv.org/pdf/2505.13282", "abs": "https://arxiv.org/abs/2505.13282", "authors": ["Sahil Mishra", "Kumar Arjun", "Tanmoy Chakraborty"], "title": "Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy Expansion", "categories": ["cs.CL"], "comment": "Accepted in ACL'25 Findings", "summary": "Taxonomies are hierarchical knowledge graphs crucial for recommendation\nsystems, and web applications. As data grows, expanding taxonomies is\nessential, but existing methods face key challenges: (1) discriminative models\nstruggle with representation limits and generalization, while (2) generative\nmethods either process all candidates at once, introducing noise and exceeding\ncontext limits, or discard relevant entities by selecting noisy candidates. We\npropose LORex ($\\textbf{L}$ineage-$\\textbf{O}$riented $\\textbf{Re}$asoning for\nTaxonomy E$\\textbf{x}$pansion), a plug-and-play framework that combines\ndiscriminative ranking and generative reasoning for efficient taxonomy\nexpansion. Unlike prior methods, LORex ranks and chunks candidate terms into\nbatches, filtering noise and iteratively refining selections by reasoning\ncandidates' hierarchy to ensure contextual efficiency. Extensive experiments\nacross four benchmarks and twelve baselines show that LORex improves accuracy\nby 12% and Wu & Palmer similarity by 5% over state-of-the-art methods."}
{"id": "2502.04463", "pdf": "https://arxiv.org/pdf/2502.04463", "abs": "https://arxiv.org/abs/2502.04463", "authors": ["Daman Arora", "Andrea Zanette"], "title": "Training Language Models to Reason Efficiently", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Scaling model size and training data has led to great advances in the\nperformance of Large Language Models (LLMs). However, the diminishing returns\nof this approach necessitate alternative methods to improve model capabilities,\nparticularly in tasks requiring advanced reasoning. Large reasoning models,\nwhich leverage long chain-of-thoughts, bring unprecedented breakthroughs in\nproblem-solving capabilities but at a substantial deployment cost associated to\nlonger generations. Reducing inference costs is crucial for the economic\nfeasibility, user experience, and environmental sustainability of these models.\n  In this work, we propose to train large reasoning models to reason\nefficiently. More precisely, we use reinforcement learning (RL) to train\nreasoning models to dynamically allocate inference-time compute based on task\ncomplexity. Our method incentivizes models to minimize unnecessary\ncomputational overhead while maintaining accuracy, thereby achieving\nsubstantial efficiency gains. It enables the derivation of a family of\nreasoning models with varying efficiency levels, controlled via a single\nhyperparameter. Experiments on two open-weight large reasoning models\ndemonstrate significant reductions in inference cost while preserving most of\nthe accuracy."}
{"id": "2505.12638", "pdf": "https://arxiv.org/pdf/2505.12638", "abs": "https://arxiv.org/abs/2505.12638", "authors": ["Yifeng Jiao", "Yuchen Liu", "Yu Zhang", "Xin Guo", "Yushuai Wu", "Chen Jiang", "Jiyang Li", "Hongwei Zhang", "Limei Han", "Xin Gao", "Yuan Qi", "Yuan Cheng"], "title": "ChromFound: Towards A Universal Foundation Model for Single-Cell Chromatin Accessibility Data", "categories": ["q-bio.GN", "cs.AI", "cs.CE", "cs.LG"], "comment": null, "summary": "The advent of single-cell Assay for Transposase-Accessible Chromatin using\nsequencing (scATAC-seq) offers an innovative perspective for deciphering\nregulatory mechanisms by assembling a vast repository of single-cell chromatin\naccessibility data. While foundation models have achieved significant success\nin single-cell transcriptomics, there is currently no foundation model for\nscATAC-seq that supports zero-shot high-quality cell identification and\ncomprehensive multi-omics analysis simultaneously. Key challenges lie in the\nhigh dimensionality and sparsity of scATAC-seq data, as well as the lack of a\nstandardized schema for representing open chromatin regions (OCRs). Here, we\npresent ChromFound, a foundation model tailored for scATAC-seq. ChromFound\nutilizes a hybrid architecture and genome-aware tokenization to effectively\ncapture genome-wide long contexts and regulatory signals from dynamic chromatin\nlandscapes. Pretrained on 1.97 million cells from 30 tissues and 6 disease\nconditions, ChromFound demonstrates broad applicability across 6 diverse tasks.\nNotably, it achieves robust zero-shot performance in generating universal cell\nrepresentations and exhibits excellent transferability in cell type annotation\nand cross-omics prediction. By uncovering enhancer-gene links undetected by\nexisting computational methods, ChromFound offers a promising framework for\nunderstanding disease risk variants in the noncoding genome."}
{"id": "2505.13346", "pdf": "https://arxiv.org/pdf/2505.13346", "abs": "https://arxiv.org/abs/2505.13346", "authors": ["Austin Xu", "Yilun Zhou", "Xuan-Phi Nguyen", "Caiming Xiong", "Shafiq Joty"], "title": "J4R: Learning to Judge with Equivalent Initial State Group Relative Policy Optimization", "categories": ["cs.CL", "cs.AI"], "comment": "25 pages, 4 figures, 6 tables. To be updated with links for\n  code/benchmark", "summary": "To keep pace with the increasing pace of large language models (LLM)\ndevelopment, model output evaluation has transitioned away from time-consuming\nhuman evaluation to automatic evaluation, where LLMs themselves are tasked with\nassessing and critiquing other model outputs. LLM-as-judge models are a class\nof generative evaluators that excel in evaluating relatively simple domains,\nlike chat quality, but struggle in reasoning intensive domains where model\nresponses contain more substantive and challenging content. To remedy existing\njudge shortcomings, we explore training judges with reinforcement learning\n(RL). We make three key contributions: (1) We propose the Equivalent Initial\nState Group Relative Policy Optimization (EIS-GRPO) algorithm, which allows us\nto train our judge to be robust to positional biases that arise in more complex\nevaluation settings. (2) We introduce ReasoningJudgeBench, a benchmark that\nevaluates judges in diverse reasoning settings not covered by prior work. (3)\nWe train Judge for Reasoning (J4R), a 7B judge trained with EIS-GRPO that\noutperforms GPT-4o and the next best small judge by 6.7% and 9%, matching or\nexceeding the performance of larger GRPO-trained judges on both JudgeBench and\nReasoningJudgeBench."}
{"id": "2502.07151", "pdf": "https://arxiv.org/pdf/2502.07151", "abs": "https://arxiv.org/abs/2502.07151", "authors": ["Blaise Delattre", "Sylvain Delattre", "Alexandre V√©rine", "Alexandre Allauzen"], "title": "Conditional Distribution Quantization in Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Conditional expectation \\mathbb{E}(Y \\mid X) often fails to capture the\ncomplexity of multimodal conditional distributions \\mathcal{L}(Y \\mid X). To\naddress this, we propose using n-point conditional quantizations--functional\nmappings of X that are learnable via gradient descent--to approximate\n\\mathcal{L}(Y \\mid X). This approach adapts Competitive Learning Vector\nQuantization (CLVQ), tailored for conditional distributions. It goes beyond\nsingle-valued predictions by providing multiple representative points that\nbetter reflect multimodal structures. It enables the approximation of the true\nconditional law in the Wasserstein distance. The resulting framework is\ntheoretically grounded and useful for uncertainty quantification and multimodal\ndata generation tasks. For example, in computer vision inpainting tasks,\nmultiple plausible reconstructions may exist for the same partially observed\ninput image X. We demonstrate the effectiveness of our approach through\nexperiments on synthetic and real-world datasets."}
{"id": "2505.12761", "pdf": "https://arxiv.org/pdf/2505.12761", "abs": "https://arxiv.org/abs/2505.12761", "authors": ["Donghwa Shin", "Edwin Zhang"], "title": "Enhancing Channel-Independent Time Series Forecasting via Cross-Variate Patch Embedding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformers have recently gained popularity in time series forecasting due\nto their ability to capture long-term dependencies. However, many existing\nmodels focus only on capturing temporal dependencies while omitting intricate\nrelationships between variables. Recent models have tried tackling this by\nexplicitly modeling both cross-time and cross-variate dependencies through a\nsequential or unified attention mechanism, but they are entirely channel\ndependent (CD) across all layers, making them potentially susceptible to\noverfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE),\na lightweight CD module that injects cross-variate context into\nchannel-independent (CI) models by simply modifying the patch embedding\nprocess. We achieve this by adding a learnable positional encoding and a\nlightweight router-attention block to the vanilla patch embedding layer. We\nthen integrate CVPE into Time-LLM, a multimodal CI forecasting model, to\ndemonstrate its effectiveness in capturing cross-variate dependencies and\nenhance the CI model's performance. Extensive experimental results on seven\nreal-world datasets show that our enhanced Time-LLM outperforms the original\nbaseline model simply by incorporating the CVPE module, with no other changes."}
{"id": "2505.13353", "pdf": "https://arxiv.org/pdf/2505.13353", "abs": "https://arxiv.org/abs/2505.13353", "authors": ["Adam ≈†torek", "Mukur Gupta", "Samira Hajizadeh", "Prashast Srivastava", "Suman Jana"], "title": "Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning", "categories": ["cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "Although modern Large Language Models (LLMs) support extremely large\ncontexts, their effectiveness in utilizing long context for code reasoning\nremains unclear. This paper investigates LLM reasoning ability over code\nsnippets within large repositories and how it relates to their recall ability.\nSpecifically, we differentiate between lexical code recall (verbatim retrieval)\nand semantic code recall (remembering what the code does). To measure semantic\nrecall, we propose SemTrace, a code reasoning technique where the impact of\nspecific statements on output is attributable and unpredictable. We also\npresent a method to quantify semantic recall sensitivity in existing\nbenchmarks. Our evaluation of state-of-the-art LLMs reveals a significant drop\nin code reasoning accuracy as a code snippet approaches the middle of the input\ncontext, particularly with techniques requiring high semantic recall like\nSemTrace. Moreover, we find that lexical recall varies by granularity, with\nmodels excelling at function retrieval but struggling with line-by-line recall.\nNotably, a disconnect exists between lexical and semantic recall, suggesting\ndifferent underlying mechanisms. Finally, our findings indicate that current\ncode reasoning benchmarks may exhibit low semantic recall sensitivity,\npotentially underestimating LLM challenges in leveraging in-context\ninformation."}
{"id": "2502.08585", "pdf": "https://arxiv.org/pdf/2502.08585", "abs": "https://arxiv.org/abs/2502.08585", "authors": ["Peiyao Xiao", "Chaosheng Dong", "Shaofeng Zou", "Kaiyi Ji"], "title": "LDC-MTL: Balancing Multi-Task Learning through Scalable Loss Discrepancy Control", "categories": ["cs.LG"], "comment": null, "summary": "Multi-task learning (MTL) has been widely adopted for its ability to\nsimultaneously learn multiple tasks. While existing gradient manipulation\nmethods often yield more balanced solutions than simple scalarization-based\napproaches, they typically incur a significant computational overhead of\n$\\mathcal{O}(K)$ in both time and memory, where $K$ is the number of tasks. In\nthis paper, we propose LDC-MTL, a simple and scalable loss discrepancy control\napproach for MTL, formulated from a bilevel optimization perspective. Our\nmethod incorporates three key components: (i) a coarse loss pre-normalization,\n(ii) a bilevel formulation for fine-grained loss discrepancy control, and (iii)\na scalable first-order bilevel algorithm that requires only $\\mathcal{O}(1)$\ntime and memory. Theoretically, we prove that LDC-MTL guarantees convergence\nnot only to a stationary point of the bilevel problem with loss discrepancy\ncontrol but also to an $\\epsilon$-accurate Pareto stationary point for all $K$\nloss functions under mild conditions. Extensive experiments on diverse\nmulti-task datasets demonstrate the superior performance of LDC-MTL in both\naccuracy and efficiency. Code is available at\nhttps://github.com/OptMN-Lab/LDC-MTL."}
{"id": "2505.12909", "pdf": "https://arxiv.org/pdf/2505.12909", "abs": "https://arxiv.org/abs/2505.12909", "authors": ["Alberto Fern√°ndez-Hern√°ndez", "Jose I. Mestre", "Manuel F. Dolz", "Jose Duato", "Enrique S. Quintana-Ort√≠"], "title": "Sinusoidal Initialization, Time for a New Start", "categories": ["cs.LG", "cs.AI", "I.2; G.3; I.2.6"], "comment": null, "summary": "Initialization plays a critical role in Deep Neural Network training,\ndirectly influencing convergence, stability, and generalization. Common\napproaches such as Glorot and He initializations rely on randomness, which can\nproduce uneven weight distributions across layer connections. In this paper, we\nintroduce the Sinusoidal initialization, a novel deterministic method that\nemploys sinusoidal functions to construct structured weight matrices expressly\nto improve the spread and balance of weights throughout the network while\nsimultaneously fostering a more uniform, well-conditioned distribution of\nneuron activation states from the very first forward pass. Because Sinusoidal\ninitialization begins with weights and activations that are already evenly and\nefficiently utilized, it delivers consistently faster convergence, greater\ntraining stability, and higher final accuracy across a wide range of models,\nincluding convolutional neural networks, vision transformers, and large\nlanguage models. On average, our experiments show an increase of 4.9% in final\nvalidation accuracy and 20.9% in convergence speed. By replacing randomness\nwith structure, this initialization provides a stronger and more reliable\nfoundation for Deep Learning systems."}
{"id": "2407.02855", "pdf": "https://arxiv.org/pdf/2407.02855", "abs": "https://arxiv.org/abs/2407.02855", "authors": ["Zhexin Zhang", "Junxiao Yang", "Yida Lu", "Pei Ke", "Shiyao Cui", "Chujie Zheng", "Hongning Wang", "Minlie Huang"], "title": "From Theft to Bomb-Making: The Ripple Effect of Unlearning in Defending Against Jailbreak Attacks", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": "19 pages", "summary": "Large Language Models (LLMs) are known to be vulnerable to jailbreak attacks.\nAn important observation is that, while different types of jailbreak attacks\ncan generate significantly different queries, they mostly result in similar\nresponses that are rooted in the same harmful knowledge (e.g., detailed steps\nto make a bomb). Consequently, unlearning-based approaches have been proposed\nto mitigate jailbreak attacks by directly removing harmful knowledge from the\nmodel. In this paper, we identify a novel ripple effect of unlearning, wherein\nLLMs can implicitly unlearn harmful knowledge that was not explicitly\nintroduced during the unlearning phase (e.g., a model unlearning the steps for\ntheft may also implicitly unlearn the steps for making a bomb). Through over\n100 experimental runs spanning multiple models, attack strategies, and defense\nmethods, we empirically validate this phenomenon, which makes unlearning-based\nmethods able to decrease the Attack Success Rate on unseen data from more than\n70% to less than 10% with only 100 training samples. Further analysis reveals\nthat the strong generalization ability of unlearning may stem from the\nintrinsic relatedness among harmful responses across harmful questions (e.g.,\nresponse patterns, shared steps and actions in response, and similarity among\ntheir learned representations in the LLM). We also discuss the potential\nlimitations of unlearning and the observed ripple effect. We hope our research\ncould contribute to a deeper understanding of unlearning. Our code is available\nat https://github.com/thu-coai/SafeUnlearning."}
{"id": "2502.09890", "pdf": "https://arxiv.org/pdf/2502.09890", "abs": "https://arxiv.org/abs/2502.09890", "authors": ["Vinh Tong", "Trung-Dung Hoang", "Anji Liu", "Guy Van den Broeck", "Mathias Niepert"], "title": "Rao-Blackwell Gradient Estimators for Equivariant Denoising Diffusion", "categories": ["cs.LG"], "comment": null, "summary": "In domains such as molecular and protein generation, physical systems exhibit\ninherent symmetries that are critical to model. Two main strategies have\nemerged for learning invariant distributions: designing equivariant network\narchitectures and using data augmentation to approximate equivariance. While\nequivariant architectures preserve symmetry by design, they often involve\ngreater complexity and pose optimization challenges. Data augmentation, on the\nother hand, offers flexibility but may fall short in fully capturing\nsymmetries. Our framework enhances both approaches by reducing training\nvariance and providing a provably lower-variance gradient estimator. We achieve\nthis by interpreting data augmentation as a Monte Carlo estimator of the\ntraining gradient and applying Rao-Blackwellization. This leads to more stable\noptimization, faster convergence, and reduced variance, all while requiring\nonly a single forward and backward pass per sample. We also present a practical\nimplementation of this estimator incorporating the loss and sampling procedure\nthrough a method we call Orbit Diffusion. Theoretically, we guarantee that our\nloss admits equivariant minimizers. Empirically, Orbit Diffusion achieves\nstate-of-the-art results on GEOM-QM9 for molecular conformation generation,\nimproves crystal structure prediction, and advances text-guided crystal\ngeneration on the Perov-5 and MP-20 benchmarks. Additionally, it enhances\nprotein designability in protein structure generation."}
{"id": "2505.12938", "pdf": "https://arxiv.org/pdf/2505.12938", "abs": "https://arxiv.org/abs/2505.12938", "authors": ["Uri Dalal", "Meirav Segal", "Zvika Ben-Haim", "Dan Lahav", "Omer Nevo"], "title": "Leveraging LLM Inconsistency to Boost Pass@k Performance", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) achieve impressive abilities in numerous\ndomains, but exhibit inconsistent performance in response to minor input\nchanges. Rather than view this as a drawback, in this paper we introduce a\nnovel method for leveraging models' inconsistency to boost Pass@k performance.\nSpecifically, we present a \"Variator\" agent that generates k variants of a\ngiven task and submits one candidate solution for each one. Our variant\ngeneration approach is applicable to a wide range of domains as it is task\nagnostic and compatible with free-form inputs. We demonstrate the efficacy of\nour agent theoretically using a probabilistic model of the inconsistency\neffect, and show empirically that it outperforms the baseline on the APPS\ndataset. Furthermore, we establish that inconsistency persists even in frontier\nreasoning models across coding and cybersecurity domains, suggesting our method\nis likely to remain relevant for future model generations."}
{"id": "2412.04756", "pdf": "https://arxiv.org/pdf/2412.04756", "abs": "https://arxiv.org/abs/2412.04756", "authors": ["Shivansh Chopra", "Hussain Ahmad", "Diksha Goel", "Claudia Szabo"], "title": "ChatNVD: Advancing Cybersecurity Vulnerability Assessment with Large Language Models", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "The increasing frequency and sophistication of cybersecurity vulnerabilities\nin software systems underscores the need for more robust and effective\nvulnerability assessment methods. However, existing approaches often rely on\nhighly technical and abstract frameworks, which hinder understanding and\nincrease the likelihood of exploitation, resulting in severe cyberattacks. In\nthis paper, we introduce ChatNVD, a support tool powered by Large Language\nModels (LLMs) that leverages the National Vulnerability Database (NVD) to\ngenerate accessible, context-rich summaries of software vulnerabilities. We\ndevelop three variants of ChatNVD, utilizing three prominent LLMs: GPT-4o Mini\nby OpenAI, LLaMA 3 by Meta, and Gemini 1.5 Pro by Google. To evaluate their\nperformance, we conduct a comparative evaluation focused on their ability to\nidentify, interpret, and explain software vulnerabilities. Our results\ndemonstrate that GPT-4o Mini outperforms the other models, achieving over 92%\naccuracy and the lowest error rates, making it the most reliable option for\nreal-world vulnerability assessment."}
{"id": "2502.09981", "pdf": "https://arxiv.org/pdf/2502.09981", "abs": "https://arxiv.org/abs/2502.09981", "authors": ["Harsh Poonia", "Felix Divo", "Kristian Kersting", "Devendra Singh Dhami"], "title": "Exploring Neural Granger Causality with xLSTMs: Unveiling Temporal Dependencies in Complex Data", "categories": ["cs.LG", "I.2.6"], "comment": null, "summary": "Causality in time series can be difficult to determine, especially in the\npresence of non-linear dependencies. The concept of Granger causality helps\nanalyze potential relationships between variables, thereby offering a method to\ndetermine whether one time series can predict - Granger cause - future values\nof another. Although successful, Granger causal methods still struggle with\ncapturing long-range relations between variables. To this end, we leverage the\nrecently successful Extended Long Short-Term Memory (xLSTM) architecture and\npropose Granger causal xLSTMs (GC-xLSTM). It first enforces sparsity between\nthe time series components by using a novel dynamic loss penalty on the initial\nprojection. Specifically, we adaptively improve the model and identify sparsity\ncandidates. Our joint optimization procedure then ensures that the Granger\ncausal relations are recovered robustly. Our experimental evaluation on six\ndiverse datasets demonstrates the overall efficacy of our proposed GC-xLSTM\nmodel."}
{"id": "2505.12981", "pdf": "https://arxiv.org/pdf/2505.12981", "abs": "https://arxiv.org/abs/2505.12981", "authors": ["Liangxuan Wu", "Chao Wang", "Tianming Liu", "Yanjie Zhao", "Haoyu Wang"], "title": "From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents", "categories": ["cs.CR", "cs.AI", "cs.HC"], "comment": null, "summary": "The growing adoption of large language models (LLMs) has led to a new\nparadigm in mobile computing--LLM-powered mobile AI agents--capable of\ndecomposing and automating complex tasks directly on smartphones. However, the\nsecurity implications of these agents remain largely unexplored. In this paper,\nwe present the first comprehensive security analysis of mobile LLM agents,\nencompassing three representative categories: System-level AI Agents developed\nby original equipment manufacturers (e.g., YOYO Assistant), Third-party\nUniversal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g.,\nAlibaba Mobile Agent). We begin by analyzing the general workflow of mobile\nagents and identifying security threats across three core capability\ndimensions: language-based reasoning, GUI-based interaction, and system-level\nexecution. Our analysis reveals 11 distinct attack surfaces, all rooted in the\nunique capabilities and interaction patterns of mobile LLM agents, and spanning\ntheir entire operational lifecycle. To investigate these threats in practice,\nwe introduce AgentScan, a semi-automated security analysis framework that\nsystematically evaluates mobile LLM agents across all 11 attack scenarios.\nApplying AgentScan to nine widely deployed agents, we uncover a concerning\ntrend: every agent is vulnerable to targeted attacks. In the most severe cases,\nagents exhibit vulnerabilities across eight distinct attack vectors. These\nattacks can cause behavioral deviations, privacy leakage, or even full\nexecution hijacking. Based on these findings, we propose a set of defensive\ndesign principles and practical recommendations for building secure mobile LLM\nagents. Our disclosures have received positive feedback from two major device\nvendors. Overall, this work highlights the urgent need for standardized\nsecurity practices in the fast-evolving landscape of LLM-driven mobile\nautomation."}
{"id": "2502.00198", "pdf": "https://arxiv.org/pdf/2502.00198", "abs": "https://arxiv.org/abs/2502.00198", "authors": ["Luyang Zhang", "Cathy Jiao", "Beibei Li", "Chenyan Xiong"], "title": "Fairshare Data Pricing via Data Valuation for Large Language Models", "categories": ["cs.GT", "cs.CL"], "comment": null, "summary": "Training data is the backbone of large language models (LLMs), yet today's\ndata markets often operate under exploitative pricing -- sourcing data from\nmarginalized groups with little pay or recognition. This paper introduces a\ntheoretical framework for LLM data markets, modeling the strategic interactions\nbetween buyers (LLM builders) and sellers (human annotators). We begin with\ntheoretical and empirical analysis showing how exploitative pricing drives\nhigh-quality sellers out of the market, degrading data quality and long-term\nmodel performance. Then we introduce fairshare, a pricing mechanism grounded in\ndata valuation that quantifies each data's contribution. It aligns incentives\nby sustaining seller participation and optimizing utility for both buyers and\nsellers. Theoretically, we show that fairshare yields mutually optimal\noutcomes: maximizing long-term buyer utility and seller profit while sustaining\nmarket participation. Empirically when training open-source LLMs on complex NLP\ntasks, including math problems, medical diagnosis, and physical reasoning,\nfairshare boosts seller earnings and ensures a stable supply of high-quality\ndata, while improving buyers' performance-per-dollar and long-term welfare. Our\nfindings offer a concrete path toward fair, transparent, and economically\nsustainable data markets for LLM. Our code will be open sourced."}
{"id": "2502.10095", "pdf": "https://arxiv.org/pdf/2502.10095", "abs": "https://arxiv.org/abs/2502.10095", "authors": ["Achmad Ginanjar", "Xue Li", "Priyanka Singh", "Wen Hua"], "title": "Representation Learning on Out of Distribution in Tabular Data", "categories": ["cs.LG"], "comment": "Accepted on IEEE IAICT 2025", "summary": "The open-world assumption in model development suggests that a model might\nlack sufficient information to adequately handle data that is entirely distinct\nor out of distribution (OOD). While deep learning methods have shown promising\nresults in handling OOD data through generalization techniques, they often\nrequire specialized hardware that may not be accessible to all users. We\npresent TCL, a lightweight yet effective solution that operates efficiently on\nstandard CPU hardware. Our approach adapts contrastive learning principles\nspecifically for tabular data structures, incorporating full matrix\naugmentation and simplified loss calculation. Through comprehensive experiments\nacross 10 diverse datasets, we demonstrate that TCL outperforms existing\nmodels, including FT-Transformer and ResNet, particularly in classification\ntasks, while maintaining competitive performance in regression problems. TCL\nachieves these results with significantly reduced computational requirements,\nmaking it accessible to users with limited hardware capabilities. This study\nalso provides practical guidance for detecting and evaluating OOD data through\nstraightforward experiments and visualizations. Our findings show that TCL\noffers a promising balance between performance and efficiency in handling OOD\nprediction tasks, which is particularly beneficial for general machine learning\npractitioners working with computational constraints."}
{"id": "2505.13028", "pdf": "https://arxiv.org/pdf/2505.13028", "abs": "https://arxiv.org/abs/2505.13028", "authors": ["Sayon Palit", "Daniel Woods"], "title": "Evaluating the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset", "categories": ["cs.CR", "cs.AI", "cs.CL", "F.2.2; I.2.7; F.2.2; I.2.7; F.2.2; I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into critical\nsystems in industries like healthcare and finance. Users can often submit\nqueries to LLM-enabled chatbots, some of which can enrich responses with\ninformation retrieved from internal databases storing sensitive data. This\ngives rise to a range of attacks in which a user submits a malicious query and\nthe LLM-system outputs a response that creates harm to the owner, such as\nleaking internal data or creating legal liability by harming a third-party.\nWhile security tools are being developed to counter these threats, there is\nlittle formal evaluation of their effectiveness and usability. This study\naddresses this gap by conducting a thorough comparative analysis of LLM\nsecurity tools. We identified 13 solutions (9 closed-source, 4 open-source),\nbut only 7 were evaluated due to a lack of participation by proprietary model\nowners.To evaluate, we built a benchmark dataset of malicious prompts, and\nevaluate these tools performance against a baseline LLM model\n(ChatGPT-3.5-Turbo). Our results show that the baseline model has too many\nfalse positives to be used for this task. Lakera Guard and ProtectAI LLM Guard\nemerged as the best overall tools showcasing the tradeoff between usability and\nperformance. The study concluded with recommendations for greater transparency\namong closed source providers, improved context-aware detections, enhanced\nopen-source engagement, increased user awareness, and the adoption of more\nrepresentative performance metrics."}
{"id": "2502.18167", "pdf": "https://arxiv.org/pdf/2502.18167", "abs": "https://arxiv.org/abs/2502.18167", "authors": ["Xiao Shao", "Guoqiang Wu"], "title": "Sharper Risk Bound for Multi-Task Learning with Multi-Graph Dependent Data", "categories": ["cs.LG", "stat.ML"], "comment": "46 pages", "summary": "In multi-task learning (MTL) with each task involving graph-dependent data,\nexisting generalization analyses yield a \\emph{sub-optimal} risk bound of\n$O(\\frac{1}{\\sqrt{n}})$, where $n$ is the number of training samples of each\ntask. However, to improve the risk bound is technically challenging, which is\nattributed to the lack of a foundational sharper concentration inequality for\nmulti-graph dependent random variables. To fill up this gap, this paper\nproposes a new Bennett-type inequality, enabling the derivation of a sharper\nrisk bound of $O(\\frac{\\log n}{n})$. Technically, building on the proposed\nBennett-type inequality, we propose a new Talagrand-type inequality for the\nempirical process, and further develop a new analytical framework of the local\nfractional Rademacher complexity to enhance generalization analyses in MTL with\nmulti-graph dependent data. Finally, we apply the theoretical advancements to\napplications such as Macro-AUC optimization, illustrating the superiority of\nour theoretical results over prior work, which is also verified by experimental\nresults."}
{"id": "2505.13358", "pdf": "https://arxiv.org/pdf/2505.13358", "abs": "https://arxiv.org/abs/2505.13358", "authors": ["Nimrod Berman", "Ilan Naiman", "Moshe Eliasof", "Hedi Zisling", "Omri Azencot"], "title": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion-based generative models have demonstrated exceptional performance,\nyet their iterative sampling procedures remain computationally expensive. A\nprominent strategy to mitigate this cost is distillation, with offline\ndistillation offering particular advantages in terms of efficiency, modularity,\nand flexibility. In this work, we identify two key observations that motivate a\nprincipled distillation framework: (1) while diffusion models have been viewed\nthrough the lens of dynamical systems theory, powerful and underexplored tools\ncan be further leveraged; and (2) diffusion models inherently impose\nstructured, semantically coherent trajectories in latent space. Building on\nthese observations, we introduce the Koopman Distillation Model KDM, a novel\noffline distillation approach grounded in Koopman theory-a classical framework\nfor representing nonlinear dynamics linearly in a transformed space. KDM\nencodes noisy inputs into an embedded space where a learned linear operator\npropagates them forward, followed by a decoder that reconstructs clean samples.\nThis enables single-step generation while preserving semantic fidelity. We\nprovide theoretical justification for our approach: (1) under mild assumptions,\nthe learned diffusion dynamics admit a finite-dimensional Koopman\nrepresentation; and (2) proximity in the Koopman latent space correlates with\nsemantic similarity in the generated outputs, allowing for effective trajectory\nalignment. Empirically, KDM achieves state-of-the-art performance across\nstandard offline distillation benchmarks, improving FID scores by up to 40% in\na single generation step. All implementation details and code for the\nexperimental setups are provided in our GitHub -\nhttps://github.com/azencot-group/KDM, or in our project page -\nhttps://sites.google.com/view/koopman-distillation-model."}
{"id": "2503.14476", "pdf": "https://arxiv.org/pdf/2503.14476", "abs": "https://arxiv.org/abs/2503.14476", "authors": ["Qiying Yu", "Zheng Zhang", "Ruofei Zhu", "Yufeng Yuan", "Xiaochen Zuo", "Yu Yue", "Weinan Dai", "Tiantian Fan", "Gaohong Liu", "Lingjun Liu", "Xin Liu", "Haibin Lin", "Zhiqi Lin", "Bole Ma", "Guangming Sheng", "Yuxuan Tong", "Chi Zhang", "Mofan Zhang", "Wang Zhang", "Hang Zhu", "Jinhua Zhu", "Jiaze Chen", "Jiangjie Chen", "Chengyi Wang", "Hongli Yu", "Yuxuan Song", "Xiangpeng Wei", "Hao Zhou", "Jingjing Liu", "Wei-Ying Ma", "Ya-Qin Zhang", "Lin Yan", "Mu Qiao", "Yonghui Wu", "Mingxuan Wang"], "title": "DAPO: An Open-Source LLM Reinforcement Learning System at Scale", "categories": ["cs.LG", "cs.CL"], "comment": "Project Page: https://dapo-sia.github.io/", "summary": "Inference scaling empowers LLMs with unprecedented reasoning ability, with\nreinforcement learning as the core technique to elicit complex reasoning.\nHowever, key technical details of state-of-the-art reasoning LLMs are concealed\n(such as in OpenAI o1 blog and DeepSeek R1 technical report), thus the\ncommunity still struggles to reproduce their RL training results. We propose\nthe $\\textbf{D}$ecoupled Clip and $\\textbf{D}$ynamic s$\\textbf{A}$mpling\n$\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{DAPO}$) algorithm, and\nfully open-source a state-of-the-art large-scale RL system that achieves 50\npoints on AIME 2024 using Qwen2.5-32B base model. Unlike previous works that\nwithhold training details, we introduce four key techniques of our algorithm\nthat make large-scale LLM RL a success. In addition, we open-source our\ntraining code, which is built on the verl framework, along with a carefully\ncurated and processed dataset. These components of our open-source system\nenhance reproducibility and support future research in large-scale LLM RL."}
{"id": "2502.20139", "pdf": "https://arxiv.org/pdf/2502.20139", "abs": "https://arxiv.org/abs/2502.20139", "authors": ["J. Schmidinger", "S. Vogel", "V. Barkov", "A. -D. Pham", "R. Gebbers", "H. Tavakoli", "J. Correa", "T. R. Tavares", "P. Filippi", "E. J. Jones", "V. Lukas", "E. Boenecke", "J. Ruehlmann", "I. Schroeter", "E. Kramer", "S. Paetzold", "M. Kodaira", "A. M. J. -C. Wadoux", "L. Bragazza", "K. Metzger", "J. Huang", "D. S. M. Valente", "J. L. Safanelli", "E. L. Bottega", "R. S. D. Dalmolin", "C. Farkas", "A. Steiger", "T. Z. Horst", "L. Ramirez-Lopez", "T. Scholten", "F. Stumpf", "P. Rosso", "M. M. Costa", "R. S. Zandonadi", "J. Wetterlind", "M. Atzmueller"], "title": "LimeSoDa: A Dataset Collection for Benchmarking of Machine Learning Regressors in Digital Soil Mapping", "categories": ["cs.LG"], "comment": null, "summary": "Digital soil mapping (DSM) relies on a broad pool of statistical methods, yet\ndetermining the optimal method for a given context remains challenging and\ncontentious. Benchmarking studies on multiple datasets are needed to reveal\nstrengths and limitations of commonly used methods. Existing DSM studies\nusually rely on a single dataset with restricted access, leading to incomplete\nand potentially misleading conclusions. To address these issues, we introduce\nan open-access dataset collection called Precision Liming Soil Datasets\n(LimeSoDa). LimeSoDa consists of 31 field- and farm-scale datasets from various\ncountries. Each dataset has three target soil properties: (1) soil organic\nmatter or soil organic carbon, (2) clay content and (3) pH, alongside a set of\nfeatures. Features are dataset-specific and were obtained by optical\nspectroscopy, proximal- and remote soil sensing. All datasets were aligned to a\ntabular format and are ready-to-use for modeling. We demonstrated the use of\nLimeSoDa for benchmarking by comparing the predictive performance of four\nlearning algorithms across all datasets. This comparison included multiple\nlinear regression (MLR), support vector regression (SVR), categorical boosting\n(CatBoost) and random forest (RF). The results showed that although no single\nalgorithm was universally superior, certain algorithms performed better in\nspecific contexts. MLR and SVR performed better on high-dimensional spectral\ndatasets, likely due to better compatibility with principal components. In\ncontrast, CatBoost and RF exhibited considerably better performances when\napplied to datasets with a moderate number (< 20) of features. These\nbenchmarking results illustrate that the performance of a method is highly\ncontext-dependent. LimeSoDa therefore provides an important resource for\nimproving the development and evaluation of statistical methods in DSM."}
{"id": "2503.16505", "pdf": "https://arxiv.org/pdf/2503.16505", "abs": "https://arxiv.org/abs/2503.16505", "authors": ["Dimitris Tsirmpas", "Ion Androutsopoulos", "John Pavlopoulos"], "title": "Scalable Evaluation of Online Facilitation Strategies via Synthetic Simulation of Discussions", "categories": ["cs.HC", "cs.CL", "cs.LG", "68T50", "I.2.7"], "comment": "19 pages, 3 tables, 12 figures", "summary": "Limited large-scale evaluations exist for facilitation strategies of online\ndiscussions due to significant costs associated with human involvement. An\neffective solution is synthetic discussion simulations using Large Language\nModels (LLMs) to create initial pilot experiments. We propose a simple,\ngeneralizable, LLM-driven methodology to prototype the development of LLM\nfacilitators, and produce high-quality synthetic data without human\ninvolvement. We use our methodology to test whether current facilitation\nstrategies can improve the performance of LLM facilitators. We find that, while\nLLM facilitators significantly improve synthetic discussions, there is no\nevidence that the application of more elaborate facilitation strategies\nproposed in modern Social Science research lead to further improvements in\ndiscussion quality, compared to more basic approaches. Additionally, we find\nthat small LLMs (such as Mistral Nemo 12B) can perform comparably to larger\nmodels (such as LLaMa 70B), and that special instructions must be used for\ninstruction-tuned models to induce toxicity in synthetic discussions. We\nconfirm that each component of our methodology contributes substantially to\nhigh quality data via an ablation study. We release an open-source framework,\n\"SynDisco\" (pip install syndisco), which implements our methodology. We also\nrelease the \"Virtual Moderation Dataset\"\n(https://paperswithcode.com/dataset/vmd), a large, publicly available dataset\ncontaining LLM-generated and LLM-annotated discussions using multiple\nopen-source LLMs."}
{"id": "2503.01598", "pdf": "https://arxiv.org/pdf/2503.01598", "abs": "https://arxiv.org/abs/2503.01598", "authors": ["Masoud Kavian", "Romain Chor", "Milad Sefidgaran", "Abdellatif Zaidi"], "title": "Heterogeneity Matters even More in Distributed Learning: Study from Generalization Perspective", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "comment": "47 pages, 13 figures", "summary": "In this paper, we investigate the effect of data heterogeneity across clients\non the performance of distributed learning systems, i.e., one-round Federated\nLearning, as measured by the associated generalization error. Specifically, $K$\nclients have each $n$ training samples generated independently according to a\npossibly different data distribution, and their individually chosen models are\naggregated by a central server. We study the effect of the discrepancy between\nthe clients' data distributions on the generalization error of the aggregated\nmodel. First, we establish in-expectation and tail upper bounds on the\ngeneralization error in terms of the distributions. In part, the bounds extend\nthe popular Conditional Mutual Information (CMI) bound, which was developed for\nthe centralized learning setting, i.e., $K=1$, to the distributed learning\nsetting with an arbitrary number of clients $K \\geq 1$. Then, we connect with\ninformation-theoretic rate-distortion theory to derive possibly tighter\n\\textit{lossy} versions of these bounds. Next, we apply our lossy bounds to\nstudy the effect of data heterogeneity across clients on the generalization\nerror for the distributed classification problem in which each client uses\nSupport Vector Machines (DSVM). In this case, we establish explicit\ngeneralization error bounds that depend explicitly on the data heterogeneity\ndegree. It is shown that the bound gets smaller as the degree of data\nheterogeneity across clients increases, thereby suggesting that DSVM\ngeneralizes better when the dissimilarity between the clients' training samples\nis bigger. This finding, which goes beyond DSVM, is validated experimentally\nthrough several experiments."}
{"id": "2504.21751", "pdf": "https://arxiv.org/pdf/2504.21751", "abs": "https://arxiv.org/abs/2504.21751", "authors": ["Sizhe Wang", "Zhengren Wang", "Dongsheng Ma", "Yongan Yu", "Rui Ling", "Zhiyu Li", "Feiyu Xiong", "Wentao Zhang"], "title": "CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Modern software development demands code that is maintainable, testable, and\nscalable by organizing the implementation into modular components with\niterative reuse of existing codes. We formalize this iterative, multi-turn\nparadigm as codeflow and introduce CodeFlowBench, the first benchmark designed\nto comprehensively evaluate LLMs' ability to perform codeflow, namely\nimplementing new functionality by reusing existing functions over multiple\nturns. CodeFlowBench comprises 5,258 problems from Codeforces and is\ncontinuously updated via an automated pipeline, which decomposes each problem\ninto subproblems with unit tests based on dependency tree analysis and dataflow\nanalysis. We further propose a novel evaluation framework featured dual\nassessment protocol and structural metrics derived from dependency trees.\nExtensive experiments on 16 popular LLMs reveal significant performance\ndegradation in multi-turn scenarios. For instance, o1-mini retains only 20.8%\nPass@1 in multi-turn scenario versus 37.8% in single-turn scenario. More\nfine-grained analysis illustrates that model performance inversely correlates\nwith dependency complexity. These findings not only highlight the critical\nchallenges for supporting real-world workflows, but also establish\nCodeFlowBench as an essential tool for advancing code generation research."}
{"id": "2503.04582", "pdf": "https://arxiv.org/pdf/2503.04582", "abs": "https://arxiv.org/abs/2503.04582", "authors": ["Th√©o Gnassounou", "Antoine Collas", "R√©mi Flamary", "Alexandre Gramfort"], "title": "PSDNorm: Test-Time Temporal Normalization for Deep Learning in Sleep Staging", "categories": ["cs.LG"], "comment": null, "summary": "Distribution shift poses a significant challenge in machine learning,\nparticularly in biomedical applications using data collected across different\nsubjects, institutions, and recording devices, such as sleep data. While\nexisting normalization layers, BatchNorm, LayerNorm and InstanceNorm, help\nmitigate distribution shifts, when applied over the time dimension they ignore\nthe dependencies and auto-correlation inherent to the vector coefficients they\nnormalize. In this paper, we propose PSDNorm that leverages Monge mapping and\ntemporal context to normalize feature maps in deep learning models for signals.\nNotably, the proposed method operates as a test-time domain adaptation\ntechnique, addressing distribution shifts without additional training.\nEvaluations with architectures based on U-Net or transformer backbones trained\non 10K subjects across 10 datasets, show that PSDNorm achieves state-of-the-art\nperformance on unseen left-out datasets while being 4-times more data-efficient\nthan BatchNorm."}
{"id": "2505.07558", "pdf": "https://arxiv.org/pdf/2505.07558", "abs": "https://arxiv.org/abs/2505.07558", "authors": ["Rei Higuchi", "Taiji Suzuki"], "title": "Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": null, "summary": "Aligning large language models (LLMs) with human preferences is crucial for\nsafe deployment, yet existing methods assume specific preference models like\nBradley-Terry model. This assumption leads to statistical inconsistency, where\nmore data doesn't guarantee convergence to true human preferences. To address\nthis critical gap, we introduce a novel alignment method Direct Density Ratio\nOptimization (DDRO). DDRO directly estimates the density ratio between\npreferred and unpreferred output distributions, circumventing the need for\nexplicit human preference modeling. We theoretically prove that DDRO is\nstatistically consistent, ensuring convergence to the true preferred\ndistribution as the data size grows, regardless of the underlying preference\nstructure. Experiments demonstrate that DDRO achieves superior performance\ncompared to existing methods on many major benchmarks. DDRO unlocks the\npotential for truly data-driven alignment, paving the way for more reliable and\nhuman-aligned LLMs."}
{"id": "2503.11126", "pdf": "https://arxiv.org/pdf/2503.11126", "abs": "https://arxiv.org/abs/2503.11126", "authors": ["Vu Nguyen", "Andrey Kan"], "title": "MUSS: Multilevel Subset Selection for Relevance and Diversity", "categories": ["cs.LG"], "comment": "model in production at Amazon", "summary": "The problem of relevant and diverse subset selection has a wide range of\napplications, including recommender systems and retrieval-augmented generation\n(RAG). For example, in recommender systems, one is interested in selecting\nrelevant items, while providing a diversified recommendation. Constrained\nsubset selection problem is NP-hard, and popular approaches such as Maximum\nMarginal Relevance (MMR) are based on greedy selection. Many real-world\napplications involve large data, but the original MMR work did not consider\ndistributed selection. This limitation was later addressed by a method called\nDGDS which allows for a distributed setting using random data partitioning.\nHere, we exploit structure in the data to further improve both scalability and\nperformance on the target application. We propose MUSS, a novel method that\nuses a multilevel approach to relevant and diverse selection. In a recommender\nsystem application, our method can not only improve the performance up to $4$\npercent points in precision, but is also $20$ to $80$ times faster. Our method\nis also capable of outperforming baselines on RAG-based question answering\naccuracy. We present a novel theoretical approach for analyzing this type of\nproblems, and show that our method achieves a constant factor approximation of\nthe optimal objective. Moreover, our analysis also resulted in a $\\times 2$\ntighter bound for DGDS compared to previously known bound."}
{"id": "2504.14854", "pdf": "https://arxiv.org/pdf/2504.14854", "abs": "https://arxiv.org/abs/2504.14854", "authors": ["Cosmin Safta", "Reese E. Jones", "Ravi G. Patel", "Raelynn Wonnacot", "Dan S. Bolintineanu", "Craig M. Hamel", "Sharlotte L. B. Kramer"], "title": "Uncertainty quantification of neural network models of evolving processes via Langevin sampling", "categories": ["cs.LG", "stat.ML"], "comment": "23 pages, 14 figures", "summary": "We propose a scalable, approximate inference hypernetwork framework for a\ngeneral model of history-dependent processes. The flexible data model is based\non a neural ordinary differential equation (NODE) representing the evolution of\ninternal states together with a trainable observation model subcomponent. The\nposterior distribution corresponding to the data model parameters (weights and\nbiases) follows a stochastic differential equation with a drift term related to\nthe score of the posterior that is learned jointly with the data model\nparameters. This Langevin sampling approach offers flexibility in balancing the\ncomputational budget between the evaluation cost of the data model and the\napproximation of the posterior density of its parameters. We demonstrate\nperformance of the ensemble sampling hypernetwork on chemical reaction and\nmaterial physics data and compare it to standard variational inference."}
{"id": "2504.16318", "pdf": "https://arxiv.org/pdf/2504.16318", "abs": "https://arxiv.org/abs/2504.16318", "authors": ["Kisung You"], "title": "Semantics at an Angle: When Cosine Similarity Works Until It Doesn't", "categories": ["cs.LG"], "comment": null, "summary": "Cosine similarity has become a standard metric for comparing embeddings in\nmodern machine learning. Its scale-invariance and alignment with model training\nobjectives have contributed to its widespread adoption. However, recent studies\nhave revealed important limitations, particularly when embedding norms carry\nmeaningful semantic information. This informal article offers a reflective and\nselective examination of the evolution, strengths, and limitations of cosine\nsimilarity. We highlight why it performs well in many settings, where it tends\nto break down, and how emerging alternatives are beginning to address its blind\nspots. We hope to offer a mix of conceptual clarity and practical perspective,\nespecially for quantitative scientists who think about embeddings not just as\nvectors, but as geometric and philosophical objects."}
{"id": "2504.20660", "pdf": "https://arxiv.org/pdf/2504.20660", "abs": "https://arxiv.org/abs/2504.20660", "authors": ["Sahil Tomar", "Shamshe Alam", "Sandeep Kumar", "Amit Mathur"], "title": "Quantum-Enhanced Hybrid Reinforcement Learning Framework for Dynamic Path Planning in Autonomous Systems", "categories": ["cs.LG", "cs.ET", "cs.IT", "math.IT"], "comment": "16 pages", "summary": "In this paper, a novel quantum classical hybrid framework is proposed that\nsynergizes quantum with Classical Reinforcement Learning. By leveraging the\ninherent parallelism of quantum computing, the proposed approach generates\nrobust Q tables and specialized turn cost estimations, which are then\nintegrated with a classical Reinforcement Learning pipeline. The Classical\nQuantum fusion results in rapid convergence of training, reducing the training\ntime significantly and improved adaptability in scenarios featuring static,\ndynamic, and moving obstacles. Simulator based evaluations demonstrate\nsignificant enhancements in path efficiency, trajectory smoothness, and mission\nsuccess rates, underscoring the potential of framework for real time,\nautonomous navigation in complex and unpredictable environments. Furthermore,\nthe proposed framework was tested beyond simulations on practical scenarios,\nincluding real world map data such as the IIT Delhi campus, reinforcing its\npotential for real time, autonomous navigation in complex and unpredictable\nenvironments."}
{"id": "2505.01420", "pdf": "https://arxiv.org/pdf/2505.01420", "abs": "https://arxiv.org/abs/2505.01420", "authors": ["Mary Phuong", "Roland S. Zimmermann", "Ziyue Wang", "David Lindner", "Victoria Krakovna", "Sarah Cogan", "Allan Dafoe", "Lewis Ho", "Rohin Shah"], "title": "Evaluating Frontier Models for Stealth and Situational Awareness", "categories": ["cs.LG"], "comment": null, "summary": "Recent work has demonstrated the plausibility of frontier AI models scheming\n-- knowingly and covertly pursuing an objective misaligned with its developer's\nintentions. Such behavior could be very hard to detect, and if present in\nfuture advanced systems, could pose severe loss of control risk. It is\ntherefore important for AI developers to rule out harm from scheming prior to\nmodel deployment. In this paper, we present a suite of scheming reasoning\nevaluations measuring two types of reasoning capabilities that we believe are\nprerequisites for successful scheming: First, we propose five evaluations of\nability to reason about and circumvent oversight (stealth). Second, we present\neleven evaluations for measuring a model's ability to instrumentally reason\nabout itself, its environment and its deployment (situational awareness). We\ndemonstrate how these evaluations can be used as part of a scheming inability\nsafety case: a model that does not succeed on these evaluations is almost\ncertainly incapable of causing severe harm via scheming in real deployment. We\nrun our evaluations on current frontier models and find that none of them show\nconcerning levels of either situational awareness or stealth."}
{"id": "2505.02222", "pdf": "https://arxiv.org/pdf/2505.02222", "abs": "https://arxiv.org/abs/2505.02222", "authors": ["Essential AI", ":", "Ishaan Shah", "Anthony M. Polloreno", "Karl Stratos", "Philip Monk", "Adarsh Chaluvaraju", "Andrew Hojel", "Andrew Ma", "Anil Thomas", "Ashish Tanwer", "Darsh J Shah", "Khoi Nguyen", "Kurt Smith", "Michael Callahan", "Michael Pust", "Mohit Parmar", "Peter Rushton", "Platon Mazarakis", "Ritvik Kapila", "Saurabh Srivastava", "Somanshu Singla", "Tim Romanski", "Yash Vanjani", "Ashish Vaswani"], "title": "Practical Efficiency of Muon for Pretraining", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We demonstrate that Muon, the simplest instantiation of a second-order\noptimizer, explicitly expands the Pareto frontier over AdamW on the\ncompute-time tradeoff. We find that Muon is more effective than AdamW in\nretaining data efficiency at large batch sizes, far beyond the so-called\ncritical batch size, while remaining computationally efficient, thus enabling\nmore economical training. We study the combination of Muon and the maximal\nupdate parameterization (muP) for efficient hyperparameter transfer and present\na simple telescoping algorithm that accounts for all sources of error in muP\nwhile introducing only a modest overhead in resources. We validate our findings\nthrough extensive experiments with model sizes up to four billion parameters\nand ablations on the data distribution and architecture."}
{"id": "2505.05819", "pdf": "https://arxiv.org/pdf/2505.05819", "abs": "https://arxiv.org/abs/2505.05819", "authors": ["Lorenzo Beretta"], "title": "New Statistical and Computational Results for Learning Junta Distributions", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "We study the problem of learning junta distributions on $\\{0, 1\\}^n$, where a\ndistribution is a $k$-junta if its probability mass function depends on a\nsubset of at most $k$ variables. We make two main contributions:\n  - We show that learning $k$-junta distributions is \\emph{computationally}\nequivalent to learning $k$-parity functions with noise (LPN), a landmark\nproblem in computational learning theory.\n  - We design an algorithm for learning junta distributions whose statistical\ncomplexity is optimal, up to polylogarithmic factors. Computationally, our\nalgorithm matches the complexity of previous (non-sample-optimal) algorithms.\n  Combined, our two contributions imply that our algorithm cannot be\nsignificantly improved, statistically or computationally, barring a\nbreakthrough for LPN."}
{"id": "2505.08782", "pdf": "https://arxiv.org/pdf/2505.08782", "abs": "https://arxiv.org/abs/2505.08782", "authors": ["Junghoon Justin Park", "Jiook Cha", "Samuel Yen-Chi Chen", "Huan-Hsin Tseng", "Shinjae Yoo"], "title": "Addressing the Current Challenges of Quantum Machine Learning through Multi-Chip Ensembles", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Practical Quantum Machine Learning (QML) is challenged by noise, limited\nscalability, and poor trainability in Variational Quantum Circuits (VQCs) on\ncurrent hardware. We propose a multi-chip ensemble VQC framework that\nsystematically overcomes these hurdles. By partitioning high-dimensional\ncomputations across ensembles of smaller, independently operating quantum chips\nand leveraging controlled inter-chip entanglement boundaries, our approach\ndemonstrably mitigates barren plateaus, enhances generalization, and uniquely\nreduces both quantum error bias and variance simultaneously without additional\nmitigation overhead. This allows for robust processing of large-scale data, as\nvalidated on standard benchmarks (MNIST, FashionMNIST, CIFAR-10) and a\nreal-world PhysioNet EEG dataset, aligning with emerging modular quantum\nhardware and paving the way for more scalable QML."}
{"id": "2505.11117", "pdf": "https://arxiv.org/pdf/2505.11117", "abs": "https://arxiv.org/abs/2505.11117", "authors": ["Chenhong Zhou", "Jie Chen", "Zaifeng Yang", "Ching Eng Png"], "title": "Dual-Balancing for Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "Accepted at IJCAI 2025 (34th International Joint Conference on\n  Artificial Intelligence)", "summary": "Physics-informed neural networks (PINNs) have emerged as a new learning\nparadigm for solving partial differential equations (PDEs) by enforcing the\nconstraints of physical equations, boundary conditions (BCs), and initial\nconditions (ICs) into the loss function. Despite their successes, vanilla PINNs\nstill suffer from poor accuracy and slow convergence due to the intractable\nmulti-objective optimization issue. In this paper, we propose a novel\nDual-Balanced PINN (DB-PINN), which dynamically adjusts loss weights by\nintegrating inter-balancing and intra-balancing to alleviate two imbalance\nissues in PINNs. Inter-balancing aims to mitigate the gradient imbalance\nbetween PDE residual loss and condition-fitting losses by determining an\naggregated weight that offsets their gradient distribution discrepancies.\nIntra-balancing acts on condition-fitting losses to tackle the imbalance in\nfitting difficulty across diverse conditions. By evaluating the fitting\ndifficulty based on the loss records, intra-balancing can allocate the\naggregated weight proportionally to each condition loss according to its\nfitting difficulty level. We further introduce a robust weight update strategy\nto prevent abrupt spikes and arithmetic overflow in instantaneous weight values\ncaused by large loss variances, enabling smooth weight updating and stable\ntraining. Extensive experiments demonstrate that DB-PINN achieves significantly\nsuperior performance than those popular gradient-based weighting methods in\nterms of convergence speed and prediction accuracy. Our code and supplementary\nmaterial are available at https://github.com/chenhong-zhou/DualBalanced-PINNs."}
{"id": "2505.11790", "pdf": "https://arxiv.org/pdf/2505.11790", "abs": "https://arxiv.org/abs/2505.11790", "authors": ["Jesson Wang", "Zhanhao Hu", "David Wagner"], "title": "JULI: Jailbreak Large Language Models by Self-Introspection", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) are trained with safety alignment to prevent\ngenerating malicious content. Although some attacks have highlighted\nvulnerabilities in these safety-aligned LLMs, they typically have limitations,\nsuch as necessitating access to the model weights or the generation process.\nSince proprietary models through API-calling do not grant users such\npermissions, these attacks find it challenging to compromise them. In this\npaper, we propose Jailbreaking Using LLM Introspection (JULI), which jailbreaks\nLLMs by manipulating the token log probabilities, using a tiny plug-in block,\nBiasNet. JULI relies solely on the knowledge of the target LLM's predicted\ntoken log probabilities. It can effectively jailbreak API-calling LLMs under a\nblack-box setting and knowing only top-$5$ token log probabilities. Our\napproach demonstrates superior effectiveness, outperforming existing\nstate-of-the-art (SOTA) approaches across multiple metrics."}
{"id": "2505.11985", "pdf": "https://arxiv.org/pdf/2505.11985", "abs": "https://arxiv.org/abs/2505.11985", "authors": ["Sabrina Khurshid", "Gourab Ghatak", "Mohammad Shahid Abdulla"], "title": "Variance-Optimal Arm Selection: Regret Minimization and Best Arm Identification", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper focuses on selecting the arm with the highest variance from a set\nof $K$ independent arms. Specifically, we focus on two settings: (i) regret\nsetting, that penalizes the number of pulls of suboptimal arms in terms of\nvariance, and (ii) fixed-budget BAI setting, that evaluates the ability of an\nalgorithm to determine the arm with the highest variance after a fixed number\nof pulls. We develop a novel online algorithm called \\texttt{UCB-VV} for the\nregret setting and show that its upper bound on regret for bounded rewards\nevolves as $\\mathcal{O}\\left(\\log{n}\\right)$ where $n$ is the horizon. By\nderiving the lower bound on the regret, we show that \\texttt{UCB-VV} is order\noptimal. For the fixed budget BAI setting, we propose the \\texttt{SHVV}\nalgorithm. We show that the upper bound of the error probability of\n\\texttt{SHVV} evolves as $\\exp\\left(-\\frac{n}{\\log(K) H}\\right)$, where $H$\nrepresents the complexity of the problem, and this rate matches the\ncorresponding lower bound. We extend the framework from bounded distributions\nto sub-Gaussian distributions using a novel concentration inequality on the\nsample variance. Leveraging the same, we derive a concentration inequality for\nthe empirical Sharpe ratio (SR) for sub-Gaussian distributions, which was\npreviously unknown in the literature. Empirical simulations show that\n\\texttt{UCB-VV} consistently outperforms \\texttt{$\\epsilon$-greedy} across\ndifferent sub-optimality gaps, though it is surpassed by \\texttt{VTS}, which\nexhibits the lowest regret, albeit lacking in theoretical guarantees. We also\nillustrate the superior performance of \\texttt{SHVV}, for a fixed budget\nsetting under 6 different setups against uniform sampling. Finally, we conduct\na case study to empirically evaluate the performance of the \\texttt{UCB-VV} and\n\\texttt{SHVV} in call option trading on $100$ stocks generated using geometric\nBrownian motion (GBM)."}
{"id": "2505.12540", "pdf": "https://arxiv.org/pdf/2505.12540", "abs": "https://arxiv.org/abs/2505.12540", "authors": ["Rishi Jha", "Collin Zhang", "Vitaly Shmatikov", "John X. Morris"], "title": "Harnessing the Universal Geometry of Embeddings", "categories": ["cs.LG"], "comment": null, "summary": "We introduce the first method for translating text embeddings from one vector\nspace to another without any paired data, encoders, or predefined sets of\nmatches. Our unsupervised approach translates any embedding to and from a\nuniversal latent representation (i.e., a universal semantic structure\nconjectured by the Platonic Representation Hypothesis). Our translations\nachieve high cosine similarity across model pairs with different architectures,\nparameter counts, and training datasets.\n  The ability to translate unknown embeddings into a different space while\npreserving their geometry has serious implications for the security of vector\ndatabases. An adversary with access only to embedding vectors can extract\nsensitive information about the underlying documents, sufficient for\nclassification and attribute inference."}
{"id": "2505.12586", "pdf": "https://arxiv.org/pdf/2505.12586", "abs": "https://arxiv.org/abs/2505.12586", "authors": ["Sanggeon Yun", "Ryozo Masukawa", "Hyunwoo Oh", "Nathaniel D. Bastian", "Mohsen Imani"], "title": "A Few Large Shifts: Layer-Inconsistency Based Minimal Overhead Adversarial Example Detection", "categories": ["cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) are highly susceptible to adversarial\nexamples--subtle, imperceptible perturbations that can lead to incorrect\npredictions. While detection-based defenses offer a practical alternative to\nadversarial training, many existing methods depend on external models, complex\narchitectures, heavy augmentations, or adversarial data, limiting their\nefficiency and generalizability. We introduce a lightweight, plug-in detection\nframework that leverages internal layer-wise inconsistencies within the target\nmodel itself, requiring only benign data for calibration. Our approach is\ngrounded in the A Few Large Shifts Assumption, which posits that adversarial\nperturbations typically induce large representation shifts in a small subset of\nlayers. Building on this, we propose two complementary strategies--Recovery\nTesting (RT) and Logit-layer Testing (LT)--to expose internal disruptions\ncaused by adversaries. Evaluated on CIFAR-10, CIFAR-100, and ImageNet under\nboth standard and adaptive threat models, our method achieves state-of-the-art\ndetection performance with negligible computational overhead and no compromise\nto clean accuracy."}
{"id": "2505.13197", "pdf": "https://arxiv.org/pdf/2505.13197", "abs": "https://arxiv.org/abs/2505.13197", "authors": ["Stephen Zhang", "Suryanarayana Maddu", "Xiaojie Qiu", "Victor Chard√®s"], "title": "Inferring stochastic dynamics with growth from cross-sectional data", "categories": ["cs.LG", "physics.bio-ph", "q-bio.QM"], "comment": "9 pages, 5 figures", "summary": "Time-resolved single-cell omics data offers high-throughput, genome-wide\nmeasurements of cellular states, which are instrumental to reverse-engineer the\nprocesses underpinning cell fate. Such technologies are inherently destructive,\nallowing only cross-sectional measurements of the underlying stochastic\ndynamical system. Furthermore, cells may divide or die in addition to changing\ntheir molecular state. Collectively these present a major challenge to\ninferring realistic biophysical models. We present a novel approach,\n\\emph{unbalanced} probability flow inference, that addresses this challenge for\nbiological processes modelled as stochastic dynamics with growth. By leveraging\na Lagrangian formulation of the Fokker-Planck equation, our method accurately\ndisentangles drift from intrinsic noise and growth. We showcase the\napplicability of our approach through evaluation on a range of simulated and\nreal single-cell RNA-seq datasets. Comparing to several existing methods, we\nfind our method achieves higher accuracy while enjoying a simple two-step\ntraining scheme."}
{"id": "2505.13317", "pdf": "https://arxiv.org/pdf/2505.13317", "abs": "https://arxiv.org/abs/2505.13317", "authors": ["Song-Lin Li", "Rui Zhu", "Yu-Feng Li", "Lan-Zhe Guo"], "title": "Unlabeled Data or Pre-trained Model: Rethinking Semi-Supervised Learning and Pretrain-Finetuning", "categories": ["cs.LG"], "comment": null, "summary": "Semi-supervised learning (SSL) alleviates the cost of data labeling process\nby exploiting unlabeled data, and has achieved promising results on various\ntasks such as image classification. Meanwhile, the Pretrain-Finetuning paradigm\nhas garnered significant attention in recent years, and exploiting pre-trained\nmodels could also reduce the requirement of labeled data in downstream tasks.\nTherefore, a question naturally occurs: \\emph{When the labeled data is scarce\nin the target tasks, should we exploit unlabeled data or pre-trained models?}\nTo answer this question, we select pre-trained Vision-Language Models (VLMs) as\nrepresentative pretrain-finetuning instances and propose \\textit{Few-shot SSL}\n-- a framework that enables fair comparison between these two paradigms by\ncontrolling the amount of labeled data used. Extensive experiments across\nvarious settings demonstrate that pre-trained VLMs generally outperform SSL\nmethods in nearly all cases, except when the data has low resolution or lacks\nclear semantic structure. Therefore, we encourage future SSL research to\ncompare with pre-trained models and explore deeper integration, such as using\npre-trained knowledge to enhance pseudo-labeling. To support future research,\nwe release our unified reproduction and evaluation framework. Codes are\navailable\n\\href{https://anonymous.4open.science/r/Rethinking-SSL-and-Pretrain-Finetuning-5566\n}{here}."}
{"id": "2505.13405", "pdf": "https://arxiv.org/pdf/2505.13405", "abs": "https://arxiv.org/abs/2505.13405", "authors": ["Gabriel Malikal", "Ismail Alkhouri", "Alvaro Velasquez", "Adam M Alessio", "Saiprasad Ravishankar"], "title": "A Dataless Reinforcement Learning Approach to Rounding Hyperplane Optimization for Max-Cut", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The Maximum Cut (MaxCut) problem is NP-Complete, and obtaining its optimal\nsolution is NP-hard in the worst case. As a result, heuristic-based algorithms\nare commonly used, though their design often requires significant domain\nexpertise. More recently, learning-based methods trained on large (un)labeled\ndatasets have been proposed; however, these approaches often struggle with\ngeneralizability and scalability. A well-known approximation algorithm for\nMaxCut is the Goemans-Williamson (GW) algorithm, which relaxes the Quadratic\nUnconstrained Binary Optimization (QUBO) formulation into a semidefinite\nprogram (SDP). The GW algorithm then applies hyperplane rounding by uniformly\nsampling a random hyperplane to convert the SDP solution into binary node\nassignments. In this paper, we propose a training-data-free approach based on a\nnon-episodic reinforcement learning formulation, in which an agent learns to\nselect improved rounding hyperplanes that yield better cuts than those produced\nby the GW algorithm. By optimizing over a Markov Decision Process (MDP), our\nmethod consistently achieves better cuts across large-scale graphs with varying\ndensities and degree distributions."}
{"id": "2212.07383", "pdf": "https://arxiv.org/pdf/2212.07383", "abs": "https://arxiv.org/abs/2212.07383", "authors": ["Aleksandr Podkopaev", "Patrick Bl√∂baum", "Shiva Prasad Kasiviswanathan", "Aaditya Ramdas"], "title": "Sequential Kernelized Independence Testing", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "ICML 2023", "summary": "Independence testing is a classical statistical problem that has been\nextensively studied in the batch setting when one fixes the sample size before\ncollecting data. However, practitioners often prefer procedures that adapt to\nthe complexity of a problem at hand instead of setting sample size in advance.\nIdeally, such procedures should (a) stop earlier on easy tasks (and later on\nharder tasks), hence making better use of available resources, and (b)\ncontinuously monitor the data and efficiently incorporate statistical evidence\nafter collecting new data, while controlling the false alarm rate. Classical\nbatch tests are not tailored for streaming data: valid inference after data\npeeking requires correcting for multiple testing which results in low power.\nFollowing the principle of testing by betting, we design sequential kernelized\nindependence tests that overcome such shortcomings. We exemplify our broad\nframework using bets inspired by kernelized dependence measures, e.g., the\nHilbert-Schmidt independence criterion. Our test is also valid under\nnon-i.i.d., time-varying settings. We demonstrate the power of our approaches\non both simulated and real data."}
{"id": "2307.10870", "pdf": "https://arxiv.org/pdf/2307.10870", "abs": "https://arxiv.org/abs/2307.10870", "authors": ["Dimitri Meunier", "Zhu Li", "Arthur Gretton", "Samory Kpotufe"], "title": "Nonlinear Meta-Learning Can Guarantee Faster Rates", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "Published", "summary": "Many recent theoretical works on \\emph{meta-learning} aim to achieve\nguarantees in leveraging similar representational structures from related tasks\ntowards simplifying a target task. The main aim of theoretical guarantees on\nthe subject is to establish the extent to which convergence rates -- in\nlearning a common representation -- \\emph{may scale with the number $N$ of\ntasks} (as well as the number of samples per task). First steps in this setting\ndemonstrate this property when both the shared representation amongst tasks,\nand task-specific regression functions, are linear. This linear setting readily\nreveals the benefits of aggregating tasks, e.g., via averaging arguments. In\npractice, however, the representation is often highly nonlinear, introducing\nnontrivial biases in each task that cannot easily be averaged out as in the\nlinear case. In the present work, we derive theoretical guarantees for\nmeta-learning with nonlinear representations. In particular, assuming the\nshared nonlinearity maps to an infinite dimensional reproducing kernel Hilbert\nspace, we show that additional biases can be mitigated with careful\nregularization that leverages the smoothness of task-specific regression\nfunctions, yielding improved rates that scale with the number of tasks as\ndesired."}
{"id": "2311.00721", "pdf": "https://arxiv.org/pdf/2311.00721", "abs": "https://arxiv.org/abs/2311.00721", "authors": ["Md Rakibul Hasan", "Md Zakir Hossain", "Shreya Ghosh", "Aneesh Krishna", "Tom Gedeon"], "title": "Empathy Detection from Text, Audiovisual, Audio or Physiological Signals: A Systematic Review of Task Formulations and Machine Learning Methods", "categories": ["cs.HC", "cs.LG", "cs.SI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Empathy indicates an individual's ability to understand others. Over the past\nfew years, empathy has drawn attention from various disciplines, including but\nnot limited to Affective Computing, Cognitive Science, and Psychology.\nDetecting empathy has potential applications in society, healthcare and\neducation. Despite being a broad and overlapping topic, the avenue of empathy\ndetection leveraging Machine Learning remains underexplored from a systematic\nliterature review perspective. We collected 849 papers from 10 well-known\nacademic databases, systematically screened them and analysed the final 82\npapers. Our analyses reveal several prominent task formulations - including\nempathy on localised utterances or overall expressions, unidirectional or\nparallel empathy, and emotional contagion - in monadic, dyadic and group\ninteractions. Empathy detection methods are summarised based on four input\nmodalities - text, audiovisual, audio and physiological signals - thereby\npresenting modality-specific network architecture design protocols. We discuss\nchallenges, research gaps and potential applications in the Affective\nComputing-based empathy domain, which can facilitate new avenues of\nexploration. We further enlist the public availability of datasets and codes.\nThis paper, therefore, provides a structured overview of recent advancements\nand remaining challenges towards developing a robust empathy detection system\nthat could meaningfully contribute to enhancing human well-being."}
{"id": "2407.00943", "pdf": "https://arxiv.org/pdf/2407.00943", "abs": "https://arxiv.org/abs/2407.00943", "authors": ["Jiaxiang Geng", "Boyu Li", "Xiaoqi Qin", "Yixuan Li", "Liang Li", "Yanzhao Hou", "Miao Pan"], "title": "FedEx: Expediting Federated Learning over Heterogeneous Mobile Devices by Overlapping and Participant Selection", "categories": ["cs.DC", "cs.LG"], "comment": "17 pages, 10 figures, Published in Transactions on Mobile Computing", "summary": "Training latency is critical for the success of numerous intrigued\napplications ignited by federated learning (FL) over heterogeneous mobile\ndevices. By revolutionarily overlapping local gradient transmission with\ncontinuous local computing, FL can remarkably reduce its training latency over\nhomogeneous clients, yet encounter severe model staleness, model drifts, memory\ncost and straggler issues in heterogeneous environments. To unleash the full\npotential of overlapping, we propose, FedEx, a novel \\underline{fed}erated\nlearning approach to \\underline{ex}pedite FL training over mobile devices under\ndata, computing and wireless heterogeneity. FedEx redefines the overlapping\nprocedure with staleness ceilings to constrain memory consumption and make\noverlapping compatible with participation selection (PS) designs. Then, FedEx\ncharacterizes the PS utility function by considering the latency reduced by\noverlapping, and provides a holistic PS solution to address the straggler\nissue. FedEx also introduces a simple but effective metric to trigger\noverlapping, in order to avoid model drifts. Experimental results show that\ncompared with its peer designs, FedEx demonstrates substantial reductions in FL\ntraining latency over heterogeneous mobile devices with limited memory cost."}
{"id": "2407.07885", "pdf": "https://arxiv.org/pdf/2407.07885", "abs": "https://arxiv.org/abs/2407.07885", "authors": ["Jessica Yin", "Haozhi Qi", "Jitendra Malik", "James Pikul", "Mark Yim", "Tess Hellebrekers"], "title": "Learning In-Hand Translation Using Tactile Skin With Shear and Normal Force Sensing", "categories": ["cs.RO", "cs.LG"], "comment": "Website: https://jessicayin.github.io/tactile-skin-rl/. Accepted to\n  ICRA 2025", "summary": "Recent progress in reinforcement learning (RL) and tactile sensing has\nsignificantly advanced dexterous manipulation. However, these methods often\nutilize simplified tactile signals due to the gap between tactile simulation\nand the real world. We introduce a sensor model for tactile skin that enables\nzero-shot sim-to-real transfer of ternary shear and binary normal forces. Using\nthis model, we develop an RL policy that leverages sliding contact for\ndexterous in-hand translation. We conduct extensive real-world experiments to\nassess how tactile sensing facilitates policy adaptation to various unseen\nobject properties and robot hand orientations. We demonstrate that our 3-axis\ntactile policies consistently outperform baselines that use only shear forces,\nonly normal forces, or only proprioception. Website:\nhttps://jessicayin.github.io/tactile-skin-rl/"}
{"id": "2408.04406", "pdf": "https://arxiv.org/pdf/2408.04406", "abs": "https://arxiv.org/abs/2408.04406", "authors": ["Nikolaus Vertovec", "Kostas Margellos", "Maria Prandini"], "title": "Finite sample learning of moving targets", "categories": ["math.OC", "cs.LG"], "comment": "13 pages, 7 figures", "summary": "We consider a moving target that we seek to learn from samples. Our results\nextend randomized techniques developed in control and optimization for a\nconstant target to the case where the target is changing. We derive a novel\nbound on the number of samples that are required to construct a probably\napproximately correct (PAC) estimate of the target. Furthermore, when the\nmoving target is a convex polytope, we provide a constructive method of\ngenerating the PAC estimate using a mixed integer linear program (MILP). The\nproposed method is demonstrated on an application to autonomous emergency\nbraking."}
{"id": "2410.03191", "pdf": "https://arxiv.org/pdf/2410.03191", "abs": "https://arxiv.org/abs/2410.03191", "authors": ["Fangyi Wei", "Jiajie Mo", "Kai Zhang", "Haipeng Shen", "Srikantan Nagarajan", "Fei Jiang"], "title": "Nested Deep Learning Model Towards A Foundation Model for Brain Signal Data", "categories": ["stat.ML", "cs.LG"], "comment": "47 pages; abstract updated; graphs and charts updated", "summary": "Epilepsy affects around 50 million people globally. Electroencephalography\n(EEG) or Magnetoencephalography (MEG) based spike detection plays a crucial\nrole in diagnosis and treatment. Manual spike identification is time-consuming\nand requires specialized training that further limits the number of qualified\nprofessionals. To ease the difficulty, various algorithmic approaches have been\ndeveloped. However, the existing methods face challenges in handling varying\nchannel configurations and in identifying the specific channels where the\nspikes originate. A novel Nested Deep Learning (NDL) framework is proposed to\novercome these limitations. NDL applies a weighted combination of signals\nacross all channels, ensuring adaptability to different channel setups, and\nallows clinicians to identify key channels more accurately. Through theoretical\nanalysis and empirical validation on real EEG/MEG datasets, NDL is shown to\nimprove prediction accuracy, achieve channel localization, support\ncross-modality data integration, and adapt to various neurophysiological\napplications."}
{"id": "2410.05530", "pdf": "https://arxiv.org/pdf/2410.05530", "abs": "https://arxiv.org/abs/2410.05530", "authors": ["Rahul Moorthy", "Jun-Jee Chao", "Volkan Isler"], "title": "VisDiff: SDF-Guided Polygon Generation for Visibility Reconstruction and Recognition", "categories": ["cs.CG", "cs.LG"], "comment": null, "summary": "The ability to capture rich representations of combinatorial structures has\nenabled the application of machine learning to tasks such as analysis and\ngeneration of floorplans, terrains, images, and animations. Recent work has\nprimarily focused on understanding structures with well-defined features,\nneighborhoods, or underlying distance metrics, while those lacking such\ncharacteristics remain largely unstudied. Examples of these combinatorial\nstructures can be found in polygons, where a small change in the vertex\nlocations causes a significant rearrangement of the combinatorial structure,\nexpressed as a visibility or triangulation graphs. Current representation\nlearning approaches fail to capture structures without well-defined features\nand distance metrics. In this paper, we study the open problem of Visibility\nReconstruction: Given a visibility graph $G$, construct a polygon $P$ whose\nvisibility graph is $G$.\n  We introduce VisDiff, a novel diffusion-based approach to generate polygon\n$P$ from the input visibility graph $G$. The main novelty of our approach is\nthat, rather than generating the polygon's vertex set directly, we first\nestimate the signed distance function (SDF) associated with the polygon. The\nSDF is then used to extract the vertex location representing the final polygon.\nWe show that going through the SDF allows VisDiff to learn the visibility\nrelationship much more effectively than generating vertex locations directly.\nIn order to train VisDiff, we create a carefully curated dataset. We use this\ndataset to benchmark our method and achieve 26% improvement in F1-Score over\nstandard methods as well as state of the art approaches."}
{"id": "2412.04657", "pdf": "https://arxiv.org/pdf/2412.04657", "abs": "https://arxiv.org/abs/2412.04657", "authors": ["Forough Majidi", "Foutse Khomh", "Heng Li", "Amin Nikanjam"], "title": "An Efficient Model Maintenance Approach for MLOps", "categories": ["cs.SE", "cs.LG"], "comment": "46 Pages, 10 Figures, 15 Tables, 1 Algorithm, Submitted to a journal", "summary": "In recent years, many industries have utilized machine learning (ML) models\nin their systems. Ideally, ML models should be trained on and applied to data\nfrom the same distributions. However, the data evolves over time in many\napplication areas, leading to concept drift, which in turn causes the\nperformance of the ML models to degrade over time. Therefore, maintaining\nup-to-date ML models plays a critical role in the MLOps pipeline. Existing ML\nmodel maintenance approaches are often computationally resource-intensive,\ncostly, time-consuming, and model-dependent. Thus, we propose an improved MLOps\npipeline, a new model maintenance approach and a Similarity-Based Model Reuse\n(SimReuse) tool to address the challenges of ML model maintenance. We identify\nseasonal and recurrent data distribution patterns in time series datasets\nthroughout a preliminary study. Recurrent data distribution patterns enable us\nto reuse previously trained models for similar distributions in the future,\nthus avoiding frequent unnecessary retrainings. Then, we integrated the model\nreuse approach into the MLOps pipeline and proposed our improved MLOps\npipeline. Furthermore, we develop SimReuse, a tool to implement the new\ncomponents of our MLOps pipeline to store models and reuse them for inference\nof data segments with similar data distributions in the future. Our evaluation\nresults on five time series datasets demonstrate that our model reuse approach\ncan maintain the models' performance while significantly reducing maintenance\ntime, costs, and the number of retrainings. Our model reuse approach achieves\nML model performance comparable to the best baselines, while reducing the\ncomputation time and costs to 1/8th. Therefore, industries and practitioners\ncan benefit from our approach and use our tool to maintain their ML models'\nperformance in the deployment phase to reduce their maintenance time and costs."}
{"id": "2412.13928", "pdf": "https://arxiv.org/pdf/2412.13928", "abs": "https://arxiv.org/abs/2412.13928", "authors": ["Tyler Maunu", "Jiayi Yao"], "title": "Subspace Langevin Monte Carlo", "categories": ["stat.ML", "cs.LG"], "comment": "26 pages, 5 figures, 1 table", "summary": "Sampling from high-dimensional distributions has wide applications in data\nscience and machine learning but poses significant computational challenges. We\nintroduce Subspace Langevin Monte Carlo (SLMC), a novel and efficient sampling\nmethod that generalizes random-coordinate Langevin Monte Carlo and\npreconditioned Langevin Monte Carlo by projecting the Langevin update onto\nsubsampled eigenblocks of a time-varying preconditioner at each iteration. The\nadvantage of SLMC is its superior adaptability and computational efficiency\ncompared to traditional Langevin Monte Carlo and preconditioned Langevin Monte\nCarlo. Using coupling arguments, we establish error guarantees for SLMC and\ndemonstrate its practical effectiveness through a few experiments on sampling\nfrom ill-conditioned distributions."}
{"id": "2412.19802", "pdf": "https://arxiv.org/pdf/2412.19802", "abs": "https://arxiv.org/abs/2412.19802", "authors": ["Sabyasachi Chatterjee", "Subhajit Goswami", "Soumendu Sundar Mukherjee"], "title": "A new approach to locally adaptive polynomial regression", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.ME", "stat.TH"], "comment": "29 pages, 4 figures; in this version, the title has been updated and\n  the exposition significantly expanded", "summary": "Adaptive bandwidth selection is a fundamental challenge in nonparametric\nregression. This paper introduces a new bandwidth selection procedure inspired\nby the optimality criteria for $\\ell_0$-penalized regression. Although similar\nin spirit to Lepski's method and its variants in selecting the largest interval\nsatisfying an admissibility criterion, our approach stems from a distinct\nphilosophy, utilizing criteria based on $\\ell_2$-norms of interval projections\nrather than explicit point and variance estimates. We obtain non-asymptotic\nrisk bounds for the local polynomial regression methods based on our bandwidth\nselection procedure which adapt (near-)optimally to the local H\\\"{o}lder\nexponent of the underlying regression function simultaneously at all points in\nits domain. Furthermore, we show that there is a single ideal choice of a\nglobal tuning parameter in each case under which the above-mentioned local\nadaptivity holds. The optimal risks of our methods derive from the properties\nof solutions to a new ``bandwidth selection equation'' which is of independent\ninterest. We believe that the principles underlying our approach provide a new\nperspective to the classical yet ever relevant problem of locally adaptive\nnonparametric regression."}
{"id": "2502.03261", "pdf": "https://arxiv.org/pdf/2502.03261", "abs": "https://arxiv.org/abs/2502.03261", "authors": ["Seamus Somerstep", "Felipe Maia Polo", "Allysson Flavio Melo de Oliveira", "Prattyush Mangal", "M√≠rian Silva", "Onkar Bhardwaj", "Mikhail Yurochkin", "Subha Maity"], "title": "CARROT: A Cost Aware Rate Optimal Router", "categories": ["stat.ML", "cs.LG", "cs.NI", "math.ST", "stat.TH"], "comment": "v2: Added o3-mini to CARROT and SPROUT", "summary": "With the rapid growth in the number of Large Language Models (LLMs), there\nhas been a recent interest in LLM routing, or directing queries to the cheapest\nLLM that can deliver a suitable response. We conduct a minimax analysis of the\nrouting problem, providing a lower bound and finding that a simple router that\npredicts both cost and accuracy for each question can be minimax optimal.\nInspired by this, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that\nselects a model based on estimates of the models' cost and performance.\nAlongside CARROT, we also introduce the Smart Price-aware ROUTing (SPROUT)\ndataset to facilitate routing on a wide spectrum of queries with the latest\nstate-of-the-art LLMs. Using SPROUT and prior benchmarks such as Routerbench\nand open-LLM-leaderboard-v2 we empirically validate CARROT's performance\nagainst several alternative routers."}
{"id": "2502.04949", "pdf": "https://arxiv.org/pdf/2502.04949", "abs": "https://arxiv.org/abs/2502.04949", "authors": ["Lasse Elsem√ºller", "Valentin Pratz", "Mischa von Krause", "Andreas Voss", "Paul-Christian B√ºrkner", "Stefan T. Radev"], "title": "Does Unsupervised Domain Adaptation Improve the Robustness of Amortized Bayesian Inference? A Systematic Evaluation", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Neural networks are fragile when confronted with data that significantly\ndeviates from their training distribution. This is true in particular for\nsimulation-based inference methods, such as neural amortized Bayesian inference\n(ABI), where models trained on simulated data are deployed on noisy real-world\nobservations. Recent robust approaches employ unsupervised domain adaptation\n(UDA) to match the embedding spaces of simulated and observed data. However,\nthe lack of comprehensive evaluations across different domain mismatches raises\nconcerns about the reliability in high-stakes applications. We address this gap\nby systematically testing UDA approaches across a wide range of\nmisspecification scenarios in silico and practice. We demonstrate that aligning\nsummary spaces between domains effectively mitigates the impact of unmodeled\nphenomena or noise. However, the same alignment mechanism can lead to failures\nunder prior misspecifications - a critical finding with practical consequences.\nOur results underscore the need for careful consideration of misspecification\ntypes when using UDA to increase the robustness of ABI."}
{"id": "2502.09790", "pdf": "https://arxiv.org/pdf/2502.09790", "abs": "https://arxiv.org/abs/2502.09790", "authors": ["Hamed Valizadegan", "Miguel J. S. Martinho", "Jon M. Jenkins", "Joseph D. Twicken", "Douglas A. Caldwell", "Patrick Maynard", "Hongbo Wei", "William Zhong", "Charles Yates", "Sam Donald", "Karen A. Collins", "David Latham", "Khalid Barkaoui", "Michael L. Calkins", "Kylee Carden", "Nikita Chazov", "Gilbert A. Esquerdo", "Tristan Guillot", "Vadim Krushinsky", "Grzegorz Nowak", "Benjamin V. Rackham", "Amaury Triaud", "Richard P. Schwarz", "Denise Stephens", "Chris Stockdale", "Cristilyn N. Watkins", "Francis P. Wilkin"], "title": "ExoMiner++: Enhanced Transit Classification and a New Vetting Catalog for 2-Minute TESS Data", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": null, "summary": "We present ExoMiner++, an enhanced deep learning model that builds on the\nsuccess of ExoMiner to improve transit signal classification in 2-minute TESS\ndata. ExoMiner++ incorporates additional diagnostic inputs, including\nperiodogram, flux trend, difference image, unfolded flux, and spacecraft\nattitude control data, all of which are crucial for effectively distinguishing\ntransit signals from more challenging sources of false positives. To further\nenhance performance, we leverage multi-source training by combining\nhigh-quality labeled data from the Kepler space telescope with TESS data. This\napproach mitigates the impact of TESS's noisier and more ambiguous labels.\nExoMiner++ achieves high accuracy across various classification and ranking\nmetrics, significantly narrowing the search space for follow-up investigations\nto confirm new planets. To serve the exoplanet community, we introduce new TESS\ncatalog containing ExoMiner++ classifications and confidence scores for each\ntransit signal. Among the 147,568 unlabeled TCEs, ExoMiner++ identifies 7,330\nas planet candidates, with the remainder classified as false positives. These\n7,330 planet candidates correspond to 1,868 existing TESS Objects of Interest\n(TOIs), 69 Community TESS Objects of Interest (CTOIs), and 50 newly introduced\nCTOIs. 1,797 out of the 2,506 TOIs previously labeled as planet candidates in\nExoFOP are classified as planet candidates by ExoMiner++. This reduction in\nplausible candidates combined with the excellent ranking quality of ExoMiner++\nallows the follow-up efforts to be focused on the most likely candidates,\nincreasing the overall planet yield."}
{"id": "2502.18314", "pdf": "https://arxiv.org/pdf/2502.18314", "abs": "https://arxiv.org/abs/2502.18314", "authors": ["Henrique Musseli Cezar", "Tilmann Bodenstein", "Henrik Andersen Sveinsson", "Morten Ledum", "Simen Reine", "Sigbj√∏rn L√∏land Bore"], "title": "Learning atomic forces from uncertainty-calibrated adversarial attacks", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "Adversarial approaches, which intentionally challenge machine learning models\nby generating difficult examples, are increasingly being adopted to improve\nmachine learning interatomic potentials (MLIPs). While already providing great\npractical value, little is known about the actual prediction errors of MLIPs on\nadversarial structures and whether these errors can be controlled. We propose\nthe Calibrated Adversarial Geometry Optimization (CAGO) algorithm to discover\nadversarial structures with user-assigned errors. Through uncertainty\ncalibration, the estimated uncertainty of MLIPs is unified with real errors. By\nperforming geometry optimization for calibrated uncertainty, we reach\nadversarial structures with the user-assigned target MLIP prediction error.\nIntegrating with active learning pipelines, we benchmark CAGO, demonstrating\nstable MLIPs that systematically converge structural, dynamical, and\nthermodynamical properties for liquid water and water adsorption in a\nmetal-organic framework within only hundreds of training structures, where\npreviously many thousands were typically required."}
{"id": "2502.19240", "pdf": "https://arxiv.org/pdf/2502.19240", "abs": "https://arxiv.org/abs/2502.19240", "authors": ["Luxu Liang", "Yuhang Jia", "Feng Zhou"], "title": "Enhancing Gradient-based Discrete Sampling via Parallel Tempering", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "25 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:2402.17699 by other authors", "summary": "While gradient-based discrete samplers are effective in sampling from complex\ndistributions, they are susceptible to getting trapped in local minima,\nparticularly in high-dimensional, multimodal discrete distributions, owing to\nthe discontinuities inherent in these landscapes. To circumvent this issue, we\ncombine parallel tempering, also known as replica exchange, with the discrete\nLangevin proposal and develop the Parallel Tempering enhanced Discrete Langevin\nProposal (PTDLP), which are simulated at a series of temperatures. Significant\nenergy differences prompt sample swaps, which are governed by a Metropolis\ncriterion specifically designed for discrete sampling to ensure detailed\nbalance is maintained. Additionally, we introduce an automatic scheme to\ndetermine the optimal temperature schedule and the number of chains, ensuring\nadaptability across diverse tasks with minimal tuning. Theoretically, we\nestablish that our algorithm converges non-asymptotically to the target energy\nand exhibits faster mixing compared to a single chain. Empirical results\nfurther emphasize the superiority of our method in sampling from complex,\nmultimodal discrete distributions, including synthetic problems, restricted\nBoltzmann machines, and deep energy-based models."}
{"id": "2503.14281", "pdf": "https://arxiv.org/pdf/2503.14281", "abs": "https://arxiv.org/abs/2503.14281", "authors": ["Adam ≈†torek", "Mukur Gupta", "Noopur Bhatt", "Aditya Gupta", "Janie Kim", "Prashast Srivastava", "Suman Jana"], "title": "XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants", "categories": ["cs.CR", "cs.LG", "cs.SE"], "comment": null, "summary": "AI coding assistants are widely used for tasks like code generation. These\ntools now require large and complex contexts, automatically sourced from\nvarious origins$\\unicode{x2014}$across files, projects, and\ncontributors$\\unicode{x2014}$forming part of the prompt fed to underlying LLMs.\nThis automatic context-gathering introduces new vulnerabilities, allowing\nattackers to subtly poison input to compromise the assistant's outputs,\npotentially generating vulnerable code or introducing critical errors. We\npropose a novel attack, Cross-Origin Context Poisoning (XOXO), that is\nchallenging to detect as it relies on adversarial code modifications that are\nsemantically equivalent. Traditional program analysis techniques struggle to\nidentify these perturbations since the semantics of the code remains correct,\nmaking it appear legitimate. This allows attackers to manipulate coding\nassistants into producing incorrect outputs, while shifting the blame to the\nvictim developer. We introduce a novel, task-agnostic, black-box attack\nalgorithm GCGS that systematically searches the transformation space using a\nCayley Graph, achieving a 75.72% attack success rate on average across five\ntasks and eleven models, including GPT 4.1 and Claude 3.5 Sonnet v2 used by\npopular AI coding assistants. Furthermore, defenses like adversarial\nfine-tuning are ineffective against our attack, underscoring the need for new\nsecurity measures in LLM-powered coding tools."}
{"id": "2503.17558", "pdf": "https://arxiv.org/pdf/2503.17558", "abs": "https://arxiv.org/abs/2503.17558", "authors": ["Eric Lei", "Hamed Hassani", "Shirin Saeedi Bidokhti"], "title": "Optimal Neural Compressors for the Rate-Distortion-Perception Tradeoff", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Recent efforts in neural compression have focused on the\nrate-distortion-perception (RDP) tradeoff, where the perception constraint\nensures the source and reconstruction distributions are close in terms of a\nstatistical divergence. Theoretical work on RDP describes properties of\nRDP-optimal compressors without providing constructive and low complexity\nsolutions. While classical rate distortion theory shows that optimal\ncompressors should efficiently pack space, RDP theory additionally shows that\ninfinite randomness shared between the encoder and decoder may be necessary for\nRDP optimality. In this paper, we propose neural compressors that are low\ncomplexity and benefit from high packing efficiency through lattice coding and\nshared randomness through shared dithering over the lattice cells. For two\nimportant settings, namely infinite shared and zero shared randomness, we\nanalyze the RDP tradeoff achieved by our proposed neural compressors and show\noptimality in both cases. Experimentally, we investigate the roles that these\ntwo components of our design, lattice coding and randomness, play in the\nperformance of neural compressors on synthetic and real-world data. We observe\nthat performance improves with more shared randomness and better lattice\npacking."}
{"id": "2503.23866", "pdf": "https://arxiv.org/pdf/2503.23866", "abs": "https://arxiv.org/abs/2503.23866", "authors": ["Jialin Wan", "Jinglong Shen", "Nan Cheng", "Zhisheng Yin", "Yiliang Liu", "Wenchao Xu", "Xuemin", "Shen"], "title": "A Channel-Triggered Backdoor Attack on Wireless Semantic Image Reconstruction", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This paper investigates backdoor attacks in image-oriented semantic\ncommunications. The threat of backdoor attacks on symbol reconstruction in\nsemantic communication (SemCom) systems has received limited attention.\nPrevious research on backdoor attacks targeting SemCom symbol reconstruction\nprimarily focuses on input-level triggers, which are impractical in scenarios\nwith strict input constraints. In this paper, we propose a novel\nchannel-triggered backdoor attack (CT-BA) framework that exploits inherent\nwireless channel characteristics as activation triggers. Our key innovation\ninvolves utilizing fundamental channel statistics parameters, specifically\nchannel gain with different fading distributions or channel noise with\ndifferent power, as potential triggers. This approach enhances stealth by\neliminating explicit input manipulation, provides flexibility through trigger\nselection from diverse channel conditions, and enables automatic activation via\nnatural channel variations without adversary intervention. We extensively\nevaluate CT-BA across four joint source-channel coding (JSCC) communication\nsystem architectures and three benchmark datasets. Simulation results\ndemonstrate that our attack achieves near-perfect attack success rate (ASR)\nwhile maintaining effective stealth. Finally, we discuss potential defense\nmechanisms against such attacks."}
{"id": "2504.13936", "pdf": "https://arxiv.org/pdf/2504.13936", "abs": "https://arxiv.org/abs/2504.13936", "authors": ["Dezhao Luo", "Bohan Tang", "Kang Li", "Georgios Papoudakis", "Jifei Song", "Shaogang Gong", "Jianye Hao", "Jun Wang", "Kun Shao"], "title": "ViMo: A Generative Visual GUI World Model for App Agents", "categories": ["cs.HC", "cs.LG", "cs.SY", "eess.SY"], "comment": "https://ai-agents-2030.github.io/ViMo/", "summary": "App agents, which autonomously operate mobile Apps through Graphical User\nInterfaces (GUIs), have gained significant interest in real-world applications.\nYet, they often struggle with long-horizon planning, failing to find the\noptimal actions for complex tasks with longer steps. To address this, world\nmodels are used to predict the next GUI observation based on user actions,\nenabling more effective agent planning. However, existing world models\nprimarily focus on generating only textual descriptions, lacking essential\nvisual details. To fill this gap, we propose ViMo, the first visual world model\ndesigned to generate future App observations as images. For the challenge of\ngenerating text in image patches, where even minor pixel errors can distort\nreadability, we decompose GUI generation into graphic and text content\ngeneration. We propose a novel data representation, the Symbolic Text\nRepresentation~(STR) to overlay text content with symbolic placeholders while\npreserving graphics. With this design, ViMo employs a STR Predictor to predict\nfuture GUIs' graphics and a GUI-text Predictor for generating the corresponding\ntext. Moreover, we deploy ViMo to enhance agent-focused tasks by predicting the\noutcome of different action options. Experiments show ViMo's ability to\ngenerate visually plausible and functionally effective GUIs that enable App\nagents to make more informed decisions."}
{"id": "2504.20194", "pdf": "https://arxiv.org/pdf/2504.20194", "abs": "https://arxiv.org/abs/2504.20194", "authors": ["Alex Kokot", "Alex Luedtke"], "title": "Coreset selection for the Sinkhorn divergence and generic smooth divergences", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We introduce CO2, an efficient algorithm to produce convexly-weighted\ncoresets with respect to generic smooth divergences. By employing a functional\nTaylor expansion, we show a local equivalence between sufficiently regular\nlosses and their second order approximations, reducing the coreset selection\nproblem to maximum mean discrepancy minimization. We apply CO2 to the Sinkhorn\ndivergence, providing a novel sampling procedure that requires\npoly-logarithmically many data points to match the approximation guarantees of\nrandom sampling. To show this, we additionally verify several new regularity\nproperties for entropically regularized optimal transport of independent\ninterest. Our approach leads to a new perspective linking coreset selection and\nkernel quadrature to classical statistical methods such as moment and score\nmatching. We showcase this method with a practical application of subsampling\nimage data, and highlight key directions to explore for improved algorithmic\nefficiency and theoretical guarantees."}
{"id": "2505.02987", "pdf": "https://arxiv.org/pdf/2505.02987", "abs": "https://arxiv.org/abs/2505.02987", "authors": ["Yifan Chen"], "title": "New affine invariant ensemble samplers and their dimensional scaling", "categories": ["stat.CO", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": "Any feedback welcome!", "summary": "We introduce new affine invariant ensemble samplers that are easy to\nconstruct and improve upon existing algorithms, especially for high-dimensional\nproblems. Specifically, we propose a derivative-free ensemble side move sampler\nthat performs favorably compared to popular samplers in the $\\texttt{emcee}$\npackage. Additionally, we develop a class of derivative-based ensemble\nHamiltonian Monte Carlo (HMC) samplers with affine invariance, which outperform\nstandard HMC without affine invariance when sampling highly skewed\ndistributions. We provide asymptotic scaling analysis for high-dimensional\nGaussian targets to further elucidate the properties of these affine invariant\nensemble samplers. In particular, with derivative information, the affine\ninvariant ensemble HMC can scale much better with dimension compared to\nderivative-free ensemble samplers."}
{"id": "2505.11638", "pdf": "https://arxiv.org/pdf/2505.11638", "abs": "https://arxiv.org/abs/2505.11638", "authors": ["Ivan Bioli", "Carlo Marcati", "Giancarlo Sangalli"], "title": "Accelerating Natural Gradient Descent for PINNs with Randomized Numerical Linear Algebra", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "Natural Gradient Descent (NGD) has emerged as a promising optimization\nalgorithm for training neural network-based solvers for partial differential\nequations (PDEs), such as Physics-Informed Neural Networks (PINNs). However,\nits practical use is often limited by the high computational cost of solving\nlinear systems involving the Gramian matrix. While matrix-free NGD methods\nbased on the conjugate gradient (CG) method avoid explicit matrix inversion,\nthe ill-conditioning of the Gramian significantly slows the convergence of CG.\nIn this work, we extend matrix-free NGD to broader classes of problems than\npreviously considered and propose the use of Randomized Nystr\\\"om\npreconditioning to accelerate convergence of the inner CG solver. The resulting\nalgorithm demonstrates substantial performance improvements over existing\nNGD-based methods on a range of PDE problems discretized using neural networks."}
{"id": "2505.12092", "pdf": "https://arxiv.org/pdf/2505.12092", "abs": "https://arxiv.org/abs/2505.12092", "authors": ["Marco Fiandri", "Alberto Maria Metelli", "Francesco Trov√≤"], "title": "Thompson Sampling-like Algorithms for Stochastic Rising Bandits", "categories": ["stat.ML", "cs.LG"], "comment": "57 pages", "summary": "Stochastic rising rested bandit (SRRB) is a setting where the arms' expected\nrewards increase as they are pulled. It models scenarios in which the\nperformances of the different options grow as an effect of an underlying\nlearning process (e.g., online model selection). Even if the bandit literature\nprovides specifically crafted algorithms based on upper-confidence bounds for\nsuch a setting, no study about Thompson sampling TS-like algorithms has been\nperformed so far. The strong regularity of the expected rewards in the SRRB\nsetting suggests that specific instances may be tackled effectively using\nadapted and sliding-window TS approaches. This work provides novel regret\nanalyses for such algorithms in SRRBs, highlighting the challenges and\nproviding new technical tools of independent interest. Our results allow us to\nidentify under which assumptions TS-like algorithms succeed in achieving\nsublinear regret and which properties of the environment govern the complexity\nof the regret minimization problem when approached with TS. Furthermore, we\nprovide a regret lower bound based on a complexity index we introduce. Finally,\nwe conduct numerical simulations comparing TS-like algorithms with\nstate-of-the-art approaches for SRRBs in synthetic and real-world settings."}
{"id": "2505.12331", "pdf": "https://arxiv.org/pdf/2505.12331", "abs": "https://arxiv.org/abs/2505.12331", "authors": ["Yuancheng Jiang", "Roland Yap", "Zhenkai Liang"], "title": "OSS-Bench: Benchmark Generator for Coding LLMs", "categories": ["cs.SE", "cs.LG"], "comment": "13 pages", "summary": "In light of the rapid adoption of AI coding assistants, LLM-assisted\ndevelopment has become increasingly prevalent, creating an urgent need for\nrobust evaluation of generated code quality. Existing benchmarks often require\nextensive manual effort to create static datasets, rely on indirect or\ninsufficiently challenging tasks, depend on non-scalable ground truth, or\nneglect critical low-level security evaluations, particularly memory-safety\nissues. In this work, we introduce OSS-Bench, a benchmark generator that\nautomatically constructs large-scale, live evaluation tasks from real-world\nopen-source software. OSS-Bench replaces functions with LLM-generated code and\nevaluates them using three natural metrics: compilability, functional\ncorrectness, and memory safety, leveraging robust signals like compilation\nfailures, test-suite violations, and sanitizer alerts as ground truth. In our\nevaluation, the benchmark, instantiated as OSS-Bench(php) and OSS-Bench(sql),\nprofiles 17 diverse LLMs, revealing insights such as intra-family behavioral\npatterns and inconsistencies between model size and performance. Our results\ndemonstrate that OSS-Bench mitigates overfitting by leveraging the evolving\ncomplexity of OSS and highlights LLMs' limited understanding of low-level code\nsecurity via extended fuzzing experiments. Overall, OSS-Bench offers a\npractical and scalable framework for benchmarking the real-world coding\ncapabilities of LLMs."}
{"id": "2505.13375", "pdf": "https://arxiv.org/pdf/2505.13375", "abs": "https://arxiv.org/abs/2505.13375", "authors": ["Christopher Kolloff", "Tobias H√∂ppe", "Emmanouil Angelis", "Mathias Jacob Schreiner", "Stefan Bauer", "Andrea Dittadi", "Simon Olsson"], "title": "Minimum-Excess-Work Guidance", "categories": ["stat.ML", "cs.LG"], "comment": "30 pages, 18 figures", "summary": "We propose a regularization framework inspired by thermodynamic work for\nguiding pre-trained probability flow generative models (e.g., continuous\nnormalizing flows or diffusion models) by minimizing excess work, a concept\nrooted in statistical mechanics and with strong conceptual connections to\noptimal transport. Our approach enables efficient guidance in sparse-data\nregimes common to scientific applications, where only limited target samples or\npartial density constraints are available. We introduce two strategies: Path\nGuidance for sampling rare transition states by concentrating probability mass\non user-defined subsets, and Observable Guidance for aligning generated\ndistributions with experimental observables while preserving entropy. We\ndemonstrate the framework's versatility on a coarse-grained protein model,\nguiding it to sample transition configurations between folded/unfolded states\nand correct systematic biases using experimental data. The method bridges\nthermodynamic principles with modern generative architectures, offering a\nprincipled, efficient, and physics-inspired alternative to standard fine-tuning\nin data-scarce domains. Empirical results highlight improved sample efficiency\nand bias reduction, underscoring its applicability to molecular simulations and\nbeyond."}
