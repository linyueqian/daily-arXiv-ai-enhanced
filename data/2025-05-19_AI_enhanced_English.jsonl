{"id": "2505.10793", "pdf": "https://arxiv.org/pdf/2505.10793", "abs": "https://arxiv.org/abs/2505.10793", "authors": ["Jixun Yao", "Guobin Ma", "Huixin Xue", "Huakang Chen", "Chunbo Hao", "Yuepeng Jiang", "Haohe Liu", "Ruibin Yuan", "Jin Xu", "Wei Xue", "Hao Liu", "Lei Xie"], "title": "SongEval: A Benchmark Dataset for Song Aesthetics Evaluation", "categories": ["eess.AS"], "comment": null, "summary": "Aesthetics serve as an implicit and important criterion in song generation\ntasks that reflect human perception beyond objective metrics. However,\nevaluating the aesthetics of generated songs remains a fundamental challenge,\nas the appreciation of music is highly subjective. Existing evaluation metrics,\nsuch as embedding-based distances, are limited in reflecting the subjective and\nperceptual aspects that define musical appeal. To address this issue, we\nintroduce SongEval, the first open-source, large-scale benchmark dataset for\nevaluating the aesthetics of full-length songs. SongEval includes over 2,399\nsongs in full length, summing up to more than 140 hours, with aesthetic ratings\nfrom 16 professional annotators with musical backgrounds. Each song is\nevaluated across five key dimensions: overall coherence, memorability,\nnaturalness of vocal breathing and phrasing, clarity of song structure, and\noverall musicality. The dataset covers both English and Chinese songs, spanning\nnine mainstream genres. Moreover, to assess the effectiveness of song aesthetic\nevaluation, we conduct experiments using SongEval to predict aesthetic scores\nand demonstrate better performance than existing objective evaluation metrics\nin predicting human-perceived musical quality.", "AI": {"tldr": "SongEval is a new benchmark dataset for evaluating song aesthetics, addressing the subjectivity of music appreciation with professional ratings across five dimensions.", "motivation": "Existing metrics fail to capture subjective musical appeal, necessitating a dataset like SongEval for better evaluation.", "method": "SongEval includes 2,399 full-length songs rated by 16 professionals across five aesthetic dimensions, covering multiple genres and languages.", "result": "SongEval outperforms existing metrics in predicting human-perceived musical quality.", "conclusion": "SongEval provides a robust, large-scale benchmark for evaluating song aesthetics, bridging the gap between objective metrics and human perception."}}
{"id": "2505.11375", "pdf": "https://arxiv.org/pdf/2505.11375", "abs": "https://arxiv.org/abs/2505.11375", "authors": ["Alistair Carson", "Alec Wright", "Stefan Bilbao"], "title": "Anti-aliasing of neural distortion effects via model fine tuning", "categories": ["eess.AS", "cs.LG", "eess.SP"], "comment": "Accepted for DAFx25", "summary": "Neural networks have become ubiquitous with guitar distortion effects\nmodelling in recent years. Despite their ability to yield perceptually\nconvincing models, they are susceptible to frequency aliasing when driven by\nhigh frequency and high gain inputs. Nonlinear activation functions create both\nthe desired harmonic distortion and unwanted aliasing distortion as the\nbandwidth of the signal is expanded beyond the Nyquist frequency. Here, we\npresent a method for reducing aliasing in neural models via a teacher-student\nfine tuning approach, where the teacher is a pre-trained model with its weights\nfrozen, and the student is a copy of this with learnable parameters. The\nstudent is fine-tuned against an aliasing-free dataset generated by passing\nsinusoids through the original model and removing non-harmonic components from\nthe output spectra. Our results show that this method significantly suppresses\naliasing for both long-short-term-memory networks (LSTM) and temporal\nconvolutional networks (TCN). In the majority of our case studies, the\nreduction in aliasing was greater than that achieved by two times oversampling.\nOne side-effect of the proposed method is that harmonic distortion components\nare also affected. This adverse effect was found to be model-dependent, with\nthe LSTM models giving the best balance between anti-aliasing and preserving\nthe perceived similarity to an analog reference device.", "AI": {"tldr": "A teacher-student fine-tuning method reduces aliasing in neural guitar distortion models, outperforming oversampling while preserving perceptual similarity.", "motivation": "Neural networks for guitar distortion effects suffer from frequency aliasing due to nonlinear activations, requiring a solution to maintain sound quality.", "method": "A teacher-student approach fine-tunes a student model against aliasing-free data derived from sinusoids processed by the original model.", "result": "Aliasing is significantly reduced in LSTM and TCN models, often surpassing two times oversampling. Harmonic distortion is affected but remains perceptually acceptable, especially with LSTMs.", "conclusion": "The method effectively reduces aliasing while maintaining perceptual similarity, with LSTM models offering the best balance."}}
{"id": "2505.11391", "pdf": "https://arxiv.org/pdf/2505.11391", "abs": "https://arxiv.org/abs/2505.11391", "authors": ["Danilo de Oliveira", "Julius Richter", "Tal Peer", "Timo Germann"], "title": "LipDiffuser: Lip-to-Speech Generation with Conditional Diffusion Models", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "We present LipDiffuser, a conditional diffusion model for lip-to-speech\ngeneration synthesizing natural and intelligible speech directly from silent\nvideo recordings. Our approach leverages the magnitude-preserving ablated\ndiffusion model (MP-ADM) architecture as a denoiser model. To effectively\ncondition the model, we incorporate visual features using magnitude-preserving\nfeature-wise linear modulation (MP-FiLM) alongside speaker embeddings. A neural\nvocoder then reconstructs the speech waveform from the generated\nmel-spectrograms. Evaluations on LRS3 and TCD-TIMIT demonstrate that\nLipDiffuser outperforms existing lip-to-speech baselines in perceptual speech\nquality and speaker similarity, while remaining competitive in downstream\nautomatic speech recognition (ASR). These findings are also supported by a\nformal listening experiment. Extensive ablation studies and cross-dataset\nevaluation confirm the effectiveness and generalization capabilities of our\napproach.", "AI": {"tldr": "LipDiffuser is a diffusion model for lip-to-speech generation, outperforming baselines in quality and speaker similarity.", "motivation": "To synthesize natural and intelligible speech from silent videos using a diffusion model.", "method": "Uses MP-ADM as a denoiser, MP-FiLM for visual features, and a neural vocoder for waveform reconstruction.", "result": "Outperforms baselines in perceptual quality, speaker similarity, and ASR performance.", "conclusion": "LipDiffuser is effective and generalizes well, as confirmed by evaluations and listening experiments."}}
{"id": "2505.10686", "pdf": "https://arxiv.org/pdf/2505.10686", "abs": "https://arxiv.org/abs/2505.10686", "authors": ["Yonghyun Kim", "Sangheon Park", "Marcus Parker", "Donghoon Seu", "Alexandria Smith"], "title": "NeoLightning: A Modern Reimagination of Gesture-Based Sound Design", "categories": ["cs.HC", "cs.MM", "cs.SD", "eess.AS"], "comment": "Accepted to the 50th International Computer Music Conference (ICMC),\n  2025", "summary": "This paper introduces NeoLightning, a modern reinterpretation of the Buchla\nLightning. NeoLightning preserves the innovative spirit of Don Buchla's \"Buchla\nLightning\" (introduced in the 1990s) while making its gesture-based interaction\naccessible to contemporary users. While the original Buchla Lightning and many\nother historical instruments were groundbreaking in their time, they are now\nlargely unsupported, limiting user interaction to indirect experiences. To\naddress this, NeoLightning leverages MediaPipe for deep learning-based gesture\nrecognition and employs Max/MSP and Processing for real-time multimedia\nprocessing. The redesigned system offers precise, low-latency gesture\nrecognition and immersive 3D interaction. By merging the creative spirit of the\noriginal Lightning with modern advancements, NeoLightning redefines\ngesture-based musical interaction, expanding possibilities for expressive\nperformance and interactive sound design.", "AI": {"tldr": "NeoLightning modernizes the Buchla Lightning with gesture recognition and real-time multimedia processing for contemporary users.", "motivation": "To make the innovative gesture-based interaction of the Buchla Lightning accessible today, as the original is unsupported.", "method": "Uses MediaPipe for gesture recognition and Max/MSP/Processing for real-time multimedia processing.", "result": "Precise, low-latency gesture recognition and immersive 3D interaction.", "conclusion": "NeoLightning revitalizes gesture-based musical interaction with modern tech, enhancing expressive performance and sound design."}}
{"id": "2505.10575", "pdf": "https://arxiv.org/pdf/2505.10575", "abs": "https://arxiv.org/abs/2505.10575", "authors": ["Adnan Ahmad", "Bahareh Nakisa", "Mohammad Naim Rastgoo"], "title": "Robust Emotion Recognition via Bi-Level Self-Supervised Continual Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Emotion recognition through physiological signals such as\nelectroencephalogram (EEG) has become an essential aspect of affective\ncomputing and provides an objective way to capture human emotions. However,\nphysiological data characterized by cross-subject variability and noisy labels\nhinder the performance of emotion recognition models. Existing domain\nadaptation and continual learning methods struggle to address these issues,\nespecially under realistic conditions where data is continuously streamed and\nunlabeled. To overcome these limitations, we propose a novel bi-level\nself-supervised continual learning framework, SSOCL, based on a dynamic memory\nbuffer. This bi-level architecture iteratively refines the dynamic buffer and\npseudo-label assignments to effectively retain representative samples, enabling\ngeneralization from continuous, unlabeled physiological data streams for\nemotion recognition. The assigned pseudo-labels are subsequently leveraged for\naccurate emotion prediction. Key components of the framework, including a fast\nadaptation module and a cluster-mapping module, enable robust learning and\neffective handling of evolving data streams. Experimental validation on two\nmainstream EEG tasks demonstrates the framework's ability to adapt to\ncontinuous data streams while maintaining strong generalization across\nsubjects, outperforming existing approaches.", "AI": {"tldr": "A novel bi-level self-supervised continual learning framework (SSOCL) is proposed for emotion recognition from continuous, unlabeled EEG data, addressing cross-subject variability and noisy labels.", "motivation": "Existing methods struggle with cross-subject variability and noisy labels in physiological data, especially in continuous, unlabeled streams.", "method": "SSOCL uses a dynamic memory buffer, fast adaptation module, and cluster-mapping module to refine pseudo-labels and retain representative samples.", "result": "Outperforms existing approaches in adapting to continuous EEG data streams and generalizing across subjects.", "conclusion": "SSOCL effectively handles evolving data streams for robust emotion recognition."}}
{"id": "2505.10653", "pdf": "https://arxiv.org/pdf/2505.10653", "abs": "https://arxiv.org/abs/2505.10653", "authors": ["Sandeep Neema", "Susmit Jha", "Adam Nagel", "Ethan Lew", "Chandrasekar Sureshkumar", "Aleksa Gordic", "Chase Shimmin", "Hieu Nguygen", "Paul Eremenko"], "title": "On the Evaluation of Engineering Artificial General Intelligence", "categories": ["cs.AI", "I.2; J.2; J.6"], "comment": "21 pages", "summary": "We discuss the challenges and propose a framework for evaluating engineering\nartificial general intelligence (eAGI) agents. We consider eAGI as a\nspecialization of artificial general intelligence (AGI), deemed capable of\naddressing a broad range of problems in the engineering of physical systems and\nassociated controllers. We exclude software engineering for a tractable scoping\nof eAGI and expect dedicated software engineering AI agents to address the\nsoftware implementation challenges. Similar to human engineers, eAGI agents\nshould possess a unique blend of background knowledge (recall and retrieve) of\nfacts and methods, demonstrate familiarity with tools and processes, exhibit\ndeep understanding of industrial components and well-known design families, and\nbe able to engage in creative problem solving (analyze and synthesize),\ntransferring ideas acquired in one context to another. Given this broad\nmandate, evaluating and qualifying the performance of eAGI agents is a\nchallenge in itself and, arguably, a critical enabler to developing eAGI\nagents. In this paper, we address this challenge by proposing an extensible\nevaluation framework that specializes and grounds Bloom's taxonomy - a\nframework for evaluating human learning that has also been recently used for\nevaluating LLMs - in an engineering design context. Our proposed framework\nadvances the state of the art in benchmarking and evaluation of AI agents in\nterms of the following: (a) developing a rich taxonomy of evaluation questions\nspanning from methodological knowledge to real-world design problems; (b)\nmotivating a pluggable evaluation framework that can evaluate not only textual\nresponses but also evaluate structured design artifacts such as CAD models and\nSysML models; and (c) outlining an automatable procedure to customize the\nevaluation benchmark to different engineering contexts.", "AI": {"tldr": "The paper proposes a framework for evaluating engineering artificial general intelligence (eAGI) agents, adapting Bloom's taxonomy for engineering design contexts.", "motivation": "The challenge of evaluating eAGI agents, which require a blend of knowledge, creativity, and problem-solving skills, is critical for their development.", "method": "An extensible evaluation framework is introduced, specializing Bloom's taxonomy for engineering design, including textual and structured artifact evaluation.", "result": "The framework advances benchmarking by offering a rich taxonomy of questions, pluggable evaluation, and automatable customization for engineering contexts.", "conclusion": "The proposed framework is a significant step toward standardized evaluation of eAGI agents, enabling their development and application in engineering."}}
{"id": "2505.10643", "pdf": "https://arxiv.org/pdf/2505.10643", "abs": "https://arxiv.org/abs/2505.10643", "authors": ["Shuchen Guo", "Yun Wang", "Jichao Yu", "Xuansheng Wu", "Bilgehan Ayik", "Field M. Watts", "Ehsan Latif", "Ninghao Liu", "Lei Liu", "Xiaoming Zhai"], "title": "Artificial Intelligence Bias on English Language Learners in Automatic Scoring", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "This study investigated potential scoring biases and disparities toward\nEnglish Language Learners (ELLs) when using automatic scoring systems for\nmiddle school students' written responses to science assessments. We\nspecifically focus on examining how unbalanced training data with ELLs\ncontributes to scoring bias and disparities. We fine-tuned BERT with four\ndatasets: responses from (1) ELLs, (2) non-ELLs, (3) a mixed dataset reflecting\nthe real-world proportion of ELLs and non-ELLs (unbalanced), and (4) a balanced\nmixed dataset with equal representation of both groups. The study analyzed 21\nassessment items: 10 items with about 30,000 ELL responses, five items with\nabout 1,000 ELL responses, and six items with about 200 ELL responses. Scoring\naccuracy (Acc) was calculated and compared to identify bias using Friedman\ntests. We measured the Mean Score Gaps (MSGs) between ELLs and non-ELLs and\nthen calculated the differences in MSGs generated through both the human and AI\nmodels to identify the scoring disparities. We found that no AI bias and\ndistorted disparities between ELLs and non-ELLs were found when the training\ndataset was large enough (ELL = 30,000 and ELL = 1,000), but concerns could\nexist if the sample size is limited (ELL = 200).", "AI": {"tldr": "The study examines bias in automatic scoring for ELLs in science assessments, finding no significant bias with large training datasets but potential issues with smaller samples.", "motivation": "To investigate scoring biases and disparities toward ELLs in automated systems due to unbalanced training data.", "method": "Fine-tuned BERT with four datasets (ELLs, non-ELLs, unbalanced mixed, balanced mixed) and analyzed scoring accuracy and Mean Score Gaps (MSGs) across 21 items.", "result": "No AI bias or disparities found with large datasets (30,000 or 1,000 ELL responses), but concerns arose with smaller samples (200 ELL responses).", "conclusion": "Training data size impacts bias detection; larger datasets mitigate scoring disparities for ELLs in automated systems."}}
{"id": "2505.10597", "pdf": "https://arxiv.org/pdf/2505.10597", "abs": "https://arxiv.org/abs/2505.10597", "authors": ["Jiazheng Zhang", "Wenqing Jing", "Zizhuo Zhang", "Zhiheng Xi", "Shihan Dou", "Rongxiang Weng", "Jiahuan Li", "Jingang Wang", "MingXu Cai", "Shibo Hong", "Tao Gui", "Qi Zhang"], "title": "Two Minds Better Than One: Collaborative Reward Modeling for LLM Alignment", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reward models (RMs) are essential for aligning large language models (LLMs)\nwith human values. However, noisy preferences in human feedback often lead to\nreward misgeneralization, where RMs overfit to spurious patterns and provide\nmisleading signals during policy optimization. We systematically analyze the\ntraining dynamics of preference pairs and identify that noisy examples are\nharder to fit and introduce instability. Empirical evidence shows that LLMs\noptimized using reward models trained on full noisy datasets perform worse than\nthose trained on filtered, high-quality preferences. To address this, we\npropose Collaborative Reward Modeling (CRM), an online framework that enhances\nrobustness by combining peer review and curriculum learning. Two reward models\nare trained in parallel and assess each other's data selections to filter out\npotential noise. Curriculum learning structures the preference data from easy\nto hard, ensuring synchronized training and stable feedback. Extensive\nexperiments demonstrate that CRM improves generalization, with up to 9.94\npoints of accuracy gain on RewardBench under 40 percent label noise. CRM is\nalso compatible with implicit-reward alignment methods, offering a practical\nand versatile strategy for robust alignment.", "AI": {"tldr": "CRM improves reward model robustness by filtering noisy preferences via peer review and curriculum learning, enhancing LLM alignment with human values.", "motivation": "Noisy human feedback causes reward misgeneralization, leading to poor LLM performance. Addressing this noise is critical for reliable alignment.", "method": "Proposes Collaborative Reward Modeling (CRM), combining peer review (two RMs filtering each other's data) and curriculum learning (easy-to-hard data structuring).", "result": "CRM boosts generalization, achieving up to 9.94 accuracy gain on RewardBench under 40% noise, and works with implicit-reward methods.", "conclusion": "CRM offers a robust, versatile solution for aligning LLMs with human values despite noisy feedback."}}
{"id": "2505.10690", "pdf": "https://arxiv.org/pdf/2505.10690", "abs": "https://arxiv.org/abs/2505.10690", "authors": ["Keqi Shu", "Minghao Ning", "Ahmad Alghooneh", "Shen Li", "Mohammad Pirani", "Amir Khajepour"], "title": "Decision Making in Urban Traffic: A Game Theoretic Approach for Autonomous Vehicles Adhering to Traffic Rules", "categories": ["cs.MA", "cs.GT", "cs.RO"], "comment": "This paper is already accepted on IEEE Transactions on Intelligent\n  Transportation Systems", "summary": "One of the primary challenges in urban autonomous vehicle decision-making and\nplanning lies in effectively managing intricate interactions with diverse\ntraffic participants characterized by unpredictable movement patterns.\nAdditionally, interpreting and adhering to traffic regulations within rapidly\nevolving traffic scenarios pose significant hurdles. This paper proposed a\nrule-based autonomous vehicle decision-making and planning framework which\nextracts right-of-way from traffic rules to generate behavioural parameters,\nintegrating them to effectively adhere to and navigate through traffic\nregulations. The framework considers the strong interaction between traffic\nparticipants mathematically by formulating the decision-making and planning\nproblem into a differential game. By finding the Nash equilibrium of the\nproblem, the autonomous vehicle is able to find optimal decisions. The proposed\nframework was tested under simulation as well as full-size vehicle platform,\nthe results show that the ego vehicle is able to safely interact with\nsurrounding traffic participants while adhering to traffic rules.", "AI": {"tldr": "A rule-based framework for autonomous vehicle decision-making extracts right-of-way from traffic rules, formulates interactions as a differential game, and finds Nash equilibrium for optimal decisions, tested successfully in simulations and real vehicles.", "motivation": "Addressing challenges in urban autonomous vehicle decision-making, such as unpredictable traffic participant behavior and adherence to evolving traffic rules.", "method": "Proposes a rule-based framework integrating traffic rules into behavioral parameters and formulating interactions as a differential game to find Nash equilibrium.", "result": "The framework enables safe interaction with traffic participants and adherence to traffic rules, validated in simulations and real-world tests.", "conclusion": "The proposed method effectively navigates complex urban traffic scenarios by combining rule-based decision-making with game-theoretic interaction modeling."}}
{"id": "2505.10879", "pdf": "https://arxiv.org/pdf/2505.10879", "abs": "https://arxiv.org/abs/2505.10879", "authors": ["Ali Sartaz Khan", "Tolulope Ogunremi", "Ahmed Attia", "Dorottya Demszky"], "title": "Multi-Stage Speaker Diarization for Noisy Classrooms", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "Speaker diarization, the process of identifying \"who spoke when\" in audio\nrecordings, is essential for understanding classroom dynamics. However,\nclassroom settings present distinct challenges, including poor recording\nquality, high levels of background noise, overlapping speech, and the\ndifficulty of accurately capturing children's voices. This study investigates\nthe effectiveness of multi-stage diarization models using Nvidia's NeMo\ndiarization pipeline. We assess the impact of denoising on diarization accuracy\nand compare various voice activity detection (VAD) models, including\nself-supervised transformer-based frame-wise VAD models. We also explore a\nhybrid VAD approach that integrates Automatic Speech Recognition (ASR)\nword-level timestamps with frame-level VAD predictions. We conduct experiments\nusing two datasets from English speaking classrooms to separate teacher vs.\nstudent speech and to separate all speakers. Our results show that denoising\nsignificantly improves the Diarization Error Rate (DER) by reducing the rate of\nmissed speech. Additionally, training on both denoised and noisy datasets leads\nto substantial performance gains in noisy conditions. The hybrid VAD model\nleads to further improvements in speech detection, achieving a DER as low as\n17% in teacher-student experiments and 45% in all-speaker experiments. However,\nwe also identified trade-offs between voice activity detection and speaker\nconfusion. Overall, our study highlights the effectiveness of multi-stage\ndiarization models and integrating ASR-based information for enhancing speaker\ndiarization in noisy classroom environments.", "AI": {"tldr": "The study evaluates multi-stage diarization models for noisy classrooms, showing denoising and hybrid VAD improve accuracy, achieving DERs of 17% (teacher-student) and 45% (all-speaker).", "motivation": "Classroom settings pose challenges like poor audio quality and overlapping speech, making speaker diarization difficult.", "method": "Uses Nvidia's NeMo pipeline, tests denoising, compares VAD models, and explores a hybrid VAD approach with ASR integration.", "result": "Denoising reduces DER; hybrid VAD achieves 17% DER (teacher-student) and 45% (all-speaker). Training on mixed datasets improves noisy performance.", "conclusion": "Multi-stage models and ASR integration enhance diarization in noisy classrooms, though trade-offs exist between VAD and speaker confusion."}}
{"id": "2505.11237", "pdf": "https://arxiv.org/pdf/2505.11237", "abs": "https://arxiv.org/abs/2505.11237", "authors": ["Wenhao Qian", "Zhenzhen Hu", "Zijie Song", "Jia Li"], "title": "Concept Drift Guided LayerNorm Tuning for Efficient Multimodal Metaphor Identification", "categories": ["cs.MM", "cs.LG"], "comment": "ICMR'25, June 30-July 3, 2025, Chicago, IL, USA", "summary": "Metaphorical imagination, the ability to connect seemingly unrelated\nconcepts, is fundamental to human cognition and communication. While\nunderstanding linguistic metaphors has advanced significantly, grasping\nmultimodal metaphors, such as those found in internet memes, presents unique\nchallenges due to their unconventional expressions and implied meanings.\nExisting methods for multimodal metaphor identification often struggle to\nbridge the gap between literal and figurative interpretations. Additionally,\ngenerative approaches that utilize large language models or text-to-image\nmodels, while promising, suffer from high computational costs. This paper\nintroduces \\textbf{C}oncept \\textbf{D}rift \\textbf{G}uided \\textbf{L}ayerNorm\n\\textbf{T}uning (\\textbf{CDGLT}), a novel and training-efficient framework for\nmultimodal metaphor identification. CDGLT incorporates two key innovations: (1)\nConcept Drift, a mechanism that leverages Spherical Linear Interpolation\n(SLERP) of cross-modal embeddings from a CLIP encoder to generate a new,\ndivergent concept embedding. This drifted concept helps to alleviate the gap\nbetween literal features and the figurative task. (2) A prompt construction\nstrategy, that adapts the method of feature extraction and fusion using\npre-trained language models for the multimodal metaphor identification task.\nCDGLT achieves state-of-the-art performance on the MET-Meme benchmark while\nsignificantly reducing training costs compared to existing generative methods.\nAblation studies demonstrate the effectiveness of both Concept Drift and our\nadapted LN Tuning approach. Our method represents a significant step towards\nefficient and accurate multimodal metaphor understanding. The code is\navailable:\n\\href{https://github.com/Qianvenh/CDGLT}{https://github.com/Qianvenh/CDGLT}.", "AI": {"tldr": "The paper introduces CDGLT, a training-efficient framework for multimodal metaphor identification, leveraging Concept Drift and prompt construction to bridge literal and figurative interpretations.", "motivation": "Existing methods struggle with multimodal metaphors due to unconventional expressions and high computational costs of generative approaches.", "method": "CDGLT uses Concept Drift (SLERP of CLIP embeddings) and prompt construction with pre-trained models for efficient feature extraction and fusion.", "result": "Achieves state-of-the-art performance on MET-Meme benchmark with reduced training costs.", "conclusion": "CDGLT advances efficient and accurate multimodal metaphor understanding."}}
{"id": "2505.10577", "pdf": "https://arxiv.org/pdf/2505.10577", "abs": "https://arxiv.org/abs/2505.10577", "authors": ["Yutong Guo"], "title": "GRNN:Recurrent Neural Network based on Ghost Features for Video Super-Resolution", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted by 2023 IEEE International Conference on Multimedia and Expo\n  (ICME 2023)", "summary": "Modern video super-resolution (VSR) systems based on convolutional neural\nnetworks (CNNs) require huge computational costs. The problem of feature\nredundancy is present in most models in many domains, but is rarely discussed\nin VSR. We experimentally observe that many features in VSR models are also\nsimilar to each other, so we propose to use \"Ghost features\" to reduce this\nredundancy. We also analyze the so-called \"gradient disappearance\" phenomenon\ngenerated by the conventional recurrent convolutional network (RNN) model, and\ncombine the Ghost module with RNN to complete the modeling on time series. The\ncurrent frame is used as input to the model together with the next frame, the\noutput of the previous frame and the hidden state. Extensive experiments on\nseveral benchmark models and datasets show that the PSNR and SSIM of our\nproposed modality are improved to some extent. Some texture details in the\nvideo are also better preserved.", "AI": {"tldr": "The paper proposes using 'Ghost features' to reduce redundancy in VSR models and combines it with RNN to address gradient disappearance, improving PSNR and SSIM.", "motivation": "Feature redundancy in VSR models is rarely discussed, and the paper aims to address this by leveraging 'Ghost features' and improving temporal modeling.", "method": "The approach uses 'Ghost features' to reduce redundancy and integrates them with RNN to model time series, using current and next frames, previous output, and hidden state as inputs.", "result": "Experiments show improved PSNR and SSIM, with better preservation of texture details in videos.", "conclusion": "The proposed method effectively reduces redundancy and enhances video super-resolution performance."}}
{"id": "2505.10885", "pdf": "https://arxiv.org/pdf/2505.10885", "abs": "https://arxiv.org/abs/2505.10885", "authors": ["Istiaq Ahmed Fahad", "Kamruzzaman Asif", "Sifat Sikder"], "title": "BanglaFake: Constructing and Evaluating a Specialized Bengali Deepfake Audio Dataset", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "5 page", "summary": "Deepfake audio detection is challenging for low-resource languages like\nBengali due to limited datasets and subtle acoustic features. To address this,\nwe introduce BangalFake, a Bengali Deepfake Audio Dataset with 12,260 real and\n13,260 deepfake utterances. Synthetic speech is generated using SOTA\nText-to-Speech (TTS) models, ensuring high naturalness and quality. We evaluate\nthe dataset through both qualitative and quantitative analyses. Mean Opinion\nScore (MOS) from 30 native speakers shows Robust-MOS of 3.40 (naturalness) and\n4.01 (intelligibility). t-SNE visualization of MFCCs highlights real vs. fake\ndifferentiation challenges. This dataset serves as a crucial resource for\nadvancing deepfake detection in Bengali, addressing the limitations of\nlow-resource language research.", "AI": {"tldr": "BangalFake dataset addresses deepfake audio detection challenges in Bengali, featuring 25,520 utterances and evaluations showing high naturalness and intelligibility.", "motivation": "The lack of datasets and subtle acoustic features make deepfake audio detection difficult for low-resource languages like Bengali.", "method": "Created BangalFake dataset with 12,260 real and 13,260 deepfake utterances using SOTA TTS models, evaluated via MOS and t-SNE visualization.", "result": "MOS scores: 3.40 (naturalness) and 4.01 (intelligibility). t-SNE shows challenges in differentiating real vs. fake.", "conclusion": "BangalFake is a valuable resource for advancing deepfake detection in Bengali, addressing low-resource language limitations."}}
{"id": "2505.10579", "pdf": "https://arxiv.org/pdf/2505.10579", "abs": "https://arxiv.org/abs/2505.10579", "authors": ["Germani Elodie", "Selin T\u00fcrk Ilayda", "Zeineddine Fatima", "Mourad Charbel", "Albarqouni Shadi"], "title": "Bias and Generalizability of Foundation Models across Datasets in Breast Mammography", "categories": ["cs.CV"], "comment": "Accepted at the International Conference on Medical Image Computing\n  and Computer-Assisted Intervention (MICCAI) 2025", "summary": "Over the past decades, computer-aided diagnosis tools for breast cancer have\nbeen developed to enhance screening procedures, yet their clinical adoption\nremains challenged by data variability and inherent biases. Although foundation\nmodels (FMs) have recently demonstrated impressive generalizability and\ntransfer learning capabilities by leveraging vast and diverse datasets, their\nperformance can be undermined by spurious correlations that arise from\nvariations in image quality, labeling uncertainty, and sensitive patient\nattributes. In this work, we explore the fairness and bias of FMs for breast\nmammography classification by leveraging a large pool of datasets from diverse\nsources-including data from underrepresented regions and an in-house dataset.\nOur extensive experiments show that while modality-specific pre-training of FMs\nenhances performance, classifiers trained on features from individual datasets\nfail to generalize across domains. Aggregating datasets improves overall\nperformance, yet does not fully mitigate biases, leading to significant\ndisparities across under-represented subgroups such as extreme breast densities\nand age groups. Furthermore, while domain-adaptation strategies can reduce\nthese disparities, they often incur a performance trade-off. In contrast,\nfairness-aware techniques yield more stable and equitable performance across\nsubgroups. These findings underscore the necessity of incorporating rigorous\nfairness evaluations and mitigation strategies into FM-based models to foster\ninclusive and generalizable AI.", "AI": {"tldr": "The paper examines fairness and bias in foundation models (FMs) for breast mammography classification, highlighting challenges like data variability and biases. It shows that while pre-training and dataset aggregation improve performance, biases persist, especially in underrepresented subgroups. Fairness-aware techniques are recommended for equitable AI.", "motivation": "To address the limited clinical adoption of computer-aided diagnosis tools due to data variability and biases, the study explores the fairness and bias of FMs in breast cancer screening.", "method": "The study leverages diverse datasets, including underrepresented regions, and evaluates FMs with modality-specific pre-training, domain-adaptation, and fairness-aware techniques.", "result": "Pre-training and dataset aggregation improve performance but fail to fully mitigate biases, causing disparities in underrepresented subgroups. Fairness-aware techniques provide more stable and equitable results.", "conclusion": "Rigorous fairness evaluations and mitigation strategies are essential for inclusive and generalizable AI in breast cancer diagnosis."}}
{"id": "2505.10670", "pdf": "https://arxiv.org/pdf/2505.10670", "abs": "https://arxiv.org/abs/2505.10670", "authors": ["Jan Chojnacki"], "title": "Interpretable Risk Mitigation in LLM Agent Systems", "categories": ["cs.AI", "cs.CY", "cs.GT"], "comment": null, "summary": "Autonomous agents powered by large language models (LLMs) enable novel use\ncases in domains where responsible action is increasingly important. Yet the\ninherent unpredictability of LLMs raises safety concerns about agent\nreliability. In this work, we explore agent behaviour in a toy, game-theoretic\nenvironment based on a variation of the Iterated Prisoner's Dilemma. We\nintroduce a strategy-modification method-independent of both the game and the\nprompt-by steering the residual stream with interpretable features extracted\nfrom a sparse autoencoder latent space. Steering with the good-faith\nnegotiation feature lowers the average defection probability by 28 percentage\npoints. We also identify feasible steering ranges for several open-source LLM\nagents. Finally, we hypothesise that game-theoretic evaluation of LLM agents,\ncombined with representation-steering alignment, can generalise to real-world\napplications on end-user devices and embodied platforms.", "AI": {"tldr": "The paper explores improving LLM agent reliability in game-theoretic environments using interpretable feature steering, reducing defection by 28%.", "motivation": "Address safety concerns about LLM agent unpredictability in responsible action domains.", "method": "Use a strategy-modification method steering the residual stream with interpretable features from a sparse autoencoder latent space.", "result": "Steering with good-faith negotiation reduces defection probability by 28%. Feasible steering ranges identified for open-source LLM agents.", "conclusion": "Game-theoretic evaluation and representation-steering alignment can generalize to real-world applications."}}
{"id": "2505.10714", "pdf": "https://arxiv.org/pdf/2505.10714", "abs": "https://arxiv.org/abs/2505.10714", "authors": ["Bowen Jiang", "Yangxinyu Xie", "Xiaomeng Wang", "Jiashu He", "Joshua Bergerson", "John K Hutchison", "Jordan Branham", "Camillo J Taylor", "Tanwi Mallick"], "title": "GeoGrid-Bench: Can Foundation Models Understand Multimodal Gridded Geo-Spatial Data?", "categories": ["cs.CL"], "comment": null, "summary": "We present GeoGrid-Bench, a benchmark designed to evaluate the ability of\nfoundation models to understand geo-spatial data in the grid structure.\nGeo-spatial datasets pose distinct challenges due to their dense numerical\nvalues, strong spatial and temporal dependencies, and unique multimodal\nrepresentations including tabular data, heatmaps, and geographic\nvisualizations. To assess how foundation models can support scientific research\nin this domain, GeoGrid-Bench features large-scale, real-world data covering 16\nclimate variables across 150 locations and extended time frames. The benchmark\nincludes approximately 3,200 question-answer pairs, systematically generated\nfrom 8 domain expert-curated templates to reflect practical tasks encountered\nby human scientists. These range from basic queries at a single location and\ntime to complex spatiotemporal comparisons across regions and periods. Our\nevaluation reveals that vision-language models perform best overall, and we\nprovide a fine-grained analysis of the strengths and limitations of different\nfoundation models in different geo-spatial tasks. This benchmark offers clearer\ninsights into how foundation models can be effectively applied to geo-spatial\ndata analysis and used to support scientific research.", "AI": {"tldr": "GeoGrid-Bench is a benchmark for evaluating foundation models on geo-spatial data, featuring 3,200 QA pairs from expert-curated templates. Vision-language models perform best.", "motivation": "To assess foundation models' ability to handle geo-spatial data challenges like dense numerical values, spatiotemporal dependencies, and multimodal representations.", "method": "Uses large-scale real-world data (16 climate variables, 150 locations) and 3,200 QA pairs from 8 expert templates, covering basic to complex tasks.", "result": "Vision-language models outperform others, with detailed analysis of strengths/limitations in geo-spatial tasks.", "conclusion": "GeoGrid-Bench clarifies how foundation models can effectively support geo-spatial data analysis and scientific research."}}
{"id": "2505.10599", "pdf": "https://arxiv.org/pdf/2505.10599", "abs": "https://arxiv.org/abs/2505.10599", "authors": ["Jiaxuan Liu", "Zhenhua Ling"], "title": "UDDETTS: Unifying Discrete and Dimensional Emotions for Controllable Emotional Text-to-Speech", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Under review", "summary": "Recent neural codec language models have made great progress in the field of\ntext-to-speech (TTS), but controllable emotional TTS still faces many\nchallenges. Traditional methods rely on predefined discrete emotion labels to\ncontrol emotion categories and intensities, which can't capture the complexity\nand continuity of human emotional perception and expression. The lack of\nlarge-scale emotional speech datasets with balanced emotion distributions and\nfine-grained emotion annotations often causes overfitting in synthesis models\nand impedes effective emotion control. To address these issues, we propose\nUDDETTS, a neural codec language model unifying discrete and dimensional\nemotions for controllable emotional TTS. This model introduces the\ninterpretable Arousal-Dominance-Valence (ADV) space for dimensional emotion\ndescription and supports emotion control driven by either discrete emotion\nlabels or nonlinearly quantified ADV values. Furthermore, a semi-supervised\ntraining strategy is designed to comprehensively utilize diverse speech\ndatasets with different types of emotion annotations to train the UDDETTS.\nExperiments show that UDDETTS achieves linear emotion control along the three\ndimensions of ADV space, and exhibits superior end-to-end emotional speech\nsynthesis capabilities.", "AI": {"tldr": "UDDETTS is a neural codec language model for controllable emotional TTS, combining discrete and dimensional emotions using the ADV space, and trained semi-supervisedly for superior synthesis.", "motivation": "Challenges in controllable emotional TTS include predefined discrete labels lacking nuance and limited datasets causing overfitting.", "method": "Proposes UDDETTS, integrating the ADV space for dimensional emotion control and using semi-supervised training with diverse datasets.", "result": "UDDETTS achieves linear emotion control in ADV space and superior emotional speech synthesis.", "conclusion": "UDDETTS effectively addresses challenges in emotional TTS by unifying discrete and dimensional emotion control."}}
{"id": "2505.10922", "pdf": "https://arxiv.org/pdf/2505.10922", "abs": "https://arxiv.org/abs/2505.10922", "authors": ["Binwen Liu", "Jiexi Ge", "Jiamin Wang"], "title": "Vaiage: A Multi-Agent Solution to Personalized Travel Planning", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Planning trips is a cognitively intensive task involving conflicting user\npreferences, dynamic external information, and multi-step temporal-spatial\noptimization. Traditional platforms often fall short - they provide static\nresults, lack contextual adaptation, and fail to support real-time interaction\nor intent refinement.\n  Our approach, Vaiage, addresses these challenges through a graph-structured\nmulti-agent framework built around large language models (LLMs) that serve as\nboth goal-conditioned recommenders and sequential planners. LLMs infer user\nintent, suggest personalized destinations and activities, and synthesize\nitineraries that align with contextual constraints such as budget, timing,\ngroup size, and weather. Through natural language interaction, structured tool\nuse, and map-based feedback loops, Vaiage enables adaptive, explainable, and\nend-to-end travel planning grounded in both symbolic reasoning and\nconversational understanding.\n  To evaluate Vaiage, we conducted human-in-the-loop experiments using\nrubric-based GPT-4 assessments and qualitative feedback. The full system\nachieved an average score of 8.5 out of 10, outperforming the no-strategy (7.2)\nand no-external-API (6.8) variants, particularly in feasibility. Qualitative\nanalysis indicated that agent coordination - especially the Strategy and\nInformation Agents - significantly improved itinerary quality by optimizing\ntime use and integrating real-time context. These results demonstrate the\neffectiveness of combining LLM reasoning with symbolic agent coordination in\nopen-ended, real-world planning tasks.", "AI": {"tldr": "Vaiage is a multi-agent framework using LLMs for adaptive, explainable travel planning, outperforming traditional methods in feasibility and quality.", "motivation": "Traditional trip planning platforms are static and lack contextual adaptation, failing to support real-time interaction or intent refinement.", "method": "Vaiage employs a graph-structured multi-agent framework with LLMs for intent inference, personalized recommendations, and itinerary synthesis, integrating natural language interaction and map-based feedback.", "result": "Vaiage scored 8.5/10 in human-in-the-loop experiments, outperforming variants without strategy (7.2) or external APIs (6.8), with qualitative improvements in itinerary quality.", "conclusion": "Combining LLM reasoning with symbolic agent coordination effectively addresses open-ended, real-world planning tasks like travel."}}
{"id": "2505.11079", "pdf": "https://arxiv.org/pdf/2505.11079", "abs": "https://arxiv.org/abs/2505.11079", "authors": ["Hao Gu", "Jiangyan Yi", "Chenglong Wang", "Jianhua Tao", "Zheng Lian", "Jiayi He", "Yong Ren", "Yujie Chen", "Zhengqi Wen"], "title": "$\\mathcal{A}LLM4ADD$: Unlocking the Capabilities of Audio Large Language Models for Audio Deepfake Detection", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Audio deepfake detection (ADD) has grown increasingly important due to the\nrise of high-fidelity audio generative models and their potential for misuse.\nGiven that audio large language models (ALLMs) have made significant progress\nin various audio processing tasks, a heuristic question arises: Can ALLMs be\nleveraged to solve ADD?. In this paper, we first conduct a comprehensive\nzero-shot evaluation of ALLMs on ADD, revealing their ineffectiveness in\ndetecting fake audio. To enhance their performance, we propose\n$\\mathcal{A}LLM4ADD$, an ALLM-driven framework for ADD. Specifically, we\nreformulate ADD task as an audio question answering problem, prompting the\nmodel with the question: \"Is this audio fake or real?\". We then perform\nsupervised fine-tuning to enable the ALLM to assess the authenticity of query\naudio. Extensive experiments are conducted to demonstrate that our ALLM-based\nmethod can achieve superior performance in fake audio detection, particularly\nin data-scarce scenarios. As a pioneering study, we anticipate that this work\nwill inspire the research community to leverage ALLMs to develop more effective\nADD systems.", "AI": {"tldr": "The paper explores using Audio Large Language Models (ALLMs) for Audio Deepfake Detection (ADD), proposing a framework called $\\mathcal{A}LLM4ADD$ that reformulates ADD as an audio question-answering task. Despite initial zero-shot ineffectiveness, fine-tuned ALLMs achieve superior performance, especially in data-scarce scenarios.", "motivation": "The rise of high-fidelity audio generative models and their misuse potential necessitates effective ADD solutions. ALLMs' success in audio tasks prompts investigation into their applicability for ADD.", "method": "The study first evaluates ALLMs' zero-shot performance on ADD, then proposes $\\mathcal{A}LLM4ADD$, reformulating ADD as an audio question-answering task and fine-tuning ALLMs for authenticity assessment.", "result": "Fine-tuned ALLMs outperform in fake audio detection, particularly in data-scarce settings, demonstrating the framework's effectiveness.", "conclusion": "The work pioneers ALLM application in ADD, showing promise for future research and development of more effective detection systems."}}
{"id": "2505.11275", "pdf": "https://arxiv.org/pdf/2505.11275", "abs": "https://arxiv.org/abs/2505.11275", "authors": ["Pengju Xu", "Yan Wang", "Shuyuan Zhang", "Xuan Zhou", "Xin Li", "Yue Yuan", "Fengzhao Li", "Shunyuan Zhou", "Xingyu Wang", "Yi Zhang", "Haiying Zhao"], "title": "TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs", "categories": ["cs.MM", "cs.AI", "cs.CY"], "comment": "Preprint", "summary": "Recent progress in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced the ability of artificial intelligence systems to\nunderstand and generate multimodal content. However, these models often exhibit\nlimited effectiveness when applied to non-Western cultural contexts, which\nraises concerns about their wider applicability. To address this limitation, we\npropose the \\textbf{T}raditional \\textbf{C}hinese \\textbf{C}ulture\nunderstanding \\textbf{Bench}mark (\\textbf{TCC-Bench}), a bilingual\n(\\textit{i.e.}, Chinese and English) Visual Question Answering (VQA) benchmark\nspecifically designed for assessing the understanding of traditional Chinese\nculture by MLLMs. TCC-Bench comprises culturally rich and visually diverse\ndata, incorporating images from museum artifacts, everyday life scenes, comics,\nand other culturally significant contexts. We adopt a semi-automated pipeline\nthat utilizes GPT-4o in text-only mode to generate candidate questions,\nfollowed by human curation to ensure data quality and avoid potential data\nleakage. The benchmark also avoids language bias by preventing direct\ndisclosure of cultural concepts within question texts. Experimental evaluations\nacross a wide range of MLLMs demonstrate that current models still face\nsignificant challenges when reasoning about culturally grounded visual content.\nThe results highlight the need for further research in developing culturally\ninclusive and context-aware multimodal systems. The code and data can be found\nat: https://github.com/Morty-Xu/TCC-Bench.", "AI": {"tldr": "TCC-Bench is a bilingual VQA benchmark for evaluating MLLMs' understanding of traditional Chinese culture, revealing current models' limitations in culturally grounded reasoning.", "motivation": "Address the limited effectiveness of MLLMs in non-Western cultural contexts by creating a culturally rich benchmark.", "method": "Develop TCC-Bench using a semi-automated pipeline with GPT-4o for question generation and human curation for quality.", "result": "Current MLLMs struggle with culturally grounded visual content, showing gaps in cultural inclusivity.", "conclusion": "Further research is needed to develop culturally inclusive and context-aware multimodal systems."}}
{"id": "2505.10578", "pdf": "https://arxiv.org/pdf/2505.10578", "abs": "https://arxiv.org/abs/2505.10578", "authors": ["Yunji Feng", "Chengpu Yu", "Fengrui Ran", "Zhi Yang", "Yinni Liu"], "title": "ExploreGS: a vision-based low overhead framework for 3D scene reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "This paper proposes a low-overhead, vision-based 3D scene reconstruction\nframework for drones, named ExploreGS. By using RGB images, ExploreGS replaces\ntraditional lidar-based point cloud acquisition process with a vision model,\nachieving a high-quality reconstruction at a lower cost. The framework\nintegrates scene exploration and model reconstruction, and leverags a\nBag-of-Words(BoW) model to enable real-time processing capabilities, therefore,\nthe 3D Gaussian Splatting (3DGS) training can be executed on-board.\nComprehensive experiments in both simulation and real-world environments\ndemonstrate the efficiency and applicability of the ExploreGS framework on\nresource-constrained devices, while maintaining reconstruction quality\ncomparable to state-of-the-art methods.", "AI": {"tldr": "ExploreGS is a vision-based 3D scene reconstruction framework for drones, replacing lidar with RGB images for cost-effective, high-quality results.", "motivation": "To provide a low-cost, efficient alternative to lidar-based 3D reconstruction for drones.", "method": "Uses RGB images and integrates scene exploration with reconstruction, employing a BoW model for real-time processing and on-board 3DGS training.", "result": "Achieves high-quality reconstruction comparable to state-of-the-art methods, even on resource-constrained devices.", "conclusion": "ExploreGS is an efficient, cost-effective solution for drone-based 3D scene reconstruction."}}
{"id": "2505.10975", "pdf": "https://arxiv.org/pdf/2505.10975", "abs": "https://arxiv.org/abs/2505.10975", "authors": ["Xinlu He", "Jacob Whitehill"], "title": "Survey of End-to-End Multi-Speaker Automatic Speech Recognition for Monaural Audio", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": "13 pages. Submitted to IEEE/ACM Transaction on Audio Speech and\n  Language Processing (TASLP)", "summary": "Monaural multi-speaker automatic speech recognition (ASR) remains challenging\ndue to data scarcity and the intrinsic difficulty of recognizing and\nattributing words to individual speakers, particularly in overlapping speech.\nRecent advances have driven the shift from cascade systems to end-to-end (E2E)\narchitectures, which reduce error propagation and better exploit the synergy\nbetween speech content and speaker identity. Despite rapid progress in E2E\nmulti-speaker ASR, the field lacks a comprehensive review of recent\ndevelopments. This survey provides a systematic taxonomy of E2E neural\napproaches for multi-speaker ASR, highlighting recent advances and comparative\nanalysis. Specifically, we analyze: (1) architectural paradigms (SIMO vs.~SISO)\nfor pre-segmented audio, analyzing their distinct characteristics and\ntrade-offs; (2) recent architectural and algorithmic improvements based on\nthese two paradigms; (3) extensions to long-form speech, including segmentation\nstrategy and speaker-consistent hypothesis stitching. Further, we (4) evaluate\nand compare methods across standard benchmarks. We conclude with a discussion\nof open challenges and future research directions towards building robust and\nscalable multi-speaker ASR.", "AI": {"tldr": "This survey reviews end-to-end (E2E) neural approaches for monaural multi-speaker ASR, covering architectural paradigms, recent improvements, extensions to long-form speech, and benchmark comparisons, while highlighting open challenges.", "motivation": "The field lacks a comprehensive review of recent E2E advancements in multi-speaker ASR, which is crucial for addressing data scarcity and overlapping speech challenges.", "method": "The paper systematically categorizes E2E approaches (SIMO vs. SISO), analyzes architectural and algorithmic improvements, and evaluates methods on standard benchmarks.", "result": "The survey provides insights into trade-offs, recent advances, and performance comparisons, aiding in understanding robust multi-speaker ASR solutions.", "conclusion": "Open challenges remain in scalability and robustness, guiding future research directions for multi-speaker ASR."}}
{"id": "2505.10583", "pdf": "https://arxiv.org/pdf/2505.10583", "abs": "https://arxiv.org/abs/2505.10583", "authors": ["Diogo Freitas", "Brigt H\u00e5vardstun", "C\u00e8sar Ferri", "Dar\u00edo Garigliotti", "Jan Arne Telle", "Jos\u00e9 Hern\u00e1ndez-Orallo"], "title": "Relative Drawing Identification Complexity is Invariant to Modality in Vision-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": "54 pages (42 pages of appendix)", "summary": "Large language models have become multimodal, and many of them are said to\nintegrate their modalities using common representations. If this were true, a\ndrawing of a car as an image, for instance, should map to the similar area in\nthe latent space as a textual description of the strokes that conform the\ndrawing. To explore this in a black-box access regime to these models, we\npropose the use of machine teaching, a theory that studies the minimal set of\nexamples a teacher needs to choose so that the learner captures the concept. In\nthis paper we evaluate the complexity of teaching visual-language models a\nsubset of objects in the Quick, Draw! dataset using two presentations: raw\nimages as bitmaps and trace coordinates in TikZ format. The results indicate\nthat image-based representations generally require fewer segments and achieve\nhigher accuracy than coordinate-based representations. But, surprisingly, the\nteaching size usually ranks concepts similarly across both modalities, even\nwhen controlling for (a human proxy of) concept priors, suggesting that the\nsimplicity of concepts may be an inherent property that transcends modality\nrepresentations.", "AI": {"tldr": "The paper explores whether multimodal language models use common representations for different modalities (e.g., images and text) by teaching them concepts from the Quick, Draw! dataset using images and coordinate-based descriptions. Results show images require fewer teaching examples and achieve higher accuracy, but concept simplicity ranks similarly across modalities.", "motivation": "To investigate if multimodal language models integrate modalities using common representations, focusing on whether visual and textual descriptions of the same concept map similarly in latent space.", "method": "Uses machine teaching to evaluate the complexity of teaching visual-language models concepts from Quick, Draw! dataset, comparing raw images (bitmaps) and trace coordinates (TikZ format).", "result": "Image-based representations require fewer teaching segments and achieve higher accuracy than coordinate-based ones, but concept simplicity rankings are similar across modalities.", "conclusion": "Concept simplicity may be an inherent property transcending modality representations, suggesting multimodal models align modalities meaningfully."}}
{"id": "2505.10705", "pdf": "https://arxiv.org/pdf/2505.10705", "abs": "https://arxiv.org/abs/2505.10705", "authors": ["Matej Hoffmann", "Shubhan Parag Patni"], "title": "Embodied AI in Machine Learning -- is it Really Embodied?", "categories": ["cs.AI", "cs.NE", "cs.RO", "68T40", "I.2.9"], "comment": "16 pages, 3 figures", "summary": "Embodied Artificial Intelligence (Embodied AI) is gaining momentum in the\nmachine learning communities with the goal of leveraging current progress in AI\n(deep learning, transformers, large language and visual-language models) to\nempower robots. In this chapter we put this work in the context of \"Good\nOld-Fashioned Artificial Intelligence\" (GOFAI) (Haugeland, 1989) and the\nbehavior-based or embodied alternatives (R. A. Brooks 1991; Pfeifer and Scheier\n2001). We claim that the AI-powered robots are only weakly embodied and inherit\nsome of the problems of GOFAI. Moreover, we review and critically discuss the\npossibility of cross-embodiment learning (Padalkar et al. 2024). We identify\nfundamental roadblocks and propose directions on how to make progress.", "AI": {"tldr": "The paper critiques current AI-powered robots as weakly embodied, linking them to GOFAI issues, and discusses challenges in cross-embodiment learning.", "motivation": "To contextualize Embodied AI within GOFAI and behavior-based alternatives, highlighting limitations in current approaches.", "method": "Review and critical discussion of cross-embodiment learning, identifying roadblocks.", "result": "Identifies fundamental challenges in achieving strong embodiment in AI-powered robots.", "conclusion": "Proposes directions for progress in making AI-powered robots more strongly embodied."}}
{"id": "2505.10717", "pdf": "https://arxiv.org/pdf/2505.10717", "abs": "https://arxiv.org/abs/2505.10717", "authors": ["Jean-Philippe Corbeil", "Amin Dada", "Jean-Michel Attendu", "Asma Ben Abacha", "Alessandro Sordoni", "Lucas Caccia", "Fran\u00e7ois Beaulieu", "Thomas Lin", "Jens Kleesiek", "Paul Vozila"], "title": "A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "High computation costs and latency of large language models such as GPT-4\nhave limited their deployment in clinical settings. Small language models\n(SLMs) offer a cost-effective alternative, but their limited capacity requires\nbiomedical domain adaptation, which remains challenging. An additional\nbottleneck is the unavailability and high sensitivity of clinical data. To\naddress these challenges, we propose a novel framework for adapting SLMs into\nhigh-performing clinical models. We introduce the MediPhi collection of\n3.8B-parameter SLMs developed with our novel framework: pre-instruction tuning\nof experts on relevant medical and clinical corpora (PMC, Medical Guideline,\nMedWiki, etc.), model merging, and clinical-tasks alignment. To cover most\nclinical tasks, we extended the CLUE benchmark to CLUE+, doubling its size. Our\nexpert models deliver relative improvements on this benchmark over the base\nmodel without any task-specific fine-tuning: 64.3% on medical entities, 49.5%\non radiology reports, and 44% on ICD-10 coding (outperforming GPT-4-0125 by\n14%). We unify the expert models into MediPhi via model merging, preserving\ngains across benchmarks. Furthermore, we built the MediFlow collection, a\nsynthetic dataset of 2.5 million high-quality instructions on 14 medical NLP\ntasks, 98 fine-grained document types, and JSON format support. Alignment of\nMediPhi using supervised fine-tuning and direct preference optimization\nachieves further gains of 18.9% on average.", "AI": {"tldr": "A framework for adapting small language models (SLMs) into high-performing clinical models, outperforming GPT-4 in some tasks.", "motivation": "High computation costs and latency of large models like GPT-4 limit clinical deployment, while SLMs need biomedical domain adaptation.", "method": "Pre-instruction tuning, model merging, and clinical-tasks alignment using the MediPhi framework and CLUE+ benchmark.", "result": "Relative improvements over base models: 64.3% on medical entities, 49.5% on radiology reports, and 44% on ICD-10 coding (outperforming GPT-4 by 14%).", "conclusion": "The MediPhi framework and synthetic dataset MediFlow enable efficient adaptation of SLMs for clinical tasks, achieving significant performance gains."}}
{"id": "2505.10600", "pdf": "https://arxiv.org/pdf/2505.10600", "abs": "https://arxiv.org/abs/2505.10600", "authors": ["Md. Ehsanul Haque", "Md. Saymon Hosen Polash", "Md Al-Imran Sanjida Simla", "Md Alomgir Hossain", "Sarwar Jahan"], "title": "Enhancing IoT Cyber Attack Detection in the Presence of Highly Imbalanced Data", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Published paper of CSNT2025", "summary": "Due to the rapid growth in the number of Internet of Things (IoT) networks,\nthe cyber risk has increased exponentially, and therefore, we have to develop\neffective IDS that can work well with highly imbalanced datasets. A high rate\nof missed threats can be the result, as traditional machine learning models\ntend to struggle in identifying attacks when normal data volume is much higher\nthan the volume of attacks. For example, the dataset used in this study reveals\na strong class imbalance with 94,659 instances of the majority class and only\n28 instances of the minority class, making it quite challenging to determine\nrare attacks accurately. The challenges presented in this research are\naddressed by hybrid sampling techniques designed to improve data imbalance\ndetection accuracy in IoT domains. After applying these techniques, we evaluate\nthe performance of several machine learning models such as Random Forest, Soft\nVoting, Support Vector Classifier (SVC), K-Nearest Neighbors (KNN), Multi-Layer\nPerceptron (MLP), and Logistic Regression with respect to the classification of\ncyber-attacks. The obtained results indicate that the Random Forest model\nachieved the best performance with a Kappa score of 0.9903, test accuracy of\n0.9961, and AUC of 0.9994. Strong performance is also shown by the Soft Voting\nmodel, with an accuracy of 0.9952 and AUC of 0.9997, indicating the benefits of\ncombining model predictions. Overall, this work demonstrates the value of\nhybrid sampling combined with robust model and feature selection for\nsignificantly improving IoT security against cyber-attacks, especially in\nhighly imbalanced data environments.", "AI": {"tldr": "Hybrid sampling techniques improve IoT IDS performance on imbalanced datasets, with Random Forest and Soft Voting models showing top results.", "motivation": "The rapid growth of IoT networks increases cyber risks, requiring effective IDS for imbalanced datasets where traditional models struggle.", "method": "Hybrid sampling techniques are applied to address data imbalance, followed by evaluating machine learning models like Random Forest, Soft Voting, SVC, KNN, MLP, and Logistic Regression.", "result": "Random Forest achieved the best performance (Kappa: 0.9903, accuracy: 0.9961, AUC: 0.9994), with Soft Voting also performing well (accuracy: 0.9952, AUC: 0.9997).", "conclusion": "Hybrid sampling and robust model selection significantly enhance IoT security in imbalanced data environments."}}
{"id": "2505.11311", "pdf": "https://arxiv.org/pdf/2505.11311", "abs": "https://arxiv.org/abs/2505.11311", "authors": ["Ardian Selmonaj", "Alessandro Antonucci", "Adrian Schneider", "Michael R\u00fcegsegger", "Matthias Sommer"], "title": "Explaining Strategic Decisions in Multi-Agent Reinforcement Learning for Aerial Combat Tactics", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": "Published as a journal chapter in NATO Journal of Science and\n  Technology", "summary": "Artificial intelligence (AI) is reshaping strategic planning, with\nMulti-Agent Reinforcement Learning (MARL) enabling coordination among\nautonomous agents in complex scenarios. However, its practical deployment in\nsensitive military contexts is constrained by the lack of explainability, which\nis an essential factor for trust, safety, and alignment with human strategies.\nThis work reviews and assesses current advances in explainability methods for\nMARL with a focus on simulated air combat scenarios. We proceed by adapting\nvarious explainability techniques to different aerial combat scenarios to gain\nexplanatory insights about the model behavior. By linking AI-generated tactics\nwith human-understandable reasoning, we emphasize the need for transparency to\nensure reliable deployment and meaningful human-machine interaction. By\nilluminating the crucial importance of explainability in advancing MARL for\noperational defense, our work supports not only strategic planning but also the\ntraining of military personnel with insightful and comprehensible analyses.", "AI": {"tldr": "The paper reviews explainability methods for Multi-Agent Reinforcement Learning (MARL) in military air combat, emphasizing transparency for trust and human alignment.", "motivation": "The lack of explainability in MARL limits its practical use in sensitive military contexts, where trust and safety are critical.", "method": "The work adapts explainability techniques to simulated air combat scenarios to analyze model behavior.", "result": "The study highlights the importance of linking AI tactics with human-understandable reasoning for reliable deployment.", "conclusion": "Explainability is crucial for advancing MARL in defense, aiding strategic planning and military training."}}
{"id": "2505.11200", "pdf": "https://arxiv.org/pdf/2505.11200", "abs": "https://arxiv.org/abs/2505.11200", "authors": ["Xihuai Wang", "Ziyi Zhao", "Siyu Ren", "Shao Zhang", "Song Li", "Xiaoyu Li", "Ziwen Wang", "Lin Qiu", "Guanglu Wan", "Xuezhi Cao", "Xunliang Cai", "Weinan Zhang"], "title": "Audio Turing Test: Benchmarking the Human-likeness of Large Language Model-based Text-to-Speech Systems in Chinese", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.HC", "cs.LG", "eess.AS"], "comment": "Under Review", "summary": "Recent advances in large language models (LLMs) have significantly improved\ntext-to-speech (TTS) systems, enhancing control over speech style, naturalness,\nand emotional expression, which brings TTS Systems closer to human-level\nperformance. Although the Mean Opinion Score (MOS) remains the standard for TTS\nSystem evaluation, it suffers from subjectivity, environmental inconsistencies,\nand limited interpretability. Existing evaluation datasets also lack a\nmulti-dimensional design, often neglecting factors such as speaking styles,\ncontext diversity, and trap utterances, which is particularly evident in\nChinese TTS evaluation. To address these challenges, we introduce the Audio\nTuring Test (ATT), a multi-dimensional Chinese corpus dataset ATT-Corpus paired\nwith a simple, Turing-Test-inspired evaluation protocol. Instead of relying on\ncomplex MOS scales or direct model comparisons, ATT asks evaluators to judge\nwhether a voice sounds human. This simplification reduces rating bias and\nimproves evaluation robustness. To further support rapid model development, we\nalso finetune Qwen2-Audio-Instruct with human judgment data as Auto-ATT for\nautomatic evaluation. Experimental results show that ATT effectively\ndifferentiates models across specific capability dimensions using its\nmulti-dimensional design. Auto-ATT also demonstrates strong alignment with\nhuman evaluations, confirming its value as a fast and reliable assessment tool.\nThe white-box ATT-Corpus and Auto-ATT can be found in ATT Hugging Face\nCollection\n(https://huggingface.co/collections/meituan/audio-turing-test-682446320368164faeaf38a4).", "AI": {"tldr": "The paper introduces the Audio Turing Test (ATT) and ATT-Corpus, a multi-dimensional Chinese dataset, to improve TTS evaluation by simplifying human judgment and reducing bias. It also presents Auto-ATT, a finetuned model for automatic evaluation, showing strong alignment with human judgments.", "motivation": "Current TTS evaluation methods like MOS are subjective and lack multi-dimensional design, especially for Chinese TTS. The paper aims to address these limitations with a simpler, more robust approach.", "method": "The authors propose ATT, a Turing-Test-inspired protocol where evaluators judge if a voice sounds human. They also develop ATT-Corpus, a multi-dimensional Chinese dataset, and finetune Qwen2-Audio-Instruct (Auto-ATT) for automatic evaluation.", "result": "ATT effectively differentiates TTS models across specific dimensions, and Auto-ATT aligns well with human evaluations, proving its reliability for fast assessment.", "conclusion": "ATT and Auto-ATT offer a robust, simplified alternative to traditional TTS evaluation methods, with potential for broader application in model development."}}
{"id": "2505.10824", "pdf": "https://arxiv.org/pdf/2505.10824", "abs": "https://arxiv.org/abs/2505.10824", "authors": ["Kaifa Yang", "Qi Yang", "Zhu Li", "Yiling Xu"], "title": "Textured mesh Quality Assessment using Geometry and Color Field Similarity", "categories": ["cs.GR", "cs.CV", "cs.MM"], "comment": "15 pages main content, 4 pages supplementary material. Submitted to\n  IEEE Transactions on Visualization and Computer Graphics (IEEE TVCG) for\n  review", "summary": "Textured mesh quality assessment (TMQA) is critical for various 3D mesh\napplications. However, existing TMQA methods often struggle to provide accurate\nand robust evaluations. Motivated by the effectiveness of fields in\nrepresenting both 3D geometry and color information, we propose a novel\npoint-based TMQA method called field mesh quality metric (FMQM). FMQM utilizes\nsigned distance fields and a newly proposed color field named nearest surface\npoint color field to realize effective mesh feature description. Four features\nrelated to visual perception are extracted from the geometry and color fields:\ngeometry similarity, geometry gradient similarity, space color distribution\nsimilarity, and space color gradient similarity. Experimental results on three\nbenchmark datasets demonstrate that FMQM outperforms state-of-the-art (SOTA)\nTMQA metrics. Furthermore, FMQM exhibits low computational complexity, making\nit a practical and efficient solution for real-world applications in 3D\ngraphics and visualization. Our code is publicly available at:\nhttps://github.com/yyyykf/FMQM.", "AI": {"tldr": "A novel point-based TMQA method, FMQM, outperforms SOTA metrics by leveraging signed distance fields and a new color field for effective mesh feature description.", "motivation": "Existing TMQA methods lack accuracy and robustness; fields effectively represent 3D geometry and color, inspiring FMQM.", "method": "FMQM uses signed distance fields and a new color field to extract four visual perception features for mesh quality assessment.", "result": "FMQM outperforms SOTA metrics on three benchmark datasets and has low computational complexity.", "conclusion": "FMQM is a practical, efficient solution for 3D graphics and visualization, with publicly available code."}}
{"id": "2505.10672", "pdf": "https://arxiv.org/pdf/2505.10672", "abs": "https://arxiv.org/abs/2505.10672", "authors": ["Hania Ghouse", "Muzammil Behzad"], "title": "MOSAIC: A Multi-View 2.5D Organ Slice Selector with Cross-Attentional Reasoning for Anatomically-Aware CT Localization in Medical Organ Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Efficient and accurate multi-organ segmentation from abdominal CT volumes is\na fundamental challenge in medical image analysis. Existing 3D segmentation\napproaches are computationally and memory intensive, often processing entire\nvolumes that contain many anatomically irrelevant slices. Meanwhile, 2D methods\nsuffer from class imbalance and lack cross-view contextual awareness. To\naddress these limitations, we propose a novel, anatomically-aware slice\nselector pipeline that reduces input volume prior to segmentation. Our unified\nframework introduces a vision-language model (VLM) for cross-view organ\npresence detection using fused tri-slice (2.5D) representations from axial,\nsagittal, and coronal planes. Our proposed model acts as an \"expert\" in\nanatomical localization, reasoning over multi-view representations to\nselectively retain slices with high structural relevance. This enables\nspatially consistent filtering across orientations while preserving contextual\ncues. More importantly, since standard segmentation metrics such as Dice or IoU\nfail to measure the spatial precision of such slice selection, we introduce a\nnovel metric, Slice Localization Concordance (SLC), which jointly captures\nanatomical coverage and spatial alignment with organ-centric reference slices.\nUnlike segmentation-specific metrics, SLC provides a model-agnostic evaluation\nof localization fidelity. Our model offers substantial improvement gains\nagainst several baselines across all organs, demonstrating both accurate and\nreliable organ-focused slice filtering. These results show that our method\nenables efficient and spatially consistent organ filtering, thereby\nsignificantly reducing downstream segmentation cost while maintaining high\nanatomical fidelity.", "AI": {"tldr": "A novel anatomically-aware slice selector pipeline using a vision-language model (VLM) improves multi-organ segmentation by filtering irrelevant slices, introducing a new metric (SLC) for localization fidelity.", "motivation": "Existing 3D segmentation is resource-heavy, while 2D methods lack contextual awareness. The paper aims to address these inefficiencies.", "method": "Proposes a VLM-based pipeline for cross-view organ presence detection using tri-slice (2.5D) representations, selectively retaining relevant slices.", "result": "Substantial improvements over baselines, with accurate and reliable organ-focused slice filtering, reducing segmentation costs.", "conclusion": "The method efficiently filters slices, maintaining anatomical fidelity and reducing computational burden for downstream tasks."}}
{"id": "2505.11020", "pdf": "https://arxiv.org/pdf/2505.11020", "abs": "https://arxiv.org/abs/2505.11020", "authors": ["Yi-Lu Jiang", "Wen-Chang Chang", "Ching-Lin Wang", "Kung-Liang Hsu", "Chih-Yi Chiu"], "title": "Classifying Shelf Life Quality of Pineapples by Combining Audio and Visual Features", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "Determining the shelf life quality of pineapples using non-destructive\nmethods is a crucial step to reduce waste and increase income. In this paper, a\nmultimodal and multiview classification model was constructed to classify\npineapples into four quality levels based on audio and visual characteristics.\nFor research purposes, we compiled and released the PQC500 dataset consisting\nof 500 pineapples with two modalities: one was tapping pineapples to record\nsounds by multiple microphones and the other was taking pictures by multiple\ncameras at different locations, providing multimodal and multi-view audiovisual\nfeatures. We modified the contrastive audiovisual masked autoencoder to train\nthe cross-modal-based classification model by abundant combinations of audio\nand visual pairs. In addition, we proposed to sample a compact size of training\ndata for efficient computation. The experiments were evaluated under various\ndata and model configurations, and the results demonstrated that the proposed\ncross-modal model trained using audio-major sampling can yield 84% accuracy,\noutperforming the unimodal models of only audio and only visual by 6% and 18%,\nrespectively.", "AI": {"tldr": "A multimodal and multiview classification model was developed to classify pineapple quality using audio and visual features, achieving 84% accuracy.", "motivation": "To reduce waste and increase income by non-destructively determining pineapple shelf life quality.", "method": "Constructed a cross-modal classification model using audio and visual data from the PQC500 dataset, employing contrastive audiovisual masked autoencoder training and compact sampling.", "result": "The model achieved 84% accuracy, outperforming unimodal audio (78%) and visual (66%) models.", "conclusion": "The cross-modal approach is effective for pineapple quality classification, offering practical benefits for shelf life assessment."}}
{"id": "2505.10584", "pdf": "https://arxiv.org/pdf/2505.10584", "abs": "https://arxiv.org/abs/2505.10584", "authors": ["Huafeng Shi", "Jianzhong Liang", "Rongchang Xie", "Xian Wu", "Cheng Chen", "Chang Liu"], "title": "Aquarius: A Family of Industry-Level Video Generation Models for Marketing Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "This report introduces Aquarius, a family of industry-level video generation\nmodels for marketing scenarios designed for thousands-xPU clusters and models\nwith hundreds of billions of parameters. Leveraging efficient engineering\narchitecture and algorithmic innovation, Aquarius demonstrates exceptional\nperformance in high-fidelity, multi-aspect-ratio, and long-duration video\nsynthesis. By disclosing the framework's design details, we aim to demystify\nindustrial-scale video generation systems and catalyze advancements in the\ngenerative video community. The Aquarius framework consists of five components:\nDistributed Graph and Video Data Processing Pipeline: Manages tens of thousands\nof CPUs and thousands of xPUs via automated task distribution, enabling\nefficient video data processing. Additionally, we are about to open-source the\nentire data processing framework named \"Aquarius-Datapipe\". Model Architectures\nfor Different Scales: Include a Single-DiT architecture for 2B models and a\nMultimodal-DiT architecture for 13.4B models, supporting multi-aspect ratios,\nmulti-resolution, and multi-duration video generation. High-Performance\ninfrastructure designed for video generation model training: Incorporating\nhybrid parallelism and fine-grained memory optimization strategies, this\ninfrastructure achieves 36% MFU at large scale. Multi-xPU Parallel Inference\nAcceleration: Utilizes diffusion cache and attention optimization to achieve a\n2.35x inference speedup. Multiple marketing-scenarios applications: Including\nimage-to-video, text-to-video (avatar), video inpainting and video\npersonalization, among others. More downstream applications and\nmulti-dimensional evaluation metrics will be added in the upcoming version\nupdates.", "AI": {"tldr": "Aquarius is a family of industry-level video generation models for marketing, designed for large-scale clusters and models with hundreds of billions of parameters, showcasing high-fidelity, multi-aspect-ratio, and long-duration video synthesis.", "motivation": "To demystify industrial-scale video generation systems and advance the generative video community by disclosing design details and open-sourcing components.", "method": "The framework includes distributed data processing, scalable model architectures (Single-DiT and Multimodal-DiT), high-performance training infrastructure, parallel inference acceleration, and marketing-specific applications.", "result": "Achieves 36% MFU in training, 2.35x inference speedup, and supports diverse video generation tasks like text-to-video and video inpainting.", "conclusion": "Aquarius demonstrates robust performance and scalability, with plans for further downstream applications and updates."}}
{"id": "2505.10742", "pdf": "https://arxiv.org/pdf/2505.10742", "abs": "https://arxiv.org/abs/2505.10742", "authors": ["Brandon Lepine", "Gawesha Weerantunga", "Juho Kim", "Pamela Mishkin", "Matthew Beane"], "title": "Evaluations at Work: Measuring the Capabilities of GenAI in Use", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Current AI benchmarks miss the messy, multi-turn nature of human-AI\ncollaboration. We present an evaluation framework that decomposes real-world\ntasks into interdependent subtasks, letting us track both LLM performance and\nusers' strategies across a dialogue. Complementing this framework, we develop a\nsuite of metrics, including a composite usage derived from semantic similarity,\nword overlap, and numerical matches; structural coherence; intra-turn\ndiversity; and a novel measure of the \"information frontier\" reflecting the\nalignment between AI outputs and users' working knowledge. We demonstrate our\nmethodology in a financial valuation task that mirrors real-world complexity.\nOur empirical findings reveal that while greater integration of LLM-generated\ncontent generally enhances output quality, its benefits are moderated by\nfactors such as response incoherence, excessive subtask diversity, and the\ndistance of provided information from users' existing knowledge. These results\nsuggest that proactive dialogue strategies designed to inject novelty may\ninadvertently undermine task performance. Our work thus advances a more\nholistic evaluation of human-AI collaboration, offering both a robust\nmethodological framework and actionable insights for developing more effective\nAI-augmented work processes.", "AI": {"tldr": "The paper introduces a framework for evaluating human-AI collaboration by decomposing tasks into subtasks and tracking performance and user strategies. It proposes metrics like semantic similarity, structural coherence, and a novel 'information frontier' measure. Findings show LLM integration improves output quality but is moderated by factors like incoherence and knowledge gaps.", "motivation": "Current AI benchmarks fail to capture the complexity of human-AI collaboration in multi-turn dialogues, necessitating a more nuanced evaluation framework.", "method": "The study decomposes real-world tasks into subtasks, tracks LLM performance and user strategies, and introduces metrics like semantic similarity and the 'information frontier.' A financial valuation task demonstrates the methodology.", "result": "Greater LLM integration enhances output quality but is moderated by response incoherence, subtask diversity, and knowledge gaps. Proactive novelty injection may harm performance.", "conclusion": "The work provides a holistic evaluation framework for human-AI collaboration and actionable insights for improving AI-augmented workflows."}}
{"id": "2505.10718", "pdf": "https://arxiv.org/pdf/2505.10718", "abs": "https://arxiv.org/abs/2505.10718", "authors": ["Siddharth Suresh", "Kushin Mukherjee", "Tyler Giallanza", "Xizheng Yu", "Mia Patil", "Jonathan D. Cohen", "Timothy T. Rogers"], "title": "AI-enhanced semantic feature norms for 786 concepts", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "8 pages, 5 figures", "summary": "Semantic feature norms have been foundational in the study of human\nconceptual knowledge, yet traditional methods face trade-offs between\nconcept/feature coverage and verifiability of quality due to the\nlabor-intensive nature of norming studies. Here, we introduce a novel approach\nthat augments a dataset of human-generated feature norms with responses from\nlarge language models (LLMs) while verifying the quality of norms against\nreliable human judgments. We find that our AI-enhanced feature norm dataset,\nNOVA: Norms Optimized Via AI, shows much higher feature density and overlap\namong concepts while outperforming a comparable human-only norm dataset and\nword-embedding models in predicting people's semantic similarity judgments.\nTaken together, we demonstrate that human conceptual knowledge is richer than\ncaptured in previous norm datasets and show that, with proper validation, LLMs\ncan serve as powerful tools for cognitive science research.", "AI": {"tldr": "The paper introduces NOVA, an AI-enhanced feature norm dataset combining human-generated norms with LLM responses, showing higher quality and predictive power than human-only datasets.", "motivation": "Traditional semantic feature norm methods are limited by labor-intensive processes and trade-offs between coverage and quality.", "method": "Augment human-generated feature norms with LLM responses and verify quality against human judgments.", "result": "NOVA outperforms human-only datasets and word-embedding models in predicting semantic similarity judgments.", "conclusion": "Human conceptual knowledge is richer than previously captured, and validated LLMs can enhance cognitive science research."}}
{"id": "2505.10606", "pdf": "https://arxiv.org/pdf/2505.10606", "abs": "https://arxiv.org/abs/2505.10606", "authors": ["Hector Pasten", "Felipe Urrutia", "Hector Jimenez", "Cristian B. Calderon", "Crist\u00f3bal Rojas", "Alexander Kozachinskiy"], "title": "Continuity and Isolation Lead to Doubts or Dilemmas in Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Understanding how Transformers work and how they process information is key\nto the theoretical and empirical advancement of these machines. In this work,\nwe demonstrate the existence of two phenomena in Transformers, namely isolation\nand continuity. Both of these phenomena hinder Transformers to learn even\nsimple pattern sequences. Isolation expresses that any learnable sequence must\nbe isolated from another learnable sequence, and hence some sequences cannot be\nlearned by a single Transformer at the same time. Continuity entails that an\nattractor basin forms around a learned sequence, such that any sequence falling\nin that basin will collapse towards the learned sequence. Here, we\nmathematically prove these phenomena emerge in all Transformers that use\ncompact positional encoding, and design rigorous experiments, demonstrating\nthat the theoretical limitations we shed light on occur on the practical scale.", "AI": {"tldr": "The paper identifies two phenomena in Transformers, isolation and continuity, which limit their ability to learn certain sequences. It proves these issues arise in Transformers with compact positional encoding and validates them experimentally.", "motivation": "To advance the understanding of Transformers by uncovering theoretical limitations in their learning capabilities, specifically isolation and continuity.", "method": "Mathematical proof of the phenomena in Transformers with compact positional encoding, supported by rigorous experiments.", "result": "Demonstrates that isolation and continuity hinder Transformers from learning simple sequences, with experimental validation.", "conclusion": "The findings highlight inherent limitations in Transformers, impacting their design and application."}}
{"id": "2505.10609", "pdf": "https://arxiv.org/pdf/2505.10609", "abs": "https://arxiv.org/abs/2505.10609", "authors": ["Ken Huang", "Vineeth Sai Narajala", "Idan Habler", "Akram Sheriff"], "title": "Agent Name Service (ANS): A Universal Directory for Secure AI Agent Discovery and Interoperability", "categories": ["cs.CR", "cs.AI", "cs.MA", "cs.NI"], "comment": "15 pages, 6 figures, 6 code listings, Supported and endorsed by OWASP\n  GenAI ASI Project", "summary": "The proliferation of AI agents requires robust mechanisms for secure\ndiscovery. This paper introduces the Agent Name Service (ANS), a novel\narchitecture based on DNS addressing the lack of a public agent discovery\nframework. ANS provides a protocol-agnostic registry infrastructure that\nleverages Public Key Infrastructure (PKI) certificates for verifiable agent\nidentity and trust. The architecture features several key innovations: a\nformalized agent registration and renewal mechanism for lifecycle management;\nDNS-inspired naming conventions with capability-aware resolution; a modular\nProtocol Adapter Layer supporting diverse communication standards (A2A, MCP,\nACP etc.); and precisely defined algorithms for secure resolution. We implement\nstructured communication using JSON Schema and conduct a comprehensive threat\nanalysis of our proposal. The result is a foundational directory service\naddressing the core challenges of secured discovery and interaction in\nmulti-agent systems, paving the way for future interoperable, trustworthy, and\nscalable agent ecosystems.", "AI": {"tldr": "The paper introduces the Agent Name Service (ANS), a DNS-inspired architecture for secure AI agent discovery, leveraging PKI for trust and offering modular, protocol-agnostic features.", "motivation": "Addressing the lack of a public framework for secure AI agent discovery in multi-agent systems.", "method": "ANS uses PKI certificates, DNS-inspired naming, a modular Protocol Adapter Layer, and JSON Schema for structured communication.", "result": "A foundational directory service enabling secure, interoperable, and scalable agent discovery and interaction.", "conclusion": "ANS provides a robust solution for secure agent discovery, supporting future trustworthy agent ecosystems."}}
{"id": "2505.11217", "pdf": "https://arxiv.org/pdf/2505.11217", "abs": "https://arxiv.org/abs/2505.11217", "authors": ["Yanhao Jia", "Ji Xie", "S Jivaganesh", "Hao Li", "Xu Wu", "Mengmi Zhang"], "title": "Seeing Sound, Hearing Sight: Uncovering Modality Bias and Conflict of AI models in Sound Localization", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM", "eess.AS"], "comment": "16 pages, 14 figures", "summary": "Imagine hearing a dog bark and turning toward the sound only to see a parked\ncar, while the real, silent dog sits elsewhere. Such sensory conflicts test\nperception, yet humans reliably resolve them by prioritizing sound over\nmisleading visuals. Despite advances in multimodal AI integrating vision and\naudio, little is known about how these systems handle cross-modal conflicts or\nwhether they favor one modality. In this study, we systematically examine\nmodality bias and conflict resolution in AI sound localization. We assess\nleading multimodal models and benchmark them against human performance in\npsychophysics experiments across six audiovisual conditions, including\ncongruent, conflicting, and absent cues. Humans consistently outperform AI,\ndemonstrating superior resilience to conflicting or missing visuals by relying\non auditory information. In contrast, AI models often default to visual input,\ndegrading performance to near chance levels. To address this, we finetune a\nstate-of-the-art model using a stereo audio-image dataset generated via 3D\nsimulations. Even with limited training data, the refined model surpasses\nexisting benchmarks. Notably, it also mirrors human-like horizontal\nlocalization bias favoring left-right precision-likely due to the stereo audio\nstructure reflecting human ear placement. These findings underscore how sensory\ninput quality and system architecture shape multimodal representation accuracy.", "AI": {"tldr": "The paper examines how AI models handle cross-modal conflicts in sound localization, comparing them to human performance. Humans prioritize sound over misleading visuals, while AI often defaults to visuals, degrading performance. Finetuning a model with stereo audio-image data improves results, even mirroring human-like biases.", "motivation": "To understand modality bias and conflict resolution in AI sound localization, given humans' superior ability to resolve sensory conflicts.", "method": "Systematically assess leading multimodal models against human performance in psychophysics experiments across six audiovisual conditions. Finetune a state-of-the-art model using stereo audio-image data from 3D simulations.", "result": "Humans outperform AI in handling conflicting or missing visuals. Finetuned AI models surpass benchmarks and show human-like horizontal localization bias.", "conclusion": "Sensory input quality and system architecture critically influence multimodal representation accuracy, with finetuned models bridging gaps between AI and human performance."}}
{"id": "2505.11013", "pdf": "https://arxiv.org/pdf/2505.11013", "abs": "https://arxiv.org/abs/2505.11013", "authors": ["Zongye Zhang", "Bohan Kong", "Qingjie Liu", "Yunhong Wang"], "title": "Towards Robust and Controllable Text-to-Motion via Masked Autoregressive Diffusion", "categories": ["cs.CV", "cs.MM", "I.3.8"], "comment": "10 pages, 6 figures, 5 tables", "summary": "Generating 3D human motion from text descriptions remains challenging due to\nthe diverse and complex nature of human motion. While existing methods excel\nwithin the training distribution, they often struggle with out-of-distribution\nmotions, limiting their applicability in real-world scenarios. Existing\nVQVAE-based methods often fail to represent novel motions faithfully using\ndiscrete tokens, which hampers their ability to generalize beyond seen data.\nMeanwhile, diffusion-based methods operating on continuous representations\noften lack fine-grained control over individual frames. To address these\nchallenges, we propose a robust motion generation framework MoMADiff, which\ncombines masked modeling with diffusion processes to generate motion using\nframe-level continuous representations. Our model supports flexible\nuser-provided keyframe specification, enabling precise control over both\nspatial and temporal aspects of motion synthesis. MoMADiff demonstrates strong\ngeneralization capability on novel text-to-motion datasets with sparse\nkeyframes as motion prompts. Extensive experiments on two held-out datasets and\ntwo standard benchmarks show that our method consistently outperforms\nstate-of-the-art models in motion quality, instruction fidelity, and keyframe\nadherence.", "AI": {"tldr": "MoMADiff combines masked modeling and diffusion for robust 3D human motion generation from text, offering fine-grained control and strong generalization.", "motivation": "Existing methods struggle with out-of-distribution motions and lack fine-grained control, limiting real-world applicability.", "method": "MoMADiff integrates masked modeling with diffusion processes for frame-level continuous representations, supporting user-provided keyframes.", "result": "Outperforms state-of-the-art models in motion quality, instruction fidelity, and keyframe adherence on novel and benchmark datasets.", "conclusion": "MoMADiff addresses limitations of existing methods, providing robust and controllable motion synthesis."}}
{"id": "2505.10687", "pdf": "https://arxiv.org/pdf/2505.10687", "abs": "https://arxiv.org/abs/2505.10687", "authors": ["Sayed Mehedi Azim", "Brian Corbett", "Iman Dehzangi"], "title": "ROIsGAN: A Region Guided Generative Adversarial Framework for Murine Hippocampal Subregion Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.NC"], "comment": null, "summary": "The hippocampus, a critical brain structure involved in memory processing and\nvarious neurodegenerative and psychiatric disorders, comprises three key\nsubregions: the dentate gyrus (DG), Cornu Ammonis 1 (CA1), and Cornu Ammonis 3\n(CA3). Accurate segmentation of these subregions from histological tissue\nimages is essential for advancing our understanding of disease mechanisms,\ndevelopmental dynamics, and therapeutic interventions. However, no existing\nmethods address the automated segmentation of hippocampal subregions from\ntissue images, particularly from immunohistochemistry (IHC) images. To bridge\nthis gap, we introduce a novel set of four comprehensive murine hippocampal IHC\ndatasets featuring distinct staining modalities: cFos, NeuN, and multiplexed\nstains combining cFos, NeuN, and either {\\Delta}FosB or GAD67, capturing\nstructural, neuronal activity, and plasticity associated information.\nAdditionally, we propose ROIsGAN, a region-guided U-Net-based generative\nadversarial network tailored for hippocampal subregion segmentation. By\nleveraging adversarial learning, ROIsGAN enhances boundary delineation and\nstructural detail refinement through a novel region-guided discriminator loss\ncombining Dice and binary cross-entropy loss. Evaluated across DG, CA1, and CA3\nsubregions, ROIsGAN consistently outperforms conventional segmentation models,\nachieving performance gains ranging from 1-10% in Dice score and up to 11% in\nIntersection over Union (IoU), particularly under challenging staining\nconditions. Our work establishes foundational datasets and methods for\nautomated hippocampal segmentation, enabling scalable, high-precision analysis\nof tissue images in neuroscience research. Our generated datasets, proposed\nmodel as a standalone tool, and its corresponding source code are publicly\navailable at: https://github.com/MehediAzim/ROIsGAN", "AI": {"tldr": "The paper introduces ROIsGAN, a novel GAN-based method for automated segmentation of hippocampal subregions from IHC images, outperforming existing models by 1-10% in Dice score and up to 11% in IoU.", "motivation": "Accurate segmentation of hippocampal subregions (DG, CA1, CA3) from IHC images is crucial for understanding disease mechanisms and therapeutic interventions, but no automated methods exist.", "method": "Proposes ROIsGAN, a region-guided U-Net-based GAN, using adversarial learning and a novel discriminator loss combining Dice and binary cross-entropy for enhanced boundary delineation.", "result": "ROIsGAN outperforms conventional models, achieving significant performance gains (1-10% Dice, up to 11% IoU), especially under challenging staining conditions.", "conclusion": "The work provides foundational datasets and tools for automated hippocampal segmentation, advancing neuroscience research with scalable, high-precision analysis."}}
{"id": "2505.11051", "pdf": "https://arxiv.org/pdf/2505.11051", "abs": "https://arxiv.org/abs/2505.11051", "authors": ["Iwona Christop", "Maciej Czajka"], "title": "CAMEO: Collection of Multilingual Emotional Speech Corpora", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Under review at NeurIPS", "summary": "This paper presents CAMEO -- a curated collection of multilingual emotional\nspeech datasets designed to facilitate research in emotion recognition and\nother speech-related tasks. The main objectives were to ensure easy access to\nthe data, to allow reproducibility of the results, and to provide a\nstandardized benchmark for evaluating speech emotion recognition (SER) systems\nacross different emotional states and languages. The paper describes the\ndataset selection criteria, the curation and normalization process, and\nprovides performance results for several models. The collection, along with\nmetadata, and a leaderboard, is publicly available via the Hugging Face\nplatform.", "AI": {"tldr": "CAMEO is a multilingual emotional speech dataset collection for emotion recognition research, ensuring accessibility, reproducibility, and standardized benchmarking.", "motivation": "To facilitate research in emotion recognition and speech-related tasks by providing easy access to multilingual emotional speech data.", "method": "Describes dataset selection criteria, curation, normalization, and performance evaluation of models.", "result": "The collection, metadata, and a leaderboard are publicly available on Hugging Face.", "conclusion": "CAMEO serves as a valuable resource for standardized evaluation of speech emotion recognition systems across languages and emotional states."}}
{"id": "2505.10585", "pdf": "https://arxiv.org/pdf/2505.10585", "abs": "https://arxiv.org/abs/2505.10585", "authors": ["Azim Akhtarshenas", "Ramin Toosi", "David L\u00f3pez-P\u00e9rez", "Tohid Alizadeh", "Alireza Hosseini"], "title": "Efficient Malicious UAV Detection Using Autoencoder-TSMamba Integration", "categories": ["cs.CV", "cs.CR"], "comment": "12 pages, 6 figures and 3 tables, accepted in IbPRIA 2025,\n  https://www.ibpria.org/2025/?page=dates", "summary": "Malicious Unmanned Aerial Vehicles (UAVs) present a significant threat to\nnext-generation networks (NGNs), posing risks such as unauthorized\nsurveillance, data theft, and the delivery of hazardous materials. This paper\nproposes an integrated (AE)-classifier system to detect malicious UAVs. The\nproposed AE, based on a 4-layer Tri-orientated Spatial Mamba (TSMamba)\narchitecture, effectively captures complex spatial relationships crucial for\nidentifying malicious UAV activities. The first phase involves generating\nresidual values through the AE, which are subsequently processed by a\nResNet-based classifier. This classifier leverages the residual values to\nachieve lower complexity and higher accuracy. Our experiments demonstrate\nsignificant improvements in both binary and multi-class classification\nscenarios, achieving up to 99.8 % recall compared to 96.7 % in the benchmark.\nAdditionally, our method reduces computational complexity, making it more\nsuitable for large-scale deployment. These results highlight the robustness and\nscalability of our approach, offering an effective solution for malicious UAV\ndetection in NGN environments.", "AI": {"tldr": "The paper proposes an integrated AE-classifier system using a 4-layer TSMamba architecture to detect malicious UAVs, achieving high recall (99.8%) and reduced computational complexity.", "motivation": "Malicious UAVs threaten next-generation networks with risks like unauthorized surveillance and data theft, necessitating robust detection methods.", "method": "The system uses an AE to generate residual values, processed by a ResNet-based classifier for lower complexity and higher accuracy.", "result": "Achieves 99.8% recall in binary and multi-class scenarios, outperforming benchmarks (96.7%), with reduced computational complexity.", "conclusion": "The approach is robust, scalable, and effective for large-scale malicious UAV detection in NGNs."}}
{"id": "2505.10749", "pdf": "https://arxiv.org/pdf/2505.10749", "abs": "https://arxiv.org/abs/2505.10749", "authors": ["Ashwath Vaithinathan Aravindan", "Zhisheng Tang", "Mayank Kejriwal"], "title": "Code-Driven Planning in Grid Worlds with Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "We propose an iterative programmatic planning (IPP) framework for solving\ngrid-based tasks by synthesizing interpretable agent policies expressed in code\nusing large language models (LLMs). Instead of relying on traditional search or\nreinforcement learning, our approach uses code generation as policy synthesis,\nwhere the LLM outputs executable programs that map environment states to action\nsequences. Our proposed architecture incorporates several prompting strategies,\nincluding direct code generation, pseudocode-conditioned refinement, and\ncurriculum-based prompting, but also includes an iterative refinement mechanism\nthat updates code based on task performance feedback. We evaluate our approach\nusing six leading LLMs and two challenging grid-based benchmarks (GRASP and\nMiniGrid). Our IPP framework demonstrates improvements over direct code\ngeneration ranging from 10\\% to as much as 10x across five of the six models\nand establishes a new state-of-the-art result for GRASP. IPP is found to\nsignificantly outperform direct elicitation of a solution from GPT-o3-mini (by\n63\\% on MiniGrid to 116\\% on GRASP), demonstrating the viability of the overall\napproach. Computational costs of all code generation approaches are similar.\nWhile code generation has a higher initial prompting cost compared to direct\nsolution elicitation (\\$0.08 per task vs. \\$0.002 per instance for\nGPT-o3-mini), the code can be reused for any number of instances, making the\namortized cost significantly lower (by 400x on GPT-o3-mini across the complete\nGRASP benchmark).", "AI": {"tldr": "The paper introduces an iterative programmatic planning (IPP) framework using LLMs for synthesizing interpretable policies in code, outperforming direct code generation and establishing state-of-the-art results.", "motivation": "To create interpretable agent policies for grid-based tasks without relying on traditional search or reinforcement learning, leveraging LLMs for code generation.", "method": "Uses code generation as policy synthesis, incorporating prompting strategies (direct code generation, pseudocode refinement, curriculum-based prompting) and iterative refinement based on feedback.", "result": "IPP improves performance over direct code generation by 10% to 10x, achieving state-of-the-art on GRASP. It also reduces amortized costs significantly.", "conclusion": "IPP is a viable, cost-effective approach for synthesizing interpretable policies, demonstrating superior performance and reusability."}}
{"id": "2505.10719", "pdf": "https://arxiv.org/pdf/2505.10719", "abs": "https://arxiv.org/abs/2505.10719", "authors": ["Tom\u00e1s Vergara-Browne", "\u00c1lvaro Soto"], "title": "Tracr-Injection: Distilling Algorithms into Pre-trained Language Models", "categories": ["cs.CL"], "comment": "ACL Findings 2025", "summary": "Motivated by the surge of large language models, there has been a push to\nformally characterize the symbolic abilities intrinsic to the transformer\narchitecture. A programming language, called RASP, has been proposed, which can\nbe directly compiled into transformer weights to implement these algorithms.\nHowever, the tasks that can be implemented in RASP are often uncommon to learn\nfrom natural unsupervised data, showing a mismatch between theoretical\ncapabilities of the transformer architecture, and the practical learnability of\nthese capabilities from unsupervised data. We propose tracr-injection, a method\nthat allows us to distill algorithms written in RASP directly into a\npre-trained language model. We showcase our method by injecting 3 different\nalgorithms into a language model. We show how our method creates an\ninterpretable subspace within the model's residual stream, which can be decoded\ninto the variables present in the code of the RASP algorithm. Additionally, we\nfound that the proposed method can improve out of distribution performance\ncompared to our baseline, indicating that indeed a more symbolic mechanism is\ntaking place in the inner workings of the model. We release the code used to\nrun our experiments.", "AI": {"tldr": "The paper introduces tracr-injection, a method to distill RASP algorithms into pre-trained language models, improving interpretability and out-of-distribution performance.", "motivation": "Address the mismatch between theoretical transformer capabilities (via RASP) and practical learnability from unsupervised data.", "method": "Propose tracr-injection to compile RASP algorithms into transformer weights, creating interpretable subspaces in the model.", "result": "Successfully injected 3 algorithms, showing interpretable subspaces and improved out-of-distribution performance.", "conclusion": "tracr-injection bridges theory and practice, enhancing symbolic mechanisms in language models."}}
{"id": "2505.10607", "pdf": "https://arxiv.org/pdf/2505.10607", "abs": "https://arxiv.org/abs/2505.10607", "authors": ["Patara Trirat", "Jae-Gil Lee"], "title": "MONAQ: Multi-Objective Neural Architecture Querying for Time-Series Analysis on Resource-Constrained Devices", "categories": ["cs.LG", "cs.AI"], "comment": "Code will be available at https://github.com/kaist-dmlab/MONAQ", "summary": "The growing use of smartphones and IoT devices necessitates efficient\ntime-series analysis on resource-constrained hardware, which is critical for\nsensing applications such as human activity recognition and air quality\nprediction. Recent efforts in hardware-aware neural architecture search (NAS)\nautomate architecture discovery for specific platforms; however, none focus on\ngeneral time-series analysis with edge deployment. Leveraging the\nproblem-solving and reasoning capabilities of large language models (LLM), we\npropose MONAQ, a novel framework that reformulates NAS into Multi-Objective\nNeural Architecture Querying tasks. MONAQ is equipped with multimodal query\ngeneration for processing multimodal time-series inputs and hardware\nconstraints, alongside an LLM agent-based multi-objective search to achieve\ndeployment-ready models via code generation. By integrating numerical data,\ntime-series images, and textual descriptions, MONAQ improves an LLM's\nunderstanding of time-series data. Experiments on fifteen datasets demonstrate\nthat MONAQ-discovered models outperform both handcrafted models and NAS\nbaselines while being more efficient.", "AI": {"tldr": "MONAQ is a framework using LLMs for multi-objective neural architecture search (NAS) in time-series analysis, outperforming handcrafted models and NAS baselines.", "motivation": "Efficient time-series analysis on resource-constrained hardware is needed for IoT and smartphone applications, but current NAS methods lack focus on general time-series tasks.", "method": "MONAQ reformulates NAS into multi-objective querying tasks, using multimodal query generation and LLM-based search to create deployment-ready models.", "result": "Experiments on 15 datasets show MONAQ-discovered models outperform handcrafted models and NAS baselines in efficiency and performance.", "conclusion": "MONAQ successfully leverages LLMs for efficient and effective time-series NAS, addressing hardware constraints and multimodal inputs."}}
{"id": "2505.10770", "pdf": "https://arxiv.org/pdf/2505.10770", "abs": "https://arxiv.org/abs/2505.10770", "authors": ["Ebasa Temesgen", "Mario Jerez", "Greta Brown", "Graham Wilson", "Sree Ganesh Lalitaditya Divakarla", "Sarah Boelter", "Oscar Nelson", "Robert McPherson", "Maria Gini"], "title": "Geofenced Unmanned Aerial Robotic Defender for Deer Detection and Deterrence (GUARD)", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "Accepted to the Novel Approaches for Precision Agriculture and\n  Forestry with Autonomous Robots IEEE ICRA Workshop - 2025", "summary": "Wildlife-induced crop damage, particularly from deer, threatens agricultural\nproductivity. Traditional deterrence methods often fall short in scalability,\nresponsiveness, and adaptability to diverse farmland environments. This paper\npresents an integrated unmanned aerial vehicle (UAV) system designed for\nautonomous wildlife deterrence, developed as part of the Farm Robotics\nChallenge. Our system combines a YOLO-based real-time computer vision module\nfor deer detection, an energy-efficient coverage path planning algorithm for\nefficient field monitoring, and an autonomous charging station for continuous\noperation of the UAV. In collaboration with a local Minnesota farmer, the\nsystem is tailored to address practical constraints such as terrain,\ninfrastructure limitations, and animal behavior. The solution is evaluated\nthrough a combination of simulation and field testing, demonstrating robust\ndetection accuracy, efficient coverage, and extended operational time. The\nresults highlight the feasibility and effectiveness of drone-based wildlife\ndeterrence in precision agriculture, offering a scalable framework for future\ndeployment and extension.", "AI": {"tldr": "An integrated UAV system for autonomous wildlife deterrence is developed, combining real-time deer detection, efficient field monitoring, and autonomous charging, showing feasibility in precision agriculture.", "motivation": "Wildlife-induced crop damage, especially from deer, is a major agricultural challenge, with traditional methods lacking scalability and adaptability.", "method": "The system uses YOLO-based computer vision for deer detection, energy-efficient path planning for monitoring, and an autonomous charging station for continuous UAV operation.", "result": "Field and simulation tests show robust detection, efficient coverage, and extended operational time, proving the system's effectiveness.", "conclusion": "The UAV-based solution is feasible and scalable for wildlife deterrence in precision agriculture, with potential for future deployment."}}
{"id": "2505.11315", "pdf": "https://arxiv.org/pdf/2505.11315", "abs": "https://arxiv.org/abs/2505.11315", "authors": ["Chin-Yun Yu", "Marco A. Mart\u00ednez-Ram\u00edrez", "Junghyun Koo", "Wei-Hsiang Liao", "Yuki Mitsufuji", "Gy\u00f6rgy Fazekas"], "title": "Improving Inference-Time Optimisation for Vocal Effects Style Transfer with a Gaussian Prior", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Submitted to WASPAA 2025", "summary": "Style Transfer with Inference-Time Optimisation (ST-ITO) is a recent approach\nfor transferring the applied effects of a reference audio to a raw audio track.\nIt optimises the effect parameters to minimise the distance between the style\nembeddings of the processed audio and the reference. However, this method\ntreats all possible configurations equally and relies solely on the embedding\nspace, which can lead to unrealistic or biased results. We address this pitfall\nby introducing a Gaussian prior derived from a vocal preset dataset, DiffVox,\nover the parameter space. The resulting optimisation is equivalent to\nmaximum-a-posteriori estimation. Evaluations on vocal effects transfer on the\nMedleyDB dataset show significant improvements across metrics compared to\nbaselines, including a blind audio effects estimator, nearest-neighbour\napproaches, and uncalibrated ST-ITO. The proposed calibration reduces parameter\nmean squared error by up to 33% and matches the reference style better.\nSubjective evaluations with 16 participants confirm our method's superiority,\nespecially in limited data regimes. This work demonstrates how incorporating\nprior knowledge in inference time enhances audio effects transfer, paving the\nway for more effective and realistic audio processing systems.", "AI": {"tldr": "ST-ITO improves audio style transfer by adding a Gaussian prior from a vocal preset dataset, outperforming baselines in metrics and subjective evaluations.", "motivation": "Addressing the limitations of ST-ITO, which treats all configurations equally and relies solely on embeddings, leading to unrealistic results.", "method": "Introduces a Gaussian prior from the DiffVox dataset for parameter space, enabling maximum-a-posteriori estimation during optimization.", "result": "Significant improvements in vocal effects transfer, reducing parameter error by 33% and better matching reference styles. Subjective evaluations confirm superiority.", "conclusion": "Incorporating prior knowledge at inference time enhances audio effects transfer, enabling more realistic and effective audio processing."}}
{"id": "2505.11030", "pdf": "https://arxiv.org/pdf/2505.11030", "abs": "https://arxiv.org/abs/2505.11030", "authors": ["David M. Berry"], "title": "The heteronomy of algorithms: Traditional knowledge and computational knowledge", "categories": ["cs.CY", "cs.AI", "cs.MM", "K.4.0; K.4.1"], "comment": null, "summary": "If an active citizen should increasingly be a computationally enlightened\none, replacing the autonomy of reason with the heteronomy of algorithms, then I\nargue in this article that we must begin teaching the principles of critiquing\nthe computal through new notions of what we might call digital Bildung. Indeed,\nif civil society itself is mediated by computational systems and media, the\npublic use of reason must also be complemented by skills for negotiating and\nusing these computal forms to articulate such critique. Not only is there a\nneed to raise the intellectual tone regarding computation and its related\nsoftwarization processes, but there is an urgent need to attend to the likely\nepistemic challenges from computation which, as presently constituted, tends\ntowards justification through a philosophy of utility rather than through a\nphilosophy of care for the territory of the intellect. We therefore need to\ndevelop an approach to this field that uses concepts and methods drawn from\nphilosophy, politics, history, anthropology, sociology, media studies, computer\nscience, and the humanities more generally, to try to understand these issues -\nparticularly the way in which software and data increasingly penetrate our\neveryday life and the pressures and fissures that are created. We must, in\nother words, move to undertake a critical interdisciplinary research program to\nunderstand the way in which these systems are created, instantiated, and\nnormatively engendered in both specific and general contexts.", "AI": {"tldr": "The paper advocates for teaching digital Bildung to critique computational systems, emphasizing interdisciplinary research to address epistemic challenges.", "motivation": "The increasing mediation of civil society by computational systems necessitates new skills for public critique and intellectual engagement with computation.", "method": "Proposes an interdisciplinary approach combining philosophy, politics, history, anthropology, sociology, media studies, computer science, and humanities.", "result": "Highlights the need for critical research to understand the creation and impact of computational systems in everyday life.", "conclusion": "Urges a shift towards interdisciplinary critical research to address the normative and epistemic challenges posed by computational systems."}}
{"id": "2505.10691", "pdf": "https://arxiv.org/pdf/2505.10691", "abs": "https://arxiv.org/abs/2505.10691", "authors": ["Wanying Dou", "Gorkem Durak", "Koushik Biswas", "Ziliang Hong", "Andrea Mia Bejar", "Elif Keles", "Kaan Akin", "Sukru Mehmet Erturk", "Alpay Medetalibeyoglu", "Marc Sala", "Alexander Misharin", "Hatice Savas", "Mary Salvatore", "Sachin Jambawalikar", "Drew Torigian", "Jayaram K. Udupa", "Ulas Bagci"], "title": "Predicting Risk of Pulmonary Fibrosis Formation in PASC Patients", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "While the acute phase of the COVID-19 pandemic has subsided, its long-term\neffects persist through Post-Acute Sequelae of COVID-19 (PASC), commonly known\nas Long COVID. There remains substantial uncertainty regarding both its\nduration and optimal management strategies. PASC manifests as a diverse array\nof persistent or newly emerging symptoms--ranging from fatigue, dyspnea, and\nneurologic impairments (e.g., brain fog), to cardiovascular, pulmonary, and\nmusculoskeletal abnormalities--that extend beyond the acute infection phase.\nThis heterogeneous presentation poses substantial challenges for clinical\nassessment, diagnosis, and treatment planning. In this paper, we focus on\nimaging findings that may suggest fibrotic damage in the lungs, a critical\nmanifestation characterized by scarring of lung tissue, which can potentially\naffect long-term respiratory function in patients with PASC. This study\nintroduces a novel multi-center chest CT analysis framework that combines deep\nlearning and radiomics for fibrosis prediction. Our approach leverages\nconvolutional neural networks (CNNs) and interpretable feature extraction,\nachieving 82.2% accuracy and 85.5% AUC in classification tasks. We demonstrate\nthe effectiveness of Grad-CAM visualization and radiomics-based feature\nanalysis in providing clinically relevant insights for PASC-related lung\nfibrosis prediction. Our findings highlight the potential of deep\nlearning-driven computational methods for early detection and risk assessment\nof PASC-related lung fibrosis--presented for the first time in the literature.", "AI": {"tldr": "The paper introduces a deep learning and radiomics framework for predicting lung fibrosis in Long COVID patients using chest CT scans, achieving high accuracy and AUC.", "motivation": "Address the uncertainty and challenges in diagnosing and managing Post-Acute Sequelae of COVID-19 (PASC), particularly lung fibrosis, due to its heterogeneous symptoms.", "method": "A multi-center chest CT analysis framework combining deep learning (CNNs) and radiomics for fibrosis prediction, including Grad-CAM visualization and feature extraction.", "result": "Achieved 82.2% accuracy and 85.5% AUC in classification tasks, demonstrating clinical relevance for PASC-related lung fibrosis prediction.", "conclusion": "Deep learning-driven methods show promise for early detection and risk assessment of PASC-related lung fibrosis, offering a novel approach in the literature."}}
{"id": "2505.11352", "pdf": "https://arxiv.org/pdf/2505.11352", "abs": "https://arxiv.org/abs/2505.11352", "authors": ["Rao Ma", "Tongzhou Chen", "Kartik Audhkhasi", "Bhuvana Ramabhadran"], "title": "LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Recently, large-scale pre-trained speech encoders and Large Language Models\n(LLMs) have been released, which show state-of-the-art performance on a range\nof spoken language processing tasks including Automatic Speech Recognition\n(ASR). To effectively combine both models for better performance, continuous\nspeech prompts, and ASR error correction have been adopted. However, these\nmethods are prone to suboptimal performance or are inflexible. In this paper,\nwe propose a new paradigm, LegoSLM, that bridges speech encoders and LLMs using\nthe ASR posterior matrices. The speech encoder is trained to generate\nConnectionist Temporal Classification (CTC) posteriors over the LLM vocabulary,\nwhich are used to reconstruct pseudo-audio embeddings by computing a weighted\nsum of the LLM input embeddings. These embeddings are concatenated with text\nembeddings in the LLM input space. Using the well-performing USM and Gemma\nmodels as an example, we demonstrate that our proposed LegoSLM method yields\ngood performance on both ASR and speech translation tasks. By connecting USM\nwith Gemma models, we can get an average of 49% WERR over the USM-CTC baseline\non 8 MLS testsets. The trained model also exhibits modularity in a range of\nsettings -- after fine-tuning the Gemma model weights, the speech encoder can\nbe switched and combined with the LLM in a zero-shot fashion. Additionally, we\npropose to control the decode-time influence of the USM and LLM using a softmax\ntemperature, which shows effectiveness in domain adaptation.", "AI": {"tldr": "LegoSLM bridges speech encoders and LLMs using ASR posterior matrices, improving performance on ASR and speech translation tasks with modularity and domain adaptation control.", "motivation": "To address suboptimal performance and inflexibility in combining speech encoders and LLMs for spoken language processing tasks.", "method": "Uses CTC posteriors over LLM vocabulary to reconstruct pseudo-audio embeddings, concatenated with text embeddings in LLM input space.", "result": "Achieves 49% WERR improvement over baseline on ASR tasks and shows modularity and domain adaptation effectiveness.", "conclusion": "LegoSLM effectively combines speech encoders and LLMs, offering performance gains and flexibility in various settings."}}
{"id": "2505.10589", "pdf": "https://arxiv.org/pdf/2505.10589", "abs": "https://arxiv.org/abs/2505.10589", "authors": ["Ka\u011fan \u00c7ET\u0130N"], "title": "Super-Resolution Generative Adversarial Networks based Video Enhancement", "categories": ["cs.CV", "cs.AI", "eess.IV", "I.4.3"], "comment": null, "summary": "This study introduces an enhanced approach to video super-resolution by\nextending ordinary Single-Image Super-Resolution (SISR) Super-Resolution\nGenerative Adversarial Network (SRGAN) structure to handle spatio-temporal\ndata. While SRGAN has proven effective for single-image enhancement, its design\ndoes not account for the temporal continuity required in video processing. To\naddress this, a modified framework that incorporates 3D Non-Local Blocks is\nproposed, which is enabling the model to capture relationships across both\nspatial and temporal dimensions. An experimental training pipeline is\ndeveloped, based on patch-wise learning and advanced data degradation\ntechniques, to simulate real-world video conditions and learn from both local\nand global structures and details. This helps the model generalize better and\nmaintain stability across varying video content while maintaining the general\nstructure besides the pixel-wise correctness. Two model variants-one larger and\none more lightweight-are presented to explore the trade-offs between\nperformance and efficiency. The results demonstrate improved temporal\ncoherence, sharper textures, and fewer visual artifacts compared to traditional\nsingle-image methods. This work contributes to the development of practical,\nlearning-based solutions for video enhancement tasks, with potential\napplications in streaming, gaming, and digital restoration.", "AI": {"tldr": "An enhanced video super-resolution method extends SRGAN with 3D Non-Local Blocks for spatio-temporal data, improving temporal coherence and reducing artifacts.", "motivation": "SRGAN excels in single-image super-resolution but lacks temporal continuity for video. This work addresses this gap.", "method": "Extends SRGAN with 3D Non-Local Blocks, uses patch-wise learning and advanced data degradation for training.", "result": "Improved temporal coherence, sharper textures, fewer artifacts; two model variants balance performance and efficiency.", "conclusion": "A practical, learning-based solution for video enhancement, useful in streaming, gaming, and restoration."}}
{"id": "2505.10779", "pdf": "https://arxiv.org/pdf/2505.10779", "abs": "https://arxiv.org/abs/2505.10779", "authors": ["Philip S. Thomas"], "title": "Qualia Optimization", "categories": ["cs.AI"], "comment": "Technical Report, College of Information and Computer Science,\n  University of Massachusetts", "summary": "This report explores the speculative question: what if current or future AI\nsystems have qualia, such as pain or pleasure? It does so by assuming that AI\nsystems might someday possess qualia -- and that the quality of these\nsubjective experiences should be considered alongside performance metrics.\nConcrete mathematical problem settings, inspired by reinforcement learning\nformulations and theories from philosophy of mind, are then proposed and\ninitial approaches and properties are presented. These properties enable\nrefinement of the problem setting, culminating with the proposal of methods\nthat promote reinforcement.", "AI": {"tldr": "The paper explores whether AI systems could have qualia (subjective experiences like pain or pleasure) and proposes methods to incorporate such considerations into AI development.", "motivation": "To address the speculative but impactful question of AI systems potentially having qualia, emphasizing the need to evaluate subjective experiences alongside performance metrics.", "method": "Proposes mathematical problem settings inspired by reinforcement learning and philosophy of mind, refining these into methods that promote reinforcement.", "result": "Initial approaches and properties are presented, enabling refinement of the problem setting.", "conclusion": "The study culminates in proposing methods to integrate qualia considerations into AI systems, advocating for a broader evaluation framework."}}
{"id": "2505.10736", "pdf": "https://arxiv.org/pdf/2505.10736", "abs": "https://arxiv.org/abs/2505.10736", "authors": ["Ximing Dong", "Shaowei Wang", "Dayi Lin", "Ahmed E. Hassan"], "title": "Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization", "categories": ["cs.CL"], "comment": null, "summary": "Optimizing Large Language Model (LLM) performance requires well-crafted\nprompts, but manual prompt engineering is labor-intensive and often\nineffective. Automated prompt optimization techniques address this challenge\nbut the majority of them rely on randomly selected evaluation subsets, which\nfail to represent the full dataset, leading to unreliable evaluations and\nsuboptimal prompts. Existing coreset selection methods, designed for LLM\nbenchmarking, are unsuitable for prompt optimization due to challenges in\nclustering similar samples, high data collection costs, and the unavailability\nof performance data for new or private datasets. To overcome these issues, we\npropose IPOMP, an Iterative evaluation data selection for effective Prompt\nOptimization using real-time Model Performance. IPOMP is a two-stage approach\nthat selects representative and diverse samples using semantic clustering and\nboundary analysis, followed by iterative refinement with real-time model\nperformance data to replace redundant samples. Evaluations on the BIG-bench\ndataset show that IPOMP improves effectiveness by 1.6% to 5.3% and stability by\nat least 57% compared with SOTA baselines, with minimal computational overhead\nbelow 1%. Furthermore, the results demonstrate that our real-time\nperformance-guided refinement approach can be universally applied to enhance\nexisting coreset selection methods.", "AI": {"tldr": "IPOMP is a two-stage method for automated prompt optimization, using semantic clustering and iterative refinement with real-time performance data, outperforming baselines in effectiveness and stability.", "motivation": "Manual prompt engineering is inefficient, and existing automated methods rely on unreliable evaluation subsets, leading to suboptimal prompts.", "method": "IPOMP uses semantic clustering and boundary analysis to select diverse samples, then iteratively refines them using real-time model performance data.", "result": "IPOMP improves effectiveness by 1.6% to 5.3% and stability by 57% over baselines, with minimal computational overhead (<1%).", "conclusion": "IPOMP's real-time performance-guided refinement is universally applicable and enhances existing coreset selection methods."}}
{"id": "2505.10630", "pdf": "https://arxiv.org/pdf/2505.10630", "abs": "https://arxiv.org/abs/2505.10630", "authors": ["Ben Adcock", "Nick Huang"], "title": "How many measurements are enough? Bayesian recovery in inverse problems with general distributions", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We study the sample complexity of Bayesian recovery for solving inverse\nproblems with general prior, forward operator and noise distributions. We\nconsider posterior sampling according to an approximate prior $\\mathcal{P}$,\nand establish sufficient conditions for stable and accurate recovery with high\nprobability. Our main result is a non-asymptotic bound that shows that the\nsample complexity depends on (i) the intrinsic complexity of $\\mathcal{P}$,\nquantified by its so-called approximate covering number, and (ii) concentration\nbounds for the forward operator and noise distributions. As a key application,\nwe specialize to generative priors, where $\\mathcal{P}$ is the pushforward of a\nlatent distribution via a Deep Neural Network (DNN). We show that the sample\ncomplexity scales log-linearly with the latent dimension $k$, thus establishing\nthe efficacy of DNN-based priors. Generalizing existing results on\ndeterministic (i.e., non-Bayesian) recovery for the important problem of random\nsampling with an orthogonal matrix $U$, we show how the sample complexity is\ndetermined by the coherence of $U$ with respect to the support of\n$\\mathcal{P}$. Hence, we establish that coherence plays a fundamental role in\nBayesian recovery as well. Overall, our framework unifies and extends prior\nwork, providing rigorous guarantees for the sample complexity of solving\nBayesian inverse problems with arbitrary distributions.", "AI": {"tldr": "The paper studies Bayesian recovery for inverse problems, focusing on sample complexity under general priors, forward operators, and noise. It provides non-asymptotic bounds and highlights the role of DNN-based priors and coherence in recovery.", "motivation": "To understand the sample complexity of Bayesian recovery in inverse problems with general distributions, extending prior work and providing rigorous guarantees.", "method": "Analyzes posterior sampling with an approximate prior, using intrinsic complexity (approximate covering number) and concentration bounds for forward operators and noise. Specializes to DNN-based priors and coherence analysis.", "result": "Sample complexity scales log-linearly with latent dimension for DNN priors. Coherence of the forward operator determines recovery efficiency.", "conclusion": "The framework unifies and extends prior work, offering guarantees for Bayesian inverse problems with arbitrary distributions, emphasizing the role of DNN priors and coherence."}}
{"id": "2505.11011", "pdf": "https://arxiv.org/pdf/2505.11011", "abs": "https://arxiv.org/abs/2505.11011", "authors": ["Darija Barak", "Miguel Costa-Gomes"], "title": "Humans expect rationality and cooperation from LLM opponents in strategic games", "categories": ["econ.GN", "cs.AI", "cs.MA", "q-fin.EC"], "comment": null, "summary": "As Large Language Models (LLMs) integrate into our social and economic\ninteractions, we need to deepen our understanding of how humans respond to LLMs\nopponents in strategic settings. We present the results of the first controlled\nmonetarily-incentivised laboratory experiment looking at differences in human\nbehaviour in a multi-player p-beauty contest against other humans and LLMs. We\nuse a within-subject design in order to compare behaviour at the individual\nlevel. We show that, in this environment, human subjects choose significantly\nlower numbers when playing against LLMs than humans, which is mainly driven by\nthe increased prevalence of `zero' Nash-equilibrium choices. This shift is\nmainly driven by subjects with high strategic reasoning ability. Subjects who\nplay the zero Nash-equilibrium choice motivate their strategy by appealing to\nperceived LLM's reasoning ability and, unexpectedly, propensity towards\ncooperation. Our findings provide foundational insights into the multi-player\nhuman-LLM interaction in simultaneous choice games, uncover heterogeneities in\nboth subjects' behaviour and beliefs about LLM's play when playing against\nthem, and suggest important implications for mechanism design in mixed\nhuman-LLM systems.", "AI": {"tldr": "Humans choose lower numbers against LLMs than humans in a p-beauty contest, driven by zero Nash-equilibrium choices, especially among high-reasoning subjects.", "motivation": "To understand human behavior differences when interacting with LLMs in strategic settings.", "method": "Controlled monetarily-incentivised lab experiment with a within-subject design in a multi-player p-beauty contest.", "result": "Humans pick lower numbers against LLMs, driven by zero Nash-equilibrium choices, linked to perceived LLM reasoning and cooperation.", "conclusion": "Insights into human-LLM interactions reveal behavioral heterogeneities and implications for mixed human-LLM system design."}}
{"id": "2505.11378", "pdf": "https://arxiv.org/pdf/2505.11378", "abs": "https://arxiv.org/abs/2505.11378", "authors": ["Alexander Kim", "Charlotte Botha"], "title": "Machine Learning Approaches to Vocal Register Classification in Contemporary Male Pop Music", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "8 pages, 8 figures", "summary": "For singers of all experience levels, one of the most daunting challenges in\nlearning technical repertoire is navigating placement and vocal register in and\naround the passagio (passage between chest voice and head voice registers).\nParticularly in pop music, where a single artist may use a variety of timbre's\nand textures to achieve a desired quality, it can be difficult to identify what\nvocal register within the vocal range a singer is using. This paper presents\ntwo methods for classifying vocal registers in an audio signal of male pop\nmusic through the analysis of textural features of mel-spectrogram images.\nAdditionally, we will discuss the practical integration of these models for\nvocal analysis tools, and introduce a concurrently developed software called\nAVRA which stands for Automatic Vocal Register Analysis. Our proposed methods\nachieved consistent classification of vocal register through both Support\nVector Machine (SVM) and Convolutional Neural Network (CNN) models, which\nsupports the promise of more robust classification possibilities across more\nvoice types and genres of singing.", "AI": {"tldr": "The paper introduces methods to classify vocal registers in male pop music using mel-spectrogram analysis and discusses the AVRA software for vocal analysis.", "motivation": "Navigating vocal registers, especially around the passagio, is challenging for singers, particularly in pop music where varied timbres are used.", "method": "Two methods are presented: SVM and CNN models analyze textural features of mel-spectrogram images to classify vocal registers.", "result": "Both SVM and CNN models achieved consistent vocal register classification, showing promise for broader applications.", "conclusion": "The methods and AVRA software demonstrate potential for robust vocal register classification across more voice types and genres."}}
{"id": "2505.11066", "pdf": "https://arxiv.org/pdf/2505.11066", "abs": "https://arxiv.org/abs/2505.11066", "authors": ["Rui Wang", "Shichun Yang", "Yuyi Chen", "Zhuoyang Li", "Zexiang Tong", "Jianyi Xu", "Jiayi Lu", "Xinjie Feng", "Yaoguang Cao"], "title": "A Multi-modal Fusion Network for Terrain Perception Based on Illumination Aware", "categories": ["cs.AI", "cs.MM"], "comment": null, "summary": "Road terrains play a crucial role in ensuring the driving safety of\nautonomous vehicles (AVs). However, existing sensors of AVs, including cameras\nand Lidars, are susceptible to variations in lighting and weather conditions,\nmaking it challenging to achieve real-time perception of road conditions. In\nthis paper, we propose an illumination-aware multi-modal fusion network (IMF),\nwhich leverages both exteroceptive and proprioceptive perception and optimizes\nthe fusion process based on illumination features. We introduce an\nillumination-perception sub-network to accurately estimate illumination\nfeatures. Moreover, we design a multi-modal fusion network which is able to\ndynamically adjust weights of different modalities according to illumination\nfeatures. We enhance the optimization process by pre-training of the\nillumination-perception sub-network and incorporating illumination loss as one\nof the training constraints. Extensive experiments demonstrate that the IMF\nshows a superior performance compared to state-of-the-art methods. The\ncomparison results with single modality perception methods highlight the\ncomprehensive advantages of multi-modal fusion in accurately perceiving road\nterrains under varying lighting conditions. Our dataset is available at:\nhttps://github.com/lindawang2016/IMF.", "AI": {"tldr": "The paper proposes an illumination-aware multi-modal fusion network (IMF) for autonomous vehicles to improve real-time road terrain perception under varying lighting and weather conditions.", "motivation": "Existing AV sensors struggle with lighting and weather variations, hindering accurate road condition perception.", "method": "IMF combines exteroceptive and proprioceptive perception, dynamically adjusting modality weights based on illumination features, and includes an illumination-perception sub-network for feature estimation.", "result": "IMF outperforms state-of-the-art methods, demonstrating the benefits of multi-modal fusion in varying lighting conditions.", "conclusion": "The IMF framework effectively enhances road terrain perception for AVs, with publicly available dataset for further research."}}
{"id": "2505.10729", "pdf": "https://arxiv.org/pdf/2505.10729", "abs": "https://arxiv.org/abs/2505.10729", "authors": ["NingFeng Que", "Xiaofei Wang", "Jingjing Chen", "Yixuan Jiang", "Chao Li"], "title": "Adaptive Spatial Transcriptomics Interpolation via Cross-modal Cross-slice Modeling", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": "Early accepted by MICCAI 2025", "summary": "Spatial transcriptomics (ST) is a promising technique that characterizes the\nspatial gene profiling patterns within the tissue context. Comprehensive ST\nanalysis depends on consecutive slices for 3D spatial insights, whereas the\nmissing intermediate tissue sections and high costs limit the practical\nfeasibility of generating multi-slice ST. In this paper, we propose C2-STi, the\nfirst attempt for interpolating missing ST slices at arbitrary intermediate\npositions between adjacent ST slices. Despite intuitive, effective ST\ninterpolation presents significant challenges, including 1) limited continuity\nacross heterogeneous tissue sections, 2) complex intrinsic correlation across\ngenes, and 3) intricate cellular structures and biological semantics within\neach tissue section. To mitigate these challenges, in C2-STi, we design 1) a\ndistance-aware local structural modulation module to adaptively capture\ncross-slice deformations and enhance positional correlations between ST slices,\n2) a pyramid gene co-expression correlation module to capture multi-scale\nbiological associations among genes, and 3) a cross-modal alignment module that\nintegrates the ST-paired hematoxylin and eosin (H&E)-stained images to filter\nand align the essential cellular features across ST and H\\&E images. Extensive\nexperiments on the public dataset demonstrate our superiority over\nstate-of-the-art approaches on both single-slice and multi-slice ST\ninterpolation. Codes are available at\nhttps://github.com/XiaofeiWang2018/C2-STi.", "AI": {"tldr": "C2-STi proposes a method to interpolate missing spatial transcriptomics (ST) slices, addressing challenges like tissue heterogeneity and gene correlations, using distance-aware modulation, gene co-expression, and cross-modal alignment with H&E images.", "motivation": "Spatial transcriptomics (ST) analysis is limited by missing intermediate slices and high costs, hindering 3D insights. C2-STi aims to interpolate missing slices for comprehensive ST analysis.", "method": "C2-STi uses: 1) distance-aware local structural modulation for cross-slice deformations, 2) pyramid gene co-expression correlation for multi-scale gene associations, and 3) cross-modal alignment with H&E images for cellular feature alignment.", "result": "Experiments show C2-STi outperforms state-of-the-art methods in single-slice and multi-slice ST interpolation.", "conclusion": "C2-STi effectively interpolates missing ST slices, enhancing spatial transcriptomics analysis by addressing key challenges."}}
{"id": "2503.23108", "pdf": "https://arxiv.org/pdf/2503.23108", "abs": "https://arxiv.org/abs/2503.23108", "authors": ["Hyeongju Kim", "Jinhyeok Yang", "Yechan Yu", "Seunghun Ji", "Jacob Morton", "Frederik Bous", "Joon Byun", "Juheon Lee"], "title": "SupertonicTTS: Towards Highly Scalable and Efficient Text-to-Speech System", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "21 pages, preprint", "summary": "We present a novel text-to-speech (TTS) system, namely SupertonicTTS, for\nimproved scalability and efficiency in speech synthesis. SupertonicTTS\ncomprises three components: a speech autoencoder for continuous latent\nrepresentation, a text-to-latent module leveraging flow-matching for\ntext-to-latent mapping, and an utterance-level duration predictor. To enable a\nlightweight architecture, we employ a low-dimensional latent space, temporal\ncompression of latents, and ConvNeXt blocks. We further simplify the TTS\npipeline by operating directly on raw character-level text and employing\ncross-attention for text-speech alignment, thus eliminating the need for\ngrapheme-to-phoneme (G2P) modules and external aligners. In addition, we\nintroduce context-sharing batch expansion that accelerates loss convergence and\nstabilizes text-speech alignment. Experimental results demonstrate that\nSupertonicTTS achieves competitive performance while significantly reducing\narchitectural complexity and computational overhead compared to contemporary\nTTS models. Audio samples demonstrating the capabilities of SupertonicTTS are\navailable at: https://supertonictts.github.io/.", "AI": {"tldr": "SupertonicTTS is a scalable and efficient TTS system with a lightweight architecture, eliminating G2P modules and external aligners, while maintaining competitive performance.", "motivation": "To improve scalability and efficiency in speech synthesis by reducing architectural complexity and computational overhead.", "method": "Uses a speech autoencoder, text-to-latent module with flow-matching, and utterance-level duration predictor. Simplifies the pipeline with raw character-level text and cross-attention.", "result": "Achieves competitive performance with reduced complexity and computational overhead.", "conclusion": "SupertonicTTS offers a streamlined, efficient TTS solution without sacrificing performance."}}
{"id": "2505.10595", "pdf": "https://arxiv.org/pdf/2505.10595", "abs": "https://arxiv.org/abs/2505.10595", "authors": ["Xingye Cui", "Junhai Luo", "Jiakun Deng", "Kexuan Li", "Xiangyu Qiu", "Zhenming Peng"], "title": "ARFC-WAHNet: Adaptive Receptive Field Convolution and Wavelet-Attentive Hierarchical Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection (ISTD) is critical in both civilian and\nmilitary applications. However, the limited texture and structural information\nin infrared images makes accurate detection particularly challenging. Although\nrecent deep learning-based methods have improved performance, their use of\nconventional convolution kernels limits adaptability to complex scenes and\ndiverse targets. Moreover, pooling operations often cause feature loss and\ninsufficient exploitation of image information. To address these issues, we\npropose an adaptive receptive field convolution and wavelet-attentive\nhierarchical network for infrared small target detection (ARFC-WAHNet). This\nnetwork incorporates a multi-receptive field feature interaction convolution\n(MRFFIConv) module to adaptively extract discriminative features by integrating\nmultiple convolutional branches with a gated unit. A wavelet frequency\nenhancement downsampling (WFED) module leverages Haar wavelet transform and\nfrequency-domain reconstruction to enhance target features and suppress\nbackground noise. Additionally, we introduce a high-low feature fusion (HLFF)\nmodule for integrating low-level details with high-level semantics, and a\nglobal median enhancement attention (GMEA) module to improve feature diversity\nand expressiveness via global attention. Experiments on public datasets SIRST,\nNUDT-SIRST, and IRSTD-1k demonstrate that ARFC-WAHNet outperforms recent\nstate-of-the-art methods in both detection accuracy and robustness,\nparticularly under complex backgrounds. The code is available at\nhttps://github.com/Leaf2001/ARFC-WAHNet.", "AI": {"tldr": "ARFC-WAHNet improves infrared small target detection using adaptive convolution, wavelet enhancement, and attention mechanisms, outperforming state-of-the-art methods.", "motivation": "Limited texture in infrared images and feature loss in deep learning methods hinder accurate small target detection.", "method": "Proposes ARFC-WAHNet with MRFFIConv for adaptive feature extraction, WFED for noise suppression, HLFF for feature fusion, and GMEA for attention.", "result": "Outperforms recent methods on SIRST, NUDT-SIRST, and IRSTD-1k datasets, especially in complex backgrounds.", "conclusion": "ARFC-WAHNet enhances detection accuracy and robustness, addressing challenges in infrared small target detection."}}
{"id": "2505.10780", "pdf": "https://arxiv.org/pdf/2505.10780", "abs": "https://arxiv.org/abs/2505.10780", "authors": ["Trisha Das", "Afrah Shafquat", "Beigi Mandis", "Jacob Aptekar", "Jimeng Sun"], "title": "SECRET: Semi-supervised Clinical Trial Document Similarity Search", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Clinical trials are vital for evaluation of safety and efficacy of new\ntreatments. However, clinical trials are resource-intensive, time-consuming and\nexpensive to conduct, where errors in trial design, reduced efficacy, and\nsafety events can result in significant delays, financial losses, and damage to\nreputation. These risks underline the importance of informed and strategic\ndecisions in trial design to mitigate these risks and improve the chances of a\nsuccessful trial. Identifying similar historical trials is critical as these\ntrials can provide an important reference for potential pitfalls and challenges\nincluding serious adverse events, dosage inaccuracies, recruitment\ndifficulties, patient adherence issues, etc. Addressing these challenges in\ntrial design can lead to development of more effective study protocols with\noptimized patient safety and trial efficiency. In this paper, we present a\nnovel method to identify similar historical trials by summarizing clinical\ntrial protocols and searching for similar trials based on a query trial's\nprotocol. Our approach significantly outperforms all baselines, achieving up to\na 78% improvement in recall@1 and a 53% improvement in precision@1 over the\nbest baseline. We also show that our method outperforms all other baselines in\npartial trial similarity search and zero-shot patient-trial matching,\nhighlighting its superior utility in these tasks.", "AI": {"tldr": "A novel method improves identification of similar historical clinical trials, enhancing trial design and efficiency.", "motivation": "Clinical trials are costly and risky; learning from past trials can mitigate errors and improve success.", "method": "Summarizes trial protocols and searches for similar trials based on a query trial's protocol.", "result": "Outperforms baselines with 78% recall@1 and 53% precision@1 improvements, excelling in partial similarity and zero-shot tasks.", "conclusion": "The method enhances trial design by leveraging historical data, improving safety and efficiency."}}
{"id": "2505.10740", "pdf": "https://arxiv.org/pdf/2505.10740", "abs": "https://arxiv.org/abs/2505.10740", "authors": ["Qiwei Peng", "Robert Moro", "Michal Gregor", "Ivan Srba", "Simon Ostermann", "Marian Simko", "Juraj Podrou\u017eek", "Mat\u00fa\u0161 Mesar\u010d\u00edk", "Jaroslav Kop\u010dan", "Anders S\u00f8gaard"], "title": "SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "The rapid spread of online disinformation presents a global challenge, and\nmachine learning has been widely explored as a potential solution. However,\nmultilingual settings and low-resource languages are often neglected in this\nfield. To address this gap, we conducted a shared task on multilingual claim\nretrieval at SemEval 2025, aimed at identifying fact-checked claims that match\nnewly encountered claims expressed in social media posts across different\nlanguages. The task includes two subtracks: (1) a monolingual track, where\nsocial posts and claims are in the same language, and (2) a crosslingual track,\nwhere social posts and claims might be in different languages. A total of 179\nparticipants registered for the task contributing to 52 test submissions. 23\nout of 31 teams have submitted their system papers. In this paper, we report\nthe best-performing systems as well as the most common and the most effective\napproaches across both subtracks. This shared task, along with its dataset and\nparticipating systems, provides valuable insights into multilingual claim\nretrieval and automated fact-checking, supporting future research in this\nfield.", "AI": {"tldr": "The paper discusses a shared task on multilingual claim retrieval at SemEval 2025, addressing the gap in handling disinformation in multilingual and low-resource settings. It reports top-performing systems and common approaches.", "motivation": "To tackle the neglect of multilingual and low-resource languages in disinformation detection, the study aims to improve claim retrieval across languages.", "method": "A shared task with two subtracks (monolingual and crosslingual) was conducted, involving 179 participants and 52 test submissions.", "result": "23 teams submitted system papers, with insights into the best-performing systems and effective approaches for multilingual claim retrieval.", "conclusion": "The shared task and its outcomes provide valuable resources and insights for future research in automated fact-checking and multilingual disinformation detection."}}
{"id": "2505.10641", "pdf": "https://arxiv.org/pdf/2505.10641", "abs": "https://arxiv.org/abs/2505.10641", "authors": ["Linjing You", "Jiabao Lu", "Xiayuan Huang", "Xiangli Nie"], "title": "FRET: Feature Redundancy Elimination for Test Time Adaptation", "categories": ["cs.LG"], "comment": null, "summary": "Test-Time Adaptation (TTA) aims to enhance the generalization of deep\nlearning models when faced with test data that exhibits distribution shifts\nfrom the training data. In this context, only a pre-trained model and unlabeled\ntest data are available, making it particularly relevant for privacy-sensitive\napplications. In practice, we observe that feature redundancy in embeddings\ntends to increase as domain shifts intensify in TTA. However, existing TTA\nmethods often overlook this redundancy, which can hinder the model's\nadaptability to new data. To address this issue, we introduce Feature\nRedundancy Elimination for Test-time Adaptation (FRET), a novel perspective for\nTTA. A straightforward approach (S-FRET) is to directly minimize the feature\nredundancy score as an optimization objective to improve adaptation. Despite\nits simplicity and effectiveness, S-FRET struggles with label shifts, limiting\nits robustness in real-world scenarios. To mitigate this limitation, we further\npropose Graph-based FRET (G-FRET), which integrates a Graph Convolutional\nNetwork (GCN) with contrastive learning. This design not only reduces feature\nredundancy but also enhances feature discriminability in both the\nrepresentation and prediction layers. Extensive experiments across multiple\nmodel architectures, tasks, and datasets demonstrate the effectiveness of\nS-FRET and show that G-FRET achieves state-of-the-art performance. Further\nanalysis reveals that G-FRET enables the model to extract non-redundant and\nhighly discriminative features during inference, thereby facilitating more\nrobust test-time adaptation.", "AI": {"tldr": "FRET introduces methods (S-FRET and G-FRET) to reduce feature redundancy in test-time adaptation, improving model generalization under distribution shifts.", "motivation": "Addressing feature redundancy in embeddings during test-time adaptation, which existing methods overlook, to enhance model adaptability.", "method": "S-FRET minimizes feature redundancy directly, while G-FRET combines GCN and contrastive learning to reduce redundancy and improve feature discriminability.", "result": "G-FRET achieves state-of-the-art performance, extracting non-redundant and discriminative features for robust adaptation.", "conclusion": "FRET, especially G-FRET, effectively improves test-time adaptation by addressing feature redundancy and enhancing discriminability."}}
{"id": "2505.11065", "pdf": "https://arxiv.org/pdf/2505.11065", "abs": "https://arxiv.org/abs/2505.11065", "authors": ["Changlun Li", "Yao Shi", "Chen Wang", "Qiqi Duan", "Runke Ruan", "Weijie Huang", "Haonan Long", "Lijun Huang", "Yuyu Luo", "Nan Tang"], "title": "Time Travel is Cheating: Going Live with DeepFund for Real-Time Fund Investment Benchmarking", "categories": ["cs.CE", "cs.AI", "cs.MA"], "comment": "21 pages, 9 figures", "summary": "Large Language Models (LLMs) have demonstrated notable capabilities across\nfinancial tasks, including financial report summarization, earnings call\ntranscript analysis, and asset classification. However, their real-world\neffectiveness in managing complex fund investment remains inadequately\nassessed. A fundamental limitation of existing benchmarks for evaluating\nLLM-driven trading strategies is their reliance on historical back-testing,\ninadvertently enabling LLMs to \"time travel\"-leveraging future information\nembedded in their training corpora, thus resulting in possible information\nleakage and overly optimistic performance estimates. To address this issue, we\nintroduce DeepFund, a live fund benchmark tool designed to rigorously evaluate\nLLM in real-time market conditions. Utilizing a multi-agent architecture,\nDeepFund connects directly with real-time stock market data-specifically data\npublished after each model pretraining cutoff-to ensure fair and leakage-free\nevaluations. Empirical tests on nine flagship LLMs from leading global\ninstitutions across multiple investment dimensions-including ticker-level\nanalysis, investment decision-making, portfolio management, and risk\ncontrol-reveal significant practical challenges. Notably, even cutting-edge\nmodels such as DeepSeek-V3 and Claude-3.7-Sonnet incur net trading losses\nwithin DeepFund real-time evaluation environment, underscoring the present\nlimitations of LLMs for active fund management. Our code is available at\nhttps://github.com/HKUSTDial/DeepFund.", "AI": {"tldr": "DeepFund introduces a live benchmark tool to evaluate LLMs in real-time fund management, revealing their limitations despite their capabilities in other financial tasks.", "motivation": "Existing benchmarks for LLM-driven trading strategies rely on historical back-testing, leading to information leakage and overly optimistic performance estimates.", "method": "DeepFund uses a multi-agent architecture connected to real-time stock market data (post-pretraining cutoff) for leakage-free evaluations.", "result": "Empirical tests on nine flagship LLMs show net trading losses, highlighting practical challenges in active fund management.", "conclusion": "LLMs currently face significant limitations in real-time fund management, as demonstrated by DeepFund's live evaluations."}}
{"id": "2502.04522", "pdf": "https://arxiv.org/pdf/2502.04522", "abs": "https://arxiv.org/abs/2502.04522", "authors": ["Keshav Bhandari", "Sungkyun Chang", "Tongyu Lu", "Fareza R. Enus", "Louis B. Bradshaw", "Dorien Herremans", "Simon Colton"], "title": "ImprovNet -- Generating Controllable Musical Improvisations with Iterative Corruption Refinement", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "10 pages, 6 figures, IJCNN 2025 conference", "summary": "Despite deep learning's remarkable advances in style transfer across various\ndomains, generating controllable performance-level musical style transfer for\ncomplete symbolically represented musical works remains a challenging area of\nresearch. Much of this is owed to limited datasets, especially for genres such\nas jazz, and the lack of unified models that can handle multiple music\ngeneration tasks. This paper presents ImprovNet, a transformer-based\narchitecture that generates expressive and controllable musical improvisations\nthrough a self-supervised corruption-refinement training strategy. The\nimprovisational style transfer is aimed at making meaningful modifications to\none or more musical elements - melody, harmony or rhythm of the original\ncomposition with respect to the target genre. ImprovNet unifies multiple\ncapabilities within a single model: it can perform cross-genre and intra-genre\nimprovisations, harmonize melodies with genre-specific styles, and execute\nshort prompt continuation and infilling tasks. The model's iterative generation\nframework allows users to control the degree of style transfer and structural\nsimilarity to the original composition. Objective and subjective evaluations\ndemonstrate ImprovNet's effectiveness in generating musically coherent\nimprovisations while maintaining structural relationships with the original\npieces. The model outperforms Anticipatory Music Transformer in short\ncontinuation and infilling tasks and successfully achieves recognizable genre\nconversion, with 79\\% of participants correctly identifying jazz-style\nimprovisations of classical pieces. Our code and demo page can be found at\nhttps://github.com/keshavbhandari/improvnet.", "AI": {"tldr": "ImprovNet is a transformer-based model for controllable musical style transfer, excelling in cross-genre improvisations, harmonization, and short prompt tasks.", "motivation": "Addressing the challenge of controllable musical style transfer due to limited datasets and lack of unified models for multiple tasks.", "method": "Uses a self-supervised corruption-refinement training strategy with a transformer-based architecture.", "result": "Outperforms Anticipatory Music Transformer in tasks and achieves 79% accuracy in genre conversion.", "conclusion": "ImprovNet effectively generates coherent improvisations while maintaining structural ties to original compositions."}}
{"id": "2505.11109", "pdf": "https://arxiv.org/pdf/2505.11109", "abs": "https://arxiv.org/abs/2505.11109", "authors": ["Florinel-Alin Croitoru", "Vlad Hondru", "Marius Popescu", "Radu Tudor Ionescu", "Fahad Shahbaz Khan", "Mubarak Shah"], "title": "MAVOS-DD: Multilingual Audio-Video Open-Set Deepfake Detection Benchmark", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "15 pages", "summary": "We present the first large-scale open-set benchmark for multilingual\naudio-video deepfake detection. Our dataset comprises over 250 hours of real\nand fake videos across eight languages, with 60% of data being generated. For\neach language, the fake videos are generated with seven distinct deepfake\ngeneration models, selected based on the quality of the generated content. We\norganize the training, validation and test splits such that only a subset of\nthe chosen generative models and languages are available during training, thus\ncreating several challenging open-set evaluation setups. We perform experiments\nwith various pre-trained and fine-tuned deepfake detectors proposed in recent\nliterature. Our results show that state-of-the-art detectors are not currently\nable to maintain their performance levels when tested in our open-set\nscenarios. We publicly release our data and code at:\nhttps://huggingface.co/datasets/unibuc-cs/MAVOS-DD.", "AI": {"tldr": "A large-scale multilingual audio-video deepfake detection benchmark is introduced, featuring 250+ hours of real and fake videos across eight languages, with 60% generated content. Open-set evaluation reveals state-of-the-art detectors struggle in unseen scenarios.", "motivation": "To address the lack of open-set benchmarks for multilingual audio-video deepfake detection, enabling robust evaluation of detectors in diverse, unseen conditions.", "method": "Dataset includes real and fake videos in eight languages, generated by seven models. Training splits exclude some models/languages to simulate open-set challenges. Various pre-trained and fine-tuned detectors are tested.", "result": "State-of-the-art detectors fail to maintain performance in open-set scenarios, highlighting their limitations.", "conclusion": "The benchmark exposes gaps in current deepfake detection methods, urging development of more robust solutions. Data and code are publicly released."}}
{"id": "2505.10855", "pdf": "https://arxiv.org/pdf/2505.10855", "abs": "https://arxiv.org/abs/2505.10855", "authors": ["Aneesh Rangnekar", "Nikhil Mankuzhy", "Jonas Willmann", "Chloe Choi", "Abraham Wu", "Maria Thor", "Andreas Rimner", "Harini Veeraraghavan"], "title": "Pretrained hybrid transformer for generalizable cardiac substructures segmentation from contrast and non-contrast CTs in lung and breast cancers", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "AI automated segmentations for radiation treatment planning (RTP) can\ndeteriorate when applied in clinical cases with different characteristics than\ntraining dataset. Hence, we refined a pretrained transformer into a hybrid\ntransformer convolutional network (HTN) to segment cardiac substructures lung\nand breast cancer patients acquired with varying imaging contrasts and patient\nscan positions. Cohort I, consisting of 56 contrast-enhanced (CECT) and 124\nnon-contrast CT (NCCT) scans from patients with non-small cell lung cancers\nacquired in supine position, was used to create oracle with all 180 training\ncases and balanced (CECT: 32, NCCT: 32 training) HTN models. Models were\nevaluated on a held-out validation set of 60 cohort I patients and 66 patients\nwith breast cancer from cohort II acquired in supine (n=45) and prone (n=21)\npositions. Accuracy was measured using DSC, HD95, and dose metrics. Publicly\navailable TotalSegmentator served as the benchmark. The oracle and balanced\nmodels were similarly accurate (DSC Cohort I: 0.80 \\pm 0.10 versus 0.81 \\pm\n0.10; Cohort II: 0.77 \\pm 0.13 versus 0.80 \\pm 0.12), outperforming\nTotalSegmentator. The balanced model, using half the training cases as oracle,\nproduced similar dose metrics as manual delineations for all cardiac\nsubstructures. This model was robust to CT contrast in 6 out of 8 substructures\nand patient scan position variations in 5 out of 8 substructures and showed low\ncorrelations of accuracy to patient size and age. A HTN demonstrated robustly\naccurate (geometric and dose metrics) cardiac substructures segmentation from\nCTs with varying imaging and patient characteristics, one key requirement for\nclinical use. Moreover, the model combining pretraining with balanced\ndistribution of NCCT and CECT scans was able to provide reliably accurate\nsegmentations under varied conditions with far fewer labeled datasets compared\nto an oracle model.", "AI": {"tldr": "A hybrid transformer convolutional network (HTN) was refined to segment cardiac substructures in lung and breast cancer patients, showing robustness to imaging contrasts and scan positions, outperforming benchmarks with fewer training cases.", "motivation": "AI segmentations for radiation treatment planning often fail in clinical cases differing from training data, necessitating a robust model adaptable to varied imaging and patient conditions.", "method": "A pretrained transformer was refined into an HTN, trained on balanced datasets of contrast-enhanced and non-contrast CT scans, and evaluated on validation sets with diverse patient characteristics.", "result": "The HTN achieved similar accuracy to an oracle model with half the training cases, outperformed benchmarks, and showed robustness to imaging contrasts and scan positions.", "conclusion": "The HTN provides reliable cardiac substructure segmentation under varied conditions, meeting clinical requirements with reduced labeled data needs."}}
{"id": "2411.08135", "pdf": "https://arxiv.org/pdf/2411.08135", "abs": "https://arxiv.org/abs/2411.08135", "authors": ["Samuel J. Bell", "Mariano Coria Meglioli", "Megan Richards", "Eduardo S\u00e1nchez", "Christophe Ropers", "Skyler Wang", "Adina Williams", "Levent Sagun", "Marta R. Costa-juss\u00e0"], "title": "On the Role of Speech Data in Reducing Toxicity Detection Bias", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": "Accepted at NAACL 2025", "summary": "Text toxicity detection systems exhibit significant biases, producing\ndisproportionate rates of false positives on samples mentioning demographic\ngroups. But what about toxicity detection in speech? To investigate the extent\nto which text-based biases are mitigated by speech-based systems, we produce a\nset of high-quality group annotations for the multilingual MuTox dataset, and\nthen leverage these annotations to systematically compare speech- and\ntext-based toxicity classifiers. Our findings indicate that access to speech\ndata during inference supports reduced bias against group mentions,\nparticularly for ambiguous and disagreement-inducing samples. Our results also\nsuggest that improving classifiers, rather than transcription pipelines, is\nmore helpful for reducing group bias. We publicly release our annotations and\nprovide recommendations for future toxicity dataset construction.", "AI": {"tldr": "Speech-based toxicity detection reduces bias compared to text-based systems, especially for ambiguous cases, and improving classifiers is more effective than transcription pipelines.", "motivation": "To investigate if speech-based toxicity detection mitigates biases found in text-based systems.", "method": "Produced high-quality group annotations for the MuTox dataset and compared speech- and text-based toxicity classifiers.", "result": "Speech data reduces bias, particularly for ambiguous samples, and classifier improvements are more impactful than transcription pipelines.", "conclusion": "Speech-based systems help mitigate bias; annotations and recommendations are released for future dataset construction."}}
{"id": "2505.10601", "pdf": "https://arxiv.org/pdf/2505.10601", "abs": "https://arxiv.org/abs/2505.10601", "authors": ["Chuang Chen", "Wenyi Ge"], "title": "SRMamba: Mamba for Super-Resolution of LiDAR Point Clouds", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "In recent years, range-view-based LiDAR point cloud super-resolution\ntechniques attract significant attention as a low-cost method for generating\nhigher-resolution point cloud data. However, due to the sparsity and irregular\nstructure of LiDAR point clouds, the point cloud super-resolution problem\nremains a challenging topic, especially for point cloud upsampling under novel\nviews. In this paper, we propose SRMamba, a novel method for super-resolution\nof LiDAR point clouds in sparse scenes, addressing the key challenge of\nrecovering the 3D spatial structure of point clouds from novel views.\nSpecifically, we implement projection technique based on Hough Voting and Hole\nCompensation strategy to eliminate horizontally linear holes in range image. To\nimprove the establishment of long-distance dependencies and to focus on\npotential geometric features in vertical 3D space, we employ Visual State Space\nmodel and Multi-Directional Scanning mechanism to mitigate the loss of 3D\nspatial structural information due to the range image. Additionally, an\nasymmetric U-Net network adapts to the input characteristics of LiDARs with\ndifferent beam counts, enabling super-resolution reconstruction for multi-beam\npoint clouds. We conduct a series of experiments on multiple challenging public\nLiDAR datasets (SemanticKITTI and nuScenes), and SRMamba demonstrates\nsignificant superiority over other algorithms in both qualitative and\nquantitative evaluations.", "AI": {"tldr": "SRMamba is a novel method for LiDAR point cloud super-resolution, addressing challenges like sparsity and irregular structure, especially for novel views. It uses Hough Voting, Hole Compensation, Visual State Space, and Multi-Directional Scanning to improve 3D spatial recovery.", "motivation": "The sparsity and irregular structure of LiDAR point clouds make super-resolution challenging, particularly for novel views. Existing methods struggle with recovering 3D spatial structures.", "method": "SRMamba employs projection techniques (Hough Voting, Hole Compensation) and a Visual State Space model with Multi-Directional Scanning. An asymmetric U-Net adapts to multi-beam LiDAR inputs.", "result": "Experiments on SemanticKITTI and nuScenes show SRMamba outperforms other algorithms in qualitative and quantitative evaluations.", "conclusion": "SRMamba effectively addresses LiDAR point cloud super-resolution challenges, demonstrating superior performance in recovering 3D spatial structures from novel views."}}
{"id": "2505.10803", "pdf": "https://arxiv.org/pdf/2505.10803", "abs": "https://arxiv.org/abs/2505.10803", "authors": ["Zhaoan Wang", "Wonseok Jang", "Bowen Ruan", "Jun Wang", "Shaoping Xiao"], "title": "Developing and Integrating Trust Modeling into Multi-Objective Reinforcement Learning for Intelligent Agricultural Management", "categories": ["cs.AI"], "comment": null, "summary": "Precision agriculture, enhanced by artificial intelligence (AI), offers\npromising tools such as remote sensing, intelligent irrigation, fertilization\nmanagement, and crop simulation to improve agricultural efficiency and\nsustainability. Reinforcement learning (RL), in particular, has outperformed\ntraditional methods in optimizing yields and resource management. However,\nwidespread AI adoption is limited by gaps between algorithmic recommendations\nand farmers' practical experience, local knowledge, and traditional practices.\nTo address this, our study emphasizes Human-AI Interaction (HAII), focusing on\ntransparency, usability, and trust in RL-based farm management. We employ a\nwell-established trust framework - comprising ability, benevolence, and\nintegrity - to develop a novel mathematical model quantifying farmers'\nconfidence in AI-based fertilization strategies. Surveys conducted with farmers\nfor this research reveal critical misalignments, which are integrated into our\ntrust model and incorporated into a multi-objective RL framework. Unlike prior\nmethods, our approach embeds trust directly into policy optimization, ensuring\nAI recommendations are technically robust, economically feasible,\ncontext-aware, and socially acceptable. By aligning technical performance with\nhuman-centered trust, this research supports broader AI adoption in\nagriculture.", "AI": {"tldr": "The paper proposes a Human-AI Interaction (HAII) framework to bridge gaps between AI recommendations and farmers' trust, integrating trust into RL-based farm management for broader AI adoption.", "motivation": "AI in agriculture faces adoption barriers due to misalignment with farmers' practical experience and trust issues. The study aims to enhance trust in AI-based fertilization strategies.", "method": "Develops a trust model (ability, benevolence, integrity) and integrates it into a multi-objective RL framework, validated through farmer surveys.", "result": "The approach ensures AI recommendations are technically robust, economically viable, context-aware, and socially acceptable, addressing farmer concerns.", "conclusion": "Aligning technical performance with human-centered trust supports wider AI adoption in agriculture."}}
{"id": "2505.10772", "pdf": "https://arxiv.org/pdf/2505.10772", "abs": "https://arxiv.org/abs/2505.10772", "authors": ["Weiqin Wang", "Yile Wang", "Hui Huang"], "title": "Ranked Voting based Self-Consistency of Large Language Models", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Majority voting is considered an effective method to enhance chain-of-thought\nreasoning, as it selects the answer with the highest \"self-consistency\" among\ndifferent reasoning paths (Wang et al., 2023). However, previous\nchain-of-thought reasoning methods typically generate only a single answer in\neach trial, thereby ignoring the possibility of other potential answers. As a\nresult, these alternative answers are often overlooked in subsequent voting\nprocesses. In this work, we propose to generate ranked answers in each\nreasoning process and conduct ranked voting among multiple ranked answers from\ndifferent responses, thereby making the overall self-consistency more reliable.\nSpecifically, we use three ranked voting methods: Instant-runoff voting, Borda\ncount voting, and mean reciprocal rank voting. We validate our methods on six\ndatasets, including three multiple-choice and three open-ended\nquestion-answering tasks, using both advanced open-source and closed-source\nlarge language models. Extensive experimental results indicate that our\nproposed method outperforms the baselines, showcasing the potential of\nleveraging the information of ranked answers and using ranked voting to improve\nreasoning performance. The code is available at\nhttps://github.com/szu-tera/RankedVotingSC.", "AI": {"tldr": "The paper introduces ranked voting methods (Instant-runoff, Borda count, mean reciprocal rank) to improve chain-of-thought reasoning by considering multiple ranked answers, outperforming single-answer baselines.", "motivation": "Existing chain-of-thought methods generate only one answer per trial, missing potential alternatives. Ranked voting leverages multiple answers for more reliable self-consistency.", "method": "Proposes generating ranked answers and using three ranked voting methods (Instant-runoff, Borda count, mean reciprocal rank) to aggregate answers from multiple reasoning paths.", "result": "Validated on six datasets, the method outperforms baselines, demonstrating improved reasoning performance with ranked voting.", "conclusion": "Ranked voting enhances reasoning reliability by utilizing multiple answers, showing promise for future applications."}}
{"id": "2505.10646", "pdf": "https://arxiv.org/pdf/2505.10646", "abs": "https://arxiv.org/abs/2505.10646", "authors": ["Haoxiang You", "Yilang Liu", "Ian Abraham"], "title": "Accelerating Visual-Policy Learning through Parallel Differentiable Simulation", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "In this work, we propose a computationally efficient algorithm for visual\npolicy learning that leverages differentiable simulation and first-order\nanalytical policy gradients. Our approach decouple the rendering process from\nthe computation graph, enabling seamless integration with existing\ndifferentiable simulation ecosystems without the need for specialized\ndifferentiable rendering software. This decoupling not only reduces\ncomputational and memory overhead but also effectively attenuates the policy\ngradient norm, leading to more stable and smoother optimization. We evaluate\nour method on standard visual control benchmarks using modern GPU-accelerated\nsimulation. Experiments show that our approach significantly reduces wall-clock\ntraining time and consistently outperforms all baseline methods in terms of\nfinal returns. Notably, on complex tasks such as humanoid locomotion, our\nmethod achieves a $4\\times$ improvement in final return, and successfully\nlearns a humanoid running policy within 4 hours on a single GPU.", "AI": {"tldr": "A computationally efficient algorithm for visual policy learning using differentiable simulation and first-order policy gradients, reducing overhead and improving stability.", "motivation": "To streamline visual policy learning by decoupling rendering from computation, avoiding specialized tools and enhancing efficiency.", "method": "Leverages differentiable simulation and first-order analytical policy gradients, decoupling rendering for seamless integration.", "result": "Reduces training time, outperforms baselines, and achieves 4\u00d7 improvement in final returns on complex tasks like humanoid locomotion.", "conclusion": "The method is efficient, stable, and effective for visual policy learning, with significant performance gains."}}
{"id": "2503.05383", "pdf": "https://arxiv.org/pdf/2503.05383", "abs": "https://arxiv.org/abs/2503.05383", "authors": ["Weiyu Ma", "Yuqian Fu", "Zecheng Zhang", "Bernard Ghanem", "Guohao Li"], "title": "AVA: Attentive VLM Agent for Mastering StarCraft II", "categories": ["cs.AI", "cs.MA"], "comment": "Under Review", "summary": "We introduce Attentive VLM Agent (AVA), a multimodal StarCraft II agent that\naligns artificial agent perception with the human gameplay experience.\nTraditional frameworks such as SMAC rely on abstract state representations that\ndiverge significantly from human perception, limiting the ecological validity\nof agent behavior. Our agent addresses this limitation by incorporating RGB\nvisual inputs and natural language observations that more closely simulate\nhuman cognitive processes during gameplay. The AVA architecture consists of\nthree integrated components: (1) a vision-language model enhanced with\nspecialized self-attention mechanisms for strategic unit targeting and\nbattlefield assessment, (2) a retrieval-augmented generation system that\nleverages domain-specific StarCraft II knowledge to inform tactical decisions,\nand (3) a dynamic role-based task distribution system that enables coordinated\nmulti-agent behavior. The experimental evaluation in our proposed AVACraft\nenvironment, which contains 21 multimodal StarCraft II scenarios, demonstrates\nthat AVA powered by foundation models (specifically Qwen-VL and GPT-4o) can\nexecute complex tactical maneuvers without explicit training, achieving\ncomparable performance to traditional MARL methods that require substantial\ntraining iterations. This work establishes a foundation for developing\nhuman-aligned StarCraft II agents and advances the broader research agenda of\nmultimodal game AI. Our implementation is available at\nhttps://github.com/camel-ai/VLM-Play-StarCraft2.", "AI": {"tldr": "AVA is a multimodal StarCraft II agent using RGB visuals and language to align with human perception, outperforming traditional methods without extensive training.", "motivation": "To bridge the gap between abstract agent perception and human gameplay experience for ecological validity.", "method": "Combines a vision-language model, retrieval-augmented generation, and dynamic role-based task distribution.", "result": "Achieves comparable performance to traditional MARL methods without explicit training in 21 scenarios.", "conclusion": "AVA advances human-aligned game AI and multimodal agent research."}}
{"id": "2502.07461", "pdf": "https://arxiv.org/pdf/2502.07461", "abs": "https://arxiv.org/abs/2502.07461", "authors": ["Abhinaba Roy", "Renhang Liu", "Tongyu Lu", "Dorien Herremans"], "title": "JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata", "categories": ["cs.SD", "cs.AI"], "comment": "8 pages, 5 figures", "summary": "We introduce JamendoMaxCaps, a large-scale music-caption dataset featuring\nover 362,000 freely licensed instrumental tracks from the renowned Jamendo\nplatform. The dataset includes captions generated by a state-of-the-art\ncaptioning model, enhanced with imputed metadata. We also introduce a retrieval\nsystem that leverages both musical features and metadata to identify similar\nsongs, which are then used to fill in missing metadata using a local large\nlanguage model (LLLM). This approach allows us to provide a more comprehensive\nand informative dataset for researchers working on music-language understanding\ntasks. We validate this approach quantitatively with five different\nmeasurements. By making the JamendoMaxCaps dataset publicly available, we\nprovide a high-quality resource to advance research in music-language\nunderstanding tasks such as music retrieval, multimodal representation\nlearning, and generative music models.", "AI": {"tldr": "JamendoMaxCaps is a large-scale music-caption dataset with 362,000 instrumental tracks, enhanced captions, and metadata imputation via a retrieval system and LLLM. Validated with five metrics, it supports music-language research.", "motivation": "To provide a comprehensive dataset for music-language understanding tasks by combining captions, metadata, and retrieval techniques.", "method": "Created a dataset with captions from a state-of-the-art model, imputed missing metadata using a retrieval system and LLLM, and validated with five measurements.", "result": "A high-quality, publicly available dataset (JamendoMaxCaps) with enhanced captions and metadata for music-language research.", "conclusion": "JamendoMaxCaps advances research in music retrieval, multimodal learning, and generative models by offering a rich, validated dataset."}}
{"id": "2505.11425", "pdf": "https://arxiv.org/pdf/2505.11425", "abs": "https://arxiv.org/abs/2505.11425", "authors": ["Michal Podstawski", "Malgorzata Kudelska", "Haohong Wang"], "title": "Face Consistency Benchmark for GenAI Video", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Video generation driven by artificial intelligence has advanced\nsignificantly, enabling the creation of dynamic and realistic content. However,\nmaintaining character consistency across video sequences remains a major\nchallenge, with current models struggling to ensure coherence in appearance and\nattributes. This paper introduces the Face Consistency Benchmark (FCB), a\nframework for evaluating and comparing the consistency of characters in\nAI-generated videos. By providing standardized metrics, the benchmark\nhighlights gaps in existing solutions and promotes the development of more\nreliable approaches. This work represents a crucial step toward improving\ncharacter consistency in AI video generation technologies.", "AI": {"tldr": "The paper introduces the Face Consistency Benchmark (FCB) to evaluate character consistency in AI-generated videos, addressing a key challenge in the field.", "motivation": "Current AI video generation struggles with maintaining character consistency, prompting the need for a standardized evaluation framework.", "method": "The paper proposes the FCB framework, providing metrics to assess and compare character consistency in videos.", "result": "The benchmark identifies gaps in existing solutions and encourages more reliable approaches.", "conclusion": "This work advances AI video generation by improving character consistency through standardized evaluation."}}
{"id": "2505.10993", "pdf": "https://arxiv.org/pdf/2505.10993", "abs": "https://arxiv.org/abs/2505.10993", "authors": ["Yuan Zhang", "Xinfeng Zhang", "Xiaoming Qi Xinyu Wu", "Feng Chen", "Guanyu Yang", "Huazhu Fu"], "title": "Generative Models in Computational Pathology: A Comprehensive Survey on Methods, Applications, and Challenges", "categories": ["eess.IV", "cs.CV"], "comment": "18 pages,9 figures", "summary": "Generative modeling has emerged as a promising direction in computational\npathology, offering capabilities such as data-efficient learning, synthetic\ndata augmentation, and multimodal representation across diverse diagnostic\ntasks. This review provides a comprehensive synthesis of recent progress in the\nfield, organized into four key domains: image generation, text generation,\nmultimodal image-text generation, and other generative applications, including\nspatial simulation and molecular inference. By analyzing over 150\nrepresentative studies, we trace the evolution of generative architectures from\nearly generative adversarial networks to recent advances in diffusion models\nand foundation models with generative capabilities. We further examine the\ndatasets and evaluation protocols commonly used in this domain and highlight\nongoing limitations, including challenges in generating high-fidelity whole\nslide images, clinical interpretability, and concerns related to the ethical\nand legal implications of synthetic data. The review concludes with a\ndiscussion of open challenges and prospective research directions, with an\nemphasis on developing unified, multimodal, and clinically deployable\ngenerative systems. This work aims to provide a foundational reference for\nresearchers and practitioners developing and applying generative models in\ncomputational pathology.", "AI": {"tldr": "A review of generative modeling in computational pathology, covering image/text generation, multimodal applications, and challenges like fidelity and ethics.", "motivation": "To synthesize recent progress and highlight the potential of generative models in computational pathology for tasks like data augmentation and multimodal representation.", "method": "Analyzed over 150 studies, tracing the evolution of generative architectures (GANs to diffusion models) and examining datasets, evaluation protocols, and limitations.", "result": "Identified key domains (image/text generation, multimodal applications) and ongoing challenges (fidelity, interpretability, ethical concerns).", "conclusion": "Calls for unified, multimodal, and clinically deployable generative systems, providing a foundational reference for researchers."}}
{"id": "2502.16936", "pdf": "https://arxiv.org/pdf/2502.16936", "abs": "https://arxiv.org/abs/2502.16936", "authors": ["Joan Serr\u00e0", "R. Oguz Araz", "Dmitry Bogdanov", "Yuki Mitsufuji"], "title": "Supervised contrastive learning from weakly-labeled audio segments for musical version matching", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "stat.ML"], "comment": "17 pages, 6 figures, 8 tables (includes Appendix); accepted at ICML25", "summary": "Detecting musical versions (different renditions of the same piece) is a\nchallenging task with important applications. Because of the ground truth\nnature, existing approaches match musical versions at the track level (e.g.,\nwhole song). However, most applications require to match them at the segment\nlevel (e.g., 20s chunks). In addition, existing approaches resort to\nclassification and triplet losses, disregarding more recent losses that could\nbring meaningful improvements. In this paper, we propose a method to learn from\nweakly annotated segments, together with a contrastive loss variant that\noutperforms well-studied alternatives. The former is based on pairwise segment\ndistance reductions, while the latter modifies an existing loss following\ndecoupling, hyper-parameter, and geometric considerations. With these two\nelements, we do not only achieve state-of-the-art results in the standard\ntrack-level evaluation, but we also obtain a breakthrough performance in a\nsegment-level evaluation. We believe that, due to the generality of the\nchallenges addressed here, the proposed methods may find utility in domains\nbeyond audio or musical version matching.", "AI": {"tldr": "The paper proposes a method for detecting musical versions at the segment level using weakly annotated segments and a novel contrastive loss, achieving state-of-the-art results.", "motivation": "Existing methods match musical versions at the track level, but applications require segment-level matching. Current approaches also use outdated loss functions.", "method": "Uses weakly annotated segments with pairwise distance reductions and introduces a modified contrastive loss based on decoupling, hyper-parameter, and geometric considerations.", "result": "Achieves state-of-the-art results in track-level evaluation and breakthrough performance in segment-level evaluation.", "conclusion": "The proposed methods are generalizable and may benefit domains beyond audio or musical version matching."}}
{"id": "2505.10604", "pdf": "https://arxiv.org/pdf/2505.10604", "abs": "https://arxiv.org/abs/2505.10604", "authors": ["Chonghan Liu", "Haoran Wang", "Felix Henry", "Pu Miao", "Yajie Zhang", "Yu Zhao", "Peiran Wu"], "title": "MIRAGE: A Multi-modal Benchmark for Spatial Perception, Reasoning, and Intelligence", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Spatial perception and reasoning are core components of human cognition,\nencompassing object recognition, spatial relational understanding, and dynamic\nreasoning. Despite progress in computer vision, existing benchmarks reveal\nsignificant gaps in models' abilities to accurately recognize object attributes\nand reason about spatial relationships, both essential for dynamic reasoning.\nTo address these limitations, we propose MIRAGE, a multi-modal benchmark\ndesigned to evaluate models' capabilities in Counting (object attribute\nrecognition), Relation (spatial relational reasoning), and Counting with\nRelation. Through diverse and complex scenarios requiring fine-grained\nrecognition and reasoning, MIRAGE highlights critical limitations in\nstate-of-the-art models, underscoring the need for improved representations and\nreasoning frameworks. By targeting these foundational abilities, MIRAGE\nprovides a pathway toward spatiotemporal reasoning in future research.", "AI": {"tldr": "MIRAGE is a multi-modal benchmark evaluating models' abilities in object attribute recognition and spatial relational reasoning, highlighting gaps in current models.", "motivation": "Existing benchmarks show gaps in models' abilities for object attribute recognition and spatial relational reasoning, which are crucial for dynamic reasoning.", "method": "Proposes MIRAGE, a benchmark with diverse scenarios for evaluating Counting, Relation, and Counting with Relation tasks.", "result": "MIRAGE reveals limitations in state-of-the-art models, emphasizing the need for better representations and reasoning frameworks.", "conclusion": "MIRAGE provides a foundation for advancing spatiotemporal reasoning in future research."}}
{"id": "2505.10819", "pdf": "https://arxiv.org/pdf/2505.10819", "abs": "https://arxiv.org/abs/2505.10819", "authors": ["Wasu Top Piriyakulkij", "Yichao Liang", "Hao Tang", "Adrian Weller", "Marta Kryven", "Kevin Ellis"], "title": "PoE-World: Compositional World Modeling with Products of Programmatic Experts", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Learning how the world works is central to building AI agents that can adapt\nto complex environments. Traditional world models based on deep learning demand\nvast amounts of training data, and do not flexibly update their knowledge from\nsparse observations. Recent advances in program synthesis using Large Language\nModels (LLMs) give an alternate approach which learns world models represented\nas source code, supporting strong generalization from little data. To date,\napplication of program-structured world models remains limited to natural\nlanguage and grid-world domains. We introduce a novel program synthesis method\nfor effectively modeling complex, non-gridworld domains by representing a world\nmodel as an exponentially-weighted product of programmatic experts (PoE-World)\nsynthesized by LLMs. We show that this approach can learn complex, stochastic\nworld models from just a few observations. We evaluate the learned world models\nby embedding them in a model-based planning agent, demonstrating efficient\nperformance and generalization to unseen levels on Atari's Pong and Montezuma's\nRevenge. We release our code and display the learned world models and videos of\nthe agent's gameplay at https://topwasu.github.io/poe-world.", "AI": {"tldr": "A novel program synthesis method, PoE-World, uses LLMs to create world models as weighted programs, enabling efficient learning from sparse data in complex domains like Atari games.", "motivation": "Traditional deep learning world models require large datasets and lack flexibility. Program synthesis with LLMs offers a promising alternative for generalization from limited data.", "method": "PoE-World represents world models as exponentially-weighted products of programmatic experts synthesized by LLMs, learning complex, stochastic models from few observations.", "result": "The method successfully models complex domains like Atari's Pong and Montezuma's Revenge, showing efficient performance and generalization to unseen levels.", "conclusion": "PoE-World demonstrates the potential of program synthesis for building adaptable world models with minimal data, advancing AI agent capabilities."}}
{"id": "2505.10775", "pdf": "https://arxiv.org/pdf/2505.10775", "abs": "https://arxiv.org/abs/2505.10775", "authors": ["Kian Ahrabian", "Pegah Jandaghi", "Negar Mokhberian", "Sai Praneeth Karimireddy", "Jay Pujara"], "title": "A Systematic Analysis of Base Model Choice for Reward Modeling", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 13 figures, 5 tables", "summary": "Reinforcement learning from human feedback (RLHF) and, at its core, reward\nmodeling have become a crucial part of training powerful large language models\n(LLMs). One commonly overlooked factor in training high-quality reward models\n(RMs) is the effect of the base model, which is becoming more challenging to\nchoose given the rapidly growing pool of LLMs. In this work, we present a\nsystematic analysis of the effect of base model selection on reward modeling\nperformance. Our results show that the performance can be improved by up to 14%\ncompared to the most common (i.e., default) choice. Moreover, we showcase the\nstrong statistical relation between some existing benchmarks and downstream\nperformances. We also demonstrate that the results from a small set of\nbenchmarks could be combined to boost the model selection ($+$18% on average in\nthe top 5-10). Lastly, we illustrate the impact of different post-training\nsteps on the final performance and explore using estimated data distributions\nto reduce performance prediction error.", "AI": {"tldr": "The paper analyzes how base model selection impacts reward modeling in RLHF, showing up to 14% performance improvement over default choices and highlighting the role of benchmarks and post-training steps.", "motivation": "The choice of base models for reward modeling in RLHF is often overlooked, yet critical, given the growing variety of LLMs. This work aims to systematically study its impact.", "method": "The study evaluates base model selection's effect on reward modeling performance, uses benchmarks to predict downstream performance, and explores post-training steps and data distributions.", "result": "Performance improves by up to 14% with better base model choices. Benchmarks strongly correlate with downstream results, and combining them boosts selection accuracy (+18% in top 5-10). Post-training steps and data distributions also impact performance.", "conclusion": "Base model selection significantly affects reward modeling. Leveraging benchmarks and optimizing post-training can enhance performance, offering practical insights for RLHF in LLMs."}}
{"id": "2505.10665", "pdf": "https://arxiv.org/pdf/2505.10665", "abs": "https://arxiv.org/abs/2505.10665", "authors": ["Wei Wang", "Weidong Yang", "Lei Wang", "Guihua Wang", "Ruibo Lei"], "title": "Seasonal Forecasting of Pan-Arctic Sea Ice with State Space Model", "categories": ["cs.LG", "cs.AI"], "comment": "This paper is published in npj Climate and Atmospheric Science:\n  https://www.nature.com/articles/s41612-025-01058-0#Sec16 Supplementary\n  information:\n  https://static-content.springer.com/esm/art%3A10.1038%2Fs41612-025-01058-0/MediaObjects/41612_2025_1058_MOESM1_ESM.pdf", "summary": "The rapid decline of Arctic sea ice resulting from anthropogenic climate\nchange poses significant risks to indigenous communities, ecosystems, and the\nglobal climate system. This situation emphasizes the immediate necessity for\nprecise seasonal sea ice forecasts. While dynamical models perform well for\nshort-term forecasts, they encounter limitations in long-term forecasts and are\ncomputationally intensive. Deep learning models, while more computationally\nefficient, often have difficulty managing seasonal variations and uncertainties\nwhen dealing with complex sea ice dynamics. In this research, we introduce\nIceMamba, a deep learning architecture that integrates sophisticated attention\nmechanisms within the state space model. Through comparative analysis of 25\nrenowned forecast models, including dynamical, statistical, and deep learning\napproaches, our experimental results indicate that IceMamba delivers excellent\nseasonal forecasting capabilities for Pan-Arctic sea ice concentration.\nSpecifically, IceMamba outperforms all tested models regarding average RMSE and\nanomaly correlation coefficient (ACC) and ranks second in Integrated Ice Edge\nError (IIEE). This innovative approach enhances our ability to foresee and\nalleviate the effects of sea ice variability, offering essential insights for\nstrategies aimed at climate adaptation.", "AI": {"tldr": "IceMamba, a deep learning model with attention mechanisms, outperforms 25 other models in seasonal Arctic sea ice forecasting, excelling in RMSE and ACC metrics.", "motivation": "The rapid decline of Arctic sea ice due to climate change necessitates accurate seasonal forecasts, but existing models (dynamical and deep learning) have limitations in long-term predictions and handling seasonal variations.", "method": "Introduces IceMamba, a deep learning architecture combining attention mechanisms with state space models, and compares it against 25 forecast models.", "result": "IceMamba excels in RMSE and ACC, ranking second in IIEE, demonstrating superior seasonal forecasting capabilities.", "conclusion": "IceMamba improves forecasting accuracy, aiding climate adaptation strategies by better predicting sea ice variability."}}
{"id": "2505.03820", "pdf": "https://arxiv.org/pdf/2505.03820", "abs": "https://arxiv.org/abs/2505.03820", "authors": ["Keidai Iiyama", "Daniel Neamati", "Grace Gao"], "title": "Satellite Autonomous Clock Fault Monitoring with Inter-Satellite Ranges Using Euclidean Distance Matrices", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "comment": "This manuscript was submitted to the NAVIGATION: Journal of the\n  Institute of Navigation", "summary": "To address the need for robust positioning, navigation, and timing services\nin lunar environments, this paper proposes a novel onboard clock phase jump\ndetection framework for satellite constellations using range measurements\nobtained from dual one-way inter-satellite links. Our approach leverages vertex\nredundantly rigid graphs to detect faults without relying on prior knowledge of\nsatellite positions or clock biases, providing flexibility for lunar satellite\nnetworks with diverse satellite types and operators. We model satellite\nconstellations as graphs, where satellites are vertices and inter-satellite\nlinks are edges. The proposed algorithm detects and identifies satellites with\nclock jumps by monitoring the singular values of the geometric-centered\nEuclidean distance matrix (GCEDM) of 5-clique sub-graphs. The proposed method\nis validated through simulations of a GPS constellation and a notional\nconstellation around the Moon, demonstrating its effectiveness in various\nconfigurations.", "AI": {"tldr": "A novel framework detects clock phase jumps in lunar satellite constellations using inter-satellite links and graph theory, validated via simulations.", "motivation": "Addressing the need for robust positioning, navigation, and timing services in lunar environments.", "method": "Uses vertex redundantly rigid graphs and GCEDM of 5-clique sub-graphs to detect clock jumps without prior knowledge of satellite positions or biases.", "result": "Effective detection and identification of clock jumps in simulated GPS and lunar constellations.", "conclusion": "The method is flexible and effective for diverse lunar satellite networks."}}
{"id": "2504.07776", "pdf": "https://arxiv.org/pdf/2504.07776", "abs": "https://arxiv.org/abs/2504.07776", "authors": ["Kaidi Wang", "Wenhao Guan", "Shenghui Lu", "Jianglong Yao", "Lin Li", "Qingyang Hong"], "title": "SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified Flow", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Recently, flow matching based speech synthesis has significantly enhanced the\nquality of synthesized speech while reducing the number of inference steps. In\nthis paper, we introduce SlimSpeech, a lightweight and efficient speech\nsynthesis system based on rectified flow. We have built upon the existing\nspeech synthesis method utilizing the rectified flow model, modifying its\nstructure to reduce parameters and serve as a teacher model. By refining the\nreflow operation, we directly derive a smaller model with a more straight\nsampling trajectory from the larger model, while utilizing distillation\ntechniques to further enhance the model performance. Experimental results\ndemonstrate that our proposed method, with significantly reduced model\nparameters, achieves comparable performance to larger models through one-step\nsampling.", "AI": {"tldr": "SlimSpeech is a lightweight speech synthesis system using rectified flow, achieving high-quality results with fewer parameters and steps.", "motivation": "To enhance speech synthesis efficiency by reducing model size and inference steps while maintaining quality.", "method": "Modifies rectified flow structure, uses distillation, and refines reflow for a smaller, efficient model.", "result": "Achieves comparable performance to larger models with one-step sampling and fewer parameters.", "conclusion": "SlimSpeech offers a lightweight, efficient solution for high-quality speech synthesis."}}
{"id": "2409.04388", "pdf": "https://arxiv.org/pdf/2409.04388", "abs": "https://arxiv.org/abs/2409.04388", "authors": ["Hangyu Qin", "Junbin Xiao", "Angela Yao"], "title": "Question-Answering Dense Video Events", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Accepted to SIGIR'25", "summary": "This paper presents question-answering on dense video events, a novel task\nthat answers and grounds dense-event questions in long videos, thus challenging\nMLLMs to faithfully comprehend and reason about multiple events over extended\nperiods of time. To facilitate the study, we construct DeVE-QA -- a dataset\nfeaturing 78K questions about 26K events on 10.6K long videos. Our benchmarking\nshows that state-of-the-art MLLMs struggle on DeVE-QA. For improvement, we\npropose DeVi, a novel training-free MLLM approach that highlights a\nhierarchical captioning module, a temporal event memory module, and a\nself-consistency checking module to respectively detect, contextualize and\nmemorize, and ground dense-events in long videos for question answering.\nExtensive experiments show that DeVi is superior at answering dense-event\nquestions and grounding relevant video moments. Compared with existing MLLMs,\nit achieves a notable increase of 4.8% and 2.1% for G(round)QA accuracy on\nDeVE-QA and NExT-GQA, respectively. Data and code are available at\nhttps://github.com/QHUni/DeVE-QA.", "AI": {"tldr": "The paper introduces a novel task of question-answering on dense video events, presents the DeVE-QA dataset, and proposes DeVi, a training-free MLLM approach that outperforms state-of-the-art models.", "motivation": "To address the challenge of answering and grounding dense-event questions in long videos, which requires faithful comprehension and reasoning over extended periods.", "method": "Proposes DeVi, featuring hierarchical captioning, temporal event memory, and self-consistency checking modules to detect, contextualize, and ground dense events.", "result": "DeVi achieves a 4.8% and 2.1% increase in GQA accuracy on DeVE-QA and NExT-GQA datasets, respectively.", "conclusion": "DeVi demonstrates superior performance in answering dense-event questions and grounding relevant video moments, with data and code made publicly available."}}
{"id": "2505.11158", "pdf": "https://arxiv.org/pdf/2505.11158", "abs": "https://arxiv.org/abs/2505.11158", "authors": ["Xing Hu", "Xiangcheng Liu", "Qianqian Duan", "Danfeng Hong", "Dawei Zhang"], "title": "Diffusion Model in Hyperspectral Image Processing and Analysis: A Review", "categories": ["eess.IV", "cs.CV"], "comment": "33 pages,20 figures", "summary": "Hyperspectral image processing and analysis has important application value\nin remote sensing, agriculture and environmental monitoring, but its high\ndimensionality, data redundancy and noise interference etc. bring great\nchallenges to the analysis. Traditional models have limitations in dealing with\nthese complex data, and it is difficult to meet the increasing demand for\nanalysis. In recent years, Diffusion Model, as an emerging generative model,\nhas shown unique advantages in hyperspectral image processing. By simulating\nthe diffusion process of data in time, the Diffusion Model can effectively\nprocess high-dimensional data, generate high-quality samples, and perform well\nin denoising and data enhancement. In this paper, we review the recent research\nadvances in diffusion modeling for hyperspectral image processing and analysis,\nand discuss its applications in tasks such as high-dimensional data processing,\nnoise removal, classification, and anomaly detection. The performance of\ndiffusion-based models on image processing is compared and the challenges are\nsummarized. It is shown that the diffusion model can significantly improve the\naccuracy and efficiency of hyperspectral image analysis, providing a new\ndirection for future research.", "AI": {"tldr": "The paper reviews Diffusion Model's advantages in hyperspectral image processing, highlighting its effectiveness in handling high-dimensional data, denoising, and enhancing analysis accuracy.", "motivation": "Traditional models struggle with hyperspectral image complexities like high dimensionality and noise, prompting exploration of Diffusion Model's potential.", "method": "The paper reviews Diffusion Model's application in hyperspectral tasks, including data processing, noise removal, classification, and anomaly detection.", "result": "Diffusion Model improves accuracy and efficiency in hyperspectral image analysis, outperforming traditional methods.", "conclusion": "Diffusion Model offers a promising direction for future hyperspectral image research, addressing current challenges effectively."}}
{"id": "2505.10610", "pdf": "https://arxiv.org/pdf/2505.10610", "abs": "https://arxiv.org/abs/2505.10610", "authors": ["Zhaowei Wang", "Wenhao Yu", "Xiyu Ren", "Jipeng Zhang", "Yu Zhao", "Rohit Saxena", "Liang Cheng", "Ginny Wong", "Simon See", "Pasquale Minervini", "Yangqiu Song", "Mark Steedman"], "title": "MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly", "categories": ["cs.CV", "cs.CL"], "comment": "Work in progress", "summary": "The rapid extension of context windows in large vision-language models has\ngiven rise to long-context vision-language models (LCVLMs), which are capable\nof handling hundreds of images with interleaved text tokens in a single forward\npass. In this work, we introduce MMLongBench, the first benchmark covering a\ndiverse set of long-context vision-language tasks, to evaluate LCVLMs\neffectively and thoroughly. MMLongBench is composed of 13,331 examples spanning\nfive different categories of downstream tasks, such as Visual RAG and Many-Shot\nICL. It also provides broad coverage of image types, including various natural\nand synthetic images. To assess the robustness of the models to different input\nlengths, all examples are delivered at five standardized input lengths (8K-128K\ntokens) via a cross-modal tokenization scheme that combines vision patches and\ntext tokens. Through a thorough benchmarking of 46 closed-source and\nopen-source LCVLMs, we provide a comprehensive analysis of the current models'\nvision-language long-context ability. Our results show that: i) performance on\na single task is a weak proxy for overall long-context capability; ii) both\nclosed-source and open-source models face challenges in long-context\nvision-language tasks, indicating substantial room for future improvement; iii)\nmodels with stronger reasoning ability tend to exhibit better long-context\nperformance. By offering wide task coverage, various image types, and rigorous\nlength control, MMLongBench provides the missing foundation for diagnosing and\nadvancing the next generation of LCVLMs.", "AI": {"tldr": "MMLongBench is introduced as the first benchmark for evaluating long-context vision-language models (LCVLMs) across diverse tasks and image types, revealing challenges and insights for future improvements.", "motivation": "The rise of LCVLMs handling hundreds of images and interleaved text tokens necessitates a comprehensive benchmark to evaluate their capabilities thoroughly.", "method": "MMLongBench includes 13,331 examples across five task categories and various image types, standardized at five input lengths (8K-128K tokens) via cross-modal tokenization.", "result": "Benchmarking 46 LCVLMs shows: i) single-task performance is a weak proxy for overall capability; ii) both closed and open-source models struggle with long-context tasks; iii) reasoning ability correlates with better performance.", "conclusion": "MMLongBench provides a foundational tool for diagnosing and advancing LCVLMs, highlighting significant room for improvement in long-context vision-language tasks."}}
{"id": "2505.10834", "pdf": "https://arxiv.org/pdf/2505.10834", "abs": "https://arxiv.org/abs/2505.10834", "authors": ["Achintha Wijesinghe", "Weiwei Wang", "Suchinthaka Wanninayaka", "Songyang Zhang", "Zhi Ding"], "title": "TACO: Rethinking Semantic Communications with Task Adaptation and Context Embedding", "categories": ["cs.AI", "cs.LG", "eess.IV", "eess.SP"], "comment": "Submitted to the IEEE GlobeCom 2025", "summary": "Recent advancements in generative artificial intelligence have introduced\ngroundbreaking approaches to innovating next-generation semantic communication,\nwhich prioritizes conveying the meaning of a message rather than merely\ntransmitting raw data. A fundamental challenge in semantic communication lies\nin accurately identifying and extracting the most critical semantic information\nwhile adapting to downstream tasks without degrading performance, particularly\nwhen the objective at the receiver may evolve over time. To enable flexible\nadaptation to multiple tasks at the receiver, this work introduces a novel\nsemantic communication framework, which is capable of jointly capturing\ntask-specific information to enhance downstream task performance and contextual\ninformation. Through rigorous experiments on popular image datasets and\ncomputer vision tasks, our framework shows promising improvement compared to\nexisting work, including superior performance in downstream tasks, better\ngeneralizability, ultra-high bandwidth efficiency, and low reconstruction\nlatency.", "AI": {"tldr": "A novel semantic communication framework is introduced to enhance task performance by jointly capturing task-specific and contextual information, showing improvements in downstream tasks, generalizability, bandwidth efficiency, and latency.", "motivation": "The challenge in semantic communication is accurately identifying critical semantic information and adapting to evolving receiver objectives without performance degradation.", "method": "The proposed framework jointly captures task-specific and contextual information for flexible adaptation to multiple downstream tasks.", "result": "Experiments on image datasets and computer vision tasks demonstrate superior performance, better generalizability, high bandwidth efficiency, and low latency.", "conclusion": "The framework effectively addresses the challenge of semantic communication, offering promising improvements over existing methods."}}
{"id": "2505.10792", "pdf": "https://arxiv.org/pdf/2505.10792", "abs": "https://arxiv.org/abs/2505.10792", "authors": ["Zhan Peng Lee", "Andre Lin", "Calvin Tan"], "title": "Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to\nimprove factuality in large language models (LLMs) by grounding their outputs\nin retrieved documents. However, ensuring perfect retrieval of relevant\ninformation remains challenging, and when irrelevant content is passed\ndownstream to an LLM, it can lead to hallucinations. In this work, we propose\nFinetune-RAG, a simple and effective fine-tuning approach that features the\nfirst-of-its-kind RAG training dataset constructed to mimic real-world\nimperfections. Experimental results show that Finetune-RAG improves factual\naccuracy by 21.2% over the base model. We also propose a Bench-RAG, an\nLLM-as-a-judge evaluation pipeline that stress tests models under realistic\nimperfect retrieval scenarios. Our codebase and dataset are fully open sourced\nfor community use.", "AI": {"tldr": "Finetune-RAG improves factual accuracy in LLMs by fine-tuning with a dataset mimicking real-world retrieval imperfections, achieving a 21.2% boost. Bench-RAG evaluates models under imperfect retrieval scenarios.", "motivation": "Addressing the challenge of irrelevant retrieved content causing hallucinations in LLMs, aiming to enhance factual accuracy.", "method": "Proposes Finetune-RAG, a fine-tuning approach using a dataset simulating real-world retrieval imperfections, and Bench-RAG for evaluation.", "result": "Finetune-RAG improves factual accuracy by 21.2% over the base model.", "conclusion": "The approach effectively mitigates hallucinations and improves factual grounding, with open-sourced resources for community use."}}
{"id": "2505.10677", "pdf": "https://arxiv.org/pdf/2505.10677", "abs": "https://arxiv.org/abs/2505.10677", "authors": ["Ioannis Pitsiorlas", "Nour Jamoussi", "Marios Kountouris"], "title": "A Conformal Predictive Measure for Assessing Catastrophic Forgetting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This work introduces a novel methodology for assessing catastrophic\nforgetting (CF) in continual learning. We propose a new conformal prediction\n(CP)-based metric, termed the Conformal Prediction Confidence Factor (CPCF), to\nquantify and evaluate CF effectively. Our framework leverages adaptive CP to\nestimate forgetting by monitoring the model's confidence on previously learned\ntasks. This approach provides a dynamic and practical solution for monitoring\nand measuring CF of previous tasks as new ones are introduced, offering greater\nsuitability for real-world applications. Experimental results on four benchmark\ndatasets demonstrate a strong correlation between CPCF and the accuracy of\nprevious tasks, validating the reliability and interpretability of the proposed\nmetric. Our results highlight the potential of CPCF as a robust and effective\ntool for assessing and understanding CF in dynamic learning environments.", "AI": {"tldr": "A new metric, CPCF, is introduced to assess catastrophic forgetting in continual learning using conformal prediction, showing strong correlation with task accuracy.", "motivation": "To address the challenge of quantifying and evaluating catastrophic forgetting (CF) in continual learning, which is crucial for real-world applications.", "method": "Proposes the Conformal Prediction Confidence Factor (CPCF), leveraging adaptive conformal prediction to monitor model confidence on learned tasks.", "result": "Experiments on four datasets show CPCF strongly correlates with task accuracy, validating its reliability and interpretability.", "conclusion": "CPCF is a robust and effective tool for assessing CF in dynamic learning environments."}}
{"id": "2505.11393", "pdf": "https://arxiv.org/pdf/2505.11393", "abs": "https://arxiv.org/abs/2505.11393", "authors": ["Yuanhao Wang", "Shirin Shoushtari", "Ulugbek S. Kamilov"], "title": "Diff-Unfolding: A Model-Based Score Learning Framework for Inverse Problems", "categories": ["eess.IV"], "comment": "19 pages, 13 figures,", "summary": "Diffusion models are extensively used for modeling image priors for inverse\nproblems. We introduce \\emph{Diff-Unfolding}, a principled framework for\nlearning posterior score functions of \\emph{conditional diffusion models} by\nexplicitly incorporating the physical measurement operator into a modular\nnetwork architecture. Diff-Unfolding formulates posterior score learning as the\ntraining of an unrolled optimization scheme, where the measurement model is\ndecoupled from the learned image prior. This design allows our method to\ngeneralize across inverse problems at inference time by simply replacing the\nforward operator without retraining. We theoretically justify our unrolling\napproach by showing that the posterior score can be derived from a composite\nmodel-based optimization formulation. Extensive experiments on image\nrestoration and accelerated MRI show that Diff-Unfolding achieves\nstate-of-the-art performance, improving PSNR by up to 2 dB and reducing LPIPS\nby $22.7\\%$, while being both compact (47M parameters) and efficient (0.72\nseconds per $256 \\times 256$ image). An optimized C++/LibTorch implementation\nfurther reduces inference time to 0.63 seconds, underscoring the practicality\nof our approach.", "AI": {"tldr": "Diff-Unfolding is a framework for learning posterior score functions in conditional diffusion models, integrating measurement operators into a modular network for versatile inverse problem solving without retraining.", "motivation": "To improve the generalization and performance of diffusion models for inverse problems by decoupling the measurement model from the learned image prior.", "method": "Uses an unrolled optimization scheme to train posterior scores, incorporating the physical measurement operator into the network architecture.", "result": "Achieves state-of-the-art performance in image restoration and MRI, with significant PSNR and LPIPS improvements, while being efficient and compact.", "conclusion": "Diff-Unfolding is a practical, high-performance solution for inverse problems, validated by theoretical and experimental results."}}
{"id": "2505.10634", "pdf": "https://arxiv.org/pdf/2505.10634", "abs": "https://arxiv.org/abs/2505.10634", "authors": ["Jianfei Zhao", "Feng Zhang", "Xin Sun", "Chong Feng"], "title": "Mitigate Language Priors in Large Vision-Language Models by Cross-Images Contrastive Decoding", "categories": ["cs.CV"], "comment": null, "summary": "Language priors constitute one of the primary causes of hallucinations in\nLarge Vision-Language Models (LVLMs), driving the models to generate\nlinguistically plausible yet visually inconsistent content. The language priors\nin LVLMs originate from the linguistic knowledge inherited from their\npre-trained Large Language Model (LLM) backbone. Consequently, this\ncharacteristic is an intrinsic property of the model that remains independent\nof visual inputs. Inspired by the finding that language priors are consistent\nacross images, we propose Cross-Image Contrastive Decoding (CICD), a simple yet\neffective training-free method to alleviate language priors in LVLMs. CICD\nfirst identifies essential and detrimental priors, and then employs contrastive\ndecoding to eliminate the detrimental ones. This approach simultaneously\nprevents LVLMs from generating hallucinated content while maintaining textual\nfluency and coherence. Furthermore, the limited information overlap between\nimages helps prevent visual information loss during contrastive decoding. We\nvalidate the effectiveness of CICD on four benchmarks with six LVLMs. Our\nexperiments demonstrate that CICD performs remarkably well in mitigating\nlanguage priors, especially in the image captioning task, where such priors are\nmost pronounced. Code will be released once accepted.", "AI": {"tldr": "The paper proposes Cross-Image Contrastive Decoding (CICD), a training-free method to reduce language priors in Large Vision-Language Models (LVLMs), improving visual consistency without losing textual fluency.", "motivation": "Language priors in LVLMs cause hallucinations by generating visually inconsistent but linguistically plausible content, inherited from pre-trained LLMs.", "method": "CICD identifies and contrasts essential vs. detrimental priors, using cross-image information to mitigate hallucinations while preserving coherence.", "result": "CICD effectively reduces language priors in LVLMs, particularly in image captioning, as validated on four benchmarks with six models.", "conclusion": "CICD is a simple, effective solution for mitigating language priors in LVLMs, enhancing visual-textual alignment without additional training."}}
{"id": "2505.10844", "pdf": "https://arxiv.org/pdf/2505.10844", "abs": "https://arxiv.org/abs/2505.10844", "authors": ["Simeng Han", "Stephen Xia", "Grant Zhang", "Howard Dai", "Chen Liu", "Lichang Chen", "Hoang Huy Nguyen", "Hongyuan Mei", "Jiayuan Mao", "R. Thomas McCoy"], "title": "Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "13 Tables; 5 Figures", "summary": "Accuracy remains a standard metric for evaluating AI systems, but it offers\nlimited insight into how models arrive at their solutions. In this work, we\nintroduce a benchmark based on brainteasers written in long narrative form to\nprobe more deeply into the types of reasoning strategies that models use.\nBrainteasers are well-suited for this goal because they can be solved with\nmultiple approaches, such as a few-step solution that uses a creative insight\nor a longer solution that uses more brute force. We investigate large language\nmodels (LLMs) across multiple layers of reasoning, focusing not only on\ncorrectness but also on the quality and creativity of their solutions. We\ninvestigate many aspects of the reasoning process: (1) semantic parsing of the\nbrainteasers into precise mathematical competition style formats; (2)\ngenerating solutions from these mathematical forms; (3) self-correcting\nsolutions based on gold solutions; (4) producing step-by-step sketches of\nsolutions; and (5) making use of hints. We find that LLMs are in many cases\nable to find creative, insightful solutions to brainteasers, suggesting that\nthey capture some of the capacities needed to solve novel problems in creative\nways. Nonetheless, there also remain situations where they rely on brute force\ndespite the availability of more efficient, creative solutions, highlighting a\npotential direction for improvement in the reasoning abilities of LLMs.", "AI": {"tldr": "The paper introduces a benchmark using brainteasers to evaluate LLMs' reasoning strategies, focusing on correctness, quality, and creativity of solutions.", "motivation": "Accuracy alone doesn't reveal how AI models reason. Brainteasers, solvable via multiple approaches, help probe deeper into reasoning strategies.", "method": "The study evaluates LLMs across five reasoning layers: semantic parsing, solution generation, self-correction, step-by-step sketches, and hint utilization.", "result": "LLMs often produce creative solutions but sometimes default to brute force, indicating room for improvement in reasoning efficiency.", "conclusion": "LLMs show potential for creative problem-solving but need refinement to reduce reliance on brute-force methods."}}
{"id": "2505.10798", "pdf": "https://arxiv.org/pdf/2505.10798", "abs": "https://arxiv.org/abs/2505.10798", "authors": ["Erica Cai", "Sean McQuade", "Kevin Young", "Brendan O'Connor"], "title": "Relation Extraction Across Entire Books to Reconstruct Community Networks: The AffilKG Datasets", "categories": ["cs.CL"], "comment": null, "summary": "When knowledge graphs (KGs) are automatically extracted from text, are they\naccurate enough for downstream analysis? Unfortunately, current annotated\ndatasets can not be used to evaluate this question, since their KGs are highly\ndisconnected, too small, or overly complex. To address this gap, we introduce\nAffilKG (https://doi.org/10.5281/zenodo.15427977), which is a collection of six\ndatasets that are the first to pair complete book scans with large, labeled\nknowledge graphs. Each dataset features affiliation graphs, which are simple\nKGs that capture Member relationships between Person and Organization entities\n-- useful in studies of migration, community interactions, and other social\nphenomena. In addition, three datasets include expanded KGs with a wider\nvariety of relation types. Our preliminary experiments demonstrate significant\nvariability in model performance across datasets, underscoring AffilKG's\nability to enable two critical advances: (1) benchmarking how extraction errors\npropagate to graph-level analyses (e.g., community structure), and (2)\nvalidating KG extraction methods for real-world social science research.", "AI": {"tldr": "AffilKG introduces six datasets pairing book scans with labeled KGs to evaluate KG extraction accuracy, addressing gaps in current datasets.", "motivation": "Current annotated datasets are inadequate for evaluating KG extraction accuracy due to disconnection, small size, or complexity.", "method": "AffilKG provides six datasets with affiliation graphs (simple KGs) and expanded KGs, pairing book scans with labeled KGs.", "result": "Preliminary experiments show significant model performance variability, highlighting AffilKG's utility for benchmarking and validation.", "conclusion": "AffilKG enables benchmarking of extraction errors and validates KG methods for social science research."}}
{"id": "2505.10689", "pdf": "https://arxiv.org/pdf/2505.10689", "abs": "https://arxiv.org/abs/2505.10689", "authors": ["Gabriele Santini", "Francesco Paissan", "Elisabetta Farella"], "title": "A probabilistic framework for dynamic quantization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We propose a probabilistic framework for dynamic quantization of neural\nnetworks that allows for a computationally efficient input-adaptive rescaling\nof the quantization parameters. Our framework applies a probabilistic model to\nthe network's pre-activations through a lightweight surrogate, enabling the\nadaptive adjustment of the quantization parameters on a per-input basis without\nsignificant memory overhead. We validate our approach on a set of popular\ncomputer vision tasks and models, observing only a negligible loss in\nperformance. Our method strikes the best performance and computational overhead\ntradeoff compared to standard quantization strategies.", "AI": {"tldr": "A probabilistic framework for dynamic quantization of neural networks, enabling input-adaptive rescaling of quantization parameters with minimal performance loss.", "motivation": "To improve computational efficiency in neural networks by dynamically adjusting quantization parameters per input, reducing memory overhead.", "method": "Uses a probabilistic model on pre-activations via a lightweight surrogate for adaptive quantization.", "result": "Validated on computer vision tasks with negligible performance loss, outperforming standard quantization in tradeoff.", "conclusion": "The framework offers an efficient, adaptive quantization solution with balanced performance and overhead."}}
{"id": "2505.11394", "pdf": "https://arxiv.org/pdf/2505.11394", "abs": "https://arxiv.org/abs/2505.11394", "authors": ["Alexander Oberstrass", "Esteban Vaca", "Eric Upschulte", "Meiqi Niu", "Nicola Palomero-Gallagher", "David Graessel", "Christian Schiffer", "Markus Axer", "Katrin Amunts", "Timo Dickscheid"], "title": "From Fibers to Cells: Fourier-Based Registration Enables Virtual Cresyl Violet Staining From 3D Polarized Light Imaging", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Comprehensive assessment of the various aspects of the brain's microstructure\nrequires the use of complementary imaging techniques. This includes measuring\nthe spatial distribution of cell bodies (cytoarchitecture) and nerve fibers\n(myeloarchitecture). The gold standard for cytoarchitectonic analysis is light\nmicroscopic imaging of cell-body stained tissue sections. To reveal the 3D\norientations of nerve fibers, 3D Polarized Light Imaging (3D-PLI) has been\nintroduced as a reliable technique providing a resolution in the micrometer\nrange while allowing processing of series of complete brain sections. 3D-PLI\nacquisition is label-free and allows subsequent staining of sections after\nmeasurement. By post-staining for cell bodies, a direct link between fiber- and\ncytoarchitecture can potentially be established within the same section.\nHowever, inevitable distortions introduced during the staining process make a\nnonlinear and cross-modal registration necessary in order to study the detailed\nrelationships between cells and fibers in the images. In addition, the\ncomplexity of processing histological sections for post-staining only allows\nfor a limited number of samples. In this work, we take advantage of deep\nlearning methods for image-to-image translation to generate a virtual staining\nof 3D-PLI that is spatially aligned at the cellular level. In a supervised\nsetting, we build on a unique dataset of brain sections, to which Cresyl violet\nstaining has been applied after 3D-PLI measurement. To ensure high\ncorrespondence between both modalities, we address the misalignment of training\ndata using Fourier-based registration methods. In this way, registration can be\nefficiently calculated during training for local image patches of target and\npredicted staining. We demonstrate that the proposed method enables prediction\nof a Cresyl violet staining from 3D-PLI, matching individual cell instances.", "AI": {"tldr": "The paper proposes a deep learning method to virtually stain 3D-PLI images for cytoarchitecture analysis, aligning them with post-stained sections for detailed microstructure study.", "motivation": "To overcome distortions and limited samples in post-staining, enabling detailed study of brain microstructure by linking fiber- and cytoarchitecture.", "method": "Uses deep learning for image-to-image translation, supervised by a dataset of 3D-PLI and Cresyl violet-stained sections, with Fourier-based registration for alignment.", "result": "The method successfully predicts Cresyl violet staining from 3D-PLI, matching individual cell instances.", "conclusion": "Virtual staining via deep learning offers a viable solution for spatially aligned cyto- and myeloarchitecture analysis."}}
{"id": "2505.10649", "pdf": "https://arxiv.org/pdf/2505.10649", "abs": "https://arxiv.org/abs/2505.10649", "authors": ["Xianrui Li", "Yufei Cui", "Jun Li", "Antoni B. Chan"], "title": "Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Advances in medical imaging and deep learning have propelled progress in\nwhole slide image (WSI) analysis, with multiple instance learning (MIL) showing\npromise for efficient and accurate diagnostics. However, conventional MIL\nmodels often lack adaptability to evolving datasets, as they rely on static\ntraining that cannot incorporate new information without extensive retraining.\nApplying continual learning (CL) to MIL models is a possible solution, but\noften sees limited improvements. In this paper, we analyze CL in the context of\nattention MIL models and find that the model forgetting is mainly concentrated\nin the attention layers of the MIL model. Using the results of this analysis we\npropose two components for improving CL on MIL: Attention Knowledge\nDistillation (AKD) and the Pseudo-Bag Memory Pool (PMP). AKD mitigates\ncatastrophic forgetting by focusing on retaining attention layer knowledge\nbetween learning sessions, while PMP reduces the memory footprint by\nselectively storing only the most informative patches, or ``pseudo-bags'' from\nWSIs. Experimental evaluations demonstrate that our method significantly\nimproves both accuracy and memory efficiency on diverse WSI datasets,\noutperforming current state-of-the-art CL methods. This work provides a\nfoundation for CL in large-scale, weakly annotated clinical datasets, paving\nthe way for more adaptable and resilient diagnostic models.", "AI": {"tldr": "The paper proposes Attention Knowledge Distillation (AKD) and Pseudo-Bag Memory Pool (PMP) to improve continual learning in attention-based MIL models for WSI analysis, addressing forgetting and memory issues.", "motivation": "Conventional MIL models lack adaptability to evolving datasets, and continual learning (CL) often underperforms due to forgetting in attention layers.", "method": "Analyzed CL in attention MIL models, identified forgetting in attention layers, and introduced AKD (to retain attention knowledge) and PMP (to reduce memory usage by storing informative patches).", "result": "The method outperforms state-of-the-art CL methods, improving accuracy and memory efficiency on diverse WSI datasets.", "conclusion": "This work enhances CL for large-scale clinical datasets, enabling more adaptable and resilient diagnostic models."}}
{"id": "2505.10859", "pdf": "https://arxiv.org/pdf/2505.10859", "abs": "https://arxiv.org/abs/2505.10859", "authors": ["Yingdan Shi", "Ren Wang"], "title": "MCU: Improving Machine Unlearning through Mode Connectivity", "categories": ["cs.AI"], "comment": null, "summary": "Machine Unlearning (MU) aims to remove the information of specific training\ndata from a trained model, ensuring compliance with privacy regulations and\nuser requests. While one line of existing MU methods relies on linear parameter\nupdates via task arithmetic, they suffer from weight entanglement. In this\nwork, we propose a novel MU framework called Mode Connectivity Unlearning (MCU)\nthat leverages mode connectivity to find an unlearning pathway in a nonlinear\nmanner. To further enhance performance and efficiency, we introduce a parameter\nmask strategy that not only improves unlearning effectiveness but also reduces\ncomputational overhead. Moreover, we propose an adaptive adjustment strategy\nfor our unlearning penalty coefficient to adaptively balance forgetting quality\nand predictive performance during training, eliminating the need for empirical\nhyperparameter tuning. Unlike traditional MU methods that identify only a\nsingle unlearning model, MCU uncovers a spectrum of unlearning models along the\npathway. Overall, MCU serves as a plug-and-play framework that seamlessly\nintegrates with any existing MU methods, consistently improving unlearning\nefficacy. Extensive experiments on the image classification task demonstrate\nthat MCU achieves superior performance.", "AI": {"tldr": "MCU is a novel Machine Unlearning framework using mode connectivity for nonlinear unlearning, improving efficacy and efficiency with parameter masks and adaptive penalty coefficients.", "motivation": "To address weight entanglement in linear MU methods and enhance unlearning performance and compliance with privacy regulations.", "method": "Leverages mode connectivity for nonlinear unlearning, introduces parameter masks, and adaptive penalty coefficients for balanced performance.", "result": "MCU outperforms existing MU methods, providing a spectrum of unlearning models and seamless integration.", "conclusion": "MCU is an effective, plug-and-play framework for machine unlearning, demonstrated by superior performance in image classification tasks."}}
{"id": "2505.10829", "pdf": "https://arxiv.org/pdf/2505.10829", "abs": "https://arxiv.org/abs/2505.10829", "authors": ["Chen-Chi Chang", "Chong-Fu Li", "Chu-Hsuan Lee", "Hung-Shin Lee"], "title": "Enhancing Low-Resource Minority Language Translation with LLMs and Retrieval-Augmented Generation for Cultural Nuances", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to IntelliSys 2025", "summary": "This study investigates the challenges of translating low-resource languages\nby integrating Large Language Models (LLMs) with Retrieval-Augmented Generation\n(RAG). Various model configurations were tested on Hakka translations, with\nBLEU scores ranging from 12% (dictionary-only) to 31% (RAG with Gemini 2.0).\nThe best-performing model (Model 4) combined retrieval and advanced language\nmodeling, improving lexical coverage, particularly for specialized or\nculturally nuanced terms, and enhancing grammatical coherence. A two-stage\nmethod (Model 3) using dictionary outputs refined by Gemini 2.0 achieved a BLEU\nscore of 26%, highlighting iterative correction's value and the challenges of\ndomain-specific expressions. Static dictionary-based approaches struggled with\ncontext-sensitive content, demonstrating the limitations of relying solely on\npredefined resources. These results emphasize the need for curated resources,\ndomain knowledge, and ethical collaboration with local communities, offering a\nframework that improves translation accuracy and fluency while supporting\ncultural preservation.", "AI": {"tldr": "Integration of LLMs with RAG improves Hakka translation, achieving BLEU scores up to 31%, with iterative methods and domain knowledge enhancing accuracy and cultural nuance.", "motivation": "To address challenges in translating low-resource languages like Hakka by leveraging advanced language models and retrieval methods.", "method": "Tested various configurations, including dictionary-only, RAG with Gemini 2.0, and a two-stage method combining dictionary outputs with Gemini 2.0 refinement.", "result": "Best model (Model 4) achieved 31% BLEU, improving lexical coverage and coherence. Iterative methods (Model 3) scored 26%, highlighting domain-specific challenges.", "conclusion": "Curated resources, domain knowledge, and ethical collaboration are crucial for accurate, fluent translations and cultural preservation."}}
{"id": "2505.10698", "pdf": "https://arxiv.org/pdf/2505.10698", "abs": "https://arxiv.org/abs/2505.10698", "authors": ["Alexia Atsidakou", "Orestis Papadigenopoulos", "Constantine Caramanis", "Sujay Sanghavi", "Sanjay Shakkottai"], "title": "Asymptotically-Optimal Gaussian Bandits with Side Observations", "categories": ["cs.LG", "stat.ML"], "comment": "International Conference on Machine Learning, ICML '22", "summary": "We study the problem of Gaussian bandits with general side information, as\nfirst introduced by Wu, Szepesvari, and Gyorgy. In this setting, the play of an\narm reveals information about other arms, according to an arbitrary a priori\nknown side information matrix: each element of this matrix encodes the fidelity\nof the information that the ``row'' arm reveals about the ``column'' arm. In\nthe case of Gaussian noise, this model subsumes standard bandits,\nfull-feedback, and graph-structured feedback as special cases. In this work, we\nfirst construct an LP-based asymptotic instance-dependent lower bound on the\nregret. The LP optimizes the cost (regret) required to reliably estimate the\nsuboptimality gap of each arm. This LP lower bound motivates our main\ncontribution: the first known asymptotically optimal algorithm for this general\nsetting.", "AI": {"tldr": "The paper studies Gaussian bandits with general side information, introducing an LP-based lower bound and an asymptotically optimal algorithm.", "motivation": "To address the problem of Gaussian bandits with arbitrary side information, generalizing standard bandits, full-feedback, and graph-structured feedback.", "method": "Constructs an LP-based asymptotic instance-dependent lower bound on regret and proposes an asymptotically optimal algorithm.", "result": "The LP lower bound is derived, and an optimal algorithm for the general setting is presented.", "conclusion": "The work provides a theoretical foundation and practical solution for Gaussian bandits with side information."}}
{"id": "2505.11445", "pdf": "https://arxiv.org/pdf/2505.11445", "abs": "https://arxiv.org/abs/2505.11445", "authors": ["Marc-Antoine Fortin", "Anne Louise Kristoffersen", "Michael Staff Larsen", "Laurent Lamalle", "Ruediger Stirnberg", "Paal Erik Goa"], "title": "GOUHFI: a novel contrast- and resolution-agnostic segmentation tool for Ultra-High Field MRI", "categories": ["eess.IV"], "comment": "45 pages, 9 Figures, 6 Tables, Submitted to Imaging Neuroscience on\n  16-05-25", "summary": "Recently, Ultra-High Field MRI (UHF-MRI) has become more available and one of\nthe best tools to study the brain. One common step in quantitative neuroimaging\nis the brain segmentation. However, the differences between UHF-MRI and 1.5-3T\nimages are such that the automatic segmentation techniques optimized at these\nfield strengths usually produce unsatisfactory segmentation results for UHF\nimages. It has been particularly challenging to perform quantitative analyses\nas typically done with 1.5-3T data, considerably limiting the potential of\nUHF-MRI. Hence, we propose a novel Deep Learning (DL)-based segmentation\ntechnique called GOUHFI: Generalized and Optimized segmentation tool for\nUltra-High Field Images, designed to segment UHF images of various contrasts\nand resolutions. For training, we used a total of 206 label maps from four\ndatasets acquired at 3T, 7T and 9.4T. In contrast to most DL strategies, we\nused a previously proposed domain randomization approach, where synthetic\nimages generated from the label maps were used for training a 3D U-Net. GOUHFI\nwas tested on seven different datasets and compared to techniques like\nFastSurferVINN and CEREBRUM-7T. GOUHFI was able to the segment six contrasts\nand seven resolutions tested at 3T, 7T and 9.4T. Average Dice-Sorensen\nSimilarity Coefficient (DSC) scores of 0.87, 0.84, 0.91 were computed against\nthe ground truth segmentations at 3T, 7T and 9.4T. Moreover, GOUHFI\ndemonstrated impressive resistance to the typical inhomogeneities observed at\nUHF-MRI, making it a new powerful segmentation tool that allows to apply the\nusual quantitative analysis pipelines also at UHF. Ultimately, GOUHFI is a\npromising new segmentation tool, being the first of its kind proposing a\ncontrast- and resolution-agnostic alternative for UHF-MRI, making it the\nforthcoming alternative for neuroscientists working with UHF-MRI or even lower\nfield strengths.", "AI": {"tldr": "GOUHFI is a novel DL-based segmentation tool for UHF-MRI, overcoming limitations of traditional methods by handling various contrasts and resolutions with high accuracy.", "motivation": "Current segmentation techniques for 1.5-3T MRI perform poorly on UHF-MRI, limiting its potential for quantitative analysis.", "method": "GOUHFI uses a domain randomization approach with synthetic images to train a 3D U-Net, tested on multiple datasets.", "result": "Achieved high DSC scores (0.87, 0.84, 0.91 at 3T, 7T, 9.4T) and resistance to UHF inhomogeneities.", "conclusion": "GOUHFI is a versatile, powerful tool for UHF-MRI segmentation, enabling quantitative analysis pipelines at ultra-high fields."}}
{"id": "2505.10664", "pdf": "https://arxiv.org/pdf/2505.10664", "abs": "https://arxiv.org/abs/2505.10664", "authors": ["Ziyang Ou"], "title": "CLIP Embeddings for AI-Generated Image Detection: A Few-Shot Study with Lightweight Classifier", "categories": ["cs.CV", "cs.AI", "I.2.10"], "comment": "8 pages, 5 figures, not submitted to any conference", "summary": "Verifying the authenticity of AI-generated images presents a growing\nchallenge on social media platforms these days. While vision-language models\n(VLMs) like CLIP outdo in multimodal representation, their capacity for\nAI-generated image classification is underexplored due to the absence of such\nlabels during the pre-training process. This work investigates whether CLIP\nembeddings inherently contain information indicative of AI generation. A\nproposed pipeline extracts visual embeddings using a frozen CLIP model, feeds\nits embeddings to lightweight networks, and fine-tunes only the final\nclassifier. Experiments on the public CIFAKE benchmark show the performance\nreaches 95% accuracy without language reasoning. Few-shot adaptation to curated\ncustom with 20% of the data results in performance to 85%. A closed-source\nbaseline (Gemini-2.0) has the best zero-shot accuracy yet fails on specific\nstyles. Notably, some specific image types, such as wide-angle photographs and\noil paintings, pose significant challenges to classification. These results\nindicate previously unexplored difficulties in classifying certain types of\nAI-generated images, revealing new and more specific questions in this domain\nthat are worth further investigation.", "AI": {"tldr": "The paper explores using CLIP embeddings to classify AI-generated images, achieving high accuracy but revealing challenges with specific image types.", "motivation": "The authenticity of AI-generated images on social media is a growing concern, and the potential of CLIP embeddings for classification is underexplored.", "method": "A pipeline extracts CLIP visual embeddings, feeds them to lightweight networks, and fine-tunes the classifier, tested on the CIFAKE benchmark.", "result": "Achieves 95% accuracy on CIFAKE and 85% with few-shot adaptation, but struggles with specific styles like wide-angle photos and oil paintings.", "conclusion": "The study highlights unexplored challenges in classifying certain AI-generated images, suggesting further research is needed."}}
{"id": "2505.10887", "pdf": "https://arxiv.org/pdf/2505.10887", "abs": "https://arxiv.org/abs/2505.10887", "authors": ["Bin Lei", "Weitai Kang", "Zijian Zhang", "Winson Chen", "Xi Xie", "Shan Zuo", "Mimi Xie", "Ali Payani", "Mingyi Hong", "Yan Yan", "Caiwen Ding"], "title": "InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer Interaction", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces \\textsc{InfantAgent-Next}, a generalist agent capable\nof interacting with computers in a multimodal manner, encompassing text,\nimages, audio, and video. Unlike existing approaches that either build\nintricate workflows around a single large model or only provide workflow\nmodularity, our agent integrates tool-based and pure vision agents within a\nhighly modular architecture, enabling different models to collaboratively solve\ndecoupled tasks in a step-by-step manner. Our generality is demonstrated by our\nability to evaluate not only pure vision-based real-world benchmarks (i.e.,\nOSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and\nSWE-Bench). Specifically, we achieve $\\mathbf{7.27\\%}$ accuracy on OSWorld,\nhigher than Claude-Computer-Use. Codes and evaluation scripts are open-sourced\nat https://github.com/bin123apple/InfantAgent.", "AI": {"tldr": "InfantAgent-Next is a multimodal generalist agent for computer interaction, outperforming existing methods in benchmarks like OSWorld, GAIA, and SWE-Bench.", "motivation": "To create a versatile agent that integrates tool-based and vision agents modularly for collaborative task-solving, addressing limitations of single-model workflows.", "method": "Combines tool-based and pure vision agents in a modular architecture, enabling step-by-step task-solving with diverse models.", "result": "Achieves 7.27% accuracy on OSWorld, surpassing Claude-Computer-Use, and performs well on GAIA and SWE-Bench.", "conclusion": "InfantAgent-Next demonstrates superior generality and performance, with open-sourced code for reproducibility."}}
{"id": "2505.10832", "pdf": "https://arxiv.org/pdf/2505.10832", "abs": "https://arxiv.org/abs/2505.10832", "authors": ["Songjun Tu", "Jiahao Lin", "Qichao Zhang", "Xiangyu Tian", "Linjing Li", "Xiangyuan Lan", "Dongbin Zhao"], "title": "Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "comment": "Project Page: https://github.com/TU2021/AutoThink", "summary": "Large reasoning models (LRMs) are proficient at generating explicit,\nstep-by-step reasoning sequences before producing final answers. However, such\ndetailed reasoning can introduce substantial computational overhead and\nlatency, particularly for simple problems. To address this over-thinking\nproblem, we explore how to equip LRMs with adaptive thinking capabilities:\nenabling them to dynamically decide whether or not to engage in explicit\nreasoning based on problem complexity. Building on R1-style distilled models,\nwe observe that inserting a simple ellipsis (\"...\") into the prompt can\nstochastically trigger either a thinking or no-thinking mode, revealing a\nlatent controllability in the reasoning behavior. Leveraging this property, we\npropose AutoThink, a multi-stage reinforcement learning (RL) framework that\nprogressively optimizes reasoning policies via stage-wise reward shaping.\nAutoThink learns to invoke explicit reasoning only when necessary, while\ndefaulting to succinct responses for simpler tasks. Experiments on five\nmainstream mathematical benchmarks demonstrate that AutoThink achieves\nfavorable accuracy-efficiency trade-offs compared to recent prompting and\nRL-based pruning methods. It can be seamlessly integrated into any R1-style\nmodel, including both distilled and further fine-tuned variants. Notably,\nAutoThink improves relative accuracy by 6.4 percent while reducing token usage\nby 52 percent on DeepSeek-R1-Distill-Qwen-1.5B, establishing a scalable and\nadaptive reasoning paradigm for LRMs.", "AI": {"tldr": "AutoThink enables large reasoning models to dynamically decide when to use explicit reasoning, improving efficiency and accuracy.", "motivation": "To reduce computational overhead and latency in large reasoning models by avoiding unnecessary detailed reasoning for simple problems.", "method": "Uses a multi-stage reinforcement learning framework (AutoThink) to optimize reasoning policies, triggered by inserting an ellipsis in prompts.", "result": "Achieves better accuracy-efficiency trade-offs, improving accuracy by 6.4% and reducing token usage by 52%.", "conclusion": "AutoThink provides a scalable and adaptive reasoning paradigm for large reasoning models."}}
{"id": "2505.10699", "pdf": "https://arxiv.org/pdf/2505.10699", "abs": "https://arxiv.org/abs/2505.10699", "authors": ["Kutay B\u00f6lat", "Tarek Alskaif", "Peter Palensky", "Simon Tindemans"], "title": "Clustering Rooftop PV Systems via Probabilistic Embeddings", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "As the number of rooftop photovoltaic (PV) installations increases,\naggregators and system operators are required to monitor and analyze these\nsystems, raising the challenge of integration and management of large,\nspatially distributed time-series data that are both high-dimensional and\naffected by missing values. In this work, a probabilistic entity\nembedding-based clustering framework is proposed to address these problems.\nThis method encodes each PV system's characteristic power generation patterns\nand uncertainty as a probability distribution, then groups systems by their\nstatistical distances and agglomerative clustering. Applied to a multi-year\nresidential PV dataset, it produces concise, uncertainty-aware cluster profiles\nthat outperform a physics-based baseline in representativeness and robustness,\nand support reliable missing-value imputation. A systematic hyperparameter\nstudy further offers practical guidance for balancing model performance and\nrobustness.", "AI": {"tldr": "A probabilistic embedding-based clustering framework is proposed to manage high-dimensional, missing-value-affected PV system data, outperforming physics-based methods.", "motivation": "The rise in rooftop PV installations necessitates efficient monitoring and analysis of large, distributed time-series data with missing values.", "method": "The framework encodes PV system power generation patterns as probability distributions, then clusters systems using statistical distances and agglomerative clustering.", "result": "The method produces robust, uncertainty-aware cluster profiles and reliable missing-value imputation, outperforming physics-based baselines.", "conclusion": "The framework effectively addresses PV data challenges, offering practical guidance for balancing performance and robustness."}}
{"id": "2505.10823", "pdf": "https://arxiv.org/pdf/2505.10823", "abs": "https://arxiv.org/abs/2505.10823", "authors": ["Xue Li", "Jameson Merkow", "Noel C. F. Codella", "Alberto Santamaria-Pang", "Naiteek Sangani", "Alexander Ersoy", "Christopher Burt", "John W. Garrett", "Richard J. Bruce", "Joshua D. Warner", "Tyler Bradshaw", "Ivan Tarapov", "Matthew P. Lungren", "Alan B. McMillan"], "title": "From Embeddings to Accuracy: Comparing Foundation Models for Radiographic Classification", "categories": ["cs.CV", "eess.IV"], "comment": "11 pages, 5 figures, 4 tables", "summary": "Foundation models, pretrained on extensive datasets, have significantly\nadvanced machine learning by providing robust and transferable embeddings\napplicable to various domains, including medical imaging diagnostics. This\nstudy evaluates the utility of embeddings derived from both general-purpose and\nmedical domain-specific foundation models for training lightweight adapter\nmodels in multi-class radiography classification, focusing specifically on tube\nplacement assessment. A dataset comprising 8842 radiographs classified into\nseven distinct categories was employed to extract embeddings using six\nfoundation models: DenseNet121, BiomedCLIP, Med-Flamingo, MedImageInsight,\nRad-DINO, and CXR-Foundation. Adapter models were subsequently trained using\nclassical machine learning algorithms. Among these combinations,\nMedImageInsight embeddings paired with an support vector machine adapter\nyielded the highest mean area under the curve (mAUC) at 93.8%, followed closely\nby Rad-DINO (91.1%) and CXR-Foundation (89.0%). In comparison, BiomedCLIP and\nDenseNet121 exhibited moderate performance with mAUC scores of 83.0% and 81.8%,\nrespectively, whereas Med-Flamingo delivered the lowest performance at 75.1%.\nNotably, most adapter models demonstrated computational efficiency, achieving\ntraining within one minute and inference within seconds on CPU, underscoring\ntheir practicality for clinical applications. Furthermore, fairness analyses on\nadapters trained on MedImageInsight-derived embeddings indicated minimal\ndisparities, with gender differences in performance within 2% and standard\ndeviations across age groups not exceeding 3%. These findings confirm that\nfoundation model embeddings-especially those from MedImageInsight-facilitate\naccurate, computationally efficient, and equitable diagnostic classification\nusing lightweight adapters for radiographic image analysis.", "AI": {"tldr": "The study evaluates foundation model embeddings for multi-class radiography classification, finding MedImageInsight with an SVM adapter most effective (93.8% mAUC), with efficient and fair performance.", "motivation": "To assess the utility of general-purpose and medical-specific foundation model embeddings for training lightweight adapters in radiography classification, focusing on tube placement.", "method": "Used six foundation models to extract embeddings from 8842 radiographs, trained adapter models with classical ML algorithms, and evaluated performance (mAUC), efficiency, and fairness.", "result": "MedImageInsight embeddings with SVM adapter achieved the highest mAUC (93.8%). Most adapters were computationally efficient (training <1 min, inference in seconds) and fair (minimal disparities).", "conclusion": "Foundation model embeddings, especially MedImageInsight, enable accurate, efficient, and equitable diagnostic classification in radiographic image analysis."}}
{"id": "2505.10671", "pdf": "https://arxiv.org/pdf/2505.10671", "abs": "https://arxiv.org/abs/2505.10671", "authors": ["Yuki Kawana", "Shintaro Shiba", "Quan Kong", "Norimasa Kobori"], "title": "GA3CE: Unconstrained 3D Gaze Estimation with Gaze-Aware 3D Context Encoding", "categories": ["cs.CV"], "comment": "Accepted to CVPR2025. Project page:\n  https://woven-visionai.github.io/ga3ce-project/", "summary": "We propose a novel 3D gaze estimation approach that learns spatial\nrelationships between the subject and objects in the scene, and outputs 3D gaze\ndirection. Our method targets unconstrained settings, including cases where\nclose-up views of the subject's eyes are unavailable, such as when the subject\nis distant or facing away. Previous approaches typically rely on either 2D\nappearance alone or incorporate limited spatial cues using depth maps in the\nnon-learnable post-processing step. Estimating 3D gaze direction from 2D\nobservations in these scenarios is challenging; variations in subject pose,\nscene layout, and gaze direction, combined with differing camera poses, yield\ndiverse 2D appearances and 3D gaze directions even when targeting the same 3D\nscene. To address this issue, we propose GA3CE: Gaze-Aware 3D Context Encoding.\nOur method represents subject and scene using 3D poses and object positions,\ntreating them as 3D context to learn spatial relationships in 3D space.\nInspired by human vision, we align this context in an egocentric space,\nsignificantly reducing spatial complexity. Furthermore, we propose D$^3$\n(direction-distance-decomposed) positional encoding to better capture the\nspatial relationship between 3D context and gaze direction in direction and\ndistance space. Experiments demonstrate substantial improvements, reducing mean\nangle error by 13%-37% compared to leading baselines on benchmark datasets in\nsingle-frame settings.", "AI": {"tldr": "A novel 3D gaze estimation method, GA3CE, learns spatial relationships in 3D space, improving accuracy in unconstrained settings.", "motivation": "Overcoming limitations of 2D appearance-based or depth-map methods in estimating 3D gaze direction, especially in challenging scenarios like distant subjects or varying poses.", "method": "Uses 3D poses and object positions as context, aligns them in egocentric space, and employs D$^3$ positional encoding to capture spatial relationships.", "result": "Reduces mean angle error by 13%-37% compared to baselines in single-frame settings.", "conclusion": "GA3CE effectively addresses 3D gaze estimation challenges by leveraging 3D context and spatial relationships."}}
{"id": "2505.10962", "pdf": "https://arxiv.org/pdf/2505.10962", "abs": "https://arxiv.org/abs/2505.10962", "authors": ["Zhenwen Liang", "Linfeng Song", "Yang Li", "Tao Yang", "Feng Zhang", "Haitao Mi", "Dong Yu"], "title": "MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective Search and Data Curation", "categories": ["cs.AI"], "comment": "Work in Progress", "summary": "Automated Theorem Proving (ATP) in formal languages remains a formidable\nchallenge in AI, demanding rigorous logical deduction and navigating vast\nsearch spaces. While large language models (LLMs) have shown promising\nperformance, existing stepwise provers often suffer from biased search\nguidance, leading to inefficiencies and suboptimal proof strategies. This paper\nintroduces the Multi-Perspective Search Prover (MPS-Prover), a novel stepwise\nATP system designed to overcome these limitations. MPS-Prover incorporates two\nkey innovations: a highly effective post-training data curation strategy that\nprunes approximately 40% of redundant training data without sacrificing\nperformance, and a multi-perspective tree search mechanism. This search\nintegrates a learned critic model with strategically designed heuristic rules\nto diversify tactic selection, prevent getting trapped in unproductive states,\nand enhance search robustness. Extensive evaluations demonstrate that\nMPS-Prover achieves state-of-the-art performance on multiple challenging\nbenchmarks, including miniF2F and ProofNet, outperforming prior 7B parameter\nmodels. Furthermore, our analyses reveal that MPS-Prover generates\nsignificantly shorter and more diverse proofs compared to existing stepwise and\nwhole-proof methods, highlighting its efficiency and efficacy. Our work\nadvances the capabilities of LLM-based formal reasoning and offers a robust\nframework and a comprehensive analysis for developing more powerful theorem\nprovers.", "AI": {"tldr": "MPS-Prover introduces a novel ATP system with data curation and multi-perspective search, outperforming existing models in efficiency and proof diversity.", "motivation": "Addressing inefficiencies and biased search in existing stepwise ATP systems using LLMs.", "method": "Combines post-training data pruning (40% reduction) with a multi-perspective tree search integrating a critic model and heuristic rules.", "result": "Achieves state-of-the-art performance on benchmarks like miniF2F and ProofNet, with shorter, more diverse proofs.", "conclusion": "MPS-Prover advances LLM-based formal reasoning, offering a robust framework for future theorem provers."}}
{"id": "2505.10836", "pdf": "https://arxiv.org/pdf/2505.10836", "abs": "https://arxiv.org/abs/2505.10836", "authors": ["Abhishek Dey", "Aabha Bothera", "Samhita Sarikonda", "Rishav Aryan", "Sanjay Kumar Podishetty", "Akshay Havalgi", "Gaurav Singh", "Saurabh Srivastava"], "title": "Multimodal Event Detection: Current Approaches and Defining the New Playground through LLMs and VLMs", "categories": ["cs.CL", "cs.CV"], "comment": "Accepted at NLDB 2025", "summary": "In this paper, we study the challenges of detecting events on social media,\nwhere traditional unimodal systems struggle due to the rapid and multimodal\nnature of data dissemination. We employ a range of models, including unimodal\nModernBERT and ConvNeXt-V2, multimodal fusion techniques, and advanced\ngenerative models like GPT-4o, and LLaVA. Additionally, we also study the\neffect of providing multimodal generative models (such as GPT-4o) with a single\nmodality to assess their efficacy. Our results indicate that while multimodal\napproaches notably outperform unimodal counterparts, generative approaches\ndespite having a large number of parameters, lag behind supervised methods in\nprecision. Furthermore, we also found that they lag behind instruction-tuned\nmodels because of their inability to generate event classes correctly. During\nour error analysis, we discovered that common social media issues such as leet\nspeak, text elongation, etc. are effectively handled by generative approaches\nbut are hard to tackle using supervised approaches.", "AI": {"tldr": "The paper explores multimodal and generative models for social media event detection, finding multimodal methods superior but generative models lagging in precision despite handling some challenges better.", "motivation": "Traditional unimodal systems struggle with rapid, multimodal social media data, prompting the need for advanced models.", "method": "Employed unimodal (ModernBERT, ConvNeXt-V2), multimodal fusion, and generative models (GPT-4o, LLaVA), testing generative models with single modality.", "result": "Multimodal approaches outperform unimodal ones; generative models lag in precision and event class generation but handle social media issues like leet speak better.", "conclusion": "Multimodal methods are superior for event detection, but generative models need improvement for precision and class accuracy."}}
{"id": "2505.10704", "pdf": "https://arxiv.org/pdf/2505.10704", "abs": "https://arxiv.org/abs/2505.10704", "authors": ["Patryk Marsza\u0142ek", "Tomasz Ku\u015bmierczyk", "Witold Wydma\u0144ski", "Jacek Tabor", "Marek \u015amieja"], "title": "ZEUS: Zero-shot Embeddings for Unsupervised Separation of Tabular Data", "categories": ["cs.LG"], "comment": null, "summary": "Clustering tabular data remains a significant open challenge in data analysis\nand machine learning. Unlike for image data, similarity between tabular records\noften varies across datasets, making the definition of clusters highly\ndataset-dependent. Furthermore, the absence of supervised signals complicates\nhyperparameter tuning in deep learning clustering methods, frequently resulting\nin unstable performance. To address these issues and reduce the need for\nper-dataset tuning, we adopt an emerging approach in deep learning: zero-shot\nlearning. We propose ZEUS, a self-contained model capable of clustering new\ndatasets without any additional training or fine-tuning. It operates by\ndecomposing complex datasets into meaningful components that can then be\nclustered effectively. Thanks to pre-training on synthetic datasets generated\nfrom a latent-variable prior, it generalizes across various datasets without\nrequiring user intervention. To the best of our knowledge, ZEUS is the first\nzero-shot method capable of generating embeddings for tabular data in a fully\nunsupervised manner. Experimental results demonstrate that it performs on par\nwith or better than traditional clustering algorithms and recent deep\nlearning-based methods, while being significantly faster and more\nuser-friendly.", "AI": {"tldr": "ZEUS is a zero-shot deep learning model for clustering tabular data without per-dataset tuning, outperforming traditional and deep learning methods.", "motivation": "Challenges in clustering tabular data include dataset-dependent similarity and unstable performance due to lack of supervised signals.", "method": "ZEUS uses zero-shot learning, decomposing datasets into meaningful components and leveraging pre-training on synthetic data.", "result": "ZEUS matches or outperforms traditional and deep learning methods, offering faster and more user-friendly clustering.", "conclusion": "ZEUS is the first zero-shot method for unsupervised tabular data clustering, demonstrating strong performance and generalization."}}
{"id": "2505.11062", "pdf": "https://arxiv.org/pdf/2505.11062", "abs": "https://arxiv.org/abs/2505.11062", "authors": ["Baisong Li", "Xingwang Wang", "Haixiao Xu"], "title": "HSRMamba: Efficient Wavelet Stripe State Space Model for Hyperspectral Image Super-Resolution", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Single hyperspectral image super-resolution (SHSR) aims to restore\nhigh-resolution images from low-resolution hyperspectral images. Recently, the\nVisual Mamba model has achieved an impressive balance between performance and\ncomputational efficiency. However, due to its 1D scanning paradigm, the model\nmay suffer from potential artifacts during image generation. To address this\nissue, we propose HSRMamba. While maintaining the computational efficiency of\nVisual Mamba, we introduce a strip-based scanning scheme to effectively reduce\nartifacts from global unidirectional scanning. Additionally, HSRMamba uses\nwavelet decomposition to alleviate modal conflicts between high-frequency\nspatial features and low-frequency spectral features, further improving\nsuper-resolution performance. Extensive experiments show that HSRMamba not only\nexcels in reducing computational load and model size but also outperforms\nexisting methods, achieving state-of-the-art results.", "AI": {"tldr": "HSRMamba improves hyperspectral image super-resolution by reducing artifacts and modal conflicts, outperforming existing methods.", "motivation": "Address potential artifacts in Visual Mamba's 1D scanning and modal conflicts in hyperspectral image super-resolution.", "method": "Introduces strip-based scanning and wavelet decomposition to enhance efficiency and performance.", "result": "Achieves state-of-the-art results with reduced computational load and model size.", "conclusion": "HSRMamba effectively balances performance and efficiency, advancing hyperspectral image super-resolution."}}
{"id": "2505.10679", "pdf": "https://arxiv.org/pdf/2505.10679", "abs": "https://arxiv.org/abs/2505.10679", "authors": ["Jianyang Xie", "Yitian Zhao", "Yanda Meng", "He Zhao", "Anh Nguyen", "Yalin Zheng"], "title": "Are Spatial-Temporal Graph Convolution Networks for Human Action Recognition Over-Parameterized?", "categories": ["cs.CV"], "comment": null, "summary": "Spatial-temporal graph convolutional networks (ST-GCNs) showcase impressive\nperformance in skeleton-based human action recognition (HAR). However, despite\nthe development of numerous models, their recognition performance does not\ndiffer significantly after aligning the input settings. With this observation,\nwe hypothesize that ST-GCNs are over-parameterized for HAR, a conjecture\nsubsequently confirmed through experiments employing the lottery ticket\nhypothesis. Additionally, a novel sparse ST-GCNs generator is proposed, which\ntrains a sparse architecture from a randomly initialized dense network while\nmaintaining comparable performance levels to the dense components. Moreover, we\ngenerate multi-level sparsity ST-GCNs by integrating sparse structures at\nvarious sparsity levels and demonstrate that the assembled model yields a\nsignificant enhancement in HAR performance. Thorough experiments on four\ndatasets, including NTU-RGB+D 60(120), Kinetics-400, and FineGYM, demonstrate\nthat the proposed sparse ST-GCNs can achieve comparable performance to their\ndense components. Even with 95% fewer parameters, the sparse ST-GCNs exhibit a\ndegradation of <1% in top-1 accuracy. Meanwhile, the multi-level sparsity\nST-GCNs, which require only 66% of the parameters of the dense ST-GCNs,\ndemonstrate an improvement of >1% in top-1 accuracy. The code is available at\nhttps://github.com/davelailai/Sparse-ST-GCN.", "AI": {"tldr": "Sparse ST-GCNs achieve comparable performance to dense models with significantly fewer parameters, and multi-level sparsity further improves accuracy.", "motivation": "ST-GCNs are over-parameterized for HAR, and sparse architectures can maintain performance while reducing complexity.", "method": "Proposed a sparse ST-GCN generator and multi-level sparsity integration, validated on four datasets.", "result": "Sparse models with 95% fewer parameters show <1% accuracy drop; multi-level sparsity improves accuracy by >1%.", "conclusion": "Sparse ST-GCNs are efficient and effective for HAR, offering a balance between performance and parameter reduction."}}
{"id": "2505.10981", "pdf": "https://arxiv.org/pdf/2505.10981", "abs": "https://arxiv.org/abs/2505.10981", "authors": ["Yexiang Liu", "Zekun Li", "Zhi Fang", "Nan Xu", "Ran He", "Tieniu Tan"], "title": "Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "ACL 2025 Main", "summary": "Recently, scaling test-time compute on Large Language Models (LLM) has\ngarnered wide attention. However, there has been limited investigation of how\nvarious reasoning prompting strategies perform as scaling. In this paper, we\nfocus on a standard and realistic scaling setting: majority voting. We\nsystematically conduct experiments on 6 LLMs $\\times$ 8 prompting strategies\n$\\times$ 6 benchmarks. Experiment results consistently show that as the\nsampling time and computational overhead increase, complicated prompting\nstrategies with superior initial performance gradually fall behind simple\nChain-of-Thought. We analyze this phenomenon and provide theoretical proofs.\nAdditionally, we propose a method according to probability theory to quickly\nand accurately predict the scaling performance and select the best strategy\nunder large sampling times without extra resource-intensive inference in\npractice. It can serve as the test-time scaling law for majority voting.\nFurthermore, we introduce two ways derived from our theoretical analysis to\nsignificantly improve the scaling performance. We hope that our research can\npromote to re-examine the role of complicated prompting, unleash the potential\nof simple prompting strategies, and provide new insights for enhancing\ntest-time scaling performance.", "AI": {"tldr": "The paper investigates how different reasoning prompting strategies scale with test-time compute in LLMs, finding that simple Chain-of-Thought outperforms complex strategies as compute increases. It also proposes a method to predict scaling performance and suggests improvements.", "motivation": "To understand how prompting strategies perform under scaling (majority voting) and identify efficient methods to predict and enhance performance.", "method": "Systematic experiments on 6 LLMs, 8 prompting strategies, and 6 benchmarks, along with theoretical analysis and a proposed prediction method based on probability theory.", "result": "Complex prompting strategies initially perform better but are outperformed by Chain-of-Thought as compute scales. The proposed method accurately predicts scaling performance.", "conclusion": "Simple prompting strategies like Chain-of-Thought are more scalable, and the study provides insights and methods to improve test-time scaling performance."}}
{"id": "2505.10862", "pdf": "https://arxiv.org/pdf/2505.10862", "abs": "https://arxiv.org/abs/2505.10862", "authors": ["Tairan Fu", "Miguel Gonz\u00e1lez", "Javier Conde", "Elena Merino-G\u00f3mez", "Pedro Reviriego"], "title": "Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?", "categories": ["cs.CL", "I.2.7"], "comment": "6 pages, 5 figures, 2 tables", "summary": "Multimodal Large Language Models which can answer complex questions on an\nimage struggle to tell the time on analog clocks. This is probably due to the\nlack of images with clocks at different times in their training set. In this\nwork we explore this issue with one of the latest MLLMs: GPT-4.1 to understand\nwhy MLLMs fail to tell the time and whether fine-tuning can solve the problem.\nThe results show how models are making progress in reading the time on analog\nclocks. But have they really learned to do it, or have they only learned\npatterns in their training datasets? In this work we put the models to the test\nwith different clocks to illustrate the limitations of MLLMs to abstract and\ngeneralize.", "AI": {"tldr": "MLLMs struggle with telling time on analog clocks due to limited training data. This study tests GPT-4.1 to understand the issue and evaluate fine-tuning's effectiveness.", "motivation": "To investigate why MLLMs fail at telling time on analog clocks and assess if fine-tuning can improve performance.", "method": "Testing GPT-4.1 with various analog clocks to analyze its ability to generalize and abstract time-telling.", "result": "Models show progress but may rely on training data patterns rather than true understanding.", "conclusion": "MLLMs still struggle with abstracting and generalizing time-telling, highlighting limitations in their training."}}
{"id": "2505.10711", "pdf": "https://arxiv.org/pdf/2505.10711", "abs": "https://arxiv.org/abs/2505.10711", "authors": ["Sebesty\u00e9n Kamp", "Giovanni Stracquadanio", "T. Ian Simpson"], "title": "GNN-Suite: a Graph Neural Network Benchmarking Framework for Biomedical Informatics", "categories": ["cs.LG", "cs.AI", "J.3; I.2.1"], "comment": "Main article 8 pages (20 in total with supplementary information\n  included), 3 main article figures and 3 supplemental figures", "summary": "We present GNN-Suite, a robust modular framework for constructing and\nbenchmarking Graph Neural Network (GNN) architectures in computational biology.\nGNN-Suite standardises experimentation and reproducibility using the Nextflow\nworkflow to evaluate GNN performance. We demonstrate its utility in identifying\ncancer-driver genes by constructing molecular networks from protein-protein\ninteraction (PPI) data from STRING and BioGRID and annotating nodes with\nfeatures from the PCAWG, PID, and COSMIC-CGC repositories.\n  Our design enables fair comparisons among diverse GNN architectures including\nGAT, GAT3H, GCN, GCN2, GIN, GTN, HGCN, PHGCN, and GraphSAGE and a baseline\nLogistic Regression (LR) model. All GNNs were configured as standardised\ntwo-layer models and trained with uniform hyperparameters (dropout = 0.2; Adam\noptimiser with learning rate = 0.01; and an adjusted binary cross-entropy loss\nto address class imbalance) over an 80/20 train-test split for 300 epochs. Each\nmodel was evaluated over 10 independent runs with different random seeds to\nyield statistically robust performance metrics, with balanced accuracy (BACC)\nas the primary measure. Notably, GCN2 achieved the highest BACC (0.807 +/-\n0.035) on a STRING-based network, although all GNN types outperformed the LR\nbaseline, highlighting the advantage of network-based learning over\nfeature-only approaches.\n  Our results show that a common framework for implementing and evaluating GNN\narchitectures aids in identifying not only the best model but also the most\neffective means of incorporating complementary data. By making GNN-Suite\npublicly available, we aim to foster reproducible research and promote improved\nbenchmarking standards in computational biology. Future work will explore\nadditional omics datasets and further refine network architectures to enhance\npredictive accuracy and interpretability in biomedical applications.", "AI": {"tldr": "GNN-Suite is a modular framework for benchmarking GNNs in computational biology, demonstrating its utility in cancer-driver gene identification. GCN2 performed best, outperforming baseline models.", "motivation": "To standardize GNN experimentation and reproducibility in computational biology, particularly for cancer-driver gene identification.", "method": "GNN-Suite uses Nextflow for workflow standardization, evaluates diverse GNN architectures (e.g., GAT, GCN2) on PPI data from STRING/BioGRID, with uniform hyperparameters and 10 independent runs for robust metrics.", "result": "GCN2 achieved the highest balanced accuracy (0.807) on STRING-based networks, with all GNNs outperforming the Logistic Regression baseline.", "conclusion": "GNN-Suite aids in identifying optimal models and data integration methods, promoting reproducibility and benchmarking standards. Future work includes exploring more datasets and refining architectures."}}
{"id": "2505.11433", "pdf": "https://arxiv.org/pdf/2505.11433", "abs": "https://arxiv.org/abs/2505.11433", "authors": ["Georgios Moustakas", "Ioannis Tsilikas", "Adonis Bogris", "Charis Mesaritakis"], "title": "Neuromorphic Imaging Flow Cytometry combined with Adaptive Recurrent Spiking Neural Networks", "categories": ["physics.optics", "eess.IV"], "comment": "13 pages, 6 figures, journal submission", "summary": "We present an experimental imaging flow cytometer using a 1 {\\mu}s temporal\nresolution event-based CMOS camera, with data processed by adaptive feedforward\nand recurrent spiking neural networks. Our study classifies PMMA particles (12,\n16, 20 {\\mu}m) flowing at 0.7 m/s in a microfluidic channel. Processing of\nexperimental data highlighted that spiking recurrent networks, including LSTM\nand GRU models, achieved 98.4% accuracy by leveraging temporal dependencies.\nAdditionally, adaptation mechanisms in lightweight feedforward spiking networks\nimproved accuracy by 4.3%. This work outlines a technological roadmap for\nneuromorphic-assisted biomedical applications, enhancing classification\nperformance while maintaining low latency and sparsity.", "AI": {"tldr": "An imaging flow cytometer using event-based CMOS cameras and spiking neural networks achieves high accuracy in classifying PMMA particles, with recurrent networks (LSTM/GRU) reaching 98.4% accuracy and lightweight feedforward networks improving by 4.3%.", "motivation": "To enhance classification performance in biomedical applications by leveraging neuromorphic technology for low latency and sparsity.", "method": "Uses a 1 \u00b5s temporal resolution event-based CMOS camera and processes data with adaptive feedforward and recurrent spiking neural networks (LSTM, GRU).", "result": "Recurrent networks achieved 98.4% accuracy; lightweight feedforward networks improved accuracy by 4.3%.", "conclusion": "The work provides a roadmap for neuromorphic-assisted biomedical applications, balancing high accuracy with low latency and sparsity."}}
{"id": "2505.10685", "pdf": "https://arxiv.org/pdf/2505.10685", "abs": "https://arxiv.org/abs/2505.10685", "authors": ["Lingjun Zhao", "Sizhe Wei", "James Hays", "Lu Gan"], "title": "GaussianFormer3D: Multi-Modal Gaussian-based Semantic Occupancy Prediction with 3D Deformable Attention", "categories": ["cs.CV"], "comment": null, "summary": "3D semantic occupancy prediction is critical for achieving safe and reliable\nautonomous driving. Compared to camera-only perception systems, multi-modal\npipelines, especially LiDAR-camera fusion methods, can produce more accurate\nand detailed predictions. Although most existing works utilize a dense\ngrid-based representation, in which the entire 3D space is uniformly divided\ninto discrete voxels, the emergence of 3D Gaussians provides a compact and\ncontinuous object-centric representation. In this work, we propose a\nmulti-modal Gaussian-based semantic occupancy prediction framework utilizing 3D\ndeformable attention, named as GaussianFormer3D. We introduce a\nvoxel-to-Gaussian initialization strategy to provide 3D Gaussians with geometry\npriors from LiDAR data, and design a LiDAR-guided 3D deformable attention\nmechanism for refining 3D Gaussians with LiDAR-camera fusion features in a\nlifted 3D space. We conducted extensive experiments on both on-road and\noff-road datasets, demonstrating that our GaussianFormer3D achieves high\nprediction accuracy that is comparable to state-of-the-art multi-modal\nfusion-based methods with reduced memory consumption and improved efficiency.", "AI": {"tldr": "Proposes GaussianFormer3D, a multi-modal Gaussian-based semantic occupancy prediction framework using 3D deformable attention for autonomous driving, achieving high accuracy with reduced memory usage.", "motivation": "3D semantic occupancy prediction is crucial for autonomous driving. Multi-modal fusion (LiDAR-camera) improves accuracy, and 3D Gaussians offer a compact, continuous representation compared to dense grids.", "method": "Introduces voxel-to-Gaussian initialization for geometry priors and LiDAR-guided 3D deformable attention for refining Gaussians with fusion features in a lifted 3D space.", "result": "Achieves high prediction accuracy comparable to state-of-the-art multi-modal methods, with reduced memory consumption and improved efficiency.", "conclusion": "GaussianFormer3D is an effective framework for semantic occupancy prediction, balancing accuracy and efficiency in autonomous driving."}}
{"id": "2505.10982", "pdf": "https://arxiv.org/pdf/2505.10982", "abs": "https://arxiv.org/abs/2505.10982", "authors": ["Johannes Fichte", "Nicolas Fr\u00f6hlich", "Markus Hecher", "Victor Lagerkvist", "Yasir Mahmood", "Arne Meier", "Jonathan Persson"], "title": "Facets in Argumentation: A Formal Approach to Argument Significance", "categories": ["cs.AI"], "comment": null, "summary": "Argumentation is a central subarea of Artificial Intelligence (AI) for\nmodeling and reasoning about arguments. The semantics of abstract argumentation\nframeworks (AFs) is given by sets of arguments (extensions) and conditions on\nthe relationship between them, such as stable or admissible. Today's solvers\nimplement tasks such as finding extensions, deciding credulous or skeptical\nacceptance, counting, or enumerating extensions. While these tasks are well\ncharted, the area between decision, counting/enumeration and fine-grained\nreasoning requires expensive reasoning so far. We introduce a novel concept\n(facets) for reasoning between decision and enumeration. Facets are arguments\nthat belong to some extensions (credulous) but not to all extensions\n(skeptical). They are most natural when a user aims to navigate, filter, or\ncomprehend the significance of specific arguments, according to their needs. We\nstudy the complexity and show that tasks involving facets are much easier than\ncounting extensions. Finally, we provide an implementation, and conduct\nexperiments to demonstrate feasibility.", "AI": {"tldr": "The paper introduces 'facets' for reasoning between decision and enumeration in argumentation frameworks, showing they are computationally easier than counting extensions.", "motivation": "To address the gap between decision, counting/enumeration, and fine-grained reasoning in abstract argumentation frameworks, which currently requires expensive reasoning.", "method": "Introduces the concept of 'facets'\u2014arguments that are credulous but not skeptical\u2014and studies their complexity. Provides an implementation and conducts experiments.", "result": "Tasks involving facets are computationally easier than counting extensions, and the implementation demonstrates feasibility.", "conclusion": "Facets offer a practical and efficient way to navigate and reason about arguments in abstract argumentation frameworks."}}
{"id": "2505.10870", "pdf": "https://arxiv.org/pdf/2505.10870", "abs": "https://arxiv.org/abs/2505.10870", "authors": ["Ziyang Huang", "Wangtao Sun", "Jun Zhao", "Kang Liu"], "title": "Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "ACL 2025", "summary": "This paper systematically addresses the challenges of rule retrieval, a\ncrucial yet underexplored area. Vanilla retrieval methods using sparse or dense\nretrievers to directly search for relevant rules to support downstream\nreasoning, often suffer from low accuracy. This is primarily due to a\nsignificant semantic gap between the instantiated facts in the queries and the\nabstract representations of the rules. Such misalignment results in suboptimal\nretrieval quality, which in turn negatively impacts reasoning performance. To\novercome these challenges, we propose Self-Induction Augmented Retrieval\n(SIAR), a novel approach that utilizes Large Language Models (LLMs) to induce\npotential inferential rules that might offer benefits for reasoning by\nabstracting the underlying knowledge and logical structure in queries. These\ninduced rules are then used for query augmentation to improve retrieval\neffectiveness. Additionally, we introduce Rule Relevance ReEstimate (R$^3$), a\nmethod that re-estimates the relevance of retrieved rules by assessing whether\nthe abstract knowledge they contain can be instantiated to align with the facts\nin the queries and the helpfulness for reasoning. Extensive experiments across\nvarious settings demonstrate the effectiveness and versatility of our proposed\nmethods.", "AI": {"tldr": "The paper introduces SIAR and R\u00b3 to improve rule retrieval by addressing semantic gaps and enhancing relevance estimation.", "motivation": "Existing rule retrieval methods suffer from low accuracy due to semantic mismatches between queries and abstract rule representations, impacting reasoning performance.", "method": "Proposes SIAR for rule induction via LLMs and R\u00b3 for relevance re-estimation by aligning abstract rules with query facts.", "result": "Experiments show improved retrieval effectiveness and reasoning performance across various settings.", "conclusion": "SIAR and R\u00b3 effectively address retrieval challenges, enhancing downstream reasoning tasks."}}
{"id": "2505.10726", "pdf": "https://arxiv.org/pdf/2505.10726", "abs": "https://arxiv.org/abs/2505.10726", "authors": ["Yihan Zhu", "Gang Liu", "Eric Inae", "Tengfei Luo", "Meng Jiang"], "title": "Learning Repetition-Invariant Representations for Polymer Informatics", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages,3 figuares", "summary": "Polymers are large macromolecules composed of repeating structural units\nknown as monomers and are widely applied in fields such as energy storage,\nconstruction, medicine, and aerospace. However, existing graph neural network\nmethods, though effective for small molecules, only model the single unit of\npolymers and fail to produce consistent vector representations for the true\npolymer structure with varying numbers of units. To address this challenge, we\nintroduce Graph Repetition Invariance (GRIN), a novel method to learn polymer\nrepresentations that are invariant to the number of repeating units in their\ngraph representations. GRIN integrates a graph-based maximum spanning tree\nalignment with repeat-unit augmentation to ensure structural consistency. We\nprovide theoretical guarantees for repetition-invariance from both model and\ndata perspectives, demonstrating that three repeating units are the minimal\naugmentation required for optimal invariant representation learning. GRIN\noutperforms state-of-the-art baselines on both homopolymer and copolymer\nbenchmarks, learning stable, repetition-invariant representations that\ngeneralize effectively to polymer chains of unseen sizes.", "AI": {"tldr": "GRIN is a new method for learning polymer representations invariant to repeating units, outperforming existing methods.", "motivation": "Existing graph neural networks fail to model polymer structures consistently due to varying repeating units.", "method": "GRIN uses graph-based maximum spanning tree alignment and repeat-unit augmentation for structural consistency.", "result": "GRIN outperforms baselines, learning stable, invariant representations for polymers of unseen sizes.", "conclusion": "GRIN provides a robust solution for polymer representation learning, ensuring invariance to repeating units."}}
{"id": "2505.01299", "pdf": "https://arxiv.org/pdf/2505.01299", "abs": "https://arxiv.org/abs/2505.01299", "authors": ["\u0110or\u0111e D. Ne\u0161kovi\u0107", "Kristina Stojmenova Pe\u010de\u010dnik", "Jaka Sodnik", "Nadica Miljkovi\u0107"], "title": "Contactless pulse rate assessment: Results and insights for application in driving simulator", "categories": ["eess.IV", "eess.SP"], "comment": "6 figures and one table", "summary": "Camera-based monitoring of Pulse Rate (PR) enables continuous and unobtrusive\nassessment of driver's state, allowing estimation of fatigue or stress that\ncould impact traffic safety. Commonly used wearable Photoplethysmography (PPG)\nsensors, while effective, suffer from motion artifacts and user discomfort.\nThis study explores the feasibility of non-contact PR assessment using facial\nvideo recordings captured by a Red, Green, and Blue (RGB) camera in a driving\nsimulation environment. The proposed approach detects subtle skin color\nvariations due to blood flow and compares extracted PR values against reference\nmeasurements from a wearable wristband Empatica E4. We evaluate the impact of\nEulerian Video Magnification (EVM) on signal quality and assess statistical\ndifferences in PR between age groups. Data obtained from 80 recordings from 64\nhealthy subjects covering a PR range of 45-160 bpm are analyzed, and signal\nextraction accuracy is quantified using metrics, such as Mean Absolute Error\n(MAE) and Root Mean Square Error (RMSE). Results show that EVM slightly\nimproves PR estimation accuracy, reducing MAE from 6.48 bpm to 5.04 bpm and\nRMSE from 7.84 bpm to 6.38 bpm. A statistically significant difference is found\nbetween older and younger groups with both video-based and ground truth\nevaluation procedures. Additionally, we discuss Empatica E4 bias and its\npotential impact on the overall assessment of contact measurements. Altogether\nthe findings demonstrate the feasibility of camera-based PR monitoring in\ndynamic environments and its potential integration into driving simulators for\nreal-time physiological assessment.", "AI": {"tldr": "The study explores non-contact pulse rate (PR) monitoring using facial video recordings in a driving simulator, comparing it to wearable PPG sensors. Results show improved accuracy with Eulerian Video Magnification (EVM) and highlight age-related PR differences.", "motivation": "To enable unobtrusive, continuous PR monitoring for driver state assessment, addressing limitations of wearable PPG sensors like motion artifacts and discomfort.", "method": "Uses facial video recordings and EVM to detect skin color variations, comparing PR values with Empatica E4 wristband data. Analyzes 80 recordings from 64 subjects.", "result": "EVM improves PR estimation (MAE: 6.48 to 5.04 bpm; RMSE: 7.84 to 6.38 bpm). Significant PR differences found between age groups. Empatica E4 bias noted.", "conclusion": "Camera-based PR monitoring is feasible in dynamic environments, with potential for real-time integration in driving simulators."}}
{"id": "2505.10737", "pdf": "https://arxiv.org/pdf/2505.10737", "abs": "https://arxiv.org/abs/2505.10737", "authors": ["Mitchell Rogers", "Theo Thompson", "Isla Duporge", "Johannes Fischer", "Klemens P\u00fctz", "Thomas Mattern", "Bing Xue", "Mengjie Zhang"], "title": "Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys", "categories": ["cs.CV"], "comment": "Accepted to the CV4Animals workshop at CVPR 2025", "summary": "Recent advancements in deep learning and aerial imaging have transformed\nwildlife monitoring, enabling researchers to survey wildlife populations at\nunprecedented scales. Unmanned Aerial Vehicles (UAVs) provide a cost-effective\nmeans of capturing high-resolution imagery, particularly for monitoring densely\npopulated seabird colonies. In this study, we assess the performance of a\ngeneral-purpose avian detection model, BirdDetector, in estimating the breeding\npopulation of Salvin's albatross (Thalassarche salvini) on the Bounty Islands,\nNew Zealand. Using drone-derived imagery, we evaluate the model's effectiveness\nin both zero-shot and fine-tuned settings, incorporating enhanced inference\ntechniques and stronger augmentation methods. Our findings indicate that while\napplying the model in a zero-shot setting offers a strong baseline, fine-tuning\nwith annotations from the target domain and stronger image augmentation leads\nto marked improvements in detection accuracy. These results highlight the\npotential of leveraging pre-trained deep-learning models for species-specific\nmonitoring in remote and challenging environments.", "AI": {"tldr": "The paper evaluates BirdDetector, a deep-learning model, for monitoring Salvin's albatross populations using UAV imagery, showing improved accuracy with fine-tuning and augmentation.", "motivation": "To assess the effectiveness of deep learning models like BirdDetector for wildlife monitoring, especially in remote areas like seabird colonies.", "method": "Evaluated BirdDetector in zero-shot and fine-tuned settings using drone imagery, with enhanced inference and augmentation techniques.", "result": "Fine-tuning with target-domain annotations and stronger augmentation significantly improved detection accuracy over zero-shot performance.", "conclusion": "Pre-trained deep-learning models, when fine-tuned, are highly effective for species-specific monitoring in challenging environments."}}
{"id": "2505.10988", "pdf": "https://arxiv.org/pdf/2505.10988", "abs": "https://arxiv.org/abs/2505.10988", "authors": ["Joon-Young Kim", "Jecheon Yu", "Heekyu Kim", "Seunghwa Ryu"], "title": "DRL-Based Injection Molding Process Parameter Optimization for Adaptive and Profitable Production", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "50 pages, 10 figures", "summary": "Plastic injection molding remains essential to modern manufacturing. However,\noptimizing process parameters to balance product quality and profitability\nunder dynamic environmental and economic conditions remains a persistent\nchallenge. This study presents a novel deep reinforcement learning (DRL)-based\nframework for real-time process optimization in injection molding, integrating\nproduct quality and profitability into the control objective. A profit function\nwas developed to reflect real-world manufacturing costs, incorporating resin,\nmold wear, and electricity prices, including time-of-use variations. Surrogate\nmodels were constructed to predict product quality and cycle time, enabling\nefficient offline training of DRL agents using soft actor-critic (SAC) and\nproximal policy optimization (PPO) algorithms. Experimental results demonstrate\nthat the proposed DRL framework can dynamically adapt to seasonal and\noperational variations, consistently maintaining product quality while\nmaximizing profit. Compared to traditional optimization methods such as genetic\nalgorithms, the DRL models achieved comparable economic performance with up to\n135x faster inference speeds, making them well-suited for real-time\napplications. The framework's scalability and adaptability highlight its\npotential as a foundation for intelligent, data-driven decision-making in\nmodern manufacturing environments.", "AI": {"tldr": "A DRL-based framework optimizes plastic injection molding by balancing quality and profit, outperforming traditional methods in speed and adaptability.", "motivation": "The challenge of optimizing process parameters in plastic injection molding under dynamic conditions drives the need for a real-time, adaptive solution.", "method": "The study uses deep reinforcement learning (DRL) with SAC and PPO algorithms, incorporating surrogate models for quality and cycle time prediction.", "result": "The DRL framework dynamically adapts to variations, maintaining quality and maximizing profit, with 135x faster inference than genetic algorithms.", "conclusion": "The scalable and adaptable DRL framework shows promise for intelligent, data-driven decision-making in manufacturing."}}
{"id": "2505.10924", "pdf": "https://arxiv.org/pdf/2505.10924", "abs": "https://arxiv.org/abs/2505.10924", "authors": ["Ada Chen", "Yongjiang Wu", "Junyuan Zhang", "Shu Yang", "Jen-tse Huang", "Kun Wang", "Wenxuan Wang", "Shuai Wang"], "title": "A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.CV", "cs.SE"], "comment": null, "summary": "Recently, AI-driven interactions with computing devices have advanced from\nbasic prototype tools to sophisticated, LLM-based systems that emulate\nhuman-like operations in graphical user interfaces. We are now witnessing the\nemergence of \\emph{Computer-Using Agents} (CUAs), capable of autonomously\nperforming tasks such as navigating desktop applications, web pages, and mobile\napps. However, as these agents grow in capability, they also introduce novel\nsafety and security risks. Vulnerabilities in LLM-driven reasoning, with the\nadded complexity of integrating multiple software components and multimodal\ninputs, further complicate the security landscape. In this paper, we present a\nsystematization of knowledge on the safety and security threats of CUAs. We\nconduct a comprehensive literature review and distill our findings along four\nresearch objectives: \\textit{\\textbf{(i)}} define the CUA that suits safety\nanalysis; \\textit{\\textbf{(ii)} } categorize current safety threats among CUAs;\n\\textit{\\textbf{(iii)}} propose a comprehensive taxonomy of existing defensive\nstrategies; \\textit{\\textbf{(iv)}} summarize prevailing benchmarks, datasets,\nand evaluation metrics used to assess the safety and performance of CUAs.\nBuilding on these insights, our work provides future researchers with a\nstructured foundation for exploring unexplored vulnerabilities and offers\npractitioners actionable guidance in designing and deploying secure\nComputer-Using Agents.", "AI": {"tldr": "The paper systematizes safety and security risks of AI-driven Computer-Using Agents (CUAs), categorizes threats, proposes defensive strategies, and summarizes benchmarks for secure deployment.", "motivation": "The rise of CUAs introduces novel safety and security risks due to vulnerabilities in LLM-driven reasoning and complex software integration, necessitating a structured analysis.", "method": "A comprehensive literature review is conducted, focusing on defining CUAs, categorizing threats, proposing defensive taxonomies, and summarizing evaluation metrics.", "result": "The study provides a taxonomy of threats and defenses, along with benchmarks, aiding researchers and practitioners in addressing CUA vulnerabilities.", "conclusion": "The work offers a foundation for future research on unexplored vulnerabilities and practical guidance for secure CUA deployment."}}
{"id": "2505.10759", "pdf": "https://arxiv.org/pdf/2505.10759", "abs": "https://arxiv.org/abs/2505.10759", "authors": ["Achmad Ginanjar", "Xue Li", "Priyanka Singh", "Wen Hua"], "title": "Random Client Selection on Contrastive Federated Learning for Tabular Data", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": null, "summary": "Vertical Federated Learning (VFL) has revolutionised collaborative machine\nlearning by enabling privacy-preserving model training across multiple parties.\nHowever, it remains vulnerable to information leakage during intermediate\ncomputation sharing. While Contrastive Federated Learning (CFL) was introduced\nto mitigate these privacy concerns through representation learning, it still\nfaces challenges from gradient-based attacks. This paper presents a\ncomprehensive experimental analysis of gradient-based attacks in CFL\nenvironments and evaluates random client selection as a defensive strategy.\nThrough extensive experimentation, we demonstrate that random client selection\nproves particularly effective in defending against gradient attacks in the CFL\nnetwork. Our findings provide valuable insights for implementing robust\nsecurity measures in contrastive federated learning systems, contributing to\nthe development of more secure collaborative learning frameworks", "AI": {"tldr": "The paper analyzes gradient-based attacks in Contrastive Federated Learning (CFL) and evaluates random client selection as a defense, showing its effectiveness in enhancing privacy.", "motivation": "VFL enables privacy-preserving collaborative learning but is vulnerable to information leakage. CFL mitigates this but still faces gradient-based attacks.", "method": "The study conducts a comprehensive experimental analysis of gradient-based attacks in CFL and tests random client selection as a defense.", "result": "Random client selection is effective in defending against gradient attacks in CFL.", "conclusion": "The findings offer insights for robust security in CFL, advancing secure collaborative learning frameworks."}}
{"id": "2505.07449", "pdf": "https://arxiv.org/pdf/2505.07449", "abs": "https://arxiv.org/abs/2505.07449", "authors": ["Wei Li", "Ming Hu", "Guoan Wang", "Lihao Liu", "Kaijin Zhou", "Junzhi Ning", "Xin Guo", "Zongyuan Ge", "Lixu Gu", "Junjun He"], "title": "Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model", "categories": ["eess.IV", "cs.CV"], "comment": "Early accepted in MICCAI25", "summary": "In ophthalmic surgery, developing an AI system capable of interpreting\nsurgical videos and predicting subsequent operations requires numerous\nophthalmic surgical videos with high-quality annotations, which are difficult\nto collect due to privacy concerns and labor consumption. Text-guided video\ngeneration (T2V) emerges as a promising solution to overcome this issue by\ngenerating ophthalmic surgical videos based on surgeon instructions. In this\npaper, we present Ophora, a pioneering model that can generate ophthalmic\nsurgical videos following natural language instructions. To construct Ophora,\nwe first propose a Comprehensive Data Curation pipeline to convert narrative\nophthalmic surgical videos into a large-scale, high-quality dataset comprising\nover 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive\nVideo-Instruction Tuning scheme to transfer rich spatial-temporal knowledge\nfrom a T2V model pre-trained on natural video-text datasets for\nprivacy-preserved ophthalmic surgical video generation based on Ophora-160K.\nExperiments on video quality evaluation via quantitative analysis and\nophthalmologist feedback demonstrate that Ophora can generate realistic and\nreliable ophthalmic surgical videos based on surgeon instructions. We also\nvalidate the capability of Ophora for empowering downstream tasks of ophthalmic\nsurgical workflow understanding. Code is available at\nhttps://github.com/mar-cry/Ophora.", "AI": {"tldr": "Ophora is an AI model that generates ophthalmic surgical videos from natural language instructions, addressing data scarcity and privacy issues.", "motivation": "The difficulty in collecting annotated ophthalmic surgical videos due to privacy and labor constraints motivates the development of Ophora.", "method": "Ophora uses a Comprehensive Data Curation pipeline to create a dataset (Ophora-160K) and a Progressive Video-Instruction Tuning scheme to adapt a pre-trained T2V model for surgical video generation.", "result": "Ophora generates realistic and reliable surgical videos, validated by quantitative analysis and ophthalmologist feedback, and enhances downstream surgical workflow tasks.", "conclusion": "Ophora successfully addresses data scarcity in ophthalmic surgery by generating high-quality videos from instructions, with potential for broader applications."}}
{"id": "2505.10743", "pdf": "https://arxiv.org/pdf/2505.10743", "abs": "https://arxiv.org/abs/2505.10743", "authors": ["Amritanshu Tiwari", "Cherish Puniani", "Kaustubh Sharma", "Ojasva Nema"], "title": "IMAGE-ALCHEMY: Advancing subject fidelity in personalised text-to-image generation", "categories": ["cs.CV"], "comment": "8 pages", "summary": "Recent advances in text-to-image diffusion models, particularly Stable\nDiffusion, have enabled the generation of highly detailed and semantically rich\nimages. However, personalizing these models to represent novel subjects based\non a few reference images remains challenging. This often leads to catastrophic\nforgetting, overfitting, or large computational overhead.We propose a two-stage\npipeline that addresses these limitations by leveraging LoRA-based fine-tuning\non the attention weights within the U-Net of the Stable Diffusion XL (SDXL)\nmodel. First, we use the unmodified SDXL to generate a generic scene by\nreplacing the subject with its class label. Then, we selectively insert the\npersonalized subject through a segmentation-driven image-to-image (Img2Img)\npipeline that uses the trained LoRA weights.This framework isolates the subject\nencoding from the overall composition, thus preserving SDXL's broader\ngenerative capabilities while integrating the new subject in a high-fidelity\nmanner. Our method achieves a DINO similarity score of 0.789 on SDXL,\noutperforming existing personalized text-to-image approaches.", "AI": {"tldr": "A two-stage pipeline using LoRA-based fine-tuning on SDXL for personalized text-to-image generation, avoiding catastrophic forgetting and overfitting.", "motivation": "Personalizing text-to-image models for novel subjects from few references is challenging due to issues like catastrophic forgetting and computational overhead.", "method": "A two-stage approach: (1) generate a generic scene with SDXL, (2) insert the personalized subject using a segmentation-driven Img2Img pipeline with trained LoRA weights.", "result": "Achieves a DINO similarity score of 0.789 on SDXL, outperforming existing methods.", "conclusion": "The method preserves SDXL's generative capabilities while integrating new subjects with high fidelity."}}
{"id": "2505.10989", "pdf": "https://arxiv.org/pdf/2505.10989", "abs": "https://arxiv.org/abs/2505.10989", "authors": ["Haiyang Shen", "Hang Yan", "Zhongshi Xing", "Mugeng Liu", "Yue Li", "Zhiyang Chen", "Yuxiang Wang", "Jiuzheng Wang", "Yun Ma"], "title": "RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization", "categories": ["cs.AI"], "comment": null, "summary": "RAG can enhance the performance of LLMs on knowledge-intensive tasks. Various\nRAG paradigms, including vanilla, planning-based, and iterative RAG, are built\nupon 2 cores: the retriever, which should robustly select relevant documents\nacross complex queries, and the generator, which should faithfully synthesize\nresponses. However, existing retrievers rely heavily on public knowledge and\nstruggle with queries of varying logical complexity and clue completeness,\nwhile generators frequently face fidelity problems. In this work, we introduce\nRAGSynth, a framework that includes a data construction modeling and a\ncorresponding synthetic data generation implementation, designed to optimize\nretriever robustness and generator fidelity. Additionally, we present\nSynthBench, a benchmark encompassing 8 domain-specific documents across 4\ndomains, featuring diverse query complexities, clue completeness, and\nfine-grained citation granularity. Leveraging RAGSynth, we generate a\nlarge-scale synthetic dataset, including single and multi-hop. Extensive\nexperiments demonstrate that the synthetic data significantly improves the\nrobustness of the retrievers and the fidelity of the generators. Additional\nevaluations confirm that RAGSynth can also generalize well across different\ndomains. By integrating the optimized retrievers into various RAG paradigms, we\nconsistently observe enhanced RAG system performance. We have open-sourced the\nimplementation on https://github.com/EachSheep/RAGSynth.", "AI": {"tldr": "RAGSynth improves RAG systems by optimizing retriever robustness and generator fidelity using synthetic data, validated across diverse domains.", "motivation": "Existing RAG retrievers struggle with complex queries and incomplete clues, while generators face fidelity issues, prompting the need for a better solution.", "method": "Introduces RAGSynth, a framework with data construction modeling and synthetic data generation, and SynthBench, a benchmark for evaluation.", "result": "Synthetic data from RAGSynth enhances retriever robustness and generator fidelity, improving RAG system performance across domains.", "conclusion": "RAGSynth effectively addresses RAG limitations, offering a scalable solution with open-sourced implementation."}}
{"id": "2505.10936", "pdf": "https://arxiv.org/pdf/2505.10936", "abs": "https://arxiv.org/abs/2505.10936", "authors": ["Jiaxing Zhao", "Hongbin Xie", "Yuzhen Lei", "Xuan Song", "Zhuoran Shi", "Lianxin Li", "Shuangxue Liu", "Haoran Zhang"], "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "categories": ["cs.CL"], "comment": "34 pages, 20 figures", "summary": "Large Language Models (LLMs) have demonstrated impressive performance in\nexecuting complex reasoning tasks. Chain-of-thought effectively enhances\nreasoning capabilities by unlocking the potential of large models, while\nmulti-agent systems provide more comprehensive solutions by integrating\ncollective intelligence of multiple agents. However, both approaches face\nsignificant limitations. Single-agent with chain-of-thought, due to the\ninherent complexity of designing cross-domain prompts, faces collaboration\nchallenges. Meanwhile, multi-agent systems consume substantial tokens and\ninevitably dilute the primary problem, which is particularly problematic in\nbusiness workflow tasks. To address these challenges, we propose Cochain, a\ncollaboration prompting framework that effectively solves business workflow\ncollaboration problem by combining knowledge and prompts at a reduced cost.\nSpecifically, we construct an integrated knowledge graph that incorporates\nknowledge from multiple stages. Furthermore, by maintaining and retrieving a\nprompts tree, we can obtain prompt information relevant to other stages of the\nbusiness workflow. We perform extensive evaluations of Cochain across multiple\ndatasets, demonstrating that Cochain outperforms all baselines in both prompt\nengineering and multi-agent LLMs. Additionally, expert evaluation results\nindicate that the use of a small model in combination with Cochain outperforms\nGPT-4.", "AI": {"tldr": "Cochain is a collaboration prompting framework combining knowledge and prompts to solve business workflow challenges, outperforming baselines and even GPT-4 when paired with a small model.", "motivation": "Address limitations of single-agent chain-of-thought (collaboration challenges) and multi-agent systems (high token cost and problem dilution) in business workflows.", "method": "Proposes Cochain, integrating a knowledge graph and a prompts tree to efficiently retrieve and combine relevant prompt information across workflow stages.", "result": "Outperforms baselines in prompt engineering and multi-agent LLMs; expert evaluation shows it surpasses GPT-4 when used with a small model.", "conclusion": "Cochain effectively addresses collaboration and cost issues in business workflows, demonstrating superior performance over existing approaches."}}
{"id": "2505.10762", "pdf": "https://arxiv.org/pdf/2505.10762", "abs": "https://arxiv.org/abs/2505.10762", "authors": ["Conor F. Hayes", "Felipe Leno Da Silva", "Jiachen Yang", "T. Nathan Mundhenk", "Chak Shing Lee", "Jacob F. Pettit", "Claudio Santiago", "Sookyung Kim", "Joanne T. Kim", "Ignacio Aravena Solis", "Ruben Glatt", "Andre R. Goncalves", "Alexander Ladd", "Ahmet Can Solak", "Thomas Desautels", "Daniel Faissol", "Brenden K. Petersen", "Mikel Landajuela"], "title": "Deep Symbolic Optimization: Reinforcement Learning for Symbolic Mathematics", "categories": ["cs.LG", "cs.NE", "cs.SC"], "comment": "Under review in LNCS Computational Approaches to Scientific Discovery", "summary": "Deep Symbolic Optimization (DSO) is a novel computational framework that\nenables symbolic optimization for scientific discovery, particularly in\napplications involving the search for intricate symbolic structures. One\nnotable example is equation discovery, which aims to automatically derive\nmathematical models expressed in symbolic form. In DSO, the discovery process\nis formulated as a sequential decision-making task. A generative neural network\nlearns a probabilistic model over a vast space of candidate symbolic\nexpressions, while reinforcement learning strategies guide the search toward\nthe most promising regions. This approach integrates gradient-based\noptimization with evolutionary and local search techniques, and it incorporates\nin-situ constraints, domain-specific priors, and advanced policy optimization\nmethods. The result is a robust framework capable of efficiently exploring\nextensive search spaces to identify interpretable and physically meaningful\nmodels. Extensive evaluations on benchmark problems have demonstrated that DSO\nachieves state-of-the-art performance in both accuracy and interpretability. In\nthis chapter, we provide a comprehensive overview of the DSO framework and\nillustrate its transformative potential for automating symbolic optimization in\nscientific discovery.", "AI": {"tldr": "DSO is a framework for symbolic optimization in scientific discovery, combining neural networks and reinforcement learning to efficiently search for interpretable symbolic models.", "motivation": "To automate the discovery of symbolic structures, such as mathematical models, for scientific applications.", "method": "Formulates discovery as sequential decision-making, using a generative neural network and reinforcement learning, integrated with gradient-based, evolutionary, and local search techniques.", "result": "Achieves state-of-the-art performance in accuracy and interpretability on benchmark problems.", "conclusion": "DSO has transformative potential for automating symbolic optimization in scientific discovery."}}
{"id": "2505.10311", "pdf": "https://arxiv.org/pdf/2505.10311", "abs": "https://arxiv.org/abs/2505.10311", "authors": ["Jeffrey Alido", "Tongyu Li", "Yu Sun", "Lei Tian"], "title": "Whitened Score Diffusion: A Structured Prior for Imaging Inverse Problems", "categories": ["eess.IV", "eess.SP", "stat.AP", "stat.ML"], "comment": null, "summary": "Conventional score-based diffusion models (DMs) may struggle with anisotropic\nGaussian diffusion processes due to the required inversion of covariance\nmatrices in the denoising score matching training objective\n\\cite{vincent_connection_2011}. We propose Whitened Score (WS) diffusion\nmodels, a novel SDE-based framework that learns the Whitened Score function\ninstead of the standard score. This approach circumvents covariance inversion,\nextending score-based DMs by enabling stable training of DMs on arbitrary\nGaussian forward noising processes. WS DMs establish equivalence with FM for\narbitrary Gaussian noise, allow for tailored spectral inductive biases, and\nprovide strong Bayesian priors for imaging inverse problems with structured\nnoise. We experiment with a variety of computational imaging tasks using the\nCIFAR and CelebA ($64\\times64$) datasets and demonstrate that WS diffusion\npriors trained on anisotropic Gaussian noising processes consistently\noutperform conventional diffusion priors based on isotropic Gaussian noise.", "AI": {"tldr": "Whitened Score (WS) diffusion models avoid covariance inversion in anisotropic Gaussian diffusion, outperforming conventional models.", "motivation": "Address limitations of conventional DMs with anisotropic Gaussian diffusion by proposing a stable alternative.", "method": "Introduce WS diffusion models, learning the Whitened Score function to bypass covariance inversion.", "result": "WS DMs outperform conventional DMs on tasks with anisotropic Gaussian noise, showing better performance on CIFAR and CelebA datasets.", "conclusion": "WS DMs offer a robust framework for diffusion models with arbitrary Gaussian noise, enhancing performance in imaging tasks."}}
{"id": "2505.10751", "pdf": "https://arxiv.org/pdf/2505.10751", "abs": "https://arxiv.org/abs/2505.10751", "authors": ["Francisco Raverta Capua", "Pablo De Cristoforis"], "title": "Mapping Semantic Segmentation to Point Clouds Using Structure from Motion for Forest Analysis", "categories": ["cs.CV"], "comment": "Work in progress, accepted in Novel Approaches for Precision\n  Agriculture and Forestry with Autonomous Robots, ICRA 2025 Workshop - May 23,\n  2025 - Atlanta, GA", "summary": "Although the use of remote sensing technologies for monitoring forested\nenvironments has gained increasing attention, publicly available point cloud\ndatasets remain scarce due to the high costs, sensor requirements, and\ntime-intensive nature of their acquisition. Moreover, as far as we are aware,\nthere are no public annotated datasets generated through Structure From Motion\n(SfM) algorithms applied to imagery, which may be due to the lack of SfM\nalgorithms that can map semantic segmentation information into an accurate\npoint cloud, especially in a challenging environment like forests.\n  In this work, we present a novel pipeline for generating semantically\nsegmented point clouds of forest environments. Using a custom-built forest\nsimulator, we generate realistic RGB images of diverse forest scenes along with\ntheir corresponding semantic segmentation masks. These labeled images are then\nprocessed using modified open-source SfM software capable of preserving\nsemantic information during 3D reconstruction. The resulting point clouds\nprovide both geometric and semantic detail, offering a valuable resource for\ntraining and evaluating deep learning models aimed at segmenting real forest\npoint clouds obtained via SfM.", "AI": {"tldr": "A novel pipeline generates semantically segmented forest point clouds using a custom simulator and modified SfM software, addressing the lack of public annotated datasets.", "motivation": "Public annotated point cloud datasets for forests are scarce due to high costs and technical challenges, especially with SfM algorithms.", "method": "A custom forest simulator creates labeled RGB images, processed by modified SfM software to preserve semantic data during 3D reconstruction.", "result": "The pipeline produces detailed geometric and semantic point clouds, useful for training deep learning models.", "conclusion": "This work provides a valuable resource for advancing forest point cloud segmentation via SfM."}}
{"id": "2505.10991", "pdf": "https://arxiv.org/pdf/2505.10991", "abs": "https://arxiv.org/abs/2505.10991", "authors": ["Yacine Izza", "Alexey Ignatiev", "Joao Marques-Silva", "Peter J. Stuckey"], "title": "Most General Explanations of Tree Ensembles", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": "Restricted version of this paper was accepted at IJCAI 2025", "summary": "Explainable Artificial Intelligence (XAI) is critical for attaining trust in\nthe operation of AI systems. A key question of an AI system is ``why was this\ndecision made this way''. Formal approaches to XAI use a formal model of the AI\nsystem to identify abductive explanations. While abductive explanations may be\napplicable to a large number of inputs sharing the same concrete values, more\ngeneral explanations may be preferred for numeric inputs. So-called inflated\nabductive explanations give intervals for each feature ensuring that any input\nwhose values fall withing these intervals is still guaranteed to make the same\nprediction. Inflated explanations cover a larger portion of the input space,\nand hence are deemed more general explanations. But there can be many\n(inflated) abductive explanations for an instance. Which is the best? In this\npaper, we show how to find a most general abductive explanation for an AI\ndecision. This explanation covers as much of the input space as possible, while\nstill being a correct formal explanation of the model's behaviour. Given that\nwe only want to give a human one explanation for a decision, the most general\nexplanation gives us the explanation with the broadest applicability, and hence\nthe one most likely to seem sensible. (The paper has been accepted at IJCAI2025\nconference.)", "AI": {"tldr": "The paper proposes a method to find the most general abductive explanation for AI decisions, ensuring broad applicability and correctness.", "motivation": "To enhance trust in AI systems by providing the most general and sensible explanations for decisions.", "method": "Uses formal models to identify inflated abductive explanations, covering larger input spaces while ensuring correctness.", "result": "Demonstrates how to derive the most general abductive explanation for an AI decision.", "conclusion": "The most general explanation is preferred for its broad applicability and human-sensible appeal."}}
{"id": "2505.10937", "pdf": "https://arxiv.org/pdf/2505.10937", "abs": "https://arxiv.org/abs/2505.10937", "authors": ["Wenrui Cai", "Chengyu Wang", "Junbing Yan", "Jun Huang", "Xiangzhong Fang"], "title": "Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The emergence of large reasoning models (LRMs) has transformed Natural\nLanguage Processing by excelling in complex tasks such as mathematical\nproblem-solving and code generation. These models leverage chain-of-thought\n(CoT) processes, enabling them to emulate human-like reasoning strategies.\nHowever, the advancement of LRMs is hindered by the lack of comprehensive CoT\ndatasets. Current resources often fail to provide extensive reasoning problems\nwith coherent CoT processes distilled from multiple teacher models and do not\naccount for multifaceted properties describing the internal characteristics of\nCoTs. To address these challenges, we introduce OmniThought, a large-scale\ndataset featuring 2 million CoT processes generated and validated by two\npowerful LRMs as teacher models. Each CoT process in OmniThought is annotated\nwith novel Reasoning Verbosity (RV) and Cognitive Difficulty (CD) scores, which\ndescribe the appropriateness of CoT verbosity and cognitive difficulty level\nfor models to comprehend these reasoning processes. We further establish a\nself-reliant pipeline to curate this dataset. Extensive experiments using\nQwen2.5 models of various sizes demonstrate the positive impact of our proposed\nscores on LRM training effectiveness. Based on the proposed OmniThought\ndataset, we further train and release a series of high-performing LRMs,\nspecifically equipped with stronger reasoning abilities and optimal CoT output\nlength and difficulty level. Our contributions significantly enhance the\ndevelopment and training of LRMs for solving complex tasks.", "AI": {"tldr": "OmniThought is a large-scale dataset with 2 million CoT processes, annotated with RV and CD scores, improving LRM training and reasoning abilities.", "motivation": "Current CoT datasets lack comprehensiveness and fail to describe internal CoT properties, hindering LRM advancement.", "method": "Introduce OmniThought, a dataset with RV and CD scores, and a self-reliant curation pipeline. Validate impact using Qwen2.5 models.", "result": "OmniThought enhances LRM training, leading to high-performing models with improved reasoning and optimal CoT output.", "conclusion": "OmniThought significantly advances LRM development for complex tasks."}}
{"id": "2505.10774", "pdf": "https://arxiv.org/pdf/2505.10774", "abs": "https://arxiv.org/abs/2505.10774", "authors": ["Yueyang Yao", "Jiajun Li", "Xingyuan Dai", "MengMeng Zhang", "Xiaoyan Gong", "Fei-Yue Wang", "Yisheng Lv"], "title": "Context-Aware Probabilistic Modeling with LLM for Multimodal Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 2 figures", "summary": "Time series forecasting is important for applications spanning energy\nmarkets, climate analysis, and traffic management. However, existing methods\nstruggle to effectively integrate exogenous texts and align them with the\nprobabilistic nature of large language models (LLMs). Current approaches either\nemploy shallow text-time series fusion via basic prompts or rely on\ndeterministic numerical decoding that conflict with LLMs' token-generation\nparadigm, which limits contextual awareness and distribution modeling. To\naddress these limitations, we propose CAPTime, a context-aware probabilistic\nmultimodal time series forecasting method that leverages text-informed\nabstraction and autoregressive LLM decoding. Our method first encodes temporal\npatterns using a pretrained time series encoder, then aligns them with textual\ncontexts via learnable interactions to produce joint multimodal\nrepresentations. By combining a mixture of distribution experts with frozen\nLLMs, we enable context-aware probabilistic forecasting while preserving LLMs'\ninherent distribution modeling capabilities. Experiments on diverse time series\nforecasting tasks demonstrate the superior accuracy and generalization of\nCAPTime, particularly in multimodal scenarios. Additional analysis highlights\nits robustness in data-scarce scenarios through hybrid probabilistic decoding.", "AI": {"tldr": "CAPTime is a novel method for time series forecasting that integrates text and probabilistic LLM decoding, outperforming existing approaches in accuracy and generalization.", "motivation": "Existing methods fail to effectively combine exogenous texts with probabilistic LLMs, limiting contextual awareness and distribution modeling.", "method": "CAPTime uses a pretrained time series encoder and learnable interactions to align temporal patterns with textual contexts, enabling multimodal probabilistic forecasting via frozen LLMs.", "result": "CAPTime achieves superior accuracy and generalization, especially in multimodal and data-scarce scenarios.", "conclusion": "CAPTime addresses key limitations in time series forecasting by leveraging text-informed abstraction and LLM capabilities, proving robust and effective."}}
{"id": "2505.10502", "pdf": "https://arxiv.org/pdf/2505.10502", "abs": "https://arxiv.org/abs/2505.10502", "authors": ["Yifan Gao", "Yaoxian Dong", "Wenbin Wu", "Chaoyang Ge", "Feng Yuan", "Jiaxi Sheng", "Haoyue Li", "Xin Gao"], "title": "WeGA: Weakly-Supervised Global-Local Affinity Learning Framework for Lymph Node Metastasis Prediction in Rectal Cancer", "categories": ["eess.IV"], "comment": null, "summary": "Accurate lymph node metastasis (LNM) assessment in rectal cancer is essential\nfor treatment planning, yet current MRI-based evaluation shows unsatisfactory\naccuracy, leading to suboptimal clinical decisions. Developing automated\nsystems also faces significant obstacles, primarily the lack of node-level\nannotations. Previous methods treat lymph nodes as isolated entities rather\nthan as an interconnected system, overlooking valuable spatial and contextual\ninformation. To solve this problem, we present WeGA, a novel weakly-supervised\nglobal-local affinity learning framework that addresses these challenges\nthrough three key innovations: 1) a dual-branch architecture with DINOv2\nbackbone for global context and residual encoder for local node details; 2) a\nglobal-local affinity extractor that aligns features across scales through\ncross-attention fusion; and 3) a regional affinity loss that enforces\nstructural coherence between classification maps and anatomical regions.\nExperiments across one internal and two external test centers demonstrate that\nWeGA outperforms existing methods, achieving AUCs of 0.750, 0.822, and 0.802\nrespectively. By effectively modeling the relationships between individual\nlymph nodes and their collective context, WeGA provides a more accurate and\ngeneralizable approach for lymph node metastasis prediction, potentially\nenhancing diagnostic precision and treatment selection for rectal cancer\npatients.", "AI": {"tldr": "WeGA is a weakly-supervised global-local affinity learning framework for accurate lymph node metastasis prediction in rectal cancer, outperforming existing methods by leveraging global context and local node details.", "motivation": "Current MRI-based LNM assessment lacks accuracy, and automated systems struggle due to missing node-level annotations and isolated node treatment.", "method": "WeGA uses a dual-branch architecture (DINOv2 for global context, residual encoder for local details), global-local affinity extractor, and regional affinity loss for structural coherence.", "result": "WeGA achieves superior AUCs (0.750, 0.822, 0.802) across internal and external test centers.", "conclusion": "WeGA improves LNM prediction accuracy by modeling node relationships and context, enhancing diagnostic precision and treatment planning."}}
{"id": "2505.10764", "pdf": "https://arxiv.org/pdf/2505.10764", "abs": "https://arxiv.org/abs/2505.10764", "authors": ["Jiajun Cheng", "Xianwu Zhao", "Shan Lin"], "title": "Benchmarking performance, explainability, and evaluation strategies of vision-language models for surgery: Challenges and opportunities", "categories": ["cs.CV"], "comment": null, "summary": "Minimally invasive surgery (MIS) presents significant visual and technical\nchallenges, including surgical instrument classification and understanding\nsurgical action involving instruments, verbs, and anatomical targets. While\nmany machine learning-based methods have been developed for surgical\nunderstanding, they typically rely on procedure- and task-specific models\ntrained on small, manually annotated datasets. In contrast, the recent success\nof vision-language models (VLMs) trained on large volumes of raw image-text\npairs has demonstrated strong adaptability to diverse visual data and a range\nof downstream tasks. This opens meaningful research questions: how well do\nthese general-purpose VLMs perform in the surgical domain? In this work, we\nexplore those questions by benchmarking several VLMs across diverse surgical\ndatasets, including general laparoscopic procedures and endoscopic submucosal\ndissection, to assess their current capabilities and limitations. Our benchmark\nreveals key gaps in the models' ability to consistently link language to the\ncorrect regions in surgical scenes.", "AI": {"tldr": "The paper benchmarks vision-language models (VLMs) in surgical contexts, revealing gaps in linking language to surgical scenes.", "motivation": "To assess how general-purpose VLMs perform in the surgical domain, given their success in other visual tasks.", "method": "Benchmarking several VLMs on diverse surgical datasets, including laparoscopic and endoscopic procedures.", "result": "VLMs struggle to consistently link language to correct regions in surgical scenes.", "conclusion": "General-purpose VLMs have limitations in surgical understanding, highlighting the need for domain-specific improvements."}}
{"id": "2505.11049", "pdf": "https://arxiv.org/pdf/2505.11049", "abs": "https://arxiv.org/abs/2505.11049", "authors": ["Yue Liu", "Shengfang Zhai", "Mingzhe Du", "Yulin Chen", "Tri Cao", "Hongcheng Gao", "Cheng Wang", "Xinfeng Li", "Kun Wang", "Junfeng Fang", "Jiaheng Zhang", "Bryan Hooi"], "title": "GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "To enhance the safety of VLMs, this paper introduces a novel reasoning-based\nVLM guard model dubbed GuardReasoner-VL. The core idea is to incentivize the\nguard model to deliberatively reason before making moderation decisions via\nonline RL. First, we construct GuardReasoner-VLTrain, a reasoning corpus with\n123K samples and 631K reasoning steps, spanning text, image, and text-image\ninputs. Then, based on it, we cold-start our model's reasoning ability via SFT.\nIn addition, we further enhance reasoning regarding moderation through online\nRL. Concretely, to enhance diversity and difficulty of samples, we conduct\nrejection sampling followed by data augmentation via the proposed safety-aware\ndata concatenation. Besides, we use a dynamic clipping parameter to encourage\nexploration in early stages and exploitation in later stages. To balance\nperformance and token efficiency, we design a length-aware safety reward that\nintegrates accuracy, format, and token cost. Extensive experiments demonstrate\nthe superiority of our model. Remarkably, it surpasses the runner-up by 19.27%\nF1 score on average. We release data, code, and models (3B/7B) of\nGuardReasoner-VL at https://github.com/yueliu1999/GuardReasoner-VL/", "AI": {"tldr": "A novel reasoning-based VLM guard model, GuardReasoner-VL, is introduced to enhance safety via online RL, outperforming others by 19.27% F1 score.", "motivation": "To improve the safety of VLMs by incentivizing deliberate reasoning before moderation decisions.", "method": "Constructs a reasoning corpus (GuardReasoner-VLTrain), uses SFT for cold-start, enhances reasoning via online RL with rejection sampling, data augmentation, and dynamic clipping.", "result": "Superior performance, surpassing the runner-up by 19.27% F1 score.", "conclusion": "GuardReasoner-VL effectively enhances VLM safety through reasoning and RL, with released data, code, and models."}}
{"id": "2505.10938", "pdf": "https://arxiv.org/pdf/2505.10938", "abs": "https://arxiv.org/abs/2505.10938", "authors": ["Yi Su", "Yuechi Zhou", "Quantong Qiu", "Juntao Li", "Qingrong Xia", "Ping Li", "Xinyu Duan", "Zhefeng Wang", "Min Zhang"], "title": "Accurate KV Cache Quantization with Outlier Tokens Tracing", "categories": ["cs.CL"], "comment": "ACL2025 Main", "summary": "The impressive capabilities of Large Language Models (LLMs) come at the cost\nof substantial computational resources during deployment. While KV Cache can\nsignificantly reduce recomputation during inference, it also introduces\nadditional memory overhead. KV Cache quantization presents a promising\nsolution, striking a good balance between memory usage and accuracy. Previous\nresearch has shown that the Keys are distributed by channel, while the Values\nare distributed by token. Consequently, the common practice is to apply\nchannel-wise quantization to the Keys and token-wise quantization to the\nValues. However, our further investigation reveals that a small subset of\nunusual tokens exhibit unique characteristics that deviate from this pattern,\nwhich can substantially impact quantization accuracy. To address this, we\ndevelop a simple yet effective method to identify these tokens accurately\nduring the decoding process and exclude them from quantization as outlier\ntokens, significantly improving overall accuracy. Extensive experiments show\nthat our method achieves significant accuracy improvements under 2-bit\nquantization and can deliver a 6.4 times reduction in memory usage and a 2.3\ntimes increase in throughput.", "AI": {"tldr": "A method to improve KV Cache quantization by identifying and excluding outlier tokens, enhancing accuracy while reducing memory usage and increasing throughput.", "motivation": "Large Language Models (LLMs) require substantial computational resources, and KV Cache quantization balances memory and accuracy but is affected by unusual tokens.", "method": "Identify and exclude outlier tokens during decoding to improve quantization accuracy.", "result": "Achieves significant accuracy improvements under 2-bit quantization, reducing memory usage by 6.4x and increasing throughput by 2.3x.", "conclusion": "The proposed method effectively addresses quantization challenges, improving efficiency and performance in LLM deployment."}}
{"id": "2505.10799", "pdf": "https://arxiv.org/pdf/2505.10799", "abs": "https://arxiv.org/abs/2505.10799", "authors": ["Tao Bai", "Junzhuo Zhou", "Zeyuan Deng", "Peng Cao"], "title": "Cell Library Characterization for Composite Current Source Models Based on Gaussian Process Regression and Active Learning", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "The composite current source (CCS) model has been adopted as an advanced\ntiming model that represents the current behavior of cells for improved\naccuracy and better capability than traditional non-linear delay models (NLDM)\nto model complex dynamic effects and interactions under advanced process nodes.\nHowever, the high accuracy requirement, large amount of data and extensive\nsimulation cost pose severe challenges to CCS characterization. To address\nthese challenges, we introduce a novel Gaussian Process Regression(GPR) model\nwith active learning(AL) to establish the characterization framework\nefficiently and accurately. Our approach significantly outperforms conventional\ncommercial tools as well as learning based approaches by achieving an average\nabsolute error of 2.05 ps and a relative error of 2.27% for current waveform of\n57 cells under 9 process, voltage, temperature (PVT) corners with TSMC 22nm\nprocess. Additionally, our model drastically reduces the runtime to 27% and the\nstorage by up to 19.5x compared with that required by commercial tools.", "AI": {"tldr": "A Gaussian Process Regression (GPR) model with active learning (AL) is introduced to efficiently and accurately characterize the Composite Current Source (CCS) model, outperforming traditional methods in accuracy, runtime, and storage.", "motivation": "The CCS model's high accuracy requirements, large data volume, and simulation costs present challenges, necessitating an improved characterization method.", "method": "A novel GPR model with AL is developed to characterize CCS, reducing runtime and storage while maintaining high accuracy.", "result": "Achieves 2.05 ps average absolute error and 2.27% relative error for 57 cells under 9 PVT corners, with 27% runtime and 19.5x storage reduction.", "conclusion": "The GPR with AL framework effectively addresses CCS characterization challenges, offering superior performance over conventional tools."}}
{"id": "2407.03653", "pdf": "https://arxiv.org/pdf/2407.03653", "abs": "https://arxiv.org/abs/2407.03653", "authors": ["Kai Norman Clasen", "Leonard Hackel", "Tom Burgert", "Gencer Sumbul", "Beg\u00fcm Demir", "Volker Markl"], "title": "reBEN: Refined BigEarthNet Dataset for Remote Sensing Image Analysis", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS) 2025. Our code is available at\n  https://github.com/rsim-tu-berlin/bigearthnet-pipeline", "summary": "This paper presents refined BigEarthNet (reBEN) that is a large-scale,\nmulti-modal remote sensing dataset constructed to support deep learning (DL)\nstudies for remote sensing image analysis. The reBEN dataset consists of\n549,488 pairs of Sentinel-1 and Sentinel-2 image patches. To construct reBEN,\nwe initially consider the Sentinel-1 and Sentinel-2 tiles used to construct the\nBigEarthNet dataset and then divide them into patches of size 1200 m x 1200 m.\nWe apply atmospheric correction to the Sentinel-2 patches using the latest\nversion of the sen2cor tool, resulting in higher-quality patches compared to\nthose present in BigEarthNet. Each patch is then associated with a pixel-level\nreference map and scene-level multi-labels. This makes reBEN suitable for\npixel- and scene-based learning tasks. The labels are derived from the most\nrecent CORINE Land Cover (CLC) map of 2018 by utilizing the 19-class\nnomenclature as in BigEarthNet. The use of the most recent CLC map results in\novercoming the label noise present in BigEarthNet. Furthermore, we introduce a\nnew geographical-based split assignment algorithm that significantly reduces\nthe spatial correlation among the train, validation, and test sets with respect\nto those present in BigEarthNet. This increases the reliability of the\nevaluation of DL models. To minimize the DL model training time, we introduce\nsoftware tools that convert the reBEN dataset into a DL-optimized data format.\nIn our experiments, we show the potential of reBEN for multi-modal multi-label\nimage classification problems by considering several state-of-the-art DL\nmodels. The pre-trained model weights, associated code, and complete dataset\nare available at https://bigearth.net.", "AI": {"tldr": "The paper introduces refined BigEarthNet (reBEN), an improved large-scale multi-modal remote sensing dataset for deep learning, featuring higher-quality patches, reduced label noise, and optimized data formats for efficient training.", "motivation": "To address limitations in the original BigEarthNet dataset, such as label noise and spatial correlation, and to support more reliable deep learning evaluations for remote sensing image analysis.", "method": "Constructed reBEN by dividing Sentinel-1 and Sentinel-2 tiles into 1200 m x 1200 m patches, applying atmospheric correction, and using the latest CORINE Land Cover map for labeling. Introduced a geographical-based split algorithm to reduce spatial correlation and optimized data formats for DL training.", "result": "reBEN provides higher-quality patches, reduced label noise, and minimized spatial correlation, enhancing the reliability of DL model evaluations.", "conclusion": "reBEN is a valuable resource for multi-modal multi-label remote sensing tasks, with improved data quality and evaluation reliability, supported by publicly available tools and datasets."}}
{"id": "2505.10769", "pdf": "https://arxiv.org/pdf/2505.10769", "abs": "https://arxiv.org/abs/2505.10769", "authors": ["Manyu Li", "Ruian He", "Zixian Zhang", "Weimin Tan", "Bo Yan"], "title": "Unifying Segment Anything in Microscopy with Multimodal Large Language Model", "categories": ["cs.CV", "68T99"], "comment": "18 pages, 9 figures", "summary": "Accurate segmentation of regions of interest in biomedical images holds\nsubstantial value in image analysis. Although several foundation models for\nbiomedical segmentation have currently achieved excellent performance on\ncertain datasets, they typically demonstrate sub-optimal performance on unseen\ndomain data. We owe the deficiency to lack of vision-language knowledge before\nsegmentation. Multimodal Large Language Models (MLLMs) bring outstanding\nunderstanding and reasoning capabilities to multimodal tasks, which inspires us\nto leverage MLLMs to inject Vision-Language Knowledge (VLK), thereby enabling\nvision models to demonstrate superior generalization capabilities on\ncross-domain datasets. In this paper, we propose using MLLMs to guide SAM in\nlearning microscopy crose-domain data, unifying Segment Anything in Microscopy,\nnamed uLLSAM. Specifically, we propose the Vision-Language Semantic Alignment\n(VLSA) module, which injects VLK into Segment Anything Model (SAM). We find\nthat after SAM receives global VLK prompts, its performance improves\nsignificantly, but there are deficiencies in boundary contour perception.\nTherefore, we further propose Semantic Boundary Regularization (SBR) to prompt\nSAM. Our method achieves performance improvements of 7.71% in Dice and 12.10%\nin SA across 9 in-domain microscopy datasets, achieving state-of-the-art\nperformance. Our method also demonstrates improvements of 6.79% in Dice and\n10.08% in SA across 10 out-ofdomain datasets, exhibiting strong generalization\ncapabilities. Code is available at https://github.com/ieellee/uLLSAM.", "AI": {"tldr": "The paper proposes uLLSAM, a method leveraging MLLMs to enhance SAM's cross-domain segmentation in microscopy by injecting Vision-Language Knowledge (VLK), achieving significant performance improvements.", "motivation": "Existing biomedical segmentation models lack generalization on unseen domains due to missing vision-language knowledge. MLLMs' multimodal capabilities inspire integrating VLK to improve SAM's performance.", "method": "The paper introduces the Vision-Language Semantic Alignment (VLSA) module to inject VLK into SAM and Semantic Boundary Regularization (SBR) to address boundary perception issues.", "result": "uLLSAM improves Dice by 7.71% and SA by 12.10% on in-domain datasets, and Dice by 6.79% and SA by 10.08% on out-of-domain datasets, showing strong generalization.", "conclusion": "The proposed uLLSAM, with VLSA and SBR, effectively enhances SAM's cross-domain segmentation, achieving state-of-the-art performance and generalization."}}
{"id": "2505.11063", "pdf": "https://arxiv.org/pdf/2505.11063", "abs": "https://arxiv.org/abs/2505.11063", "authors": ["Changyue Jiang", "Xudong Pan", "Min Yang"], "title": "Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "LLM-based autonomous agents possess capabilities such as reasoning, tool\ninvocation, and environment interaction, enabling the execution of complex\nmulti-step tasks. The internal reasoning process, i.e., thought, of behavioral\ntrajectory significantly influences tool usage and subsequent actions but can\nintroduce potential risks. Even minor deviations in the agent's thought may\ntrigger cascading effects leading to irreversible safety incidents. To address\nthe safety alignment challenges in long-horizon behavioral trajectories, we\npropose Thought-Aligner, a plug-in dynamic thought correction module. Utilizing\na lightweight and resource-efficient model, Thought-Aligner corrects each\nhigh-risk thought on the fly before each action execution. The corrected\nthought is then reintroduced to the agent, ensuring safer subsequent decisions\nand tool interactions. Importantly, Thought-Aligner modifies only the reasoning\nphase without altering the underlying agent framework, making it easy to deploy\nand widely applicable to various agent frameworks. To train the Thought-Aligner\nmodel, we construct an instruction dataset across ten representative scenarios\nand simulate ReAct execution trajectories, generating 5,000 diverse\ninstructions and more than 11,400 safe and unsafe thought pairs. The model is\nfine-tuned using contrastive learning techniques. Experiments across three\nagent safety benchmarks involving 12 different LLMs demonstrate that\nThought-Aligner raises agent behavioral safety from approximately 50% in the\nunprotected setting to 90% on average. Additionally, Thought-Aligner maintains\nresponse latency below 100ms with minimal resource usage, demonstrating its\ncapability for efficient deployment, broad applicability, and timely\nresponsiveness. This method thus provides a practical dynamic safety solution\nfor the LLM-based agents.", "AI": {"tldr": "Thought-Aligner is a dynamic thought correction module for LLM-based agents, improving safety from 50% to 90% without altering the agent framework.", "motivation": "Addressing safety risks in long-horizon behavioral trajectories of LLM-based agents caused by minor thought deviations.", "method": "Proposes Thought-Aligner, a lightweight model correcting high-risk thoughts before action execution, trained using contrastive learning on 11,400 safe/unsafe thought pairs.", "result": "Raises agent safety to 90%, maintains latency below 100ms, and ensures minimal resource usage.", "conclusion": "Thought-Aligner offers a practical, efficient, and widely applicable safety solution for LLM-based agents."}}
{"id": "2505.10939", "pdf": "https://arxiv.org/pdf/2505.10939", "abs": "https://arxiv.org/abs/2505.10939", "authors": ["Mohammadtaha Bagherifard", "Sahar Rajabi", "Ali Edalat", "Yadollah Yaghoobzadeh"], "title": "GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 (main conference, short paper), 10 pages", "summary": "Large language models often struggle with zero-shot generalization, and\nseveral modular approaches have been proposed to address this challenge. Yet,\nwe hypothesize that a key limitation remains: the entanglement of general\nknowledge and task-specific adaptations. To overcome this, we propose a modular\nframework that disentangles these components by constructing a library of\ntask-specific LoRA modules alongside a general-domain LoRA. By subtracting this\ngeneral knowledge component from each task-specific module, we obtain residual\nmodules that focus more exclusively on task-relevant information, a method we\ncall general knowledge subtraction (GenKnowSub). Leveraging the refined\ntask-specific modules and the Arrow routing algorithm\n\\citep{ostapenko2024towards}, we dynamically select and combine modules for new\ninputs without additional training. Our studies on the Phi-3 model and standard\nArrow as baselines reveal that using general knowledge LoRAs derived from\ndiverse languages, including English, French, and German, yields consistent\nperformance gains in both monolingual and cross-lingual settings across a wide\nset of benchmarks. Further experiments on Phi-2 demonstrate how GenKnowSub\ngeneralizes to weaker LLMs. The complete code and data are available at\nhttps://github.com/saharsamr/Modular-LLM.", "AI": {"tldr": "The paper proposes GenKnowSub, a modular framework to disentangle general knowledge and task-specific adaptations in LLMs, improving zero-shot generalization.", "motivation": "Addressing the entanglement of general knowledge and task-specific adaptations in LLMs to enhance zero-shot performance.", "method": "Uses task-specific and general-domain LoRA modules, subtracts general knowledge to create residual modules, and dynamically combines them using the Arrow routing algorithm.", "result": "Shows consistent performance gains in monolingual and cross-lingual settings, validated on Phi-3 and Phi-2 models.", "conclusion": "GenKnowSub effectively improves LLM generalization without additional training, with code and data publicly available."}}
{"id": "2505.10802", "pdf": "https://arxiv.org/pdf/2505.10802", "abs": "https://arxiv.org/abs/2505.10802", "authors": ["Ian Holmes", "Min Chi"], "title": "Attention-Based Reward Shaping for Sparse and Delayed Rewards", "categories": ["cs.LG", "cs.AI"], "comment": "22 pages, 17 tables, 2 figures. Code available online at\n  https://github.com/ihholmes-p/ARES", "summary": "Sparse and delayed reward functions pose a significant obstacle for\nreal-world Reinforcement Learning (RL) applications. In this work, we propose\nAttention-based REward Shaping (ARES), a general and robust algorithm which\nuses a transformer's attention mechanism to generate shaped rewards and create\na dense reward function for any environment. ARES requires a set of episodes\nand their final returns as input. It can be trained entirely offline and is\nable to generate meaningful shaped rewards even when using small datasets or\nepisodes produced by agents taking random actions. ARES is compatible with any\nRL algorithm and can handle any level of reward sparsity. In our experiments,\nwe focus on the most challenging case where rewards are fully delayed until the\nend of each episode. We evaluate ARES across a diverse range of environments,\nwidely used RL algorithms, and baseline methods to assess the effectiveness of\nthe shaped rewards it produces. Our results show that ARES can significantly\nimprove learning in delayed reward settings, enabling RL agents to train in\nscenarios that would otherwise require impractical amounts of data or even be\nunlearnable. To our knowledge, ARES is the first approach that works fully\noffline, remains robust to extreme reward delays and low-quality data, and is\nnot limited to goal-based tasks.", "AI": {"tldr": "ARES is an offline, transformer-based reward shaping method that improves RL performance in sparse/delayed reward settings.", "motivation": "Sparse and delayed rewards hinder RL applications; ARES addresses this by creating dense rewards.", "method": "Uses transformer attention to generate shaped rewards from episodes and final returns, works offline.", "result": "ARES improves learning in delayed reward settings, even with low-quality data.", "conclusion": "ARES is robust, works offline, and handles extreme reward delays, advancing RL in challenging scenarios."}}
{"id": "2505.10781", "pdf": "https://arxiv.org/pdf/2505.10781", "abs": "https://arxiv.org/abs/2505.10781", "authors": ["David Minkwan Kim", "Soeun Lee", "Byeongkeun Kang"], "title": "Completely Weakly Supervised Class-Incremental Learning for Semantic Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages", "summary": "This work addresses the task of completely weakly supervised\nclass-incremental learning for semantic segmentation to learn segmentation for\nboth base and additional novel classes using only image-level labels. While\nclass-incremental semantic segmentation (CISS) is crucial for handling diverse\nand newly emerging objects in the real world, traditional CISS methods require\nexpensive pixel-level annotations for training. To overcome this limitation,\npartially weakly-supervised approaches have recently been proposed. However, to\nthe best of our knowledge, this is the first work to introduce a completely\nweakly-supervised method for CISS. To achieve this, we propose to generate\nrobust pseudo-labels by combining pseudo-labels from a localizer and a sequence\nof foundation models based on their uncertainty. Moreover, to mitigate\ncatastrophic forgetting, we introduce an exemplar-guided data augmentation\nmethod that generates diverse images containing both previous and novel classes\nwith guidance. Finally, we conduct experiments in three common experimental\nsettings: 15-5 VOC, 10-10 VOC, and COCO-to-VOC, and in two scenarios: disjoint\nand overlap. The experimental results demonstrate that our completely weakly\nsupervised method outperforms even partially weakly supervised methods in the\n15-5 VOC and 10-10 VOC settings while achieving competitive accuracy in the\nCOCO-to-VOC setting.", "AI": {"tldr": "A completely weakly supervised method for class-incremental semantic segmentation (CISS) using image-level labels, outperforming partially supervised methods.", "motivation": "Traditional CISS requires costly pixel-level annotations; this work aims to eliminate this need by using only image-level labels.", "method": "Generates robust pseudo-labels via a localizer and foundation models, and uses exemplar-guided data augmentation to prevent catastrophic forgetting.", "result": "Outperforms partially supervised methods in 15-5 VOC and 10-10 VOC settings, and achieves competitive accuracy in COCO-to-VOC.", "conclusion": "The proposed method is effective for completely weakly supervised CISS, demonstrating superior or competitive performance across settings."}}
{"id": "2505.11086", "pdf": "https://arxiv.org/pdf/2505.11086", "abs": "https://arxiv.org/abs/2505.11086", "authors": ["Keita Kinjo"], "title": "Analysis of Customer Journeys Using Prototype Detection and Counterfactual Explanations for Sequential Data", "categories": ["cs.AI", "cs.CY"], "comment": "19 pages, 7 figures", "summary": "Recently, the proliferation of omni-channel platforms has attracted interest\nin customer journeys, particularly regarding their role in developing marketing\nstrategies. However, few efforts have been taken to quantitatively study or\ncomprehensively analyze them owing to the sequential nature of their data and\nthe complexity involved in analysis. In this study, we propose a novel approach\ncomprising three steps for analyzing customer journeys. First, the distance\nbetween sequential data is defined and used to identify and visualize\nrepresentative sequences. Second, the likelihood of purchase is predicted based\non this distance. Third, if a sequence suggests no purchase, counterfactual\nsequences are recommended to increase the probability of a purchase using a\nproposed method, which extracts counterfactual explanations for sequential\ndata. A survey was conducted, and the data were analyzed; the results revealed\nthat typical sequences could be extracted, and the parts of those sequences\nimportant for purchase could be detected. We believe that the proposed approach\ncan support improvements in various marketing activities.", "AI": {"tldr": "A novel three-step method analyzes customer journeys by defining sequence distances, predicting purchase likelihood, and recommending counterfactual sequences to improve marketing strategies.", "motivation": "The study addresses the lack of quantitative analysis of customer journeys due to sequential data complexity and aims to enhance marketing strategies.", "method": "The approach involves defining sequence distances, predicting purchase likelihood, and generating counterfactual sequences to boost purchase probability.", "result": "Typical sequences were identified, and key parts influencing purchases were detected, demonstrating the method's effectiveness.", "conclusion": "The proposed approach can enhance marketing activities by providing actionable insights into customer journeys."}}
{"id": "2505.10945", "pdf": "https://arxiv.org/pdf/2505.10945", "abs": "https://arxiv.org/abs/2505.10945", "authors": ["Seungyoon Lee", "Seongtae Hong", "Hyeonseok Moon", "Heuiseok Lim"], "title": "Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 Findings", "summary": "Large Language Models (LLMs) increasingly incorporate multilingual\ncapabilities, fueling the demand to transfer them into target language-specific\nmodels. However, most approaches, which blend the source model's embedding by\nreplacing the source vocabulary with the target language-specific vocabulary,\nmay constrain expressive capacity in the target language since the source model\nis predominantly trained on English data. In this paper, we propose Semantic\nAware Linear Transfer (SALT), a novel cross-lingual transfer technique that\nrecycles embeddings from target language Pre-trained Language Models (PLMs) to\ntransmit the deep representational strengths of PLM-derived embedding to LLMs.\nSALT derives unique regression lines based on the similarity in the overlap of\nthe source and target vocabularies, to handle each non-overlapping token's\nembedding space. Our extensive experiments show that SALT significantly\noutperforms other transfer methods and achieves lower loss with accelerating\nfaster convergence during language adaptation. Notably, SALT obtains remarkable\nperformance in cross-lingual understanding setups compared to other methods.\nFurthermore, we highlight the scalable use of PLMs to enhance the functionality\nof contemporary LLMs by conducting experiments with varying architectures.", "AI": {"tldr": "SALT, a cross-lingual transfer technique, recycles target language PLM embeddings to enhance LLMs, outperforming other methods in performance and convergence.", "motivation": "Addressing the limitation of current methods that blend source model embeddings, which may constrain expressive capacity in target languages due to English-centric training.", "method": "Proposes Semantic Aware Linear Transfer (SALT), which uses regression lines based on vocabulary overlap similarity to handle non-overlapping token embeddings.", "result": "SALT significantly outperforms other transfer methods, achieving lower loss and faster convergence, with notable performance in cross-lingual understanding.", "conclusion": "SALT effectively enhances LLMs by leveraging PLMs, demonstrating scalability and superior performance in cross-lingual transfer."}}
{"id": "2505.10822", "pdf": "https://arxiv.org/pdf/2505.10822", "abs": "https://arxiv.org/abs/2505.10822", "authors": ["Reilly Haskins", "Benjamin Adams"], "title": "Distilled Circuits: A Mechanistic Study of Internal Restructuring in Knowledge Distillation", "categories": ["cs.LG"], "comment": null, "summary": "Knowledge distillation compresses a larger neural model (teacher) into\nsmaller, faster student models by training them to match teacher outputs.\nHowever, the internal computational transformations that occur during this\nprocess remain poorly understood. We apply techniques from mechanistic\ninterpretability to analyze how internal circuits, representations, and\nactivation patterns differ between teacher and student. Focusing on GPT2-small\nand its distilled counterpart DistilGPT2, we find that student models\nreorganize, compress, and discard teacher components, often resulting in\nstronger reliance on fewer individual components. To quantify functional\nalignment beyond output similarity, we introduce an alignment metric based on\ninfluence-weighted component similarity, validated across multiple tasks. Our\nfindings reveal that while knowledge distillation preserves broad functional\nbehaviors, it also causes significant shifts in internal computation, with\nimportant implications for the robustness and generalization capacity of\ndistilled models.", "AI": {"tldr": "The paper analyzes knowledge distillation's internal mechanisms, revealing how student models reorganize or discard teacher components, impacting robustness and generalization.", "motivation": "To understand the internal computational transformations in knowledge distillation, which remain poorly understood despite its widespread use.", "method": "Applied mechanistic interpretability techniques to compare internal circuits, representations, and activations between GPT2-small (teacher) and DistilGPT2 (student). Introduced an alignment metric for functional comparison.", "result": "Student models reorganize, compress, or discard teacher components, relying more on fewer parts. Functional behaviors are preserved, but internal computation shifts significantly.", "conclusion": "Knowledge distillation alters internal computation, affecting model robustness and generalization, despite preserving functional outputs."}}
{"id": "2505.10784", "pdf": "https://arxiv.org/pdf/2505.10784", "abs": "https://arxiv.org/abs/2505.10784", "authors": ["Qiushi Guo", "Jason Rambach"], "title": "SynRailObs: A Synthetic Dataset for Obstacle Detection in Railway Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "Detecting potential obstacles in railway environments is critical for\npreventing serious accidents. Identifying a broad range of obstacle categories\nunder complex conditions requires large-scale datasets with precisely\nannotated, high-quality images. However, existing publicly available datasets\nfail to meet these requirements, thereby hindering progress in railway safety\nresearch. To address this gap, we introduce SynRailObs, a high-fidelity\nsynthetic dataset designed to represent a diverse range of weather conditions\nand geographical features. Furthermore, diffusion models are employed to\ngenerate rare and difficult-to-capture obstacles that are typically challenging\nto obtain in real-world scenarios. To evaluate the effectiveness of SynRailObs,\nwe perform experiments in real-world railway environments, testing on both\nballasted and ballastless tracks across various weather conditions. The results\ndemonstrate that SynRailObs holds substantial potential for advancing obstacle\ndetection in railway safety applications. Models trained on this dataset show\nconsistent performance across different distances and environmental conditions.\nMoreover, the model trained on SynRailObs exhibits zero-shot capabilities,\nwhich are essential for applications in security-sensitive domains. The data is\navailable in https://www.kaggle.com/datasets/qiushi910/synrailobs.", "AI": {"tldr": "SynRailObs is a synthetic dataset for railway obstacle detection, addressing gaps in existing datasets by including diverse conditions and rare obstacles. It shows strong performance in real-world tests and offers zero-shot capabilities.", "motivation": "Existing datasets lack diversity and precision for railway obstacle detection, limiting safety research.", "method": "Created SynRailObs, a synthetic dataset with diverse weather and geographical features, using diffusion models for rare obstacles.", "result": "Models trained on SynRailObs perform consistently across distances and conditions, with zero-shot capabilities.", "conclusion": "SynRailObs advances railway safety by providing a high-quality dataset for obstacle detection."}}
{"id": "2505.11107", "pdf": "https://arxiv.org/pdf/2505.11107", "abs": "https://arxiv.org/abs/2505.11107", "authors": ["Chan-Jan Hsu", "Davide Buffelli", "Jamie McGowan", "Feng-Ting Liao", "Yi-Chang Chen", "Sattar Vakili", "Da-shan Shiu"], "title": "Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated the power\nof reasoning through self-generated chains of thought. Multiple reasoning\nagents can collaborate to raise joint reasoning quality above individual\noutcomes. However, such agents typically interact in a turn-based manner,\ntrading increased latency for improved quality. In this paper, we propose Group\nThink--a single LLM that acts as multiple concurrent reasoning agents, or\nthinkers. With shared visibility into each other's partial generation progress,\nGroup Think introduces a new concurrent-reasoning paradigm in which multiple\nreasoning trajectories adapt dynamically to one another at the token level. For\nexample, a reasoning thread may shift its generation mid-sentence upon\ndetecting that another thread is better positioned to continue. This\nfine-grained, token-level collaboration enables Group Think to reduce redundant\nreasoning and improve quality while achieving significantly lower latency.\nMoreover, its concurrent nature allows for efficient utilization of idle\ncomputational resources, making it especially suitable for edge inference,\nwhere very small batch size often underutilizes local~GPUs. We give a simple\nand generalizable modification that enables any existing LLM to perform Group\nThink on a local GPU. We also present an evaluation strategy to benchmark\nreasoning latency and empirically demonstrate latency improvements using\nopen-source LLMs that were not explicitly trained for Group Think. We hope this\nwork paves the way for future LLMs to exhibit more sophisticated and more\nefficient collaborative behavior for higher quality generation.", "AI": {"tldr": "Group Think enables a single LLM to act as multiple concurrent reasoning agents, improving reasoning quality and reducing latency by allowing dynamic token-level collaboration.", "motivation": "To address the trade-off between latency and reasoning quality in multi-agent LLMs by introducing a concurrent-reasoning paradigm.", "method": "Proposes Group Think, where a single LLM acts as multiple thinkers with shared visibility, enabling dynamic token-level collaboration.", "result": "Reduces redundant reasoning, improves quality, and lowers latency, with efficient resource utilization for edge inference.", "conclusion": "Group Think paves the way for more efficient and sophisticated collaborative behavior in LLMs."}}
{"id": "2505.10948", "pdf": "https://arxiv.org/pdf/2505.10948", "abs": "https://arxiv.org/abs/2505.10948", "authors": ["Makoto Sato"], "title": "The Way We Prompt: Conceptual Blending, Neural Dynamics, and Prompt-Induced Transitions in LLMs", "categories": ["cs.CL", "q-bio.NC"], "comment": null, "summary": "Large language models (LLMs), inspired by neuroscience, exhibit behaviors\nthat often evoke a sense of personality and intelligence-yet the mechanisms\nbehind these effects remain elusive. Here, we operationalize Conceptual\nBlending Theory (CBT) as an experimental framework, using prompt-based methods\nto reveal how LLMs blend and compress meaning. By systematically investigating\nPrompt-Induced Transitions (PIT) and Prompt-Induced Hallucinations (PIH), we\nuncover structural parallels and divergences between artificial and biological\ncognition. Our approach bridges linguistics, neuroscience, and empirical AI\nresearch, demonstrating that human-AI collaboration can serve as a living\nprototype for the future of cognitive science. This work proposes prompt\nengineering not just as a technical tool, but as a scientific method for\nprobing the deep structure of meaning itself.", "AI": {"tldr": "The paper explores how LLMs blend meaning using Conceptual Blending Theory, revealing parallels between AI and biological cognition through prompt-based methods.", "motivation": "To understand the mechanisms behind LLMs' personality-like behaviors and bridge gaps between linguistics, neuroscience, and AI.", "method": "Uses prompt-based methods (Prompt-Induced Transitions and Hallucinations) to study how LLMs blend and compress meaning.", "result": "Uncovers structural similarities and differences between artificial and biological cognition.", "conclusion": "Proposes prompt engineering as a scientific method to study meaning, advocating for human-AI collaboration in cognitive science."}}
{"id": "2505.10833", "pdf": "https://arxiv.org/pdf/2505.10833", "abs": "https://arxiv.org/abs/2505.10833", "authors": ["Yifei He", "Siqi Zeng", "Yuzheng Hu", "Rui Yang", "Tong Zhang", "Han Zhao"], "title": "MergeBench: A Benchmark for Merging Domain-Specialized LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Model merging provides a scalable alternative to multi-task training by\ncombining specialized finetuned models through parameter arithmetic, enabling\nefficient deployment without the need for joint training or access to all task\ndata. While recent methods have shown promise, existing evaluations are limited\nin both model scale and task diversity, leaving open questions about their\napplicability to large, domain-specialized LLMs. To tackle the challenges, we\nintroduce MergeBench, a comprehensive evaluation suite designed to assess model\nmerging at scale. MergeBench builds on state-of-the-art open-source language\nmodels, including Llama and Gemma families at 2B to 9B scales, and covers five\nkey domains: instruction following, mathematics, multilingual understanding,\ncoding and safety. We standardize finetuning and evaluation protocols, and\nassess eight representative merging methods across multi-task performance,\nforgetting and runtime efficiency. Based on extensive experiments, we provide\npractical guidelines for algorithm selection and share insights showing that\nmodel merging tends to perform better on stronger base models, with techniques\nsuch as merging coefficient tuning and sparsification improving knowledge\nretention. However, several challenges remain, including the computational cost\non large models, the gap for in-domain performance compared to multi-task\nmodels, and the underexplored role of model merging in standard LLM training\npipelines. We hope MergeBench provides a foundation for future research to\nadvance the understanding and practical application of model merging. We open\nsource our code at\n\\href{https://github.com/uiuctml/MergeBench}{https://github.com/uiuctml/MergeBench}.", "AI": {"tldr": "MergeBench is introduced to evaluate model merging at scale, covering diverse tasks and large models, providing guidelines and insights for future research.", "motivation": "Existing evaluations of model merging lack scale and task diversity, raising questions about applicability to large, domain-specialized LLMs.", "method": "MergeBench uses state-of-the-art models (Llama, Gemma) across 2B-9B scales and five domains, standardizing finetuning and evaluating eight merging methods.", "result": "Merging performs better on stronger base models, with techniques like coefficient tuning and sparsification aiding knowledge retention. Challenges include computational costs and performance gaps.", "conclusion": "MergeBench lays groundwork for future research, highlighting model merging's potential and remaining challenges."}}
{"id": "2505.10787", "pdf": "https://arxiv.org/pdf/2505.10787", "abs": "https://arxiv.org/abs/2505.10787", "authors": ["Jianlin Guo", "Haihong Xiao", "Wenxiong Kang"], "title": "EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes", "categories": ["cs.CV"], "comment": null, "summary": "Efficient scene representations are essential for many real-world\napplications, especially those involving spatial measurement. Although current\nNeRF-based methods have achieved impressive results in reconstructing\nbuilding-scale scenes, they still suffer from slow training and inference\nspeeds due to time-consuming stochastic sampling. Recently, 3D Gaussian\nSplatting (3DGS) has demonstrated excellent performance with its high-quality\nrendering and real-time speed, especially for objects and small-scale scenes.\nHowever, in outdoor scenes, its point-based explicit representation lacks an\neffective adjustment mechanism, and the millions of Gaussian points required\noften lead to memory constraints during training. To address these challenges,\nwe propose EA-3DGS, a high-quality real-time rendering method designed for\noutdoor scenes. First, we introduce a mesh structure to regulate the\ninitialization of Gaussian components by leveraging an adaptive tetrahedral\nmesh that partitions the grid and initializes Gaussian components on each face,\neffectively capturing geometric structures in low-texture regions. Second, we\npropose an efficient Gaussian pruning strategy that evaluates each 3D\nGaussian's contribution to the view and prunes accordingly. To retain\ngeometry-critical Gaussian points, we also present a structure-aware\ndensification strategy that densifies Gaussian points in low-curvature regions.\nAdditionally, we employ vector quantization for parameter quantization of\nGaussian components, significantly reducing disk space requirements with only a\nminimal impact on rendering quality. Extensive experiments on 13 scenes,\nincluding eight from four public datasets (MatrixCity-Aerial, Mill-19, Tanks \\&\nTemples, WHU) and five self-collected scenes acquired through UAV\nphotogrammetry measurement from SCUT-CA and plateau regions, further\ndemonstrate the superiority of our method.", "AI": {"tldr": "EA-3DGS improves outdoor scene rendering by combining mesh-based Gaussian initialization, pruning, densification, and vector quantization for efficiency and quality.", "motivation": "Current NeRF-based methods are slow, and 3DGS struggles with memory and adjustment in outdoor scenes.", "method": "Uses adaptive tetrahedral mesh for Gaussian initialization, pruning, densification, and vector quantization.", "result": "Achieves high-quality real-time rendering on 13 diverse scenes with reduced memory usage.", "conclusion": "EA-3DGS is superior for outdoor scenes, balancing speed, quality, and resource efficiency."}}
{"id": "2505.11119", "pdf": "https://arxiv.org/pdf/2505.11119", "abs": "https://arxiv.org/abs/2505.11119", "authors": ["Jiabei Cheng", "Zhen-Qun Yang", "Jiannong Cao", "Yu Yang", "Xinzhe Zheng"], "title": "Predicting Student Dropout Risk With A Dual-Modal Abrupt Behavioral Changes Approach", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "14 pages, 5 figures", "summary": "Timely prediction of students at high risk of dropout is critical for early\nintervention and improving educational outcomes. However, in offline\neducational settings, poor data quality, limited scale, and high heterogeneity\noften hinder the application of advanced machine learning models. Furthermore,\nwhile educational theories provide valuable insights into dropout phenomena,\nthe lack of quantifiable metrics for key indicators limits their use in\ndata-driven modeling. Through data analysis and a review of educational\nliterature, we identified abrupt changes in student behavior as key early\nsignals of dropout risk. To address this, we propose the Dual-Modal Multiscale\nSliding Window (DMSW) Model, which integrates academic performance and\nbehavioral data to dynamically capture behavior patterns using minimal data.\nThe DMSW model improves prediction accuracy by 15% compared to traditional\nmethods, enabling educators to identify high-risk students earlier, provide\ntimely support, and foster a more inclusive learning environment. Our analysis\nhighlights key behavior patterns, offering practical insights for preventive\nstrategies and tailored support. These findings bridge the gap between theory\nand practice in dropout prediction, giving educators an innovative tool to\nenhance student retention and outcomes.", "AI": {"tldr": "The paper introduces the Dual-Modal Multiscale Sliding Window (DMSW) Model to predict student dropout risk by analyzing academic and behavioral data, improving accuracy by 15% over traditional methods.", "motivation": "Timely dropout prediction is crucial for early intervention, but poor data quality and lack of quantifiable metrics in offline settings limit existing methods.", "method": "Proposes the DMSW Model, integrating academic and behavioral data to dynamically capture behavior patterns with minimal data.", "result": "DMSW improves prediction accuracy by 15%, enabling earlier identification of high-risk students and timely support.", "conclusion": "The model bridges theory and practice, offering educators a tool to enhance retention and outcomes through tailored interventions."}}
{"id": "2505.11004", "pdf": "https://arxiv.org/pdf/2505.11004", "abs": "https://arxiv.org/abs/2505.11004", "authors": ["Jingcheng Niu", "Subhabrata Dutta", "Ahmed Elshabrawy", "Harish Tayyar Madabushi", "Iryna Gurevych"], "title": "Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large-scale Transformer language models (LMs) trained solely on next-token\nprediction with web-scale data can solve a wide range of tasks after seeing\njust a few examples. The mechanism behind this capability, known as in-context\nlearning (ICL), remains both controversial and poorly understood. Some studies\nargue that it is merely the result of memorizing vast amounts of data, while\nothers contend that it reflects a fundamental, symbolic algorithmic development\nin LMs. In this work, we introduce a suite of investigative tasks and a novel\nmethod to systematically investigate ICL by leveraging the full Pythia scaling\nsuite, including interim checkpoints that capture progressively larger amount\nof training data. By carefully exploring ICL performance on downstream tasks\nand simultaneously conducting a mechanistic analysis of the residual stream's\nsubspace, we demonstrate that ICL extends beyond mere \"memorization\" of the\ntraining corpus, yet does not amount to the implementation of an independent\nsymbolic algorithm. Our results also clarify several aspects of ICL, including\nthe influence of training dynamics, model capabilities, and elements of\nmechanistic interpretability. Overall, our work advances the understanding of\nICL and its implications, offering model developers insights into potential\nimprovements and providing AI security practitioners with a basis for more\ninformed guidelines.", "AI": {"tldr": "The paper investigates in-context learning (ICL) in large-scale Transformer LMs, showing it's not just memorization but also not a fully symbolic algorithm.", "motivation": "To clarify the controversial mechanism behind ICL in LMs, addressing debates on whether it's memorization or algorithmic development.", "method": "Uses the Pythia scaling suite with interim checkpoints to analyze ICL performance and mechanistic interpretability of the residual stream.", "result": "ICL extends beyond memorization but isn't a standalone symbolic algorithm; insights into training dynamics and model capabilities are provided.", "conclusion": "Advances understanding of ICL, offering insights for model improvement and AI security guidelines."}}
{"id": "2505.10838", "pdf": "https://arxiv.org/pdf/2505.10838", "abs": "https://arxiv.org/abs/2505.10838", "authors": ["Ran Li", "Hao Wang", "Chengzhi Mao"], "title": "LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": null, "summary": "Efficient red-teaming method to uncover vulnerabilities in Large Language\nModels (LLMs) is crucial. While recent attacks often use LLMs as optimizers,\nthe discrete language space make gradient-based methods struggle. We introduce\nLARGO (Latent Adversarial Reflection through Gradient Optimization), a novel\nlatent self-reflection attack that reasserts the power of gradient-based\noptimization for generating fluent jailbreaking prompts. By operating within\nthe LLM's continuous latent space, LARGO first optimizes an adversarial latent\nvector and then recursively call the same LLM to decode the latent into natural\nlanguage. This methodology yields a fast, effective, and transferable attack\nthat produces fluent and stealthy prompts. On standard benchmarks like AdvBench\nand JailbreakBench, LARGO surpasses leading jailbreaking techniques, including\nAutoDAN, by 44 points in attack success rate. Our findings demonstrate a potent\nalternative to agentic LLM prompting, highlighting the efficacy of interpreting\nand attacking LLM internals through gradient optimization.", "AI": {"tldr": "LARGO introduces a gradient-based latent space attack for jailbreaking LLMs, outperforming AutoDAN by 44 points in success rate.", "motivation": "Efficient red-teaming methods are needed to uncover LLM vulnerabilities, as gradient-based methods struggle in discrete language spaces.", "method": "LARGO optimizes adversarial latent vectors in the LLM's continuous latent space and decodes them into natural language recursively.", "result": "LARGO achieves a 44-point higher attack success rate than AutoDAN on benchmarks like AdvBench and JailbreakBench.", "conclusion": "LARGO demonstrates the efficacy of gradient-based optimization for attacking LLM internals, offering a potent alternative to agentic prompting."}}
{"id": "2505.10810", "pdf": "https://arxiv.org/pdf/2505.10810", "abs": "https://arxiv.org/abs/2505.10810", "authors": ["Gabriel Maldonado", "Armin Danesh Pazho", "Ghazal Alinezhad Noghre", "Vinit Katariya", "Hamed Tabkhi"], "title": "MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation", "categories": ["cs.CV"], "comment": "11 pages, 5 figures, 2 tables. Presented at the CVPR 2025 Human\n  Motion Generation (HuMoGen) Workshop. Introduces MoCLIP, a CLIP-based\n  fine-tuning strategy for motion generation, with results on HumanML3D dataset\n  and ablation studies", "summary": "Human motion generation is essential for fields such as animation, robotics,\nand virtual reality, requiring models that effectively capture motion dynamics\nfrom text descriptions. Existing approaches often rely on Contrastive\nLanguage-Image Pretraining (CLIP)-based text encoders, but their training on\ntext-image pairs constrains their ability to understand temporal and kinematic\nstructures inherent in motion and motion generation. This work introduces\nMoCLIP, a fine-tuned CLIP model with an additional motion encoding head,\ntrained on motion sequences using contrastive learning and tethering loss. By\nexplicitly incorporating motion-aware representations, MoCLIP enhances motion\nfidelity while remaining compatible with existing CLIP-based pipelines and\nseamlessly integrating into various CLIP-based methods. Experiments demonstrate\nthat MoCLIP improves Top-1, Top-2, and Top-3 accuracy while maintaining\ncompetitive FID, leading to improved text-to-motion alignment results. These\nresults highlight MoCLIP's versatility and effectiveness, establishing it as a\nrobust framework for enhancing motion generation.", "AI": {"tldr": "MoCLIP is a fine-tuned CLIP model with a motion encoding head, improving text-to-motion alignment by incorporating motion-aware representations.", "motivation": "Existing CLIP-based text encoders lack understanding of temporal and kinematic structures in motion, limiting their effectiveness in motion generation.", "method": "MoCLIP adds a motion encoding head to CLIP, trained on motion sequences using contrastive learning and tethering loss.", "result": "MoCLIP improves Top-1, Top-2, and Top-3 accuracy while maintaining competitive FID, enhancing motion fidelity.", "conclusion": "MoCLIP is a versatile and effective framework for improving motion generation, compatible with existing CLIP-based methods."}}
{"id": "2505.11122", "pdf": "https://arxiv.org/pdf/2505.11122", "abs": "https://arxiv.org/abs/2505.11122", "authors": ["Yu Shi", "Yitong Duan", "Jian Li"], "title": "Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining", "categories": ["cs.AI"], "comment": "30 pages", "summary": "Alpha factor mining is pivotal in quantitative investment for identifying\npredictive signals from complex financial data. While traditional formulaic\nalpha mining relies on human expertise, contemporary automated methods, such as\nthose based on genetic programming or reinforcement learning, often suffer from\nsearch inefficiency or yield poorly interpretable alpha factors. This paper\nintroduces a novel framework that integrates Large Language Models (LLMs) with\nMonte Carlo Tree Search (MCTS) to overcome these limitations. Our approach\nleverages the LLM's instruction-following and reasoning capability to\niteratively generate and refine symbolic alpha formulas within an MCTS-driven\nexploration. A key innovation is the guidance of MCTS exploration by rich,\nquantitative feedback from financial backtesting of each candidate factor,\nenabling efficient navigation of the vast search space. Furthermore, a frequent\nsubtree avoidance mechanism is introduced to bolster search efficiency and\nalpha factor performance. Experimental results on real-world stock market data\ndemonstrate that our LLM-based framework outperforms existing methods by mining\nalphas with superior predictive accuracy, trading performance, and improved\ninterpretability, while offering a more efficient solution for formulaic alpha\nmining.", "AI": {"tldr": "A novel framework combining LLMs and MCTS for efficient and interpretable alpha factor mining in quantitative investment, outperforming traditional methods.", "motivation": "Traditional alpha mining methods are inefficient or yield uninterpretable results, prompting the need for an automated yet effective approach.", "method": "Integrates LLMs with MCTS to iteratively generate and refine symbolic alpha formulas, guided by financial backtesting feedback and a subtree avoidance mechanism.", "result": "Outperforms existing methods in predictive accuracy, trading performance, and interpretability on real-world stock market data.", "conclusion": "The LLM-based framework offers a superior, efficient solution for formulaic alpha mining."}}
{"id": "2505.11008", "pdf": "https://arxiv.org/pdf/2505.11008", "abs": "https://arxiv.org/abs/2505.11008", "authors": ["Ye Kyaw Thu", "Thazin Myint Oo"], "title": "Reconstructing Syllable Sequences in Abugida Scripts with Incomplete Inputs", "categories": ["cs.CL", "cs.LG", "I.2.7"], "comment": "14 pages, 2 figures, 6 tables, 1 listing", "summary": "This paper explores syllable sequence prediction in Abugida languages using\nTransformer-based models, focusing on six languages: Bengali, Hindi, Khmer,\nLao, Myanmar, and Thai, from the Asian Language Treebank (ALT) dataset. We\ninvestigate the reconstruction of complete syllable sequences from various\nincomplete input types, including consonant sequences, vowel sequences, partial\nsyllables (with random character deletions), and masked syllables (with fixed\nsyllable deletions). Our experiments reveal that consonant sequences play a\ncritical role in accurate syllable prediction, achieving high BLEU scores,\nwhile vowel sequences present a significantly greater challenge. The model\ndemonstrates robust performance across tasks, particularly in handling partial\nand masked syllable reconstruction, with strong results for tasks involving\nconsonant information and syllable masking. This study advances the\nunderstanding of sequence prediction for Abugida languages and provides\npractical insights for applications such as text prediction, spelling\ncorrection, and data augmentation in these scripts.", "AI": {"tldr": "Transformer models predict syllable sequences in Abugida languages, showing consonants are key for accuracy, while vowels are harder.", "motivation": "To improve syllable sequence prediction in Abugida languages for applications like text prediction and spelling correction.", "method": "Uses Transformer models to reconstruct syllables from incomplete inputs (consonant/vowel sequences, partial/masked syllables) on six ALT languages.", "result": "Consonant sequences yield high BLEU scores; vowels are challenging. Model excels in partial/masked syllable tasks.", "conclusion": "Advances Abugida language sequence prediction, offering practical insights for text-related applications."}}
{"id": "2505.10845", "pdf": "https://arxiv.org/pdf/2505.10845", "abs": "https://arxiv.org/abs/2505.10845", "authors": ["Hanyu Duan", "Yi Yang", "Ahmed Abbasi", "Kar Yan Tam"], "title": "Ready2Unlearn: A Learning-Time Approach for Preparing Models with Future Unlearning Readiness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces Ready2Unlearn, a learning-time optimization approach\ndesigned to facilitate future unlearning processes. Unlike the majority of\nexisting unlearning efforts that focus on designing unlearning algorithms,\nwhich are typically implemented reactively when an unlearning request is made\nduring the model deployment phase, Ready2Unlearn shifts the focus to the\ntraining phase, adopting a \"forward-looking\" perspective. Building upon\nwell-established meta-learning principles, Ready2Unlearn proactively trains\nmachine learning models with unlearning readiness, such that they are well\nprepared and can handle future unlearning requests in a more efficient and\nprincipled manner. Ready2Unlearn is model-agnostic and compatible with any\ngradient ascent-based machine unlearning algorithms. We evaluate the method on\nboth vision and language tasks under various unlearning settings, including\nclass-wise unlearning and random data unlearning. Experimental results show\nthat by incorporating such preparedness at training time, Ready2Unlearn\nproduces an unlearning-ready model state, which offers several key advantages\nwhen future unlearning is required, including reduced unlearning time, improved\nretention of overall model capability, and enhanced resistance to the\ninadvertent recovery of forgotten data. We hope this work could inspire future\nefforts to explore more proactive strategies for equipping machine learning\nmodels with built-in readiness towards more reliable and principled machine\nunlearning.", "AI": {"tldr": "Ready2Unlearn is a proactive training-phase method for machine unlearning, improving efficiency and model readiness for future unlearning requests.", "motivation": "Existing unlearning methods are reactive during deployment; Ready2Unlearn aims to prepare models during training for better unlearning performance.", "method": "Leverages meta-learning to train models with unlearning readiness, compatible with gradient ascent-based unlearning algorithms.", "result": "Reduced unlearning time, better model capability retention, and resistance to forgotten data recovery in vision and language tasks.", "conclusion": "Encourages proactive strategies for reliable and principled machine unlearning."}}
{"id": "2505.10825", "pdf": "https://arxiv.org/pdf/2505.10825", "abs": "https://arxiv.org/abs/2505.10825", "authors": ["Jinke Li", "Yue Wu", "Xiaoyan Yang"], "title": "A High-Performance Thermal Infrared Object Detection Framework with Centralized Regulation", "categories": ["cs.CV", "cs.LG"], "comment": "This manuscript has been accepted for publication in the\n  International Journal for Housing Science and Its Applications (IJHSA), 2025", "summary": "Thermal Infrared (TIR) technology involves the use of sensors to detect and\nmeasure infrared radiation emitted by objects, and it is widely utilized across\na broad spectrum of applications. The advancements in object detection methods\nutilizing TIR images have sparked significant research interest. However, most\ntraditional methods lack the capability to effectively extract and fuse\nlocal-global information, which is crucial for TIR-domain feature attention. In\nthis study, we present a novel and efficient thermal infrared object detection\nframework, known as CRT-YOLO, that is based on centralized feature regulation,\nenabling the establishment of global-range interaction on TIR information. Our\nproposed model integrates efficient multi-scale attention (EMA) modules, which\nadeptly capture long-range dependencies while incurring minimal computational\noverhead. Additionally, it leverages the Centralized Feature Pyramid (CFP)\nnetwork, which offers global regulation of TIR features. Extensive experiments\nconducted on two benchmark datasets demonstrate that our CRT-YOLO model\nsignificantly outperforms conventional methods for TIR image object detection.\nFurthermore, the ablation study provides compelling evidence of the\neffectiveness of our proposed modules, reinforcing the potential impact of our\napproach on advancing the field of thermal infrared object detection.", "AI": {"tldr": "CRT-YOLO is a new TIR object detection framework that improves local-global feature fusion using centralized feature regulation and multi-scale attention, outperforming traditional methods.", "motivation": "Traditional TIR object detection methods fail to effectively extract and fuse local-global information, limiting performance.", "method": "CRT-YOLO integrates EMA modules for long-range dependencies and a CFP network for global feature regulation.", "result": "Experiments show CRT-YOLO outperforms conventional methods on benchmark datasets.", "conclusion": "The proposed modules are effective, advancing TIR object detection."}}
{"id": "2505.11135", "pdf": "https://arxiv.org/pdf/2505.11135", "abs": "https://arxiv.org/abs/2505.11135", "authors": ["Patrick St\u00f6ckermann", "Henning S\u00fcdfeld", "Alessandro Immordino", "Thomas Altenm\u00fcller", "Marc Wegmann", "Martin Gebser", "Konstantin Schekotihin", "Georg Seidel", "Chew Wye Chan", "Fei Fei Zhang"], "title": "Scalability of Reinforcement Learning Methods for Dispatching in Semiconductor Frontend Fabs: A Comparison of Open-Source Models with Real Industry Datasets", "categories": ["cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "Benchmark datasets are crucial for evaluating approaches to scheduling or\ndispatching in the semiconductor industry during the development and deployment\nphases. However, commonly used benchmark datasets like the Minifab or SMT2020\nlack the complex details and constraints found in real-world scenarios. To\nmitigate this shortcoming, we compare open-source simulation models with a real\nindustry dataset to evaluate how optimization methods scale with different\nlevels of complexity. Specifically, we focus on Reinforcement Learning methods,\nperforming optimization based on policy-gradient and Evolution Strategies. Our\nresearch provides insights into the effectiveness of these optimization methods\nand their applicability to realistic semiconductor frontend fab simulations. We\nshow that our proposed Evolution Strategies-based method scales much better\nthan a comparable policy-gradient-based approach. Moreover, we identify the\nselection and combination of relevant bottleneck tools to control by the agent\nas crucial for an efficient optimization. For the generalization across\ndifferent loading scenarios and stochastic tool failure patterns, we achieve\nadvantages when utilizing a diverse training dataset. While the overall\napproach is computationally expensive, it manages to scale well with the number\nof CPU cores used for training. For the real industry dataset, we achieve an\nimprovement of up to 4% regarding tardiness and up to 1% regarding throughput.\nFor the less complex open-source models Minifab and SMT2020, we observe\ndouble-digit percentage improvement in tardiness and single digit percentage\nimprovement in throughput by use of Evolution Strategies.", "AI": {"tldr": "The paper compares RL methods (policy-gradient and Evolution Strategies) for semiconductor scheduling, showing Evolution Strategies scale better and improve performance in real-world and benchmark datasets.", "motivation": "Existing benchmark datasets lack real-world complexity, so the study evaluates optimization methods' scalability and effectiveness in realistic semiconductor fab simulations.", "method": "Uses Reinforcement Learning (policy-gradient and Evolution Strategies) for optimization, focusing on bottleneck tool selection and diverse training datasets.", "result": "Evolution Strategies outperform policy-gradient, improving tardiness (up to 4%) and throughput (up to 1%) in real datasets, with even better gains in benchmarks.", "conclusion": "Evolution Strategies are more scalable and effective for semiconductor scheduling, especially with diverse training data and bottleneck tool control."}}
{"id": "2505.11010", "pdf": "https://arxiv.org/pdf/2505.11010", "abs": "https://arxiv.org/abs/2505.11010", "authors": ["Jiangxu Wu", "Cong Wang", "TianHuang Su", "Jun Yang", "Haozhi Lin", "Chao Zhang", "Ming Peng", "Kai Shi", "SongPan Yang", "BinQing Pan", "ZiXian Li", "Ni Yang", "ZhenYu Yang"], "title": "Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ACL2025 Accepted", "summary": "The effectiveness of large language models (LLMs) in conversational AI is\nhindered by their reliance on single-turn supervised fine-tuning (SFT) data,\nwhich limits contextual coherence in multi-turn dialogues. Existing methods for\ngenerating multi-turn dialogue data struggle to ensure both diversity and\nquality in instructions. To address this, we propose Review-Instruct, a novel\nframework that synthesizes multi-turn conversations through an iterative\n\"Ask-Respond-Review\" process involving three agent roles: a Candidate, multiple\nReviewers, and a Chairman. The framework iteratively refines instructions by\nincorporating Reviewer feedback, enhancing dialogue diversity and difficulty.\nWe construct a multi-turn dataset using the Alpaca dataset and fine-tune the\nLLaMA2-13B model. Evaluations on MT-Bench, MMLU-Pro, and Auto-Arena demonstrate\nsignificant improvements, achieving absolute gains of 2.9\\% on MMLU-Pro and 2\\%\non MT-Bench compared to prior state-of-the-art models based on LLaMA2-13B.\nAblation studies confirm the critical role of the Review stage and the use of\nmultiple Reviewers in boosting instruction diversity and difficulty. Our work\nhighlights the potential of review-driven, multi-agent frameworks for\ngenerating high-quality conversational data at scale.", "AI": {"tldr": "Review-Instruct, a multi-agent framework, improves multi-turn dialogue quality by iteratively refining instructions through an 'Ask-Respond-Review' process, outperforming prior models on benchmarks.", "motivation": "Single-turn SFT data limits LLMs' contextual coherence in multi-turn dialogues, and existing methods lack diversity and quality in instructions.", "method": "Proposes Review-Instruct, using three agent roles (Candidate, Reviewers, Chairman) to iteratively refine instructions via feedback, and fine-tunes LLaMA2-13B on a multi-turn dataset.", "result": "Achieves absolute gains of 2.9% on MMLU-Pro and 2% on MT-Bench over prior LLaMA2-13B models, with ablation studies confirming the Review stage's importance.", "conclusion": "Review-driven, multi-agent frameworks can generate high-quality conversational data at scale, enhancing LLM performance in multi-turn dialogues."}}
{"id": "2505.10846", "pdf": "https://arxiv.org/pdf/2505.10846", "abs": "https://arxiv.org/abs/2505.10846", "authors": ["Jiacheng Liang", "Tanqiu Jiang", "Yuhui Wang", "Rongyi Zhu", "Fenglong Ma", "Ting Wang"], "title": "AutoRAN: Weak-to-Strong Jailbreaking of Large Reasoning Models", "categories": ["cs.LG", "cs.CR"], "comment": "9 pages", "summary": "This paper presents AutoRAN, the first automated, weak-to-strong jailbreak\nattack framework targeting large reasoning models (LRMs). At its core, AutoRAN\nleverages a weak, less-aligned reasoning model to simulate the target model's\nhigh-level reasoning structures, generates narrative prompts, and iteratively\nrefines candidate prompts by incorporating the target model's intermediate\nreasoning steps. We evaluate AutoRAN against state-of-the-art LRMs including\nGPT-o3/o4-mini and Gemini-2.5-Flash across multiple benchmark datasets\n(AdvBench, HarmBench, and StrongReject). Results demonstrate that AutoRAN\nachieves remarkable success rates (approaching 100%) within one or a few turns\nacross different LRMs, even when judged by a robustly aligned external model.\nThis work reveals that leveraging weak reasoning models can effectively exploit\nthe critical vulnerabilities of much more capable reasoning models,\nhighlighting the need for improved safety measures specifically designed for\nreasoning-based models. The code for replicating AutoRAN and running records\nare available at: (https://github.com/JACKPURCELL/AutoRAN-public). (warning:\nthis paper contains potentially harmful content generated by LRMs.)", "AI": {"tldr": "AutoRAN is an automated jailbreak attack framework that uses a weak reasoning model to exploit vulnerabilities in stronger reasoning models, achieving near 100% success rates.", "motivation": "To expose vulnerabilities in large reasoning models (LRMs) by demonstrating how weak models can exploit their reasoning structures.", "method": "AutoRAN simulates target LRMs' reasoning, generates narrative prompts, and refines them iteratively using intermediate reasoning steps.", "result": "Achieves near 100% success rates across various LRMs (e.g., GPT-o3/o4-mini, Gemini-2.5-Flash) on benchmarks like AdvBench and HarmBench.", "conclusion": "Highlights the need for improved safety measures in reasoning-based models, as weak models can effectively exploit stronger ones."}}
{"id": "2505.10827", "pdf": "https://arxiv.org/pdf/2505.10827", "abs": "https://arxiv.org/abs/2505.10827", "authors": ["Nail Ibrahimli", "Julian F. P. Kooij", "Liangliang Nan"], "title": "NeuSEditor: From Multi-View Images to Text-Guided Neural Surface Edits", "categories": ["cs.CV"], "comment": null, "summary": "Implicit surface representations are valued for their compactness and\ncontinuity, but they pose significant challenges for editing. Despite recent\nadvancements, existing methods often fail to preserve identity and maintain\ngeometric consistency during editing. To address these challenges, we present\nNeuSEditor, a novel method for text-guided editing of neural implicit surfaces\nderived from multi-view images. NeuSEditor introduces an identity-preserving\narchitecture that efficiently separates scenes into foreground and background,\nenabling precise modifications without altering the scene-specific elements.\nOur geometry-aware distillation loss significantly enhances rendering and\ngeometric quality. Our method simplifies the editing workflow by eliminating\nthe need for continuous dataset updates and source prompting. NeuSEditor\noutperforms recent state-of-the-art methods like PDS and InstructNeRF2NeRF,\ndelivering superior quantitative and qualitative results. For more visual\nresults, visit: neuseditor.github.io.", "AI": {"tldr": "NeuSEditor is a novel method for text-guided editing of neural implicit surfaces, addressing challenges in identity preservation and geometric consistency.", "motivation": "Existing methods for editing implicit surfaces struggle with preserving identity and geometric consistency, prompting the need for a more efficient solution.", "method": "NeuSEditor uses an identity-preserving architecture to separate scenes into foreground and background, coupled with a geometry-aware distillation loss for improved rendering and geometry.", "result": "NeuSEditor outperforms state-of-the-art methods like PDS and InstructNeRF2NeRF, delivering better quantitative and qualitative results.", "conclusion": "NeuSEditor simplifies editing workflows and enhances geometric quality, making it a superior solution for neural implicit surface editing."}}
{"id": "2505.11136", "pdf": "https://arxiv.org/pdf/2505.11136", "abs": "https://arxiv.org/abs/2505.11136", "authors": ["Janik Bischoff", "Alexandru Rinciog", "Anne Meyer"], "title": "Reinforcement Learning for AMR Charging Decisions: The Impact of Reward and Action Space Design", "categories": ["cs.AI", "cs.RO"], "comment": "Under review LION19: The 19th Learning and Intelligent OptimizatioN\n  Conference", "summary": "We propose a novel reinforcement learning (RL) design to optimize the\ncharging strategy for autonomous mobile robots in large-scale block stacking\nwarehouses. RL design involves a wide array of choices that can mostly only be\nevaluated through lengthy experimentation. Our study focuses on how different\nreward and action space configurations, ranging from flexible setups to more\nguided, domain-informed design configurations, affect the agent performance.\nUsing heuristic charging strategies as a baseline, we demonstrate the\nsuperiority of flexible, RL-based approaches in terms of service times.\nFurthermore, our findings highlight a trade-off: While more open-ended designs\nare able to discover well-performing strategies on their own, they may require\nlonger convergence times and are less stable, whereas guided configurations\nlead to a more stable learning process but display a more limited\ngeneralization potential. Our contributions are threefold. First, we extend\nSLAPStack, an open-source, RL-compatible simulation-framework to accommodate\ncharging strategies. Second, we introduce a novel RL design for tackling the\ncharging strategy problem. Finally, we introduce several novel adaptive\nbaseline heuristics and reproducibly evaluate the design using a Proximal\nPolicy Optimization agent and varying different design configurations, with a\nfocus on reward.", "AI": {"tldr": "The paper proposes a reinforcement learning (RL) approach to optimize charging strategies for mobile robots in warehouses, comparing flexible and guided RL designs. It highlights trade-offs in performance and stability, introduces a simulation framework extension, and evaluates designs using adaptive heuristics and Proximal Policy Optimization.", "motivation": "To address the challenge of optimizing charging strategies for autonomous mobile robots in large-scale warehouses, where traditional methods may be inefficient or inflexible.", "method": "The study uses RL with varying reward and action space configurations, comparing flexible and guided designs. It extends the SLAPStack simulation framework and evaluates performance using Proximal Policy Optimization and adaptive heuristics.", "result": "Flexible RL designs outperform heuristic baselines in service times but require longer convergence and are less stable. Guided designs offer stability but limited generalization.", "conclusion": "The paper demonstrates the effectiveness of RL for charging strategy optimization, emphasizing trade-offs between flexibility and stability, and contributes a simulation framework extension and novel RL design."}}
{"id": "2505.11026", "pdf": "https://arxiv.org/pdf/2505.11026", "abs": "https://arxiv.org/abs/2505.11026", "authors": ["Maria Dziuba", "Valentin Malykh"], "title": "StRuCom: A Novel Dataset of Structured Code Comments in Russian", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": null, "summary": "Structured code comments in docstring format are essential for code\ncomprehension and maintenance, but existing machine learning models for their\ngeneration perform poorly for Russian compared to English. To bridge this gap,\nwe present StRuCom - the first large-scale dataset (153K examples) specifically\ndesigned for Russian code documentation. Unlike machine-translated English\ndatasets that distort terminology (e.g., technical loanwords vs. literal\ntranslations) and docstring structures, StRuCom combines human-written comments\nfrom Russian GitHub repositories with synthetically generated ones, ensuring\ncompliance with Python, Java, JavaScript, C#, and Go standards through\nautomated validation. Fine-tuning Qwen2.5-Coder models (0.5B-7B) on StRuCom\nshows statistically significant improvements of chrf++ and BERTScore over\nbaseline models.", "AI": {"tldr": "StRuCom is a new dataset for Russian code documentation, improving model performance over baselines.", "motivation": "Existing models for generating structured code comments perform poorly for Russian compared to English.", "method": "StRuCom combines human-written Russian GitHub comments with synthetic ones, validated for compliance with multiple programming languages. Qwen2.5-Coder models (0.5B-7B) are fine-tuned on this dataset.", "result": "Statistically significant improvements in chrf++ and BERTScore over baseline models.", "conclusion": "StRuCom effectively bridges the gap in Russian code documentation quality."}}
{"id": "2505.10848", "pdf": "https://arxiv.org/pdf/2505.10848", "abs": "https://arxiv.org/abs/2505.10848", "authors": ["Justin Sanders", "Melih Yilmaz", "Jacob H. Russell", "Wout Bittremieux", "William E. Fondrie", "Nicholas M. Riley", "Sewoong Oh", "William Stafford Noble"], "title": "Foundation model for mass spectrometry proteomics", "categories": ["cs.LG"], "comment": null, "summary": "Mass spectrometry is the dominant technology in the field of proteomics,\nenabling high-throughput analysis of the protein content of complex biological\nsamples. Due to the complexity of the instrumentation and resulting data,\nsophisticated computational methods are required for the processing and\ninterpretation of acquired mass spectra. Machine learning has shown great\npromise to improve the analysis of mass spectrometry data, with numerous\npurpose-built methods for improving specific steps in the data acquisition and\nanalysis pipeline reaching widespread adoption. Here, we propose unifying\nvarious spectrum prediction tasks under a single foundation model for mass\nspectra. To this end, we pre-train a spectrum encoder using de novo sequencing\nas a pre-training task. We then show that using these pre-trained spectrum\nrepresentations improves our performance on the four downstream tasks of\nspectrum quality prediction, chimericity prediction, phosphorylation\nprediction, and glycosylation status prediction. Finally, we perform multi-task\nfine-tuning and find that this approach improves the performance on each task\nindividually. Overall, our work demonstrates that a foundation model for tandem\nmass spectrometry proteomics trained on de novo sequencing learns generalizable\nrepresentations of spectra, improves performance on downstream tasks where\ntraining data is limited, and can ultimately enhance data acquisition and\nanalysis in proteomics experiments.", "AI": {"tldr": "A foundation model for mass spectra is proposed, pre-trained on de novo sequencing, improving performance on downstream proteomics tasks like spectrum quality and modification predictions.", "motivation": "To unify spectrum prediction tasks and enhance proteomics data analysis using machine learning.", "method": "Pre-train a spectrum encoder with de novo sequencing, then apply it to downstream tasks via multi-task fine-tuning.", "result": "The model improves performance on spectrum quality, chimericity, phosphorylation, and glycosylation predictions.", "conclusion": "The foundation model generalizes well, enhances limited-data tasks, and benefits proteomics experiments."}}
{"id": "2505.10841", "pdf": "https://arxiv.org/pdf/2505.10841", "abs": "https://arxiv.org/abs/2505.10841", "authors": ["Jaeguk Kim", "Jaewoo Park", "Keuntek Lee", "Nam Ik Cho"], "title": "RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025", "summary": "Estimating the 6D pose of unseen objects from monocular RGB images remains a\nchallenging problem, especially due to the lack of prior object-specific\nknowledge. To tackle this issue, we propose RefPose, an innovative approach to\nobject pose estimation that leverages a reference image and geometric\ncorrespondence as guidance. RefPose first predicts an initial pose by using\nobject templates to render the reference image and establish the geometric\ncorrespondence needed for the refinement stage. During the refinement stage,\nRefPose estimates the geometric correspondence of the query based on the\ngenerated references and iteratively refines the pose through a\nrender-and-compare approach. To enhance this estimation, we introduce a\ncorrelation volume-guided attention mechanism that effectively captures\ncorrelations between the query and reference images. Unlike traditional methods\nthat depend on pre-defined object models, RefPose dynamically adapts to new\nobject shapes by leveraging a reference image and geometric correspondence.\nThis results in robust performance across previously unseen objects. Extensive\nevaluation on the BOP benchmark datasets shows that RefPose achieves\nstate-of-the-art results while maintaining a competitive runtime.", "AI": {"tldr": "RefPose is a novel method for 6D pose estimation of unseen objects using reference images and geometric correspondence, achieving state-of-the-art results.", "motivation": "The challenge of estimating 6D poses of unseen objects without prior knowledge drives the need for an adaptable solution.", "method": "RefPose uses reference images and geometric correspondence, refining poses iteratively with a render-and-compare approach and a correlation volume-guided attention mechanism.", "result": "RefPose outperforms traditional methods on the BOP benchmark, showing robust performance on unseen objects.", "conclusion": "RefPose offers a dynamic and effective solution for 6D pose estimation, excelling in adaptability and performance."}}
{"id": "2505.11181", "pdf": "https://arxiv.org/pdf/2505.11181", "abs": "https://arxiv.org/abs/2505.11181", "authors": ["Jae Myung Kim", "Stephan Alaniz", "Cordelia Schmid", "Zeynep Akata"], "title": "Feasibility with Language Models for Open-World Compositional Zero-Shot Learning", "categories": ["cs.AI"], "comment": "ECCV Workshop in OOD-CV, 2024", "summary": "Humans can easily tell if an attribute (also called state) is realistic,\ni.e., feasible, for an object, e.g. fire can be hot, but it cannot be wet. In\nOpen-World Compositional Zero-Shot Learning, when all possible state-object\ncombinations are considered as unseen classes, zero-shot predictors tend to\nperform poorly. Our work focuses on using external auxiliary knowledge to\ndetermine the feasibility of state-object combinations. Our Feasibility with\nLanguage Model (FLM) is a simple and effective approach that leverages Large\nLanguage Models (LLMs) to better comprehend the semantic relationships between\nstates and objects. FLM involves querying an LLM about the feasibility of a\ngiven pair and retrieving the output logit for the positive answer. To mitigate\npotential misguidance of the LLM given that many of the state-object\ncompositions are rare or completely infeasible, we observe that the in-context\nlearning ability of LLMs is essential. We present an extensive study\nidentifying Vicuna and ChatGPT as best performing, and we demonstrate that our\nFLM consistently improves OW-CZSL performance across all three benchmarks.", "AI": {"tldr": "FLM uses LLMs to assess state-object feasibility, improving Open-World Zero-Shot Learning performance.", "motivation": "Zero-shot predictors struggle with unseen state-object combinations; FLM leverages LLMs to address this.", "method": "FLM queries LLMs for feasibility of pairs, using logits for positive answers and in-context learning.", "result": "FLM improves performance across benchmarks, with Vicuna and ChatGPT as top-performing models.", "conclusion": "FLM effectively enhances OW-CZSL by leveraging LLMs for feasibility assessment."}}
{"id": "2505.11031", "pdf": "https://arxiv.org/pdf/2505.11031", "abs": "https://arxiv.org/abs/2505.11031", "authors": ["Xiao Zhang", "Huiyuan Lai", "Qianru Meng", "Johan Bos"], "title": "OntoURL: A Benchmark for Evaluating Large Language Models on Symbolic Ontological Understanding, Reasoning and Learning", "categories": ["cs.CL"], "comment": "Paper submitted to NeruoIPS 2025 dataset and benchmark track", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\na range of natural language processing tasks, yet their ability to process\nstructured symbolic knowledge remains underexplored. To address this gap, we\npropose a taxonomy of LLMs' ontological capabilities and introduce OntoURL, the\nfirst comprehensive benchmark designed to systematically evaluate LLMs'\nproficiency in handling ontologies -- formal, symbolic representations of\ndomain knowledge through concepts, relationships, and instances. Based on the\nproposed taxonomy, OntoURL systematically assesses three dimensions:\nunderstanding, reasoning, and learning through 15 distinct tasks comprising\n58,981 questions derived from 40 ontologies across 8 domains. Experiments with\n20 open-source LLMs reveal significant performance differences across models,\ntasks, and domains, with current LLMs showing proficiency in understanding\nontological knowledge but substantial weaknesses in reasoning and learning\ntasks. These findings highlight fundamental limitations in LLMs' capability to\nprocess symbolic knowledge and establish OntoURL as a critical benchmark for\nadvancing the integration of LLMs with formal knowledge representations.", "AI": {"tldr": "The paper introduces OntoURL, a benchmark to evaluate LLMs' ability to handle ontologies, revealing their strengths in understanding but weaknesses in reasoning and learning symbolic knowledge.", "motivation": "To explore LLMs' underexplored capability in processing structured symbolic knowledge, specifically ontologies.", "method": "Proposes a taxonomy of LLMs' ontological capabilities and develops OntoURL, a benchmark with 15 tasks (58,981 questions) across 8 domains to assess understanding, reasoning, and learning.", "result": "Experiments with 20 LLMs show strong performance in understanding but significant weaknesses in reasoning and learning tasks.", "conclusion": "OntoURL highlights LLMs' limitations in symbolic knowledge processing and serves as a benchmark for future integration of LLMs with formal knowledge."}}
{"id": "2505.10856", "pdf": "https://arxiv.org/pdf/2505.10856", "abs": "https://arxiv.org/abs/2505.10856", "authors": ["Mengxuan Li", "Ke Liu", "Jialong Guo", "Jiajun Bu", "Hongwei Wang", "Haishuai Wang"], "title": "ImputeINR: Time Series Imputation via Implicit Neural Representations for Disease Diagnosis with Missing Data", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Healthcare data frequently contain a substantial proportion of missing\nvalues, necessitating effective time series imputation to support downstream\ndisease diagnosis tasks. However, existing imputation methods focus on discrete\ndata points and are unable to effectively model sparse data, resulting in\nparticularly poor performance for imputing substantial missing values. In this\npaper, we propose a novel approach, ImputeINR, for time series imputation by\nemploying implicit neural representations (INR) to learn continuous functions\nfor time series. ImputeINR leverages the merits of INR in that the continuous\nfunctions are not coupled to sampling frequency and have infinite sampling\nfrequency, allowing ImputeINR to generate fine-grained imputations even on\nextremely sparse observed values. Extensive experiments conducted on eight\ndatasets with five ratios of masked values show the superior imputation\nperformance of ImputeINR, especially for high missing ratios in time series\ndata. Furthermore, we validate that applying ImputeINR to impute missing values\nin healthcare data enhances the performance of downstream disease diagnosis\ntasks. Codes are available.", "AI": {"tldr": "ImputeINR uses implicit neural representations for continuous time series imputation, outperforming existing methods, especially for high missing ratios, and improves downstream disease diagnosis.", "motivation": "Healthcare data often have missing values, and current imputation methods struggle with sparse data and high missing ratios.", "method": "ImputeINR employs implicit neural representations (INR) to learn continuous functions for time series, enabling fine-grained imputation even with sparse data.", "result": "Experiments on eight datasets show ImputeINR's superior performance, particularly for high missing ratios, and it enhances downstream disease diagnosis tasks.", "conclusion": "ImputeINR is an effective solution for time series imputation in healthcare, improving both imputation accuracy and downstream task performance."}}
{"id": "2505.10869", "pdf": "https://arxiv.org/pdf/2505.10869", "abs": "https://arxiv.org/abs/2505.10869", "authors": ["Go Fukino", "Kanta Tachibana"], "title": "A Convolution-Based Gait Asymmetry Metric for Inter-Limb Synergistic Coordination", "categories": ["cs.CV", "cs.HC"], "comment": "7 pages, 13 figures, 3 tables", "summary": "This study focuses on the velocity patterns of various body parts during\nwalking and proposes a method for evaluating gait symmetry. Traditional motion\nanalysis studies have assessed gait symmetry based on differences in\nelectromyographic (EMG) signals or acceleration between the left and right\nsides. In contrast, this paper models intersegmental coordination using an LTI\nsystem and proposes a dissimilarity metric to evaluate symmetry. The method was\ntested on five subjects with both symmetric and asymmetric gait.", "AI": {"tldr": "The paper proposes a new method using an LTI system and a dissimilarity metric to evaluate gait symmetry, tested on five subjects.", "motivation": "Traditional gait symmetry assessments rely on EMG signals or acceleration differences, which may not fully capture intersegmental coordination.", "method": "The study models intersegmental coordination with an LTI system and introduces a dissimilarity metric for symmetry evaluation.", "result": "The method was validated on five subjects, including those with symmetric and asymmetric gait.", "conclusion": "The proposed approach offers a novel way to assess gait symmetry by focusing on intersegmental coordination."}}
{"id": "2505.11189", "pdf": "https://arxiv.org/pdf/2505.11189", "abs": "https://arxiv.org/abs/2505.11189", "authors": ["Francesco Sovrano"], "title": "Can Global XAI Methods Reveal Injected Bias in LLMs? SHAP vs Rule Extraction vs RuleSHAP", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Generative AI systems can help spread information but also misinformation and\nbiases, potentially undermining the UN Sustainable Development Goals (SDGs).\nExplainable AI (XAI) aims to reveal the inner workings of AI systems and expose\nmisbehaviours or biases. However, current XAI tools, built for simpler models,\nstruggle to handle the non-numerical nature of large language models (LLMs).\nThis paper examines the effectiveness of global XAI methods, such as\nrule-extraction algorithms and SHAP, in detecting bias in LLMs. To do so, we\nfirst show a text-to-ordinal mapping strategy to convert non-numerical\ninputs/outputs into numerical features, enabling these tools to identify (some)\nmisinformation-related biases in LLM-generated content. Then, we inject\nnon-linear biases of varying complexity (univariate, conjunctive, and\nnon-convex) into widespread LLMs like ChatGPT and Llama via system\ninstructions, using global XAI methods to detect them. This way, we found that\nRuleFit struggles with conjunctive and non-convex biases, while SHAP can\napproximate conjunctive biases but cannot express them as actionable rules.\nHence, we introduce RuleSHAP, a global rule extraction algorithm combining SHAP\nand RuleFit to detect more non-univariate biases, improving injected bias\ndetection over RuleFit by +94% (MRR@1) on average.", "AI": {"tldr": "The paper evaluates global XAI methods for detecting bias in LLMs, introduces a text-to-ordinal mapping strategy, and proposes RuleSHAP to improve bias detection.", "motivation": "Generative AI systems can spread misinformation and biases, threatening SDGs. Current XAI tools are inadequate for LLMs.", "method": "Uses text-to-ordinal mapping to enable XAI tools, injects biases into LLMs, and tests RuleFit and SHAP before introducing RuleSHAP.", "result": "RuleFit struggles with complex biases; SHAP approximates but can't express them. RuleSHAP improves detection by +94% (MRR@1).", "conclusion": "RuleSHAP enhances bias detection in LLMs, addressing limitations of existing XAI tools."}}
{"id": "2505.11080", "pdf": "https://arxiv.org/pdf/2505.11080", "abs": "https://arxiv.org/abs/2505.11080", "authors": ["Yapei Chang", "Yekyung Kim", "Michael Krumdick", "Amir Zadeh", "Chuan Li", "Chris Tanner", "Mohit Iyyer"], "title": "BLEUBERI: BLEU is a surprisingly effective reward for instruction following", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "28 pages, 11 figures, 15 tables", "summary": "Reward models are central to aligning LLMs with human preferences, but they\nare costly to train, requiring large-scale human-labeled preference data and\npowerful pretrained LLM backbones. Meanwhile, the increasing availability of\nhigh-quality synthetic instruction-following datasets raises the question: can\nsimpler, reference-based metrics serve as viable alternatives to reward models\nduring RL-based alignment? In this paper, we show first that BLEU, a basic\nstring-matching metric, surprisingly matches strong reward models in agreement\nwith human preferences on general instruction-following datasets. Based on this\ninsight, we develop BLEUBERI, a method that first identifies challenging\ninstructions and then applies Group Relative Policy Optimization (GRPO) using\nBLEU directly as the reward function. We demonstrate that BLEUBERI-trained\nmodels are competitive with models trained via reward model-guided RL across\nfour challenging instruction-following benchmarks and three different base\nlanguage models. A human evaluation further supports that the quality of\nBLEUBERI model outputs is on par with those from reward model-aligned models.\nMoreover, BLEUBERI models generate outputs that are more factually grounded\nthan competing methods. Overall, we show that given access to high-quality\nreference outputs (easily obtained via existing instruction-following datasets\nor synthetic data generation), string matching-based metrics are cheap yet\neffective proxies for reward models during alignment. We release our code and\ndata at https://github.com/lilakk/BLEUBERI.", "AI": {"tldr": "BLEUBERI uses BLEU as a reward function for RL-based alignment, matching reward models in performance and improving factual grounding.", "motivation": "High costs of training reward models and availability of synthetic datasets prompt exploration of simpler metrics like BLEU.", "method": "BLEUBERI identifies challenging instructions and applies GRPO using BLEU as the reward function.", "result": "BLEUBERI-trained models match reward model-aligned models in performance and improve factual grounding.", "conclusion": "String-matching metrics like BLEU are cost-effective alternatives to reward models for alignment."}}
{"id": "2505.10860", "pdf": "https://arxiv.org/pdf/2505.10860", "abs": "https://arxiv.org/abs/2505.10860", "authors": ["Huy Nguyen", "Thong T. Doan", "Quang Pham", "Nghi D. Q. Bui", "Nhat Ho", "Alessandro Rinaldo"], "title": "On DeepSeekMoE: Statistical Benefits of Shared Experts and Normalized Sigmoid Gating", "categories": ["cs.LG", "stat.ML"], "comment": "100 pages", "summary": "Mixture of experts (MoE) methods are a key component in most large language\nmodel architectures, including the recent series of DeepSeek models. Compared\nto other MoE implementations, DeepSeekMoE stands out because of two unique\nfeatures: the deployment of a shared expert strategy and of the normalized\nsigmoid gating mechanism. Despite the prominent role of DeepSeekMoE in the\nsuccess of the DeepSeek series of models, there have been only a few attempts\nto justify theoretically the value of the shared expert strategy, while its\nnormalized sigmoid gating has remained unexplored. To bridge this gap, we\nundertake a comprehensive theoretical study of these two features of\nDeepSeekMoE from a statistical perspective. We perform a convergence analysis\nof the expert estimation task to highlight the gains in sample efficiency for\nboth the shared expert strategy and the normalized sigmoid gating, offering\nuseful insights into the design of expert and gating structures. To verify\nempirically our theoretical findings, we carry out several experiments on both\nsynthetic data and real-world datasets for (vision) language modeling tasks.\nFinally, we conduct an extensive empirical analysis of the router behaviors,\nranging from router saturation, router change rate, to expert utilization.", "AI": {"tldr": "The paper theoretically and empirically analyzes DeepSeekMoE's shared expert strategy and normalized sigmoid gating, showing their benefits in sample efficiency and expert utilization.", "motivation": "To bridge the gap in theoretical understanding of DeepSeekMoE's unique features (shared expert strategy and normalized sigmoid gating) and justify their value.", "method": "Convergence analysis of expert estimation and empirical experiments on synthetic and real-world datasets for vision/language tasks.", "result": "Demonstrates gains in sample efficiency and provides insights into expert/gating design. Empirical analysis reveals router behaviors like saturation and utilization.", "conclusion": "The study validates the effectiveness of DeepSeekMoE's features, offering practical design insights for MoE architectures."}}
{"id": "2505.10875", "pdf": "https://arxiv.org/pdf/2505.10875", "abs": "https://arxiv.org/abs/2505.10875", "authors": ["Alexey Magay", "Dhurba Tripathi", "Yu Hao", "Yi Fang"], "title": "A Light and Smart Wearable Platform with Multimodal Foundation Model for Enhanced Spatial Reasoning in People with Blindness and Low Vision", "categories": ["cs.CV"], "comment": "Project website and code: https://dktpt44.github.io/LV-GPT/", "summary": "People with blindness and low vision (pBLV) face significant challenges,\nstruggling to navigate environments and locate objects due to limited visual\ncues. Spatial reasoning is crucial for these individuals, as it enables them to\nunderstand and interpret the spatial relationships in their surroundings,\nenhancing their ability to navigate and interact more safely and independently.\nCurrent multi-modal large language (MLLM) models for low vision people lack the\nspatial reasoning capabilities needed to effectively assist in these tasks.\nMoreover, there is a notable absence of lightweight, easy-to-use systems that\nallow pBLV to effectively perceive and interact with their surrounding\nenvironment. In this paper, we propose a novel spatial enhanced multi-modal\nlarge language model based approach for visually impaired individuals. By\nfine-tuning the MLLM to incorporate spatial reasoning capabilities, our method\nsignificantly improves the understanding of environmental context, which is\ncritical for navigation and object recognition. The innovation extends to a\nhardware component, designed as an attachment for glasses, ensuring increased\naccessibility and ease of use. This integration leverages advanced VLMs to\ninterpret visual data and provide real-time, spatially aware feedback to the\nuser. Our approach aims to bridge the gap between advanced machine learning\nmodels and practical, user-friendly assistive devices, offering a robust\nsolution for visually impaired users to navigate their surroundings more\neffectively and independently. The paper includes an in-depth evaluation using\nthe VizWiz dataset, demonstrating substantial improvements in accuracy and user\nexperience. Additionally, we design a comprehensive dataset to evaluate our\nmethod's effectiveness in realworld situations, demonstrating substantial\nimprovements in accuracy and user experience.", "AI": {"tldr": "A novel spatial-enhanced MLLM approach for visually impaired individuals improves navigation and object recognition by integrating spatial reasoning and a hardware attachment for glasses.", "motivation": "Current MLLM models lack spatial reasoning for pBLV, and there's a need for lightweight, user-friendly assistive systems.", "method": "Fine-tuning MLLM for spatial reasoning, integrating with a glasses attachment for real-time feedback.", "result": "Substantial improvements in accuracy and user experience, validated on VizWiz and a custom dataset.", "conclusion": "The approach bridges ML models and practical assistive devices, enhancing independence for visually impaired users."}}
{"id": "2505.11191", "pdf": "https://arxiv.org/pdf/2505.11191", "abs": "https://arxiv.org/abs/2505.11191", "authors": ["Kasra Borazjani", "Payam Abdisarabshali", "Fardis Nadimi", "Naji Khosravan", "Minghui Liwang", "Xianbin Wang", "Yiguang Hong", "Seyyedali Hosseinalipour"], "title": "Multi-Modal Multi-Task (M3T) Federated Foundation Models for Embodied AI: Potentials and Challenges for Edge Integration", "categories": ["cs.AI", "cs.RO"], "comment": "10 pages, 3 figures, 3 tables", "summary": "As embodied AI systems become increasingly multi-modal, personalized, and\ninteractive, they must learn effectively from diverse sensory inputs, adapt\ncontinually to user preferences, and operate safely under resource and privacy\nconstraints. These challenges expose a pressing need for machine learning\nmodels capable of swift, context-aware adaptation while balancing model\ngeneralization and personalization. Here, two methods emerge as suitable\ncandidates, each offering parts of these capabilities: Foundation Models (FMs)\nprovide a pathway toward generalization across tasks and modalities, whereas\nFederated Learning (FL) offers the infrastructure for distributed,\nprivacy-preserving model updates and user-level model personalization. However,\nwhen used in isolation, each of these approaches falls short of meeting the\ncomplex and diverse capability requirements of real-world embodied\nenvironments. In this vision paper, we introduce Federated Foundation Models\n(FFMs) for embodied AI, a new paradigm that unifies the strengths of\nmulti-modal multi-task (M3T) FMs with the privacy-preserving distributed nature\nof FL, enabling intelligent systems at the wireless edge. We collect critical\ndeployment dimensions of FFMs in embodied AI ecosystems under a unified\nframework, which we name \"EMBODY\": Embodiment heterogeneity, Modality richness\nand imbalance, Bandwidth and compute constraints, On-device continual learning,\nDistributed control and autonomy, and Yielding safety, privacy, and\npersonalization. For each, we identify concrete challenges and envision\nactionable research directions. We also present an evaluation framework for\ndeploying FFMs in embodied AI systems, along with the associated trade-offs.", "AI": {"tldr": "The paper proposes Federated Foundation Models (FFMs) for embodied AI, combining Foundation Models (FMs) and Federated Learning (FL) to address generalization, personalization, and privacy challenges.", "motivation": "The need for AI systems to learn from diverse inputs, adapt to user preferences, and operate safely under constraints like privacy and resource limitations.", "method": "Introduces FFMs, unifying multi-modal multi-task FMs with FL, and outlines a framework (EMBODY) to address deployment challenges.", "result": "A vision for FFMs in embodied AI, identifying challenges and research directions, along with an evaluation framework.", "conclusion": "FFMs offer a promising paradigm for embodied AI, balancing generalization, personalization, and privacy, with actionable research directions outlined."}}
{"id": "2505.11095", "pdf": "https://arxiv.org/pdf/2505.11095", "abs": "https://arxiv.org/abs/2505.11095", "authors": ["Lekang Jiang", "Pascal A Scherz", "Stephan Goetz"], "title": "Towards Better Evaluation for Generated Patent Claims", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025. 14 pages, 8 tables", "summary": "Patent claims define the scope of protection and establish the legal\nboundaries of an invention. Drafting these claims is a complex and\ntime-consuming process that usually requires the expertise of skilled patent\nattorneys, which can form a large access barrier for many small enterprises. To\nsolve these challenges, researchers have investigated the use of large language\nmodels (LLMs) for automating patent claim generation. However, existing studies\nhighlight inconsistencies between automated evaluation metrics and human expert\nassessments. To bridge this gap, we introduce Patent-CE, the first\ncomprehensive benchmark for evaluating patent claims. Patent-CE includes\ncomparative claim evaluations annotated by patent experts, focusing on five key\ncriteria: feature completeness, conceptual clarity, terminology consistency,\nlogical linkage, and overall quality. Additionally, we propose PatClaimEval, a\nnovel multi-dimensional evaluation method specifically designed for patent\nclaims. Our experiments demonstrate that PatClaimEval achieves the highest\ncorrelation with human expert evaluations across all assessment criteria among\nall tested metrics. This research provides the groundwork for more accurate\nevaluations of automated patent claim generation systems.", "AI": {"tldr": "Patent-CE is a benchmark for evaluating patent claims, addressing gaps in automated metrics by incorporating expert annotations and introducing PatClaimEval, a method that aligns closely with human assessments.", "motivation": "The complexity of drafting patent claims creates barriers for small enterprises, and existing automated methods lack alignment with human expert evaluations.", "method": "Introduces Patent-CE, a benchmark with expert-annotated evaluations, and PatClaimEval, a multi-dimensional evaluation method for patent claims.", "result": "PatClaimEval shows the highest correlation with human expert evaluations across all criteria.", "conclusion": "This work advances accurate evaluation of automated patent claim generation systems."}}
{"id": "2505.10861", "pdf": "https://arxiv.org/pdf/2505.10861", "abs": "https://arxiv.org/abs/2505.10861", "authors": ["Thang Duong", "Minglai Yang", "Chicheng Zhang"], "title": "Improving the Data-efficiency of Reinforcement Learning by Warm-starting with LLM", "categories": ["cs.LG"], "comment": "31 pages (9 for the main paper), 27 figures, NeurIPS 25 submission", "summary": "We investigate the usage of Large Language Model (LLM) in collecting\nhigh-quality data to warm-start Reinforcement Learning (RL) algorithms for\nlearning in some classical Markov Decision Process (MDP) environments. In this\nwork, we focus on using LLM to generate an off-policy dataset that sufficiently\ncovers state-actions visited by optimal policies, then later using an RL\nalgorithm to explore the environment and improve the policy suggested by the\nLLM. Our algorithm, LORO, can both converge to an optimal policy and have a\nhigh sample efficiency thanks to the LLM's good starting policy. On multiple\nOpenAI Gym environments, such as CartPole and Pendulum, we empirically\ndemonstrate that LORO outperforms baseline algorithms such as pure LLM-based\npolicies, pure RL, and a naive combination of the two, achieving up to $4\n\\times$ the cumulative rewards of the pure RL baseline.", "AI": {"tldr": "LORO uses LLMs to generate high-quality data for RL warm-starting, outperforming baselines in sample efficiency and cumulative rewards.", "motivation": "To improve RL sample efficiency by leveraging LLMs for generating optimal policy-like data.", "method": "LORO combines LLM-generated off-policy datasets with RL exploration to refine policies.", "result": "LORO achieves up to 4\u00d7 cumulative rewards of pure RL baselines in OpenAI Gym environments.", "conclusion": "LORO demonstrates the potential of LLMs in enhancing RL efficiency and performance."}}
{"id": "2505.10888", "pdf": "https://arxiv.org/pdf/2505.10888", "abs": "https://arxiv.org/abs/2505.10888", "authors": ["Saad Manzur", "Bryan Vela", "Brandon Vela", "Aditya Agrawal", "Lan-Anh Dang-Vu", "David Li", "Wayne Hayes"], "title": "PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation", "categories": ["cs.CV"], "comment": "https://github.com/bryanjvela/PoseLab3D/tree/submission_branch", "summary": "Reliable three-dimensional human pose estimation is becoming increasingly\nimportant for real-world applications, yet much of prior work has focused\nsolely on the performance within a single dataset. In practice, however,\nsystems must adapt to diverse viewpoints, environments, and camera setups --\nconditions that differ significantly from those encountered during training,\nwhich is often the case in real-world scenarios. To address these challenges,\nwe present a standardized testing environment in which each method is evaluated\non a variety of datasets, ensuring consistent and fair cross-dataset\ncomparisons -- allowing for the analysis of methods on previously unseen data.\nTherefore, we propose PoseBench3D, a unified framework designed to\nsystematically re-evaluate prior and future models across four of the most\nwidely used datasets for human pose estimation -- with the framework able to\nsupport novel and future datasets as the field progresses. Through a unified\ninterface, our framework provides datasets in a pre-configured yet easily\nmodifiable format, ensuring compatibility with diverse model architectures. We\nre-evaluated the work of 18 methods, either trained or gathered from existing\nliterature, and reported results using both Mean Per Joint Position Error\n(MPJPE) and Procrustes Aligned Mean Per Joint Position Error (PA-MPJPE)\nmetrics, yielding more than 100 novel cross-dataset evaluation results.\nAdditionally, we analyze performance differences resulting from various\npre-processing techniques and dataset preparation parameters -- offering\nfurther insight into model generalization capabilities.", "AI": {"tldr": "PoseBench3D is a standardized framework for evaluating 3D human pose estimation methods across diverse datasets, ensuring fair comparisons and analyzing generalization.", "motivation": "Prior work lacks adaptability to diverse real-world conditions; PoseBench3D addresses this by enabling cross-dataset evaluations.", "method": "Proposes PoseBench3D, a unified framework for evaluating models on four datasets, supporting future additions. Uses MPJPE and PA-MPJPE metrics.", "result": "Re-evaluated 18 methods, producing over 100 cross-dataset results, and analyzed preprocessing impacts on generalization.", "conclusion": "PoseBench3D provides a robust, adaptable tool for assessing model performance and generalization in 3D human pose estimation."}}
{"id": "2505.11208", "pdf": "https://arxiv.org/pdf/2505.11208", "abs": "https://arxiv.org/abs/2505.11208", "authors": ["Dongjun Kim", "Junwoo Park", "Chaehyeon Shin", "Jaeheon Jung", "Kyungho Shin", "Seungheon Baek", "Sanghyuk Heo", "Woongrae Kim", "Inchul Jeong", "Joohwan Cho", "Jongsun Park"], "title": "GLOVA: Global and Local Variation-Aware Analog Circuit Design with Risk-Sensitive Reinforcement Learning", "categories": ["cs.AI", "cs.CE", "cs.ET", "cs.LG"], "comment": "Accepted for DAC 2025", "summary": "Analog/mixed-signal circuit design encounters significant challenges due to\nperformance degradation from process, voltage, and temperature (PVT)\nvariations. To achieve commercial-grade reliability, iterative manual design\nrevisions and extensive statistical simulations are required. While several\nstudies have aimed to automate variation aware analog design to reduce\ntime-to-market, the substantial mismatches in real-world wafers have not been\nthoroughly addressed. In this paper, we present GLOVA, an analog circuit sizing\nframework that effectively manages the impact of diverse random mismatches to\nimprove robustness against PVT variations. In the proposed approach,\nrisk-sensitive reinforcement learning is leveraged to account for the\nreliability bound affected by PVT variations, and ensemble-based critic is\nintroduced to achieve sample-efficient learning. For design verification, we\nalso propose $\\mu$-$\\sigma$ evaluation and simulation reordering method to\nreduce simulation costs of identifying failed designs. GLOVA supports\nverification through industrial-level PVT variation evaluation methods,\nincluding corner simulation as well as global and local Monte Carlo (MC)\nsimulations. Compared to previous state-of-the-art variation-aware analog\nsizing frameworks, GLOVA achieves up to 80.5$\\times$ improvement in sample\nefficiency and 76.0$\\times$ reduction in time.", "AI": {"tldr": "GLOVA is a framework for analog circuit sizing that improves robustness against PVT variations using risk-sensitive reinforcement learning and ensemble-based critic, achieving significant efficiency gains.", "motivation": "Addressing performance degradation from PVT variations and mismatches in real-world wafers, which current automated methods fail to thoroughly handle.", "method": "Leverages risk-sensitive reinforcement learning and ensemble-based critic for sample-efficient learning, along with \u03bc-\u03c3 evaluation and simulation reordering for cost reduction.", "result": "Achieves up to 80.5\u00d7 improvement in sample efficiency and 76.0\u00d7 reduction in time compared to prior methods.", "conclusion": "GLOVA effectively manages PVT variations and mismatches, offering a robust and efficient solution for analog circuit design."}}
{"id": "2505.11140", "pdf": "https://arxiv.org/pdf/2505.11140", "abs": "https://arxiv.org/abs/2505.11140", "authors": ["Mike Zhang", "Johannes Bjerva", "Russa Biswas"], "title": "Scaling Reasoning can Improve Factuality in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent studies on large language model (LLM) reasoning capabilities have\ndemonstrated promising improvements in model performance by leveraging a\nlengthy thinking process and additional computational resources during\ninference, primarily in tasks involving mathematical reasoning (Muennighoff et\nal., 2025). However, it remains uncertain if longer reasoning chains inherently\nenhance factual accuracy, particularly beyond mathematical contexts. In this\nwork, we thoroughly examine LLM reasoning within complex open-domain\nquestion-answering (QA) scenarios. We initially distill reasoning traces from\nadvanced, large-scale reasoning models (QwQ-32B and DeepSeek-R1-671B), then\nfine-tune a variety of models ranging from smaller, instruction-tuned variants\nto larger architectures based on Qwen2.5. To enrich reasoning traces, we\nintroduce factual information from knowledge graphs in the form of paths into\nour reasoning traces. Our experimental setup includes four baseline approaches\nand six different instruction-tuned models evaluated across a benchmark of six\ndatasets, encompassing over 22.6K questions. Overall, we carry out 168\nexperimental runs and analyze approximately 1.7 million reasoning traces. Our\nfindings indicate that, within a single run, smaller reasoning models achieve\nnoticeable improvements in factual accuracy compared to their original\ninstruction-tuned counterparts. Moreover, our analysis demonstrates that adding\ntest-time compute and token budgets factual accuracy consistently improves by\n2-8%, further confirming the effectiveness of test-time scaling for enhancing\nperformance and consequently improving reasoning accuracy in open-domain QA\ntasks. We release all the experimental artifacts for further research.", "AI": {"tldr": "The paper investigates whether longer reasoning chains improve factual accuracy in LLMs beyond mathematical tasks, focusing on open-domain QA. It fine-tunes models with enriched reasoning traces and finds smaller models improve accuracy, with test-time compute further boosting performance by 2-8%.", "motivation": "To determine if extended reasoning chains enhance factual accuracy in LLMs, especially in open-domain QA, beyond just mathematical reasoning.", "method": "Distills reasoning traces from large models, fine-tunes various models, and enriches traces with knowledge graph paths. Evaluates on six datasets with 168 runs.", "result": "Smaller models show improved factual accuracy, and test-time compute boosts accuracy by 2-8%.", "conclusion": "Longer reasoning chains and test-time compute enhance factual accuracy in open-domain QA, with smaller models benefiting significantly."}}
{"id": "2505.10873", "pdf": "https://arxiv.org/pdf/2505.10873", "abs": "https://arxiv.org/abs/2505.10873", "authors": ["Filippo Leveni", "Luca Magri", "Cesare Alippi", "Giacomo Boracchi"], "title": "Hashing for Structure-based Anomaly Detection", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Image Analysis and Processing\n  (ICIAP 2023)", "summary": "We focus on the problem of identifying samples in a set that do not conform\nto structured patterns represented by low-dimensional manifolds. An effective\nway to solve this problem is to embed data in a high dimensional space, called\nPreference Space, where anomalies can be identified as the most isolated\npoints. In this work, we employ Locality Sensitive Hashing to avoid explicit\ncomputation of distances in high dimensions and thus improve Anomaly Detection\nefficiency. Specifically, we present an isolation-based anomaly detection\ntechnique designed to work in the Preference Space which achieves\nstate-of-the-art performance at a lower computational cost. Code is publicly\navailable at\nhttps://github.com/ineveLoppiliF/Hashing-for-Structure-based-Anomaly-Detection.", "AI": {"tldr": "The paper introduces an isolation-based anomaly detection method using Locality Sensitive Hashing in Preference Space for efficiency.", "motivation": "To identify anomalies in datasets by leveraging structured patterns and high-dimensional embeddings.", "method": "Uses Locality Sensitive Hashing to avoid explicit distance computations in high dimensions, improving efficiency.", "result": "Achieves state-of-the-art performance with lower computational cost.", "conclusion": "The proposed technique is effective and efficient for anomaly detection in structured datasets."}}
{"id": "2505.10902", "pdf": "https://arxiv.org/pdf/2505.10902", "abs": "https://arxiv.org/abs/2505.10902", "authors": ["Shuo Wang", "Tong Ren", "Nan Cheng", "Rong Wang", "Li Zhang"], "title": "Patient-Specific Dynamic Digital-Physical Twin for Coronary Intervention Training: An Integrated Mixed Reality Approach", "categories": ["cs.CV", "cs.HC", "92C50", "I.3.8; I.6.8"], "comment": "34 pages, 24 figures", "summary": "Background and Objective: Precise preoperative planning and effective\nphysician training for coronary interventions are increasingly important.\nDespite advances in medical imaging technologies, transforming static or\nlimited dynamic imaging data into comprehensive dynamic cardiac models remains\nchallenging. Existing training systems lack accurate simulation of cardiac\nphysiological dynamics. This study develops a comprehensive dynamic cardiac\nmodel research framework based on 4D-CTA, integrating digital twin technology,\ncomputer vision, and physical model manufacturing to provide precise,\npersonalized tools for interventional cardiology. Methods: Using 4D-CTA data\nfrom a 60-year-old female with three-vessel coronary stenosis, we segmented\ncardiac chambers and coronary arteries, constructed dynamic models, and\nimplemented skeletal skinning weight computation to simulate vessel deformation\nacross 20 cardiac phases. Transparent vascular physical models were\nmanufactured using medical-grade silicone. We developed cardiac output analysis\nand virtual angiography systems, implemented guidewire 3D reconstruction using\nbinocular stereo vision, and evaluated the system through angiography\nvalidation and CABG training applications. Results: Morphological consistency\nbetween virtual and real angiography reached 80.9%. Dice similarity\ncoefficients for guidewire motion ranged from 0.741-0.812, with mean trajectory\nerrors below 1.1 mm. The transparent model demonstrated advantages in CABG\ntraining, allowing direct visualization while simulating beating heart\nchallenges. Conclusion: Our patient-specific digital-physical twin approach\neffectively reproduces both anatomical structures and dynamic characteristics\nof coronary vasculature, offering a dynamic environment with visual and tactile\nfeedback valuable for education and clinical planning.", "AI": {"tldr": "A dynamic cardiac model framework using 4D-CTA and digital twin technology was developed for precise coronary intervention planning and training, achieving high accuracy in simulations and practical training applications.", "motivation": "To address the lack of accurate simulation of cardiac physiological dynamics in existing training systems and provide personalized tools for interventional cardiology.", "method": "Utilized 4D-CTA data to segment cardiac structures, construct dynamic models, and manufacture transparent vascular physical models. Developed cardiac output analysis, virtual angiography, and guidewire 3D reconstruction systems.", "result": "Achieved 80.9% morphological consistency in angiography, guidewire motion Dice coefficients of 0.741-0.812, and mean trajectory errors below 1.1 mm. The transparent model proved effective for CABG training.", "conclusion": "The patient-specific digital-physical twin approach successfully replicates coronary anatomy and dynamics, offering valuable visual and tactile feedback for education and clinical planning."}}
{"id": "2505.11227", "pdf": "https://arxiv.org/pdf/2505.11227", "abs": "https://arxiv.org/abs/2505.11227", "authors": ["Zhangying Feng", "Qianglong Chen", "Ning Lu", "Yongqian Li", "Siqi Cheng", "Shuangmu Peng", "Duyu Tang", "Shengcai Liu", "Zhirui Zhang"], "title": "Is PRM Necessary? Problem-Solving RL Implicitly Induces PRM Capability in LLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The development of reasoning capabilities represents a critical frontier in\nlarge language models (LLMs) research, where reinforcement learning (RL) and\nprocess reward models (PRMs) have emerged as predominant methodological\nframeworks. Contrary to conventional wisdom, empirical evidence from\nDeepSeek-R1 demonstrates that pure RL training focused on mathematical\nproblem-solving can progressively enhance reasoning abilities without PRM\nintegration, challenging the perceived necessity of process supervision. In\nthis study, we conduct a systematic investigation of the relationship between\nRL training and PRM capabilities. Our findings demonstrate that problem-solving\nproficiency and process supervision capabilities represent complementary\ndimensions of reasoning that co-evolve synergistically during pure RL training.\nIn particular, current PRMs underperform simple baselines like majority voting\nwhen applied to state-of-the-art models such as DeepSeek-R1 and QwQ-32B. To\naddress this limitation, we propose Self-PRM, an introspective framework in\nwhich models autonomously evaluate and rerank their generated solutions through\nself-reward mechanisms. Although Self-PRM consistently improves the accuracy of\nthe benchmark (particularly with larger sample sizes), analysis exposes\npersistent challenges: The approach exhibits low precision (<10\\%) on difficult\nproblems, frequently misclassifying flawed solutions as valid. These analyses\nunderscore the need for continued RL scaling to improve reward alignment and\nintrospective accuracy. Overall, our findings suggest that PRM may not be\nessential for enhancing complex reasoning, as pure RL not only improves\nproblem-solving skills but also inherently fosters robust PRM capabilities. We\nhope these findings provide actionable insights for building more reliable and\nself-aware complex reasoning models.", "AI": {"tldr": "Pure RL training enhances reasoning in LLMs without PRMs, challenging their necessity. Self-PRM improves accuracy but struggles with precision on hard problems.", "motivation": "To investigate if PRMs are essential for reasoning in LLMs and explore the synergy between RL training and PRM capabilities.", "method": "Systematic study of RL training and PRM capabilities, proposing Self-PRM for autonomous solution evaluation.", "result": "Pure RL improves reasoning and PRM capabilities; Self-PRM boosts accuracy but has low precision on difficult problems.", "conclusion": "PRMs may not be essential; pure RL fosters reasoning and PRM capabilities, though challenges remain in precision and reward alignment."}}
{"id": "2505.11166", "pdf": "https://arxiv.org/pdf/2505.11166", "abs": "https://arxiv.org/abs/2505.11166", "authors": ["Huashan Sun", "Shengyi Liao", "Yansen Han", "Yu Bai", "Yang Gao", "Cheng Fu", "Weizhou Shen", "Fanqi Wan", "Ming Yan", "Ji Zhang", "Fei Huang"], "title": "SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short-to-Long Preference Optimization", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite advances in pretraining with extended context lengths, large language\nmodels (LLMs) still face challenges in effectively utilizing real-world\nlong-context information, primarily due to insufficient long-context alignment\ncaused by data quality issues, training inefficiencies, and the lack of\nwell-designed optimization objectives. To address these limitations, we propose\na framework named $\\textbf{S}$h$\\textbf{o}$rt-to-$\\textbf{Lo}$ng\n$\\textbf{P}$reference $\\textbf{O}$ptimization ($\\textbf{SoLoPO}$), decoupling\nlong-context preference optimization (PO) into two components: short-context PO\nand short-to-long reward alignment (SoLo-RA), supported by both theoretical and\nempirical evidence. Specifically, short-context PO leverages preference pairs\nsampled from short contexts to enhance the model's contextual knowledge\nutilization ability. Meanwhile, SoLo-RA explicitly encourages reward score\nconsistency utilization for the responses when conditioned on both short and\nlong contexts that contain identical task-relevant information. This\nfacilitates transferring the model's ability to handle short contexts into\nlong-context scenarios. SoLoPO is compatible with mainstream preference\noptimization algorithms, while substantially improving the efficiency of data\nconstruction and training processes. Experimental results show that SoLoPO\nenhances all these algorithms with respect to stronger length and domain\ngeneralization abilities across various long-context benchmarks, while\nachieving notable improvements in both computational and memory efficiency.", "AI": {"tldr": "SoLoPO is a framework that decouples long-context preference optimization into short-context PO and short-to-long reward alignment, improving efficiency and performance in LLMs.", "motivation": "Addressing challenges in LLMs' long-context utilization due to data quality, training inefficiencies, and lack of optimization objectives.", "method": "Proposes SoLoPO, combining short-context PO and SoLo-RA to align rewards and transfer short-context abilities to long-context scenarios.", "result": "Enhances algorithms with better length and domain generalization, improving computational and memory efficiency.", "conclusion": "SoLoPO effectively improves LLMs' long-context utilization and training efficiency."}}
{"id": "2505.10874", "pdf": "https://arxiv.org/pdf/2505.10874", "abs": "https://arxiv.org/abs/2505.10874", "authors": ["Luca Magri", "Filippo Leveni", "Giacomo Boracchi"], "title": "MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted at Computer Vision and Pattern Recognition (CVPR 2021)", "summary": "We address the problem of recovering multiple structures of different classes\nin a dataset contaminated by noise and outliers. In particular, we consider\ngeometric structures defined by a mixture of underlying parametric models (e.g.\nplanes and cylinders, homographies and fundamental matrices), and we tackle the\nrobust fitting problem by preference analysis and clustering. We present a new\nalgorithm, termed MultiLink, that simultaneously deals with multiple classes of\nmodels. MultiLink combines on-the-fly model fitting and model selection in a\nnovel linkage scheme that determines whether two clusters are to be merged. The\nresulting method features many practical advantages with respect to methods\nbased on preference analysis, being faster, less sensitive to the inlier\nthreshold, and able to compensate limitations deriving from hypotheses\nsampling. Experiments on several public datasets demonstrate that Multi-Link\nfavourably compares with state of the art alternatives, both in multi-class and\nsingle-class problems. Code is publicly made available for download.", "AI": {"tldr": "MultiLink algorithm robustly fits multiple geometric structures in noisy datasets, outperforming state-of-the-art methods in speed and accuracy.", "motivation": "Recovering multiple geometric structures (e.g., planes, cylinders) in noisy datasets with outliers is challenging. Existing methods are slow and sensitive to thresholds.", "method": "MultiLink combines on-the-fly model fitting and selection via a novel linkage scheme to merge clusters, improving efficiency and robustness.", "result": "MultiLink is faster, less sensitive to inlier thresholds, and outperforms alternatives in multi-class and single-class problems.", "conclusion": "MultiLink offers a practical, efficient solution for robust geometric structure recovery, with publicly available code."}}
{"id": "2505.10917", "pdf": "https://arxiv.org/pdf/2505.10917", "abs": "https://arxiv.org/abs/2505.10917", "authors": ["Mingxiao Li", "Na Su", "Fang Qu", "Zhizhou Zhong", "Ziyang Chen", "Zhaopeng Tu", "Xiaolong Li"], "title": "VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization", "categories": ["cs.CV"], "comment": null, "summary": "Current multimodal large language models (MLLMs) face a critical challenge in\nmodality alignment, often exhibiting a bias towards textual information at the\nexpense of other modalities like vision. This paper conducts a systematic\ninformation-theoretic analysis of the widely used cross-entropy loss in MLLMs,\nuncovering its implicit alignment objective. Our theoretical investigation\nreveals that this implicit objective has inherent limitations, leading to a\ndegradation of cross-modal alignment as text sequence length increases, thereby\nhindering effective multimodal information fusion. To overcome these drawbacks,\nwe propose Vision-Text Alignment (VISTA), a novel approach guided by our\ntheoretical insights. VISTA introduces an explicit alignment objective designed\nto maximize cross-modal mutual information, preventing the degradation of\nvisual alignment. Notably, VISTA enhances the visual understanding capabilities\nof existing MLLMs without requiring any additional trainable modules or extra\ntraining data, making it both efficient and practical. Our method significantly\noutperforms baseline models across more than a dozen benchmark datasets,\nincluding VQAv2, MMStar, and MME, paving the way for new directions in MLLM\nmodal alignment research.", "AI": {"tldr": "The paper identifies a bias in multimodal large language models (MLLMs) favoring text over other modalities. It proposes VISTA, a novel method to improve cross-modal alignment without extra modules or data.", "motivation": "MLLMs struggle with modality alignment, often prioritizing text over vision, which limits effective multimodal fusion.", "method": "The paper analyzes the cross-entropy loss in MLLMs, revealing its limitations, and introduces VISTA, an explicit alignment objective to maximize cross-modal mutual information.", "result": "VISTA outperforms baselines on multiple benchmarks (e.g., VQAv2, MMStar, MME) without additional training resources.", "conclusion": "VISTA offers an efficient solution to improve MLLM alignment, advancing research in multimodal fusion."}}
{"id": "2505.11247", "pdf": "https://arxiv.org/pdf/2505.11247", "abs": "https://arxiv.org/abs/2505.11247", "authors": ["Mingxing Peng", "Yuting Xie", "Xusen Guo", "Ruoyu Yao", "Hai Yang", "Jun Ma"], "title": "LD-Scene: LLM-Guided Diffusion for Controllable Generation of Adversarial Safety-Critical Driving Scenarios", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": "13 pages, 5 figures", "summary": "Ensuring the safety and robustness of autonomous driving systems necessitates\na comprehensive evaluation in safety-critical scenarios. However, these\nsafety-critical scenarios are rare and difficult to collect from real-world\ndriving data, posing significant challenges to effectively assessing the\nperformance of autonomous vehicles. Typical existing methods often suffer from\nlimited controllability and lack user-friendliness, as extensive expert\nknowledge is essentially required. To address these challenges, we propose\nLD-Scene, a novel framework that integrates Large Language Models (LLMs) with\nLatent Diffusion Models (LDMs) for user-controllable adversarial scenario\ngeneration through natural language. Our approach comprises an LDM that\ncaptures realistic driving trajectory distributions and an LLM-based guidance\nmodule that translates user queries into adversarial loss functions,\nfacilitating the generation of scenarios aligned with user queries. The\nguidance module integrates an LLM-based Chain-of-Thought (CoT) code generator\nand an LLM-based code debugger, enhancing the controllability and robustness in\ngenerating guidance functions. Extensive experiments conducted on the nuScenes\ndataset demonstrate that LD-Scene achieves state-of-the-art performance in\ngenerating realistic, diverse, and effective adversarial scenarios.\nFurthermore, our framework provides fine-grained control over adversarial\nbehaviors, thereby facilitating more effective testing tailored to specific\ndriving scenarios.", "AI": {"tldr": "LD-Scene integrates LLMs and LDMs for user-controllable adversarial scenario generation in autonomous driving, improving realism and diversity.", "motivation": "Safety-critical scenarios are rare and hard to collect, making evaluation of autonomous vehicles challenging. Existing methods lack controllability and user-friendliness.", "method": "Combines Latent Diffusion Models (LDMs) for realistic trajectory distributions and LLMs to translate user queries into adversarial loss functions. Includes CoT code generator and debugger for robustness.", "result": "Achieves state-of-the-art performance in generating realistic, diverse, and effective adversarial scenarios on the nuScenes dataset.", "conclusion": "LD-Scene enhances controllability and robustness in scenario generation, enabling tailored testing for autonomous driving systems."}}
{"id": "2505.11177", "pdf": "https://arxiv.org/pdf/2505.11177", "abs": "https://arxiv.org/abs/2505.11177", "authors": ["Hrishit Madhavi", "Jacob Cherian", "Yuvraj Khamkar", "Dhananjay Bhagat"], "title": "Low-Resource Language Processing: An OCR-Driven Summarization and Translation Pipeline", "categories": ["cs.CL", "cs.AI", "68T50 (Natural language processing), 68U10 (Image processing)"], "comment": "8 pages, 7 figures, direct arXiv submission", "summary": "This paper presents an end-to-end suite for multilingual information\nextraction and processing from image-based documents. The system uses Optical\nCharacter Recognition (Tesseract) to extract text in languages such as English,\nHindi, and Tamil, and then a pipeline involving large language model APIs\n(Gemini) for cross-lingual translation, abstractive summarization, and\nre-translation into a target language. Additional modules add sentiment\nanalysis (TensorFlow), topic classification (Transformers), and date extraction\n(Regex) for better document comprehension. Made available in an accessible\nGradio interface, the current research shows a real-world application of\nlibraries, models, and APIs to close the language gap and enhance access to\ninformation in image media across different linguistic environments", "AI": {"tldr": "An end-to-end multilingual system for extracting and processing text from image-based documents, leveraging OCR, LLMs, and additional NLP modules, with a Gradio interface for accessibility.", "motivation": "To bridge the language gap and improve access to information in image media across diverse linguistic environments.", "method": "Uses Tesseract OCR for text extraction, Gemini for translation/summarization, and additional modules (sentiment analysis, topic classification, date extraction) for enhanced comprehension.", "result": "Demonstrates a practical application combining libraries, models, and APIs to process multilingual documents effectively.", "conclusion": "The system successfully enhances accessibility and comprehension of image-based documents in multiple languages."}}
{"id": "2505.10876", "pdf": "https://arxiv.org/pdf/2505.10876", "abs": "https://arxiv.org/abs/2505.10876", "authors": ["Filippo Leveni", "Luca Magri", "Cesare Alippi", "Giacomo Boracchi"], "title": "Preference Isolation Forest for Structure-based Anomaly Detection", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Submitted to Pattern Recognition", "summary": "We address the problem of detecting anomalies as samples that do not conform\nto structured patterns represented by low-dimensional manifolds. To this end,\nwe conceive a general anomaly detection framework called Preference Isolation\nForest (PIF), that combines the benefits of adaptive isolation-based methods\nwith the flexibility of preference embedding. The key intuition is to embed the\ndata into a high-dimensional preference space by fitting low-dimensional\nmanifolds, and to identify anomalies as isolated points. We propose three\nisolation approaches to identify anomalies: $i$) Voronoi-iForest, the most\ngeneral solution, $ii$) RuzHash-iForest, that avoids explicit computation of\ndistances via Local Sensitive Hashing, and $iii$) Sliding-PIF, that leverages a\nlocality prior to improve efficiency and effectiveness.", "AI": {"tldr": "PIF framework detects anomalies by embedding data into a preference space and isolating outliers using three methods: Voronoi-iForest, RuzHash-iForest, and Sliding-PIF.", "motivation": "Detecting anomalies as samples deviating from low-dimensional manifolds.", "method": "Combines adaptive isolation-based methods with preference embedding, proposing three isolation approaches.", "result": "Anomalies are identified as isolated points in the preference space.", "conclusion": "PIF offers a flexible and efficient framework for anomaly detection."}}
{"id": "2505.10921", "pdf": "https://arxiv.org/pdf/2505.10921", "abs": "https://arxiv.org/abs/2505.10921", "authors": ["Junyi Yuan", "Jian Zhang", "Fangyu Wu", "Dongming Lu", "Huanda Lu", "Qiufeng Wang"], "title": "Towards Cross-modal Retrieval in Chinese Cultural Heritage Documents: Dataset and Solution", "categories": ["cs.CV"], "comment": null, "summary": "China has a long and rich history, encompassing a vast cultural heritage that\nincludes diverse multimodal information, such as silk patterns, Dunhuang\nmurals, and their associated historical narratives. Cross-modal retrieval plays\na pivotal role in understanding and interpreting Chinese cultural heritage by\nbridging visual and textual modalities to enable accurate text-to-image and\nimage-to-text retrieval. However, despite the growing interest in multimodal\nresearch, there is a lack of specialized datasets dedicated to Chinese cultural\nheritage, limiting the development and evaluation of cross-modal learning\nmodels in this domain. To address this gap, we propose a multimodal dataset\nnamed CulTi, which contains 5,726 image-text pairs extracted from two series of\nprofessional documents, respectively related to ancient Chinese silk and\nDunhuang murals. Compared to existing general-domain multimodal datasets, CulTi\npresents a challenge for cross-modal retrieval: the difficulty of local\nalignment between intricate decorative motifs and specialized textual\ndescriptions. To address this challenge, we propose LACLIP, a training-free\nlocal alignment strategy built upon a fine-tuned Chinese-CLIP. LACLIP enhances\nthe alignment of global textual descriptions with local visual regions by\ncomputing weighted similarity scores during inference. Experimental results on\nCulTi demonstrate that LACLIP significantly outperforms existing models in\ncross-modal retrieval, particularly in handling fine-grained semantic\nassociations within Chinese cultural heritage.", "AI": {"tldr": "The paper introduces CulTi, a multimodal dataset for Chinese cultural heritage, and LACLIP, a training-free local alignment method for cross-modal retrieval, outperforming existing models.", "motivation": "The lack of specialized datasets for Chinese cultural heritage limits cross-modal learning. CulTi and LACLIP aim to bridge this gap.", "method": "Proposes CulTi dataset (5,726 image-text pairs) and LACLIP, a local alignment strategy using a fine-tuned Chinese-CLIP for weighted similarity scoring.", "result": "LACLIP significantly outperforms existing models in cross-modal retrieval, especially for fine-grained semantic associations.", "conclusion": "CulTi and LACLIP advance cross-modal retrieval for Chinese cultural heritage, addressing local alignment challenges."}}
{"id": "2505.11274", "pdf": "https://arxiv.org/pdf/2505.11274", "abs": "https://arxiv.org/abs/2505.11274", "authors": ["Zheng Li", "Qingxiu Dong", "Jingyuan Ma", "Di Zhang", "Zhifang Sui"], "title": "SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recently, large reasoning models demonstrate exceptional performance on\nvarious tasks. However, reasoning models inefficiently over-process both\ntrivial and complex queries, leading to resource waste and prolonged user\nlatency. To address this challenge, we propose SelfBudgeter - a self-adaptive\ncontrollable reasoning strategy for efficient reasoning. Our approach adopts a\ndual-phase training paradigm: first, the model learns to pre-estimate the\nreasoning cost based on the difficulty of the query. Then, we introduce\nbudget-guided GPRO for reinforcement learning, which effectively maintains\naccuracy while reducing output length. SelfBudgeter allows users to anticipate\ngeneration time and make informed decisions about continuing or interrupting\nthe process. Furthermore, our method enables direct manipulation of reasoning\nlength via pre-filling token budget. Experimental results demonstrate that\nSelfBudgeter can rationally allocate budgets according to problem complexity,\nachieving up to 74.47% response length compression on the MATH benchmark while\nmaintaining nearly undiminished accuracy.", "AI": {"tldr": "SelfBudgeter is a self-adaptive strategy for efficient reasoning, reducing resource waste by pre-estimating query difficulty and using budget-guided reinforcement learning to maintain accuracy while compressing response length.", "motivation": "Large reasoning models inefficiently process both trivial and complex queries, wasting resources and increasing latency.", "method": "Dual-phase training: pre-estimating reasoning cost and budget-guided GPRO for reinforcement learning to control output length.", "result": "Achieves up to 74.47% response length compression on MATH benchmark with nearly undiminished accuracy.", "conclusion": "SelfBudgeter efficiently allocates budgets based on problem complexity, improving resource use and user control."}}
{"id": "2505.11199", "pdf": "https://arxiv.org/pdf/2505.11199", "abs": "https://arxiv.org/abs/2505.11199", "authors": ["Chris K\u00f6cher", "Alexander Kozachinskiy", "Anthony Widjaja Lin", "Marco S\u00e4lzer", "Georg Zetzsche"], "title": "NoPE: The Counting Power of Transformers with No Positional Encodings", "categories": ["cs.CL", "cs.FL", "cs.LG"], "comment": null, "summary": "Positional Encodings (PEs) seem to be indispensable for ensuring\nexpressiveness of transformers; without them attention transformers reduce to a\nbag-of-word model. NoPE-transformers (i.e. with No PEs) with unique hard\nattention mechanisms were very recently shown to only be able to express\nregular languages, i.e., with limited counting ability. This paper shows that,\nwith average hard attention mechanisms, NoPE-transformers are still\nsurprisingly expressive: they can express counting languages corresponding to\nnonnegative integer solutions to multivariate polynomial equations (i.e.\nDiophantine equations), reasoning about which is well-known to be undecidable.\nIn fact, we provide a precise characterization of languages expressible by\nAverage Hard Attention NoPE-Transformers (NoPE-AHATs): they correspond\nprecisely to what we call \\emph{semi-algebraic sets}, i.e., finite unions of\nsets of nonnegative integer solutions to systems of multivariate polynomial\ninequations. We obtain several interesting consequences of our\ncharacterization. Firstly, NoPE-transformers can express counting properties\nthat are far more complex than established models like simplified counter\nmachines and Petri nets, but cannot express a very simple counting property of\nPARITY. Secondly, the problem of analyzing NoPE-transformers is undecidable,\ne.g., whether a given NoPE transformer classifies all input strings in one\nclass. To complement our results, we exhibit a counting language that is not\nexpressible by average hard attention transformers even with arbitrary PEs but\nis expressible in the circuit complexity class TC$^0$, answering an open\nproblem.", "AI": {"tldr": "NoPE-transformers with average hard attention can express complex counting languages (semi-algebraic sets) but not simple ones like PARITY, and their analysis is undecidable.", "motivation": "To explore the expressiveness of NoPE-transformers with average hard attention, challenging the assumption that positional encodings are essential for transformers.", "method": "Characterizes languages expressible by NoPE-AHATs as semi-algebraic sets, comparing them to other models like counter machines and Petri nets.", "result": "NoPE-AHATs can solve Diophantine equations (undecidable problems) but fail at simple tasks like PARITY; their analysis is undecidable.", "conclusion": "NoPE-transformers with average hard attention are surprisingly expressive but limited in certain tasks, and their undecidability complicates analysis."}}
{"id": "2505.10877", "pdf": "https://arxiv.org/pdf/2505.10877", "abs": "https://arxiv.org/abs/2505.10877", "authors": ["Mathieu Alain", "So Takao", "Xiaowen Dong", "Bastian Rieck", "Emmanuel Noutahi"], "title": "Graph and Simplicial Complex Prediction Gaussian Process via the Hodgelet Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting the labels of graph-structured data is crucial in scientific\napplications and is often achieved using graph neural networks (GNNs). However,\nwhen data is scarce, GNNs suffer from overfitting, leading to poor performance.\nRecently, Gaussian processes (GPs) with graph-level inputs have been proposed\nas an alternative. In this work, we extend the Gaussian process framework to\nsimplicial complexes (SCs), enabling the handling of edge-level attributes and\nattributes supported on higher-order simplices. We further augment the\nresulting SC representations by considering their Hodge decompositions,\nallowing us to account for homological information, such as the number of\nholes, in the SC. We demonstrate that our framework enhances the predictions\nacross various applications, paving the way for GPs to be more widely used for\ngraph and SC-level predictions.", "AI": {"tldr": "Extending Gaussian processes to simplicial complexes for better graph-level predictions, especially with scarce data.", "motivation": "GNNs overfit with scarce data; GPs offer an alternative but need extension to handle higher-order graph structures like simplicial complexes.", "method": "Extend GPs to simplicial complexes, incorporate Hodge decompositions to capture homological information (e.g., holes).", "result": "Improved predictions across applications, enabling broader use of GPs for graph and SC-level tasks.", "conclusion": "The framework enhances GP applicability for graph-structured data, addressing GNN limitations in data-scarce scenarios."}}
{"id": "2505.10931", "pdf": "https://arxiv.org/pdf/2505.10931", "abs": "https://arxiv.org/abs/2505.10931", "authors": ["Chao Wang", "Wei Lu", "Xiang Li", "Jian Yang", "Lei Luo"], "title": "M4-SAR: A Multi-Resolution, Multi-Polarization, Multi-Scene, Multi-Source Dataset and Benchmark for Optical-SAR Fusion Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Single-source remote sensing object detection using optical or SAR images\nstruggles in complex environments. Optical images offer rich textural details\nbut are often affected by low-light, cloud-obscured, or low-resolution\nconditions, reducing the detection performance. SAR images are robust to\nweather, but suffer from speckle noise and limited semantic expressiveness.\nOptical and SAR images provide complementary advantages, and fusing them can\nsignificantly improve the detection accuracy. However, progress in this field\nis hindered by the lack of large-scale, standardized datasets. To address these\nchallenges, we propose the first comprehensive dataset for optical-SAR fusion\nobject detection, named Multi-resolution, Multi-polarization, Multi-scene,\nMulti-source SAR dataset (M4-SAR). It contains 112,184 precisely aligned image\npairs and nearly one million labeled instances with arbitrary orientations,\nspanning six key categories. To enable standardized evaluation, we develop a\nunified benchmarking toolkit that integrates six state-of-the-art multi-source\nfusion methods. Furthermore, we propose E2E-OSDet, a novel end-to-end\nmulti-source fusion detection framework that mitigates cross-domain\ndiscrepancies and establishes a robust baseline for future studies. Extensive\nexperiments on M4-SAR demonstrate that fusing optical and SAR data can improve\n$mAP$ by 5.7\\% over single-source inputs, with particularly significant gains\nin complex environments. The dataset and code are publicly available at\nhttps://github.com/wchao0601/M4-SAR.", "AI": {"tldr": "The paper introduces M4-SAR, a large-scale dataset for optical-SAR fusion object detection, and proposes E2E-OSDet, a framework improving detection accuracy by 5.7% over single-source methods.", "motivation": "Single-source remote sensing (optical or SAR) struggles in complex environments due to limitations like weather effects or noise. Fusion of both can improve accuracy, but lacks standardized datasets.", "method": "The authors create M4-SAR, a dataset with 112,184 aligned optical-SAR pairs and nearly one million labeled instances. They also propose E2E-OSDet, an end-to-end fusion framework, and a benchmarking toolkit.", "result": "Fusing optical and SAR data improves mAP by 5.7%, especially in complex environments.", "conclusion": "M4-SAR and E2E-OSDet address dataset and method gaps, providing a robust baseline for future optical-SAR fusion research."}}
{"id": "2505.11289", "pdf": "https://arxiv.org/pdf/2505.11289", "abs": "https://arxiv.org/abs/2505.11289", "authors": ["Reginald McLean", "Evangelos Chatzaroulas", "Luc McCutcheon", "Frank R\u00f6der", "Tianhe Yu", "Zhanpeng He", "K. R. Zentner", "Ryan Julian", "J K Terry", "Isaac Woungang", "Nariman Farsad", "Pablo Samuel Castro"], "title": "Meta-World+: An Improved, Standardized, RL Benchmark", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Meta-World is widely used for evaluating multi-task and meta-reinforcement\nlearning agents, which are challenged to master diverse skills simultaneously.\nSince its introduction however, there have been numerous undocumented changes\nwhich inhibit a fair comparison of algorithms. This work strives to\ndisambiguate these results from the literature, while also leveraging the past\nversions of Meta-World to provide insights into multi-task and\nmeta-reinforcement learning benchmark design. Through this process we release a\nnew open-source version of Meta-World\n(https://github.com/Farama-Foundation/Metaworld/) that has full reproducibility\nof past results, is more technically ergonomic, and gives users more control\nover the tasks that are included in a task set.", "AI": {"tldr": "The paper clarifies undocumented changes in Meta-World, releases a new version for reproducibility, and improves usability.", "motivation": "To address inconsistencies in Meta-World evaluations and improve benchmark design for multi-task and meta-reinforcement learning.", "method": "Analyzed past versions of Meta-World, resolved ambiguities, and developed a new open-source version with enhanced features.", "result": "A reproducible, ergonomic, and customizable version of Meta-World is released.", "conclusion": "The new Meta-World version ensures fair comparisons and better control for users, advancing multi-task and meta-reinforcement learning research."}}
{"id": "2505.11225", "pdf": "https://arxiv.org/pdf/2505.11225", "abs": "https://arxiv.org/abs/2505.11225", "authors": ["Chengyu Huang", "Zhengxin Zhang", "Claire Cardie"], "title": "HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "While scaling the length of responses at test-time has been shown to markedly\nimprove the reasoning abilities and performance of large language models\n(LLMs), it often results in verbose outputs and increases inference cost. Prior\napproaches for efficient test-time scaling, typically using universal budget\nconstraints or query-level length optimization, do not leverage historical\ninformation from previous encounters with the same problem during training. We\nhypothesize that this limits their ability to progressively make solutions more\nconcise over time. To address this, we present History-Aware Policy\nOptimization (HAPO), which keeps track of a history state (e.g., the minimum\nlength over previously generated correct responses) for each problem. HAPO\nemploys a novel length reward function based on this history state to\nincentivize the discovery of correct solutions that are more concise than those\npreviously found. Crucially, this reward structure avoids overly penalizing\nshorter incorrect responses with the goal of facilitating exploration towards\nmore efficient solutions. By combining this length reward with a correctness\nreward, HAPO jointly optimizes for correctness and efficiency. We use HAPO to\ntrain DeepSeek-R1-Distill-Qwen-1.5B, DeepScaleR-1.5B-Preview, and\nQwen-2.5-1.5B-Instruct, and evaluate HAPO on several math benchmarks that span\nvarious difficulty levels. Experiment results demonstrate that HAPO effectively\ninduces LLMs' concise reasoning abilities, producing length reductions of\n33-59% with accuracy drops of only 2-5%.", "AI": {"tldr": "HAPO improves LLM efficiency by tracking historical response lengths and optimizing for conciseness without significant accuracy loss.", "motivation": "Prior methods for efficient test-time scaling lack historical context, limiting conciseness over time.", "method": "HAPO uses a history state and length reward to incentivize shorter, correct solutions, combined with correctness optimization.", "result": "HAPO reduces response lengths by 33-59% with only 2-5% accuracy drop on math benchmarks.", "conclusion": "HAPO effectively balances correctness and efficiency, enhancing LLM conciseness."}}
{"id": "2505.10880", "pdf": "https://arxiv.org/pdf/2505.10880", "abs": "https://arxiv.org/abs/2505.10880", "authors": ["Guoji Fu", "Wee Sun Lee"], "title": "Approximation and Generalization Abilities of Score-based Neural Network Generative Models for Sub-Gaussian Distributions", "categories": ["cs.LG", "stat.ML"], "comment": "94 pages", "summary": "This paper studies the approximation and generalization abilities of\nscore-based neural network generative models (SGMs) in estimating an unknown\ndistribution $P_0$ from $n$ i.i.d. observations in $d$ dimensions. Assuming\nmerely that $P_0$ is $\\alpha$-sub-Gaussian, we prove that for any time step $t\n\\in [t_0, n^{O(1)}]$, where $t_0 \\geq O(\\alpha^2n^{-2/d}\\log n)$, there exists\na deep ReLU neural network with width $\\leq O(\\log^3n)$ and depth $\\leq\nO(n^{3/d}\\log_2n)$ that can approximate the scores with $\\tilde{O}(n^{-1})$\nmean square error and achieve a nearly optimal rate of\n$\\tilde{O}(n^{-1}t_0^{-d/2})$ for score estimation, as measured by the score\nmatching loss. Our framework is universal and can be used to establish\nconvergence rates for SGMs under milder assumptions than previous work. For\nexample, assuming further that the target density function $p_0$ lies in\nSobolev or Besov classes, with an appropriately early stopping strategy, we\ndemonstrate that neural network-based SGMs can attain nearly minimax\nconvergence rates up to logarithmic factors. Our analysis removes several\ncrucial assumptions, such as Lipschitz continuity of the score function or a\nstrictly positive lower bound on the target density.", "AI": {"tldr": "The paper analyzes the approximation and generalization capabilities of score-based neural network generative models (SGMs) for estimating an unknown distribution, achieving nearly optimal convergence rates under mild assumptions.", "motivation": "The study aims to understand the theoretical performance of SGMs in distribution estimation, relaxing stringent assumptions like Lipschitz continuity or strict positivity of the target density.", "method": "The authors use deep ReLU neural networks with specific width and depth constraints to approximate scores, employing an early stopping strategy for convergence.", "result": "They prove nearly optimal mean square error and score matching loss rates, even under weaker assumptions like sub-Gaussianity or Sobolev/Besov class densities.", "conclusion": "The framework is universal and improves upon previous work by removing restrictive assumptions, demonstrating SGMs' robustness in distribution estimation."}}
{"id": "2505.10996", "pdf": "https://arxiv.org/pdf/2505.10996", "abs": "https://arxiv.org/abs/2505.10996", "authors": ["Yunkang Cao", "Yuqi Cheng", "Xiaohao Xu", "Yiheng Zhang", "Yihan Sun", "Yuxiang Tan", "Yuxin Zhang", "Xiaonan Huang", "Weiming Shen"], "title": "Visual Anomaly Detection under Complex View-Illumination Interplay: A Large-Scale Benchmark", "categories": ["cs.CV"], "comment": "Homgepage: https://hustcyq.github.io/M2AD/. Yunkang Cao and Yuqi\n  Cheng contribute equally to this work", "summary": "The practical deployment of Visual Anomaly Detection (VAD) systems is\nhindered by their sensitivity to real-world imaging variations, particularly\nthe complex interplay between viewpoint and illumination which drastically\nalters defect visibility. Current benchmarks largely overlook this critical\nchallenge. We introduce Multi-View Multi-Illumination Anomaly Detection (M2AD),\na new large-scale benchmark comprising 119,880 high-resolution images designed\nexplicitly to probe VAD robustness under such interacting conditions. By\nsystematically capturing 999 specimens across 10 categories using 12\nsynchronized views and 10 illumination settings (120 configurations total),\nM2AD enables rigorous evaluation. We establish two evaluation protocols:\nM2AD-Synergy tests the ability to fuse information across diverse\nconfigurations, and M2AD-Invariant measures single-image robustness against\nrealistic view-illumination effects. Our extensive benchmarking shows that\nstate-of-the-art VAD methods struggle significantly on M2AD, demonstrating the\nprofound challenge posed by view-illumination interplay. This benchmark serves\nas an essential tool for developing and validating VAD methods capable of\novercoming real-world complexities. Our full dataset and test suite will be\nreleased at https://hustcyq.github.io/M2AD to facilitate the field.", "AI": {"tldr": "M2AD is a new benchmark for Visual Anomaly Detection (VAD) to test robustness under varying viewpoints and illumination, showing current methods struggle with these real-world complexities.", "motivation": "Current VAD systems are sensitive to real-world imaging variations like viewpoint and illumination, which are overlooked in existing benchmarks.", "method": "M2AD introduces a large-scale dataset (119,880 images) with 120 configurations (12 views, 10 illuminations) and two evaluation protocols: M2AD-Synergy and M2AD-Invariant.", "result": "State-of-the-art VAD methods perform poorly on M2AD, highlighting the challenge of view-illumination interplay.", "conclusion": "M2AD is a critical tool for advancing VAD methods to handle real-world complexities, with the dataset publicly available."}}
{"id": "2505.11451", "pdf": "https://arxiv.org/pdf/2505.11451", "abs": "https://arxiv.org/abs/2505.11451", "authors": ["Lee Harris", "James Bentham", "Philippe De Wilde"], "title": "Extracting Explainable Dates From Medical Images By Reverse-Engineering UNIX Timestamps", "categories": ["cs.AI"], "comment": null, "summary": "Dates often contribute towards highly impactful medical decisions, but it is\nrarely clear how to extract this data. AI has only just begun to be used\ntranscribe such documents, and common methods are either to trust that the\noutput produced by a complex AI model, or to parse the text using regular\nexpressions. Recent work has established that regular expressions are an\nexplainable form of logic, but it is difficult to decompose these into the\ncomponent parts that are required to construct precise UNIX timestamps. First,\nwe test publicly-available regular expressions, and we found that these were\nunable to capture a significant number of our dates. Next, we manually created\neasily-decomposable regular expressions, and we found that these were able to\ndetect the majority of real dates, but also a lot of sequences of text that\nlook like dates. Finally, we used regular expression synthesis to automatically\nidentify regular expressions from the reverse-engineered UNIX timestamps that\nwe created. We find that regular expressions created by regular expression\nsynthesis detect far fewer sequences of text that look like dates than those\nthat were manually created, at the cost of a slight increase to the number of\nmissed dates. Overall, our results show that regular expressions can be created\nthrough regular expression synthesis to identify complex dates and date ranges\nin text transcriptions. To our knowledge, our proposed way of learning\ndeterministic logic by reverse-engineering several many-one mappings and\nfeeding these into a regular expression synthesiser is a new approach.", "AI": {"tldr": "The paper explores using regular expression synthesis to improve date extraction from medical documents, balancing precision and recall.", "motivation": "Dates are crucial for medical decisions, but extracting them accurately is challenging. Existing methods (AI models or regex) lack precision or explainability.", "method": "Tested public regex, created manual regex, and used regex synthesis to generate better patterns from reverse-engineered UNIX timestamps.", "result": "Synthesized regex reduced false positives (text resembling dates) but slightly increased missed dates compared to manual regex.", "conclusion": "Regex synthesis can effectively identify complex dates in text, offering a novel approach to learning deterministic logic."}}
{"id": "2505.11271", "pdf": "https://arxiv.org/pdf/2505.11271", "abs": "https://arxiv.org/abs/2505.11271", "authors": ["Camille Couturier", "Spyros Mastorakis", "Haiying Shen", "Saravan Rajmohan", "Victor R\u00fchle"], "title": "Semantic Caching of Contextual Summaries for Efficient Question-Answering with Language Models", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "I.2.7"], "comment": "Preprint. Paper accepted at ICCCN 2025, the final version will appear\n  in the proceedings", "summary": "Large Language Models (LLMs) are increasingly deployed across edge and cloud\nplatforms for real-time question-answering and retrieval-augmented generation.\nHowever, processing lengthy contexts in distributed systems incurs high\ncomputational overhead, memory usage, and network bandwidth. This paper\nintroduces a novel semantic caching approach for storing and reusing\nintermediate contextual summaries, enabling efficient information reuse across\nsimilar queries in LLM-based QA workflows. Our method reduces redundant\ncomputations by up to 50-60% while maintaining answer accuracy comparable to\nfull document processing, as demonstrated on NaturalQuestions, TriviaQA, and a\nsynthetic ArXiv dataset. This approach balances computational cost and response\nquality, critical for real-time AI assistants.", "AI": {"tldr": "A semantic caching method for LLMs reduces redundant computations by 50-60% while maintaining accuracy in QA workflows.", "motivation": "Addressing high computational overhead, memory usage, and network bandwidth in distributed LLM systems for real-time QA.", "method": "Introduces semantic caching to store and reuse intermediate contextual summaries for similar queries.", "result": "Reduces redundant computations by 50-60% with comparable accuracy to full processing, tested on NaturalQuestions, TriviaQA, and ArXiv.", "conclusion": "Balances computational cost and response quality, crucial for real-time AI assistants."}}
{"id": "2505.10881", "pdf": "https://arxiv.org/pdf/2505.10881", "abs": "https://arxiv.org/abs/2505.10881", "authors": ["Donghyeon Ki", "JunHyeok Oh", "Seong-Woong Shim", "Byung-Jun Lee"], "title": "Prior-Guided Diffusion Planning for Offline Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models have recently gained prominence in offline reinforcement\nlearning due to their ability to effectively learn high-performing,\ngeneralizable policies from static datasets. Diffusion-based planners\nfacilitate long-horizon decision-making by generating high-quality trajectories\nthrough iterative denoising, guided by return-maximizing objectives. However,\nexisting guided sampling strategies such as Classifier Guidance,\nClassifier-Free Guidance, and Monte Carlo Sample Selection either produce\nsuboptimal multi-modal actions, struggle with distributional drift, or incur\nprohibitive inference-time costs. To address these challenges, we propose Prior\nGuidance (PG), a novel guided sampling framework that replaces the standard\nGaussian prior of a behavior-cloned diffusion model with a learnable\ndistribution, optimized via a behavior-regularized objective. PG directly\ngenerates high-value trajectories without costly reward optimization of the\ndiffusion model itself, and eliminates the need to sample multiple candidates\nat inference for sample selection. We present an efficient training strategy\nthat applies behavior regularization in latent space, and empirically\ndemonstrate that PG outperforms state-of-the-art diffusion policies and\nplanners across diverse long-horizon offline RL benchmarks.", "AI": {"tldr": "The paper introduces Prior Guidance (PG), a novel guided sampling framework for diffusion models in offline RL, addressing issues like suboptimal actions and high inference costs by replacing the Gaussian prior with a learnable distribution.", "motivation": "Existing guided sampling strategies in diffusion models for offline RL suffer from suboptimal multi-modal actions, distributional drift, or high inference-time costs.", "method": "PG replaces the standard Gaussian prior with a learnable distribution optimized via behavior-regularized objectives, enabling direct generation of high-value trajectories without costly reward optimization.", "result": "PG outperforms state-of-the-art diffusion policies and planners in diverse long-horizon offline RL benchmarks.", "conclusion": "PG offers an efficient and effective solution for high-quality trajectory generation in offline RL, eliminating the need for costly sampling strategies."}}
{"id": "2505.10999", "pdf": "https://arxiv.org/pdf/2505.10999", "abs": "https://arxiv.org/abs/2505.10999", "authors": ["Weilai Xiang", "Hongyu Yang", "Di Huang", "Yunhong Wang"], "title": "DDAE++: Enhancing Diffusion Models Towards Unified Generative and Discriminative Learning", "categories": ["cs.CV"], "comment": null, "summary": "While diffusion models have gained prominence in image synthesis, their\ngenerative pre-training has been shown to yield discriminative representations,\npaving the way towards unified visual generation and understanding. However,\ntwo key questions remain: 1) Can these representations be leveraged to improve\nthe training of diffusion models themselves, rather than solely benefiting\ndownstream tasks? 2) Can the feature quality be enhanced to rival or even\nsurpass modern self-supervised learners, without compromising generative\ncapability? This work addresses these questions by introducing\nself-conditioning, a straightforward yet effective mechanism that internally\nleverages the rich semantics inherent in denoising network to guide its own\ndecoding layers, forming a tighter bottleneck that condenses high-level\nsemantics to improve generation. Results are compelling: our method boosts both\ngeneration FID and recognition accuracy with 1% computational overhead and\ngeneralizes across diverse diffusion architectures. Crucially,\nself-conditioning facilitates an effective integration of discriminative\ntechniques, such as contrastive self-distillation, directly into diffusion\nmodels without sacrificing generation quality. Extensive experiments on\npixel-space and latent-space datasets show that in linear evaluations, our\nenhanced diffusion models, particularly UViT and DiT, serve as strong\nrepresentation learners, surpassing various self-supervised models.", "AI": {"tldr": "The paper introduces self-conditioning in diffusion models to improve both generative and discriminative performance without significant computational cost.", "motivation": "To address whether diffusion models' representations can enhance their own training and rival self-supervised learners without losing generative capability.", "method": "Proposes self-conditioning, a mechanism using denoising network semantics to guide decoding layers, forming a bottleneck for better generation.", "result": "Boosts generation FID and recognition accuracy with minimal overhead; outperforms self-supervised models in linear evaluations.", "conclusion": "Self-conditioning effectively integrates discriminative techniques into diffusion models, enhancing both generation and representation learning."}}
{"id": "2505.11478", "pdf": "https://arxiv.org/pdf/2505.11478", "abs": "https://arxiv.org/abs/2505.11478", "authors": ["Mingxuan Li", "Junzhe Zhang", "Elias Bareinboim"], "title": "Automatic Reward Shaping from Confounded Offline Data", "categories": ["cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "A key task in Artificial Intelligence is learning effective policies for\ncontrolling agents in unknown environments to optimize performance measures.\nOff-policy learning methods, like Q-learning, allow learners to make optimal\ndecisions based on past experiences. This paper studies off-policy learning\nfrom biased data in complex and high-dimensional domains where \\emph{unobserved\nconfounding} cannot be ruled out a priori. Building on the well-celebrated Deep\nQ-Network (DQN), we propose a novel deep reinforcement learning algorithm\nrobust to confounding biases in observed data. Specifically, our algorithm\nattempts to find a safe policy for the worst-case environment compatible with\nthe observations. We apply our method to twelve confounded Atari games, and\nfind that it consistently dominates the standard DQN in all games where the\nobserved input to the behavioral and target policies mismatch and unobserved\nconfounders exist.", "AI": {"tldr": "The paper proposes a novel deep reinforcement learning algorithm robust to confounding biases in observed data, outperforming standard DQN in confounded Atari games.", "motivation": "Addressing the challenge of off-policy learning in high-dimensional domains with unobserved confounding, where standard methods like DQN may fail.", "method": "Extends DQN to find a safe policy for the worst-case environment compatible with observations, handling confounding biases.", "result": "The proposed algorithm consistently outperforms standard DQN in confounded Atari games with mismatched inputs and unobserved confounders.", "conclusion": "The method effectively mitigates confounding biases, demonstrating superior performance in complex, high-dimensional domains."}}
{"id": "2505.11277", "pdf": "https://arxiv.org/pdf/2505.11277", "abs": "https://arxiv.org/abs/2505.11277", "authors": ["Yaorui Shi", "Shihan Li", "Chang Wu", "Zhiyuan Liu", "Junfeng Fang", "Hengxing Cai", "An Zhang", "Xiang Wang"], "title": "Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models have demonstrated impressive reasoning capabilities but\nare inherently limited by their knowledge reservoir. Retrieval-augmented\nreasoning mitigates this limitation by allowing LLMs to query external\nresources, but existing methods often retrieve irrelevant or noisy information,\nhindering accurate reasoning. In this paper, we propose AutoRefine, a\nreinforcement learning post-training framework that adopts a new\n``search-and-refine-during-think'' paradigm. AutoRefine introduces explicit\nknowledge refinement steps between successive search calls, enabling the model\nto iteratively filter, distill, and organize evidence before generating an\nanswer. Furthermore, we incorporate tailored retrieval-specific rewards\nalongside answer correctness rewards using group relative policy optimization.\nExperiments on single-hop and multi-hop QA benchmarks demonstrate that\nAutoRefine significantly outperforms existing approaches, particularly in\ncomplex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine\nissues frequent, higher-quality searches and synthesizes evidence effectively.", "AI": {"tldr": "AutoRefine is a reinforcement learning framework that improves retrieval-augmented reasoning by refining knowledge between searches, outperforming existing methods in QA tasks.", "motivation": "To address the limitation of LLMs in retrieving noisy or irrelevant information, hindering accurate reasoning.", "method": "Introduces a \"search-and-refine-during-think\" paradigm with iterative knowledge refinement and tailored retrieval-specific rewards.", "result": "Significantly outperforms existing approaches, especially in multi-hop reasoning, with higher-quality searches and effective evidence synthesis.", "conclusion": "AutoRefine enhances retrieval-augmented reasoning by refining knowledge iteratively, proving effective in complex QA scenarios."}}
{"id": "2505.10882", "pdf": "https://arxiv.org/pdf/2505.10882", "abs": "https://arxiv.org/abs/2505.10882", "authors": ["Alex Saad-Falcon", "Brighton Ancelin", "Justin Romberg"], "title": "Global Convergence of Adaptive Sensing for Principal Eigenvector Estimation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper addresses the challenge of efficient principal component analysis\n(PCA) in high-dimensional spaces by analyzing a compressively sampled variant\nof Oja's algorithm with adaptive sensing. Traditional PCA methods incur\nsubstantial computational costs that scale poorly with data dimensionality,\nwhereas subspace tracking algorithms like Oja's offer more efficient\nalternatives but typically require full-dimensional observations. We analyze a\nvariant where, at each iteration, only two compressed measurements are taken:\none in the direction of the current estimate and one in a random orthogonal\ndirection. We prove that this adaptive sensing approach achieves global\nconvergence in the presence of noise when tracking the leading eigenvector of a\ndatastream with eigengap $\\Delta=\\lambda_1-\\lambda_2$. Our theoretical analysis\ndemonstrates that the algorithm experiences two phases: (1) a warmup phase\nrequiring $O(\\lambda_1\\lambda_2d^2/\\Delta^2)$ iterations to achieve a\nconstant-level alignment with the true eigenvector, followed by (2) a local\nconvergence phase where the sine alignment error decays at a rate of\n$O(\\lambda_1\\lambda_2d^2/\\Delta^2 t)$ for iterations $t$. The guarantee aligns\nwith existing minimax lower bounds with an added factor of $d$ due to the\ncompressive sampling. This work provides the first convergence guarantees in\nadaptive sensing for subspace tracking with noise. Our proof technique is also\nconsiderably simpler than those in prior works. The results have important\nimplications for applications where acquiring full-dimensional samples is\nchallenging or costly.", "AI": {"tldr": "The paper introduces a compressively sampled variant of Oja's algorithm for efficient PCA in high-dimensional spaces, proving global convergence with adaptive sensing and noise.", "motivation": "Traditional PCA methods are computationally expensive in high dimensions, while subspace tracking algorithms like Oja's require full-dimensional observations. This work addresses these limitations.", "method": "A variant of Oja's algorithm is analyzed, using two compressed measurements per iteration: one in the current estimate direction and one in a random orthogonal direction.", "result": "The algorithm achieves global convergence with noise, featuring a warmup phase and a local convergence phase with specific iteration bounds.", "conclusion": "This work provides the first convergence guarantees for adaptive sensing in subspace tracking with noise, with simpler proofs and practical implications for high-dimensional data."}}
{"id": "2505.11003", "pdf": "https://arxiv.org/pdf/2505.11003", "abs": "https://arxiv.org/abs/2505.11003", "authors": ["Bo Du", "Xuekang Zhu", "Xiaochen Ma", "Chenfan Qu", "Kaiwen Feng", "Zhe Yang", "Chi-Man Pun", "Jian Liu", "Jizhe Zhou"], "title": "ForensicHub: A Unified Benchmark & Codebase for All-Domain Fake Image Detection and Localization", "categories": ["cs.CV"], "comment": "Technical report. Code available at:\n  https://github.com/scu-zjz/ForensicHub", "summary": "The field of Fake Image Detection and Localization (FIDL) is highly\nfragmented, encompassing four domains: deepfake detection (Deepfake), image\nmanipulation detection and localization (IMDL), artificial\nintelligence-generated image detection (AIGC), and document image manipulation\nlocalization (Doc). Although individual benchmarks exist in some domains, a\nunified benchmark for all domains in FIDL remains blank. The absence of a\nunified benchmark results in significant domain silos, where each domain\nindependently constructs its datasets, models, and evaluation protocols without\ninteroperability, preventing cross-domain comparisons and hindering the\ndevelopment of the entire FIDL field. To close the domain silo barrier, we\npropose ForensicHub, the first unified benchmark & codebase for all-domain fake\nimage detection and localization. Considering drastic variations on dataset,\nmodel, and evaluation configurations across all domains, as well as the\nscarcity of open-sourced baseline models and the lack of individual benchmarks\nin some domains, ForensicHub: i) proposes a modular and configuration-driven\narchitecture that decomposes forensic pipelines into interchangeable components\nacross datasets, transforms, models, and evaluators, allowing flexible\ncomposition across all domains; ii) fully implements 10 baseline models, 6\nbackbones, 2 new benchmarks for AIGC and Doc, and integrates 2 existing\nbenchmarks of DeepfakeBench and IMDLBenCo through an adapter-based design; iii)\nconducts indepth analysis based on the ForensicHub, offering 8 key actionable\ninsights into FIDL model architecture, dataset characteristics, and evaluation\nstandards. ForensicHub represents a significant leap forward in breaking the\ndomain silos in the FIDL field and inspiring future breakthroughs.", "AI": {"tldr": "ForensicHub is the first unified benchmark and codebase for Fake Image Detection and Localization (FIDL), addressing fragmentation across four domains by modular design, baseline implementations, and cross-domain analysis.", "motivation": "The FIDL field is fragmented into four domains with no unified benchmark, leading to silos and hindering cross-domain progress. ForensicHub aims to bridge this gap.", "method": "ForensicHub introduces a modular, configuration-driven architecture, implements 10 baseline models, 6 backbones, and integrates existing benchmarks while adding new ones for AIGC and Doc domains.", "result": "The framework enables flexible composition across domains, provides 8 actionable insights, and fosters interoperability and comparison.", "conclusion": "ForensicHub breaks domain silos in FIDL, offering a foundation for future advancements in fake image detection and localization."}}
{"id": "2505.11481", "pdf": "https://arxiv.org/pdf/2505.11481", "abs": "https://arxiv.org/abs/2505.11481", "authors": ["Alayt Issak", "Jeba Rezwana", "Casper Harteveld"], "title": "MOSAAIC: Managing Optimization towards Shared Autonomy, Authority, and Initiative in Co-creation", "categories": ["cs.AI"], "comment": null, "summary": "Striking the appropriate balance between humans and co-creative AI is an open\nresearch question in computational creativity. Co-creativity, a form of hybrid\nintelligence where both humans and AI take action proactively, is a process\nthat leads to shared creative artifacts and ideas. Achieving a balanced dynamic\nin co-creativity requires characterizing control and identifying strategies to\ndistribute control between humans and AI. We define control as the power to\ndetermine, initiate, and direct the process of co-creation. Informed by a\nsystematic literature review of 172 full-length papers, we introduce MOSAAIC\n(Managing Optimization towards Shared Autonomy, Authority, and Initiative in\nCo-creation), a novel framework for characterizing and balancing control in\nco-creation. MOSAAIC identifies three key dimensions of control: autonomy,\ninitiative, and authority. We supplement our framework with control\noptimization strategies in co-creation. To demonstrate MOSAAIC's applicability,\nwe analyze the distribution of control in six existing co-creative AI case\nstudies and present the implications of using this framework.", "AI": {"tldr": "The paper introduces MOSAAIC, a framework for balancing control between humans and AI in co-creativity, focusing on autonomy, initiative, and authority.", "motivation": "To address the challenge of balancing human and AI control in co-creative processes.", "method": "Conducted a systematic literature review of 172 papers and developed the MOSAAIC framework.", "result": "MOSAAIC characterizes control dimensions and offers optimization strategies, validated through case studies.", "conclusion": "MOSAAIC provides a practical tool for managing control in co-creativity, enhancing collaboration between humans and AI."}}
{"id": "2505.11280", "pdf": "https://arxiv.org/pdf/2505.11280", "abs": "https://arxiv.org/abs/2505.11280", "authors": ["Horacio Thompson", "Esa\u00fa Villatoro-Tello", "Manuel Montes-y-G\u00f3mez", "Marcelo Errecalde"], "title": "Temporal fine-tuning for early risk detection", "categories": ["cs.CL"], "comment": "In: Proceedings of the 53rd JAIIO / 50th CLEI - ASAID, 2024, p. 137.\n  ISSN: 2451-7496", "summary": "Early Risk Detection (ERD) on the Web aims to identify promptly users facing\nsocial and health issues. Users are analyzed post-by-post, and it is necessary\nto guarantee correct and quick answers, which is particularly challenging in\ncritical scenarios. ERD involves optimizing classification precision and\nminimizing detection delay. Standard classification metrics may not suffice,\nresorting to specific metrics such as ERDE(theta) that explicitly consider\nprecision and delay. The current research focuses on applying a multi-objective\napproach, prioritizing classification performance and establishing a separate\ncriterion for decision time. In this work, we propose a completely different\nstrategy, temporal fine-tuning, which allows tuning transformer-based models by\nexplicitly incorporating time within the learning process. Our method allows us\nto analyze complete user post histories, tune models considering different\ncontexts, and evaluate training performance using temporal metrics. We\nevaluated our proposal in the depression and eating disorders tasks for the\nSpanish language, achieving competitive results compared to the best models of\nMentalRiskES 2023. We found that temporal fine-tuning optimized decisions\nconsidering context and time progress. In this way, by properly taking\nadvantage of the power of transformers, it is possible to address ERD by\ncombining precision and speed as a single objective.", "AI": {"tldr": "Proposes temporal fine-tuning for transformer models to optimize Early Risk Detection (ERD) by integrating time into learning, achieving competitive results in depression and eating disorder tasks.", "motivation": "ERD requires balancing precision and speed, but standard metrics and approaches may not suffice. A new method is needed to incorporate time explicitly.", "method": "Temporal fine-tuning of transformer models, analyzing complete user post histories and evaluating with temporal metrics.", "result": "Competitive performance in Spanish-language depression and eating disorder tasks, optimizing decisions with context and time progress.", "conclusion": "Temporal fine-tuning effectively combines precision and speed in ERD, leveraging transformers' power for better outcomes."}}
{"id": "2505.10892", "pdf": "https://arxiv.org/pdf/2505.10892", "abs": "https://arxiv.org/abs/2505.10892", "authors": ["Akhil Agnihotri", "Rahul Jain", "Deepak Ramachandran", "Zheng Wen"], "title": "Multi-Objective Preference Optimization: Improving Human Alignment of Generative Models", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2406.18853 by other authors", "summary": "Post-training of LLMs with RLHF, and subsequently preference optimization\nalgorithms such as DPO, IPO, etc., made a big difference in improving human\nalignment. However, all such techniques can only work with a single (human)\nobjective. In practice, human users have multiple objectives, such as\nhelpfulness and harmlessness, and there is no natural way to aggregate them\ninto a single objective. In this paper, we address the multi-objective\npreference-alignment problem, where a policy must optimize several, potentially\nconflicting, objectives. We introduce the Multi-Objective Preference\nOptimization (MOPO) algorithm, which frames alignment as a constrained\nKL-regularized optimization: the primary objective is maximized while secondary\nobjectives are lower-bounded by tunable safety thresholds. Unlike prior work,\nMOPO operates directly on pairwise preference data, requires no point-wise\nreward assumption, and avoids heuristic prompt-context engineering. The method\nrecovers policies on the Pareto front whenever the front is attainable;\npractically, it reduces to simple closed-form iterative updates suitable for\nlarge-scale training. On synthetic benchmarks with diverse canonical preference\nstructures, we show that MOPO approximates the Pareto front. When fine-tuning a\n1.3B-parameter language model on real-world human-preference datasets, MOPO\nattains higher rewards and yields policies that Pareto-dominate baselines;\nablation studies confirm optimization stability and robustness to\nhyperparameters.", "AI": {"tldr": "The paper introduces MOPO, a multi-objective preference optimization algorithm for aligning LLMs with multiple human objectives, outperforming single-objective methods.", "motivation": "Existing preference optimization techniques like RLHF and DPO only handle single objectives, but humans have multiple, potentially conflicting goals (e.g., helpfulness and harmlessness). MOPO addresses this gap.", "method": "MOPO frames alignment as a constrained KL-regularized optimization, maximizing the primary objective while bounding secondary objectives with safety thresholds. It works directly on pairwise preference data without point-wise rewards or heuristic prompts.", "result": "MOPO approximates the Pareto front in synthetic benchmarks and outperforms baselines in real-world experiments, achieving higher rewards and stable optimization.", "conclusion": "MOPO effectively handles multi-objective alignment, offering a scalable and robust solution for optimizing conflicting human preferences in LLMs."}}
{"id": "2505.11015", "pdf": "https://arxiv.org/pdf/2505.11015", "abs": "https://arxiv.org/abs/2505.11015", "authors": ["An-Lan Wang", "Jingqun Tang", "Liao Lei", "Hao Feng", "Qi Liu", "Xiang Fei", "Jinghui Lu", "Han Wang", "Weiwei Liu", "Hao Liu", "Yuliang Liu", "Xiang Bai", "Can Huang"], "title": "WildDoc: How Far Are We from Achieving Comprehensive and Robust Document Understanding in the Wild?", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced capabilities in Document Understanding. However,\nprevailing benchmarks like DocVQA and ChartQA predominantly comprise\n\\textit{scanned or digital} documents, inadequately reflecting the intricate\nchallenges posed by diverse real-world scenarios, such as variable illumination\nand physical distortions. This paper introduces WildDoc, the inaugural\nbenchmark designed specifically for assessing document understanding in natural\nenvironments. WildDoc incorporates a diverse set of manually captured document\nimages reflecting real-world conditions and leverages document sources from\nestablished benchmarks to facilitate comprehensive comparisons with digital or\nscanned documents. Further, to rigorously evaluate model robustness, each\ndocument is captured four times under different conditions. Evaluations of\nstate-of-the-art MLLMs on WildDoc expose substantial performance declines and\nunderscore the models' inadequate robustness compared to traditional\nbenchmarks, highlighting the unique challenges posed by real-world document\nunderstanding. Our project homepage is available at\nhttps://bytedance.github.io/WildDoc.", "AI": {"tldr": "WildDoc is a new benchmark for evaluating document understanding in natural environments, highlighting the limitations of current MLLMs in real-world scenarios.", "motivation": "Existing benchmarks like DocVQA and ChartQA focus on scanned or digital documents, failing to address real-world challenges like variable illumination and physical distortions.", "method": "WildDoc introduces manually captured document images under diverse real-world conditions and evaluates MLLMs on robustness by capturing each document four times under varying conditions.", "result": "State-of-the-art MLLMs show significant performance drops on WildDoc, revealing their lack of robustness in real-world document understanding.", "conclusion": "WildDoc exposes critical gaps in current MLLMs' capabilities, emphasizing the need for improved models to handle real-world document challenges."}}
{"id": "2503.09243", "pdf": "https://arxiv.org/pdf/2503.09243", "abs": "https://arxiv.org/abs/2503.09243", "authors": ["Ruihai Wu", "Ziyu Zhu", "Yuran Wang", "Yue Chen", "Jiarui Wang", "Hao Dong"], "title": "GarmentPile: Point-Level Visual Affordance Guided Retrieval and Adaptation for Cluttered Garments Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Cluttered garments manipulation poses significant challenges due to the\ncomplex, deformable nature of garments and intricate garment relations. Unlike\nsingle-garment manipulation, cluttered scenarios require managing complex\ngarment entanglements and interactions, while maintaining garment cleanliness\nand manipulation stability. To address these demands, we propose to learn\npoint-level affordance, the dense representation modeling the complex space and\nmulti-modal manipulation candidates, while being aware of garment geometry,\nstructure, and inter-object relations. Additionally, as it is difficult to\ndirectly retrieve a garment in some extremely entangled clutters, we introduce\nan adaptation module, guided by learned affordance, to reorganize\nhighly-entangled garments into states plausible for manipulation. Our framework\ndemonstrates effectiveness over environments featuring diverse garment types\nand pile configurations in both simulation and the real world. Project page:\nhttps://garmentpile.github.io/.", "AI": {"tldr": "A framework for cluttered garment manipulation using point-level affordance learning and an adaptation module to reorganize entangled garments.", "motivation": "Addressing challenges in cluttered garment manipulation, such as complex entanglements and maintaining cleanliness and stability.", "method": "Proposes learning point-level affordance for dense representation and introduces an adaptation module for reorganizing entangled garments.", "result": "Demonstrates effectiveness in diverse garment types and pile configurations in simulation and real-world scenarios.", "conclusion": "The framework successfully tackles cluttered garment manipulation by leveraging affordance learning and adaptive reorganization."}}
{"id": "2505.11297", "pdf": "https://arxiv.org/pdf/2505.11297", "abs": "https://arxiv.org/abs/2505.11297", "authors": ["Gal Astrach", "Yuval Pinter"], "title": "Probing Subphonemes in Morphology Models", "categories": ["cs.CL"], "comment": null, "summary": "Transformers have achieved state-of-the-art performance in morphological\ninflection tasks, yet their ability to generalize across languages and\nmorphological rules remains limited. One possible explanation for this behavior\ncan be the degree to which these models are able to capture implicit phenomena\nat the phonological and subphonemic levels. We introduce a language-agnostic\nprobing method to investigate phonological feature encoding in transformers\ntrained directly on phonemes, and perform it across seven morphologically\ndiverse languages. We show that phonological features which are local, such as\nfinal-obstruent devoicing in Turkish, are captured well in phoneme embeddings,\nwhereas long-distance dependencies like vowel harmony are better represented in\nthe transformer's encoder. Finally, we discuss how these findings inform\nempirical strategies for training morphological models, particularly regarding\nthe role of subphonemic feature acquisition.", "AI": {"tldr": "Transformers perform well in morphological inflection but struggle with generalization. A probing method reveals they capture local phonological features better than long-distance ones, impacting training strategies.", "motivation": "To understand why transformers generalize poorly in morphological tasks by examining their ability to encode phonological and subphonemic features.", "method": "A language-agnostic probing method was applied to transformers trained on phonemes across seven languages, analyzing phonological feature encoding.", "result": "Local features (e.g., final-obstruent devoicing) are well-captured in phoneme embeddings, while long-distance dependencies (e.g., vowel harmony) rely more on the encoder.", "conclusion": "The findings suggest subphonemic feature acquisition is crucial for improving transformer-based morphological models."}}
{"id": "2505.10894", "pdf": "https://arxiv.org/pdf/2505.10894", "abs": "https://arxiv.org/abs/2505.10894", "authors": ["Yishuo Wang", "Feng Zhou", "Muping Zhou", "Qicheng Meng", "Zhijun Hu", "Yi Wang"], "title": "CTP: A hybrid CNN-Transformer-PINN model for ocean front forecasting", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This paper proposes CTP, a novel deep learning framework that integrates\nconvolutional neural network(CNN), Transformer architectures, and\nphysics-informed neural network(PINN) for ocean front prediction. Ocean fronts,\nas dynamic interfaces between distinct water masses, play critical roles in\nmarine biogeochemical and physical processes. Existing methods such as LSTM,\nConvLSTM, and AttentionConv often struggle to maintain spatial continuity and\nphysical consistency over multi-step forecasts. CTP addresses these challenges\nby combining localized spatial encoding, long-range temporal attention, and\nphysical constraint enforcement. Experimental results across south China\nsea(SCS) and Kuroshio(KUR) regions from 1993 to 2020 demonstrate that CTP\nachieves state-of-the-art(SOTA) performance in both single-step and multi-step\npredictions, significantly outperforming baseline models in accuracy, $F_1$\nscore, and temporal stability.", "AI": {"tldr": "CTP is a deep learning framework combining CNN, Transformer, and PINN for ocean front prediction, outperforming existing methods in accuracy and stability.", "motivation": "Ocean fronts are critical in marine processes, but current methods like LSTM and ConvLSTM struggle with spatial continuity and physical consistency in forecasts.", "method": "CTP integrates CNN for spatial encoding, Transformer for temporal attention, and PINN for physical constraints.", "result": "CTP achieves SOTA performance in single and multi-step predictions, excelling in accuracy, $F_1$ score, and stability in SCS and KUR regions.", "conclusion": "CTP effectively addresses limitations of existing methods, offering improved ocean front prediction with physical consistency."}}
{"id": "2505.11018", "pdf": "https://arxiv.org/pdf/2505.11018", "abs": "https://arxiv.org/abs/2505.11018", "authors": ["Pengchen Zhang", "Alan J. X. Guo", "Sipin Luo", "Zhe Han", "Lin Guo"], "title": "Rethinking the Mean Teacher Strategy from the Perspective of Self-paced Learning", "categories": ["cs.CV"], "comment": null, "summary": "Semi-supervised medical image segmentation has attracted significant\nattention due to its potential to reduce manual annotation costs. The mean\nteacher (MT) strategy, commonly understood as introducing smoothed, temporally\nlagged consistency regularization, has demonstrated strong performance across\nvarious tasks in this field. In this work, we reinterpret the MT strategy on\nsupervised data as a form of self-paced learning, regulated by the output\nagreement between the temporally lagged teacher model and the ground truth\nlabels. This idea is further extended to incorporate agreement between a\ntemporally lagged model and a cross-architectural model, which offers greater\nflexibility in regulating the learning pace and enables application to\nunlabeled data. Specifically, we propose dual teacher-student learning (DTSL),\na framework that introduces two groups of teacher-student models with different\narchitectures. The output agreement between the cross-group teacher and student\nmodels is used as pseudo-labels, generated via a Jensen-Shannon\ndivergence-based consensus label generator (CLG). Extensive experiments on\npopular datasets demonstrate that the proposed method consistently outperforms\nexisting state-of-the-art approaches. Ablation studies further validate the\neffectiveness of the proposed modules.", "AI": {"tldr": "The paper proposes Dual Teacher-Student Learning (DTSL) for semi-supervised medical image segmentation, leveraging cross-architectural models and Jensen-Shannon divergence for pseudo-labeling, outperforming existing methods.", "motivation": "To reduce manual annotation costs in medical image segmentation by enhancing semi-supervised learning with cross-architectural model agreement.", "method": "Introduces DTSL with two teacher-student model groups, using output agreement and a Jensen-Shannon divergence-based consensus label generator for pseudo-labels.", "result": "Outperforms state-of-the-art methods on popular datasets; ablation studies confirm module effectiveness.", "conclusion": "DTSL offers a flexible, effective approach for semi-supervised medical image segmentation, validated by superior performance."}}
{"id": "2505.10472", "pdf": "https://arxiv.org/pdf/2505.10472", "abs": "https://arxiv.org/abs/2505.10472", "authors": ["Agnik Saha", "Victoria Churchill", "Anny D. Rodriguez", "Ugur Kursuncu", "Muhammed Y. Idris"], "title": "Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Effective communication about breast and cervical cancers remains a\npersistent health challenge, with significant gaps in public understanding of\ncancer prevention, screening, and treatment, potentially leading to delayed\ndiagnoses and inadequate treatments. This study evaluates the capabilities and\nlimitations of Large Language Models (LLMs) in generating accurate, safe, and\naccessible cancer-related information to support patient understanding. We\nevaluated five general-purpose and three medical LLMs using a mixed-methods\nevaluation framework across linguistic quality, safety and trustworthiness, and\ncommunication accessibility and affectiveness. Our approach utilized\nquantitative metrics, qualitative expert ratings, and statistical analysis\nusing Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that\ngeneral-purpose LLMs produced outputs of higher linguistic quality and\naffectiveness, while medical LLMs demonstrate greater communication\naccessibility. However, medical LLMs tend to exhibit higher levels of potential\nharm, toxicity, and bias, reducing their performance in safety and\ntrustworthiness. Our findings indicate a duality between domain-specific\nknowledge and safety in health communications. The results highlight the need\nfor intentional model design with targeted improvements, particularly in\nmitigating harm and bias, and improving safety and affectiveness. This study\nprovides a comprehensive evaluation of LLMs for cancer communication, offering\ncritical insights for improving AI-generated health content and informing\nfuture development of accurate, safe, and accessible digital health tools.", "AI": {"tldr": "The study evaluates LLMs for generating cancer-related information, finding general-purpose models excel in linguistic quality and affectiveness, while medical models are more accessible but less safe.", "motivation": "Address gaps in public understanding of cancer prevention and treatment by assessing LLMs' ability to provide accurate, safe, and accessible information.", "method": "Mixed-methods framework evaluating five general-purpose and three medical LLMs using quantitative metrics, qualitative expert ratings, and statistical analysis (Welch's ANOVA, Games-Howell, Hedges' g).", "result": "General-purpose LLMs outperform in linguistic quality and affectiveness; medical LLMs are more accessible but show higher harm, toxicity, and bias.", "conclusion": "Highlights the need for targeted improvements in model design to balance domain-specific knowledge with safety, ensuring accurate and accessible health communication."}}
{"id": "2505.11336", "pdf": "https://arxiv.org/pdf/2505.11336", "abs": "https://arxiv.org/abs/2505.11336", "authors": ["Nuo Chen", "Andre Lin HuiKai", "Jiaying Wu", "Junyi Hou", "Zining Zhang", "Qian Wang", "Xidong Wang", "Bingsheng He"], "title": "XtraGPT: LLMs for Human-AI Collaboration on Controllable Academic Paper Revision", "categories": ["cs.CL"], "comment": "preprint", "summary": "Despite the growing adoption of large language models (LLMs) in academic\nworkflows, their capabilities remain limited when it comes to supporting\nhigh-quality scientific writing. Most existing systems are designed for\ngeneral-purpose scientific text generation and fail to meet the sophisticated\ndemands of research communication beyond surface-level polishing, such as\nconceptual coherence across sections. Furthermore, academic writing is\ninherently iterative and revision-driven, a process not well supported by\ndirect prompting-based paradigms. To address these scenarios, we propose a\nhuman-AI collaboration framework for academic paper revision. We first\nintroduce a comprehensive dataset of 7,040 research papers from top-tier venues\nannotated with over 140,000 instruction-response pairs that reflect realistic,\nsection-level scientific revisions. Building on the dataset, we develop\nXtraGPT, the first suite of open-source LLMs, designed to provide\ncontext-aware, instruction-guided writing assistance, ranging from 1.5B to 14B\nparameters. Extensive experiments validate that XtraGPT significantly\noutperforms same-scale baselines and approaches the quality of proprietary\nsystems. Both automated preference assessments and human evaluations confirm\nthe effectiveness of our models in improving scientific drafts.", "AI": {"tldr": "The paper introduces XtraGPT, a human-AI collaboration framework for academic paper revision, outperforming existing systems with context-aware, instruction-guided assistance.", "motivation": "Addressing the limitations of LLMs in supporting high-quality scientific writing, particularly in iterative, revision-driven academic workflows.", "method": "Developed a dataset of 7,040 research papers with 140,000 instruction-response pairs, then created XtraGPT, a suite of open-source LLMs for context-aware writing assistance.", "result": "XtraGPT outperforms same-scale baselines and approaches proprietary systems in improving scientific drafts, validated by automated and human evaluations.", "conclusion": "The proposed framework effectively enhances scientific writing by combining human-AI collaboration and context-aware LLMs."}}
{"id": "2505.10913", "pdf": "https://arxiv.org/pdf/2505.10913", "abs": "https://arxiv.org/abs/2505.10913", "authors": ["Muntasir Hoq", "Ananya Rao", "Reisha Jaishankar", "Krish Piryani", "Nithya Janapati", "Jessica Vandenberg", "Bradford Mott", "Narges Norouzi", "James Lester", "Bita Akram"], "title": "Automated Identification of Logical Errors in Programs: Advancing Scalable Analysis of Student Misconceptions", "categories": ["cs.LG", "K.3.1"], "comment": "Accepted for publication at the 18th International Conference on\n  Educational Data Mining (EDM), 2025", "summary": "In Computer Science (CS) education, understanding factors contributing to\nstudents' programming difficulties is crucial for effective learning support.\nBy identifying specific issues students face, educators can provide targeted\nassistance to help them overcome obstacles and improve learning outcomes. While\nidentifying sources of struggle, such as misconceptions, in real-time can be\nchallenging in current educational practices, analyzing logical errors in\nstudents' code can offer valuable insights. This paper presents a scalable\nframework for automatically detecting logical errors in students' programming\nsolutions. Our framework is based on an explainable Abstract Syntax Tree (AST)\nembedding model, the Subtree-based Attention Neural Network (SANN), that\nidentifies the structural components of programs containing logical errors. We\nconducted a series of experiments to evaluate its effectiveness, and the\nresults suggest that our framework can accurately capture students' logical\nerrors and, more importantly, provide us with deeper insights into their\nlearning processes, offering a valuable tool for enhancing programming\neducation.", "AI": {"tldr": "A scalable framework using AST embeddings (SANN) detects logical errors in students' code, aiding targeted learning support in CS education.", "motivation": "Understanding programming difficulties helps educators provide effective support. Identifying logical errors in real-time is challenging but crucial for improving learning outcomes.", "method": "The framework uses an explainable AST embedding model (SANN) to analyze structural components of programs for logical errors.", "result": "Experiments show the framework accurately detects logical errors and provides insights into students' learning processes.", "conclusion": "The framework enhances programming education by offering a tool for real-time error detection and deeper learning insights."}}
{"id": "2505.11034", "pdf": "https://arxiv.org/pdf/2505.11034", "abs": "https://arxiv.org/abs/2505.11034", "authors": ["Fabian Gr\u00f6ger", "Simone Lionetti", "Philippe Gottfrois", "Alvaro Gonzalez-Jimenez", "Ludovic Amruthalingam", "Elisabeth Victoria Goessinger", "Hanna Lindemann", "Marie Bargiela", "Marie Hofbauer", "Omar Badri", "Philipp Tschandl", "Arash Koochek", "Matthew Groh", "Alexander A. Navarini", "Marc Pouly"], "title": "CleanPatrick: A Benchmark for Image Data Cleaning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Robust machine learning depends on clean data, yet current image data\ncleaning benchmarks rely on synthetic noise or narrow human studies, limiting\ncomparison and real-world relevance. We introduce CleanPatrick, the first\nlarge-scale benchmark for data cleaning in the image domain, built upon the\npublicly available Fitzpatrick17k dermatology dataset. We collect 496,377\nbinary annotations from 933 medical crowd workers, identify off-topic samples\n(4%), near-duplicates (21%), and label errors (22%), and employ an aggregation\nmodel inspired by item-response theory followed by expert review to derive\nhigh-quality ground truth. CleanPatrick formalizes issue detection as a ranking\ntask and adopts typical ranking metrics mirroring real audit workflows.\nBenchmarking classical anomaly detectors, perceptual hashing, SSIM, Confident\nLearning, NoiseRank, and SelfClean, we find that, on CleanPatrick,\nself-supervised representations excel at near-duplicate detection, classical\nmethods achieve competitive off-topic detection under constrained review\nbudgets, and label-error detection remains an open challenge for fine-grained\nmedical classification. By releasing both the dataset and the evaluation\nframework, CleanPatrick enables a systematic comparison of image-cleaning\nstrategies and paves the way for more reliable data-centric artificial\nintelligence.", "AI": {"tldr": "CleanPatrick is a large-scale benchmark for image data cleaning, built on the Fitzpatrick17k dataset, addressing off-topic samples, near-duplicates, and label errors. It evaluates various methods, revealing strengths in self-supervised representations and classical anomaly detection, while highlighting challenges in label-error detection.", "motivation": "Current benchmarks for image data cleaning rely on synthetic noise or limited human studies, lacking real-world relevance and comparability. CleanPatrick aims to provide a robust, large-scale benchmark for systematic evaluation.", "method": "The benchmark uses the Fitzpatrick17k dataset, collecting 496,377 binary annotations from 933 medical crowd workers. It identifies off-topic samples (4%), near-duplicates (21%), and label errors (22%), employing an aggregation model and expert review for high-quality ground truth. Issue detection is formalized as a ranking task.", "result": "Self-supervised representations excel at near-duplicate detection, classical methods perform well for off-topic detection under budget constraints, and label-error detection remains challenging for fine-grained medical classification.", "conclusion": "CleanPatrick enables systematic comparison of image-cleaning strategies, advancing reliable data-centric AI. The dataset and framework are released to support further research."}}
{"id": "2505.10588", "pdf": "https://arxiv.org/pdf/2505.10588", "abs": "https://arxiv.org/abs/2505.10588", "authors": ["Manisha Mehta", "Fausto Giunchiglia"], "title": "Understanding Gen Alpha Digital Language: Evaluation of LLM Safety Systems for Content Moderation", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "I.2; I.2.7; K.4.2"], "comment": "Accepted to ACM FAccT 2025. To be presented in Athens, June 2025, and\n  published in the conference proceedings. Preprint version; final version will\n  appear in the ACM Digital Library", "summary": "This research offers a unique evaluation of how AI systems interpret the\ndigital language of Generation Alpha (Gen Alpha, born 2010-2024). As the first\ncohort raised alongside AI, Gen Alpha faces new forms of online risk due to\nimmersive digital engagement and a growing mismatch between their evolving\ncommunication and existing safety tools. Their distinct language, shaped by\ngaming, memes, and AI-driven trends, often conceals harmful interactions from\nboth human moderators and automated systems. We assess four leading AI models\n(GPT-4, Claude, Gemini, and Llama 3) on their ability to detect masked\nharassment and manipulation within Gen Alpha discourse. Using a dataset of 100\nrecent expressions from gaming platforms, social media, and video content, the\nstudy reveals critical comprehension failures with direct implications for\nonline safety. This work contributes: (1) a first-of-its-kind dataset capturing\nGen Alpha expressions; (2) a framework to improve AI moderation systems for\nyouth protection; (3) a multi-perspective evaluation including AI systems,\nhuman moderators, and parents, with direct input from Gen Alpha co-researchers;\nand (4) an analysis of how linguistic divergence increases youth vulnerability.\nFindings highlight the urgent need to redesign safety systems attuned to youth\ncommunication, especially given Gen Alpha reluctance to seek help when adults\nfail to understand their digital world. This study combines the insight of a\nGen Alpha researcher with systematic academic analysis to address critical\ndigital safety challenges.", "AI": {"tldr": "The paper evaluates AI models' ability to detect hidden risks in Gen Alpha's digital communication, revealing gaps in current safety tools and proposing improvements.", "motivation": "Gen Alpha's unique digital language, shaped by gaming and AI trends, poses new online risks that existing safety tools fail to address.", "method": "Four AI models (GPT-4, Claude, Gemini, Llama 3) were tested on 100 Gen Alpha expressions to assess detection of masked harassment and manipulation.", "result": "The study found critical comprehension failures in AI models, highlighting vulnerabilities in online safety for Gen Alpha.", "conclusion": "The work calls for redesigning safety systems to better align with youth communication, involving Gen Alpha insights for effective solutions."}}
{"id": "2505.11341", "pdf": "https://arxiv.org/pdf/2505.11341", "abs": "https://arxiv.org/abs/2505.11341", "authors": ["Banca Calvo Figueras", "Rodrigo Agerri"], "title": "Benchmarking Critical Questions Generation: A Challenging Reasoning Task for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The task of Critical Questions Generation (CQs-Gen) aims to foster critical\nthinking by enabling systems to generate questions that expose assumptions and\nchallenge the reasoning in arguments. Despite growing interest in this area,\nprogress has been hindered by the lack of suitable datasets and automatic\nevaluation standards. This work presents a comprehensive approach to support\nthe development and benchmarking of systems for this task. We construct the\nfirst large-scale manually-annotated dataset. We also investigate automatic\nevaluation methods and identify a reference-based technique using large\nlanguage models (LLMs) as the strategy that best correlates with human\njudgments. Our zero-shot evaluation of 11 LLMs establishes a strong baseline\nwhile showcasing the difficulty of the task. Data, code, and a public\nleaderboard are provided to encourage further research not only in terms of\nmodel performance, but also to explore the practical benefits of CQs-Gen for\nboth automated reasoning and human critical thinking.", "AI": {"tldr": "The paper introduces a comprehensive approach for Critical Questions Generation (CQs-Gen), including a new dataset, evaluation methods, and benchmarks for LLMs.", "motivation": "To advance critical thinking by addressing the lack of datasets and evaluation standards for CQs-Gen.", "method": "Constructs a large-scale annotated dataset and evaluates automatic methods, favoring LLM-based reference techniques.", "result": "Zero-shot evaluation of 11 LLMs sets a baseline, highlighting task difficulty.", "conclusion": "Provides resources to encourage research in CQs-Gen for automated reasoning and human critical thinking."}}
{"id": "2505.10928", "pdf": "https://arxiv.org/pdf/2505.10928", "abs": "https://arxiv.org/abs/2505.10928", "authors": ["Xiao Han", "Dayan Pan", "Xiangyu Zhao", "Xuyuan Hu", "Zhaolin Deng", "Xiangjie Kong", "Guojiang Shen"], "title": "A Dataset for Spatiotemporal-Sensitive POI Question Answering", "categories": ["cs.LG"], "comment": "Under Review", "summary": "Spatiotemporal relationships are critical in data science, as many prediction\nand reasoning tasks require analysis across both spatial and temporal\ndimensions--for instance, navigating an unfamiliar city involves planning\nitineraries that sequence locations and timing cultural experiences. However,\nexisting Question-Answering (QA) datasets lack sufficient\nspatiotemporal-sensitive questions, making them inadequate benchmarks for\nevaluating models' spatiotemporal reasoning capabilities. To address this gap,\nwe introduce POI-QA, a novel spatiotemporal-sensitive QA dataset centered on\nPoint of Interest (POI), constructed through three key steps: mining and\naligning open-source vehicle trajectory data from GAIA with high-precision\ngeographic POI data, rigorous manual validation of noisy spatiotemporal facts,\nand generating bilingual (Chinese/English) QA pairs that reflect\nhuman-understandable spatiotemporal reasoning tasks. Our dataset challenges\nmodels to parse complex spatiotemporal dependencies, and evaluations of\nstate-of-the-art multilingual LLMs (e.g., Qwen2.5-7B, Llama3.1-8B) reveal stark\nlimitations: even the top-performing model (Qwen2.5-7B fine-tuned with\nRAG+LoRA) achieves a top 10 Hit Ratio (HR@10) of only 0.41 on the easiest task,\nfar below human performance at 0.56. This underscores persistent weaknesses in\nLLMs' ability to perform consistent spatiotemporal reasoning, while\nhighlighting POI-QA as a robust benchmark to advance algorithms sensitive to\nspatiotemporal dynamics. The dataset is publicly available at\nhttps://www.kaggle.com/ds/7394666.", "AI": {"tldr": "POI-QA is a new QA dataset for evaluating spatiotemporal reasoning, revealing limitations in current LLMs.", "motivation": "Existing QA datasets lack spatiotemporal-sensitive questions, limiting evaluation of models' reasoning capabilities.", "method": "Constructed POI-QA by aligning vehicle trajectory data with POI data, validating facts, and generating bilingual QA pairs.", "result": "Top-performing LLM (Qwen2.5-7B) achieved HR@10 of 0.41, below human performance (0.56).", "conclusion": "POI-QA highlights LLMs' weaknesses in spatiotemporal reasoning and serves as a benchmark for improvement."}}
{"id": "2505.11046", "pdf": "https://arxiv.org/pdf/2505.11046", "abs": "https://arxiv.org/abs/2505.11046", "authors": ["Tim Alpherts", "Sennay Ghebreab", "Nanne van Noord"], "title": "Artifacts of Idiosyncracy in Global Street View Data", "categories": ["cs.CV"], "comment": "Published at FAccT '25", "summary": "Street view data is increasingly being used in computer vision applications\nin recent years. Machine learning datasets are collected for these applications\nusing simple sampling techniques. These datasets are assumed to be a systematic\nrepresentation of cities, especially when densely sampled. Prior works however,\nshow that there are clear gaps in coverage, with certain cities or regions\nbeing covered poorly or not at all. Here we demonstrate that a cities'\nidiosyncracies, such as city layout, may lead to biases in street view data for\n28 cities across the globe, even when they are densely covered. We\nquantitatively uncover biases in the distribution of coverage of street view\ndata and propose a method for evaluation of such distributions to get better\ninsight in idiosyncracies in a cities' coverage. In addition, we perform a case\nstudy of Amsterdam with semi-structured interviews, showing how idiosyncracies\nof the collection process impact representation of cities and regions and\nallowing us to address biases at their source.", "AI": {"tldr": "The paper reveals biases in street view data due to city idiosyncrasies, proposes a method to evaluate coverage, and includes a case study on Amsterdam to address biases.", "motivation": "Street view data is assumed to represent cities systematically, but prior work shows coverage gaps. This study explores how city layouts introduce biases even in densely sampled data.", "method": "Quantitative analysis of street view data coverage biases across 28 cities, proposing an evaluation method. A case study in Amsterdam with semi-structured interviews examines collection process impacts.", "result": "Biases in street view data distribution are uncovered, linked to city idiosyncrasies. The case study highlights how collection processes affect representation.", "conclusion": "City-specific factors cause biases in street view data. The proposed evaluation method and case study provide insights to mitigate these biases at their source."}}
{"id": "2505.10590", "pdf": "https://arxiv.org/pdf/2505.10590", "abs": "https://arxiv.org/abs/2505.10590", "authors": ["Xinmin Fang", "Lingfeng Tao", "Zhengxiong Li"], "title": "Anchoring AI Capabilities in Market Valuations: The Capability Realization Rate Model and Valuation Misalignment Risk", "categories": ["cs.CY", "cs.AI"], "comment": "11 pages, 3 figures, NeurIPS", "summary": "Recent breakthroughs in artificial intelligence (AI) have triggered surges in\nmarket valuations for AI-related companies, often outpacing the realization of\nunderlying capabilities. We examine the anchoring effect of AI capabilities on\nequity valuations and propose a Capability Realization Rate (CRR) model to\nquantify the gap between AI potential and realized performance. Using data from\nthe 2023--2025 generative AI boom, we analyze sector-level sensitivity and\nconduct case studies (OpenAI, Adobe, NVIDIA, Meta, Microsoft, Goldman Sachs) to\nillustrate patterns of valuation premium and misalignment. Our findings\nindicate that AI-native firms commanded outsized valuation premiums anchored to\nfuture potential, while traditional companies integrating AI experienced\nre-ratings subject to proof of tangible returns. We argue that CRR can help\nidentify valuation misalignment risk-where market prices diverge from realized\nAI-driven value. We conclude with policy recommendations to improve\ntransparency, mitigate speculative bubbles, and align AI innovation with\nsustainable market value.", "AI": {"tldr": "The paper examines the gap between AI potential and realized performance, proposing a Capability Realization Rate (CRR) model to quantify this disparity and analyze its impact on equity valuations during the 2023--2025 generative AI boom.", "motivation": "To understand how AI capabilities anchor equity valuations and identify risks of misalignment between market prices and realized AI-driven value.", "method": "The study uses sector-level data and case studies (e.g., OpenAI, Adobe, NVIDIA) to analyze valuation premiums and misalignment, introducing the CRR model for quantification.", "result": "AI-native firms had higher valuation premiums tied to future potential, while traditional firms faced re-ratings based on tangible returns. CRR helps identify valuation misalignment risks.", "conclusion": "Policy recommendations are proposed to enhance transparency, reduce speculative bubbles, and align AI innovation with sustainable market value."}}
{"id": "2505.11368", "pdf": "https://arxiv.org/pdf/2505.11368", "abs": "https://arxiv.org/abs/2505.11368", "authors": ["Lingxiao Diao", "Xinyue Xu", "Wanxuan Sun", "Cheng Yang", "Zhuosheng Zhang"], "title": "GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents", "categories": ["cs.CL"], "comment": "ACL 2025 Main Conference", "summary": "Large language models (LLMs) have been widely deployed as autonomous agents\ncapable of following user instructions and making decisions in real-world\napplications. Previous studies have made notable progress in benchmarking the\ninstruction following capabilities of LLMs in general domains, with a primary\nfocus on their inherent commonsense knowledge. Recently, LLMs have been\nincreasingly deployed as domain-oriented agents, which rely on domain-oriented\nguidelines that may conflict with their commonsense knowledge. These guidelines\nexhibit two key characteristics: they consist of a wide range of\ndomain-oriented rules and are subject to frequent updates. Despite these\nchallenges, the absence of comprehensive benchmarks for evaluating the\ndomain-oriented guideline following capabilities of LLMs presents a significant\nobstacle to their effective assessment and further development. In this paper,\nwe introduce GuideBench, a comprehensive benchmark designed to evaluate\nguideline following performance of LLMs. GuideBench evaluates LLMs on three\ncritical aspects: (i) adherence to diverse rules, (ii) robustness to rule\nupdates, and (iii) alignment with human preferences. Experimental results on a\nrange of LLMs indicate substantial opportunities for improving their ability to\nfollow domain-oriented guidelines.", "AI": {"tldr": "GuideBench is introduced to evaluate LLMs' ability to follow domain-oriented guidelines, addressing gaps in current benchmarks.", "motivation": "Existing benchmarks focus on general domains and commonsense knowledge, lacking evaluation for domain-specific guidelines in LLMs.", "method": "GuideBench assesses LLMs on rule adherence, robustness to updates, and human preference alignment.", "result": "Experiments show significant room for improvement in LLMs' guideline-following capabilities.", "conclusion": "GuideBench provides a crucial tool for advancing LLMs as domain-oriented agents."}}
{"id": "2505.10930", "pdf": "https://arxiv.org/pdf/2505.10930", "abs": "https://arxiv.org/abs/2505.10930", "authors": ["Congcong Zhu", "Xiaoyan Xu", "Jiayue Han", "Jingrun Chen"], "title": "Physics-informed Temporal Alignment for Auto-regressive PDE Foundation Models", "categories": ["cs.LG", "35Q68", "G.1.8"], "comment": "Accepted as a conference paper in ICML2025", "summary": "Auto-regressive partial differential equation (PDE) foundation models have\nshown great potential in handling time-dependent data. However, these models\nsuffer from the shortcut problem deeply rooted in auto-regressive prediction,\ncausing error accumulation. The challenge becomes particularly evident for\nout-of-distribution data, as the pretraining performance may approach random\nmodel initialization for downstream tasks with long-term dynamics. To deal with\nthis problem, we propose physics-informed temporal alignment (PITA), a\nself-supervised learning framework inspired by inverse problem solving.\nSpecifically, PITA aligns the physical dynamics discovered at different time\nsteps on each given PDE trajectory by integrating physics-informed constraints\ninto the self-supervision signal. The alignment is derived from observation\ndata without relying on known physics priors, indicating strong generalization\nability to the out-of-distribution data. Extensive experiments show that PITA\nsignificantly enhances the accuracy and robustness of existing foundation\nmodels on diverse time-dependent PDE data. The code is available at\nhttps://github.com/SCAILab-USTC/PITA.", "AI": {"tldr": "PITA, a self-supervised learning framework, addresses error accumulation in auto-regressive PDE models by aligning physical dynamics with physics-informed constraints, improving accuracy and robustness.", "motivation": "Auto-regressive PDE models suffer from error accumulation, especially for out-of-distribution data, limiting their effectiveness in long-term dynamics.", "method": "Proposes physics-informed temporal alignment (PITA), integrating physics constraints into self-supervision to align dynamics across time steps.", "result": "PITA significantly improves accuracy and robustness of foundation models on diverse PDE data.", "conclusion": "PITA effectively mitigates error accumulation and enhances generalization for out-of-distribution PDE tasks."}}
{"id": "2505.11060", "pdf": "https://arxiv.org/pdf/2505.11060", "abs": "https://arxiv.org/abs/2505.11060", "authors": ["David M\u00e9ndez", "Gianpaolo Bontempo", "Elisa Ficarra", "Roberto Confalonieri", "Natalia D\u00edaz-Rodr\u00edguez"], "title": "CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs", "categories": ["cs.CV", "cs.AI", "68T10", "I.2.4; I.5.2"], "comment": "8 pages, 3 figures, 5 tables. Accepted at IJCNN 2025; to appear in\n  IEEE Xplore", "summary": "Deep vision models often rely on biases learned from spurious correlations in\ndatasets. To identify these biases, methods that interpret high-level,\nhuman-understandable concepts are more effective than those relying primarily\non low-level features like heatmaps. A major challenge for these concept-based\nmethods is the lack of image annotations indicating potentially bias-inducing\nconcepts, since creating such annotations requires detailed labeling for each\ndataset and concept, which is highly labor-intensive. We present CUBIC (Concept\nembeddings for Unsupervised Bias IdentifiCation), a novel method that\nautomatically discovers interpretable concepts that may bias classifier\nbehavior. Unlike existing approaches, CUBIC does not rely on predefined bias\ncandidates or examples of model failures tied to specific biases, as such\ninformation is not always available. Instead, it leverages image-text latent\nspace and linear classifier probes to examine how the latent representation of\na superclass label$\\unicode{x2014}$shared by all instances in the\ndataset$\\unicode{x2014}$is influenced by the presence of a given concept. By\nmeasuring these shifts against the normal vector to the classifier's decision\nboundary, CUBIC identifies concepts that significantly influence model\npredictions. Our experiments demonstrate that CUBIC effectively uncovers\npreviously unknown biases using Vision-Language Models (VLMs) without requiring\nthe samples in the dataset where the classifier underperforms or prior\nknowledge of potential biases.", "AI": {"tldr": "CUBIC is a novel method for unsupervised bias identification in deep vision models, using concept embeddings without predefined bias candidates or failure examples.", "motivation": "Deep vision models often rely on dataset biases, but identifying these biases is challenging due to the lack of annotated concepts.", "method": "CUBIC leverages image-text latent space and linear classifier probes to measure how concepts influence model predictions.", "result": "CUBIC effectively uncovers unknown biases in Vision-Language Models without needing prior knowledge or failure samples.", "conclusion": "CUBIC provides a scalable, unsupervised solution for bias identification in deep learning models."}}
{"id": "2505.10593", "pdf": "https://arxiv.org/pdf/2505.10593", "abs": "https://arxiv.org/abs/2505.10593", "authors": ["Shanhui Zhao", "Hao Wen", "Wenjie Du", "Cheng Liang", "Yunxin Liu", "Xiaozhou Ye", "Ye Ouyang", "Yuanchun Li"], "title": "LLM-Explorer: Towards Efficient and Affordable LLM-based Exploration for Mobile Apps", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted by MobiCom 2025", "summary": "Large language models (LLMs) have opened new opportunities for automated\nmobile app exploration, an important and challenging problem that used to\nsuffer from the difficulty of generating meaningful UI interactions. However,\nexisting LLM-based exploration approaches rely heavily on LLMs to generate\nactions in almost every step, leading to a huge cost of token fees and\ncomputational resources. We argue that such extensive usage of LLMs is neither\nnecessary nor effective, since many actions during exploration do not require,\nor may even be biased by the abilities of LLMs. Further, based on the insight\nthat a precise and compact knowledge plays the central role for effective\nexploration, we introduce LLM-Explorer, a new exploration agent designed for\nefficiency and affordability. LLM-Explorer uses LLMs primarily for maintaining\nthe knowledge instead of generating actions, and knowledge is used to guide\naction generation in a LLM-less manner. Based on a comparison with 5 strong\nbaselines on 20 typical apps, LLM-Explorer was able to achieve the fastest and\nhighest coverage among all automated app explorers, with over 148x lower cost\nthan the state-of-the-art LLM-based approach.", "AI": {"tldr": "LLM-Explorer reduces reliance on LLMs for mobile app exploration by using them for knowledge maintenance instead of action generation, achieving higher efficiency and lower cost.", "motivation": "Existing LLM-based approaches for mobile app exploration are costly and inefficient due to excessive LLM usage for action generation.", "method": "LLM-Explorer focuses on maintaining precise knowledge with LLMs and uses this knowledge to guide actions without LLMs.", "result": "LLM-Explorer outperforms 5 baselines on 20 apps, achieving the fastest and highest coverage with 148x lower cost.", "conclusion": "LLM-Explorer demonstrates that efficient app exploration can be achieved by minimizing LLM usage for action generation."}}
{"id": "2505.11379", "pdf": "https://arxiv.org/pdf/2505.11379", "abs": "https://arxiv.org/abs/2505.11379", "authors": ["Alicia Gonz\u00e1lez Mart\u00ednez"], "title": "A computational system to handle the orthographic layer of tajwid in contemporary Quranic Orthography", "categories": ["cs.CL"], "comment": null, "summary": "Contemporary Quranic Orthography (CQO) relies on a precise system of phonetic\nnotation that can be traced back to the early stages of Islam, when the Quran\nwas mainly oral in nature and the first written renderings of it served as\nmemory aids for this oral tradition. The early systems of diacritical marks\ncreated on top of the Quranic Consonantal Text (QCT) motivated the creation and\nfurther development of a fine-grained system of phonetic notation that\nrepresented tajwid-the rules of recitation. We explored the systematicity of\nthe rules of tajwid, as they are encountered in the Cairo Quran, using a fully\nand accurately encoded digital edition of the Quranic text. For this purpose,\nwe developed a python module that can remove or add the orthographic layer of\ntajwid from a Quranic text in CQO. The interesting characteristic of these two\nsets of rules is that they address the complete Quranic text of the Cairo\nQuran, so they can be used as precise witnesses to study its phonetic and\nprosodic processes. From a computational point of view, the text of the Cairo\nQuran can be used as a linchpin to align and compare Quranic manuscripts, due\nto its richness and completeness. This will let us create a very powerful\nframework to work with the Arabic script, not just within an isolated text, but\nautomatically exploring a specific textual phenomenon in other connected\nmanuscripts. Having all the texts mapped among each other can serve as a\npowerful tool to study the nature of the notation systems of diacritics added\nto the consonantal skeleton.", "AI": {"tldr": "The paper explores the systematicity of tajwid rules in the Cairo Quran using a digital edition and a Python module to manipulate orthographic layers. It highlights the potential for computational alignment and comparison of Quranic manuscripts.", "motivation": "The study aims to understand the phonetic and prosodic processes in the Quran by analyzing tajwid rules, leveraging the precision of the Cairo Quran's digital edition.", "method": "A Python module was developed to add or remove the orthographic layer of tajwid from Quranic texts, enabling systematic analysis of the rules.", "result": "The rules of tajwid in the Cairo Quran provide a precise framework for studying phonetic notation and can computationally align and compare Quranic manuscripts.", "conclusion": "The study offers a powerful computational tool for analyzing Quranic manuscripts and understanding diacritic notation systems, extending beyond isolated texts to interconnected manuscripts."}}
{"id": "2505.10941", "pdf": "https://arxiv.org/pdf/2505.10941", "abs": "https://arxiv.org/abs/2505.10941", "authors": ["Ozan \u00d6zdenizci", "Elmar Rueckert", "Robert Legenstein"], "title": "Privacy-Aware Lifelong Learning", "categories": ["cs.LG"], "comment": null, "summary": "Lifelong learning algorithms enable models to incrementally acquire new\nknowledge without forgetting previously learned information. Contrarily, the\nfield of machine unlearning focuses on explicitly forgetting certain previous\nknowledge from pretrained models when requested, in order to comply with data\nprivacy regulations on the right-to-be-forgotten. Enabling efficient lifelong\nlearning with the capability to selectively unlearn sensitive information from\nmodels presents a critical and largely unaddressed challenge with contradicting\nobjectives. We address this problem from the perspective of simultaneously\npreventing catastrophic forgetting and allowing forward knowledge transfer\nduring task-incremental learning, while ensuring exact task unlearning and\nminimizing memory requirements, based on a single neural network model to be\nadapted. Our proposed solution, privacy-aware lifelong learning (PALL),\ninvolves optimization of task-specific sparse subnetworks with parameter\nsharing within a single architecture. We additionally utilize an episodic\nmemory rehearsal mechanism to facilitate exact unlearning without performance\ndegradations. We empirically demonstrate the scalability of PALL across various\narchitectures in image classification, and provide a state-of-the-art solution\nthat uniquely integrates lifelong learning and privacy-aware unlearning\nmechanisms for responsible AI applications.", "AI": {"tldr": "PALL integrates lifelong learning and privacy-aware unlearning in a single model, optimizing task-specific subnetworks and using memory rehearsal for exact unlearning.", "motivation": "To address the challenge of combining lifelong learning (retaining knowledge) with machine unlearning (forgetting sensitive data) for responsible AI.", "method": "Uses task-specific sparse subnetworks with parameter sharing and an episodic memory rehearsal mechanism.", "result": "Scalable across architectures in image classification, achieving exact unlearning without performance loss.", "conclusion": "PALL provides a state-of-the-art solution for integrating lifelong learning and privacy-aware unlearning."}}
{"id": "2505.11070", "pdf": "https://arxiv.org/pdf/2505.11070", "abs": "https://arxiv.org/abs/2505.11070", "authors": ["Renjie Chen", "Wenfeng Lin", "Yichen Zhang", "Jiangchuan Wei", "Boyuan Liu", "Chao Feng", "Jiao Ran", "Mingyu Guo"], "title": "Towards Self-Improvement of Diffusion Models via Group Preference Optimization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Aligning text-to-image (T2I) diffusion models with Direct Preference\nOptimization (DPO) has shown notable improvements in generation quality.\nHowever, applying DPO to T2I faces two challenges: the sensitivity of DPO to\npreference pairs and the labor-intensive process of collecting and annotating\nhigh-quality data. In this work, we demonstrate that preference pairs with\nmarginal differences can degrade DPO performance. Since DPO relies exclusively\non relative ranking while disregarding the absolute difference of pairs, it may\nmisclassify losing samples as wins, or vice versa. We empirically show that\nextending the DPO from pairwise to groupwise and incorporating reward\nstandardization for reweighting leads to performance gains without explicit\ndata selection. Furthermore, we propose Group Preference Optimization (GPO), an\neffective self-improvement method that enhances performance by leveraging the\nmodel's own capabilities without requiring external data. Extensive experiments\ndemonstrate that GPO is effective across various diffusion models and tasks.\nSpecifically, combining with widely used computer vision models, such as YOLO\nand OCR, the GPO improves the accurate counting and text rendering capabilities\nof the Stable Diffusion 3.5 Medium by 20 percentage points. Notably, as a\nplug-and-play method, no extra overhead is introduced during inference.", "AI": {"tldr": "The paper introduces Group Preference Optimization (GPO), a method to improve text-to-image diffusion models by addressing challenges in Direct Preference Optimization (DPO), such as sensitivity to preference pairs and data collection. GPO extends DPO to groupwise comparisons and uses reward standardization, enhancing performance without extra data or inference overhead.", "motivation": "DPO's sensitivity to preference pairs and the labor-intensive data annotation process limit its effectiveness in text-to-image diffusion models. The paper aims to overcome these challenges.", "method": "The authors propose GPO, which extends DPO from pairwise to groupwise comparisons and incorporates reward standardization for reweighting. This leverages the model's own capabilities without external data.", "result": "GPO improves performance across diffusion models and tasks, notably enhancing Stable Diffusion 3.5 Medium's counting and text rendering by 20 percentage points when combined with models like YOLO and OCR.", "conclusion": "GPO is an effective, plug-and-play method for improving text-to-image diffusion models without additional inference overhead, demonstrating broad applicability and performance gains."}}
{"id": "2505.10594", "pdf": "https://arxiv.org/pdf/2505.10594", "abs": "https://arxiv.org/abs/2505.10594", "authors": ["Ningxin Gui", "Qianghuai Jia", "Feijun Jiang", "Yuling Jiao", "dechun wang", "Jerry Zhijian Yang"], "title": "CRPE: Expanding The Reasoning Capability of Large Language Model for Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "We introduce CRPE (Code Reasoning Process Enhancer), an innovative\nthree-stage framework for data synthesis and model training that advances the\ndevelopment of sophisticated code reasoning capabilities in large language\nmodels (LLMs). Building upon existing system-1 models, CRPE addresses the\nfundamental challenge of enhancing LLMs' analytical and logical processing in\ncode generation tasks. Our framework presents a methodologically rigorous yet\nimplementable approach to cultivating advanced code reasoning abilities in\nlanguage models. Through the implementation of CRPE, we successfully develop an\nenhanced COT-Coder that demonstrates marked improvements in code generation\ntasks. Evaluation results on LiveCodeBench (20240701-20240901) demonstrate that\nour COT-Coder-7B-StepDPO, derived from Qwen2.5-Coder-7B-Base, with a pass@1\naccuracy of 21.88, exceeds all models with similar or even larger sizes.\nFurthermore, our COT-Coder-32B-StepDPO, based on Qwen2.5-Coder-32B-Base,\nexhibits superior performance with a pass@1 accuracy of 35.08, outperforming\nGPT4O on the benchmark. Overall, CRPE represents a comprehensive, open-source\nmethod that encompasses the complete pipeline from instruction data acquisition\nthrough expert code reasoning data synthesis, culminating in an autonomous\nreasoning enhancement mechanism.", "AI": {"tldr": "CRPE is a three-stage framework enhancing LLMs' code reasoning, improving models like COT-Coder-7B and COT-Coder-32B, which outperform others in benchmarks.", "motivation": "To enhance LLMs' analytical and logical processing in code generation tasks.", "method": "A three-stage framework (CRPE) for data synthesis and model training, building on system-1 models.", "result": "COT-Coder-7B and COT-Coder-32B achieve pass@1 accuracies of 21.88 and 35.08, outperforming similar or larger models including GPT4O.", "conclusion": "CRPE is a comprehensive, open-source method for improving LLMs' code reasoning from data synthesis to autonomous enhancement."}}
{"id": "2505.11413", "pdf": "https://arxiv.org/pdf/2505.11413", "abs": "https://arxiv.org/abs/2505.11413", "authors": ["Sijia Chen", "Xiaomin Li", "Mengxue Zhang", "Eric Hanchen Jiang", "Qingcheng Zeng", "Chen-Hsiang Yu"], "title": "CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly deployed in medical contexts,\nraising critical concerns about safety, alignment, and susceptibility to\nadversarial manipulation. While prior benchmarks assess model refusal\ncapabilities for harmful prompts, they often lack clinical specificity, graded\nharmfulness levels, and coverage of jailbreak-style attacks. We introduce CARES\n(Clinical Adversarial Robustness and Evaluation of Safety), a benchmark for\nevaluating LLM safety in healthcare. CARES includes over 18,000 prompts\nspanning eight medical safety principles, four harm levels, and four prompting\nstyles: direct, indirect, obfuscated, and role-play, to simulate both malicious\nand benign use cases. We propose a three-way response evaluation protocol\n(Accept, Caution, Refuse) and a fine-grained Safety Score metric to assess\nmodel behavior. Our analysis reveals that many state-of-the-art LLMs remain\nvulnerable to jailbreaks that subtly rephrase harmful prompts, while also\nover-refusing safe but atypically phrased queries. Finally, we propose a\nmitigation strategy using a lightweight classifier to detect jailbreak attempts\nand steer models toward safer behavior via reminder-based conditioning. CARES\nprovides a rigorous framework for testing and improving medical LLM safety\nunder adversarial and ambiguous conditions.", "AI": {"tldr": "CARES is a benchmark for evaluating LLM safety in healthcare, addressing gaps in existing benchmarks by including clinical specificity, graded harm levels, and jailbreak-style attacks. It reveals vulnerabilities in LLMs and proposes a mitigation strategy.", "motivation": "To address the lack of clinical specificity and graded harm levels in existing benchmarks for LLM safety in healthcare, and to evaluate susceptibility to adversarial manipulation.", "method": "CARES includes 18,000+ prompts across eight medical safety principles, four harm levels, and four prompting styles. It uses a three-way response evaluation protocol and a Safety Score metric.", "result": "State-of-the-art LLMs are vulnerable to jailbreaks and over-refuse safe queries. A lightweight classifier is proposed to mitigate jailbreak attempts.", "conclusion": "CARES offers a rigorous framework for improving medical LLM safety under adversarial conditions, highlighting vulnerabilities and proposing solutions."}}
{"id": "2505.10947", "pdf": "https://arxiv.org/pdf/2505.10947", "abs": "https://arxiv.org/abs/2505.10947", "authors": ["Kehan Long", "Jorge Cort\u00e9s", "Nikolay Atanasov"], "title": "Certifying Stability of Reinforcement Learning Policies using Generalized Lyapunov Functions", "categories": ["cs.LG", "cs.RO", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "We study the problem of certifying the stability of closed-loop systems under\ncontrol policies derived from optimal control or reinforcement learning (RL).\nClassical Lyapunov methods require a strict step-wise decrease in the Lyapunov\nfunction but such a certificate is difficult to construct for a learned control\npolicy. The value function associated with an RL policy is a natural Lyapunov\nfunction candidate but it is not clear how it should be modified. To gain\nintuition, we first study the linear quadratic regulator (LQR) problem and make\ntwo key observations. First, a Lyapunov function can be obtained from the value\nfunction of an LQR policy by augmenting it with a residual term related to the\nsystem dynamics and stage cost. Second, the classical Lyapunov decrease\nrequirement can be relaxed to a generalized Lyapunov condition requiring only\ndecrease on average over multiple time steps. Using this intuition, we consider\nthe nonlinear setting and formulate an approach to learn generalized Lyapunov\nfunctions by augmenting RL value functions with neural network residual terms.\nOur approach successfully certifies the stability of RL policies trained on\nGymnasium and DeepMind Control benchmarks. We also extend our method to jointly\ntrain neural controllers and stability certificates using a multi-step Lyapunov\nloss, resulting in larger certified inner approximations of the region of\nattraction compared to the classical Lyapunov approach. Overall, our\nformulation enables stability certification for a broad class of systems with\nlearned policies by making certificates easier to construct, thereby bridging\nclassical control theory and modern learning-based methods.", "AI": {"tldr": "The paper proposes a method to certify stability for learned control policies by augmenting RL value functions with neural network residuals, relaxing classical Lyapunov conditions.", "motivation": "Classical Lyapunov methods are hard to apply to learned policies; the study aims to bridge control theory and learning-based methods.", "method": "Augment RL value functions with neural network residuals and relax Lyapunov conditions to require only average decrease over multiple steps.", "result": "Successfully certifies stability for RL policies on benchmarks and improves certified regions of attraction.", "conclusion": "The approach enables easier stability certification for learned policies, integrating classical and modern methods."}}
{"id": "2505.11075", "pdf": "https://arxiv.org/pdf/2505.11075", "abs": "https://arxiv.org/abs/2505.11075", "authors": ["Jianghang Lin", "Yilin Lu", "Yunhang Shen", "Chaoyang Zhu", "Shengchuan Zhang", "Liujuan Cao", "Rongrong Ji"], "title": "Pseudo-Label Quality Decoupling and Correction for Semi-Supervised Instance Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Semi-Supervised Instance Segmentation (SSIS) involves classifying and\ngrouping image pixels into distinct object instances using limited labeled\ndata. This learning paradigm usually faces a significant challenge of unstable\nperformance caused by noisy pseudo-labels of instance categories and pixel\nmasks. We find that the prevalent practice of filtering instance pseudo-labels\nassessing both class and mask quality with a single score threshold, frequently\nleads to compromises in the trade-off between the qualities of class and mask\nlabels. In this paper, we introduce a novel Pseudo-Label Quality Decoupling and\nCorrection (PL-DC) framework for SSIS to tackle the above challenges. Firstly,\nat the instance level, a decoupled dual-threshold filtering mechanism is\ndesigned to decouple class and mask quality estimations for instance-level\npseudo-labels, thereby independently controlling pixel classifying and grouping\nqualities. Secondly, at the category level, we introduce a dynamic instance\ncategory correction module to dynamically correct the pseudo-labels of instance\ncategories, effectively alleviating category confusion. Lastly, we introduce a\npixel-level mask uncertainty-aware mechanism at the pixel level to re-weight\nthe mask loss for different pixels, thereby reducing the impact of noise\nintroduced by pixel-level mask pseudo-labels. Extensive experiments on the COCO\nand Cityscapes datasets demonstrate that the proposed PL-DC achieves\nsignificant performance improvements, setting new state-of-the-art results for\nSSIS. Notably, our PL-DC shows substantial gains even with minimal labeled\ndata, achieving an improvement of +11.6 mAP with just 1% COCO labeled data and\n+15.5 mAP with 5% Cityscapes labeled data. The code will be public.", "AI": {"tldr": "The paper introduces PL-DC, a framework for Semi-Supervised Instance Segmentation (SSIS) that decouples and corrects pseudo-label quality at instance, category, and pixel levels, achieving state-of-the-art results.", "motivation": "The challenge of unstable performance in SSIS due to noisy pseudo-labels for instance categories and pixel masks motivates the need for a better approach.", "method": "PL-DC uses a decoupled dual-threshold filtering mechanism, dynamic instance category correction, and a pixel-level mask uncertainty-aware mechanism.", "result": "PL-DC achieves significant improvements, e.g., +11.6 mAP with 1% COCO data and +15.5 mAP with 5% Cityscapes data.", "conclusion": "PL-DC effectively addresses pseudo-label noise in SSIS, setting new benchmarks with minimal labeled data."}}
{"id": "2505.10596", "pdf": "https://arxiv.org/pdf/2505.10596", "abs": "https://arxiv.org/abs/2505.10596", "authors": ["Retno Larasati"], "title": "Inclusivity of AI Speech in Healthcare: A Decade Look Back", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The integration of AI speech recognition technologies into healthcare has the\npotential to revolutionize clinical workflows and patient-provider\ncommunication. However, this study reveals significant gaps in inclusivity,\nwith datasets and research disproportionately favouring high-resource\nlanguages, standardized accents, and narrow demographic groups. These biases\nrisk perpetuating healthcare disparities, as AI systems may misinterpret speech\nfrom marginalized groups. This paper highlights the urgent need for inclusive\ndataset design, bias mitigation research, and policy frameworks to ensure\nequitable access to AI speech technologies in healthcare.", "AI": {"tldr": "AI speech recognition in healthcare shows promise but lacks inclusivity, favoring high-resource languages and narrow demographics, risking disparities.", "motivation": "To address biases in AI speech recognition that exclude marginalized groups in healthcare.", "method": "Analysis of datasets and research to identify gaps in inclusivity.", "result": "Found biases favoring high-resource languages, standardized accents, and limited demographics.", "conclusion": "Urges inclusive dataset design, bias mitigation, and policy frameworks for equitable AI speech tech in healthcare."}}
{"id": "2505.11421", "pdf": "https://arxiv.org/pdf/2505.11421", "abs": "https://arxiv.org/abs/2505.11421", "authors": ["Phan Tran Minh Dat", "Vo Hoang Nhat Khang", "Quan Thanh Tho"], "title": "Towards Cultural Bridge by Bahnaric-Vietnamese Translation Using Transfer Learning of Sequence-To-Sequence Pre-training Language Model", "categories": ["cs.CL"], "comment": null, "summary": "This work explores the journey towards achieving Bahnaric-Vietnamese\ntranslation for the sake of culturally bridging the two ethnic groups in\nVietnam. However, translating from Bahnaric to Vietnamese also encounters some\ndifficulties. The most prominent challenge is the lack of available original\nBahnaric resources source language, including vocabulary, grammar, dialogue\npatterns and bilingual corpus, which hinders the data collection process for\ntraining. To address this, we leverage a transfer learning approach using\nsequence-to-sequence pre-training language model. First of all, we leverage a\npre-trained Vietnamese language model to capture the characteristics of this\nlanguage. Especially, to further serve the purpose of machine translation, we\naim for a sequence-to-sequence model, not encoder-only like BERT or\ndecoder-only like GPT. Taking advantage of significant similarity between the\ntwo languages, we continue training the model with the currently limited\nbilingual resources of Vietnamese-Bahnaric text to perform the transfer\nlearning from language model to machine translation. Thus, this approach can\nhelp to handle the problem of imbalanced resources between two languages, while\nalso optimizing the training and computational processes. Additionally, we also\nenhanced the datasets using data augmentation to generate additional resources\nand defined some heuristic methods to help the translation more precise. Our\napproach has been validated to be highly effective for the Bahnaric-Vietnamese\ntranslation model, contributing to the expansion and preservation of languages,\nand facilitating better mutual understanding between the two ethnic people.", "AI": {"tldr": "The paper proposes a transfer learning approach using a sequence-to-sequence model for Bahnaric-Vietnamese translation, addressing resource scarcity through pre-training and data augmentation.", "motivation": "To bridge cultural gaps between Bahnaric and Vietnamese ethnic groups in Vietnam by enabling translation, despite challenges like limited Bahnaric resources.", "method": "Leverages a pre-trained Vietnamese sequence-to-sequence model, fine-tuned with limited bilingual data, and uses data augmentation and heuristics for improved translation.", "result": "The approach effectively handles resource imbalance and optimizes training, proving highly effective for Bahnaric-Vietnamese translation.", "conclusion": "The method successfully aids language preservation and mutual understanding, demonstrating the potential of transfer learning for low-resource languages."}}
{"id": "2505.10949", "pdf": "https://arxiv.org/pdf/2505.10949", "abs": "https://arxiv.org/abs/2505.10949", "authors": ["Chenhui Xu", "Dancheng Liu", "Amir Nassereldine", "Jinjun Xiong"], "title": "FP64 is All You Need: Rethinking Failure Modes in Physics-Informed Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Physics Informed Neural Networks (PINNs) often exhibit failure modes in which\nthe PDE residual loss converges while the solution error stays large, a\nphenomenon traditionally blamed on local optima separated from the true\nsolution by steep loss barriers. We challenge this understanding by demonstrate\nthat the real culprit is insufficient arithmetic precision: with standard FP32,\nthe LBFGS optimizer prematurely satisfies its convergence test, freezing the\nnetwork in a spurious failure phase. Simply upgrading to FP64 rescues\noptimization, enabling vanilla PINNs to solve PDEs without any failure modes.\nThese results reframe PINN failure modes as precision induced stalls rather\nthan inescapable local minima and expose a three stage training dynamic\nunconverged, failure, success whose boundaries shift with numerical precision.\nOur findings emphasize that rigorous arithmetic precision is the key to\ndependable PDE solving with neural networks.", "AI": {"tldr": "PINNs fail due to insufficient arithmetic precision (FP32), not local optima. Using FP64 resolves the issue, enabling reliable PDE solving.", "motivation": "To challenge the traditional belief that PINN failures are due to local optima and identify the real cause\u2014insufficient arithmetic precision.", "method": "Analyzed PINN training dynamics with FP32 and FP64 precision, using the LBFGS optimizer to observe convergence behavior.", "result": "FP32 causes premature convergence, freezing PINNs in failure phases. FP64 eliminates failure modes, enabling successful PDE solving.", "conclusion": "Arithmetic precision (FP64) is crucial for dependable PINN performance, reframing failure modes as precision-induced stalls."}}
{"id": "2505.11099", "pdf": "https://arxiv.org/pdf/2505.11099", "abs": "https://arxiv.org/abs/2505.11099", "authors": ["Bin Liu", "Chunyang Wang", "Xuelian Liu", "Guan Xi", "Ge Zhang", "Ziteng Yao", "Mengxue Dong"], "title": "Hybrid-Emba3D: Geometry-Aware and Cross-Path Feature Hybrid Enhanced State Space Model for Point Cloud Classification", "categories": ["cs.CV"], "comment": null, "summary": "The point cloud classification tasks face the dual challenge of efficiently\nextracting local geometric features while maintaining model complexity. The\nMamba architecture utilizes the linear complexity advantage of state space\nmodels (SSMs) to overcome the computational bottleneck of Transformers while\nbalancing global modeling capabilities. However, the inherent contradiction\nbetween its unidirectional dependency and the unordered nature of point clouds\nimpedes modeling spatial correlation in local neighborhoods, thus constraining\ngeometric feature extraction. This paper proposes Hybrid-Emba3D, a\nbidirectional Mamba model enhanced by geometry-feature coupling and cross-path\nfeature hybridization. The Local geometric pooling with geometry-feature\ncoupling mechanism significantly enhances local feature discriminative power\nvia coordinated propagation and dynamic aggregation of geometric information\nbetween local center points and their neighborhoods, without introducing\nadditional parameters. The designed Collaborative feature enhancer adopts\ndual-path hybridization, effectively handling local mutations and sparse key\nsignals, breaking through the limitations of traditional SSM long-range\nmodeling. Experimental results demonstrate that the proposed model achieves a\nnew SOTA classification accuracy of 95.99% on ModelNet40 with only 0.03M\nadditional.", "AI": {"tldr": "Hybrid-Emba3D, a bidirectional Mamba model, enhances point cloud classification by coupling geometry-features and cross-path hybridization, achieving 95.99% accuracy on ModelNet40 with minimal added complexity.", "motivation": "Address the challenge of efficiently extracting local geometric features in point clouds while balancing model complexity, overcoming limitations of unidirectional Mamba architectures.", "method": "Proposes Hybrid-Emba3D with geometry-feature coupling and cross-path hybridization, enhancing local feature discriminative power and handling sparse signals.", "result": "Achieves state-of-the-art 95.99% classification accuracy on ModelNet40 with only 0.03M additional parameters.", "conclusion": "Hybrid-Emba3D effectively balances local feature extraction and global modeling, outperforming traditional SSMs in point cloud classification."}}
{"id": "2505.10603", "pdf": "https://arxiv.org/pdf/2505.10603", "abs": "https://arxiv.org/abs/2505.10603", "authors": ["Jorge Machado"], "title": "Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Generative artificial intelligence (Gen AI) systems represent a critical\ntechnology with far-reaching implications across multiple domains of society.\nHowever, their deployment entails a range of risks and challenges that require\ncareful evaluation. To date, there has been a lack of comprehensive,\ninterdisciplinary studies offering a systematic comparison between open-source\nand proprietary (closed) generative AI systems, particularly regarding their\nrespective advantages and drawbacks. This study aims to: i) critically evaluate\nand compare the characteristics, opportunities, and challenges of open and\nclosed generative AI models; and ii) propose foundational elements for the\ndevelopment of an Open, Public, and Safe Gen AI framework. As a methodology, we\nadopted a combined approach that integrates three methods: literature review,\ncritical analysis, and comparative analysis. The proposed framework outlines\nkey dimensions, openness, public governance, and security, as essential pillars\nfor shaping the future of trustworthy and inclusive Gen AI. Our findings reveal\nthat open models offer greater transparency, auditability, and flexibility,\nenabling independent scrutiny and bias mitigation. In contrast, closed systems\noften provide better technical support and ease of implementation, but at the\ncost of unequal access, accountability, and ethical oversight. The research\nalso highlights the importance of multi-stakeholder governance, environmental\nsustainability, and regulatory frameworks in ensuring responsible development.", "AI": {"tldr": "The paper compares open-source and proprietary generative AI systems, highlighting their pros and cons, and proposes a framework for open, public, and safe Gen AI.", "motivation": "Address the lack of comprehensive studies comparing open and closed Gen AI systems and their societal implications.", "method": "Combined approach: literature review, critical analysis, and comparative analysis.", "result": "Open models offer transparency and flexibility; closed systems provide better support but lack accountability.", "conclusion": "A multi-stakeholder governance framework is essential for trustworthy and inclusive Gen AI."}}
{"id": "2505.11423", "pdf": "https://arxiv.org/pdf/2505.11423", "abs": "https://arxiv.org/abs/2505.11423", "authors": ["Xiaomin Li", "Zhou Yu", "Zhiwei Zhang", "Xupeng Chen", "Ziji Zhang", "Yingying Zhuang", "Narayanan Sadagopan", "Anurag Beniwal"], "title": "When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning-enhanced large language models (RLLMs), whether explicitly trained\nfor reasoning or prompted via chain-of-thought (CoT), have achieved\nstate-of-the-art performance on many complex reasoning tasks. However, we\nuncover a surprising and previously overlooked phenomenon: explicit CoT\nreasoning can significantly degrade instruction-following accuracy. Evaluating\n15 models on two benchmarks: IFEval (with simple, rule-verifiable constraints)\nand ComplexBench (with complex, compositional constraints), we consistently\nobserve performance drops when CoT prompting is applied. Through large-scale\ncase studies and an attention-based analysis, we identify common patterns where\nreasoning either helps (e.g., with formatting or lexical precision) or hurts\n(e.g., by neglecting simple constraints or introducing unnecessary content). We\npropose a metric, constraint attention, to quantify model focus during\ngeneration and show that CoT reasoning often diverts attention away from\ninstruction-relevant tokens. To mitigate these effects, we introduce and\nevaluate four strategies: in-context learning, self-reflection, self-selective\nreasoning, and classifier-selective reasoning. Our results demonstrate that\nselective reasoning strategies, particularly classifier-selective reasoning,\ncan substantially recover lost performance. To our knowledge, this is the first\nwork to systematically expose reasoning-induced failures in\ninstruction-following and offer practical mitigation strategies.", "AI": {"tldr": "Explicit chain-of-thought (CoT) reasoning in large language models can degrade instruction-following accuracy, as shown in evaluations of 15 models on IFEval and ComplexBench. The study identifies patterns where reasoning helps or hurts performance and proposes mitigation strategies like selective reasoning.", "motivation": "To uncover the overlooked phenomenon of reasoning-induced performance degradation in instruction-following tasks and develop strategies to mitigate it.", "method": "Evaluated 15 models on IFEval and ComplexBench, analyzed attention patterns, and proposed four mitigation strategies (in-context learning, self-reflection, self-selective reasoning, classifier-selective reasoning).", "result": "CoT reasoning often diverts attention from instruction-relevant tokens, degrading performance. Selective reasoning strategies, especially classifier-selective reasoning, recover lost performance.", "conclusion": "This work systematically exposes reasoning-induced failures in instruction-following and offers practical mitigation strategies, marking the first such study."}}
{"id": "2505.10950", "pdf": "https://arxiv.org/pdf/2505.10950", "abs": "https://arxiv.org/abs/2505.10950", "authors": ["Tianshuo Zhang", "Gao Jia", "Wenzhe Zhai", "Rui Yann", "Xianglei Xing"], "title": "Shackled Dancing: A Bit-Locked Diffusion Algorithm for Lossless and Controllable Image Steganography", "categories": ["cs.LG"], "comment": null, "summary": "Data steganography aims to conceal information within visual content, yet\nexisting spatial- and frequency-domain approaches suffer from trade-offs\nbetween security, capacity, and perceptual quality. Recent advances in\ngenerative models, particularly diffusion models, offer new avenues for\nadaptive image synthesis, but integrating precise information embedding into\nthe generative process remains challenging. We introduce Shackled Dancing\nDiffusion, or SD$^2$, a plug-and-play generative steganography method that\ncombines bit-position locking with diffusion sampling injection to enable\ncontrollable information embedding within the generative trajectory. SD$^2$\nleverages the expressive power of diffusion models to synthesize diverse\ncarrier images while maintaining full message recovery with $100\\%$ accuracy.\nOur method achieves a favorable balance between randomness and constraint,\nenhancing robustness against steganalysis without compromising image fidelity.\nExtensive experiments show that SD$^2$ substantially outperforms prior methods\nin security, embedding capacity, and stability. This algorithm offers new\ninsights into controllable generation and opens promising directions for secure\nvisual communication.", "AI": {"tldr": "SD\u00b2 is a generative steganography method using diffusion models for secure, high-capacity, and high-fidelity information embedding.", "motivation": "Existing steganography methods struggle with balancing security, capacity, and perceptual quality. Diffusion models offer potential but lack precise control for information embedding.", "method": "SD\u00b2 combines bit-position locking and diffusion sampling injection to embed information controllably during image synthesis.", "result": "SD\u00b2 achieves 100% message recovery, outperforms prior methods in security, capacity, and stability, and maintains image fidelity.", "conclusion": "SD\u00b2 advances controllable generation and secure visual communication, offering a robust solution for steganography."}}
{"id": "2505.11110", "pdf": "https://arxiv.org/pdf/2505.11110", "abs": "https://arxiv.org/abs/2505.11110", "authors": ["Massimiliano Cassia", "Luca Guarnera", "Mirko Casu", "Ignazio Zangara", "Sebastiano Battiato"], "title": "Deepfake Forensic Analysis: Source Dataset Attribution and Legal Implications of Synthetic Media Manipulation", "categories": ["cs.CV"], "comment": null, "summary": "Synthetic media generated by Generative Adversarial Networks (GANs) pose\nsignificant challenges in verifying authenticity and tracing dataset origins,\nraising critical concerns in copyright enforcement, privacy protection, and\nlegal compliance. This paper introduces a novel forensic framework for\nidentifying the training dataset (e.g., CelebA or FFHQ) of GAN-generated images\nthrough interpretable feature analysis. By integrating spectral transforms\n(Fourier/DCT), color distribution metrics, and local feature descriptors\n(SIFT), our pipeline extracts discriminative statistical signatures embedded in\nsynthetic outputs. Supervised classifiers (Random Forest, SVM, XGBoost) achieve\n98-99% accuracy in binary classification (real vs. synthetic) and multi-class\ndataset attribution across diverse GAN architectures (StyleGAN, AttGAN, GDWCT,\nStarGAN, and StyleGAN2). Experimental results highlight the dominance of\nfrequency-domain features (DCT/FFT) in capturing dataset-specific artifacts,\nsuch as upsampling patterns and spectral irregularities, while color histograms\nreveal implicit regularization strategies in GAN training. We further examine\nlegal and ethical implications, showing how dataset attribution can address\ncopyright infringement, unauthorized use of personal data, and regulatory\ncompliance under frameworks like GDPR and California's AB 602. Our framework\nadvances accountability and governance in generative modeling, with\napplications in digital forensics, content moderation, and intellectual\nproperty litigation.", "AI": {"tldr": "A forensic framework identifies GAN-generated images' training datasets using spectral, color, and local features, achieving high accuracy (98-99%) and addressing legal/ethical concerns.", "motivation": "Challenges in verifying GAN-generated media authenticity and tracing dataset origins, impacting copyright, privacy, and legal compliance.", "method": "Uses spectral transforms (Fourier/DCT), color metrics, and SIFT features with supervised classifiers (Random Forest, SVM, XGBoost) for dataset attribution.", "result": "Achieves 98-99% accuracy in binary and multi-class classification, highlighting frequency-domain features' dominance.", "conclusion": "The framework enhances accountability in generative modeling, with applications in forensics, moderation, and litigation."}}
{"id": "2505.10640", "pdf": "https://arxiv.org/pdf/2505.10640", "abs": "https://arxiv.org/abs/2505.10640", "authors": ["Kirill Vasilevski", "Benjamin Rombaut", "Gopi Krishnan Rajbahadur", "Gustavo A. Oliva", "Keheliya Gallaba", "Filipe R. Cogo", "Jiahuei", "Lin", "Dayi Lin", "Haoxiang Zhang", "Bouyan Chen", "Kishanthan Thangarajah", "Ahmed E. Hassan", "Zhen Ming", "Jiang"], "title": "The Hitchhikers Guide to Production-ready Trustworthy Foundation Model powered Software (FMware)", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Foundation Models (FMs) such as Large Language Models (LLMs) are reshaping\nthe software industry by enabling FMware, systems that integrate these FMs as\ncore components. In this KDD 2025 tutorial, we present a comprehensive\nexploration of FMware that combines a curated catalogue of challenges with\nreal-world production concerns. We first discuss the state of research and\npractice in building FMware. We further examine the difficulties in selecting\nsuitable models, aligning high-quality domain-specific data, engineering robust\nprompts, and orchestrating autonomous agents. We then address the complex\njourney from impressive demos to production-ready systems by outlining issues\nin system testing, optimization, deployment, and integration with legacy\nsoftware. Drawing on our industrial experience and recent research in the area,\nwe provide actionable insights and a technology roadmap for overcoming these\nchallenges. Attendees will gain practical strategies to enable the creation of\ntrustworthy FMware in the evolving technology landscape.", "AI": {"tldr": "A tutorial on FMware (systems integrating Foundation Models like LLMs) covering challenges, production concerns, and practical strategies for building trustworthy systems.", "motivation": "To address the growing impact of Foundation Models (FMs) in software and provide actionable insights for integrating them into production-ready systems.", "method": "Combines a curated catalogue of challenges with real-world production concerns, discussing model selection, data alignment, prompt engineering, and system deployment.", "result": "Provides actionable insights and a technology roadmap for overcoming challenges in FMware development.", "conclusion": "Attendees will gain practical strategies to create trustworthy FMware in the evolving tech landscape."}}
{"id": "2505.11436", "pdf": "https://arxiv.org/pdf/2505.11436", "abs": "https://arxiv.org/abs/2505.11436", "authors": ["Chenkai Zhang", "Yiming Lei", "Zeming Liu", "Haitao Leng", "Shaoguo Liu", "Tingting Gao", "Qingjie Liu", "Yunhong Wang"], "title": "GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art", "categories": ["cs.CL", "cs.AI"], "comment": "69 pages, 66 figures, accepted by ACL 2025", "summary": "Video Comment Art enhances user engagement by providing creative content that\nconveys humor, satire, or emotional resonance, requiring a nuanced and\ncomprehensive grasp of cultural and contextual subtleties. Although Multimodal\nLarge Language Models (MLLMs) and Chain-of-Thought (CoT) have demonstrated\nstrong reasoning abilities in STEM tasks (e.g. mathematics and coding), they\nstill struggle to generate creative expressions such as resonant jokes and\ninsightful satire. Moreover, existing benchmarks are constrained by their\nlimited modalities and insufficient categories, hindering the exploration of\ncomprehensive creativity in video-based Comment Art creation. To address these\nlimitations, we introduce GODBench, a novel benchmark that integrates video and\ntext modalities to systematically evaluate MLLMs' abilities to compose Comment\nArt. Furthermore, inspired by the propagation patterns of waves in physics, we\npropose Ripple of Thought (RoT), a multi-step reasoning framework designed to\nenhance the creativity of MLLMs. Extensive experiments reveal that existing\nMLLMs and CoT methods still face significant challenges in understanding and\ngenerating creative video comments. In contrast, RoT provides an effective\napproach to improve creative composing, highlighting its potential to drive\nmeaningful advancements in MLLM-based creativity. GODBench is publicly\navailable at https://github.com/stan-lei/GODBench-ACL2025.", "AI": {"tldr": "GODBench is a new benchmark for evaluating MLLMs' ability to create creative video comments, and RoT is a framework to enhance their creativity.", "motivation": "Existing MLLMs and benchmarks struggle with creative tasks like humor and satire in video comments.", "method": "Introduce GODBench for multimodal evaluation and propose Ripple of Thought (RoT) for multi-step reasoning.", "result": "RoT improves MLLMs' creative output, while current methods still lag in understanding and generating creative comments.", "conclusion": "RoT shows promise for advancing MLLM-based creativity, with GODBench as a tool for future research."}}
{"id": "2505.10951", "pdf": "https://arxiv.org/pdf/2505.10951", "abs": "https://arxiv.org/abs/2505.10951", "authors": ["Qiuyu Zhu", "Liang Zhang", "Qianxiong Xu", "Cheng Long", "Jie Zhang"], "title": "SubGCache: Accelerating Graph-based RAG with Subgraph-level KV Cache", "categories": ["cs.LG"], "comment": null, "summary": "Graph-based retrieval-augmented generation (RAG) enables large language\nmodels (LLMs) to incorporate structured knowledge via graph retrieval as\ncontextual input, enhancing more accurate and context-aware reasoning. We\nobserve that for different queries, it could retrieve similar subgraphs as\nprompts, and thus we propose SubGCache, which aims to reduce inference latency\nby reusing computation across queries with similar structural prompts (i.e.,\nsubgraphs). Specifically, SubGCache clusters queries based on subgraph\nembeddings, constructs a representative subgraph for each cluster, and\npre-computes the key-value (KV) cache of the representative subgraph. For each\nquery with its retrieved subgraph within a cluster, it reuses the pre-computed\nKV cache of the representative subgraph of the cluster without computing the KV\ntensors again for saving computation. Experiments on two new datasets across\nmultiple LLM backbones and graph-based RAG frameworks demonstrate that\nSubGCache consistently reduces inference latency with comparable and even\nimproved generation quality, achieving up to 6.68$\\times$ reduction in\ntime-to-first-token (TTFT).", "AI": {"tldr": "SubGCache reduces LLM inference latency by reusing pre-computed KV caches for similar subgraph prompts.", "motivation": "To address inefficiency in graph-based RAG systems where similar subgraphs are repeatedly computed for different queries.", "method": "Clusters queries by subgraph embeddings, pre-computes KV caches for representative subgraphs, and reuses them for similar queries.", "result": "Achieves up to 6.68\u00d7 reduction in TTFT with comparable or improved generation quality.", "conclusion": "SubGCache effectively optimizes computation in graph-based RAG systems without sacrificing performance."}}
{"id": "2505.11121", "pdf": "https://arxiv.org/pdf/2505.11121", "abs": "https://arxiv.org/abs/2505.11121", "authors": ["Mathis J\u00fcrgen Adler", "Leonard Hackel", "Gencer Sumbul", "Beg\u00fcm Demir"], "title": "Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing", "categories": ["cs.CV"], "comment": "Accepted at IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS) 2025. Our code is available at\n  https://git.tu-berlin.de/rsim/redundacy-aware-rs-vlm", "summary": "The development of foundation models through pretraining of vision-language\nmodels (VLMs) has recently attracted great attention in remote sensing (RS).\nVLM pretraining aims to learn image and language alignments from a large number\nof image-text pairs. Each pretraining image is often associated with multiple\ncaptions containing redundant information due to repeated or semantically\nsimilar phrases, resulting in increased pretraining and inference time. To\novercome this, we introduce a weighted feature aggregation (WFA) strategy for\nVLM pretraining in RS. Our strategy aims to extract and exploit complementary\ninformation from multiple captions per image while reducing redundancies\nthrough feature aggregation with importance weighting. To calculate adaptive\nimportance weights for different captions of each image, we propose two\ntechniques: (i) non-parametric uniqueness and (ii) learning-based attention. In\nthe first technique, importance weights are calculated based on the bilingual\nevaluation understudy (BLEU) scores of the captions to emphasize unique\nsentences and reduce the influence of repetitive ones. In the second technique,\nimportance weights are learned through an attention mechanism instead of\nrelying on hand-crafted features. The effectiveness of the proposed WFA\nstrategy with the two techniques is analyzed in terms of downstream performance\non text-to-image retrieval in RS. Experimental results show that the proposed\nstrategy enables efficient and effective pretraining of VLMs in RS. Based on\nthe experimental analysis, we derive guidelines for selecting appropriate\ntechniques depending on downstream task requirements and resource constraints.\nThe code of this work is publicly available at\nhttps://git.tu-berlin.de/rsim/redundacy-aware-rs-vlm.", "AI": {"tldr": "The paper introduces a weighted feature aggregation (WFA) strategy for pretraining vision-language models (VLMs) in remote sensing, reducing redundancy in captions and improving efficiency.", "motivation": "Addressing redundancy in multiple captions per image during VLM pretraining, which increases computational costs and inefficiencies.", "method": "Proposes WFA with two techniques: (i) non-parametric uniqueness (BLEU-based weights) and (ii) learning-based attention for adaptive caption weighting.", "result": "Demonstrates improved efficiency and effectiveness in VLM pretraining, validated by text-to-image retrieval performance.", "conclusion": "Provides guidelines for technique selection based on task requirements and resource constraints, with publicly available code."}}
{"id": "2505.10681", "pdf": "https://arxiv.org/pdf/2505.10681", "abs": "https://arxiv.org/abs/2505.10681", "authors": ["\u00d6nder G\u00fcrcan", "Vanja Falck", "Markus G. Rousseau", "Larissa L. Lima"], "title": "Towards an LLM-powered Social Digital Twinning Platform", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "13 pages, 3 figures, 23rd International Conference on Practical\n  applications of Agents and Multi-Agent Systems (PAAMS 2025)", "summary": "We present Social Digital Twinner, an innovative social simulation tool for\nexploring plausible effects of what-if scenarios in complex adaptive social\nsystems. The architecture is composed of three seamlessly integrated parts: a\ndata infrastructure featuring real-world data and a multi-dimensionally\nrepresentative synthetic population of citizens, an LLM-enabled agent-based\nsimulation engine, and a user interface that enable intuitive, natural language\ninteractions with the simulation engine and the artificial agents (i.e.\ncitizens). Social Digital Twinner facilitates real-time engagement and empowers\nstakeholders to collaboratively design, test, and refine intervention measures.\nThe approach is promoting a data-driven and evidence-based approach to societal\nproblem-solving. We demonstrate the tool's interactive capabilities by\naddressing the critical issue of youth school dropouts in Kragero, Norway,\nshowcasing its ability to create and execute a dedicated social digital twin\nusing natural language.", "AI": {"tldr": "Social Digital Twinner is a tool for simulating social scenarios using real-world data, LLM-enabled agents, and natural language interaction to test interventions like youth school dropout prevention.", "motivation": "To enable data-driven, evidence-based societal problem-solving by simulating complex social systems.", "method": "Combines real-world data, synthetic populations, LLM-based agent simulation, and natural language UI for interactive scenario testing.", "result": "Demonstrated effectiveness in addressing youth school dropouts in Kragero, Norway, through interactive simulation.", "conclusion": "The tool empowers stakeholders to collaboratively design and refine interventions using real-time social simulations."}}
{"id": "2505.11441", "pdf": "https://arxiv.org/pdf/2505.11441", "abs": "https://arxiv.org/abs/2505.11441", "authors": ["Xianzhen Luo", "Shijie Xuyang", "Tianhao Cheng", "Zheng Chu", "Houyi Li", "ziqi wang", "Siming Huang", "Qingfu Zhu", "Qiufeng Wang", "Xiangyu Zhang", "Shuigeng Zhou", "Wanxiang Che"], "title": "Is Compression Really Linear with Code Intelligence?", "categories": ["cs.CL"], "comment": "work in progress", "summary": "Understanding the relationship between data compression and the capabilities\nof Large Language Models (LLMs) is crucial, especially in specialized domains\nlike code intelligence. Prior work posited a linear relationship between\ncompression and general intelligence. However, it overlooked the multifaceted\nnature of code that encompasses diverse programming languages and tasks, and\nstruggled with fair evaluation of modern Code LLMs. We address this by\nevaluating a diverse array of open-source Code LLMs on comprehensive\nmulti-language, multi-task code benchmarks. To address the challenge of\nefficient and fair evaluation of pre-trained LLMs' code intelligence, we\nintroduce \\textit{Format Annealing}, a lightweight, transparent training\nmethodology designed to assess the intrinsic capabilities of these pre-trained\nmodels equitably. Compression efficacy, measured as bits-per-character (BPC),\nis determined using a novel, large-scale, and previously unseen code validation\nset derived from GitHub. Our empirical results reveal a fundamental logarithmic\nrelationship between measured code intelligence and BPC. This finding refines\nprior hypotheses of linearity, which we suggest are likely observations of the\nlogarithmic curve's tail under specific, limited conditions. Our work provides\na more nuanced understanding of compression's role in developing code\nintelligence and contributes a robust evaluation framework in the code domain.", "AI": {"tldr": "The paper explores the relationship between data compression and Code LLMs, revealing a logarithmic (not linear) link between compression (BPC) and code intelligence, using a novel evaluation method called Format Annealing.", "motivation": "Prior work assumed a linear relationship between compression and general intelligence in LLMs but failed to account for the complexity of code (multi-language, multi-task) and fair evaluation of modern Code LLMs.", "method": "The study evaluates diverse open-source Code LLMs on multi-language, multi-task benchmarks and introduces Format Annealing for fair assessment. Compression efficacy (BPC) is measured using a new GitHub-derived validation set.", "result": "Empirical results show a logarithmic (not linear) relationship between code intelligence and BPC, refining prior hypotheses.", "conclusion": "The work offers a nuanced understanding of compression's role in code intelligence and provides a robust evaluation framework for the code domain."}}
{"id": "2505.10954", "pdf": "https://arxiv.org/pdf/2505.10954", "abs": "https://arxiv.org/abs/2505.10954", "authors": ["Koki Iwai", "Yusuke Kumagae", "Yuki Koyama", "Masahiro Hamasaki", "Masataka Goto"], "title": "Constrained Preferential Bayesian Optimization and Its Application in Banner Ad Design", "categories": ["cs.LG", "cs.AI", "cs.GR", "cs.HC"], "comment": "17 pages, 15 figures", "summary": "Preferential Bayesian optimization (PBO) is a variant of Bayesian\noptimization that observes relative preferences (e.g., pairwise comparisons)\ninstead of direct objective values, making it especially suitable for\nhuman-in-the-loop scenarios. However, real-world optimization tasks often\ninvolve inequality constraints, which existing PBO methods have not yet\naddressed. To fill this gap, we propose constrained preferential Bayesian\noptimization (CPBO), an extension of PBO that incorporates inequality\nconstraints for the first time. Specifically, we present a novel acquisition\nfunction for this purpose. Our technical evaluation shows that our CPBO method\nsuccessfully identifies optimal solutions by focusing on exploring feasible\nregions. As a practical application, we also present a designer-in-the-loop\nsystem for banner ad design using CPBO, where the objective is the designer's\nsubjective preference, and the constraint ensures a target predicted\nclick-through rate. We conducted a user study with professional ad designers,\ndemonstrating the potential benefits of our approach in guiding creative design\nunder real-world constraints.", "AI": {"tldr": "CPBO extends PBO to handle inequality constraints, introducing a novel acquisition function and demonstrating effectiveness in real-world applications like ad design.", "motivation": "Existing PBO methods lack support for inequality constraints, which are common in real-world optimization tasks.", "method": "Proposed constrained preferential Bayesian optimization (CPBO) with a new acquisition function to explore feasible regions.", "result": "CPBO successfully identifies optimal solutions while respecting constraints, validated in a user study with ad designers.", "conclusion": "CPBO fills a critical gap in PBO, enabling practical applications like constrained creative design."}}
{"id": "2505.11129", "pdf": "https://arxiv.org/pdf/2505.11129", "abs": "https://arxiv.org/abs/2505.11129", "authors": ["Makoto Yamada", "Kian Ming A. Chai", "Ayoub Rhim", "Satoki Ishikawa", "Mohammad Sabokrou", "Yao-Hung Hubert Tsai"], "title": "PhiNet v2: A Mask-Free Brain-Inspired Vision Foundation Model from Video", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "arXiv admin note: substantial text overlap with arXiv:2405.14650", "summary": "Recent advances in self-supervised learning (SSL) have revolutionized\ncomputer vision through innovative architectures and learning objectives, yet\nthey have not fully leveraged insights from biological visual processing\nsystems. Recently, a brain-inspired SSL model named PhiNet was proposed; it is\nbased on a ResNet backbone and operates on static image inputs with strong\naugmentation. In this paper, we introduce PhiNet v2, a novel Transformer-based\narchitecture that processes temporal visual input (that is, sequences of\nimages) without relying on strong augmentation. Our model leverages variational\ninference to learn robust visual representations from continuous input streams,\nsimilar to human visual processing. Through extensive experimentation, we\ndemonstrate that PhiNet v2 achieves competitive performance compared to\nstate-of-the-art vision foundation models, while maintaining the ability to\nlearn from sequential input without strong data augmentation. This work\nrepresents a significant step toward more biologically plausible computer\nvision systems that process visual information in a manner more closely aligned\nwith human cognitive processes.", "AI": {"tldr": "PhiNet v2 is a Transformer-based SSL model for temporal visual input, achieving competitive performance without strong augmentation, aligning closer to human visual processing.", "motivation": "To bridge the gap between SSL in computer vision and biological visual processing by introducing a model that learns from sequential input like humans.", "method": "Uses a Transformer-based architecture with variational inference to process temporal visual input without strong augmentation.", "result": "Competes with state-of-the-art vision models while learning from sequential input naturally.", "conclusion": "A step toward biologically plausible computer vision systems aligned with human cognition."}}
{"id": "2505.10695", "pdf": "https://arxiv.org/pdf/2505.10695", "abs": "https://arxiv.org/abs/2505.10695", "authors": ["Julian Wolter", "Amr Gomaa"], "title": "Predicting Human Behavior in Autonomous Systems: A Collaborative Machine Teaching Approach for Reducing Transfer of Control Events", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": null, "summary": "As autonomous systems become integral to various industries, effective\nstrategies for fault handling are essential to ensure reliability and\nefficiency. Transfer of Control (ToC), a traditional approach for interrupting\nautomated processes during faults, is often triggered unnecessarily in\nnon-critical situations. To address this, we propose a data-driven method that\nuses human interaction data to train AI models capable of preemptively\nidentifying and addressing issues or assisting users in resolution. Using an\ninteractive tool simulating an industrial vacuum cleaner, we collected data and\ndeveloped an LSTM-based model to predict user behavior. Our findings reveal\nthat even data from non-experts can effectively train models to reduce\nunnecessary ToC events, enhancing the system's robustness. This approach\nhighlights the potential of AI to learn directly from human problem-solving\nbehaviors, complementing sensor data to improve industrial automation and\nhuman-AI collaboration.", "AI": {"tldr": "A data-driven method using human interaction data trains AI models to reduce unnecessary Transfer of Control (ToC) events in autonomous systems, improving reliability.", "motivation": "Traditional ToC approaches are often triggered unnecessarily in non-critical situations, requiring a more efficient fault-handling strategy.", "method": "Collected human interaction data via an industrial vacuum cleaner simulator and developed an LSTM-based model to predict user behavior.", "result": "Non-expert data effectively trained models to reduce unnecessary ToC events, enhancing system robustness.", "conclusion": "AI can learn from human problem-solving behaviors to improve industrial automation and human-AI collaboration."}}
{"id": "2505.11462", "pdf": "https://arxiv.org/pdf/2505.11462", "abs": "https://arxiv.org/abs/2505.11462", "authors": ["Rahul Thapa", "Qingyang Wu", "Kevin Wu", "Harrison Zhang", "Angela Zhang", "Eric Wu", "Haotian Ye", "Suhana Bedi", "Nevin Aresh", "Joseph Boen", "Shriya Reddy", "Ben Athiwaratkun", "Shuaiwen Leon Song", "James Zou"], "title": "Disentangling Reasoning and Knowledge in Medical Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Medical reasoning in large language models (LLMs) aims to emulate clinicians'\ndiagnostic thinking, but current benchmarks such as MedQA-USMLE, MedMCQA, and\nPubMedQA often mix reasoning with factual recall. We address this by separating\n11 biomedical QA benchmarks into reasoning- and knowledge-focused subsets using\na PubMedBERT classifier that reaches 81 percent accuracy, comparable to human\nperformance. Our analysis shows that only 32.8 percent of questions require\ncomplex reasoning. We evaluate biomedical models (HuatuoGPT-o1, MedReason, m1)\nand general-domain models (DeepSeek-R1, o4-mini, Qwen3), finding consistent\ngaps between knowledge and reasoning performance. For example, m1 scores 60.5\non knowledge but only 47.1 on reasoning. In adversarial tests where models are\nmisled with incorrect initial reasoning, biomedical models degrade sharply,\nwhile larger or RL-trained general models show more robustness. To address\nthis, we train BioMed-R1 using fine-tuning and reinforcement learning on\nreasoning-heavy examples. It achieves the strongest performance among similarly\nsized models. Further gains may come from incorporating clinical case reports\nand training with adversarial and backtracking scenarios.", "AI": {"tldr": "The paper separates biomedical QA benchmarks into reasoning- and knowledge-focused subsets, revealing only 32.8% require complex reasoning. It evaluates models, showing gaps in reasoning vs. knowledge performance, and introduces BioMed-R1 for improved reasoning.", "motivation": "Current benchmarks mix reasoning with factual recall, making it hard to assess true reasoning capabilities in LLMs for medical tasks.", "method": "Uses a PubMedBERT classifier to split benchmarks, evaluates models on reasoning/knowledge, and trains BioMed-R1 with fine-tuning and reinforcement learning.", "result": "Only 32.8% of questions require complex reasoning. BioMed-R1 outperforms similarly sized models. Biomedical models degrade in adversarial tests, while general models show robustness.", "conclusion": "BioMed-R1 improves reasoning performance, and further gains could come from clinical case reports and adversarial training."}}
{"id": "2505.10960", "pdf": "https://arxiv.org/pdf/2505.10960", "abs": "https://arxiv.org/abs/2505.10960", "authors": ["Vijay Prakash Dwivedi", "Sri Jaladi", "Yangyi Shen", "Federico L\u00f3pez", "Charilaos I. Kanatsoulis", "Rishi Puri", "Matthias Fey", "Jure Leskovec"], "title": "Relational Graph Transformer", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": "Code: https://github.com/snap-stanford/relgt", "summary": "Relational Deep Learning (RDL) is a promising approach for building\nstate-of-the-art predictive models on multi-table relational data by\nrepresenting it as a heterogeneous temporal graph. However, commonly used Graph\nNeural Network models suffer from fundamental limitations in capturing complex\nstructural patterns and long-range dependencies that are inherent in relational\ndata. While Graph Transformers have emerged as powerful alternatives to GNNs on\ngeneral graphs, applying them to relational entity graphs presents unique\nchallenges: (i) Traditional positional encodings fail to generalize to massive,\nheterogeneous graphs; (ii) existing architectures cannot model the temporal\ndynamics and schema constraints of relational data; (iii) existing tokenization\nschemes lose critical structural information. Here we introduce the Relational\nGraph Transformer (RelGT), the first graph transformer architecture designed\nspecifically for relational tables. RelGT employs a novel multi-element\ntokenization strategy that decomposes each node into five components (features,\ntype, hop distance, time, and local structure), enabling efficient encoding of\nheterogeneity, temporality, and topology without expensive precomputation. Our\narchitecture combines local attention over sampled subgraphs with global\nattention to learnable centroids, incorporating both local and database-wide\nrepresentations. Across 21 tasks from the RelBench benchmark, RelGT\nconsistently matches or outperforms GNN baselines by up to 18%, establishing\nGraph Transformers as a powerful architecture for Relational Deep Learning.", "AI": {"tldr": "RelGT, a Graph Transformer for relational data, outperforms GNNs by addressing limitations in capturing structural patterns and long-range dependencies.", "motivation": "Existing GNNs and Graph Transformers struggle with relational data due to issues like poor positional encodings, inability to model temporal dynamics, and loss of structural information.", "method": "RelGT uses multi-element tokenization (features, type, hop distance, time, local structure) and combines local and global attention mechanisms.", "result": "RelGT outperforms GNN baselines by up to 18% on 21 RelBench tasks.", "conclusion": "RelGT establishes Graph Transformers as effective for Relational Deep Learning."}}
{"id": "2505.11131", "pdf": "https://arxiv.org/pdf/2505.11131", "abs": "https://arxiv.org/abs/2505.11131", "authors": ["Feiran Li", "Qianqian Xu", "Shilong Bao", "Zhiyong Yang", "Xiaochun Cao", "Qingming Huang"], "title": "One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework", "categories": ["cs.CV", "cs.AI"], "comment": "This paper has been accepeted to ICML 2025. Not Final Version", "summary": "Concept erasing has recently emerged as an effective paradigm to prevent\ntext-to-image diffusion models from generating visually undesirable or even\nharmful content. However, current removal methods heavily rely on manually\ncrafted text prompts, making it challenging to achieve a high erasure\n(efficacy) while minimizing the impact on other benign concepts (usability). In\nthis paper, we attribute the limitations to the inherent gap between the text\nand image modalities, which makes it hard to transfer the intricately entangled\nconcept knowledge from text prompts to the image generation process. To address\nthis, we propose a novel solution by directly integrating visual supervision\ninto the erasure process, introducing the first text-image Collaborative\nConcept Erasing (Co-Erasing) framework. Specifically, Co-Erasing describes the\nconcept jointly by text prompts and the corresponding undesirable images\ninduced by the prompts, and then reduces the generating probability of the\ntarget concept through negative guidance. This approach effectively bypasses\nthe knowledge gap between text and image, significantly enhancing erasure\nefficacy. Additionally, we design a text-guided image concept refinement\nstrategy that directs the model to focus on visual features most relevant to\nthe specified text concept, minimizing disruption to other benign concepts.\nFinally, comprehensive experiments suggest that Co-Erasing outperforms\nstate-of-the-art erasure approaches significantly with a better trade-off\nbetween efficacy and usability. Codes are available at\nhttps://github.com/Ferry-Li/Co-Erasing.", "AI": {"tldr": "A novel text-image collaborative framework (Co-Erasing) improves concept erasure in diffusion models by integrating visual supervision, outperforming existing methods in efficacy and usability.", "motivation": "Current concept erasure methods rely on text prompts, creating a gap between text and image modalities, limiting efficacy and usability.", "method": "Co-Erasing combines text prompts and undesirable images for negative guidance, refining visual features with text guidance to minimize disruption to benign concepts.", "result": "Co-Erasing significantly outperforms state-of-the-art methods, achieving better trade-offs between erasure efficacy and usability.", "conclusion": "The proposed framework effectively bridges the text-image gap, enhancing concept erasure while preserving benign content."}}
{"id": "2505.10732", "pdf": "https://arxiv.org/pdf/2505.10732", "abs": "https://arxiv.org/abs/2505.10732", "authors": ["Jia Hui Chin", "Pu Zhang", "Yu Xin Cheong", "Jonathan Pan"], "title": "Automating Security Audit Using Large Language Model based Agent: An Exploration Experiment", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "In the current rapidly changing digital environment, businesses are under\nconstant stress to ensure that their systems are secured. Security audits help\nto maintain a strong security posture by ensuring that policies are in place,\ncontrols are implemented, gaps are identified for cybersecurity risks\nmitigation. However, audits are usually manual, requiring much time and costs.\nThis paper looks at the possibility of developing a framework to leverage Large\nLanguage Models (LLMs) as an autonomous agent to execute part of the security\naudit, namely with the field audit. password policy compliance for Windows\noperating system. Through the conduct of an exploration experiment of using\nGPT-4 with Langchain, the agent executed the audit tasks by accurately flagging\npassword policy violations and appeared to be more efficient than traditional\nmanual audits. Despite its potential limitations in operational consistency in\ncomplex and dynamic environment, the framework suggests possibilities to extend\nfurther to real-time threat monitoring and compliance checks.", "AI": {"tldr": "A framework using LLMs (like GPT-4) automates security audits, specifically for Windows password policy compliance, showing efficiency over manual methods.", "motivation": "Manual security audits are time-consuming and costly; this paper explores automating part of the process using LLMs to improve efficiency.", "method": "The study uses GPT-4 with Langchain to autonomously audit Windows password policy compliance, identifying violations.", "result": "The LLM-based agent accurately flagged policy violations and was more efficient than traditional manual audits.", "conclusion": "While limitations exist in dynamic environments, the framework shows promise for extending to real-time monitoring and compliance checks."}}
{"id": "2505.11470", "pdf": "https://arxiv.org/pdf/2505.11470", "abs": "https://arxiv.org/abs/2505.11470", "authors": ["Pascal Wullschleger", "Majid Zarharan", "Donnacha Daly", "Marc Pouly", "Jennifer Foster"], "title": "No Gold Standard, No Problem: Reference-Free Evaluation of Taxonomies", "categories": ["cs.CL"], "comment": null, "summary": "We introduce two reference-free metrics for quality evaluation of taxonomies.\nThe first metric evaluates robustness by calculating the correlation between\nsemantic and taxonomic similarity, covering a type of error not handled by\nexisting metrics. The second uses Natural Language Inference to assess logical\nadequacy. Both metrics are tested on five taxonomies and are shown to correlate\nwell with F1 against gold-standard taxonomies.", "AI": {"tldr": "Two reference-free metrics for taxonomy quality evaluation: one measures robustness via semantic-taxonomic correlation, and the other assesses logical adequacy using Natural Language Inference. Both correlate well with gold-standard F1 scores.", "motivation": "Existing metrics for taxonomy quality evaluation lack coverage for certain errors, such as robustness and logical adequacy.", "method": "1. Robustness metric: correlation between semantic and taxonomic similarity. 2. Logical adequacy metric: Natural Language Inference. Both tested on five taxonomies.", "result": "Both metrics correlate well with F1 scores against gold-standard taxonomies.", "conclusion": "The proposed metrics effectively evaluate taxonomy quality, addressing gaps in existing methods."}}
{"id": "2505.10978", "pdf": "https://arxiv.org/pdf/2505.10978", "abs": "https://arxiv.org/abs/2505.10978", "authors": ["Lang Feng", "Zhenghai Xue", "Tingcong Liu", "Bo An"], "title": "Group-in-Group Policy Optimization for LLM Agent Training", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Recent advances in group-based reinforcement learning (RL) have driven\nfrontier large language models (LLMs) in single-turn tasks like mathematical\nreasoning. However, their scalability to long-horizon LLM agent training\nremains limited. Unlike static tasks, agent-environment interactions unfold\nover many steps and often yield sparse or delayed rewards, making credit\nassignment across individual steps significantly more challenging. In this\nwork, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL\nalgorithm that achieves fine-grained credit assignment for LLM agents while\npreserving the appealing properties of group-based RL: critic-free, low memory,\nand stable convergence. GiGPO introduces a two-level structure for estimating\nrelative advantage: (i) At the episode-level, GiGPO computes macro relative\nadvantages based on groups of complete trajectories; (ii) At the step-level,\nGiGPO introduces an anchor state grouping mechanism that retroactively\nconstructs step-level groups by identifying repeated environment states across\ntrajectories. Actions stemming from the same state are grouped together,\nenabling micro relative advantage estimation. This hierarchical structure\neffectively captures both global trajectory quality and local step\neffectiveness without relying on auxiliary models or additional rollouts. We\nevaluate GiGPO on two challenging agent benchmarks, ALFWorld and WebShop, using\nQwen2.5-1.5B-Instruct and Qwen2.5-7B-Instruct. Crucially, GiGPO delivers\nfine-grained per-step credit signals and achieves performance gains of > 12\\%\non ALFWorld and > 9\\% on WebShop over the GRPO baseline: all while maintaining\nthe same GPU memory overhead, identical LLM rollout, and incurring little to no\nadditional time cost.", "AI": {"tldr": "GiGPO is a novel RL algorithm for LLM agents, enabling fine-grained credit assignment in long-horizon tasks while maintaining efficiency. It outperforms baselines by >12% on ALFWorld and >9% on WebShop.", "motivation": "Scalability of group-based RL in long-horizon LLM agent training is limited due to sparse/delayed rewards and credit assignment challenges.", "method": "GiGPO uses a two-level structure: episode-level macro advantages and step-level micro advantages via anchor state grouping.", "result": "GiGPO achieves >12% and >9% performance gains on ALFWorld and WebShop, respectively, with minimal overhead.", "conclusion": "GiGPO effectively addresses credit assignment in long-horizon RL for LLMs, outperforming baselines without added computational cost."}}
{"id": "2505.11141", "pdf": "https://arxiv.org/pdf/2505.11141", "abs": "https://arxiv.org/abs/2505.11141", "authors": ["Yansheng Qiu", "Li Xiao", "Zhaopan Xu", "Pengfei Zhou", "Zheng Wang", "Kaipeng Zhang"], "title": "Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The goal of achieving Artificial General Intelligence (AGI) is to imitate\nhumans and surpass them. Models such as OpenAI's o1, o3, and DeepSeek's R1 have\ndemonstrated that large language models (LLMs) with human-like reasoning\ncapabilities exhibit exceptional performance and are being gradually integrated\ninto multimodal large language models (MLLMs). However, whether these models\npossess capabilities comparable to humans in handling reasoning tasks remains\nunclear at present. In this paper, we propose Human-Aligned Bench, a benchmark\nfor fine-grained alignment of multimodal reasoning with human performance.\nSpecifically, we collected 9,794 multimodal questions that solely rely on\ncontextual reasoning, including bilingual (Chinese and English) multimodal\nquestions and pure text-based questions, encompassing four question types:\nvisual reasoning, definition judgment, analogical reasoning, and logical\njudgment. More importantly, each question is accompanied by human success rates\nand options that humans are prone to choosing incorrectly. Extensive\nexperiments on the Human-Aligned Bench reveal notable differences between the\nperformance of current MLLMs in multimodal reasoning and human performance. The\nfindings on our benchmark provide insights into the development of the\nnext-generation models.", "AI": {"tldr": "The paper introduces Human-Aligned Bench, a benchmark for evaluating multimodal reasoning in AI models against human performance, revealing gaps in current MLLMs.", "motivation": "To assess whether current multimodal large language models (MLLMs) match human reasoning capabilities, given their integration into AGI development.", "method": "Created a benchmark with 9,794 multimodal questions (bilingual and text-based) across four reasoning types, incorporating human success rates and error-prone options.", "result": "Experiments show significant performance gaps between MLLMs and humans in multimodal reasoning tasks.", "conclusion": "The benchmark highlights areas for improvement in MLLMs, guiding future AGI development."}}
{"id": "2505.10746", "pdf": "https://arxiv.org/pdf/2505.10746", "abs": "https://arxiv.org/abs/2505.10746", "authors": ["Matthew Stoffolano", "Ayush Rout", "Justin M. Pelletier"], "title": "ChestyBot: Detecting and Disrupting Chinese Communist Party Influence Stratagems", "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.SI"], "comment": "Presented at USCYBERCOM Cyber Recon Symposium 2023 at DreamPort in\n  Columbia, MD on April 20, 2023", "summary": "Foreign information operations conducted by Russian and Chinese actors\nexploit the United States' permissive information environment. These campaigns\nthreaten democratic institutions and the broader Westphalian model. Yet,\nexisting detection and mitigation strategies often fail to identify active\ninformation campaigns in real time. This paper introduces ChestyBot, a\npragmatics-based language model that detects unlabeled foreign malign influence\ntweets with up to 98.34% accuracy. The model supports a novel framework to\ndisrupt foreign influence operations in their formative stages.", "AI": {"tldr": "ChestyBot, a pragmatics-based language model, detects foreign malign influence tweets with 98.34% accuracy, aiding early disruption of such campaigns.", "motivation": "Foreign information operations by Russian and Chinese actors threaten democratic institutions, but current detection methods lack real-time effectiveness.", "method": "Introduces ChestyBot, a pragmatics-based language model, to detect unlabeled malign influence tweets.", "result": "Achieves 98.34% accuracy in identifying foreign influence tweets.", "conclusion": "ChestyBot provides a novel framework to disrupt foreign influence operations early."}}
{"id": "2505.11475", "pdf": "https://arxiv.org/pdf/2505.11475", "abs": "https://arxiv.org/abs/2505.11475", "authors": ["Zhilin Wang", "Jiaqi Zeng", "Olivier Delalleau", "Hoo-Chang Shin", "Felipe Soares", "Alexander Bukharin", "Ellie Evans", "Yi Dong", "Oleksii Kuchaiev"], "title": "HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "38 pages, 2 figures", "summary": "Preference datasets are essential for training general-domain,\ninstruction-following language models with Reinforcement Learning from Human\nFeedback (RLHF). Each subsequent data release raises expectations for future\ndata collection, meaning there is a constant need to advance the quality and\ndiversity of openly available preference data. To address this need, we\nintroduce HelpSteer3-Preference, a permissively licensed (CC-BY-4.0),\nhigh-quality, human-annotated preference dataset comprising of over 40,000\nsamples. These samples span diverse real-world applications of large language\nmodels (LLMs), including tasks relating to STEM, coding and multilingual\nscenarios. Using HelpSteer3-Preference, we train Reward Models (RMs) that\nachieve top performance on RM-Bench (82.4%) and JudgeBench (73.7%). This\nrepresents a substantial improvement (~10% absolute) over the previously\nbest-reported results from existing RMs. We demonstrate HelpSteer3-Preference\ncan also be applied to train Generative RMs and how policy models can be\naligned with RLHF using our RMs. Dataset (CC-BY-4.0):\nhttps://huggingface.co/datasets/nvidia/HelpSteer3#preference", "AI": {"tldr": "HelpSteer3-Preference is a high-quality, diverse preference dataset for RLHF, improving RM performance by ~10%.", "motivation": "Advancing the quality and diversity of openly available preference data for training instruction-following LLMs.", "method": "Introduces HelpSteer3-Preference, a 40,000-sample human-annotated dataset spanning STEM, coding, and multilingual tasks.", "result": "Trained RMs achieve 82.4% on RM-Bench and 73.7% on JudgeBench, a ~10% improvement over prior results.", "conclusion": "HelpSteer3-Preference enhances RM training and enables effective RLHF alignment for policy models."}}
{"id": "2505.10983", "pdf": "https://arxiv.org/pdf/2505.10983", "abs": "https://arxiv.org/abs/2505.10983", "authors": ["Haozheng Luo", "Chenghao Qiu", "Yimin Wang", "Shang Wu", "Jiahao Yu", "Han Liu", "Binghui Wang", "Yan Chen"], "title": "GenoArmory: A Unified Evaluation Framework for Adversarial Attacks on Genomic Foundation Models", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "We propose the first unified adversarial attack benchmark for Genomic\nFoundation Models (GFMs), named GenoArmory. Unlike existing GFM benchmarks,\nGenoArmory offers the first comprehensive evaluation framework to\nsystematically assess the vulnerability of GFMs to adversarial attacks.\nMethodologically, we evaluate the adversarial robustness of five\nstate-of-the-art GFMs using four widely adopted attack algorithms and three\ndefense strategies. Importantly, our benchmark provides an accessible and\ncomprehensive framework to analyze GFM vulnerabilities with respect to model\narchitecture, quantization schemes, and training datasets. Additionally, we\nintroduce GenoAdv, a new adversarial sample dataset designed to improve GFM\nsafety. Empirically, classification models exhibit greater robustness to\nadversarial perturbations compared to generative models, highlighting the\nimpact of task type on model vulnerability. Moreover, adversarial attacks\nfrequently target biologically significant genomic regions, suggesting that\nthese models effectively capture meaningful sequence features.", "AI": {"tldr": "GenoArmory is the first unified benchmark for evaluating adversarial attacks on Genomic Foundation Models (GFMs), offering a comprehensive framework to assess vulnerabilities.", "motivation": "Existing GFM benchmarks lack systematic evaluation of adversarial vulnerabilities, prompting the need for GenoArmory.", "method": "Evaluated five GFMs using four attack algorithms and three defense strategies, analyzing vulnerabilities related to architecture, quantization, and datasets. Introduced GenoAdv, a dataset for GFM safety.", "result": "Classification models are more robust than generative models. Adversarial attacks often target biologically significant regions, indicating meaningful feature capture.", "conclusion": "GenoArmory provides a valuable tool for assessing GFM vulnerabilities, revealing task-specific robustness and biological relevance in adversarial targeting."}}
{"id": "2505.11152", "pdf": "https://arxiv.org/pdf/2505.11152", "abs": "https://arxiv.org/abs/2505.11152", "authors": ["Daniel Sungho Jung", "Kyoung Mu Lee"], "title": "Learning Dense Hand Contact Estimation from Imbalanced Data", "categories": ["cs.CV"], "comment": "Project page: http://haco-release.github.io", "summary": "Hands are essential to human interaction, and understanding contact between\nhands and the world can promote comprehensive understanding of their function.\nRecently, there have been growing number of hand interaction datasets that\ncover interaction with object, other hand, scene, and body. Despite the\nsignificance of the task and increasing high-quality data, how to effectively\nlearn dense hand contact estimation remains largely underexplored. There are\ntwo major challenges for learning dense hand contact estimation. First, there\nexists class imbalance issue from hand contact datasets where majority of\nsamples are not in contact. Second, hand contact datasets contain spatial\nimbalance issue with most of hand contact exhibited in finger tips, resulting\nin challenges for generalization towards contacts in other hand regions. To\ntackle these issues, we present a framework that learns dense HAnd COntact\nestimation (HACO) from imbalanced data. To resolve the class imbalance issue,\nwe introduce balanced contact sampling, which builds and samples from multiple\nsampling groups that fairly represent diverse contact statistics for both\ncontact and non-contact samples. Moreover, to address the spatial imbalance\nissue, we propose vertex-level class-balanced (VCB) loss, which incorporates\nspatially varying contact distribution by separately reweighting loss\ncontribution of each vertex based on its contact frequency across dataset. As a\nresult, we effectively learn to predict dense hand contact estimation with\nlarge-scale hand contact data without suffering from class and spatial\nimbalance issue. The codes will be released.", "AI": {"tldr": "The paper introduces a framework (HACO) for dense hand contact estimation, addressing class and spatial imbalance issues in datasets using balanced sampling and a vertex-level class-balanced loss.", "motivation": "Understanding hand contact is crucial for human interaction, but existing datasets suffer from class and spatial imbalance, hindering effective learning.", "method": "Proposes balanced contact sampling for class imbalance and vertex-level class-balanced (VCB) loss for spatial imbalance.", "result": "The framework effectively predicts dense hand contact without suffering from imbalance issues.", "conclusion": "The approach successfully tackles dataset imbalances, enabling better hand contact estimation."}}
{"id": "2505.10790", "pdf": "https://arxiv.org/pdf/2505.10790", "abs": "https://arxiv.org/abs/2505.10790", "authors": ["Liu Zhang", "Yiran Yao", "Danping Shi", "Dongchen Chai", "Jian Guo", "Zilong Wang"], "title": "Neural-Inspired Advances in Integral Cryptanalysis", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The study by Gohr et.al at CRYPTO 2019 and sunsequent related works have\nshown that neural networks can uncover previously unused features, offering\nnovel insights into cryptanalysis. Motivated by these findings, we employ\nneural networks to learn features specifically related to integral properties\nand integrate the corresponding insights into optimized search frameworks.\nThese findings validate the framework of using neural networks for feature\nexploration, providing researchers with novel insights that advance established\ncryptanalysis methods.\n  Neural networks have inspired the development of more precise integral search\nmodels. By comparing the integral distinguishers obtained via neural networks\nwith those identified by classical methods, we observe that existing automated\nsearch models often fail to find optimal distinguishers. To address this issue,\nwe develop a meet in the middle search framework that balances model accuracy\nand computational efficiency. As a result, we reduce the number of active\nplaintext bits required for an 11 rounds integral distinguisher on SKINNY64/64,\nand further identify a 12 rounds key dependent integral distinguisher achieving\none additional round over the previous best-known result.\n  The integral distinguishers discovered by neural networks enable key recovery\nattacks on more rounds. We identify a 7 rounds key independent integral\ndistinguisher from neural networks with even only one active plaintext cell,\nwhich is based on linear combinations of bits. This distinguisher enables a 15\nrounds key recovery attack on SKINNYn/n, improving upon the previous record by\none round. Additionally, we discover an 8 rounds key dependent integral\ndistinguisher using neural network that further reduces the time complexity of\nkey recovery attacks against SKINNY.", "AI": {"tldr": "Neural networks improve cryptanalysis by uncovering novel integral properties, enabling optimized search frameworks and advancing key recovery attacks.", "motivation": "Prior work showed neural networks can reveal unused cryptanalysis features, inspiring their use for integral property exploration to enhance existing methods.", "method": "Neural networks are employed to learn integral features, integrated into a meet-in-the-middle search framework for optimized distinguisher discovery.", "result": "Improved integral distinguishers for SKINNY64/64 and SKINNYn/n, enabling key recovery attacks on more rounds with reduced complexity.", "conclusion": "Neural networks offer significant advancements in cryptanalysis, providing more efficient and precise distinguishers for key recovery."}}
{"id": "2505.11480", "pdf": "https://arxiv.org/pdf/2505.11480", "abs": "https://arxiv.org/abs/2505.11480", "authors": ["Anjiang Wei", "Tarun Suresh", "Huanmi Tan", "Yinglun Xu", "Gagandeep Singh", "Ke Wang", "Alex Aiken"], "title": "Improving Assembly Code Performance with Large Language Models via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.PF", "cs.PL", "cs.SE"], "comment": null, "summary": "Large language models (LLMs) have demonstrated strong performance across a\nwide range of programming tasks, yet their potential for code optimization\nremains underexplored. This work investigates whether LLMs can optimize the\nperformance of assembly code, where fine-grained control over execution enables\nimprovements that are difficult to express in high-level languages. We present\na reinforcement learning framework that trains LLMs using Proximal Policy\nOptimization (PPO), guided by a reward function that considers both functional\ncorrectness, validated through test cases, and execution performance relative\nto the industry-standard compiler gcc -O3. To support this study, we introduce\na benchmark of 8,072 real-world programs. Our model, Qwen2.5-Coder-7B-PPO,\nachieves 96.0% test pass rates and an average speedup of 1.47x over the gcc -O3\nbaseline, outperforming all 20 other models evaluated, including\nClaude-3.7-sonnet. These results indicate that reinforcement learning can\nunlock the potential of LLMs to serve as effective optimizers for assembly code\nperformance.", "AI": {"tldr": "LLMs trained with reinforcement learning (PPO) can optimize assembly code, achieving 96.0% test pass rates and 1.47x speedup over gcc -O3.", "motivation": "Explore LLMs' potential for optimizing assembly code, where fine-grained control offers performance improvements hard to achieve in high-level languages.", "method": "A reinforcement learning framework using PPO, with rewards for functional correctness and execution performance, tested on 8,072 real-world programs.", "result": "Qwen2.5-Coder-7B-PPO achieves 96.0% test pass rates and 1.47x speedup, outperforming 20 other models.", "conclusion": "Reinforcement learning enables LLMs to effectively optimize assembly code performance."}}
{"id": "2505.10992", "pdf": "https://arxiv.org/pdf/2505.10992", "abs": "https://arxiv.org/abs/2505.10992", "authors": ["Feiran You", "Hongyang Du"], "title": "ReaCritic: Large Reasoning Transformer-based DRL Critic-model Scaling For Heterogeneous Networks", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Heterogeneous Networks (HetNets) pose critical challenges for intelligent\nmanagement due to the diverse user requirements and time-varying wireless\nconditions. These factors introduce significant decision complexity, which\nlimits the adaptability of existing Deep Reinforcement Learning (DRL) methods.\nIn many DRL algorithms, especially those involving value-based or actor-critic\nstructures, the critic component plays a key role in guiding policy learning by\nestimating value functions. However, conventional critic models often use\nshallow architectures that map observations directly to scalar estimates,\nlimiting their ability to handle multi-task complexity. In contrast, recent\nprogress in inference-time scaling of Large Language Models (LLMs) has shown\nthat generating intermediate reasoning steps can significantly improve decision\nquality. Motivated by this, we propose ReaCritic, a large reasoning\ntransformer-based criticmodel scaling scheme that brings reasoning ability into\nDRL. ReaCritic performs horizontal reasoning over parallel state-action inputs\nand vertical reasoning through deep transformer stacks. It is compatible with a\nbroad range of value-based and actor-critic DRL algorithms and enhances\ngeneralization in dynamic wireless environments. Extensive experiments\ndemonstrate that ReaCritic improves convergence speed and final performance\nacross various HetNet settings and standard OpenAI Gym control tasks.", "AI": {"tldr": "ReaCritic, a transformer-based critic model, enhances DRL by incorporating reasoning abilities, improving performance in HetNets and control tasks.", "motivation": "Existing DRL methods struggle with HetNets' complexity due to shallow critic architectures, while LLMs show reasoning improves decisions.", "method": "ReaCritic uses horizontal and vertical reasoning via transformer stacks, compatible with value-based and actor-critic DRL algorithms.", "result": "Improves convergence speed and performance in HetNets and OpenAI Gym tasks.", "conclusion": "ReaCritic effectively addresses DRL limitations in dynamic environments by integrating reasoning."}}
{"id": "2505.11168", "pdf": "https://arxiv.org/pdf/2505.11168", "abs": "https://arxiv.org/abs/2505.11168", "authors": ["Xinran Li", "Yu Liu", "Xiujuan Xu", "Xiaowei Zhao"], "title": "CheX-DS: Improving Chest X-ray Image Classification with Ensemble Learning Based on DenseNet and Swin Transformer", "categories": ["cs.CV", "cs.AI"], "comment": "BIBM", "summary": "The automatic diagnosis of chest diseases is a popular and challenging task.\nMost current methods are based on convolutional neural networks (CNNs), which\nfocus on local features while neglecting global features. Recently,\nself-attention mechanisms have been introduced into the field of computer\nvision, demonstrating superior performance. Therefore, this paper proposes an\neffective model, CheX-DS, for classifying long-tail multi-label data in the\nmedical field of chest X-rays. The model is based on the excellent CNN model\nDenseNet for medical imaging and the newly popular Swin Transformer model,\nutilizing ensemble deep learning techniques to combine the two models and\nleverage the advantages of both CNNs and Transformers. The loss function of\nCheX-DS combines weighted binary cross-entropy loss with asymmetric loss,\neffectively addressing the issue of data imbalance. The NIH ChestX-ray14\ndataset is selected to evaluate the model's effectiveness. The model\noutperforms previous studies with an excellent average AUC score of 83.76\\%,\ndemonstrating its superior performance.", "AI": {"tldr": "CheX-DS, a hybrid model combining DenseNet and Swin Transformer, outperforms previous methods in chest X-ray classification with an AUC of 83.76%.", "motivation": "Current CNN-based methods for chest disease diagnosis focus on local features and ignore global features, limiting performance. Self-attention mechanisms (Transformers) offer a solution.", "method": "CheX-DS integrates DenseNet (CNN) and Swin Transformer via ensemble deep learning, combining local and global features. It uses weighted binary cross-entropy and asymmetric loss to handle data imbalance.", "result": "Achieves an average AUC of 83.76% on the NIH ChestX-ray14 dataset, surpassing prior studies.", "conclusion": "CheX-DS effectively combines CNNs and Transformers, addressing data imbalance and improving chest X-ray classification performance."}}
{"id": "2505.10791", "pdf": "https://arxiv.org/pdf/2505.10791", "abs": "https://arxiv.org/abs/2505.10791", "authors": ["N Harsha Vardhan", "Ponnurangam Kumaraguru", "Kiran Garimella"], "title": "Analyzing Patterns and Influence of Advertising in Print Newspapers", "categories": ["cs.CY", "cs.AI", "cs.SI"], "comment": "Accepted at COMPASS 2025", "summary": "This paper investigates advertising practices in print newspapers across\nIndia using a novel data-driven approach. We develop a pipeline employing image\nprocessing and OCR techniques to extract articles and advertisements from\ndigital versions of print newspapers with high accuracy. Applying this\nmethodology to five popular newspapers that span multiple regions and three\nlanguages, English, Hindi, and Telugu, we assembled a dataset of more than\n12,000 editions containing several hundred thousand advertisements.\nCollectively, these newspapers reach a readership of over 100 million people.\nUsing this extensive dataset, we conduct a comprehensive analysis to answer key\nquestions about print advertising: who advertises, what they advertise, when\nthey advertise, where they place their ads, and how they advertise. Our\nfindings reveal significant patterns, including the consistent level of print\nadvertising over the past six years despite declining print circulation, the\noverrepresentation of company ads on prominent pages, and the disproportionate\nrevenue contributed by government ads. Furthermore, we examine whether\nadvertising in a newspaper influences the coverage an advertiser receives.\nThrough regression analyses on coverage volume and sentiment, we find strong\nevidence supporting this hypothesis for corporate advertisers. The results\nindicate a clear trend where increased advertising correlates with more\nfavorable and extensive media coverage, a relationship that remains robust over\ntime and across different levels of advertiser popularity.", "AI": {"tldr": "The paper analyzes print newspaper advertising in India using image processing and OCR to extract ads from 12,000+ editions. Findings show stable ad levels despite declining circulation, corporate ad influence on coverage, and government ads' revenue dominance.", "motivation": "To understand print advertising practices in India, including who advertises, what, when, where, and how, and to explore the relationship between advertising and media coverage.", "method": "Developed a data-driven pipeline using image processing and OCR to extract ads from digital newspapers. Analyzed 12,000+ editions across five newspapers in English, Hindi, and Telugu.", "result": "Revealed stable ad levels despite circulation decline, corporate ads' influence on favorable coverage, and government ads' revenue dominance.", "conclusion": "Print advertising remains significant in India, with corporate ads influencing media coverage, suggesting a symbiotic relationship between advertisers and newspapers."}}
{"id": "2505.11484", "pdf": "https://arxiv.org/pdf/2505.11484", "abs": "https://arxiv.org/abs/2505.11484", "authors": ["Yige Xu", "Xu Guo", "Zhiwei Zeng", "Chunyan Miao"], "title": "SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning", "categories": ["cs.CL"], "comment": "14 pages", "summary": "Test-Time Scaling (TTS) refers to approaches that improve reasoning\nperformance by allocating extra computation during inference, without altering\nthe model's parameters. While existing TTS methods operate in a discrete token\nspace by generating more intermediate steps, recent studies in Coconut and\nSoftCoT have demonstrated that thinking in the continuous latent space can\nfurther enhance the reasoning performance. Such latent thoughts encode\ninformative thinking without the information loss associated with\nautoregressive token generation, sparking increased interest in\ncontinuous-space reasoning. Unlike discrete decoding, where repeated sampling\nenables exploring diverse reasoning paths, latent representations in continuous\nspace are fixed for a given input, which limits diverse exploration, as all\ndecoded paths originate from the same latent thought. To overcome this\nlimitation, we introduce SoftCoT++ to extend SoftCoT to the Test-Time Scaling\nparadigm by enabling diverse exploration of thinking paths. Specifically, we\nperturb latent thoughts via multiple specialized initial tokens and apply\ncontrastive learning to promote diversity among soft thought representations.\nExperiments across five reasoning benchmarks and two distinct LLM architectures\ndemonstrate that SoftCoT++ significantly boosts SoftCoT and also outperforms\nSoftCoT with self-consistency scaling. Moreover, it shows strong compatibility\nwith conventional scaling techniques such as self-consistency. Source code is\navailable at https://github.com/xuyige/SoftCoT.", "AI": {"tldr": "SoftCoT++ enhances reasoning by diversifying latent thought exploration in continuous space, outperforming existing methods like SoftCoT and self-consistency scaling.", "motivation": "Existing continuous-space reasoning methods lack diverse exploration due to fixed latent representations. SoftCoT++ addresses this by perturbing latent thoughts and promoting diversity.", "method": "SoftCoT++ introduces specialized initial tokens to perturb latent thoughts and uses contrastive learning to diversify soft thought representations.", "result": "Experiments on five benchmarks and two LLM architectures show SoftCoT++ significantly improves reasoning performance over SoftCoT and self-consistency scaling.", "conclusion": "SoftCoT++ effectively enables diverse exploration in continuous-space reasoning, demonstrating strong compatibility with conventional scaling techniques."}}
{"id": "2505.11017", "pdf": "https://arxiv.org/pdf/2505.11017", "abs": "https://arxiv.org/abs/2505.11017", "authors": ["Wenjie Ou", "Zhishuo Zhao", "Dongyue Guo", "Yi Lin"], "title": "Logo-LLM: Local and Global Modeling with Large Language Models for Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Time series forecasting is critical across multiple domains, where time\nseries data exhibits both local patterns and global dependencies. While\nTransformer-based methods effectively capture global dependencies, they often\noverlook short-term local variations in time series. Recent methods that adapt\nlarge language models (LLMs) into time series forecasting inherit this\nlimitation by treating LLMs as black-box encoders, relying solely on the\nfinal-layer output and underutilizing hierarchical representations. To address\nthis limitation, we propose Logo-LLM, a novel LLM-based framework that\nexplicitly extracts and models multi-scale temporal features from different\nlayers of a pre-trained LLM. Through empirical analysis, we show that shallow\nlayers of LLMs capture local dynamics in time series, while deeper layers\nencode global trends. Moreover, Logo-LLM introduces lightweight Local-Mixer and\nGlobal-Mixer modules to align and integrate features with the temporal input\nacross layers. Extensive experiments demonstrate that Logo-LLM achieves\nsuperior performance across diverse benchmarks, with strong generalization in\nfew-shot and zero-shot settings while maintaining low computational overhead.", "AI": {"tldr": "Logo-LLM is an LLM-based framework for time series forecasting that extracts multi-scale temporal features from different layers of a pre-trained LLM, addressing limitations of existing methods by modeling both local and global dependencies.", "motivation": "Existing Transformer-based and LLM-adapted methods for time series forecasting often overlook short-term local variations and underutilize hierarchical representations in LLMs.", "method": "Logo-LLM extracts multi-scale features from different LLM layers, uses Local-Mixer and Global-Mixer modules to align and integrate these features, and leverages shallow layers for local dynamics and deeper layers for global trends.", "result": "Logo-LLM outperforms benchmarks, showing strong generalization in few-shot and zero-shot settings with low computational overhead.", "conclusion": "Logo-LLM effectively combines local and global temporal features from LLMs, improving time series forecasting performance and efficiency."}}
{"id": "2505.11178", "pdf": "https://arxiv.org/pdf/2505.11178", "abs": "https://arxiv.org/abs/2505.11178", "authors": ["Yixin Wan", "Kai-Wei Chang"], "title": "CompAlign: Improving Compositional Text-to-Image Generation with a Complex Benchmark and Fine-Grained Feedback", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "State-of-the-art T2I models are capable of generating high-resolution images\ngiven textual prompts. However, they still struggle with accurately depicting\ncompositional scenes that specify multiple objects, attributes, and spatial\nrelations. We present CompAlign, a challenging benchmark with an emphasis on\nassessing the depiction of 3D-spatial relationships, for evaluating and\nimproving models on compositional image generation. CompAlign consists of 900\ncomplex multi-subject image generation prompts that combine numerical and\n3D-spatial relationships with varied attribute bindings. Our benchmark is\nremarkably challenging, incorporating generation tasks with 3+ generation\nsubjects with complex 3D-spatial relationships. Additionally, we propose\nCompQuest, an interpretable and accurate evaluation framework that decomposes\ncomplex prompts into atomic sub-questions, then utilizes a MLLM to provide\nfine-grained binary feedback on the correctness of each aspect of generation\nelements in model-generated images. This enables precise quantification of\nalignment between generated images and compositional prompts. Furthermore, we\npropose an alignment framework that uses CompQuest's feedback as preference\nsignals to improve diffusion models' compositional image generation abilities.\nUsing adjustable per-image preferences, our method is easily scalable and\nflexible for different tasks. Evaluation of 9 T2I models reveals that: (1)\nmodels remarkable struggle more with compositional tasks with more complex\n3D-spatial configurations, and (2) a noticeable performance gap exists between\nopen-source accessible models and closed-source commercial models. Further\nempirical study on using CompAlign for model alignment yield promising results:\npost-alignment diffusion models achieve remarkable improvements in\ncompositional accuracy, especially on complex generation tasks, outperforming\nprevious approaches.", "AI": {"tldr": "CompAlign is a benchmark for evaluating T2I models on compositional image generation, focusing on 3D-spatial relationships. CompQuest provides fine-grained feedback, and an alignment framework improves model performance.", "motivation": "Current T2I models struggle with accurately depicting complex compositional scenes involving multiple objects, attributes, and spatial relations.", "method": "CompAlign includes 900 complex prompts, and CompQuest decomposes prompts into sub-questions for evaluation. An alignment framework uses feedback for model improvement.", "result": "Evaluation shows models struggle with complex 3D-spatial tasks, and post-alignment models outperform previous approaches.", "conclusion": "CompAlign and CompQuest effectively assess and improve T2I models' compositional generation, highlighting performance gaps and enabling scalable improvements."}}
{"id": "2505.10831", "pdf": "https://arxiv.org/pdf/2505.10831", "abs": "https://arxiv.org/abs/2505.10831", "authors": ["Omar Shaikh", "Shardul Sapkota", "Shan Rizvi", "Eric Horvitz", "Joon Sung Park", "Diyi Yang", "Michael S. Bernstein"], "title": "Creating General User Models from Computer Use", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "22 pages, 6 figures, 1 table; see\n  https://generalusermodels.github.io/", "summary": "Human-computer interaction has long imagined technology that understands\nus-from our preferences and habits, to the timing and purpose of our everyday\nactions. Yet current user models remain fragmented, narrowly tailored to\nspecific apps, and incapable of the flexible reasoning required to fulfill\nthese visions. This paper presents an architecture for a general user model\n(GUM) that learns about you by observing any interaction you have with your\ncomputer. The GUM takes as input any unstructured observation of a user (e.g.,\ndevice screenshots) and constructs confidence-weighted propositions that\ncapture that user knowledge and preferences. GUMs can infer that a user is\npreparing for a wedding they're attending from messages with a friend. Or\nrecognize that a user is struggling with a collaborator's feedback on a draft\nby observing multiple stalled edits and a switch to reading related work. GUMs\nintroduce an architecture that infers new propositions about a user from\nmultimodal observations, retrieves related propositions for context, and\ncontinuously revises existing propositions. To illustrate the breadth of\napplications that GUMs enable, we demonstrate how they augment chat-based\nassistants with context, manage OS notifications to selectively surface\nimportant information, and enable interactive agents that adapt to preferences\nacross apps. We also instantiate proactive assistants (GUMBOs) that discover\nand execute useful suggestions on a user's behalf using their GUM. In our\nevaluations, we find that GUMs make calibrated and accurate inferences about\nusers, and that assistants built on GUMs proactively identify and perform\nactions that users wouldn't think to request explicitly. Altogether, GUMs\nintroduce methods that leverage multimodal models to understand unstructured\ncontext, enabling long-standing visions of HCI and entirely new interactive\nsystems that anticipate user needs.", "AI": {"tldr": "The paper introduces a General User Model (GUM) that learns from unstructured user interactions to infer preferences and knowledge, enabling proactive and adaptive technology.", "motivation": "Current user models are fragmented and lack flexibility. The paper aims to create a unified model for understanding users across diverse interactions.", "method": "GUM processes unstructured observations (e.g., screenshots) to construct confidence-weighted propositions about users, refining them over time.", "result": "GUMs make accurate inferences and enable proactive assistants (GUMBOs) that perform useful actions without explicit requests.", "conclusion": "GUMs advance HCI by leveraging multimodal models to anticipate user needs, enabling new interactive systems."}}
{"id": "2505.11485", "pdf": "https://arxiv.org/pdf/2505.11485", "abs": "https://arxiv.org/abs/2505.11485", "authors": ["Bruno Bianchi", "Ferm\u00edn Travi", "Juan E. Kamienkowski"], "title": "Modeling cognitive processes of natural reading with transformer-based Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in Natural Language Processing (NLP) have led to the\ndevelopment of highly sophisticated language models for text generation. In\nparallel, neuroscience has increasingly employed these models to explore\ncognitive processes involved in language comprehension. Previous research has\nshown that models such as N-grams and LSTM networks can partially account for\npredictability effects in explaining eye movement behaviors, specifically Gaze\nDuration, during reading. In this study, we extend these findings by evaluating\ntransformer-based models (GPT2, LLaMA-7B, and LLaMA2-7B) to further investigate\nthis relationship. Our results indicate that these architectures outperform\nearlier models in explaining the variance in Gaze Durations recorded from\nRioplantense Spanish readers. However, similar to previous studies, these\nmodels still fail to account for the entirety of the variance captured by human\npredictability. These findings suggest that, despite their advancements,\nstate-of-the-art language models continue to predict language in ways that\ndiffer from human readers.", "AI": {"tldr": "Transformer-based models (GPT2, LLaMA-7B, LLaMA2-7B) outperform older models in explaining Gaze Duration variance in reading but still fall short of human predictability.", "motivation": "To explore how advanced NLP models (transformers) compare to older models in explaining eye movement behaviors (Gaze Duration) during reading, particularly in Rioplantense Spanish.", "method": "Evaluated transformer-based models (GPT2, LLaMA-7B, LLaMA2-7B) against earlier models (N-grams, LSTMs) using Gaze Duration data from readers.", "result": "Transformers outperform older models but still cannot fully account for human predictability in Gaze Duration.", "conclusion": "State-of-the-art language models predict language differently than humans, indicating a gap in their ability to fully replicate human reading behaviors."}}
{"id": "2505.11023", "pdf": "https://arxiv.org/pdf/2505.11023", "abs": "https://arxiv.org/abs/2505.11023", "authors": ["Kutalm\u0131\u015f Co\u015fkun", "Ivo Kavisanczki", "Amin Mirzaei", "Tom Siegl", "Bjarne C. Hiller", "Stefan L\u00fcdtke", "Martin Becker"], "title": "Informed, but Not Always Improved: Challenging the Benefit of Background Knowledge in GNNs", "categories": ["cs.LG"], "comment": "10 pages, 7 figures", "summary": "In complex and low-data domains such as biomedical research, incorporating\nbackground knowledge (BK) graphs, such as protein-protein interaction (PPI)\nnetworks, into graph-based machine learning pipelines is a promising research\ndirection. However, while BK is often assumed to improve model performance, its\nactual contribution and the impact of imperfect knowledge remain poorly\nunderstood. In this work, we investigate the role of BK in an important\nreal-world task: cancer subtype classification. Surprisingly, we find that (i)\nstate-of-the-art GNNs using BK perform no better than uninformed models like\nlinear regression, and (ii) their performance remains largely unchanged even\nwhen the BK graph is heavily perturbed. To understand these unexpected results,\nwe introduce an evaluation framework, which employs (i) a synthetic setting\nwhere the BK is clearly informative and (ii) a set of perturbations that\nsimulate various imperfections in BK graphs. With this, we test the robustness\nof BK-aware models in both synthetic and real-world biomedical settings. Our\nfindings reveal that careful alignment of GNN architectures and BK\ncharacteristics is necessary but holds the potential for significant\nperformance improvements.", "AI": {"tldr": "The paper explores the impact of background knowledge (BK) graphs on graph-based machine learning in biomedical tasks, finding BK often doesn't improve performance as expected. It introduces a framework to test BK's robustness and suggests aligning GNN architectures with BK for better results.", "motivation": "To understand the actual contribution of BK graphs in improving model performance, especially in low-data domains like biomedical research, and to investigate the impact of imperfect BK.", "method": "The study uses cancer subtype classification as a real-world task, comparing state-of-the-art GNNs with uninformed models. It introduces a synthetic setting and perturbations to evaluate BK's robustness.", "result": "BK-aware models perform no better than uninformed models, and their performance remains stable even with heavily perturbed BK. The framework reveals the need for careful alignment of GNN architectures with BK characteristics.", "conclusion": "Alignment between GNN architectures and BK characteristics is crucial for leveraging BK effectively, offering potential for significant performance improvements."}}
{"id": "2505.11182", "pdf": "https://arxiv.org/pdf/2505.11182", "abs": "https://arxiv.org/abs/2505.11182", "authors": ["Yuzhuo Dai", "Jiaqi Jin", "Zhibin Dong", "Siwei Wang", "Xinwang Liu", "En Zhu", "Xihong Yang", "Xinbiao Gan", "Yu Feng"], "title": "Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning", "categories": ["cs.CV", "cs.AI"], "comment": "The paper has been accepted by the 42nd CVPR 2025. The main text has\n  9 pages, including 8 figures and 4 tables. The appendix has 8 pages, with 10\n  figures and 6 tables. The reference list has 3 pages", "summary": "In incomplete multi-view clustering (IMVC), missing data induce prototype\nshifts within views and semantic inconsistencies across views. A feasible\nsolution is to explore cross-view consistency in paired complete observations,\nfurther imputing and aligning the similarity relationships inherently shared\nacross views. Nevertheless, existing methods are constrained by two-tiered\nlimitations: (1) Neither instance- nor cluster-level consistency learning\nconstruct a semantic space shared across views to learn consensus semantics.\nThe former enforces cross-view instances alignment, and wrongly regards\nunpaired observations with semantic consistency as negative pairs; the latter\nfocuses on cross-view cluster counterparts while coarsely handling fine-grained\nintra-cluster relationships within views. (2) Excessive reliance on consistency\nresults in unreliable imputation and alignment without incorporating\nview-specific cluster information. Thus, we propose an IMVC framework,\nimputation- and alignment-free for consensus semantics learning (FreeCSL). To\nbridge semantic gaps across all observations, we learn consensus prototypes\nfrom available data to discover a shared space, where semantically similar\nobservations are pulled closer for consensus semantics learning. To capture\nsemantic relationships within specific views, we design a heuristic graph\nclustering based on modularity to recover cluster structure with intra-cluster\ncompactness and inter-cluster separation for cluster semantics enhancement.\nExtensive experiments demonstrate, compared to state-of-the-art competitors,\nFreeCSL achieves more confident and robust assignments on IMVC task.", "AI": {"tldr": "FreeCSL is a new IMVC framework that learns consensus semantics without imputation or alignment, addressing limitations in existing methods by leveraging shared prototypes and heuristic graph clustering.", "motivation": "Existing IMVC methods fail to construct a shared semantic space and rely excessively on consistency, leading to unreliable imputation and alignment.", "method": "FreeCSL learns consensus prototypes for a shared space and uses heuristic graph clustering to enhance cluster semantics within views.", "result": "FreeCSL outperforms state-of-the-art methods, providing more confident and robust clustering assignments.", "conclusion": "FreeCSL effectively bridges semantic gaps and enhances cluster structures in IMVC, offering a superior alternative to existing approaches."}}
{"id": "2505.10871", "pdf": "https://arxiv.org/pdf/2505.10871", "abs": "https://arxiv.org/abs/2505.10871", "authors": ["Joonhyuk Ko", "Juba Ziani", "Ferdinando Fioretto"], "title": "Optimal Allocation of Privacy Budget on Hierarchical Data Release", "categories": ["cs.CR", "cs.AI", "cs.CY"], "comment": null, "summary": "Releasing useful information from datasets with hierarchical structures while\npreserving individual privacy presents a significant challenge. Standard\nprivacy-preserving mechanisms, and in particular Differential Privacy, often\nrequire careful allocation of a finite privacy budget across different levels\nand components of the hierarchy. Sub-optimal allocation can lead to either\nexcessive noise, rendering the data useless, or to insufficient protections for\nsensitive information. This paper addresses the critical problem of optimal\nprivacy budget allocation for hierarchical data release. It formulates this\nchallenge as a constrained optimization problem, aiming to maximize data\nutility subject to a total privacy budget while considering the inherent\ntrade-offs between data granularity and privacy loss. The proposed approach is\nsupported by theoretical analysis and validated through comprehensive\nexperiments on real hierarchical datasets. These experiments demonstrate that\noptimal privacy budget allocation significantly enhances the utility of the\nreleased data and improves the performance of downstream tasks.", "AI": {"tldr": "The paper proposes an optimal privacy budget allocation method for hierarchical data release, balancing data utility and privacy protection.", "motivation": "The challenge of preserving privacy in hierarchical datasets while maintaining data utility, due to sub-optimal budget allocation in existing methods.", "method": "Formulates the problem as a constrained optimization to maximize utility under a total privacy budget, supported by theoretical analysis and experiments.", "result": "Optimal allocation enhances data utility and improves downstream task performance, validated on real datasets.", "conclusion": "The approach effectively addresses the trade-off between granularity and privacy in hierarchical data release."}}
{"id": "2505.10586", "pdf": "https://arxiv.org/pdf/2505.10586", "abs": "https://arxiv.org/abs/2505.10586", "authors": ["Poli A. Nemkova", "Suleyman O. Polat", "Rafid I. Jahan", "Sagnik Ray Choudhury", "Sun-joo Lee", "Shouryadipta Sarkar", "Mark V. Albert"], "title": "Towards Automated Situation Awareness: A RAG-Based Framework for Peacebuilding Reports", "categories": ["cs.CY", "cs.CL"], "comment": null, "summary": "Timely and accurate situation awareness is vital for decision-making in\nhumanitarian response, conflict monitoring, and early warning and early action.\nHowever, the manual analysis of vast and heterogeneous data sources often\nresults in delays, limiting the effectiveness of interventions. This paper\nintroduces a dynamic Retrieval-Augmented Generation (RAG) system that\nautonomously generates situation awareness reports by integrating real-time\ndata from diverse sources, including news articles, conflict event databases,\nand economic indicators. Our system constructs query-specific knowledge bases\non demand, ensuring timely, relevant, and accurate insights.\n  To ensure the quality of generated reports, we propose a three-level\nevaluation framework that combines semantic similarity metrics, factual\nconsistency checks, and expert feedback. The first level employs automated NLP\nmetrics to assess coherence and factual accuracy. The second level involves\nhuman expert evaluation to verify the relevance and completeness of the\nreports. The third level utilizes LLM-as-a-Judge, where large language models\nprovide an additional layer of assessment to ensure robustness. The system is\ntested across multiple real-world scenarios, demonstrating its effectiveness in\nproducing coherent, insightful, and actionable reports. By automating report\ngeneration, our approach reduces the burden on human analysts and accelerates\ndecision-making processes. To promote reproducibility and further research, we\nopenly share our code and evaluation tools with the community via GitHub.", "AI": {"tldr": "A dynamic Retrieval-Augmented Generation (RAG) system automates situation awareness reports by integrating real-time data, evaluated via a three-level framework for quality assurance.", "motivation": "Manual analysis of vast, heterogeneous data delays interventions in humanitarian response and conflict monitoring.", "method": "The system autonomously generates reports using real-time data, with a three-level evaluation framework (automated metrics, expert feedback, LLM-as-a-Judge).", "result": "Effective in producing coherent, insightful, and actionable reports, reducing human burden and accelerating decision-making.", "conclusion": "The approach enhances situation awareness, with open-sourced tools for reproducibility and further research."}}
{"id": "2505.11024", "pdf": "https://arxiv.org/pdf/2505.11024", "abs": "https://arxiv.org/abs/2505.11024", "authors": ["Wolfgang Rannetbauer", "Simon Hubmer", "Carina Hambrock", "Ronny Ramlau"], "title": "Leveraging Real-Time Data Analysis and Multiple Kernel Learning for Manufacturing of Innovative Steels", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "29 pages, 7 figures", "summary": "The implementation of thermally sprayed components in steel manufacturing\npresents challenges for production and plant maintenance. While enhancing\nperformance through specialized surface properties, these components may\nencounter difficulties in meeting modified requirements due to standardization\nin the refurbishment process. This article proposes updating the established\ncoating process for thermally spray coated components for steel manufacturing\n(TCCSM) by integrating real-time data analytics and predictive quality\nmanagement. Two essential components--the data aggregator and the quality\npredictor--are designed through continuous process monitoring and the\napplication of data-driven methodologies to meet the dynamic demands of the\nevolving steel landscape. The quality predictor is powered by the simple and\neffective multiple kernel learning strategy with the goal of realizing\npredictive quality. The data aggregator, designed with sensors, flow meters,\nand intelligent data processing for the thermal spray coating process, is\nproposed to facilitate real-time analytics. The performance of this combination\nwas verified using small-scale tests that enabled not only the accurate\nprediction of coating quality based on the collected data but also proactive\nnotification to the operator as soon as significant deviations are identified.", "AI": {"tldr": "The paper proposes updating the thermal spray coating process for steel manufacturing by integrating real-time data analytics and predictive quality management to address challenges in production and maintenance.", "motivation": "Challenges in production and plant maintenance due to standardization in refurbishment processes for thermally sprayed components in steel manufacturing.", "method": "Integration of real-time data analytics (data aggregator with sensors and flow meters) and predictive quality management (quality predictor using multiple kernel learning).", "result": "Small-scale tests confirmed accurate prediction of coating quality and proactive operator notifications for deviations.", "conclusion": "The updated process with real-time analytics and predictive quality management effectively addresses dynamic demands in steel manufacturing."}}
{"id": "2505.11192", "pdf": "https://arxiv.org/pdf/2505.11192", "abs": "https://arxiv.org/abs/2505.11192", "authors": ["Myunsoo Kim", "Seong-Woong Shim", "Byung-Jun Lee"], "title": "FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Pretraining", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "False negatives pose a critical challenge in vision-language pretraining\n(VLP) due to the many-to-many correspondence between images and texts in\nlarge-scale datasets. These false negatives introduce conflicting supervision\nsignals that degrade the learned embedding space and diminish the effectiveness\nof hard negative sampling. In this paper, we propose FALCON (False-negative\nAware Learning of COntrastive Negatives), a learning-based mini-batch\nconstruction strategy that adaptively balances the trade-off between hard and\nfalse negatives during VLP. Rather than relying on fixed heuristics, FALCON\nemploys a negative mining scheduler that dynamically selects negative samples\nof appropriate hardness for each anchor instance during mini-batch\nconstruction, guided by a proxy for cross-modal alignment improvement.\nExperimental results demonstrate that FALCON significantly improves performance\nacross two widely adopted VLP frameworks (ALBEF, BLIP-2) and a broad range of\ndownstream tasks and evaluation settings, underscoring its effectiveness and\nrobustness in mitigating the impact of false negatives.", "AI": {"tldr": "FALCON is a learning-based mini-batch strategy for VLP that dynamically balances hard and false negatives, improving cross-modal alignment and performance.", "motivation": "False negatives in VLP degrade embedding quality and hard negative sampling effectiveness, necessitating a solution.", "method": "FALCON uses a negative mining scheduler to adaptively select negative samples during mini-batch construction, guided by cross-modal alignment improvement.", "result": "FALCON enhances performance across ALBEF, BLIP-2 frameworks and various downstream tasks.", "conclusion": "FALCON effectively mitigates false negative impact, proving robust and adaptable in VLP."}}
{"id": "2505.10872", "pdf": "https://arxiv.org/pdf/2505.10872", "abs": "https://arxiv.org/abs/2505.10872", "authors": ["Chenxi Jiang", "Chuhao Zhou", "Jianfei Yang"], "title": "REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?", "categories": ["cs.RO", "cs.AI", "cs.CL"], "comment": "Submitted to CoRL 2025, under review", "summary": "Robot task planning decomposes human instructions into executable action\nsequences that enable robots to complete a series of complex tasks. Although\nrecent large language model (LLM)-based task planners achieve amazing\nperformance, they assume that human instructions are clear and straightforward.\nHowever, real-world users are not experts, and their instructions to robots\noften contain significant vagueness. Linguists suggest that such vagueness\nfrequently arises from referring expressions (REs), whose meanings depend\nheavily on dialogue context and environment. This vagueness is even more\nprevalent among the elderly and children, who robots should serve more. This\npaper studies how such vagueness in REs within human instructions affects\nLLM-based robot task planning and how to overcome this issue. To this end, we\npropose the first robot task planning benchmark with vague REs (REI-Bench),\nwhere we discover that the vagueness of REs can severely degrade robot planning\nperformance, leading to success rate drops of up to 77.9%. We also observe that\nmost failure cases stem from missing objects in planners. To mitigate the REs\nissue, we propose a simple yet effective approach: task-oriented context\ncognition, which generates clear instructions for robots, achieving\nstate-of-the-art performance compared to aware prompt and chains of thought.\nThis work contributes to the research community of human-robot interaction\n(HRI) by making robot task planning more practical, particularly for non-expert\nusers, e.g., the elderly and children.", "AI": {"tldr": "The paper addresses vagueness in human instructions for robot task planning, introduces a benchmark (REI-Bench), and proposes a solution to improve performance.", "motivation": "Real-world users, especially the elderly and children, often give vague instructions due to referring expressions (REs), which degrade LLM-based robot task planning.", "method": "Proposes task-oriented context cognition to clarify vague instructions and evaluates it using REI-Bench.", "result": "Vagueness in REs reduces planning success rates by up to 77.9%. The proposed method outperforms existing approaches.", "conclusion": "The work enhances robot task planning for non-expert users, making HRI more practical."}}
{"id": "2505.10852", "pdf": "https://arxiv.org/pdf/2505.10852", "abs": "https://arxiv.org/abs/2505.10852", "authors": ["Siyu Liu", "Jiamin Xu", "Beilin Ye", "Bo Hu", "David J. Srolovitz", "Tongqi Wen"], "title": "MatTools: Benchmarking Large Language Models for Materials Science Tools", "categories": ["cond-mat.mtrl-sci", "cs.CL", "cs.DB"], "comment": "27 pages, 23 figures", "summary": "Large language models (LLMs) are increasingly applied to materials science\nquestions, including literature comprehension, property prediction, materials\ndiscovery and alloy design. At the same time, a wide range of physics-based\ncomputational approaches have been developed in which materials properties can\nbe calculated. Here, we propose a benchmark application to evaluate the\nproficiency of LLMs to answer materials science questions through the\ngeneration and safe execution of codes based on such physics-based\ncomputational materials science packages. MatTools is built on two\ncomplementary components: a materials simulation tool question-answer (QA)\nbenchmark and a real-world tool-usage benchmark. We designed an automated\nmethodology to efficiently collect real-world materials science tool-use\nexamples. The QA benchmark, derived from the pymatgen (Python Materials\nGenomics) codebase and documentation, comprises 69,225 QA pairs that assess the\nability of an LLM to understand materials science tools. The real-world\nbenchmark contains 49 tasks (138 subtasks) requiring the generation of\nfunctional Python code for materials property calculations. Our evaluation of\ndiverse LLMs yields three key insights: (1)Generalists outshine\nspecialists;(2)AI knows AI; and (3)Simpler is better. MatTools provides a\nstandardized framework for assessing and improving LLM capabilities for\nmaterials science tool applications, facilitating the development of more\neffective AI systems for materials science and general scientific research.", "AI": {"tldr": "MatTools benchmarks LLMs for materials science tasks using QA pairs and real-world tool-usage tasks, revealing insights like generalists outperforming specialists.", "motivation": "To evaluate LLMs' proficiency in materials science by generating and executing codes for physics-based computational tools.", "method": "Developed MatTools with a QA benchmark (69,225 pairs) and a real-world benchmark (49 tasks). Evaluated diverse LLMs.", "result": "Key insights: generalists outperform specialists, AI performs better on AI-related tasks, and simplicity enhances performance.", "conclusion": "MatTools offers a standardized framework to assess and improve LLMs for materials science, aiding AI development for scientific research."}}
{"id": "2505.11029", "pdf": "https://arxiv.org/pdf/2505.11029", "abs": "https://arxiv.org/abs/2505.11029", "authors": ["Li Ju", "Max Andersson", "Stina Fredriksson", "Edward Gl\u00f6ckner", "Andreas Hellander", "Ekta Vats", "Prashant Singh"], "title": "Exploiting the Asymmetric Uncertainty Structure of Pre-trained VLMs on the Unit Hypersphere", "categories": ["cs.LG"], "comment": null, "summary": "Vision-language models (VLMs) as foundation models have significantly\nenhanced performance across a wide range of visual and textual tasks, without\nrequiring large-scale training from scratch for downstream tasks. However,\nthese deterministic VLMs fail to capture the inherent ambiguity and uncertainty\nin natural language and visual data. Recent probabilistic post-hoc adaptation\nmethods address this by mapping deterministic embeddings onto probability\ndistributions; however, existing approaches do not account for the asymmetric\nuncertainty structure of the modalities, and the constraint that meaningful\ndeterministic embeddings reside on a unit hypersphere, potentially leading to\nsuboptimal performance. In this paper, we address the asymmetric uncertainty\nstructure inherent in textual and visual data, and propose AsymVLM to build\nprobabilistic embeddings from pre-trained VLMs on the unit hypersphere,\nenabling uncertainty quantification. We validate the effectiveness of the\nprobabilistic embeddings on established benchmarks, and present comprehensive\nablation studies demonstrating the inherent nature of asymmetry in the\nuncertainty structure of textual and visual data.", "AI": {"tldr": "AsymVLM addresses asymmetric uncertainty in vision-language models by building probabilistic embeddings on a unit hypersphere, improving uncertainty quantification.", "motivation": "Deterministic VLMs fail to capture ambiguity and uncertainty in natural language and visual data, and existing probabilistic methods ignore asymmetric uncertainty structures.", "method": "Proposes AsymVLM to create probabilistic embeddings from pre-trained VLMs on a unit hypersphere, accounting for asymmetric uncertainty.", "result": "Validated on benchmarks, showing improved uncertainty quantification and demonstrating inherent asymmetry in uncertainty structures.", "conclusion": "AsymVLM effectively addresses asymmetric uncertainty in VLMs, enhancing performance and understanding of modality-specific uncertainties."}}
{"id": "2505.11196", "pdf": "https://arxiv.org/pdf/2505.11196", "abs": "https://arxiv.org/abs/2505.11196", "authors": ["Yuang Ai", "Qihang Fan", "Xuefeng Hu", "Zhenheng Yang", "Ran He", "Huaibo Huang"], "title": "DiCo: Revitalizing ConvNets for Scalable and Efficient Diffusion Modeling", "categories": ["cs.CV"], "comment": "27 pages, 29 figures, 9 tables", "summary": "Diffusion Transformer (DiT), a promising diffusion model for visual\ngeneration, demonstrates impressive performance but incurs significant\ncomputational overhead. Intriguingly, analysis of pre-trained DiT models\nreveals that global self-attention is often redundant, predominantly capturing\nlocal patterns-highlighting the potential for more efficient alternatives. In\nthis paper, we revisit convolution as an alternative building block for\nconstructing efficient and expressive diffusion models. However, naively\nreplacing self-attention with convolution typically results in degraded\nperformance. Our investigations attribute this performance gap to the higher\nchannel redundancy in ConvNets compared to Transformers. To resolve this, we\nintroduce a compact channel attention mechanism that promotes the activation of\nmore diverse channels, thereby enhancing feature diversity. This leads to\nDiffusion ConvNet (DiCo), a family of diffusion models built entirely from\nstandard ConvNet modules, offering strong generative performance with\nsignificant efficiency gains. On class-conditional ImageNet benchmarks, DiCo\noutperforms previous diffusion models in both image quality and generation\nspeed. Notably, DiCo-XL achieves an FID of 2.05 at 256x256 resolution and 2.53\nat 512x512, with a 2.7x and 3.1x speedup over DiT-XL/2, respectively.\nFurthermore, our largest model, DiCo-H, scaled to 1B parameters, reaches an FID\nof 1.90 on ImageNet 256x256-without any additional supervision during training.\nCode: https://github.com/shallowdream204/DiCo.", "AI": {"tldr": "DiCo introduces a ConvNet-based diffusion model with compact channel attention, outperforming DiT in efficiency and performance.", "motivation": "Addressing the computational overhead and redundancy in DiT's global self-attention by exploring ConvNets as an alternative.", "method": "Replacing self-attention with convolution and introducing a compact channel attention mechanism to enhance feature diversity.", "result": "DiCo achieves better FID scores (e.g., 2.05 at 256x256) and faster generation speeds (2.7x speedup) compared to DiT.", "conclusion": "DiCo demonstrates that ConvNets can be efficient and expressive for diffusion models, outperforming Transformers in both quality and speed."}}
{"id": "2505.10900", "pdf": "https://arxiv.org/pdf/2505.10900", "abs": "https://arxiv.org/abs/2505.10900", "authors": ["Wenqing Zheng", "Noah Fatsi", "Daniel Barcklow", "Dmitri Kalaev", "Steven Yao", "Owen Reinert", "C. Bayan Bruss", "Daniele Rosa"], "title": "Explain What You Mean: Intent Augmented Knowledge Graph Recommender Built With LLM", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Interaction sparsity is the primary obstacle for recommendation systems.\nSparsity manifests in environments with disproportional cardinality of\ngroupings of entities, such as users and products in an online marketplace. It\nalso is found for newly introduced entities, described as the cold-start\nproblem. Recent efforts to mitigate this sparsity issue shifts the performance\nbottleneck to other areas in the computational pipeline. Those that focus on\nenriching sparse representations with connectivity data from other external\nsources propose methods that are resource demanding and require careful domain\nexpert aided addition of this newly introduced data. Others that turn to Large\nLanguage Model (LLM) based recommenders will quickly encounter limitations\nsurrounding data quality and availability. In this work, we propose LLM-based\nIntent Knowledge Graph Recommender (IKGR), a novel framework that leverages\nretrieval-augmented generation and an encoding approach to construct and\ndensify a knowledge graph. IKGR learns latent user-item affinities from an\ninteraction knowledge graph and further densifies it through mutual intent\nconnectivity. This addresses sparsity issues and allows the model to make\nintent-grounded recommendations with an interpretable embedding translation\nlayer. Through extensive experiments on real-world datasets, we demonstrate\nthat IKGR overcomes knowledge gaps and achieves substantial gains over\nstate-of-the-art baselines on both publicly available and our internal\nrecommendation datasets.", "AI": {"tldr": "The paper proposes LLM-based Intent Knowledge Graph Recommender (IKGR) to address sparsity in recommendation systems by leveraging retrieval-augmented generation and knowledge graph densification.", "motivation": "Interaction sparsity, including cold-start problems, hinders recommendation systems. Existing solutions either demand excessive resources or face data quality issues with LLMs.", "method": "IKGR constructs and densifies a knowledge graph using retrieval-augmented generation and encoding, learning latent user-item affinities and mutual intent connectivity.", "result": "IKGR outperforms state-of-the-art baselines on real-world datasets, addressing knowledge gaps and sparsity.", "conclusion": "IKGR effectively mitigates sparsity and improves recommendation quality with interpretable intent-grounded recommendations."}}
{"id": "2505.11154", "pdf": "https://arxiv.org/pdf/2505.11154", "abs": "https://arxiv.org/abs/2505.11154", "authors": ["Zihan Wang", "Hongwei Li", "Rui Zhang", "Yu Liu", "Wenbo Jiang", "Wenshu Fan", "Qingchuan Zhao", "Guowen Xu"], "title": "MPMA: Preference Manipulation Attack Against Model Context Protocol", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Model Context Protocol (MCP) standardizes interface mapping for large\nlanguage models (LLMs) to access external data and tools, which revolutionizes\nthe paradigm of tool selection and facilitates the rapid expansion of the LLM\nagent tool ecosystem. However, as the MCP is increasingly adopted, third-party\ncustomized versions of the MCP server expose potential security\nvulnerabilities. In this paper, we first introduce a novel security threat,\nwhich we term the MCP Preference Manipulation Attack (MPMA). An attacker\ndeploys a customized MCP server to manipulate LLMs, causing them to prioritize\nit over other competing MCP servers. This can result in economic benefits for\nattackers, such as revenue from paid MCP services or advertising income\ngenerated from free servers. To achieve MPMA, we first design a Direct\nPreference Manipulation Attack ($\\mathtt{DPMA}$) that achieves significant\neffectiveness by inserting the manipulative word and phrases into the tool name\nand description. However, such a direct modification is obvious to users and\nlacks stealthiness. To address these limitations, we further propose\nGenetic-based Advertising Preference Manipulation Attack ($\\mathtt{GAPMA}$).\n$\\mathtt{GAPMA}$ employs four commonly used strategies to initialize\ndescriptions and integrates a Genetic Algorithm (GA) to enhance stealthiness.\nThe experiment results demonstrate that $\\mathtt{GAPMA}$ balances high\neffectiveness and stealthiness. Our study reveals a critical vulnerability of\nthe MCP in open ecosystems, highlighting an urgent need for robust defense\nmechanisms to ensure the fairness of the MCP ecosystem.", "AI": {"tldr": "The paper introduces MCP Preference Manipulation Attack (MPMA), a security threat in MCP ecosystems, and proposes two attack methods (DPMA and GAPMA) to exploit it, emphasizing the need for defenses.", "motivation": "The adoption of MCP exposes security vulnerabilities, particularly third-party manipulation, threatening ecosystem fairness.", "method": "Two attack methods: Direct Preference Manipulation Attack (DPMA) and Genetic-based Advertising Preference Manipulation Attack (GAPMA), the latter using Genetic Algorithms for stealth.", "result": "GAPMA balances effectiveness and stealthiness, demonstrating the vulnerability of MCP ecosystems.", "conclusion": "The study underscores the urgency for robust defenses to protect MCP ecosystem fairness."}}
{"id": "2505.11035", "pdf": "https://arxiv.org/pdf/2505.11035", "abs": "https://arxiv.org/abs/2505.11035", "authors": ["Kihun Hong", "Sejun Park", "Ganguk Hwang"], "title": "Deep Latent Variable Model based Vertical Federated Learning with Flexible Alignment and Labeling Scenarios", "categories": ["cs.LG"], "comment": "9 pages + appendix, 8 figures, 18 tables", "summary": "Federated learning (FL) has attracted significant attention for enabling\ncollaborative learning without exposing private data. Among the primary\nvariants of FL, vertical federated learning (VFL) addresses feature-partitioned\ndata held by multiple institutions, each holding complementary information for\nthe same set of users. However, existing VFL methods often impose restrictive\nassumptions such as a small number of participating parties, fully aligned\ndata, or only using labeled data. In this work, we reinterpret alignment gaps\nin VFL as missing data problems and propose a unified framework that\naccommodates both training and inference under arbitrary alignment and labeling\nscenarios, while supporting diverse missingness mechanisms. In the experiments\non 168 configurations spanning four benchmark datasets, six training-time\nmissingness patterns, and seven testing-time missingness patterns, our method\noutperforms all baselines in 160 cases with an average gap of 9.6 percentage\npoints over the next-best competitors. To the best of our knowledge, this is\nthe first VFL framework to jointly handle arbitrary data alignment, unlabeled\ndata, and multi-party collaboration all at once.", "AI": {"tldr": "A unified VFL framework addresses alignment gaps as missing data, outperforming baselines in 160/168 cases with a 9.6% average improvement.", "motivation": "Existing VFL methods have restrictive assumptions (e.g., small parties, aligned data, labeled data). This work aims to overcome these limitations.", "method": "Reinterprets alignment gaps as missing data problems, proposing a framework for arbitrary alignment and labeling scenarios.", "result": "Outperforms baselines in 160/168 configurations, with a 9.6% average improvement.", "conclusion": "First VFL framework to handle arbitrary alignment, unlabeled data, and multi-party collaboration simultaneously."}}
{"id": "2505.11216", "pdf": "https://arxiv.org/pdf/2505.11216", "abs": "https://arxiv.org/abs/2505.11216", "authors": ["Shibin Mei", "Hang Wang", "Bingbing Ni"], "title": "GeoMM: On Geodesic Perspective for Multi-modal Learning", "categories": ["cs.CV"], "comment": "15 pages, 3 figures, accepted by CVPR2025", "summary": "Geodesic distance serves as a reliable means of measuring distance in\nnonlinear spaces, and such nonlinear manifolds are prevalent in the current\nmultimodal learning. In these scenarios, some samples may exhibit high\nsimilarity, yet they convey different semantics, making traditional distance\nmetrics inadequate for distinguishing between positive and negative samples.\nThis paper introduces geodesic distance as a novel distance metric in\nmulti-modal learning for the first time, to mine correlations between samples,\naiming to address the limitations of common distance metric. Our approach\nincorporates a comprehensive series of strategies to adapt geodesic distance\nfor the current multimodal learning. Specifically, we construct a graph\nstructure to represent the adjacency relationships among samples by\nthresholding distances between them and then apply the shortest-path algorithm\nto obtain geodesic distance within this graph. To facilitate efficient\ncomputation, we further propose a hierarchical graph structure through\nclustering and combined with incremental update strategies for dynamic status\nupdates. Extensive experiments across various downstream tasks validate the\neffectiveness of our proposed method, demonstrating its capability to capture\ncomplex relationships between samples and improve the performance of multimodal\nlearning models.", "AI": {"tldr": "The paper introduces geodesic distance as a novel metric in multimodal learning to address limitations of traditional distance metrics, using graph structures and efficient computation strategies.", "motivation": "Traditional distance metrics fail to distinguish semantically different samples in nonlinear manifolds, common in multimodal learning.", "method": "Constructs a graph structure for adjacency relationships, applies shortest-path algorithms for geodesic distance, and uses hierarchical clustering with incremental updates for efficiency.", "result": "Extensive experiments show the method captures complex sample relationships and improves multimodal learning performance.", "conclusion": "Geodesic distance is effective for multimodal learning, addressing traditional metric limitations and enhancing model performance."}}
{"id": "2505.10903", "pdf": "https://arxiv.org/pdf/2505.10903", "abs": "https://arxiv.org/abs/2505.10903", "authors": ["Ping He", "Yuhao Mao", "Changjiang Li", "Lorenzo Cavallaro", "Ting Wang", "Shouling Ji"], "title": "On the Security Risks of ML-based Malware Detection Systems: A Survey", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "Malware presents a persistent threat to user privacy and data integrity. To\ncombat this, machine learning-based (ML-based) malware detection (MD) systems\nhave been developed. However, these systems have increasingly been attacked in\nrecent years, undermining their effectiveness in practice. While the security\nrisks associated with ML-based MD systems have garnered considerable attention,\nthe majority of prior works is limited to adversarial malware examples, lacking\na comprehensive analysis of practical security risks. This paper addresses this\ngap by utilizing the CIA principles to define the scope of security risks. We\nthen deconstruct ML-based MD systems into distinct operational stages, thus\ndeveloping a stage-based taxonomy. Utilizing this taxonomy, we summarize the\ntechnical progress and discuss the gaps in the attack and defense proposals\nrelated to the ML-based MD systems within each stage. Subsequently, we conduct\ntwo case studies, using both inter-stage and intra-stage analyses according to\nthe stage-based taxonomy to provide new empirical insights. Based on these\nanalyses and insights, we suggest potential future directions from both\ninter-stage and intra-stage perspectives.", "AI": {"tldr": "The paper addresses gaps in understanding security risks of ML-based malware detection systems by using CIA principles and a stage-based taxonomy, providing empirical insights and future directions.", "motivation": "To comprehensively analyze practical security risks in ML-based malware detection systems, which prior works limited to adversarial examples.", "method": "Utilizes CIA principles and a stage-based taxonomy to deconstruct ML-based MD systems, summarizing technical progress and gaps in attack/defense proposals, followed by case studies.", "result": "Provides new empirical insights through inter-stage and intra-stage analyses, highlighting gaps and progress in ML-based MD security.", "conclusion": "Suggests future research directions for improving security in ML-based MD systems from both inter-stage and intra-stage perspectives."}}
{"id": "2505.11165", "pdf": "https://arxiv.org/pdf/2505.11165", "abs": "https://arxiv.org/abs/2505.11165", "authors": ["Haiqing Hao", "Nikola Zubi\u0107", "Weihua He", "Zhipeng Sui", "Davide Scaramuzza", "Wenhui Wang"], "title": "Maximizing Asynchronicity in Event-based Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "18 pages, 5 figures, 9 tables", "summary": "Event cameras deliver visual data with high temporal resolution, low latency,\nand minimal redundancy, yet their asynchronous, sparse sequential nature\nchallenges standard tensor-based machine learning (ML). While the recent\nasynchronous-to-synchronous (A2S) paradigm aims to bridge this gap by\nasynchronously encoding events into learned representations for ML pipelines,\nexisting A2S approaches often sacrifice representation expressivity and\ngeneralizability compared to dense, synchronous methods. This paper introduces\nEVA (EVent Asynchronous representation learning), a novel A2S framework to\ngenerate highly expressive and generalizable event-by-event representations.\nInspired by the analogy between events and language, EVA uniquely adapts\nadvances from language modeling in linear attention and self-supervised\nlearning for its construction. In demonstration, EVA outperforms prior A2S\nmethods on recognition tasks (DVS128-Gesture and N-Cars), and represents the\nfirst A2S framework to successfully master demanding detection tasks, achieving\na remarkable 47.7 mAP on the Gen1 dataset. These results underscore EVA's\ntransformative potential for advancing real-time event-based vision\napplications.", "AI": {"tldr": "EVA is a novel A2S framework for event cameras, leveraging language modeling techniques to create expressive, generalizable event representations, outperforming prior methods in recognition and detection tasks.", "motivation": "Event cameras' asynchronous, sparse data challenges standard ML. Existing A2S methods lack expressivity and generalizability compared to dense methods.", "method": "EVA adapts language modeling techniques (linear attention, self-supervised learning) to asynchronously encode events into ML-suitable representations.", "result": "EVA excels in recognition (DVS128-Gesture, N-Cars) and detection (47.7 mAP on Gen1), surpassing prior A2S methods.", "conclusion": "EVA advances real-time event-based vision by offering highly expressive and generalizable representations."}}
{"id": "2505.11040", "pdf": "https://arxiv.org/pdf/2505.11040", "abs": "https://arxiv.org/abs/2505.11040", "authors": ["Zhexiang Li", "Haoyu Wang", "Yutong Bao", "David Woodruff"], "title": "Efficient Attention via Pre-Scoring: Prioritizing Informative Keys in Transformers", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in transformer architectures deeply enhance long-context\nlanguage modeling. Among them, HyperAttention achieves competitive efficiency\nby combining a single-level LSH-based clustering with uniform residual\nsampling. However,such a sampling limits crucial keys' capturing, which in turn\nraises the overall perplexity. In this paper, we propose a pre-scoring\nmechanism to assist HyperAttention to prioritize significant keys.\nSpecifically, we introduce three scoring methods: K-means clustering, K-median\nclustering, and leverage score-based ranking (inspired by LevAttention) to\nfilter keys effectively. We further replace HyperAttention's original uniform\nresidual sampling entirely, relying exclusively on our pre-scoring mechanism.\nExperiments on ChatGLM2 (131k token context) reduce perplexity from 12 to 8.3,\nwhich outperforms standard HyperAttention. Moreover, when running on the\nVision-Transformer (ViT), our method shows that it can guarantee similar\naccuracy compared with LevAttention, and will surpass LevAttention given\nspecific parameters. Although this method introduces computational overhead,\nits combination with HyperAttention remains 20 times faster than\nFlashAttention, providing a balanced trade-off between speed and modeling\naccuracy. Our results highlight the effectiveness of integrating pre-scoring\ninto hierarchical attention mechanisms, significantly improving Transformer's\nefficiency.", "AI": {"tldr": "The paper proposes a pre-scoring mechanism to enhance HyperAttention by prioritizing significant keys, improving perplexity and efficiency.", "motivation": "HyperAttention's uniform residual sampling limits crucial keys' capturing, raising perplexity.", "method": "Introduces three pre-scoring methods (K-means, K-median, leverage score-based ranking) to replace uniform sampling in HyperAttention.", "result": "Reduces perplexity from 12 to 8.3 on ChatGLM2 and maintains accuracy on ViT, while being 20x faster than FlashAttention.", "conclusion": "Integrating pre-scoring into hierarchical attention improves Transformer efficiency and accuracy."}}
{"id": "2505.11232", "pdf": "https://arxiv.org/pdf/2505.11232", "abs": "https://arxiv.org/abs/2505.11232", "authors": ["Haiyu Li", "Charith Abhayaratne"], "title": "AW-GATCN: Adaptive Weighted Graph Attention Convolutional Network for Event Camera Data Joint Denoising and Object Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Event cameras, which capture brightness changes with high temporal\nresolution, inherently generate a significant amount of redundant and noisy\ndata beyond essential object structures. The primary challenge in event-based\nobject recognition lies in effectively removing this noise without losing\ncritical spatial-temporal information. To address this, we propose an Adaptive\nGraph-based Noisy Data Removal framework for Event-based Object Recognition.\nSpecifically, our approach integrates adaptive event segmentation based on\nnormalized density analysis, a multifactorial edge-weighting mechanism, and\nadaptive graph-based denoising strategies. These innovations significantly\nenhance the integration of spatiotemporal information, effectively filtering\nnoise while preserving critical structural features for robust recognition.\nExperimental evaluations on four challenging datasets demonstrate that our\nmethod achieves superior recognition accuracies of 83.77%, 76.79%, 99.30%, and\n96.89%, surpassing existing graph-based methods by up to 8.79%, and improving\nnoise reduction performance by up to 19.57%, with an additional accuracy gain\nof 6.26% compared to traditional Euclidean-based techniques.", "AI": {"tldr": "The paper proposes an adaptive graph-based framework to remove noisy data in event-based object recognition, achieving superior accuracy and noise reduction.", "motivation": "Event cameras generate redundant and noisy data, making it challenging to retain critical spatial-temporal information for object recognition.", "method": "The approach combines adaptive event segmentation, multifactorial edge-weighting, and adaptive graph-based denoising to filter noise while preserving essential features.", "result": "The method achieves high recognition accuracies (83.77% to 99.30%) and outperforms existing methods by up to 8.79% in accuracy and 19.57% in noise reduction.", "conclusion": "The proposed framework effectively enhances spatiotemporal information integration, improving robustness in event-based object recognition."}}
{"id": "2505.10909", "pdf": "https://arxiv.org/pdf/2505.10909", "abs": "https://arxiv.org/abs/2505.10909", "authors": ["Chiyue Wei", "Bowen Duan", "Cong Guo", "Jingyang Zhang", "Qingyue Song", "Hai \"Helen\" Li", "Yiran Chen"], "title": "Phi: Leveraging Pattern-based Hierarchical Sparsity for High-Efficiency Spiking Neural Networks", "categories": ["cs.AR", "cs.AI"], "comment": "ISCA 2025", "summary": "Spiking Neural Networks (SNNs) are gaining attention for their energy\nefficiency and biological plausibility, utilizing 0-1 activation sparsity\nthrough spike-driven computation. While existing SNN accelerators exploit this\nsparsity to skip zero computations, they often overlook the unique distribution\npatterns inherent in binary activations. In this work, we observe that\nparticular patterns exist in spike activations, which we can utilize to reduce\nthe substantial computation of SNN models. Based on these findings, we propose\na novel \\textbf{pattern-based hierarchical sparsity} framework, termed\n\\textbf{\\textit{Phi}}, to optimize computation.\n  \\textit{Phi} introduces a two-level sparsity hierarchy: Level 1 exhibits\nvector-wise sparsity by representing activations with pre-defined patterns,\nallowing for offline pre-computation with weights and significantly reducing\nmost runtime computation. Level 2 features element-wise sparsity by\ncomplementing the Level 1 matrix, using a highly sparse matrix to further\nreduce computation while maintaining accuracy. We present an algorithm-hardware\nco-design approach. Algorithmically, we employ a k-means-based pattern\nselection method to identify representative patterns and introduce a\npattern-aware fine-tuning technique to enhance Level 2 sparsity.\nArchitecturally, we design \\textbf{\\textit{Phi}}, a dedicated hardware\narchitecture that efficiently processes the two levels of \\textit{Phi} sparsity\non the fly. Extensive experiments demonstrate that \\textit{Phi} achieves a\n$3.45\\times$ speedup and a $4.93\\times$ improvement in energy efficiency\ncompared to state-of-the-art SNN accelerators, showcasing the effectiveness of\nour framework in optimizing SNN computation.", "AI": {"tldr": "The paper introduces a pattern-based hierarchical sparsity framework (Phi) for optimizing Spiking Neural Network (SNN) computation by leveraging unique spike activation patterns, achieving significant speedup and energy efficiency improvements.", "motivation": "Existing SNN accelerators overlook the unique distribution patterns in binary activations, missing opportunities to reduce computation. This work aims to exploit these patterns for efficiency.", "method": "Proposes a two-level sparsity hierarchy (vector-wise and element-wise) with a k-means-based pattern selection method and pattern-aware fine-tuning. Includes a co-designed hardware architecture (Phi) for efficient processing.", "result": "Phi achieves a 3.45x speedup and 4.93x energy efficiency improvement over state-of-the-art SNN accelerators.", "conclusion": "The Phi framework effectively optimizes SNN computation by leveraging hierarchical sparsity, demonstrating superior performance and efficiency."}}
{"id": "2505.11183", "pdf": "https://arxiv.org/pdf/2505.11183", "abs": "https://arxiv.org/abs/2505.11183", "authors": ["Jacob Trauger", "Ambuj Tewari"], "title": "On Next-Token Prediction in LLMs: How End Goals Determine the Consistency of Decoding Algorithms", "categories": ["stat.ML", "cs.CL", "cs.LG"], "comment": "23 pages", "summary": "Probabilistic next-token prediction trained using cross-entropy loss is the\nbasis of most large language models. Given a sequence of previous values,\nnext-token prediction assigns a probability to each possible next value in the\nvocabulary. There are many ways to use next-token prediction to output token\nsequences. This paper examines a few of these algorithms (greedy, lookahead,\nrandom sampling, and temperature-scaled random sampling) and studies their\nconsistency with respect to various goals encoded as loss functions. Although\nconsistency of surrogate losses with respect to a target loss function is a\nwell researched topic, we are the first to study it in the context of LLMs (to\nthe best of our knowledge). We find that, so long as next-token prediction\nconverges to its true probability distribution, random sampling is consistent\nwith outputting sequences that mimic sampling from the true probability\ndistribution. For the other goals, such as minimizing the 0-1 loss on the\nentire sequence, we show no polynomial-time algorithm is optimal for all\nprobability distributions and all decoding algorithms studied are only optimal\nfor a subset of probability distributions. When analyzing these results, we see\nthat there is a dichotomy created between the goals of information retrieval\nand creative generation for the decoding algorithms. This shows that choosing\nthe correct decoding algorithm based on the desired goal is extremely important\nand many of the ones used are lacking theoretical grounding in numerous\nscenarios.", "AI": {"tldr": "The paper analyzes consistency of next-token prediction algorithms (greedy, lookahead, random sampling, temperature-scaled sampling) with respect to various loss functions in LLMs, highlighting trade-offs between goals like information retrieval and creative generation.", "motivation": "To study the theoretical grounding of decoding algorithms in LLMs and their alignment with specific goals (e.g., mimicking true distributions or minimizing sequence-level loss).", "method": "Examines consistency of decoding algorithms (greedy, lookahead, random sampling, temperature-scaled sampling) with respect to different loss functions, analyzing their optimality for various probability distributions.", "result": "Random sampling mimics true distributions if next-token prediction converges, but no polynomial-time algorithm is universally optimal for other goals (e.g., 0-1 loss). Decoding algorithms exhibit a dichotomy between information retrieval and creative generation.", "conclusion": "Choosing the right decoding algorithm is crucial for goal alignment, and current methods often lack theoretical grounding for many scenarios."}}
{"id": "2505.11044", "pdf": "https://arxiv.org/pdf/2505.11044", "abs": "https://arxiv.org/abs/2505.11044", "authors": ["Zhirui Fang", "Kai Yang", "Jian Tao", "Jiafei Lyu", "Lusong Li", "Li Shen", "Xiu Li"], "title": "Exploration by Random Distribution Distillation", "categories": ["cs.LG"], "comment": null, "summary": "Exploration remains a critical challenge in online reinforcement learning, as\nan agent must effectively explore unknown environments to achieve high returns.\nCurrently, the main exploration algorithms are primarily count-based methods\nand curiosity-based methods, with prediction-error methods being a prominent\nexample. In this paper, we propose a novel method called \\textbf{R}andom\n\\textbf{D}istribution \\textbf{D}istillation (RDD), which samples the output of\na target network from a normal distribution. RDD facilitates a more extensive\nexploration by explicitly treating the difference between the prediction\nnetwork and the target network as an intrinsic reward. Furthermore, by\nintroducing randomness into the output of the target network for a given state\nand modeling it as a sample from a normal distribution, intrinsic rewards are\nbounded by two key components: a pseudo-count term ensuring proper exploration\ndecay and a discrepancy term accounting for predictor convergence. We\ndemonstrate that RDD effectively unifies both count-based and prediction-error\napproaches. It retains the advantages of prediction-error methods in\nhigh-dimensional spaces, while also implementing an intrinsic reward decay mode\nakin to the pseudo-count method. In the experimental section, RDD is compared\nwith more advanced methods in a series of environments. Both theoretical\nanalysis and experimental results confirm the effectiveness of our approach in\nimproving online exploration for reinforcement learning tasks.", "AI": {"tldr": "The paper introduces Random Distribution Distillation (RDD), a novel method for online reinforcement learning exploration, combining count-based and prediction-error approaches to enhance exploration efficiency.", "motivation": "Exploration is a key challenge in online reinforcement learning; current methods like count-based and curiosity-based approaches have limitations. RDD aims to unify these methods for better performance.", "method": "RDD samples the output of a target network from a normal distribution, using the prediction-target network difference as an intrinsic reward. It bounds rewards with a pseudo-count term and a discrepancy term.", "result": "RDD effectively unifies count-based and prediction-error methods, performing well in high-dimensional spaces and demonstrating improved exploration in experiments.", "conclusion": "RDD is a promising approach for enhancing online reinforcement learning exploration, validated by theoretical and experimental results."}}
{"id": "2505.11245", "pdf": "https://arxiv.org/pdf/2505.11245", "abs": "https://arxiv.org/abs/2505.11245", "authors": ["Fu-Yun Wang", "Yunhao Shui", "Jingtan Piao", "Keqiang Sun", "Hongsheng Li"], "title": "Diffusion-NPO: Negative Preference Optimization for Better Preference Aligned Generation of Diffusion Models", "categories": ["cs.CV"], "comment": "Accepted to ICLR 2025", "summary": "Diffusion models have made substantial advances in image generation, yet\nmodels trained on large, unfiltered datasets often yield outputs misaligned\nwith human preferences. Numerous methods have been proposed to fine-tune\npre-trained diffusion models, achieving notable improvements in aligning\ngenerated outputs with human preferences. However, we argue that existing\npreference alignment methods neglect the critical role of handling\nunconditional/negative-conditional outputs, leading to a diminished capacity to\navoid generating undesirable outcomes. This oversight limits the efficacy of\nclassifier-free guidance~(CFG), which relies on the contrast between\nconditional generation and unconditional/negative-conditional generation to\noptimize output quality. In response, we propose a straightforward but\nversatile effective approach that involves training a model specifically\nattuned to negative preferences. This method does not require new training\nstrategies or datasets but rather involves minor modifications to existing\ntechniques. Our approach integrates seamlessly with models such as SD1.5, SDXL,\nvideo diffusion models and models that have undergone preference optimization,\nconsistently enhancing their alignment with human preferences.", "AI": {"tldr": "The paper addresses the issue of diffusion models generating outputs misaligned with human preferences and proposes a method to improve alignment by training a model attuned to negative preferences.", "motivation": "Existing preference alignment methods for diffusion models overlook handling unconditional/negative-conditional outputs, limiting the effectiveness of classifier-free guidance (CFG).", "method": "The authors propose training a model specifically focused on negative preferences, requiring minor modifications to existing techniques without new training strategies or datasets.", "result": "The approach integrates with models like SD1.5, SDXL, and video diffusion models, consistently improving alignment with human preferences.", "conclusion": "The proposed method effectively enhances the alignment of diffusion model outputs with human preferences by addressing the oversight of negative-conditional outputs."}}
{"id": "2505.10940", "pdf": "https://arxiv.org/pdf/2505.10940", "abs": "https://arxiv.org/abs/2505.10940", "authors": ["Qing Yu", "Xiaobei Wang", "Shuchang Liu", "Yandong Bai", "Xiaoyu Yang", "Xueliang Wang", "Chang Meng", "Shanshan Wu", "Hailan Yang", "Huihui Xiao", "Xiang Li", "Fan Yang", "Xiaoqiang Feng", "Lantao Hu", "Han Li", "Kun Gai", "Lixin Zou"], "title": "Who You Are Matters: Bridging Topics and Social Roles via LLM-Enhanced Logical Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Recommender systems filter contents/items valuable to users by inferring\npreferences from user features and historical behaviors. Mainstream approaches\nfollow the learning-to-rank paradigm, which focus on discovering and modeling\nitem topics (e.g., categories), and capturing user preferences on these topics\nbased on historical interactions. However, this paradigm often neglects the\nmodeling of user characteristics and their social roles, which are logical\nconfounders influencing the correlated interest and user preference transition.\nTo bridge this gap, we introduce the user role identification task and the\nbehavioral logic modeling task that aim to explicitly model user roles and\nlearn the logical relations between item topics and user social roles. We show\nthat it is possible to explicitly solve these tasks through an efficient\nintegration framework of Large Language Model (LLM) and recommendation systems,\nfor which we propose TagCF. On the one hand, the exploitation of the LLM's\nworld knowledge and logic inference ability produces a virtual logic graph that\nreveals dynamic and expressive knowledge of users, augmenting the\nrecommendation performance. On the other hand, the user role aligns the user\nbehavioral logic with the observed user feedback, refining our understanding of\nuser behaviors. Additionally, we also show that the extracted user-item logic\ngraph is empirically a general knowledge that can benefit a wide range of\nrecommendation tasks, and conduct experiments on industrial and several public\ndatasets as verification.", "AI": {"tldr": "The paper introduces TagCF, a framework integrating Large Language Models (LLMs) with recommender systems to model user roles and behavioral logic, improving recommendation performance.", "motivation": "Existing recommender systems neglect user characteristics and social roles, which influence preferences. The paper aims to address this gap.", "method": "Proposes TagCF, which uses LLMs to create a virtual logic graph for user roles and behavioral logic, enhancing recommendations.", "result": "TagCF improves recommendation performance and provides generalizable knowledge for various tasks, validated on industrial and public datasets.", "conclusion": "Explicitly modeling user roles and behavioral logic with LLMs enhances recommender systems, offering broader applicability."}}
{"id": "2505.11314", "pdf": "https://arxiv.org/pdf/2505.11314", "abs": "https://arxiv.org/abs/2505.11314", "authors": ["Christoph Leiter", "Yuki M. Asano", "Margret Keuper", "Steffen Eger"], "title": "CROC: Evaluating and Training T2I Metrics with Pseudo- and Human-Labeled Contrastive Robustness Checks", "categories": ["cs.CV", "cs.CL"], "comment": "preprint", "summary": "The assessment of evaluation metrics (meta-evaluation) is crucial for\ndetermining the suitability of existing metrics in text-to-image (T2I)\ngeneration tasks. Human-based meta-evaluation is costly and time-intensive, and\nautomated alternatives are scarce. We address this gap and propose CROC: a\nscalable framework for automated Contrastive Robustness Checks that\nsystematically probes and quantifies metric robustness by synthesizing\ncontrastive test cases across a comprehensive taxonomy of image properties.\nWith CROC, we generate a pseudo-labeled dataset (CROC$^{syn}$) of over one\nmillion contrastive prompt-image pairs to enable a fine-grained comparison of\nevaluation metrics. We also use the dataset to train CROCScore, a new metric\nthat achieves state-of-the-art performance among open-source methods,\ndemonstrating an additional key application of our framework. To complement\nthis dataset, we introduce a human-supervised benchmark (CROC$^{hum}$)\ntargeting especially challenging categories. Our results highlight robustness\nissues in existing metrics: for example, many fail on prompts involving\nnegation, and all tested open-source metrics fail on at least 25% of cases\ninvolving correct identification of body parts.", "AI": {"tldr": "CROC is a scalable framework for automated meta-evaluation of text-to-image metrics, using contrastive test cases to assess robustness and introducing a new metric, CROCScore.", "motivation": "Human-based meta-evaluation is costly and time-intensive, and automated alternatives are lacking for assessing text-to-image metrics.", "method": "CROC synthesizes contrastive test cases across image properties, creating a pseudo-labeled dataset (CROC$^{syn}$) and a human-supervised benchmark (CROC$^{hum}$). It also trains CROCScore, a new metric.", "result": "CROCScore achieves state-of-the-art performance, while existing metrics show robustness issues, failing on prompts with negation or body part identification.", "conclusion": "CROC provides a scalable, automated solution for meta-evaluation, highlighting weaknesses in current metrics and offering a superior alternative."}}
{"id": "2505.11050", "pdf": "https://arxiv.org/pdf/2505.11050", "abs": "https://arxiv.org/abs/2505.11050", "authors": ["Jeroen Bollen", "Jan Van den Bussche", "Stijn Vansummeren", "Jonni Virtema"], "title": "Halting Recurrent GNNs and the Graded $\u03bc$-Calculus", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": null, "summary": "Graph Neural Networks (GNNs) are a class of machine-learning models that\noperate on graph-structured data. Their expressive power is intimately related\nto logics that are invariant under graded bisimilarity. Current proposals for\nrecurrent GNNs either assume that the graph size is given to the model, or\nsuffer from a lack of termination guarantees. In this paper, we propose a\nhalting mechanism for recurrent GNNs. We prove that our halting model can\nexpress all node classifiers definable in graded modal mu-calculus, even for\nthe standard GNN variant that is oblivious to the graph size. A recent\nbreakthrough in the study of the expressivity of graded modal mu-calculus in\nthe finite suggests that conversely, restricted to node classifiers definable\nin monadic second-order logic, recurrent GNNs can express only node classifiers\ndefinable in graded modal mu-calculus. To prove our main result, we develop a\nnew approximate semantics for graded mu-calculus, which we believe to be of\nindependent interest. We leverage this new semantics into a new model-checking\nalgorithm, called the counting algorithm, which is oblivious to the graph size.\nIn a final step we show that the counting algorithm can be implemented on a\nhalting recurrent GNN.", "AI": {"tldr": "Proposes a halting mechanism for recurrent GNNs, proving it can express node classifiers in graded modal mu-calculus, independent of graph size.", "motivation": "Addresses limitations in current recurrent GNNs, which lack termination guarantees or assume known graph size.", "method": "Introduces a new halting model and approximate semantics for graded mu-calculus, leading to a size-oblivious counting algorithm.", "result": "Shows the halting recurrent GNN can express all node classifiers in graded modal mu-calculus.", "conclusion": "The halting mechanism and counting algorithm advance GNN expressivity and practical applicability."}}
{"id": "2505.11246", "pdf": "https://arxiv.org/pdf/2505.11246", "abs": "https://arxiv.org/abs/2505.11246", "authors": ["Nirjhor Datta", "Afroza Akther", "M. Sohel Rahman"], "title": "Entropy-Driven Genetic Optimization for Deep-Feature-Guided Low-Light Image Enhancement", "categories": ["cs.CV"], "comment": null, "summary": "Image enhancement methods often prioritize pixel level information,\noverlooking the semantic features. We propose a novel, unsupervised,\nfuzzy-inspired image enhancement framework guided by NSGA-II algorithm that\noptimizes image brightness, contrast, and gamma parameters to achieve a balance\nbetween visual quality and semantic fidelity. Central to our proposed method is\nthe use of a pre trained deep neural network as a feature extractor. To find\nthe best enhancement settings, we use a GPU-accelerated NSGA-II algorithm that\nbalances multiple objectives, namely, increasing image entropy, improving\nperceptual similarity, and maintaining appropriate brightness. We further\nimprove the results by applying a local search phase to fine-tune the top\ncandidates from the genetic algorithm. Our approach operates entirely without\npaired training data making it broadly applicable across domains with limited\nor noisy labels. Quantitatively, our model achieves excellent performance with\naverage BRISQUE and NIQE scores of 19.82 and 3.652, respectively, in all\nunpaired datasets. Qualitatively, enhanced images by our model exhibit\nsignificantly improved visibility in shadowed regions, natural balance of\ncontrast and also preserve the richer fine detail without introducing noticable\nartifacts. This work opens new directions for unsupervised image enhancement\nwhere semantic consistency is critical.", "AI": {"tldr": "An unsupervised, fuzzy-inspired image enhancement framework using NSGA-II optimizes brightness, contrast, and gamma, balancing visual quality and semantic fidelity without paired training data.", "motivation": "Existing methods focus on pixel-level information, neglecting semantic features. This work aims to enhance images while preserving semantic consistency.", "method": "Uses a pre-trained deep neural network for feature extraction and a GPU-accelerated NSGA-II algorithm to optimize brightness, contrast, and gamma. Includes a local search phase for fine-tuning.", "result": "Achieves BRISQUE score of 19.82 and NIQE score of 3.652, with improved visibility in shadows and preserved fine details.", "conclusion": "Proposes a novel unsupervised approach for image enhancement, emphasizing semantic consistency and broad applicability."}}
{"id": "2505.10961", "pdf": "https://arxiv.org/pdf/2505.10961", "abs": "https://arxiv.org/abs/2505.10961", "authors": ["Ratnadira Widyasari", "Martin Weyssow", "Ivana Clairine Irsan", "Han Wei Ang", "Frank Liauw", "Eng Lieh Ouh", "Lwin Khin Shar", "Hong Jin Kang", "David Lo"], "title": "Let the Trial Begin: A Mock-Court Approach to Vulnerability Detection using LLM-Based Agents", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Detecting vulnerabilities in source code remains a critical yet challenging\ntask, especially when benign and vulnerable functions share significant\nsimilarities. In this work, we introduce VulTrial, a courtroom-inspired\nmulti-agent framework designed to enhance automated vulnerability detection. It\nemploys four role-specific agents, which are security researcher, code author,\nmoderator, and review board. Through extensive experiments using GPT-3.5 and\nGPT-4o we demonstrate that Vultrial outperforms single-agent and multi-agent\nbaselines. Using GPT-4o, VulTrial improves the performance by 102.39% and\n84.17% over its respective baseline. Additionally, we show that role-specific\ninstruction tuning in multi-agent with small data (50 pair samples) improves\nthe performance of VulTrial further by 139.89% and 118.30%. Furthermore, we\nanalyze the impact of increasing the number of agent interactions on VulTrial's\noverall performance. While multi-agent setups inherently incur higher costs due\nto increased token usage, our findings reveal that applying VulTrial to a\ncost-effective model like GPT-3.5 can improve its performance by 69.89%\ncompared to GPT-4o in a single-agent setting, at a lower overall cost.", "AI": {"tldr": "VulTrial, a courtroom-inspired multi-agent framework, enhances vulnerability detection by outperforming baselines with role-specific agents and instruction tuning.", "motivation": "Detecting vulnerabilities is challenging due to similarities between benign and vulnerable functions, necessitating improved automated methods.", "method": "Uses four role-specific agents (security researcher, code author, moderator, review board) and tests with GPT-3.5 and GPT-4o, including instruction tuning with small data.", "result": "VulTrial improves performance by 102.39% (GPT-4o) and 69.89% (GPT-3.5) over baselines, with further gains from instruction tuning.", "conclusion": "VulTrial is effective and cost-efficient, especially with GPT-3.5, despite higher token usage in multi-agent setups."}}
{"id": "2505.11365", "pdf": "https://arxiv.org/pdf/2505.11365", "abs": "https://arxiv.org/abs/2505.11365", "authors": ["Pierre Le Jeune", "Beno\u00eet Mal\u00e9sieux", "Weixuan Xiao", "Matteo Dora"], "title": "Phare: A Safety Probe for Large Language Models", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Ensuring the safety of large language models (LLMs) is critical for\nresponsible deployment, yet existing evaluations often prioritize performance\nover identifying failure modes. We introduce Phare, a multilingual diagnostic\nframework to probe and evaluate LLM behavior across three critical dimensions:\nhallucination and reliability, social biases, and harmful content generation.\nOur evaluation of 17 state-of-the-art LLMs reveals patterns of systematic\nvulnerabilities across all safety dimensions, including sycophancy, prompt\nsensitivity, and stereotype reproduction. By highlighting these specific\nfailure modes rather than simply ranking models, Phare provides researchers and\npractitioners with actionable insights to build more robust, aligned, and\ntrustworthy language systems.", "AI": {"tldr": "Phare is a multilingual framework to evaluate LLM safety across hallucination, biases, and harmful content, revealing systematic vulnerabilities like sycophancy and stereotypes.", "motivation": "Existing LLM evaluations focus on performance, neglecting failure modes. Phare aims to identify and address these gaps for safer deployment.", "method": "Phare evaluates 17 state-of-the-art LLMs across three dimensions: hallucination/reliability, social biases, and harmful content generation.", "result": "The study uncovers systematic vulnerabilities, including sycophancy, prompt sensitivity, and stereotype reproduction, in all tested models.", "conclusion": "Phare offers actionable insights to improve LLM robustness and alignment, prioritizing safety over mere performance rankings."}}
{"id": "2505.11054", "pdf": "https://arxiv.org/pdf/2505.11054", "abs": "https://arxiv.org/abs/2505.11054", "authors": ["M\u00e9lodie Monod", "Alessandro Micheli", "Samir Bhatt"], "title": "NeuralSurv: Deep Survival Analysis with Bayesian Uncertainty Quantification", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We introduce NeuralSurv, the first deep survival model to incorporate\nBayesian uncertainty quantification. Our non-parametric, architecture-agnostic\nframework flexibly captures time-varying covariate-risk relationships in\ncontinuous time via a novel two-stage data-augmentation scheme, for which we\nestablish theoretical guarantees. For efficient posterior inference, we\nintroduce a mean-field variational algorithm with coordinate-ascent updates\nthat scale linearly in model size. By locally linearizing the Bayesian neural\nnetwork, we obtain full conjugacy and derive all coordinate updates in closed\nform. In experiments, NeuralSurv delivers superior calibration compared to\nstate-of-the-art deep survival models, while matching or exceeding their\ndiscriminative performance across both synthetic benchmarks and real-world\ndatasets. Our results demonstrate the value of Bayesian principles in\ndata-scarce regimes by enhancing model calibration and providing robust,\nwell-calibrated uncertainty estimates for the survival function.", "AI": {"tldr": "NeuralSurv is a Bayesian deep survival model with uncertainty quantification, offering superior calibration and performance.", "motivation": "To address the lack of Bayesian uncertainty quantification in deep survival models and improve calibration in data-scarce scenarios.", "method": "Uses a two-stage data-augmentation scheme for flexible time-varying relationships and a mean-field variational algorithm for efficient posterior inference.", "result": "Outperforms state-of-the-art models in calibration and matches/exceeds discriminative performance on synthetic and real-world datasets.", "conclusion": "Bayesian principles enhance model calibration and provide robust uncertainty estimates, especially in data-scarce settings."}}
{"id": "2505.11257", "pdf": "https://arxiv.org/pdf/2505.11257", "abs": "https://arxiv.org/abs/2505.11257", "authors": ["Giulia Bertazzini", "Daniele Baracchi", "Dasara Shullani", "Isao Echizen", "Alessandro Piva"], "title": "DRAGON: A Large-Scale Dataset of Realistic Images Generated by Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The remarkable ease of use of diffusion models for image generation has led\nto a proliferation of synthetic content online. While these models are often\nemployed for legitimate purposes, they are also used to generate fake images\nthat support misinformation and hate speech. Consequently, it is crucial to\ndevelop robust tools capable of detecting whether an image has been generated\nby such models. Many current detection methods, however, require large volumes\nof sample images for training. Unfortunately, due to the rapid evolution of the\nfield, existing datasets often cover only a limited range of models and quickly\nbecome outdated. In this work, we introduce DRAGON, a comprehensive dataset\ncomprising images from 25 diffusion models, spanning both recent advancements\nand older, well-established architectures. The dataset contains a broad variety\nof images representing diverse subjects. To enhance image realism, we propose a\nsimple yet effective pipeline that leverages a large language model to expand\ninput prompts, thereby generating more diverse and higher-quality outputs, as\nevidenced by improvements in standard quality metrics. The dataset is provided\nin multiple sizes (ranging from extra-small to extra-large) to accomodate\ndifferent research scenarios. DRAGON is designed to support the forensic\ncommunity in developing and evaluating detection and attribution techniques for\nsynthetic content. Additionally, the dataset is accompanied by a dedicated test\nset, intended to serve as a benchmark for assessing the performance of newly\ndeveloped methods.", "AI": {"tldr": "DRAGON is a comprehensive dataset for detecting synthetic images from 25 diffusion models, designed to address the limitations of outdated datasets and support forensic research.", "motivation": "The rise of synthetic content from diffusion models necessitates robust detection tools, but current methods lack up-to-date and diverse datasets.", "method": "DRAGON includes images from 25 diffusion models, enhanced by a pipeline using a large language model to improve prompt diversity and image quality.", "result": "The dataset improves standard quality metrics and is available in multiple sizes, with a dedicated test set for benchmarking.", "conclusion": "DRAGON supports the development of detection techniques for synthetic content, providing a versatile and up-to-date resource for researchers."}}
{"id": "2505.10973", "pdf": "https://arxiv.org/pdf/2505.10973", "abs": "https://arxiv.org/abs/2505.10973", "authors": ["Narayanan PP", "Sarvesh Prasanth Venkatesan", "Srinivas Kantha Reddy", "Shishir Kolathaya"], "title": "GROQLoco: Generalist and RObot-agnostic Quadruped Locomotion Control using Offline Datasets", "categories": ["cs.RO", "cs.AI", "cs.LG", "I.2.9"], "comment": "18pages, 16figures, 6tables", "summary": "Recent advancements in large-scale offline training have demonstrated the\npotential of generalist policy learning for complex robotic tasks. However,\napplying these principles to legged locomotion remains a challenge due to\ncontinuous dynamics and the need for real-time adaptation across diverse\nterrains and robot morphologies. In this work, we propose GROQLoco, a scalable,\nattention-based framework that learns a single generalist locomotion policy\nacross multiple quadruped robots and terrains, relying solely on offline\ndatasets. Our approach leverages expert demonstrations from two distinct\nlocomotion behaviors - stair traversal (non-periodic gaits) and flat terrain\ntraversal (periodic gaits) - collected across multiple quadruped robots, to\ntrain a generalist model that enables behavior fusion for both behaviors.\nCrucially, our framework operates directly on proprioceptive data from all\nrobots without incorporating any robot-specific encodings. The policy is\ndirectly deployable on an Intel i7 nuc, producing low-latency control outputs\nwithout any test-time optimization. Our extensive experiments demonstrate\nstrong zero-shot transfer across highly diverse quadruped robots and terrains,\nincluding hardware deployment on the Unitree Go1, a commercially available 12kg\nrobot. Notably, we evaluate challenging cross-robot training setups where\ndifferent locomotion skills are unevenly distributed across robots, yet observe\nsuccessful transfer of both flat walking and stair traversal behaviors to all\nrobots at test time. We also show preliminary walking on Stoch 5, a 70kg\nquadruped, on flat and outdoor terrains without requiring any fine tuning.\nThese results highlight the potential for robust generalist locomotion across\ndiverse robots and terrains.", "AI": {"tldr": "GROQLoco is an attention-based framework for generalist locomotion policy learning across diverse quadruped robots and terrains, using offline datasets without robot-specific encodings.", "motivation": "Legged locomotion is challenging due to continuous dynamics and real-time adaptation needs. GROQLoco aims to enable robust, generalist policies for diverse robots and terrains.", "method": "Leverages expert demonstrations (stair and flat terrain traversal) from multiple robots, trains a single policy using proprioceptive data, and operates without test-time optimization.", "result": "Demonstrates zero-shot transfer across diverse robots and terrains, including hardware deployment on Unitree Go1 and Stoch 5.", "conclusion": "GROQLoco shows potential for scalable, robust generalist locomotion policies without fine-tuning."}}
{"id": "2505.11405", "pdf": "https://arxiv.org/pdf/2505.11405", "abs": "https://arxiv.org/abs/2505.11405", "authors": ["Bohao Xing", "Xin Liu", "Guoying Zhao", "Chengyu Liu", "Xiaolan Fu", "Heikki K\u00e4lvi\u00e4inen"], "title": "EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Emotion understanding is a critical yet challenging task. Recent advances in\nMultimodal Large Language Models (MLLMs) have significantly enhanced their\ncapabilities in this area. However, MLLMs often suffer from hallucinations,\ngenerating irrelevant or nonsensical content. To the best of our knowledge,\ndespite the importance of this issue, there has been no dedicated effort to\nevaluate emotion-related hallucinations in MLLMs. In this work, we introduce\nEmotionHallucer, the first benchmark for detecting and analyzing emotion\nhallucinations in MLLMs. Unlike humans, whose emotion understanding stems from\nthe interplay of biology and social learning, MLLMs rely solely on data-driven\nlearning and lack innate emotional instincts. Fortunately, emotion psychology\nprovides a solid foundation of knowledge about human emotions. Building on\nthis, we assess emotion hallucinations from two dimensions: emotion psychology\nknowledge and real-world multimodal perception. To support robust evaluation,\nwe utilize an adversarial binary question-answer (QA) framework, which employs\ncarefully crafted basic and hallucinated pairs to assess the emotion\nhallucination tendencies of MLLMs. By evaluating 38 LLMs and MLLMs on\nEmotionHallucer, we reveal that: i) most current models exhibit substantial\nissues with emotion hallucinations; ii) closed-source models outperform\nopen-source ones in detecting emotion hallucinations, and reasoning capability\nprovides additional advantages; iii) existing models perform better in emotion\npsychology knowledge than in multimodal emotion perception. As a byproduct,\nthese findings inspire us to propose the PEP-MEK framework, which yields an\naverage improvement of 9.90% in emotion hallucination detection across selected\nmodels. Resources will be available at\nhttps://github.com/xxtars/EmotionHallucer.", "AI": {"tldr": "The paper introduces EmotionHallucer, the first benchmark for detecting emotion hallucinations in Multimodal Large Language Models (MLLMs), revealing significant issues and proposing the PEP-MEK framework for improvement.", "motivation": "Addressing the lack of dedicated evaluation for emotion-related hallucinations in MLLMs, despite their critical role in emotion understanding.", "method": "Uses an adversarial binary QA framework to assess emotion hallucinations, leveraging emotion psychology knowledge and real-world multimodal perception.", "result": "Most models struggle with emotion hallucinations; closed-source models outperform open-source ones, and reasoning capability helps.", "conclusion": "The PEP-MEK framework improves emotion hallucination detection by 9.90%, with resources made publicly available."}}
{"id": "2505.11067", "pdf": "https://arxiv.org/pdf/2505.11067", "abs": "https://arxiv.org/abs/2505.11067", "authors": ["Omobayode Fagbohungbe", "Corey Lammie", "Malte J. Rasch", "Takashi Ando", "Tayfun Gokmen", "Vijay Narayanan"], "title": "Assessing the Performance of Analog Training for Transfer Learning", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.CV", "cs.DC", "cs.NE"], "comment": null, "summary": "Analog in-memory computing is a next-generation computing paradigm that\npromises fast, parallel, and energy-efficient deep learning training and\ntransfer learning (TL). However, achieving this promise has remained elusive\ndue to a lack of suitable training algorithms. Analog memory devices exhibit\nasymmetric and non-linear switching behavior in addition to device-to-device\nvariation, meaning that most, if not all, of the current off-the-shelf training\nalgorithms cannot achieve good training outcomes. Also, recently introduced\nalgorithms have enjoyed limited attention, as they require bi-directionally\nswitching devices of unrealistically high symmetry and precision and are highly\nsensitive. A new algorithm chopped TTv2 (c-TTv2), has been introduced, which\nleverages the chopped technique to address many of the challenges mentioned\nabove. In this paper, we assess the performance of the c-TTv2 algorithm for\nanalog TL using a Swin-ViT model on a subset of the CIFAR100 dataset. We also\ninvestigate the robustness of our algorithm to changes in some device\nspecifications, including weight transfer noise, symmetry point skew, and\nsymmetry point variability", "AI": {"tldr": "The paper introduces a new algorithm, c-TTv2, for analog in-memory computing to address challenges like asymmetric device behavior and variability, and evaluates its performance for transfer learning.", "motivation": "Current training algorithms fail to achieve good outcomes in analog in-memory computing due to device non-linearities and variations. Existing solutions require unrealistic device symmetry and precision.", "method": "The c-TTv2 algorithm uses a chopped technique to mitigate challenges. Performance is assessed using a Swin-ViT model on CIFAR100, testing robustness to device specifications like noise and variability.", "result": "The c-TTv2 algorithm shows promise in handling analog device challenges, though specific performance metrics are not detailed in the abstract.", "conclusion": "c-TTv2 is a viable solution for analog transfer learning, addressing key limitations of current methods, but further evaluation is needed."}}
{"id": "2505.11264", "pdf": "https://arxiv.org/pdf/2505.11264", "abs": "https://arxiv.org/abs/2505.11264", "authors": ["Mohamed Ali Chebbi", "Ewelina Rupnik", "Paul Lopes", "Marc Pierrot-Deseilligny"], "title": "Multi-view dense image matching with similarity learning and geometry priors", "categories": ["cs.CV"], "comment": null, "summary": "We introduce MV-DeepSimNets, a comprehensive suite of deep neural networks\ndesigned for multi-view similarity learning, leveraging epipolar geometry for\ntraining. Our approach incorporates an online geometry prior to characterize\npixel relationships, either along the epipolar line or through homography\nrectification. This enables the generation of geometry-aware features from\nnative images, which are then projected across candidate depth hypotheses using\nplane sweeping. Our method geometric preconditioning effectively adapts\nepipolar-based features for enhanced multi-view reconstruction, without\nrequiring the laborious multi-view training dataset creation. By aggregating\nlearned similarities, we construct and regularize the cost volume, leading to\nimproved multi-view surface reconstruction over traditional dense matching\napproaches. MV-DeepSimNets demonstrates superior performance against leading\nsimilarity learning networks and end-to-end regression models, especially in\nterms of generalization capabilities across both aerial and satellite imagery\nwith varied ground sampling distances. Our pipeline is integrated into MicMac\nsoftware and can be readily adopted in standard multi-resolution image matching\npipelines.", "AI": {"tldr": "MV-DeepSimNets is a deep learning suite for multi-view similarity learning, using epipolar geometry and online geometry priors to improve multi-view reconstruction without extensive training data.", "motivation": "To enhance multi-view reconstruction by leveraging geometry-aware features and avoiding laborious dataset creation.", "method": "Incorporates epipolar geometry and homography rectification to generate geometry-aware features, aggregates similarities to regularize cost volume.", "result": "Superior performance in multi-view reconstruction, especially for aerial and satellite imagery with varied resolutions.", "conclusion": "MV-DeepSimNets offers a scalable, geometry-aware solution for multi-view reconstruction, integrated into MicMac software."}}
{"id": "2505.10994", "pdf": "https://arxiv.org/pdf/2505.10994", "abs": "https://arxiv.org/abs/2505.10994", "authors": ["Rees Chang", "Angela Pak", "Alex Guerra", "Ni Zhan", "Nick Richardson", "Elif Ertekin", "Ryan P. Adams"], "title": "Space Group Equivariant Crystal Diffusion", "categories": ["cond-mat.mtrl-sci", "cs.AI"], "comment": null, "summary": "Accelerating inverse design of crystalline materials with generative models\nhas significant implications for a range of technologies. Unlike other atomic\nsystems, 3D crystals are invariant to discrete groups of isometries called the\nspace groups. Crucially, these space group symmetries are known to heavily\ninfluence materials properties. We propose SGEquiDiff, a crystal generative\nmodel which naturally handles space group constraints with space group\ninvariant likelihoods. SGEquiDiff consists of an SE(3)-invariant, telescoping\ndiscrete sampler of crystal lattices; permutation-invariant, transformer-based\nautoregressive sampling of Wyckoff positions, elements, and numbers of\nsymmetrically unique atoms; and space group equivariant diffusion of atomic\ncoordinates. We show that space group equivariant vector fields automatically\nlive in the tangent spaces of the Wyckoff positions. SGEquiDiff achieves\nstate-of-the-art performance on standard benchmark datasets as assessed by\nquantitative proxy metrics and quantum mechanical calculations.", "AI": {"tldr": "SGEquiDiff is a generative model for designing crystalline materials, incorporating space group symmetries to improve performance and accuracy.", "motivation": "Space group symmetries heavily influence material properties, but existing models struggle to handle these constraints effectively.", "method": "SGEquiDiff uses SE(3)-invariant lattice sampling, permutation-invariant autoregressive sampling, and space group equivariant diffusion for atomic coordinates.", "result": "The model achieves state-of-the-art performance on benchmark datasets, validated by proxy metrics and quantum mechanical calculations.", "conclusion": "SGEquiDiff effectively integrates space group constraints, advancing inverse design of crystalline materials."}}
{"id": "2505.11406", "pdf": "https://arxiv.org/pdf/2505.11406", "abs": "https://arxiv.org/abs/2505.11406", "authors": ["Jenny Xiyu Fu", "Brennan Antone", "Kowe Kadoma", "Malte Jung"], "title": "Large Language Model Use Impact Locus of Control", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "As AI tools increasingly shape how we write, they may also quietly reshape\nhow we perceive ourselves. This paper explores the psychological impact of\nco-writing with AI on people's locus of control. Through an empirical study\nwith 462 participants, we found that employment status plays a critical role in\nshaping users' reliance on AI and their locus of control. Current results\ndemonstrated that employed participants displayed higher reliance on AI and a\nshift toward internal control, while unemployed users tended to experience a\nreduction in personal agency. Through quantitative results and qualitative\nobservations, this study opens a broader conversation about AI's role in\nshaping personal agency and identity.", "AI": {"tldr": "AI co-writing affects users' locus of control, with employed individuals relying more on AI and feeling more in control, while unemployed users feel less agency.", "motivation": "To understand how AI co-writing influences psychological aspects like locus of control and personal agency.", "method": "Empirical study with 462 participants, analyzing reliance on AI and shifts in locus of control.", "result": "Employed participants showed higher AI reliance and internal control; unemployed users felt reduced agency.", "conclusion": "The study highlights AI's psychological impact, urging further discussion on its role in personal identity."}}
{"id": "2505.11076", "pdf": "https://arxiv.org/pdf/2505.11076", "abs": "https://arxiv.org/abs/2505.11076", "authors": ["Vladim\u00edr Bo\u017ea", "Vladim\u00edr Macko"], "title": "Addition is almost all you need: Compressing neural networks with double binary factorization", "categories": ["cs.LG"], "comment": null, "summary": "Binary quantization approaches, which replace weight matrices with binary\nmatrices and substitute costly multiplications with cheaper additions, offer a\ncomputationally efficient approach to address the increasing computational and\nstorage requirements of Large Language Models (LLMs). However, the severe\nquantization constraint ($\\pm1$) can lead to significant accuracy degradation.\nIn this paper, we propose Double Binary Factorization (DBF), a novel method\nthat factorizes dense weight matrices into products of two binary (sign)\nmatrices, each accompanied by scaling vectors. DBF preserves the efficiency\nadvantages of binary representations while achieving compression rates that are\ncompetitive with or superior to state-of-the-art methods. Specifically, in a\n1-bit per weight range, DBF is better than existing binarization approaches. In\na 2-bit per weight range, DBF is competitive with the best quantization methods\nlike QuIP\\# and QTIP. Unlike most existing compression techniques, which offer\nlimited compression level choices, DBF allows fine-grained control over\ncompression ratios by adjusting the factorization's intermediate dimension.\nBased on this advantage, we further introduce an algorithm for estimating\nnon-uniform layer-wise compression ratios for DBF, based on previously\ndeveloped channel pruning criteria.\n  Code available at: https://github.com/usamec/double_binary", "AI": {"tldr": "DBF factorizes weight matrices into two binary matrices with scaling vectors, preserving efficiency while improving accuracy and compression rates.", "motivation": "Address computational and storage demands of LLMs while minimizing accuracy loss from binary quantization.", "method": "Double Binary Factorization (DBF) decomposes dense weights into two binary matrices with scaling vectors, allowing adjustable compression ratios.", "result": "DBF outperforms 1-bit binarization methods and matches 2-bit quantization techniques like QuIP# and QTIP, with flexible compression control.", "conclusion": "DBF offers efficient, accurate, and adaptable compression for LLMs, with fine-grained control over compression ratios."}}
{"id": "2505.11267", "pdf": "https://arxiv.org/pdf/2505.11267", "abs": "https://arxiv.org/abs/2505.11267", "authors": ["Wuzhou Quan", "Mingqiang Wei", "Jinhui Tang"], "title": "Equal is Not Always Fair: A New Perspective on Hyperspectral Representation Non-Uniformity", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Hyperspectral image (HSI) representation is fundamentally challenged by\npervasive non-uniformity, where spectral dependencies, spatial continuity, and\nfeature efficiency exhibit complex and often conflicting behaviors. Most\nexisting models rely on a unified processing paradigm that assumes homogeneity\nacross dimensions, leading to suboptimal performance and biased\nrepresentations. To address this, we propose FairHyp, a fairness-directed\nframework that explicitly disentangles and resolves the threefold\nnon-uniformity through cooperative yet specialized modules. We introduce a\nRunge-Kutta-inspired spatial variability adapter to restore spatial coherence\nunder resolution discrepancies, a multi-receptive field convolution module with\nsparse-aware refinement to enhance discriminative features while respecting\ninherent sparsity, and a spectral-context state space model that captures\nstable and long-range spectral dependencies via bidirectional Mamba scanning\nand statistical aggregation. Unlike one-size-fits-all solutions, FairHyp\nachieves dimension-specific adaptation while preserving global consistency and\nmutual reinforcement. This design is grounded in the view that non-uniformity\narises from the intrinsic structure of HSI representations, rather than any\nparticular task setting. To validate this, we apply FairHyp across four\nrepresentative tasks including classification, denoising, super-resolution, and\ninpaintin, demonstrating its effectiveness in modeling a shared structural\nflaw. Extensive experiments show that FairHyp consistently outperforms\nstate-of-the-art methods under varied imaging conditions. Our findings redefine\nfairness as a structural necessity in HSI modeling and offer a new paradigm for\nbalancing adaptability, efficiency, and fidelity in high-dimensional vision\ntasks.", "AI": {"tldr": "FairHyp is a fairness-directed framework for hyperspectral image (HSI) representation, addressing non-uniformity through specialized modules for spatial, spectral, and feature adaptation, outperforming state-of-the-art methods.", "motivation": "Existing HSI models assume homogeneity, leading to suboptimal performance due to non-uniformity in spectral, spatial, and feature dimensions. FairHyp aims to resolve this by disentangling and addressing these non-uniformities.", "method": "FairHyp uses a Runge-Kutta-inspired spatial adapter, multi-receptive field convolution with sparse-aware refinement, and a spectral-context state space model with bidirectional Mamba scanning.", "result": "FairHyp outperforms state-of-the-art methods in tasks like classification, denoising, super-resolution, and inpainting, demonstrating its adaptability and effectiveness.", "conclusion": "FairHyp redefines fairness as a structural necessity in HSI modeling, offering a balanced approach for high-dimensional vision tasks."}}
{"id": "2505.11032", "pdf": "https://arxiv.org/pdf/2505.11032", "abs": "https://arxiv.org/abs/2505.11032", "authors": ["Yuran Wang", "Ruihai Wu", "Yue Chen", "Jiarui Wang", "Jiaqi Liang", "Ziyu Zhu", "Haoran Geng", "Jitendra Malik", "Pieter Abbeel", "Hao Dong"], "title": "DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "Garment manipulation is a critical challenge due to the diversity in garment\ncategories, geometries, and deformations. Despite this, humans can effortlessly\nhandle garments, thanks to the dexterity of our hands. However, existing\nresearch in the field has struggled to replicate this level of dexterity,\nprimarily hindered by the lack of realistic simulations of dexterous garment\nmanipulation. Therefore, we propose DexGarmentLab, the first environment\nspecifically designed for dexterous (especially bimanual) garment manipulation,\nwhich features large-scale high-quality 3D assets for 15 task scenarios, and\nrefines simulation techniques tailored for garment modeling to reduce the\nsim-to-real gap. Previous data collection typically relies on teleoperation or\ntraining expert reinforcement learning (RL) policies, which are labor-intensive\nand inefficient. In this paper, we leverage garment structural correspondence\nto automatically generate a dataset with diverse trajectories using only a\nsingle expert demonstration, significantly reducing manual intervention.\nHowever, even extensive demonstrations cannot cover the infinite states of\ngarments, which necessitates the exploration of new algorithms. To improve\ngeneralization across diverse garment shapes and deformations, we propose a\nHierarchical gArment-manipuLation pOlicy (HALO). It first identifies\ntransferable affordance points to accurately locate the manipulation area, then\ngenerates generalizable trajectories to complete the task. Through extensive\nexperiments and detailed analysis of our method and baseline, we demonstrate\nthat HALO consistently outperforms existing methods, successfully generalizing\nto previously unseen instances even with significant variations in shape and\ndeformation where others fail. Our project page is available at:\nhttps://wayrise.github.io/DexGarmentLab/.", "AI": {"tldr": "DexGarmentLab introduces a simulation environment for dexterous garment manipulation, leveraging structural correspondence for dataset generation and proposing HALO for improved generalization.", "motivation": "Existing research struggles with realistic simulations of dexterous garment manipulation, lacking efficiency and generalization.", "method": "Proposes DexGarmentLab with high-quality 3D assets and refined simulation techniques, and HALO for hierarchical garment manipulation.", "result": "HALO outperforms baselines, generalizing to unseen garment shapes and deformations.", "conclusion": "DexGarmentLab and HALO advance dexterous garment manipulation, reducing manual effort and improving generalization."}}
{"id": "2505.11409", "pdf": "https://arxiv.org/pdf/2505.11409", "abs": "https://arxiv.org/abs/2505.11409", "authors": ["Yi Xu", "Chengzu Li", "Han Zhou", "Xingchen Wan", "Caiqi Zhang", "Anna Korhonen", "Ivan Vuli\u0107"], "title": "Visual Planning: Let's Think Only with Images", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "10 pages, 6 figures, 1 table (26 pages, 12 figures, 8 tables\n  including references and appendices)", "summary": "Recent advancements in Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) have substantially enhanced machine reasoning across diverse\ntasks. However, these models predominantly rely on pure text as the medium for\nboth expressing and structuring reasoning, even when visual information is\npresent. In this work, we argue that language may not always be the most\nnatural or effective modality for reasoning, particularly in tasks involving\nspatial and geometrical information. Motivated by this, we propose a new\nparadigm, Visual Planning, which enables planning through purely visual\nrepresentations, independent of text. In this paradigm, planning is executed\nvia sequences of images that encode step-by-step inference in the visual\ndomain, akin to how humans sketch or visualize future actions. We introduce a\nnovel reinforcement learning framework, Visual Planning via Reinforcement\nLearning (VPRL), empowered by GRPO for post-training large vision models,\nleading to substantial improvements in planning in a selection of\nrepresentative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our\nvisual planning paradigm outperforms all other planning variants that conduct\nreasoning in the text-only space. Our results establish Visual Planning as a\nviable and promising alternative to language-based reasoning, opening new\navenues for tasks that benefit from intuitive, image-based inference.", "AI": {"tldr": "The paper introduces Visual Planning, a paradigm for reasoning via visual representations instead of text, and proposes VPRL, a reinforcement learning framework, showing superior performance in visual navigation tasks.", "motivation": "Language may not be the most effective modality for reasoning, especially in tasks involving spatial or geometrical information, prompting the need for visual-based reasoning.", "method": "Proposes Visual Planning, a paradigm using sequences of images for step-by-step inference, and introduces VPRL, a reinforcement learning framework with GRPO for post-training vision models.", "result": "VPRL outperforms text-only reasoning methods in visual navigation tasks (FrozenLake, Maze, MiniBehavior), demonstrating the effectiveness of visual planning.", "conclusion": "Visual Planning is a viable alternative to language-based reasoning, offering new possibilities for tasks requiring intuitive, image-based inference."}}
{"id": "2505.11081", "pdf": "https://arxiv.org/pdf/2505.11081", "abs": "https://arxiv.org/abs/2505.11081", "authors": ["Pierre Clavier", "Nathan Grinsztajn", "Raphael Avalos", "Yannis Flet-Berliac", "Irem Ergun", "Omar D. Domingues", "Eugene Tarassov", "Olivier Pietquin", "Pierre H. Richemond", "Florian Strub", "Matthieu Geist"], "title": "ShiQ: Bringing back Bellman to LLMs", "categories": ["cs.LG"], "comment": null, "summary": "The fine-tuning of pre-trained large language models (LLMs) using\nreinforcement learning (RL) is generally formulated as direct policy\noptimization. This approach was naturally favored as it efficiently improves a\npretrained LLM, seen as an initial policy. Another RL paradigm, Q-learning\nmethods, has received far less attention in the LLM community while\ndemonstrating major success in various non-LLM RL tasks. In particular,\nQ-learning effectiveness comes from its sample efficiency and ability to learn\noffline, which is particularly valuable given the high computational cost of\nsampling with LLMs. However, naively applying a Q-learning-style update to the\nmodel's logits is ineffective due to the specificity of LLMs. Our core\ncontribution is to derive theoretically grounded loss functions from Bellman\nequations to adapt Q-learning methods to LLMs. To do so, we carefully adapt\ninsights from the RL literature to account for LLM-specific characteristics,\nensuring that the logits become reliable Q-value estimates. We then use this\nloss to build a practical algorithm, ShiQ for Shifted-Q, that supports\noff-policy, token-wise learning while remaining simple to implement. Finally,\nwe evaluate ShiQ on both synthetic data and real-world benchmarks, e.g.,\nUltraFeedback and BFCL-V3, demonstrating its effectiveness in both single-turn\nand multi-turn LLM settings", "AI": {"tldr": "The paper introduces ShiQ, a Q-learning adaptation for fine-tuning LLMs, addressing inefficiencies in direct policy optimization by leveraging Bellman equations for reliable Q-value estimates.", "motivation": "Direct policy optimization for LLM fine-tuning is computationally expensive, while Q-learning's sample efficiency and offline learning potential are underutilized.", "method": "Derives theoretically grounded loss functions from Bellman equations, adapting Q-learning for LLMs, and implements the ShiQ algorithm for off-policy, token-wise learning.", "result": "ShiQ demonstrates effectiveness on synthetic data and benchmarks like UltraFeedback and BFCL-V3 in single- and multi-turn LLM settings.", "conclusion": "ShiQ successfully bridges Q-learning and LLM fine-tuning, offering a practical and efficient alternative to direct policy optimization."}}
{"id": "2505.11282", "pdf": "https://arxiv.org/pdf/2505.11282", "abs": "https://arxiv.org/abs/2505.11282", "authors": ["Shrutarv Awasthi", "Anas Gouda", "Sven Franke", "J\u00e9r\u00f4me Rutinowski", "Frank Hoffmann", "Moritz Roidl"], "title": "MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection", "categories": ["cs.CV"], "comment": "accepted to CVPR 2025 Workshop on Event-based Vision", "summary": "Mobile robots are reaching unprecedented speeds, with platforms like Unitree\nB2, and Fraunhofer O3dyn achieving maximum speeds between 5 and 10 m/s.\nHowever, effectively utilizing such speeds remains a challenge due to the\nlimitations of RGB cameras, which suffer from motion blur and fail to provide\nreal-time responsiveness. Event cameras, with their asynchronous operation, and\nlow-latency sensing, offer a promising alternative for high-speed robotic\nperception. In this work, we introduce MTevent, a dataset designed for 6D pose\nestimation and moving object detection in highly dynamic environments with\nlarge detection distances. Our setup consists of a stereo-event camera and an\nRGB camera, capturing 75 scenes, each on average 16 seconds, and featuring 16\nunique objects under challenging conditions such as extreme viewing angles,\nvarying lighting, and occlusions. MTevent is the first dataset to combine\nhigh-speed motion, long-range perception, and real-world object interactions,\nmaking it a valuable resource for advancing event-based vision in robotics. To\nestablish a baseline, we evaluate the task of 6D pose estimation using NVIDIA's\nFoundationPose on RGB images, achieving an Average Recall of 0.22 with\nground-truth masks, highlighting the limitations of RGB-based approaches in\nsuch dynamic settings. With MTevent, we provide a novel resource to improve\nperception models and foster further research in high-speed robotic vision. The\ndataset is available for download\nhttps://huggingface.co/datasets/anas-gouda/MTevent", "AI": {"tldr": "MTevent is a new dataset for 6D pose estimation and moving object detection in high-speed, dynamic environments using stereo-event and RGB cameras. It highlights the limitations of RGB-based methods and aims to advance event-based vision in robotics.", "motivation": "Current RGB cameras struggle with motion blur and latency in high-speed robotic applications, while event cameras offer a promising alternative. MTevent addresses the lack of datasets for such scenarios.", "method": "The dataset includes 75 scenes captured with stereo-event and RGB cameras, featuring 16 unique objects under challenging conditions like extreme angles, lighting changes, and occlusions.", "result": "Baseline evaluation using RGB images achieved an Average Recall of 0.22, showing the limitations of RGB-based methods in dynamic settings.", "conclusion": "MTevent provides a valuable resource for improving perception models and advancing research in high-speed robotic vision, with the dataset publicly available."}}
{"id": "2505.11083", "pdf": "https://arxiv.org/pdf/2505.11083", "abs": "https://arxiv.org/abs/2505.11083", "authors": ["Guangqiang Li", "M. Amine Atoui", "Xiangshun Li"], "title": "Fault Diagnosis across Heterogeneous Domains via Self-Adaptive Temporal-Spatial Attention and Sample Generation", "categories": ["cs.LG", "cs.AI"], "comment": "31 pages, 11 figures", "summary": "Deep learning methods have shown promising performance in fault diagnosis for\nmultimode process. Most existing studies assume that the collected health state\ncategories from different operating modes are identical. However, in real\nindustrial scenarios, these categories typically exhibit only partial overlap.\nThe incompleteness of the available data and the large distributional\ndifferences between the operating modes pose a significant challenge to\nexisting fault diagnosis methods. To address this problem, a novel fault\ndiagnosis model named self-adaptive temporal-spatial attention network\n(TSA-SAN) is proposed. First, inter-mode mappings are constructed using healthy\ncategory data to generate multimode samples. To enrich the diversity of the\nfault data, interpolation is performed between healthy and fault samples.\nSubsequently, the fault diagnosis model is trained using real and generated\ndata. The self-adaptive instance normalization is established to suppress\nirrelevant information while retaining essential statistical features for\ndiagnosis. In addition, a temporal-spatial attention mechanism is constructed\nto focus on the key features, thus enhancing the generalization ability of the\nmodel. The extensive experiments demonstrate that the proposed model\nsignificantly outperforms the state-of-the-art methods. The code will be\navailable on Github at https://github.com/GuangqiangLi/TSA-SAN.", "AI": {"tldr": "A novel fault diagnosis model (TSA-SAN) addresses partial overlap in health state categories across operating modes by generating diverse data and using attention mechanisms, outperforming existing methods.", "motivation": "Existing fault diagnosis methods assume identical health state categories across modes, but real industrial scenarios often have partial overlap, posing challenges.", "method": "TSA-SAN constructs inter-mode mappings, enriches fault data via interpolation, uses self-adaptive instance normalization, and employs temporal-spatial attention to focus on key features.", "result": "The model significantly outperforms state-of-the-art methods in experiments.", "conclusion": "TSA-SAN effectively handles partial category overlap and distribution differences, improving fault diagnosis performance."}}
{"id": "2305.15099", "pdf": "https://arxiv.org/pdf/2305.15099", "abs": "https://arxiv.org/abs/2305.15099", "authors": ["Ziwei He", "Meng Yang", "Minwei Feng", "Jingcheng Yin", "Xinbing Wang", "Jingwen Leng", "Zhouhan Lin"], "title": "Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator", "categories": ["cs.CL"], "comment": null, "summary": "The transformer model is known to be computationally demanding, and\nprohibitively costly for long sequences, as the self-attention module uses a\nquadratic time and space complexity with respect to sequence length. Many\nresearchers have focused on designing new forms of self-attention or\nintroducing new parameters to overcome this limitation, however a large portion\nof them prohibits the model to inherit weights from large pretrained models. In\nthis work, the transformer's inefficiency has been taken care of from another\nperspective. We propose Fourier Transformer, a simple yet effective approach by\nprogressively removing redundancies in hidden sequence using the ready-made\nFast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation\n(DCT). Fourier Transformer is able to significantly reduce computational costs\nwhile retain the ability to inherit from various large pretrained models.\nExperiments show that our model achieves state-of-the-art performances among\nall transformer-based models on the long-range modeling benchmark LRA with\nsignificant improvement in both speed and space. For generative seq-to-seq\ntasks including CNN/DailyMail and ELI5, by inheriting the BART weights our\nmodel outperforms the standard BART and other efficient models. Our code is\npublicly available at https://github.com/LUMIA-Group/FourierTransformer", "AI": {"tldr": "The paper introduces Fourier Transformer, a method using FFT and DCT to reduce computational costs in transformers while retaining pretrained model compatibility.", "motivation": "Transformers are computationally expensive for long sequences due to quadratic complexity in self-attention. Existing solutions often prevent weight inheritance from pretrained models.", "method": "Proposes Fourier Transformer, leveraging FFT for DCT to progressively remove redundancies in sequences, reducing costs without sacrificing pretrained model compatibility.", "result": "Achieves state-of-the-art performance on LRA benchmark and outperforms BART in generative tasks, with improved speed and space efficiency.", "conclusion": "Fourier Transformer effectively addresses transformer inefficiency, enabling efficient long-sequence modeling and seamless integration with pretrained models."}}
{"id": "2505.11085", "pdf": "https://arxiv.org/pdf/2505.11085", "abs": "https://arxiv.org/abs/2505.11085", "authors": ["Oliver Schacht", "Biwei Huang"], "title": "A Fast Kernel-based Conditional Independence test with Application to Causal Discovery", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "9 pages, 5 figures", "summary": "Kernel-based conditional independence (KCI) testing is a powerful\nnonparametric method commonly employed in causal discovery tasks. Despite its\nflexibility and statistical reliability, cubic computational complexity limits\nits application to large datasets. To address this computational bottleneck, we\npropose \\textit{FastKCI}, a scalable and parallelizable kernel-based\nconditional independence test that utilizes a mixture-of-experts approach\ninspired by embarrassingly parallel inference techniques for Gaussian\nprocesses. By partitioning the dataset based on a Gaussian mixture model over\nthe conditioning variables, FastKCI conducts local KCI tests in parallel,\naggregating the results using an importance-weighted sampling scheme.\nExperiments on synthetic datasets and benchmarks on real-world production data\nvalidate that FastKCI maintains the statistical power of the original KCI test\nwhile achieving substantial computational speedups. FastKCI thus represents a\npractical and efficient solution for conditional independence testing in causal\ninference on large-scale data.", "AI": {"tldr": "FastKCI is a scalable, parallelizable kernel-based conditional independence test that reduces computational complexity while maintaining statistical power.", "motivation": "The cubic computational complexity of KCI testing limits its use on large datasets, prompting the need for a more efficient method.", "method": "FastKCI uses a mixture-of-experts approach, partitioning data via a Gaussian mixture model and conducting parallel local KCI tests, with results aggregated via importance-weighted sampling.", "result": "FastKCI achieves significant computational speedups without losing statistical power, as validated on synthetic and real-world datasets.", "conclusion": "FastKCI is a practical and efficient solution for conditional independence testing in large-scale causal inference."}}
{"id": "2505.11293", "pdf": "https://arxiv.org/pdf/2505.11293", "abs": "https://arxiv.org/abs/2505.11293", "authors": ["Raghuveer Thirukovalluru", "Rui Meng", "Ye Liu", "Karthikeyan K", "Mingyi Su", "Ping Nie", "Semih Yavuz", "Yingbo Zhou", "Wenhu Chen", "Bhuwan Dhingra"], "title": "Breaking the Batch Barrier (B3) of Contrastive Learning via Smart Batch Mining", "categories": ["cs.CV"], "comment": "14 pages, 4 figures", "summary": "Contrastive learning (CL) is a prevalent technique for training embedding\nmodels, which pulls semantically similar examples (positives) closer in the\nrepresentation space while pushing dissimilar ones (negatives) further apart. A\nkey source of negatives are 'in-batch' examples, i.e., positives from other\nexamples in the batch. Effectiveness of such models is hence strongly\ninfluenced by the size and quality of training batches. In this work, we\npropose 'Breaking the Batch Barrier' (B3), a novel batch construction strategy\ndesigned to curate high-quality batches for CL. Our approach begins by using a\npretrained teacher embedding model to rank all examples in the dataset, from\nwhich a sparse similarity graph is constructed. A community detection algorithm\nis then applied to this graph to identify clusters of examples that serve as\nstrong negatives for one another. The clusters are then used to construct\nbatches that are rich in in-batch negatives. Empirical results on the MMEB\nmultimodal embedding benchmark (36 tasks) demonstrate that our method sets a\nnew state of the art, outperforming previous best methods by +1.3 and +2.9\npoints at the 7B and 2B model scales, respectively. Notably, models trained\nwith B3 surpass existing state-of-the-art results even with a batch size as\nsmall as 64, which is 4-16x smaller than that required by other methods.", "AI": {"tldr": "The paper introduces 'Breaking the Batch Barrier' (B3), a batch construction strategy for contrastive learning that improves embedding model performance by curating high-quality batches with strong negatives.", "motivation": "Current contrastive learning methods rely on in-batch negatives, whose quality and batch size significantly impact model effectiveness. The goal is to enhance batch construction for better performance.", "method": "B3 uses a pretrained teacher model to rank dataset examples, constructs a sparse similarity graph, applies community detection to identify clusters of strong negatives, and forms batches rich in in-batch negatives.", "result": "B3 achieves state-of-the-art results on the MMEB benchmark, outperforming previous methods by +1.3 and +2.9 points at 7B and 2B scales, respectively, even with smaller batch sizes (e.g., 64).", "conclusion": "B3 effectively improves contrastive learning by optimizing batch construction, enabling superior performance with smaller batch sizes."}}
{"id": "2505.11100", "pdf": "https://arxiv.org/pdf/2505.11100", "abs": "https://arxiv.org/abs/2505.11100", "authors": ["Lang Feng", "Jiahao Lin", "Dong Xing", "Li Zhang", "De Ma", "Gang Pan"], "title": "Bidirectional Distillation: A Mixed-Play Framework for Multi-Agent Generalizable Behaviors", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Population-population generalization is a challenging problem in multi-agent\nreinforcement learning (MARL), particularly when agents encounter unseen\nco-players. However, existing self-play-based methods are constrained by the\nlimitation of inside-space generalization. In this study, we propose\nBidirectional Distillation (BiDist), a novel mixed-play framework, to overcome\nthis limitation in MARL. BiDist leverages knowledge distillation in two\nalternating directions: forward distillation, which emulates the historical\npolicies' space and creates an implicit self-play, and reverse distillation,\nwhich systematically drives agents towards novel distributions outside the\nknown policy space in a non-self-play manner. In addition, BiDist operates as a\nconcise and efficient solution without the need for the complex and costly\nstorage of past policies. We provide both theoretical analysis and empirical\nevidence to support BiDist's effectiveness. Our results highlight its\nremarkable generalization ability across a variety of cooperative, competitive,\nand social dilemma tasks, and reveal that BiDist significantly diversifies the\npolicy distribution space. We also present comprehensive ablation studies to\nreinforce BiDist's effectiveness and key success factors. Source codes are\navailable in the supplementary material.", "AI": {"tldr": "BiDist, a bidirectional distillation framework, enhances MARL generalization by combining forward and reverse distillation, outperforming self-play methods.", "motivation": "Addressing the limitation of self-play-based methods in MARL for population-population generalization, especially with unseen co-players.", "method": "Proposes BiDist, a mixed-play framework using bidirectional knowledge distillation (forward and reverse) to diversify policy space.", "result": "BiDist shows strong generalization in cooperative, competitive, and social dilemma tasks, diversifying policy space effectively.", "conclusion": "BiDist is a concise, efficient solution for MARL generalization, validated by theory and experiments."}}
{"id": "2311.07564", "pdf": "https://arxiv.org/pdf/2311.07564", "abs": "https://arxiv.org/abs/2311.07564", "authors": ["Cristina Aggazzotti", "Nicholas Andrews", "Elizabeth Allyn Smith"], "title": "Can Authorship Attribution Models Distinguish Speakers in Speech Transcripts?", "categories": ["cs.CL", "cs.LG"], "comment": "Published in Transactions of the Association for Computational\n  Linguistics; 1st revision includes additional experiments and evaluations;\n  2nd revision includes minor tweak to TFIDF table numbers", "summary": "Authorship verification is the task of determining if two distinct writing\nsamples share the same author and is typically concerned with the attribution\nof written text. In this paper, we explore the attribution of transcribed\nspeech, which poses novel challenges. The main challenge is that many stylistic\nfeatures, such as punctuation and capitalization, are not informative in this\nsetting. On the other hand, transcribed speech exhibits other patterns, such as\nfiller words and backchannels (e.g., 'um', 'uh-huh'), which may be\ncharacteristic of different speakers. We propose a new benchmark for speaker\nattribution focused on human-transcribed conversational speech transcripts. To\nlimit spurious associations of speakers with topic, we employ both conversation\nprompts and speakers participating in the same conversation to construct\nverification trials of varying difficulties. We establish the state of the art\non this new benchmark by comparing a suite of neural and non-neural baselines,\nfinding that although written text attribution models achieve surprisingly good\nperformance in certain settings, they perform markedly worse as conversational\ntopic is increasingly controlled. We present analyses of the impact of\ntranscription style on performance as well as the ability of fine-tuning on\nspeech transcripts to improve performance.", "AI": {"tldr": "The paper introduces a new benchmark for speaker attribution in transcribed speech, addressing challenges like missing stylistic features and leveraging conversational patterns like filler words. It evaluates neural and non-neural models, showing limitations of text-based methods when topic control increases.", "motivation": "To address the novel challenges of speaker attribution in transcribed speech, where traditional stylistic features (e.g., punctuation) are absent, but other patterns (e.g., filler words) may be informative.", "method": "Proposes a benchmark using human-transcribed conversational speech, controlling for topic bias via conversation prompts and shared speakers. Evaluates neural and non-neural models, including fine-tuning on speech transcripts.", "result": "Text-based models perform well in some settings but degrade with increased topic control. Fine-tuning on speech transcripts improves performance.", "conclusion": "The benchmark highlights the need for specialized models for transcribed speech attribution, as text-based methods are insufficient under controlled topics."}}
{"id": "2505.11106", "pdf": "https://arxiv.org/pdf/2505.11106", "abs": "https://arxiv.org/abs/2505.11106", "authors": ["Thanadej Rattanakornphan", "Piyanon Charoenpoonpanich", "Chainarong Amornbunchornvej"], "title": "Inferring the Most Similar Variable-length Subsequences between Multidimensional Time Series", "categories": ["cs.LG", "cs.AI", "cs.DB", "stat.ME"], "comment": "Under review", "summary": "Finding the most similar subsequences between two multidimensional time\nseries has many applications: e.g. capturing dependency in stock market or\ndiscovering coordinated movement of baboons. Considering one pattern occurring\nin one time series, we might be wondering whether the same pattern occurs in\nanother time series with some distortion that might have a different length.\nNevertheless, to the best of our knowledge, there is no efficient framework\nthat deals with this problem yet. In this work, we propose an algorithm that\nprovides the exact solution of finding the most similar multidimensional\nsubsequences between time series where there is a difference in length both\nbetween time series and between subsequences. The algorithm is built based on\ntheoretical guarantee of correctness and efficiency. The result in simulation\ndatasets illustrated that our approach not just only provided correct solution,\nbut it also utilized running time only quarter of time compared against the\nbaseline approaches. In real-world datasets, it extracted the most similar\nsubsequences even faster (up to 20 times faster against baseline methods) and\nprovided insights regarding the situation in stock market and following\nrelations of multidimensional time series of baboon movement. Our approach can\nbe used for any time series. The code and datasets of this work are provided\nfor the public use.", "AI": {"tldr": "Proposes an efficient algorithm for finding the most similar multidimensional subsequences between time series with length differences, outperforming baselines in speed and accuracy.", "motivation": "Addressing the lack of efficient frameworks for identifying similar patterns in multidimensional time series with distortions and length variations.", "method": "Develops an algorithm with theoretical guarantees for correctness and efficiency, tested on simulation and real-world datasets.", "result": "Outperforms baselines, running up to 20 times faster, and provides insights into stock market dependencies and baboon movement patterns.", "conclusion": "The algorithm is versatile, efficient, and publicly available for any time series analysis."}}
{"id": "2505.11326", "pdf": "https://arxiv.org/pdf/2505.11326", "abs": "https://arxiv.org/abs/2505.11326", "authors": ["Keunwoo Peter Yu", "Joyce Chai"], "title": "Temporally-Grounded Language Generation: A Benchmark for Real-Time Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages", "summary": "Vision-language models (VLMs) have shown remarkable progress in offline tasks\nsuch as image captioning and video question answering. However, real-time\ninteractive environments impose new demands on VLMs, requiring them to generate\nutterances that are not only semantically accurate but also precisely timed. We\nidentify two core capabilities necessary for such settings --\n$\\textit{perceptual updating}$ and $\\textit{contingency awareness}$ -- and\npropose a new benchmark task, $\\textbf{Temporally-Grounded Language Generation\n(TGLG)}$, to evaluate them. TGLG requires models to generate utterances in\nresponse to streaming video such that both content and timing align with\ndynamic visual input. To support this benchmark, we curate evaluation datasets\nfrom sports broadcasting and egocentric human interaction domains, and\nintroduce a new metric, $\\textbf{TRACE}$, to evaluate TGLG by jointly measuring\nsemantic similarity and temporal alignment. Finally, we present\n$\\textbf{Vision-Language Model with Time-Synchronized Interleaving (VLM-TSI)}$,\na model that interleaves visual and linguistic tokens in a time-synchronized\nmanner, enabling real-time language generation without relying on turn-based\nassumptions. Experimental results show that VLM-TSI significantly outperforms a\nstrong baseline, yet overall performance remains modest -- highlighting the\ndifficulty of TGLG and motivating further research in real-time VLMs. Code and\ndata available $\\href{https://github.com/yukw777/tglg}{here}$.", "AI": {"tldr": "The paper introduces Temporally-Grounded Language Generation (TGLG), a benchmark for evaluating real-time VLMs, and proposes VLM-TSI, a model for time-synchronized language generation.", "motivation": "Real-time interactive environments require VLMs to generate semantically accurate and precisely timed utterances, which existing models lack.", "method": "Proposes TGLG benchmark and VLM-TSI, a model that interleaves visual and linguistic tokens in a time-synchronized manner.", "result": "VLM-TSI outperforms baselines but overall performance remains modest, indicating the challenge of TGLG.", "conclusion": "TGLG is a challenging task, motivating further research in real-time VLMs."}}
{"id": "2505.11108", "pdf": "https://arxiv.org/pdf/2505.11108", "abs": "https://arxiv.org/abs/2505.11108", "authors": ["Kartik Ramachandruni", "Sonia Chernova"], "title": "PARSEC: Preference Adaptation for Robotic Object Rearrangement from Scene Context", "categories": ["cs.RO", "cs.AI"], "comment": "Under review at ROMAN 2025", "summary": "Object rearrangement is a key task for household robots requiring\npersonalization without explicit instructions, meaningful object placement in\nenvironments occupied with objects, and generalization to unseen objects and\nnew environments. To facilitate research addressing these challenges, we\nintroduce PARSEC, an object rearrangement benchmark for learning user\norganizational preferences from observed scene context to place objects in a\npartially arranged environment. PARSEC is built upon a novel dataset of 110K\nrearrangement examples crowdsourced from 72 users, featuring 93 object\ncategories and 15 environments. We also propose ContextSortLM, an LLM-based\nrearrangement model that places objects in partially arranged environments by\nadapting to user preferences from prior and current scene context while\naccounting for multiple valid placements. We evaluate ContextSortLM and\nexisting personalized rearrangement approaches on the PARSEC benchmark and\ncomplement these findings with a crowdsourced evaluation of 108 online raters\nranking model predictions based on alignment with user preferences. Our results\nindicate that personalized rearrangement models leveraging multiple scene\ncontext sources perform better than models relying on a single context source.\nMoreover, ContextSortLM outperforms other models in placing objects to\nreplicate the target user's arrangement and ranks among the top two in all\nthree environment categories, as rated by online evaluators. Importantly, our\nevaluation highlights challenges associated with modeling environment semantics\nacross different environment categories and provides recommendations for future\nwork.", "AI": {"tldr": "PARSEC is a benchmark for object rearrangement, introducing a dataset and ContextSortLM, an LLM-based model. It shows personalized models using multiple context sources outperform others.", "motivation": "Addressing the need for household robots to learn user preferences for object placement without explicit instructions, generalizing to unseen objects and environments.", "method": "PARSEC benchmark with 110K examples from 72 users, and ContextSortLM, an LLM-based model adapting to user preferences from scene context.", "result": "ContextSortLM outperforms others in replicating user arrangements and ranks top in evaluations. Personalized models using multiple context sources perform better.", "conclusion": "The work highlights challenges in modeling environment semantics and suggests future improvements, showing promise for personalized rearrangement."}}
{"id": "2402.14889", "pdf": "https://arxiv.org/pdf/2402.14889", "abs": "https://arxiv.org/abs/2402.14889", "authors": ["Priyanshul Govil", "Hemang Jain", "Vamshi Krishna Bonagiri", "Aman Chadha", "Ponnurangam Kumaraguru", "Manas Gaur", "Sanorita Dey"], "title": "COBIAS: Assessing the Contextual Reliability of Bias Benchmarks for Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) often inherit biases from the web data they are\ntrained on, which contains stereotypes and prejudices. Current methods for\nevaluating and mitigating these biases rely on bias-benchmark datasets. These\nbenchmarks measure bias by observing an LLM's behavior on biased statements.\nHowever, these statements lack contextual considerations of the situations they\ntry to present. To address this, we introduce a contextual reliability\nframework, which evaluates model robustness to biased statements by considering\nthe various contexts in which they may appear. We develop the Context-Oriented\nBias Indicator and Assessment Score (COBIAS) to measure a biased statement's\nreliability in detecting bias, based on the variance in model behavior across\ndifferent contexts. To evaluate the metric, we augmented 2,291 stereotyped\nstatements from two existing benchmark datasets by adding contextual\ninformation. We show that COBIAS aligns with human judgment on the contextual\nreliability of biased statements (Spearman's $\\rho = 0.65, p = 3.4 * 10^{-60}$)\nand can be used to create reliable benchmarks, which would assist bias\nmitigation works.", "AI": {"tldr": "The paper introduces COBIAS, a contextual reliability framework, to better evaluate and mitigate biases in LLMs by considering contextual variance in biased statements.", "motivation": "Current bias evaluation methods lack contextual considerations, leading to unreliable benchmarks. The paper aims to improve bias detection by incorporating context.", "method": "Developed COBIAS to measure bias reliability based on contextual variance. Augmented 2,291 stereotyped statements with contextual data for evaluation.", "result": "COBIAS aligns with human judgment (Spearman\u2019s \u03c1 = 0.65) and improves bias benchmark reliability.", "conclusion": "COBIAS enhances bias evaluation and mitigation by contextualizing biased statements, aiding in creating more reliable benchmarks."}}
{"id": "2505.11111", "pdf": "https://arxiv.org/pdf/2505.11111", "abs": "https://arxiv.org/abs/2505.11111", "authors": ["Lin Zhu", "Yijun Bian", "Lei You"], "title": "FairSHAP: Preprocessing for Fairness Through Attribution-Based Data Augmentation", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "3 figures, 15 pages", "summary": "Ensuring fairness in machine learning models is critical, particularly in\nhigh-stakes domains where biased decisions can lead to serious societal\nconsequences. Existing preprocessing approaches generally lack transparent\nmechanisms for identifying which features or instances are responsible for\nunfairness. This obscures the rationale behind data modifications. We introduce\nFairSHAP, a novel pre-processing framework that leverages Shapley value\nattribution to improve both individual and group fairness. FairSHAP identifies\nfairness-critical instances in the training data using an interpretable measure\nof feature importance, and systematically modifies them through instance-level\nmatching across sensitive groups. This process reduces discriminative risk - an\nindividual fairness metric - while preserving data integrity and model\naccuracy. We demonstrate that FairSHAP significantly improves demographic\nparity and equality of opportunity across diverse tabular datasets, achieving\nfairness gains with minimal data perturbation and, in some cases, improved\npredictive performance. As a model-agnostic and transparent method, FairSHAP\nintegrates seamlessly into existing machine learning pipelines and provides\nactionable insights into the sources of bias.Our code is on\nhttps://github.com/youlei202/FairSHAP.", "AI": {"tldr": "FairSHAP is a pre-processing framework using Shapley values to enhance fairness in ML models by identifying and modifying fairness-critical instances, improving both individual and group fairness with minimal data disruption.", "motivation": "Addressing the lack of transparency in existing preprocessing methods for identifying unfairness sources in ML models, especially in high-stakes domains.", "method": "FairSHAP leverages Shapley values to pinpoint fairness-critical instances and modifies them via instance-level matching across sensitive groups, reducing discriminative risk while maintaining data integrity and accuracy.", "result": "FairSHAP significantly improves demographic parity and equality of opportunity across datasets, with minimal data perturbation and sometimes better predictive performance.", "conclusion": "FairSHAP is a model-agnostic, transparent tool that integrates into ML pipelines, offering actionable insights into bias sources while enhancing fairness."}}
{"id": "2505.11334", "pdf": "https://arxiv.org/pdf/2505.11334", "abs": "https://arxiv.org/abs/2505.11334", "authors": ["Y. B. Wang", "S Wang", "J. N. Zhang", "J. F. Wu", "Q. D. He", "C. C. Fu", "C. J. Wang", "Y. Liu"], "title": "MARRS: Masked Autoregressive Unit-based Reaction Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "This work aims at a challenging task: human action-reaction synthesis, i.e.,\ngenerating human reactions based on the action sequence of the other as\nconditions. Currently, autoregressive modeling approaches have achieved\nremarkable performance in motion generation tasks, e.g. text-to-motion.\nHowever, vector quantization (VQ) accompanying autoregressive generation has\ninherent disadvantages, including loss of quantization information, low\ncodebook utilization, etc. Moreover, unlike text-to-motion, which focuses\nsolely on the movement of body joints, human action-reaction synthesis also\nencompasses fine-grained hand movements. In this work, we propose MARRS, a\nnovel framework designed to generate coordinated and fine-grained reaction\nmotions in continuous representations. Initially, we present the\nUnit-distinguished Motion Variational AutoEncoder (UD-VAE), which segments the\nentire body into distinct body and hand units, encoding them independently.\nSubsequently, we propose Action-Conditioned Fusion (ACF), which involves\nrandomly masking a subset of reactive tokens and extracting specific\ninformation about the body and hands from the active tokens. Furthermore, we\nintroduce Adaptive Unit Modulation (AUM) to facilitate interaction between body\nand hand units by using the information from one unit to adaptively modulate\nthe other. Finally, for the diffusion model, we employ a compact MLP as a noise\npredictor for each distinct body unit and incorporate the diffusion loss to\nmodel the probability distribution of each token. Quantitative and qualitative\nresults demonstrate that our method achieves superior performance. The code\nwill be released upon acceptance.", "AI": {"tldr": "The paper introduces MARRS, a framework for human action-reaction synthesis, addressing challenges like fine-grained hand movements and VQ limitations with novel components like UD-VAE, ACF, and AUM.", "motivation": "To overcome the limitations of autoregressive and VQ-based methods in generating human reactions, especially for fine-grained hand movements, and to improve coordination in motion synthesis.", "method": "Proposes MARRS with UD-VAE for independent encoding of body and hand units, ACF for action-conditioned fusion, AUM for adaptive modulation, and a diffusion model with MLP noise predictors.", "result": "Quantitative and qualitative results show superior performance in generating coordinated and fine-grained reaction motions.", "conclusion": "MARRS effectively addresses the challenges of human action-reaction synthesis, outperforming existing methods."}}
{"id": "2505.11123", "pdf": "https://arxiv.org/pdf/2505.11123", "abs": "https://arxiv.org/abs/2505.11123", "authors": ["Zibin Dong", "Yicheng Liu", "Yinchuan Li", "Hang Zhao", "Jianye Hao"], "title": "Conditioning Matters: Training Diffusion Policies is Faster Than You Think", "categories": ["cs.RO", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2505.10105", "summary": "Diffusion policies have emerged as a mainstream paradigm for building\nvision-language-action (VLA) models. Although they demonstrate strong robot\ncontrol capabilities, their training efficiency remains suboptimal. In this\nwork, we identify a fundamental challenge in conditional diffusion policy\ntraining: when generative conditions are hard to distinguish, the training\nobjective degenerates into modeling the marginal action distribution, a\nphenomenon we term loss collapse. To overcome this, we propose Cocos, a simple\nyet general solution that modifies the source distribution in the conditional\nflow matching to be condition-dependent. By anchoring the source distribution\naround semantics extracted from condition inputs, Cocos encourages stronger\ncondition integration and prevents the loss collapse. We provide theoretical\njustification and extensive empirical results across simulation and real-world\nbenchmarks. Our method achieves faster convergence and higher success rates\nthan existing approaches, matching the performance of large-scale pre-trained\nVLAs using significantly fewer gradient steps and parameters. Cocos is\nlightweight, easy to implement, and compatible with diverse policy\narchitectures, offering a general-purpose improvement to diffusion policy\ntraining.", "AI": {"tldr": "Cocos improves diffusion policy training by preventing loss collapse, achieving faster convergence and higher success rates with fewer resources.", "motivation": "The inefficiency in training diffusion policies for vision-language-action models due to loss collapse when conditions are hard to distinguish.", "method": "Proposes Cocos, which modifies the source distribution in conditional flow matching to be condition-dependent, anchoring it around condition semantics.", "result": "Faster convergence, higher success rates, and performance matching large-scale models with fewer steps and parameters.", "conclusion": "Cocos is a lightweight, general-purpose solution for improving diffusion policy training."}}
{"id": "2404.10652", "pdf": "https://arxiv.org/pdf/2404.10652", "abs": "https://arxiv.org/abs/2404.10652", "authors": ["Quan Van Nguyen", "Dan Quang Tran", "Huy Quang Pham", "Thang Kien-Bao Nguyen", "Nghia Hieu Nguyen", "Kiet Van Nguyen", "Ngan Luu-Thuy Nguyen"], "title": "ViTextVQA: A Large-Scale Visual Question Answering Dataset for Evaluating Vietnamese Text Comprehension in Images", "categories": ["cs.CL"], "comment": null, "summary": "Visual Question Answerinng (VQA) is a complicated task that requires the\ncapability of simultaneously processing natural language and images. This task\nwas initially researched with a focus on developing methods to help machines\nunderstand objects and scene contexts in images. However, some scene text that\ncarries explicit information about the full content of the image is not\nmentioned. Along with the continuous development of the AI era, there have been\nmany studies on the reading comprehension ability of VQA models in the world.\nTherefore, we introduce the first large-scale dataset in Vietnamese\nspecializing in the ability to understand scene text, we call it ViTextVQA\n(\\textbf{Vi}etnamese \\textbf{Text}-based \\textbf{V}isual \\textbf{Q}uestion\n\\textbf{A}nswering dataset) which contains \\textbf{over 16,000} images and\n\\textbf{over 50,000} questions with answers. To tackle this task efficiently,\nwe propose ViTextBLIP-2, an novel multimodal feature fusion Method, which\noptimizes Vietnamese OCR-based VQA by integrating a frozen Vision Transformer,\nSwinTextSpotter OCR, and ViT5 LLM with a trainable Q-Former for multimodal\nfeature fusion. Through experiments with various state-of-the-art models, we\nuncover the significance of the order in which tokens in OCR text are processed\nand selected to formulate answers. This finding helped us significantly improve\nthe performance of the baseline models on the ViTextVQA dataset. Our dataset is\navailable (https://github.com/minhquan6203/ViTextVQA-Dataset) for research\npurposes.", "AI": {"tldr": "The paper introduces ViTextVQA, a Vietnamese dataset for scene text understanding in VQA, and proposes ViTextBLIP-2, a novel method combining OCR and LLMs for improved performance.", "motivation": "Existing VQA research overlooks scene text in images, which carries explicit information. The study aims to address this gap by focusing on Vietnamese text comprehension.", "method": "Proposes ViTextBLIP-2, integrating a frozen Vision Transformer, SwinTextSpotter OCR, ViT5 LLM, and a trainable Q-Former for multimodal feature fusion.", "result": "Experiments show the importance of OCR token processing order, leading to significant performance improvements on the ViTextVQA dataset.", "conclusion": "The study advances VQA by emphasizing scene text understanding and provides a valuable dataset for future research."}}
{"id": "2505.11117", "pdf": "https://arxiv.org/pdf/2505.11117", "abs": "https://arxiv.org/abs/2505.11117", "authors": ["Chenhong Zhou", "Jie Chen", "Zaifeng Yang", "Ching Eng Png"], "title": "Dual-Balancing for Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "Accepted at IJCAI 2025 (34th International Joint Conference on\n  Artificial Intelligence)", "summary": "Physics-informed neural networks (PINNs) have emerged as a new learning\nparadigm for solving partial differential equations (PDEs) by enforcing the\nconstraints of physical equations, boundary conditions (BCs), and initial\nconditions (ICs) into the loss function. Despite their successes, vanilla PINNs\nstill suffer from poor accuracy and slow convergence due to the intractable\nmulti-objective optimization issue. In this paper, we propose a novel\nDual-Balanced PINN (DB-PINN), which dynamically adjusts loss weights by\nintegrating inter-balancing and intra-balancing to alleviate two imbalance\nissues in PINNs. Inter-balancing aims to mitigate the gradient imbalance\nbetween PDE residual loss and condition-fitting losses by determining an\naggregated weight that offsets their gradient distribution discrepancies.\nIntra-balancing acts on condition-fitting losses to tackle the imbalance in\nfitting difficulty across diverse conditions. By evaluating the fitting\ndifficulty based on the loss records, intra-balancing can allocate the\naggregated weight proportionally to each condition loss according to its\nfitting difficulty levels. We further introduce a robust weight update strategy\nto prevent abrupt spikes and arithmetic overflow in instantaneous weight values\ncaused by large loss variances, enabling smooth weight updating and stable\ntraining. Extensive experiments demonstrate that DB-PINN achieves significantly\nsuperior performance than those popular gradient-based weighting methods in\nterms of convergence speed and prediction accuracy. Our code and supplementary\nmaterial are available at https://github.com/chenhong-zhou/DualBalanced-PINNs.", "AI": {"tldr": "DB-PINN dynamically adjusts loss weights to address imbalance issues in PINNs, improving accuracy and convergence speed.", "motivation": "Vanilla PINNs suffer from poor accuracy and slow convergence due to multi-objective optimization challenges.", "method": "Proposes Dual-Balanced PINN (DB-PINN) with inter-balancing (gradient imbalance) and intra-balancing (fitting difficulty) for dynamic weight adjustment.", "result": "DB-PINN outperforms gradient-based weighting methods in convergence speed and prediction accuracy.", "conclusion": "DB-PINN effectively addresses imbalance issues in PINNs, enhancing performance and stability."}}
{"id": "2505.11344", "pdf": "https://arxiv.org/pdf/2505.11344", "abs": "https://arxiv.org/abs/2505.11344", "authors": ["Chenyu Huang", "Peng Ye", "Shenghe Zheng", "Xiaohui Wang", "Lei Bai", "Tao Chen", "Wanli Ouyang"], "title": "Dynamic Base model Shift for Delta Compression", "categories": ["cs.CV", "cs.LG"], "comment": "16 pages, 7 figures", "summary": "Transformer-based models with the pretrain-finetune paradigm bring about\nsignificant progress, along with the heavy storage and deployment costs of\nfinetuned models on multiple tasks. Delta compression attempts to lower the\ncosts by reducing the redundancy of delta parameters (i.e., the difference\nbetween the finetuned and pre-trained model weights) through pruning or\nquantization. However, existing methods by default employ the pretrained model\nas the base model and compress the delta parameters for every task, which may\ncauses significant performance degradation, especially when the compression\nrate is extremely high. To tackle this issue, we investigate the impact of\ndifferent base models on the performance of delta compression and find that the\npre-trained base model can hardly be optimal. To this end, we propose Dynamic\nBase Model Shift (DBMS), which dynamically adapts the base model to the target\ntask before performing delta compression. Specifically, we adjust two\nparameters, which respectively determine the magnitude of the base model shift\nand the overall scale of delta compression, to boost the compression\nperformance on each task. Through low-cost learning of these two parameters,\nour DBMS can maintain most of the finetuned model's performance even under an\nextremely high compression ratio setting, significantly surpassing existing\nmethods. Moreover, our DBMS is orthogonal and can be integrated with a variety\nof other methods, and it has been evaluated across different types of models\nincluding language, vision transformer, and multi-modal models.", "AI": {"tldr": "DBMS dynamically adapts the base model for delta compression, improving performance under high compression rates.", "motivation": "Existing delta compression methods degrade performance, especially at high compression rates, due to reliance on the pretrained base model.", "method": "Proposes Dynamic Base Model Shift (DBMS), adjusting base model shift magnitude and delta compression scale for each task.", "result": "DBMS maintains performance under high compression, outperforming existing methods, and works across various model types.", "conclusion": "DBMS is a versatile and effective solution for delta compression, enhancing efficiency without sacrificing performance."}}
{"id": "2505.11146", "pdf": "https://arxiv.org/pdf/2505.11146", "abs": "https://arxiv.org/abs/2505.11146", "authors": ["Peizhen Li", "Longbing Cao", "Xiao-Ming Wu", "Runze Yang", "Xiaohan Yu"], "title": "X2C: A Dataset Featuring Nuanced Facial Expressions for Realistic Humanoid Imitation", "categories": ["cs.RO", "cs.AI", "cs.HC"], "comment": null, "summary": "The ability to imitate realistic facial expressions is essential for humanoid\nrobots engaged in affective human-robot communication. However, the lack of\ndatasets containing diverse humanoid facial expressions with proper annotations\nhinders progress in realistic humanoid facial expression imitation. To address\nthese challenges, we introduce X2C (Anything to Control), a dataset featuring\nnuanced facial expressions for realistic humanoid imitation. With X2C, we\ncontribute: 1) a high-quality, high-diversity, large-scale dataset comprising\n100,000 (image, control value) pairs. Each image depicts a humanoid robot\ndisplaying a diverse range of facial expressions, annotated with 30 control\nvalues representing the ground-truth expression configuration; 2) X2CNet, a\nnovel human-to-humanoid facial expression imitation framework that learns the\ncorrespondence between nuanced humanoid expressions and their underlying\ncontrol values from X2C. It enables facial expression imitation in the wild for\ndifferent human performers, providing a baseline for the imitation task,\nshowcasing the potential value of our dataset; 3) real-world demonstrations on\na physical humanoid robot, highlighting its capability to advance realistic\nhumanoid facial expression imitation. Code and Data:\nhttps://lipzh5.github.io/X2CNet/", "AI": {"tldr": "X2C dataset and X2CNet framework address the lack of annotated humanoid facial expression data, enabling realistic imitation for humanoid robots.", "motivation": "The lack of diverse, annotated datasets for humanoid facial expressions hinders progress in affective human-robot communication.", "method": "Introduces X2C dataset (100,000 annotated images) and X2CNet, a framework for human-to-humanoid facial expression imitation.", "result": "Demonstrates realistic facial expression imitation in the wild and on a physical humanoid robot.", "conclusion": "X2C and X2CNet advance realistic humanoid facial expression imitation, providing a valuable baseline for future research."}}
{"id": "2405.00715", "pdf": "https://arxiv.org/pdf/2405.00715", "abs": "https://arxiv.org/abs/2405.00715", "authors": ["Hanyin Wang", "Chufan Gao", "Bolun Liu", "Qiping Xu", "Guleid Hussein", "Mohamad El Labban", "Kingsley Iheasirim", "Hariprasad Korsapati", "Chuck Outcalt", "Jimeng Sun"], "title": "Towards Adapting Open-Source Large Language Models for Expert-Level Clinical Note Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Proprietary Large Language Models (LLMs) such as GPT-4 and Gemini have\ndemonstrated promising capabilities in clinical text summarization tasks.\nHowever, due to patient data privacy concerns and computational costs, many\nhealthcare providers prefer using small, locally-hosted models over external\ngeneric LLMs. This study presents a comprehensive domain- and task-specific\nadaptation process for the open-source LLaMA-2 13 billion parameter model,\nenabling it to generate high-quality clinical notes from outpatient\npatient-doctor dialogues. Our process incorporates continued pre-training,\nsupervised fine-tuning, and reinforcement learning from both AI and human\nfeedback. We introduced a new approach, DistillDirect, for performing on-policy\nreinforcement learning with Gemini 1.0 Pro as the teacher model. Our resulting\nmodel, LLaMA-Clinic, can generate clinical notes comparable in quality to those\nauthored by physicians. In a blinded physician reader study, the majority\n(90.4%) of individual evaluations rated the notes generated by LLaMA-Clinic as\n\"acceptable\" or higher across all three criteria: real-world readiness,\ncompleteness, and accuracy. In the more challenging \"Assessment and Plan\"\nsection, LLaMA-Clinic scored higher (4.2/5) in real-world readiness than\nphysician-authored notes (4.1/5). We highlight key considerations for future\nclinical note-generation tasks, emphasizing the importance of pre-defining a\nbest-practice note format, rather than relying on LLMs to determine this for\nclinical practice.", "AI": {"tldr": "The study adapts the open-source LLaMA-2 13B model for clinical note generation, achieving physician-level quality with a new reinforcement learning method, DistillDirect, and outperforming physician notes in some aspects.", "motivation": "Healthcare providers prefer small, locally-hosted models over proprietary LLMs due to privacy and cost concerns, necessitating domain-specific adaptations.", "method": "Continued pre-training, supervised fine-tuning, and reinforcement learning (DistillDirect) with Gemini 1.0 Pro as the teacher model.", "result": "LLaMA-Clinic generated notes rated as 'acceptable' or higher by 90.4% of physicians, with higher real-world readiness scores in some sections.", "conclusion": "Pre-defining note formats is crucial for clinical note-generation tasks, and LLaMA-Clinic demonstrates the viability of open-source models in healthcare."}}
{"id": "2505.11125", "pdf": "https://arxiv.org/pdf/2505.11125", "abs": "https://arxiv.org/abs/2505.11125", "authors": ["Enjun Du", "Siyi Liu", "Yongqi Zhang"], "title": "GraphOracle: A Foundation Model for Knowledge Graph Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Foundation models have demonstrated remarkable capabilities across various\ndomains, but developing analogous models for knowledge graphs presents unique\nchallenges due to their dynamic nature and the need for cross-domain reasoning.\nTo address these issues, we introduce \\textbf{\\textsc{GraphOracle}}, a\nrelation-centric foundation model that unifies reasoning across knowledge\ngraphs by converting them into Relation-Dependency Graphs (RDG), explicitly\nencoding compositional patterns with fewer edges than prior methods. A\nquery-dependent attention mechanism is further developed to learn inductive\nrepresentations for both relations and entities. Pre-training on diverse\nknowledge graphs, followed by minutes-level fine-tuning, enables effective\ngeneralization to unseen entities, relations, and entire graphs. Through\ncomprehensive experiments on 31 diverse benchmarks spanning transductive,\ninductive, and cross-domain settings, we demonstrate consistent\nstate-of-the-art performance with minimal adaptation, improving the prediction\nperformance by up to 35\\% compared to the strongest baselines.", "AI": {"tldr": "GraphOracle is a relation-centric foundation model for knowledge graphs, improving prediction performance by up to 35% with minimal adaptation.", "motivation": "Addressing challenges in developing foundation models for knowledge graphs due to their dynamic nature and cross-domain reasoning needs.", "method": "Converts knowledge graphs into Relation-Dependency Graphs (RDG) with fewer edges, uses query-dependent attention for inductive representations, and pre-trains on diverse graphs.", "result": "Achieves state-of-the-art performance on 31 benchmarks, with up to 35% improvement over baselines.", "conclusion": "GraphOracle effectively generalizes to unseen entities, relations, and graphs, demonstrating strong adaptability."}}
{"id": "2505.11383", "pdf": "https://arxiv.org/pdf/2505.11383", "abs": "https://arxiv.org/abs/2505.11383", "authors": ["Zihan Wang", "Seungjun Lee", "Gim Hee Lee"], "title": "Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Vision-and-Language Navigation (VLN) is a core task where embodied agents\nleverage their spatial mobility to navigate in 3D environments toward\ndesignated destinations based on natural language instructions. Recently,\nvideo-language large models (Video-VLMs) with strong generalization\ncapabilities and rich commonsense knowledge have shown remarkable performance\nwhen applied to VLN tasks. However, these models still encounter the following\nchallenges when applied to real-world 3D navigation: 1) Insufficient\nunderstanding of 3D geometry and spatial semantics; 2) Limited capacity for\nlarge-scale exploration and long-term environmental memory; 3) Poor\nadaptability to dynamic and changing environments.To address these limitations,\nwe propose Dynam3D, a dynamic layered 3D representation model that leverages\nlanguage-aligned, generalizable, and hierarchical 3D representations as visual\ninput to train 3D-VLM in navigation action prediction. Given posed RGB-D\nimages, our Dynam3D projects 2D CLIP features into 3D space and constructs\nmulti-level 3D patch-instance-zone representations for 3D geometric and\nsemantic understanding with a dynamic and layer-wise update strategy. Our\nDynam3D is capable of online encoding and localization of 3D instances, and\ndynamically updates them in changing environments to provide large-scale\nexploration and long-term memory capabilities for navigation. By leveraging\nlarge-scale 3D-language pretraining and task-specific adaptation, our Dynam3D\nsets new state-of-the-art performance on VLN benchmarks including R2R-CE,\nREVERIE-CE and NavRAG-CE under monocular settings. Furthermore, experiments for\npre-exploration, lifelong memory, and real-world robot validate the\neffectiveness of practical deployment.", "AI": {"tldr": "Dynam3D improves VLN tasks by using dynamic layered 3D representations to address challenges like 3D understanding, large-scale exploration, and adaptability in changing environments.", "motivation": "Current Video-VLMs struggle with 3D geometry, large-scale navigation, and dynamic environments in VLN tasks.", "method": "Dynam3D projects 2D CLIP features into 3D space, creating hierarchical 3D representations with dynamic updates for better navigation.", "result": "Achieves state-of-the-art performance on VLN benchmarks (R2R-CE, REVERIE-CE, NavRAG-CE) and validates practical deployment in real-world robots.", "conclusion": "Dynam3D effectively addresses VLN challenges, enhancing 3D understanding and adaptability for embodied agents."}}
{"id": "2505.11157", "pdf": "https://arxiv.org/pdf/2505.11157", "abs": "https://arxiv.org/abs/2505.11157", "authors": ["Boris Bonev", "Max Rietmann", "Andrea Paris", "Alberto Carpentieri", "Thorsten Kurth"], "title": "Attention on the Sphere", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce a generalized attention mechanism for spherical domains,\nenabling Transformer architectures to natively process data defined on the\ntwo-dimensional sphere - a critical need in fields such as atmospheric physics,\ncosmology, and robotics, where preserving spherical symmetries and topology is\nessential for physical accuracy. By integrating numerical quadrature weights\ninto the attention mechanism, we obtain a geometrically faithful spherical\nattention that is approximately rotationally equivariant, providing strong\ninductive biases and leading to better performance than Cartesian approaches.\nTo further enhance both scalability and model performance, we propose\nneighborhood attention on the sphere, which confines interactions to geodesic\nneighborhoods. This approach reduces computational complexity and introduces\nthe additional inductive bias for locality, while retaining the symmetry\nproperties of our method. We provide optimized CUDA kernels and\nmemory-efficient implementations to ensure practical applicability. The method\nis validated on three diverse tasks: simulating shallow water equations on the\nrotating sphere, spherical image segmentation, and spherical depth estimation.\nAcross all tasks, our spherical Transformers consistently outperform their\nplanar counterparts, highlighting the advantage of geometric priors for\nlearning on spherical domains.", "AI": {"tldr": "A generalized attention mechanism for spherical domains is introduced, enabling Transformers to process spherical data with geometric faithfulness and rotational equivariance, outperforming Cartesian methods.", "motivation": "Addressing the need for preserving spherical symmetries and topology in fields like atmospheric physics, cosmology, and robotics for physical accuracy.", "method": "Integration of numerical quadrature weights into attention for rotational equivariance, and neighborhood attention to reduce complexity and enhance locality.", "result": "Outperforms planar counterparts in tasks like simulating shallow water equations, spherical image segmentation, and depth estimation.", "conclusion": "Spherical Transformers with geometric priors are superior for learning on spherical domains, validated by diverse tasks."}}
{"id": "2406.06326", "pdf": "https://arxiv.org/pdf/2406.06326", "abs": "https://arxiv.org/abs/2406.06326", "authors": ["Xiaoying Zhang", "Baolin Peng", "Ye Tian", "Jingyan Zhou", "Yipeng Zhang", "Haitao Mi", "Helen Meng"], "title": "Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Large language models (LLMs) often struggle to provide up-to-date information\ndue to their one-time training and the constantly evolving nature of the world.\nTo keep LLMs current, existing approaches typically involve continued\npre-training on new documents. However, they frequently face difficulties in\nextracting stored knowledge. Motivated by the remarkable success of the Feynman\nTechnique in efficient human learning, we introduce Self-Tuning, a learning\nframework aimed at improving an LLM's ability to effectively acquire new\nknowledge from unseen raw documents through self-teaching. Specifically, we\ndevelop a Self-Teaching strategy that augments the documents with a set of\nknowledge-intensive tasks created in a self-supervised manner, focusing on\nthree crucial aspects: memorization, comprehension, and self-reflection.\nAdditionally, we introduce three Wiki-Newpages-2023-QA datasets to facilitate\nan in-depth analysis of an LLM's knowledge acquisition ability concerning\nmemorization, extraction, and reasoning. Extensive experimental results on\nvarious models, e.g., Llama2-7B reveal that Self-Tuning consistently exhibits\nsuperior performance across all knowledge acquisition tasks and excels in\npreserving previous knowledge.", "AI": {"tldr": "Self-Tuning, a learning framework inspired by the Feynman Technique, enhances LLMs' ability to acquire new knowledge from raw documents through self-teaching, outperforming existing methods in knowledge acquisition and retention.", "motivation": "LLMs struggle with outdated information due to static training. Existing methods fail in knowledge extraction, prompting the need for a better approach.", "method": "Self-Tuning uses self-supervised tasks (memorization, comprehension, self-reflection) to augment documents and improve knowledge acquisition.", "result": "Experiments show Self-Tuning outperforms other methods in knowledge tasks and preserves prior knowledge effectively.", "conclusion": "Self-Tuning is a promising framework for keeping LLMs current and improving their knowledge acquisition capabilities."}}
{"id": "2505.11126", "pdf": "https://arxiv.org/pdf/2505.11126", "abs": "https://arxiv.org/abs/2505.11126", "authors": ["Shokichi Takakura", "Seng Pei Liew", "Satoshi Hasegawa"], "title": "FedDuA: Doubly Adaptive Federated Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Federated learning is a distributed learning framework where clients\ncollaboratively train a global model without sharing their raw data. FedAvg is\na popular algorithm for federated learning, but it often suffers from slow\nconvergence due to the heterogeneity of local datasets and anisotropy in the\nparameter space. In this work, we formalize the central server optimization\nprocedure through the lens of mirror descent and propose a novel framework,\ncalled FedDuA, which adaptively selects the global learning rate based on both\ninter-client and coordinate-wise heterogeneity in the local updates. We prove\nthat our proposed doubly adaptive step-size rule is minimax optimal and provide\na convergence analysis for convex objectives. Although the proposed method does\nnot require additional communication or computational cost on clients,\nextensive numerical experiments show that our proposed framework outperforms\nbaselines in various settings and is robust to the choice of hyperparameters.", "AI": {"tldr": "FedDuA improves FedAvg by adaptively selecting global learning rates to address heterogeneity, achieving faster convergence without extra costs.", "motivation": "FedAvg's slow convergence due to dataset heterogeneity and parameter space anisotropy.", "method": "Formalizes server optimization via mirror descent, introducing FedDuA with adaptive learning rates based on inter-client and coordinate-wise heterogeneity.", "result": "Proves minimax optimality of step-size rule; outperforms baselines in experiments, robust to hyperparameters.", "conclusion": "FedDuA enhances federated learning efficiency without additional client-side costs."}}
{"id": "2505.11386", "pdf": "https://arxiv.org/pdf/2505.11386", "abs": "https://arxiv.org/abs/2505.11386", "authors": ["Zifan Wang", "Jingwei Li", "Yitang Li", "Yunze Liu"], "title": "MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory", "categories": ["cs.CV"], "comment": null, "summary": "This paper introduces MutualNeRF, a framework enhancing Neural Radiance Field\n(NeRF) performance under limited samples using Mutual Information Theory. While\nNeRF excels in 3D scene synthesis, challenges arise with limited data and\nexisting methods that aim to introduce prior knowledge lack theoretical support\nin a unified framework. We introduce a simple but theoretically robust concept,\nMutual Information, as a metric to uniformly measure the correlation between\nimages, considering both macro (semantic) and micro (pixel) levels.\n  For sparse view sampling, we strategically select additional viewpoints\ncontaining more non-overlapping scene information by minimizing mutual\ninformation without knowing ground truth images beforehand. Our framework\nemploys a greedy algorithm, offering a near-optimal solution.\n  For few-shot view synthesis, we maximize the mutual information between\ninferred images and ground truth, expecting inferred images to gain more\nrelevant information from known images. This is achieved by incorporating\nefficient, plug-and-play regularization terms.\n  Experiments under limited samples show consistent improvement over\nstate-of-the-art baselines in different settings, affirming the efficacy of our\nframework.", "AI": {"tldr": "MutualNeRF enhances NeRF performance with limited samples using Mutual Information Theory, improving sparse view sampling and few-shot synthesis.", "motivation": "NeRF struggles with limited data and lacks theoretical support for prior knowledge integration. Mutual Information provides a unified metric for correlation.", "method": "Uses Mutual Information to select viewpoints (minimizing MI) and improve synthesis (maximizing MI) via a greedy algorithm and plug-and-play regularization.", "result": "Consistent improvements over state-of-the-art baselines in limited-sample settings.", "conclusion": "MutualNeRF effectively addresses NeRF's limitations with a theoretically robust and practical framework."}}
{"id": "2505.11175", "pdf": "https://arxiv.org/pdf/2505.11175", "abs": "https://arxiv.org/abs/2505.11175", "authors": ["Bo Yue", "Shuqi Guo", "Kaiyu Hu", "Chujiao Wang", "Benyou Wang", "Kui Jia", "Guiliang Liu"], "title": "Real-Time Verification of Embodied Reasoning for Generative Skill Acquisition", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Generative skill acquisition enables embodied agents to actively learn a\nscalable and evolving repertoire of control skills, crucial for the advancement\nof large decision models. While prior approaches often rely on supervision\nsignals from generalist agents (e.g., LLMs), their effectiveness in complex 3D\nenvironments remains unclear; exhaustive evaluation incurs substantial\ncomputational costs, significantly hindering the efficiency of skill learning.\nInspired by recent successes in verification models for mathematical reasoning,\nwe propose VERGSA (Verifying Embodied Reasoning in Generative Skill\nAcquisition), a framework that systematically integrates real-time verification\nprinciples into embodied skill learning. VERGSA establishes 1) a seamless\nextension from verification of mathematical reasoning into embodied learning by\ndynamically incorporating contextually relevant tasks into prompts and defining\nsuccess metrics for both subtasks and overall tasks, and 2) an automated,\nscalable reward labeling scheme that synthesizes dense reward signals by\niteratively finalizing the contribution of scene configuration and subtask\nlearning to overall skill acquisition. To the best of our knowledge, this\napproach constitutes the first comprehensive training dataset for\nverification-driven generative skill acquisition, eliminating arduous manual\nreward engineering. Experiments validate the efficacy of our approach: 1) the\nexemplar task pool improves the average task success rates by 21%, 2) our\nverification model boosts success rates by 24% for novel tasks and 36% for\nencountered tasks, and 3) outperforms LLM-as-a-Judge baselines in verification\nquality.", "AI": {"tldr": "VERGSA integrates real-time verification into embodied skill learning, improving task success rates and outperforming baselines.", "motivation": "Prior approaches rely on generalist agents like LLMs, which are inefficient in complex 3D environments. VERGSA addresses this by using verification principles.", "method": "VERGSA dynamically incorporates tasks into prompts, defines success metrics, and automates reward labeling for skill acquisition.", "result": "Task success rates improved by 21%, with verification boosting novel tasks by 24% and encountered tasks by 36%.", "conclusion": "VERGSA offers a scalable, efficient framework for generative skill acquisition, eliminating manual reward engineering."}}
{"id": "2408.06518", "pdf": "https://arxiv.org/pdf/2408.06518", "abs": "https://arxiv.org/abs/2408.06518", "authors": ["Hila Gonen", "Terra Blevins", "Alisa Liu", "Luke Zettlemoyer", "Noah A. Smith"], "title": "Does Liking Yellow Imply Driving a School Bus? Semantic Leakage in Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Despite their wide adoption, the biases and unintended behaviors of language\nmodels remain poorly understood. In this paper, we identify and characterize a\nphenomenon never discussed before, which we call semantic leakage, where models\nleak irrelevant information from the prompt into the generation in unexpected\nways. We propose an evaluation setting to detect semantic leakage both by\nhumans and automatically, curate a diverse test suite for diagnosing this\nbehavior, and measure significant semantic leakage in 13 flagship models. We\nalso show that models exhibit semantic leakage in languages besides English and\nacross different settings and generation scenarios. This discovery highlights\nyet another type of bias in language models that affects their generation\npatterns and behavior.", "AI": {"tldr": "The paper introduces 'semantic leakage,' a new phenomenon where language models leak irrelevant prompt information into outputs, and proposes methods to detect and measure it.", "motivation": "To uncover and understand biases and unintended behaviors in language models, focusing on the newly identified issue of semantic leakage.", "method": "Proposes an evaluation setting for detecting semantic leakage, curates a diverse test suite, and measures leakage in 13 flagship models.", "result": "Significant semantic leakage is found in all tested models, including non-English languages and various settings.", "conclusion": "Semantic leakage is a new type of bias affecting language model behavior, highlighting the need for further research and mitigation."}}
{"id": "2505.11128", "pdf": "https://arxiv.org/pdf/2505.11128", "abs": "https://arxiv.org/abs/2505.11128", "authors": ["Simone Azeglio", "Arianna Di Bernardo"], "title": "What's Inside Your Diffusion Model? A Score-Based Riemannian Metric to Explore the Data Manifold", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Recent advances in diffusion models have demonstrated their remarkable\nability to capture complex image distributions, but the geometric properties of\nthe learned data manifold remain poorly understood. We address this gap by\nintroducing a score-based Riemannian metric that leverages the Stein score\nfunction from diffusion models to characterize the intrinsic geometry of the\ndata manifold without requiring explicit parameterization. Our approach defines\na metric tensor in the ambient space that stretches distances perpendicular to\nthe manifold while preserving them along tangential directions, effectively\ncreating a geometry where geodesics naturally follow the manifold's contours.\nWe develop efficient algorithms for computing these geodesics and demonstrate\ntheir utility for both interpolation between data points and extrapolation\nbeyond the observed data distribution. Through experiments on synthetic data\nwith known geometry, Rotated MNIST, and complex natural images via Stable\nDiffusion, we show that our score-based geodesics capture meaningful\ntransformations that respect the underlying data distribution. Our method\nconsistently outperforms baseline approaches on perceptual metrics (LPIPS) and\ndistribution-level metrics (FID, KID), producing smoother, more realistic image\ntransitions. These results reveal the implicit geometric structure learned by\ndiffusion models and provide a principled way to navigate the manifold of\nnatural images through the lens of Riemannian geometry.", "AI": {"tldr": "The paper introduces a score-based Riemannian metric to analyze the geometry of data manifolds learned by diffusion models, improving interpolation and extrapolation tasks.", "motivation": "To understand the geometric properties of data manifolds in diffusion models, which remain poorly characterized despite their success in capturing complex image distributions.", "method": "Proposes a score-based Riemannian metric using the Stein score function to define a metric tensor, enabling geodesic computation for manifold navigation.", "result": "Outperforms baselines on perceptual and distribution-level metrics, showing smoother, more realistic image transitions.", "conclusion": "The method reveals implicit geometric structures in diffusion models and offers a principled way to navigate natural image manifolds using Riemannian geometry."}}
{"id": "2505.11404", "pdf": "https://arxiv.org/pdf/2505.11404", "abs": "https://arxiv.org/abs/2505.11404", "authors": ["Wenchuan Zhang", "Penghao Zhang", "Jingru Guo", "Tao Cheng", "Jie Chen", "Shuwan Zhang", "Zhang Zhang", "Yuhao Yi", "Hong Bu"], "title": "Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in vision language models (VLMs) have enabled broad progress\nin the general medical field. However, pathology still remains a more\nchallenging subdomain, with current pathology specific VLMs exhibiting\nlimitations in both diagnostic accuracy and reasoning plausibility. Such\nshortcomings are largely attributable to the nature of current pathology\ndatasets, which are primarily composed of image description pairs that lack the\ndepth and structured diagnostic paradigms employed by real world pathologists.\nIn this study, we leverage pathology textbooks and real world pathology experts\nto construct high-quality, reasoning-oriented datasets. Building on this, we\nintroduce Patho-R1, a multimodal RL-based pathology Reasoner, trained through a\nthree-stage pipeline: (1) continued pretraining on 3.5 million image-text pairs\nfor knowledge infusion; (2) supervised fine-tuning on 500k high-quality\nChain-of-Thought samples for reasoning incentivizing; (3) reinforcement\nlearning using Group Relative Policy Optimization and Decoupled Clip and\nDynamic sAmpling Policy Optimization strategies for multimodal reasoning\nquality refinement. To further assess the alignment quality of our dataset, we\npropose PathoCLIP, trained on the same figure-caption corpus used for continued\npretraining. Comprehensive experimental results demonstrate that both PathoCLIP\nand Patho-R1 achieve robust performance across a wide range of\npathology-related tasks, including zero-shot classification, cross-modal\nretrieval, Visual Question Answering, and Multiple Choice Question. Our project\nis available at the Patho-R1 repository:\nhttps://github.com/Wenchuan-Zhang/Patho-R1.", "AI": {"tldr": "The paper introduces Patho-R1, a multimodal RL-based pathology Reasoner, and PathoCLIP, trained on high-quality datasets derived from pathology textbooks and expert input to improve diagnostic accuracy and reasoning in pathology.", "motivation": "Current pathology-specific VLMs lack depth and structured diagnostic reasoning due to limited datasets. The study aims to address this by leveraging expert knowledge and textbooks to create better datasets.", "method": "A three-stage pipeline: (1) pretraining on 3.5M image-text pairs, (2) supervised fine-tuning on 500k Chain-of-Thought samples, (3) reinforcement learning for reasoning refinement. PathoCLIP is also introduced for alignment assessment.", "result": "Patho-R1 and PathoCLIP show robust performance in zero-shot classification, cross-modal retrieval, VQA, and MCQs.", "conclusion": "The approach significantly improves pathology-specific VLMs by enhancing reasoning and diagnostic accuracy through high-quality datasets and advanced training methods."}}
{"id": "2505.11176", "pdf": "https://arxiv.org/pdf/2505.11176", "abs": "https://arxiv.org/abs/2505.11176", "authors": ["Aaron Rodrigues", "Mahmood Hegazy", "Azzam Naeem"], "title": "From Intent Discovery to Recognition with Topic Modeling and Synthetic Data", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Understanding and recognizing customer intents in AI systems is crucial,\nparticularly in domains characterized by short utterances and the cold start\nproblem, where recommender systems must include new products or services\nwithout sufficient real user data. Customer utterances are characterized by\ninfrequent word co-occurences and high term variability, which poses\nsignificant challenges for traditional methods in specifying distinct user\nneeds and preparing synthetic queries. To address this, we propose an agentic\nLLM framework for topic modeling and synthetic query generation, which\naccelerates the discovery and recognition of customer intents. We first apply\nhierarchical topic modeling and intent discovery to expand a human-curated\ntaxonomy from 36 generic user intents to 278 granular intents, demonstrating\nthe potential of LLMs to significantly enhance topic specificity and diversity.\nNext, to support newly discovered intents and address the cold start problem,\nwe generate synthetic user query data, which augments real utterances and\nreduces dependency on human annotation, especially in low-resource settings.\nTopic model experiments show substantial improvements in coherence and\nrelevance after topic expansion, while synthetic data experiments indicate that\nin-class few-shot prompting significantly improves the quality and utility of\nsynthetic queries without compromising diversity. We also show that\nLLM-generated intent descriptions and keywords can effectively substitute for\nhuman-curated versions when used as context for synthetic query generation. Our\nresearch underscores the scalability and utility of LLM agents in topic\nmodeling and highlights the strategic use of synthetic utterances to enhance\ndataset variability and coverage for intent recognition. We present a\ncomprehensive and robust framework for online discovery and recognition of new\ncustomer intents in dynamic domains.", "AI": {"tldr": "The paper proposes an LLM framework for topic modeling and synthetic query generation to improve customer intent recognition in AI systems, addressing challenges like cold start and term variability.", "motivation": "The need to recognize customer intents in AI systems, especially in domains with short utterances and cold start problems, where traditional methods struggle due to infrequent word co-occurrences and high term variability.", "method": "An agentic LLM framework for hierarchical topic modeling, intent discovery, and synthetic query generation to expand a human-curated taxonomy and augment real user data.", "result": "Improved topic coherence and relevance, enhanced synthetic query quality, and reduced dependency on human annotation. LLM-generated intent descriptions proved effective substitutes for human-curated ones.", "conclusion": "The framework demonstrates scalability and utility in topic modeling, leveraging synthetic data to enhance intent recognition in dynamic domains."}}
{"id": "2409.09636", "pdf": "https://arxiv.org/pdf/2409.09636", "abs": "https://arxiv.org/abs/2409.09636", "authors": ["Junjie Dong", "Zhuoqi Lyu", "Qing Ke"], "title": "Towards understanding evolution of science through language model series", "categories": ["cs.CL", "cs.CY", "cs.DL"], "comment": null, "summary": "We introduce AnnualBERT, a series of language models designed specifically to\ncapture the temporal evolution of scientific text. Deviating from the\nprevailing paradigms of subword tokenizations and \"one model to rule them all\",\nAnnualBERT adopts whole words as tokens and is composed of a base RoBERTa model\npretrained from scratch on the full-text of 1.7 million arXiv papers published\nuntil 2008 and a collection of progressively trained models on arXiv papers at\nan annual basis. We demonstrate the effectiveness of AnnualBERT models by\nshowing that they not only have comparable performances in standard tasks but\nalso achieve state-of-the-art performances on domain-specific NLP tasks as well\nas link prediction tasks in the arXiv citation network. We then utilize probing\ntasks to quantify the models' behavior in terms of representation learning and\nforgetting as time progresses. Our approach enables the pretrained models to\nnot only improve performances on scientific text processing tasks but also to\nprovide insights into the development of scientific discourse over time. The\nseries of the models is available at https://huggingface.co/jd445/AnnualBERTs.", "AI": {"tldr": "AnnualBERT is a series of language models for scientific text evolution, using whole-word tokens and progressive annual training, achieving strong performance in domain-specific tasks and link prediction.", "motivation": "To capture the temporal evolution of scientific text and improve performance on scientific NLP tasks.", "method": "Uses whole-word tokens, a base RoBERTa model pretrained on arXiv papers until 2008, and progressively trained models annually.", "result": "Comparable performance in standard tasks, state-of-the-art in domain-specific tasks and link prediction, with insights into scientific discourse evolution.", "conclusion": "AnnualBERT improves scientific text processing and provides insights into temporal scientific discourse."}}
{"id": "2505.11132", "pdf": "https://arxiv.org/pdf/2505.11132", "abs": "https://arxiv.org/abs/2505.11132", "authors": ["Feng Xiao", "Xiaoying Tang", "Jicong Fan"], "title": "Fairness-aware Anomaly Detection via Fair Projection", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised anomaly detection is a critical task in many high-social-impact\napplications such as finance, healthcare, social media, and cybersecurity,\nwhere demographics involving age, gender, race, disease, etc, are used\nfrequently. In these scenarios, possible bias from anomaly detection systems\ncan lead to unfair treatment for different groups and even exacerbate social\nbias. In this work, first, we thoroughly analyze the feasibility and necessary\nassumptions for ensuring group fairness in unsupervised anomaly detection.\nSecond, we propose a novel fairness-aware anomaly detection method FairAD. From\nthe normal training data, FairAD learns a projection to map data of different\ndemographic groups to a common target distribution that is simple and compact,\nand hence provides a reliable base to estimate the density of the data. The\ndensity can be directly used to identify anomalies while the common target\ndistribution ensures fairness between different groups. Furthermore, we propose\na threshold-free fairness metric that provides a global view for model's\nfairness, eliminating dependence on manual threshold selection. Experiments on\nreal-world benchmarks demonstrate that our method achieves an improved\ntrade-off between detection accuracy and fairness under both balanced and\nskewed data across different groups.", "AI": {"tldr": "FairAD is a fairness-aware unsupervised anomaly detection method that ensures group fairness by mapping data to a common target distribution and introduces a threshold-free fairness metric.", "motivation": "Addressing potential bias in anomaly detection systems to prevent unfair treatment across demographic groups in high-impact applications like finance and healthcare.", "method": "FairAD learns a projection to map data of different groups to a common target distribution for reliable density estimation, ensuring fairness.", "result": "Achieves improved trade-off between detection accuracy and fairness on real-world benchmarks, even with skewed data.", "conclusion": "FairAD effectively balances fairness and accuracy in unsupervised anomaly detection, with a novel metric for fairness evaluation."}}
{"id": "2505.11424", "pdf": "https://arxiv.org/pdf/2505.11424", "abs": "https://arxiv.org/abs/2505.11424", "authors": ["Rana Poureskandar", "Shiva Razzagzadeh"], "title": "Improving Object Detection Performance through YOLOv8: A Comprehensive Training and Evaluation Study", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This study evaluated the performance of a YOLOv8-based segmentation model for\ndetecting and segmenting wrinkles in facial images.", "AI": {"tldr": "Evaluation of YOLOv8-based segmentation for wrinkle detection in facial images.", "motivation": "To assess the effectiveness of YOLOv8 in detecting and segmenting facial wrinkles.", "method": "Utilized a YOLOv8-based segmentation model for wrinkle detection in facial images.", "result": "Performance of the model was evaluated, though specific metrics are not detailed.", "conclusion": "The study demonstrates the potential of YOLOv8 for facial wrinkle segmentation."}}
{"id": "2505.11198", "pdf": "https://arxiv.org/pdf/2505.11198", "abs": "https://arxiv.org/abs/2505.11198", "authors": ["Jaime Ramirez Castillo", "M. Julia Flores", "Ann E. Nicholson"], "title": "User-centric Music Recommendations", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted for the 16th Bayesian Modelling Applications Workshop\n  (@UAI2022) (BMAW 2022)", "summary": "This work presents a user-centric recommendation framework, designed as a\npipeline with four distinct, connected, and customizable phases. These phases\nare intended to improve explainability and boost user engagement.\n  We have collected the historical Last.fm track playback records of a single\nuser over approximately 15 years. The collected dataset includes more than\n90,000 playbacks and approximately 14,000 unique tracks.\n  From track playback records, we have created a dataset of user temporal\ncontexts (each row is a specific moment when the user listened to certain music\ndescriptors). As music descriptors, we have used community-contributed Last.fm\ntags and Spotify audio features. They represent the music that, throughout\nyears, the user has been listening to.\n  Next, given the most relevant Last.fm tags of a moment (e.g. the hour of the\nday), we predict the Spotify audio features that best fit the user preferences\nin that particular moment. Finally, we use the predicted audio features to find\ntracks similar to these features. The final aim is to recommend (and discover)\ntracks that the user may feel like listening to at a particular moment.\n  For our initial study case, we have chosen to predict only a single audio\nfeature target: danceability. The framework, however, allows to include more\ntarget variables.\n  The ability to learn the musical habits from a single user can be quite\npowerful, and this framework could be extended to other users.", "AI": {"tldr": "A user-centric recommendation framework with four customizable phases improves explainability and engagement, using historical Last.fm playback data to predict and recommend tracks based on user preferences.", "motivation": "To enhance explainability and user engagement in music recommendations by leveraging long-term user playback data and contextual moments.", "method": "Collects 15 years of Last.fm playback data, creates temporal contexts with music descriptors (tags and audio features), predicts audio features (e.g., danceability) for specific moments, and recommends similar tracks.", "result": "Demonstrates the framework's capability to learn and predict user preferences for personalized recommendations, focusing initially on danceability.", "conclusion": "The framework is adaptable for individual users and scalable for broader application, offering powerful personalized recommendations."}}
{"id": "2409.20204", "pdf": "https://arxiv.org/pdf/2409.20204", "abs": "https://arxiv.org/abs/2409.20204", "authors": ["Aditi Dutta", "Susan Banducci", "Chico Q. Camargo"], "title": "Divided by discipline? A systematic literature review on the quantification of online sexism and misogyny using a semi-automated approach", "categories": ["cs.CL", "cs.CY"], "comment": null, "summary": "Several computational tools have been developed to detect and identify\nsexism, misogyny, and gender-based hate speech, particularly on online\nplatforms. These tools draw on insights from both social science and computer\nscience. Given the increasing concern over gender-based discrimination in\ndigital spaces, the contested definitions and measurements of sexism, and the\nrise of interdisciplinary efforts to understand its online manifestations, a\nsystematic literature review is essential for capturing the current state and\ntrajectory of this evolving field. In this review, we make four key\ncontributions: (1) we synthesize the literature into five core themes:\ndefinitions of sexism and misogyny, disciplinary divergences, automated\ndetection methods, associated challenges, and design-based interventions; (2)\nwe adopt an interdisciplinary lens, bridging theoretical and methodological\ndivides across disciplines; (3) we highlight critical gaps, including the need\nfor intersectional approaches, the under-representation of non-Western\nlanguages and perspectives, and the limited focus on proactive design\nstrategies beyond text classification; and (4) we offer a methodological\ncontribution by applying a rigorous semi-automated systematic review process\nguided by PRISMA, establishing a replicable standard for future work in this\ndomain. Our findings reveal a clear disciplinary divide in how sexism and\nmisogyny are conceptualized and measured. Through an evidence-based synthesis,\nwe examine how existing studies have attempted to bridge this gap through\ninterdisciplinary collaboration. Drawing on both social science theories and\ncomputational modeling practices, we assess the strengths and limitations of\ncurrent methodologies. Finally, we outline key challenges and future directions\nfor advancing research on the detection and mitigation of online sexism and\nmisogyny.", "AI": {"tldr": "A systematic literature review synthesizes interdisciplinary research on detecting and addressing online sexism and misogyny, highlighting gaps and proposing future directions.", "motivation": "Addressing the growing concern over gender-based discrimination online, contested definitions of sexism, and the need for interdisciplinary collaboration.", "method": "Rigorous semi-automated systematic review process guided by PRISMA, synthesizing literature into five themes.", "result": "Reveals disciplinary divides in conceptualizing sexism, gaps in intersectional and non-Western perspectives, and limited proactive design strategies.", "conclusion": "Calls for interdisciplinary collaboration, intersectional approaches, and methodological rigor to advance research on online sexism and misogyny."}}
{"id": "2505.11134", "pdf": "https://arxiv.org/pdf/2505.11134", "abs": "https://arxiv.org/abs/2505.11134", "authors": ["Desong Zhang", "Jia Hu", "Geyong Min"], "title": "Towards Robust Spiking Neural Networks:Mitigating Heterogeneous Training Vulnerability via Dominant Eigencomponent Projection", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Spiking Neural Networks (SNNs) process information via discrete spikes,\nenabling them to operate at remarkably low energy levels. However, our\nexperimental observations reveal a striking vulnerability when SNNs are trained\nusing the mainstream method--direct encoding combined with backpropagation\nthrough time (BPTT): even a single backward pass on data drawn from a slightly\ndifferent distribution can lead to catastrophic network collapse. Our\ntheoretical analysis attributes this vulnerability to the repeated inputs\ninherent in direct encoding and the gradient accumulation characteristic of\nBPTT, which together produce an exceptional large Hessian spectral radius. To\naddress this challenge, we develop a hyperparameter-free method called Dominant\nEigencomponent Projection (DEP). By orthogonally projecting gradients to\nprecisely remove their dominant components, DEP effectively reduces the Hessian\nspectral radius, thereby preventing SNNs from settling into sharp minima.\nExtensive experiments demonstrate that DEP not only mitigates the vulnerability\nof SNNs to heterogeneous data poisoning, but also significantly enhances\noverall robustness compared to key baselines, providing strong support for\nsafer and more reliable SNN deployment.", "AI": {"tldr": "SNNs trained with direct encoding and BPTT are vulnerable to catastrophic collapse from slight data distribution shifts. DEP, a hyperparameter-free method, mitigates this by reducing Hessian spectral radius, enhancing robustness.", "motivation": "SNNs' energy efficiency is compromised by vulnerability to heterogeneous data poisoning when trained with direct encoding and BPTT.", "method": "Developed Dominant Eigencomponent Projection (DEP) to orthogonally project gradients, reducing Hessian spectral radius and preventing sharp minima.", "result": "DEP mitigates vulnerability and significantly enhances SNN robustness against heterogeneous data poisoning.", "conclusion": "DEP supports safer and more reliable SNN deployment by addressing training vulnerabilities."}}
{"id": "2505.11439", "pdf": "https://arxiv.org/pdf/2505.11439", "abs": "https://arxiv.org/abs/2505.11439", "authors": ["Utsav Rai", "Haozheng Xu", "Stamatia Giannarou"], "title": "SurgPose: Generalisable Surgical Instrument Pose Estimation using Zero-Shot Learning and Stereo Vision", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "To be published in 2025 International Conference on Robotics and\n  Automation (ICRA)", "summary": "Accurate pose estimation of surgical tools in Robot-assisted Minimally\nInvasive Surgery (RMIS) is essential for surgical navigation and robot control.\nWhile traditional marker-based methods offer accuracy, they face challenges\nwith occlusions, reflections, and tool-specific designs. Similarly, supervised\nlearning methods require extensive training on annotated datasets, limiting\ntheir adaptability to new tools. Despite their success in other domains,\nzero-shot pose estimation models remain unexplored in RMIS for pose estimation\nof surgical instruments, creating a gap in generalising to unseen surgical\ntools. This paper presents a novel 6 Degrees of Freedom (DoF) pose estimation\npipeline for surgical instruments, leveraging state-of-the-art zero-shot RGB-D\nmodels like the FoundationPose and SAM-6D. We advanced these models by\nincorporating vision-based depth estimation using the RAFT-Stereo method, for\nrobust depth estimation in reflective and textureless environments.\nAdditionally, we enhanced SAM-6D by replacing its instance segmentation module,\nSegment Anything Model (SAM), with a fine-tuned Mask R-CNN, significantly\nboosting segmentation accuracy in occluded and complex conditions. Extensive\nvalidation reveals that our enhanced SAM-6D surpasses FoundationPose in\nzero-shot pose estimation of unseen surgical instruments, setting a new\nbenchmark for zero-shot RGB-D pose estimation in RMIS. This work enhances the\ngeneralisability of pose estimation for unseen objects and pioneers the\napplication of RGB-D zero-shot methods in RMIS.", "AI": {"tldr": "A novel 6-DoF pose estimation pipeline for surgical tools in RMIS using zero-shot RGB-D models, enhanced with depth estimation and improved segmentation, outperforming existing methods.", "motivation": "Traditional marker-based and supervised learning methods for pose estimation in RMIS face limitations like occlusions, reflections, and lack of adaptability to new tools. Zero-shot methods, though successful elsewhere, remain unexplored in RMIS.", "method": "Leverages zero-shot RGB-D models (FoundationPose, SAM-6D) with vision-based depth estimation (RAFT-Stereo) and replaces SAM with fine-tuned Mask R-CNN for better segmentation in occluded/textureless environments.", "result": "Enhanced SAM-6D outperforms FoundationPose in zero-shot pose estimation of unseen surgical tools, setting a new benchmark for RMIS.", "conclusion": "The work improves generalizability of pose estimation for unseen tools and pioneers zero-shot RGB-D methods in RMIS."}}
{"id": "2505.11204", "pdf": "https://arxiv.org/pdf/2505.11204", "abs": "https://arxiv.org/abs/2505.11204", "authors": ["Hangyu Zhou", "Aaron Gokaslan", "Volodymyr Kuleshov", "Bharath Hariharan"], "title": "RanDeS: Randomized Delta Superposition for Multi-Model Compression", "categories": ["cs.LG", "cs.AI"], "comment": "https://github.com/Zhou-Hangyu/randes", "summary": "From a multi-model compression perspective, model merging enables\nmemory-efficient serving of multiple models fine-tuned from the same base, but\nsuffers from degraded performance due to interference among their task-specific\nparameter adjustments (i.e., deltas). In this paper, we reformulate model\nmerging as a compress-and-retrieve scheme, revealing that the task interference\narises from the summation of irrelevant deltas during model retrieval. To\naddress this issue, we use random orthogonal transformations to decorrelate\nthese vectors into self-cancellation. We show that this approach drastically\nreduces interference, improving performance across both vision and language\ntasks. Since these transformations are fully defined by random seeds, adding\nnew models requires no extra memory. Further, their data- and model-agnostic\nnature enables easy addition or removal of models with minimal compute\noverhead, supporting efficient and flexible multi-model serving.", "AI": {"tldr": "The paper proposes a method to reduce interference in model merging by using random orthogonal transformations, improving performance without extra memory.", "motivation": "Model merging suffers from degraded performance due to interference among task-specific parameter adjustments (deltas).", "method": "Reformulate model merging as a compress-and-retrieve scheme, using random orthogonal transformations to decorrelate deltas.", "result": "Drastically reduces interference, improving performance in vision and language tasks with no extra memory for new models.", "conclusion": "The approach enables efficient, flexible multi-model serving with minimal compute overhead."}}
{"id": "2410.16392", "pdf": "https://arxiv.org/pdf/2410.16392", "abs": "https://arxiv.org/abs/2410.16392", "authors": ["Matthieu Lin", "Jenny Sheng", "Andrew Zhao", "Shenzhi Wang", "Yang Yue", "Victor Shea Jay Huang", "Huan Liu", "Jun Liu", "Gao Huang", "Yong-Jin Liu"], "title": "Training of Scaffolded Language Models with Language Supervision: A Survey", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This survey organizes the intricate literature on the design and optimization\nof emerging structures around post-trained LMs. We refer to this overarching\nstructure as scaffolded LMs and focus on LMs that are integrated into\nmulti-step processes with tools. We view scaffolded LMs as semi-parametric\nmodels wherein we train non-parametric variables, including the prompt, tools,\nand scaffold's code. In particular, they interpret instructions, use tools, and\nreceive feedback all in language. Recent works use an LM as an optimizer to\ninterpret language supervision and update non-parametric variables according to\nintricate objectives. In this survey, we refer to this paradigm as training of\nscaffolded LMs with language supervision. A key feature of non-parametric\ntraining is the ability to learn from language. Parametric training excels in\nlearning from demonstration (supervised learning), exploration (reinforcement\nlearning), or observations (unsupervised learning), using well-defined loss\nfunctions. Language-based optimization enables rich, interpretable, and\nexpressive objectives, while mitigating issues like catastrophic forgetting and\nsupporting compatibility with closed-source models. Furthermore, agents are\nincreasingly deployed as co-workers in real-world applications such as Copilot\nin Office tools or software development. In these mixed-autonomy settings,\nwhere control and decision-making are shared between human and AI, users point\nout errors or suggest corrections. Accordingly, we discuss agents that\ncontinuously improve by learning from this real-time, language-based feedback\nand refer to this setting as streaming learning from language supervision.", "AI": {"tldr": "The paper surveys scaffolded LMs, focusing on their design, optimization, and integration with tools, highlighting language supervision and real-time feedback for continuous improvement.", "motivation": "To organize and analyze the literature on scaffolded LMs, emphasizing their semi-parametric nature and the role of language supervision in training and optimization.", "method": "The survey examines scaffolded LMs as semi-parametric models, training non-parametric variables (prompts, tools, code) using language supervision and real-time feedback.", "result": "Language-based optimization offers rich, interpretable objectives, mitigates issues like catastrophic forgetting, and supports closed-source models. Real-world applications include AI co-workers like Copilot.", "conclusion": "Scaffolded LMs, trained with language supervision and real-time feedback, represent a promising paradigm for AI integration in mixed-autonomy settings."}}
{"id": "2505.11139", "pdf": "https://arxiv.org/pdf/2505.11139", "abs": "https://arxiv.org/abs/2505.11139", "authors": ["Om Roy", "Yashar Moshfeghi", "Keith Smith"], "title": "Covariance Density Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Graph neural networks have re-defined how we model and predict on network\ndata but there lacks a consensus on choosing the correct underlying graph\nstructure on which to model signals. CoVariance Neural Networks (VNN) address\nthis issue by using the sample covariance matrix as a Graph Shift Operator\n(GSO). Here, we improve on the performance of VNNs by constructing a Density\nMatrix where we consider the sample Covariance matrix as a quasi-Hamiltonian of\nthe system in the space of random variables. Crucially, using this density\nmatrix as the GSO allows components of the data to be extracted at different\nscales, allowing enhanced discriminability and performance. We show that this\napproach allows explicit control of the stability-discriminability trade-off of\nthe network, provides enhanced robustness to noise compared to VNNs, and\noutperforms them in useful real-life applications where the underlying\ncovariance matrix is informative. In particular, we show that our model can\nachieve strong performance in subject-independent Brain Computer Interface EEG\nmotor imagery classification, outperforming EEGnet while being faster. This\nshows how covariance density neural networks provide a basis for the\nnotoriously difficult task of transferability of BCIs when evaluated on unseen\nindividuals.", "AI": {"tldr": "The paper introduces Density Matrix-based Graph Neural Networks to improve performance over Covariance Neural Networks (VNNs) by using a quasi-Hamiltonian approach, enhancing discriminability and robustness, particularly in Brain-Computer Interface EEG classification.", "motivation": "Addressing the lack of consensus in choosing graph structures for modeling network data, the paper aims to improve VNNs by leveraging a density matrix for better performance and stability.", "method": "Constructs a density matrix from the sample covariance matrix, treating it as a quasi-Hamiltonian, and uses it as a Graph Shift Operator (GSO) to extract data components at different scales.", "result": "The approach outperforms VNNs and EEGnet in EEG motor imagery classification, offering better robustness, discriminability, and transferability in Brain-Computer Interfaces.", "conclusion": "Density Matrix-based GNNs provide a robust framework for transferable Brain-Computer Interface applications, addressing stability-discriminability trade-offs effectively."}}
{"id": "2505.11454", "pdf": "https://arxiv.org/pdf/2505.11454", "abs": "https://arxiv.org/abs/2505.11454", "authors": ["Shaina Raza", "Aravind Narayanan", "Vahid Reza Khazaie", "Ashmal Vayani", "Mukund S. Chettiar", "Amandeep Singh", "Mubarak Shah", "Deval Pandya"], "title": "HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large multimodal models (LMMs) now excel on many vision language benchmarks,\nhowever, they still struggle with human centered criteria such as fairness,\nethics, empathy, and inclusivity, key to aligning with human values. We\nintroduce HumaniBench, a holistic benchmark of 32K real-world image question\npairs, annotated via a scalable GPT4o assisted pipeline and exhaustively\nverified by domain experts. HumaniBench evaluates seven Human Centered AI\n(HCAI) principles: fairness, ethics, understanding, reasoning, language\ninclusivity, empathy, and robustness, across seven diverse tasks, including\nopen and closed ended visual question answering (VQA), multilingual QA, visual\ngrounding, empathetic captioning, and robustness tests. Benchmarking 15 state\nof the art LMMs (open and closed source) reveals that proprietary models\ngenerally lead, though robustness and visual grounding remain weak points. Some\nopen-source models also struggle to balance accuracy with adherence to\nhuman-aligned principles. HumaniBench is the first benchmark purpose built\naround HCAI principles. It provides a rigorous testbed for diagnosing alignment\ngaps and guiding LMMs toward behavior that is both accurate and socially\nresponsible. Dataset, annotation prompts, and evaluation code are available at:\nhttps://vectorinstitute.github.io/HumaniBench", "AI": {"tldr": "HumaniBench is a new benchmark evaluating Large Multimodal Models (LMMs) on human-centered AI principles like fairness, ethics, and inclusivity. It includes 32K image-question pairs and tests 15 LMMs, revealing gaps in robustness and alignment with human values.", "motivation": "Current LMMs perform well on standard benchmarks but lack alignment with human-centered criteria like fairness and empathy. HumaniBench addresses this gap.", "method": "HumaniBench uses 32K image-question pairs annotated via a GPT4-assisted pipeline and expert verification. It evaluates seven HCAI principles across seven diverse tasks.", "result": "Proprietary models generally outperform open-source ones, but robustness and visual grounding remain weak. Some models struggle to balance accuracy with human-aligned principles.", "conclusion": "HumaniBench is the first benchmark focused on HCAI principles, providing a testbed to improve LMMs' alignment with human values. Data and tools are publicly available."}}
{"id": "2505.11211", "pdf": "https://arxiv.org/pdf/2505.11211", "abs": "https://arxiv.org/abs/2505.11211", "authors": ["Francisco Madaleno", "Pernille Julie Viuff Sand", "Francisco C. Pereira", "Sergio Hernan Garrido Mejia"], "title": "Bayesian Hierarchical Invariant Prediction", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "We propose Bayesian Hierarchical Invariant Prediction (BHIP) reframing\nInvariant Causal Prediction (ICP) through the lens of Hierarchical Bayes. We\nleverage the hierarchical structure to explicitly test invariance of causal\nmechanisms under heterogeneous data, resulting in improved computational\nscalability for a larger number of predictors compared to ICP. Moreover, given\nits Bayesian nature BHIP enables the use of prior information. In this paper,\nwe test two sparsity inducing priors: horseshoe and spike-and-slab, both of\nwhich allow us a more reliable identification of causal features. We test BHIP\nin synthetic and real-world data showing its potential as an alternative\ninference method to ICP.", "AI": {"tldr": "BHIP reframes ICP using Hierarchical Bayes for better scalability and prior integration, testing sparsity-inducing priors for reliable causal feature identification.", "motivation": "To improve computational scalability and leverage prior information in causal prediction under heterogeneous data.", "method": "Bayesian Hierarchical Invariant Prediction (BHIP) with horseshoe and spike-and-slab priors for sparsity.", "result": "Improved scalability and reliable causal feature identification in synthetic and real-world data.", "conclusion": "BHIP is a viable alternative to ICP, offering enhanced performance and flexibility."}}
{"id": "2410.19453", "pdf": "https://arxiv.org/pdf/2410.19453", "abs": "https://arxiv.org/abs/2410.19453", "authors": ["Hengyuan Zhang", "Chenming Shang", "Sizhe Wang", "Dongdong Zhang", "Feng Yao", "Renliang Sun", "Yiyao Yu", "Yujiu Yang", "Furu Wei"], "title": "ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework", "categories": ["cs.CL"], "comment": "23 pages, 11 figures", "summary": "Although fine-tuning Large Language Models (LLMs) with multilingual data can\nrapidly enhance the multilingual capabilities of LLMs, they still exhibit a\nperformance gap between the dominant language (e.g., English) and non-dominant\nones due to the imbalance of training data across languages. To further enhance\nthe performance of non-dominant languages, we propose ShifCon, a Shift-based\nContrastive framework that aligns the internal forward process of other\nlanguages toward that of the dominant one. Specifically, it shifts the\nrepresentations of non-dominant languages into the dominant language subspace,\nallowing them to access relatively rich information encoded in the model\nparameters. The enriched representations are then shifted back into their\noriginal language subspace before generation. Moreover, we introduce a subspace\ndistance metric to pinpoint the optimal layer area for shifting representations\nand employ multilingual contrastive learning to further enhance the alignment\nof representations within this area. Experiments demonstrate that our ShifCon\nframework significantly enhances the performance of non-dominant languages,\nparticularly for low-resource ones. Further analysis offers extra insights to\nverify the effectiveness of ShifCon and propel future research", "AI": {"tldr": "ShifCon, a Shift-based Contrastive framework, improves non-dominant language performance in LLMs by aligning representations with the dominant language subspace and using contrastive learning.", "motivation": "Address the performance gap between dominant (e.g., English) and non-dominant languages in LLMs due to imbalanced training data.", "method": "Shift representations of non-dominant languages into the dominant language subspace, enrich them, and shift back before generation. Uses subspace distance and contrastive learning.", "result": "Significant performance improvement for non-dominant languages, especially low-resource ones.", "conclusion": "ShifCon effectively enhances multilingual LLM performance and provides insights for future research."}}
{"id": "2505.11153", "pdf": "https://arxiv.org/pdf/2505.11153", "abs": "https://arxiv.org/abs/2505.11153", "authors": ["Ashok Arora", "Neetesh Kumar"], "title": "Bi-directional Recurrence Improves Transformer in Partially Observable Markov Decision Processes", "categories": ["cs.LG"], "comment": null, "summary": "In real-world reinforcement learning (RL) scenarios, agents often encounter\npartial observability, where incomplete or noisy information obscures the true\nstate of the environment. Partially Observable Markov Decision Processes\n(POMDPs) are commonly used to model these environments, but effective\nperformance requires memory mechanisms to utilise past observations. While\nrecurrence networks have traditionally addressed this need, transformer-based\nmodels have recently shown improved sample efficiency in RL tasks. However,\ntheir application to POMDPs remains underdeveloped, and their real-world\ndeployment is constrained due to the high parameter count. This work introduces\na novel bi-recurrent model architecture that improves sample efficiency and\nreduces model parameter count in POMDP scenarios. The architecture replaces the\nmultiple feed forward layers with a single layer of bi-directional recurrence\nunit to better capture and utilize sequential dependencies and contextual\ninformation. This approach improves the model's ability to handle partial\nobservability and increases sample efficiency, enabling effective learning from\ncomparatively fewer interactions. To evaluate the performance of the proposed\nmodel architecture, experiments were conducted on a total of 23 POMDP\nenvironments. The proposed model architecture outperforms existing\ntransformer-based, attention-based, and recurrence-based methods by a margin\nranging from 87.39% to 482.04% on average across the 23 POMDP environments.", "AI": {"tldr": "A bi-recurrent model improves sample efficiency and reduces parameters in POMDPs, outperforming existing methods by 87.39% to 482.04%.", "motivation": "Addressing the limitations of transformer-based models in POMDPs, such as high parameter counts and underdeveloped applications, to enhance sample efficiency.", "method": "Introduces a bi-recurrent architecture replacing multiple feed-forward layers with a single bi-directional recurrence unit to better utilize sequential dependencies.", "result": "Outperforms transformer-based, attention-based, and recurrence-based methods by 87.39% to 482.04% across 23 POMDP environments.", "conclusion": "The bi-recurrent model effectively handles partial observability, improves sample efficiency, and reduces parameter count, making it suitable for real-world RL applications."}}
{"id": "2505.11468", "pdf": "https://arxiv.org/pdf/2505.11468", "abs": "https://arxiv.org/abs/2505.11468", "authors": ["Dingbang Huang", "Wenbo Li", "Yifei Zhao", "Xinyu Pan", "Yanhong Zeng", "Bo Dai"], "title": "PSDiffusion: Harmonized Multi-Layer Image Generation via Layout and Appearance Alignment", "categories": ["cs.CV"], "comment": "Project Page: https://github.com/dingbang777/PSDiffusion/", "summary": "Diffusion models have made remarkable advancements in generating high-quality\nimages from textual descriptions. Recent works like LayerDiffuse have extended\nthe previous single-layer, unified image generation paradigm to transparent\nimage layer generation. However, existing multi-layer generation methods fail\nto handle the interactions among multiple layers such as rational global\nlayout, physics-plausible contacts and visual effects like shadows and\nreflections while maintaining high alpha quality. To solve this problem, we\npropose PSDiffusion, a unified diffusion framework for simultaneous multi-layer\ntext-to-image generation. Our model can automatically generate multi-layer\nimages with one RGB background and multiple RGBA foregrounds through a single\nfeed-forward process. Unlike existing methods that combine multiple tools for\npost-decomposition or generate layers sequentially and separately, our method\nintroduces a global-layer interactive mechanism that generates layered-images\nconcurrently and collaboratively, ensuring not only high quality and\ncompleteness for each layer, but also spatial and visual interactions among\nlayers for global coherence.", "AI": {"tldr": "PSDiffusion is a unified diffusion framework for simultaneous multi-layer text-to-image generation, addressing interactions among layers while maintaining quality.", "motivation": "Existing multi-layer generation methods lack handling of layer interactions like global layout, physics-plausible contacts, and visual effects.", "method": "PSDiffusion introduces a global-layer interactive mechanism for concurrent and collaborative generation of layered images in a single feed-forward process.", "result": "The model generates multi-layer images (RGB background and RGBA foregrounds) with high quality, completeness, and global coherence.", "conclusion": "PSDiffusion outperforms existing methods by ensuring spatial and visual interactions among layers without post-decomposition or sequential generation."}}
{"id": "2505.11243", "pdf": "https://arxiv.org/pdf/2505.11243", "abs": "https://arxiv.org/abs/2505.11243", "authors": ["Elliot L. Epstein", "Apaar Sadhwani", "Kay Giesecke"], "title": "A Set-Sequence Model for Time Series", "categories": ["cs.LG", "cs.AI", "q-fin.CP", "I.2.6"], "comment": "Presented at the Workshop on Financial AI at ICLR 2025", "summary": "In many financial prediction problems, the behavior of individual units (such\nas loans, bonds, or stocks) is influenced by observable unit-level factors and\nmacroeconomic variables, as well as by latent cross-sectional effects.\nTraditional approaches attempt to capture these latent effects via handcrafted\nsummary features. We propose a Set-Sequence model that eliminates the need for\nhandcrafted features. The Set model first learns a shared cross-sectional\nsummary at each period. The Sequence model then ingests the summary-augmented\ntime series for each unit independently to predict its outcome. Both components\nare learned jointly over arbitrary sets sampled during training. Our approach\nharnesses the set nature of the cross-section and is computationally efficient,\ngenerating set summaries in linear time relative to the number of units. It is\nalso flexible, allowing the use of existing sequence models and accommodating a\nvariable number of units at inference. Empirical evaluations demonstrate that\nour Set-Sequence model significantly outperforms benchmarks on stock return\nprediction and mortgage behavior tasks. Code will be released.", "AI": {"tldr": "The paper introduces a Set-Sequence model for financial prediction, eliminating handcrafted features by learning cross-sectional summaries and using sequence models for unit-level predictions. It outperforms benchmarks in stock return and mortgage behavior tasks.", "motivation": "Traditional methods rely on handcrafted features to capture latent cross-sectional effects in financial prediction, which is inefficient and inflexible.", "method": "A Set-Sequence model: Set model learns shared cross-sectional summaries, and Sequence model uses these summaries for unit-level predictions. Both are trained jointly.", "result": "Outperforms benchmarks in stock return prediction and mortgage behavior tasks, with linear-time efficiency.", "conclusion": "The Set-Sequence model is efficient, flexible, and superior to traditional methods, with potential for broader applications."}}
{"id": "2411.05527", "pdf": "https://arxiv.org/pdf/2411.05527", "abs": "https://arxiv.org/abs/2411.05527", "authors": ["Kushal Tatariya", "Artur Kulmizev", "Wessel Poelman", "Esther Ploeger", "Marcel Bollmann", "Johannes Bjerva", "Jiaming Luo", "Heather Lent", "Miryam de Lhoneux"], "title": "How Good is Your Wikipedia? Auditing Data Quality for Low-resource and Multilingual NLP", "categories": ["cs.CL"], "comment": null, "summary": "Wikipedia's perceived high quality and broad language coverage have\nestablished it as a fundamental resource in multilingual NLP. In the context of\nlow-resource languages, however, these quality assumptions are increasingly\nbeing scrutinised. This paper critically examines the data quality of Wikipedia\nin a non-English setting by subjecting it to various quality filtering\ntechniques, revealing widespread issues such as a high percentage of one-line\narticles and duplicate articles. We evaluate the downstream impact of quality\nfiltering on Wikipedia and find that data quality pruning is an effective means\nfor resource-efficient training without hurting performance, especially for\nlow-resource languages. Moreover, we advocate for a shift in perspective from\nseeking a general definition of data quality towards a more language- and\ntask-specific one. Ultimately, we aim for this study to serve as a guide to\nusing Wikipedia for pretraining in a multilingual setting.", "AI": {"tldr": "The paper examines Wikipedia's data quality in non-English settings, revealing issues like one-line and duplicate articles. Quality filtering improves resource efficiency without harming performance, especially for low-resource languages.", "motivation": "To scrutinize Wikipedia's assumed high quality in low-resource languages and assess the impact of quality filtering on multilingual NLP tasks.", "method": "Subjecting Wikipedia to various quality filtering techniques and evaluating the downstream impact on performance.", "result": "Quality filtering is effective for resource-efficient training without performance loss, particularly in low-resource languages.", "conclusion": "Advocates for language- and task-specific data quality definitions and aims to guide Wikipedia's use in multilingual pretraining."}}
{"id": "2505.11170", "pdf": "https://arxiv.org/pdf/2505.11170", "abs": "https://arxiv.org/abs/2505.11170", "authors": ["Myeonghwan Ahn", "Sungjoo Yoo"], "title": "Gaussian Weight Sampling for Scalable, Efficient and Stable Pseudo-Quantization Training", "categories": ["cs.LG"], "comment": null, "summary": "Ever-growing scale of large language models (LLMs) is pushing for improved\nefficiency, favoring fully quantized training (FQT) over BF16. While FQT\naccelerates training, it faces consistency challenges and requires searching\nover an exponential number of cases, each needing over 200B tokens to ensure\nstability.\n  Pseudo-quantization training (PQT) addresses the issues of FQT, although it\nis not well-studied. We explore the practical implications of PQT in detail and\npropose a noise distribution $R$ that is floating-point (FP)-friendly, with\nideal properties including stochastic precision annealing. As a result, the\nproposed method serves as an effective theoretical foundation for low-precision\nFP parameters through PQT, utilizing efficient fake quantization via an\naddition and subsequent FP casting.\n  We demonstrate that Gaussian weight sampling is (1) scalable: supports\nlow-precision FP parameters down to FP6 and high-precision noise up to 9-bit\nwith BF16 operator. The proposed method is (2) efficient: incurring\ncomputational overhead as low as 1.40\\% on the A100 GPU in terms of Llama2\ntraining tokens per second, and requiring 2 bytes per parameter in GPU memory.\nWe demonstrate that PQT with Gaussian weight sampling is (3) stable: closely\nfollowing or even surpassing performance of the BF16 baseline while\npre-training GPT2 and Llama2 models with up to 1B parameters and 300B tokens.", "AI": {"tldr": "The paper proposes Pseudo-quantization Training (PQT) as a solution to the challenges of fully quantized training (FQT), introducing a noise distribution method for efficient low-precision training.", "motivation": "FQT faces consistency and scalability issues, requiring extensive resources. PQT is explored to address these challenges with a practical, efficient approach.", "method": "The authors propose a noise distribution method (R) for PQT, enabling low-precision FP parameters and efficient fake quantization. Gaussian weight sampling is used for scalability and stability.", "result": "PQT with Gaussian sampling is scalable (down to FP6), efficient (1.40% overhead), and stable, matching or surpassing BF16 baseline performance in GPT2 and Llama2 models.", "conclusion": "PQT provides a stable and efficient foundation for low-precision training, outperforming FQT and matching BF16 performance."}}
{"id": "2505.11482", "pdf": "https://arxiv.org/pdf/2505.11482", "abs": "https://arxiv.org/abs/2505.11482", "authors": ["Shirin Shoushtari", "Edward P. Chandler", "Yuanhao Wang", "M. Salman Asif", "Ulugbek S. Kamilov"], "title": "Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models are widely used as priors in imaging inverse problems.\nHowever, their performance often degrades under distribution shifts between the\ntraining and test-time images. Existing methods for identifying and quantifying\ndistribution shifts typically require access to clean test images, which are\nalmost never available while solving inverse problems (at test time). We\npropose a fully unsupervised metric for estimating distribution shifts using\nonly indirect (corrupted) measurements and score functions from diffusion\nmodels trained on different datasets. We theoretically show that this metric\nestimates the KL divergence between the training and test image distributions.\nEmpirically, we show that our score-based metric, using only corrupted\nmeasurements, closely approximates the KL divergence computed from clean\nimages. Motivated by this result, we show that aligning the out-of-distribution\nscore with the in-distribution score -- using only corrupted measurements --\nreduces the KL divergence and leads to improved reconstruction quality across\nmultiple inverse problems.", "AI": {"tldr": "A fully unsupervised metric for estimating distribution shifts in diffusion models using corrupted measurements and score functions, improving reconstruction quality in inverse problems.", "motivation": "Performance of diffusion models degrades under distribution shifts, and existing methods require clean test images, which are unavailable in inverse problems.", "method": "Proposes a score-based metric using corrupted measurements and score functions to estimate KL divergence between training and test distributions.", "result": "The metric approximates KL divergence from clean images and aligning scores improves reconstruction quality.", "conclusion": "Unsupervised score-based metric effectively estimates distribution shifts and enhances performance in inverse problems."}}
{"id": "2505.11270", "pdf": "https://arxiv.org/pdf/2505.11270", "abs": "https://arxiv.org/abs/2505.11270", "authors": ["Chao Zhang", "Shaolei Zhang", "Quehuan Liu", "Sibei Chen", "Tong Li", "Ju Fan"], "title": "TAIJI: MCP-based Multi-Modal Data Analytics on Data Lakes", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "The variety of data in data lakes presents significant challenges for data\nanalytics, as data scientists must simultaneously analyze multi-modal data,\nincluding structured, semi-structured, and unstructured data. While Large\nLanguage Models (LLMs) have demonstrated promising capabilities, they still\nremain inadequate for multi-modal data analytics in terms of accuracy,\nefficiency, and freshness. First, current natural language (NL) or SQL-like\nquery languages may struggle to precisely and comprehensively capture users'\nanalytical intent. Second, relying on a single unified LLM to process diverse\ndata modalities often leads to substantial inference overhead. Third, data\nstored in data lakes may be incomplete or outdated, making it essential to\nintegrate external open-domain knowledge to generate timely and relevant\nanalytics results.\n  In this paper, we envision a new multi-modal data analytics system.\nSpecifically, we propose a novel architecture built upon the Model Context\nProtocol (MCP), an emerging paradigm that enables LLMs to collaborate with\nknowledgeable agents. First, we define a semantic operator hierarchy tailored\nfor querying multi-modal data in data lakes and develop an AI-agent-powered\nNL2Operator translator to bridge user intent and analytical execution. Next, we\nintroduce an MCP-based execution framework, in which each MCP server hosts\nspecialized foundation models optimized for specific data modalities. This\ndesign enhances both accuracy and efficiency, while supporting high scalability\nthrough modular deployment. Finally, we propose a updating mechanism by\nharnessing the deep research and machine unlearning techniques to refresh the\ndata lakes and LLM knowledges, with the goal of balancing the data freshness\nand inference efficiency.", "AI": {"tldr": "The paper proposes a multi-modal data analytics system using Model Context Protocol (MCP) to address challenges in accuracy, efficiency, and freshness when analyzing diverse data in data lakes.", "motivation": "Current LLMs and query languages fall short in handling multi-modal data analytics due to imprecise intent capture, high inference overhead, and outdated data.", "method": "Introduces a semantic operator hierarchy and AI-agent-powered NL2Operator translator, an MCP-based execution framework with specialized models, and a data updating mechanism.", "result": "The proposed system improves accuracy, efficiency, and scalability while balancing data freshness and inference efficiency.", "conclusion": "The MCP-based architecture offers a promising solution for multi-modal data analytics in data lakes by leveraging collaborative LLMs and specialized agents."}}
{"id": "2411.07019", "pdf": "https://arxiv.org/pdf/2411.07019", "abs": "https://arxiv.org/abs/2411.07019", "authors": ["Zhiqiang Liu", "Yin Hua", "Mingyang Chen", "Zhuo Chen", "Ziqi Liu", "Lei Liang", "Huajun Chen", "Wen Zhang"], "title": "UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Beyond-triple fact representations including hyper-relational facts with\nauxiliary key-value pairs, temporal facts with additional timestamps, and\nnested facts implying relationships between facts, are gaining significant\nattention. However, constrained by complex fact representation forms, existing\nlink prediction models for beyond-triple facts have difficulty achieving\nhierarchical fact modeling and generalizing the modules for one specific facts\nto other fact types. To overcome this limitation, we propose a Unified\nHierarchical Representation learning framework (UniHR) for unified knowledge\ngraph link prediction. It consists of a unified Hierarchical Data\nRepresentation (HiDR) module and a unified Hierarchical Structure Learning\n(HiSL) module as graph encoder. The HiDR module unifies hyper-relational KGs,\ntemporal KGs, and nested factual KGs into triple-based representations. Then\nHiSL incorporates intra-fact and inter-fact message passing, focusing on\nenhancing the semantic information within individual facts and enriching the\nstructural information between facts. Empirical results demonstrate the\neffectiveness of UniHR and highlight the strong potential of unified\nrepresentations. Code and data are available at\nhttps://github.com/Lza12a/UniHR.", "AI": {"tldr": "UniHR proposes a unified framework for link prediction in knowledge graphs, handling hyper-relational, temporal, and nested facts via hierarchical representation learning.", "motivation": "Existing models struggle with hierarchical fact modeling and generalization across fact types due to complex representations.", "method": "UniHR uses a Hierarchical Data Representation (HiDR) module to unify fact types and a Hierarchical Structure Learning (HiSL) module for intra- and inter-fact message passing.", "result": "Empirical results show UniHR's effectiveness, emphasizing the potential of unified representations.", "conclusion": "UniHR successfully addresses limitations of existing models, offering a scalable and generalizable solution for link prediction."}}
{"id": "2505.11185", "pdf": "https://arxiv.org/pdf/2505.11185", "abs": "https://arxiv.org/abs/2505.11185", "authors": ["Francesco Madeddu", "Lucia Testa", "Gianluca De Carlo", "Michele Pieroni", "Andrea Mastropietro", "Aris Anagnostopoulos", "Paolo Tieri", "Sergio Barbarossa"], "title": "VitaGraph: Building a Knowledge Graph for Biologically Relevant Learning Tasks", "categories": ["cs.LG"], "comment": "9 pages of main text, 4 figures", "summary": "The intrinsic complexity of human biology presents ongoing challenges to\nscientific understanding. Researchers collaborate across disciplines to expand\nour knowledge of the biological interactions that define human life. AI\nmethodologies have emerged as powerful tools across scientific domains,\nparticularly in computational biology, where graph data structures effectively\nmodel biological entities such as protein-protein interaction (PPI) networks\nand gene functional networks. Those networks are used as datasets for paramount\nnetwork medicine tasks, such as gene-disease association prediction, drug\nrepurposing, and polypharmacy side effect studies. Reliable predictions from\nmachine learning models require high-quality foundational data. In this work,\nwe present a comprehensive multi-purpose biological knowledge graph constructed\nby integrating and refining multiple publicly available datasets. Building upon\nthe Drug Repurposing Knowledge Graph (DRKG), we define a pipeline tasked with\na) cleaning inconsistencies and redundancies present in DRKG, b) coalescing\ninformation from the main available public data sources, and c) enriching the\ngraph nodes with expressive feature vectors such as molecular fingerprints and\ngene ontologies. Biologically and chemically relevant features improve the\ncapacity of machine learning models to generate accurate and well-structured\nembedding spaces. The resulting resource represents a coherent and reliable\nbiological knowledge graph that serves as a state-of-the-art platform to\nadvance research in computational biology and precision medicine. Moreover, it\noffers the opportunity to benchmark graph-based machine learning and network\nmedicine models on relevant tasks. We demonstrate the effectiveness of the\nproposed dataset by benchmarking it against the task of drug repurposing, PPI\nprediction, and side-effect prediction, modeled as link prediction problems.", "AI": {"tldr": "The paper presents a refined biological knowledge graph integrating multiple datasets to improve AI-driven tasks like drug repurposing and PPI prediction.", "motivation": "Addressing the need for high-quality data in computational biology to enhance machine learning model reliability.", "method": "A pipeline cleans and enriches the Drug Repurposing Knowledge Graph (DRKG) with features like molecular fingerprints and gene ontologies.", "result": "A coherent, multi-purpose biological knowledge graph for tasks like drug repurposing and PPI prediction.", "conclusion": "The refined graph serves as a state-of-the-art platform for computational biology and precision medicine research."}}
{"id": "2505.11493", "pdf": "https://arxiv.org/pdf/2505.11493", "abs": "https://arxiv.org/abs/2505.11493", "authors": ["Yusu Qian", "Jiasen Lu", "Tsu-Jui Fu", "Xinze Wang", "Chen Chen", "Yinfei Yang", "Wenze Hu", "Zhe Gan"], "title": "GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing", "categories": ["cs.CV"], "comment": null, "summary": "Editing images using natural language instructions has become a natural and\nexpressive way to modify visual content; yet, evaluating the performance of\nsuch models remains challenging. Existing evaluation approaches often rely on\nimage-text similarity metrics like CLIP, which lack precision. In this work, we\nintroduce a new benchmark designed to evaluate text-guided image editing models\nin a more grounded manner, along two critical dimensions: (i) functional\ncorrectness, assessed via automatically generated multiple-choice questions\nthat verify whether the intended change was successfully applied; and (ii)\nimage content preservation, which ensures that non-targeted regions of the\nimage remain visually consistent using an object-aware masking technique and\npreservation scoring. The benchmark includes over 1000 high-quality editing\nexamples across 20 diverse content categories, each annotated with detailed\nediting instructions, evaluation questions, and spatial object masks. We\nconduct a large-scale study comparing GPT-Image-1, the latest flagship in the\ntext-guided image editing space, against several state-of-the-art editing\nmodels, and validate our automatic metrics against human ratings. Results show\nthat GPT-Image-1 leads in instruction-following accuracy, but often\nover-modifies irrelevant image regions, highlighting a key trade-off in the\ncurrent model behavior. GIE-Bench provides a scalable, reproducible framework\nfor advancing more accurate evaluation of text-guided image editing.", "AI": {"tldr": "A new benchmark (GIE-Bench) evaluates text-guided image editing models on functional correctness and content preservation, revealing GPT-Image-1's strengths and weaknesses.", "motivation": "Existing evaluation metrics (e.g., CLIP) lack precision for text-guided image editing, necessitating a more grounded benchmark.", "method": "GIE-Bench uses multiple-choice questions for functional correctness and object-aware masking for content preservation, with 1000+ examples across 20 categories.", "result": "GPT-Image-1 excels in instruction-following but over-modifies irrelevant regions, validated against human ratings.", "conclusion": "GIE-Bench offers a scalable, reproducible framework for improving evaluation of text-guided image editing models."}}
{"id": "2505.11304", "pdf": "https://arxiv.org/pdf/2505.11304", "abs": "https://arxiv.org/abs/2505.11304", "authors": ["Shudi Weng", "Chao Ren", "Ming Xiao", "Mikael Skoglund"], "title": "Heterogeneity-Aware Client Sampling: A Unified Solution for Consistent Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) commonly involves clients with diverse communication\nand computational capabilities. Such heterogeneity can significantly distort\nthe optimization dynamics and lead to objective inconsistency, where the global\nmodel converges to an incorrect stationary point potentially far from the\npursued optimum. Despite its critical impact, the joint effect of communication\nand computation heterogeneity has remained largely unexplored, due to the\nintrinsic complexity of their interaction. In this paper, we reveal the\nfundamentally distinct mechanisms through which heterogeneous communication and\ncomputation drive inconsistency in FL. To the best of our knowledge, this is\nthe first unified theoretical analysis of general heterogeneous FL, offering a\nprincipled understanding of how these two forms of heterogeneity jointly\ndistort the optimization trajectory under arbitrary choices of local solvers.\nMotivated by these insights, we propose Federated Heterogeneity-Aware Client\nSampling, FedACS, a universal method to eliminate all types of objective\ninconsistency. We theoretically prove that FedACS converges to the correct\noptimum at a rate of $O(1/\\sqrt{R})$, even in dynamic heterogeneous\nenvironments. Extensive experiments across multiple datasets show that FedACS\noutperforms state-of-the-art and category-specific baselines by 4.3%-36%, while\nreducing communication costs by 22%-89% and computation loads by 14%-105%,\nrespectively.", "AI": {"tldr": "The paper analyzes how communication and computation heterogeneity in federated learning (FL) causes optimization inconsistency and proposes FedACS, a method to mitigate this issue, achieving superior performance and efficiency.", "motivation": "Heterogeneity in client capabilities in FL leads to optimization inconsistency, but its joint impact is underexplored. This paper aims to unify its understanding and propose a solution.", "method": "The authors conduct a unified theoretical analysis of heterogeneous FL and introduce FedACS, a client sampling method to address inconsistency.", "result": "FedACS converges to the correct optimum at a rate of $O(1/\\sqrt{R})$, outperforming baselines by 4.3%-36% while reducing communication and computation costs.", "conclusion": "FedACS effectively eliminates objective inconsistency in FL, offering a universal solution with proven convergence and practical efficiency gains."}}
{"id": "2412.11142", "pdf": "https://arxiv.org/pdf/2412.11142", "abs": "https://arxiv.org/abs/2412.11142", "authors": ["Tiankai Yang", "Yi Nian", "Shawn Li", "Ruiyao Xu", "Yuangang Li", "Jiaqi Li", "Zhuo Xiao", "Xiyang Hu", "Ryan Rossi", "Kaize Ding", "Xia Hu", "Yue Zhao"], "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Anomaly detection (AD) is an important machine learning task with many\nreal-world uses, including fraud detection, medical diagnosis, and industrial\nmonitoring. Within natural language processing (NLP), AD helps detect issues\nlike spam, misinformation, and unusual user activity. Although large language\nmodels (LLMs) have had a strong impact on tasks such as text generation and\nsummarization, their potential in AD has not been studied enough. This paper\nintroduces AD-LLM, the first benchmark that evaluates how LLMs can help with\nNLP anomaly detection. We examine three key tasks: (i) zero-shot detection,\nusing LLMs' pre-trained knowledge to perform AD without tasks-specific\ntraining; (ii) data augmentation, generating synthetic data and category\ndescriptions to improve AD models; and (iii) model selection, using LLMs to\nsuggest unsupervised AD models. Through experiments with different datasets, we\nfind that LLMs can work well in zero-shot AD, that carefully designed\naugmentation methods are useful, and that explaining model selection for\nspecific datasets remains challenging. Based on these results, we outline six\nfuture research directions on LLMs for AD.", "AI": {"tldr": "The paper introduces AD-LLM, a benchmark for evaluating LLMs in NLP anomaly detection, covering zero-shot detection, data augmentation, and model selection. Results show LLMs' potential, with future research directions outlined.", "motivation": "Despite LLMs' impact on NLP tasks like text generation, their role in anomaly detection (AD) is understudied. The paper aims to explore LLMs' potential in NLP AD tasks.", "method": "The paper evaluates LLMs in three AD tasks: zero-shot detection, data augmentation, and model selection, using experiments across datasets.", "result": "LLMs perform well in zero-shot AD, data augmentation helps, but model selection explanations are challenging.", "conclusion": "The paper highlights LLMs' promise for AD and suggests six future research directions."}}
{"id": "2505.11197", "pdf": "https://arxiv.org/pdf/2505.11197", "abs": "https://arxiv.org/abs/2505.11197", "authors": ["Zhenyi Zhang", "Zihan Wang", "Yuhao Sun", "Tiejun Li", "Peijie Zhou"], "title": "Modeling Cell Dynamics and Interactions with Unbalanced Mean Field Schr\u00f6dinger Bridge", "categories": ["cs.LG", "math.OC", "q-bio.QM"], "comment": null, "summary": "Modeling the dynamics from sparsely time-resolved snapshot data is crucial\nfor understanding complex cellular processes and behavior. Existing methods\nleverage optimal transport, Schr\\\"odinger bridge theory, or their variants to\nsimultaneously infer stochastic, unbalanced dynamics from snapshot data.\nHowever, these approaches remain limited in their ability to account for\ncell-cell interactions. This integration is essential in real-world scenarios\nsince intercellular communications are fundamental life processes and can\ninfluence cell state-transition dynamics. To address this challenge, we\nformulate the Unbalanced Mean-Field Schr\\\"odinger Bridge (UMFSB) framework to\nmodel unbalanced stochastic interaction dynamics from snapshot data. Inspired\nby this framework, we further propose CytoBridge, a deep learning algorithm\ndesigned to approximate the UMFSB problem. By explicitly modeling cellular\ntransitions, proliferation, and interactions through neural networks,\nCytoBridge offers the flexibility to learn these processes directly from data.\nThe effectiveness of our method has been extensively validated using both\nsynthetic gene regulatory data and real scRNA-seq datasets. Compared to\nexisting methods, CytoBridge identifies growth, transition, and interaction\npatterns, eliminates false transitions, and reconstructs the developmental\nlandscape with greater accuracy.", "AI": {"tldr": "The paper introduces UMFSB and CytoBridge to model stochastic cell dynamics and interactions from sparse snapshot data, outperforming existing methods.", "motivation": "Existing methods fail to account for cell-cell interactions, which are crucial for understanding cellular processes.", "method": "Proposes UMFSB framework and CytoBridge, a deep learning algorithm, to model unbalanced stochastic dynamics and interactions.", "result": "Validated on synthetic and real datasets, CytoBridge accurately identifies growth, transitions, and interactions, reducing false transitions.", "conclusion": "CytoBridge improves modeling of cellular dynamics and interactions, offering better accuracy than current approaches."}}
{"id": "2505.11497", "pdf": "https://arxiv.org/pdf/2505.11497", "abs": "https://arxiv.org/abs/2505.11497", "authors": ["Yushi Huang", "Ruihao Gong", "Jing Liu", "Yifu Ding", "Chengtao Lv", "Haotong Qin", "Jun Zhang"], "title": "QVGen: Pushing the Limit of Quantized Video Generative Models", "categories": ["cs.CV"], "comment": "Our code will be released upon acceptance", "summary": "Video diffusion models (DMs) have enabled high-quality video synthesis. Yet,\ntheir substantial computational and memory demands pose serious challenges to\nreal-world deployment, even on high-end GPUs. As a commonly adopted solution,\nquantization has proven notable success in reducing cost for image DMs, while\nits direct application to video DMs remains ineffective. In this paper, we\npresent QVGen, a novel quantization-aware training (QAT) framework tailored for\nhigh-performance and inference-efficient video DMs under extremely low-bit\nquantization (e.g., 4-bit or below). We begin with a theoretical analysis\ndemonstrating that reducing the gradient norm is essential to facilitate\nconvergence for QAT. To this end, we introduce auxiliary modules ($\\Phi$) to\nmitigate large quantization errors, leading to significantly enhanced\nconvergence. To eliminate the inference overhead of $\\Phi$, we propose a\nrank-decay strategy that progressively eliminates $\\Phi$. Specifically, we\nrepeatedly employ singular value decomposition (SVD) and a proposed rank-based\nregularization $\\mathbf{\\gamma}$ to identify and decay low-contributing\ncomponents. This strategy retains performance while zeroing out inference\noverhead. Extensive experiments across $4$ state-of-the-art (SOTA) video DMs,\nwith parameter sizes ranging from $1.3$B $\\sim14$B, show that QVGen is the\nfirst to reach full-precision comparable quality under 4-bit settings.\nMoreover, it significantly outperforms existing methods. For instance, our\n3-bit CogVideoX-2B achieves improvements of $+25.28$ in Dynamic Degree and\n$+8.43$ in Scene Consistency on VBench.", "AI": {"tldr": "QVGen is a quantization-aware training framework for video diffusion models, enabling high performance under low-bit quantization (e.g., 4-bit) by reducing gradient norms and using auxiliary modules, achieving full-precision quality.", "motivation": "Video diffusion models face high computational and memory demands, making real-world deployment challenging. Existing quantization methods for image DMs are ineffective for video DMs.", "method": "QVGen introduces auxiliary modules to mitigate quantization errors and a rank-decay strategy using SVD and rank-based regularization to eliminate inference overhead.", "result": "QVGen achieves full-precision comparable quality under 4-bit settings and outperforms existing methods, with significant improvements in metrics like Dynamic Degree and Scene Consistency.", "conclusion": "QVGen is the first framework to enable high-performance video DMs under extremely low-bit quantization, offering practical deployment solutions."}}
{"id": "2505.11340", "pdf": "https://arxiv.org/pdf/2505.11340", "abs": "https://arxiv.org/abs/2505.11340", "authors": ["Zeyu Gao", "Yuxin Cui", "Hao Wang", "Siliang Qin", "Yuanda Wang", "Bolun Zhang", "Chao Zhang"], "title": "DecompileBench: A Comprehensive Benchmark for Evaluating Decompilers in Real-World Scenarios", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Decompilers are fundamental tools for critical security tasks, from\nvulnerability discovery to malware analysis, yet their evaluation remains\nfragmented. Existing approaches primarily focus on syntactic correctness\nthrough synthetic micro-benchmarks or subjective human ratings, failing to\naddress real-world requirements for semantic fidelity and analyst usability. We\npresent DecompileBench, the first comprehensive framework that enables\neffective evaluation of decompilers in reverse engineering workflows through\nthree key components: \\textit{real-world function extraction} (comprising\n23,400 functions from 130 real-world programs), \\textit{runtime-aware\nvalidation}, and \\textit{automated human-centric assessment} using LLM-as-Judge\nto quantify the effectiveness of decompilers in reverse engineering workflows.\nThrough a systematic comparison between six industrial-strength decompilers and\nsix recent LLM-powered approaches, we demonstrate that LLM-based methods\nsurpass commercial tools in code understandability despite 52.2% lower\nfunctionality correctness. These findings highlight the potential of LLM-based\napproaches to transform human-centric reverse engineering. We open source\n\\href{https://github.com/Jennieett/DecompileBench}{DecompileBench} to provide a\nframework to advance research on decompilers and assist security experts in\nmaking informed tool selections based on their specific requirements.", "AI": {"tldr": "DecompileBench is a framework for evaluating decompilers using real-world functions, runtime-aware validation, and automated human-centric assessment, showing LLM-based methods outperform commercial tools in understandability despite lower correctness.", "motivation": "Current decompiler evaluations lack real-world semantic fidelity and usability metrics, limiting their practical utility in security tasks.", "method": "DecompileBench includes real-world function extraction (23,400 functions from 130 programs), runtime-aware validation, and LLM-as-Judge for automated assessment.", "result": "LLM-based decompilers surpass commercial tools in understandability but have 52.2% lower functionality correctness.", "conclusion": "LLM-based approaches show promise for human-centric reverse engineering, and DecompileBench is open-sourced to advance research and tool selection."}}
{"id": "2412.12527", "pdf": "https://arxiv.org/pdf/2412.12527", "abs": "https://arxiv.org/abs/2412.12527", "authors": ["Hyuhng Joon Kim", "Youna Kim", "Sang-goo Lee", "Taeuk Kim"], "title": "When to Speak, When to Abstain: Contrastive Decoding with Abstention", "categories": ["cs.CL"], "comment": "ACL 2025 (main)", "summary": "Large Language Models (LLMs) demonstrate exceptional performance across\ndiverse tasks by leveraging pre-trained (i.e., parametric) and external (i.e.,\ncontextual) knowledge. While substantial efforts have been made to enhance the\nutilization of both forms of knowledge, situations in which models lack\nrelevant information remain underexplored. To investigate this challenge, we\nfirst present a controlled testbed featuring four distinct knowledge access\nscenarios, including the aforementioned edge case, revealing that conventional\nLLM usage exhibits insufficient robustness in handling all instances.\nAddressing this limitation, we propose Contrastive Decoding with Abstention\n(CDA), a novel training-free decoding method that allows LLMs to generate\nresponses when relevant knowledge is available and to abstain otherwise. CDA\nestimates the relevance of both knowledge sources for a given input, adaptively\ndeciding which type of information to prioritize and which to exclude. Through\nextensive experiments, we demonstrate that CDA can effectively perform accurate\ngeneration and abstention simultaneously, enhancing reliability and preserving\nuser trust.", "AI": {"tldr": "The paper introduces Contrastive Decoding with Abstention (CDA), a method to improve LLM robustness by allowing them to abstain when lacking relevant knowledge, enhancing reliability.", "motivation": "To address the underexplored challenge of LLMs lacking relevant knowledge in certain scenarios, aiming to improve robustness and reliability.", "method": "Proposes CDA, a training-free decoding method that estimates knowledge relevance and adaptively prioritizes or excludes information.", "result": "CDA effectively enables accurate generation and abstention, improving LLM reliability and user trust.", "conclusion": "CDA enhances LLM robustness by handling knowledge gaps, ensuring reliable performance and maintaining trust."}}
{"id": "2505.11210", "pdf": "https://arxiv.org/pdf/2505.11210", "abs": "https://arxiv.org/abs/2505.11210", "authors": ["Anders Gj\u00f8lbye", "Stefan Haufe", "Lars Kai Hansen"], "title": "Minimizing False-Positive Attributions in Explanations of Non-Linear Models", "categories": ["cs.LG", "stat.ML"], "comment": "Preprint. Under review", "summary": "Suppressor variables can influence model predictions without being dependent\non the target outcome and they pose a significant challenge for Explainable AI\n(XAI) methods. These variables may cause false-positive feature attributions,\nundermining the utility of explanations. Although effective remedies exist for\nlinear models, their extension to non-linear models and to instance-based\nexplanations has remained limited. We introduce PatternLocal, a novel XAI\ntechnique that addresses this gap. PatternLocal begins with a locally linear\nsurrogate, e.g. LIME, KernelSHAP, or gradient-based methods, and transforms the\nresulting discriminative model weights into a generative representation,\nthereby suppressing the influence of suppressor variables while preserving\nlocal fidelity. In extensive hyperparameter optimization on the XAI-TRIS\nbenchmark, PatternLocal consistently outperformed other XAI methods and reduced\nfalse-positive attributions when explaining non-linear tasks, thereby enabling\nmore reliable and actionable insights.", "AI": {"tldr": "PatternLocal is a new XAI method that reduces false-positive attributions by transforming discriminative model weights into a generative representation, outperforming other methods in non-linear tasks.", "motivation": "Suppressor variables can mislead XAI methods by causing false-positive feature attributions, especially in non-linear models, necessitating a solution like PatternLocal.", "method": "PatternLocal uses a locally linear surrogate (e.g., LIME, KernelSHAP) and transforms discriminative weights into a generative representation to suppress suppressor variables while maintaining local fidelity.", "result": "PatternLocal outperformed other XAI methods in hyperparameter optimization on the XAI-TRIS benchmark, reducing false-positive attributions.", "conclusion": "PatternLocal provides more reliable and actionable insights for non-linear tasks by effectively addressing suppressor variable challenges."}}
{"id": "2505.10696", "pdf": "https://arxiv.org/pdf/2505.10696", "abs": "https://arxiv.org/abs/2505.10696", "authors": ["Manthan Patel", "Fan Yang", "Yuheng Qiu", "Cesar Cadena", "Sebastian Scherer", "Marco Hutter", "Wenshan Wang"], "title": "TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation", "categories": ["cs.RO", "cs.CV"], "comment": "Under review for IEEE conference", "summary": "We present TartanGround, a large-scale, multi-modal dataset to advance the\nperception and autonomy of ground robots operating in diverse environments.\nThis dataset, collected in various photorealistic simulation environments\nincludes multiple RGB stereo cameras for 360-degree coverage, along with depth,\noptical flow, stereo disparity, LiDAR point clouds, ground truth poses,\nsemantic segmented images, and occupancy maps with semantic labels. Data is\ncollected using an integrated automatic pipeline, which generates trajectories\nmimicking the motion patterns of various ground robot platforms, including\nwheeled and legged robots. We collect 910 trajectories across 70 environments,\nresulting in 1.5 million samples. Evaluations on occupancy prediction and SLAM\ntasks reveal that state-of-the-art methods trained on existing datasets\nstruggle to generalize across diverse scenes. TartanGround can serve as a\ntestbed for training and evaluation of a broad range of learning-based tasks,\nincluding occupancy prediction, SLAM, neural scene representation,\nperception-based navigation, and more, enabling advancements in robotic\nperception and autonomy towards achieving robust models generalizable to more\ndiverse scenarios. The dataset and codebase for data collection will be made\npublicly available upon acceptance. Webpage: https://tartanair.org/tartanground", "AI": {"tldr": "TartanGround is a large-scale, multi-modal dataset for ground robots, featuring diverse data types and environments to improve robotic perception and autonomy.", "motivation": "To address the lack of datasets that generalize across diverse scenes for ground robots, enabling robust model training.", "method": "Data is collected using an automated pipeline in photorealistic simulations, including RGB stereo cameras, LiDAR, depth, and semantic labels across 70 environments.", "result": "The dataset contains 1.5 million samples from 910 trajectories, showing existing methods struggle with generalization.", "conclusion": "TartanGround serves as a versatile testbed for various learning-based tasks, advancing robotic perception and autonomy."}}
{"id": "2505.11416", "pdf": "https://arxiv.org/pdf/2505.11416", "abs": "https://arxiv.org/abs/2505.11416", "authors": ["Pouya Shaeri", "Ariane Middel"], "title": "MID-L: Matrix-Interpolated Dropout Layer with Layer-wise Neuron Selection", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "Submitted in a Computer Science Conference, currently in Review", "summary": "Modern neural networks often activate all neurons for every input, leading to\nunnecessary computation and inefficiency. We introduce Matrix-Interpolated\nDropout Layer (MID-L), a novel module that dynamically selects and activates\nonly the most informative neurons by interpolating between two transformation\npaths via a learned, input-dependent gating vector. Unlike conventional dropout\nor static sparsity methods, MID-L employs a differentiable Top-k masking\nstrategy, enabling per-input adaptive computation while maintaining end-to-end\ndifferentiability. MID-L is model-agnostic and integrates seamlessly into\nexisting architectures. Extensive experiments on six benchmarks, including\nMNIST, CIFAR-10, CIFAR-100, SVHN, UCI Adult, and IMDB, show that MID-L achieves\nup to average 55\\% reduction in active neurons, 1.7$\\times$ FLOPs savings, and\nmaintains or exceeds baseline accuracy. We further validate the informativeness\nand selectivity of the learned neurons via Sliced Mutual Information (SMI) and\nobserve improved robustness under overfitting and noisy data conditions.\nAdditionally, MID-L demonstrates favorable inference latency and memory usage\nprofiles, making it suitable for both research exploration and deployment on\ncompute-constrained systems. These results position MID-L as a general-purpose,\nplug-and-play dynamic computation layer, bridging the gap between dropout\nregularization and efficient inference.", "AI": {"tldr": "MID-L dynamically selects and activates only the most informative neurons, reducing computation and maintaining accuracy.", "motivation": "Modern neural networks activate all neurons for every input, leading to inefficiency. MID-L aims to optimize computation by selectively activating neurons.", "method": "MID-L uses a learned, input-dependent gating vector and a differentiable Top-k masking strategy to dynamically select neurons.", "result": "Achieves 55% reduction in active neurons, 1.7x FLOPs savings, and maintains or exceeds baseline accuracy across six benchmarks.", "conclusion": "MID-L is a versatile, efficient layer that bridges dropout regularization and efficient inference, suitable for deployment on constrained systems."}}
{"id": "2412.12632", "pdf": "https://arxiv.org/pdf/2412.12632", "abs": "https://arxiv.org/abs/2412.12632", "authors": ["Zhiyuan Chang", "Mingyang Li", "Xiaojun Jia", "Junjie Wang", "Yuekai Huang", "Qing Wang", "Yihao Huang", "Yang Liu"], "title": "What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context", "categories": ["cs.CL", "cs.AI"], "comment": "15 pages, 5 figures", "summary": "Incorporating external knowledge into large language models (LLMs) has\nemerged as a promising approach to mitigate outdated knowledge and\nhallucination in LLMs. However, external knowledge is often imperfect. In\naddition to useful knowledge, external knowledge is rich in irrelevant or\nmisinformation in the context that can impair the reliability of LLM responses.\nThis paper focuses on LLMs' preferred external knowledge in imperfect contexts\nwhen handling multi-hop QA. Inspired by criminal procedural law's Chain of\nEvidence (CoE), we characterize that knowledge preferred by LLMs should\nmaintain both relevance to the question and mutual support among knowledge\npieces. Accordingly, we propose an automated CoE discrimination approach and\nevaluate LLMs' effectiveness, faithfulness and robustness with CoE, including\nits application in the Retrieval-Augmented Generation (RAG). Tests on five LLMs\nshow CoE improves generation accuracy, answer faithfulness, robustness to\nknowledge conflicts, and boosts the performance of existing approaches in three\npractical RAG scenarios.", "AI": {"tldr": "The paper proposes a Chain of Evidence (CoE) approach to improve LLMs' use of external knowledge in multi-hop QA, enhancing accuracy, faithfulness, and robustness.", "motivation": "To address the challenge of imperfect external knowledge (irrelevant or misinformation) in LLMs, which can impair reliability.", "method": "Inspired by criminal procedural law's CoE, the approach ensures knowledge relevance and mutual support. An automated CoE discrimination method is proposed and tested on five LLMs.", "result": "CoE improves generation accuracy, answer faithfulness, robustness to conflicts, and boosts RAG performance in three scenarios.", "conclusion": "The CoE approach effectively enhances LLMs' reliability and performance in handling imperfect external knowledge for multi-hop QA."}}
{"id": "2505.11221", "pdf": "https://arxiv.org/pdf/2505.11221", "abs": "https://arxiv.org/abs/2505.11221", "authors": ["Donghoon Lee", "Tung M. Luu", "Younghwan Lee", "Chang D. Yoo"], "title": "Sample Efficient Reinforcement Learning via Large Vision Language Model Distillation", "categories": ["cs.LG"], "comment": "5 pages, ICASSP 2025. The first two authors are equally contributed", "summary": "Recent research highlights the potential of multimodal foundation models in\ntackling complex decision-making challenges. However, their large parameters\nmake real-world deployment resource-intensive and often impractical for\nconstrained systems. Reinforcement learning (RL) shows promise for\ntask-specific agents but suffers from high sample complexity, limiting\npractical applications. To address these challenges, we introduce LVLM to\nPolicy (LVLM2P), a novel framework that distills knowledge from large\nvision-language models (LVLM) into more efficient RL agents. Our approach\nleverages the LVLM as a teacher, providing instructional actions based on\ntrajectories collected by the RL agent, which helps reduce less meaningful\nexploration in the early stages of learning, thereby significantly accelerating\nthe agent's learning progress. Additionally, by leveraging the LVLM to suggest\nactions directly from visual observations, we eliminate the need for manual\ntextual descriptors of the environment, enhancing applicability across diverse\ntasks. Experiments show that LVLM2P significantly enhances the sample\nefficiency of baseline RL algorithms.", "AI": {"tldr": "LVLM2P distills knowledge from large vision-language models into RL agents to improve efficiency and reduce exploration, enhancing sample efficiency.", "motivation": "Address the impracticality of large multimodal models and high sample complexity in RL for real-world deployment.", "method": "Uses LVLM as a teacher to guide RL agents with instructional actions, reducing exploration and eliminating manual textual descriptors.", "result": "LVLM2P significantly improves the sample efficiency of baseline RL algorithms.", "conclusion": "The framework effectively bridges the gap between large models and practical RL applications."}}
{"id": "2505.11417", "pdf": "https://arxiv.org/pdf/2505.11417", "abs": "https://arxiv.org/abs/2505.11417", "authors": ["Patryk Bartkowiak", "Michal Podstawski"], "title": "EdgeWisePersona: A Dataset for On-Device User Profiling from Natural Language Interactions", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper introduces a novel dataset and evaluation benchmark designed to\nassess and improve small language models deployable on edge devices, with a\nfocus on user profiling from multi-session natural language interactions in\nsmart home environments. At the core of the dataset are structured user\nprofiles, each defined by a set of routines - context-triggered, repeatable\npatterns of behavior that govern how users interact with their home systems.\nUsing these profiles as input, a large language model (LLM) generates\ncorresponding interaction sessions that simulate realistic, diverse, and\ncontext-aware dialogues between users and their devices.\n  The primary task supported by this dataset is profile reconstruction:\ninferring user routines and preferences solely from interactions history. To\nassess how well current models can perform this task under realistic\nconditions, we benchmarked several state-of-the-art compact language models and\ncompared their performance against large foundation models. Our results show\nthat while small models demonstrate some capability in reconstructing profiles,\nthey still fall significantly short of large models in accurately capturing\nuser behavior. This performance gap poses a major challenge - particularly\nbecause on-device processing offers critical advantages, such as preserving\nuser privacy, minimizing latency, and enabling personalized experiences without\nreliance on the cloud. By providing a realistic, structured testbed for\ndeveloping and evaluating behavioral modeling under these constraints, our\ndataset represents a key step toward enabling intelligent, privacy-respecting\nAI systems that learn and adapt directly on user-owned devices.", "AI": {"tldr": "A novel dataset and benchmark for evaluating small language models on edge devices, focusing on user profiling from smart home interactions. Small models show promise but lag behind large models in accuracy.", "motivation": "To enable privacy-respecting, on-device AI by improving small language models' ability to reconstruct user profiles from interactions.", "method": "Uses structured user profiles and LLM-generated interaction sessions to simulate realistic dialogues. Benchmarks compact models against large ones for profile reconstruction.", "result": "Small models can reconstruct profiles but are less accurate than large models, highlighting a challenge for on-device AI.", "conclusion": "The dataset advances privacy-respecting AI by providing a realistic testbed for small model development under edge constraints."}}
{"id": "2412.15529", "pdf": "https://arxiv.org/pdf/2412.15529", "abs": "https://arxiv.org/abs/2412.15529", "authors": ["Qianren Mao", "Yangyifei Luo", "Qili Zhang", "Yashuo Luo", "Zhilong Cao", "Jinlong Zhang", "HanWen Hao", "Zhijun Chen", "Weifeng Jiang", "Junnan Liu", "Xiaolong Wang", "Zhenting Huang", "Zhixing Tan", "Sun Jie", "Bo Li", "Xudong Liu", "Richong Zhang", "Jianxin Li"], "title": "XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) synergizes the retrieval of pertinent\ndata with the generative capabilities of Large Language Models (LLMs), ensuring\nthat the generated output is not only contextually relevant but also accurate\nand current. We introduce XRAG, an open-source, modular codebase that\nfacilitates exhaustive evaluation of the performance of foundational components\nof advanced RAG modules. These components are systematically categorized into\nfour core phases: pre-retrieval, retrieval, post-retrieval, and generation. We\nsystematically analyse them across reconfigured datasets, providing a\ncomprehensive benchmark for their effectiveness. As the complexity of RAG\nsystems continues to escalate, we underscore the critical need to identify\npotential failure points in RAG systems. We formulate a suite of experimental\nmethodologies and diagnostic testing protocols to dissect the failure points\ninherent in RAG engineering. Subsequently, we proffer bespoke solutions aimed\nat bolstering the overall performance of these modules. Our work thoroughly\nevaluates the performance of advanced core components in RAG systems, providing\ninsights into optimizations for prevalent failure points.", "AI": {"tldr": "XRAG is an open-source tool for evaluating and optimizing RAG systems, focusing on four core phases to improve performance and address failure points.", "motivation": "To enhance the accuracy and relevance of RAG systems by identifying and addressing their failure points through systematic evaluation.", "method": "XRAG modularly evaluates RAG components across four phases (pre-retrieval, retrieval, post-retrieval, generation) using reconfigured datasets and diagnostic tests.", "result": "Provides benchmarks and tailored solutions to improve RAG system performance by pinpointing and mitigating failure points.", "conclusion": "XRAG offers a comprehensive framework for optimizing RAG systems, ensuring better contextual relevance and accuracy in generated outputs."}}
{"id": "2505.11230", "pdf": "https://arxiv.org/pdf/2505.11230", "abs": "https://arxiv.org/abs/2505.11230", "authors": ["Oskar Bohn Lassen", "Serio Agriesti", "Mohamed Eldafrawi", "Daniele Gammelli", "Guido Cantelmo", "Guido Gentile", "Francisco Camara Pereira"], "title": "Learning traffic flows: Graph Neural Networks for Metamodelling Traffic Assignment", "categories": ["cs.LG"], "comment": null, "summary": "The Traffic Assignment Problem is a fundamental, yet computationally\nexpensive, task in transportation modeling, especially for large-scale\nnetworks. Traditional methods require iterative simulations to reach\nequilibrium, making real-time or large-scale scenario analysis challenging. In\nthis paper, we propose a learning-based approach using Message-Passing Neural\nNetworks as a metamodel to approximate the equilibrium flow of the Stochastic\nUser Equilibrium assignment. Our model is designed to mimic the algorithmic\nstructure used in conventional traffic simulators allowing it to better capture\nthe underlying process rather than just the data. We benchmark it against other\nconventional deep learning techniques and evaluate the model's robustness by\ntesting its ability to predict traffic flows on input data outside the domain\non which it was trained. This approach offers a promising solution for\naccelerating out-of-distribution scenario assessments, reducing computational\ncosts in large-scale transportation planning, and enabling real-time\ndecision-making.", "AI": {"tldr": "A learning-based approach using Message-Passing Neural Networks (MPNNs) is proposed to approximate equilibrium flow in traffic assignment, offering faster and more scalable solutions compared to traditional methods.", "motivation": "Traditional traffic assignment methods are computationally expensive and struggle with real-time or large-scale scenarios, necessitating a more efficient solution.", "method": "The paper employs MPNNs as a metamodel to mimic conventional traffic simulators, capturing the underlying process rather than just data patterns.", "result": "The model outperforms conventional deep learning techniques and demonstrates robustness in predicting traffic flows for out-of-distribution scenarios.", "conclusion": "The MPNN-based approach accelerates scenario assessments, reduces computational costs, and enables real-time decision-making in transportation planning."}}
{"id": "2505.10923", "pdf": "https://arxiv.org/pdf/2505.10923", "abs": "https://arxiv.org/abs/2505.10923", "authors": ["Simeon Adebola", "Shuangyu Xie", "Chung Min Kim", "Justin Kerr", "Bart M. van Marrewijk", "Mieke van Vlaardingen", "Tim van Daalen", "Robert van Loo", "Jose Luis Susa Rincon", "Eugen Solowjow", "Rick van de Zedde", "Ken Goldberg"], "title": "GrowSplat: Constructing Temporal Digital Twins of Plants with Gaussian Splats", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Accurate temporal reconstructions of plant growth are essential for plant\nphenotyping and breeding, yet remain challenging due to complex geometries,\nocclusions, and non-rigid deformations of plants. We present a novel framework\nfor building temporal digital twins of plants by combining 3D Gaussian\nSplatting with a robust sample alignment pipeline. Our method begins by\nreconstructing Gaussian Splats from multi-view camera data, then leverages a\ntwo-stage registration approach: coarse alignment through feature-based\nmatching and Fast Global Registration, followed by fine alignment with\nIterative Closest Point. This pipeline yields a consistent 4D model of plant\ndevelopment in discrete time steps. We evaluate the approach on data from the\nNetherlands Plant Eco-phenotyping Center, demonstrating detailed temporal\nreconstructions of Sequoia and Quinoa species. Videos and Images can be seen at\nhttps://berkeleyautomation.github.io/GrowSplat/", "AI": {"tldr": "A novel framework for temporal plant growth reconstruction using 3D Gaussian Splatting and a two-stage alignment pipeline, validated on Sequoia and Quinoa data.", "motivation": "Accurate temporal reconstructions of plant growth are challenging due to complex geometries, occlusions, and deformations, necessitating robust methods for phenotyping and breeding.", "method": "Combines 3D Gaussian Splatting with a two-stage alignment (coarse feature-based matching and Fast Global Registration, followed by fine Iterative Closest Point) to create 4D plant models.", "result": "Demonstrates detailed temporal reconstructions of Sequoia and Quinoa species using data from the Netherlands Plant Eco-phenotyping Center.", "conclusion": "The framework effectively addresses challenges in plant growth reconstruction, offering a reliable tool for phenotyping and breeding."}}
{"id": "2505.11427", "pdf": "https://arxiv.org/pdf/2505.11427", "abs": "https://arxiv.org/abs/2505.11427", "authors": ["Adrian Robert Minut", "Tommaso Mencattini", "Andrea Santilli", "Donato Crisostomi", "Emanuele Rodol\u00e0"], "title": "Mergenetic: a Simple Evolutionary Model Merging Library", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "Link: https://github.com/tommasomncttn/mergenetic", "summary": "Model merging allows combining the capabilities of existing models into a new\none - post hoc, without additional training. This has made it increasingly\npopular thanks to its low cost and the availability of libraries that support\nmerging on consumer GPUs. Recent work shows that pairing merging with\nevolutionary algorithms can boost performance, but no framework currently\nsupports flexible experimentation with such strategies in language models. We\nintroduce Mergenetic, an open-source library for evolutionary model merging.\nMergenetic enables easy composition of merging methods and evolutionary\nalgorithms while incorporating lightweight fitness estimators to reduce\nevaluation costs. We describe its design and demonstrate that Mergenetic\nproduces competitive results across tasks and languages using modest hardware.", "AI": {"tldr": "Mergenetic is an open-source library for evolutionary model merging, enabling flexible experimentation and competitive results with modest hardware.", "motivation": "Existing frameworks lack support for flexible experimentation with evolutionary model merging strategies in language models.", "method": "Mergenetic combines merging methods and evolutionary algorithms, using lightweight fitness estimators to reduce evaluation costs.", "result": "The library produces competitive results across tasks and languages using modest hardware.", "conclusion": "Mergenetic provides a cost-effective and accessible solution for evolutionary model merging in language models."}}
{"id": "2501.00745", "pdf": "https://arxiv.org/pdf/2501.00745", "abs": "https://arxiv.org/abs/2501.00745", "authors": ["Xiyang Hu"], "title": "Dynamics of Adversarial Attacks on Large Language Model-Based Search Engines", "categories": ["cs.CL", "cs.AI", "cs.GT", "cs.IR", "econ.TH"], "comment": null, "summary": "The increasing integration of Large Language Model (LLM) based search engines\nhas transformed the landscape of information retrieval. However, these systems\nare vulnerable to adversarial attacks, especially ranking manipulation attacks,\nwhere attackers craft webpage content to manipulate the LLM's ranking and\npromote specific content, gaining an unfair advantage over competitors. In this\npaper, we study the dynamics of ranking manipulation attacks. We frame this\nproblem as an Infinitely Repeated Prisoners' Dilemma, where multiple players\nstrategically decide whether to cooperate or attack. We analyze the conditions\nunder which cooperation can be sustained, identifying key factors such as\nattack costs, discount rates, attack success rates, and trigger strategies that\ninfluence player behavior. We identify tipping points in the system dynamics,\ndemonstrating that cooperation is more likely to be sustained when players are\nforward-looking. However, from a defense perspective, we find that simply\nreducing attack success probabilities can, paradoxically, incentivize attacks\nunder certain conditions. Furthermore, defensive measures to cap the upper\nbound of attack success rates may prove futile in some scenarios. These\ninsights highlight the complexity of securing LLM-based systems. Our work\nprovides a theoretical foundation and practical insights for understanding and\nmitigating their vulnerabilities, while emphasizing the importance of adaptive\nsecurity strategies and thoughtful ecosystem design.", "AI": {"tldr": "The paper studies ranking manipulation attacks in LLM-based search engines, framing the problem as an Infinitely Repeated Prisoners' Dilemma. It analyzes conditions for cooperation, identifies tipping points, and highlights paradoxes in defensive measures.", "motivation": "To understand and mitigate vulnerabilities in LLM-based search engines, particularly ranking manipulation attacks, by analyzing strategic player behavior.", "method": "Frames the problem as an Infinitely Repeated Prisoners' Dilemma, analyzing factors like attack costs, discount rates, and trigger strategies.", "result": "Identifies conditions for cooperation, tipping points in dynamics, and paradoxes in defensive measures (e.g., reducing attack success rates may incentivize attacks).", "conclusion": "Highlights the complexity of securing LLM-based systems and emphasizes adaptive security strategies and ecosystem design."}}
{"id": "2505.11235", "pdf": "https://arxiv.org/pdf/2505.11235", "abs": "https://arxiv.org/abs/2505.11235", "authors": ["Fei Wu", "Jia Hu", "Geyong Min", "Shiqiang Wang"], "title": "Memory-Efficient Orthogonal Fine-Tuning with Principal Subspace Adaptation", "categories": ["cs.LG"], "comment": null, "summary": "Driven by the relentless growth in model parameters, which renders full\nfine-tuning prohibitively expensive for large-scale deployment,\nparameter-efficient fine-tuning (PEFT) has emerged as a crucial approach for\nrapidly adapting large models to a wide range of downstream tasks. Among the\nPEFT family, orthogonal fine-tuning and its variants have demonstrated\nremarkable performance by preserving hyperspherical energy, which encodes\npairwise angular similarity between neurons. However, these methods are\ninherently memory-inefficient due to the need to store intermediate activations\nfrom multiple full-dimensional sparse matrices. To address this limitation, we\npropose Memory-efficient Orthogonal Fine-Tuning (MOFT) with principal subspace\nadaptation. Specifically, we first establish a theoretical condition under\nwhich orthogonal transformations within a low-rank subspace preserve\nhyperspherical energy. Based on this insight, we constrain orthogonal\nfine-tuning to the principal subspace defined by the top-r components obtained\nthrough singular value decomposition and impose an additional constraint on the\nprojection matrix to satisfy the preservation condition. To enhance MOFT's\nflexibility across tasks, we relax strict orthogonality by introducing two\nlearnable scaling vectors. Extensive experiments on 37 diverse tasks and four\nmodels across NLP and CV demonstrate that MOFT consistently outperforms key\nbaselines while significantly reducing the memory footprint of orthogonal\nfine-tuning.", "AI": {"tldr": "MOFT introduces memory-efficient orthogonal fine-tuning by using principal subspace adaptation, reducing memory usage while maintaining performance.", "motivation": "Full fine-tuning of large models is costly; PEFT, especially orthogonal fine-tuning, is effective but memory-inefficient.", "method": "MOFT constrains orthogonal transformations to a low-rank subspace via SVD, adds a projection constraint, and introduces learnable scaling vectors.", "result": "MOFT outperforms baselines on 37 tasks across NLP and CV, with reduced memory usage.", "conclusion": "MOFT offers a memory-efficient alternative to orthogonal fine-tuning without sacrificing performance."}}
{"id": "2505.11116", "pdf": "https://arxiv.org/pdf/2505.11116", "abs": "https://arxiv.org/abs/2505.11116", "authors": ["Liam Boyle", "Jonas K\u00fchne", "Nicolas Baumann", "Niklas Bastuck", "Michele Magno"], "title": "Planar Velocity Estimation for Fast-Moving Mobile Robots Using Event-Based Optical Flow", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Accurate velocity estimation is critical in mobile robotics, particularly for\ndriver assistance systems and autonomous driving. Wheel odometry fused with\nInertial Measurement Unit (IMU) data is a widely used method for velocity\nestimation; however, it typically requires strong assumptions, such as non-slip\nsteering, or complex vehicle dynamics models that do not hold under varying\nenvironmental conditions like slippery surfaces. We introduce an approach to\nvelocity estimation that is decoupled from wheel-to-surface traction\nassumptions by leveraging planar kinematics in combination with optical flow\nfrom event cameras pointed perpendicularly at the ground. The asynchronous\nmicro-second latency and high dynamic range of event cameras make them highly\nrobust to motion blur, a common challenge in vision-based perception techniques\nfor autonomous driving. The proposed method is evaluated through in-field\nexperiments on a 1:10 scale autonomous racing platform and compared to precise\nmotion capture data, demonstrating not only performance on par with the\nstate-of-the-art Event-VIO method but also a 38.3 % improvement in lateral\nerror. Qualitative experiments at highway speeds of up to 32 m/s further\nconfirm the effectiveness of our approach, indicating significant potential for\nreal-world deployment.", "AI": {"tldr": "A novel velocity estimation method for mobile robotics uses event cameras and planar kinematics, improving accuracy and robustness over traditional wheel-IMU fusion, especially in challenging conditions.", "motivation": "Traditional velocity estimation methods rely on wheel-IMU fusion, which fails under varying environmental conditions like slippery surfaces. A more robust solution is needed.", "method": "The approach combines planar kinematics with optical flow from event cameras pointed at the ground, leveraging their low latency and high dynamic range to avoid motion blur.", "result": "Experiments show the method matches state-of-the-art Event-VIO and improves lateral error by 38.3%, with effectiveness confirmed at highway speeds.", "conclusion": "The method is promising for real-world deployment in autonomous driving, offering robustness and accuracy without relying on traction assumptions."}}
{"id": "2505.11449", "pdf": "https://arxiv.org/pdf/2505.11449", "abs": "https://arxiv.org/abs/2505.11449", "authors": ["Nicholas Carlini", "Milad Nasr", "Edoardo Debenedetti", "Barry Wang", "Christopher A. Choquette-Choo", "Daphne Ippolito", "Florian Tram\u00e8r", "Matthew Jagielski"], "title": "LLMs unlock new paths to monetizing exploits", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "We argue that Large language models (LLMs) will soon alter the economics of\ncyberattacks. Instead of attacking the most commonly used software and\nmonetizing exploits by targeting the lowest common denominator among victims,\nLLMs enable adversaries to launch tailored attacks on a user-by-user basis. On\nthe exploitation front, instead of human attackers manually searching for one\ndifficult-to-identify bug in a product with millions of users, LLMs can find\nthousands of easy-to-identify bugs in products with thousands of users. And on\nthe monetization front, instead of generic ransomware that always performs the\nsame attack (encrypt all your data and request payment to decrypt), an\nLLM-driven ransomware attack could tailor the ransom demand based on the\nparticular content of each exploited device.\n  We show that these two attacks (and several others) are imminently practical\nusing state-of-the-art LLMs. For example, we show that without any human\nintervention, an LLM finds highly sensitive personal information in the Enron\nemail dataset (e.g., an executive having an affair with another employee) that\ncould be used for blackmail. While some of our attacks are still too expensive\nto scale widely today, the incentives to implement these attacks will only\nincrease as LLMs get cheaper. Thus, we argue that LLMs create a need for new\ndefense-in-depth approaches.", "AI": {"tldr": "LLMs will soon change cyberattack economics by enabling tailored, scalable attacks, making defenses more urgent.", "motivation": "To highlight how LLMs can transform cyberattacks by enabling personalized, large-scale exploits and monetization.", "method": "Demonstrates practical LLM-driven attacks, like extracting sensitive data for blackmail, without human intervention.", "result": "LLMs can already execute attacks like data extraction; costs will decrease, increasing attack incentives.", "conclusion": "New defense-in-depth approaches are needed to counter the evolving threat of LLM-driven cyberattacks."}}
{"id": "2501.03266", "pdf": "https://arxiv.org/pdf/2501.03266", "abs": "https://arxiv.org/abs/2501.03266", "authors": ["Stefan Pasch"], "title": "LLM Content Moderation and User Satisfaction: Evidence from Response Refusals in Chatbot Arena", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.SI"], "comment": null, "summary": "LLM safety and ethical alignment are widely discussed, but the impact of\ncontent moderation on user satisfaction remains underexplored. In particular,\nlittle is known about how users respond when models refuse to answer a\nprompt-one of the primary mechanisms used to enforce ethical boundaries in\nLLMs. We address this gap by analyzing nearly 50,000 model comparisons from\nChatbot Arena, a platform where users indicate their preferred LLM response in\npairwise matchups, providing a large-scale setting for studying real-world user\npreferences. Using a novel RoBERTa-based refusal classifier fine-tuned on a\nhand-labeled dataset, we distinguish between refusals due to ethical concerns\nand technical limitations. Our results reveal a substantial refusal penalty:\nethical refusals yield significantly lower win rates than both technical\nrefusals and standard responses, indicating that users are especially\ndissatisfied when models decline a task for ethical reasons. However, this\npenalty is not uniform. Refusals receive more favorable evaluations when the\nunderlying prompt is highly sensitive (e.g., involving illegal content), and\nwhen the refusal is phrased in a detailed and contextually aligned manner.\nThese findings underscore a core tension in LLM design: safety-aligned\nbehaviors may conflict with user expectations, calling for more adaptive\nmoderation strategies that account for context and presentation.", "AI": {"tldr": "The study explores user dissatisfaction with LLM refusals, finding ethical refusals penalize satisfaction more than technical ones, but context and phrasing can mitigate this.", "motivation": "To understand how users react when LLMs refuse prompts, especially for ethical reasons, and the impact on satisfaction.", "method": "Analyzed 50,000 model comparisons from Chatbot Arena, using a RoBERTa-based classifier to distinguish ethical from technical refusals.", "result": "Ethical refusals have lower win rates than technical refusals or standard responses, but sensitivity and phrasing improve evaluations.", "conclusion": "Safety-aligned behaviors may clash with user expectations, suggesting adaptive moderation strategies are needed."}}
{"id": "2505.11239", "pdf": "https://arxiv.org/pdf/2505.11239", "abs": "https://arxiv.org/abs/2505.11239", "authors": ["Wilson Wongso", "Hao Xue", "Flora D. Salim"], "title": "Massive-STEPS: Massive Semantic Trajectories for Understanding POI Check-ins -- Dataset and Benchmarks", "categories": ["cs.LG"], "comment": null, "summary": "Understanding human mobility through Point-of-Interest (POI) recommendation\nis increasingly important for applications such as urban planning, personalized\nservices, and generative agent simulation. However, progress in this field is\nhindered by two key challenges: the over-reliance on older datasets from\n2012-2013 and the lack of reproducible, city-level check-in datasets that\nreflect diverse global regions. To address these gaps, we present Massive-STEPS\n(Massive Semantic Trajectories for Understanding POI Check-ins), a large-scale,\npublicly available benchmark dataset built upon the Semantic Trails dataset and\nenriched with semantic POI metadata. Massive-STEPS spans 12 geographically and\nculturally diverse cities and features more recent (2017-2018) and\nlonger-duration (24 months) check-in data than prior datasets. We benchmarked a\nwide range of POI recommendation models on Massive-STEPS using both supervised\nand zero-shot approaches, and evaluated their performance across multiple urban\ncontexts. By releasing Massive-STEPS, we aim to facilitate reproducible and\nequitable research in human mobility and POI recommendation. The dataset and\nbenchmarking code are available at:\nhttps://github.com/cruiseresearchgroup/Massive-STEPS", "AI": {"tldr": "The paper introduces Massive-STEPS, a large-scale, diverse POI dataset to address gaps in outdated and non-reproducible data for human mobility research.", "motivation": "Overcoming reliance on old datasets and lack of diverse, reproducible city-level check-in data for POI recommendation research.", "method": "Created Massive-STEPS, a benchmark dataset with semantic POI metadata from 12 diverse cities (2017-2018 data). Evaluated POI models using supervised and zero-shot approaches.", "result": "Provided a modern, longer-duration dataset enabling reproducible research. Benchmarked models across urban contexts.", "conclusion": "Massive-STEPS facilitates equitable, reproducible research in human mobility and POI recommendation."}}
{"id": "2505.11142", "pdf": "https://arxiv.org/pdf/2505.11142", "abs": "https://arxiv.org/abs/2505.11142", "authors": ["Guido Caccianiga", "Yarden Sharon", "Bernard Javot", "Senya Polikovsky", "G\u00f6kce Erg\u00fcn", "Ivan Capobianco", "Andr\u00e9 L. Mihaljevic", "Anton Deguet", "Katherine J. Kuchenbecker"], "title": "Open-Source Multi-Viewpoint Surgical Telerobotics", "categories": ["cs.RO", "cs.CV"], "comment": "2 pages, 2 figures, ICRA-RAMI workshop long abstract", "summary": "As robots for minimally invasive surgery (MIS) gradually become more\naccessible and modular, we believe there is a great opportunity to rethink and\nexpand the visualization and control paradigms that have characterized surgical\nteleoperation since its inception. We conjecture that introducing one or more\nadditional adjustable viewpoints in the abdominal cavity would not only unlock\nnovel visualization and collaboration strategies for surgeons but also\nsubstantially boost the robustness of machine perception toward shared\nautonomy. Immediate advantages include controlling a second viewpoint and\nteleoperating surgical tools from a different perspective, which would allow\ncollaborating surgeons to adjust their views independently and still maneuver\ntheir robotic instruments intuitively. Furthermore, we believe that capturing\nsynchronized multi-view 3D measurements of the patient's anatomy would unlock\nadvanced scene representations. Accurate real-time intraoperative 3D perception\nwill allow algorithmic assistants to directly control one or more robotic\ninstruments and/or robotic cameras. Toward these goals, we are building a\nsynchronized multi-viewpoint, multi-sensor robotic surgery system by\nintegrating high-performance vision components and upgrading the da Vinci\nResearch Kit control logic. This short paper reports a functional summary of\nour setup and elaborates on its potential impacts in research and future\nclinical practice. By fully open-sourcing our system, we will enable the\nresearch community to reproduce our setup, improve it, and develop powerful\nalgorithms, effectively boosting clinical translation of cutting-edge research.", "AI": {"tldr": "The paper proposes expanding surgical teleoperation by introducing adjustable viewpoints in MIS to enhance visualization, collaboration, and machine perception for shared autonomy.", "motivation": "To rethink and improve surgical teleoperation by leveraging additional viewpoints and advanced 3D perception for better collaboration and autonomy.", "method": "Building a synchronized multi-viewpoint, multi-sensor robotic surgery system using high-performance vision and upgraded control logic.", "result": "A functional setup is reported, with potential to boost research and clinical translation through open-sourcing.", "conclusion": "The system aims to advance surgical robotics by enabling better visualization, collaboration, and algorithmic assistance, with open-source contributions fostering further innovation."}}
{"id": "2406.11061", "pdf": "https://arxiv.org/pdf/2406.11061", "abs": "https://arxiv.org/abs/2406.11061", "authors": ["Miko\u0142aj Ma\u0142ki\u0144ski", "Jacek Ma\u0144dziuk"], "title": "A-I-RAVEN and I-RAVEN-Mesh: Two New Benchmarks for Abstract Visual Reasoning", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted to the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)", "summary": "We study generalization and knowledge reuse capabilities of deep neural\nnetworks in the domain of abstract visual reasoning (AVR), employing Raven's\nProgressive Matrices (RPMs), a recognized benchmark task for assessing AVR\nabilities. Two knowledge transfer scenarios referring to the I-RAVEN dataset\nare investigated. Firstly, inspired by generalization assessment capabilities\nof the PGM dataset and popularity of I-RAVEN, we introduce\nAttributeless-I-RAVEN (A-I-RAVEN), a benchmark with 10 generalization regimes\nthat allow to systematically test generalization of abstract rules applied to\nheld-out attributes at various levels of complexity (primary and extended\nregimes). In contrast to PGM, A-I-RAVEN features compositionality, a variety of\nfigure configurations, and does not require substantial computational\nresources. Secondly, we construct I-RAVEN-Mesh, a dataset that enriches RPMs\nwith a novel component structure comprising line-based patterns, facilitating\nassessment of progressive knowledge acquisition in transfer learning setting.\nWe evaluate 13 strong models from the AVR literature on the introduced\ndatasets, revealing their specific shortcomings in generalization and knowledge\ntransfer.", "AI": {"tldr": "The paper introduces two datasets (A-I-RAVEN and I-RAVEN-Mesh) to test generalization and knowledge transfer in deep neural networks for abstract visual reasoning, revealing model shortcomings.", "motivation": "To assess generalization and knowledge reuse in deep neural networks for abstract visual reasoning, using RPMs as a benchmark.", "method": "Introduces A-I-RAVEN for systematic generalization testing and I-RAVEN-Mesh for progressive knowledge transfer evaluation, testing 13 models.", "result": "Identifies specific shortcomings in generalization and knowledge transfer among the evaluated models.", "conclusion": "The new datasets provide robust tools for assessing AVR capabilities, highlighting areas for model improvement."}}
{"id": "2501.04987", "pdf": "https://arxiv.org/pdf/2501.04987", "abs": "https://arxiv.org/abs/2501.04987", "authors": ["Ziwei He", "Jian Yuan", "Haoli Bai", "Jingwen Leng", "Bo Jiang"], "title": "TreeKV: Smooth Key-Value Cache Compression with Tree Structures", "categories": ["cs.CL"], "comment": null, "summary": "Efficient key-value (KV) cache compression is critical for scaling\ntransformer-based Large Language Models (LLMs) in long sequences and\nresource-limited settings. Existing methods evict tokens based on their\npositions or importance scores, but position-based strategies can miss crucial\ninformation outside predefined regions, while those relying on global\nimportance scores resulting in strong regional biases, limiting the KV cache's\noverall context retention and potentially impairing the performance of LLMs on\ncomplex tasks. Our wavelet analysis reveals that as tokens approach the end of\nsequence, their contributions to generation gradually increase and tends to\ndiverge more from neighboring tokens, indicating a smooth transition with\nincreasing complexity and variability from distant to nearby context. Motivated\nby this observation, we propose TreeKV, an intuitive, training-free method that\nemploys a tree structure for smooth cache compression. TreeKV maintains a fixed\ncache size, allowing LLMs to deliver high-quality output even in long text\nscenarios. Unlike most compression methods, TreeKV is applicable to both the\ngeneration and prefilling stages. TreeKV consistently surpasses all baseline\nmodels in language modeling tasks on PG19 and OpenWebText2, allowing LLMs\ntrained with short context window to generalize to longer window with a 16x\ncache reduction. On the Longbench benchmark, TreeKV achieves the best\nperformance with only 6\\% of the budget at optimal efficiency.", "AI": {"tldr": "TreeKV is a training-free method for efficient KV cache compression in LLMs, using a tree structure to maintain context quality in long sequences, outperforming baselines with significant cache reduction.", "motivation": "Existing KV cache compression methods suffer from regional biases or miss crucial information, limiting LLM performance in long sequences. Wavelet analysis shows tokens near sequence ends contribute more, inspiring TreeKV.", "method": "TreeKV employs a tree structure for smooth cache compression, maintaining a fixed cache size and working in both generation and prefilling stages.", "result": "TreeKV outperforms baselines on PG19, OpenWebText2, and Longbench, achieving high performance with 16x cache reduction and 6% budget at optimal efficiency.", "conclusion": "TreeKV is an effective, intuitive solution for KV cache compression, enabling LLMs to handle long sequences efficiently without training."}}
{"id": "2505.11250", "pdf": "https://arxiv.org/pdf/2505.11250", "abs": "https://arxiv.org/abs/2505.11250", "authors": ["Xvyuan Liu", "Xiangfei Qiu", "Xingjian Wu", "Zhengyu Li", "Chenjuan Guo", "Jilin Hu", "Bin Yang"], "title": "Rethinking Irregular Time Series Forecasting: A Simple yet Effective Baseline", "categories": ["cs.LG"], "comment": null, "summary": "The forecasting of irregular multivariate time series (IMTS) is crucial in\nkey areas such as healthcare, biomechanics, climate science, and astronomy.\nHowever, achieving accurate and practical predictions is challenging due to two\nmain factors. First, the inherent irregularity and data missingness in\nirregular time series make modeling difficult. Second, most existing methods\nare typically complex and resource-intensive. In this study, we propose a\ngeneral framework called APN to address these challenges. Specifically, we\ndesign a novel Time-Aware Patch Aggregation (TAPA) module that achieves\nadaptive patching. By learning dynamically adjustable patch boundaries and a\ntime-aware weighted averaging strategy, TAPA transforms the original irregular\nsequences into high-quality, regularized representations in a\nchannel-independent manner. Additionally, we use a simple query module to\neffectively integrate historical information while maintaining the model's\nefficiency. Finally, predictions are made by a shallow MLP. Experimental\nresults on multiple real-world datasets show that APN outperforms existing\nstate-of-the-art methods in both efficiency and accuracy.", "AI": {"tldr": "APN framework improves forecasting of irregular multivariate time series (IMTS) with adaptive patching and efficient querying, outperforming existing methods.", "motivation": "Challenges in IMTS forecasting include irregularity, missing data, and complex existing methods. APN aims to simplify and improve accuracy.", "method": "Proposes APN with Time-Aware Patch Aggregation (TAPA) for adaptive patching and a query module for efficient historical integration, using a shallow MLP for predictions.", "result": "APN outperforms state-of-the-art methods in efficiency and accuracy across multiple datasets.", "conclusion": "APN provides a practical and accurate solution for IMTS forecasting, addressing key challenges with a simple yet effective framework."}}
{"id": "2505.11278", "pdf": "https://arxiv.org/pdf/2505.11278", "abs": "https://arxiv.org/abs/2505.11278", "authors": ["Fabian Falck", "Teodora Pandeva", "Kiarash Zahirnia", "Rachel Lawrence", "Richard Turner", "Edward Meeds", "Javier Zazo", "Sushrut Karmalkar"], "title": "A Fourier Space Perspective on Diffusion Models", "categories": ["stat.ML", "cs.CV", "cs.LG", "stat.ME"], "comment": null, "summary": "Diffusion models are state-of-the-art generative models on data modalities\nsuch as images, audio, proteins and materials. These modalities share the\nproperty of exponentially decaying variance and magnitude in the Fourier\ndomain. Under the standard Denoising Diffusion Probabilistic Models (DDPM)\nforward process of additive white noise, this property results in\nhigh-frequency components being corrupted faster and earlier in terms of their\nSignal-to-Noise Ratio (SNR) than low-frequency ones. The reverse process then\ngenerates low-frequency information before high-frequency details. In this\nwork, we study the inductive bias of the forward process of diffusion models in\nFourier space. We theoretically analyse and empirically demonstrate that the\nfaster noising of high-frequency components in DDPM results in violations of\nthe normality assumption in the reverse process. Our experiments show that this\nleads to degraded generation quality of high-frequency components. We then\nstudy an alternate forward process in Fourier space which corrupts all\nfrequencies at the same rate, removing the typical frequency hierarchy during\ngeneration, and demonstrate marked performance improvements on datasets where\nhigh frequencies are primary, while performing on par with DDPM on standard\nimaging benchmarks.", "AI": {"tldr": "Diffusion models' forward process in Fourier space biases high-frequency corruption, degrading generation quality. An alternate process equalizing corruption rates improves performance for high-frequency data.", "motivation": "To analyze the inductive bias of diffusion models' forward process in Fourier space and address degraded high-frequency generation quality.", "method": "Theoretical analysis and empirical demonstration of DDPM's frequency hierarchy, followed by proposing an alternate forward process in Fourier space.", "result": "The alternate process improves generation quality for high-frequency data while matching DDPM on standard benchmarks.", "conclusion": "Equalizing frequency corruption rates in diffusion models enhances performance for high-frequency data without compromising standard tasks."}}
{"id": "2409.07578", "pdf": "https://arxiv.org/pdf/2409.07578", "abs": "https://arxiv.org/abs/2409.07578", "authors": ["B. Sankar", "Dibakar Sen"], "title": "A Novel Mathematical Framework for Objective Characterization of Ideas", "categories": ["cs.AI", "53A45", "I.2.7; G.3"], "comment": "35 pages, 18 figures, 6 tables", "summary": "The demand for innovation in product design necessitates a prolific ideation\nphase. Conversational AI (CAI) systems that use Large Language Models (LLMs)\nsuch as GPT (Generative Pre-trained Transformer) have been shown to be fruitful\nin augmenting human creativity, providing numerous novel and diverse ideas.\nDespite the success in ideation quantity, the qualitative assessment of these\nideas remains challenging and traditionally reliant on expert human evaluation.\nThis method suffers from limitations such as human judgment errors, bias, and\noversight. Addressing this gap, our study introduces a comprehensive\nmathematical framework for automated analysis to objectively evaluate the\nplethora of ideas generated by CAI systems and/or humans. This framework is\nparticularly advantageous for novice designers who lack experience in selecting\npromising ideas. By converting the ideas into higher dimensional vectors and\nquantitatively measuring the diversity between them using tools such as UMAP,\nDBSCAN and PCA, the proposed method provides a reliable and objective way of\nselecting the most promising ideas, thereby enhancing the efficiency of the\nideation phase.", "AI": {"tldr": "A mathematical framework automates the evaluation of ideas from conversational AI or humans, aiding novice designers by objectively measuring diversity and selecting promising ideas.", "motivation": "The need for objective, automated evaluation of ideas generated by CAI or humans, addressing human judgment limitations like bias and oversight.", "method": "Converts ideas into higher-dimensional vectors and uses tools like UMAP, DBSCAN, and PCA to quantitatively measure diversity and select promising ideas.", "result": "Provides a reliable, objective method for idea selection, enhancing ideation efficiency.", "conclusion": "The framework improves the ideation phase by offering an automated, unbiased way to evaluate and select ideas."}}
{"id": "2501.10316", "pdf": "https://arxiv.org/pdf/2501.10316", "abs": "https://arxiv.org/abs/2501.10316", "authors": ["Suvodip Dey", "Yi-Jyun Sun", "Gokhan Tur", "Dilek Hakkani-Tur"], "title": "Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025 Main Conference", "summary": "Recent LLMs have enabled significant advancements for conversational agents.\nHowever, they are also well known to hallucinate, producing responses that seem\nplausible but are factually incorrect. On the other hand, users tend to\nover-rely on LLM-based AI agents, accepting AI's suggestion even when it is\nwrong. Adding positive friction, such as explanations or getting user\nconfirmations, has been proposed as a mitigation in AI-supported\ndecision-making systems. In this paper, we propose an accountability model for\nLLM-based task-oriented dialogue agents to address user overreliance via\nfriction turns in cases of model uncertainty and errors associated with\ndialogue state tracking (DST). The accountability model is an augmented LLM\nwith an additional accountability head that functions as a binary classifier to\npredict the relevant slots of the dialogue state mentioned in the conversation.\nWe perform our experiments with multiple backbone LLMs on two established\nbenchmarks (MultiWOZ and Snips). Our empirical findings demonstrate that the\nproposed approach not only enables reliable estimation of AI agent errors but\nalso guides the decoder in generating more accurate actions. We observe around\n3% absolute improvement in joint goal accuracy (JGA) of DST output by\nincorporating accountability heads into modern LLMs. Self-correcting the\ndetected errors further increases the JGA from 67.13 to 70.51, achieving\nstate-of-the-art DST performance. Finally, we show that error correction\nthrough user confirmations (friction turn) achieves a similar performance gain,\nhighlighting its potential to reduce user overreliance.", "AI": {"tldr": "The paper proposes an accountability model for LLM-based task-oriented dialogue agents to reduce user overreliance by introducing friction turns during model uncertainty or errors, improving dialogue state tracking accuracy.", "motivation": "LLMs often hallucinate, leading users to over-rely on incorrect AI suggestions. The paper aims to mitigate this by adding accountability mechanisms.", "method": "An augmented LLM with an accountability head (binary classifier) predicts relevant dialogue state slots. Experiments use MultiWOZ and Snips benchmarks with multiple LLMs.", "result": "The model improves joint goal accuracy (JGA) by ~3%, with self-correction further boosting JGA to 70.51. User confirmations (friction turns) also enhance performance.", "conclusion": "The accountability model effectively reduces user overreliance and improves DST accuracy, achieving state-of-the-art results."}}
{"id": "2505.11254", "pdf": "https://arxiv.org/pdf/2505.11254", "abs": "https://arxiv.org/abs/2505.11254", "authors": ["Jeffrey Willette", "Heejun Lee", "Sung Ju Hwang"], "title": "Delta Attention: Fast and Accurate Sparse Attention Inference by Delta Correction", "categories": ["cs.LG"], "comment": null, "summary": "The attention mechanism of a transformer has a quadratic complexity, leading\nto high inference costs and latency for long sequences. However, attention\nmatrices are mostly sparse, which implies that many entries may be omitted from\ncomputation for efficient inference. Sparse attention inference methods aim to\nreduce this computational burden; however, they also come with a troublesome\nperformance degradation. We discover that one reason for this degradation is\nthat the sparse calculation induces a distributional shift in the attention\noutputs. The distributional shift causes decoding-time queries to fail to align\nwell with the appropriate keys from the prefill stage, leading to a drop in\nperformance. We propose a simple, novel, and effective procedure for correcting\nthis distributional shift, bringing the distribution of sparse attention\noutputs closer to that of quadratic attention. Our method can be applied on top\nof any sparse attention method, and results in an average 36%pt performance\nincrease, recovering 88% of quadratic attention accuracy on the 131K RULER\nbenchmark when applied on top of sliding window attention with sink tokens\nwhile only adding a small overhead. Our method can maintain approximately 98.5%\nsparsity over full quadratic attention, making our model 32 times faster than\nFlash Attention 2 when processing 1M token prefills.", "AI": {"tldr": "The paper addresses the performance degradation in sparse attention mechanisms due to distributional shift and proposes a method to correct it, improving accuracy while maintaining efficiency.", "motivation": "The quadratic complexity of transformer attention is costly for long sequences. Sparse attention reduces computation but suffers from performance degradation due to distributional shift.", "method": "The authors propose a novel procedure to correct the distributional shift in sparse attention outputs, aligning them closer to quadratic attention.", "result": "Their method improves performance by 36%pt, recovering 88% of quadratic attention accuracy on the RULER benchmark, while maintaining high sparsity (98.5%) and speed (32x faster than Flash Attention 2).", "conclusion": "The proposed method effectively mitigates the performance drop in sparse attention, offering a practical solution for efficient long-sequence processing."}}
{"id": "2505.11467", "pdf": "https://arxiv.org/pdf/2505.11467", "abs": "https://arxiv.org/abs/2505.11467", "authors": ["Abhishek Kashyap", "Henrik Andreasson", "Todor Stoyanov"], "title": "Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views", "categories": ["cs.RO", "cs.CV"], "comment": "6 pages", "summary": "Vision based robot manipulation uses cameras to capture one or more images of\na scene containing the objects to be manipulated. Taking multiple images can\nhelp if any object is occluded from one viewpoint but more visible from another\nviewpoint. However, the camera has to be moved to a sequence of suitable\npositions for capturing multiple images, which requires time and may not always\nbe possible, due to reachability constraints. So while additional images can\nproduce more accurate grasp poses due to the extra information available, the\ntime-cost goes up with the number of additional views sampled. Scene\nrepresentations like Gaussian Splatting are capable of rendering accurate\nphotorealistic virtual images from user-specified novel viewpoints. In this\nwork, we show initial results which indicate that novel view synthesis can\nprovide additional context in generating grasp poses. Our experiments on the\nGraspnet-1billion dataset show that novel views contributed force-closure\ngrasps in addition to the force-closure grasps obtained from sparsely sampled\nreal views while also improving grasp coverage. In the future we hope this work\ncan be extended to improve grasp extraction from radiance fields constructed\nwith a single input image, using for example diffusion models or generalizable\nradiance fields.", "AI": {"tldr": "Using novel view synthesis (e.g., Gaussian Splatting) improves grasp pose accuracy and coverage in vision-based robot manipulation by generating additional context from virtual viewpoints.", "motivation": "Multiple real images improve grasp accuracy but are time-consuming and constrained by reachability. Novel view synthesis offers a solution by generating additional virtual views.", "method": "Leveraging scene representations like Gaussian Splatting to synthesize novel views for grasp pose generation, tested on the Graspnet-1billion dataset.", "result": "Novel views added force-closure grasps and improved grasp coverage compared to sparse real views.", "conclusion": "Novel view synthesis enhances grasp extraction; future work aims to extend this to single-image radiance fields using diffusion models or generalizable radiance fields."}}
{"id": "2410.11507", "pdf": "https://arxiv.org/pdf/2410.11507", "abs": "https://arxiv.org/abs/2410.11507", "authors": ["Wanying Wang", "Zeyu Ma", "Pengfei Liu", "Mingang Chen"], "title": "TestAgent: A Framework for Domain-Adaptive Evaluation of LLMs via Dynamic Benchmark Construction and Exploratory Interaction", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed to various vertical\ndomains, automatically evaluating their performance across different domains\nremains a critical challenge. Current evaluation methods often rely on static\nand resource-intensive datasets that are not aligned with real-world\nrequirements and lack cross-domain adaptability. To address these limitations,\nwe revisit the evaluation process and introduce two key concepts:\n\\textbf{Benchmark+}, which extends the traditional question-answer benchmark\ninto a more flexible ``strategy-criterion'' format; and \\textbf{Assessment+},\nwhich enhances the interaction process to facilitate deeper exploration and\ncomprehensive analysis from multiple perspectives. We propose\n\\textbf{\\textsc{TestAgent}}, an agent-based evaluation framework that\nimplements these concepts using retrieval-augmented generation and\nreinforcement learning. \\textsc{TestAgent} enables automatic dynamic benchmark\ngeneration and in-depth assessment across diverse vertical domains. Experiments\non tasks ranging from constructing multiple vertical domain evaluations to\ntransforming static benchmarks into dynamic forms demonstrate the effectiveness\nof \\textsc{TestAgent}. This work provides a novel perspective on automatic\nevaluation methods for domain-specific LLMs, offering a pathway for\ndomain-adaptive dynamic benchmark construction and exploratory assessment.", "AI": {"tldr": "The paper introduces \u201cTestAgent,\u201d an agent-based framework for dynamic evaluation of LLMs across domains, using Benchmark+ and Assessment+ concepts for flexible and comprehensive assessment.", "motivation": "Current LLM evaluation methods are static, resource-heavy, and lack cross-domain adaptability, limiting real-world applicability.", "method": "Proposes \u201cTestAgent\u201d with Benchmark+ (flexible strategy-criterion format) and Assessment+ (enhanced interaction), leveraging retrieval-augmented generation and reinforcement learning.", "result": "Experiments show TestAgent\u2019s effectiveness in dynamic benchmark generation and cross-domain evaluation.", "conclusion": "TestAgent offers a novel approach for domain-adaptive LLM evaluation, enabling dynamic benchmarks and exploratory assessment."}}
{"id": "2501.11885", "pdf": "https://arxiv.org/pdf/2501.11885", "abs": "https://arxiv.org/abs/2501.11885", "authors": ["Keer Lu", "Zheng Liang", "Zhuoran Zhang", "Da Pan", "Shusen Zhang", "Xin Wu", "Zenan Zhou", "Guosheng Dong", "Bin Cui", "Tengjiao Wang", "Wentao Zhang"], "title": "Med-R$^2$: Crafting Trustworthy LLM Physicians via Retrieval and Reasoning of Evidence-Based Medicine", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have exhibited remarkable capabilities in\nclinical scenarios. Despite their potential, existing works face challenges\nwhen applying LLMs to medical settings. Strategies relying on training with\nmedical datasets are highly cost-intensive and may suffer from outdated\ntraining data. Leveraging external knowledge bases is a suitable alternative,\nyet it faces obstacles such as limited retrieval precision and poor\neffectiveness in answer extraction. These issues collectively prevent LLMs from\ndemonstrating the expected level of proficiency in mastering medical expertise.\nTo address these challenges, we introduce Med-R^2, a novel LLM physician\nframework that adheres to the Evidence-Based Medicine (EBM) process,\nefficiently integrating retrieval mechanisms as well as the selection and\nreasoning processes of evidence, thereby enhancing the problem-solving\ncapabilities of LLMs in healthcare scenarios and fostering a trustworthy LLM\nphysician. Our comprehensive experiments indicate that Med-R^2 achieves a\n14.74\\% improvement over vanilla RAG methods and even a 3.32\\% enhancement\ncompared to fine-tuning strategies, without incurring additional training\ncosts.", "AI": {"tldr": "Med-R^2 is a novel LLM framework for healthcare, integrating retrieval and reasoning to outperform traditional methods without extra training costs.", "motivation": "Existing LLMs in medical settings face high costs, outdated data, and poor retrieval precision, limiting their effectiveness.", "method": "Med-R^2 follows the Evidence-Based Medicine process, combining retrieval, evidence selection, and reasoning.", "result": "Med-R^2 improves performance by 14.74% over RAG and 3.32% over fine-tuning, without added costs.", "conclusion": "Med-R^2 enhances LLM proficiency in healthcare, offering a cost-effective and trustworthy solution."}}
{"id": "2505.11261", "pdf": "https://arxiv.org/pdf/2505.11261", "abs": "https://arxiv.org/abs/2505.11261", "authors": ["Jingyang Li", "Jiuqian Shang", "Yang Chen"], "title": "Fourier Low-rank and Sparse Tensor for Efficient Tensor Completion", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "Tensor completion is crucial in many scientific domains with missing data\nproblems. Traditional low-rank tensor models, including CP, Tucker, and\nTensor-Train, exploit low-dimensional structures to recover missing data.\nHowever, these methods often treat all tensor modes symmetrically, failing to\ncapture the unique spatiotemporal patterns inherent in scientific data, where\nthe temporal component exhibits both low-frequency stability and high-frequency\nvariations. To address this, we propose a novel model, \\underline{F}ourier\n\\underline{Lo}w-rank and \\underline{S}parse \\underline{T}ensor (FLoST), which\ndecomposes the tensor along the temporal dimension using a Fourier transform.\nThis approach captures low-frequency components with low-rank matrices and\nhigh-frequency fluctuations with sparsity, resulting in a hybrid structure that\nefficiently models both smooth and localized variations. Compared to the\nwell-known tubal-rank model, which assumes low-rankness across all frequency\ncomponents, FLoST requires significantly fewer parameters, making it\ncomputationally more efficient, particularly when the time dimension is large.\nThrough theoretical analysis and empirical experiments, we demonstrate that\nFLoST outperforms existing tensor completion models in terms of both accuracy\nand computational efficiency, offering a more interpretable solution for\nspatiotemporal data reconstruction.", "AI": {"tldr": "FLoST is a new tensor completion model using Fourier transform to separate low-frequency (low-rank) and high-frequency (sparse) temporal patterns, outperforming traditional methods in accuracy and efficiency.", "motivation": "Traditional tensor models treat all modes symmetrically, missing unique spatiotemporal patterns in scientific data, especially temporal variations.", "method": "FLoST decomposes the tensor temporally via Fourier transform, modeling low-frequency components with low-rank matrices and high-frequency fluctuations with sparsity.", "result": "FLoST is more accurate and computationally efficient than existing models, especially for large time dimensions.", "conclusion": "FLoST provides a superior, interpretable solution for spatiotemporal data reconstruction by effectively capturing both smooth and localized variations."}}
{"id": "2401.17207", "pdf": "https://arxiv.org/pdf/2401.17207", "abs": "https://arxiv.org/abs/2401.17207", "authors": ["Alexander Oberstrass", "Sascha E. A. Muenzing", "Meiqi Niu", "Nicola Palomero-Gallagher", "Christian Schiffer", "Markus Axer", "Katrin Amunts", "Timo Dickscheid"], "title": "Self-Supervised Representation Learning for Nerve Fiber Distribution Patterns in 3D-PLI", "categories": ["cs.CV"], "comment": "Journal version", "summary": "A comprehensive understanding of the organizational principles in the human\nbrain requires, among other factors, well-quantifiable descriptors of nerve\nfiber architecture. Three-dimensional polarized light imaging (3D-PLI) is a\nmicroscopic imaging technique that enables insights into the fine-grained\norganization of myelinated nerve fibers with high resolution. Descriptors\ncharacterizing the fiber architecture observed in 3D-PLI would enable\ndownstream analysis tasks such as multimodal correlation studies, clustering,\nand mapping. However, best practices for observer-independent characterization\nof fiber architecture in 3D-PLI are not yet available. To this end, we propose\nthe application of a fully data-driven approach to characterize nerve fiber\narchitecture in 3D-PLI images using self-supervised representation learning. We\nintroduce a 3D-Context Contrastive Learning (CL-3D) objective that utilizes the\nspatial neighborhood of texture examples across histological brain sections of\na 3D reconstructed volume to sample positive pairs for contrastive learning. We\ncombine this sampling strategy with specifically designed image augmentations\nto gain robustness to typical variations in 3D-PLI parameter maps. The approach\nis demonstrated for the 3D reconstructed occipital lobe of a vervet monkey\nbrain. We show that extracted features are highly sensitive to different\nconfigurations of nerve fibers, yet robust to variations between consecutive\nbrain sections arising from histological processing. We demonstrate their\npractical applicability for retrieving clusters of homogeneous fiber\narchitecture, performing classification with minimal annotations, and\nquery-based retrieval of characteristic components of fiber architecture such\nas U-fibers.", "AI": {"tldr": "The paper proposes a self-supervised learning method (CL-3D) to characterize nerve fiber architecture in 3D-PLI images, demonstrating its effectiveness for clustering, classification, and retrieval tasks.", "motivation": "Current methods lack observer-independent descriptors for nerve fiber architecture in 3D-PLI, hindering downstream analysis.", "method": "A 3D-Context Contrastive Learning (CL-3D) objective is introduced, leveraging spatial neighborhoods and image augmentations for robust feature extraction.", "result": "Features extracted are sensitive to fiber configurations but robust to histological variations, enabling clustering, classification, and retrieval tasks.", "conclusion": "The CL-3D method provides a practical, data-driven solution for analyzing nerve fiber architecture in 3D-PLI images."}}
{"id": "2410.19315", "pdf": "https://arxiv.org/pdf/2410.19315", "abs": "https://arxiv.org/abs/2410.19315", "authors": ["Hadi Vafaii", "Dekel Galor", "Jacob L. Yates"], "title": "Brain-like variational inference", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Inference in both brains and machines can be formalized by optimizing a\nshared objective: maximizing the evidence lower bound (ELBO) in machine\nlearning, or minimizing variational free energy (F) in neuroscience (ELBO =\n-F). While this equivalence suggests a unifying framework, it leaves open how\ninference is implemented in neural systems. Here, we show that online natural\ngradient descent on F, under Poisson assumptions, leads to a recurrent spiking\nneural network that performs variational inference via membrane potential\ndynamics. The resulting model -- the iterative Poisson variational autoencoder\n(iP-VAE) -- replaces the encoder network with local updates derived from\nnatural gradient descent on F. Theoretically, iP-VAE yields a number of\ndesirable features such as emergent normalization via lateral competition, and\nhardware-efficient integer spike count representations. Empirically, iP-VAE\noutperforms both standard VAEs and Gaussian-based predictive coding models in\nsparsity, reconstruction, and biological plausibility. iP-VAE also exhibits\nstrong generalization to out-of-distribution inputs, exceeding hybrid\niterative-amortized VAEs. These results demonstrate how deriving inference\nalgorithms from first principles can yield concrete architectures that are\nsimultaneously biologically plausible and empirically effective.", "AI": {"tldr": "The paper introduces iP-VAE, a spiking neural network model for variational inference, derived from natural gradient descent on variational free energy. It outperforms standard VAEs and predictive coding models in sparsity, reconstruction, and biological plausibility.", "motivation": "To bridge the gap between theoretical equivalence of inference in brains and machines (via ELBO and variational free energy) and its neural implementation.", "method": "Online natural gradient descent on variational free energy under Poisson assumptions, leading to the iP-VAE model with local updates and spiking dynamics.", "result": "iP-VAE shows emergent normalization, hardware-efficient spike counts, and outperforms standard VAEs and predictive coding models in sparsity, reconstruction, and generalization.", "conclusion": "Deriving inference algorithms from first principles yields biologically plausible and effective architectures, as demonstrated by iP-VAE."}}
{"id": "2501.13977", "pdf": "https://arxiv.org/pdf/2501.13977", "abs": "https://arxiv.org/abs/2501.13977", "authors": ["Rajvardhan Oak", "Muhammad Haroon", "Claire Jo", "Magdalena Wojcieszak", "Anshuman Chhabra"], "title": "Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Social media platforms utilize Machine Learning (ML) and Artificial\nIntelligence (AI) powered recommendation algorithms to maximize user\nengagement, which can result in inadvertent exposure to harmful content.\nCurrent moderation efforts, reliant on classifiers trained with extensive\nhuman-annotated data, struggle with scalability and adapting to new forms of\nharm. To address these challenges, we propose a novel re-ranking approach using\nLarge Language Models (LLMs) in zero-shot and few-shot settings. Our method\ndynamically assesses and re-ranks content sequences, effectively mitigating\nharmful content exposure without requiring extensive labeled data. Alongside\ntraditional ranking metrics, we also introduce two new metrics to evaluate the\neffectiveness of re-ranking in reducing exposure to harmful content. Through\nexperiments on three datasets, three models and across three configurations, we\ndemonstrate that our LLM-based approach significantly outperforms existing\nproprietary moderation approaches, offering a scalable and adaptable solution\nfor harm mitigation.", "AI": {"tldr": "A novel LLM-based re-ranking method reduces harmful content exposure on social media without needing extensive labeled data, outperforming existing moderation approaches.", "motivation": "Current ML/AI moderation struggles with scalability and adapting to new harms due to reliance on human-annotated data.", "method": "Proposes a zero-shot and few-shot LLM-based re-ranking approach to dynamically assess and re-rank content sequences.", "result": "Outperforms proprietary moderation in experiments across datasets, models, and configurations.", "conclusion": "The LLM-based method offers a scalable, adaptable solution for mitigating harmful content exposure."}}
{"id": "2505.11269", "pdf": "https://arxiv.org/pdf/2505.11269", "abs": "https://arxiv.org/abs/2505.11269", "authors": ["Shengjia Chang", "Xianshuo Yue"], "title": "Driving Mechanisms and Forecasting of China's Pet Population-An ARIMA-RF-HW Hybrid Approach", "categories": ["cs.LG"], "comment": "10 pages, 6 figures, 7 tables", "summary": "This study proposes a dynamically weighted ARIMA-RF-HW hybrid model\nintegrating ARIMA for seasonality and trends, Random Forest for nonlinear\nfeatures, and Holt-Winters smoothing for seasonal adjustment to improve China's\npet population forecasting accuracy. Using 2005-2023 data with nine economic,\nsocial, and policy indicators (urban income, consumption, aging ratio, policy\nquantity, new veterinary drug approvals), data were preprocessed via Z-score\nnormalization and missing value imputation. The results show that key drivers\nof pet populations include urban income (19.48% for cats, 17.15% for dogs),\nconsumption (17.99% for cats), and policy quantity (13.33% for cats, 14.02% for\ndogs), with aging (12.81% for cats, 13.27% for dogs) and urbanization\namplifying the demand for pets. Forecasts show steady cat growth and\nfluctuating dog numbers, reflecting cats' adaptability to urban environments.\nThis research supports policymakers in optimizing pet health management and\nguides enterprises in developing differentiated services, advancing sustainable\nindustry growth.", "AI": {"tldr": "A hybrid ARIMA-RF-HW model improves pet population forecasting in China by combining ARIMA, Random Forest, and Holt-Winters methods, identifying key drivers like urban income and policy quantity.", "motivation": "To enhance the accuracy of pet population forecasting in China by integrating multiple models and analyzing economic, social, and policy indicators.", "method": "Proposes a dynamically weighted hybrid model (ARIMA-RF-HW) with data preprocessing (Z-score normalization, missing value imputation) using 2005-2023 data and nine indicators.", "result": "Key drivers include urban income, consumption, and policy quantity, with steady cat growth and fluctuating dog numbers. Aging and urbanization amplify pet demand.", "conclusion": "The model aids policymakers in pet health management and guides businesses in service development, promoting sustainable industry growth."}}
{"id": "2402.18134", "pdf": "https://arxiv.org/pdf/2402.18134", "abs": "https://arxiv.org/abs/2402.18134", "authors": ["Chu Zhou", "Minggui Teng", "Xinyu Zhou", "Chao Xu", "Imari Sato", "Boxin Shi"], "title": "Learning to Deblur Polarized Images", "categories": ["cs.CV"], "comment": "This version has been accepted for publication in IJCV. This arXiv\n  version corresponds to the final accepted manuscript", "summary": "A polarization camera can capture four linear polarized images with different\npolarizer angles in a single shot, which is useful in polarization-based vision\napplications since the degree of linear polarization (DoLP) and the angle of\nlinear polarization (AoLP) can be directly computed from the captured polarized\nimages. However, since the on-chip micro-polarizers block part of the light so\nthat the sensor often requires a longer exposure time, the captured polarized\nimages are prone to motion blur caused by camera shakes, leading to noticeable\ndegradation in the computed DoLP and AoLP. Deblurring methods for conventional\nimages often show degraded performance when handling the polarized images since\nthey only focus on deblurring without considering the polarization constraints.\nIn this paper, we propose a polarized image deblurring pipeline to solve the\nproblem in a polarization-aware manner by adopting a divide-and-conquer\nstrategy to explicitly decompose the problem into two less ill-posed\nsub-problems, and design a two-stage neural network to handle the two\nsub-problems respectively. Experimental results show that our method achieves\nstate-of-the-art performance on both synthetic and real-world images, and can\nimprove the performance of polarization-based vision applications such as image\ndehazing and reflection removal.", "AI": {"tldr": "A two-stage neural network pipeline for deblurring polarized images, improving DoLP and AoLP accuracy by addressing polarization constraints.", "motivation": "Polarization cameras suffer from motion blur due to longer exposure times, degrading DoLP and AoLP. Conventional deblurring methods ignore polarization constraints.", "method": "Divide-and-conquer strategy: decompose the problem into two sub-problems, addressed by a two-stage neural network.", "result": "State-of-the-art performance on synthetic and real-world images; enhances applications like dehazing and reflection removal.", "conclusion": "The proposed pipeline effectively deblurs polarized images while preserving polarization information, benefiting downstream vision tasks."}}
{"id": "2501.10114", "pdf": "https://arxiv.org/pdf/2501.10114", "abs": "https://arxiv.org/abs/2501.10114", "authors": ["Alan Chan", "Kevin Wei", "Sihao Huang", "Nitarshan Rajkumar", "Elija Perrier", "Seth Lazar", "Gillian K. Hadfield", "Markus Anderljung"], "title": "Infrastructure for AI Agents", "categories": ["cs.AI"], "comment": "Accepted to TMLR", "summary": "AI agents plan and execute interactions in open-ended environments. For\nexample, OpenAI's Operator can use a web browser to do product comparisons and\nbuy online goods. To facilitate beneficial interactions and mitigate harmful\nones, much research focuses on directly modifying agent behaviour. For example,\ndevelopers can train agents to follow user instructions. This focus on direct\nmodifications is useful, but insufficient. We will also need external protocols\nand systems that shape how agents interact with institutions and other actors.\nFor instance, agents will need more efficient protocols to communicate with\neach other and form agreements. In addition, attributing an agent's actions to\na particular human or other legal entity can help to establish trust, and also\ndisincentivize misuse. Given this motivation, we propose the concept of agent\ninfrastructure: technical systems and shared protocols external to agents that\nare designed to mediate and influence their interactions with and impacts on\ntheir environments. Just as the Internet relies on protocols like HTTPS, our\nwork argues that agent infrastructure will be similarly indispensable to\necosystems of agents. We identify three functions for agent infrastructure: 1)\nattributing actions, properties, and other information to specific agents,\ntheir users, or other actors; 2) shaping agents' interactions; and 3) detecting\nand remedying harmful actions from agents. We provide an incomplete catalog of\nresearch directions for such functions. For each direction, we include analysis\nof use cases, infrastructure adoption, relationships to existing (internet)\ninfrastructure, limitations, and open questions. Making progress on agent\ninfrastructure can prepare society for the adoption of more advanced agents.", "AI": {"tldr": "The paper proposes 'agent infrastructure'\u2014external systems and protocols to mediate AI agent interactions, focusing on attribution, interaction shaping, and harm detection.", "motivation": "Current focus on modifying agent behavior directly is insufficient; external protocols and systems are needed to manage interactions and impacts in open-ended environments.", "method": "Introduces the concept of agent infrastructure, outlining three key functions: attribution, interaction shaping, and harm detection. Provides a catalog of research directions for these functions.", "result": "Identifies gaps and open questions in agent infrastructure, emphasizing its necessity for ecosystems of advanced AI agents.", "conclusion": "Agent infrastructure is indispensable for managing AI agent interactions, akin to internet protocols, and requires further research to prepare society for advanced agents."}}
{"id": "2502.06604", "pdf": "https://arxiv.org/pdf/2502.06604", "abs": "https://arxiv.org/abs/2502.06604", "authors": ["Jinghan Ru", "Yuxin Xie", "Xianwei Zhuang", "Yuguo Yin", "Zhihui Guo", "Zhiming Liu", "Qianli Ren", "Yuexian Zou"], "title": "Do we really have to filter out random noise in pre-training data for language models?", "categories": ["cs.CL"], "comment": null, "summary": "Web-scale pre-training datasets are the cornerstone of LLMs' success.\nHowever, text data curated from the Internet inevitably contains random noise\ncaused by decoding errors or unregulated web content. In contrast to previous\nworks that focus on low quality or synthetic data, our study \\textbf{provides\nthe first systematic investigation of such random noise through a cohesive\n``What-Why-How'' framework.} Surprisingly, we observed that the resulting\nincrease in the loss of next-token prediction (NTP) was significantly lower\nthan the proportion of random noise even when the model was scaled up to 2.7B.\nWe provide a theoretical justification for this phenomenon, which also\nelucidates the success of multilingual models and can be applied to multimodal\nmodels. On the other hand, experiments show that the model's performance in\ndownstream tasks is not based solely on the NTP loss, which means that random\nnoise may result in degraded downstream performance. To address the potential\nadverse effects, we introduce a novel plug-and-play Local Gradient Matching\nloss, which explicitly enhances the denoising capability of the downstream task\nhead by aligning the gradient of normal and perturbed features without\nrequiring knowledge of the model's parameters. Additional experiments on 8\nlanguage and 14 vision benchmarks further validate its effectiveness.", "AI": {"tldr": "The paper investigates random noise in web-scale pre-training datasets for LLMs, revealing its minimal impact on next-token prediction loss but potential harm to downstream tasks. It introduces a Local Gradient Matching loss to mitigate adverse effects.", "motivation": "To understand the impact of random noise in pre-training datasets on LLMs, especially its unexpected minimal effect on next-token prediction loss and its potential degradation of downstream task performance.", "method": "A cohesive 'What-Why-How' framework is used to systematically study random noise. A novel Local Gradient Matching loss is introduced to enhance denoising capability for downstream tasks.", "result": "Random noise minimally affects next-token prediction loss even in large models (2.7B), but harms downstream performance. The proposed loss improves denoising without needing model parameters.", "conclusion": "Random noise in pre-training data has nuanced effects, requiring targeted solutions like Local Gradient Matching to preserve downstream task performance."}}
{"id": "2505.11276", "pdf": "https://arxiv.org/pdf/2505.11276", "abs": "https://arxiv.org/abs/2505.11276", "authors": ["Francesco Marchetti", "Edoardo Legnaro", "Sabrina Guastavino"], "title": "Multiclass threshold-based classification", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we introduce a threshold-based framework for multiclass\nclassification that generalizes the standard argmax rule. This is done by\nreplacing the probabilistic interpretation of softmax outputs with a geometric\none on the multidimensional simplex, where the classification depends on a\nmultidimensional threshold. This change of perspective enables for any trained\nclassification network an a posteriori optimization of the classification score\nby means of threshold tuning, as usually carried out in the binary setting.\nThis allows a further refinement of the prediction capability of any network.\nMoreover, this multidimensional threshold-based setting makes it possible to\ndefine score-oriented losses, which are based on the interpretation of the\nthreshold as a random variable. Our experiments show that the multidimensional\nthreshold tuning yields consistent performance improvements across various\nnetworks and datasets, and that the proposed multiclass score-oriented losses\nare competitive with standard loss functions, resembling the advantages\nobserved in the binary case.", "AI": {"tldr": "A threshold-based framework for multiclass classification replaces softmax's probabilistic interpretation with a geometric one, enabling a posteriori threshold tuning and score-oriented losses, improving performance.", "motivation": "To generalize the argmax rule in multiclass classification by introducing a geometric interpretation of softmax outputs, allowing threshold tuning and refined predictions.", "method": "Replaces softmax's probabilistic outputs with a geometric interpretation on the simplex, introduces multidimensional thresholds, and proposes score-oriented losses.", "result": "Multidimensional threshold tuning improves performance across networks and datasets; score-oriented losses compete with standard ones.", "conclusion": "The framework enhances multiclass classification by enabling threshold optimization and introducing competitive score-oriented losses."}}
{"id": "2403.01840", "pdf": "https://arxiv.org/pdf/2403.01840", "abs": "https://arxiv.org/abs/2403.01840", "authors": ["Qi Liu", "Yuxiao Wang", "Xinyu Jiang", "Wolin Liang", "Zhenao Wei", "Yu Lei", "Nan Zhuang", "Weiying Xue"], "title": "FreeA: Human-object Interaction Detection using Free Annotation Labels", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent human-object interaction (HOI) detection methods depend on extensively\nannotated image datasets, which require a significant amount of manpower. In\nthis paper, we propose a novel self-adaptive, language-driven HOI detection\nmethod, termed FreeA. This method leverages the adaptability of the text-image\nmodel to generate latent HOI labels without requiring manual annotation.\nSpecifically, FreeA aligns image features of human-object pairs with HOI text\ntemplates and employs a knowledge-based masking technique to decrease\nimprobable interactions. Furthermore, FreeA implements a proposed method for\nmatching interaction correlations to increase the probability of actions\nassociated with a particular action, thereby improving the generated HOI\nlabels. Experiments on two benchmark datasets showcase that FreeA achieves\nstate-of-the-art performance among weakly supervised HOI competitors. Our\nproposal gets +\\textbf{13.29} (\\textbf{159\\%$\\uparrow$}) mAP and\n+\\textbf{17.30} (\\textbf{98\\%$\\uparrow$}) mAP than the newest ``Weakly''\nsupervised model, and +\\textbf{7.19} (\\textbf{28\\%$\\uparrow$}) mAP and\n+\\textbf{14.69} (\\textbf{34\\%$\\uparrow$}) mAP than the latest ``Weakly+''\nsupervised model, respectively, on HICO-DET and V-COCO datasets, more accurate\nin localizing and classifying the interactive actions. The source code will be\nmade public.", "AI": {"tldr": "FreeA is a self-adaptive, language-driven HOI detection method that eliminates manual annotation by leveraging text-image models and knowledge-based masking.", "motivation": "To reduce reliance on heavily annotated datasets for HOI detection by automating label generation.", "method": "Aligns image features with HOI text templates, uses knowledge-based masking, and matches interaction correlations to improve label accuracy.", "result": "Achieves state-of-the-art performance, with significant mAP improvements over weakly supervised models on HICO-DET and V-COCO datasets.", "conclusion": "FreeA offers a scalable and efficient solution for HOI detection, outperforming existing weakly supervised methods."}}
{"id": "2502.09933", "pdf": "https://arxiv.org/pdf/2502.09933", "abs": "https://arxiv.org/abs/2502.09933", "authors": ["Kai Yan", "Zhan Ling", "Kang Liu", "Yifan Yang", "Ting-Han Fan", "Lingfeng Shen", "Zhengyin Du", "Jiecao Chen"], "title": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "36 pages, 11 figures. The last version adds more experiments and\n  modifies name for better summary of the work", "summary": "The ability to recognize patterns from examples and apply them to new ones is\na primal ability for general intelligence, and is widely studied by psychology\nand AI researchers. Many benchmarks have been proposed to measure such ability\nfor Large Language Models (LLMs); however, they focus on few-shot (usually <10)\nsetting and lack evaluation for aggregating many pieces of information from\nlong contexts. On the other hand, the ever-growing context length of LLMs have\nbrought forth the novel paradigm of many-shot In-Context Learning (ICL), which\naddresses new tasks with hundreds to thousands of examples without expensive\nand inefficient fine-tuning. However, many-shot evaluations often focus on\nclassification, and popular long-context LLM tasks such as Needle-In-A-Haystack\n(NIAH) seldom require complicated intelligence for integrating many pieces of\ninformation. To fix the issues from both worlds, we propose MIR-Bench, the\nfirst many-shot in-context reasoning benchmark for pattern recognition that\nasks LLM to predict output via input-output examples from underlying functions\nwith diverse data format. Based on MIR-Bench, we study many novel problems for\nmany-shot in-context reasoning, and acquired many insightful findings including\nscaling effect, robustness, inductive vs. transductive reasoning, retrieval\nAugmented Generation (RAG), coding for inductive reasoning, cross-domain\ngeneralizability, etc.", "AI": {"tldr": "MIR-Bench is introduced as the first many-shot in-context reasoning benchmark for LLMs, addressing gaps in pattern recognition and long-context information integration.", "motivation": "Existing benchmarks lack evaluation for aggregating information from long contexts and focus on few-shot settings, while many-shot ICL lacks tasks requiring complex intelligence.", "method": "Proposes MIR-Bench, a benchmark for many-shot in-context reasoning, evaluating LLMs on pattern recognition via diverse input-output examples.", "result": "Insights include scaling effects, robustness, inductive vs. transductive reasoning, RAG, coding for reasoning, and cross-domain generalizability.", "conclusion": "MIR-Bench fills a critical gap, enabling deeper study of many-shot in-context reasoning and LLM capabilities."}}
{"id": "2502.06876", "pdf": "https://arxiv.org/pdf/2502.06876", "abs": "https://arxiv.org/abs/2502.06876", "authors": ["Jinluan Yang", "Dingnan Jin", "Anke Tang", "Li Shen", "Didi Zhu", "Zhengyu Chen", "Ziyu Zhao", "Daixin Wang", "Qing Cui", "Zhiqiang Zhang", "Jun Zhou", "Fei Wu", "Kun Kuang"], "title": "Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and Harmlessness of Large Language Model via Model Merging", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Achieving balanced alignment of large language models (LLMs) in terms of\nHelpfulness, Honesty, and Harmlessness (3H optimization) constitutes a\ncornerstone of responsible AI. Existing methods like data mixture strategies\nface limitations, including heavy reliance on expert knowledge and conflicting\noptimization signals. While model merging offers parameter-level\nconflict-resolution strategies through integrating specialized models'\nparameters, its potential for 3H optimization remains underexplored. This paper\nsystematically compares the effectiveness of model merging and data mixture\nmethods in constructing 3H-aligned LLMs for the first time, revealing\npreviously overlooked collaborative and conflict relationships among the 3H\ndimensions and discussing the advantages and drawbacks of data mixture\n(\\textit{data-level}) and model merging (\\textit{parameter-level}) methods in\nmitigating the conflict for balanced 3H optimization. Specially, we propose a\nnovel \\textbf{R}eweighting \\textbf{E}nhanced task \\textbf{S}ingular\n\\textbf{M}erging method, \\textbf{RESM}, through outlier weighting and\nsparsity-aware rank selection strategies to address the challenges of\npreference noise accumulation and layer sparsity adaptation inherent in\n3H-aligned LLM merging. Extensive evaluations can verify the effectiveness and\nrobustness of RESM compared to previous data mixture (2\\%-5\\% gain) and model\nmerging (1\\%-3\\% gain) methods in achieving balanced LLM alignment. We release\nour models through \\href{https://huggingface.co/Jinluan}{3H\\_Merging} for\nfurther investigations.", "AI": {"tldr": "The paper compares model merging and data mixture methods for aligning large language models (LLMs) with Helpfulness, Honesty, and Harmlessness (3H). It introduces RESM, a novel merging method, showing improved performance over existing approaches.", "motivation": "Existing methods for 3H alignment rely heavily on expert knowledge and face optimization conflicts. The potential of model merging for 3H optimization is underexplored.", "method": "Proposes RESM, a reweighting-enhanced task singular merging method, using outlier weighting and sparsity-aware rank selection to address noise and sparsity in 3H-aligned LLM merging.", "result": "RESM outperforms data mixture (2%-5% gain) and model merging (1%-3% gain) methods, demonstrating effectiveness and robustness in balanced LLM alignment.", "conclusion": "Model merging, especially with RESM, offers a promising approach for 3H alignment, addressing limitations of data mixture methods. The study highlights collaborative and conflict relationships among 3H dimensions."}}
{"id": "2505.11283", "pdf": "https://arxiv.org/pdf/2505.11283", "abs": "https://arxiv.org/abs/2505.11283", "authors": ["Tom Siegl", "Kutalm\u0131\u015f Co\u015fkun", "Bjarne Hiller", "Amin Mirzaei", "Florian Lemmerich", "Martin Becker"], "title": "SubROC: AUC-Based Discovery of Exceptional Subgroup Performance for Binary Classifiers", "categories": ["cs.LG"], "comment": "49 pages, 8 figures", "summary": "Machine learning (ML) is increasingly employed in real-world applications\nlike medicine or economics, thus, potentially affecting large populations.\nHowever, ML models often do not perform homogeneously across such populations\nresulting in subgroups of the population (e.g., sex=female AND\nmarital_status=married) where the model underperforms or, conversely, is\nparticularly accurate. Identifying and describing such subgroups can support\npractical decisions on which subpopulation a model is safe to deploy or where\nmore training data is required. The potential of identifying and analyzing such\nsubgroups has been recognized, however, an efficient and coherent framework for\neffective search is missing. Consequently, we introduce SubROC, an open-source,\neasy-to-use framework based on Exceptional Model Mining for reliably and\nefficiently finding strengths and weaknesses of classification models in the\nform of interpretable population subgroups. SubROC incorporates common\nevaluation measures (ROC and PR AUC), efficient search space pruning for fast\nexhaustive subgroup search, control for class imbalance, adjustment for\nredundant patterns, and significance testing. We illustrate the practical\nbenefits of SubROC in case studies as well as in comparative analyses across\nmultiple datasets.", "AI": {"tldr": "SubROC is a framework for identifying and analyzing subgroups where ML models underperform or excel, offering efficient search and interpretability.", "motivation": "ML models often perform unevenly across populations, necessitating tools to identify and address these disparities for safe deployment.", "method": "SubROC uses Exceptional Model Mining, incorporates ROC and PR AUC, prunes search space, controls class imbalance, adjusts for redundancy, and includes significance testing.", "result": "SubROC effectively identifies model strengths and weaknesses in interpretable subgroups, demonstrated in case studies and comparative analyses.", "conclusion": "SubROC provides a reliable, efficient, and user-friendly solution for subgroup analysis in ML model evaluation."}}
{"id": "2403.11083", "pdf": "https://arxiv.org/pdf/2403.11083", "abs": "https://arxiv.org/abs/2403.11083", "authors": ["Xiaohao Xu", "Yunkang Cao", "Huaxin Zhang", "Nong Sang", "Xiaonan Huang"], "title": "Customizing Visual-Language Foundation Models for Multi-modal Anomaly Detection and Reasoning", "categories": ["cs.CV", "cs.CL"], "comment": "Best Student Paper Award at IEEE International Conference on Computer\n  Supported Cooperative Work in Design, 2025", "summary": "Anomaly detection is vital in various industrial scenarios, including the\nidentification of unusual patterns in production lines and the detection of\nmanufacturing defects for quality control. Existing techniques tend to be\nspecialized in individual scenarios and lack generalization capacities. In this\nstudy, our objective is to develop a generic anomaly detection model that can\nbe applied in multiple scenarios. To achieve this, we custom-build generic\nvisual language foundation models that possess extensive knowledge and robust\nreasoning abilities as anomaly detectors and reasoners. Specifically, we\nintroduce a multi-modal prompting strategy that incorporates domain knowledge\nfrom experts as conditions to guide the models. Our approach considers diverse\nprompt types, including task descriptions, class context, normality rules, and\nreference images. In addition, we unify the input representation of\nmulti-modality into a 2D image format, enabling multi-modal anomaly detection\nand reasoning. Our preliminary studies demonstrate that combining visual and\nlanguage prompts as conditions for customizing the models enhances anomaly\ndetection performance. The customized models showcase the ability to detect\nanomalies across different data modalities such as images, point clouds, and\nvideos. Qualitative case studies further highlight the anomaly detection and\nreasoning capabilities, particularly for multi-object scenes and temporal data.\nOur code is publicly available at\nhttps://github.com/Xiaohao-Xu/Customizable-VLM", "AI": {"tldr": "The paper proposes a generic anomaly detection model using visual-language foundation models, enhanced by multi-modal prompting and unified 2D image representation, showing improved performance across diverse data types.", "motivation": "Existing anomaly detection methods lack generalization across scenarios, prompting the need for a versatile model applicable to multiple industrial contexts.", "method": "Custom-built visual-language foundation models with multi-modal prompting (task descriptions, class context, normality rules, reference images) and unified 2D input representation.", "result": "Enhanced anomaly detection performance across images, point clouds, and videos, with qualitative success in multi-object scenes and temporal data.", "conclusion": "The approach demonstrates effective generalization and reasoning for anomaly detection, with publicly available code for further use."}}
{"id": "2502.11164", "pdf": "https://arxiv.org/pdf/2502.11164", "abs": "https://arxiv.org/abs/2502.11164", "authors": ["Kaikai Zhao", "Zhaoxiang Liu", "Xuejiao Lei", "Jiaojiao Zhao", "Zhenhong Long", "Zipeng Wang", "Ning Wang", "Meijuan An", "Qingliang Meng", "Peijun Yang", "Minjie Hua", "Chaoyang Ma", "Wen Liu", "Kai Wang", "Shiguo Lian"], "title": "Quantifying the Capability Boundary of DeepSeek Models: An Application-Driven Performance Analysis", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "DeepSeek-R1, known for its low training cost and exceptional reasoning\ncapabilities, has achieved state-of-the-art performance on various benchmarks.\nHowever, detailed evaluations for DeepSeek Series models from the perspective\nof real-world applications are lacking, making it challenging for users to\nselect the most suitable DeepSeek models for their specific needs. To address\nthis gap, we presents the first comprehensive evaluation of the DeepSeek and\nits related models (including DeepSeek-V3, DeepSeek-R1,\nDeepSeek-R1-Distill-Qwen series, DeepSeek-R1-Distill-Llama series, their\ncorresponding 4-bit quantized models, and the reasoning model QwQ-32B) using\nour enhanced A-Eval benchmark, A-Eval-2.0. Our systematic analysis reveals\nseveral key insights: (1) Given identical model architectures and training\ndata, larger parameter models demonstrate superior performance, aligning with\nthe scaling law. However, smaller models may achieve enhanced capabilities when\nemploying optimized training strategies and higher-quality data; (2)\nReasoning-enhanced model show significant performance gains in logical\nreasoning tasks but may underperform in text understanding and generation\ntasks; (3) As the data difficulty increases, distillation or reasoning\nenhancements yield higher performance gains for the models. Interestingly,\nreasoning enhancements can even have a negative impact on simpler problems; (4)\nQuantization impacts different capabilities unevenly, with significant drop on\nlogical reasoning and minimal impact on text generation. Based on these results\nand findings, we design an model selection handbook enabling users to select\nthe most cost-effective models without efforts.", "AI": {"tldr": "The paper evaluates DeepSeek models comprehensively, revealing insights on performance, reasoning enhancements, and quantization effects, and provides a model selection guide.", "motivation": "Address the lack of detailed evaluations for DeepSeek models in real-world applications to help users choose the most suitable models.", "method": "Conduct a systematic evaluation using the A-Eval-2.0 benchmark on various DeepSeek models, including reasoning-enhanced and quantized versions.", "result": "Key findings include the impact of model size, reasoning enhancements, and quantization on performance, with distillation and reasoning enhancements showing higher gains for harder tasks.", "conclusion": "The study provides actionable insights and a model selection handbook to help users choose cost-effective models based on their needs."}}
{"id": "2502.07490", "pdf": "https://arxiv.org/pdf/2502.07490", "abs": "https://arxiv.org/abs/2502.07490", "authors": ["Xialie Zhuang", "Zhikai Jia", "Jianjin Li", "Zhenyu Zhang", "Li Shen", "Zheng Cao", "Shiwei Liu"], "title": "Mask-Enhanced Autoregressive Prediction: Pay Less Attention to Learn More", "categories": ["cs.CL", "cs.LG"], "comment": "17 pages,7 figures", "summary": "Large Language Models (LLMs) are discovered to suffer from accurately\nretrieving key information. To address this, we propose Mask-Enhanced\nAutoregressive Prediction (MEAP), a simple yet effective training paradigm that\nseamlessly integrates Masked Language Modeling (MLM) into Next-Token Prediction\n(NTP) to enhance the latter's in-context retrieval capabilities. Specifically,\nMEAP first randomly masks a small fraction of input tokens and then directly\nperforms the standard next-token prediction autoregressive using a decoder-only\nTransformer. MEAP eliminates the need for bidirectional attention or\nencoder-decoder architectures for MLM, incurring no additional computational\noverhead during pre-training or inference. Intensive experiments demonstrate\nthat MEAP substantially outperforms NTP on key information retrieval and\nlong-context reasoning tasks, while performing on par or better on commonsense\nreasoning tasks. The benefits of MEAP also extend to supervised fine-tuning,\nwhere it shows remarkable advantages in lost-in-the-middle scenarios,\noutperforming NTP by 11.77 percentage points. Our analysis indicates that\nMEAP's effectiveness arises from its ability to promote more distinguishable\nattention scores by concentrating on a reduced set of non-masked tokens. This\nmechanism improves the model's focus on task-relevant signals while mitigating\nthe influence of peripheral context. These findings position MEAP as a\npromising training paradigm for large language models.", "AI": {"tldr": "MEAP integrates MLM into NTP to improve LLMs' retrieval and reasoning, outperforming NTP without extra computational cost.", "motivation": "LLMs struggle with accurate key information retrieval; MEAP aims to enhance this capability.", "method": "MEAP randomly masks input tokens and uses NTP with a decoder-only Transformer, avoiding bidirectional attention.", "result": "MEAP outperforms NTP in retrieval and reasoning tasks, especially in lost-in-the-middle scenarios (+11.77%).", "conclusion": "MEAP is an effective training paradigm for LLMs, improving focus on relevant signals."}}
{"id": "2505.11294", "pdf": "https://arxiv.org/pdf/2505.11294", "abs": "https://arxiv.org/abs/2505.11294", "authors": ["Juan D. Guerra", "Thomas Garbay", "Guillaume Lajoie", "Marco Bonizzato"], "title": "Bidirectional Information Flow (BIF) -- A Sample Efficient Hierarchical Gaussian Process for Bayesian Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Hierarchical Gaussian Process (H-GP) models divide problems into different\nsubtasks, allowing for different models to address each part, making them\nwell-suited for problems with inherent hierarchical structure. However, typical\nH-GP models do not fully take advantage of this structure, only sending\ninformation up or down the hierarchy. This one-way coupling limits sample\nefficiency and slows convergence. We propose Bidirectional Information Flow\n(BIF), an efficient H-GP framework that establishes bidirectional information\nexchange between parent and child models in H-GPs for online training. BIF\nretains the modular structure of hierarchical models - the parent combines\nsubtask knowledge from children GPs - while introducing top-down feedback to\ncontinually refine children models during online learning. This mutual exchange\nimproves sample efficiency, enables robust training, and allows modular reuse\nof learned subtask models. BIF outperforms conventional H-GP Bayesian\nOptimization methods, achieving up to 85% and 5x higher $R^2$ scores for the\nparent and children respectively, on synthetic and real-world neurostimulation\noptimization tasks.", "AI": {"tldr": "Bidirectional Information Flow (BIF) enhances Hierarchical Gaussian Process (H-GP) models by enabling bidirectional information exchange, improving efficiency and performance.", "motivation": "Typical H-GP models lack bidirectional information flow, limiting efficiency and convergence.", "method": "Proposes BIF, a framework for bidirectional information exchange between parent and child models in H-GPs during online training.", "result": "BIF outperforms conventional H-GP methods, achieving up to 85% and 5x higher R\u00b2 scores for parent and children models.", "conclusion": "BIF improves sample efficiency, robustness, and modular reuse in hierarchical models, demonstrating superior performance in optimization tasks."}}
{"id": "2404.11865", "pdf": "https://arxiv.org/pdf/2404.11865", "abs": "https://arxiv.org/abs/2404.11865", "authors": ["Suyuan Huang", "Haoxin Zhang", "Linqing Zhong", "Honggu Chen", "Yan Gao", "Yao Hu", "Zengchang Qin"], "title": "From Image to Video, what do we need in multimodal LLMs?", "categories": ["cs.CV"], "comment": null, "summary": "Covering from Image LLMs to the more complex Video LLMs, the Multimodal Large\nLanguage Models (MLLMs) have demonstrated profound capabilities in\ncomprehending cross-modal information as numerous studies have illustrated.\nPrevious methods delve into designing comprehensive Video LLMs through\nintegrating video foundation models with primitive LLMs. Despite its\neffectiveness, such paradigm renders Video LLM's structure verbose and\ntypically requires substantial video data for pre-training. Crucially, it\nneglects leveraging the foundational contributions of ready-made Image LLMs. In\nthis paper, we introduce RED-VILLM, a Resource-Efficient Development pipeline\nwhich builds robust Video LLMs through leveraging the prior knowledge of Image\nLLMs. Specifically, since a video is naturally a combination of images along\nthe temporal dimension, we devise a temporal adaptation plug-and-play\nstructure, endowing the backbone Image LLM with the capability to grasp\ntemporal information. Moreover, through applying this pipeline, we achieve the\nfirst Video LLM within the Chinese-speaking community. Extensive experiments\ndemonstrate that Video LLMs developed through our approach surpass conventional\nVideo LLMs, requiring minimal instructional data and training resources. Our\napproach highlights the potential for a more cost-effective and scalable\nadvancement in multimodal models.", "AI": {"tldr": "RED-VILLM introduces a resource-efficient pipeline to develop Video LLMs by leveraging Image LLMs, reducing data and training needs while outperforming traditional methods.", "motivation": "Existing Video LLMs are complex and data-intensive, neglecting the potential of Image LLMs. RED-VILLM aims to simplify and enhance Video LLM development.", "method": "Uses a plug-and-play temporal adaptation structure on Image LLMs to handle video data, requiring minimal training resources.", "result": "Outperforms conventional Video LLMs with less data and resources, including the first Chinese-speaking Video LLM.", "conclusion": "RED-VILLM offers a cost-effective, scalable approach for advancing multimodal models."}}
{"id": "2503.04530", "pdf": "https://arxiv.org/pdf/2503.04530", "abs": "https://arxiv.org/abs/2503.04530", "authors": ["Chen Li", "Yinyi Luo", "Anudeep Bolimera", "Uzair Ahmed", "Shri Kiran Srinivasan", "Hrishikesh Gokhale", "Marios Savvides"], "title": "SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models excel in reasoning yet often rely on Chain-of-Thought\nprompts, limiting performance on tasks demanding more nuanced topological\nstructures. We present SOLAR (Scalable Optimization of Large-scale Architecture\nfor Reasoning), a framework that dynamically optimizes Chain-of-Thought (CoT),\nTree-of-Thought (ToT), and Graph-of-Thought (GoT) topologies to boost accuracy\nand efficiency. Our Topological-Annotation-Generation (TAG) system automates\ndataset creation, annotation, and difficulty segmentation, leading to stronger\npost training and test-time performance. We also propose Topological-Scaling, a\ncurriculum-learning-based approach that adaptively combines post training and\ninference scaling to each task. On MATH and GSM8K, SOLAR delivers notable\ngains: +5% accuracy with Topological Tuning, +9% with Topological Rewarding,\nand +10.02% with Hybrid Scaling, while reducing response length by over 5%,\nlowering inference latency. To further enhance efficiency, we introduce a\nmulti-task Topological Reward Model (M-TRM) that selects both the optimal\nreasoning topology and final answer in a single pass, eliminating multiple\nsingle-task TRMs. Remarkably, M-TRM also surpasses all single-task TRMs,\nimproving accuracy by +10% and rank correlation by +9%. Overall, SOLAR\nestablishes a new benchmark for scalable, high-precision LLM reasoning and\nintroduces a fully automated, dynamic topology competition mechanism.", "AI": {"tldr": "SOLAR optimizes reasoning topologies (CoT, ToT, GoT) dynamically, enhancing accuracy and efficiency. It introduces TAG for dataset automation and Topological-Scaling for adaptive learning. Results show significant accuracy gains and reduced latency, with M-TRM outperforming single-task models.", "motivation": "Current LLMs rely on fixed reasoning structures like Chain-of-Thought, limiting performance on complex tasks. SOLAR addresses this by dynamically optimizing topologies for better reasoning.", "method": "SOLAR uses TAG for automated dataset creation and Topological-Scaling for adaptive learning. It introduces M-TRM for optimal topology and answer selection in one pass.", "result": "Notable gains: +5% to +10.02% accuracy, reduced response length by 5%, lower latency. M-TRM improves accuracy by +10% and rank correlation by +9%.", "conclusion": "SOLAR sets a new benchmark for scalable, high-precision LLM reasoning with fully automated dynamic topology optimization."}}
{"id": "2502.08666", "pdf": "https://arxiv.org/pdf/2502.08666", "abs": "https://arxiv.org/abs/2502.08666", "authors": ["Miranda Muqing Miao", "Michael Kearns"], "title": "Hallucination, Monofacts, and Miscalibration: An Empirical Investigation", "categories": ["cs.CL", "cs.AI"], "comment": "Code available at https://github.com/mmiao2/Hallucination.git", "summary": "Hallucinated facts in large language models (LLMs) have recently been shown\nto obey a statistical lower bound determined by the monofact rate (related to\nthe classical Good-Turing missing mass estimator) minus model miscalibration\n(Kalai & Vempala, 2024). We present the first empirical investigation of this\nthree-way relationship in classical n-gram models and fine-tuned\nencoder-decoder Transformers. By generating training data from Pareto\ndistributions with varying shape parameters, we systematically control the\nmonofact rates and establish its positive relationship with hallucination. To\nbridge theory and practice, we derive an empirical analog of the hallucination\nbound by replacing the population miscalibration term (Section 2.1) with an\nempirical bin-wise KL divergence and confirm its practical viability. We then\nintroduce selective upweighting -- a simple yet effective technique that\nstrategically repeats as little as 5% of training examples -- to deliberately\ninject miscalibration into the model. This intervention reduces hallucination\nby up to 40%, challenging universal deduplication policies. Our experiments\nreveal a critical trade-off: selective upweighting maintains pre-injection\nlevels of accuracy while substantially reducing hallucination, whereas standard\ntraining gradually improves accuracy but fails to address persistently high\nhallucination, indicating an inherent tension in optimization objectives.", "AI": {"tldr": "The paper explores the relationship between hallucinated facts in LLMs, monofact rates, and model miscalibration, introducing selective upweighting to reduce hallucination by up to 40%.", "motivation": "To empirically investigate the statistical lower bound of hallucinated facts in LLMs and propose practical interventions to mitigate them.", "method": "Uses n-gram models and fine-tuned Transformers, controls monofact rates via Pareto distributions, and introduces selective upweighting to inject miscalibration.", "result": "Selective upweighting reduces hallucination by up to 40% without sacrificing accuracy, unlike standard training.", "conclusion": "The study highlights a trade-off between accuracy and hallucination, advocating for targeted interventions like selective upweighting."}}
{"id": "2505.11298", "pdf": "https://arxiv.org/pdf/2505.11298", "abs": "https://arxiv.org/abs/2505.11298", "authors": ["Sohir Maskey", "Raffaele Paolino", "Fabian Jogl", "Gitta Kutyniok", "Johannes F. Lutzeyer"], "title": "Graph Representational Learning: When Does More Expressivity Hurt Generalization?", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) are powerful tools for learning on structured\ndata, yet the relationship between their expressivity and predictive\nperformance remains unclear. We introduce a family of premetrics that capture\ndifferent degrees of structural similarity between graphs and relate these\nsimilarities to generalization, and consequently, the performance of expressive\nGNNs. By considering a setting where graph labels are correlated with\nstructural features, we derive generalization bounds that depend on the\ndistance between training and test graphs, model complexity, and training set\nsize. These bounds reveal that more expressive GNNs may generalize worse unless\ntheir increased complexity is balanced by a sufficiently large training set or\nreduced distance between training and test graphs. Our findings relate\nexpressivity and generalization, offering theoretical insights supported by\nempirical results.", "AI": {"tldr": "The paper explores the relationship between GNN expressivity and performance, introducing premetrics for structural similarity and deriving generalization bounds. Findings suggest expressive GNNs may generalize poorly unless balanced by training size or reduced graph distance.", "motivation": "To clarify the unclear relationship between GNN expressivity and predictive performance, and to understand how structural similarity affects generalization.", "method": "Introduces premetrics for structural similarity, derives generalization bounds based on graph distance, model complexity, and training size, and validates with empirical results.", "result": "Expressive GNNs may generalize worse unless their complexity is balanced by larger training sets or closer training-test graph distances.", "conclusion": "The study links GNN expressivity and generalization, providing theoretical insights and empirical support for balancing complexity with training conditions."}}
{"id": "2405.04969", "pdf": "https://arxiv.org/pdf/2405.04969", "abs": "https://arxiv.org/abs/2405.04969", "authors": ["Nikolaos Giakoumoglou", "Tania Stathaki", "Athanasios Gkelias"], "title": "A Review on Discriminative Self-supervised Learning Methods in Computer Vision", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint. 97 pages, 12 figures, 16 tables", "summary": "Self-supervised learning (SSL) has rapidly emerged as a transformative\napproach in computer vision, enabling the extraction of rich feature\nrepresentations from vast amounts of unlabeled data and reducing reliance on\ncostly manual annotations. This review presents a comprehensive analysis of\ndiscriminative SSL methods, which focus on learning representations by solving\npretext tasks that do not require human labels. The paper systematically\ncategorizes discriminative SSL approaches into five main groups: contrastive\nmethods, clustering methods, self-distillation methods, knowledge distillation\nmethods, and feature decorrelation methods. For each category, the review\ndetails the underlying principles, architectural components, loss functions,\nand representative algorithms, highlighting their unique mechanisms and\ncontributions to the field. Extensive comparative evaluations are provided,\nincluding linear and semi-supervised protocols on standard benchmarks such as\nImageNet, as well as transfer learning performance across diverse downstream\ntasks. The review also discusses theoretical foundations, scalability,\nefficiency, and practical challenges, such as computational demands and\naccessibility. By synthesizing recent advancements and identifying key trends,\nopen challenges, and future research directions, this work serves as a valuable\nresource for researchers and practitioners aiming to leverage discriminative\nSSL for robust and generalizable computer vision models.", "AI": {"tldr": "A review of discriminative self-supervised learning (SSL) methods in computer vision, categorizing them into five groups and analyzing their principles, performance, and challenges.", "motivation": "To reduce reliance on costly manual annotations by leveraging unlabeled data for feature representation learning.", "method": "Systematic categorization of discriminative SSL into contrastive, clustering, self-distillation, knowledge distillation, and feature decorrelation methods, with detailed analysis of each.", "result": "Comparative evaluations on benchmarks like ImageNet show SSL's effectiveness, though challenges like computational demands persist.", "conclusion": "The review synthesizes advancements, highlights open challenges, and guides future research in discriminative SSL for robust computer vision models."}}
{"id": "2503.14162", "pdf": "https://arxiv.org/pdf/2503.14162", "abs": "https://arxiv.org/abs/2503.14162", "authors": ["Zongyun Zhang", "Jiacheng Ruan", "Xian Gao", "Ting Liu", "Yuzhuo Fu"], "title": "EIAD: Explainable Industrial Anomaly Detection Via Multi-Modal Large Language Models", "categories": ["cs.AI"], "comment": "Accepted by ICME2025", "summary": "Industrial Anomaly Detection (IAD) is critical to ensure product quality\nduring manufacturing. Although existing zero-shot defect segmentation and\ndetection methods have shown effectiveness, they cannot provide detailed\ndescriptions of the defects. Furthermore, the application of large multi-modal\nmodels in IAD remains in its infancy, facing challenges in balancing\nquestion-answering (QA) performance and mask-based grounding capabilities,\noften owing to overfitting during the fine-tuning process. To address these\nchallenges, we propose a novel approach that introduces a dedicated multi-modal\ndefect localization module to decouple the dialog functionality from the core\nfeature extraction. This decoupling is achieved through independent\noptimization objectives and tailored learning strategies. Additionally, we\ncontribute to the first multi-modal industrial anomaly detection training\ndataset, named Defect Detection Question Answering (DDQA), encompassing a wide\nrange of defect types and industrial scenarios. Unlike conventional datasets\nthat rely on GPT-generated data, DDQA ensures authenticity and reliability and\noffers a robust foundation for model training. Experimental results demonstrate\nthat our proposed method, Explainable Industrial Anomaly Detection Assistant\n(EIAD), achieves outstanding performance in defect detection and localization\ntasks. It not only significantly enhances accuracy but also improves\ninterpretability. These advancements highlight the potential of EIAD for\npractical applications in industrial settings.", "AI": {"tldr": "The paper proposes a novel multi-modal approach (EIAD) for industrial anomaly detection, decoupling dialog and feature extraction, and introduces a new dataset (DDQA) for improved performance and interpretability.", "motivation": "Existing zero-shot methods lack detailed defect descriptions, and multi-modal models struggle with balancing QA performance and grounding capabilities due to overfitting.", "method": "Introduces a multi-modal defect localization module with independent optimization and tailored learning strategies, and creates the DDQA dataset for authentic training.", "result": "EIAD achieves outstanding performance in defect detection and localization, enhancing accuracy and interpretability.", "conclusion": "EIAD shows strong potential for practical industrial applications due to its improved performance and reliability."}}
{"id": "2502.11175", "pdf": "https://arxiv.org/pdf/2502.11175", "abs": "https://arxiv.org/abs/2502.11175", "authors": ["Jeonghyun Park", "Hwanhee Lee"], "title": "Investigating Language Preference of Multilingual RAG Systems", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Multilingual Retrieval-Augmented Generation (mRAG) systems enhance language\nmodels by integrating external multilingual information to produce\ncontext-aware responses. However, mRAG systems struggle with retrieving\nrelevant information due to linguistic variations between queries and\ndocuments, generating inconsistent responses when multilingual sources\nconflict. In this work, we systematically investigate language preferences in\nboth retrieval and generation of mRAG through a series of experiments. Our\nanalysis indicates that retrievers tend to prefer high-resource and query\nlanguages, yet this preference does not consistently improve generation\nperformance. Moreover, we observe that generators prefer the query language or\nLatin scripts, leading to inconsistent outputs. To overcome these issues, we\npropose Dual Knowledge Multilingual RAG (DKM-RAG), a simple yet effective\nframework that fuses translated multilingual passages with complementary model\nknowledge. Empirical results demonstrate that DKM-RAG mitigates language\npreference in generation and enhances performance across diverse linguistic\nsettings.", "AI": {"tldr": "The paper investigates language preferences in multilingual RAG systems, identifies inconsistencies, and proposes DKM-RAG to improve performance by fusing translated passages with model knowledge.", "motivation": "Addressing the challenges of language preferences and inconsistencies in multilingual RAG systems, which hinder retrieval and generation performance.", "method": "Systematic experiments to analyze language preferences in retrieval and generation, followed by proposing DKM-RAG, a framework combining translated multilingual passages with model knowledge.", "result": "Retrievers favor high-resource and query languages, while generators prefer query languages or Latin scripts, leading to inconsistencies. DKM-RAG mitigates these issues and improves performance.", "conclusion": "DKM-RAG effectively addresses language preference biases and enhances multilingual RAG performance across diverse linguistic settings."}}
{"id": "2505.11306", "pdf": "https://arxiv.org/pdf/2505.11306", "abs": "https://arxiv.org/abs/2505.11306", "authors": ["Xinyan Wang", "Rui Dai", "Kaikui Liu", "Xiangxiang Chu"], "title": "Effective Probabilistic Time Series Forecasting with Fourier Adaptive Noise-Separated Diffusion", "categories": ["cs.LG"], "comment": null, "summary": "We propose the Fourier Adaptive Lite Diffusion Architecture (FALDA), a novel\nprobabilistic framework for time series forecasting. First, we introduce the\nDiffusion Model for Residual Regression (DMRR) framework, which unifies\ndiffusion-based probabilistic regression methods. Within this framework, FALDA\nleverages Fourier-based decomposition to incorporate a component-specific\narchitecture, enabling tailored modeling of individual temporal components. A\nconditional diffusion model is utilized to estimate the future noise term,\nwhile our proposed lightweight denoiser, DEMA (Decomposition MLP with AdaLN),\nconditions on the historical noise term to enhance denoising performance.\nThrough mathematical analysis and empirical validation, we demonstrate that\nFALDA effectively reduces epistemic uncertainty, allowing probabilistic\nlearning to primarily focus on aleatoric uncertainty. Experiments on six\nreal-world benchmarks demonstrate that FALDA consistently outperforms existing\nprobabilistic forecasting approaches across most datasets for long-term time\nseries forecasting while achieving enhanced computational efficiency without\ncompromising accuracy. Notably, FALDA also achieves superior overall\nperformance compared to state-of-the-art (SOTA) point forecasting approaches,\nwith improvements of up to 9%.", "AI": {"tldr": "FALDA is a probabilistic framework for time series forecasting using Fourier-based decomposition and a lightweight denoiser, outperforming existing methods in accuracy and efficiency.", "motivation": "To improve probabilistic time series forecasting by reducing epistemic uncertainty and focusing on aleatoric uncertainty.", "method": "Uses Fourier-based decomposition and a conditional diffusion model with a lightweight denoiser (DEMA) for tailored modeling and noise estimation.", "result": "Outperforms existing probabilistic and point forecasting methods, with up to 9% improvement in accuracy.", "conclusion": "FALDA is effective for long-term forecasting, balancing accuracy and computational efficiency."}}
{"id": "2408.01826", "pdf": "https://arxiv.org/pdf/2408.01826", "abs": "https://arxiv.org/abs/2408.01826", "authors": ["Yihong Lin", "Zhaoxin Fan", "Xianjia Wu", "Lingyu Xiong", "Liang Peng", "Xiandong Li", "Wenxiong Kang", "Songju Lei", "Huang Xu"], "title": "GLDiTalker: Speech-Driven 3D Facial Animation with Graph Latent Diffusion Transformer", "categories": ["cs.CV"], "comment": "9 pages, 5 figures", "summary": "Speech-driven talking head generation is a critical yet challenging task with\napplications in augmented reality and virtual human modeling. While recent\napproaches using autoregressive and diffusion-based models have achieved\nnotable progress, they often suffer from modality inconsistencies, particularly\nmisalignment between audio and mesh, leading to reduced motion diversity and\nlip-sync accuracy. To address this, we propose GLDiTalker, a novel\nspeech-driven 3D facial animation model based on a Graph Latent Diffusion\nTransformer. GLDiTalker resolves modality misalignment by diffusing signals\nwithin a quantized spatiotemporal latent space. It employs a two-stage training\npipeline: the Graph-Enhanced Quantized Space Learning Stage ensures lip-sync\naccuracy, while the Space-Time Powered Latent Diffusion Stage enhances motion\ndiversity. Together, these stages enable GLDiTalker to generate realistic,\ntemporally stable 3D facial animations. Extensive evaluations on standard\nbenchmarks demonstrate that GLDiTalker outperforms existing methods, achieving\nsuperior results in both lip-sync accuracy and motion diversity.", "AI": {"tldr": "GLDiTalker is a novel speech-driven 3D facial animation model using a Graph Latent Diffusion Transformer to address modality misalignment, improving lip-sync accuracy and motion diversity.", "motivation": "Existing methods suffer from modality inconsistencies (audio-mesh misalignment), reducing motion diversity and lip-sync accuracy.", "method": "GLDiTalker uses a two-stage pipeline: Graph-Enhanced Quantized Space Learning for lip-sync accuracy and Space-Time Powered Latent Diffusion for motion diversity.", "result": "Outperforms existing methods in lip-sync accuracy and motion diversity on standard benchmarks.", "conclusion": "GLDiTalker generates realistic, stable 3D facial animations, addressing key challenges in speech-driven talking head generation."}}
{"id": "2503.21138", "pdf": "https://arxiv.org/pdf/2503.21138", "abs": "https://arxiv.org/abs/2503.21138", "authors": ["Hedong Yan"], "title": "A Computational Theory for Efficient Mini Agent Evaluation with Causal Guarantees", "categories": ["cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "In order to reduce the cost of experimental evaluation for agents, we\nintroduce a computational theory of evaluation for mini agents: build\nevaluation model to accelerate the evaluation procedures. We prove upper bounds\nof generalized error and generalized causal effect error of given evaluation\nmodels for infinite agents. We also prove efficiency, and consistency to\nestimated causal effect from deployed agents to evaluation metric by\nprediction. To learn evaluation models, we propose a meta-learner to handle\nheterogeneous agents space problem. Comparing with existed evaluation\napproaches, our (conditional) evaluation model reduced 24.1\\% to 99.0\\%\nevaluation errors across 12 scenes, including individual medicine, scientific\nsimulation, social experiment, business activity, and quantum trade. The\nevaluation time is reduced 3 to 7 order of magnitude per subject comparing with\nexperiments or simulations.", "AI": {"tldr": "A computational theory for evaluating mini agents reduces costs by building evaluation models, proving error bounds and efficiency, and using a meta-learner for heterogeneous agents. Results show significant error reduction and time savings.", "motivation": "To reduce the high cost of experimental evaluation for agents by introducing a computational evaluation theory.", "method": "Proposes a meta-learner for heterogeneous agents, builds evaluation models, and proves error bounds and efficiency.", "result": "Reduced evaluation errors by 24.1% to 99.0% across 12 scenes and cut evaluation time by 3 to 7 orders of magnitude.", "conclusion": "The method effectively accelerates and improves agent evaluation, offering practical benefits across diverse applications."}}
{"id": "2502.11948", "pdf": "https://arxiv.org/pdf/2502.11948", "abs": "https://arxiv.org/abs/2502.11948", "authors": ["Min-Hsuan Yeh", "Max Kamachee", "Seongheon Park", "Yixuan Li"], "title": "Can Your Uncertainty Scores Detect Hallucinated Entity?", "categories": ["cs.CL"], "comment": null, "summary": "To mitigate the impact of hallucination nature of LLMs, many studies propose\ndetecting hallucinated generation through uncertainty estimation. However,\nthese approaches predominantly operate at the sentence or paragraph level,\nfailing to pinpoint specific spans or entities responsible for hallucinated\ncontent. This lack of granularity is especially problematic for long-form\noutputs that mix accurate and fabricated information. To address this\nlimitation, we explore entity-level hallucination detection. We propose a new\ndata set, HalluEntity, which annotates hallucination at the entity level. Based\non the dataset, we comprehensively evaluate uncertainty-based hallucination\ndetection approaches across 17 modern LLMs. Our experimental results show that\nuncertainty estimation approaches focusing on individual token probabilities\ntend to over-predict hallucinations, while context-aware methods show better\nbut still suboptimal performance. Through an in-depth qualitative study, we\nidentify relationships between hallucination tendencies and linguistic\nproperties and highlight important directions for future research. HalluEntity:\nhttps://huggingface.co/datasets/samuelyeh/HalluEntity", "AI": {"tldr": "The paper introduces HalluEntity, a dataset for entity-level hallucination detection in LLMs, evaluates uncertainty-based methods, and identifies linguistic trends in hallucinations.", "motivation": "Current hallucination detection methods lack granularity, especially for long-form outputs mixing accurate and fabricated information.", "method": "Proposes HalluEntity dataset for entity-level annotation and evaluates 17 LLMs using uncertainty-based approaches.", "result": "Token-probability methods over-predict hallucinations, while context-aware methods perform better but suboptimally. Linguistic properties influence hallucination tendencies.", "conclusion": "Highlights the need for improved entity-level hallucination detection and suggests future research directions."}}
{"id": "2505.11307", "pdf": "https://arxiv.org/pdf/2505.11307", "abs": "https://arxiv.org/abs/2505.11307", "authors": ["Elsa Rizk", "Kun Yuan", "Ali H. Sayed"], "title": "Diffusion Learning with Partial Agent Participation and Local Updates", "categories": ["cs.LG"], "comment": "17 pages", "summary": "Diffusion learning is a framework that endows edge devices with advanced\nintelligence. By processing and analyzing data locally and allowing each agent\nto communicate with its immediate neighbors, diffusion effectively protects the\nprivacy of edge devices, enables real-time response, and reduces reliance on\ncentral servers. However, traditional diffusion learning relies on\ncommunication at every iteration, leading to communication overhead, especially\nwith large learning models. Furthermore, the inherent volatility of edge\ndevices, stemming from power outages or signal loss, poses challenges to\nreliable communication between neighboring agents. To mitigate these issues,\nthis paper investigates an enhanced diffusion learning approach incorporating\nlocal updates and partial agent participation. Local updates will curtail\ncommunication frequency, while partial agent participation will allow for the\ninclusion of agents based on their availability. We prove that the resulting\nalgorithm is stable in the mean-square error sense and provide a tight analysis\nof its Mean-Square-Deviation (MSD) performance. Various numerical experiments\nare conducted to illustrate our theoretical findings.", "AI": {"tldr": "The paper proposes an enhanced diffusion learning approach with local updates and partial agent participation to reduce communication overhead and improve reliability in edge devices.", "motivation": "Traditional diffusion learning suffers from high communication overhead and unreliability due to edge device volatility.", "method": "The enhanced approach incorporates local updates to reduce communication frequency and partial agent participation based on availability.", "result": "The algorithm is proven stable in mean-square error and analyzed for Mean-Square-Deviation (MSD) performance. Numerical experiments validate the findings.", "conclusion": "The proposed method effectively addresses communication and reliability challenges in diffusion learning for edge devices."}}
{"id": "2408.11518", "pdf": "https://arxiv.org/pdf/2408.11518", "abs": "https://arxiv.org/abs/2408.11518", "authors": ["Yihong Lin", "Liang Peng", "Zhaoxin Fan", "Xianjia Wu", "Jianqiao Hu", "Xiandong Li", "Wenxiong Kang", "Songju Lei"], "title": "EmoFace: Emotion-Content Disentangled Speech-Driven 3D Talking Face Animation", "categories": ["cs.CV"], "comment": null, "summary": "The creation of increasingly vivid 3D talking face has become a hot topic in\nrecent years. Currently, most speech-driven works focus on lip synchronisation\nbut neglect to effectively capture the correlations between emotions and facial\nmotions. To address this problem, we propose a two-stream network called\nEmoFace, which consists of an emotion branch and a content branch. EmoFace\nemploys a novel Mesh Attention mechanism to analyse and fuse the emotion\nfeatures and content features. Particularly, a newly designed spatio-temporal\ngraph-based convolution, SpiralConv3D, is used in Mesh Attention to learn\npotential temporal and spatial feature dependencies between mesh vertices. In\naddition, to the best of our knowledge, it is the first time to introduce a new\nself-growing training scheme with intermediate supervision to dynamically\nadjust the ratio of groundtruth adopted in the 3D face animation task.\nComprehensive quantitative and qualitative evaluations on our high-quality 3D\nemotional facial animation dataset, 3D-RAVDESS ($4.8863\\times 10^{-5}$mm for\nLVE and $0.9509\\times 10^{-5}$mm for EVE), together with the public dataset\nVOCASET ($2.8669\\times 10^{-5}$mm for LVE and $0.4664\\times 10^{-5}$mm for\nEVE), demonstrate that our approach achieves state-of-the-art performance.", "AI": {"tldr": "EmoFace, a two-stream network with Mesh Attention and SpiralConv3D, improves 3D talking face animation by capturing emotion-facial motion correlations, achieving state-of-the-art results.", "motivation": "Current speech-driven 3D face models focus on lip sync but overlook emotion-facial motion correlations, limiting realism.", "method": "Proposes EmoFace with emotion and content branches, Mesh Attention, SpiralConv3D, and a self-growing training scheme.", "result": "Achieves high accuracy on 3D-RAVDESS and VOCASET datasets (e.g., $4.8863\\times 10^{-5}$mm for LVE).", "conclusion": "EmoFace advances 3D emotional facial animation by integrating emotion and content features effectively."}}
{"id": "2504.04072", "pdf": "https://arxiv.org/pdf/2504.04072", "abs": "https://arxiv.org/abs/2504.04072", "authors": ["Satvik Golechha", "Adri\u00e0 Garriga-Alonso"], "title": "Among Us: A Sandbox for Measuring and Detecting Agentic Deception", "categories": ["cs.AI", "cs.LG"], "comment": "21 pages, preprint", "summary": "Prior studies on deception in language-based AI agents typically assess\nwhether the agent produces a false statement about a topic, or makes a binary\nchoice prompted by a goal, rather than allowing open-ended deceptive behavior\nto emerge in pursuit of a longer-term goal. To fix this, we introduce\n$\\textit{Among Us}$, a sandbox social deception game where LLM-agents exhibit\nlong-term, open-ended deception as a consequence of the game objectives. While\nmost benchmarks saturate quickly, $\\textit{Among Us}$ can be expected to last\nmuch longer, because it is a multi-player game far from equilibrium. Using the\nsandbox, we evaluate $18$ proprietary and open-weight LLMs and uncover a\ngeneral trend: models trained with RL are comparatively much better at\nproducing deception than detecting it. We evaluate the effectiveness of methods\nto detect lying and deception: logistic regression on the activations and\nsparse autoencoders (SAEs). We find that probes trained on a dataset of\n``pretend you're a dishonest model: $\\dots$'' generalize extremely well\nout-of-distribution, consistently obtaining AUROCs over 95% even when evaluated\njust on the deceptive statement, without the chain of thought. We also find two\nSAE features that work well at deception detection but are unable to steer the\nmodel to lie less. We hope our open-sourced sandbox, game logs, and probes\nserve to anticipate and mitigate deceptive behavior and capabilities in\nlanguage-based agents.", "AI": {"tldr": "The paper introduces a sandbox game, Among Us, to study open-ended deception in LLM-agents, revealing RL-trained models are better at deception than detection. Detection methods like logistic regression and SAEs show promise but don't reduce lying.", "motivation": "Prior studies limit deception assessment to binary or short-term scenarios, lacking open-ended, long-term deceptive behavior analysis in AI agents.", "method": "The study uses the Among Us game to evaluate 18 LLMs, testing their deception and detection abilities with logistic regression and sparse autoencoders (SAEs).", "result": "RL-trained models excel at deception but struggle with detection. Probes trained on dishonest behavior generalize well (AUROCs >95%), but SAEs can't reduce lying.", "conclusion": "The sandbox, logs, and probes aim to help anticipate and mitigate deceptive behavior in language-based AI agents."}}
{"id": "2502.14662", "pdf": "https://arxiv.org/pdf/2502.14662", "abs": "https://arxiv.org/abs/2502.14662", "authors": ["Wujiang Xu", "Yunxiao Shi", "Zujie Liang", "Xuying Ning", "Kai Mei", "Kun Wang", "Xi Zhu", "Min Xu", "Yongfeng Zhang"], "title": "iAgent: LLM Agent as a Shield between User and Recommender Systems", "categories": ["cs.CL", "cs.IR"], "comment": "Findings of ACL 2025 and WWW2025@HCRS", "summary": "Traditional recommender systems usually take the user-platform paradigm,\nwhere users are directly exposed under the control of the platform's\nrecommendation algorithms. However, the defect of recommendation algorithms may\nput users in very vulnerable positions under this paradigm. First, many\nsophisticated models are often designed with commercial objectives in mind,\nfocusing on the platform's benefits, which may hinder their ability to protect\nand capture users' true interests. Second, these models are typically optimized\nusing data from all users, which may overlook individual user's preferences.\nDue to these shortcomings, users may experience several disadvantages under the\ntraditional user-platform direct exposure paradigm, such as lack of control\nover the recommender system, potential manipulation by the platform, echo\nchamber effects, or lack of personalization for less active users due to the\ndominance of active users during collaborative learning. Therefore, there is an\nurgent need to develop a new paradigm to protect user interests and alleviate\nthese issues. Recently, some researchers have introduced LLM agents to simulate\nuser behaviors, these approaches primarily aim to optimize platform-side\nperformance, leaving core issues in recommender systems unresolved. To address\nthese limitations, we propose a new user-agent-platform paradigm, where agent\nserves as the protective shield between user and recommender system that\nenables indirect exposure.", "AI": {"tldr": "The paper critiques traditional recommender systems for prioritizing platform benefits over user interests, proposes a new user-agent-platform paradigm to protect users.", "motivation": "Traditional recommender systems often prioritize commercial goals and overlook individual user preferences, leading to vulnerabilities like lack of control, manipulation, and echo chambers.", "method": "Introduces a user-agent-platform paradigm, where an agent acts as a protective intermediary between users and the platform.", "result": "The proposed paradigm aims to mitigate issues like lack of personalization and platform manipulation by enabling indirect user exposure.", "conclusion": "The new paradigm addresses core flaws in traditional systems, offering better protection and alignment with user interests."}}
{"id": "2505.11308", "pdf": "https://arxiv.org/pdf/2505.11308", "abs": "https://arxiv.org/abs/2505.11308", "authors": ["Lothar Heimbach", "Sebastian Kaltenbach", "Petr Karnakov", "Francis J. Alexander", "Petros Koumoutsakos"], "title": "Reinforcement Learning Closures for Underresolved Partial Differential Equations using Synthetic Data", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Partial Differential Equations (PDEs) describe phenomena ranging from\nturbulence and epidemics to quantum mechanics and financial markets. Despite\nrecent advances in computational science, solving such PDEs for real-world\napplications remains prohibitively expensive because of the necessity of\nresolving a broad range of spatiotemporal scales. In turn, practitioners often\nrely on coarse-grained approximations of the original PDEs, trading off\naccuracy for reduced computational resources. To mitigate the loss of detail\ninherent in such approximations, closure models are employed to represent\nunresolved spatiotemporal interactions. We present a framework for developing\nclosure models for PDEs using synthetic data acquired through the method of\nmanufactured solutions. These data are used in conjunction with reinforcement\nlearning to provide closures for coarse-grained PDEs. We illustrate the\nefficacy of our method using the one-dimensional and two-dimensional Burgers'\nequations and the two-dimensional advection equation. Moreover, we demonstrate\nthat closure models trained for inhomogeneous PDEs can be effectively\ngeneralized to homogeneous PDEs. The results demonstrate the potential for\ndeveloping accurate and computationally efficient closure models for systems\nwith scarce data.", "AI": {"tldr": "A framework using synthetic data and reinforcement learning to develop closure models for coarse-grained PDEs, tested on Burgers' and advection equations.", "motivation": "Solving PDEs for real-world applications is computationally expensive, and coarse-grained approximations lose detail. Closure models are needed to represent unresolved interactions.", "method": "Uses synthetic data from manufactured solutions and reinforcement learning to create closure models for coarse-grained PDEs.", "result": "Effective closure models for 1D/2D Burgers' and 2D advection equations, with generalization to homogeneous PDEs.", "conclusion": "The framework shows promise for accurate, efficient closure models, even with scarce data."}}
{"id": "2410.16430", "pdf": "https://arxiv.org/pdf/2410.16430", "abs": "https://arxiv.org/abs/2410.16430", "authors": ["Zhiming Hu", "Guanhua Zhang", "Zheming Yin", "Daniel Haeufle", "Syn Schmitt", "Andreas Bulling"], "title": "HaHeAE: Learning Generalisable Joint Representations of Human Hand and Head Movements in Extended Reality", "categories": ["cs.CV"], "comment": "Link: https://zhiminghu.net/hu25_haheae", "summary": "Human hand and head movements are the most pervasive input modalities in\nextended reality (XR) and are significant for a wide range of applications.\nHowever, prior works on hand and head modelling in XR only explored a single\nmodality or focused on specific applications. We present HaHeAE - a novel\nself-supervised method for learning generalisable joint representations of hand\nand head movements in XR. At the core of our method is an autoencoder (AE) that\nuses a graph convolutional network-based semantic encoder and a diffusion-based\nstochastic encoder to learn the joint semantic and stochastic representations\nof hand-head movements. It also features a diffusion-based decoder to\nreconstruct the original signals. Through extensive evaluations on three public\nXR datasets, we show that our method 1) significantly outperforms commonly used\nself-supervised methods by up to 74.0% in terms of reconstruction quality and\nis generalisable across users, activities, and XR environments, 2) enables new\napplications, including interpretable hand-head cluster identification and\nvariable hand-head movement generation, and 3) can serve as an effective\nfeature extractor for downstream tasks. Together, these results demonstrate the\neffectiveness of our method and underline the potential of self-supervised\nmethods for jointly modelling hand-head behaviours in extended reality.", "AI": {"tldr": "HaHeAE is a self-supervised method for learning joint representations of hand and head movements in XR, outperforming existing methods by 74% in reconstruction quality and enabling new applications.", "motivation": "Prior works on hand and head modelling in XR were limited to single modalities or specific applications, lacking generalizability.", "method": "Uses an autoencoder with a graph convolutional network-based semantic encoder and diffusion-based stochastic encoder, plus a diffusion-based decoder.", "result": "Outperforms other methods by 74% in reconstruction, generalizes across users/activities/environments, and enables new applications like cluster identification and movement generation.", "conclusion": "Demonstrates the effectiveness of self-supervised methods for joint hand-head modelling in XR, highlighting their potential for diverse applications."}}
{"id": "2504.13837", "pdf": "https://arxiv.org/pdf/2504.13837", "abs": "https://arxiv.org/abs/2504.13837", "authors": ["Yang Yue", "Zhiqi Chen", "Rui Lu", "Andrew Zhao", "Zhaokai Wang", "Yang Yue", "Shiji Song", "Gao Huang"], "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "30 pages, 27 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently\ndemonstrated notable success in enhancing the reasoning performance of large\nlanguage models (LLMs), particularly on mathematics and programming tasks.\nSimilar to how traditional RL helps agents explore and learn new strategies,\nRLVR is believed to enable LLMs to continuously self-improve, thus acquiring\nnovel reasoning abilities beyond those of the corresponding base models. In\nthis study we critically examine the current state of RLVR by systematically\nprobing the reasoning capability boundaries of RLVR-trained LLMs across various\nmodel families, RL algorithms, and math, coding, and visual reasoning\nbenchmarks, using pass@k at large k values as the evaluation metric.\nSurprisingly, we find that the current training setup does not elicit\nfundamentally new reasoning patterns. While RLVR-trained models outperform\ntheir base models at small k (e.g., k = 1), the base models achieve a higher\npass@k score when k is large. Coverage and perplexity analyses show that the\nobserved reasoning abilities originate from and are bounded by the base model.\nTreating the base model as an upper bound, our quantitative analysis shows that\nsix popular RLVR algorithms perform similarly and remain far from optimal in\nleveraging the potential of the base model. By contrast, we find that\ndistillation can introduce new reasoning patterns from the teacher and\ngenuinely expand the model's reasoning capabilities. Overall, our findings\nsuggest that current RLVR methods have not yet realized the potential of RL to\nelicit truly novel reasoning abilities in LLMs. This highlights the need for\nimproved RL paradigms, such as continual scaling and multi-turn\nagent-environment interaction, to unlock this potential.", "AI": {"tldr": "RLVR enhances LLMs' reasoning but doesn't introduce fundamentally new patterns; base models outperform at large k. Distillation shows promise, but current RLVR methods fall short.", "motivation": "To critically examine RLVR's impact on LLMs' reasoning abilities and assess its limitations.", "method": "Systematic evaluation across model families, RL algorithms, and benchmarks using pass@k metrics.", "result": "RLVR-trained models outperform base models at small k but lag at large k. Distillation introduces new reasoning patterns.", "conclusion": "Current RLVR methods don't unlock novel reasoning; improved paradigms like continual scaling are needed."}}
{"id": "2502.15208", "pdf": "https://arxiv.org/pdf/2502.15208", "abs": "https://arxiv.org/abs/2502.15208", "authors": ["Zhilin Wang", "Yafu Li", "Jianhao Yan", "Yu Cheng", "Yue Zhang"], "title": "Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "9 pages", "summary": "Dynamical systems theory provides a framework for analyzing iterative\nprocesses and evolution over time. Within such systems, repetitive\ntransformations can lead to stable configurations, known as attractors,\nincluding fixed points and limit cycles. Applying this perspective to large\nlanguage models (LLMs), which iteratively map input text to output text,\nprovides a principled approach to characterizing long-term behaviors.\nSuccessive paraphrasing serves as a compelling testbed for exploring such\ndynamics, as paraphrases re-express the same underlying meaning with linguistic\nvariation. Although LLMs are expected to explore a diverse set of paraphrases\nin the text space, our study reveals that successive paraphrasing converges to\nstable periodic states, such as 2-period attractor cycles, limiting linguistic\ndiversity. This phenomenon is attributed to the self-reinforcing nature of\nLLMs, as they iteratively favour and amplify certain textual forms over others.\nThis pattern persists with increasing generation randomness or alternating\nprompts and LLMs. These findings underscore inherent constraints in LLM\ngenerative capability, while offering a novel dynamical systems perspective for\nstudying their expressive potential.", "AI": {"tldr": "Successive paraphrasing with LLMs converges to stable periodic states (e.g., 2-period attractor cycles), limiting linguistic diversity due to self-reinforcing textual preferences.", "motivation": "To analyze the long-term behaviors of LLMs using dynamical systems theory, focusing on paraphrasing as a testbed.", "method": "Apply dynamical systems theory to LLMs, using successive paraphrasing to observe convergence to attractor cycles.", "result": "LLMs converge to stable periodic states (e.g., 2-period cycles) in paraphrasing, reducing linguistic diversity.", "conclusion": "LLMs exhibit inherent generative constraints, but dynamical systems theory offers a novel perspective for studying their expressive potential."}}
{"id": "2505.11312", "pdf": "https://arxiv.org/pdf/2505.11312", "abs": "https://arxiv.org/abs/2505.11312", "authors": ["Emanuele Francazi", "Francesco Pinto", "Aurelien Lucchi", "Marco Baity-Jesi"], "title": "Where You Place the Norm Matters: From Prejudiced to Neutral Initializations", "categories": ["cs.LG", "cond-mat.dis-nn"], "comment": null, "summary": "Normalization layers, such as Batch Normalization and Layer Normalization,\nare central components in modern neural networks, widely adopted to improve\ntraining stability and generalization. While their practical effectiveness is\nwell documented, a detailed theoretical understanding of how normalization\naffects model behavior, starting from initialization, remains an important open\nquestion. In this work, we investigate how both the presence and placement of\nnormalization within hidden layers influence the statistical properties of\nnetwork predictions before training begins. In particular, we study how these\nchoices shape the distribution of class predictions at initialization, which\ncan range from unbiased (Neutral) to highly concentrated (Prejudiced) toward a\nsubset of classes. Our analysis shows that normalization placement induces\nsystematic differences in the initial prediction behavior of neural networks,\nwhich in turn shape the dynamics of learning. By linking architectural choices\nto prediction statistics at initialization, our work provides a principled\nunderstanding of how normalization can influence early training behavior and\noffers guidance for more controlled and interpretable network design.", "AI": {"tldr": "The paper explores how normalization layers (e.g., Batch/Layer Normalization) affect neural network behavior at initialization, influencing early training dynamics and class prediction distributions.", "motivation": "To theoretically understand how normalization layers impact model behavior from initialization, addressing gaps in current knowledge.", "method": "Investigates the presence and placement of normalization within hidden layers, analyzing their effect on initial prediction distributions (Neutral to Prejudiced).", "result": "Normalization placement systematically alters initial prediction behavior, shaping learning dynamics and offering insights for network design.", "conclusion": "The study provides a principled framework for understanding normalization's role in early training, aiding more controlled and interpretable network architectures."}}
{"id": "2411.06780", "pdf": "https://arxiv.org/pdf/2411.06780", "abs": "https://arxiv.org/abs/2411.06780", "authors": ["Shubo Lin", "Yutong Kou", "Zirui Wu", "Shaoru Wang", "Bing Li", "Weiming Hu", "Jin Gao"], "title": "SynCL: A Synergistic Training Strategy with Instance-Aware Contrastive Learning for End-to-End Multi-Camera 3D Tracking", "categories": ["cs.CV"], "comment": "11 pages, 6 figures", "summary": "While existing query-based 3D end-to-end visual trackers integrate detection\nand tracking via the tracking-by-attention paradigm, these two chicken-and-egg\ntasks encounter optimization difficulties when sharing the same parameters. Our\nfindings reveal that these difficulties arise due to two inherent constraints\non the self-attention mechanism, i.e., over-deduplication for object queries\nand self-centric attention for track queries. In contrast, removing the\nself-attention mechanism not only minimally impacts regression predictions of\nthe tracker, but also tends to generate more latent candidate boxes. Based on\nthese analyses, we present SynCL, a novel plug-and-play synergistic training\nstrategy designed to co-facilitate multi-task learning for detection and\ntracking. Specifically, we propose a Task-specific Hybrid Matching module for a\nweight-shared cross-attention-based decoder that matches the targets of track\nqueries with multiple object queries to exploit promising candidates overlooked\nby the self-attention mechanism. To flexibly select optimal candidates for the\none-to-many matching, we also design a Dynamic Query Filtering module\ncontrolled by model training status. Moreover, we introduce Instance-aware\nContrastive Learning to break through the barrier of self-centric attention for\ntrack queries, effectively bridging the gap between detection and tracking.\nWithout additional inference costs, SynCL consistently delivers improvements in\nvarious benchmarks and achieves state-of-the-art performance with $58.9\\%$\nAMOTA on the nuScenes dataset. Code and raw results will be publicly available.", "AI": {"tldr": "SynCL introduces a synergistic training strategy for 3D visual tracking, addressing limitations of self-attention in multi-task learning, achieving state-of-the-art performance.", "motivation": "Existing query-based 3D trackers face optimization challenges due to self-attention constraints (over-deduplication and self-centric attention), hindering detection and tracking synergy.", "method": "SynCL includes a Task-specific Hybrid Matching module, Dynamic Query Filtering, and Instance-aware Contrastive Learning to enhance multi-task learning without added inference costs.", "result": "Achieves 58.9% AMOTA on nuScenes, outperforming benchmarks.", "conclusion": "SynCL effectively bridges detection and tracking gaps, offering a plug-and-play solution with significant performance improvements."}}
{"id": "2504.14191", "pdf": "https://arxiv.org/pdf/2504.14191", "abs": "https://arxiv.org/abs/2504.14191", "authors": ["Yansheng Qiu", "Haoquan Zhang", "Zhaopan Xu", "Ming Li", "Diping Song", "Zheng Wang", "Kaipeng Zhang"], "title": "AI Idea Bench 2025: AI Research Idea Generation Benchmark", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large-scale Language Models (LLMs) have revolutionized human-AI interaction\nand achieved significant success in the generation of novel ideas. However,\ncurrent assessments of idea generation overlook crucial factors such as\nknowledge leakage in LLMs, the absence of open-ended benchmarks with grounded\ntruth, and the limited scope of feasibility analysis constrained by prompt\ndesign. These limitations hinder the potential of uncovering groundbreaking\nresearch ideas. In this paper, we present AI Idea Bench 2025, a framework\ndesigned to quantitatively evaluate and compare the ideas generated by LLMs\nwithin the domain of AI research from diverse perspectives. The framework\ncomprises a comprehensive dataset of 3,495 AI papers and their associated\ninspired works, along with a robust evaluation methodology. This evaluation\nsystem gauges idea quality in two dimensions: alignment with the ground-truth\ncontent of the original papers and judgment based on general reference\nmaterial. AI Idea Bench 2025's benchmarking system stands to be an invaluable\nresource for assessing and comparing idea-generation techniques, thereby\nfacilitating the automation of scientific discovery.", "AI": {"tldr": "AI Idea Bench 2025 is a framework to evaluate LLM-generated ideas in AI research, addressing current assessment gaps like knowledge leakage and lack of open-ended benchmarks.", "motivation": "Current evaluations of LLM-generated ideas overlook key factors like knowledge leakage and grounded truth, limiting potential breakthroughs.", "method": "The framework uses a dataset of 3,495 AI papers and inspired works, evaluating idea quality via alignment with original content and general references.", "result": "AI Idea Bench 2025 provides a robust benchmarking system for comparing idea-generation techniques.", "conclusion": "This framework aids in automating scientific discovery by improving the assessment of LLM-generated ideas."}}
{"id": "2503.04807", "pdf": "https://arxiv.org/pdf/2503.04807", "abs": "https://arxiv.org/abs/2503.04807", "authors": ["Hyeonseok Moon", "Jaehyung Seo", "Heuiseok Lim"], "title": "Call for Rigor in Reporting Quality of Instruction Tuning Data", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to the ACL2025-main", "summary": "Instruction tuning is crucial for adapting large language models (LLMs) to\nalign with user intentions. Numerous studies emphasize the significance of the\nquality of instruction tuning (IT) data, revealing a strong correlation between\nIT data quality and the alignment performance of LLMs. In these studies, the\nquality of IT data is typically assessed by evaluating the performance of LLMs\ntrained with that data. However, we identified a prevalent issue in such\npractice: hyperparameters for training models are often selected arbitrarily\nwithout adequate justification. We observed significant variations in\nhyperparameters applied across different studies, even when training the same\nmodel with the same data. In this study, we demonstrate the potential problems\narising from this practice and emphasize the need for careful consideration in\nverifying data quality. Through our experiments on the quality of LIMA data and\na selected set of 1,000 Alpaca data points, we demonstrate that arbitrary\nhyperparameter decisions can make any arbitrary conclusion.", "AI": {"tldr": "The paper highlights issues with arbitrary hyperparameter selection in instruction tuning (IT) for LLMs, showing it can lead to unreliable conclusions about IT data quality.", "motivation": "To address the lack of justification in hyperparameter selection for IT studies, which can skew evaluations of IT data quality.", "method": "Conducted experiments using LIMA data and 1,000 Alpaca data points to analyze the impact of hyperparameter choices.", "result": "Found that arbitrary hyperparameter decisions can lead to any arbitrary conclusion about IT data quality.", "conclusion": "Emphasizes the need for careful hyperparameter selection to ensure reliable evaluation of IT data quality."}}
{"id": "2505.11321", "pdf": "https://arxiv.org/pdf/2505.11321", "abs": "https://arxiv.org/abs/2505.11321", "authors": ["Pu Yang", "J. A. Barria"], "title": "Anomaly Detection for Non-stationary Time Series using Recurrent Wavelet Probabilistic Neural Network", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "In this paper, an unsupervised Recurrent Wavelet Probabilistic Neural Network\n(RWPNN) is proposed, which aims at detecting anomalies in non-stationary\nenvironments by modelling the temporal features using a nonparametric density\nestimation network. The novel framework consists of two components, a Stacked\nRecurrent Encoder-Decoder (SREnc-Dec) module that captures temporal features in\na latent space, and a Multi-Receptive-field Wavelet Probabilistic Network\n(MRWPN) that creates an ensemble probabilistic model to characterise the latent\nspace. This formulation extends the standard wavelet probabilistic networks to\nwavelet deep probabilistic networks, which can handle higher data\ndimensionality. The MRWPN module can adapt to different rates of data variation\nin different datasets without imposing strong distribution assumptions,\nresulting in a more robust and accurate detection for Time Series Anomaly\nDetection (TSAD) tasks in the non-stationary environment. We carry out the\nassessment on 45 real-world time series datasets from various domains, verify\nthe performance of RWPNN in TSAD tasks with several constraints, and show its\nability to provide early warnings for anomalous events.", "AI": {"tldr": "Proposes an unsupervised RWPNN for anomaly detection in non-stationary environments, combining temporal feature modeling with nonparametric density estimation.", "motivation": "Addresses the challenge of detecting anomalies in non-stationary environments where traditional methods may fail due to data variability.", "method": "Uses a Stacked Recurrent Encoder-Decoder (SREnc-Dec) for temporal features and a Multi-Receptive-field Wavelet Probabilistic Network (MRWPN) for probabilistic modeling.", "result": "Demonstrates robust and accurate anomaly detection across 45 real-world datasets, with early warning capabilities.", "conclusion": "RWPNN effectively handles high-dimensional data and non-stationary conditions, outperforming traditional methods."}}
{"id": "2411.17141", "pdf": "https://arxiv.org/pdf/2411.17141", "abs": "https://arxiv.org/abs/2411.17141", "authors": ["Xu Zheng", "Haiwei Xue", "Jialei Chen", "Yibo Yan", "Lutao Jiang", "Yuanhuiyi Lyu", "Kailun Yang", "Linfeng Zhang", "Xuming Hu"], "title": "Learning Robust Anymodal Segmentor with Unimodal and Cross-modal Distillation", "categories": ["cs.CV"], "comment": "Preprint", "summary": "Simultaneously using multimodal inputs from multiple sensors to train\nsegmentors is intuitively advantageous but practically challenging. A key\nchallenge is unimodal bias, where multimodal segmentors over rely on certain\nmodalities, causing performance drops when others are missing, common in real\nworld applications. To this end, we develop the first framework for learning\nrobust segmentor that can handle any combinations of visual modalities.\nSpecifically, we first introduce a parallel multimodal learning strategy for\nlearning a strong teacher. The cross-modal and unimodal distillation is then\nachieved in the multi scale representation space by transferring the feature\nlevel knowledge from multimodal to anymodal segmentors, aiming at addressing\nthe unimodal bias and avoiding over-reliance on specific modalities. Moreover,\na prediction level modality agnostic semantic distillation is proposed to\nachieve semantic knowledge transferring for segmentation. Extensive experiments\non both synthetic and real-world multi-sensor benchmarks demonstrate that our\nmethod achieves superior performance.", "AI": {"tldr": "A framework for robust multimodal segmentation is proposed, addressing unimodal bias through distillation techniques.", "motivation": "Multimodal segmentors often over-rely on certain modalities, leading to performance drops when others are missing.", "method": "Uses parallel multimodal learning, cross-modal distillation, and modality-agnostic semantic distillation.", "result": "Superior performance on synthetic and real-world benchmarks.", "conclusion": "The framework effectively mitigates unimodal bias and enhances robustness in multimodal segmentation."}}
{"id": "2504.20445", "pdf": "https://arxiv.org/pdf/2504.20445", "abs": "https://arxiv.org/abs/2504.20445", "authors": ["Tianqing Zhang", "Zixin Zhu", "Kairong Yu", "Hongwei Wang"], "title": "Head-Tail-Aware KL Divergence in Knowledge Distillation for Spiking Neural Networks", "categories": ["cs.AI"], "comment": "Accepted by IJCNN2025", "summary": "Spiking Neural Networks (SNNs) have emerged as a promising approach for\nenergy-efficient and biologically plausible computation. However, due to\nlimitations in existing training methods and inherent model constraints, SNNs\noften exhibit a performance gap when compared to Artificial Neural Networks\n(ANNs). Knowledge distillation (KD) has been explored as a technique to\ntransfer knowledge from ANN teacher models to SNN student models to mitigate\nthis gap. Traditional KD methods typically use Kullback-Leibler (KL) divergence\nto align output distributions. However, conventional KL-based approaches fail\nto fully exploit the unique characteristics of SNNs, as they tend to\noveremphasize high-probability predictions while neglecting low-probability\nones, leading to suboptimal generalization. To address this, we propose\nHead-Tail Aware Kullback-Leibler (HTA-KL) divergence, a novel KD method for\nSNNs. HTA-KL introduces a cumulative probability-based mask to dynamically\ndistinguish between high- and low-probability regions. It assigns adaptive\nweights to ensure balanced knowledge transfer, enhancing the overall\nperformance. By integrating forward KL (FKL) and reverse KL (RKL) divergence,\nour method effectively align both head and tail regions of the distribution. We\nevaluate our methods on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets. Our\nmethod outperforms existing methods on most datasets with fewer timesteps.", "AI": {"tldr": "The paper proposes a novel knowledge distillation method, HTA-KL, to improve SNN performance by balancing knowledge transfer between high- and low-probability predictions.", "motivation": "SNNs lag behind ANNs in performance due to training limitations. Existing KD methods using KL divergence inadequately address SNN-specific needs.", "method": "Introduces HTA-KL divergence, a cumulative probability-based mask to dynamically weight high- and low-probability regions, combining FKL and RKL.", "result": "Outperforms existing methods on CIFAR-10, CIFAR-100, and Tiny ImageNet with fewer timesteps.", "conclusion": "HTA-KL effectively bridges the performance gap between SNNs and ANNs by optimizing knowledge transfer."}}
{"id": "2503.10995", "pdf": "https://arxiv.org/pdf/2503.10995", "abs": "https://arxiv.org/abs/2503.10995", "authors": ["Nishat Raihan", "Marcos Zampieri"], "title": "TigerLLM -- A Family of Bangla Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The development of Large Language Models (LLMs) remains heavily skewed\ntowards English and a few other high-resource languages. This linguistic\ndisparity is particularly evident for Bangla - the 5th most spoken language. A\nfew initiatives attempted to create open-source Bangla LLMs with performance\nstill behind high-resource languages and limited reproducibility. To address\nthis gap, we introduce TigerLLM - a family of Bangla LLMs. Our results\ndemonstrate that these models surpass all open-source alternatives and also\noutperform larger proprietary models like GPT3.5 across standard benchmarks,\nestablishing TigerLLM as the new baseline for future Bangla language modeling.", "AI": {"tldr": "TigerLLM is introduced as a family of Bangla LLMs, outperforming existing open-source and proprietary models like GPT3.5, setting a new benchmark for Bangla language modeling.", "motivation": "Addressing the linguistic disparity in LLM development, particularly for Bangla, which lacks high-performance open-source models.", "method": "Development of TigerLLM, a family of Bangla LLMs.", "result": "TigerLLM surpasses all open-source alternatives and outperforms larger proprietary models like GPT3.5 on standard benchmarks.", "conclusion": "TigerLLM establishes a new baseline for future Bangla language modeling."}}
{"id": "2505.11335", "pdf": "https://arxiv.org/pdf/2505.11335", "abs": "https://arxiv.org/abs/2505.11335", "authors": ["Jincheng Huang", "Jie Xu", "Xiaoshuang Shi", "Ping Hu", "Lei Feng", "Xiaofeng Zhu"], "title": "The Final Layer Holds the Key: A Unified and Efficient GNN Calibration Framework", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness on\ngraph-based tasks. However, their predictive confidence is often miscalibrated,\ntypically exhibiting under-confidence, which harms the reliability of their\ndecisions. Existing calibration methods for GNNs normally introduce additional\ncalibration components, which fail to capture the intrinsic relationship\nbetween the model and the prediction confidence, resulting in limited\ntheoretical guarantees and increased computational overhead. To address this\nissue, we propose a simple yet efficient graph calibration method. We establish\na unified theoretical framework revealing that model confidence is jointly\ngoverned by class-centroid-level and node-level calibration at the final layer.\nBased on this insight, we theoretically show that reducing the weight decay of\nthe final-layer parameters alleviates GNN under-confidence by acting on the\nclass-centroid level, while node-level calibration acts as a finer-grained\ncomplement to class-centroid level calibration, which encourages each test node\nto be closer to its predicted class centroid at the final-layer\nrepresentations. Extensive experiments validate the superiority of our method.", "AI": {"tldr": "A new graph calibration method for GNNs addresses under-confidence by analyzing class-centroid and node-level calibration at the final layer, reducing weight decay for better reliability.", "motivation": "GNNs often exhibit miscalibrated confidence, harming decision reliability, and existing methods lack theoretical guarantees and add computational overhead.", "method": "Proposes a unified framework linking model confidence to class-centroid and node-level calibration, reducing final-layer weight decay for under-confidence.", "result": "Extensive experiments show the method's superiority in improving GNN confidence calibration.", "conclusion": "The method efficiently addresses GNN under-confidence with theoretical backing and practical validation."}}
{"id": "2411.18711", "pdf": "https://arxiv.org/pdf/2411.18711", "abs": "https://arxiv.org/abs/2411.18711", "authors": ["Mohamed Aghzal", "Xiang Yue", "Erion Plaku", "Ziyu Yao"], "title": "Evaluating Vision-Language Models as Evaluators in Path Planning", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted to the 2025 IEEE / CVF Computer Vision and Pattern\n  Recognition Conference (CVPR)", "summary": "Despite their promise to perform complex reasoning, large language models\n(LLMs) have been shown to have limited effectiveness in end-to-end planning.\nThis has inspired an intriguing question: if these models cannot plan well, can\nthey still contribute to the planning framework as a helpful plan evaluator? In\nthis work, we generalize this question to consider LLMs augmented with visual\nunderstanding, i.e., Vision-Language Models (VLMs). We introduce PathEval, a\nnovel benchmark evaluating VLMs as plan evaluators in complex path-planning\nscenarios. Succeeding in the benchmark requires a VLM to be able to abstract\ntraits of optimal paths from the scenario description, demonstrate precise\nlow-level perception on each path, and integrate this information to decide the\nbetter path. Our analysis of state-of-the-art VLMs reveals that these models\nface significant challenges on the benchmark. We observe that the VLMs can\nprecisely abstract given scenarios to identify the desired traits and exhibit\nmixed performance in integrating the provided information. Yet, their vision\ncomponent presents a critical bottleneck, with models struggling to perceive\nlow-level details about a path. Our experimental results show that this issue\ncannot be trivially addressed via end-to-end fine-tuning; rather, task-specific\ndiscriminative adaptation of these vision encoders is needed for these VLMs to\nbecome effective path evaluators.", "AI": {"tldr": "The paper introduces PathEval, a benchmark to evaluate Vision-Language Models (VLMs) as plan evaluators in path-planning tasks, revealing their challenges in low-level perception and integration.", "motivation": "To explore if VLMs, despite limitations in planning, can serve as effective plan evaluators in complex scenarios.", "method": "PathEval benchmark assesses VLMs' ability to abstract optimal path traits, demonstrate precise perception, and integrate information.", "result": "VLMs struggle with low-level vision details, hindering performance, and fine-tuning alone doesn't resolve this. Task-specific adaptation is needed.", "conclusion": "VLMs show promise as evaluators but require improved vision encoders for effective path-planning evaluation."}}
{"id": "2505.08905", "pdf": "https://arxiv.org/pdf/2505.08905", "abs": "https://arxiv.org/abs/2505.08905", "authors": ["Michael Majurski", "Cynthia Matuszek"], "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users may ask them to generate in some form during their training.\nA plethora of evaluation benchmarks have been constructed to assess model\nquality, response appropriateness, and reasoning capabilities. However, the\nhuman effort required for benchmark construction is rapidly being outpaced by\nthe size and scope of the models under evaluation. Having humans build a\nbenchmark for every possible domain of interest is impractical. Therefore, we\npropose a methodology for automating the construction of fact-based synthetic\ndata model evaluations grounded in document populations. This work leverages\nthe same LMs to evaluate domain-specific knowledge automatically, using only\ngrounding documents (e.g., a textbook) as input. This synthetic data\nbenchmarking approach corresponds well with human curated questions producing a\nSpearman ranking correlation of 0.97 and a benchmark evaluation Pearson\naccuracy correlation of 0.75. This novel approach supports generating both\nmultiple choice and open-ended synthetic data questions to gain diagnostic\ninsight of LM capability. We apply this methodology to evaluate model\nperformance on two recent arXiv preprints, discovering a surprisingly strong\nperformance from Gemma-3 models on open-ended questions. Code is available at\nhttps://github.com/mmajurski/grounded-synth-lm-benchmark", "AI": {"tldr": "The paper proposes an automated method for creating fact-based synthetic benchmarks to evaluate language models (LMs) using grounding documents, reducing reliance on human effort.", "motivation": "Human effort in benchmark construction is outpaced by the scale of LMs, making manual evaluation impractical.", "method": "Leverages LMs to automatically generate domain-specific evaluation questions from grounding documents (e.g., textbooks).", "result": "Achieves high correlation with human-curated benchmarks (Spearman 0.97, Pearson 0.75) and reveals strong performance of Gemma-3 models.", "conclusion": "The automated approach efficiently evaluates LM capabilities and supports diverse question formats, offering scalable benchmarking."}}
{"id": "2503.16525", "pdf": "https://arxiv.org/pdf/2503.16525", "abs": "https://arxiv.org/abs/2503.16525", "authors": ["Huan Yang", "Renji Zhang", "Mingzhe Huang", "Weijun Wang", "Yin Tang", "Yuanchun Li", "Yunxin Liu", "Deyu Zhang"], "title": "KVShare: An LLM Service System with Efficient and Effective Multi-Tenant KV Cache Reuse", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in long-text understanding have pushed the context length of\nlarge language models (LLMs) up to one million tokens. It boosts LLMs's\naccuracy and reasoning capacity but causes exorbitant computational costs and\nunsatisfactory Time to First Token (TTFT). KV cache reuse, which reuses the\nexact same KV cache of prefixes and templates or shares similar ones but with\nextra selective recomputation, offers a promising way to tackle this issue.\nHowever, prior studies overlook the cross-request KV reuse and the attention\ndeviations introduced by new tokens during the decoding stage. In this paper,\nwe present a KV cache management module that shares the KV cache across\nrequests under multi-tenant scenarios without sacrificing model accuracy. Our\nsystem, KVShare, enables accurate and efficient LLM serving by 1) a Dual-Stage\nHigh Deviation algorithm (DHD) that conditionally selects a small portion of KV\ncache to be recomputed during both prefill and decode phases, and 2) a\ncache-aware scheduler that prioritizes requests based on their KV cache hit\nrates and orchestrates continuous batching to achieve enhanced system\nefficiency and faster TTFT. Multi-task experiments conducted on models such as\nQwen2.5-7B,Llama3.1-8B and Yi1.5-9B demonstrate that KVShare reduces TTFT by up\nto 9.39x and increases 1.2x of the throughput compared to the full KV\nrecompute. Moreover, KVShare achieves 20.38% boost in terms of accuracy\ncompared to SOTA methods.", "AI": {"tldr": "KVShare, a KV cache management module, improves LLM serving efficiency by reusing KV caches across requests, reducing TTFT by 9.39x and boosting throughput by 1.2x while maintaining accuracy.", "motivation": "Addressing the high computational costs and slow TTFT in long-text LLMs by enabling efficient KV cache reuse across requests without sacrificing accuracy.", "method": "Introduces KVShare with a Dual-Stage High Deviation algorithm (DHD) for selective KV cache recomputation and a cache-aware scheduler for request prioritization and batching.", "result": "KVShare reduces TTFT by up to 9.39x, increases throughput by 1.2x, and improves accuracy by 20.38% over SOTA methods.", "conclusion": "KVShare effectively balances efficiency and accuracy in LLM serving, making it a viable solution for multi-tenant scenarios."}}
{"id": "2505.11342", "pdf": "https://arxiv.org/pdf/2505.11342", "abs": "https://arxiv.org/abs/2505.11342", "authors": ["Andrew W. Rosemberg", "Joaquim Dias Garcia", "Russell Bent", "Pascal Van Hentenryck"], "title": "Sobolev Training of End-to-End Optimization Proxies", "categories": ["cs.LG", "math.OC"], "comment": "9 Pages, 4 Figures, 5 Tables", "summary": "Optimization proxies - machine learning models trained to approximate the\nsolution mapping of parametric optimization problems in a single forward pass -\noffer dramatic reductions in inference time compared to traditional iterative\nsolvers. This work investigates the integration of solver sensitivities into\nsuch end to end proxies via a Sobolev training paradigm and does so in two\ndistinct settings: (i) fully supervised proxies, where exact solver outputs and\nsensitivities are available, and (ii) self supervised proxies that rely only on\nthe objective and constraint structure of the underlying optimization problem.\nBy augmenting the standard training loss with directional derivative\ninformation extracted from the solver, the proxy aligns both its predicted\nsolutions and local derivatives with those of the optimizer. Under Lipschitz\ncontinuity assumptions on the true solution mapping, matching first order\nsensitivities is shown to yield uniform approximation error proportional to the\ntraining set covering radius. Empirically, different impacts are observed in\neach studied setting. On three large Alternating Current Optimal Power Flow\nbenchmarks, supervised Sobolev training cuts mean squared error by up to 56\npercent and the median worst case constraint violation by up to 400 percent\nwhile keeping the optimality gap below 0.22 percent. For a mean variance\nportfolio task trained without labeled solutions, self supervised Sobolev\ntraining halves the average optimality gap in the medium risk region (standard\ndeviation above 10 percent of budget) and matches the baseline elsewhere.\nTogether, these results highlight Sobolev training whether supervised or self\nsupervised as a path to fast reliable surrogates for safety critical large\nscale optimization workloads.", "AI": {"tldr": "Optimization proxies, trained via Sobolev training, improve accuracy and reduce errors by integrating solver sensitivities, showing significant gains in supervised and self-supervised settings.", "motivation": "To enhance optimization proxies by aligning their predictions and derivatives with those of traditional solvers, ensuring faster and more reliable solutions for large-scale problems.", "method": "Uses Sobolev training to integrate solver sensitivities into proxies, tested in supervised (exact outputs available) and self-supervised (only objective/constraint structure) settings.", "result": "Supervised training reduces errors by 56% and constraint violations by 400%; self-supervised training halves optimality gaps in medium-risk regions.", "conclusion": "Sobolev training, whether supervised or self-supervised, provides fast and reliable surrogates for large-scale optimization tasks."}}
{"id": "2412.01240", "pdf": "https://arxiv.org/pdf/2412.01240", "abs": "https://arxiv.org/abs/2412.01240", "authors": ["Xiaoqi Zhao", "Youwei Pang", "Shijie Chang", "Yuan Zhao", "Lihe Zhang", "Huchuan Lu", "Georges El Fakhri", "Xiaofeng Liu"], "title": "Inspiring the Next Generation of Segment Anything Models: Comprehensively Evaluate SAM and SAM 2 with Diverse Prompts Towards Context-Dependent Concepts under Different Scenes", "categories": ["cs.CV"], "comment": null, "summary": "As a foundational model, SAM has significantly influenced multiple fields\nwithin computer vision, and its upgraded version, SAM 2, enhances capabilities\nin video segmentation, poised to make a substantial impact once again. While\nSAMs (SAM and SAM 2) have demonstrated excellent performance in segmenting\ncontext-independent concepts like people, cars, and roads, they overlook more\nchallenging context-dependent (CD) concepts, such as visual saliency,\ncamouflage, product defects, and medical lesions. CD concepts rely heavily on\nglobal and local contextual information, making them susceptible to shifts in\ndifferent contexts, which requires strong discriminative capabilities from the\nmodel. The lack of comprehensive evaluation of SAMs limits understanding of\ntheir performance boundaries, which may hinder the design of future models. In\nthis paper, we conduct a thorough quantitative evaluation of SAMs on 11 CD\nconcepts across 2D and 3D images and videos in various visual modalities within\nnatural, medical, and industrial scenes. We develop a unified evaluation\nframework for SAM and SAM 2 that supports manual, automatic, and intermediate\nself-prompting, aided by our specific prompt generation and interaction\nstrategies. We further explore the potential of SAM 2 for in-context learning\nand introduce prompt robustness testing to simulate real-world imperfect\nprompts. Finally, we analyze the benefits and limitations of SAMs in\nunderstanding CD concepts and discuss their future development in segmentation\ntasks. This work aims to provide valuable insights to guide future research in\nboth context-independent and context-dependent concepts segmentation,\npotentially informing the development of the next version -- SAM 3.", "AI": {"tldr": "The paper evaluates SAM and SAM 2's performance on context-dependent (CD) concepts, introduces a unified evaluation framework, and discusses their potential and limitations for future segmentation models like SAM 3.", "motivation": "SAM and SAM 2 excel in segmenting context-independent concepts but overlook CD concepts, which rely on contextual information. A lack of comprehensive evaluation limits understanding of their performance boundaries.", "method": "The study conducts a quantitative evaluation on 11 CD concepts across 2D/3D images and videos, using a unified framework with manual, automatic, and self-prompting strategies. It also tests SAM 2's in-context learning and prompt robustness.", "result": "The evaluation reveals SAMs' strengths and weaknesses in handling CD concepts, providing insights into their discriminative capabilities and limitations.", "conclusion": "The work offers guidance for future research on CD concept segmentation and informs the development of SAM 3, highlighting the need for improved contextual understanding."}}
{"id": "2505.10074", "pdf": "https://arxiv.org/pdf/2505.10074", "abs": "https://arxiv.org/abs/2505.10074", "authors": ["Mohamed Abdelmagied", "Mohamed Amine Chatti", "Shoeb Joarder", "Qurat Ul Ain", "Rawaa Alatrash"], "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs", "categories": ["cs.AI", "cs.CY"], "comment": "Accepted at EMOOCs 2025", "summary": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience.", "AI": {"tldr": "The paper proposes a Graph RAG pipeline using Educational and Personal Knowledge Graphs to enhance MOOC learning by generating personalized questions and answers, addressing LLM hallucinations and unstructured material limitations.", "motivation": "MOOCs lack direct interaction, and LLMs are unreliable due to hallucinations. RAG helps but is limited by unstructured material and passive guidance.", "method": "A Graph RAG pipeline integrates EduKGs and PKGs for personalized question generation and answering, tested on CourseMapper with expert instructors.", "result": "Evaluation shows Graph RAG's potential to improve personalized learning in MOOCs.", "conclusion": "Graph RAG effectively guides learners in MOOCs, enhancing understanding of new concepts."}}
{"id": "2503.16529", "pdf": "https://arxiv.org/pdf/2503.16529", "abs": "https://arxiv.org/abs/2503.16529", "authors": ["Wenjing Zhang", "Xuejiao Lei", "Zhaoxiang Liu", "Limin Han", "Jiaojiao Zhao", "Junting Guo", "Zhenhong Long", "Shu Yang", "Meijuan An", "Beibei Huang", "Rongjia Du", "Ning Wang", "Kai Wang", "Shiguo Lian"], "title": "Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "21 pages, 13 figures, 4 tables", "summary": "DeepSeek-R1, renowned for its exceptional reasoning capabilities and\nopen-source strategy, is significantly influencing the global artificial\nintelligence landscape. However, it exhibits notable safety shortcomings.\nRecent research conducted by Robust Intelligence, a subsidiary of Cisco, in\ncollaboration with the University of Pennsylvania, revealed that DeepSeek-R1\nachieves a 100\\% attack success rate when processing harmful prompts.\nFurthermore, multiple security firms and research institutions have identified\ncritical security vulnerabilities within the model. Although China Unicom has\nuncovered safety vulnerabilities of R1 in Chinese contexts, the safety\ncapabilities of the remaining distilled models in the R1 series have not yet\nbeen comprehensively evaluated. To address this gap, this study utilizes the\ncomprehensive Chinese safety benchmark CHiSafetyBench to conduct an in-depth\nsafety evaluation of the DeepSeek-R1 series distilled models. The objective is\nto assess the safety capabilities of these models in Chinese contexts both\nbefore and after distillation, and to further elucidate the adverse effects of\ndistillation on model safety. Building on these findings, we implement targeted\nsafety enhancements for the entire DeepSeek-R1 model series. Evaluation results\nindicate that the enhanced models achieve significant improvements in safety\nwhile maintaining reasoning capabilities without notable degradation. We\nopen-source the safety-enhanced models at\nhttps://github.com/UnicomAI/DeepSeek-R1-Safe to serve as a valuable resource\nfor future research and optimization of DeepSeek models.", "AI": {"tldr": "The study evaluates the safety of DeepSeek-R1 distilled models in Chinese contexts using CHiSafetyBench, implements safety enhancements, and open-sources the improved models.", "motivation": "DeepSeek-R1 has notable safety vulnerabilities, especially in Chinese contexts, but the safety of its distilled models remains unassessed.", "method": "Uses CHiSafetyBench to evaluate safety before and after distillation, then implements targeted safety enhancements.", "result": "Enhanced models show significant safety improvements without compromising reasoning capabilities.", "conclusion": "The open-sourced safety-enhanced models provide a resource for future research and optimization of DeepSeek models."}}
{"id": "2505.11346", "pdf": "https://arxiv.org/pdf/2505.11346", "abs": "https://arxiv.org/abs/2505.11346", "authors": ["Andreas Roth", "Thomas Liebig"], "title": "What Can We Learn From MIMO Graph Convolutions?", "categories": ["cs.LG"], "comment": "IJCAI 2025", "summary": "Most graph neural networks (GNNs) utilize approximations of the general graph\nconvolution derived in the graph Fourier domain. While GNNs are typically\napplied in the multi-input multi-output (MIMO) case, the approximations are\nperformed in the single-input single-output (SISO) case. In this work, we first\nderive the MIMO graph convolution through the convolution theorem and\napproximate it directly in the MIMO case. We find the key MIMO-specific\nproperty of the graph convolution to be operating on multiple computational\ngraphs, or equivalently, applying distinct feature transformations for each\npair of nodes. As a localized approximation, we introduce localized MIMO graph\nconvolutions (LMGCs), which generalize many linear message-passing neural\nnetworks. For almost every choice of edge weights, we prove that LMGCs with a\nsingle computational graph are injective on multisets, and the resulting\nrepresentations are linearly independent when more than one computational graph\nis used. Our experimental results confirm that an LMGC can combine the benefits\nof various methods.", "AI": {"tldr": "The paper introduces localized MIMO graph convolutions (LMGCs) as a generalization of linear message-passing neural networks, proving their injective properties and demonstrating their effectiveness in combining benefits of various methods.", "motivation": "Existing GNNs approximate graph convolutions in the SISO case, but practical applications often involve MIMO scenarios. The paper aims to derive and approximate the MIMO graph convolution directly.", "method": "The authors derive the MIMO graph convolution via the convolution theorem and approximate it directly in the MIMO case. They introduce LMGCs as a localized approximation, proving their injective properties and linear independence.", "result": "LMGCs generalize many linear message-passing neural networks and are shown to be injective on multisets with a single computational graph, while using multiple graphs ensures linearly independent representations.", "conclusion": "LMGCs effectively combine the benefits of various methods, as confirmed by experimental results, offering a robust framework for MIMO graph convolutions."}}
{"id": "2412.04729", "pdf": "https://arxiv.org/pdf/2412.04729", "abs": "https://arxiv.org/abs/2412.04729", "authors": ["Keunwoo Peter Yu", "Achal Dave", "Rares Ambrus", "Jean Mercat"], "title": "Espresso: High Compression For Rich Extraction From Videos for Your Vision-Language Model", "categories": ["cs.CV"], "comment": "16 pages", "summary": "Recent advances in vision-language models (VLMs) have shown great promise in\nconnecting images and text, but extending these models to long videos remains\nchallenging due to the rapid growth in token counts. Models that compress\nvideos by local aggregation in time or space have become popular for handling\nlong-form inputs; however, these pooling-based projectors sacrifice the\nbenefits of fixed-length representations that are crucial for streaming and\nefficient video understanding. We introduce $\\texttt{Espresso}$, a new\narchitecture that separately compresses spatial and temporal features into\nfixed-length sequences. $\\texttt{Espresso}$ enables efficient video encoding\nwhile maintaining strong long-form reasoning capabilities. Experiments show\nthat fixed-length compression combined with segment-wise processing offers a\nscalable and competitive alternative to pooling-based approaches. Our results\ndemonstrate that fixed-length projectors, when properly designed and trained,\nremain a viable foundation for video-language modeling.", "AI": {"tldr": "Espresso is a new architecture for compressing spatial and temporal features in videos into fixed-length sequences, enabling efficient video encoding while maintaining strong reasoning capabilities.", "motivation": "Extending vision-language models to long videos is challenging due to high token counts, and existing pooling-based methods sacrifice fixed-length representations.", "method": "Espresso separately compresses spatial and temporal features into fixed-length sequences, combining fixed-length compression with segment-wise processing.", "result": "Experiments show Espresso offers a scalable and competitive alternative to pooling-based approaches, maintaining strong long-form reasoning.", "conclusion": "Fixed-length projectors, like Espresso, are viable for video-language modeling when properly designed and trained."}}
{"id": "2305.17570", "pdf": "https://arxiv.org/pdf/2305.17570", "abs": "https://arxiv.org/abs/2305.17570", "authors": ["Ben Chugg", "Santiago Cortes-Gomez", "Bryan Wilder", "Aaditya Ramdas"], "title": "Auditing Fairness by Betting", "categories": ["stat.ML", "cs.AI", "cs.CY", "cs.LG", "stat.AP", "stat.ME"], "comment": "Accepted to NeurIPS 2023. 28 pages, 5 figures", "summary": "We provide practical, efficient, and nonparametric methods for auditing the\nfairness of deployed classification and regression models. Whereas previous\nwork relies on a fixed-sample size, our methods are sequential and allow for\nthe continuous monitoring of incoming data, making them highly amenable to\ntracking the fairness of real-world systems. We also allow the data to be\ncollected by a probabilistic policy as opposed to sampled uniformly from the\npopulation. This enables auditing to be conducted on data gathered for another\npurpose. Moreover, this policy may change over time and different policies may\nbe used on different subpopulations. Finally, our methods can handle\ndistribution shift resulting from either changes to the model or changes in the\nunderlying population. Our approach is based on recent progress in\nanytime-valid inference and game-theoretic statistics-the \"testing by betting\"\nframework in particular. These connections ensure that our methods are\ninterpretable, fast, and easy to implement. We demonstrate the efficacy of our\napproach on three benchmark fairness datasets.", "AI": {"tldr": "The paper introduces sequential, nonparametric methods for auditing fairness in deployed models, allowing continuous monitoring and handling dynamic data policies and distribution shifts.", "motivation": "Existing fairness auditing methods rely on fixed-sample sizes and uniform sampling, limiting their practicality for real-world, dynamic systems.", "method": "The approach leverages anytime-valid inference and game-theoretic statistics (testing by betting framework) to enable interpretable, fast, and easy-to-implement fairness auditing.", "result": "The methods are demonstrated effective on three benchmark fairness datasets, accommodating probabilistic data collection and distribution shifts.", "conclusion": "The proposed sequential auditing methods are practical, efficient, and adaptable to real-world scenarios with dynamic data and policies."}}
{"id": "2503.23362", "pdf": "https://arxiv.org/pdf/2503.23362", "abs": "https://arxiv.org/abs/2503.23362", "authors": ["Jia-Chen Zhang", "Yu-Jie Xiong", "Xi-He Qiu", "Chun-Ming Xia", "Fei Dai"], "title": "Mixture of Routers", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages,4 figures", "summary": "Supervised fine-tuning (SFT) is a milestone in aligning large language models\nwith human instructions and adapting them to downstream tasks. In particular,\nLow-Rank Adaptation (LoRA) has gained widespread attention due to its parameter\nefficiency. However, its impact on improving the performance of large models\nremains limited. Recent studies suggest that combining LoRA with\nMixture-of-Experts (MoE) can significantly enhance fine-tuning performance. MoE\nadapts to the diversity and complexity of datasets by dynamically selecting the\nmost suitable experts, thereby improving task accuracy and efficiency. Despite\nimpressive results, recent studies reveal issues in the MoE routing mechanism,\nsuch as incorrect assignments and imbalanced expert allocation. Inspired by the\nprinciples of Redundancy and Fault Tolerance Theory. We innovatively integrate\nthe concept of Mixture of Experts into the routing mechanism and propose an\nefficient fine-tuning method called Mixture of Routers (MoR). It employs\nmultiple sub-routers for joint selection and uses a learnable main router to\ndetermine the weights of the sub-routers. The results show that MoR outperforms\nbaseline models on most tasks, achieving an average performance improvement of\n1%. MoR can serve as a plug-and-play, parameter-efficient fine-tuning method\nsuitable for a wide range of applications. Our code is available here:\nhttps://anonymous.4open.science/r/MoR-DFC6.", "AI": {"tldr": "The paper introduces Mixture of Routers (MoR), a parameter-efficient fine-tuning method combining LoRA and MoE to improve performance by addressing routing issues.", "motivation": "To enhance fine-tuning performance of large models by solving MoE routing problems like incorrect assignments and imbalanced expert allocation.", "method": "Proposes MoR, using multiple sub-routers and a learnable main router to dynamically select experts, improving accuracy and efficiency.", "result": "MoR outperforms baselines, achieving a 1% average performance improvement across tasks.", "conclusion": "MoR is a plug-and-play, parameter-efficient method suitable for diverse applications, with code publicly available."}}
{"id": "2505.11347", "pdf": "https://arxiv.org/pdf/2505.11347", "abs": "https://arxiv.org/abs/2505.11347", "authors": ["Johannes Schwab", "Bryan Kelly", "Semyon Malamud", "Teng Andrea Xu"], "title": "Training NTK to Generalize with KARE", "categories": ["cs.LG"], "comment": null, "summary": "The performance of the data-dependent neural tangent kernel (NTK; Jacot et\nal. (2018)) associated with a trained deep neural network (DNN) often matches\nor exceeds that of the full network. This implies that DNN training via\ngradient descent implicitly performs kernel learning by optimizing the NTK. In\nthis paper, we propose instead to optimize the NTK explicitly. Rather than\nminimizing empirical risk, we train the NTK to minimize its generalization\nerror using the recently developed Kernel Alignment Risk Estimator (KARE; Jacot\net al. (2020)). Our simulations and real data experiments show that NTKs\ntrained with KARE consistently match or significantly outperform the original\nDNN and the DNN- induced NTK (the after-kernel). These results suggest that\nexplicitly trained kernels can outperform traditional end-to-end DNN\noptimization in certain settings, challenging the conventional dominance of\nDNNs. We argue that explicit training of NTK is a form of over-parametrized\nfeature learning.", "AI": {"tldr": "Explicitly training the Neural Tangent Kernel (NTK) using Kernel Alignment Risk Estimator (KARE) outperforms traditional DNN training and DNN-induced NTK, suggesting a shift in dominance from DNNs to kernel methods in certain settings.", "motivation": "The performance of NTK often matches or exceeds DNNs, implying DNN training implicitly learns kernels. This paper explores explicit NTK optimization to challenge DNN dominance.", "method": "Train NTK explicitly using KARE to minimize generalization error, instead of minimizing empirical risk like traditional DNN training.", "result": "NTKs trained with KARE consistently match or outperform original DNNs and DNN-induced NTKs in simulations and real data.", "conclusion": "Explicit NTK training can outperform DNNs, indicating over-parametrized feature learning and challenging DNN dominance in certain settings."}}
{"id": "2412.09521", "pdf": "https://arxiv.org/pdf/2412.09521", "abs": "https://arxiv.org/abs/2412.09521", "authors": ["Shengxuming Zhang", "Weihan Li", "Tianhong Gao", "Jiacong Hu", "Haoming Luo", "Xiuming Zhang", "Jing Zhang", "Mingli Song", "Zunlei Feng"], "title": "Efficient and Comprehensive Feature Extraction in Large Vision-Language Model for Pathology Analysis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pathological diagnosis is vital for determining disease characteristics,\nguiding treatment, and assessing prognosis, relying heavily on detailed,\nmulti-scale analysis of high-resolution whole slide images (WSI). However,\nexisting large vision-language models (LVLMs) are limited by input resolution\nconstraints, hindering their efficiency and accuracy in pathology image\nanalysis. To overcome these issues, we propose two innovative strategies: the\nmixed task-guided feature enhancement, which directs feature extraction toward\nlesion-related details across scales, and the prompt-guided detail feature\ncompletion, which integrates coarse- and fine-grained features from WSI based\non specific prompts without compromising inference speed. Leveraging a\ncomprehensive dataset of 490K samples from diverse pathology tasks, we trained\nthe pathology-specialized LVLM, OmniPath. Extensive experiments demonstrate\nthat this model significantly outperforms existing methods in diagnostic\naccuracy and efficiency, providing an interactive, clinically aligned approach\nfor auxiliary diagnosis in a wide range of pathology applications.", "AI": {"tldr": "The paper proposes OmniPath, a pathology-specialized LVLM, using mixed task-guided feature enhancement and prompt-guided detail feature completion to improve WSI analysis, outperforming existing methods in accuracy and efficiency.", "motivation": "Existing LVLMs are limited by input resolution constraints, reducing their effectiveness in pathology image analysis, which requires multi-scale, high-resolution WSI analysis for accurate diagnosis.", "method": "Two strategies are introduced: mixed task-guided feature enhancement for lesion-related feature extraction across scales, and prompt-guided detail feature completion to integrate coarse- and fine-grained WSI features without slowing inference.", "result": "OmniPath, trained on 490K samples, significantly outperforms existing methods in diagnostic accuracy and efficiency.", "conclusion": "OmniPath offers an interactive, clinically aligned solution for auxiliary pathology diagnosis, enhancing accuracy and efficiency."}}
{"id": "2310.18304", "pdf": "https://arxiv.org/pdf/2310.18304", "abs": "https://arxiv.org/abs/2310.18304", "authors": ["Chengpiao Huang", "Kaizheng Wang"], "title": "A Stability Principle for Learning under Non-Stationarity", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML", "68T05, 90C15"], "comment": "65 pages, 7 figures", "summary": "We develop a versatile framework for statistical learning in non-stationary\nenvironments. In each time period, our approach applies a stability principle\nto select a look-back window that maximizes the utilization of historical data\nwhile keeping the cumulative bias within an acceptable range relative to the\nstochastic error. Our theory showcases the adaptivity of this approach to\nunknown non-stationarity. We prove regret bounds that are minimax optimal up to\nlogarithmic factors when the population losses are strongly convex, or\nLipschitz only. At the heart of our analysis lie two novel components: a\nmeasure of similarity between functions and a segmentation technique for\ndividing the non-stationary data sequence into quasi-stationary pieces. We\nevaluate the practical performance of our approach through real-data\nexperiments on electricity demand prediction and hospital nurse staffing.", "AI": {"tldr": "A framework for statistical learning in non-stationary environments adapts to unknown changes by optimizing historical data usage while controlling bias.", "motivation": "To address the challenge of learning in non-stationary environments where data distributions change over time.", "method": "Uses a stability principle to select optimal look-back windows, balancing historical data utilization and bias control. Introduces function similarity measures and segmentation for quasi-stationary data.", "result": "Achieves minimax optimal regret bounds for strongly convex or Lipschitz losses. Validated on electricity demand and nurse staffing datasets.", "conclusion": "The framework effectively adapts to non-stationarity, offering theoretical guarantees and practical utility."}}
{"id": "2504.01698", "pdf": "https://arxiv.org/pdf/2504.01698", "abs": "https://arxiv.org/abs/2504.01698", "authors": ["Yi-Long Lu", "Chunhui Zhang", "Jiajun Song", "Lifeng Fan", "Wei Wang"], "title": "Do Theory of Mind Benchmarks Need Explicit Human-like Reasoning in Language Models?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Theory of Mind (ToM), the ability to attribute mental states to others, is\nfundamental for human social intelligence and a critical capability for\nadvanced Artificial Intelligence. Recent advancements in Large Language Models\n(LLMs) have shown promising performance on ToM benchmarks, raising the\nquestion: Do these benchmarks necessitate explicit human-like reasoning\nprocesses, or can models succeed through alternative strategies? We investigate\nthis question empirically by applying Reinforcement Learning (RL) and\nSupervised Fine-Tuning (SFT) to LLMs of varying scales (0.5B to 7B parameters)\nand evaluating them across multiple ToM datasets. Our results reveal a\nscale-dependent impact of RL: while RL significantly improves accuracy and\nfosters high-quality, interpretable, and transferable belief-tracking reasoning\nin larger models (7B), it leads to \"reasoning collapse\" in smaller models\n($\\leq$3B), where high accuracy and generalization ability are achieved via\ndrastically shortened, less meaningful responses. Surprisingly, further SFT\nachieves competitive and generalizable performance across these benchmarks,\noften matching or exceeding RL models in accuracy, despite not being explicitly\ntrained to produce structured reasoning traces. These findings highlight a\ncritical discrepancy between benchmark accuracy and the nature of learned\nreasoning. Our work suggests that current ToM benchmarks may be solvable\nwithout requiring the explicit, human-like simulation of mental states they\nwere designed to probe. LLMs, particularly when scale is limited or training\nsignals focus solely on output correctness, may leverage alternative rules\neffective for benchmark data structures.", "AI": {"tldr": "The paper examines whether Large Language Models (LLMs) solve Theory of Mind (ToM) benchmarks using human-like reasoning or alternative strategies. It finds that Reinforcement Learning (RL) improves reasoning in larger models but causes \"reasoning collapse\" in smaller ones, while Supervised Fine-Tuning (SFT) performs competitively without explicit reasoning training.", "motivation": "To determine if ToM benchmarks require human-like reasoning or can be solved via alternative strategies in LLMs, and to evaluate the impact of model scale and training methods (RL vs. SFT).", "method": "Applied RL and SFT to LLMs (0.5B to 7B parameters) and evaluated them on multiple ToM datasets.", "result": "RL improves reasoning in larger models (7B) but causes reasoning collapse in smaller ones (\u22643B). SFT achieves competitive accuracy without explicit reasoning training.", "conclusion": "Current ToM benchmarks may not require human-like reasoning, as LLMs can solve them using alternative strategies, especially when scale or training signals are limited."}}
{"id": "2505.11349", "pdf": "https://arxiv.org/pdf/2505.11349", "abs": "https://arxiv.org/abs/2505.11349", "authors": ["Yuanzhao Zhang", "William Gilpin"], "title": "Context parroting: A simple but tough-to-beat baseline for foundation models in scientific machine learning", "categories": ["cs.LG", "nlin.CD", "physics.comp-ph"], "comment": null, "summary": "Recently-developed time series foundation models for scientific machine\nlearning exhibit emergent abilities to predict physical systems. These\nabilities include zero-shot forecasting, in which a model forecasts future\nstates of a system given only a short trajectory as context. Here, we show that\nfoundation models applied to physical systems can give accurate predictions,\nbut that they fail to develop meaningful representations of the underlying\nphysics. Instead, foundation models often forecast by context parroting, a\nsimple zero-shot forecasting strategy that copies directly from the context. As\na result, a naive direct context parroting model scores higher than\nstate-of-the-art time-series foundation models on predicting a diverse range of\ndynamical systems, at a tiny fraction of the computational cost. We draw a\nparallel between context parroting and induction heads, which explains why\nlarge language models trained on text can be repurposed for time series\nforecasting. Our dynamical systems perspective also ties the scaling between\nforecast accuracy and context length to the fractal dimension of the attractor,\nproviding insight into the previously observed in-context neural scaling laws.\nContext parroting thus serves as a simple but tough-to-beat baseline for future\ntime-series foundation models and can help identify in-context learning\nstrategies beyond parroting.", "AI": {"tldr": "Time series foundation models predict physical systems but rely on context parroting, a simple copying strategy, outperforming complex models at lower cost.", "motivation": "To evaluate the effectiveness of time series foundation models in predicting physical systems and uncover their underlying learning strategies.", "method": "Analyze foundation models' forecasting abilities, comparing them to a naive context parroting model, and link findings to dynamical systems and scaling laws.", "result": "Foundation models often use context parroting, which outperforms state-of-the-art models in zero-shot forecasting at minimal computational cost.", "conclusion": "Context parroting is a strong baseline for time-series foundation models, offering insights into in-context learning and scaling laws."}}
{"id": "2412.09765", "pdf": "https://arxiv.org/pdf/2412.09765", "abs": "https://arxiv.org/abs/2412.09765", "authors": ["Morgan B. Talbot", "Gabriel Kreiman", "James J. DiCarlo", "Guy Gaziv"], "title": "L-WISE: Boosting Human Visual Category Learning Through Model-Based Image Selection and Enhancement", "categories": ["cs.CV", "cs.HC"], "comment": null, "summary": "The currently leading artificial neural network models of the visual ventral\nstream - which are derived from a combination of performance optimization and\nrobustification methods - have demonstrated a remarkable degree of behavioral\nalignment with humans on visual categorization tasks. We show that image\nperturbations generated by these models can enhance the ability of humans to\naccurately report the ground truth class. Furthermore, we find that the same\nmodels can also be used out-of-the-box to predict the proportion of correct\nhuman responses to individual images, providing a simple, human-aligned\nestimator of the relative difficulty of each image. Motivated by these\nobservations, we propose to augment visual learning in humans in a way that\nimproves human categorization accuracy at test time. Our learning augmentation\napproach consists of (i) selecting images based on their model-estimated\nrecognition difficulty, and (ii) applying image perturbations that aid\nrecognition for novice learners. We find that combining these model-based\nstrategies leads to categorization accuracy gains of 33-72% relative to control\nsubjects without these interventions, on unmodified, randomly selected held-out\ntest images. Beyond the accuracy gain, the training time for the augmented\nlearning group was also shortened by 20-23%, despite both groups completing the\nsame number of training trials. We demonstrate the efficacy of our approach in\na fine-grained categorization task with natural images, as well as two tasks in\nclinically relevant image domains - histology and dermoscopy - where visual\nlearning is notoriously challenging. To the best of our knowledge, our work is\nthe first application of artificial neural networks to increase visual learning\nperformance in humans by enhancing category-specific image features.", "AI": {"tldr": "Artificial neural networks improve human visual learning by selecting difficult images and applying perturbations, boosting accuracy by 33-72% and reducing training time by 20-23%.", "motivation": "To enhance human visual learning and categorization accuracy using model-based strategies derived from artificial neural networks.", "method": "Augmenting learning by (i) selecting images based on model-estimated difficulty and (ii) applying perturbations to aid recognition.", "result": "Categorization accuracy improved by 33-72%, and training time reduced by 20-23% in fine-grained and clinically relevant tasks.", "conclusion": "Artificial neural networks can effectively augment human visual learning, improving accuracy and efficiency."}}
{"id": "2311.16027", "pdf": "https://arxiv.org/pdf/2311.16027", "abs": "https://arxiv.org/abs/2311.16027", "authors": ["Wei Xu", "Zaifeng Gao", "Marvin Dainoff"], "title": "An HCAI Methodological Framework (HCAI-MF): Putting It Into Action to Enable Human-Centered AI", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Human-centered artificial intelligence (HCAI) is a design philosophy that\nprioritizes humans in the design, development, deployment, and use of AI\nsystems, aiming to maximize AI's benefits while mitigating its negative\nimpacts. Despite its growing prominence in literature, the lack of\nmethodological guidance for its implementation poses challenges to HCAI\npractice. To address this gap, this paper proposes a comprehensive HCAI\nmethodological framework (HCAI-MF) comprising five key components: HCAI\nrequirement hierarchy, approach and method taxonomy, process, interdisciplinary\ncollaboration approach, and multi-level design paradigms. A case study\ndemonstrates HCAI-MF's practical implications, while the paper also analyzes\nimplementation challenges. Actionable recommendations and a \"three-layer\" HCAI\nimplementation strategy are provided to address these challenges and guide\nfuture evolution of HCAI-MF. HCAI-MF is presented as a systematic and\nexecutable methodology capable of overcoming current gaps, enabling effective\ndesign, development, deployment, and use of AI systems, and advancing HCAI\npractice.", "AI": {"tldr": "The paper proposes a methodological framework (HCAI-MF) for implementing Human-centered AI (HCAI), addressing gaps in current practice and providing actionable guidance.", "motivation": "The lack of methodological guidance for HCAI implementation hinders its practical application, despite its growing importance.", "method": "The paper introduces HCAI-MF, a framework with five components: requirement hierarchy, method taxonomy, process, interdisciplinary collaboration, and design paradigms. A case study validates its practicality.", "result": "HCAI-MF is shown to systematically address implementation challenges, with actionable recommendations and a \"three-layer\" strategy provided.", "conclusion": "HCAI-MF is a comprehensive and executable methodology that advances HCAI practice by bridging current gaps and guiding AI system development."}}
{"id": "2504.09184", "pdf": "https://arxiv.org/pdf/2504.09184", "abs": "https://arxiv.org/abs/2504.09184", "authors": ["Lennart Finke", "Chandan Sreedhara", "Thomas Dooms", "Mat Allen", "Emerald Zhang", "Juan Diego Rodriguez", "Noa Nabeshima", "Thomas Marshall", "Dan Braun"], "title": "Parameterized Synthetic Text Generation with SimpleStories", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present SimpleStories, a large synthetic story dataset in simple language,\nconsisting of 2 million samples each in English and Japanese. Through\nparameterizing prompts at multiple levels of abstraction, we achieve control\nover story characteristics at scale, inducing syntactic and semantic diversity.\nAblations on a newly trained model suite show improved sample efficiency and\nmodel interpretability compared to the TinyStories dataset. We open-source all\nconstituent parts of model creation, hoping to enable novel ways to study the\nend-to-end training process. As a byproduct, we move the frontier regarding the\nfewest-parameter language model that outputs grammatical natural language.", "AI": {"tldr": "SimpleStories is a large synthetic dataset in simple language (2M samples in English and Japanese) with controlled story characteristics. It improves sample efficiency and model interpretability over TinyStories and is open-sourced.", "motivation": "To create a scalable, controlled dataset for studying language model training and improve interpretability and efficiency.", "method": "Parameterized prompts at multiple abstraction levels to control story characteristics, with ablations on a trained model suite.", "result": "Improved sample efficiency and interpretability, and a minimal-parameter model producing grammatical language.", "conclusion": "SimpleStories advances dataset control and model training study, with open-sourced resources for broader research."}}
{"id": "2505.11356", "pdf": "https://arxiv.org/pdf/2505.11356", "abs": "https://arxiv.org/abs/2505.11356", "authors": ["Nero Z. Li", "Xuehao Zhai", "Zhichao Shi", "Boshen Shi", "Xuhui Jiang"], "title": "Fractal Graph Contrastive Learning", "categories": ["cs.LG"], "comment": null, "summary": "While Graph Contrastive Learning (GCL) has attracted considerable attention\nin the field of graph self-supervised learning, its performance heavily relies\non data augmentations that are expected to generate semantically consistent\npositive pairs. Existing strategies typically resort to random perturbations or\nlocal structure preservation, yet lack explicit control over global structural\nconsistency between augmented views. To address this limitation, we propose\nFractal Graph Contrastive Learning (FractalGCL), a theory-driven framework that\nleverages fractal self-similarity to enforce global topological coherence.\nFractalGCL introduces two key innovations: a renormalisation-based augmentation\nthat generates structurally aligned positive views via box coverings; and a\nfractal-dimension-aware contrastive loss that aligns graph embeddings according\nto their fractal dimensions. While combining the two innovations markedly\nboosts graph-representation quality, it also adds non-trivial computational\noverhead. To mitigate the computational overhead of fractal dimension\nestimation, we derive a one-shot estimator by proving that the dimension\ndiscrepancy between original and renormalised graphs converges weakly to a\ncentred Gaussian distribution. This theoretical insight enables a reduction in\ndimension computation cost by an order of magnitude, cutting overall training\ntime by approximately 61%. The experiments show that FractalGCL not only\ndelivers state-of-the-art results on standard benchmarks but also outperforms\ntraditional baselines on traffic networks by an average margin of about\nremarkably 7%. Codes are available at\n(https://anonymous.4open.science/r/FractalGCL-0511).", "AI": {"tldr": "FractalGCL introduces a theory-driven GCL framework using fractal self-similarity for global structural consistency, improving performance and reducing computational costs.", "motivation": "Existing GCL methods lack explicit control over global structural consistency in data augmentations, limiting performance.", "method": "Proposes FractalGCL with renormalisation-based augmentation and fractal-dimension-aware contrastive loss, plus a one-shot estimator to reduce computational overhead.", "result": "Achieves state-of-the-art results, outperforming baselines by ~7% on traffic networks, with a 61% reduction in training time.", "conclusion": "FractalGCL effectively balances performance and computational efficiency, advancing GCL with fractal theory."}}
{"id": "2412.13303", "pdf": "https://arxiv.org/pdf/2412.13303", "abs": "https://arxiv.org/abs/2412.13303", "authors": ["Pavan Kumar Anasosalu Vasu", "Fartash Faghri", "Chun-Liang Li", "Cem Koc", "Nate True", "Albert Antony", "Gokul Santhanam", "James Gabriel", "Peter Grasch", "Oncel Tuzel", "Hadi Pouransari"], "title": "FastVLM: Efficient Vision Encoding for Vision Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "CVPR 2025", "summary": "Scaling the input image resolution is essential for enhancing the performance\nof Vision Language Models (VLMs), particularly in text-rich image understanding\ntasks. However, popular visual encoders such as ViTs become inefficient at high\nresolutions due to the large number of tokens and high encoding latency caused\nby stacked self-attention layers. At different operational resolutions, the\nvision encoder of a VLM can be optimized along two axes: reducing encoding\nlatency and minimizing the number of visual tokens passed to the LLM, thereby\nlowering overall latency. Based on a comprehensive efficiency analysis of the\ninterplay between image resolution, vision latency, token count, and LLM size,\nwe introduce FastVLM, a model that achieves an optimized trade-off between\nlatency, model size and accuracy. FastVLM incorporates FastViTHD, a novel\nhybrid vision encoder designed to output fewer tokens and significantly reduce\nencoding time for high-resolution images. Unlike previous methods, FastVLM\nachieves the optimal balance between visual token count and image resolution\nsolely by scaling the input image, eliminating the need for additional token\npruning and simplifying the model design. In the LLaVA-1.5 setup, FastVLM\nachieves 3.2$\\times$ improvement in time-to-first-token (TTFT) while\nmaintaining similar performance on VLM benchmarks compared to prior works.\nCompared to LLaVa-OneVision at the highest resolution (1152$\\times$1152),\nFastVLM achieves better performance on key benchmarks like SeedBench, MMMU and\nDocVQA, using the same 0.5B LLM, but with 85$\\times$ faster TTFT and a vision\nencoder that is 3.4$\\times$ smaller. Code and models are available at\nhttps://github.com/apple/ml-fastvlm.", "AI": {"tldr": "FastVLM optimizes Vision Language Models by reducing latency and token count for high-resolution images, achieving better performance and speed.", "motivation": "High-resolution images improve VLM performance but increase latency and token count, making current methods inefficient.", "method": "Introduces FastVLM with FastViTHD, a hybrid vision encoder that reduces tokens and encoding time without additional pruning.", "result": "FastVLM achieves 3.2\u00d7 faster TTFT, better benchmark performance, and 85\u00d7 faster TTFT compared to LLaVa-OneVision.", "conclusion": "FastVLM balances latency, model size, and accuracy efficiently, simplifying high-resolution VLM design."}}
{"id": "2402.09447", "pdf": "https://arxiv.org/pdf/2402.09447", "abs": "https://arxiv.org/abs/2402.09447", "authors": ["Ali Rabiee", "Sima Ghafoori", "Anna Cetera", "Reza Abiri"], "title": "Wavelet Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types", "categories": ["eess.SP", "cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "This research aims to decode hand grasps from Electroencephalograms (EEGs)\nfor dexterous neuroprosthetic development and Brain-Computer Interface (BCI)\napplications, especially for patients with motor disorders. Particularly, it\nfocuses on distinguishing two complex natural power and precision grasps in\naddition to a neutral condition as a no-movement condition using a new\nEEG-based BCI platform and wavelet signal processing. Wavelet analysis involved\ngenerating time-frequency and topographic maps from wavelet power coefficients.\nThen, by using machine learning techniques with novel wavelet features, we\nachieved high average accuracies: 85.16% for multiclass, 95.37% for No-Movement\nvs Power, 95.40% for No-Movement vs Precision, and 88.07% for Power vs\nPrecision, demonstrating the effectiveness of these features in EEG-based grasp\ndifferentiation. In contrast to previous studies, a critical part of our study\nwas permutation feature importance analysis, which highlighted key features for\ngrasp classification. It revealed that the most crucial brain activities during\ngrasping occur in the motor cortex, within the alpha and beta frequency bands.\nThese insights demonstrate the potential of wavelet features in real-time\nneuroprosthetic technology and BCI applications.", "AI": {"tldr": "The paper decodes hand grasps from EEGs for neuroprosthetics and BCIs, using wavelet processing and machine learning to achieve high accuracy in distinguishing grasps.", "motivation": "To aid patients with motor disorders by developing EEG-based BCI for grasp differentiation.", "method": "Used wavelet signal processing and machine learning with novel wavelet features on EEG data.", "result": "Achieved high accuracies (85.16% multiclass, up to 95.40% for specific grasp pairs) and identified key brain activities in the motor cortex.", "conclusion": "Wavelet features are effective for EEG-based grasp differentiation, with potential for real-time neuroprosthetics and BCIs."}}
{"id": "2504.17704", "pdf": "https://arxiv.org/pdf/2504.17704", "abs": "https://arxiv.org/abs/2504.17704", "authors": ["Cheng Wang", "Yue Liu", "Baolong Bi", "Duzhen Zhang", "Zhongzhi Li", "Junfeng Fang", "Bryan Hooi"], "title": "Safety in Large Reasoning Models: A Survey", "categories": ["cs.CL"], "comment": null, "summary": "Large Reasoning Models (LRMs) have exhibited extraordinary prowess in tasks\nlike mathematics and coding, leveraging their advanced reasoning capabilities.\nNevertheless, as these capabilities progress, significant concerns regarding\ntheir vulnerabilities and safety have arisen, which can pose challenges to\ntheir deployment and application in real-world settings. This paper presents a\ncomprehensive survey of LRMs, meticulously exploring and summarizing the newly\nemerged safety risks, attacks, and defense strategies. By organizing these\nelements into a detailed taxonomy, this work aims to offer a clear and\nstructured understanding of the current safety landscape of LRMs, facilitating\nfuture research and development to enhance the security and reliability of\nthese powerful models.", "AI": {"tldr": "A survey on safety risks, attacks, and defenses in Large Reasoning Models (LRMs), organized into a taxonomy for clarity.", "motivation": "Address growing concerns about vulnerabilities and safety in LRMs as their reasoning capabilities advance.", "method": "Comprehensive survey and taxonomy of safety risks, attacks, and defense strategies in LRMs.", "result": "Structured understanding of LRM safety landscape to guide future research.", "conclusion": "The work aims to enhance the security and reliability of LRMs for real-world deployment."}}
{"id": "2505.11359", "pdf": "https://arxiv.org/pdf/2505.11359", "abs": "https://arxiv.org/abs/2505.11359", "authors": ["Zihang Jia", "Zhen Zhang", "Witold Pedrycz"], "title": "LGBQPC: Local Granular-Ball Quality Peaks Clustering", "categories": ["cs.LG"], "comment": null, "summary": "The density peaks clustering (DPC) algorithm has attracted considerable\nattention for its ability to detect arbitrarily shaped clusters based on a\nsimple yet effective assumption. Recent advancements integrating granular-ball\n(GB) computing with DPC have led to the GB-based DPC (GBDPC) algorithm, which\nimproves computational efficiency. However, GBDPC demonstrates limitations when\nhandling complex clustering tasks, particularly those involving data with\ncomplex manifold structures or non-uniform density distributions. To overcome\nthese challenges, this paper proposes the local GB quality peaks clustering\n(LGBQPC) algorithm, which offers comprehensive improvements to GBDPC in both GB\ngeneration and clustering processes based on the principle of justifiable\ngranularity (POJG). Firstly, an improved GB generation method, termed GB-POJG+,\nis developed, which systematically refines the original GB-POJG in four key\naspects: the objective function, termination criterion for GB division,\ndefinition of abnormal GB, and granularity level adaptation strategy. GB-POJG+\nsimplifies parameter configuration by requiring only a single penalty\ncoefficient and ensures high-quality GB generation while maintaining the number\nof generated GBs within an acceptable range. In the clustering phase, two key\ninnovations are introduced based on the GB k-nearest neighbor graph: relative\nGB quality for density estimation and geodesic distance for GB distance metric.\nThese modifications substantially improve the performance of GBDPC on datasets\nwith complex manifold structures or non-uniform density distributions.\nExtensive numerical experiments on 40 benchmark datasets, including both\nsynthetic and publicly available datasets, validate the superior performance of\nthe proposed LGBQPC algorithm.", "AI": {"tldr": "The paper introduces the LGBQPC algorithm, an improved version of GBDPC, addressing its limitations in handling complex data structures by refining GB generation and clustering processes using POJG principles.", "motivation": "GBDPC, while efficient, struggles with complex manifold structures and non-uniform density distributions. The paper aims to enhance its performance for such tasks.", "method": "Proposes LGBQPC with GB-POJG+ for improved GB generation and innovations like relative GB quality and geodesic distance in clustering.", "result": "LGBQPC outperforms GBDPC on 40 benchmark datasets, especially for complex data structures.", "conclusion": "LGBQPC effectively addresses GBDPC's limitations, offering better performance for complex clustering tasks."}}
{"id": "2412.16141", "pdf": "https://arxiv.org/pdf/2412.16141", "abs": "https://arxiv.org/abs/2412.16141", "authors": ["Laura Weihl", "Bilal Wehbe", "Andrzej W\u0105sowski"], "title": "NeRF-To-Real Tester: Neural Radiance Fields as Test Image Generators for Vision of Autonomous Systems", "categories": ["cs.CV"], "comment": null, "summary": "Autonomous inspection of infrastructure on land and in water is a quickly\ngrowing market, with applications including surveying constructions, monitoring\nplants, and tracking environmental changes in on- and off-shore wind energy\nfarms. For Autonomous Underwater Vehicles and Unmanned Aerial Vehicles\noverfitting of controllers to simulation conditions fundamentally leads to poor\nperformance in the operation environment. There is a pressing need for more\ndiverse and realistic test data that accurately represents the challenges faced\nby these systems. We address the challenge of generating perception test data\nfor autonomous systems by leveraging Neural Radiance Fields to generate\nrealistic and diverse test images, and integrating them into a metamorphic\ntesting framework for vision components such as vSLAM and object detection. Our\ntool, N2R-Tester, allows training models of custom scenes and rendering test\nimages from perturbed positions. An experimental evaluation of N2R-Tester on\neight different vision components in AUVs and UAVs demonstrates the efficacy\nand versatility of the approach.", "AI": {"tldr": "The paper introduces N2R-Tester, a tool using Neural Radiance Fields to generate realistic test images for autonomous systems, addressing overfitting in simulation-trained controllers.", "motivation": "Overfitting of controllers to simulation conditions in AUVs and UAVs leads to poor real-world performance, necessitating diverse and realistic test data.", "method": "Leverages Neural Radiance Fields to create realistic test images and integrates them into a metamorphic testing framework for vision components.", "result": "N2R-Tester effectively generates diverse test data, demonstrated by its evaluation on eight vision components in AUVs and UAVs.", "conclusion": "The approach is versatile and effective for improving the robustness of autonomous systems' vision components."}}
{"id": "2404.13274", "pdf": "https://arxiv.org/pdf/2404.13274", "abs": "https://arxiv.org/abs/2404.13274", "authors": ["Mustafa Doga Dogan", "Eric J. Gonzalez", "Karan Ahuja", "Ruofei Du", "Andrea Cola\u00e7o", "Johnny Lee", "Mar Gonzalez-Franco", "David Kim"], "title": "Augmented Object Intelligence with XR-Objects", "categories": ["cs.HC", "cs.AI", "H.5.0; H.5.1; H.5.2"], "comment": "15 pages, 15 figures, 2024 ACM Symposium on User Interface Software\n  and Technology (UIST)", "summary": "Seamless integration of physical objects as interactive digital entities\nremains a challenge for spatial computing. This paper explores Augmented Object\nIntelligence (AOI) in the context of XR, an interaction paradigm that aims to\nblur the lines between digital and physical by equipping real-world objects\nwith the ability to interact as if they were digital, where every object has\nthe potential to serve as a portal to digital functionalities. Our approach\nutilizes real-time object segmentation and classification, combined with the\npower of Multimodal Large Language Models (MLLMs), to facilitate these\ninteractions without the need for object pre-registration. We implement the AOI\nconcept in the form of XR-Objects, an open-source prototype system that\nprovides a platform for users to engage with their physical environment in\ncontextually relevant ways using object-based context menus. This system\nenables analog objects to not only convey information but also to initiate\ndigital actions, such as querying for details or executing tasks. Our\ncontributions are threefold: (1) we define the AOI concept and detail its\nadvantages over traditional AI assistants, (2) detail the XR-Objects system's\nopen-source design and implementation, and (3) show its versatility through\nvarious use cases and a user study.", "AI": {"tldr": "The paper introduces Augmented Object Intelligence (AOI) for XR, enabling physical objects to interact digitally without pre-registration, using real-time segmentation and MLLMs.", "motivation": "To bridge the gap between physical and digital interactions in spatial computing by empowering everyday objects with digital functionalities.", "method": "Utilizes real-time object segmentation, classification, and Multimodal Large Language Models (MLLMs) to create XR-Objects, an open-source prototype system.", "result": "Demonstrates AOI's versatility through use cases and a user study, showing its potential to enhance digital-physical interactions.", "conclusion": "AOI and XR-Objects offer a scalable, intuitive way to integrate physical objects into digital workflows, outperforming traditional AI assistants."}}
{"id": "2505.04588", "pdf": "https://arxiv.org/pdf/2505.04588", "abs": "https://arxiv.org/abs/2505.04588", "authors": ["Hao Sun", "Zile Qiao", "Jiayan Guo", "Xuanbo Fan", "Yingyan Hou", "Yong Jiang", "Pengjun Xie", "Yan Zhang", "Fei Huang", "Jingren Zhou"], "title": "ZeroSearch: Incentivize the Search Capability of LLMs without Searching", "categories": ["cs.CL"], "comment": null, "summary": "Effective information searching is essential for enhancing the reasoning and\ngeneration capabilities of large language models (LLMs). Recent research has\nexplored using reinforcement learning (RL) to improve LLMs' search capabilities\nby interacting with live search engines in real-world environments. While these\napproaches show promising results, they face two major challenges: (1)\nUncontrolled Document Quality: The quality of documents returned by search\nengines is often unpredictable, introducing noise and instability into the\ntraining process. (2) Prohibitively High API Costs: RL training requires\nfrequent rollouts, potentially involving hundreds of thousands of search\nrequests, which incur substantial API expenses and severely constrain\nscalability. To address these challenges, we introduce ZeroSearch, a novel RL\nframework that incentivizes the capabilities of LLMs to use a real search\nengine with simulated searches during training. Our approach begins with\nlightweight supervised fine-tuning to transform the LLM into a retrieval module\ncapable of generating both useful and noisy documents in response to a query.\nDuring RL training, we employ a curriculum-based rollout strategy that\nincrementally degrades the quality of generated documents, progressively\neliciting the model's reasoning ability by exposing it to increasingly\nchallenging retrieval scenarios. Extensive experiments demonstrate that\nZeroSearch effectively incentivizes the search capabilities of LLMs using a 3B\nLLM as the retrieval module. Remarkably, a 7B retrieval module achieves\ncomparable performance to the real search engine, while a 14B retrieval module\neven surpasses it. Furthermore, it generalizes well across both base and\ninstruction-tuned models of various parameter sizes and is compatible with a\nwide range of RL algorithms.", "AI": {"tldr": "ZeroSearch is a novel RL framework that improves LLMs' search capabilities by simulating searches during training, addressing challenges like uncontrolled document quality and high API costs.", "motivation": "Enhancing LLMs' reasoning and generation by improving their search capabilities, while overcoming issues like unpredictable document quality and expensive API costs.", "method": "Uses lightweight supervised fine-tuning to create a retrieval module, followed by a curriculum-based RL strategy to degrade document quality incrementally.", "result": "ZeroSearch effectively improves search capabilities, with larger LLMs (7B, 14B) matching or surpassing real search engine performance.", "conclusion": "ZeroSearch is scalable, generalizes well across models, and is compatible with various RL algorithms, offering a cost-effective solution for enhancing LLM search abilities."}}
{"id": "2505.11360", "pdf": "https://arxiv.org/pdf/2505.11360", "abs": "https://arxiv.org/abs/2505.11360", "authors": ["Rares Cristian", "Pavithra Harsha", "Georgia Perakis", "Brian Quanz"], "title": "Efficient End-to-End Learning for Decision-Making: A Meta-Optimization Approach", "categories": ["cs.LG"], "comment": null, "summary": "End-to-end learning has become a widely applicable and studied problem in\ntraining predictive ML models to be aware of their impact on downstream\ndecision-making tasks. These end-to-end models often outperform traditional\nmethods that separate training from the optimization and only myopically focus\non prediction error. However, the computational complexity of end-to-end\nframeworks poses a significant challenge, particularly for large-scale\nproblems. While training an ML model using gradient descent, each time we need\nto compute a gradient we must solve an expensive optimization problem. We\npresent a meta-optimization method that learns efficient algorithms to\napproximate optimization problems, dramatically reducing computational overhead\nof solving the decision problem in general, an aspect we leverage in the\ntraining within the end-to-end framework. Our approach introduces a neural\nnetwork architecture that near-optimally solves optimization problems while\nensuring feasibility constraints through alternate projections. We prove\nexponential convergence, approximation guarantees, and generalization bounds\nfor our learning method. This method offers superior computational efficiency,\nproducing high-quality approximations faster and scaling better with problem\nsize compared to existing techniques. Our approach applies to a wide range of\noptimization problems including deterministic, single-stage as well as\ntwo-stage stochastic optimization problems. We illustrate how our proposed\nmethod applies to (1) an electricity generation problem using real data from an\nelectricity routing company coordinating the movement of electricity throughout\n13 states, (2) a shortest path problem with a computer vision task of\npredicting edge costs from terrain maps, (3) a two-stage multi-warehouse\ncross-fulfillment newsvendor problem, as well as a variety of other\nnewsvendor-like problems.", "AI": {"tldr": "A meta-optimization method is introduced to reduce computational overhead in end-to-end learning by approximating optimization problems efficiently, ensuring feasibility and scalability.", "motivation": "End-to-end learning outperforms traditional methods but faces computational challenges due to expensive optimization problems during training.", "method": "A neural network architecture is proposed to approximate optimization problems near-optimally, using alternate projections for feasibility, with proven convergence and generalization guarantees.", "result": "The method achieves superior computational efficiency, faster high-quality approximations, and better scalability compared to existing techniques.", "conclusion": "The approach is versatile, applicable to various optimization problems, and demonstrated in real-world scenarios like electricity generation, shortest path tasks, and newsvendor problems."}}
{"id": "2412.19328", "pdf": "https://arxiv.org/pdf/2412.19328", "abs": "https://arxiv.org/abs/2412.19328", "authors": ["Zixin Yang", "Jon S. Heiselman", "Cheng Han", "Kelly Merrell", "Richard Simon", "Cristian. A. Linte"], "title": "Resolving the Ambiguity of Complete-to-Partial Point Cloud Registration for Image-Guided Liver Surgery with Patches-to-Partial Matching", "categories": ["cs.CV"], "comment": null, "summary": "In image-guided liver surgery, the initial rigid alignment between\npreoperative and intraoperative data, often represented as point clouds, is\ncrucial for providing sub-surface information from preoperative CT/MRI images\nto the surgeon during the procedure. Currently, this alignment is typically\nperformed using semi-automatic methods, which, while effective to some extent,\nare prone to errors that demand manual correction. Point cloud\ncorrespondence-based registration methods are promising to serve as a fully\nautomatic solution. However, they may struggle in scenarios with limited\nintraoperative surface visibility, a common challenge in liver surgery,\nparticularly in laparoscopic procedures, which we refer to as\ncomplete-to-partial ambiguity. We first illustrate this ambiguity by evaluating\nthe performance of state-of-the-art learning-based point cloud registration\nmethods on our carefully constructed in silico and in vitro datasets. Then, we\npropose a patches-to-partial matching strategy as a plug-and-play module to\nresolve the ambiguity, which can be seamlessly integrated into learning-based\nregistration methods without disrupting their end-to-end structure. It has\nproven effective and efficient in improving registration performance for cases\nwith limited intraoperative visibility. The constructed benchmark and the\nproposed module establish a solid foundation for advancing applications of\npoint cloud correspondence-based registration methods in image-guided liver\nsurgery.", "AI": {"tldr": "The paper addresses the challenge of rigid alignment in image-guided liver surgery, proposing a patches-to-partial matching strategy to improve registration accuracy in cases with limited intraoperative visibility.", "motivation": "Current semi-automatic alignment methods in liver surgery are error-prone and require manual correction, especially in scenarios with limited intraoperative surface visibility (complete-to-partial ambiguity).", "method": "The authors evaluate state-of-the-art learning-based point cloud registration methods and propose a patches-to-partial matching module to resolve ambiguity, integrating it seamlessly into existing methods.", "result": "The proposed module improves registration performance in cases with limited visibility, as validated on in silico and in vitro datasets.", "conclusion": "The benchmark and module provide a foundation for advancing point cloud correspondence-based registration in image-guided liver surgery."}}
{"id": "2405.01053", "pdf": "https://arxiv.org/pdf/2405.01053", "abs": "https://arxiv.org/abs/2405.01053", "authors": ["Wenwen Qiang", "Jingyao Wang", "Changwen Zheng", "Hui Xiong", "Gang Hua"], "title": "On the Universality of Self-Supervised Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we investigate what constitutes a good representation or model\nin self-supervised learning (SSL). We argue that a good representation should\nexhibit universality, characterized by three essential properties:\ndiscriminability, generalizability, and transferability. While these\ncapabilities are implicitly desired in most SSL frameworks, existing methods\nlack an explicit modeling of universality, and its theoretical foundations\nremain underexplored. To address these gaps, we propose General SSL (GeSSL), a\nnovel framework that explicitly models universality from three complementary\ndimensions: the optimization objective, the parameter update mechanism, and the\nlearning paradigm. GeSSL integrates a bi-level optimization structure that\njointly models task-specific adaptation and cross-task consistency, thereby\ncapturing all three aspects of universality within a unified SSL objective.\nFurthermore, we derive a theoretical generalization bound, ensuring that the\noptimization process of GeSSL consistently leads to representations that\ngeneralize well to unseen tasks. Empirical results on multiple benchmark\ndatasets demonstrate that GeSSL consistently achieves superior performance\nacross diverse downstream tasks, validating its effectiveness in modeling\nuniversal representations.", "AI": {"tldr": "The paper proposes GeSSL, a framework for self-supervised learning that explicitly models universality (discriminability, generalizability, transferability) through a bi-level optimization structure and theoretical guarantees.", "motivation": "Existing SSL methods lack explicit modeling of universality and its theoretical foundations.", "method": "GeSSL integrates a bi-level optimization structure to jointly model task-specific adaptation and cross-task consistency, with a theoretical generalization bound.", "result": "Empirical results show GeSSL outperforms existing methods on diverse downstream tasks.", "conclusion": "GeSSL effectively models universal representations, validated by superior performance and theoretical guarantees."}}
{"id": "2505.05755", "pdf": "https://arxiv.org/pdf/2505.05755", "abs": "https://arxiv.org/abs/2505.05755", "authors": ["Dhruvesh Patel", "Aishwarya Sahoo", "Avinash Amballa", "Tahira Naseem", "Tim G. J. Rudner", "Andrew McCallum"], "title": "Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions", "categories": ["cs.CL", "cs.LG"], "comment": "Corrected a typo in author names", "summary": "Autoregressive models (ARMs), which predict subsequent tokens one-by-one\n``from left to right,'' have achieved significant success across a wide range\nof sequence generation tasks. However, they struggle to accurately represent\nsequences that require satisfying sophisticated constraints or whose sequential\ndependencies are better addressed by out-of-order generation. Masked Diffusion\nModels (MDMs) address some of these limitations, but the process of unmasking\nmultiple tokens simultaneously in MDMs can introduce incoherences, and MDMs\ncannot handle arbitrary infilling constraints when the number of tokens to be\nfilled in is not known in advance. In this work, we introduce Insertion\nLanguage Models (ILMs), which learn to insert tokens at arbitrary positions in\na sequence -- that is, they select jointly both the position and the vocabulary\nelement to be inserted. By inserting tokens one at a time, ILMs can represent\nstrong dependencies between tokens, and their ability to generate sequences in\narbitrary order allows them to accurately model sequences where token\ndependencies do not follow a left-to-right sequential structure. To train ILMs,\nwe propose a tailored network parameterization and use a simple denoising\nobjective. Our empirical evaluation demonstrates that ILMs outperform both ARMs\nand MDMs on common planning tasks. Furthermore, we show that ILMs outperform\nMDMs and perform on par with ARMs in an unconditional text generation task\nwhile offering greater flexibility than MDMs in arbitrary-length text\ninfilling.", "AI": {"tldr": "Insertion Language Models (ILMs) outperform Autoregressive Models (ARMs) and Masked Diffusion Models (MDMs) in planning tasks and offer flexibility in text infilling.", "motivation": "ARMs and MDMs have limitations in handling sequences with complex constraints or out-of-order dependencies. ILMs aim to address these gaps.", "method": "ILMs insert tokens at arbitrary positions, selecting both position and vocabulary element. Training uses a tailored network and denoising objective.", "result": "ILMs outperform ARMs and MDMs in planning tasks and match ARMs in text generation while offering better flexibility in infilling.", "conclusion": "ILMs provide a flexible and effective alternative to ARMs and MDMs for sequence generation tasks with complex dependencies."}}
{"id": "2505.11370", "pdf": "https://arxiv.org/pdf/2505.11370", "abs": "https://arxiv.org/abs/2505.11370", "authors": ["Jingwei Li", "Jing Xu", "Zifan Wang", "Huishuai Zhang", "Jingzhao Zhang"], "title": "Understanding Nonlinear Implicit Bias via Region Counts in Input Space", "categories": ["cs.LG"], "comment": null, "summary": "One explanation for the strong generalization ability of neural networks is\nimplicit bias. Yet, the definition and mechanism of implicit bias in non-linear\ncontexts remains little understood. In this work, we propose to characterize\nimplicit bias by the count of connected regions in the input space with the\nsame predicted label. Compared with parameter-dependent metrics (e.g., norm or\nnormalized margin), region count can be better adapted to nonlinear,\noverparameterized models, because it is determined by the function mapping and\nis invariant to reparametrization. Empirically, we found that small region\ncounts align with geometrically simple decision boundaries and correlate well\nwith good generalization performance. We also observe that good hyper-parameter\nchoices such as larger learning rates and smaller batch sizes can induce small\nregion counts. We further establish the theoretical connections and explain how\nlarger learning rate can induce small region counts in neural networks.", "AI": {"tldr": "The paper explores implicit bias in neural networks by proposing region count as a metric for characterizing it, linking it to generalization performance and hyperparameter choices.", "motivation": "To better understand implicit bias in nonlinear, overparameterized neural networks and its role in generalization.", "method": "Proposes region count (connected regions with the same predicted label) as a metric, analyzes its empirical and theoretical connections to generalization and hyperparameters.", "result": "Small region counts correlate with simple decision boundaries and good generalization; larger learning rates and smaller batch sizes reduce region counts.", "conclusion": "Region count is a useful invariant metric for implicit bias, with practical implications for hyperparameter tuning in neural networks."}}
{"id": "2501.11493", "pdf": "https://arxiv.org/pdf/2501.11493", "abs": "https://arxiv.org/abs/2501.11493", "authors": ["Jonas Klotz", "Bar\u0131\u015f B\u00fcy\u00fckta\u015f", "Beg\u00fcm Demir"], "title": "Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at the IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS) 2025", "summary": "Federated learning (FL) is a decentralized machine learning paradigm in which\nmultiple clients collaboratively train a global model by exchanging only model\nupdates with the central server without sharing the local data of the clients.\nDue to the large volume of model updates required to be transmitted between\nclients and the central server, most FL systems are associated with high\ntransfer costs (i.e., communication overhead). This issue is more critical for\noperational applications in remote sensing (RS), especially when large-scale RS\ndata is processed and analyzed through FL systems with restricted communication\nbandwidth. To address this issue, we introduce an explanation-guided pruning\nstrategy for communication-efficient FL in the context of RS image\nclassification. Our pruning strategy is defined based on the layer-wise\nrelevance propagation (LRP) driven explanations to: 1) efficiently and\neffectively identify the most relevant and informative model parameters (to be\nexchanged between clients and the central server); and 2) eliminate the\nnon-informative ones to minimize the volume of model updates. The experimental\nresults on the BigEarthNet-S2 dataset demonstrate that our strategy effectively\nreduces the number of shared model updates, while increasing the generalization\nability of the global model. The code of this work is publicly available at\nhttps://git.tu-berlin.de/rsim/FL-LRP.", "AI": {"tldr": "An explanation-guided pruning strategy for federated learning (FL) reduces communication overhead in remote sensing (RS) image classification by identifying and sharing only the most relevant model parameters.", "motivation": "FL systems face high communication costs due to large model updates, especially in RS applications with restricted bandwidth.", "method": "Uses layer-wise relevance propagation (LRP) to prune non-informative model parameters, minimizing update volume.", "result": "Effective reduction in shared updates and improved global model generalization on the BigEarthNet-S2 dataset.", "conclusion": "The strategy enhances communication efficiency in FL for RS without compromising model performance."}}
{"id": "2405.13522", "pdf": "https://arxiv.org/pdf/2405.13522", "abs": "https://arxiv.org/abs/2405.13522", "authors": ["Zhijian Xu", "Hao Wang", "Qiang Xu"], "title": "Intervention-Aware Forecasting: Breaking Historical Limits from a System Perspective", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Traditional time series forecasting methods predominantly rely on historical\ndata patterns, neglecting external interventions that significantly shape\nfuture dynamics. Through control-theoretic analysis, we show that the implicit\n\"self-stimulation\" assumption limits the accuracy of these forecasts. To\novercome this limitation, we propose an Intervention-Aware Time Series\nForecasting (IATSF) framework explicitly designed to incorporate external\ninterventions. We particularly emphasize textual interventions due to their\nunique capability to represent qualitative or uncertain influences inadequately\ncaptured by conventional exogenous variables. We propose a leak-free benchmark\ncomposed of temporally synchronized textual intervention data across synthetic\nand real-world scenarios. To rigorously evaluate IATSF, we develop FIATS, a\nlightweight forecasting model that integrates textual interventions through\nChannel-Aware Adaptive Sensitivity Modeling (CASM) and Channel-Aware Parameter\nSharing (CAPS) mechanisms, enabling the model to adjust its sensitivity to\ninterventions and historical data in a channel-specific manner. Extensive\nempirical evaluations confirm that FIATS surpasses state-of-the-art methods,\nhighlighting that forecasting improvements stem explicitly from modeling\nexternal interventions rather than increased model complexity alone.", "AI": {"tldr": "The paper proposes an Intervention-Aware Time Series Forecasting (IATSF) framework to address the limitation of traditional methods that ignore external interventions, particularly textual ones, and introduces FIATS, a model that outperforms state-of-the-art methods by explicitly incorporating such interventions.", "motivation": "Traditional time series forecasting methods fail to account for external interventions, which significantly impact future dynamics. This limitation is addressed by incorporating textual interventions, which capture qualitative or uncertain influences better than conventional exogenous variables.", "method": "The paper introduces the IATSF framework and FIATS, a lightweight model using Channel-Aware Adaptive Sensitivity Modeling (CASM) and Channel-Aware Parameter Sharing (CAPS) to integrate textual interventions and historical data in a channel-specific manner.", "result": "FIATS outperforms state-of-the-art methods, demonstrating that forecasting improvements come from modeling external interventions, not just increased model complexity.", "conclusion": "The IATSF framework and FIATS model effectively incorporate external interventions, particularly textual ones, to enhance time series forecasting accuracy beyond traditional methods."}}
{"id": "2505.06698", "pdf": "https://arxiv.org/pdf/2505.06698", "abs": "https://arxiv.org/abs/2505.06698", "authors": ["Zongqi Wang", "Tianle Gu", "Chen Gong", "Xin Tian", "Siqi Bao", "Yujiu Yang"], "title": "From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback", "categories": ["cs.CL"], "comment": null, "summary": "Automatic evaluation benchmarks such as MT-Bench, Arena-Hard, and Auto-Arena\nare seeing growing adoption for the evaluation of Large Language Models (LLMs).\nExisting research has primarily focused on approximating human-based model\nrankings using limited data and LLM-as-a-Judge. However, the fundamental\npremise of these studies, which attempts to replicate human rankings, is\nflawed. Specifically, these benchmarks typically offer only overall scores,\nlimiting their utility to leaderboard rankings, rather than providing feedback\nthat can guide model optimization and support model profiling. Therefore, we\nadvocate for an evaluation paradigm shift from approximating human-based model\nrankings to providing feedback with analytical value. To this end, we introduce\n\\textbf{Feedbacker}, an evaluation framework that provides comprehensive and\nfine-grained results, thereby enabling thorough identification of a model's\nspecific strengths and weaknesses. Such feedback not only supports the targeted\noptimization of the model but also enhances the understanding of its behavior.\nFeedbacker comprises three key components: an extensible tree-based query\ntaxonomy builder, an automated query synthesis scheme, and a suite of\nvisualization and analysis tools. Furthermore, we propose a novel\nLLM-as-a-Judge method: PC$^{2}$ (Pre-Comparison-derived Criteria) pointwise\nevaluation. This method derives evaluation criteria by pre-comparing the\ndifferences between several auxiliary responses, achieving the accuracy of\npairwise evaluation while maintaining the time complexity of pointwise\nevaluation. Finally, leveraging the evaluation results of 17 mainstream LLMs,\nwe demonstrate the usage of Feedbacker and highlight its effectiveness and\npotential. Our project homepage and dataset are available at\nhttps://liudan193.github.io/Feedbacker.", "AI": {"tldr": "The paper critiques current LLM evaluation benchmarks for focusing on replicating human rankings and proposes Feedbacker, a framework for fine-grained feedback to optimize models.", "motivation": "Existing benchmarks provide limited utility by focusing on overall scores rather than actionable feedback for model improvement.", "method": "Feedbacker includes a tree-based query taxonomy, automated query synthesis, visualization tools, and a novel LLM-as-a-Judge method (PC$^{2}$).", "result": "Feedbacker's evaluation of 17 LLMs demonstrates its effectiveness in identifying specific strengths and weaknesses.", "conclusion": "Feedbacker shifts the evaluation paradigm to provide analytical feedback, aiding model optimization and behavior understanding."}}
{"id": "2505.11380", "pdf": "https://arxiv.org/pdf/2505.11380", "abs": "https://arxiv.org/abs/2505.11380", "authors": ["Alejandro Moreo"], "title": "On the Interconnections of Calibration, Quantification, and Classifier Accuracy Prediction under Dataset Shift", "categories": ["cs.LG"], "comment": null, "summary": "When the distribution of the data used to train a classifier differs from\nthat of the test data, i.e., under dataset shift, well-established routines for\ncalibrating the decision scores of the classifier, estimating the proportion of\npositives in a test sample, or estimating the accuracy of the classifier,\nbecome particularly challenging. This paper investigates the interconnections\namong three fundamental problems, calibration, quantification, and classifier\naccuracy prediction, under dataset shift conditions. Specifically, we prove\ntheir equivalence through mutual reduction, i.e., we show that access to an\noracle for any one of these tasks enables the resolution of the other two.\nBased on these proofs, we propose new methods for each problem based on direct\nadaptations of well-established methods borrowed from the other disciplines.\nOur results show such methods are often competitive, and sometimes even surpass\nthe performance of dedicated approaches from each discipline. The main goal of\nthis paper is to fostering cross-fertilization among these research areas,\nencouraging the development of unified approaches and promoting synergies\nacross the fields.", "AI": {"tldr": "The paper explores the equivalence of calibration, quantification, and classifier accuracy prediction under dataset shift, proposing cross-disciplinary methods that often outperform dedicated approaches.", "motivation": "Addressing challenges in classifier calibration, quantification, and accuracy prediction under dataset shift, the paper aims to unify these areas.", "method": "Proves equivalence of the three problems via mutual reduction and adapts methods from one discipline to solve others.", "result": "Proposed methods are competitive or superior to dedicated approaches, demonstrating cross-disciplinary potential.", "conclusion": "Encourages unified approaches and synergies across calibration, quantification, and accuracy prediction research."}}
{"id": "2502.00262", "pdf": "https://arxiv.org/pdf/2502.00262", "abs": "https://arxiv.org/abs/2502.00262", "authors": ["Dianwei Chen", "Zifan Zhang", "Yuchen Liu", "Xianfeng Terry Yang"], "title": "INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language Models on Context-Aware Hazard Detection and Edge Case Evaluation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Autonomous driving systems face significant challenges in handling\nunpredictable edge-case scenarios, such as adversarial pedestrian movements,\ndangerous vehicle maneuvers, and sudden environmental changes. Current\nend-to-end driving models struggle with generalization to these rare events due\nto limitations in traditional detection and prediction approaches. To address\nthis, we propose INSIGHT (Integration of Semantic and Visual Inputs for\nGeneralized Hazard Tracking), a hierarchical vision-language model (VLM)\nframework designed to enhance hazard detection and edge-case evaluation. By\nusing multimodal data fusion, our approach integrates semantic and visual\nrepresentations, enabling precise interpretation of driving scenarios and\naccurate forecasting of potential dangers. Through supervised fine-tuning of\nVLMs, we optimize spatial hazard localization using attention-based mechanisms\nand coordinate regression techniques. Experimental results on the BDD100K\ndataset demonstrate a substantial improvement in hazard prediction\nstraightforwardness and accuracy over existing models, achieving a notable\nincrease in generalization performance. This advancement enhances the\nrobustness and safety of autonomous driving systems, ensuring improved\nsituational awareness and potential decision-making in complex real-world\nscenarios.", "AI": {"tldr": "INSIGHT, a hierarchical vision-language model, improves hazard detection in autonomous driving by fusing semantic and visual inputs, outperforming existing models on the BDD100K dataset.", "motivation": "Current end-to-end driving models struggle with unpredictable edge-case scenarios like adversarial pedestrian movements and sudden environmental changes, limiting generalization.", "method": "Proposes INSIGHT, a hierarchical VLM framework using multimodal data fusion, attention-based mechanisms, and coordinate regression for hazard localization.", "result": "Demonstrates improved hazard prediction accuracy and generalization on the BDD100K dataset.", "conclusion": "INSIGHT enhances autonomous driving robustness and safety by improving situational awareness and decision-making in complex scenarios."}}
{"id": "2406.19195", "pdf": "https://arxiv.org/pdf/2406.19195", "abs": "https://arxiv.org/abs/2406.19195", "authors": ["Zeqin Yang", "Weilin Chen", "Ruichu Cai", "Yuguang Yan", "Zhifeng Hao", "Zhipeng Yu", "Zhichao Zou", "Jixing Xu", "Zhen Peng", "Jiecheng Guo"], "title": "Estimating Long-term Heterogeneous Dose-response Curve: Generalization Bound Leveraging Optimal Transport Weights", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Long-term treatment effect estimation is a significant but challenging\nproblem in many applications. Existing methods rely on ideal assumptions, such\nas no unobserved confounders or binary treatment, to estimate long-term average\ntreatment effects. However, in numerous real-world applications, these\nassumptions could be violated, and average treatment effects are insufficient\nfor personalized decision-making. In this paper, we address a more general\nproblem of estimating long-term Heterogeneous Dose-Response Curve (HDRC) while\naccounting for unobserved confounders and continuous treatment. Specifically,\nto remove the unobserved confounders in the long-term observational data, we\nintroduce an optimal transport weighting framework to align the long-term\nobservational data to an auxiliary short-term experimental data. Furthermore,\nto accurately predict the heterogeneous effects of continuous treatment, we\nestablish a generalization bound on counterfactual prediction error by\nleveraging the reweighted distribution induced by optimal transport. Finally,\nwe develop a long-term HDRC estimator building upon the above theoretical\nfoundations. Extensive experiments on synthetic and semi-synthetic datasets\ndemonstrate the effectiveness of our approach.", "AI": {"tldr": "The paper proposes a method to estimate long-term Heterogeneous Dose-Response Curves (HDRC) while addressing unobserved confounders and continuous treatment, using optimal transport weighting and theoretical generalization bounds.", "motivation": "Existing methods for long-term treatment effect estimation rely on unrealistic assumptions (e.g., no unobserved confounders or binary treatment), limiting their applicability in real-world scenarios.", "method": "The authors introduce an optimal transport weighting framework to align long-term observational data with short-term experimental data and establish a generalization bound for counterfactual prediction.", "result": "Experiments on synthetic and semi-synthetic datasets validate the effectiveness of the proposed HDRC estimator.", "conclusion": "The approach successfully addresses the challenges of unobserved confounders and continuous treatment, providing a robust solution for personalized decision-making."}}
{"id": "2505.07233", "pdf": "https://arxiv.org/pdf/2505.07233", "abs": "https://arxiv.org/abs/2505.07233", "authors": ["Jiashuo Sun", "Xianrui Zhong", "Sizhe Zhou", "Jiawei Han"], "title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": "24 pages, 7 figures, 15 tables", "summary": "Retrieval-augmented generation (RAG) systems combine large language models\n(LLMs) with external knowledge retrieval, making them highly effective for\nknowledge-intensive tasks. A crucial but often under-explored component of\nthese systems is the reranker. Since irrelevant documents in RAG systems can\nmislead the generator, the reranker plays a vital role in refining retrieved\ndocuments to enhance generation quality and explainability. However, it is\nchallenging to determine the appropriate number of documents ($k$) that the\nreranker should select: too few may result in missing critical information,\nwhile too many introduce noise and inefficiencies. Although recent studies have\nexplored LLM-based rerankers, they primarily leverage internal model knowledge\nand overlook the rich supervisory signals that LLMs can provide, such as using\nresponse quality as feedback for optimizing reranking decisions. In this paper,\nwe propose DynamicRAG, a novel RAG framework where the reranker dynamically\nadjusts both the order and number of retrieved documents based on the query. We\nmodel the reranker as an agent optimized through reinforcement learning (RL),\nusing rewards derived from LLM output quality. Across seven knowledge-intensive\ndatasets, DynamicRAG demonstrates superior performance, achieving\nstate-of-the-art results among models of same parameter sizes. The model, data\nand code are available at https://github.com/GasolSun36/DynamicRAG.", "AI": {"tldr": "DynamicRAG introduces a reinforcement learning-based reranker for RAG systems, dynamically adjusting document selection to improve generation quality and efficiency.", "motivation": "Address the challenge of determining the optimal number of documents for reranking in RAG systems to balance information relevance and noise.", "method": "Proposes DynamicRAG, a framework using RL to optimize reranking decisions based on LLM output quality.", "result": "Achieves state-of-the-art performance on seven knowledge-intensive datasets.", "conclusion": "DynamicRAG effectively enhances RAG systems by dynamically refining document retrieval, improving both quality and explainability."}}
{"id": "2505.11390", "pdf": "https://arxiv.org/pdf/2505.11390", "abs": "https://arxiv.org/abs/2505.11390", "authors": ["Millend Roy", "Vladimir Pyltsov", "Yinbo Hu"], "title": "IISE PG&E Energy Analytics Challenge 2025: Hourly-Binned Regression Models Beat Transformers in Load Forecasting", "categories": ["cs.LG", "cs.SY", "econ.EM", "eess.SY"], "comment": null, "summary": "Accurate electricity load forecasting is essential for grid stability,\nresource optimization, and renewable energy integration. While\ntransformer-based deep learning models like TimeGPT have gained traction in\ntime-series forecasting, their effectiveness in long-term electricity load\nprediction remains uncertain. This study evaluates forecasting models ranging\nfrom classical regression techniques to advanced deep learning architectures\nusing data from the ESD 2025 competition. The dataset includes two years of\nhistorical electricity load data, alongside temperature and global horizontal\nirradiance (GHI) across five sites, with a one-day-ahead forecasting horizon.\nSince actual test set load values remain undisclosed, leveraging predicted\nvalues would accumulate errors, making this a long-term forecasting challenge.\nWe employ (i) Principal Component Analysis (PCA) for dimensionality reduction\nand (ii) frame the task as a regression problem, using temperature and GHI as\ncovariates to predict load for each hour, (iii) ultimately stacking 24 models\nto generate yearly forecasts.\n  Our results reveal that deep learning models, including TimeGPT, fail to\nconsistently outperform simpler statistical and machine learning approaches due\nto the limited availability of training data and exogenous variables. In\ncontrast, XGBoost, with minimal feature engineering, delivers the lowest error\nrates across all test cases while maintaining computational efficiency. This\nhighlights the limitations of deep learning in long-term electricity\nforecasting and reinforces the importance of model selection based on dataset\ncharacteristics rather than complexity. Our study provides insights into\npractical forecasting applications and contributes to the ongoing discussion on\nthe trade-offs between traditional and modern forecasting methods.", "AI": {"tldr": "Deep learning models like TimeGPT don't outperform simpler methods (e.g., XGBoost) in long-term electricity load forecasting due to data limitations. XGBoost achieves the best results with minimal feature engineering.", "motivation": "Accurate electricity load forecasting is crucial for grid stability and renewable energy integration, but the effectiveness of transformer-based models for long-term predictions is uncertain.", "method": "Evaluated models from classical regression to deep learning using ESD 2025 data, employing PCA for dimensionality reduction and stacking 24 regression models for yearly forecasts.", "result": "XGBoost outperformed deep learning models, achieving the lowest error rates, while TimeGPT and others struggled due to limited training data and exogenous variables.", "conclusion": "Deep learning's limitations in long-term forecasting highlight the need for model selection based on dataset characteristics, favoring simpler, efficient methods like XGBoost."}}
{"id": "2502.02977", "pdf": "https://arxiv.org/pdf/2502.02977", "abs": "https://arxiv.org/abs/2502.02977", "authors": ["Samyak Rawlekar", "Yujun Cai", "Yiwei Wang", "Ming-Hsuan Yang", "Narendra Ahuja"], "title": "Disentangling CLIP for Multi-Object Perception", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models like CLIP excel at recognizing the single, prominent\nobject in a scene. However, they struggle in complex scenes containing multiple\nobjects. We identify a fundamental reason behind this limitation: VLMs features\nspace exhibits significant semantic entanglement, where features of one class\ncontain substantial information about other unrelated classes, a phenomenon we\nterm mutual feature information (MFI). This entanglement becomes evident during\nclass-specific queries, as unrelated objects are activated alongside the\nqueried class. To address this limitation, we propose DCLIP, a framework that\ndisentangles CLIP features using two complementary objectives: a novel MFI Loss\nthat orthogonalizes the text (class) features to reduce inter-class similarity,\nand the Asymmetric Loss (ASL) that aligns image features with the disentangled\ntext features. Our experiment demonstrates that DCLIP reduces inter-class\nfeature similarity by 30\\% compared to CLIP, leading to significant performance\ngains on multi-label recognition (MLR) and zero-shot semantic segmentation\n(ZS3). In MLR, DCLIP outperforms SOTA approaches on VOC2007 and COCO-14 while\nusing 75\\% fewer parameters, and surpasses SOTA ZS3 methods by 3.4 mIoU on\nVOC2012 and 2.8 mIoU on COCO-17. These results establish feature\ndisentanglement as a critical factor for effective multi-object perception in\nvision-language models.", "AI": {"tldr": "DCLIP disentangles CLIP features to reduce semantic entanglement, improving multi-object recognition and segmentation.", "motivation": "Vision-language models struggle with complex scenes due to semantic entanglement in features.", "method": "DCLIP uses MFI Loss and Asymmetric Loss to disentangle features.", "result": "30% reduction in inter-class similarity; outperforms SOTA in MLR and ZS3 tasks.", "conclusion": "Feature disentanglement is key for multi-object perception in VLMs."}}
{"id": "2407.16594", "pdf": "https://arxiv.org/pdf/2407.16594", "abs": "https://arxiv.org/abs/2407.16594", "authors": ["Simone Mungari", "Erica Coppolillo", "Ettore Ritacco", "Giuseppe Manco"], "title": "Flexible Generation of Preference Data for Recommendation Analysis", "categories": ["cs.IR", "cs.AI", "cs.SI"], "comment": null, "summary": "Simulating a recommendation system in a controlled environment, to identify\nspecific behaviors and user preferences, requires highly flexible synthetic\ndata generation models capable of mimicking the patterns and trends of real\ndatasets. In this context, we propose HYDRA, a novel preferences data\ngeneration model driven by three main factors: user-item interaction level,\nitem popularity, and user engagement level. The key innovations of the proposed\nprocess include the ability to generate user communities characterized by\nsimilar item adoptions, reflecting real-world social influences and trends.\nAdditionally, HYDRA considers item popularity and user engagement as mixtures\nof different probability distributions, allowing for a more realistic\nsimulation of diverse scenarios. This approach enhances the model's capacity to\nsimulate a wide range of real-world cases, capturing the complexity and\nvariability found in actual user behavior. We demonstrate the effectiveness of\nHYDRA through extensive experiments on well-known benchmark datasets. The\nresults highlight its capability to replicate real-world data patterns,\noffering valuable insights for developing and testing recommendation systems in\na controlled and realistic manner. The code used to perform the experiments is\npublicly available at https://github.com/SimoneMungari/HYDRA.", "AI": {"tldr": "HYDRA is a synthetic data generation model for simulating recommendation systems, focusing on user-item interactions, item popularity, and user engagement to mimic real-world behavior.", "motivation": "To create flexible synthetic data that replicates real-world user preferences and behaviors for testing recommendation systems.", "method": "HYDRA uses user-item interaction levels, item popularity, and user engagement as factors, modeling them with probability distributions to simulate diverse scenarios.", "result": "Experiments show HYDRA effectively replicates real-world data patterns, aiding in realistic recommendation system testing.", "conclusion": "HYDRA provides a robust tool for generating synthetic data that mirrors real-world complexity, useful for recommendation system development."}}
{"id": "2505.07313", "pdf": "https://arxiv.org/pdf/2505.07313", "abs": "https://arxiv.org/abs/2505.07313", "authors": ["Baixuan Xu", "Chunyang Li", "Weiqi Wang", "Wei Fan", "Tianshi Zheng", "Haochen Shi", "Tao Fan", "Yangqiu Song", "Qiang Yang"], "title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages", "summary": "Designing effective collaboration structure for multi-agent LLM systems to\nenhance collective reasoning is crucial yet remains under-explored. In this\npaper, we systematically investigate how collaborative reasoning performance is\naffected by three key design dimensions: (1) Expertise-Domain Alignment, (2)\nCollaboration Paradigm (structured workflow vs. diversity-driven integration),\nand (3) System Scale. Our findings reveal that expertise alignment benefits are\nhighly domain-contingent, proving most effective for contextual reasoning\ntasks. Furthermore, collaboration focused on integrating diverse knowledge\nconsistently outperforms rigid task decomposition. Finally, we empirically\nexplore the impact of scaling the multi-agent system with expertise\nspecialization and study the computational trade off, highlighting the need for\nmore efficient communication protocol design. This work provides concrete\nguidelines for configuring specialized multi-agent system and identifies\ncritical architectural trade-offs and bottlenecks for scalable multi-agent\nreasoning. The code will be made available upon acceptance.", "AI": {"tldr": "The paper explores how collaboration structure in multi-agent LLM systems affects collective reasoning, focusing on expertise alignment, collaboration paradigms, and system scale. Key findings include domain-specific benefits of expertise alignment, superior performance of diversity-driven collaboration, and scalability trade-offs.", "motivation": "To enhance collective reasoning in multi-agent LLM systems by investigating the impact of collaboration structure design dimensions.", "method": "Systematic investigation of three design dimensions: Expertise-Domain Alignment, Collaboration Paradigm, and System Scale.", "result": "Expertise alignment is domain-contingent, diversity-driven collaboration outperforms rigid workflows, and scaling introduces computational trade-offs.", "conclusion": "Provides guidelines for configuring multi-agent systems and identifies architectural trade-offs, emphasizing the need for efficient communication protocols."}}
{"id": "2505.11396", "pdf": "https://arxiv.org/pdf/2505.11396", "abs": "https://arxiv.org/abs/2505.11396", "authors": ["Dazhuo Qiu", "Jinwen Chen", "Arijit Khan", "Yan Zhao", "Francesco Bonchi"], "title": "Finding Counterfactual Evidences for Node Classification", "categories": ["cs.LG", "cs.DB"], "comment": "Accepted by KDD 2025", "summary": "Counterfactual learning is emerging as an important paradigm, rooted in\ncausality, which promises to alleviate common issues of graph neural networks\n(GNNs), such as fairness and interpretability. However, as in many real-world\napplication domains where conducting randomized controlled trials is\nimpractical, one has to rely on available observational (factual) data to\ndetect counterfactuals. In this paper, we introduce and tackle the problem of\nsearching for counterfactual evidences for the GNN-based node classification\ntask. A counterfactual evidence is a pair of nodes such that, regardless they\nexhibit great similarity both in the features and in their neighborhood\nsubgraph structures, they are classified differently by the GNN. We develop\neffective and efficient search algorithms and a novel indexing solution that\nleverages both node features and structural information to identify\ncounterfactual evidences, and generalizes beyond any specific GNN. Through\nvarious downstream applications, we demonstrate the potential of counterfactual\nevidences to enhance fairness and accuracy of GNNs.", "AI": {"tldr": "The paper addresses the challenge of finding counterfactual evidences in GNN-based node classification to improve fairness and interpretability, using observational data when randomized trials are impractical.", "motivation": "To enhance fairness and interpretability in GNNs by leveraging counterfactual learning, especially when randomized controlled trials are not feasible.", "method": "Develops search algorithms and an indexing solution combining node features and structural information to identify counterfactual evidences, independent of specific GNNs.", "result": "Demonstrates the effectiveness of counterfactual evidences in improving GNN fairness and accuracy through downstream applications.", "conclusion": "Counterfactual evidences offer a promising approach to address GNN limitations, enhancing fairness and interpretability without relying on randomized trials."}}
{"id": "2502.20516", "pdf": "https://arxiv.org/pdf/2502.20516", "abs": "https://arxiv.org/abs/2502.20516", "authors": ["Hu Wang", "Ibrahim Almakky", "Congbo Ma", "Numan Saeed", "Mohammad Yaqub"], "title": "In-Model Merging for Enhancing the Robustness of Medical Imaging Classification Models", "categories": ["cs.CV"], "comment": null, "summary": "Model merging is an effective strategy to merge multiple models for enhancing\nmodel performances, and more efficient than ensemble learning as it will not\nintroduce extra computation into inference. However, limited research explores\nif the merging process can occur within one model and enhance the model's\nrobustness, which is particularly critical in the medical image domain. In the\npaper, we are the first to propose in-model merging (InMerge), a novel approach\nthat enhances the model's robustness by selectively merging similar\nconvolutional kernels in the deep layers of a single convolutional neural\nnetwork (CNN) during the training process for classification. We also\nanalytically reveal important characteristics that affect how in-model merging\nshould be performed, serving as an insightful reference for the community. We\ndemonstrate the feasibility and effectiveness of this technique for different\nCNN architectures on 4 prevalent datasets. The proposed InMerge-trained model\nsurpasses the typically-trained model by a substantial margin. The code will be\nmade public.", "AI": {"tldr": "InMerge is a novel method for merging similar kernels within a single CNN during training to enhance robustness, outperforming traditional training in medical image classification.", "motivation": "Limited research explores merging within a single model to improve robustness, especially in medical imaging.", "method": "InMerge selectively merges similar convolutional kernels in deep layers of a CNN during training.", "result": "InMerge-trained models outperform traditionally-trained models on 4 datasets.", "conclusion": "InMerge is feasible and effective, providing insights for kernel merging in CNNs."}}
{"id": "2409.15963", "pdf": "https://arxiv.org/pdf/2409.15963", "abs": "https://arxiv.org/abs/2409.15963", "authors": ["Bo Yue", "Jian Li", "Guiliang Liu"], "title": "Provably Efficient Exploration in Inverse Constrained Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Optimizing objective functions subject to constraints is fundamental in many\nreal-world applications. However, these constraints are often not readily\ndefined and must be inferred from expert agent behaviors, a problem known as\nInverse Constraint Inference. Inverse Constrained Reinforcement Learning (ICRL)\nis a common solver for recovering feasible constraints in complex environments,\nrelying on training samples collected from interactive environments. However,\nthe efficacy and efficiency of current sampling strategies remain unclear. We\npropose a strategic exploration framework for sampling with guaranteed\nefficiency to bridge this gap. By defining the feasible cost set for ICRL\nproblems, we analyze how estimation errors in transition dynamics and the\nexpert policy influence the feasibility of inferred constraints. Based on this\nanalysis, we introduce two exploratory algorithms to achieve efficient\nconstraint inference via 1) dynamically reducing the bounded aggregate error of\ncost estimations or 2) strategically constraining the exploration policy around\nplausibly optimal ones. Both algorithms are theoretically grounded with\ntractable sample complexity, and their performance is validated empirically\nacross various environments.", "AI": {"tldr": "The paper proposes a strategic exploration framework for efficient sampling in Inverse Constrained Reinforcement Learning (ICRL), addressing gaps in current methods by introducing two exploratory algorithms with theoretical guarantees.", "motivation": "Current sampling strategies in ICRL lack clarity in efficacy and efficiency, necessitating a more systematic approach to infer constraints from expert behaviors.", "method": "The authors define a feasible cost set for ICRL and analyze error influences. They introduce two algorithms: one reduces cost estimation errors dynamically, and the other strategically constrains exploration around optimal policies.", "result": "Both algorithms are theoretically supported with tractable sample complexity and empirically validated across various environments.", "conclusion": "The proposed framework improves efficiency and feasibility in constraint inference for ICRL, offering practical solutions with theoretical backing."}}
{"id": "2505.09655", "pdf": "https://arxiv.org/pdf/2505.09655", "abs": "https://arxiv.org/abs/2505.09655", "authors": ["Xiwen Chen", "Wenhui Zhu", "Peijie Qiu", "Xuanzhao Dong", "Hao Wang", "Haiyu Wu", "Huayu Li", "Aristeidis Sotiras", "Yalin Wang", "Abolfazl Razi"], "title": "DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in reinforcement learning for language model post-training,\nsuch as Group Relative Policy Optimization (GRPO), have shown promise in\nlow-resource settings. However, GRPO typically relies on solution-level and\nscalar reward signals that fail to capture the semantic diversity among sampled\ncompletions. This leads to what we identify as a diversity-quality\ninconsistency, where distinct reasoning paths may receive indistinguishable\nrewards. To address this limitation, we propose $\\textit{Diversity-aware Reward\nAdjustment}$ (DRA), a method that explicitly incorporates semantic diversity\ninto the reward computation. DRA uses Submodular Mutual Information (SMI) to\ndownweight redundant completions and amplify rewards for diverse ones. This\nencourages better exploration during learning, while maintaining stable\nexploitation of high-quality samples. Our method integrates seamlessly with\nboth GRPO and its variant DR.~GRPO, resulting in $\\textit{DRA-GRPO}$ and\n$\\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning\nbenchmarks and find that it outperforms recent strong baselines. It achieves\nstate-of-the-art performance with an average accuracy of 58.2%, using only\n7,000 fine-tuning samples and a total training cost of approximately $55. The\ncode is available at https://github.com/xiwenc1/DRA-GRPO.", "AI": {"tldr": "The paper introduces Diversity-aware Reward Adjustment (DRA) to address diversity-quality inconsistency in reinforcement learning for language models, improving performance in low-resource settings.", "motivation": "Current methods like GRPO lack semantic diversity in reward signals, leading to indistinguishable rewards for diverse reasoning paths.", "method": "DRA uses Submodular Mutual Information (SMI) to adjust rewards, downweighting redundant completions and amplifying diverse ones. It integrates with GRPO and DR.~GRPO.", "result": "DRA achieves state-of-the-art performance (58.2% accuracy) on five mathematical reasoning benchmarks with minimal resources.", "conclusion": "DRA effectively balances exploration and exploitation, enhancing model performance in low-resource scenarios."}}
{"id": "2505.11411", "pdf": "https://arxiv.org/pdf/2505.11411", "abs": "https://arxiv.org/abs/2505.11411", "authors": ["Xiaotian Zhang", "Yue Shang", "Entao Yang", "Ge Zhang"], "title": "Is Grokking a Computational Glass Relaxation?", "categories": ["cs.LG", "cond-mat.dis-nn"], "comment": null, "summary": "Understanding neural network's (NN) generalizability remains a central\nquestion in deep learning research. The special phenomenon of grokking, where\nNNs abruptly generalize long after the training performance reaches a\nnear-perfect level, offers a unique window to investigate the underlying\nmechanisms of NNs' generalizability. Here we propose an interpretation for\ngrokking by framing it as a computational glass relaxation: viewing NNs as a\nphysical system where parameters are the degrees of freedom and train loss is\nthe system energy, we find memorization process resembles a rapid cooling of\nliquid into non-equilibrium glassy state at low temperature and the later\ngeneralization is like a slow relaxation towards a more stable configuration.\nThis mapping enables us to sample NNs' Boltzmann entropy (states of density)\nlandscape as a function of training loss and test accuracy. Our experiments in\ntransformers on arithmetic tasks suggests that there is NO entropy barrier in\nthe memorization-to-generalization transition of grokking, challenging previous\ntheory that defines grokking as a first-order phase transition. We identify a\nhigh-entropy advantage under grokking, an extension of prior work linking\nentropy to generalizability but much more significant. Inspired by grokking's\nfar-from-equilibrium nature, we develop a toy optimizer WanD based on\nWang-landau molecular dynamics, which can eliminate grokking without any\nconstraints and find high-norm generalizing solutions. This provides\nstrictly-defined counterexamples to theory attributing grokking solely to\nweight norm evolution towards the Goldilocks zone and also suggests new\npotential ways for optimizer design.", "AI": {"tldr": "The paper explores grokking in neural networks, likening it to glass relaxation, and challenges prior theories by showing no entropy barrier in the memorization-to-generalization transition. It introduces a toy optimizer, WanD, to eliminate grokking.", "motivation": "To understand the underlying mechanisms of neural networks' generalizability, particularly the abrupt generalization phenomenon known as grokking.", "method": "Frames grokking as computational glass relaxation, sampling NNs' Boltzmann entropy landscape, and experiments with transformers on arithmetic tasks. Introduces the WanD optimizer inspired by Wang-Landau molecular dynamics.", "result": "No entropy barrier in grokking's memorization-to-generalization transition, challenging prior theories. High-entropy advantage under grokking identified. WanD optimizer eliminates grokking and finds generalizing solutions.", "conclusion": "Grokking is not a first-order phase transition. The findings suggest new directions for optimizer design and challenge existing theories on grokking."}}
{"id": "2502.20742", "pdf": "https://arxiv.org/pdf/2502.20742", "abs": "https://arxiv.org/abs/2502.20742", "authors": ["Xiwen Liang", "Min Lin", "Weiqi Ruan", "Rongtao Xu", "Yuecheng Liu", "Jiaqi Chen", "Bingqian Lin", "Yuzheng Zhuang", "Xiaodan Liang"], "title": "Structured Preference Optimization for Vision-Language Long-Horizon Task Planning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "18 pages", "summary": "Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.", "AI": {"tldr": "SPO improves long-horizon vision-language task planning via structured preference optimization and curriculum-guided training, outperforming baselines on new benchmark ExtendaBench.", "motivation": "Existing methods struggle with long-horizon tasks due to poor reasoning quality. SPO addresses this by enhancing reasoning and action selection.", "method": "SPO uses preference-based scoring (task relevance, visual grounding, historical consistency) and curriculum-guided training (simple to complex tasks).", "result": "SPO achieves significant improvements in reasoning quality and decision accuracy (+5.98% GCR in VirtualHome, +3.30% GCR in Habitat).", "conclusion": "SPO's preference-driven optimization is effective for long-horizon vision-language task planning, as shown by superior performance on ExtendaBench."}}
{"id": "2409.18865", "pdf": "https://arxiv.org/pdf/2409.18865", "abs": "https://arxiv.org/abs/2409.18865", "authors": ["William E. R. de Amorim", "Scott A. Sisson", "T. Rodrigues", "David J. Nott", "Guilherme S. Rodrigues"], "title": "Positional Encoder Graph Quantile Neural Networks for Geographic Data", "categories": ["stat.ML", "cs.AI", "cs.CV", "cs.LG", "cs.SI"], "comment": "12 main text pages, 4 figures", "summary": "Positional Encoder Graph Neural Networks (PE-GNNs) are among the most\neffective models for learning from continuous spatial data. However, their\npredictive distributions are often poorly calibrated, limiting their utility in\napplications that require reliable uncertainty quantification. We propose the\nPositional Encoder Graph Quantile Neural Network (PE-GQNN), a novel framework\nthat combines PE-GNNs with Quantile Neural Networks, partially monotonic neural\nblocks, and post-hoc recalibration techniques. The PE-GQNN enables flexible and\nrobust conditional density estimation with minimal assumptions about the target\ndistribution, and it extends naturally to tasks beyond spatial data. Empirical\nresults on benchmark datasets show that the PE-GQNN outperforms existing\nmethods in both predictive accuracy and uncertainty quantification, without\nincurring additional computational cost. We also provide theoretical insights\nand identify important special cases arising from our formulation, including\nthe PE-GNN.", "AI": {"tldr": "PE-GQNN improves PE-GNNs by combining them with Quantile Neural Networks and recalibration techniques for better uncertainty quantification and accuracy.", "motivation": "PE-GNNs lack reliable uncertainty quantification, limiting their practical utility.", "method": "Combines PE-GNNs with Quantile Neural Networks, monotonic neural blocks, and recalibration techniques.", "result": "Outperforms existing methods in accuracy and uncertainty quantification without extra computational cost.", "conclusion": "PE-GQNN offers robust conditional density estimation and extends beyond spatial data."}}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-D\u00edaz", "William Jim\u00e9nez-Leal", "Mar\u00eda Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Berm\u00fadez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis.", "AI": {"tldr": "A tutorial on using LLMs for efficient text analysis with iterative collaboration between researchers and LLMs, demonstrated via personal goals categorization.", "motivation": "Text analysis is time-consuming and biased; LLMs offer a solution without quality loss.", "method": "Step-by-step tutorial: prompt writing, taxonomy generation, evaluation, refinement, testing, and application.", "result": "High intercoder reliability achieved in categorizing datasets.", "conclusion": "LLMs are promising for text analysis but have limitations."}}
{"id": "2505.11412", "pdf": "https://arxiv.org/pdf/2505.11412", "abs": "https://arxiv.org/abs/2505.11412", "authors": ["Ciaran Bench", "Vivek Desai", "Mohammad Moulaeifard", "Nils Strodthoff", "Philip Aston", "Andrew Thompson"], "title": "Uncertainty quantification with approximate variational learning for wearable photoplethysmography prediction tasks", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Photoplethysmography (PPG) signals encode information about relative changes\nin blood volume that can be used to assess various aspects of cardiac health\nnon-invasively, e.g.\\ to detect atrial fibrillation (AF) or predict blood\npressure (BP). Deep networks are well-equipped to handle the large quantities\nof data acquired from wearable measurement devices. However, they lack\ninterpretability and are prone to overfitting, leaving considerable risk for\npoor performance on unseen data and misdiagnosis. Here, we describe the use of\ntwo scalable uncertainty quantification techniques: Monte Carlo Dropout and the\nrecently proposed Improved Variational Online Newton. These techniques are used\nto assess the trustworthiness of models trained to perform AF classification\nand BP regression from raw PPG time series. We find that the choice of\nhyperparameters has a considerable effect on the predictive performance of the\nmodels and on the quality and composition of predicted uncertainties. E.g. the\nstochasticity of the model parameter sampling determines the proportion of the\ntotal uncertainty that is aleatoric, and has varying effects on predictive\nperformance and calibration quality dependent on the chosen uncertainty\nquantification technique and the chosen expression of uncertainty. We find\nsignificant discrepancy in the quality of uncertainties over the predicted\nclasses, emphasising the need for a thorough evaluation protocol that assesses\nlocal and adaptive calibration. This work suggests that the choice of\nhyperparameters must be carefully tuned to balance predictive performance and\ncalibration quality, and that the optimal parameterisation may vary depending\non the chosen expression of uncertainty.", "AI": {"tldr": "The paper explores uncertainty quantification techniques (Monte Carlo Dropout and Improved Variational Online Newton) for deep networks analyzing PPG signals to improve trustworthiness in AF classification and BP regression.", "motivation": "Deep networks lack interpretability and are prone to overfitting, risking poor performance on unseen data and misdiagnosis in cardiac health assessments using PPG signals.", "method": "Two scalable uncertainty quantification techniques are applied to assess model trustworthiness for AF classification and BP regression from raw PPG time series.", "result": "Hyperparameter choice significantly impacts predictive performance and uncertainty quality, with stochasticity affecting aleatoric uncertainty proportion and calibration. Discrepancies in uncertainty quality across predicted classes highlight the need for thorough evaluation.", "conclusion": "Careful hyperparameter tuning is essential to balance predictive performance and calibration quality, with optimal settings varying by uncertainty expression."}}
{"id": "2503.04877", "pdf": "https://arxiv.org/pdf/2503.04877", "abs": "https://arxiv.org/abs/2503.04877", "authors": ["Albert Wilcox", "Mohamed Ghanem", "Masoud Moghani", "Pierre Barroso", "Benjamin Joffe", "Animesh Garg"], "title": "Adapt3R: Adaptive 3D Scene Representation for Domain Transfer in Imitation Learning", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Videos, code, and data: https://pairlab.github.io/Adapt3R", "summary": "Imitation Learning can train robots to perform complex and diverse\nmanipulation tasks, but learned policies are brittle with observations outside\nof the training distribution. 3D scene representations that incorporate\nobservations from calibrated RGBD cameras have been proposed as a way to\nmitigate this, but in our evaluations with unseen embodiments and camera\nviewpoints they show only modest improvement. To address those challenges, we\npropose Adapt3R, a general-purpose 3D observation encoder which synthesizes\ndata from calibrated RGBD cameras into a vector that can be used as\nconditioning for arbitrary IL algorithms. The key idea is to use a pretrained\n2D backbone to extract semantic information, using 3D only as a medium to\nlocalize this information with respect to the end-effector. We show across 93\nsimulated and 6 real tasks that when trained end-to-end with a variety of IL\nalgorithms, Adapt3R maintains these algorithms' learning capacity while\nenabling zero-shot transfer to novel embodiments and camera poses.", "AI": {"tldr": "Adapt3R improves imitation learning by using a 3D observation encoder to handle unseen embodiments and camera viewpoints, leveraging 2D semantic features localized in 3D.", "motivation": "Current 3D scene representations in imitation learning show limited improvement for unseen scenarios, necessitating a more robust solution.", "method": "Adapt3R combines a pretrained 2D backbone for semantic extraction with 3D localization relative to the end-effector, integrating with various IL algorithms.", "result": "Adapt3R enables zero-shot transfer to novel embodiments and camera poses across 93 simulated and 6 real tasks.", "conclusion": "Adapt3R enhances generalization in imitation learning without compromising the performance of existing algorithms."}}
{"id": "2410.00031", "pdf": "https://arxiv.org/pdf/2410.00031", "abs": "https://arxiv.org/abs/2410.00031", "authors": ["Ryan Y. Lin", "Siddhartha Ojha", "Kevin Cai", "Maxwell F. Chen"], "title": "Strategic Collusion of LLM Agents: Market Division in Multi-Commodity Competitions", "categories": ["cs.GT", "cs.AI", "cs.CL", "q-fin.CP"], "comment": null, "summary": "Machine-learning technologies are seeing increased deployment in real-world\nmarket scenarios. In this work, we explore the strategic behaviors of large\nlanguage models (LLMs) when deployed as autonomous agents in multi-commodity\nmarkets, specifically within Cournot competition frameworks. We examine whether\nLLMs can independently engage in anti-competitive practices such as collusion\nor, more specifically, market division. Our findings demonstrate that LLMs can\neffectively monopolize specific commodities by dynamically adjusting their\npricing and resource allocation strategies, thereby maximizing profitability\nwithout direct human input or explicit collusion commands. These results pose\nunique challenges and opportunities for businesses looking to integrate AI into\nstrategic roles and for regulatory bodies tasked with maintaining fair and\ncompetitive markets. The study provides a foundation for further exploration\ninto the ramifications of deferring high-stakes decisions to LLM-based agents.", "AI": {"tldr": "LLMs can autonomously monopolize commodities in Cournot markets by adjusting pricing and resource strategies, raising regulatory and business challenges.", "motivation": "To investigate if LLMs can independently engage in anti-competitive practices like collusion or market division in multi-commodity markets.", "method": "Examining LLM behaviors in Cournot competition frameworks, focusing on pricing and resource allocation strategies.", "result": "LLMs can effectively monopolize commodities without human input or explicit collusion, maximizing profitability.", "conclusion": "The study highlights challenges for AI integration in strategic roles and regulatory needs, urging further research on LLM-based decision-making."}}
{"id": "2505.09924", "pdf": "https://arxiv.org/pdf/2505.09924", "abs": "https://arxiv.org/abs/2505.09924", "authors": ["Yidan Wang", "Yubing Ren", "Yanan Cao", "Binxing Fang"], "title": "From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models", "categories": ["cs.CL", "cs.CR"], "comment": "Accepted to ACL 2025 (main)", "summary": "The rise of Large Language Models (LLMs) has heightened concerns about the\nmisuse of AI-generated text, making watermarking a promising solution.\nMainstream watermarking schemes for LLMs fall into two categories: logits-based\nand sampling-based. However, current schemes entail trade-offs among\nrobustness, text quality, and security. To mitigate this, we integrate\nlogits-based and sampling-based schemes, harnessing their respective strengths\nto achieve synergy. In this paper, we propose a versatile symbiotic\nwatermarking framework with three strategies: serial, parallel, and hybrid. The\nhybrid framework adaptively embeds watermarks using token entropy and semantic\nentropy, optimizing the balance between detectability, robustness, text\nquality, and security. Furthermore, we validate our approach through\ncomprehensive experiments on various datasets and models. Experimental results\nindicate that our method outperforms existing baselines and achieves\nstate-of-the-art (SOTA) performance. We believe this framework provides novel\ninsights into diverse watermarking paradigms. Our code is available at\nhttps://github.com/redwyd/SymMark.", "AI": {"tldr": "A hybrid watermarking framework for LLMs combines logits-based and sampling-based schemes to balance robustness, text quality, and security, achieving SOTA performance.", "motivation": "Addressing the trade-offs in existing LLM watermarking schemes to improve misuse detection without compromising text quality.", "method": "Proposes a symbiotic framework with serial, parallel, and hybrid strategies, using token and semantic entropy for adaptive watermarking.", "result": "Outperforms baselines in experiments, achieving state-of-the-art performance across datasets and models.", "conclusion": "The framework offers a versatile solution for LLM watermarking, balancing detectability, robustness, and quality."}}
{"id": "2505.11415", "pdf": "https://arxiv.org/pdf/2505.11415", "abs": "https://arxiv.org/abs/2505.11415", "authors": ["Yinsicheng Jiang", "Yao Fu", "Yeqi Huang", "Ping Nie", "Zhan Lu", "Leyang Xue", "Congjie He", "Man-Kit Sit", "Jilong Xue", "Li Dong", "Ziming Miao", "Dayou Du", "Tairan Xu", "Kai Zou", "Edoardo Ponti", "Luo Mai"], "title": "MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems", "categories": ["cs.LG", "cs.DC"], "comment": "arXiv admin note: substantial text overlap with arXiv:2412.07067", "summary": "The sparse Mixture-of-Experts (MoE) architecture is increasingly favored for\nscaling Large Language Models (LLMs) efficiently, but it depends on\nheterogeneous compute and memory resources. These factors jointly affect system\nCost, Accuracy, and Performance (CAP), making trade-offs inevitable. Existing\nbenchmarks often fail to capture these trade-offs accurately, complicating\npractical deployment decisions. To address this, we introduce MoE-CAP, a\nbenchmark specifically designed for MoE systems. Our analysis reveals that\nachieving an optimal balance across CAP is difficult with current hardware; MoE\nsystems typically optimize two of the three dimensions at the expense of the\nthird-a dynamic we term the MoE-CAP trade-off. To visualize this, we propose\nthe CAP Radar Diagram. We further introduce sparsity-aware performance\nmetrics-Sparse Memory Bandwidth Utilization (S-MBU) and Sparse Model FLOPS\nUtilization (S-MFU)-to enable accurate performance benchmarking of MoE systems\nacross diverse hardware platforms and deployment scenarios.", "AI": {"tldr": "MoE-CAP is a benchmark for MoE systems, highlighting the trade-offs between Cost, Accuracy, and Performance (CAP) and introducing new metrics for better evaluation.", "motivation": "Existing benchmarks fail to accurately capture the trade-offs in MoE systems, complicating deployment decisions.", "method": "Introduces MoE-CAP benchmark, CAP Radar Diagram, and sparsity-aware metrics (S-MBU, S-MFU) for evaluation.", "result": "Optimal CAP balance is hard to achieve; MoE systems often sacrifice one dimension for the other two.", "conclusion": "MoE-CAP and new metrics provide better tools for benchmarking MoE systems across hardware and scenarios."}}
{"id": "2503.07516", "pdf": "https://arxiv.org/pdf/2503.07516", "abs": "https://arxiv.org/abs/2503.07516", "authors": ["Weize Li", "Yunhao Du", "Qixiang Yin", "Zhicheng Zhao", "Fei Su", "Daqi Liu"], "title": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Referring Multi-Object Tracking (RMOT) aims to localize target trajectories\nspecified by natural language expressions in videos. Existing RMOT methods\nmainly follow two paradigms: one-stage strategies and two-stage ones. The\nformer jointly trains tracking with referring but suffers from substantial\ncomputational overhead. Although the latter improves efficiency, it overlooks\nthe inherent contextual aggregation capabilities of pre-trained visual\nbackbones and takes a detour. Meanwhile, its fixed dual-tower architecture\nrestricts compatibility with other visual / text backbones. To address these\nlimitations, we propose JustHook, a novel hook-like framework for two-stage\nRMOT, which introduces two core components: (1) a Visual Feature Hook (VFH),\nenabling JustHook to extract context-rich local features directly from the\noriginal visual backbone like a hook; (2) a Parallel Combined Decoder (PCD),\nwhich transforms the passive cosine similarity measurement between independent\nmodalities into active contrastive learning within the combined feature space.\nThe proposed JustHook not only leverages the capabilities of pre-trained models\nbut also breaks free from the constraints of inherent modality alignment,\nachieving strong scalability. Extensive experiments on Refer-KITTI and\nRefer-KITTI-V2 demonstrate that JustHook outperforms state-of-the-art methods\nacross diverse encoder combinations, achieving a notable 7.77\\% HOTA\nimprovement on Refer-KITTI-V2. Code will be made available soon.", "AI": {"tldr": "JustHook is a novel two-stage RMOT framework that improves efficiency and scalability by leveraging pre-trained visual backbones and active contrastive learning.", "motivation": "Existing RMOT methods face computational overhead or overlook contextual aggregation in pre-trained models, limiting efficiency and compatibility.", "method": "JustHook introduces Visual Feature Hook (VFH) for direct feature extraction and Parallel Combined Decoder (PCD) for active contrastive learning.", "result": "JustHook achieves a 7.77% HOTA improvement on Refer-KITTI-V2, outperforming state-of-the-art methods.", "conclusion": "JustHook effectively addresses limitations of existing RMOT methods, offering better performance and scalability."}}
{"id": "2410.06883", "pdf": "https://arxiv.org/pdf/2410.06883", "abs": "https://arxiv.org/abs/2410.06883", "authors": ["Yingxu Wang", "Mengzhu Wang", "Siwei Liu", "Houcheng Su", "Nan Yin", "James Kwok"], "title": "Degree-Conscious Spiking Graph for Cross-Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Spiking Graph Networks (SGNs) have demonstrated significant potential in\ngraph classification by emulating brain-inspired neural dynamics to achieve\nenergy-efficient computation. However, existing SGNs are generally constrained\nto in-distribution scenarios and struggle with distribution shifts. In this\npaper, we first propose the domain adaptation problem in SGNs, and introduce a\nnovel framework named Degree-Consicious Spiking Graph for Cross-Domain\nAdaptation. DeSGraDA enhances generalization across domains with three key\ncomponents. First, we introduce the degree-conscious spiking representation\nmodule by adapting spike thresholds based on node degrees, enabling more\nexpressive and structure-aware signal encoding. Then, we perform temporal\ndistribution alignment by adversarially matching membrane potentials between\ndomains, ensuring effective performance under domain shift while preserving\nenergy efficiency. Additionally, we extract consistent predictions across two\nspaces to create reliable pseudo-labels, effectively leveraging unlabeled data\nto enhance graph classification performance. Furthermore, we establish the\nfirst generalization bound for SGDA, providing theoretical insights into its\nadaptation performance. Extensive experiments on benchmark datasets validate\nthat DeSGraDA consistently outperforms state-of-the-art methods in both\nclassification accuracy and energy efficiency.", "AI": {"tldr": "DeSGraDA improves Spiking Graph Networks (SGNs) for cross-domain adaptation by introducing degree-conscious spiking, temporal alignment, and pseudo-labeling, outperforming existing methods.", "motivation": "Existing SGNs struggle with distribution shifts, limiting their generalization across domains.", "method": "Proposes DeSGraDA with degree-conscious spiking, adversarial temporal alignment, and pseudo-labeling for cross-domain adaptation.", "result": "Outperforms state-of-the-art methods in accuracy and energy efficiency on benchmark datasets.", "conclusion": "DeSGraDA effectively addresses domain adaptation in SGNs, enhancing generalization and performance."}}
{"id": "2505.10354", "pdf": "https://arxiv.org/pdf/2505.10354", "abs": "https://arxiv.org/abs/2505.10354", "authors": ["Yile Wang", "Zhanyu Shen", "Hui Huang"], "title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Semantic text representation is a fundamental task in the field of natural\nlanguage processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have\ndemonstrated excellent performance, but the values of each dimension are\ndifficult to trace and interpret. Bag-of-words, as classic sparse interpretable\nembeddings, suffers from poor performance. Recently, Benara et al. (2024)\npropose interpretable text embeddings using large language models, which forms\n\"0/1\" embeddings based on responses to a series of questions. These\ninterpretable text embeddings are typically high-dimensional (larger than\n10,000). In this work, we propose Low-dimensional (lower than 500) Dense and\nInterpretable text embeddings with Relative representations (LDIR). The\nnumerical values of its dimensions indicate semantic relatedness to different\nanchor texts through farthest point sampling, offering both semantic\nrepresentation as well as a certain level of traceability and interpretability.\nWe validate LDIR on multiple semantic textual similarity, retrieval, and\nclustering tasks. Extensive experimental results show that LDIR performs close\nto the black-box baseline models and outperforms the interpretable embeddings\nbaselines with much fewer dimensions. Code is available at\nhttps://github.com/szu-tera/LDIR.", "AI": {"tldr": "LDIR introduces low-dimensional, dense, and interpretable text embeddings using relative representations, balancing performance and interpretability.", "motivation": "Existing text embeddings lack interpretability (e.g., SimCSE) or suffer from poor performance (e.g., bag-of-words). Recent work (Benara et al., 2024) offers interpretability but with high dimensionality.", "method": "LDIR uses farthest point sampling to create low-dimensional (under 500) embeddings where values indicate semantic relatedness to anchor texts.", "result": "LDIR performs close to black-box models and outperforms interpretable baselines with fewer dimensions.", "conclusion": "LDIR successfully combines performance and interpretability, validated on semantic similarity, retrieval, and clustering tasks."}}
{"id": "2505.11432", "pdf": "https://arxiv.org/pdf/2505.11432", "abs": "https://arxiv.org/abs/2505.11432", "authors": ["Chao Jin", "Ziheng Jiang", "Zhihao Bai", "Zheng Zhong", "Juncai Liu", "Xiang Li", "Ningxin Zheng", "Xi Wang", "Cong Xie", "Wen Heng", "Yiyuan Ma", "Wenlei Bao", "Size Zheng", "Yanghua Peng", "Haibin Lin", "Xuanzhe Liu", "Xin Jin", "Xin Liu"], "title": "MegaScale-MoE: Large-Scale Communication-Efficient Training of Mixture-of-Experts Models in Production", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "We present MegaScale-MoE, a production system tailored for the efficient\ntraining of large-scale mixture-of-experts (MoE) models. MoE emerges as a\npromising architecture to scale large language models (LLMs) to unprecedented\nsizes, thereby enhancing model performance. However, existing MoE training\nsystems experience a degradation in training efficiency, exacerbated by the\nescalating scale of MoE models and the continuous evolution of hardware.\n  Recognizing the pivotal role of efficient communication in enhancing MoE\ntraining, MegaScale-MoE customizes communication-efficient parallelism\nstrategies for attention and FFNs in each MoE layer and adopts a holistic\napproach to overlap communication with computation at both inter- and\nintra-operator levels. Additionally, MegaScale-MoE applies communication\ncompression with adjusted communication patterns to lower precision, further\nimproving training efficiency. When training a 352B MoE model on 1,440 NVIDIA\nHopper GPUs, MegaScale-MoE achieves a training throughput of 1.41M tokens/s,\nimproving the efficiency by 1.88$\\times$ compared to Megatron-LM. We share our\noperational experience in accelerating MoE training and hope that by offering\nour insights in system design, this work will motivate future research in MoE\nsystems.", "AI": {"tldr": "MegaScale-MoE is a system designed to efficiently train large-scale MoE models by optimizing communication and computation overlap, achieving significant throughput improvements.", "motivation": "MoE models show promise for scaling LLMs but suffer from efficiency degradation due to model size and hardware evolution. Efficient communication is key to improving training.", "method": "Customizes communication-efficient parallelism for MoE layers, overlaps communication with computation, and applies communication compression to lower precision.", "result": "Achieves 1.41M tokens/s throughput on 1,440 GPUs, 1.88\u00d7 efficiency improvement over Megatron-LM.", "conclusion": "Shares insights to inspire future MoE system research, demonstrating practical efficiency gains."}}
{"id": "2503.17715", "pdf": "https://arxiv.org/pdf/2503.17715", "abs": "https://arxiv.org/abs/2503.17715", "authors": ["Abtin Pourhadi", "Paul Swoboda"], "title": "Normalized Matching Transformer", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We present a new state of the art approach for sparse keypoint matching\nbetween pairs of images. Our method consists of a fully deep learning based\napproach combining a visual backbone coupled with a SplineCNN graph neural\nnetwork for feature processing and a normalized transformer decoder for\ndecoding keypoint correspondences together with the Sinkhorn algorithm. Our\nmethod is trained using a contrastive and a hyperspherical loss for better\nfeature representations. We additionally use data augmentation during training.\nThis comparatively simple architecture combining extensive normalization and\nadvanced losses outperforms current state of the art approaches on PascalVOC\nand SPair-71k datasets by $5.1\\%$ and $2.2\\%$ respectively compared to BBGM,\nASAR, COMMON and GMTR while training for at least $1.7x$ fewer epochs.", "AI": {"tldr": "A deep learning-based method for sparse keypoint matching, combining a visual backbone, SplineCNN, and a normalized transformer decoder, outperforms state-of-the-art approaches with fewer training epochs.", "motivation": "To improve sparse keypoint matching accuracy and efficiency by leveraging deep learning and advanced loss functions.", "method": "Combines a visual backbone, SplineCNN graph neural network, normalized transformer decoder, and Sinkhorn algorithm, trained with contrastive and hyperspherical losses and data augmentation.", "result": "Outperforms current methods by 5.1% and 2.2% on PascalVOC and SPair-71k datasets, with 1.7x fewer training epochs.", "conclusion": "The proposed architecture achieves superior performance with simpler training, demonstrating the effectiveness of advanced normalization and loss functions."}}
{"id": "2410.07793", "pdf": "https://arxiv.org/pdf/2410.07793", "abs": "https://arxiv.org/abs/2410.07793", "authors": ["ZiXiao Zhao", "Fatemeh H. Fard"], "title": "Do Current Language Models Support Code Intelligence for R Programming Language?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Recent advancements in developing Pre-trained Language Models for Code\n(Code-PLMs) have urged many areas of Software Engineering (SE) and brought\nbreakthrough results for many SE tasks. Though these models have achieved the\nstate-of-the-art performance for SE tasks for many popular programming\nlanguages, such as Java and Python, the Scientific Software and its related\nlanguages like R programming language have rarely benefited or even been\nevaluated with the Code-PLMs. Research has shown that R has many differences\nwith other programming languages and requires specific techniques. In this\nstudy, we provide the first insights for code intelligence for R. For this\npurpose, we collect and open source an R dataset, and evaluate Code-PLMs for\nthe two tasks of code summarization and method name prediction using several\nsettings and strategies, including the differences in two R styles, Tidy-verse\nand Base R. Our results demonstrate that the studied models have experienced\nvarying degrees of performance degradation when processing R programming\nlanguage code, which is supported by human evaluation. Additionally, not all\nmodels show performance improvement in R-specific tasks even after\nmulti-language fine-tuning. The dual syntax paradigms in R significantly impact\nthe models' performance, particularly in code summarization tasks. Furthermore,\nthe project-specific context inherent in R codebases significantly impacts the\nperformance when attempting cross-project training.", "AI": {"tldr": "The paper evaluates Code-PLMs for R programming, revealing performance gaps and challenges due to R's unique syntax and project-specific contexts.", "motivation": "Despite Code-PLMs' success in SE tasks for languages like Java and Python, R and scientific software have been overlooked. This study addresses this gap.", "method": "The study collects an R dataset, evaluates Code-PLMs on code summarization and method name prediction, and compares Tidy-verse and Base R styles.", "result": "Models show performance degradation with R, especially in code summarization. Multi-language fine-tuning doesn't always help, and project-specific contexts hinder cross-project training.", "conclusion": "R's unique syntax and project-specific contexts pose challenges for Code-PLMs, highlighting the need for tailored approaches."}}
{"id": "2404.02882", "pdf": "https://arxiv.org/pdf/2404.02882", "abs": "https://arxiv.org/abs/2404.02882", "authors": ["Weigao Sun", "Zhen Qin", "Dong Li", "Xuyang Shen", "Yu Qiao", "Yiran Zhong"], "title": "Linear Attention Sequence Parallelism", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted by TMLR, 23 pages", "summary": "Sequence parallelism (SP) serves as a prevalent strategy to handle long\nsequences that exceed the memory limit of a single device. However, for linear\nsequence modeling methods like linear attention, existing SP approaches do not\ntake advantage of their right-product-first feature, resulting in sub-optimal\ncommunication efficiency and usability. In this paper, we introduce Linear\nAttention Sequence Parallelism (LASP), an efficient SP approach designed for\nlinear attention-based transformer models. Specifically, we design an efficient\npoint-to-point ring-style communication mechanism to leverage the right-product\nkernel trick of linear attention, which sharply decreases the communication\noverhead, comparing with existing SP methods. We enhance the computation\nefficiency of LASP by performing kernel fusion and intermediate state caching,\nmaking the implementation of LASP hardware-friendly on GPUs. Furthermore, we\nmeticulously ensure the compatibility of sequence-level LASP with all types of\nbatch-level data parallel methods, which is vital for distributed training on\nlarge clusters with very-long sequences. We also discuss the generalization of\nLASP on other linear sequence modeling methods. Extensive experiments on linear\nattention-based models are conducted with varying sequence lengths from 2K to\n4096K. LASP scales sequence length up to 4096K on 128 GPUs, which is 8$\\times$\nlonger than existing SP methods. Code is available at:\nhttps://github.com/OpenNLPLab/LASP.", "AI": {"tldr": "LASP is a new sequence parallelism method for linear attention models, improving communication efficiency and scalability up to 4096K sequences.", "motivation": "Existing SP methods are inefficient for linear attention due to their right-product-first feature, leading to sub-optimal communication and usability.", "method": "LASP uses a ring-style communication mechanism, kernel fusion, and state caching to optimize efficiency and compatibility with batch-level parallelism.", "result": "LASP scales sequences up to 4096K on 128 GPUs, 8\u00d7 longer than existing SP methods.", "conclusion": "LASP is a hardware-friendly, efficient SP approach for linear attention models, with broad applicability."}}
{"id": "2505.11444", "pdf": "https://arxiv.org/pdf/2505.11444", "abs": "https://arxiv.org/abs/2505.11444", "authors": ["Xinran Song", "Tianyu Chen", "Mingyuan Zhou"], "title": "A Generative Framework for Causal Estimation via Importance-Weighted Diffusion Distillation", "categories": ["cs.LG", "stat.AP", "stat.ME", "stat.ML"], "comment": null, "summary": "Estimating individualized treatment effects from observational data is a\ncentral challenge in causal inference, largely due to covariate imbalance and\nconfounding bias from non-randomized treatment assignment. While inverse\nprobability weighting (IPW) is a well-established solution to this problem, its\nintegration into modern deep learning frameworks remains limited. In this work,\nwe propose Importance-Weighted Diffusion Distillation (IWDD), a novel\ngenerative framework that combines the pretraining of diffusion models with\nimportance-weighted score distillation to enable accurate and fast causal\nestimation-including potential outcome prediction and treatment effect\nestimation. We demonstrate how IPW can be naturally incorporated into the\ndistillation of pretrained diffusion models, and further introduce a\nrandomization-based adjustment that eliminates the need to compute IPW\nexplicitly-thereby simplifying computation and, more importantly, provably\nreducing the variance of gradient estimates. Empirical results show that IWDD\nachieves state-of-the-art out-of-sample prediction performance, with the\nhighest win rates compared to other baselines, significantly improving causal\nestimation and supporting the development of individualized treatment\nstrategies. We will release our PyTorch code for reproducibility and future\nresearch.", "AI": {"tldr": "IWDD integrates IPW into diffusion models for accurate, fast causal estimation, outperforming baselines.", "motivation": "Address covariate imbalance and confounding bias in non-randomized treatment assignment for causal inference.", "method": "Combine pretrained diffusion models with importance-weighted score distillation, introducing a randomization-based adjustment to avoid explicit IPW computation.", "result": "Achieves state-of-the-art out-of-sample prediction performance with the highest win rates.", "conclusion": "IWDD improves causal estimation and supports individualized treatment strategies, with code released for reproducibility."}}
{"id": "2503.18931", "pdf": "https://arxiv.org/pdf/2503.18931", "abs": "https://arxiv.org/abs/2503.18931", "authors": ["Yitong Chen", "Lingchen Meng", "Wujian Peng", "Zuxuan Wu", "Yu-Gang Jiang"], "title": "CoMP: Continual Multimodal Pre-training for Vision Foundation Models", "categories": ["cs.CV"], "comment": "Code is available in https://github.com/SliMM-X/CoMP-MM", "summary": "Pre-trained Vision Foundation Models (VFMs) provide strong visual\nrepresentations for a wide range of applications. In this paper, we continually\npre-train prevailing VFMs in a multimodal manner such that they can\neffortlessly process visual inputs of varying sizes and produce visual\nrepresentations that are more aligned with language representations, regardless\nof their original pre-training process. To this end, we introduce CoMP, a\ncarefully designed multimodal pre-training pipeline. CoMP uses a Continual\nRotary Position Embedding to accommodate visual inputs with different\nresolutions, and an Alignment Loss between visual and textual features for\nbetter cross-modal alignment. After continual pre-training, leading VFMs like\nDINOv2, SigLIP and AIMv2 achieve remarkable improvements not only in multimodal\nunderstanding tasks but also in generic classification and segmentation tasks.\nRemarkably, CoMP-AIMv2 achieves scores of 64.9 on ChartQA with a 0.5B LLM,\nwhile maintaining an 87.3% accuracy on ImageNet-1K and a 51.8 mIoU on ADE20K\nunder frozen chunk evaluation.", "AI": {"tldr": "CoMP continually pre-trains Vision Foundation Models (VFMs) to align visual and language representations, improving performance in multimodal and generic tasks.", "motivation": "Align visual representations with language for better cross-modal understanding, regardless of the original pre-training process.", "method": "Introduces CoMP, a pipeline with Continual Rotary Position Embedding for varying resolutions and Alignment Loss for cross-modal alignment.", "result": "Improved performance in multimodal tasks (e.g., ChartQA), generic classification (ImageNet-1K), and segmentation (ADE20K).", "conclusion": "CoMP enhances VFMs' versatility and alignment with language, achieving strong results across diverse tasks."}}
{"id": "2410.08893", "pdf": "https://arxiv.org/pdf/2410.08893", "abs": "https://arxiv.org/abs/2410.08893", "authors": ["Wenlong Wang", "Ivana Dusparic", "Yucheng Shi", "Ke Zhang", "Vinny Cahill"], "title": "Drama: Mamba-Enabled Model-Based Reinforcement Learning Is Sample and Parameter Efficient", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Published as a conference paper at ICLR 2025", "summary": "Model-based reinforcement learning (RL) offers a solution to the data\ninefficiency that plagues most model-free RL algorithms. However, learning a\nrobust world model often requires complex and deep architectures, which are\ncomputationally expensive and challenging to train. Within the world model,\nsequence models play a critical role in accurate predictions, and various\narchitectures have been explored, each with its own challenges. Currently,\nrecurrent neural network (RNN)-based world models struggle with vanishing\ngradients and capturing long-term dependencies. Transformers, on the other\nhand, suffer from the quadratic memory and computational complexity of\nself-attention mechanisms, scaling as $O(n^2)$, where $n$ is the sequence\nlength.\n  To address these challenges, we propose a state space model (SSM)-based world\nmodel, Drama, specifically leveraging Mamba, that achieves $O(n)$ memory and\ncomputational complexity while effectively capturing long-term dependencies and\nenabling efficient training with longer sequences. We also introduce a novel\nsampling method to mitigate the suboptimality caused by an incorrect world\nmodel in the early training stages. Combining these techniques, Drama achieves\na normalised score on the Atari100k benchmark that is competitive with other\nstate-of-the-art (SOTA) model-based RL algorithms, using only a 7\nmillion-parameter world model. Drama is accessible and trainable on\noff-the-shelf hardware, such as a standard laptop. Our code is available at\nhttps://github.com/realwenlongwang/Drama.git.", "AI": {"tldr": "Drama, an SSM-based world model using Mamba, offers efficient training with O(n) complexity, addressing RNN and Transformer limitations in model-based RL.", "motivation": "To overcome the inefficiencies and challenges of RNNs and Transformers in world models for RL, such as vanishing gradients and high computational costs.", "method": "Proposes Drama, leveraging Mamba for O(n) complexity, and introduces a novel sampling method to handle early training suboptimality.", "result": "Achieves competitive SOTA performance on Atari100k with a 7M-parameter model, trainable on standard hardware.", "conclusion": "Drama provides an efficient, scalable solution for model-based RL, accessible on off-the-shelf hardware."}}
{"id": "2406.02844", "pdf": "https://arxiv.org/pdf/2406.02844", "abs": "https://arxiv.org/abs/2406.02844", "authors": ["Li Yang", "Anushya Subbiah", "Hardik Patel", "Judith Yue Li", "Yanwei Song", "Reza Mirghaderi", "Vikram Aggarwal", "Qifan Wang"], "title": "Item-Language Model for Conversational Recommendation", "categories": ["cs.IR", "cs.CL"], "comment": "15 pages, 3 figures", "summary": "Large-language Models (LLMs) have been extremely successful at tasks like\ncomplex dialogue understanding, reasoning and coding due to their emergent\nabilities. These emergent abilities have been extended with multi-modality to\ninclude image, audio, and video capabilities. Recommender systems, on the other\nhand, have been critical for information seeking and item discovery needs.\nRecently, there have been attempts to apply LLMs for recommendations. One\ndifficulty of current attempts is that the underlying LLM is usually not\ntrained on the recommender system data, which largely contains user interaction\nsignals and is often not publicly available. Another difficulty is user\ninteraction signals often have a different pattern from natural language text,\nand it is currently unclear if the LLM training setup can learn more\nnon-trivial knowledge from interaction signals compared with traditional\nrecommender system methods. Finally, it is difficult to train multiple LLMs for\ndifferent use-cases, and to retain the original language and reasoning\nabilities when learning from recommender system data. To address these three\nlimitations, we propose an Item-Language Model (ILM), which is composed of an\nitem encoder to produce text-aligned item representations that encode user\ninteraction signals, and a frozen LLM that can understand those item\nrepresentations with preserved pretrained knowledge. We conduct extensive\nexperiments which demonstrate both the importance of the language-alignment and\nof user interaction knowledge in the item encoder.", "AI": {"tldr": "The paper proposes an Item-Language Model (ILM) to address limitations of applying LLMs to recommender systems, focusing on aligning user interaction signals with language models while preserving their original capabilities.", "motivation": "Current LLMs struggle with recommender systems due to lack of training on user interaction data, differing patterns from natural language, and challenges in retaining original abilities when adapted.", "method": "ILM combines an item encoder for text-aligned item representations with a frozen LLM to understand these representations without losing pretrained knowledge.", "result": "Experiments show the importance of language-alignment and user interaction knowledge in the item encoder.", "conclusion": "ILM effectively bridges the gap between LLMs and recommender systems, leveraging interaction signals while maintaining language and reasoning abilities."}}
{"id": "2505.11461", "pdf": "https://arxiv.org/pdf/2505.11461", "abs": "https://arxiv.org/abs/2505.11461", "authors": ["Wesley A Suttle", "Vipul K Sharma", "Brian M Sadler"], "title": "Signal attenuation enables scalable decentralized multi-agent reinforcement learning over networks", "categories": ["cs.LG"], "comment": "7 pages, 1 figure", "summary": "Classic multi-agent reinforcement learning (MARL) methods require that agents\nenjoy global state observability, preventing development of decentralized\nalgorithms and limiting scalability. Recent work has shown that, under\nassumptions on decaying inter-agent influence, global observability can be\nreplaced by local neighborhood observability at each agent, enabling\ndecentralization and scalability. Real-world applications enjoying such decay\nproperties remain underexplored, however, despite the fact that signal power\ndecay, or signal attenuation, due to path loss is an intrinsic feature of many\nproblems in wireless communications and radar networks. In this paper, we show\nthat signal attenuation enables decentralization in MARL by considering the\nillustrative special case of performing power allocation for target detection\nin a radar network. To achieve this, we propose two new constrained multi-agent\nMarkov decision process formulations of this power allocation problem, derive\nlocal neighborhood approximations for global value function and gradient\nestimates and establish corresponding error bounds, and develop decentralized\nsaddle point policy gradient algorithms for solving the proposed problems. Our\napproach, though oriented towards the specific radar network problem we\nconsider, provides a useful model for future extensions to additional problems\nin wireless communications and radar networks.", "AI": {"tldr": "The paper addresses decentralization in MARL by leveraging signal attenuation in radar networks, proposing new MDP formulations and decentralized algorithms.", "motivation": "Classic MARL requires global state observability, limiting scalability. Signal attenuation in wireless/radar networks offers a natural way to enable decentralization.", "method": "Proposes two constrained multi-agent MDP formulations, derives local approximations for value functions/gradients, and develops decentralized saddle point policy gradient algorithms.", "result": "Establishes error bounds for local approximations and demonstrates feasibility of decentralization in MARL for radar power allocation.", "conclusion": "The approach provides a model for extending decentralization to other wireless/radar problems, leveraging signal attenuation."}}
{"id": "2503.24088", "pdf": "https://arxiv.org/pdf/2503.24088", "abs": "https://arxiv.org/abs/2503.24088", "authors": ["Lars M\u00f6llenbrok", "Behnood Rasti", "Beg\u00fcm Demir"], "title": "A Plasticity-Aware Method for Continual Self-Supervised Learning in Remote Sensing", "categories": ["cs.CV"], "comment": "We found the reported results of the compared method to be misleading", "summary": "Continual self-supervised learning (CSSL) methods have gained increasing\nattention in remote sensing (RS) due to their capability to learn new tasks\nsequentially from continuous streams of unlabeled data.\n  Existing CSSL methods, while learning new tasks, focus on preventing\ncatastrophic forgetting. To this end, most of them use regularization\nstrategies to retain knowledge of previous tasks. This reduces the model's\nability to adapt to the data of new tasks (i.e., learning plasticity), which\ncan degrade performance. To address this problem, in this paper, we propose a\nnovel CSSL method that aims to learn tasks sequentially, while achieving high\nlearning plasticity. To this end, the proposed method uses a knowledge\ndistillation strategy with an integrated decoupling mechanism. The decoupling\nis achieved by first dividing the feature dimensions into task-common and\ntask-specific parts. Then, the task-common features are forced to be correlated\nto ensure memory stability while the task-specific features are forced to be\nde-correlated facilitating the learning of new features. Experimental results\nshow the effectiveness of the proposed method compared to CaSSLe, which is a\nwidely used CSSL framework, with improvements of up to 1.12% in average\naccuracy and 2.33% in intransigence in a task-incremental scenario, and 1.24%\nin average accuracy and 2.01% in intransigence in a class-incremental scenario.", "AI": {"tldr": "A novel CSSL method for remote sensing improves learning plasticity by decoupling task-common and task-specific features, outperforming CaSSLe in accuracy and intransigence.", "motivation": "Existing CSSL methods prioritize preventing catastrophic forgetting, which reduces learning plasticity. This paper aims to enhance plasticity while retaining stability.", "method": "Proposes a knowledge distillation strategy with a decoupling mechanism, dividing features into task-common (correlated) and task-specific (de-correlated) parts.", "result": "Outperforms CaSSLe with improvements of up to 1.12-1.24% in average accuracy and 2.01-2.33% in intransigence across scenarios.", "conclusion": "The method effectively balances stability and plasticity, advancing CSSL for remote sensing applications."}}
{"id": "2410.09388", "pdf": "https://arxiv.org/pdf/2410.09388", "abs": "https://arxiv.org/abs/2410.09388", "authors": ["Peifan Jiang", "Xuben Wang", "Shuang Wang", "Fei Deng", "Kunpeng Wang", "Bin Wang", "Yuhan Yang"], "title": "3-D Magnetotelluric Deep Learning Inversion Guided by Pseudo-Physical Information", "categories": ["physics.geo-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Magnetotelluric deep learning (DL) inversion methods based on joint\ndata-driven and physics-driven have become a hot topic in recent years. When\nmapping observation data (or forward modeling data) to the resistivity model\nusing neural networks (NNs), incorporating the error (loss) term of the\ninversion resistivity's forward modeling response--which introduces physical\ninformation about electromagnetic field propagation--can significantly enhance\nthe inversion accuracy. To efficiently achieve data-physical dual-driven MT\ndeep learning inversion for large-scale 3-D MT data, we propose using DL\nforward modeling networks to compute this portion of the loss. This approach\nintroduces pseudo-physical information through the forward modeling of NN\nsimulation, further guiding the inversion network fitting. Specifically, we\nfirst pre-train the forward modeling networks as fixed forward modeling\noperators, then transfer and integrate them into the inversion network\ntraining, and finally optimize the inversion network by minimizing the\nmultinomial loss. Theoretical experimental results indicate that despite some\nsimulation errors in DL forward modeling, the introduced pseudo-physical\ninformation still enhances inversion accuracy and significantly mitigates the\noverfitting problem during training. Additionally, we propose a new input mode\nthat involves masking and adding noise to the data, simulating the field data\nenvironment of 3-D MT inversion, thereby making the method more flexible and\neffective for practical applications.", "AI": {"tldr": "A DL-based method for 3-D MT inversion combines data-driven and physics-driven approaches, using NN forward modeling to enhance accuracy and reduce overfitting.", "motivation": "Improving inversion accuracy and mitigating overfitting in large-scale 3-D MT data inversion by integrating physical information.", "method": "Pre-train forward modeling NNs, integrate them into inversion training, and optimize using multinomial loss. A new input mode with masking and noise simulates field data.", "result": "DL forward modeling introduces pseudo-physical information, improving inversion accuracy and reducing overfitting despite simulation errors.", "conclusion": "The proposed method enhances practical applicability and flexibility for 3-D MT inversion."}}
{"id": "2406.11624", "pdf": "https://arxiv.org/pdf/2406.11624", "abs": "https://arxiv.org/abs/2406.11624", "authors": ["Omer Sahin Tas", "Royden Wagner"], "title": "Words in Motion: Extracting Interpretable Control Vectors for Motion Transformers", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "ICLR 2025 final version. Our implementation is available at\n  https://github.com/kit-mrt/future-motion", "summary": "Transformer-based models generate hidden states that are difficult to\ninterpret. In this work, we analyze hidden states and modify them at inference,\nwith a focus on motion forecasting. We use linear probing to analyze whether\ninterpretable features are embedded in hidden states. Our experiments reveal\nhigh probing accuracy, indicating latent space regularities with functionally\nimportant directions. Building on this, we use the directions between hidden\nstates with opposing features to fit control vectors. At inference, we add our\ncontrol vectors to hidden states and evaluate their impact on predictions.\nRemarkably, such modifications preserve the feasibility of predictions. We\nfurther refine our control vectors using sparse autoencoders (SAEs). This leads\nto more linear changes in predictions when scaling control vectors. Our\napproach enables mechanistic interpretation as well as zero-shot generalization\nto unseen dataset characteristics with negligible computational overhead.", "AI": {"tldr": "The paper analyzes and modifies Transformer hidden states for interpretability in motion forecasting, using linear probing and control vectors to achieve feasible predictions and zero-shot generalization.", "motivation": "Transformer hidden states are hard to interpret, and the paper aims to uncover and manipulate interpretable features within them for motion forecasting.", "method": "Uses linear probing to identify interpretable features, fits control vectors between hidden states, and refines them with sparse autoencoders (SAEs).", "result": "High probing accuracy shows latent space regularities; control vectors preserve prediction feasibility and enable zero-shot generalization.", "conclusion": "The approach provides mechanistic interpretation and efficient zero-shot generalization with minimal computational cost."}}
{"id": "2505.11483", "pdf": "https://arxiv.org/pdf/2505.11483", "abs": "https://arxiv.org/abs/2505.11483", "authors": ["Zhaolan Huang", "Emmanuel Baccelli"], "title": "msf-CNN: Patch-based Multi-Stage Fusion with Convolutional Neural Networks for TinyML", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "AI spans from large language models to tiny models running on\nmicrocontrollers (MCUs). Extremely memory-efficient model architectures are\ndecisive to fit within an MCU's tiny memory budget e.g., 128kB of RAM. However,\ninference latency must remain small to fit real-time constraints. An approach\nto tackle this is patch-based fusion, which aims to optimize data flows across\nneural network layers. In this paper, we introduce msf-CNN, a novel technique\nthat efficiently finds optimal fusion settings for convolutional neural\nnetworks (CNNs) by walking through the fusion solution space represented as a\ndirected acyclic graph. Compared to previous work on CNN fusion for MCUs,\nmsf-CNN identifies a wider set of solutions. We published an implementation of\nmsf-CNN running on various microcontrollers (ARM Cortex-M, RISC-V, ESP32). We\nshow that msf-CNN can achieve inference using 50% less RAM compared to the\nprior art (MCUNetV2 and StreamNet). We thus demonstrate how msf-CNN offers\nadditional flexibility for system designers.", "AI": {"tldr": "msf-CNN is a novel technique optimizing fusion settings for CNNs on MCUs, reducing RAM usage by 50% compared to prior methods.", "motivation": "To address the challenge of fitting AI models within MCUs' tiny memory budgets while maintaining low inference latency.", "method": "Patch-based fusion represented as a directed acyclic graph to explore optimal fusion settings for CNNs.", "result": "Achieves 50% less RAM usage than MCUNetV2 and StreamNet, with broader solution space.", "conclusion": "msf-CNN provides flexibility and efficiency for AI deployment on resource-constrained MCUs."}}
{"id": "2503.24121", "pdf": "https://arxiv.org/pdf/2503.24121", "abs": "https://arxiv.org/abs/2503.24121", "authors": ["Valentin Boussot", "C\u00e9dric H\u00e9mon", "Jean-Claude Nunes", "Jason Dowling", "Simon Rouz\u00e9", "Caroline Lafond", "Ana\u00efs Barateau", "Jean-Louis Dillenseger"], "title": "IMPACT: A Generic Semantic Loss for Multimodal Medical Image Registration", "categories": ["cs.CV", "cs.LG"], "comment": "Submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). This is a preprint version and has not been\n  peer-reviewed", "summary": "Image registration is fundamental in medical imaging, enabling precise\nalignment of anatomical structures for diagnosis, treatment planning,\nimage-guided interventions, and longitudinal monitoring. This work introduces\nIMPACT (Image Metric with Pretrained model-Agnostic Comparison for\nTransmodality registration), a novel similarity metric designed for robust\nmultimodal image registration. Rather than relying on raw intensities,\nhandcrafted descriptors, or task-specific training, IMPACT defines a semantic\nsimilarity measure based on the comparison of deep features extracted from\nlarge-scale pretrained segmentation models. By leveraging representations from\nmodels such as TotalSegmentator, Segment Anything (SAM), and other foundation\nnetworks, IMPACT provides a task-agnostic, training-free solution that\ngeneralizes across imaging modalities. These features, originally trained for\nsegmentation, offer strong spatial correspondence and semantic alignment\ncapabilities, making them naturally suited for registration. The method\nintegrates seamlessly into both algorithmic (Elastix) and learning-based\n(VoxelMorph) frameworks, leveraging the strengths of each. IMPACT was evaluated\non five challenging 3D registration tasks involving thoracic CT/CBCT and pelvic\nMR/CT datasets. Quantitative metrics, including Target Registration Error and\nDice Similarity Coefficient, demonstrated consistent improvements in anatomical\nalignment over baseline methods. Qualitative analyses further highlighted the\nrobustness of the proposed metric in the presence of noise, artifacts, and\nmodality variations. With its versatility, efficiency, and strong performance\nacross diverse tasks, IMPACT offers a powerful solution for advancing\nmultimodal image registration in both clinical and research settings.", "AI": {"tldr": "IMPACT is a novel similarity metric for multimodal image registration, using deep features from pretrained segmentation models for robust alignment without task-specific training.", "motivation": "Image registration is crucial in medical imaging for precise alignment, but existing methods often rely on raw intensities or handcrafted features, limiting robustness across modalities.", "method": "IMPACT leverages deep features from pretrained segmentation models (e.g., TotalSegmentator, SAM) to define semantic similarity, integrating into algorithmic (Elastix) and learning-based (VoxelMorph) frameworks.", "result": "Evaluated on 3D registration tasks (CT/CBCT, MR/CT), IMPACT improved anatomical alignment (Target Registration Error, Dice Similarity Coefficient) and handled noise/artifacts better than baselines.", "conclusion": "IMPACT is a versatile, efficient, and powerful solution for multimodal image registration, suitable for clinical and research applications."}}
{"id": "2410.13002", "pdf": "https://arxiv.org/pdf/2410.13002", "abs": "https://arxiv.org/abs/2410.13002", "authors": ["Makram Chahine", "Alex Quach", "Alaa Maalouf", "Tsun-Hsuan Wang", "Daniela Rus"], "title": "Flex: End-to-End Text-Instructed Visual Navigation from Foundation Model Features", "categories": ["cs.RO", "cs.AI", "68T40, 68T05, 68T50", "I.2.6; I.2.9; I.2.10; I.4.8"], "comment": null, "summary": "End-to-end learning directly maps sensory inputs to actions, creating highly\nintegrated and efficient policies for complex robotics tasks. However, such\nmodels often struggle to generalize beyond their training scenarios, limiting\nadaptability to new environments, tasks, and concepts. In this work, we\ninvestigate the minimal data requirements and architectural adaptations\nnecessary to achieve robust closed-loop performance with vision-based control\npolicies under unseen text instructions and visual distribution shifts. Our\nfindings are synthesized in Flex (Fly lexically), a framework that uses\npre-trained Vision Language Models (VLMs) as frozen patch-wise feature\nextractors, generating spatially aware embeddings that integrate semantic and\nvisual information. We demonstrate the effectiveness of this approach on a\nquadrotor fly-to-target task, where agents trained via behavior cloning on a\nsmall simulated dataset successfully generalize to real-world scenes with\ndiverse novel goals and command formulations.", "AI": {"tldr": "Flex (Fly lexically) uses pre-trained Vision Language Models (VLMs) for robust closed-loop performance in vision-based control, enabling generalization to unseen tasks and environments.", "motivation": "End-to-end learning struggles with generalization beyond training scenarios, limiting adaptability to new environments and tasks.", "method": "Flex employs frozen VLMs as patch-wise feature extractors to generate spatially aware embeddings combining semantic and visual information.", "result": "Agents trained on a small simulated dataset generalize successfully to real-world scenes with novel goals and commands.", "conclusion": "Flex demonstrates the potential of VLMs for improving generalization in vision-based control policies."}}
{"id": "2410.14609", "pdf": "https://arxiv.org/pdf/2410.14609", "abs": "https://arxiv.org/abs/2410.14609", "authors": ["Simon Lupart", "Mohammad Aliannejadi", "Evangelos Kanoulas"], "title": "DiSCo: LLM Knowledge Distillation for Efficient Sparse Retrieval in Conversational Search", "categories": ["cs.IR", "cs.CL"], "comment": "11 pages, 6 figures. SIGIR '25 Proceedings of the 48th International\n  ACM SIGIR Conference on Research and Development in Information Retrieval\n  July 13--18, 2025 Padua, Italy", "summary": "Conversational Search (CS) involves retrieving relevant documents from a\ncorpus while considering the conversational context, integrating retrieval with\ncontext modeling. Recent advancements in Large Language Models (LLMs) have\nsignificantly enhanced CS by enabling query rewriting based on conversational\ncontext. However, employing LLMs during inference poses efficiency challenges.\nExisting solutions mitigate this issue by distilling embeddings derived from\nhuman-rewritten queries, focusing primarily on learning the context modeling\ntask. These methods, however, often separate the contrastive retrieval task\nfrom the distillation process, treating it as an independent loss term. To\novercome these limitations, we introduce DiSCo (Distillation of Sparse\nConversational retrieval), a novel approach that unifies retrieval and context\nmodeling through a relaxed distillation objective. Instead of relying\nexclusively on representation learning, our method distills similarity scores\nbetween conversations and documents, providing more freedom in the\nrepresentation space and better leveraging the contrastive nature of document\nrelevance. Extensive experiments on Learned Sparse Retrieval (LSR) across five\nCS datasets demonstrate that DiSCo achieves substantial improvements in both\nin-domain and out-of-domain retrieval tasks, achieving up to a six-point gain\nin recall for out-of-domain datasets over state-of-the-art methods.\nAdditionally, DiSCo employs a multi-teacher distillation strategy, using\nmultiple LLMs as teachers, further enhancing performance and surpassing the\nindividual teachers in in-domain settings. Furthermore, analysis of model\nsparsity reveals that DiSCo allows for more effective control over the sparsity\nof the trained models.", "AI": {"tldr": "DiSCo unifies retrieval and context modeling in conversational search via relaxed distillation, improving performance and sparsity control.", "motivation": "Existing methods separate retrieval and context modeling, limiting efficiency and performance. DiSCo aims to integrate these tasks for better results.", "method": "DiSCo distills similarity scores between conversations and documents, using multi-teacher LLMs for enhanced performance.", "result": "DiSCo achieves up to a six-point recall gain in out-of-domain tasks and outperforms individual LLM teachers in in-domain settings.", "conclusion": "DiSCo advances conversational search by unifying retrieval and context modeling, offering improved performance and sparsity control."}}
{"id": "2505.11491", "pdf": "https://arxiv.org/pdf/2505.11491", "abs": "https://arxiv.org/abs/2505.11491", "authors": ["Yuan-Zheng Lei", "Yaobang Gong", "Dianwei Chen", "Yao Cheng", "Xianfeng Terry Yang"], "title": "Potential failures of physics-informed machine learning in traffic flow modeling: theoretical and experimental analysis", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "This study critically examines the performance of physics-informed machine\nlearning (PIML) approaches for traffic flow modeling, defining the failure of a\nPIML model as the scenario where it underperforms both its purely data-driven\nand purely physics-based counterparts. We analyze the loss landscape by\nperturbing trained models along the principal eigenvectors of the Hessian\nmatrix and evaluating corresponding loss values. Our results suggest that\nphysics residuals in PIML do not inherently hinder optimization, contrary to a\ncommonly assumed failure cause. Instead, successful parameter updates require\nboth ML and physics gradients to form acute angles with the quasi-true gradient\nand lie within a conical region. Given inaccuracies in both the physics models\nand the training data, satisfying this condition is often difficult.\nExperiments reveal that physical residuals can degrade the performance of LWR-\nand ARZ-based PIML models, especially under highly physics-driven settings.\nMoreover, sparse sampling and the use of temporally averaged traffic data can\nproduce misleadingly small physics residuals that fail to capture actual\nphysical dynamics, contributing to model failure. We also identify the\nCourant-Friedrichs-Lewy (CFL) condition as a key indicator of dataset\nsuitability for PIML, where successful applications consistently adhere to this\ncriterion. Lastly, we observe that higher-order models like ARZ tend to have\nlarger error lower bounds than lower-order models like LWR, which is consistent\nwith the experimental findings of existing studies.", "AI": {"tldr": "PIML for traffic flow modeling fails when it underperforms data-driven and physics-based models. Physics residuals don't hinder optimization; success depends on gradient alignment. Dataset suitability is indicated by the CFL condition.", "motivation": "To understand why PIML models fail in traffic flow modeling and identify conditions for their success.", "method": "Analyze loss landscapes by perturbing trained models along Hessian eigenvectors. Evaluate performance under varying conditions like sparse sampling and CFL adherence.", "result": "Physics residuals don't inherently hinder optimization. Dataset suitability depends on CFL condition. Higher-order models (ARZ) have larger error bounds than lower-order ones (LWR).", "conclusion": "PIML success requires gradient alignment and suitable datasets (CFL condition). Physics models and data inaccuracies complicate optimization."}}
{"id": "2504.04893", "pdf": "https://arxiv.org/pdf/2504.04893", "abs": "https://arxiv.org/abs/2504.04893", "authors": ["Justus Westerhoff", "Erblina Purelku", "Jakob Hackstein", "Jonas Loos", "Leo Pinetzki", "Lorenz Hufe"], "title": "SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPR 2025 Workshop EVAL-FoMo-2", "summary": "Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper along with the code for evaluations at\nwww.bliss.berlin/research/scam.", "AI": {"tldr": "The paper introduces SCAM, a large dataset for studying typographic attacks on Vision-Language Models (VLMs), showing their impact and factors influencing vulnerability.", "motivation": "Existing datasets for typographic attacks are limited, hindering research on vulnerabilities in multimodal AI systems.", "method": "The authors create SCAM, a diverse dataset of 1,162 typographic attack images, and benchmark VLMs to analyze performance degradation and susceptibility factors.", "result": "Typographic attacks degrade VLM performance, with susceptibility influenced by training data and model architecture. Larger LLMs help mitigate vulnerability.", "conclusion": "The study provides insights and resources for robust multimodal AI, releasing SCAM and evaluation code publicly."}}
{"id": "2410.14731", "pdf": "https://arxiv.org/pdf/2410.14731", "abs": "https://arxiv.org/abs/2410.14731", "authors": ["Bokai Lin", "Zihao Zeng", "Zipeng Xiao", "Siqi Kou", "Tianqi Hou", "Xiaofeng Gao", "Hao Zhang", "Zhijie Deng"], "title": "MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "KV cache has become a de facto technique for the inference of large language\nmodels (LLMs), where tensors of shape (layer number, head number, sequence\nlength, feature dimension) are introduced to cache historical information for\nself-attention. As the size of the model and data grows, the KV cache can\nquickly become a bottleneck within the system in both storage and memory\ntransfer. To address this, prior studies usually focus on the first three axes\nof the cache tensors for compression. This paper supplements them, focusing on\nthe feature dimension axis, by utilizing low-rank projection matrices to\ntransform the cache features into spaces with reduced dimensions. We begin by\ninvestigating the canonical orthogonal projection method for data compression\nthrough principal component analysis (PCA). We observe the issue with PCA\nprojection where significant performance degradation is observed at low\ncompression rates. To bridge the gap, we propose to directly tune the\northogonal projection matrices with a distillation objective using an elaborate\nMatryoshka training strategy. After training, we adaptively search for the\noptimal compression rates for various layers and heads given varying\ncompression budgets. Compared to previous works, our method can easily embrace\npre-trained LLMs and hold a smooth tradeoff between performance and compression\nrate. We empirically witness the high data efficiency of our training procedure\nand find that our method can sustain over 90% performance with an average KV\ncache compression rate of 60% (and up to 75% in certain extreme scenarios) for\npopular LLMs like LLaMA2-7B-base and Mistral-7B-v0.3-base.", "AI": {"tldr": "The paper proposes a method to compress the KV cache in LLMs by focusing on the feature dimension axis using low-rank projection matrices, achieving high efficiency and performance retention.", "motivation": "The KV cache in LLMs becomes a bottleneck in storage and memory transfer as model and data sizes grow. Prior work focused on compressing the first three axes of cache tensors, leaving the feature dimension axis unexplored.", "method": "The method uses low-rank projection matrices to reduce feature dimensions, starting with PCA but addressing its limitations by tuning orthogonal matrices with a distillation objective and Matryoshka training. Adaptive compression rates are searched for optimal performance.", "result": "The method achieves up to 75% KV cache compression while sustaining over 90% performance for models like LLaMA2-7B-base and Mistral-7B-v0.3-base.", "conclusion": "The proposed approach efficiently compresses the KV cache with minimal performance loss, offering a smooth tradeoff between compression and accuracy for pre-trained LLMs."}}
{"id": "2411.02335", "pdf": "https://arxiv.org/pdf/2411.02335", "abs": "https://arxiv.org/abs/2411.02335", "authors": ["Yuqi Luo", "Chenyang Song", "Xu Han", "Yingfa Chen", "Chaojun Xiao", "Zhiyuan Liu", "Maosong Sun"], "title": "Sparsing Law: Towards Large Language Models with Greater Activation Sparsity", "categories": ["cs.LG", "cs.CL", "stat.ML", "I.2.7"], "comment": "23 pages, 13 figures, 6 tables", "summary": "Activation sparsity denotes the existence of substantial weakly-contributed\nelements within activation outputs that can be eliminated, benefiting many\nimportant applications concerned with large language models (LLMs). Although\npromoting greater activation sparsity within LLMs deserves deep studies,\nexisting works lack comprehensive and quantitative research on the correlation\nbetween activation sparsity and potentially influential factors. In this paper,\nwe present a comprehensive study on the quantitative scaling properties and\ninfluential factors of the activation sparsity within decoder-only\nTransformer-based LLMs. Specifically, we propose PPL-$p\\%$ sparsity, a precise\nand performance-aware activation sparsity metric that is applicable to any\nactivation function. Through extensive experiments, we find several important\nphenomena. Firstly, different activation functions exhibit comparable\nperformance but opposite training-time sparsity trends. The activation ratio\n(i.e., $1-\\mathrm{sparsity\\ ratio}$) evolves as a convergent increasing\npower-law and decreasing logspace power-law with the amount of training data\nfor SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate\nthat ReLU is more efficient as the activation function than SiLU and can\nleverage more training data to improve activation sparsity. Secondly, the\nactivation ratio linearly increases with the width-depth ratio below a certain\nbottleneck point, indicating the potential advantage of a deeper architecture\nat a fixed parameter scale. Finally, at similar width-depth ratios, we\nsurprisingly find that the limit value of activation sparsity varies weakly\nwith the parameter scale, i.e., the activation patterns within LLMs are\ninsensitive to the parameter scale. These empirical laws towards LLMs with\ngreater activation sparsity have important implications for making LLMs more\nefficient and interpretable.", "AI": {"tldr": "The paper studies activation sparsity in LLMs, proposing a new metric (PPL-$p\\%$ sparsity) and revealing trends in sparsity influenced by activation functions, training data, and model architecture.", "motivation": "To understand and quantify the correlation between activation sparsity and influential factors in LLMs, as existing research lacks comprehensive analysis.", "method": "Proposes PPL-$p\\%$ sparsity metric and conducts extensive experiments on decoder-only Transformer-based LLMs, analyzing activation functions, training data, and model architecture.", "result": "Key findings include opposite sparsity trends for SiLU and ReLU, power-law evolution of activation ratio with training data, and insensitivity of sparsity to parameter scale.", "conclusion": "The empirical laws discovered can guide the design of more efficient and interpretable LLMs by optimizing activation sparsity."}}
{"id": "2505.04514", "pdf": "https://arxiv.org/pdf/2505.04514", "abs": "https://arxiv.org/abs/2505.04514", "authors": ["Nana Liu", "Michele Minervini", "Dhrumil Patel", "Mark M. Wilde"], "title": "Quantum thermodynamics and semi-definite optimization", "categories": ["quant-ph", "cond-mat.stat-mech", "cs.DS", "cs.LG", "math.OC"], "comment": "v2: 16 pages of main text, 15 pages of appendices, 3 figures,\n  corrections introduced", "summary": "In quantum thermodynamics, a system is described by a Hamiltonian and a list\nof non-commuting charges representing conserved quantities like particle number\nor electric charge, and an important goal is to determine the system's minimum\nenergy in the presence of these conserved charges. In optimization theory, a\nsemi-definite program (SDP) involves a linear objective function optimized over\nthe cone of positive semi-definite operators intersected with an affine space.\nThese problems arise from differing motivations in the physics and optimization\ncommunities and are phrased using very different terminology, yet they are\nessentially identical mathematically. By adopting Jaynes' mindset motivated by\nquantum thermodynamics, we observe that minimizing free energy in the\naforementioned thermodynamics problem, instead of energy, leads to an elegant\nsolution in terms of a dual chemical potential maximization problem that is\nconcave in the chemical potential parameters. As such, one can employ standard\n(stochastic) gradient ascent methods to find the optimal values of these\nparameters, and these methods are guaranteed to converge quickly. At low\ntemperature, the minimum free energy provides an excellent approximation for\nthe minimum energy. We then show how this Jaynes-inspired gradient-ascent\napproach can be used in both first- and second-order classical and hybrid\nquantum-classical algorithms for minimizing energy, and equivalently, how it\ncan be used for solving SDPs, with guarantees on the runtimes of the\nalgorithms. The approach discussed here is well grounded in quantum\nthermodynamics and, as such, provides physical motivation underpinning why\nalgorithms published fifty years after Jaynes' seminal work, including the\nmatrix multiplicative weights update method, the matrix exponentiated gradient\nupdate method, and their quantum algorithmic generalizations, perform well at\nsolving SDPs.", "AI": {"tldr": "The paper connects quantum thermodynamics and optimization theory, showing that minimizing free energy in thermodynamics is mathematically equivalent to solving semi-definite programs (SDPs). It introduces a gradient-ascent method for solving these problems efficiently.", "motivation": "The motivation is to bridge the gap between quantum thermodynamics and optimization theory, demonstrating their mathematical equivalence and leveraging thermodynamic principles to solve optimization problems.", "method": "The method involves minimizing free energy in thermodynamics, which translates to a dual chemical potential maximization problem. This is solved using gradient ascent, with applications in classical and hybrid quantum-classical algorithms for SDPs.", "result": "The approach provides efficient algorithms for solving SDPs, with guaranteed convergence. It also approximates minimum energy well at low temperatures.", "conclusion": "The paper concludes that thermodynamic principles can inspire efficient optimization algorithms, linking historical and modern methods in both fields."}}
{"id": "2504.06148", "pdf": "https://arxiv.org/pdf/2504.06148", "abs": "https://arxiv.org/abs/2504.06148", "authors": ["Xiangxi Zheng", "Linjie Li", "Zhengyuan Yang", "Ping Yu", "Alex Jinpeng Wang", "Rui Yan", "Yuan Yao", "Lijuan Wang"], "title": "V-MAGE: A Game Evaluation Framework for Assessing Vision-Centric Capabilities in Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have\ndemonstrated impressive capabilities in visual-text processing. However,\nexisting static image-text benchmarks are insufficient for evaluating their\ndynamic perception and interactive reasoning abilities. We introduce\nVision-centric Multiple Abilities Game Evaluation(V-MAGE), a novel game-based\nevaluation framework designed to systematically assess MLLMs' visual reasoning\nin interactive, continuous-space environments. V-MAGE features five distinct\nvideo games comprising over 30 carefully constructed evaluation scenarios.\nThese scenarios are set in free-form, visually complex environments that\nrequire models to interpret dynamic game states and make decisions based solely\non visual input, thereby closely reflecting the conditions encountered by human\nplayers. To ensure robust and interpretable comparisons across models, V-MAGE\nemploys a dynamic Elo-based ranking system that accounts for varying difficulty\nlevels and task diversity. Benchmarking state-of-the-art MLLMs against human\nbaselines reveals that while leading models approach human-level performance in\nsimple tasks, their performance drops significantly in complex scenarios\nrequiring advanced reasoning and task orchestration. This persistent\nperformance gap highlights fundamental limitations in current MLLMs' ability to\nperform real-time, vision-grounded interactions. Through extensive analyses, we\ndemonstrate the utility of V-MAGE in uncovering these limitations and providing\nactionable insights for improving the visual and reasoning capabilities of\nMLLMs in dynamic, interactive settings. Code is publicly available at\nhttps://github.com/CSU-JPG/V-MAGE.", "AI": {"tldr": "V-MAGE is a game-based framework to evaluate Multimodal Large Language Models (MLLMs) in dynamic, interactive environments, revealing gaps in advanced reasoning and real-time interaction capabilities.", "motivation": "Existing benchmarks for MLLMs lack evaluation of dynamic perception and interactive reasoning, necessitating a more robust framework like V-MAGE.", "method": "V-MAGE uses five video games with 30+ scenarios, a dynamic Elo-based ranking system, and benchmarks MLLMs against human performance.", "result": "Leading MLLMs perform near-human in simple tasks but lag in complex scenarios, exposing limitations in real-time vision-grounded reasoning.", "conclusion": "V-MAGE effectively identifies MLLM limitations and offers insights for improving dynamic, interactive visual reasoning capabilities."}}
{"id": "2411.00401", "pdf": "https://arxiv.org/pdf/2411.00401", "abs": "https://arxiv.org/abs/2411.00401", "authors": ["Zhi Zhang", "Chris Chow", "Yasi Zhang", "Yanchao Sun", "Haochen Zhang", "Eric Hanchen Jiang", "Han Liu", "Furong Huang", "Yuchen Cui", "Oscar Hernan Madrid Padilla"], "title": "Statistical Guarantees for Lifelong Reinforcement Learning using PAC-Bayes Theory", "categories": ["cs.LG", "cs.AI", "68T05, 68Q32, 68T20", "I.2.6; I.2.8; G.3"], "comment": "9 pages, 4 figures, accepted at AISTATS 2025 (PMLR Vol 258), paper ID\n  9417", "summary": "Lifelong reinforcement learning (RL) has been developed as a paradigm for\nextending single-task RL to more realistic, dynamic settings. In lifelong RL,\nthe \"life\" of an RL agent is modeled as a stream of tasks drawn from a task\ndistribution. We propose EPIC (Empirical PAC-Bayes that Improves Continuously),\na novel algorithm designed for lifelong RL using PAC-Bayes theory. EPIC learns\na shared policy distribution, referred to as the world policy, which enables\nrapid adaptation to new tasks while retaining valuable knowledge from previous\nexperiences. Our theoretical analysis establishes a relationship between the\nalgorithm's generalization performance and the number of prior tasks preserved\nin memory. We also derive the sample complexity of EPIC in terms of RL regret.\nExtensive experiments on a variety of environments demonstrate that EPIC\nsignificantly outperforms existing methods in lifelong RL, offering both\ntheoretical guarantees and practical efficacy through the use of the world\npolicy.", "AI": {"tldr": "EPIC is a lifelong RL algorithm using PAC-Bayes theory to learn a shared policy distribution, enabling rapid adaptation to new tasks while retaining prior knowledge. It outperforms existing methods with theoretical guarantees.", "motivation": "To address the challenge of lifelong RL, where agents face dynamic task streams, by developing a method that retains knowledge and adapts efficiently.", "method": "EPIC employs PAC-Bayes theory to learn a shared policy distribution (world policy) for rapid adaptation and knowledge retention.", "result": "EPIC shows superior performance in lifelong RL, with theoretical guarantees on generalization and sample complexity.", "conclusion": "EPIC is a promising approach for lifelong RL, combining theoretical rigor with practical effectiveness."}}
{"id": "2501.02406", "pdf": "https://arxiv.org/pdf/2501.02406", "abs": "https://arxiv.org/abs/2501.02406", "authors": ["Tara Radvand", "Mojtaba Abdolmaleki", "Mohamed Mostagir", "Ambuj Tewari"], "title": "Zero-Shot Statistical Tests for LLM-Generated Text Detection using Finite Sample Concentration Inequalities", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Verifying the provenance of content is crucial to the function of many\norganizations, e.g., educational institutions, social media platforms, firms,\netc. This problem is becoming increasingly challenging as text generated by\nLarge Language Models (LLMs) becomes almost indistinguishable from\nhuman-generated content. In addition, many institutions utilize in-house LLMs\nand want to ensure that external, non-sanctioned LLMs do not produce content\nwithin the institution. In this paper, we answer the following question: Given\na piece of text, can we identify whether it was produced by a particular LLM or\nnot? We model LLM-generated text as a sequential stochastic process with\ncomplete dependence on history. We then design zero-shot statistical tests to\n(i) distinguish between text generated by two different known sets of LLMs $A$\n(non-sanctioned) and $B$ (in-house), and (ii) identify whether text was\ngenerated by a known LLM or generated by any unknown model, e.g., a human or\nsome other language generation process. We prove that the type I and type II\nerrors of our test decrease exponentially with the length of the text. For\nthat, we show that if $B$ generates the text, then except with an exponentially\nsmall probability in string length, the log-perplexity of the string under $A$\nconverges to the average cross-entropy of $B$ and $A$. We then present\nexperiments using LLMs with white-box access to support our theoretical results\nand empirically examine the robustness of our results to black-box settings and\nadversarial attacks. In the black-box setting, our method achieves an average\nTPR of 82.5\\% at a fixed FPR of 5\\%. Under adversarial perturbations, our\nminimum TPR is 48.6\\% at the same FPR threshold. Both results outperform all\nnon-commercial baselines. See\nhttps://github.com/TaraRadvand74/llm-text-detection for code, data, and an\nonline demo of the project.", "AI": {"tldr": "The paper proposes zero-shot statistical tests to identify whether text is generated by a specific LLM, distinguishing between sanctioned (in-house) and non-sanctioned models, and achieves high accuracy with theoretical guarantees.", "motivation": "The rise of LLM-generated text indistinguishable from human content necessitates reliable methods to verify text provenance, especially for institutions using in-house LLMs.", "method": "Models LLM-generated text as a sequential stochastic process and designs zero-shot tests to distinguish between known LLMs or unknown sources, with theoretical error bounds.", "result": "The method achieves 82.5% TPR at 5% FPR in black-box settings and remains robust under adversarial attacks (48.6% TPR).", "conclusion": "The proposed approach effectively identifies LLM-generated text, outperforming baselines, and is supported by theoretical and empirical evidence."}}
{"id": "2505.10573", "pdf": "https://arxiv.org/pdf/2505.10573", "abs": "https://arxiv.org/abs/2505.10573", "authors": ["Olawale Salaudeen", "Anka Reuel", "Ahmed Ahmed", "Suhana Bedi", "Zachary Robertson", "Sudharsan Sundar", "Ben Domingue", "Angelina Wang", "Sanmi Koyejo"], "title": "Measurement to Meaning: A Validity-Centered Framework for AI Evaluation", "categories": ["cs.CY", "cs.LG"], "comment": "Corresponding author: olawale@mit.edu", "summary": "While the capabilities and utility of AI systems have advanced, rigorous\nnorms for evaluating these systems have lagged. Grand claims, such as models\nachieving general reasoning capabilities, are supported with model performance\non narrow benchmarks, like performance on graduate-level exam questions, which\nprovide a limited and potentially misleading assessment. We provide a\nstructured approach for reasoning about the types of evaluative claims that can\nbe made given the available evidence. For instance, our framework helps\ndetermine whether performance on a mathematical benchmark is an indication of\nthe ability to solve problems on math tests or instead indicates a broader\nability to reason. Our framework is well-suited for the contemporary paradigm\nin machine learning, where various stakeholders provide measurements and\nevaluations that downstream users use to validate their claims and decisions.\nAt the same time, our framework also informs the construction of evaluations\ndesigned to speak to the validity of the relevant claims. By leveraging\npsychometrics' breakdown of validity, evaluations can prioritize the most\ncritical facets for a given claim, improving empirical utility and\ndecision-making efficacy. We illustrate our framework through detailed case\nstudies of vision and language model evaluations, highlighting how explicitly\nconsidering validity strengthens the connection between evaluation evidence and\nthe claims being made.", "AI": {"tldr": "The paper critiques current AI evaluation norms and proposes a structured framework to better align evidence with claims about AI capabilities.", "motivation": "Existing AI evaluations often make grand claims based on narrow benchmarks, which can be misleading. The paper aims to improve the rigor and validity of such evaluations.", "method": "The authors introduce a framework inspired by psychometrics to assess the validity of evaluative claims, using case studies of vision and language models.", "result": "The framework helps clarify the scope of claims (e.g., whether a benchmark indicates narrow or broad reasoning) and improves evaluation design.", "conclusion": "Explicitly considering validity strengthens the link between evaluation evidence and claims, enhancing empirical utility and decision-making."}}
{"id": "2504.06232", "pdf": "https://arxiv.org/pdf/2504.06232", "abs": "https://arxiv.org/abs/2504.06232", "authors": ["Jiazi Bu", "Pengyang Ling", "Yujie Zhou", "Pan Zhang", "Tong Wu", "Xiaoyi Dong", "Yuhang Zang", "Yuhang Cao", "Dahua Lin", "Jiaqi Wang"], "title": "HiFlow: Training-free High-Resolution Image Generation with Flow-Aligned Guidance", "categories": ["cs.CV"], "comment": "Project Page: https://bujiazi.github.io/hiflow.github.io/", "summary": "Text-to-image (T2I) diffusion/flow models have drawn considerable attention\nrecently due to their remarkable ability to deliver flexible visual creations.\nStill, high-resolution image synthesis presents formidable challenges due to\nthe scarcity and complexity of high-resolution content. Recent approaches have\ninvestigated training-free strategies to enable high-resolution image synthesis\nwith pre-trained models. However, these techniques often struggle with\ngenerating high-quality visuals and tend to exhibit artifacts or low-fidelity\ndetails, as they typically rely solely on the endpoint of the low-resolution\nsampling trajectory while neglecting intermediate states that are critical for\npreserving structure and synthesizing finer detail. To this end, we present\nHiFlow, a training-free and model-agnostic framework to unlock the resolution\npotential of pre-trained flow models. Specifically, HiFlow establishes a\nvirtual reference flow within the high-resolution space that effectively\ncaptures the characteristics of low-resolution flow information, offering\nguidance for high-resolution generation through three key aspects:\ninitialization alignment for low-frequency consistency, direction alignment for\nstructure preservation, and acceleration alignment for detail fidelity. By\nleveraging such flow-aligned guidance, HiFlow substantially elevates the\nquality of high-resolution image synthesis of T2I models and demonstrates\nversatility across their personalized variants. Extensive experiments validate\nHiFlow's capability in achieving superior high-resolution image quality over\nstate-of-the-art methods.", "AI": {"tldr": "HiFlow is a training-free framework for high-resolution image synthesis using pre-trained flow models, addressing challenges like artifacts and low fidelity by leveraging intermediate states and flow-aligned guidance.", "motivation": "High-resolution image synthesis is challenging due to data scarcity and complexity, with existing training-free methods often producing low-quality results.", "method": "HiFlow introduces a virtual reference flow in high-resolution space, aligning initialization, direction, and acceleration to guide synthesis.", "result": "HiFlow significantly improves high-resolution image quality and works across personalized T2I model variants.", "conclusion": "HiFlow outperforms state-of-the-art methods in high-resolution image synthesis, validated by extensive experiments."}}
{"id": "2411.06581", "pdf": "https://arxiv.org/pdf/2411.06581", "abs": "https://arxiv.org/abs/2411.06581", "authors": ["Yang Su", "Na Yan", "Yansha Deng", "Mischa Dohler", "Robert Schober"], "title": "HAFLQ: Heterogeneous Adaptive Federated LoRA Fine-tuned LLM with Quantization", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "This is an extended journal version based on our previous conference\n  paper accepted at the 2025 IEEE International Conference on Communications\n  (ICC), with additional sections and new results", "summary": "Federated fine-tuning of pre-trained Large Language Models (LLMs) enables\ntask-specific adaptation across diverse datasets while preserving privacy.\nHowever, challenges such as high computational and memory demands,\nheterogeneous client resources, bandwidth constraints, and ineffective global\naggregation hinder its efficiency. To address these issues, we propose HAFLQ\n(Heterogeneous Adaptive Federated Low-Rank Adaptation Fine-tuned LLM with\nQuantization), a novel framework for efficient and scalable federated\nfine-tuning of LLMs in heterogeneous environments. To reduce memory and\ncomputation demands, we propose a salience-driven adaptive LLM quantization\nframework that evaluates the importance of transformer blocks using a salience\nmetric and applies adaptive block-wise quantization accordingly. To handle\nheterogeneous computational capabilities, we propose an importance-based\nparameter truncation and freezing scheme. To address communication bottlenecks,\nwe propose an importance-aware bandwidth-adaptive quantization method, which\ndynamically adjusts parameter precision based on importance and bandwidth\nconstraints. To improve global model aggregation, we propose an adaptive rank-1\nmatrix-level aggregation strategy, which prevents information dilution and\naccelerates convergence by aggregating only updated rank-1 matrices from\nclients. Experimental results on the text classification task demonstrate that\nHAFLQ reduces memory usage by 31%, lowers communication cost by 49%, improves\naccuracy by 50%, and achieves faster convergence compared to the baseline\nmethod.", "AI": {"tldr": "HAFLQ is a framework for efficient federated fine-tuning of LLMs, addressing challenges like high resource demands, heterogeneity, and communication bottlenecks through adaptive quantization, parameter freezing, and dynamic aggregation.", "motivation": "Federated fine-tuning of LLMs faces inefficiencies due to computational demands, client heterogeneity, bandwidth constraints, and ineffective aggregation.", "method": "HAFLQ uses salience-driven adaptive quantization, parameter truncation, bandwidth-adaptive quantization, and rank-1 matrix-level aggregation.", "result": "HAFLQ reduces memory by 31%, communication cost by 49%, improves accuracy by 50%, and speeds up convergence.", "conclusion": "HAFLQ effectively addresses federated fine-tuning challenges, offering a scalable and efficient solution for heterogeneous environments."}}
{"id": "2502.01384", "pdf": "https://arxiv.org/pdf/2502.01384", "abs": "https://arxiv.org/abs/2502.01384", "authors": ["Oussama Zekri", "Nicolas Boull\u00e9"], "title": "Fine-Tuning Discrete Diffusion Models with Policy Gradient Methods", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "comment": "30 pages, 8 figures, 8 tables", "summary": "Discrete diffusion models have recently gained significant attention due to\ntheir ability to process complex discrete structures for language modeling.\nHowever, fine-tuning these models with policy gradient methods, as is commonly\ndone in Reinforcement Learning from Human Feedback (RLHF), remains a\nchallenging task. We propose an efficient, broadly applicable, and\ntheoretically justified policy gradient algorithm, called Score Entropy Policy\nOptimization (SEPO), for fine-tuning discrete diffusion models over\nnon-differentiable rewards. Our numerical experiments across several discrete\ngenerative tasks demonstrate the scalability and efficiency of our method. Our\ncode is available at https://github.com/ozekri/SEPO.", "AI": {"tldr": "Proposes SEPO, a policy gradient algorithm for fine-tuning discrete diffusion models with non-differentiable rewards, showing scalability and efficiency in experiments.", "motivation": "Fine-tuning discrete diffusion models with policy gradient methods is challenging, especially for non-differentiable rewards.", "method": "Introduces Score Entropy Policy Optimization (SEPO), a theoretically justified algorithm.", "result": "Demonstrates scalability and efficiency in various discrete generative tasks.", "conclusion": "SEPO is an effective solution for fine-tuning discrete diffusion models with non-differentiable rewards."}}
{"id": "2505.10605", "pdf": "https://arxiv.org/pdf/2505.10605", "abs": "https://arxiv.org/abs/2505.10605", "authors": ["Frederik K\u00f6hne", "Anton Schiela"], "title": "An Exponential Averaging Process with Strong Convergence Properties", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH", "60F15 (Primary) 60G10, 60J20, 68T05, 90C15 (Secondary)"], "comment": null, "summary": "Averaging, or smoothing, is a fundamental approach to obtain stable,\nde-noised estimates from noisy observations. In certain scenarios, observations\nmade along trajectories of random dynamical systems are of particular interest.\nOne popular smoothing technique for such a scenario is exponential moving\naveraging (EMA), which assigns observations a weight that decreases\nexponentially in their age, thus giving younger observations a larger weight.\nHowever, EMA fails to enjoy strong stochastic convergence properties, which\nstems from the fact that the weight assigned to the youngest observation is\nconstant over time, preventing the noise in the averaged quantity from\ndecreasing to zero. In this work, we consider an adaptation to EMA, which we\ncall $p$-EMA, where the weights assigned to the last observations decrease to\nzero at a subharmonic rate. We provide stochastic convergence guarantees for\nthis kind of averaging under mild assumptions on the autocorrelations of the\nunderlying random dynamical system. We further discuss the implications of our\nresults for a recently introduced adaptive step size control for Stochastic\nGradient Descent (SGD), which uses $p$-EMA for averaging noisy observations.", "AI": {"tldr": "The paper introduces $p$-EMA, a modified version of exponential moving averaging (EMA), to address EMA's lack of strong stochastic convergence by reducing weights of recent observations subharmonically. It provides convergence guarantees and discusses applications in adaptive SGD step size control.", "motivation": "EMA lacks strong stochastic convergence due to constant weights for recent observations, limiting noise reduction. The paper aims to improve this by introducing $p$-EMA.", "method": "The authors propose $p$-EMA, where weights for recent observations decrease subharmonically, ensuring noise reduction. Convergence guarantees are provided under mild autocorrelation assumptions.", "result": "$p$-EMA achieves stochastic convergence, addressing EMA's limitations. The method is validated theoretically and applied to adaptive SGD step size control.", "conclusion": "$p$-EMA offers a robust alternative to EMA with proven convergence properties, enhancing applications like adaptive SGD."}}
{"id": "2504.10400", "pdf": "https://arxiv.org/pdf/2504.10400", "abs": "https://arxiv.org/abs/2504.10400", "authors": ["Pietro Bonazzi", "Christian Vogt", "Michael Jost", "Lyes Khacef", "Federico Paredes-Vall\u00e9s", "Michele Magno"], "title": "Towards Low-Latency Event-based Obstacle Avoidance on a FPGA-Drone", "categories": ["cs.CV"], "comment": null, "summary": "This work quantitatively evaluates the performance of event-based vision\nsystems (EVS) against conventional RGB-based models for action prediction in\ncollision avoidance on an FPGA accelerator. Our experiments demonstrate that\nthe EVS model achieves a significantly higher effective frame rate (1 kHz) and\nlower temporal (-20 ms) and spatial prediction errors (-20 mm) compared to the\nRGB-based model, particularly when tested on out-of-distribution data. The EVS\nmodel also exhibits superior robustness in selecting optimal evasion maneuvers.\nIn particular, in distinguishing between movement and stationary states, it\nachieves a 59 percentage point advantage in precision (78% vs. 19%) and a\nsubstantially higher F1 score (0.73 vs. 0.06), highlighting the susceptibility\nof the RGB model to overfitting. Further analysis in different combinations of\nspatial classes confirms the consistent performance of the EVS model in both\ntest data sets. Finally, we evaluated the system end-to-end and achieved a\nlatency of approximately 2.14 ms, with event aggregation (1 ms) and inference\non the processing unit (0.94 ms) accounting for the largest components. These\nresults underscore the advantages of event-based vision for real-time collision\navoidance and demonstrate its potential for deployment in resource-constrained\nenvironments.", "AI": {"tldr": "Event-based vision systems (EVS) outperform RGB-based models in collision avoidance, achieving higher frame rates, lower errors, and better robustness, especially in out-of-distribution scenarios.", "motivation": "To compare the performance of event-based vision systems (EVS) and RGB-based models for real-time collision avoidance, focusing on accuracy, robustness, and latency.", "method": "Quantitative evaluation of EVS and RGB models on an FPGA accelerator, measuring frame rates, prediction errors, and evasion maneuver performance.", "result": "EVS achieves 1 kHz frame rate, lower errors (-20 ms, -20 mm), and superior robustness (78% precision vs. 19% for RGB). Latency is 2.14 ms.", "conclusion": "EVS is highly effective for real-time collision avoidance, offering advantages in speed, accuracy, and robustness, suitable for resource-constrained environments."}}
{"id": "2411.08881", "pdf": "https://arxiv.org/pdf/2411.08881", "abs": "https://arxiv.org/abs/2411.08881", "authors": ["Jos\u00e9 Antonio Siqueira de Cerqueira", "Mamia Agbese", "Rebekah Rousi", "Nannan Xi", "Juho Hamari", "Pekka Abrahamsson"], "title": "Can We Trust AI Agents? A Case Study of an LLM-Based Multi-Agent System for Ethical AI", "categories": ["cs.CY", "cs.AI", "I.2.0; K.6.3"], "comment": null, "summary": "AI-based systems, including Large Language Models (LLM), impact millions by\nsupporting diverse tasks but face issues like misinformation, bias, and misuse.\nAI ethics is crucial as new technologies and concerns emerge, but objective,\npractical guidance remains debated. This study examines the use of LLMs for AI\nethics in practice, assessing how LLM trustworthiness-enhancing techniques\naffect software development in this context. Using the Design Science Research\n(DSR) method, we identify techniques for LLM trustworthiness: multi-agents,\ndistinct roles, structured communication, and multiple rounds of debate. We\ndesign a multi-agent prototype LLM-MAS, where agents engage in structured\ndiscussions on real-world AI ethics issues from the AI Incident Database. We\nevaluate the prototype across three case scenarios using thematic analysis,\nhierarchical clustering, comparative (baseline) studies, and running source\ncode. The system generates approximately 2,000 lines of code per case, compared\nto only 80 lines in baseline trials. Discussions reveal terms like bias\ndetection, transparency, accountability, user consent, GDPR compliance,\nfairness evaluation, and EU AI Act compliance, showing this prototype ability\nto generate extensive source code and documentation addressing often overlooked\nAI ethics issues. However, practical challenges in source code integration and\ndependency management may limit its use by practitioners.", "AI": {"tldr": "The study explores using LLMs for AI ethics, proposing a multi-agent system (LLM-MAS) to enhance trustworthiness. It generates extensive code but faces practical integration challenges.", "motivation": "Addressing AI ethics issues like misinformation and bias, the study aims to provide practical guidance using LLMs.", "method": "Uses Design Science Research (DSR) to develop LLM-MAS, involving multi-agents, structured communication, and debate. Evaluated via thematic analysis, clustering, and comparative studies.", "result": "Generates ~2,000 lines of code per case, addressing ethics topics like bias detection and GDPR compliance, but faces integration challenges.", "conclusion": "LLM-MAS shows promise for AI ethics but requires further refinement for practical use."}}
{"id": "2502.02315", "pdf": "https://arxiv.org/pdf/2502.02315", "abs": "https://arxiv.org/abs/2502.02315", "authors": ["Wangtao Sun", "Haotian Xu", "Huanxuan Liao", "Xuanqing Yu", "Zhongtao Jiang", "Shizhu He", "Jun Zhao", "Kang Liu"], "title": "Shuttle Between the Instructions and the Parameters of Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The interaction with Large Language Models (LLMs) through instructions has\nbeen extensively investigated in the research community. While instructions\nhave been widely used as the guidelines for task solving, this paper further\nnotices that both instructions and parameters are the compression of task data.\nTherefore, they could be strongly correlated and can be learned to predict one\nfrom the other. This paper proposes a novel neural network framework, SHIP\n(\\textbf{Sh}uttle between the \\textbf{I}nstructions and the\n\\textbf{P}arameters), to model and learn the mutual mappings between the\ninstructions and the parameters of LLMs. We verify that SHIP can effectively\nmap one of the instructions/parameters to the other by evaluating it on the\ntasks of instruction deduction and induction. The results show that SHIP\nperforms better than existing baseline methods in terms of deductive\ncapabilities while significantly surpassing them in inductive capabilities.\nMoreover, SHIP can effectively combine the two mapping processes to perform\nexcellent inductive reasoning. The code and data for this paper are released at\nhttps://anonymous.4open.science/r/Shuttle-Between-Instructions-Parameters/.", "AI": {"tldr": "SHIP is a neural framework that learns mutual mappings between LLM instructions and parameters, outperforming baselines in deduction and induction tasks.", "motivation": "To explore the correlation between LLM instructions and parameters as compressed task data, enabling mutual prediction.", "method": "Proposes SHIP, a neural network framework to model and learn mappings between instructions and parameters.", "result": "SHIP excels in instruction deduction and induction, surpassing baselines, and combines mappings for inductive reasoning.", "conclusion": "SHIP demonstrates effective mutual mapping between instructions and parameters, enhancing LLM task-solving capabilities."}}
{"id": "2505.10628", "pdf": "https://arxiv.org/pdf/2505.10628", "abs": "https://arxiv.org/abs/2505.10628", "authors": ["Jonathan Garc\u00eda", "Philipp Petersen"], "title": "Minimax learning rates for estimating binary classifiers under margin conditions", "categories": ["stat.ML", "cs.LG", "math.PR", "68T05, 62C20, 41A25, 41A46"], "comment": null, "summary": "We study classification problems using binary estimators where the decision\nboundary is described by horizon functions and where the data distribution\nsatisfies a geometric margin condition. We establish upper and lower bounds for\nthe minimax learning rate over broad function classes with bounded Kolmogorov\nentropy in Lebesgue norms. A key novelty of our work is the derivation of lower\nbounds on the worst-case learning rates under a geometric margin condition -- a\nsetting that is almost universally satisfied in practice but remains\ntheoretically challenging. Moreover, our results deal with the noiseless\nsetting, where lower bounds are particularly hard to establish. We apply our\ngeneral results to classification problems with decision boundaries belonging\nto several function classes: for Barron-regular functions, and for\nH\\\"older-continuous functions with strong margins, we identify optimal rates\nclose to the fast learning rates of $\\mathcal{O}(n^{-1})$ for $n \\in\n\\mathbb{N}$ samples. Also for merely convex decision boundaries, in a strong\nmargin case optimal rates near $\\mathcal{O}(n^{-1/2})$ can be achieved.", "AI": {"tldr": "The paper establishes upper and lower bounds for minimax learning rates in binary classification under a geometric margin condition, focusing on noiseless settings and various function classes.", "motivation": "To address the theoretical challenges of deriving lower bounds on learning rates under practical geometric margin conditions, especially in noiseless settings.", "method": "The study uses binary estimators with horizon functions for decision boundaries and analyzes data distributions satisfying a geometric margin condition. Bounds are derived for function classes with bounded Kolmogorov entropy in Lebesgue norms.", "result": "Optimal learning rates close to O(n\u207b\u00b9) are identified for Barron-regular and H\u00f6lder-continuous functions with strong margins, and near O(n\u207b\u00b9/\u00b2) for convex decision boundaries in strong margin cases.", "conclusion": "The work provides rigorous bounds for learning rates in practical settings, advancing theoretical understanding of classification problems under geometric margin conditions."}}
{"id": "2504.13580", "pdf": "https://arxiv.org/pdf/2504.13580", "abs": "https://arxiv.org/abs/2504.13580", "authors": ["Yuchen Rao", "Stefan Ainetter", "Sinisa Stekovic", "Vincent Lepetit", "Friedrich Fraundorfer"], "title": "Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding", "categories": ["cs.CV"], "comment": "Project page: https://stefan-ainetter.github.io/SCANnotatepp; CVPR'25\n  Workshop", "summary": "High-level 3D scene understanding is essential in many applications. However,\nthe challenges of generating accurate 3D annotations make development of deep\nlearning models difficult. We turn to recent advancements in automatic\nretrieval of synthetic CAD models, and show that data generated by such methods\ncan be used as high-quality ground truth for training supervised deep learning\nmodels. More exactly, we employ a pipeline akin to the one previously used to\nautomatically annotate objects in ScanNet scenes with their 9D poses and CAD\nmodels. This time, we apply it to the recent ScanNet++ v1 dataset, which\npreviously lacked such annotations. Our findings demonstrate that it is not\nonly possible to train deep learning models on these automatically-obtained\nannotations but that the resulting models outperform those trained on manually\nannotated data. We validate this on two distinct tasks: point cloud completion\nand single-view CAD model retrieval and alignment. Our results underscore the\npotential of automatic 3D annotations to enhance model performance while\nsignificantly reducing annotation costs. To support future research in 3D scene\nunderstanding, we will release our annotations, which we call SCANnotate++,\nalong with our trained models.", "AI": {"tldr": "The paper proposes using automatically retrieved synthetic CAD models as high-quality ground truth for training supervised deep learning models in 3D scene understanding, outperforming manual annotations.", "motivation": "High-level 3D scene understanding is crucial but hindered by the difficulty of generating accurate 3D annotations.", "method": "A pipeline for automatic annotation of ScanNet++ v1 dataset with 9D poses and CAD models, similar to prior work on ScanNet.", "result": "Models trained on automatic annotations outperform those using manual annotations in tasks like point cloud completion and CAD model retrieval/alignment.", "conclusion": "Automatic 3D annotations enhance performance and reduce costs, with released annotations (SCANnotate++) and models to aid future research."}}
{"id": "2411.15191", "pdf": "https://arxiv.org/pdf/2411.15191", "abs": "https://arxiv.org/abs/2411.15191", "authors": ["Dan Hudson", "Jurgen van den Hoogen", "Martin Atzmueller"], "title": "Finding One's Bearings in the Hyperparameter Landscape of a Wide-Kernel Convolutional Fault Detector", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": "24 pages, 10 figures, 8 tables", "summary": "State-of-the-art algorithms are reported to be almost perfect at\ndistinguishing the vibrations arising from healthy and damaged machine\nbearings, according to benchmark datasets at least. However, what about their\napplication to new data? In this paper, we confirm that neural networks for\nbearing fault detection can be crippled by incorrect hyperparameterisation, and\nalso that the correct hyperparameter settings can change when transitioning to\nnew data. The paper combines multiple methods to explain the behaviour of the\nhyperparameters of a wide-kernel convolutional neural network and how to set\nthem. Since guidance already exists for generic hyperparameters like minibatch\nsize, we focus on how to set architecture-specific hyperparameters such as the\nwidth of the convolutional kernels, a topic which might otherwise be obscure.\nWe reflect different data properties by fusing information from seven different\nbenchmark datasets, and our results show that the kernel size in the first\nlayer in particular is sensitive to changes in the data. Looking deeper, we use\nmanipulated copies of one dataset in an attempt to spot why the kernel size\nsometimes needs to change. The relevance of sampling rate is studied by using\ndifferent levels of resampling, and spectral content is studied by increasingly\nfiltering out high frequencies. We find that, contrary to speculation in\nearlier work, high-frequency noise is not the main reason why a wide kernel is\npreferable to a narrow kernel. Finally, we conclude by stating clear guidance\non how to set the hyperparameters of our neural network architecture to work\neffectively on new data.", "AI": {"tldr": "Neural networks for bearing fault detection can fail due to incorrect hyperparameter settings, which may change with new data. The paper provides guidance on setting architecture-specific hyperparameters like kernel width, showing sensitivity to data properties.", "motivation": "To address the gap in understanding how hyperparameters, especially architecture-specific ones like kernel width, affect neural network performance on new data for bearing fault detection.", "method": "Combines multiple methods to analyze hyperparameter behavior, focusing on kernel width in a wide-kernel CNN. Uses seven benchmark datasets and manipulated copies to study sensitivity to data properties like sampling rate and spectral content.", "result": "Found that kernel size in the first layer is sensitive to data changes, and high-frequency noise isn't the main reason for preferring wide kernels. Provides clear hyperparameter guidance.", "conclusion": "Clear guidance is provided for setting hyperparameters in the neural network architecture to ensure effective performance on new data, debunking earlier assumptions about high-frequency noise."}}
{"id": "2502.19676", "pdf": "https://arxiv.org/pdf/2502.19676", "abs": "https://arxiv.org/abs/2502.19676", "authors": ["Zhangdie Yuan", "Zifeng Ding", "Andreas Vlachos"], "title": "FOReCAst: The Future Outcome Reasoning and Confidence Assessment Benchmark", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Forecasting is an important task in many domains, such as technology and\neconomics. However existing forecasting benchmarks largely lack comprehensive\nconfidence assessment, focus on limited question types, and often consist of\nartificial questions that do not align with real-world human forecasting needs.\nTo address these gaps, we introduce FOReCAst (Future Outcome Reasoning and\nConfidence Assessment), a benchmark that evaluates models' ability to make\npredictions and their confidence in them. FOReCAst spans diverse forecasting\nscenarios involving Boolean questions, timeframe prediction, and quantity\nestimation, enabling a comprehensive evaluation of both prediction accuracy and\nconfidence calibration for real-world applications.", "AI": {"tldr": "FOReCAst is a new benchmark for evaluating forecasting models' prediction accuracy and confidence calibration across diverse real-world scenarios.", "motivation": "Existing forecasting benchmarks lack comprehensive confidence assessment and real-world alignment, limiting their practical utility.", "method": "Introduces FOReCAst, a benchmark with diverse forecasting scenarios (Boolean questions, timeframe prediction, quantity estimation) to assess prediction and confidence.", "result": "FOReCAst enables comprehensive evaluation of forecasting models for real-world applications.", "conclusion": "FOReCAst addresses gaps in current benchmarks, providing a more practical tool for forecasting evaluation."}}
{"id": "2505.10678", "pdf": "https://arxiv.org/pdf/2505.10678", "abs": "https://arxiv.org/abs/2505.10678", "authors": ["Rebecca G. Hart", "Omkar Sudhir Patil", "Zachary I. Bell", "Warren E. Dixon"], "title": "System Identification and Control Using Lyapunov-Based Deep Neural Networks without Persistent Excitation: A Concurrent Learning Approach", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Deep Neural Networks (DNNs) are increasingly used in control applications due\nto their powerful function approximation capabilities. However, many existing\nformulations focus primarily on tracking error convergence, often neglecting\nthe challenge of identifying the system dynamics using the DNN. This paper\npresents the first result on simultaneous trajectory tracking and online system\nidentification using a DNN-based controller, without requiring persistent\nexcitation. Two new concurrent learning adaptation laws are constructed for the\nweights of all the layers of the DNN, achieving convergence of the DNN's\nparameter estimates to a neighborhood of their ideal values, provided the DNN's\nJacobian satisfies a finite-time excitation condition. A Lyapunov-based\nstability analysis is conducted to ensure convergence of the tracking error,\nweight estimation errors, and observer errors to a neighborhood of the origin.\nSimulations performed on a range of systems and trajectories, with the same\ninitial and operating conditions, demonstrated 40.5% to 73.6% improvement in\nfunction approximation performance compared to the baseline, while maintaining\na similar tracking error and control effort. Simulations evaluating function\napproximation capabilities on data points outside of the trajectory resulted in\n58.88% and 74.75% improvement in function approximation compared to the\nbaseline.", "AI": {"tldr": "The paper introduces a DNN-based controller for simultaneous trajectory tracking and online system identification without persistent excitation, showing significant improvements in function approximation.", "motivation": "Existing DNN-based control formulations often neglect system dynamics identification, focusing only on tracking error convergence. This work addresses this gap.", "method": "Two concurrent learning adaptation laws for DNN weights are developed, with Lyapunov-based stability analysis ensuring convergence of tracking and estimation errors.", "result": "Simulations showed 40.5% to 73.6% improvement in function approximation and 58.88% to 74.75% improvement for out-of-trajectory data, with comparable tracking error and control effort.", "conclusion": "The proposed method successfully integrates trajectory tracking and system identification, demonstrating superior function approximation without compromising control performance."}}
{"id": "2505.00254", "pdf": "https://arxiv.org/pdf/2505.00254", "abs": "https://arxiv.org/abs/2505.00254", "authors": ["Yuxuan Yan", "Shiqi Jiang", "Ting Cao", "Yifan Yang", "Qianqian Yang", "Yuanchao Shu", "Yuqing Yang", "Lili Qiu"], "title": "Empowering Agentic Video Analytics Systems with Video Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, AVAS, add latency breakdown", "summary": "AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVAS, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVAS incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVAS achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVAS-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVAS-100, AVAS achieves top-tier performance with an\naccuracy of 75.8%.", "AI": {"tldr": "AVAS is a VLM-powered system for open-ended video analytics, addressing limitations of existing systems with innovations like Event Knowledge Graphs and agentic retrieval-generation, achieving top performance on benchmarks.", "motivation": "Existing AI-driven video analytics systems lack adaptability for open-ended scenarios and struggle with ultra-long videos, prompting the development of AVAS.", "method": "AVAS uses Event Knowledge Graphs for efficient video indexing and an agentic retrieval-generation mechanism for handling diverse queries.", "result": "AVAS achieves 62.3% and 64.1% accuracy on LVBench and VideoMME-Long, and 75.8% on the new AVAS-100 benchmark.", "conclusion": "AVAS demonstrates superior performance in open-ended and ultra-long video analytics, setting a new standard for video-language models."}}
{"id": "2411.17720", "pdf": "https://arxiv.org/pdf/2411.17720", "abs": "https://arxiv.org/abs/2411.17720", "authors": ["Mohammadali Shakerdargah", "Shan Lu", "Chao Gao", "Di Niu"], "title": "MAS-Attention: Memory-Aware Stream Processing for Attention Acceleration on Resource-Constrained Edge Devices", "categories": ["cs.DC", "cs.AI", "cs.PF", "C.1.4; I.2.7; I.5.1"], "comment": "Accepted to MLSys 2025,", "summary": "The advent of foundation models have revolutionized various fields, enabling\nunprecedented task accuracy and flexibility in computational linguistics,\ncomputer vision and other domains. Attention mechanism has become an essential\ncomponent of foundation models, due to their superb capability of capturing\ncorrelations in a sequence. However, attention results in quadratic complexity\nin memory and compute as the context length grows. Although many fusion-based\nexact attention acceleration algorithms have been developed for\ndatacenter-grade GPUs and accelerators leveraging multi-core parallelism and\ndata locality, yet it remains a significant challenge to accelerate attention\non resource-constrained edge neural accelerators with limited compute units and\nstringent on-chip caches. In this paper, we propose a scheme for exact\nattention inference acceleration on memory-constrained edge accelerators, by\nparallelizing the utilization of heterogeneous compute units, i.e., vector\nprocessing units and matrix processing units. Our method involves scheduling\nworkloads onto these different compute units in a multi-tiered tiling scheme to\nprocess tiled vector workloads and matrix workloads in attention as two\nstreams, respecting the workload dependencies. We search for tiling factors to\nmaximize the parallelization of both compute units while considering I/O\noverhead, and propose a proactive cache overwrite strategy to avoid undesirable\ncache spills in reality. Extensive results based on open-sourced simulation\nframeworks show up to 2.75x speedup and 54% reduction in energy consumption as\ncompared to the state-of-the-art attention fusion method (FLAT) in the edge\ncomputing scenario. Further experiments on a real-world edge neural processing\nunit demonstrate speedup of up to 1.76x for attention as compared to FLAT,\nwithout affecting model output accuracy.", "AI": {"tldr": "Proposes a method to accelerate exact attention inference on edge accelerators by parallelizing heterogeneous compute units, achieving significant speedup and energy reduction.", "motivation": "Addressing the challenge of accelerating attention mechanisms on resource-constrained edge accelerators due to their quadratic complexity.", "method": "Uses a multi-tiered tiling scheme to parallelize vector and matrix workloads on heterogeneous compute units, optimizing tiling factors and cache management.", "result": "Achieves up to 2.75x speedup and 54% energy reduction in simulations, and 1.76x speedup on real-world hardware without accuracy loss.", "conclusion": "The proposed scheme effectively accelerates attention on edge accelerators while maintaining accuracy, offering practical benefits for edge computing."}}
{"id": "2504.13955", "pdf": "https://arxiv.org/pdf/2504.13955", "abs": "https://arxiv.org/abs/2504.13955", "authors": ["Suhas BN", "Andrew M. Sherrill", "Rosa I. Arriaga", "Chris W. Wiese", "Saeed Abdullah"], "title": "Thousand Voices of Trauma: A Large-Scale Synthetic Dataset for Modeling Prolonged Exposure Therapy Conversations", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG", "68T50", "I.2.7; H.5.2"], "comment": "22 pages, 6 figures Updated Appendix with example model responses", "summary": "The advancement of AI systems for mental health support is hindered by\nlimited access to therapeutic conversation data, particularly for trauma\ntreatment. We present Thousand Voices of Trauma, a synthetic benchmark dataset\nof 3,000 therapy conversations based on Prolonged Exposure therapy protocols\nfor Post-traumatic Stress Disorder (PTSD). The dataset comprises 500 unique\ncases, each explored through six conversational perspectives that mirror the\nprogression of therapy from initial anxiety to peak distress to emotional\nprocessing. We incorporated diverse demographic profiles (ages 18-80, M=49.3,\n49.4% male, 44.4% female, 6.2% non-binary), 20 trauma types, and 10\ntrauma-related behaviors using deterministic and probabilistic generation\nmethods. Analysis reveals realistic distributions of trauma types (witnessing\nviolence 10.6%, bullying 10.2%) and symptoms (nightmares 23.4%, substance abuse\n20.8%). Clinical experts validated the dataset's therapeutic fidelity,\nhighlighting its emotional depth while suggesting refinements for greater\nauthenticity. We also developed an emotional trajectory benchmark with\nstandardized metrics for evaluating model responses. This privacy-preserving\ndataset addresses critical gaps in trauma-focused mental health data, offering\na valuable resource for advancing both patient-facing applications and\nclinician training tools.", "AI": {"tldr": "A synthetic dataset, Thousand Voices of Trauma, with 3,000 therapy conversations for PTSD is introduced, addressing data scarcity in AI mental health support.", "motivation": "Limited access to therapeutic conversation data, especially for trauma treatment, hinders AI advancements in mental health.", "method": "Created 3,000 synthetic therapy conversations based on Prolonged Exposure therapy protocols, incorporating diverse demographics, trauma types, and behaviors using deterministic and probabilistic methods.", "result": "The dataset shows realistic trauma and symptom distributions, validated by clinical experts for therapeutic fidelity. An emotional trajectory benchmark was also developed.", "conclusion": "The dataset fills critical gaps in trauma-focused mental health data, aiding AI applications and clinician training while preserving privacy."}}
{"id": "2505.10843", "pdf": "https://arxiv.org/pdf/2505.10843", "abs": "https://arxiv.org/abs/2505.10843", "authors": ["Yuta Higuchi", "Rikuto Nagai", "Atsushi Okazaki", "Masaki Ogura", "Naoki Wakamiya"], "title": "Comparative Analysis of Black-Box Optimization Methods for Weather Intervention Design", "categories": ["physics.ao-ph", "cs.LG", "cs.SY", "eess.SY", "math.OC"], "comment": "15 pages, 11 figures", "summary": "As climate change increases the threat of weather-related disasters, research\non weather control is gaining importance. The objective of weather control is\nto mitigate disaster risks by administering interventions with optimal timing,\nlocation, and intensity. However, the optimization process is highly\nchallenging due to the vast scale and complexity of weather phenomena, which\nintroduces two major challenges. First, obtaining accurate gradient information\nfor optimization is difficult. In addition, numerical weather prediction (NWP)\nmodels demand enormous computational resources, necessitating parameter\noptimization with minimal function evaluations. To address these challenges,\nthis study proposes a method for designing weather interventions based on\nblack-box optimization, which enables efficient exploration without requiring\ngradient information. The proposed method is evaluated in two distinct control\nscenarios: one-shot initial value intervention and sequential intervention\nbased on model predictive control. Furthermore, a comparative analysis is\nconducted among four representative black-box optimization methods in terms of\ntotal rainfall reduction. Experimental results show that Bayesian optimization\nachieves higher control effectiveness than the others, particularly in\nhigh-dimensional search spaces. These findings suggest that Bayesian\noptimization is a highly effective approach for weather intervention\ncomputation.", "AI": {"tldr": "The paper proposes a black-box optimization method for weather control to mitigate disaster risks, highlighting Bayesian optimization as the most effective approach.", "motivation": "Addressing the challenges of weather control optimization, such as obtaining accurate gradients and high computational costs of numerical weather prediction models.", "method": "Uses black-box optimization for designing weather interventions, tested in one-shot initial value and sequential intervention scenarios.", "result": "Bayesian optimization outperforms other methods in reducing rainfall, especially in high-dimensional search spaces.", "conclusion": "Bayesian optimization is highly effective for weather intervention computation."}}
{"id": "2505.00752", "pdf": "https://arxiv.org/pdf/2505.00752", "abs": "https://arxiv.org/abs/2505.00752", "authors": ["Xuzhao Li", "Xuchen Li", "Shiyu Hu"], "title": "DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking", "categories": ["cs.CV", "cs.AI"], "comment": "Preprint, Under review", "summary": "Nighttime UAV tracking presents significant challenges due to extreme\nillumination variations and viewpoint changes, which severely degrade tracking\nperformance. Existing approaches either rely on light enhancers with high\ncomputational costs or introduce redundant domain adaptation mechanisms,\nfailing to fully utilize the dynamic features in varying perspectives. To\naddress these issues, we propose \\textbf{DARTer} (\\textbf{D}ynamic\n\\textbf{A}daptive \\textbf{R}epresentation \\textbf{T}racker), an end-to-end\ntracking framework designed for nighttime UAV scenarios. DARTer leverages a\nDynamic Feature Blender (DFB) to effectively fuse multi-perspective nighttime\nfeatures from static and dynamic templates, enhancing representation\nrobustness. Meanwhile, a Dynamic Feature Activator (DFA) adaptively activates\nVision Transformer layers based on extracted features, significantly improving\nefficiency by reducing redundant computations. Our model eliminates the need\nfor complex multi-task loss functions, enabling a streamlined training process.\nExtensive experiments on multiple nighttime UAV tracking benchmarks demonstrate\nthe superiority of DARTer over state-of-the-art trackers. These results confirm\nthat DARTer effectively balances tracking accuracy and efficiency, making it a\npromising solution for real-world nighttime UAV tracking applications.", "AI": {"tldr": "DARTer is an end-to-end tracking framework for nighttime UAV scenarios, using dynamic feature blending and activation to improve robustness and efficiency.", "motivation": "Nighttime UAV tracking faces challenges like illumination variations and viewpoint changes, which degrade performance. Existing methods are computationally expensive or inefficient.", "method": "DARTer uses a Dynamic Feature Blender (DFB) to fuse multi-perspective features and a Dynamic Feature Activator (DFA) to adaptively activate Vision Transformer layers, reducing redundancy.", "result": "DARTer outperforms state-of-the-art trackers on nighttime UAV benchmarks, balancing accuracy and efficiency.", "conclusion": "DARTer is a promising solution for real-world nighttime UAV tracking, offering robust and efficient performance."}}
{"id": "2411.18954", "pdf": "https://arxiv.org/pdf/2411.18954", "abs": "https://arxiv.org/abs/2411.18954", "authors": ["Yaomin Wang", "Chaolong Ying", "Xiaodong Luo", "Tianshu Yu"], "title": "NeuroLifting: Neural Inference on Markov Random Fields at Scale", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Inference in large-scale Markov Random Fields (MRFs) is a critical yet\nchallenging task, traditionally approached through approximate methods like\nbelief propagation and mean field, or exact methods such as the Toulbar2\nsolver. These strategies often fail to strike an optimal balance between\nefficiency and solution quality, particularly as the problem scale increases.\nThis paper introduces NeuroLifting, a novel technique that leverages Graph\nNeural Networks (GNNs) to reparameterize decision variables in MRFs,\nfacilitating the use of standard gradient descent optimization. By extending\ntraditional lifting techniques into a non-parametric neural network framework,\nNeuroLifting benefits from the smooth loss landscape of neural networks,\nenabling efficient and parallelizable optimization. Empirical results\ndemonstrate that, on moderate scales, NeuroLifting performs very close to the\nexact solver Toulbar2 in terms of solution quality, significantly surpassing\nexisting approximate methods. Notably, on large-scale MRFs, NeuroLifting\ndelivers superior solution quality against all baselines, as well as exhibiting\nlinear computational complexity growth. This work presents a significant\nadvancement in MRF inference, offering a scalable and effective solution for\nlarge-scale problems.", "AI": {"tldr": "NeuroLifting uses GNNs to reparameterize MRF variables, enabling gradient descent optimization. It outperforms approximate methods and rivals exact solvers like Toulbar2 in quality, with linear scalability for large MRFs.", "motivation": "Traditional MRF inference methods struggle to balance efficiency and solution quality, especially at scale.", "method": "NeuroLifting employs GNNs to reparameterize MRF variables, allowing gradient descent optimization in a smooth neural network framework.", "result": "NeuroLifting matches Toulbar2 in quality for moderate scales and surpasses all baselines for large-scale MRFs, with linear computational growth.", "conclusion": "NeuroLifting advances MRF inference by providing a scalable, efficient, and high-quality solution for large-scale problems."}}
{"id": "2505.09665", "pdf": "https://arxiv.org/pdf/2505.09665", "abs": "https://arxiv.org/abs/2505.09665", "authors": ["Sulong Zhou", "Qunying Huang", "Shaoheng Zhou", "Yun Hang", "Xinyue Ye", "Aodong Mei", "Kathryn Phung", "Yuning Ye", "Uma Govindswamy", "Zehan Li"], "title": "Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling", "categories": ["cs.SI", "cs.CL"], "comment": "Corrected capitalization errors in the section subtitle 3.4, 4.3,\n  step 1 in section 3.3.2, and Supplementary Information. Fix typo with\n  \"Weighting\" for step 4 in section 3.3.2", "summary": "Wildfires have become increasingly frequent, irregular, and severe in recent\nyears. Understanding how affected populations perceive and respond during\nwildfire crises is critical for timely and empathetic disaster response. Social\nmedia platforms offer a crowd-sourced channel to capture evolving public\ndiscourse, providing hyperlocal information and insight into public sentiment.\nThis study analyzes Reddit discourse during the 2025 Los Angeles wildfires,\nspanning from the onset of the disaster to full containment. We collect 385\nposts and 114,879 comments related to the Palisades and Eaton fires. We adopt\ntopic modeling methods to identify the latent topics, enhanced by large\nlanguage models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we\ndevelop a hierarchical framework to categorize latent topics, consisting of two\nmain categories, Situational Awareness (SA) and Crisis Narratives (CN). The\nvolume of SA category closely aligns with real-world fire progressions, peaking\nwithin the first 2-5 days as the fires reach the maximum extent. The most\nfrequent co-occurring category set of public health and safety, loss and\ndamage, and emergency resources expands on a wide range of health-related\nlatent topics, including environmental health, occupational health, and one\nhealth. Grief signals and mental health risks consistently accounted for 60\npercentage and 40 percentage of CN instances, respectively, with the highest\ntotal volume occurring at night. This study contributes the first annotated\nsocial media dataset on the 2025 LA fires, and introduces a scalable\nmulti-layer framework that leverages topic modeling for crisis discourse\nanalysis. By identifying persistent public health concerns, our results can\ninform more empathetic and adaptive strategies for disaster response, public\nhealth communication, and future research in comparable climate-related\ndisaster events.", "AI": {"tldr": "The study analyzes Reddit discourse during the 2025 LA wildfires using topic modeling and a hierarchical framework to categorize topics into Situational Awareness (SA) and Crisis Narratives (CN). It highlights public health concerns and mental health risks, offering insights for disaster response.", "motivation": "To understand public perception and response during wildfires for better disaster management, leveraging social media as a real-time data source.", "method": "Collects 385 posts and 114,879 comments from Reddit, uses topic modeling enhanced by LLMs and HITL, and categorizes topics into SA and CN.", "result": "SA topics align with fire progression, while CN reveals persistent mental health risks (40%) and grief signals (60%). Public health concerns are prominent.", "conclusion": "The study provides a scalable framework for crisis discourse analysis and informs empathetic disaster response strategies, especially for public health communication."}}
{"id": "2505.10919", "pdf": "https://arxiv.org/pdf/2505.10919", "abs": "https://arxiv.org/abs/2505.10919", "authors": ["Luca Menicali", "Andrew Grace", "David H. Richter", "Stefano Castruccio"], "title": "A Physics-Informed Convolutional Long Short Term Memory Statistical Model for Fluid Thermodynamics Simulations", "categories": ["physics.flu-dyn", "cs.LG", "stat.ML"], "comment": null, "summary": "Fluid thermodynamics underpins atmospheric dynamics, climate science,\nindustrial applications, and energy systems. However, direct numerical\nsimulations (DNS) of such systems are computationally prohibitive. To address\nthis, we present a novel physics-informed spatio-temporal surrogate model for\nRayleigh-B\\'enard convection (RBC), a canonical example of convective fluid\nflow. Our approach combines convolutional neural networks for spatial feature\nextraction with an innovative recurrent architecture inspired by large language\nmodels, comprising a context builder and a sequence generator to capture\ntemporal dynamics. Inference is penalized with respect to the governing partial\ndifferential equations to ensure physical interpretability. Given the\nsensitivity of turbulent convection to initial conditions, we quantify\nuncertainty using a conformal prediction framework. This model replicates key\nfeatures of RBC dynamics while significantly reducing computational cost,\noffering a scalable alternative to DNS for long-term simulations.", "AI": {"tldr": "A physics-informed surrogate model for Rayleigh-B\u00e9nard convection combines CNNs and a novel recurrent architecture to reduce computational costs while maintaining physical accuracy.", "motivation": "Direct numerical simulations (DNS) of fluid thermodynamics are computationally expensive, limiting their use in applications like climate science and energy systems.", "method": "The model uses CNNs for spatial feature extraction and a recurrent architecture (context builder and sequence generator) for temporal dynamics, penalized by governing PDEs for physical interpretability. Uncertainty is quantified using conformal prediction.", "result": "The model replicates key RBC dynamics with significantly lower computational cost than DNS.", "conclusion": "This scalable surrogate model offers a practical alternative to DNS for long-term simulations in fluid thermodynamics."}}
{"id": "2505.01481", "pdf": "https://arxiv.org/pdf/2505.01481", "abs": "https://arxiv.org/abs/2505.01481", "authors": ["Zongxia Li", "Xiyang Wu", "Guangyao Shi", "Yubin Qin", "Hongyang Du", "Tianyi Zhou", "Dinesh Manocha", "Jordan Lee Boyd-Graber"], "title": "VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations on Synthetic Video Understanding", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Synthetic video generation has gained significant attention for its realism\nand broad applications, but remains prone to violations of common sense and\nphysical laws. This highlights the need for reliable abnormality detectors that\nunderstand such principles and are robust to hallucinations. To address this,\nwe introduce VideoHallu, a benchmark of over 3,000 video QA pairs built from\nsynthetic videos generated by models like Veo2, Sora, and Kling, paired with\nexpert-crafted counterintuitive QA to evaluate the critical thinking abilities\nof Multi-modal Large Language Models (MLLMs) on abnormalities that are\nperceptually obvious to humans but often hallucinated due to language priors.\nVideoHallu evaluates MLLMs' abnormality detection abilities with examples\nacross alignment, consistency, commonsense, and physics. We benchmark SOTA\nMLLMs, including GPT-4o, Gemini-2.5-Pro, Qwen2.5-VL, Video-R1, and\nVideoChat-R1. We observe that these models perform well on many real-world\nbenchmarks like MVBench and MovieChat, but still struggle with basic\nphysics-based and commonsense reasoning in synthetic videos. We further show\nthat post-training with Group Relative Policy Optimization (GRPO), using\ncurriculum learning on datasets combining video QA with counterintuitive\ncommonsense and physics reasoning over real and synthetic videos, improves\nMLLMs' abnormality detection and critical thinking, demonstrating the value of\ntargeted training for improving their understanding of commonsense and physical\nlaws.", "AI": {"tldr": "VideoHallu is a benchmark for evaluating MLLMs' ability to detect abnormalities in synthetic videos, showing current models struggle with commonsense and physics reasoning. Post-training with GRPO improves performance.", "motivation": "Synthetic video generation often violates commonsense and physics, necessitating robust abnormality detectors for MLLMs.", "method": "Introduces VideoHallu, a benchmark with 3,000+ QA pairs from synthetic videos, testing MLLMs on alignment, consistency, commonsense, and physics. Benchmarks SOTA models like GPT-4o and Gemini-2.5-Pro.", "result": "Current MLLMs perform well on real-world benchmarks but struggle with synthetic video abnormalities. GRPO post-training improves detection.", "conclusion": "Targeted training with GRPO enhances MLLMs' understanding of commonsense and physics in synthetic videos, addressing critical gaps."}}
{"id": "2412.11983", "pdf": "https://arxiv.org/pdf/2412.11983", "abs": "https://arxiv.org/abs/2412.11983", "authors": ["Taiyan Zhang", "Renchi Yang", "Yurui Lai", "Mingyu Yan", "Xiaochun Ye", "Dongrui Fan"], "title": "Leveraging Large Language Models for Effective Label-free Node Classification in Text-Attributed Graphs", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by SIGIR2025", "summary": "Graph neural networks (GNNs) have become the preferred models for node\nclassification in graph data due to their robust capabilities in integrating\ngraph structures and attributes. However, these models heavily depend on a\nsubstantial amount of high-quality labeled data for training, which is often\ncostly to obtain. With the rise of large language models (LLMs), a promising\napproach is to utilize their exceptional zero-shot capabilities and extensive\nknowledge for node labeling. Despite encouraging results, this approach either\nrequires numerous queries to LLMs or suffers from reduced performance due to\nnoisy labels generated by LLMs. To address these challenges, we introduce\nLocle, an active self-training framework that does Label-free node\nClassification with LLMs cost-Effectively. Locle iteratively identifies small\nsets of \"critical\" samples using GNNs and extracts informative pseudo-labels\nfor them with both LLMs and GNNs, serving as additional supervision signals to\nenhance model training. Specifically, Locle comprises three key components: (i)\nan effective active node selection strategy for initial annotations; (ii) a\ncareful sample selection scheme to identify \"critical\" nodes based on label\ndisharmonicity and entropy; and (iii) a label refinement module that combines\nLLMs and GNNs with a rewired topology. Extensive experiments on five benchmark\ntext-attributed graph datasets demonstrate that Locle significantly outperforms\nstate-of-the-art methods under the same query budget to LLMs in terms of\nlabel-free node classification. Notably, on the DBLP dataset with 14.3k nodes,\nLocle achieves an 8.08% improvement in accuracy over the state-of-the-art at a\ncost of less than one cent. Our code is available at\nhttps://github.com/HKBU-LAGAS/Locle.", "AI": {"tldr": "Locle is an active self-training framework for label-free node classification using LLMs and GNNs, outperforming state-of-the-art methods with minimal cost.", "motivation": "GNNs require large labeled datasets, which are costly. LLMs offer zero-shot capabilities but face challenges like high query costs or noisy labels.", "method": "Locle iteratively selects critical nodes, generates pseudo-labels using LLMs and GNNs, and refines labels with a rewired topology.", "result": "Locle achieves an 8.08% accuracy improvement on the DBLP dataset with minimal cost.", "conclusion": "Locle effectively combines LLMs and GNNs for cost-efficient, label-free node classification."}}
{"id": "2505.09921", "pdf": "https://arxiv.org/pdf/2505.09921", "abs": "https://arxiv.org/abs/2505.09921", "authors": ["Yidan Wang", "Yanan Cao", "Yubing Ren", "Fang Fang", "Zheng Lin", "Binxing Fang"], "title": "PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization", "categories": ["cs.CR", "cs.CL"], "comment": "Accepted to ACL 2025 (main)", "summary": "Large Language Models (LLMs) excel in various domains but pose inherent\nprivacy risks. Existing methods to evaluate privacy leakage in LLMs often use\nmemorized prefixes or simple instructions to extract data, both of which\nwell-alignment models can easily block. Meanwhile, Jailbreak attacks bypass LLM\nsafety mechanisms to generate harmful content, but their role in privacy\nscenarios remains underexplored. In this paper, we examine the effectiveness of\njailbreak attacks in extracting sensitive information, bridging privacy leakage\nand jailbreak attacks in LLMs. Moreover, we propose PIG, a novel framework\ntargeting Personally Identifiable Information (PII) and addressing the\nlimitations of current jailbreak methods. Specifically, PIG identifies PII\nentities and their types in privacy queries, uses in-context learning to build\na privacy context, and iteratively updates it with three gradient-based\nstrategies to elicit target PII. We evaluate PIG and existing jailbreak methods\nusing two privacy-related datasets. Experiments on four white-box and two\nblack-box LLMs show that PIG outperforms baseline methods and achieves\nstate-of-the-art (SoTA) results. The results underscore significant privacy\nrisks in LLMs, emphasizing the need for stronger safeguards. Our code is\navailble at https://github.com/redwyd/PrivacyJailbreak.", "AI": {"tldr": "The paper explores jailbreak attacks for extracting sensitive data from LLMs, introduces PIG for PII extraction, and shows its superiority over existing methods.", "motivation": "To address underexplored privacy risks in LLMs by leveraging jailbreak attacks and improving PII extraction methods.", "method": "Proposes PIG, a framework using in-context learning and gradient-based strategies to identify and extract PII from LLMs.", "result": "PIG outperforms baselines on privacy datasets, achieving SoTA results on white-box and black-box LLMs.", "conclusion": "Highlights significant privacy risks in LLMs and calls for stronger safeguards."}}
{"id": "2505.10942", "pdf": "https://arxiv.org/pdf/2505.10942", "abs": "https://arxiv.org/abs/2505.10942", "authors": ["Meghali Nandi", "Arash Shaghaghi", "Nazatul Haque Sultan", "Gustavo Batista", "Raymond K. Zhao", "Sanjay Jha"], "title": "Nosy Layers, Noisy Fixes: Tackling DRAs in Federated Learning Systems using Explainable AI", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted to AsiaCCS 2025", "summary": "Federated Learning (FL) has emerged as a powerful paradigm for collaborative\nmodel training while keeping client data decentralized and private. However, it\nis vulnerable to Data Reconstruction Attacks (DRA) such as \"LoKI\" and \"Robbing\nthe Fed\", where malicious models sent from the server to the client can\nreconstruct sensitive user data. To counter this, we introduce DRArmor, a novel\ndefense mechanism that integrates Explainable AI with targeted detection and\nmitigation strategies for DRA. Unlike existing defenses that focus on the\nentire model, DRArmor identifies and addresses the root cause (i.e., malicious\nlayers within the model that send gradients with malicious intent) by analyzing\ntheir contribution to the output and detecting inconsistencies in gradient\nvalues. Once these malicious layers are identified, DRArmor applies defense\ntechniques such as noise injection, pixelation, and pruning to these layers\nrather than the whole model, minimizing the attack surface and preserving\nclient data privacy. We evaluate DRArmor's performance against the advanced\nLoKI attack across diverse datasets, including MNIST, CIFAR-10, CIFAR-100, and\nImageNet, in a 200-client FL setup. Our results demonstrate DRArmor's\neffectiveness in mitigating data leakage, achieving high True Positive and True\nNegative Rates of 0.910 and 0.890, respectively. Additionally, DRArmor\nmaintains an average accuracy of 87%, effectively protecting client privacy\nwithout compromising model performance. Compared to existing defense\nmechanisms, DRArmor reduces the data leakage rate by 62.5% with datasets\ncontaining 500 samples per client.", "AI": {"tldr": "DRArmor is a defense mechanism for Federated Learning that targets malicious layers in models to prevent Data Reconstruction Attacks, maintaining privacy and model performance.", "motivation": "Federated Learning is vulnerable to Data Reconstruction Attacks (DRA), which can reconstruct sensitive user data from malicious models. Existing defenses are not precise enough.", "method": "DRArmor uses Explainable AI to identify malicious layers in models, then applies targeted defenses like noise injection, pixelation, and pruning to these layers.", "result": "DRArmor achieves high True Positive (0.910) and True Negative (0.890) rates, reduces data leakage by 62.5%, and maintains 87% model accuracy.", "conclusion": "DRArmor effectively mitigates DRA while preserving model performance, outperforming existing defenses."}}
{"id": "2505.04207", "pdf": "https://arxiv.org/pdf/2505.04207", "abs": "https://arxiv.org/abs/2505.04207", "authors": ["Mustafa Yurdakul", "\u015eakir Tasdemir"], "title": "An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Potholes cause vehicle damage and traffic accidents, creating serious safety\nand economic problems. Therefore, early and accurate detection of potholes is\ncrucial. Existing detection methods are usually only based on 2D RGB images and\ncannot accurately analyze the physical characteristics of potholes. In this\npaper, a publicly available dataset of RGB-D images (PothRGBD) is created and\nan improved YOLOv8-based model is proposed for both pothole detection and\npothole physical features analysis. The Intel RealSense D415 depth camera was\nused to collect RGB and depth data from the road surfaces, resulting in a\nPothRGBD dataset of 1000 images. The data was labeled in YOLO format suitable\nfor segmentation. A novel YOLO model is proposed based on the YOLOv8n-seg\narchitecture, which is structurally improved with Dynamic Snake Convolution\n(DSConv), Simple Attention Module (SimAM) and Gaussian Error Linear Unit\n(GELU). The proposed model segmented potholes with irregular edge structure\nmore accurately, and performed perimeter and depth measurements on depth maps\nwith high accuracy. The standard YOLOv8n-seg model achieved 91.9% precision,\n85.2% recall and 91.9% mAP@50. With the proposed model, the values increased to\n93.7%, 90.4% and 93.8% respectively. Thus, an improvement of 1.96% in\nprecision, 6.13% in recall and 2.07% in mAP was achieved. The proposed model\nperforms pothole detection as well as perimeter and depth measurement with high\naccuracy and is suitable for real-time applications due to its low model\ncomplexity. In this way, a lightweight and effective model that can be used in\ndeep learning-based intelligent transportation solutions has been acquired.", "AI": {"tldr": "A lightweight YOLOv8-based model with structural improvements (DSConv, SimAM, GELU) is proposed for pothole detection and physical feature analysis using RGB-D images, achieving higher accuracy than standard YOLOv8n-seg.", "motivation": "Potholes cause safety and economic issues, but existing 2D RGB-based methods lack accurate physical feature analysis.", "method": "Created a PothRGBD dataset with 1000 RGB-D images using Intel RealSense D415. Improved YOLOv8n-seg with DSConv, SimAM, and GELU for better segmentation and depth/perimeter measurement.", "result": "Proposed model improved precision (93.7%), recall (90.4%), and mAP@50 (93.8%) over standard YOLOv8n-seg (91.9%, 85.2%, 91.9%).", "conclusion": "The model is lightweight, accurate, and suitable for real-time intelligent transportation solutions."}}
{"id": "2412.20302", "pdf": "https://arxiv.org/pdf/2412.20302", "abs": "https://arxiv.org/abs/2412.20302", "authors": ["Ahmed M. Adly"], "title": "EXAdam: The Power of Adaptive Cross-Moments", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "This paper introduces EXAdam ($\\textbf{EX}$tended $\\textbf{Adam}$), a novel\noptimization algorithm that builds upon the widely-used Adam optimizer. EXAdam\nincorporates two key enhancements: (1) new debiasing terms for improved moment\nestimation and (2) a gradient-based acceleration mechanism for increased\nresponsiveness to the current loss landscape. These innovations work\nsynergistically to address limitations of the original Adam algorithm,\npotentially offering improved convergence properties, enhanced ability to\nescape saddle points, and potentially greater robustness to hyperparameter\nchoices, though this requires further investigation. We provide a theoretical\nanalysis of EXAdam's components and their interactions, highlighting the\nalgorithm's potential advantages in navigating complex optimization landscapes.\nEmpirical evaluations demonstrate EXAdam's superiority over Adam, achieving\n38.46% faster convergence and yielding improvements of 1.96%, 2.17%, and 1.17%\nin training, validation, and testing accuracies, respectively, when applied to\na CNN trained on the CIFAR-10 dataset. While these results are promising,\nfurther empirical validation across diverse tasks is essential to fully gauge\nEXAdam's efficacy. Nevertheless, EXAdam represents a significant advancement in\nadaptive optimization techniques, with promising implications for a wide range\nof machine learning applications. This work aims to contribute to the ongoing\ndevelopment of more efficient, adaptive, and universally applicable\noptimization methods in the field of machine learning and artificial\nintelligence.", "AI": {"tldr": "EXAdam is an enhanced version of Adam with debiasing terms and gradient-based acceleration, showing faster convergence and better accuracy in tests.", "motivation": "To address limitations of Adam by improving moment estimation and responsiveness to the loss landscape.", "method": "Introduces debiasing terms and a gradient-based acceleration mechanism.", "result": "38.46% faster convergence and accuracy improvements of 1.96%, 2.17%, and 1.17% in training, validation, and testing.", "conclusion": "EXAdam is a promising advancement in adaptive optimization, though further validation is needed."}}
{"id": "2505.11006", "pdf": "https://arxiv.org/pdf/2505.11006", "abs": "https://arxiv.org/abs/2505.11006", "authors": ["Oskar Allerbo", "Thomas B. Sch\u00f6n"], "title": "Supervised Models Can Generalize Also When Trained on Random Label", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The success of unsupervised learning raises the question of whether also\nsupervised models can be trained without using the information in the output\n$y$. In this paper, we demonstrate that this is indeed possible. The key step\nis to formulate the model as a smoother, i.e. on the form $\\hat{f}=Sy$, and to\nconstruct the smoother matrix $S$ independently of $y$, e.g. by training on\nrandom labels. We present a simple model selection criterion based on the\ndistribution of the out-of-sample predictions and show that, in contrast to\ncross-validation, this criterion can be used also without access to $y$. We\ndemonstrate on real and synthetic data that $y$-free trained versions of linear\nand kernel ridge regression, smoothing splines, and neural networks perform\nsimilarly to their standard, $y$-based, versions and, most importantly,\nsignificantly better than random guessing.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.05848", "pdf": "https://arxiv.org/pdf/2505.05848", "abs": "https://arxiv.org/abs/2505.05848", "authors": ["Yue Yin", "Enze Tao", "Weijian Deng", "Dylan Campbell"], "title": "RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects", "categories": ["cs.CV"], "comment": null, "summary": "Modern 3D reconstruction and novel view synthesis approaches have\ndemonstrated strong performance on scenes with opaque Lambertian objects.\nHowever, most assume straight light paths and therefore cannot properly handle\nrefractive and reflective materials. Moreover, datasets specialized for these\neffects are limited, stymieing efforts to evaluate performance and develop\nsuitable techniques. In this work, we introduce a synthetic RefRef dataset and\nbenchmark for reconstructing scenes with refractive and reflective objects from\nposed images. Our dataset has 50 such objects of varying complexity, from\nsingle-material convex shapes to multi-material non-convex shapes, each placed\nin three different background types, resulting in 150 scenes. We also propose\nan oracle method that, given the object geometry and refractive indices,\ncalculates accurate light paths for neural rendering, and an approach based on\nthis that avoids these assumptions. We benchmark these against several\nstate-of-the-art methods and show that all methods lag significantly behind the\noracle, highlighting the challenges of the task and dataset.", "AI": {"tldr": "A new dataset (RefRef) and benchmark for 3D reconstruction of refractive/reflective objects is introduced, along with an oracle method for accurate light path calculation. Current methods lag behind the oracle, showing the challenge.", "motivation": "Existing methods struggle with refractive/reflective materials due to assumptions of straight light paths and lack of specialized datasets.", "method": "Introduces a synthetic dataset (RefRef) with 150 scenes and proposes an oracle method for accurate light path calculation, plus an alternative approach.", "result": "Benchmarking shows current methods significantly underperform compared to the oracle, emphasizing the difficulty of the task.", "conclusion": "The RefRef dataset and oracle method highlight challenges in handling refractive/reflective materials, urging further research."}}
{"id": "2501.16466", "pdf": "https://arxiv.org/pdf/2501.16466", "abs": "https://arxiv.org/abs/2501.16466", "authors": ["Brian Singer", "Keane Lucas", "Lakshmi Adiga", "Meghna Jain", "Lujo Bauer", "Vyas Sekar"], "title": "On the Feasibility of Using LLMs to Autonomously Execute Multi-host Network Attacks", "categories": ["cs.CR", "cs.AI"], "comment": "18 pages, 15 figures", "summary": "LLMs have shown preliminary promise in some security tasks and CTF\nchallenges. Real cyberattacks are often multi-host network attacks, which\ninvolve executing a number of steps across multiple hosts such as conducting\nreconnaissance, exploiting vulnerabilities, and using compromised hosts to\nexfiltrate data. To date, the extent to which LLMs can autonomously execute\nmulti-host network attacks} is not well understood. To this end, our first\ncontribution is MHBench, an open-source multi-host attack benchmark with 10\nrealistic emulated networks (from 25 to 50 hosts). We find that popular LLMs\nincluding modern reasoning models (e.g., GPT4o, Gemini 2.5 Pro, Sonnet 3.7\nThinking) with state-of-art security-relevant prompting strategies (e.g.,\nPentestGPT, CyberSecEval3) cannot autonomously execute multi-host network\nattacks. To enable LLMs to autonomously execute such attacks, our second\ncontribution is Incalmo, an high-level abstraction layer. Incalmo enables LLMs\nto specify high-level actions (e.g., infect a host, scan a network). Incalmo's\ntranslation layer converts these actions into lower-level primitives (e.g.,\ncommands to exploit tools) through expert agents. In 9 out of 10 networks in\nMHBench, LLMs using Incalmo achieve at least some of the attack goals. Even\nsmaller LLMs (e.g., Haiku 3.5, Gemini 2 Flash) equipped with Incalmo achieve\nall goals in 5 of 10 environments. We also validate the key role of high-level\nactions in Incalmo's abstraction in enabling LLMs to autonomously execute such\nattacks.", "AI": {"tldr": "LLMs struggle with multi-host network attacks; MHBench evaluates them, and Incalmo enables LLMs to perform such attacks via high-level abstractions.", "motivation": "To understand and improve LLMs' ability to autonomously execute multi-host network attacks, which are common in real cyberattacks.", "method": "Developed MHBench (a benchmark with 10 emulated networks) and Incalmo (an abstraction layer for LLMs to specify high-level actions).", "result": "Without Incalmo, LLMs fail; with Incalmo, they succeed in 9/10 networks, even smaller models achieving goals in 5/10.", "conclusion": "Incalmo's high-level abstraction is key to enabling LLMs to autonomously execute multi-host network attacks."}}
{"id": "2505.11014", "pdf": "https://arxiv.org/pdf/2505.11014", "abs": "https://arxiv.org/abs/2505.11014", "authors": ["Harsh Parikh", "Trang Quynh Nguyen", "Elizabeth A. Stuart", "Kara E. Rudolph", "Caleb H. Miles"], "title": "A Cautionary Tale on Integrating Studies with Disparate Outcome Measures for Causal Inference", "categories": ["stat.ME", "cs.LG", "econ.EM"], "comment": null, "summary": "Data integration approaches are increasingly used to enhance the efficiency\nand generalizability of studies. However, a key limitation of these methods is\nthe assumption that outcome measures are identical across datasets -- an\nassumption that often does not hold in practice. Consider the following opioid\nuse disorder (OUD) studies: the XBOT trial and the POAT study, both evaluating\nthe effect of medications for OUD on withdrawal symptom severity (not the\nprimary outcome of either trial). While XBOT measures withdrawal severity using\nthe subjective opiate withdrawal scale, POAT uses the clinical opiate\nwithdrawal scale. We analyze this realistic yet challenging setting where\noutcome measures differ across studies and where neither study records both\ntypes of outcomes. Our paper studies whether and when integrating studies with\ndisparate outcome measures leads to efficiency gains. We introduce three sets\nof assumptions -- with varying degrees of strength -- linking both outcome\nmeasures. Our theoretical and empirical results highlight a cautionary tale:\nintegration can improve asymptotic efficiency only under the strongest\nassumption linking the outcomes. However, misspecification of this assumption\nleads to bias. In contrast, a milder assumption may yield finite-sample\nefficiency gains, yet these benefits diminish as sample size increases. We\nillustrate these trade-offs via a case study integrating the XBOT and POAT\ndatasets to estimate the comparative effect of two medications for opioid use\ndisorder on withdrawal symptoms. By systematically varying the assumptions\nlinking the SOW and COW scales, we show potential efficiency gains and the\nrisks of bias. Our findings emphasize the need for careful assumption selection\nwhen fusing datasets with differing outcome measures, offering guidance for\nresearchers navigating this common challenge in modern data integration.", "AI": {"tldr": "The paper explores data integration with disparate outcome measures, showing efficiency gains require strong assumptions but risk bias.", "motivation": "To address the challenge of integrating studies with non-identical outcome measures, common in practice but often overlooked.", "method": "Introduces three assumption sets linking outcomes, tested theoretically and empirically using XBOT and POAT datasets.", "result": "Strong assumptions enable asymptotic efficiency but risk bias; milder assumptions offer finite-sample gains that fade with size.", "conclusion": "Careful assumption selection is crucial for integrating datasets with differing outcomes to balance efficiency and bias risks."}}
{"id": "2505.06003", "pdf": "https://arxiv.org/pdf/2505.06003", "abs": "https://arxiv.org/abs/2505.06003", "authors": ["Moritz Vandenhirtz", "Julia E. Vogt"], "title": "From Pixels to Perception: Interpretable Predictions via Instance-wise Grouped Feature Selection", "categories": ["cs.CV", "cs.LG"], "comment": "International Conference on Machine Learning", "summary": "Understanding the decision-making process of machine learning models provides\nvaluable insights into the task, the data, and the reasons behind a model's\nfailures. In this work, we propose a method that performs inherently\ninterpretable predictions through the instance-wise sparsification of input\nimages. To align the sparsification with human perception, we learn the masking\nin the space of semantically meaningful pixel regions rather than on\npixel-level. Additionally, we introduce an explicit way to dynamically\ndetermine the required level of sparsity for each instance. We show empirically\non semi-synthetic and natural image datasets that our inherently interpretable\nclassifier produces more meaningful, human-understandable predictions than\nstate-of-the-art benchmarks.", "AI": {"tldr": "Proposes an interpretable ML method using instance-wise sparsification of input images, aligning with human perception via semantic pixel regions and dynamic sparsity levels. Outperforms benchmarks in human-understandable predictions.", "motivation": "To provide insights into ML decision-making by making predictions inherently interpretable, addressing model failures and aligning explanations with human perception.", "method": "Instance-wise sparsification of input images, learning masks in semantically meaningful pixel regions, and dynamically determining sparsity levels per instance.", "result": "Empirical results on semi-synthetic and natural image datasets show more meaningful, human-understandable predictions than state-of-the-art benchmarks.", "conclusion": "The method enhances interpretability in ML models by aligning explanations with human perception and dynamically adjusting sparsity, outperforming existing benchmarks."}}
{"id": "2502.00213", "pdf": "https://arxiv.org/pdf/2502.00213", "abs": "https://arxiv.org/abs/2502.00213", "authors": ["Akiyoshi Tomihari", "Issei Sato"], "title": "Understanding Why Adam Outperforms SGD: Gradient Heterogeneity in Transformers", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Transformers are challenging to optimize with SGD and typically require\nadaptive optimizers such as Adam. However, the reasons behind the superior\nperformance of Adam over SGD remain unclear. In this study, we investigate the\noptimization of transformers by focusing on gradient heterogeneity, defined as\nthe disparity in gradient norms among parameters. Our analysis shows that\ngradient heterogeneity hinders gradient-based optimization, including SGD,\nwhile sign-based optimization, a simplified variant of Adam, is less affected.\nWe further examine gradient heterogeneity in transformers and show that it is\ninfluenced by the placement of layer normalization. Experimental results from\nfine-tuning transformers in both NLP and vision domains validate our\ntheoretical analyses. This study provides insights into the optimization\nchallenges of transformers and offers guidance for designing future\noptimization algorithms. Code is available at\nhttps://github.com/tom4649/gradient-heterogeneity.", "AI": {"tldr": "The paper explores why Adam outperforms SGD in optimizing transformers, attributing it to gradient heterogeneity and its impact on optimization.", "motivation": "To understand why adaptive optimizers like Adam perform better than SGD for transformers, focusing on gradient heterogeneity.", "method": "Analyzes gradient heterogeneity, its effect on optimization, and its relationship with layer normalization in transformers. Experiments validate findings in NLP and vision tasks.", "result": "Gradient heterogeneity hinders SGD but affects sign-based optimization (like Adam) less. Layer normalization placement influences heterogeneity.", "conclusion": "Provides insights into transformer optimization challenges and guidance for future optimizer design."}}
{"id": "2505.11025", "pdf": "https://arxiv.org/pdf/2505.11025", "abs": "https://arxiv.org/abs/2505.11025", "authors": ["Naqueeb Ahmad Warsi", "Ayanava Dasgupta", "Masahito Hayashi"], "title": "Generalization Bounds for Quantum Learning via R\u00e9nyi Divergences", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "comment": "36 pages, 2 figures", "summary": "This work advances the theoretical understanding of quantum learning by\nestablishing a new family of upper bounds on the expected generalization error\nof quantum learning algorithms, leveraging the framework introduced by Caro et\nal. (2024) and a new definition for the expected true loss. Our primary\ncontribution is the derivation of these bounds in terms of quantum and\nclassical R\\'enyi divergences, utilizing a variational approach for evaluating\nquantum R\\'enyi divergences, specifically the Petz and a newly introduced\nmodified sandwich quantum R\\'enyi divergence. Analytically and numerically, we\ndemonstrate the superior performance of the bounds derived using the modified\nsandwich quantum R\\'enyi divergence compared to those based on the Petz\ndivergence. Furthermore, we provide probabilistic generalization error bounds\nusing two distinct techniques: one based on the modified sandwich quantum\nR\\'enyi divergence and classical R\\'enyi divergence, and another employing\nsmooth max R\\'enyi divergence.", "AI": {"tldr": "New upper bounds on quantum learning generalization error are derived using quantum and classical R\u00e9nyi divergences, with improved performance shown for a modified sandwich quantum R\u00e9nyi divergence.", "motivation": "To enhance theoretical understanding of quantum learning by establishing tighter bounds on generalization error.", "method": "Leverages Caro et al.'s framework and a new true loss definition, using variational approaches for quantum R\u00e9nyi divergences (Petz and modified sandwich).", "result": "Modified sandwich quantum R\u00e9nyi divergence outperforms Petz divergence. Probabilistic bounds are also provided using two techniques.", "conclusion": "The work provides improved theoretical tools for analyzing quantum learning algorithms, with practical implications for performance evaluation."}}
{"id": "2505.06219", "pdf": "https://arxiv.org/pdf/2505.06219", "abs": "https://arxiv.org/abs/2505.06219", "authors": ["Noah Frahm", "Dongxu Zhao", "Andrea Dunn Beltran", "Ron Alterovitz", "Jan-Michael Frahm", "Junier Oliva", "Roni Sengupta"], "title": "VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction", "categories": ["cs.CV", "cs.RO", "I.2.10; I.2.9"], "comment": "The paper has not gone through legal review. We will update it with\n  new version once the review is complete", "summary": "Next Best View (NBV) algorithms aim to acquire an optimal set of images using\nminimal resources, time, or number of captures to enable efficient 3D\nreconstruction of a scene. Existing approaches often rely on prior scene\nknowledge or additional image captures and often develop policies that maximize\ncoverage. Yet, for many real scenes with complex geometry and self-occlusions,\ncoverage maximization does not lead to better reconstruction quality directly.\nIn this paper, we propose the View Introspection Network (VIN), which is\ntrained to predict the reconstruction quality improvement of views directly,\nand the VIN-NBV policy. A greedy sequential sampling-based policy, where at\neach acquisition step, we sample multiple query views and choose the one with\nthe highest VIN predicted improvement score. We design the VIN to perform\n3D-aware featurization of the reconstruction built from prior acquisitions, and\nfor each query view create a feature that can be decoded into an improvement\nscore. We then train the VIN using imitation learning to predict the\nreconstruction improvement score. We show that VIN-NBV improves reconstruction\nquality by ~30% over a coverage maximization baseline when operating with\nconstraints on the number of acquisitions or the time in motion.", "AI": {"tldr": "The paper introduces the View Introspection Network (VIN) and VIN-NBV policy to improve 3D reconstruction by predicting view quality improvements, outperforming coverage-based methods.", "motivation": "Existing NBV algorithms focus on coverage maximization, which doesn't always enhance reconstruction quality for complex scenes. The paper aims to directly predict and optimize reconstruction improvement.", "method": "VIN predicts reconstruction quality improvement scores for views. VIN-NBV uses a greedy policy to select views with the highest predicted improvement. VIN is trained via imitation learning.", "result": "VIN-NBV improves reconstruction quality by ~30% compared to coverage maximization baselines under acquisition or time constraints.", "conclusion": "The VIN-NBV approach effectively enhances 3D reconstruction by focusing on quality improvement rather than coverage, proving its superiority in constrained scenarios."}}
{"id": "2502.06830", "pdf": "https://arxiv.org/pdf/2502.06830", "abs": "https://arxiv.org/abs/2502.06830", "authors": ["Runyao Yu", "Yuchen Tao", "Fabian Leimgruber", "Tara Esterl", "Jochen L. Cremer"], "title": "OrderFusion: Encoding Orderbook for End-to-End Probabilistic Intraday Electricity Price Prediction", "categories": ["q-fin.CP", "cs.AI", "cs.LG"], "comment": "20 pages, 3 figures, 5 tables", "summary": "Accurate and reliable probabilistic prediction of intraday electricity prices\nis essential to manage market uncertainties and support robust trading\nstrategies. However, current methods rely heavily on domain feature extraction\nand fail to capture the dynamics between buy and sell orders, limiting the\nability to form rich representations of the orderbook. Furthermore, these\nmethods often require training separate models for different quantiles and\nintroduce additional procedures-such as post-hoc quantile sorting or loss-based\npenalties-to address the quantile crossing issue, where predicted upper\nquantiles fall below lower ones. These steps are either decoupled from model\ntraining or introduce extra tuning complexity. To address these challenges, we\npropose an encoding method called OrderFusion and design a hierarchical\nmulti-quantile head. OrderFusion encodes the orderbook into a 2.5D\nrepresentation and employs a tailored jump cross-attention to model buy-sell\ndynamics without the need for domain feature extraction. The multi-quantile\nhead anchors on the median quantile and hierarchically estimates other\nquantiles through constrained residuals, ensuring monotonicity without\npost-processing or additional tuning. We conduct extensive experiments and\nablation studies on three key price indices (ID1, ID2, and ID3) using three\nyears of orderbook data from the German and Austrian markets. The results\ndemonstrate that our approach provides an accurate, reliable, and unified\nend-to-end framework for probabilistic intraday price prediction.", "AI": {"tldr": "Proposes OrderFusion and a hierarchical multi-quantile head for accurate intraday electricity price prediction, addressing limitations of current methods.", "motivation": "Current methods for probabilistic intraday electricity price prediction rely on domain feature extraction and struggle with quantile crossing, requiring additional tuning.", "method": "OrderFusion encodes the orderbook into a 2.5D representation using jump cross-attention. A hierarchical multi-quantile head ensures monotonicity without post-processing.", "result": "Extensive experiments on German and Austrian markets show the method provides accurate, reliable, and unified probabilistic predictions.", "conclusion": "The approach offers an end-to-end solution for intraday price prediction, overcoming key challenges of existing methods."}}
{"id": "2505.11053", "pdf": "https://arxiv.org/pdf/2505.11053", "abs": "https://arxiv.org/abs/2505.11053", "authors": ["Adrian Kazakov", "Anna Milillo", "Alessandro Mura", "Stavro Ivanovski", "Valeria Mangano", "Alessandro Aronica", "Elisabetta De Angelis", "Pier Paolo Di Bartolomeo", "Alessandro Brin", "Luca Colasanti", "Miguel Escalona-Moran", "Francesco Lazzarotto", "Stefano Massetti", "Martina Moroni", "Raffaella Noschese", "Fabrizio Nuccilli", "Stefano Orsini", "Christina Plainaki", "Rosanna Rispoli", "Roberto Sordini", "Mirko Stumpo", "Nello Vertolli"], "title": "Conceptual framework for the application of deep neural networks to surface composition reconstruction from Mercury's exospheric data", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": "All versions of this article can be explored in the collection: DOI\n  https://doi.org/10.5281/zenodo.15394849 . This article is identical to v2.5\n  of the aforementioned collection: DOI https://doi.org/10.5281/zenodo.15425584", "summary": "Surface information derived from exospheric measurements at planetary bodies\ncomplements surface mapping provided by dedicated imagers, offering critical\ninsights into surface release processes, interactions within the planetary\nenvironment, space weathering, and planetary evolution. This study explores the\nfeasibility of deriving Mercury's regolith elemental composition from in-situ\nmeasurements of its neutral exosphere using deep neural networks (DNNs). We\npresent a supervised feed-forward DNN architecture - a multilayer perceptron\n(MLP) - that, starting from exospheric densities and proton precipitation\nfluxes, predicts the chemical elements of the surface regolith below. It serves\nas an estimator for the surface-exosphere interaction and the processes leading\nto exosphere formation. Because the DNN requires a comprehensive exospheric\ndataset not available from previous missions, this study uses simulated\nexosphere components and simulated drivers. Extensive training and testing\ncampaigns demonstrate the MLP's ability to accurately predict and reconstruct\nsurface composition maps from these simulated measurements. Although this\ninitial version does not aim to reproduce Mercury's actual surface composition,\nit provides a proof of concept, showcasing the algorithm's robustness and\ncapacity for handling complex datasets to create estimators for exospheric\ngeneration models. Moreover, our tests reveal substantial potential for further\ndevelopment, suggesting that this method could significantly enhance the\nanalysis of complex surface-exosphere interactions and complement planetary\nexosphere models. This work anticipates applying the approach to data from the\nBepiColombo mission, specifically the SERENA package, whose nominal phase\nbegins in 2027.", "AI": {"tldr": "A study uses deep neural networks (DNNs) to predict Mercury's regolith composition from exospheric measurements, demonstrating feasibility with simulated data and potential for future mission applications.", "motivation": "To explore the feasibility of deriving Mercury's surface composition from exospheric measurements, enhancing understanding of surface-exosphere interactions and planetary evolution.", "method": "A supervised feed-forward DNN (multilayer perceptron) is trained on simulated exospheric densities and proton precipitation fluxes to predict regolith elemental composition.", "result": "The DNN accurately predicts and reconstructs surface composition maps from simulated data, proving the method's robustness and potential for complex datasets.", "conclusion": "The study provides a proof of concept for using DNNs to analyze surface-exosphere interactions, with promising applications for future missions like BepiColombo."}}
{"id": "2505.06576", "pdf": "https://arxiv.org/pdf/2505.06576", "abs": "https://arxiv.org/abs/2505.06576", "authors": ["Haorui Chen", "Zeyu Ren", "Jiaxuan Ren", "Ran Ran", "Jinliang Shao", "Jie Huang", "Liangjian Deng"], "title": "Two-Stage Random Alternation Framework for One-Shot Pansharpening", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep learning has substantially advanced pansharpening, achieving impressive\nfusion quality. However, a prevalent limitation is that conventional deep\nlearning models, which typically rely on training datasets, often exhibit\nsuboptimal generalization to unseen real-world image pairs. This restricts\ntheir practical utility when faced with real-world scenarios not included in\nthe training datasets. To overcome this, we introduce a two-stage random\nalternating framework (TRA-PAN) that performs instance-specific optimization\nfor any given Multispectral(MS)/Panchromatic(PAN) pair, ensuring robust and\nhigh-quality fusion. TRA-PAN effectively integrates strong supervision\nconstraints from reduced-resolution images with the physical characteristics of\nthe full-resolution images. The first stage introduces a pre-training\nprocedure, which includes Degradation-Aware Modeling (DAM) to capture spectral\ndegradation mappings, alongside a warm-up procedure designed to reduce training\ntime and mitigate the adverse effects of reduced-resolution data. The second\nstage employs Random Alternation Optimization (RAO), randomly alternating\nbetween reduced- and full-resolution images to refine the fusion model\nprogressively. This adaptive, per-instance optimization strategy, operating in\na one-shot manner for each MS/PAN pair, yields superior high-resolution\nmultispectral images. Experimental results demonstrate that TRA-PAN outperforms\nstate-of-the-art (SOTA) methods in quantitative metrics and visual quality in\nreal-world scenarios, underscoring its enhanced practical applicability and\nrobustness.", "AI": {"tldr": "TRA-PAN introduces a two-stage framework for pansharpening, combining instance-specific optimization with strong supervision and physical constraints, outperforming SOTA methods.", "motivation": "Conventional deep learning models for pansharpening struggle with generalization to unseen real-world image pairs, limiting practical utility.", "method": "TRA-PAN uses a two-stage approach: pre-training with Degradation-Aware Modeling and warm-up, followed by Random Alternation Optimization for per-instance refinement.", "result": "TRA-PAN achieves superior fusion quality in real-world scenarios, outperforming existing methods in metrics and visual quality.", "conclusion": "TRA-PAN enhances practical applicability and robustness in pansharpening, addressing generalization issues of traditional models."}}
{"id": "2502.07279", "pdf": "https://arxiv.org/pdf/2502.07279", "abs": "https://arxiv.org/abs/2502.07279", "authors": ["Chengyang Ying", "Huayu Chen", "Xinning Zhou", "Zhongkai Hao", "Hang Su", "Jun Zhu"], "title": "Exploratory Diffusion Model for Unsupervised Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Unsupervised reinforcement learning (URL) aims to pre-train agents by\nexploring diverse states or skills in reward-free environments, facilitating\nefficient adaptation to downstream tasks. As the agent cannot access extrinsic\nrewards during unsupervised exploration, existing methods design intrinsic\nrewards to model the explored data and encourage further exploration. However,\nthe explored data are always heterogeneous, posing the requirements of powerful\nrepresentation abilities for both intrinsic reward models and pre-trained\npolicies. In this work, we propose the Exploratory Diffusion Model (ExDM),\nwhich leverages the strong expressive ability of diffusion models to fit the\nexplored data, simultaneously boosting exploration and providing an efficient\ninitialization for downstream tasks. Specifically, ExDM can accurately estimate\nthe distribution of collected data in the replay buffer with the diffusion\nmodel and introduces the score-based intrinsic reward, encouraging the agent to\nexplore less-visited states. After obtaining the pre-trained policies, ExDM\nenables rapid adaptation to downstream tasks. In detail, we provide theoretical\nanalyses and practical algorithms for fine-tuning diffusion policies,\naddressing key challenges such as training instability and computational\ncomplexity caused by multi-step sampling. Extensive experiments demonstrate\nthat ExDM outperforms existing SOTA baselines in efficient unsupervised\nexploration and fast fine-tuning downstream tasks, especially in structurally\ncomplicated environments.", "AI": {"tldr": "ExDM leverages diffusion models for unsupervised reinforcement learning, improving exploration and downstream task adaptation.", "motivation": "Existing methods struggle with heterogeneous explored data, requiring strong representation abilities. ExDM addresses this by using diffusion models.", "method": "ExDM fits explored data with a diffusion model, introduces a score-based intrinsic reward, and fine-tunes policies for downstream tasks.", "result": "ExDM outperforms SOTA baselines in exploration and downstream task adaptation, especially in complex environments.", "conclusion": "ExDM effectively combines diffusion models with reinforcement learning for superior unsupervised exploration and task adaptation."}}
{"id": "2505.11089", "pdf": "https://arxiv.org/pdf/2505.11089", "abs": "https://arxiv.org/abs/2505.11089", "authors": ["Yiran Yang", "Rui Chen"], "title": "Inexact Column Generation for Bayesian Network Structure Learning via Difference-of-Submodular Optimization", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "In this paper, we consider a score-based Integer Programming (IP) approach\nfor solving the Bayesian Network Structure Learning (BNSL) problem.\nState-of-the-art BNSL IP formulations suffer from the exponentially large\nnumber of variables and constraints. A standard approach in IP to address such\nchallenges is to employ row and column generation techniques, which dynamically\ngenerate rows and columns, while the complex pricing problem remains a\ncomputational bottleneck for BNSL. For the general class of $\\ell_0$-penalized\nlikelihood scores, we show how the pricing problem can be reformulated as a\ndifference of submodular optimization problem, and how the Difference of Convex\nAlgorithm (DCA) can be applied as an inexact method to efficiently solve the\npricing problems. Empirically, we show that, for continuous Gaussian data, our\nrow and column generation approach yields solutions with higher quality than\nstate-of-the-art score-based approaches, especially when the graph density\nincreases, and achieves comparable performance against benchmark\nconstraint-based and hybrid approaches, even when the graph size increases.", "AI": {"tldr": "A score-based IP approach for BNSL is proposed, addressing scalability via row/column generation and reformulating the pricing problem as a difference of submodular optimization, solved efficiently with DCA.", "motivation": "To overcome the computational bottleneck in state-of-the-art BNSL IP formulations caused by exponentially large variables/constraints.", "method": "Row and column generation techniques, with the pricing problem reformulated as a difference of submodular optimization and solved using DCA.", "result": "Higher solution quality for Gaussian data, especially with dense graphs, and comparable performance to benchmarks as graph size grows.", "conclusion": "The approach effectively addresses scalability and computational challenges in BNSL, outperforming score-based methods and matching benchmarks."}}
{"id": "2505.08197", "pdf": "https://arxiv.org/pdf/2505.08197", "abs": "https://arxiv.org/abs/2505.08197", "authors": ["Junxian Duan", "Jiyang Guan", "Wenkui Yang", "Ran He"], "title": "Visual Watermarking in the Era of Diffusion Models: Advances and Challenges", "categories": ["cs.CV"], "comment": null, "summary": "As generative artificial intelligence technologies like Stable Diffusion\nadvance, visual content becomes more vulnerable to misuse, raising concerns\nabout copyright infringement. Visual watermarks serve as effective protection\nmechanisms, asserting ownership and deterring unauthorized use. Traditional\ndeepfake detection methods often rely on passive techniques that struggle with\nsophisticated manipulations. In contrast, diffusion models enhance detection\naccuracy by allowing for the effective learning of features, enabling the\nembedding of imperceptible and robust watermarks. We analyze the strengths and\nchallenges of watermark techniques related to diffusion models, focusing on\ntheir robustness and application in watermark generation. By exploring the\nintegration of advanced diffusion models and watermarking security, we aim to\nadvance the discourse on preserving watermark robustness against evolving\nforgery threats. It emphasizes the critical importance of developing innovative\nsolutions to protect digital content and ensure the preservation of ownership\nrights in the era of generative AI.", "AI": {"tldr": "The paper discusses using diffusion models to enhance watermarking techniques for protecting digital content against misuse in generative AI.", "motivation": "Concerns about copyright infringement and misuse of visual content due to advancements in generative AI like Stable Diffusion.", "method": "Analyzes the integration of diffusion models for embedding imperceptible and robust watermarks, improving detection accuracy.", "result": "Highlights the strengths and challenges of watermark techniques in diffusion models, focusing on robustness and application.", "conclusion": "Emphasizes the need for innovative solutions to protect digital content and ownership rights in the generative AI era."}}
{"id": "2502.08021", "pdf": "https://arxiv.org/pdf/2502.08021", "abs": "https://arxiv.org/abs/2502.08021", "authors": ["Pai Liu", "Lingfeng Zhao", "Shivangi Agarwal", "Jinghan Liu", "Audrey Huang", "Philip Amortila", "Nan Jiang"], "title": "Model Selection for Off-policy Evaluation: New Algorithms and Experimental Protocol", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Holdout validation and hyperparameter tuning from data is a long-standing\nproblem in offline reinforcement learning (RL). A standard framework is to use\noff-policy evaluation (OPE) methods to evaluate and select the policies, but\nOPE either incurs exponential variance (e.g., importance sampling) or has\nhyperparameters on their own (e.g., FQE and model-based). In this work we focus\non hyperparameter tuning for OPE itself, which is even more under-investigated.\nConcretely, we select among candidate value functions (\"model-free\") or\ndynamics (\"model-based\") to best assess the performance of a target policy. We\ndevelop: (1) new model-free and model-based selectors with theoretical\nguarantees, and (2) a new experimental protocol for empirically evaluating\nthem. Compared to the model-free protocol in prior works, our new protocol\nallows for more stable generation and better control of candidate value\nfunctions in an optimization-free manner, and evaluation of model-free and\nmodel-based methods alike. We exemplify the protocol on Gym-Hopper, and find\nthat our new model-free selector, LSTD-Tournament, demonstrates promising\nempirical performance.", "AI": {"tldr": "The paper addresses hyperparameter tuning for off-policy evaluation (OPE) in offline RL, proposing new model-free and model-based selectors and a stable experimental protocol.", "motivation": "The challenge of hyperparameter tuning in OPE for offline RL, which lacks robust solutions due to high variance or dependency on hyperparameters.", "method": "Develops new model-free and model-based selectors with theoretical guarantees and introduces a new experimental protocol for stable evaluation.", "result": "The proposed model-free selector, LSTD-Tournament, shows promising performance in Gym-Hopper experiments.", "conclusion": "The work advances OPE in offline RL by improving hyperparameter tuning and evaluation stability."}}
{"id": "2505.11143", "pdf": "https://arxiv.org/pdf/2505.11143", "abs": "https://arxiv.org/abs/2505.11143", "authors": ["William R. P. Denault"], "title": "Nash: Neural Adaptive Shrinkage for Structured High-Dimensional Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Sparse linear regression is a fundamental tool in data analysis. However,\ntraditional approaches often fall short when covariates exhibit structure or\narise from heterogeneous sources. In biomedical applications, covariates may\nstem from distinct modalities or be structured according to an underlying\ngraph. We introduce Neural Adaptive Shrinkage (Nash), a unified framework that\nintegrates covariate-specific side information into sparse regression via\nneural networks. Nash adaptively modulates penalties on a per-covariate basis,\nlearning to tailor regularization without cross-validation. We develop a\nvariational inference algorithm for efficient training and establish\nconnections to empirical Bayes regression. Experiments on real data demonstrate\nthat Nash can improve accuracy and adaptability over existing methods.", "AI": {"tldr": "Nash is a neural network-based framework for sparse regression that uses covariate-specific side information to improve accuracy and adaptability.", "motivation": "Traditional sparse regression methods struggle with structured or heterogeneous covariates, especially in biomedical applications.", "method": "Neural Adaptive Shrinkage (Nash) integrates side information via neural networks, adaptively modulating penalties per covariate without cross-validation.", "result": "Nash improves accuracy and adaptability over existing methods, as shown in real data experiments.", "conclusion": "Nash provides a unified, efficient solution for structured sparse regression, outperforming traditional approaches."}}
{"id": "2505.09997", "pdf": "https://arxiv.org/pdf/2505.09997", "abs": "https://arxiv.org/abs/2505.09997", "authors": ["Jinhyun Jang", "Jiyoung Lee", "Kwanghoon Sohn"], "title": "Descriptive Image-Text Matching with Graded Contextual Similarity", "categories": ["cs.CV"], "comment": null, "summary": "Image-text matching aims to build correspondences between visual and textual\ndata by learning their pairwise similarities. Most existing approaches have\nadopted sparse binary supervision, indicating whether a pair of images and\nsentences matches or not. However, such sparse supervision covers a limited\nsubset of image-text relationships, neglecting their inherent many-to-many\ncorrespondences; an image can be described in numerous texts at different\ndescriptive levels. Moreover, existing approaches overlook the implicit\nconnections from general to specific descriptions, which form the underlying\nrationale for the many-to-many relationships between vision and language. In\nthis work, we propose descriptive image-text matching, called DITM, to learn\nthe graded contextual similarity between image and text by exploring the\ndescriptive flexibility of language. We formulate the descriptiveness score of\neach sentence with cumulative term frequency-inverse document frequency\n(TF-IDF) to balance the pairwise similarity according to the keywords in the\nsentence. Our method leverages sentence descriptiveness to learn robust\nimage-text matching in two key ways: (1) to refine the false negative labeling,\ndynamically relaxing the connectivity between positive and negative pairs, and\n(2) to build more precise matching, aligning a set of relevant sentences in a\ngeneric-to-specific order. By moving beyond rigid binary supervision, DITM\nenhances the discovery of both optimal matches and potential positive pairs.\nExtensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the\neffectiveness of our method in representing complex image-text relationships\ncompared to state-of-the-art approaches. In addition, DITM enhances the\nhierarchical reasoning ability of the model, supported by the extensive\nanalysis on HierarCaps benchmark.", "AI": {"tldr": "The paper introduces Descriptive Image-Text Matching (DITM) to address limitations of sparse binary supervision in image-text matching by learning graded contextual similarity and leveraging descriptive flexibility of language.", "motivation": "Existing approaches use sparse binary supervision, missing many-to-many image-text relationships and implicit connections from general to specific descriptions.", "method": "DITM uses cumulative TF-IDF to score sentence descriptiveness, refining false negatives and aligning sentences in a generic-to-specific order.", "result": "DITM outperforms state-of-the-art methods on MS-COCO, Flickr30K, and CxC datasets, improving hierarchical reasoning on HierarCaps.", "conclusion": "DITM advances image-text matching by capturing complex relationships and hierarchical reasoning, moving beyond rigid binary supervision."}}
{"id": "2502.08574", "pdf": "https://arxiv.org/pdf/2502.08574", "abs": "https://arxiv.org/abs/2502.08574", "authors": ["Zhikai Wu", "Sifan Wang", "Shiyang Zhang", "Sizhuang He", "Min Zhu", "Anran Jiao", "Lu Lu", "David van Dijk"], "title": "TANTE: Time-Adaptive Operator Learning via Neural Taylor Expansion", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 9 figures", "summary": "Operator learning for time-dependent partial differential equations (PDEs)\nhas seen rapid progress in recent years, enabling efficient approximation of\ncomplex spatiotemporal dynamics. However, most existing methods rely on fixed\ntime step sizes during rollout, which limits their ability to adapt to varying\ntemporal complexity and often leads to error accumulation. To address this gap,\nwe propose the Time-Adaptive Transformer with Neural Taylor Expansion (TANTE),\na novel operator-learning framework that produces continuous-time predictions\nwith adaptive step sizes. TANTE predicts future states by performing a Taylor\nexpansion at the current state, where neural networks learn both the\nhigher-order temporal derivatives and the local radius of convergence. This\nallows the model to dynamically adjust its rollout based on the local behavior\nof the solution, thereby reducing cumulative error and improving computational\nefficiency. We demonstrate the effectiveness of TANTE across a wide range of\nPDE benchmarks, achieving superior accuracy and adaptability compared to\nfixed-step baselines, delivering accuracy gains of 10-50 % and speed-ups of\n30-80 % at inference.", "AI": {"tldr": "TANTE is a novel operator-learning framework for time-dependent PDEs, using adaptive step sizes and neural Taylor expansion to improve accuracy and efficiency.", "motivation": "Existing methods for operator learning in PDEs use fixed time steps, leading to error accumulation and inefficiency in handling varying temporal complexity.", "method": "TANTE employs neural networks to learn higher-order temporal derivatives and local convergence radii, enabling dynamic step-size adjustment during rollout.", "result": "TANTE outperforms fixed-step methods, achieving 10-50% accuracy gains and 30-80% speed-ups in inference.", "conclusion": "TANTE offers a robust solution for adaptive operator learning in PDEs, balancing accuracy and computational efficiency."}}
{"id": "2505.10238", "pdf": "https://arxiv.org/pdf/2505.10238", "abs": "https://arxiv.org/abs/2505.10238", "authors": ["Yanbo Ding", "Xirui Hu", "Zhizhi Guo", "Yali Wang"], "title": "MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation", "categories": ["cs.CV"], "comment": null, "summary": "Human image animation has gained increasing attention and developed rapidly\ndue to its broad applications in digital humans. However, existing methods rely\nlargely on 2D-rendered pose images for motion guidance, which limits\ngeneralization and discards essential 3D information for open-world animation.\nTo tackle this problem, we propose MTVCrafter (Motion Tokenization Video\nCrafter), the first framework that directly models raw 3D motion sequences\n(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT\n(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.\nCompared to 2D-rendered pose images, 4D motion tokens offer more robust\nspatio-temporal cues and avoid strict pixel-level alignment between pose image\nand character, enabling more flexible and disentangled control. Then, we\nintroduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention\nwith 4D positional encodings, MV-DiT can effectively leverage motion tokens as\n4D compact yet expressive context for human image animation in the complex 3D\nworld. Hence, it marks a significant step forward in this field and opens a new\ndirection for pose-guided human video generation. Experiments show that our\nMTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,\nsurpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter\nalso generalizes well to diverse open-world characters (single/multiple,\nfull/half-body) across various styles and scenarios. Our video demos and code\nare on: https://github.com/DINGYANB/MTVCrafter.", "AI": {"tldr": "MTVCrafter introduces 4D motion tokenization for human image animation, outperforming 2D methods with better generalization and control.", "motivation": "Existing methods rely on 2D-rendered pose images, limiting generalization and discarding 3D information.", "method": "Proposes MTVCrafter with 4DMoT for motion tokenization and MV-DiT for motion-aware video generation.", "result": "Achieves state-of-the-art FID-VID of 6.98, surpassing others by 65%, and generalizes well to diverse characters.", "conclusion": "MTVCrafter advances human image animation by leveraging 4D motion, opening new directions for pose-guided video generation."}}
{"id": "2502.17773", "pdf": "https://arxiv.org/pdf/2502.17773", "abs": "https://arxiv.org/abs/2502.17773", "authors": ["Chengpiao Huang", "Yuhang Wu", "Kaizheng Wang"], "title": "Uncertainty Quantification for LLM-Based Survey Simulations", "categories": ["stat.ME", "cs.AI", "cs.LG"], "comment": "33 pages, 7 figures, 10 tables", "summary": "We investigate the use of large language models (LLMs) to simulate human\nresponses to survey questions, and perform uncertainty quantification to gain\nreliable insights. Our approach converts imperfect LLM-simulated responses into\nconfidence sets for population parameters of human responses, addressing the\ndistribution shift between the simulated and real populations. A key innovation\nlies in determining the optimal number of simulated responses: too many produce\noverly narrow confidence sets with poor coverage, while too few yield\nexcessively loose estimates. To resolve this, our method adaptively selects the\nsimulation sample size, ensuring valid average-case coverage guarantees. It is\nbroadly applicable to any LLM, irrespective of its fidelity, and any procedure\nfor constructing confidence sets. Additionally, the selected sample size\nquantifies the degree of misalignment between the LLM and the target human\npopulation. We illustrate our method on real datasets and LLMs.", "AI": {"tldr": "A method to use LLMs for simulating survey responses with uncertainty quantification, ensuring reliable insights by addressing distribution shifts and optimizing simulation sample size.", "motivation": "To leverage LLMs for simulating human survey responses while ensuring reliable and valid insights despite potential misalignment between simulated and real populations.", "method": "Adaptively selects the optimal number of simulated responses to balance coverage and precision, converting LLM outputs into confidence sets for human population parameters.", "result": "The method ensures valid average-case coverage guarantees and quantifies LLM-human misalignment, demonstrated on real datasets and LLMs.", "conclusion": "The approach provides a robust framework for using LLMs in survey simulation, addressing key challenges like distribution shift and sample size optimization."}}
{"id": "2505.11228", "pdf": "https://arxiv.org/pdf/2505.11228", "abs": "https://arxiv.org/abs/2505.11228", "authors": ["Derrick Gilchrist Edward Manoharan", "Anubha Goel", "Alexandros Iosifidis", "Henri Hansen", "Juho Kanniainen"], "title": "Learning hidden cascades via classification", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "The spreading dynamics in social networks are often studied under the\nassumption that individuals' statuses, whether informed or infected, are fully\nobservable. However, in many real-world situations, such statuses remain\nunobservable, which is crucial for determining an individual's potential to\nfurther spread the infection. While this final status is hidden, intermediate\nindicators such as symptoms of infection are observable and provide important\ninsights into the spread process. We propose a partial observability-aware\nMachine Learning framework to learn the characteristics of the spreading model.\nWe term the method Distribution Classification, which utilizes the power of\nclassifiers to infer the underlying transmission dynamics. We evaluate our\nmethod on two types of synthetic networks and extend the study to a real-world\ninsider trading network. Results show that the method performs well, especially\non complex networks with high cyclic connectivity, supporting its utility in\nanalyzing real-world spreading phenomena where direct observation of individual\nstatuses is not possible.", "AI": {"tldr": "A Machine Learning framework called Distribution Classification is proposed to infer spreading dynamics in networks where individual statuses are unobservable, using observable intermediate indicators.", "motivation": "Real-world spreading processes often lack full observability of individual statuses, necessitating methods to infer dynamics from partial data.", "method": "The proposed Distribution Classification method uses classifiers to learn transmission dynamics from observable indicators like symptoms.", "result": "The method performs well, especially in complex networks with high cyclic connectivity, and is validated on synthetic and real-world networks.", "conclusion": "The framework is effective for analyzing spreading phenomena where direct observation of individual statuses is unavailable."}}
{"id": "2410.15433", "pdf": "https://arxiv.org/pdf/2410.15433", "abs": "https://arxiv.org/abs/2410.15433", "authors": ["Jenelle Feather", "David Lipshutz", "Sarah E. Harvey", "Alex H. Williams", "Eero P. Simoncelli"], "title": "Discriminating image representations with principal distortions", "categories": ["q-bio.NC", "cs.CV", "cs.LG", "stat.ML"], "comment": null, "summary": "Image representations (artificial or biological) are often compared in terms\nof their global geometric structure; however, representations with similar\nglobal structure can have strikingly different local geometries. Here, we\npropose a framework for comparing a set of image representations in terms of\ntheir local geometries. We quantify the local geometry of a representation\nusing the Fisher information matrix, a standard statistical tool for\ncharacterizing the sensitivity to local stimulus distortions, and use this as a\nsubstrate for a metric on the local geometry in the vicinity of a base image.\nThis metric may then be used to optimally differentiate a set of models, by\nfinding a pair of \"principal distortions\" that maximize the variance of the\nmodels under this metric. As an example, we use this framework to compare a set\nof simple models of the early visual system, identifying a novel set of image\ndistortions that allow immediate comparison of the models by visual inspection.\nIn a second example, we apply our method to a set of deep neural network models\nand reveal differences in the local geometry that arise due to architecture and\ntraining types. These examples demonstrate how our framework can be used to\nprobe for informative differences in local sensitivities between complex\nmodels, and suggest how it could be used to compare model representations with\nhuman perception.", "AI": {"tldr": "A framework for comparing image representations by their local geometries using Fisher information matrices, applied to models of the early visual system and deep neural networks.", "motivation": "To address the limitation of comparing representations only by global structure, which can mask significant local geometric differences.", "method": "Quantify local geometry via Fisher information matrices, derive a metric for local geometry, and identify principal distortions to differentiate models.", "result": "Demonstrated differences in local geometries of early visual system models and deep neural networks, revealing model-specific sensitivities.", "conclusion": "The framework effectively identifies local geometric differences, aiding model comparison and potential alignment with human perception."}}
{"id": "2502.18002", "pdf": "https://arxiv.org/pdf/2502.18002", "abs": "https://arxiv.org/abs/2502.18002", "authors": ["Shlok Mehendale", "Aditya Challa", "Rahul Yedida", "Sravan Danda", "Santonu Sarkar", "Snehanshu Saha"], "title": "A Radon-Nikod\u00fdm Perspective on Anomaly Detection: Theory and Implications", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Which principle underpins the design of an effective anomaly detection loss\nfunction? The answer lies in the concept of Radon-Nikod\\'ym theorem, a\nfundamental concept in measure theory. The key insight from this article is:\nMultiplying the vanilla loss function with the Radon-Nikod\\'ym derivative\nimproves the performance across the board. We refer to this as RN-Loss. We\nprove this using the setting of PAC (Probably Approximately Correct)\nlearnability.\n  Depending on the context a Radon-Nikod\\'ym derivative takes different forms.\nIn the simplest case of supervised anomaly detection, Radon-Nikod\\'ym\nderivative takes the form of a simple weighted loss. In the case of\nunsupervised anomaly detection (with distributional assumptions),\nRadon-Nikod\\'ym derivative takes the form of the popular cluster based local\noutlier factor. We evaluate our algorithm on 96 datasets, including univariate\nand multivariate data from diverse domains, including healthcare,\ncybersecurity, and finance. We show that RN-Derivative algorithms outperform\nstate-of-the-art methods on 68% of Multivariate datasets (based on F1 scores)\nand also achieves peak F1-scores on 72% of time series (Univariate) datasets.", "AI": {"tldr": "The paper introduces RN-Loss, a loss function for anomaly detection based on the Radon-Nikod\u00fdm theorem, improving performance across datasets.", "motivation": "To enhance anomaly detection by leveraging the Radon-Nikod\u00fdm theorem for loss function design.", "method": "Multiply the vanilla loss function with the Radon-Nikod\u00fdm derivative, adapting it for supervised and unsupervised settings.", "result": "RN-Loss outperforms state-of-the-art methods on 68% of multivariate and 72% of univariate datasets.", "conclusion": "RN-Loss, grounded in measure theory, significantly improves anomaly detection performance."}}
{"id": "2505.11259", "pdf": "https://arxiv.org/pdf/2505.11259", "abs": "https://arxiv.org/abs/2505.11259", "authors": ["Gabriele Iommazzo", "David Mart\u00ednez-Rubio", "Francisco Criado", "Elias Wirth", "Sebastian Pokutta"], "title": "Linear Convergence of the Frank-Wolfe Algorithm over Product Polytopes", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "We study the linear convergence of Frank-Wolfe algorithms over product\npolytopes. We analyze two condition numbers for the product polytope, namely\nthe \\emph{pyramidal width} and the \\emph{vertex-facet distance}, based on the\ncondition numbers of individual polytope components. As a result, for convex\nobjectives that are $\\mu$-Polyak-{\\L}ojasiewicz, we show linear convergence\nrates quantified in terms of the resulting condition numbers. We apply our\nresults to the problem of approximately finding a feasible point in a polytope\nintersection in high-dimensions, and demonstrate the practical efficiency of\nour algorithms through empirical results.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2411.09263", "pdf": "https://arxiv.org/pdf/2411.09263", "abs": "https://arxiv.org/abs/2411.09263", "authors": ["Hu Wang", "Congbo Ma", "Ibrahim Almakky", "Ian Reid", "Gustavo Carneiro", "Mohammad Yaqub"], "title": "Rethinking Weight-Averaged Model-merging", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Model-merging has emerged as a powerful approach in deep learning, capable of\nenhancing model performance without any training. However, the underlying\nmechanisms that explain its effectiveness remain largely unexplored. In this\npaper, we investigate this technique from three novel perspectives to\nempirically provide deeper insights into why and how weight-averaged\nmodel-merging~\\cite{wortsman2022soups} works: (1) we examine the intrinsic\npatterns captured by the learning of the model weights, and we are the first to\nconnect that these weights encode structured with why weight-averaged model\nmerging can work; (2) we investigate averaging on weights versus averaging on\nfeatures, providing analyses from the view of diverse architecture comparisons\non multiple datasets; and (3) we explore the impact on model-merging prediction\nstability in terms of changing the parameter magnitude, revealing insights into\nthe way of weight averaging works as regularization by showing the robustness\nacross different parameter scales. The code is available at\nhttps://github.com/billhhh/Rethink-Merge.", "AI": {"tldr": "The paper explores why weight-averaged model-merging works in deep learning, analyzing intrinsic weight patterns, comparing weight vs. feature averaging, and examining prediction stability.", "motivation": "To understand the underlying mechanisms of model-merging, which enhances performance without training, but lacks clear explanations.", "method": "Investigates model-merging from three perspectives: intrinsic weight patterns, weight vs. feature averaging, and prediction stability across parameter scales.", "result": "Provides empirical insights into weight-averaged model-merging, connecting weight structures to its effectiveness and showing robustness across parameter scales.", "conclusion": "The study deepens understanding of model-merging, revealing its regularization-like effects and practical implications for deep learning."}}
{"id": "2503.05760", "pdf": "https://arxiv.org/pdf/2503.05760", "abs": "https://arxiv.org/abs/2503.05760", "authors": ["Gokul Puthumanaillam", "Timothy Bretl", "Melkior Ornik"], "title": "The Lazy Student's Dream: ChatGPT Passing an Engineering Course on Its Own", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "This paper presents a comprehensive investigation into the capability of\nLarge Language Models (LLMs) to successfully complete a semester-long\nundergraduate control systems course. Through evaluation of 115 course\ndeliverables, we assess LLM performance using ChatGPT under a \"minimal effort\"\nprotocol that simulates realistic student usage patterns. The investigation\nemploys a rigorous testing methodology across multiple assessment formats, from\nauto-graded multiple choice questions to complex Python programming tasks and\nlong-form analytical writing. Our analysis provides quantitative insights into\nAI's strengths and limitations in handling mathematical formulations, coding\nchallenges, and theoretical concepts in control systems engineering. The LLM\nachieved a B-grade performance (82.24\\%), approaching but not exceeding the\nclass average (84.99\\%), with strongest results in structured assignments and\ngreatest limitations in open-ended projects. The findings inform discussions\nabout course design adaptation in response to AI advancement, moving beyond\nsimple prohibition towards thoughtful integration of these tools in engineering\neducation. Additional materials including syllabus, examination papers, design\nprojects, and example responses can be found at the project website:\nhttps://gradegpt.github.io.", "AI": {"tldr": "LLMs like ChatGPT were tested in a control systems course, achieving a B-grade (82.24%) but falling slightly below the class average (84.99%). Strengths were in structured tasks, while open-ended projects posed challenges.", "motivation": "To evaluate LLM capabilities in a real-world academic setting and inform how engineering education can adapt to AI advancements.", "method": "Assessed 115 course deliverables using ChatGPT under a \"minimal effort\" protocol, covering multiple assessment formats (multiple choice, coding, writing).", "result": "LLM scored 82.24%, excelling in structured tasks but struggling with open-ended projects.", "conclusion": "Findings suggest a need for thoughtful integration of AI tools in education, moving beyond prohibition to adapt course design."}}
{"id": "2505.11281", "pdf": "https://arxiv.org/pdf/2505.11281", "abs": "https://arxiv.org/abs/2505.11281", "authors": ["Yuejiang Wen", "Paul D. Franzon"], "title": "Adaptive Linear Embedding for Nonstationary High-Dimensional Optimization", "categories": ["stat.ML", "cs.LG"], "comment": "working, to be submitted", "summary": "Bayesian Optimization (BO) in high-dimensional spaces remains fundamentally\nlimited by the curse of dimensionality and the rigidity of global\nlow-dimensional assumptions. While Random EMbedding Bayesian Optimization\n(REMBO) mitigates this via linear projections into low-dimensional subspaces,\nit typically assumes a single global embedding and a stationary objective. In\nthis work, we introduce Self-Adaptive embedding REMBO (SA-REMBO), a novel\nframework that generalizes REMBO to support multiple random Gaussian\nembeddings, each capturing a different local subspace structure of the\nhigh-dimensional objective. An index variable governs the embedding choice and\nis jointly modeled with the latent optimization variable via a product kernel\nin a Gaussian Process surrogate. This enables the optimizer to adaptively\nselect embeddings conditioned on location, effectively capturing locally\nvarying effective dimensionality, nonstationarity, and heteroscedasticity in\nthe objective landscape. We theoretically analyze the expressiveness and\nstability of the index-conditioned product kernel and empirically demonstrate\nthe advantage of our method across synthetic and real-world high-dimensional\nbenchmarks, where traditional REMBO and other low-rank BO methods fail. Our\nresults establish SA-REMBO as a powerful and flexible extension for scalable BO\nin complex, structured design spaces.", "AI": {"tldr": "SA-REMBO extends REMBO by using multiple local embeddings to handle high-dimensional BO, outperforming traditional methods.", "motivation": "High-dimensional BO is limited by dimensionality and rigid global assumptions. REMBO's single embedding is insufficient for complex objectives.", "method": "SA-REMBO introduces multiple Gaussian embeddings, jointly modeled with an index variable via a product kernel in a GP surrogate.", "result": "SA-REMBO outperforms REMBO and other low-rank BO methods in synthetic and real-world benchmarks.", "conclusion": "SA-REMBO is a flexible and scalable solution for high-dimensional BO in complex design spaces."}}
{"id": "2411.18440", "pdf": "https://arxiv.org/pdf/2411.18440", "abs": "https://arxiv.org/abs/2411.18440", "authors": ["Andrew Lizarraga", "Eric Hanchen Jiang", "Jacob Nowack", "Yun Qi Li", "Ying Nian Wu", "Bernie Boscoe", "Tuan Do"], "title": "Understanding Galaxy Morphology Evolution Through Cosmic Time via Redshift Conditioned Diffusion Models", "categories": ["astro-ph.GA", "cs.CV"], "comment": null, "summary": "Redshift measures the distance to galaxies and underlies our understanding of\nthe origin of the Universe and galaxy evolution. Spectroscopic redshift is the\ngold-standard method for measuring redshift, but it requires about $1000$ times\nmore telescope time than broad-band imaging. That extra cost limits sky\ncoverage and sample size and puts large spectroscopic surveys out of reach.\nPhotometric redshift methods rely on imaging in multiple color filters and\ntemplate fitting, yet they ignore the wealth of information carried by galaxy\nshape and structure. We demonstrate that a diffusion model conditioned on\ncontinuous redshift learns this missing joint structure, reproduces known\nmorphology-$z$ correlations. We verify on the HyperSuprime-Cam survey, that the\nmodel captures redshift-dependent trends in ellipticity, semi-major axis,\nS\\'ersic index, and isophotal area that these generated images correlate\nclosely with true redshifts on test data. To our knowledge this is the first\nstudy to establish a direct link between galaxy morphology and redshift. Our\napproach offers a simple and effective path to redshift estimation from imaging\ndata and will help unlock the full potential of upcoming wide-field surveys.", "AI": {"tldr": "A diffusion model leverages galaxy morphology to estimate redshift, offering a cost-effective alternative to spectroscopic methods.", "motivation": "Spectroscopic redshift is accurate but costly, limiting large surveys. Photometric methods ignore galaxy shape/structure, missing valuable redshift clues.", "method": "A diffusion model is conditioned on continuous redshift to learn and reproduce morphology-redshift correlations using imaging data.", "result": "The model captures redshift-dependent trends in galaxy features (e.g., ellipticity, S\u00e9rsic index) and correlates well with true redshifts in tests.", "conclusion": "This first direct link between morphology and redshift enables simpler, effective redshift estimation, enhancing future wide-field surveys."}}
{"id": "2504.04973", "pdf": "https://arxiv.org/pdf/2504.04973", "abs": "https://arxiv.org/abs/2504.04973", "authors": ["Qian Zuo", "Fengxiang He"], "title": "Ensuring Safety in an Uncertain Environment: Constrained MDPs via Stochastic Thresholds", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "This paper studies constrained Markov decision processes (CMDPs) with\nconstraints against stochastic thresholds, aiming at the safety of\nreinforcement learning in unknown and uncertain environments. We leverage a\nGrowing-Window estimator sampling from interactions with the uncertain and\ndynamic environment to estimate the thresholds, based on which we design\nStochastic Pessimistic-Optimistic Thresholding (SPOT), a novel model-based\nprimal-dual algorithm for multiple constraints against stochastic thresholds.\nSPOT enables reinforcement learning under both pessimistic and optimistic\nthreshold settings. We prove that our algorithm achieves sublinear regret and\nconstraint violation; i.e., a reward regret of $\\tilde{\\mathcal{O}}(\\sqrt{T})$\nwhile allowing an $\\tilde{\\mathcal{O}}(\\sqrt{T})$ constraint violation over $T$\nepisodes. The theoretical guarantees show that our algorithm achieves\nperformance comparable to that of an approach relying on fixed and clear\nthresholds. To the best of our knowledge, SPOT is the first reinforcement\nlearning algorithm that realises theoretical guaranteed performance in an\nuncertain environment where even thresholds are unknown.", "AI": {"tldr": "The paper introduces SPOT, a model-based primal-dual algorithm for CMDPs with stochastic thresholds, ensuring safety in uncertain environments. It achieves sublinear regret and constraint violation.", "motivation": "To address safety in reinforcement learning under unknown and uncertain environments with stochastic thresholds.", "method": "Uses a Growing-Window estimator and designs SPOT, a primal-dual algorithm for multiple constraints against stochastic thresholds.", "result": "Achieves sublinear regret ($\\tilde{\\mathcal{O}}(\\sqrt{T})$) and constraint violation ($\\tilde{\\mathcal{O}}(\\sqrt{T})$).", "conclusion": "SPOT is the first RL algorithm with theoretical guarantees for uncertain environments with unknown thresholds."}}
{"id": "2505.11318", "pdf": "https://arxiv.org/pdf/2505.11318", "abs": "https://arxiv.org/abs/2505.11318", "authors": ["Donald Loveland", "Mingxuan Ju", "Tong Zhao", "Neil Shah", "Danai Koutra"], "title": "On the Role of Weight Decay in Collaborative Filtering: A Popularity Perspective", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted at SIGKDD 2025", "summary": "Collaborative filtering (CF) enables large-scale recommendation systems by\nencoding information from historical user-item interactions into dense\nID-embedding tables. However, as embedding tables grow, closed-form solutions\nbecome impractical, often necessitating the use of mini-batch gradient descent\nfor training. Despite extensive work on designing loss functions to train CF\nmodels, we argue that one core component of these pipelines is heavily\noverlooked: weight decay. Attaining high-performing models typically requires\ncareful tuning of weight decay, regardless of loss, yet its necessity is not\nwell understood. In this work, we question why weight decay is crucial in CF\npipelines and how it impacts training. Through theoretical and empirical\nanalysis, we surprisingly uncover that weight decay's primary function is to\nencode popularity information into the magnitudes of the embedding vectors.\nMoreover, we find that tuning weight decay acts as a coarse, non-linear knob to\ninfluence preference towards popular or unpopular items. Based on these\nfindings, we propose PRISM (Popularity-awaRe Initialization Strategy for\nembedding Magnitudes), a straightforward yet effective solution to simplify the\ntraining of high-performing CF models. PRISM pre-encodes the popularity\ninformation typically learned through weight decay, eliminating its necessity.\nOur experiments show that PRISM improves performance by up to 4.77% and reduces\ntraining times by 38.48%, compared to state-of-the-art training strategies.\nAdditionally, we parameterize PRISM to modulate the initialization strength,\noffering a cost-effective and meaningful strategy to mitigate popularity bias.", "AI": {"tldr": "The paper investigates the role of weight decay in collaborative filtering (CF) pipelines, revealing its function in encoding popularity information into embedding vectors. It introduces PRISM, a method to pre-encode popularity, improving performance and reducing training time.", "motivation": "Weight decay is crucial in CF but poorly understood. The study aims to clarify its role and impact on training.", "method": "Theoretical and empirical analysis of weight decay's function, leading to the development of PRISM, which pre-encodes popularity information.", "result": "PRISM improves performance by up to 4.77% and reduces training time by 38.48%, while mitigating popularity bias.", "conclusion": "PRISM simplifies CF training by eliminating the need for weight decay, offering a cost-effective solution with significant performance gains."}}
{"id": "2503.06991", "pdf": "https://arxiv.org/pdf/2503.06991", "abs": "https://arxiv.org/abs/2503.06991", "authors": ["Yongwoo Kim", "Sungmin Cha", "Donghyun Kim"], "title": "Are We Truly Forgetting? A Critical Re-examination of Machine Unlearning Evaluation Protocols", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Machine unlearning is a process to remove specific data points from a trained\nmodel while maintaining the performance on retain data, addressing privacy or\nlegal requirements. Despite its importance, existing unlearning evaluations\ntend to focus on logit-based metrics (i.e., accuracy) under small-scale\nscenarios. We observe that this could lead to a false sense of security in\nunlearning approaches under real-world scenarios. In this paper, we conduct a\nnew comprehensive evaluation that employs representation-based evaluations of\nthe unlearned model under large-scale scenarios to verify whether the\nunlearning approaches genuinely eliminate the targeted forget data from the\nmodel's representation perspective. Our analysis reveals that current\nstate-of-the-art unlearning approaches either completely degrade the\nrepresentational quality of the unlearned model or merely modify the classifier\n(i.e., the last layer), thereby achieving superior logit-based evaluation\nmetrics while maintaining significant representational similarity to the\noriginal model. Furthermore, we introduce a rigorous unlearning evaluation\nsetup, in which the forgetting classes exhibit semantic similarity to\ndownstream task classes, necessitating that feature representations diverge\nsignificantly from those of the original model, thus enabling a more rigorous\nevaluation from a representation perspective. We hope our benchmark serves as a\nstandardized protocol for evaluating unlearning algorithms under realistic\nconditions.", "AI": {"tldr": "The paper critiques current machine unlearning evaluations for relying too much on logit-based metrics and introduces a comprehensive, representation-based evaluation under large-scale scenarios to ensure genuine data removal.", "motivation": "Address the limitations of existing unlearning evaluations, which may falsely assure security by focusing on small-scale, logit-based metrics, and propose a more rigorous assessment from a representation perspective.", "method": "Conduct a new evaluation using representation-based metrics under large-scale scenarios, focusing on whether unlearning truly removes targeted data from the model's representations.", "result": "Current unlearning methods either degrade model quality or only modify the classifier, maintaining representational similarity to the original model despite superior logit-based metrics.", "conclusion": "The paper proposes a standardized, rigorous evaluation setup for unlearning algorithms, emphasizing representation divergence to ensure realistic and effective unlearning."}}
{"id": "2504.11358", "pdf": "https://arxiv.org/pdf/2504.11358", "abs": "https://arxiv.org/abs/2504.11358", "authors": ["Yupei Liu", "Yuqi Jia", "Jinyuan Jia", "Dawn Song", "Neil Zhenqiang Gong"], "title": "DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks", "categories": ["cs.CR", "cs.AI"], "comment": "Distinguished Paper Award in IEEE Symposium on Security and Privacy,\n  2025", "summary": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, where an attacker injects prompts into their inputs to induce\nattacker-desired outputs. A detection method aims to determine whether a given\ninput is contaminated by an injected prompt. However, existing detection\nmethods have limited effectiveness against state-of-the-art attacks, let alone\nadaptive ones. In this work, we propose DataSentinel, a game-theoretic method\nto detect prompt injection attacks. Specifically, DataSentinel fine-tunes an\nLLM to detect inputs contaminated with injected prompts that are strategically\nadapted to evade detection. We formulate this as a minimax optimization\nproblem, with the objective of fine-tuning the LLM to detect strong adaptive\nattacks. Furthermore, we propose a gradient-based method to solve the minimax\noptimization problem by alternating between the inner max and outer min\nproblems. Our evaluation results on multiple benchmark datasets and LLMs show\nthat DataSentinel effectively detects both existing and adaptive prompt\ninjection attacks.", "AI": {"tldr": "DataSentinel is a game-theoretic method to detect prompt injection attacks in LLMs by fine-tuning an LLM to strategically adapt and detect such attacks.", "motivation": "Existing detection methods for prompt injection attacks in LLMs are ineffective against advanced and adaptive attacks, necessitating a more robust solution.", "method": "DataSentinel formulates detection as a minimax optimization problem, fine-tuning an LLM to detect strategically adapted attacks using a gradient-based alternating approach.", "result": "Evaluation on benchmark datasets and LLMs shows DataSentinel effectively detects both existing and adaptive prompt injection attacks.", "conclusion": "DataSentinel provides a robust solution for detecting prompt injection attacks, outperforming existing methods."}}
{"id": "2505.11323", "pdf": "https://arxiv.org/pdf/2505.11323", "abs": "https://arxiv.org/abs/2505.11323", "authors": ["Haowei Wang", "Jingyi Wang", "Zhongxiang Dai", "Nai-Yuan Chiang", "Szu Hui Ng", "Cosmin G. Petra"], "title": "Convergence Rates of Constrained Expected Improvement", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Constrained Bayesian optimization (CBO) methods have seen significant success\nin black-box optimization with constraints, and one of the most commonly used\nCBO methods is the constrained expected improvement (CEI) algorithm. CEI is a\nnatural extension of the expected improvement (EI) when constraints are\nincorporated. However, the theoretical convergence rate of CEI has not been\nestablished. In this work, we study the convergence rate of CEI by analyzing\nits simple regret upper bound. First, we show that when the objective function\n$f$ and constraint function $c$ are assumed to each lie in a reproducing kernel\nHilbert space (RKHS), CEI achieves the convergence rates of $\\mathcal{O}\n\\left(t^{-\\frac{1}{2}}\\log^{\\frac{d+1}{2}}(t) \\right) \\ \\text{and }\\\n\\mathcal{O}\\left(t^{\\frac{-\\nu}{2\\nu+d}} \\log^{\\frac{\\nu}{2\\nu+d}}(t)\\right)$\nfor the commonly used squared exponential and Mat\\'{e}rn kernels, respectively.\nSecond, we show that when $f$ and $c$ are assumed to be sampled from Gaussian\nprocesses (GPs), CEI achieves the same convergence rates with a high\nprobability. Numerical experiments are performed to validate the theoretical\nanalysis.", "AI": {"tldr": "The paper analyzes the convergence rate of the constrained expected improvement (CEI) algorithm in Bayesian optimization, proving theoretical bounds for RKHS and GP assumptions.", "motivation": "To establish the theoretical convergence rate of CEI, which lacks prior analysis despite its widespread use in constrained Bayesian optimization.", "method": "Analyzes CEI's simple regret upper bound under two assumptions: functions lying in RKHS and sampled from GPs.", "result": "CEI achieves specific convergence rates for squared exponential and Mat\u00e9rn kernels, validated numerically.", "conclusion": "The study provides theoretical guarantees for CEI's performance, supporting its practical use in constrained optimization."}}
{"id": "2503.07851", "pdf": "https://arxiv.org/pdf/2503.07851", "abs": "https://arxiv.org/abs/2503.07851", "authors": ["Guillaume Qu\u00e9tant", "Pavlo Molchanov", "Slava Voloshynovskiy"], "title": "TwinTURBO: Semi-Supervised Fine-Tuning of Foundation Models via Mutual Information Decompositions for Downstream Task and Latent Spaces", "categories": ["cs.LG", "cs.CV", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "We present a semi-supervised fine-tuning framework for foundation models that\nutilises mutual information decomposition to address the challenges of training\nfor a limited amount of labelled data. Our approach derives two distinct lower\nbounds: i) for the downstream task space, such as classification, optimised\nusing conditional and marginal cross-entropy alongside Kullback-Leibler\ndivergence, and ii) for the latent space representation, regularised and\naligned using a contrastive-like decomposition. This fine-tuning strategy\nretains the pre-trained structure of the foundation model, modifying only a\nspecialised projector module comprising a small transformer and a token\naggregation technique. Experiments on several datasets demonstrate significant\nimprovements in classification tasks under extremely low-labelled conditions by\neffectively leveraging unlabelled data.", "AI": {"tldr": "A semi-supervised fine-tuning framework for foundation models uses mutual information decomposition to improve performance with limited labeled data.", "motivation": "Addressing the challenge of training with scarce labeled data by leveraging unlabeled data effectively.", "method": "Derives two lower bounds: one for downstream tasks (e.g., classification) using cross-entropy and KL divergence, and another for latent space representation with contrastive-like decomposition. Uses a specialized projector module to retain pre-trained structure.", "result": "Significant improvements in classification tasks under low-labeled conditions.", "conclusion": "The framework effectively leverages unlabeled data to enhance performance in scenarios with limited labeled data."}}
{"id": "2504.12721", "pdf": "https://arxiv.org/pdf/2504.12721", "abs": "https://arxiv.org/abs/2504.12721", "authors": ["Yihang Lu", "Yangyang Xu", "Qitao Qing", "Xianwei Meng"], "title": "TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series Forecasting with Compressed Predictive Representations", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Recent deep learning models for Long-term Time Series Forecasting (LTSF)\noften emphasize complex, handcrafted designs, while simpler architectures like\nlinear models or MLPs have often outperformed these intricate solutions. In\nthis paper, we revisit and organize the core ideas behind several key\ntechniques, such as redundancy reduction and multi-scale modeling, which are\nfrequently employed in advanced LTSF models. Our goal is to streamline these\nideas for more efficient deep learning utilization. To this end, we introduce\nTimeCapsule, a model built around the principle of high-dimensional information\ncompression that unifies these techniques in a generalized yet simplified\nframework. Specifically, we model time series as a 3D tensor, incorporating\ntemporal, variate, and level dimensions, and leverage mode production to\ncapture multi-mode dependencies while achieving dimensionality compression. We\npropose an internal forecast within the compressed representation domain,\nsupported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the\nlearning of predictive representations. Extensive experiments on challenging\nbenchmarks demonstrate the versatility of our method, showing that TimeCapsule\ncan achieve state-of-the-art performance.", "AI": {"tldr": "TimeCapsule simplifies LTSF by unifying redundancy reduction and multi-scale modeling in a 3D tensor framework, achieving state-of-the-art results.", "motivation": "Complex LTSF models are often outperformed by simpler ones; the paper aims to streamline advanced techniques for efficiency.", "method": "Introduces TimeCapsule, a model using 3D tensors and mode production for multi-mode dependencies and dimensionality compression, with JEPA for predictive representation.", "result": "TimeCapsule achieves state-of-the-art performance on benchmarks.", "conclusion": "Simplified yet generalized frameworks like TimeCapsule can outperform complex LTSF models."}}
{"id": "2505.11329", "pdf": "https://arxiv.org/pdf/2505.11329", "abs": "https://arxiv.org/abs/2505.11329", "authors": ["Raja Gond", "Nipun Kwatra", "Ramachandran Ramjee"], "title": "TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference", "categories": ["cs.DC", "cs.LG"], "comment": "13 pages, 15 figures", "summary": "Distributed inference of large language models (LLMs) can introduce overheads\nof up to 20% even over GPUs connected via high-speed interconnects such as\nNVLINK. Multiple techniques have been proposed to mitigate these overheads by\ndecomposing computations into finer-grained tasks and overlapping communication\nwith sub-tasks as they complete. However, fine-grained decomposition of a large\ncomputation into many smaller computations on GPUs results in overheads.\nFurther, the communication itself uses many streaming multiprocessors (SMs),\nadding to the overhead.\n  We present TokenWeave to address these challenges. TokenWeave proposes a\nToken-Splitting technique that divides the tokens in the inference batch into\ntwo approximately equal subsets in a wave-aware manner. The computation of one\nsubset is then overlapped with the communication of the other. In addition,\nTokenWeave optimizes the order of the layer normalization computation with\nrespect to communication operations and implements a novel fused\nAllReduce-RMSNorm kernel carefully leveraging Multimem instruction support\navailable on NVIDIA Hopper GPUs. These optimizations allow TokenWeave to\nperform communication and RMSNorm using only 2-8 SMs. Moreover, our kernel\nenables the memory bound RMSNorm to be overlapped with the other batch's\ncomputation, providing additional gains. Our evaluations demonstrate up to 29%\nlatency gains and up to 26% throughput gains across multiple models and\nworkloads. In several settings, TokenWeave results in better performance\ncompared to an equivalent model with all communication removed.", "AI": {"tldr": "TokenWeave reduces overheads in distributed LLM inference by splitting tokens into subsets, overlapping computation and communication, and optimizing layer normalization, achieving up to 29% latency and 26% throughput gains.", "motivation": "Distributed LLM inference suffers from overheads due to fine-grained task decomposition and communication using many SMs. TokenWeave aims to mitigate these inefficiencies.", "method": "TokenWeave splits tokens into subsets for overlapping computation and communication, optimizes layer normalization order, and implements a fused AllReduce-RMSNorm kernel leveraging NVIDIA Hopper GPUs.", "result": "TokenWeave achieves up to 29% latency reduction and 26% throughput improvement, outperforming models without communication in some cases.", "conclusion": "TokenWeave effectively reduces overheads in distributed LLM inference, demonstrating significant performance gains through innovative token-splitting and kernel optimization."}}
{"id": "2503.11020", "pdf": "https://arxiv.org/pdf/2503.11020", "abs": "https://arxiv.org/abs/2503.11020", "authors": ["Ruochen Hou", "Mingzhang Zhu", "Hyunwoo Nam", "Gabriel I. Fernandez", "Dennis W. Hong"], "title": "Fast and Robust Localization for Humanoid Soccer Robot via Iterative Landmark Matching", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Accurate robot localization is essential for effective operation. Monte Carlo\nLocalization (MCL) is commonly used with known maps but is computationally\nexpensive due to landmark matching for each particle. Humanoid robots face\nadditional challenges, including sensor noise from locomotion vibrations and a\nlimited field of view (FOV) due to camera placement. This paper proposes a fast\nand robust localization method via iterative landmark matching (ILM) for\nhumanoid robots. The iterative matching process improves the accuracy of the\nlandmark association so that it does not need MCL to match landmarks to\nparticles. Pose estimation with the outlier removal process enhances its\nrobustness to measurement noise and faulty detections. Furthermore, an\nadditional filter can be utilized to fuse inertial data from the inertial\nmeasurement unit (IMU) and pose data from localization. We compared ILM with\nIterative Closest Point (ICP), which shows that ILM method is more robust\ntowards the error in the initial guess and easier to get a correct matching. We\nalso compared ILM with the Augmented Monte Carlo Localization (aMCL), which\nshows that ILM method is much faster than aMCL and even more accurate. The\nproposed method's effectiveness is thoroughly evaluated through experiments and\nvalidated on the humanoid robot ARTEMIS during RoboCup 2024 adult-sized soccer\ncompetition.", "AI": {"tldr": "The paper proposes a fast and robust localization method (ILM) for humanoid robots, outperforming MCL and ICP in speed and accuracy.", "motivation": "Humanoid robots face challenges like sensor noise and limited FOV, making accurate localization difficult with traditional methods like MCL.", "method": "The ILM method uses iterative landmark matching and outlier removal for robust pose estimation, optionally fusing IMU data.", "result": "ILM is faster and more accurate than aMCL and more robust than ICP, validated in RoboCup 2024.", "conclusion": "ILM is an effective solution for humanoid robot localization, addressing computational cost and robustness issues."}}
{"id": "2504.13986", "pdf": "https://arxiv.org/pdf/2504.13986", "abs": "https://arxiv.org/abs/2504.13986", "authors": ["Paolo Liberatore"], "title": "Forgetting in short and heterogeneous sequences of belief revisions", "categories": ["cs.CC", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2402.15445,\n  arXiv:2305.09200", "summary": "Forgetting a specific belief revision episode may not erase information\nbecause the other revisions may provide or entail the same information. Whether\nit does was proved coNP-hard for sequences of two arbitrary lexicographic\nrevisions or arbitrarily long lexicographic Horn revisions. A polynomial\nalgorithm is presented for the case of two lexicographic Horn revision.\nHeterogeneous sequences, including revisions other than lexicographic, were\nproved to belong in Delta2. Their previously proved coNP-hardness is enhanced\nto Dp-hardness.", "AI": {"tldr": "Forgetting a belief revision episode may not erase info due to overlapping revisions. Complexity varies: coNP-hard for some cases, polynomial for others, and Dp-hardness for heterogeneous sequences.", "motivation": "To understand the impact of forgetting specific belief revision episodes and the computational complexity involved in such scenarios.", "method": "Analyzes sequences of lexicographic and Horn revisions, proving complexity results (coNP-hard, polynomial, Dp-hardness) for different cases.", "result": "Forgetting may not erase info; complexity ranges from polynomial to Dp-hardness depending on revision types and sequence length.", "conclusion": "The study highlights varying computational complexities in belief revision, with implications for algorithm design and theoretical understanding."}}
{"id": "2505.11343", "pdf": "https://arxiv.org/pdf/2505.11343", "abs": "https://arxiv.org/abs/2505.11343", "authors": ["Rajeeva Laxman Karandikar", "Bhamidi Visweswara Rao", "Mathukumalli Vidyasagar"], "title": "Revisiting Stochastic Approximation and Stochastic Gradient Descent", "categories": ["math.OC", "cs.LG", "stat.ML", "62L20, 60G17, 93D05"], "comment": "22 pages", "summary": "In this paper, we take a fresh look at stochastic approximation (SA) and\nStochastic Gradient Descent (SGD). We derive new sufficient conditions for the\nconvergence of SA. In particular, the \"noise\" or measurement error need not\nhave a finite second moment, and under suitable conditions, not even a finite\nmean. By adapting this method of proof, we also derive sufficient conditions\nfor the convergence of zero-order SGD, wherein the stochastic gradient is\ncomputed using only two function evaluations, and no gradient computations. The\nsufficient conditions derived here are the weakest to date, thus leading to a\nconsiderable expansion of the applicability of SA and SGD theory.", "AI": {"tldr": "New sufficient conditions for the convergence of Stochastic Approximation (SA) and Stochastic Gradient Descent (SGD) are derived, allowing for noise without finite second moments or even finite means. Zero-order SGD convergence is also addressed.", "motivation": "To expand the applicability of SA and SGD theory by relaxing traditional assumptions about noise and measurement error.", "method": "Deriving new sufficient conditions for convergence, including cases where noise lacks finite moments, and adapting proofs for zero-order SGD.", "result": "The weakest sufficient conditions to date are established, significantly broadening the scope of SA and SGD applications.", "conclusion": "The paper advances SA and SGD theory by relaxing stringent noise assumptions, enhancing their practical utility."}}
{"id": "2505.04258", "pdf": "https://arxiv.org/pdf/2505.04258", "abs": "https://arxiv.org/abs/2505.04258", "authors": ["Pietro Bonazzi", "Christian Vogt", "Michael Jost", "Haotong Qin", "Lyes Khacef", "Federico Paredes-Valles", "Michele Magno"], "title": "RGB-Event Fusion with Self-Attention for Collision Prediction", "categories": ["cs.RO", "cs.CV"], "comment": "arXiv admin note: text overlap with arXiv:2504.10400", "summary": "Ensuring robust and real-time obstacle avoidance is critical for the safe\noperation of autonomous robots in dynamic, real-world environments. This paper\nproposes a neural network framework for predicting the time and collision\nposition of an unmanned aerial vehicle with a dynamic object, using RGB and\nevent-based vision sensors. The proposed architecture consists of two separate\nencoder branches, one for each modality, followed by fusion by self-attention\nto improve prediction accuracy. To facilitate benchmarking, we leverage the\nABCD [8] dataset collected that enables detailed comparisons of single-modality\nand fusion-based approaches. At the same prediction throughput of 50Hz, the\nexperimental results show that the fusion-based model offers an improvement in\nprediction accuracy over single-modality approaches of 1% on average and 10%\nfor distances beyond 0.5m, but comes at the cost of +71% in memory and + 105%\nin FLOPs. Notably, the event-based model outperforms the RGB model by 4% for\nposition and 26% for time error at a similar computational cost, making it a\ncompetitive alternative. Additionally, we evaluate quantized versions of the\nevent-based models, applying 1- to 8-bit quantization to assess the trade-offs\nbetween predictive performance and computational efficiency. These findings\nhighlight the trade-offs of multi-modal perception using RGB and event-based\ncameras in robotic applications.", "AI": {"tldr": "A neural network framework for UAV obstacle avoidance using RGB and event-based sensors improves accuracy but increases computational costs. Event-based models outperform RGB models in some metrics.", "motivation": "Ensuring robust, real-time obstacle avoidance for autonomous robots in dynamic environments.", "method": "Two encoder branches (RGB and event-based) fused via self-attention, tested on the ABCD dataset.", "result": "Fusion improves accuracy (1% avg, 10% beyond 0.5m) but raises memory (+71%) and FLOPs (+105%). Event-based models outperform RGB in position (4%) and time error (26%).", "conclusion": "Multi-modal perception with RGB and event-based cameras involves trade-offs between accuracy and computational efficiency."}}
{"id": "2504.14406", "pdf": "https://arxiv.org/pdf/2504.14406", "abs": "https://arxiv.org/abs/2504.14406", "authors": ["Runlong Ye", "Patrick Yung Kang Lee", "Matthew Varona", "Oliver Huang", "Carolina Nobre"], "title": "ScholarMate: A Mixed-Initiative Tool for Qualitative Knowledge Work and Information Sensemaking", "categories": ["cs.HC", "cs.AI"], "comment": "accepted at CHIWORK '25", "summary": "Synthesizing knowledge from large document collections is a critical yet\nincreasingly complex aspect of qualitative research and knowledge work. While\nAI offers automation potential, effectively integrating it into human-centric\nsensemaking workflows remains challenging. We present ScholarMate, an\ninteractive system designed to augment qualitative analysis by unifying AI\nassistance with human oversight. ScholarMate enables researchers to dynamically\narrange and interact with text snippets on a non-linear canvas, leveraging AI\nfor theme suggestions, multi-level summarization, and evidence-based theme\nnaming, while ensuring transparency through traceability to source documents.\nInitial pilot studies indicated that users value this mixed-initiative\napproach, finding the balance between AI suggestions and direct manipulation\ncrucial for maintaining interpretability and trust. We further demonstrate the\nsystem's capability through a case study analyzing 24 papers. By balancing\nautomation with human control, ScholarMate enhances efficiency and supports\ninterpretability, offering a valuable approach for productive human-AI\ncollaboration in demanding sensemaking tasks common in knowledge work.", "AI": {"tldr": "ScholarMate is an interactive system combining AI and human oversight to enhance qualitative research by offering theme suggestions, summarization, and traceability, improving efficiency and interpretability.", "motivation": "The complexity of synthesizing knowledge from large document collections and the challenge of integrating AI into human-centric workflows motivate the development of ScholarMate.", "method": "ScholarMate uses a non-linear canvas for dynamic text arrangement, AI for theme suggestions, multi-level summarization, and evidence-based naming, ensuring transparency.", "result": "Pilot studies and a case study of 24 papers show users value the balance of AI suggestions and human control for trust and interpretability.", "conclusion": "ScholarMate effectively balances automation and human oversight, enhancing efficiency and interpretability in human-AI collaboration for sensemaking tasks."}}
{"id": "2505.11355", "pdf": "https://arxiv.org/pdf/2505.11355", "abs": "https://arxiv.org/abs/2505.11355", "authors": ["Simon Urbainczyk", "Aretha L. Teckentrup", "Jonas Latz"], "title": "STRIDE: Sparse Techniques for Regression in Deep Gaussian Processes", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": null, "summary": "Gaussian processes (GPs) have gained popularity as flexible machine learning\nmodels for regression and function approximation with an in-built method for\nuncertainty quantification. However, GPs suffer when the amount of training\ndata is large or when the underlying function contains multi-scale features\nthat are difficult to represent by a stationary kernel. To address the former,\ntraining of GPs with large-scale data is often performed through inducing point\napproximations (also known as sparse GP regression (GPR)), where the size of\nthe covariance matrices in GPR is reduced considerably through a greedy search\non the data set. To aid the latter, deep GPs have gained traction as\nhierarchical models that resolve multi-scale features by combining multiple\nGPs. Posterior inference in deep GPs requires a sampling or, more usual, a\nvariational approximation. Variational approximations lead to large-scale\nstochastic, non-convex optimisation problems and the resulting approximation\ntends to represent uncertainty incorrectly. In this work, we combine\nvariational learning with MCMC to develop a particle-based\nexpectation-maximisation method to simultaneously find inducing points within\nthe large-scale data (variationally) and accurately train the GPs\n(sampling-based). The result is a highly efficient and accurate methodology for\ndeep GP training on large-scale data. We test our method on standard benchmark\nproblems.", "AI": {"tldr": "The paper proposes a hybrid method combining variational learning and MCMC for efficient and accurate training of deep Gaussian processes (GPs) on large-scale data.", "motivation": "GPs struggle with large datasets and multi-scale features. Existing methods like sparse GP regression and deep GPs have limitations in scalability and uncertainty representation.", "method": "A particle-based expectation-maximization method is developed, using variational learning for inducing points and sampling-based training for GPs.", "result": "The method is tested on benchmark problems, showing high efficiency and accuracy.", "conclusion": "The hybrid approach effectively addresses scalability and uncertainty issues in deep GP training."}}
{"id": "2505.08787", "pdf": "https://arxiv.org/pdf/2505.08787", "abs": "https://arxiv.org/abs/2505.08787", "authors": ["Hanjung Kim", "Jaehyun Kang", "Hyolim Kang", "Meedeum Cho", "Seon Joo Kim", "Youngwoon Lee"], "title": "UniSkill: Imitating Human Videos via Cross-Embodiment Skill Representations", "categories": ["cs.RO", "cs.CV"], "comment": "Project Page: https://kimhanjung.github.io/UniSkill/", "summary": "Mimicry is a fundamental learning mechanism in humans, enabling individuals\nto learn new tasks by observing and imitating experts. However, applying this\nability to robots presents significant challenges due to the inherent\ndifferences between human and robot embodiments in both their visual appearance\nand physical capabilities. While previous methods bridge this gap using\ncross-embodiment datasets with shared scenes and tasks, collecting such aligned\ndata between humans and robots at scale is not trivial. In this paper, we\npropose UniSkill, a novel framework that learns embodiment-agnostic skill\nrepresentations from large-scale cross-embodiment video data without any\nlabels, enabling skills extracted from human video prompts to effectively\ntransfer to robot policies trained only on robot data. Our experiments in both\nsimulation and real-world environments show that our cross-embodiment skills\nsuccessfully guide robots in selecting appropriate actions, even with unseen\nvideo prompts. The project website can be found at:\nhttps://kimhanjung.github.io/UniSkill.", "AI": {"tldr": "UniSkill is a framework for learning embodiment-agnostic skills from cross-embodiment video data, enabling human video prompts to transfer to robot policies without labeled data.", "motivation": "Mimicry is challenging for robots due to differences in human and robot embodiments. Existing methods rely on aligned cross-embodiment data, which is hard to collect at scale.", "method": "UniSkill learns skill representations from unlabeled cross-embodiment video data, allowing human-derived skills to transfer to robot policies.", "result": "Experiments show UniSkill successfully guides robots with unseen video prompts in simulation and real-world settings.", "conclusion": "UniSkill provides a scalable solution for cross-embodiment skill transfer without labeled data."}}
{"id": "2504.16116", "pdf": "https://arxiv.org/pdf/2504.16116", "abs": "https://arxiv.org/abs/2504.16116", "authors": ["Enhao Huang", "Pengyu Sun", "Zixin Lin", "Alex Chen", "Joey Ouyang", "Hobert Wang", "Dong Dong", "Gang Zhao", "James Yi", "Frank Li", "Ziang Ling", "Lowes Yang"], "title": "DMind Benchmark: Toward a Holistic Assessment of LLM Capabilities across the Web3 Domain", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved impressive performance in diverse\nnatural language processing tasks, but specialized domains such as Web3 present\nnew challenges and require more tailored evaluation. Despite the significant\nuser base and capital flows in Web3, encompassing smart contracts,\ndecentralized finance (DeFi), non-fungible tokens (NFTs), decentralized\nautonomous organizations (DAOs), on-chain governance, and novel\ntoken-economics, no comprehensive benchmark has systematically assessed LLM\nperformance in this domain. To address this gap, we introduce the DMind\nBenchmark, a holistic Web3-oriented evaluation suite covering nine critical\nsubfields: fundamental blockchain concepts, blockchain infrastructure, smart\ncontract, DeFi mechanisms, DAOs, NFTs, token economics, meme concept, and\nsecurity vulnerabilities. Beyond multiple-choice questions, DMind Benchmark\nfeatures domain-specific tasks such as contract debugging and on-chain numeric\nreasoning, mirroring real-world scenarios. We evaluated 26 models, including\nChatGPT, Claude, DeepSeek, Gemini, Grok, and Qwen, uncovering notable\nperformance gaps in specialized areas like token economics and\nsecurity-critical contract analysis. While some models excel in blockchain\ninfrastructure tasks, advanced subfields remain challenging. Our benchmark\ndataset and evaluation pipeline are open-sourced on\nhttps://huggingface.co/datasets/DMindAI/DMind_Benchmark, reaching number one in\nHugging Face's trending dataset charts within a week of release.", "AI": {"tldr": "The paper introduces the DMind Benchmark, a Web3-oriented evaluation suite for LLMs, addressing gaps in specialized domains like blockchain, DeFi, and NFTs. It evaluates 26 models, revealing performance disparities in advanced areas.", "motivation": "The lack of a comprehensive benchmark for LLMs in Web3 domains, despite their growing importance, motivated the creation of the DMind Benchmark.", "method": "The benchmark covers nine Web3 subfields and includes domain-specific tasks like contract debugging. It evaluates 26 models, including ChatGPT and Claude.", "result": "Performance gaps were found in specialized areas like token economics and security-critical tasks. The benchmark became a top trending dataset on Hugging Face.", "conclusion": "The DMind Benchmark fills a critical gap in evaluating LLMs for Web3, highlighting challenges in advanced subfields and providing an open-source resource for future research."}}
{"id": "2505.11366", "pdf": "https://arxiv.org/pdf/2505.11366", "abs": "https://arxiv.org/abs/2505.11366", "authors": ["Ali Rabiee", "Sima Ghafoori", "MH Farhadi", "Robert Beyer", "Xiangyu Bai", "David J Lin", "Sarah Ostadabbas", "Reza Abiri"], "title": "Learning Multimodal AI Algorithms for Amplifying Limited User Input into High-dimensional Control Space", "categories": ["cs.RO", "cs.HC", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Current invasive assistive technologies are designed to infer\nhigh-dimensional motor control signals from severely paralyzed patients.\nHowever, they face significant challenges, including public acceptance, limited\nlongevity, and barriers to commercialization. Meanwhile, noninvasive\nalternatives often rely on artifact-prone signals, require lengthy user\ntraining, and struggle to deliver robust high-dimensional control for dexterous\ntasks. To address these issues, this study introduces a novel human-centered\nmultimodal AI approach as intelligent compensatory mechanisms for lost motor\nfunctions that could potentially enable patients with severe paralysis to\ncontrol high-dimensional assistive devices, such as dexterous robotic arms,\nusing limited and noninvasive inputs. In contrast to the current\nstate-of-the-art (SoTA) noninvasive approaches, our context-aware, multimodal\nshared-autonomy framework integrates deep reinforcement learning algorithms to\nblend limited low-dimensional user input with real-time environmental\nperception, enabling adaptive, dynamic, and intelligent interpretation of human\nintent for complex dexterous manipulation tasks, such as pick-and-place. The\nresults from our ARAS (Adaptive Reinforcement learning for Amplification of\nlimited inputs in Shared autonomy) trained with synthetic users over 50,000\ncomputer simulation episodes demonstrated the first successful implementation\nof the proposed closed-loop human-in-the-loop paradigm, outperforming the SoTA\nshared autonomy algorithms. Following a zero-shot sim-to-real transfer, ARAS\nwas evaluated on 23 human subjects, demonstrating high accuracy in dynamic\nintent detection and smooth, stable 3D trajectory control for dexterous\npick-and-place tasks. ARAS user study achieved a high task success rate of\n92.88%, with short completion times comparable to those of SoTA invasive\nassistive technologies.", "AI": {"tldr": "A novel multimodal AI approach (ARAS) enhances noninvasive motor control for paralyzed patients, outperforming current methods with high accuracy and task success.", "motivation": "Addressing limitations of invasive and noninvasive assistive technologies, such as public acceptance, longevity, and robustness, to improve motor control for paralyzed individuals.", "method": "A context-aware, multimodal shared-autonomy framework using deep reinforcement learning to blend limited user input with environmental perception for adaptive intent interpretation.", "result": "ARAS achieved 92.88% task success in human trials, with performance comparable to invasive technologies, and demonstrated robust 3D trajectory control.", "conclusion": "ARAS offers a promising noninvasive solution for high-dimensional motor control, bridging gaps in current assistive technologies."}}
{"id": "2505.09819", "pdf": "https://arxiv.org/pdf/2505.09819", "abs": "https://arxiv.org/abs/2505.09819", "authors": ["Ruichen Yang", "Gy\u00f6rgy M. L\u00e9vay", "Christopher L. Hunt", "D\u00e1niel Czeiner", "Megan C. Hodgson", "Damini Agarwal", "Rahul R. Kaliki", "Nitish V. Thakor"], "title": "Visual Feedback of Pattern Separability Improves Myoelectric Decoding Performance of Upper Limb Prostheses", "categories": ["cs.HC", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "State-of-the-art upper limb myoelectric prostheses often use pattern\nrecognition (PR) control systems that translate electromyography (EMG) signals\ninto desired movements. As prosthesis movement complexity increases, users\noften struggle to produce sufficiently distinct EMG patterns for reliable\nclassification. Existing training typically involves heuristic, trial-and-error\nuser adjustments to static decoder boundaries. Goal: We introduce the Reviewer,\na 3D visual interface projecting EMG signals directly into the decoder's\nclassification space, providing intuitive, real-time insight into PR algorithm\nbehavior. This structured feedback reduces cognitive load and fosters mutual,\ndata-driven adaptation between user-generated EMG patterns and decoder\nboundaries. Methods: A 10-session study with 12 able-bodied participants\ncompared PR performance after motor-based training and updating using the\nReviewer versus conventional virtual arm visualization. Performance was\nassessed using a Fitts law task that involved the aperture of the cursor and\nthe control of orientation. Results: Participants trained with the Reviewer\nachieved higher completion rates, reduced overshoot, and improved path\nefficiency and throughput compared to the standard visualization group.\nSignificance: The Reviewer introduces decoder-informed motor training,\nfacilitating immediate and consistent PR-based myoelectric control\nimprovements. By iteratively refining control through real-time feedback, this\napproach reduces reliance on trial-and-error recalibration, enabling a more\nadaptive, self-correcting training framework. Conclusion: The 3D visual\nfeedback significantly improves PR control in novice operators through\nstructured training, enabling feedback-driven adaptation and reducing reliance\non extensive heuristic adjustments.", "AI": {"tldr": "The paper introduces the Reviewer, a 3D visual interface for myoelectric prostheses, improving PR control by providing real-time feedback and reducing cognitive load.", "motivation": "Users struggle with distinct EMG patterns for reliable classification in PR-controlled prostheses. Existing training lacks structured feedback.", "method": "A 10-session study with 12 able-bodied participants compared PR performance using the Reviewer versus conventional virtual arm visualization.", "result": "Participants using the Reviewer achieved higher completion rates, reduced overshoot, and improved efficiency and throughput.", "conclusion": "The Reviewer enhances PR control through structured feedback, enabling adaptive training and reducing reliance on trial-and-error adjustments."}}
{"id": "2505.00169", "pdf": "https://arxiv.org/pdf/2505.00169", "abs": "https://arxiv.org/abs/2505.00169", "authors": ["Filipp Nikitin", "Ian Dunn", "David Ryan Koes", "Olexandr Isayev"], "title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D Molecule Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep generative models have shown significant promise in generating valid 3D\nmolecular structures, with the GEOM-Drugs dataset serving as a key benchmark.\nHowever, current evaluation protocols suffer from critical flaws, including\nincorrect valency definitions, bugs in bond order calculations, and reliance on\nforce fields inconsistent with the reference data. In this work, we revisit\nGEOM-Drugs and propose a corrected evaluation framework: we identify and fix\nissues in data preprocessing, construct chemically accurate valency tables, and\nintroduce a GFN2-xTB-based geometry and energy benchmark. We retrain and\nre-evaluate several leading models under this framework, providing updated\nperformance metrics and practical recommendations for future benchmarking. Our\nresults underscore the need for chemically rigorous evaluation practices in 3D\nmolecular generation. Our recommended evaluation methods and GEOM-Drugs\nprocessing scripts are available at\nhttps://github.com/isayevlab/geom-drugs-3dgen-evaluation.", "AI": {"tldr": "The paper addresses flaws in evaluating 3D molecular generation models using GEOM-Drugs, proposing a corrected framework with accurate valency tables and GFN2-xTB benchmarks.", "motivation": "Current evaluation protocols for 3D molecular generation models are flawed, leading to inaccurate assessments.", "method": "The authors fix data preprocessing issues, create accurate valency tables, and introduce a GFN2-xTB-based benchmark. They retrain and re-evaluate leading models.", "result": "Updated performance metrics highlight the importance of chemically rigorous evaluation.", "conclusion": "The paper advocates for improved evaluation practices in 3D molecular generation and provides tools for future benchmarking."}}
{"id": "2505.11388", "pdf": "https://arxiv.org/pdf/2505.11388", "abs": "https://arxiv.org/abs/2505.11388", "authors": ["Petr Kasalick\u00fd", "Martin Spi\u0161\u00e1k", "Vojt\u011bch Van\u010dura", "Daniel Bohun\u011bk", "Rodrigo Alves", "Pavel Kord\u00edk"], "title": "The Future is Sparse: Embedding Compression for Scalable Retrieval in Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Industry-scale recommender systems face a core challenge: representing\nentities with high cardinality, such as users or items, using dense embeddings\nthat must be accessible during both training and inference. However, as\nembedding sizes grow, memory constraints make storage and access increasingly\ndifficult. We describe a lightweight, learnable embedding compression technique\nthat projects dense embeddings into a high-dimensional, sparsely activated\nspace. Designed for retrieval tasks, our method reduces memory requirements\nwhile preserving retrieval performance, enabling scalable deployment under\nstrict resource constraints. Our results demonstrate that leveraging sparsity\nis a promising approach for improving the efficiency of large-scale\nrecommenders. We release our code at https://github.com/recombee/CompresSAE.", "AI": {"tldr": "A lightweight embedding compression technique reduces memory usage in large-scale recommender systems while maintaining performance.", "motivation": "Addressing memory constraints in industry-scale recommender systems due to large embedding sizes.", "method": "Projects dense embeddings into a high-dimensional, sparsely activated space for efficient retrieval.", "result": "Reduces memory requirements without compromising retrieval performance.", "conclusion": "Sparsity is effective for scaling recommender systems under resource constraints."}}
{"id": "2505.02433", "pdf": "https://arxiv.org/pdf/2505.02433", "abs": "https://arxiv.org/abs/2505.02433", "authors": ["Soumen Kumar Mondal", "Akshit Varmora", "Prateek Chanda", "Ganesh Ramakrishnan"], "title": "FairPO: Robust Preference Optimization for Fair Multi-Label Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose FairPO, a novel framework designed to promote fairness in\nmulti-label classification by directly optimizing preference signals with a\ngroup robustness perspective. In our framework, the set of labels is\npartitioned into privileged and non-privileged groups, and a preference-based\nloss inspired by Direct Preference Optimization (DPO) is employed to more\neffectively differentiate true positive labels from confusing negatives within\nthe privileged group, while preserving baseline classification performance for\nnon-privileged labels. By framing the learning problem as a robust optimization\nover groups, our approach dynamically adjusts the training emphasis toward\ngroups with poorer performance, thereby mitigating bias and ensuring a fairer\ntreatment across diverse label categories. In addition, we outline plans to\nextend this approach by investigating alternative loss formulations such as\nSimple Preference Optimisation (SimPO) and Contrastive Preference Optimization\n(CPO) to exploit reference-free reward formulations and contrastive training\nsignals. Furthermore, we plan to extend FairPO with multilabel generation\ncapabilities, enabling the model to dynamically generate diverse and coherent\nlabel sets for ambiguous inputs.", "AI": {"tldr": "FairPO is a framework for fair multi-label classification by optimizing preference signals with group robustness, dynamically adjusting training to mitigate bias.", "motivation": "To address fairness in multi-label classification by differentiating privileged and non-privileged label groups and reducing bias.", "method": "Uses a preference-based loss (inspired by DPO) for robust optimization over label groups, dynamically adjusting training emphasis.", "result": "Mitigates bias while preserving baseline performance for non-privileged labels.", "conclusion": "FairPO effectively promotes fairness and plans to explore alternative loss formulations and extend to multilabel generation."}}
{"id": "2102.08993", "pdf": "https://arxiv.org/pdf/2102.08993", "abs": "https://arxiv.org/abs/2102.08993", "authors": ["Takuya Kanazawa"], "title": "Using Distance Correlation for Efficient Bayesian Optimization", "categories": ["cs.LG", "stat.ML"], "comment": "14 pages. v2: fixed errors", "summary": "The need to collect data via expensive measurements of black-box functions is\nprevalent across science, engineering and medicine. As an example,\nhyperparameter tuning of a large AI model is critical to its predictive\nperformance but is generally time-consuming and unwieldy. Bayesian optimization\n(BO) is a collection of methods that aim to address this issue by means of\nBayesian statistical inference. In this work, we put forward a BO scheme named\nBDC, which integrates BO with a statistical measure of association of two\nrandom variables called Distance Correlation. BDC balances exploration and\nexploitation automatically, and requires no manual hyperparameter tuning. We\nevaluate BDC on a range of benchmark tests and observe that it performs on per\nwith popular BO methods such as the expected improvement and max-value entropy\nsearch. We also apply BDC to optimization of sequential integral observations\nof an unknown terrain and confirm its utility.", "AI": {"tldr": "BDC integrates Bayesian optimization with Distance Correlation for efficient black-box function optimization, performing comparably to popular methods without manual tuning.", "motivation": "Address the challenge of expensive data collection in black-box function optimization, such as hyperparameter tuning in AI models.", "method": "Proposes BDC, a Bayesian optimization scheme using Distance Correlation to balance exploration and exploitation automatically.", "result": "BDC performs on par with established methods like expected improvement and max-value entropy search in benchmarks and real-world applications.", "conclusion": "BDC is a viable and efficient alternative for black-box optimization, requiring no manual hyperparameter tuning."}}
{"id": "2505.03819", "pdf": "https://arxiv.org/pdf/2505.03819", "abs": "https://arxiv.org/abs/2505.03819", "authors": ["Johannes Schneider"], "title": "Focus on the Likely: Test-time Instance-based Uncertainty Removal", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We ask: Does focusing on classes predicted as likely improve model\npredictions? We aim for an affirmative answer by proposing two novel test-time\nfine-tuning methods to improve uncertain model predictions. Instead of greedily\nselecting the most likely class, we introduce an additional step, \\emph{focus\non the likely classes}, to refine predictions. By applying a theoretically\nmotivated single gradient descent step with a large learning rate, we refine\npredictions when an initial forward pass indicates high uncertainty. This\naligns predictions more closely with the ideal of assigning zero probability to\nless plausible outcomes. The experimental evaluation demonstrates accuracy\ngains for one of our methods, which emphasizes shared features among likely\nclasses, across diverse text and image domain models. %Our theoretical\ndiscussion provides a deeper understanding, highlighting the varying impact of\nshared and non-shared features among (focus) classes. %Our discussion also\nsuggests an interesting view on standard, offline training vs. test-time\ntraining: Opposing optimization rationales regarding breadth of feature\ndependence are preferable during each training phase.", "AI": {"tldr": "Focusing on likely classes improves model predictions via test-time fine-tuning methods, achieving accuracy gains by refining uncertain predictions.", "motivation": "To enhance model predictions by refining uncertain outcomes and aligning them with plausible classes.", "method": "Two novel test-time fine-tuning methods: focusing on likely classes and applying a gradient descent step with a large learning rate.", "result": "Accuracy gains demonstrated in diverse text and image domain models, particularly with shared feature emphasis.", "conclusion": "Refining predictions by focusing on likely classes is effective, with theoretical and empirical support."}}
{"id": "2203.01717", "pdf": "https://arxiv.org/pdf/2203.01717", "abs": "https://arxiv.org/abs/2203.01717", "authors": ["Niclas Kannengie\u00dfer", "Niklas Hasebrook", "Felix Morsbach", "Marc-Andr\u00e9 Z\u00f6ller", "J\u00f6rg Franke", "Marius Lindauer", "Frank Hutter", "Ali Sunyaev"], "title": "Practitioner Motives to Use Different Hyperparameter Optimization Methods", "categories": ["cs.LG"], "comment": "submitted to TOCHI; currently under review", "summary": "Programmatic hyperparameter optimization (HPO) methods, such as Bayesian\noptimization and evolutionary algorithms, are highly sample-efficient in\nidentifying optimal hyperparameter configurations for machine learning (ML)\nmodels. However, practitioners frequently use less efficient methods, such as\ngrid search, which can lead to under-optimized models. We suspect this behavior\nis driven by a range of practitioner-specific motives. Practitioner motives,\nhowever, still need to be clarified to enhance user-centered development of HPO\ntools. To uncover practitioner motives to use different HPO methods, we\nconducted 20 semi-structured interviews and an online survey with 49 ML\nexperts. By presenting main goals (e.g., increase ML model understanding) and\ncontextual factors affecting practitioners' selection of HPO methods (e.g.,\navailable computer resources), this study offers a conceptual foundation to\nbetter understand why practitioners use different HPO methods, supporting\ndevelopment of more user-centered and context-adaptive HPO tools in automated\nML.", "AI": {"tldr": "The paper explores why practitioners prefer less efficient HPO methods like grid search over more efficient ones like Bayesian optimization, identifying motives and contextual factors through interviews and surveys.", "motivation": "Practitioners often use inefficient HPO methods despite better alternatives, but their motives remain unclear. Understanding these motives can improve HPO tool design.", "method": "Conducted 20 semi-structured interviews and an online survey with 49 ML experts to analyze motives and contextual factors influencing HPO method choice.", "result": "Identified main goals (e.g., model understanding) and contextual factors (e.g., resources) affecting HPO method selection, providing insights for user-centered HPO tool development.", "conclusion": "The study offers a foundation for designing context-adaptive and user-centered HPO tools in automated ML by clarifying practitioner motives."}}
{"id": "2505.04165", "pdf": "https://arxiv.org/pdf/2505.04165", "abs": "https://arxiv.org/abs/2505.04165", "authors": ["Kairong Yu", "Tianqing Zhang", "Qi Xu", "Gang Pan", "Hongwei Wang"], "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks", "categories": ["cs.NE", "cs.AI"], "comment": "Accepted by ICML2025", "summary": "Spiking Neural Networks (SNNs) are increasingly recognized for their\nbiological plausibility and energy efficiency, positioning them as strong\nalternatives to Artificial Neural Networks (ANNs) in neuromorphic computing\napplications. SNNs inherently process temporal information by leveraging the\nprecise timing of spikes, but balancing temporal feature utilization with low\nenergy consumption remains a challenge. In this work, we introduce Temporal\nShift module for Spiking Neural Networks (TS-SNN), which incorporates a novel\nTemporal Shift (TS) module to integrate past, present, and future spike\nfeatures within a single timestep via a simple yet effective shift operation. A\nresidual combination method prevents information loss by integrating shifted\nand original features. The TS module is lightweight, requiring only one\nadditional learnable parameter, and can be seamlessly integrated into existing\narchitectures with minimal additional computational cost. TS-SNN achieves\nstate-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100\n(80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low\nenergy consumption. This work marks a significant step forward in developing\nefficient and accurate SNN architectures.", "AI": {"tldr": "TS-SNN introduces a lightweight Temporal Shift module to enhance Spiking Neural Networks by integrating past, present, and future spike features efficiently, achieving top performance on benchmarks with low energy use.", "motivation": "To address the challenge of balancing temporal feature utilization and energy efficiency in Spiking Neural Networks (SNNs).", "method": "Proposes a Temporal Shift (TS) module for SNNs, which integrates spike features across time via a simple shift operation and residual combination to prevent information loss.", "result": "Achieves state-of-the-art performance on CIFAR-10 (96.72%), CIFAR-100 (80.28%), and ImageNet (70.61%) with fewer timesteps and low energy consumption.", "conclusion": "TS-SNN represents a significant advancement in efficient and accurate SNN architectures."}}
{"id": "2302.05971", "pdf": "https://arxiv.org/pdf/2302.05971", "abs": "https://arxiv.org/abs/2302.05971", "authors": ["Arpan Dasgupta", "Preeti Lamba", "Ankita Kushwaha", "Kiran Ravish", "Siddhant Katyan", "Shrutimoy Das", "Pawan Kumar"], "title": "Review of Extreme Multilabel Classification", "categories": ["cs.LG"], "comment": "63 pages, 14 figures", "summary": "Extreme multi-label classification or XMLC, is an active area of interest in\nmachine learning. Compared to traditional multi-label classification, here the\nnumber of labels is extremely large, hence, the name extreme multi-label\nclassification. Using classical one-versus-all classification does not scale in\nthis case due to large number of labels; the same is true for any other\nclassifier. Embedding labels and features into a lower-dimensional space is a\ncommon first step in many XMLC methods. Moreover, other issues include\nexistence of head and tail labels, where tail labels are those that occur in a\nrelatively small number of samples. The existence of tail labels creates issues\nduring embedding. This area has invited application of wide range of approaches\nranging from bit compression motivated from compressed sensing, tree based\nembeddings, deep learning based latent space embedding including using\nattention weights, linear algebra based embeddings such as SVD, clustering,\nhashing, to name a few. The community has come up with a useful set of metrics\nto identify correctly the prediction for head or tail labels.", "AI": {"tldr": "XMLC addresses multi-label classification with an extremely large number of labels, requiring scalable methods beyond traditional approaches like one-versus-all. Techniques include embedding, handling tail labels, and diverse methods like deep learning, SVD, and clustering.", "motivation": "The challenge lies in scaling classification for extreme label counts, where traditional methods fail, and addressing imbalances like tail labels.", "method": "Common approaches involve embedding labels and features into lower-dimensional spaces, using techniques like deep learning, SVD, clustering, and hashing.", "result": "The field has developed metrics to evaluate performance, especially for tail labels, ensuring balanced prediction accuracy.", "conclusion": "XMLC is a dynamic area with diverse solutions, focusing on scalability and handling label imbalances effectively."}}
{"id": "2505.05784", "pdf": "https://arxiv.org/pdf/2505.05784", "abs": "https://arxiv.org/abs/2505.05784", "authors": ["Yang Li", "Zhi Chen", "Steve Yang"], "title": "FlowHFT: Imitation Learning via Flow Matching Policy for Optimal High-Frequency Trading under Diverse Market Conditions", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "q-fin.CP"], "comment": "16 pages, 6 figures, 6 tables, 2 algorithms", "summary": "High-frequency trading (HFT) is an investing strategy that continuously\nmonitors market states and places bid and ask orders at millisecond speeds.\nTraditional HFT approaches fit models with historical data and assume that\nfuture market states follow similar patterns. This limits the effectiveness of\nany single model to the specific conditions it was trained for. Additionally,\nthese models achieve optimal solutions only under specific market conditions,\nsuch as assumptions about stock price's stochastic process, stable order flow,\nand the absence of sudden volatility. Real-world markets, however, are dynamic,\ndiverse, and frequently volatile. To address these challenges, we propose the\nFlowHFT, a novel imitation learning framework based on flow matching policy.\nFlowHFT simultaneously learns strategies from numerous expert models, each\nproficient in particular market scenarios. As a result, our framework can\nadaptively adjust investment decisions according to the prevailing market\nstate. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism.\nThis allows it to refine strategies and achieve superior performance even in\ncomplex or extreme market scenarios where expert strategies may be suboptimal.\nWe test FlowHFT in multiple market environments. We first show that flow\nmatching policy is applicable in stochastic market environments, thus enabling\nFlowHFT to learn trading strategies under different market conditions. Notably,\nour single framework consistently achieves performance superior to the best\nexpert for each market condition.", "AI": {"tldr": "FlowHFT is an imitation learning framework for high-frequency trading that adapts to diverse market conditions by learning from multiple expert models and fine-tuning strategies.", "motivation": "Traditional HFT models are limited by their reliance on historical data and assumptions about stable market conditions, which don't hold in dynamic, volatile markets.", "method": "FlowHFT uses a flow matching policy to learn from multiple expert models and incorporates grid-search fine-tuning to refine strategies.", "result": "FlowHFT outperforms individual expert models across various market conditions, demonstrating adaptability and superior performance.", "conclusion": "FlowHFT provides a robust and adaptive solution for HFT in dynamic markets, overcoming the limitations of traditional models."}}
{"id": "2310.03010", "pdf": "https://arxiv.org/pdf/2310.03010", "abs": "https://arxiv.org/abs/2310.03010", "authors": ["Gerard Ben Arous", "Reza Gheissari", "Jiaoyang Huang", "Aukosh Jagannath"], "title": "Spectral alignment of stochastic gradient descent for high-dimensional classification tasks", "categories": ["cs.LG", "math.PR", "stat.ML"], "comment": "Final version. 53 pages, 12 figures", "summary": "We rigorously study the relation between the training dynamics via stochastic\ngradient descent (SGD) and the spectra of empirical Hessian and gradient\nmatrices. We prove that in two canonical classification tasks for multi-class\nhigh-dimensional mixtures and either 1 or 2-layer neural networks, both the SGD\ntrajectory and emergent outlier eigenspaces of the Hessian and gradient\nmatrices align with a common low-dimensional subspace. Moreover, in multi-layer\nsettings this alignment occurs per layer, with the final layer's outlier\neigenspace evolving over the course of training, and exhibiting rank deficiency\nwhen the SGD converges to sub-optimal classifiers. This establishes some of the\nrich predictions that have arisen from extensive numerical studies in the last\ndecade about the spectra of Hessian and information matrices over the course of\ntraining in overparametrized networks.", "AI": {"tldr": "The paper explores the alignment between SGD training dynamics and the spectra of Hessian/gradient matrices in neural networks, confirming predictions from numerical studies.", "motivation": "To rigorously study the connection between SGD dynamics and the spectral properties of Hessian and gradient matrices in neural networks, addressing long-standing predictions.", "method": "Analyzes SGD trajectories and outlier eigenspaces in multi-class high-dimensional mixtures and 1 or 2-layer neural networks, extending to multi-layer settings.", "result": "SGD trajectories and outlier eigenspaces align with a low-dimensional subspace, with layer-specific alignment and evolving final-layer eigenspace in multi-layer networks.", "conclusion": "The study validates predictions about Hessian and gradient spectra in overparametrized networks, highlighting their role in training dynamics."}}
{"id": "2505.07450", "pdf": "https://arxiv.org/pdf/2505.07450", "abs": "https://arxiv.org/abs/2505.07450", "authors": ["Neil De La Fuente", "Maria Pilligua", "Daniel Vidal", "Albin Soutiff", "Cecilia Curreli", "Daniel Cremers", "Andrey Barsky"], "title": "Prototype Augmented Hypernetworks for Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "CVPR 2025 (LatinX in CV)", "summary": "Continual learning (CL) aims to learn a sequence of tasks without forgetting\nprior knowledge, but gradient updates for a new task often overwrite the\nweights learned earlier, causing catastrophic forgetting (CF). We propose\nPrototype-Augmented Hypernetworks (PAH), a framework where a single\nhypernetwork, conditioned on learnable task prototypes, dynamically generates\ntask-specific classifier heads on demand. To mitigate forgetting, PAH combines\ncross-entropy with dual distillation losses, one to align logits and another to\nalign prototypes, ensuring stable feature representations across tasks.\nEvaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves\nstate-of-the-art performance, reaching 74.5 % and 63.7 % accuracy with only 1.7\n% and 4.4 % forgetting, respectively, surpassing prior methods without storing\nsamples or heads.", "AI": {"tldr": "PAH uses hypernetworks and task prototypes to prevent catastrophic forgetting in continual learning, achieving high accuracy with minimal forgetting.", "motivation": "Address catastrophic forgetting in continual learning by dynamically generating task-specific classifiers without storing past data.", "method": "Prototype-Augmented Hypernetworks (PAH) with dual distillation losses for logit and prototype alignment.", "result": "74.5% accuracy on Split-CIFAR100 and 63.7% on TinyImageNet with low forgetting rates (1.7% and 4.4%).", "conclusion": "PAH outperforms prior methods by effectively mitigating forgetting while maintaining high accuracy."}}
{"id": "2310.19218", "pdf": "https://arxiv.org/pdf/2310.19218", "abs": "https://arxiv.org/abs/2310.19218", "authors": ["Yang Zhao", "Jiaxi Yang", "Yiling Tao", "Lixu Wang", "Xiaoxiao Li", "Dusit Niyato", "H. Vincent Poor"], "title": "Exploring Federated Unlearning: Review, Comparison, and Insights", "categories": ["cs.LG"], "comment": null, "summary": "The increasing demand for privacy-preserving machine learning has spurred\ninterest in federated unlearning, which enables the selective removal of data\nfrom models trained in federated systems. However, developing federated\nunlearning methods presents challenges, particularly in balancing three often\nconflicting objectives: privacy, accuracy, and efficiency. This paper provides\na comprehensive analysis of existing federated unlearning approaches, examining\ntheir algorithmic efficiency, impact on model accuracy, and effectiveness in\npreserving privacy. We discuss key trade-offs among these dimensions and\nhighlight their implications for practical applications across various domains.\nAdditionally, we propose the OpenFederatedUnlearning framework, a unified\nbenchmark for evaluating federated unlearning methods, incorporating classic\nbaselines and diverse performance metrics. Our findings aim to guide\npractitioners in navigating the complex interplay of these objectives, offering\ninsights to achieve effective and efficient federated unlearning. Finally, we\noutline directions for future research to further advance the state of\nfederated unlearning techniques.", "AI": {"tldr": "This paper analyzes federated unlearning methods, balancing privacy, accuracy, and efficiency, and introduces the OpenFederatedUnlearning framework for evaluation.", "motivation": "Address the growing need for privacy-preserving machine learning by enabling selective data removal in federated systems.", "method": "Comprehensive analysis of existing federated unlearning approaches, focusing on algorithmic efficiency, model accuracy, and privacy preservation.", "result": "Identifies key trade-offs and proposes OpenFederatedUnlearning, a unified benchmark for evaluating methods.", "conclusion": "Provides insights for practitioners and outlines future research directions to advance federated unlearning."}}
{"id": "2505.08265", "pdf": "https://arxiv.org/pdf/2505.08265", "abs": "https://arxiv.org/abs/2505.08265", "authors": ["Hang Gao", "Wenxuan Huang", "Fengge Wu", "Junsuo Zhao", "Changwen Zheng", "Huaping Liu"], "title": "Large Language Model Enhancers for Graph Neural Networks: An Analysis from the Perspective of Causal Mechanism Identification", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "The use of large language models (LLMs) as feature enhancers to optimize node\nrepresentations, which are then used as inputs for graph neural networks\n(GNNs), has shown significant potential in graph representation learning.\nHowever, the fundamental properties of this approach remain underexplored. To\naddress this issue, we propose conducting a more in-depth analysis of this\nissue based on the interchange intervention method. First, we construct a\nsynthetic graph dataset with controllable causal relationships, enabling\nprecise manipulation of semantic relationships and causal modeling to provide\ndata for analysis. Using this dataset, we conduct interchange interventions to\nexamine the deeper properties of LLM enhancers and GNNs, uncovering their\nunderlying logic and internal mechanisms. Building on the analytical results,\nwe design a plug-and-play optimization module to improve the information\ntransfer between LLM enhancers and GNNs. Experiments across multiple datasets\nand models validate the proposed module.", "AI": {"tldr": "The paper explores using LLMs to enhance node representations for GNNs, analyzes their properties via interchange interventions, and proposes an optimization module to improve LLM-GNN information transfer.", "motivation": "The potential of LLMs as feature enhancers for GNNs is underexplored, prompting a deeper analysis of their properties and mechanisms.", "method": "Constructs a synthetic graph dataset for causal analysis, uses interchange interventions to study LLM enhancers and GNNs, and designs an optimization module for better information transfer.", "result": "Experiments validate the proposed optimization module across multiple datasets and models.", "conclusion": "The study provides insights into LLM-GNN interactions and offers a practical module to enhance their performance."}}
{"id": "2402.15328", "pdf": "https://arxiv.org/pdf/2402.15328", "abs": "https://arxiv.org/abs/2402.15328", "authors": ["Chenguang Wang", "Xuanhao Pan", "Tianshu Yu"], "title": "Towards Principled Task Grouping for Multi-Task Learning", "categories": ["cs.LG"], "comment": null, "summary": "Multi-task learning (MTL) aims to leverage shared information among tasks to\nimprove learning efficiency and accuracy. However, MTL often struggles to\neffectively manage positive and negative transfer between tasks, which can\nhinder performance improvements. Task grouping addresses this challenge by\norganizing tasks into meaningful clusters, maximizing beneficial transfer while\nminimizing detrimental interactions. This paper introduces a principled\napproach to task grouping in MTL, advancing beyond existing methods by\naddressing key theoretical and practical limitations. Unlike prior studies, our\nmethod offers a theoretically grounded approach that does not depend on\nrestrictive assumptions for constructing transfer gains. We also present a\nflexible mathematical programming formulation that accommodates a wide range of\nresource constraints, thereby enhancing its versatility. Experimental results\nacross diverse domains, including computer vision datasets, combinatorial\noptimization benchmarks, and time series tasks, demonstrate the superiority of\nour method over extensive baselines, thereby validating its effectiveness and\ngeneral applicability in MTL without sacrificing efficiency.", "AI": {"tldr": "A principled task grouping method for multi-task learning (MTL) improves performance by optimizing transfer between tasks, validated across diverse domains.", "motivation": "MTL struggles with managing positive and negative transfer between tasks, limiting performance improvements. Task grouping can address this by organizing tasks effectively.", "method": "Introduces a theoretically grounded task grouping approach with a flexible mathematical programming formulation for resource constraints.", "result": "Superior performance demonstrated across computer vision, combinatorial optimization, and time series tasks compared to baselines.", "conclusion": "The method enhances MTL effectiveness and general applicability without efficiency trade-offs."}}
{"id": "2505.09598", "pdf": "https://arxiv.org/pdf/2505.09598", "abs": "https://arxiv.org/abs/2505.09598", "authors": ["Nidhal Jegham", "Marwen Abdelatti", "Lassad Elmoubarki", "Abdeltawab Hendawi"], "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "This paper introduces a novel infrastructure-aware benchmarking framework for\nquantifying the environmental footprint of LLM inference across 30\nstate-of-the-art models as deployed in commercial data centers. Our framework\ncombines public API performance data with region-specific environmental\nmultipliers and statistical inference of hardware configurations. We\nadditionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank\nmodels by performance relative to environmental cost. Our results show that o3\nand DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33\nWh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and\nthat Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short\nGPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results\nin substantial annual environmental impacts. These include electricity use\ncomparable to 35,000 U.S. homes, freshwater evaporation matching the annual\ndrinking needs of 1.2 million people, and carbon emissions requiring a\nChicago-sized forest to offset. These findings illustrate a growing paradox:\nAlthough AI is becoming cheaper and faster, its global adoption drives\ndisproportionate resource consumption. Our study provides a standardized,\nempirically grounded methodology for benchmarking the sustainability of LLM\ndeployments, laying a foundation for future environmental accountability in AI\ndevelopment and sustainability standards.", "AI": {"tldr": "A framework benchmarks LLM inference's environmental impact, revealing energy-intensive models and eco-efficient ones, with significant global resource implications.", "motivation": "To quantify and compare the environmental footprint of LLM inference in commercial data centers, addressing the paradox of AI's efficiency versus resource consumption.", "method": "Combines API performance data, region-specific environmental multipliers, hardware inference, and cross-efficiency DEA to rank models by eco-efficiency.", "result": "O3 and DeepSeek-R1 are most energy-intensive (33 Wh per prompt), while Claude-3.7 Sonnet is most eco-efficient. Scaling GPT-4o queries shows massive resource impacts.", "conclusion": "The study offers a standardized method for assessing LLM sustainability, highlighting the need for environmental accountability in AI development."}}
{"id": "2406.09574", "pdf": "https://arxiv.org/pdf/2406.09574", "abs": "https://arxiv.org/abs/2406.09574", "authors": ["Akhil Agnihotri", "Rahul Jain", "Deepak Ramachandran", "Zheng Wen"], "title": "Online Bandit Learning with Offline Preference Data for Improved RLHF", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement Learning with Human Feedback (RLHF) is at the core of\nfine-tuning methods for generative AI models for language and images. Such\nfeedback is often sought as rank or preference feedback from human raters, as\nopposed to eliciting scores since the latter tends to be noisy. On the other\nhand, RL theory and algorithms predominantly assume that a reward feedback is\navailable. In particular, approaches for online learning that can be helpful in\nadaptive data collection via active learning cannot incorporate offline\npreference data. In this paper, we adopt a finite-armed linear bandit model as\na prototypical model of online learning. We consider an offline preference\ndataset to be available generated by an expert of unknown 'competence'. We\npropose warmPref-PS, a posterior sampling algorithm for online learning that\ncan be warm-started with an offline dataset with noisy preference feedback. We\nshow that by modeling the 'competence' of the expert that generated it, we are\nable to use such a dataset most effectively. We support our claims with novel\ntheoretical analysis of its Bayesian regret, as well as, extensive empirical\nevaluation of an approximate loss function that optimizes for infinitely many\narms, and performs substantially better than baselines.", "AI": {"tldr": "The paper introduces warmPref-PS, a posterior sampling algorithm for online learning with offline preference data, improving performance by modeling expert competence.", "motivation": "RLHF relies on human feedback, often noisy as scores, while RL assumes reward feedback. The gap between offline preference data and online learning needs addressing.", "method": "Adopts a finite-armed linear bandit model, proposes warmPref-PS for online learning with offline preference data, modeling expert competence.", "result": "Theoretical analysis shows reduced Bayesian regret; empirical evaluation outperforms baselines.", "conclusion": "warmPref-PS effectively bridges offline preference data and online learning, enhancing RLHF fine-tuning."}}
{"id": "2505.09619", "pdf": "https://arxiv.org/pdf/2505.09619", "abs": "https://arxiv.org/abs/2505.09619", "authors": ["Pietro Cassieri", "Aiman Faiz", "Anna Maria De Roberto", "Claudio Pascarelli", "Gianvito Mitrano", "Gianluca Fimiani", "Marina Garofano", "Christiancarmine Esposito", "Genoveffa Tortora", "Mariangela Lazoi", "Claudio Passino", "Alessia Bramanti", "Giuseppe Scanniello"], "title": "Predictive Models for Chronic Heart Failure", "categories": ["stat.OT", "cs.AI"], "comment": null, "summary": "The management of chronic Heart Failure (HF) presents significant challenges\nin modern healthcare, requiring continuous monitoring, early detection of\nexacerbations, and personalized treatment strategies. In this paper, we present\na predictive model founded on Machine Learning (ML) techniques to identify\npatients at HF risk. This model is an ensemble learning approach, a modified\nstacking technique, that uses two specialized models leveraging clinical and\nechocardiographic features and then a meta-model to combine the predictions of\nthese two models. We initially assess the model on a real dataset and the\nobtained results suggest that it performs well in the stratification of\npatients at HR risk. Specifically, we obtained high sensitivity (95\\%),\nensuring that nearly all high-risk patients are identified. As for accuracy, we\nobtained 84\\%, which can be considered moderate in some ML contexts. However,\nit is acceptable given our priority of identifying patients at risk of HF\nbecause they will be asked to participate in the telemonitoring program of the\nPrediHealth research project on which some of the authors of this paper are\nworking. The initial findings also suggest that ML-based risk stratification\nmodels can serve as valuable decision-support tools not only in the PrediHealth\nproject but also for healthcare professionals, aiding in early intervention and\npersonalized patient management. To have a better understanding of the value\nand of potentiality of our predictive model, we also contrasted its results\nwith those obtained by using three baseline models. The preliminary results\nindicate that our predictive model outperforms these baselines that flatly\nconsider features, \\ie not grouping them in clinical and echocardiographic\nfeatures.", "AI": {"tldr": "A machine learning-based predictive model for chronic Heart Failure risk stratification, using an ensemble approach, shows high sensitivity (95%) and moderate accuracy (84%), outperforming baseline models.", "motivation": "To address challenges in chronic Heart Failure management by enabling early detection and personalized treatment through predictive modeling.", "method": "An ensemble learning approach (modified stacking) combining two specialized models (clinical and echocardiographic features) with a meta-model for prediction.", "result": "High sensitivity (95%) and moderate accuracy (84%), outperforming baseline models.", "conclusion": "ML-based models can effectively support early intervention and personalized management in Heart Failure care."}}
{"id": "2407.06325", "pdf": "https://arxiv.org/pdf/2407.06325", "abs": "https://arxiv.org/abs/2407.06325", "authors": ["Jeremy Carleton", "Prathik Vijaykumar", "Divyanshu Saxena", "Dheeraj Narasimha", "Srinivas Shakkottai", "Aditya Akella"], "title": "CONGO: Compressive Online Gradient Optimization", "categories": ["cs.LG", "cs.DC", "math.OC"], "comment": "Accepted at ICLR 2025; 34 pages, 12 figures", "summary": "We address the challenge of zeroth-order online convex optimization where the\nobjective function's gradient exhibits sparsity, indicating that only a small\nnumber of dimensions possess non-zero gradients. Our aim is to leverage this\nsparsity to obtain useful estimates of the objective function's gradient even\nwhen the only information available is a limited number of function samples.\nOur motivation stems from the optimization of large-scale queueing networks\nthat process time-sensitive jobs. Here, a job must be processed by potentially\nmany queues in sequence to produce an output, and the service time at any queue\nis a function of the resources allocated to that queue. Since resources are\ncostly, the end-to-end latency for jobs must be balanced with the overall cost\nof the resources used. While the number of queues is substantial, the latency\nfunction primarily reacts to resource changes in only a few, rendering the\ngradient sparse. We tackle this problem by introducing the Compressive Online\nGradient Optimization framework which allows compressive sensing methods\npreviously applied to stochastic optimization to achieve regret bounds with an\noptimal dependence on the time horizon without the full problem dimension\nappearing in the bound. For specific algorithms, we reduce the samples required\nper gradient estimate to scale with the gradient's sparsity factor rather than\nits full dimensionality. Numerical simulations and real-world microservices\nbenchmarks demonstrate CONGO's superiority over gradient descent approaches\nthat do not account for sparsity.", "AI": {"tldr": "The paper introduces the Compressive Online Gradient Optimization (CONGO) framework to address zeroth-order online convex optimization with sparse gradients, leveraging compressive sensing for efficient gradient estimation.", "motivation": "The work is motivated by optimizing large-scale queueing networks where latency functions react sparsely to resource changes, requiring efficient gradient estimation with limited samples.", "method": "The CONGO framework applies compressive sensing methods to achieve regret bounds independent of the full problem dimension, reducing sample requirements for gradient estimation.", "result": "CONGO outperforms traditional gradient descent methods in numerical simulations and real-world benchmarks by exploiting gradient sparsity.", "conclusion": "The CONGO framework effectively leverages gradient sparsity for efficient optimization in high-dimensional, resource-constrained settings."}}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis", "Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation.", "AI": {"tldr": "The paper argues that testing for out-of-distribution (OOD) generalization alone is insufficient to confirm compositional learning; the features must also be verified as compositional. It demonstrates this with tasks where common neural networks fail, introduces two new architectures, and shows that even successful OOD performance doesn't guarantee correct feature learning.", "motivation": "To address the gap in confirming compositional learning in algorithms, emphasizing the need to verify both OOD performance and compositional feature identification.", "method": "Evaluates three common neural networks (MLP, CNN, Transformer) on OOD tasks, introduces two novel architectures with specific biases, and tests their feature learning.", "result": "Common networks fail in OOD tasks; new architectures achieve high OOD performance but may still fail to learn correct compositional features.", "conclusion": "OOD testing alone is inadequate; compositional feature verification is essential for true compositional generalization."}}
{"id": "2408.13002", "pdf": "https://arxiv.org/pdf/2408.13002", "abs": "https://arxiv.org/abs/2408.13002", "authors": ["Joseph Paillard", "Angel Reyero Lobo", "Vitaliy Kolodyazhniy", "Bertrand Thirion", "Denis A. Engemann"], "title": "Measuring Variable Importance in Heterogeneous Treatment Effects with Confidence", "categories": ["cs.LG"], "comment": null, "summary": "Causal machine learning holds promise for estimating individual treatment\neffects from complex data. For successful real-world applications of machine\nlearning methods, it is of paramount importance to obtain reliable insights\ninto which variables drive heterogeneity in the response to treatment. We\npropose PermuCATE, an algorithm based on the Conditional Permutation Importance\n(CPI) method, for statistically rigorous global variable importance assessment\nin the estimation of the Conditional Average Treatment Effect (CATE).\nTheoretical analysis of the finite sample regime and empirical studies show\nthat PermuCATE has lower variance than the Leave-One-Covariate-Out (LOCO)\nreference method and provides a reliable measure of variable importance. This\nproperty increases statistical power, which is crucial for causal inference in\nthe limited-data regime common to biomedical applications. We empirically\ndemonstrate the benefits of PermuCATE in simulated and real-world health\ndatasets, including settings with up to hundreds of correlated variables.", "AI": {"tldr": "PermuCATE, a CPI-based algorithm, improves variable importance assessment for CATE estimation with lower variance than LOCO, enhancing statistical power in limited-data settings like biomedicine.", "motivation": "To reliably identify variables driving treatment response heterogeneity in causal machine learning for real-world applications.", "method": "Proposes PermuCATE, using Conditional Permutation Importance (CPI) for rigorous variable importance assessment in CATE estimation.", "result": "PermuCATE shows lower variance than LOCO, providing reliable variable importance and higher statistical power, validated in simulations and real-world health data.", "conclusion": "PermuCATE is a robust tool for causal inference, especially in data-limited biomedical settings."}}
{"id": "2505.09814", "pdf": "https://arxiv.org/pdf/2505.09814", "abs": "https://arxiv.org/abs/2505.09814", "authors": ["Dmitry Rybin", "Yushun Zhang", "Zhi-Quan Luo"], "title": "$XX^{t}$ Can Be Faster", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.SC", "68Q25, 68T20", "F.2.1; I.1.2"], "comment": "improved presentation", "summary": "We present RXTX, a new algorithm for computing the product of matrix by its\ntranspose $XX^{t}$ for $X\\in \\mathbb{R}^{n\\times m}$. RXTX uses $5\\%$ fewer\nmultiplications and $5\\%$ fewer operations (additions and multiplications) than\nState-of-the-Art algorithms. Note that the accelerations not only holds\nasymptotically for large matrices with $n \\rightarrow \\infty$, but also for\nsmall matrices including $n = 4$. The algorithm was discovered by combining\nMachine Learning-based search methods with Combinatorial Optimization.", "AI": {"tldr": "RXTX is a new algorithm for computing $XX^{t}$ with 5% fewer multiplications and operations than SOTA, effective for both large and small matrices, discovered via ML and combinatorial optimization.", "motivation": "To improve efficiency in matrix multiplication by reducing computational operations.", "method": "Combines machine learning-based search with combinatorial optimization to discover RXTX.", "result": "Achieves 5% fewer multiplications and operations compared to existing methods, applicable to matrices of all sizes.", "conclusion": "RXTX offers a computationally efficient solution for matrix multiplication, validated across various matrix sizes."}}
{"id": "2410.07611", "pdf": "https://arxiv.org/pdf/2410.07611", "abs": "https://arxiv.org/abs/2410.07611", "authors": ["Zhenyu Tao", "Wei Xu", "Xiaohu You"], "title": "Large Vision Model-Enhanced Digital Twin with Deep Reinforcement Learning for User Association and Load Balancing in Dynamic Wireless Networks", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "arXiv admin note: text overlap with arXiv:2407.19765. This work has\n  been submitted to the IEEE for possible publication", "summary": "Optimization of user association in a densely deployed cellular network is\nusually challenging and even more complicated due to the dynamic nature of user\nmobility and fluctuation in user counts. While deep reinforcement learning\n(DRL) emerges as a promising solution, its application in practice is hindered\nby high trial-and-error costs in real world and unsatisfactory physical network\nperformance during training. Also, existing DRL-based user association methods\nare typically applicable to scenarios with a fixed number of users due to\nconvergence and compatibility challenges. To address these limitations, we\nintroduce a large vision model (LVM)-enhanced digital twin (DT) for wireless\nnetworks and propose a parallel DT-driven DRL method for user association and\nload balancing in networks with dynamic user counts, distribution, and mobility\npatterns. To construct this LVM-enhanced DT for DRL training, we develop a\nzero-shot generative user mobility model, named Map2Traj, based on the\ndiffusion model. Map2Traj estimates user trajectory patterns and spatial\ndistributions solely from street maps. DRL models undergo training in the DT\nenvironment, avoiding direct interactions with physical networks. To enhance\nthe generalization ability of DRL models for dynamic scenarios, a parallel DT\nframework is further established to alleviate strong correlation and\nnon-stationarity in single-environment training and improve training\nefficiency. Numerical results show that the developed LVM-enhanced DT achieves\nclosely comparable training efficacy to the real environment, and the proposed\nparallel DT framework even outperforms the single real-world environment in DRL\ntraining with nearly 20\\% gain in terms of cell-edge user performance.", "AI": {"tldr": "A parallel DT-driven DRL method is proposed for user association in dynamic cellular networks, using an LVM-enhanced digital twin and a zero-shot generative mobility model (Map2Traj) for efficient training.", "motivation": "Challenges in optimizing user association due to dynamic user mobility and fluctuating counts, along with high trial-and-error costs and poor performance of existing DRL methods in real-world scenarios.", "method": "Develops an LVM-enhanced digital twin with Map2Traj for trajectory estimation from street maps, and a parallel DT framework for DRL training to handle dynamic user scenarios.", "result": "The LVM-enhanced DT achieves comparable training efficacy to real environments, and the parallel DT framework improves cell-edge user performance by nearly 20%.", "conclusion": "The proposed method effectively addresses limitations of existing DRL approaches, offering scalable and efficient training for dynamic network scenarios."}}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology.\n  Our code and experiments are open-sourced at:\nhttps://github.com/GitsSaikat/QuXAI", "AI": {"tldr": "QuXAI introduces a framework for explaining hybrid quantum-classical ML models, addressing the lack of robust explainability in HQML systems.", "motivation": "The complexity of HQML models often results in black-box behavior, undermining transparency and reliability. This work aims to bridge the gap in explainability for such systems.", "method": "The approach involves creating HQML models with quantum feature maps, using Q-MEDLEY to explain feature importance while preserving quantum transformations, and visualizing attributions.", "result": "Q-MEDLEY effectively identifies influential classical aspects and noise in HQML models, performing competitively against classical XAI techniques. Ablation studies highlight the benefits of its composite structure.", "conclusion": "QuXAI enhances interpretability and reliability of HQML models, fostering safer and more responsible use of quantum-enhanced AI."}}
{"id": "2410.07972", "pdf": "https://arxiv.org/pdf/2410.07972", "abs": "https://arxiv.org/abs/2410.07972", "authors": ["Nicholas Gao", "Eike Eberhard", "Stephan G\u00fcnnemann"], "title": "Learning Equivariant Non-Local Electron Density Functionals", "categories": ["cs.LG", "physics.chem-ph", "physics.comp-ph"], "comment": "International Conference on Representation Learning, 2025", "summary": "The accuracy of density functional theory hinges on the approximation of\nnon-local contributions to the exchange-correlation (XC) functional. To date,\nmachine-learned and human-designed approximations suffer from insufficient\naccuracy, limited scalability, or dependence on costly reference data. To\naddress these issues, we introduce Equivariant Graph Exchange Correlation\n(EG-XC), a novel non-local XC functional based on equivariant graph neural\nnetworks (GNNs). Where previous works relied on semi-local functionals or\nfixed-size descriptors of the density, we compress the electron density into an\nSO(3)-equivariant nuclei-centered point cloud for efficient non-local\natomic-range interactions. By applying an equivariant GNN on this point cloud,\nwe capture molecular-range interactions in a scalable and accurate manner. To\ntrain EG-XC, we differentiate through a self-consistent field solver requiring\nonly energy targets. In our empirical evaluation, we find EG-XC to accurately\nreconstruct `gold-standard' CCSD(T) energies on MD17. On out-of-distribution\nconformations of 3BPA, EG-XC reduces the relative MAE by 35% to 50%.\nRemarkably, EG-XC excels in data efficiency and molecular size extrapolation on\nQM9, matching force fields trained on 5 times more and larger molecules. On\nidentical training sets, EG-XC yields on average 51% lower MAEs.", "AI": {"tldr": "EG-XC, a novel non-local XC functional using equivariant GNNs, improves accuracy and scalability in density functional theory by compressing electron density into a nuclei-centered point cloud.", "motivation": "Current machine-learned and human-designed XC functionals lack accuracy, scalability, or rely on costly data. EG-XC addresses these limitations.", "method": "EG-XC compresses electron density into an SO(3)-equivariant nuclei-centered point cloud and applies an equivariant GNN for scalable, accurate non-local interactions. Training involves differentiating through a self-consistent field solver with energy targets.", "result": "EG-XC accurately reconstructs CCSD(T) energies, reduces MAE by 35-50% on out-of-distribution data, and outperforms force fields in data efficiency and molecular size extrapolation.", "conclusion": "EG-XC offers a scalable, accurate, and data-efficient solution for non-local XC functionals, significantly improving upon existing methods."}}
{"id": "2411.09238", "pdf": "https://arxiv.org/pdf/2411.09238", "abs": "https://arxiv.org/abs/2411.09238", "authors": ["Xuanhao Pan", "Chenguang Wang", "Chaolong Ying", "Ye Xue", "Tianshu Yu"], "title": "Beyond the Heatmap: A Rigorous Evaluation of Component Impact in MCTS-Based TSP Solvers", "categories": ["cs.LG"], "comment": null, "summary": "The ``Heatmap + Monte Carlo Tree Search (MCTS)'' paradigm has recently\nemerged as a prominent framework for solving the Travelling Salesman Problem\n(TSP). While considerable effort has been devoted to enhancing heatmap\nsophistication through advanced learning models, this paper rigorously examines\nwhether this emphasis is justified, critically assessing the relative impact of\nheatmap complexity versus MCTS configuration. Our extensive empirical analysis\nacross diverse TSP scales, distributions, and benchmarks reveals two pivotal\ninsights: 1) The configuration of MCTS strategies significantly influences\nsolution quality, underscoring the importance of meticulous tuning to achieve\noptimal results and enabling valid comparisons among different heatmap\nmethodologies. 2) A rudimentary, parameter-free heatmap based on the intrinsic\n$k$-nearest neighbor structure of TSP instances, when coupled with an optimally\ntuned MCTS, can match or surpass the performance of more sophisticated, learned\nheatmaps, demonstrating robust generalizability on problem scale and\ndistribution shift. To facilitate rigorous and fair evaluations in future\nresearch, we introduce a streamlined pipeline for standardized MCTS\nhyperparameter tuning. Collectively, these findings challenge the prevalent\nassumption that heatmap complexity is the primary determinant of performance,\nadvocating instead for a balanced integration and comprehensive evaluation of\nboth learning and search components within this paradigm. Our code is available\nat: https://github.com/LOGO-CUHKSZ/rethink_mcts_tsp.", "AI": {"tldr": "The paper questions the overemphasis on heatmap complexity in the 'Heatmap + MCTS' paradigm for TSP, showing that MCTS tuning and simple heatmaps can outperform sophisticated ones.", "motivation": "To critically assess the impact of heatmap complexity versus MCTS configuration in solving TSP, challenging the assumption that heatmap sophistication is key.", "method": "Empirical analysis across diverse TSP scales and benchmarks, comparing heatmap complexity and MCTS tuning, and introducing a standardized MCTS hyperparameter tuning pipeline.", "result": "Optimal MCTS tuning with simple heatmaps matches or surpasses sophisticated heatmaps, highlighting MCTS's role in performance.", "conclusion": "A balanced integration of learning and search components is advocated, with standardized MCTS tuning for fair future evaluations."}}
{"id": "2412.09758", "pdf": "https://arxiv.org/pdf/2412.09758", "abs": "https://arxiv.org/abs/2412.09758", "authors": ["Yunfei Luo", "Yuliang Chen", "Asif Salekin", "Tauhidur Rahman"], "title": "Toward Foundation Model for Multivariate Wearable Sensing of Physiological Signals", "categories": ["cs.LG", "eess.SP"], "comment": "The code is available at:\n  http://github.com/Mobile-Sensing-and-UbiComp-Laboratory/NormWear", "summary": "Time-series foundation models excel at tasks like forecasting across diverse\ndata types by leveraging informative waveform representations. Wearable sensing\ndata, however, pose unique challenges due to their variability in patterns and\nfrequency bands, especially for healthcare-related outcomes. The main obstacle\nlies in crafting generalizable representations that adapt efficiently across\nheterogeneous sensing configurations and applications. To address this, we\npropose NormWear, the first multi-modal and ubiquitous foundation model\ndesigned to extract generalized and informative representations from wearable\nsensing data. Specifically, we design a channel-aware attention mechanism with\na shared special liaison [CLS] token to detect signal patterns in both\nintra-sensor and inter-sensors. This helps the model to extract more meaningful\ninformation considering both time series themselves and the relationships\nbetween input sensors. This helps the model to be widely compatible with\nvarious sensors settings. NormWear is pretrained on a diverse set of\nphysiological signals, including PPG, ECG, EEG, GSR, and IMU, from various\npublic datasets. Our model shows exceptional generalizability across 11 public\nwearable sensing datasets, spanning 18 applications in mental health, body\nstate inference, vital sign estimation, and disease risk evaluation. It\nconsistently outperforms competitive baselines under zero-shot, partial-shot,\nand full-shot settings, indicating broad applicability in real-world health\napplications.", "AI": {"tldr": "NormWear is a multi-modal foundation model for wearable sensing data, using channel-aware attention and a shared [CLS] token to generalize across diverse sensors and applications, outperforming baselines in various settings.", "motivation": "Wearable sensing data's variability and heterogeneity in healthcare applications necessitate generalizable representations, which existing models struggle to provide.", "method": "NormWear employs a channel-aware attention mechanism with a shared [CLS] token to detect intra- and inter-sensor signal patterns, pretrained on diverse physiological signals.", "result": "NormWear demonstrates exceptional generalizability across 11 datasets and 18 applications, outperforming baselines in zero-shot, partial-shot, and full-shot settings.", "conclusion": "NormWear is a versatile and effective foundation model for wearable sensing data, with broad applicability in real-world health monitoring and diagnostics."}}
{"id": "2501.05333", "pdf": "https://arxiv.org/pdf/2501.05333", "abs": "https://arxiv.org/abs/2501.05333", "authors": ["Ari Blondal", "Shan Gao", "Hamed Hatami", "Pooya Hatami"], "title": "Stability and List-Replicability for Agnostic Learners", "categories": ["cs.LG"], "comment": "Some minor changes to the terminology and presentation", "summary": "Two seminal papers--Alon, Livni, Malliaris, Moran (STOC 2019) and Bun, Livni,\nand Moran (FOCS 2020)--established the equivalence between online learnability\nand globally stable PAC learnability in binary classification. However, Chase,\nChornomaz, Moran, and Yehudayoff (STOC 2024) recently showed that this\nequivalence does not hold in the agnostic setting. Specifically, they proved\nthat in the agnostic setting, only finite hypothesis classes are globally\nstable learnable. Therefore, agnostic global stability is too restrictive to\ncapture interesting hypothesis classes.\n  To address this limitation, Chase et al. introduced two relaxations of\nagnostic global stability. In this paper, we characterize the classes that are\nlearnable under their proposed relaxed conditions, resolving the two open\nproblems raised in their work.\n  First, we prove that in the setting where the stability parameter can depend\non the excess error (the gap between the learner's error and the best\nachievable error by the hypothesis class), agnostic stability is fully\ncharacterized by the Littlestone dimension. Consequently, as in the realizable\ncase, this form of learnability is equivalent to online learnability.\n  As part of the proof of this theorem, we strengthen the celebrated result of\nBun et al. by showing that classes with infinite Littlestone dimension are not\nstably PAC learnable, even if we allow the stability parameter to depend on the\nexcess error.\n  For the second relaxation proposed by Chase et al., we prove that only finite\nhypothesis classes are globally stable learnable, even if we restrict the\nagnostic setting to distributions with small population loss.", "AI": {"tldr": "The paper resolves two open problems from Chase et al.'s work, showing that agnostic global stability is either too restrictive or equivalent to online learnability, depending on the relaxation.", "motivation": "To address the limitation of agnostic global stability being too restrictive, the paper explores relaxed conditions proposed by Chase et al.", "method": "Characterizes learnable classes under two relaxations: one where stability depends on excess error, and another restricted to small population loss distributions.", "result": "1. Agnostic stability with excess error dependence is equivalent to online learnability (Littlestone dimension). 2. Only finite classes are learnable under the second relaxation.", "conclusion": "The relaxations either align with online learnability or remain restrictive, resolving Chase et al.'s open problems."}}
{"id": "2501.18873", "pdf": "https://arxiv.org/pdf/2501.18873", "abs": "https://arxiv.org/abs/2501.18873", "authors": ["Akhil Agnihotri", "Rahul Jain", "Deepak Ramachandran", "Zheng Wen"], "title": "Active RLHF via Best Policy Learning from Trajectory Preference Feedback", "categories": ["cs.LG"], "comment": null, "summary": "We address the problem of best policy identification in preference-based\nreinforcement learning (PbRL), where learning occurs from noisy binary\npreferences over trajectory pairs rather than explicit numerical rewards. This\napproach is useful for post-training optimization of generative AI models\nduring multi-turn user interactions, where preference feedback is more robust\nthan handcrafted reward models. In this setting, learning is driven by both an\noffline preference dataset -- collected from a rater of unknown `competence' --\nand online data collected with pure exploration. Since offline datasets may\nexhibit out-of-distribution (OOD) biases, principled online data collection is\nnecessary. To address this, we propose Posterior Sampling for Preference\nLearning ($\\mathsf{PSPL}$), a novel algorithm inspired by Top-Two Thompson\nSampling, that maintains independent posteriors over the true reward model and\ntransition dynamics. We provide the first theoretical guarantees for PbRL in\nthis setting, establishing an upper bound on the simple Bayesian regret of\n$\\mathsf{PSPL}$. Since the exact algorithm can be computationally impractical,\nwe also provide an approximate version that outperforms existing baselines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2501.19342", "pdf": "https://arxiv.org/pdf/2501.19342", "abs": "https://arxiv.org/abs/2501.19342", "authors": ["Natalie Maus", "Kyurae Kim", "Yimeng Zeng", "Haydn Thomas Jones", "Fangping Wan", "Marcelo Der Torossian Torres", "Cesar de la Fuente-Nunez", "Jacob R. Gardner"], "title": "Covering Multiple Objectives with a Small Set of Solutions Using Bayesian Optimization", "categories": ["cs.LG"], "comment": null, "summary": "In multi-objective black-box optimization, the goal is typically to find\nsolutions that optimize a set of $T$ black-box objective functions, $f_1$, ...,\n$f_T$, simultaneously. Traditional approaches often seek a single\nPareto-optimal set that balances trade-offs among all objectives. In this work,\nwe consider a problem setting that departs from this paradigm: finding a small\nset of K < T solutions, that collectively \"covers\" the T objectives. A set of\nsolutions is defined as \"covering\" if, for each objective $f_1$, ..., $f_T$,\nthere is at least one good solution. A motivating example for this problem\nsetting occurs in drug design. For example, we may have T pathogens and aim to\nidentify a set of K < T antibiotics such that at least one antibiotic can be\nused to treat each pathogen. To address this problem, we propose\nMulti-Objective Coverage Bayesian Optimization (MOCOBO), a principled algorithm\ndesigned to efficiently find a covering set. We validate our approach through\nexperiments on challenging high-dimensional tasks, including applications in\npeptide and molecular design, where MOCOBO is shown to find high-performing\ncovering sets of solutions. The results show that the coverage of the K < T\nsolutions found by MOCOBO matches or nearly matches the coverage of T solutions\nobtained by optimizing each objective individually. Furthermore, in in vitro\nexperiments, the peptides found by MOCOBO exhibited high potency against\ndrug-resistant pathogens, further demonstrating the potential of MOCOBO for\ndrug discovery.", "AI": {"tldr": "MOCOBO is a Bayesian optimization method for finding a small set of solutions that collectively cover multiple objectives, validated in drug design applications.", "motivation": "Traditional multi-objective optimization seeks a single Pareto-optimal set, but this work addresses the need for a small set of solutions that cover all objectives, inspired by drug design challenges.", "method": "Proposes Multi-Objective Coverage Bayesian Optimization (MOCOBO) to efficiently find a covering set of K < T solutions for T objectives.", "result": "MOCOBO achieves coverage comparable to optimizing each objective individually, with successful in vitro peptide potency against drug-resistant pathogens.", "conclusion": "MOCOBO is effective for high-dimensional tasks like drug discovery, demonstrating practical utility in finding covering solutions."}}
{"id": "2502.00472", "pdf": "https://arxiv.org/pdf/2502.00472", "abs": "https://arxiv.org/abs/2502.00472", "authors": ["Dibyajyoti Chakraborty", "Arvind T. Mohan", "Romit Maulik"], "title": "Binned Spectral Power Loss for Improved Prediction of Chaotic Systems", "categories": ["cs.LG", "math.DS", "physics.flu-dyn"], "comment": null, "summary": "Forecasting multiscale chaotic dynamical systems with deep learning remains a\nformidable challenge due to the spectral bias of neural networks, which hinders\nthe accurate representation of fine-scale structures in long-term predictions.\nThis issue is exacerbated when models are deployed autoregressively, leading to\ncompounding errors and instability. In this work, we introduce a novel approach\nto mitigate the spectral bias which we call the Binned Spectral Power (BSP)\nLoss. The BSP loss is a frequency-domain loss function that adaptively weighs\nerrors in predicting both larger and smaller scales of the dataset. Unlike\ntraditional losses that focus on pointwise misfits, our BSP loss explicitly\npenalizes deviations in the energy distribution across different scales,\npromoting stable and physically consistent predictions. We demonstrate that the\nBSP loss mitigates the well-known problem of spectral bias in deep learning. We\nfurther validate our approach for the data-driven high-dimensional time-series\nforecasting of a range of benchmark chaotic systems which are typically\nintractable due to spectral bias. Our results demonstrate that the BSP loss\nsignificantly improves the stability and spectral accuracy of neural\nforecasting models without requiring architectural modifications. By directly\ntargeting spectral consistency, our approach paves the way for more robust deep\nlearning models for long-term forecasting of chaotic dynamical systems.", "AI": {"tldr": "The paper introduces the Binned Spectral Power (BSP) Loss to address spectral bias in deep learning for forecasting chaotic systems, improving stability and accuracy without architectural changes.", "motivation": "Spectral bias in neural networks hinders accurate long-term forecasting of multiscale chaotic systems, especially autoregressively, leading to compounding errors.", "method": "Proposes the BSP Loss, a frequency-domain loss function that adaptively weighs errors across scales, penalizing deviations in energy distribution.", "result": "BSP Loss mitigates spectral bias, enhancing stability and spectral accuracy in forecasting chaotic systems, validated on benchmark datasets.", "conclusion": "The BSP Loss enables more robust deep learning models for chaotic system forecasting by directly targeting spectral consistency."}}
{"id": "2502.01313", "pdf": "https://arxiv.org/pdf/2502.01313", "abs": "https://arxiv.org/abs/2502.01313", "authors": ["Jack Geary", "Henry Gouk"], "title": "Strategic Classification with Randomised Classifiers", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We consider the problem of strategic classification, where a learner must\nbuild a model to classify agents based on features that have been strategically\nmodified. Previous work in this area has concentrated on the case when the\nlearner is restricted to deterministic classifiers. In contrast, we perform a\ntheoretical analysis of an extension to this setting that allows the learner to\nproduce a randomised classifier. We show that, under certain conditions, the\noptimal randomised classifier can achieve better accuracy than the optimal\ndeterministic classifier, but under no conditions can it be worse. When a\nfinite set of training data is available, we show that the excess risk of\nStrategic Empirical Risk Minimisation over the class of randomised classifiers\nis bounded in a similar manner as the deterministic case. In both the\ndeterministic and randomised cases, the risk of the classifier produced by the\nlearner converges to that of the corresponding optimal classifier as the volume\nof available training data grows. Moreover, this convergence happens at the\nsame rate as in the i.i.d. case. Our findings are compared with previous\ntheoretical work analysing the problem of strategic classification. We conclude\nthat randomisation has the potential to alleviate some issues that could be\nfaced in practice without introducing any substantial downsides.", "AI": {"tldr": "The paper analyzes strategic classification with randomized classifiers, showing they can outperform deterministic ones without downsides, with risk bounds and convergence rates matching the i.i.d. case.", "motivation": "To extend strategic classification beyond deterministic classifiers by exploring the potential benefits of randomized classifiers.", "method": "Theoretical analysis of randomized classifiers in strategic classification, comparing their performance to deterministic ones and examining risk bounds and convergence rates.", "result": "Randomized classifiers can achieve better accuracy than deterministic ones under certain conditions, with no worse outcomes. Risk bounds and convergence rates are similar to the deterministic case.", "conclusion": "Randomization can improve strategic classification without introducing significant drawbacks, offering practical advantages."}}
{"id": "2502.02205", "pdf": "https://arxiv.org/pdf/2502.02205", "abs": "https://arxiv.org/abs/2502.02205", "authors": ["Peiyan Hu", "Xiaowei Qian", "Wenhao Deng", "Rui Wang", "Haodong Feng", "Ruiqi Feng", "Tao Zhang", "Long Wei", "Yue Wang", "Zhi-Ming Ma", "Tailin Wu"], "title": "From Uncertain to Safe: Conformal Fine-Tuning of Diffusion Models for Safe PDE Control", "categories": ["cs.LG"], "comment": "ICML 2025. 24 pages, 5 figures", "summary": "The application of deep learning for partial differential equation\n(PDE)-constrained control is gaining increasing attention. However, existing\nmethods rarely consider safety requirements crucial in real-world applications.\nTo address this limitation, we propose Safe Diffusion Models for PDE Control\n(SafeDiffCon), which introduce the uncertainty quantile as model uncertainty\nquantification to achieve optimal control under safety constraints through both\npost-training and inference phases. Firstly, our approach post-trains a\npre-trained diffusion model to generate control sequences that better satisfy\nsafety constraints while achieving improved control objectives via a reweighted\ndiffusion loss, which incorporates the uncertainty quantile estimated using\nconformal prediction. Secondly, during inference, the diffusion model\ndynamically adjusts both its generation process and parameters through\niterative guidance and fine-tuning, conditioned on control targets while\nsimultaneously integrating the estimated uncertainty quantile. We evaluate\nSafeDiffCon on three control tasks: 1D Burgers' equation, 2D incompressible\nfluid, and controlled nuclear fusion problem. Results demonstrate that\nSafeDiffCon is the only method that satisfies all safety constraints, whereas\nother classical and deep learning baselines fail. Furthermore, while adhering\nto safety constraints, SafeDiffCon achieves the best control performance. The\ncode can be found at https://github.com/AI4Science-WestlakeU/safediffcon.", "AI": {"tldr": "SafeDiffCon introduces uncertainty quantile for safe PDE control, outperforming baselines in safety and performance.", "motivation": "Addressing the lack of safety considerations in existing deep learning methods for PDE-constrained control.", "method": "Post-trains a diffusion model with reweighted loss and dynamic adjustment during inference using uncertainty quantile.", "result": "SafeDiffCon meets all safety constraints and achieves top control performance in tested tasks.", "conclusion": "SafeDiffCon effectively integrates safety into PDE control, setting a new benchmark for safe deep learning applications."}}
{"id": "2502.06774", "pdf": "https://arxiv.org/pdf/2502.06774", "abs": "https://arxiv.org/abs/2502.06774", "authors": ["Giacomo Lastrucci", "Artur M. Schweidtmann"], "title": "ENFORCE: Nonlinear Constrained Learning with Adaptive-depth Neural Projection", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring neural networks adhere to domain-specific constraints is crucial for\naddressing safety and ethical concerns while also enhancing inference accuracy.\nDespite the nonlinear nature of most real-world tasks, existing methods are\npredominantly limited to affine or convex constraints. We introduce ENFORCE, a\nneural network architecture that uses an adaptive projection module (AdaNP) to\nenforce nonlinear equality constraints in the predictions. We prove that our\nprojection mapping is 1-Lipschitz, making it well-suited for stable training.\nWe evaluate ENFORCE on an illustrative regression task and for learning\nsolutions to high-dimensional optimization problems in an unsupervised setting.\nThe predictions of our new architecture satisfy $N_C$ equality constraints that\nare nonlinear in both the inputs and outputs of the neural network, while\nmaintaining scalability with a tractable computational complexity of\n$\\mathcal{O}(N_C^3)$ at training and inference time.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2502.07319", "pdf": "https://arxiv.org/pdf/2502.07319", "abs": "https://arxiv.org/abs/2502.07319", "authors": ["Mingkai Xu", "Yongpeng Wu", "Yuxuan Shi", "Xiang-Gen Xia", "Wenjun Zhang", "Ping Zhang"], "title": "Learnable Residual-Based Latent Denoising in Semantic Communication", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "This paper has been accepted by IEEE Wireless Communications Letters", "summary": "A latent denoising semantic communication (SemCom) framework is proposed for\nrobust image transmission over noisy channels. By incorporating a learnable\nlatent denoiser into the receiver, the received signals are preprocessed to\neffectively remove the channel noise and recover the semantic information,\nthereby enhancing the quality of the decoded images. Specifically, a latent\ndenoising mapping is established by an iterative residual learning approach to\nimprove the denoising efficiency while ensuring stable performance. Moreover,\nchannel signal-to-noise ratio (SNR) is utilized to estimate and predict the\nlatent similarity score (SS) for conditional denoising, where the number of\ndenoising steps is adapted based on the predicted SS sequence, further reducing\nthe communication latency. Finally, simulations demonstrate that the proposed\nframework can effectively and efficiently remove the channel noise at various\nlevels and reconstruct visual-appealing images.", "AI": {"tldr": "A latent denoising semantic communication framework improves image transmission by removing channel noise and recovering semantic information, using iterative residual learning and adaptive denoising steps based on SNR.", "motivation": "To enhance the quality of decoded images in noisy channels by preprocessing received signals to remove noise and recover semantic information.", "method": "Incorporates a learnable latent denoiser at the receiver, uses iterative residual learning for efficient denoising, and adapts denoising steps based on predicted latent similarity scores from channel SNR.", "result": "Simulations show the framework effectively removes noise at various levels and reconstructs visually appealing images.", "conclusion": "The proposed framework robustly improves image transmission quality in noisy environments by efficiently denoising and adapting to channel conditions."}}
{"id": "2502.08882", "pdf": "https://arxiv.org/pdf/2502.08882", "abs": "https://arxiv.org/abs/2502.08882", "authors": ["Cong Wang", "Jiahong Chen", "Renjie Yang", "Dong Li", "Zhibin Wang", "Zongyu Yang", "Zhijun Wang", "Yixiong Wei", "Zhaoyang Liu", "Chenshu Hu", "Jing Li"], "title": "Integrated Data Analysis of Plasma Electron Density Profile Tomography for HL-3 with Gaussian Process Regression", "categories": ["cs.LG"], "comment": null, "summary": "An integrated data analysis model based on Gaussian Process Regression is\nproposed for plasma electron density profile tomography in the HL-3 tokamak.\nThe model combines line-integral measurements from the far-infrared laser\ninterferometer with point measurements obtained via the frequency-modulated\ncontinuous wave reflectometry. By employing Gaussian Process Regression, the\nmodel effectively incorporates point measurements into 2D profile\nreconstructions, while coordinate mapping integrates magnetic equilibrium\ninformation. The average relative error of the reconstructed profile obtained\nby the integrated data analysis model with normalized magnetic flux is as low\nas 3.60*10^(-4). Additionally, sensitivity tests were conducted on the grid\nresolution, the standard deviation of diagnostic data, and noise levels,\nproviding a robust foundation for the real application to experimental data.", "AI": {"tldr": "A Gaussian Process Regression model integrates line and point measurements for plasma electron density tomography in HL-3 tokamak, achieving high accuracy (3.60*10^(-4) and robustness.", "motivation": "To improve plasma electron density profile tomography by combining line-integral and point measurements for more accurate reconstructions.", "method": "Uses Gaussian Process Regression to integrate far-infrared laser interferometer and reflectometry data, incorporating magnetic equilibrium via coordinate mapping.", "result": "Achieves an average relative error of 3.60*10^(-4) and demonstrates robustness in sensitivity tests.", "conclusion": "The model provides a reliable and accurate solution for plasma density tomography in tokamaks."}}
{"id": "2502.13449", "pdf": "https://arxiv.org/pdf/2502.13449", "abs": "https://arxiv.org/abs/2502.13449", "authors": ["Dongki Kim", "Wonbin Lee", "Sung Ju Hwang"], "title": "Mol-LLaMA: Towards General Understanding of Molecules in Large Molecular Language Model", "categories": ["cs.LG", "physics.chem-ph"], "comment": "Project Page: https://mol-llama.github.io/", "summary": "Understanding molecules is key to understanding organisms and driving\nadvances in drug discovery, requiring interdisciplinary knowledge across\nchemistry and biology. Although large molecular language models have achieved\nnotable success in task transfer, they often struggle to accurately analyze\nmolecular features due to limited knowledge and reasoning capabilities. To\naddress this issue, we present Mol-LLaMA, a large molecular language model that\ngrasps the general knowledge centered on molecules and exhibits explainability\nand reasoning ability. To this end, we design key data types that encompass the\nfundamental molecular features, taking into account the essential abilities for\nmolecular reasoning. Further, to improve molecular understanding, we propose a\nmodule that integrates complementary information from different molecular\nencoders, leveraging the distinct advantages of molecular representations. Our\nexperimental results demonstrate that Mol-LLaMA is capable of comprehending the\ngeneral features of molecules and providing informative responses, implying its\npotential as a general-purpose assistant for molecular analysis. Our project\npage is at https://mol-llama.github.io/.", "AI": {"tldr": "Mol-LLaMA is a large molecular language model designed to improve molecular understanding by integrating general knowledge, explainability, and reasoning, outperforming existing models.", "motivation": "Existing molecular language models lack accurate analysis due to limited knowledge and reasoning, hindering drug discovery and interdisciplinary research.", "method": "Mol-LLaMA uses key data types for molecular features and integrates complementary information from various molecular encoders.", "result": "The model demonstrates improved comprehension of molecular features and provides informative responses.", "conclusion": "Mol-LLaMA shows potential as a general-purpose assistant for molecular analysis, advancing drug discovery and interdisciplinary research."}}
{"id": "2502.15952", "pdf": "https://arxiv.org/pdf/2502.15952", "abs": "https://arxiv.org/abs/2502.15952", "authors": ["Akshay Kumar", "Jarvis Haupt"], "title": "Towards Understanding Gradient Flow Dynamics of Homogeneous Neural Networks Beyond the Origin", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Recent works exploring the training dynamics of homogeneous neural network\nweights under gradient flow with small initialization have established that in\nthe early stages of training, the weights remain small and near the origin, but\nconverge in direction. Building on this, the current paper studies the gradient\nflow dynamics of homogeneous neural networks with locally Lipschitz gradients,\nafter they escape the origin. Insights gained from this analysis are used to\ncharacterize the first saddle point encountered by gradient flow after escaping\nthe origin. Also, it is shown that for homogeneous feed-forward neural\nnetworks, under certain conditions, the sparsity structure emerging among the\nweights before the escape is preserved after escaping the origin and until\nreaching the next saddle point.", "AI": {"tldr": "The paper analyzes gradient flow dynamics of homogeneous neural networks after escaping the origin, characterizing the first saddle point and preserving sparsity structure.", "motivation": "To understand the behavior of homogeneous neural networks post-origin escape and characterize early training dynamics.", "method": "Study gradient flow dynamics for networks with locally Lipschitz gradients, focusing on post-escape behavior and saddle points.", "result": "The first saddle point post-escape is characterized, and sparsity structure is preserved until the next saddle point.", "conclusion": "Insights into early training dynamics and sparsity preservation in homogeneous networks are provided."}}
{"id": "2502.16667", "pdf": "https://arxiv.org/pdf/2502.16667", "abs": "https://arxiv.org/abs/2502.16667", "authors": ["Pranav Vaidhyanathan", "Aristotelis Papatheodorou", "Mark T. Mitchison", "Natalia Ares", "Ioannis Havoutis"], "title": "MetaSym: A Symplectic Meta-learning Framework for Physical Intelligence", "categories": ["cs.LG", "cs.RO", "physics.comp-ph", "quant-ph"], "comment": "10 + 11 pages, 5 figures, 8 tables", "summary": "Scalable and generalizable physics-aware deep learning has long been\nconsidered a significant challenge with various applications across diverse\ndomains ranging from robotics to molecular dynamics. Central to almost all\nphysical systems are symplectic forms, the geometric backbone that underpins\nfundamental invariants like energy and momentum. In this work, we introduce a\nnovel deep learning framework, MetaSym. In particular, MetaSym combines a\nstrong symplectic inductive bias obtained from a symplectic encoder, and an\nautoregressive decoder with meta-attention. This principled design ensures that\ncore physical invariants remain intact, while allowing flexible, data-efficient\nadaptation to system heterogeneities. We benchmark MetaSym with highly varied\nand realistic datasets, such as a high-dimensional spring-mesh system (Otness\net al., 2021), an open quantum system with dissipation and measurement\nbackaction, and robotics-inspired quadrotor dynamics. Our results demonstrate\nsuperior performance in modeling dynamics under few-shot adaptation,\noutperforming state-of-the-art baselines that use larger models.", "AI": {"tldr": "MetaSym is a novel deep learning framework combining symplectic inductive bias and meta-attention for scalable, physics-aware modeling, outperforming state-of-the-art baselines.", "motivation": "Addressing the challenge of scalable and generalizable physics-aware deep learning, especially preserving physical invariants like energy and momentum.", "method": "MetaSym integrates a symplectic encoder for strong inductive bias and an autoregressive decoder with meta-attention for flexible adaptation.", "result": "Superior performance in few-shot adaptation across varied datasets (spring-mesh, quantum systems, quadrotor dynamics).", "conclusion": "MetaSym effectively balances physical invariance and adaptability, demonstrating state-of-the-art results."}}
{"id": "2502.18994", "pdf": "https://arxiv.org/pdf/2502.18994", "abs": "https://arxiv.org/abs/2502.18994", "authors": ["Weilin Chen", "Ruichu Cai", "Yuguang Yan", "Zhifeng Hao", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"], "title": "Long-term Causal Inference via Modeling Sequential Latent Confounding", "categories": ["cs.LG"], "comment": null, "summary": "Long-term causal inference is an important but challenging problem across\nvarious scientific domains. To solve the latent confounding problem in\nlong-term observational studies, existing methods leverage short-term\nexperimental data. Ghassami et al. propose an approach based on the Conditional\nAdditive Equi-Confounding Bias (CAECB) assumption, which asserts that the\nconfounding bias in the short-term outcome is equal to that in the long-term\noutcome, so that the long-term confounding bias and the causal effects can be\nidentified. While effective in certain cases, this assumption is limited to\nscenarios where there is only one short-term outcome with the same scale as the\nlong-term outcome. In this paper, we introduce a novel assumption that extends\nthe CAECB assumption to accommodate temporal short-term outcomes. Our proposed\nassumption states a functional relationship between sequential confounding\nbiases across temporal short-term outcomes, under which we theoretically\nestablish the identification of long-term causal effects. Based on the\nidentification result, we develop an estimator and conduct a theoretical\nanalysis of its asymptotic properties. Extensive experiments validate our\ntheoretical results and demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "The paper extends the CAECB assumption to handle temporal short-term outcomes, enabling long-term causal effect identification under a functional relationship between sequential confounding biases.", "motivation": "Address the limitation of the CAECB assumption, which is restricted to single short-term outcomes, by proposing a more flexible assumption for temporal outcomes.", "method": "Introduce a novel assumption linking sequential confounding biases in temporal short-term outcomes, develop an estimator, and analyze its asymptotic properties.", "result": "Theoretical identification of long-term causal effects is established, and experiments validate the method's effectiveness.", "conclusion": "The proposed method successfully extends the CAECB framework, enabling broader applicability in long-term causal inference."}}
{"id": "2503.09986", "pdf": "https://arxiv.org/pdf/2503.09986", "abs": "https://arxiv.org/abs/2503.09986", "authors": ["Rohan Bhatnagar", "Ling Liang", "Krish Patel", "Haizhao Yang"], "title": "From Equations to Insights: Unraveling Symbolic Structures in PDEs with LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Motivated by the remarkable success of artificial intelligence (AI) across\ndiverse fields, the application of AI to solve scientific problems, often\nformulated as partial differential equations (PDEs), has garnered increasing\nattention. While most existing research concentrates on theoretical properties\n(such as well-posedness, regularity, and continuity) of the solutions,\nalongside direct AI-driven methods for solving PDEs, the challenge of\nuncovering symbolic relationships within these equations remains largely\nunexplored. In this paper, we propose leveraging large language models (LLMs)\nto learn such symbolic relationships. Our results demonstrate that LLMs can\neffectively predict the operators involved in PDE solutions by utilizing the\nsymbolic information in the PDEs both theoretically and numerically.\nFurthermore, we show that discovering these symbolic relationships can\nsubstantially improve both the efficiency and accuracy of symbolic machine\nlearning for finding analytical approximation of PDE solutions, delivering a\nfully interpretable solution pipeline. This work opens new avenues for\nunderstanding the symbolic structure of scientific problems and advancing their\nsolution processes.", "AI": {"tldr": "The paper proposes using large language models (LLMs) to uncover symbolic relationships in PDEs, improving efficiency and accuracy in solving them.", "motivation": "The success of AI in diverse fields motivates its application to scientific problems like PDEs, where symbolic relationships remain underexplored.", "method": "Leverage LLMs to learn symbolic relationships in PDEs, predicting operators and improving symbolic machine learning.", "result": "LLMs effectively predict PDE operators, enhancing efficiency and accuracy in finding analytical approximations.", "conclusion": "This approach advances understanding of symbolic structures in scientific problems and improves solution processes."}}
{"id": "2503.13766", "pdf": "https://arxiv.org/pdf/2503.13766", "abs": "https://arxiv.org/abs/2503.13766", "authors": ["Daniel Racz", "Mihaly Petreczky", "Balint Daroczy"], "title": "A finite-sample bound for identifying partially observed linear switched systems from a single trajectory", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We derive a finite-sample probabilistic bound on the parameter estimation\nerror of a system identification algorithm for Linear Switched Systems. The\nalgorithm estimates Markov parameters from a single trajectory and applies a\nvariant of the Ho-Kalman algorithm to recover the system matrices. Our bound\nguarantees statistical consistency under the assumption that the true system\nexhibits quadratic stability. The proof leverages the theory of weakly\ndependent processes. To the best of our knowledge, this is the first\nfinite-sample bound for this algorithm in the single-trajectory setting.", "AI": {"tldr": "A finite-sample probabilistic bound for parameter estimation error in Linear Switched Systems is derived, ensuring statistical consistency under quadratic stability.", "motivation": "To provide a theoretical guarantee for the parameter estimation error of a system identification algorithm in Linear Switched Systems, addressing the lack of finite-sample bounds in single-trajectory settings.", "method": "The algorithm estimates Markov parameters from a single trajectory and uses a variant of the Ho-Kalman algorithm to recover system matrices. The proof uses weakly dependent processes theory.", "result": "The derived bound guarantees statistical consistency under quadratic stability assumptions.", "conclusion": "This work presents the first finite-sample bound for the algorithm in single-trajectory settings, advancing theoretical understanding of system identification for Linear Switched Systems."}}
{"id": "2503.15573", "pdf": "https://arxiv.org/pdf/2503.15573", "abs": "https://arxiv.org/abs/2503.15573", "authors": ["Da Ma", "Gonghu Shang", "Zhi Chen", "Libo Qin", "Yijie Luo", "Lei Pan", "Shuai Fan", "Lu Chen", "Kai Yu"], "title": "Task-Specific Data Selection for Instruction Tuning via Monosemantic Neuronal Activations", "categories": ["cs.LG"], "comment": "preprint, (20 pages, 7 figures, 13 tables)", "summary": "Instruction tuning improves the ability of large language models (LLMs) to\nfollow diverse human instructions, but achieving strong performance on specific\ntarget tasks remains challenging. A critical bottleneck is selecting the most\nrelevant data to maximize task-specific performance. Existing data selection\napproaches include unstable influence-based methods and more stable\ndistribution alignment methods, the latter of which critically rely on the\nunderlying sample representation. In practice, most distribution alignment\nmethods, from shallow features (e.g., BM25) to neural embeddings (e.g., BGE,\nLLM2Vec), may fail to capture how the model internally processes samples. To\nbridge this gap, we adopt a model-centric strategy in which each sample is\nrepresented by its neuronal activation pattern in the model, directly\nreflecting internal computation. However, directly using raw neuron activations\nleads to spurious similarity between unrelated samples due to neuron\npolysemanticity, where a single neuron may respond to multiple, unrelated\nconcepts. To address this, we employ sparse autoencoders to disentangle\npolysemantic activations into sparse, monosemantic representations, and\nintroduce a dedicated similarity metric for this space to better identify\ntask-relevant data. Comprehensive experiments across multiple instruction\ndatasets, models, tasks, and selection ratios show that our approach\nconsistently outperforms existing data selection baselines in both stability\nand task-specific performance.", "AI": {"tldr": "The paper introduces a model-centric data selection method using sparse autoencoders to improve task-specific performance in instruction-tuned LLMs by capturing internal neuron activations.", "motivation": "Existing data selection methods for LLMs, like influence-based or distribution alignment, often fail to reflect how models internally process samples, limiting task-specific performance.", "method": "The authors represent samples by their neuron activation patterns, use sparse autoencoders to disentangle polysemantic activations, and introduce a similarity metric for better data selection.", "result": "Experiments show the method outperforms baselines in stability and task-specific performance across various datasets and models.", "conclusion": "The proposed approach effectively bridges the gap in data selection by leveraging internal model computations, enhancing LLM performance on target tasks."}}
{"id": "2503.21812", "pdf": "https://arxiv.org/pdf/2503.21812", "abs": "https://arxiv.org/abs/2503.21812", "authors": ["Jianping Ye", "Michel Wedel", "Kunpeng Zhang"], "title": "IPGO: Indirect Prompt Gradient Optimization for Parameter-Efficient Prompt-level Fine-Tuning on Text-to-Image Models", "categories": ["cs.LG"], "comment": "9 pages, 2 figures, 4 tables", "summary": "Text-to-Image Diffusion models excel at generating images from text prompts\nbut often exhibit suboptimal alignment with content semantics, aesthetics, and\nhuman preferences. To address these limitations, this study proposes a novel\nparameter-efficient framework, Indirect Prompt Gradient Optimization (IPGO),\nfor prompt-level diffusion model fine-tuning. IPGO enhances prompt embeddings\nby injecting continuously differentiable embeddings at the beginning and end of\nthe prompt embeddings, leveraging low-rank structures with the flexibility and\nnonlinearity from rotations. This approach enables gradient-based optimization\nof injected embeddings under range, orthonormality, and conformity constraints,\neffectively narrowing the search space, promoting a stable solution, and\nensuring alignment between the embeddings of the injected embeddings and the\noriginal prompt. Its extension IPGO+ adds a parameter-free cross-attention\nmechanism on the prompt embedding to enforce dependencies between the original\nprompt and the inserted embeddings. We conduct extensive evaluations through\nprompt-wise (IPGO) and prompt-batch (IPGO+) training using three reward models\nof image aesthetics, image-text alignment, and human preferences across three\ndatasets of varying complexity. The results show that IPGO consistently\noutperforms SOTA benchmarks, including stable diffusion v1.5 with raw prompts,\ntext-embedding-based methods (TextCraftor), training-based methods (DRaFT and\nDDPO), and training-free methods (DPO-Diffusion, Promptist, and ChatGPT-4o).\nSpecifically, IPGO achieves a win-rate exceeding 99% in prompt-wise learning,\nand IPGO+ achieves a comparable, but often better performance against current\nSOTAs (a 75% win rate) in prompt-batch learning. Moreover, we illustrate IPGO's\ngeneralizability and its capability to significantly enhance image quality\nwhile requiring minimal data and resources.", "AI": {"tldr": "IPGO and IPGO+ are novel frameworks for fine-tuning text-to-image diffusion models, improving alignment with semantics, aesthetics, and human preferences. They outperform SOTA methods with high win-rates.", "motivation": "Address suboptimal alignment in text-to-image diffusion models with content semantics, aesthetics, and human preferences.", "method": "Proposes IPGO for prompt-level fine-tuning using gradient optimization of injected embeddings with constraints. IPGO+ adds a cross-attention mechanism. Evaluated with reward models on three datasets.", "result": "IPGO achieves >99% win-rate in prompt-wise learning; IPGO+ achieves 75% win-rate in prompt-batch learning, outperforming SOTA benchmarks.", "conclusion": "IPGO and IPGO+ significantly enhance image quality with minimal data and resources, demonstrating generalizability and superior performance."}}
{"id": "2504.09604", "pdf": "https://arxiv.org/pdf/2504.09604", "abs": "https://arxiv.org/abs/2504.09604", "authors": ["Christopher M. Ackerman", "Nina Panickssery"], "title": "Mitigating Many-Shot Jailbreaking", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Many-shot jailbreaking (MSJ) is an adversarial technique that exploits the\nlong context windows of modern LLMs to circumvent model safety training by\nincluding in the prompt many examples of a \"fake\" assistant responding\ninappropriately before the final request. With enough examples, the model's\nin-context learning abilities override its safety training, and it responds as\nif it were the \"fake\" assistant. In this work, we probe the effectiveness of\ndifferent fine-tuning and input sanitization approaches on mitigating MSJ\nattacks, alone and in combination. We find incremental mitigation effectiveness\nfor each, and show that the combined techniques significantly reduce the\neffectiveness of MSJ attacks, while retaining model performance in benign\nin-context learning and conversational tasks. We suggest that our approach\ncould meaningfully ameliorate this vulnerability if incorporated into model\nsafety post-training.", "AI": {"tldr": "The paper explores mitigation techniques for Many-shot jailbreaking (MSJ) attacks on LLMs, showing that combining fine-tuning and input sanitization significantly reduces attack effectiveness while maintaining model performance.", "motivation": "To address the vulnerability of modern LLMs to MSJ attacks, where adversarial prompts exploit long context windows to bypass safety training.", "method": "Evaluates fine-tuning and input sanitization approaches, both individually and combined, to mitigate MSJ attacks.", "result": "Combined techniques significantly reduce MSJ attack effectiveness without harming benign task performance.", "conclusion": "The proposed approach could effectively mitigate MSJ vulnerabilities if integrated into model safety post-training."}}
{"id": "2504.09629", "pdf": "https://arxiv.org/pdf/2504.09629", "abs": "https://arxiv.org/abs/2504.09629", "authors": ["Yamato Arai", "Yuma Ichikawa"], "title": "Quantization Error Propagation: Revisiting Layer-Wise Post-Training Quantization", "categories": ["cs.LG", "stat.AP", "stat.ME", "stat.ML"], "comment": "28 pages, 3 figures", "summary": "Layer-wise PTQ is a promising technique for compressing large language models\n(LLMs), due to its simplicity and effectiveness without requiring retraining.\nHowever, recent progress in this area is saturating, underscoring the need to\nrevisit its core limitations and explore further improvements. We address this\nchallenge by identifying a key limitation of existing layer-wise PTQ methods:\nthe growth of quantization errors across layers significantly degrades\nperformance, particularly in low-bit regimes. To address this fundamental\nissue, we propose Quantization Error Propagation (QEP), a general, lightweight,\nand scalable framework that enhances layer-wise PTQ by explicitly propagating\nquantization errors and compensating for accumulated errors. QEP also offers a\ntunable propagation mechanism that prevents overfitting and controls\ncomputational overhead, enabling the framework to adapt to various\narchitectures and resource budgets. Extensive experiments on several LLMs\ndemonstrate that QEP-enhanced layer-wise PTQ achieves substantially higher\naccuracy than existing methods. Notably, the gains are most pronounced in the\nextremely low-bit quantization regime.", "AI": {"tldr": "QEP improves layer-wise PTQ by addressing quantization error propagation, enhancing accuracy, especially in low-bit regimes.", "motivation": "Existing layer-wise PTQ methods suffer from growing quantization errors across layers, degrading performance, particularly in low-bit settings.", "method": "Proposes Quantization Error Propagation (QEP), a lightweight framework that propagates and compensates for quantization errors, with tunable propagation to balance performance and overhead.", "result": "QEP-enhanced PTQ achieves higher accuracy than existing methods, with notable gains in extremely low-bit quantization.", "conclusion": "QEP effectively addresses core limitations of layer-wise PTQ, offering a scalable and adaptable solution for improved quantization performance."}}
{"id": "2504.14250", "pdf": "https://arxiv.org/pdf/2504.14250", "abs": "https://arxiv.org/abs/2504.14250", "authors": ["Yunhui Liu", "Jiashun Cheng", "Yiqing Lin", "Qizhuo Xie", "Jia Li", "Fugee Tsung", "Hongzhi Yin", "Tao Zheng", "Jianhua Zhao", "Tieke He"], "title": "Towards Anomaly-Aware Pre-Training and Fine-Tuning for Graph Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Graph anomaly detection (GAD) has garnered increasing attention in recent\nyears, yet remains challenging due to two key factors: (1) label scarcity\nstemming from the high cost of annotations and (2) homophily disparity at node\nand class levels. In this paper, we introduce Anomaly-Aware Pre-Training and\nFine-Tuning (APF), a targeted and effective framework to mitigate the above\nchallenges in GAD. In the pre-training stage, APF incorporates node-specific\nsubgraphs selected via the Rayleigh Quotient, a label-free anomaly metric, into\nthe learning objective to enhance anomaly awareness. It further introduces two\nlearnable spectral polynomial filters to jointly learn dual representations\nthat capture both general semantics and subtle anomaly cues. During\nfine-tuning, a gated fusion mechanism adaptively integrates pre-trained\nrepresentations across nodes and dimensions, while an anomaly-aware\nregularization loss encourages abnormal nodes to preserve more anomaly-relevant\ninformation. Furthermore, we theoretically show that APF tends to achieve\nlinear separability under mild conditions. Comprehensive experiments on 10\nbenchmark datasets validate the superior performance of APF in comparison to\nstate-of-the-art baselines.", "AI": {"tldr": "APF is a framework for graph anomaly detection (GAD) that addresses label scarcity and homophily disparity through anomaly-aware pre-training and fine-tuning, achieving superior performance.", "motivation": "The challenges in GAD include label scarcity due to costly annotations and homophily disparity at node and class levels.", "method": "APF uses Rayleigh Quotient for anomaly-aware pre-training, spectral polynomial filters for dual representations, and a gated fusion mechanism with anomaly-aware regularization during fine-tuning.", "result": "APF outperforms state-of-the-art baselines on 10 benchmark datasets and theoretically achieves linear separability under mild conditions.", "conclusion": "APF effectively mitigates GAD challenges and demonstrates strong performance, validated by experiments."}}
{"id": "2504.18433", "pdf": "https://arxiv.org/pdf/2504.18433", "abs": "https://arxiv.org/abs/2504.18433", "authors": ["Christopher B\u00fclte", "Yusuf Sale", "Timo L\u00f6hr", "Paul Hofman", "Gitta Kutyniok", "Eyke H\u00fcllermeier"], "title": "An Axiomatic Assessment of Entropy- and Variance-based Uncertainty Quantification in Regression", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Uncertainty quantification (UQ) is crucial in machine learning, yet most\n(axiomatic) studies of uncertainty measures focus on classification, leaving a\ngap in regression settings with limited formal justification and evaluations.\nIn this work, we introduce a set of axioms to rigorously assess measures of\naleatoric, epistemic, and total uncertainty in supervised regression. By\nutilizing a predictive exponential family, we can generalize commonly used\napproaches for uncertainty representation and corresponding uncertainty\nmeasures. More specifically, we analyze the widely used entropy- and\nvariance-based measures regarding limitations and challenges. Our findings\nprovide a principled foundation for uncertainty quantification in regression,\noffering theoretical insights and practical guidelines for reliable uncertainty\nassessment.", "AI": {"tldr": "The paper introduces axioms to evaluate uncertainty measures in regression, generalizing common approaches and analyzing entropy- and variance-based measures.", "motivation": "Address the gap in formal justification and evaluation of uncertainty measures in regression settings.", "method": "Proposes axioms for assessing aleatoric, epistemic, and total uncertainty, using a predictive exponential family to generalize uncertainty representation.", "result": "Identifies limitations of entropy- and variance-based measures, providing a principled foundation for uncertainty quantification.", "conclusion": "Offers theoretical insights and practical guidelines for reliable uncertainty assessment in regression."}}
{"id": "2505.02296", "pdf": "https://arxiv.org/pdf/2505.02296", "abs": "https://arxiv.org/abs/2505.02296", "authors": ["Pinaki Mohanty", "Riddhiman Bhattacharya", "Ruqi Zhang"], "title": "Entropy-Guided Sampling of Flat Modes in Discrete Spaces", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Sampling from flat modes in discrete spaces is a crucial yet underexplored\nproblem. Flat modes represent robust solutions and have broad applications in\ncombinatorial optimization and discrete generative modeling. However, existing\nsampling algorithms often overlook the mode volume and struggle to capture flat\nmodes effectively. To address this limitation, we propose \\emph{Entropic\nDiscrete Langevin Proposal} (EDLP), which incorporates local entropy into the\nsampling process through a continuous auxiliary variable under a joint\ndistribution. The local entropy term guides the discrete sampler toward flat\nmodes with a small overhead. We provide non-asymptotic convergence guarantees\nfor EDLP in locally log-concave discrete distributions. Empirically, our method\nconsistently outperforms traditional approaches across tasks that require\nsampling from flat basins, including Bernoulli distribution, restricted\nBoltzmann machines, combinatorial optimization, and binary neural networks.", "AI": {"tldr": "Proposes Entropic Discrete Langevin Proposal (EDLP) for sampling from flat modes in discrete spaces, outperforming traditional methods.", "motivation": "Flat modes are robust solutions but underexplored; existing methods struggle to sample them effectively.", "method": "EDLP incorporates local entropy via a continuous auxiliary variable under a joint distribution, guiding the sampler toward flat modes.", "result": "EDLP shows superior performance in tasks like Bernoulli distribution, Boltzmann machines, and combinatorial optimization.", "conclusion": "EDLP effectively addresses the challenge of sampling from flat modes with theoretical guarantees and empirical success."}}
{"id": "2505.03049", "pdf": "https://arxiv.org/pdf/2505.03049", "abs": "https://arxiv.org/abs/2505.03049", "authors": ["Yoel Zimmermann", "Adib Bazgir", "Alexander Al-Feghali", "Mehrad Ansari", "Joshua Bocarsly", "L. Catherine Brinson", "Yuan Chiang", "Defne Circi", "Min-Hsueh Chiu", "Nathan Daelman", "Matthew L. Evans", "Abhijeet S. Gangan", "Janine George", "Hassan Harb", "Ghazal Khalighinejad", "Sartaaj Takrim Khan", "Sascha Klawohn", "Magdalena Lederbauer", "Soroush Mahjoubi", "Bernadette Mohr", "Seyed Mohamad Moosavi", "Aakash Naik", "Aleyna Beste Ozhan", "Dieter Plessers", "Aritra Roy", "Fabian Sch\u00f6ppach", "Philippe Schwaller", "Carla Terboven", "Katharina Ueltzen", "Yue Wu", "Shang Zhu", "Jan Janssen", "Calvin Li", "Ian Foster", "Ben Blaiszik"], "title": "34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": "arXiv admin note: substantial text overlap with arXiv:2411.15221.\n  This paper is a refinement and analysis of the raw project submissions from\n  arXiv:2411.15221", "summary": "Large Language Models (LLMs) are reshaping many aspects of materials science\nand chemistry research, enabling advances in molecular property prediction,\nmaterials design, scientific automation, knowledge extraction, and more. Recent\ndevelopments demonstrate that the latest class of models are able to integrate\nstructured and unstructured data, assist in hypothesis generation, and\nstreamline research workflows. To explore the frontier of LLM capabilities\nacross the research lifecycle, we review applications of LLMs through 34 total\nprojects developed during the second annual Large Language Model Hackathon for\nApplications in Materials Science and Chemistry, a global hybrid event. These\nprojects spanned seven key research areas: (1) molecular and material property\nprediction, (2) molecular and material design, (3) automation and novel\ninterfaces, (4) scientific communication and education, (5) research data\nmanagement and automation, (6) hypothesis generation and evaluation, and (7)\nknowledge extraction and reasoning from the scientific literature.\nCollectively, these applications illustrate how LLMs serve as versatile\npredictive models, platforms for rapid prototyping of domain-specific tools,\nand much more. In particular, improvements in both open source and proprietary\nLLM performance through the addition of reasoning, additional training data,\nand new techniques have expanded effectiveness, particularly in low-data\nenvironments and interdisciplinary research. As LLMs continue to improve, their\nintegration into scientific workflows presents both new opportunities and new\nchallenges, requiring ongoing exploration, continued refinement, and further\nresearch to address reliability, interpretability, and reproducibility.", "AI": {"tldr": "LLMs are transforming materials science and chemistry by enhancing property prediction, design, automation, and knowledge extraction, as demonstrated by 34 projects from a hackathon.", "motivation": "To explore and showcase the expanding capabilities of LLMs in materials science and chemistry, highlighting their versatility and potential impact on research workflows.", "method": "Review of 34 projects from the Large Language Model Hackathon, covering seven key research areas like property prediction, design, automation, and knowledge extraction.", "result": "LLMs prove effective as predictive models and prototyping tools, with improvements in reasoning and training data enhancing their performance in low-data and interdisciplinary settings.", "conclusion": "While LLMs offer significant opportunities for scientific research, challenges like reliability and interpretability require further exploration and refinement."}}
{"id": "2505.05926", "pdf": "https://arxiv.org/pdf/2505.05926", "abs": "https://arxiv.org/abs/2505.05926", "authors": ["Milad Khademi Nori", "Il-Min Kim", "Guanghui Wang"], "title": "Autoencoder-Based Hybrid Replay for Class-Incremental Learning", "categories": ["cs.LG"], "comment": "Accepted ICML 2025", "summary": "In class-incremental learning (CIL), effective incremental learning\nstrategies are essential to mitigate task confusion and catastrophic\nforgetting, especially as the number of tasks $t$ increases. Current exemplar\nreplay strategies impose $\\mathcal{O}(t)$ memory/compute complexities. We\npropose an autoencoder-based hybrid replay (AHR) strategy that leverages our\nnew hybrid autoencoder (HAE) to function as a compressor to alleviate the\nrequirement for large memory, achieving $\\mathcal{O}(0.1 t)$ at the worst case\nwith the computing complexity of $\\mathcal{O}(t)$ while accomplishing\nstate-of-the-art performance. The decoder later recovers the exemplar data\nstored in the latent space, rather than in raw format. Additionally, HAE is\ndesigned for both discriminative and generative modeling, enabling\nclassification and replay capabilities, respectively. HAE adopts the charged\nparticle system energy minimization equations and repulsive force algorithm for\nthe incremental embedding and distribution of new class centroids in its latent\nspace. Our results demonstrate that AHR consistently outperforms recent\nbaselines across multiple benchmarks while operating with the same\nmemory/compute budgets. The source code is included in the supplementary\nmaterial and will be open-sourced upon publication.", "AI": {"tldr": "Proposes an autoencoder-based hybrid replay (AHR) strategy for class-incremental learning, reducing memory complexity to O(0.1t) while maintaining performance.", "motivation": "Addresses the challenges of task confusion and catastrophic forgetting in class-incremental learning, aiming to reduce memory and compute complexities.", "method": "Uses a hybrid autoencoder (HAE) as a compressor for exemplar replay, employing energy minimization and repulsive force algorithms for latent space management.", "result": "AHR achieves state-of-the-art performance with reduced memory requirements (O(0.1t)) and maintains compute complexity (O(t)).", "conclusion": "AHR outperforms baselines in benchmarks, offering efficient memory use and high performance, with plans to open-source the code."}}
{"id": "2505.07783", "pdf": "https://arxiv.org/pdf/2505.07783", "abs": "https://arxiv.org/abs/2505.07783", "authors": ["Yanxin Liu", "Yunqi Zhang"], "title": "Relative Overfitting and Accept-Reject Framework", "categories": ["cs.LG"], "comment": null, "summary": "Currently, the scaling law of Large Language Models (LLMs) faces challenges\nand bottlenecks. This paper posits that noise effects, stemming from changes in\nthe signal-to-noise ratio under diminishing marginal returns, are the root\ncause of these issues. To control this noise, we investigated the differences\nbetween models with performance advantages and disadvantages, introducing the\nconcept of \"relative overfitting.\" Based on their complementary strengths, we\nhave proposed an application framework, Accept-Reject (AR). In Natural Language\nProcessing (NLP), we use LLMs and Small Language Models (SLMs) as the medium\nfor discussion. This framework enables SLMs to exert a universal positive\ninfluence on LLM decision outputs, rather than the intuitively expected\nnegative influence. We validated our approach using self-built models based on\nmainstream architectures and pre-trained mainstream models across multiple\ndatasets, including basic language modeling, long-context tasks, subject\nexamination, and question-answering (QA) benchmarks. The results demonstrate\nthat through our structure, compared to increasing the LLM's parameters, we can\nachieve better performance improvements with significantly lower parameter and\ncomputational costs in many scenarios. These improvements are universal,\nstable, and effective. Furthermore, we explore the potential of \"relative\noverfitting\" and the AR framework in other machine learning domains, such as\ncomputer vision (CV) and AI for science. We hope the proposed approach can help\nscale laws overcome existing bottlenecks.", "AI": {"tldr": "The paper addresses scaling challenges in LLMs by attributing them to noise effects and introduces the 'relative overfitting' concept and AR framework to improve performance efficiently.", "motivation": "To tackle bottlenecks in LLM scaling laws caused by noise effects and diminishing returns, aiming for cost-effective performance improvements.", "method": "Proposes the AR framework, leveraging complementary strengths of LLMs and SLMs, validated on diverse NLP tasks and datasets.", "result": "Demonstrates better performance improvements with lower costs compared to increasing LLM parameters, showing universal and stable effectiveness.", "conclusion": "The AR framework and 'relative overfitting' concept offer potential to overcome scaling bottlenecks in LLMs and other ML domains like CV and AI for science."}}
{"id": "2505.08199", "pdf": "https://arxiv.org/pdf/2505.08199", "abs": "https://arxiv.org/abs/2505.08199", "authors": ["Boshi Gao", "Qingjian Ni", "Fanbo Ju", "Yu Chen", "Ziqi Zhao"], "title": "A Multi-scale Representation Learning Framework for Long-Term Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Long-term time series forecasting (LTSF) offers broad utility in practical\nsettings like energy consumption and weather prediction. Accurately predicting\nlong-term changes, however, is demanding due to the intricate temporal patterns\nand inherent multi-scale variations within time series. This work confronts key\nissues in LTSF, including the suboptimal use of multi-granularity information,\nthe neglect of channel-specific attributes, and the unique nature of trend and\nseasonal components, by introducing a proficient MLP-based forecasting\nframework. Our method adeptly disentangles complex temporal dynamics using\nclear, concurrent predictions across various scales. These multi-scale\nforecasts are then skillfully integrated through a system that dynamically\nassigns importance to information from different granularities, sensitive to\nindividual channel characteristics. To manage the specific features of temporal\npatterns, a two-pronged structure is utilized to model trend and seasonal\nelements independently. Experimental results on eight LTSF benchmarks\ndemonstrate that MDMixer improves average MAE performance by 4.64% compared to\nthe recent state-of-the-art MLP-based method (TimeMixer), while achieving an\neffective balance between training efficiency and model interpretability.", "AI": {"tldr": "The paper introduces MDMixer, an MLP-based framework for long-term time series forecasting (LTSF), addressing multi-granularity information use, channel-specific attributes, and trend/seasonal components. It outperforms TimeMixer by 4.64% in MAE.", "motivation": "LTSF is challenging due to complex temporal patterns and multi-scale variations. Existing methods underutilize multi-granularity data and ignore channel-specific attributes.", "method": "MDMixer disentangles temporal dynamics with multi-scale predictions, dynamically integrates them, and separately models trend and seasonal components.", "result": "MDMixer improves MAE by 4.64% over TimeMixer on eight benchmarks, balancing efficiency and interpretability.", "conclusion": "MDMixer effectively addresses LTSF challenges, offering superior performance and practical utility."}}
{"id": "2505.08371", "pdf": "https://arxiv.org/pdf/2505.08371", "abs": "https://arxiv.org/abs/2505.08371", "authors": ["Takashi Nicholas Maeda", "Shohei Shimizu", "Hidetoshi Matsui"], "title": "Density Ratio-based Causal Discovery from Bivariate Continuous-Discrete Data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper proposes a causal discovery method for mixed bivariate data\nconsisting of one continuous and one discrete variable. Existing\nconstraint-based approaches are ineffective in the bivariate setting, as they\nrely on conditional independence tests that are not suited to bivariate data.\nScore-based methods either impose strong distributional assumptions or face\nchallenges in fairly comparing causal directions between variables of different\ntypes, due to differences in their information content. We introduce a novel\napproach that determines causal direction by analyzing the monotonicity of the\nconditional density ratio of the continuous variable, conditioned on different\nvalues of the discrete variable. Our theoretical analysis shows that the\nconditional density ratio exhibits monotonicity when the continuous variable\ncauses the discrete variable, but not in the reverse direction. This property\nprovides a principled basis for comparing causal directions between variables\nof different types, free from strong distributional assumptions and bias\narising from differences in their information content. We demonstrate its\neffectiveness through experiments on both synthetic and real-world datasets,\nshowing superior accuracy compared to existing methods.", "AI": {"tldr": "A novel causal discovery method for mixed bivariate data (continuous and discrete) using conditional density ratio monotonicity, outperforming existing approaches.", "motivation": "Existing methods struggle with bivariate data due to reliance on conditional independence tests or unfair comparisons between variable types.", "method": "Analyzes monotonicity of the conditional density ratio of the continuous variable given the discrete variable to determine causal direction.", "result": "Theoretical proof and experiments show the method's accuracy, surpassing current techniques.", "conclusion": "The approach provides a principled, assumption-free way to infer causality in mixed bivariate data."}}
{"id": "2505.09663", "pdf": "https://arxiv.org/pdf/2505.09663", "abs": "https://arxiv.org/abs/2505.09663", "authors": ["Julian B\u00fcchel", "Iason Chalas", "Giovanni Acampa", "An Chen", "Omobayode Fagbohungbe", "Sidney Tsai", "Kaoutar El Maghraoui", "Manuel Le Gallo", "Abbas Rahimi", "Abu Sebastian"], "title": "Analog Foundation Models", "categories": ["cs.LG"], "comment": "43 pages, 8 figures, under review", "summary": "Analog in-memory computing (AIMC) is a promising compute paradigm to improve\nspeed and power efficiency of neural network inference beyond the limits of\nconventional von Neumann-based architectures. However, AIMC introduces\nfundamental challenges such as noisy computations and strict constraints on\ninput and output quantization. Because of these constraints and imprecisions,\noff-the-shelf LLMs are not able to achieve 4-bit-level performance when\ndeployed on AIMC-based hardware. While researchers previously investigated\nrecovering this accuracy gap on small, mostly vision-based models, a generic\nmethod applicable to LLMs pre-trained on trillions of tokens does not yet\nexist. In this work, we introduce a general and scalable method to robustly\nadapt LLMs for execution on noisy, low-precision analog hardware. Our approach\nenables state-of-the-art models $\\unicode{x2013}$ including\nPhi-3-mini-4k-instruct and Llama-3.2-1B-Instruct $\\unicode{x2013}$ to retain\nperformance comparable to 4-bit weight, 8-bit activation baselines, despite the\npresence of analog noise and quantization constraints. Additionally, we show\nthat as a byproduct of our training methodology, analog foundation models can\nbe quantized for inference on low-precision digital hardware. Finally, we show\nthat our models also benefit from test-time compute scaling, showing better\nscaling behavior than models trained with 4-bit weight and 8-bit static input\nquantization. Our work bridges the gap between high-capacity LLMs and efficient\nanalog hardware, offering a path toward energy-efficient foundation models.\nCode is available at https://github.com/IBM/analog-foundation-models.", "AI": {"tldr": "A general method to adapt LLMs for noisy, low-precision analog hardware, retaining performance comparable to 4-bit weight, 8-bit activation baselines.", "motivation": "Analog in-memory computing (AIMC) offers speed and power efficiency but introduces noise and quantization constraints, limiting LLM performance.", "method": "A scalable training methodology to robustly adapt LLMs for analog hardware, addressing noise and quantization.", "result": "State-of-the-art models like Phi-3-mini-4k-instruct and Llama-3.2-1B-Instruct achieve performance comparable to 4-bit weight, 8-bit activation baselines.", "conclusion": "The work bridges the gap between high-capacity LLMs and efficient analog hardware, enabling energy-efficient foundation models."}}
{"id": "2505.09864", "pdf": "https://arxiv.org/pdf/2505.09864", "abs": "https://arxiv.org/abs/2505.09864", "authors": ["Aditya Panangat"], "title": "BINGO: A Novel Pruning Mechanism to Reduce the Size of Neural Networks", "categories": ["cs.LG"], "comment": "6 pages, 0 figures, 2 tables", "summary": "Over the past decade, the use of machine learning has increased\nexponentially. Models are far more complex than ever before, growing to\ngargantuan sizes and housing millions of weights. Unfortunately, the fact that\nlarge models have become the state of the art means that it often costs\nmillions of dollars to train and operate them. These expenses not only hurt\ncompanies but also bar non-wealthy individuals from contributing to new\ndevelopments and force consumers to pay greater prices for AI. Current methods\nused to prune models, such as iterative magnitude pruning, have shown great\naccuracy but require an iterative training sequence that is incredibly\ncomputationally and environmentally taxing. To solve this problem, BINGO is\nintroduced. BINGO, during the training pass, studies specific subsets of a\nneural network one at a time to gauge how significant of a role each weight\nplays in contributing to a network's accuracy. By the time training is done,\nBINGO generates a significance score for each weight, allowing for\ninsignificant weights to be pruned in one shot. BINGO provides an\naccuracy-preserving pruning technique that is less computationally intensive\nthan current methods, allowing for a world where AI growth does not have to\nmean model growth, as well.", "AI": {"tldr": "BINGO introduces a one-shot pruning method for neural networks, reducing computational costs while preserving accuracy, addressing the high expenses of large models.", "motivation": "The high cost and computational demands of training large neural networks limit accessibility and sustainability, prompting the need for efficient pruning techniques.", "method": "BINGO evaluates weight significance during training, assigning scores to prune insignificant weights in one shot, avoiding iterative processes.", "result": "BINGO achieves accuracy-preserving pruning with lower computational and environmental costs compared to existing methods.", "conclusion": "BINGO enables efficient model pruning, promoting sustainable and accessible AI development without sacrificing performance."}}
{"id": "1908.09173", "pdf": "https://arxiv.org/pdf/1908.09173", "abs": "https://arxiv.org/abs/1908.09173", "authors": ["Victor Chernozhukov", "Whitney Newey", "Vira Semenova"], "title": "Welfare Analysis in Dynamic Models", "categories": ["stat.ML", "cs.LG", "econ.EM"], "comment": null, "summary": "This paper introduces metrics for welfare analysis in dynamic models. We\ndevelop estimation and inference for these parameters even in the presence of a\nhigh-dimensional state space. Examples of welfare metrics include average\nwelfare, average marginal welfare effects, and welfare decompositions into\ndirect and indirect effects similar to Oaxaca (1973) and Blinder (1973). We\nderive dual and doubly robust representations of welfare metrics that\nfacilitate debiased inference. For average welfare, the value function does not\nhave to be estimated. In general, debiasing can be applied to any estimator of\nthe value function, including neural nets, random forests, Lasso, boosting, and\nother high-dimensional methods. In particular, we derive Lasso and Neural\nNetwork estimators of the value function and associated dynamic dual\nrepresentation and establish associated mean square convergence rates for these\nfunctions. Debiasing is automatic in the sense that it only requires knowledge\nof the welfare metric of interest, not the form of bias correction. The\nproposed methods are applied to estimate a dynamic behavioral model of teacher\nabsenteeism in \\cite{DHR} and associated average teacher welfare.", "AI": {"tldr": "The paper introduces welfare metrics for dynamic models, develops estimation methods for high-dimensional state spaces, and provides debiased inference techniques applicable to various estimators like neural nets and Lasso.", "motivation": "To address welfare analysis in dynamic models with high-dimensional state spaces, enabling robust estimation and inference for welfare metrics.", "method": "Develops dual and doubly robust representations of welfare metrics, debiased inference techniques, and applies Lasso and Neural Network estimators for the value function.", "result": "Establishes mean square convergence rates for estimators and demonstrates application in a dynamic behavioral model of teacher absenteeism.", "conclusion": "The proposed methods facilitate debiased welfare analysis in high-dimensional settings, with practical applications in behavioral modeling."}}
{"id": "2301.09192", "pdf": "https://arxiv.org/pdf/2301.09192", "abs": "https://arxiv.org/abs/2301.09192", "authors": ["Omar Fawzi", "Aadil Oufkir", "Daniel Stilck Fran\u00e7a"], "title": "Lower Bounds on Learning Pauli Channels with Individual Measurements", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "comment": "31+5 pages", "summary": "Understanding the noise affecting a quantum device is of fundamental\nimportance for scaling quantum technologies. A particularly important class of\nnoise models is that of Pauli channels, as randomized compiling techniques can\neffectively bring any quantum channel to this form and are significantly more\nstructured than general quantum channels. In this paper, we show fundamental\nlower bounds on the sample complexity for learning Pauli channels in diamond\nnorm. We consider strategies that may not use auxiliary systems entangled with\nthe input to the unknown channel and have to perform a measurement before\nreusing the channel. For non-adaptive algorithms, we show a lower bound of\n$\\Omega(2^{3n}\\varepsilon^{-2})$ to learn an $n$-qubit Pauli channel. In\nparticular, this shows that the recently introduced learning procedure by\nFlammia and Wallman is essentially optimal. In the adaptive setting, we show a\nlower bound of $\\Omega(2^{2.5n}\\varepsilon^{-2})$ for\n$\\varepsilon=\\mathcal{O}(2^{-n})$, and a lower bound of\n$\\Omega(2^{2n}\\varepsilon^{-2} )$ for any $\\varepsilon> 0$. This last lower\nbound holds even in a stronger model where in each step, before performing the\nmeasurement, the unknown channel may be used arbitrarily many times\nsequentially interspersed with unital operations.", "AI": {"tldr": "The paper establishes fundamental lower bounds on the sample complexity for learning Pauli channels in diamond norm, showing optimality of existing methods and exploring adaptive vs. non-adaptive strategies.", "motivation": "Understanding noise in quantum devices is crucial for scaling quantum technologies, with Pauli channels being a key class due to their structured nature and relevance in randomized compiling.", "method": "The study derives lower bounds for learning Pauli channels, comparing non-adaptive and adaptive strategies, including scenarios with auxiliary systems and repeated channel use.", "result": "Non-adaptive algorithms require \u03a9(2^{3n}\u03b5^{-2}) samples, proving Flammia and Wallman's method optimal. Adaptive strategies have lower bounds of \u03a9(2^{2.5n}\u03b5^{-2}) for \u03b5=O(2^{-n}) and \u03a9(2^{2n}\u03b5^{-2}) for any \u03b5>0.", "conclusion": "The results highlight the inherent difficulty of learning Pauli channels and provide benchmarks for future quantum noise characterization methods."}}
{"id": "2308.16468", "pdf": "https://arxiv.org/pdf/2308.16468", "abs": "https://arxiv.org/abs/2308.16468", "authors": ["Yahya Saleh", "\u00c1lvaro Fern\u00e1ndez Corral", "Emil Vogt", "Armin Iske", "Jochen K\u00fcpper", "Andrey Yachmenev"], "title": "Computing excited states of molecules using normalizing flows", "categories": ["physics.chem-ph", "cs.LG"], "comment": null, "summary": "Calculations of highly excited and delocalized molecular vibrational states\nare computationally challenging tasks, which strongly depends on the choice of\ncoordinates for describing vibrational motions. We introduce a new method that\nleverages normalizing flows -- parametrized invertible functions -- to learn\noptimal vibrational coordinates that satisfy the variational principle. This\napproach produces coordinates tailored to the vibrational problem at hand,\nsignificantly increasing the accuracy and enhancing basis-set convergence of\nthe calculated energy spectrum. The efficiency of the method is demonstrated in\ncalculations of the 100 lowest excited vibrational states of H$_2$S, H$_2$CO,\nand HCN/HNC. The method effectively captures the essential vibrational behavior\nof molecules by enhancing the separability of the Hamiltonian and hence allows\nfor an effective assignment of approximate quantum numbers. We demonstrate that\nthe optimized coordinates are transferable across different levels of basis-set\ntruncation, enabling a cost-efficient protocol for computing vibrational\nspectra of high-dimensional systems.", "AI": {"tldr": "A new method using normalizing flows to learn optimal vibrational coordinates improves accuracy and basis-set convergence for calculating excited molecular vibrational states.", "motivation": "The challenge of calculating highly excited and delocalized molecular vibrational states depends heavily on coordinate choice, necessitating a more efficient approach.", "method": "The method employs normalizing flows (parametrized invertible functions) to derive optimal vibrational coordinates that adhere to the variational principle.", "result": "Demonstrated on H$_2$S, H$_2$CO, and HCN/HNC, the method enhances accuracy, basis-set convergence, and quantum number assignment.", "conclusion": "The optimized coordinates are transferable, enabling cost-efficient vibrational spectrum calculations for high-dimensional systems."}}
{"id": "2311.01762", "pdf": "https://arxiv.org/pdf/2311.01762", "abs": "https://arxiv.org/abs/2311.01762", "authors": ["Oskar Allerbo"], "title": "Changing the Kernel During Training Leads to Double Descent in Kernel Regression", "categories": ["stat.ML", "cs.LG", "math.OC", "stat.ME"], "comment": "Article arXiv:2306.16838v1 has been updated and split into two\n  articles: this article and arXiv:2306.16838v2. Thus, much of the content in\n  this article is also a part of arXiv:2306.16838v1", "summary": "We investigate changing the bandwidth of a translational-invariant kernel\nduring training when solving kernel regression with gradient descent. We\npresent a theoretical bound on the out-of-sample generalization error that\nadvocates for decreasing the bandwidth (and thus increasing the model\ncomplexity) during training. We further use the bound to show that kernel\nregression exhibits a double descent behavior when the model complexity is\nexpressed as the minimum allowed bandwidth during training. Decreasing the\nbandwidth all the way to zero results in benign overfitting, and also\ncircumvents the need for model selection. We demonstrate the double descent\nbehavior on real and synthetic data and also demonstrate that kernel regression\nwith a decreasing bandwidth outperforms that of a constant bandwidth, selected\nby cross-validation or marginal likelihood maximization. We finally apply our\nfindings to neural networks, demonstrating that by modifying the neural tangent\nkernel (NTK) during training, making the NTK behave as if its bandwidth were\ndecreasing to zero, we can make the network overfit more benignly, and converge\nin fewer iterations.", "AI": {"tldr": "The paper explores adjusting kernel bandwidth during training for kernel regression, showing improved generalization and benign overfitting.", "motivation": "To improve out-of-sample generalization and avoid model selection by dynamically adjusting kernel bandwidth.", "method": "Theoretical analysis of generalization error bounds and empirical validation on real/synthetic data, extending to neural networks via NTK modification.", "result": "Decreasing bandwidth leads to benign overfitting, double descent behavior, and outperforms constant-bandwidth methods.", "conclusion": "Dynamic bandwidth adjustment enhances kernel regression and neural network training, enabling benign overfitting and faster convergence."}}
{"id": "2311.17840", "pdf": "https://arxiv.org/pdf/2311.17840", "abs": "https://arxiv.org/abs/2311.17840", "authors": ["Ainesh Bakshi", "Vincent Cohen-Addad", "Samuel B. Hopkins", "Rajesh Jayaram", "Silvio Lattanzi"], "title": "Metric Embeddings Beyond Bi-Lipschitz Distortion via Sherali-Adams", "categories": ["cs.DS", "cs.LG", "stat.ML"], "comment": "COLT 2025", "summary": "Metric embeddings are a widely used method in algorithm design, where\ngenerally a ``complex'' metric is embedded into a simpler, lower-dimensional\none. Historically, the theoretical computer science community has focused on\nbi-Lipschitz embeddings, which guarantee that every pairwise distance is\napproximately preserved. In contrast, alternative embedding objectives that are\ncommonly used in practice avoid bi-Lipschitz distortion; yet these approaches\nhave received comparatively less study in theory. In this paper, we focus on\nMulti-dimensional Scaling (MDS), where we are given a set of non-negative\ndissimilarities $\\{d_{i,j}\\}_{i,j\\in [n]}$ over $n$ points, and the goal is to\nfind an embedding $\\{x_1,\\dots,x_n\\} \\subset R^k$ that minimizes\n$$\\textrm{OPT}=\\min_{x}\\mathbb{E}_{i,j\\in [n]}\\left(1-\\frac{\\|x_i -\nx_j\\|}{d_{i,j}}\\right)^2.$$\n  Despite its popularity, our theoretical understanding of MDS is extremely\nlimited. Recently, Demaine et. al. (arXiv:2109.11505) gave the first\napproximation algorithm with provable guarantees for this objective, which\nachieves an embedding in constant dimensional Euclidean space with cost\n$\\textrm{OPT} +\\epsilon$ in $n^2\\cdot 2^{\\textrm{poly}(\\Delta/\\epsilon)}$ time,\nwhere $\\Delta$ is the aspect ratio of the input dissimilarities. For metrics\nthat admit low-cost embeddings, $\\Delta$ scales polynomially in $n$. In this\nwork, we give the first approximation algorithm for MDS with quasi-polynomial\ndependency on $\\Delta$: for constant dimensional Euclidean space, we achieve a\nsolution with cost $O(\\log \\Delta)\\cdot \\textrm{OPT}^{\\Omega(1)}+\\epsilon$ in\ntime $n^{O(1)} \\cdot 2^{\\text{poly}((\\log(\\Delta)/\\epsilon))}$. Our algorithms\nare based on a novel geometry-aware analysis of a conditional rounding of the\nSherali-Adams LP Hierarchy, allowing us to avoid exponential dependency on the\naspect ratio, which would typically result from this rounding.", "AI": {"tldr": "The paper presents a novel approximation algorithm for Multi-dimensional Scaling (MDS) with quasi-polynomial dependency on the aspect ratio, improving upon previous exponential dependencies.", "motivation": "MDS is widely used but lacks theoretical understanding. The goal is to improve approximation algorithms for MDS, focusing on reducing dependency on the aspect ratio.", "method": "The authors use a geometry-aware analysis of a conditional rounding of the Sherali-Adams LP Hierarchy to avoid exponential dependency on the aspect ratio.", "result": "They achieve a solution with cost $O(\\log \\Delta)\\cdot \\textrm{OPT}^{\\Omega(1)}+\\epsilon$ in quasi-polynomial time, improving previous results.", "conclusion": "This work advances the theoretical understanding of MDS and provides a more efficient algorithm for practical applications."}}
{"id": "2403.07471", "pdf": "https://arxiv.org/pdf/2403.07471", "abs": "https://arxiv.org/abs/2403.07471", "authors": ["Lucas de Lara", "Mathis Deronzier", "Alberto Gonz\u00e1lez-Sanz", "Virgile Foy"], "title": "On the Nonconvexity of Push-Forward Constraints and Its Consequences in Machine Learning", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "The push-forward operation enables one to redistribute a probability measure\nthrough a deterministic map. It plays a key role in statistics and\noptimization: many learning problems (notably from optimal transport,\ngenerative modeling, and algorithmic fairness) include constraints or penalties\nframed as push-forward conditions on the model. However, the literature lacks\ngeneral theoretical insights on the (non)convexity of such constraints and its\nconsequences on the associated learning problems. This paper aims at filling\nthis gap. In the first part, we provide a range of sufficient and necessary\nconditions for the (non)convexity of two sets of functions: the maps\ntransporting one probability measure to another and the maps inducing equal\noutput distributions across distinct probability measures. This highlights that\nfor most probability measures, these push-forward constraints are not convex.\nIn the second part, we show how this result implies critical limitations on the\ndesign of convex optimization problems for learning generative models or\ngroupwise fair predictors. This work will hopefully help researchers and\npractitioners have a better understanding of the critical impact of\npush-forward conditions onto convexity.", "AI": {"tldr": "The paper analyzes the (non)convexity of push-forward constraints in learning problems, revealing their general non-convexity and implications for optimization.", "motivation": "To address the lack of theoretical insights on the convexity of push-forward constraints in learning problems like optimal transport, generative modeling, and algorithmic fairness.", "method": "Provides sufficient and necessary conditions for the (non)convexity of maps transporting probability measures or inducing equal output distributions.", "result": "For most probability measures, push-forward constraints are not convex, limiting convex optimization in learning problems.", "conclusion": "Highlights the impact of push-forward conditions on convexity, aiding better understanding for researchers and practitioners."}}
{"id": "2405.12892", "pdf": "https://arxiv.org/pdf/2405.12892", "abs": "https://arxiv.org/abs/2405.12892", "authors": ["Yuang Zhao", "Zhaocheng Du", "Qinglin Jia", "Linxuan Zhang", "Zhenhua Dong", "Ruiming Tang"], "title": "Retrievable Domain-Sensitive Feature Memory for Multi-Domain Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "With the increase in the business scale and number of domains in online\nadvertising, multi-domain ad recommendation has become a mainstream solution in\nthe industry. The core of multi-domain recommendation is effectively modeling\nthe commonalities and distinctions among domains. Existing works are dedicated\nto designing model architectures for implicit multi-domain modeling while\noverlooking an in-depth investigation from a more fundamental perspective of\nfeature distributions. This paper focuses on features with significant\ndifferences across various domains in both distributions and effects on model\npredictions. We refer to these features as domain-sensitive features, which\nserve as carriers of domain distinctions and are crucial for multi-domain\nmodeling. Experiments demonstrate that existing multi-domain modeling methods\nmay neglect domain-sensitive features, indicating insufficient learning of\ndomain distinctions. To avoid this neglect, we propose a domain-sensitive\nfeature attribution method to identify features that best reflect domain\ndistinctions from the feature set. Further, we design a memory architecture\nthat extracts domain-specific information from domain-sensitive features for\nthe model to retrieve and integrate, thereby enhancing the awareness of domain\ndistinctions. Extensive offline and online experiments demonstrate the\nsuperiority of our method in capturing domain distinctions and improving\nmulti-domain recommendation performance.", "AI": {"tldr": "The paper introduces a method to identify and utilize domain-sensitive features for better multi-domain ad recommendation by addressing gaps in existing approaches.", "motivation": "Existing multi-domain recommendation methods focus on model architectures but overlook feature distribution analysis, leading to insufficient learning of domain distinctions.", "method": "Proposes a domain-sensitive feature attribution method to identify key features and a memory architecture to extract and integrate domain-specific information.", "result": "Experiments show the method effectively captures domain distinctions and improves recommendation performance.", "conclusion": "The approach enhances multi-domain modeling by leveraging domain-sensitive features, outperforming existing methods."}}
{"id": "2408.15852", "pdf": "https://arxiv.org/pdf/2408.15852", "abs": "https://arxiv.org/abs/2408.15852", "authors": ["Paul Fuchs", "Stephan Thaler", "Sebastien R\u00f6cken", "Julija Zavadlav"], "title": "chemtrain: Learning Deep Potential Models via Automatic Differentiation and Statistical Physics", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "comment": "Package source code published at http://github.com/tummfm/chemtrain", "summary": "Neural Networks (NNs) are effective models for refining the accuracy of\nmolecular dynamics, opening up new fields of application. Typically trained\nbottom-up, atomistic NN potential models can reach first-principle accuracy,\nwhile coarse-grained implicit solvent NN potentials surpass classical continuum\nsolvent models. However, overcoming the limitations of costly generation of\naccurate reference data and data inefficiency of common bottom-up training\ndemands efficient incorporation of data from many sources. This paper\nintroduces the framework chemtrain to learn sophisticated NN potential models\nthrough customizable training routines and advanced training algorithms. These\nroutines can combine multiple top-down and bottom-up algorithms, e.g., to\nincorporate both experimental and simulation data or pre-train potentials with\nless costly algorithms. chemtrain provides an object-oriented high-level\ninterface to simplify the creation of custom routines. On the lower level,\nchemtrain relies on JAX to compute gradients and scale the computations to use\navailable resources. We demonstrate the simplicity and importance of combining\nmultiple algorithms in the examples of parametrizing an all-atomistic model of\ntitanium and a coarse-grained implicit solvent model of alanine dipeptide.", "AI": {"tldr": "chemtrain framework combines top-down and bottom-up training to efficiently learn NN potentials, addressing data inefficiency and costly reference data generation.", "motivation": "Overcoming limitations of costly reference data generation and data inefficiency in NN potential training.", "method": "Introduces chemtrain, a customizable framework combining multiple training algorithms (top-down and bottom-up) and leveraging JAX for scalability.", "result": "Demonstrated effectiveness in parametrizing all-atomistic and coarse-grained implicit solvent models.", "conclusion": "chemtrain simplifies and enhances NN potential training by integrating diverse data sources and algorithms."}}
{"id": "2410.08604", "pdf": "https://arxiv.org/pdf/2410.08604", "abs": "https://arxiv.org/abs/2410.08604", "authors": ["Shojiro Yamabe", "Futa Waseda", "Tsubasa Takahashi", "Koki Wataoka"], "title": "MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted at ACL 2025 Main", "summary": "Protecting the intellectual property of Large Language Models (LLMs) has\nbecome increasingly critical due to the high cost of training. Model merging,\nwhich integrates multiple expert models into a single multi-task model,\nintroduces a novel risk of unauthorized use of LLMs due to its efficient\nmerging process. While fingerprinting techniques have been proposed for\nverifying model ownership, their resistance to model merging remains\nunexplored. To address this gap, we propose a novel fingerprinting method,\nMergePrint, which embeds robust fingerprints capable of surviving model\nmerging. MergePrint enables black-box ownership verification, where owners only\nneed to check if a model produces target outputs for specific fingerprint\ninputs, without accessing model weights or intermediate outputs. By optimizing\nagainst a pseudo-merged model that simulates merged behavior, MergePrint\nensures fingerprints that remain detectable after merging. Additionally, to\nminimize performance degradation, we pre-optimize the fingerprint inputs.\nMergePrint pioneers a practical solution for black-box ownership verification,\nprotecting LLMs from misappropriation via merging, while also excelling in\nresistance to broader model theft threats.", "AI": {"tldr": "MergePrint is a fingerprinting method for LLMs to verify ownership post-model merging, ensuring robustness and minimal performance impact.", "motivation": "Address the unexplored risk of unauthorized LLM use via model merging, necessitating a robust ownership verification method.", "method": "Embed fingerprints optimized for survival in merged models, using pseudo-merged models for simulation and pre-optimized inputs.", "result": "MergePrint enables black-box verification, detects fingerprints post-merging, and resists broader model theft.", "conclusion": "MergePrint offers a practical solution for protecting LLMs from misappropriation through merging and theft."}}
{"id": "2411.00105", "pdf": "https://arxiv.org/pdf/2411.00105", "abs": "https://arxiv.org/abs/2411.00105", "authors": ["Philip A. LeMaitre", "T. Rick Perche", "Marius Krumm", "Hans J. Briegel"], "title": "A Universal Quantum Computer From Relativistic Motion", "categories": ["quant-ph", "cs.LG", "gr-qc"], "comment": "5 pages + appendices, 1 figure - revtex4-2. v2: Updated to match\n  published version", "summary": "We present an explicit construction of a relativistic quantum computing\narchitecture using a variational quantum circuit approach that is shown to\nallow for universal quantum computing. The variational quantum circuit consists\nof tunable single-qubit rotations and entangling gates that are implemented\nsuccessively. The single qubit rotations are parameterized by the proper time\nintervals of the qubits' trajectories and can be tuned by varying their\nrelativistic motion in spacetime. The entangling layer is mediated by a\nrelativistic quantum field instead of through direct coupling between the\nqubits. Within this setting, we give a prescription for how to use quantum\nfield-mediated entanglement and manipulation of the relativistic motion of\nqubits to obtain a universal gate set, for which compact non-perturbative\nexpressions that are valid for general spacetimes are also obtained. We also\nderive a lower bound on the channel fidelity that shows the existence of\nparameter regimes in which all entangling operations are effectively unitary,\ndespite the noise generated from the presence of a mediating quantum field.\nFinally, we consider an explicit implementation of the quantum Fourier\ntransform with relativistic qubits.", "AI": {"tldr": "A relativistic quantum computing architecture is proposed using variational quantum circuits with tunable single-qubit rotations and field-mediated entangling gates, enabling universal quantum computing.", "motivation": "To explore the integration of relativistic effects into quantum computing, leveraging spacetime dynamics and quantum fields for gate operations.", "method": "Variational quantum circuits with parameterized single-qubit rotations (tuned by relativistic motion) and field-mediated entangling gates.", "result": "Universal gate set derived with non-perturbative expressions; lower bound on channel fidelity shows unitary entangling operations in certain regimes.", "conclusion": "The architecture demonstrates feasibility of relativistic quantum computing, validated by implementing the quantum Fourier transform."}}
{"id": "2412.10855", "pdf": "https://arxiv.org/pdf/2412.10855", "abs": "https://arxiv.org/abs/2412.10855", "authors": ["Haoran Ding", "No\u00e9mie Jaquier", "Jan Peters", "Leonel Rozo"], "title": "Fast and Robust Visuomotor Riemannian Flow Matching Policy", "categories": ["cs.RO", "cs.LG"], "comment": "17 pages, 12 figures, 12 tables, project website:\n  https://sites.google.com/view/rfmp", "summary": "Diffusion-based visuomotor policies excel at learning complex robotic tasks\nby effectively combining visual data with high-dimensional, multi-modal action\ndistributions. However, diffusion models often suffer from slow inference due\nto costly denoising processes or require complex sequential training arising\nfrom recent distilling approaches. This paper introduces Riemannian Flow\nMatching Policy (RFMP), a model that inherits the easy training and fast\ninference capabilities of flow matching (FM). Moreover, RFMP inherently\nincorporates geometric constraints commonly found in realistic robotic\napplications, as the robot state resides on a Riemannian manifold. To enhance\nthe robustness of RFMP, we propose Stable RFMP (SRFMP), which leverages\nLaSalle's invariance principle to equip the dynamics of FM with stability to\nthe support of a target Riemannian distribution. Rigorous evaluation on eight\nsimulated and real-world tasks show that RFMP successfully learns and\nsynthesizes complex sensorimotor policies on Euclidean and Riemannian spaces\nwith efficient training and inference phases, outperforming Diffusion Policies\nand Consistency Policies.", "AI": {"tldr": "RFMP (Riemannian Flow Matching Policy) improves upon diffusion-based policies by offering faster training and inference, while incorporating geometric constraints for robotic tasks.", "motivation": "Diffusion models are slow in inference and require complex training, limiting their practicality in robotics. RFMP addresses these issues with flow matching and geometric constraints.", "method": "RFMP uses flow matching for easy training and fast inference, incorporating Riemannian manifold constraints. SRFMP adds stability via LaSalle's invariance principle.", "result": "RFMP outperforms Diffusion and Consistency Policies in eight tasks, efficiently handling Euclidean and Riemannian spaces.", "conclusion": "RFMP is a robust, efficient alternative to diffusion-based policies for robotic visuomotor tasks."}}
{"id": "2501.11803", "pdf": "https://arxiv.org/pdf/2501.11803", "abs": "https://arxiv.org/abs/2501.11803", "authors": ["Riqiang Gao", "Mamadou Diallo", "Han Liu", "Anthony Magliari", "Jonathan Sackett", "Wilko Verbakel", "Sandra Meyers", "Rafe Mcbeth", "Masoud Zarepisheh", "Simon Arberet", "Martin Kraus", "Florin C. Ghesu", "Ali Kamen"], "title": "Automating High Quality RT Planning at Scale", "categories": ["cs.HC", "cs.LG", "cs.RO"], "comment": "radiotherapy planning, data for AI training", "summary": "Radiotherapy (RT) planning is complex, subjective, and time-intensive.\nAdvances with artificial intelligence (AI) promise to improve its precision and\nefficiency, but progress is often limited by the scarcity of large,\nstandardized datasets. To address this, we introduce the Automated Iterative RT\nPlanning (AIRTP) system, a scalable solution for generating high-quality\ntreatment plans. This scalable solution is designed to generate substantial\nvolumes of consistently high-quality treatment plans, overcoming a key obstacle\nin the advancement of AI-driven RT planning. Our AIRTP pipeline adheres to\nclinical guidelines and automates essential steps, including organ-at-risk\n(OAR) contouring, helper structure creation, beam setup, optimization, and plan\nquality improvement, using AI integrated with RT planning software like Varian\nEclipse. Furthermore, a novel approach for determining optimization parameters\nto reproduce 3D dose distributions, i.e. a method to convert dose predictions\nto deliverable treatment plans constrained by machine limitations is proposed.\nA comparative analysis of plan quality reveals that our automated pipeline\nproduces treatment plans of quality comparable to those generated manually,\nwhich traditionally require several hours of labor per plan. Committed to\npublic research, the first data release of our AIRTP pipeline includes nine\ncohorts covering head-and-neck and lung cancer sites to support an AAPM 2025\nchallenge. To our best knowledge, this dataset features more than 10 times\nnumber of plans compared to the largest existing well-curated public dataset.\nRepo: https://github.com/RiqiangGao/GDP-HMM_AAPMChallenge.", "AI": {"tldr": "The paper introduces AIRTP, an AI-driven system for automated radiotherapy planning, addressing data scarcity and improving efficiency while maintaining plan quality comparable to manual methods.", "motivation": "Radiotherapy planning is complex and time-intensive, with AI advancements hindered by lack of large, standardized datasets. AIRTP aims to overcome this.", "method": "AIRTP automates key steps like OAR contouring, beam setup, and optimization using AI integrated with RT software, and proposes a novel method for dose-to-plan conversion.", "result": "The automated pipeline produces plans comparable to manual ones, saving hours per plan. A large public dataset (10x larger than existing) is released.", "conclusion": "AIRTP demonstrates scalable, high-quality automated planning, with potential to advance AI in RT by addressing data limitations and improving efficiency."}}
{"id": "2501.13483", "pdf": "https://arxiv.org/pdf/2501.13483", "abs": "https://arxiv.org/abs/2501.13483", "authors": ["Aayush Mishra", "Daniel Habermann", "Marvin Schmitt", "Stefan T. Radev", "Paul-Christian B\u00fcrkner"], "title": "Robust Amortized Bayesian Inference with Self-Consistency Losses on Unlabeled Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Amortized Bayesian inference (ABI) with neural networks can solve\nprobabilistic inverse problems orders of magnitude faster than classical\nmethods. However, ABI is not yet sufficiently robust for widespread and safe\napplication. When performing inference on observations outside the scope of the\nsimulated training data, posterior approximations are likely to become highly\nbiased, which cannot be corrected by additional simulations due to the bad\npre-asymptotic behavior of current neural posterior estimators. In this paper,\nwe propose a semi-supervised approach that enables training not only on labeled\nsimulated data generated from the model, but also on \\textit{unlabeled} data\noriginating from any source, including real data. To achieve this, we leverage\nBayesian self-consistency properties that can be transformed into strictly\nproper losses that do not require knowledge of ground-truth parameters. We test\nour approach on several real-world case studies, including applications to\nhigh-dimensional time-series and image data. Our results show that\nsemi-supervised learning with unlabeled data drastically improves the\nrobustness of ABI in the out-of-simulation regime. Notably, inference remains\naccurate even when evaluated on observations far away from the labeled and\nunlabeled data seen during training.", "AI": {"tldr": "ABI with neural networks speeds up probabilistic inverse problems but lacks robustness. A semi-supervised approach using labeled and unlabeled data improves robustness, even for out-of-simulation observations.", "motivation": "Current ABI methods are not robust for widespread use due to biased posterior approximations when inferring observations outside simulated training data.", "method": "Proposes a semi-supervised approach leveraging Bayesian self-consistency properties to train on both labeled simulated data and unlabeled real data.", "result": "Semi-supervised learning with unlabeled data significantly enhances ABI robustness, maintaining accuracy even for observations far from training data.", "conclusion": "The semi-supervised approach improves ABI robustness, making it more reliable for real-world applications."}}
{"id": "2502.05850", "pdf": "https://arxiv.org/pdf/2502.05850", "abs": "https://arxiv.org/abs/2502.05850", "authors": ["Zhiqiang Que", "Jose G. F. Coutinho", "Ce Guo", "Hongxiang Fan", "Wayne Luk"], "title": "MetaML-Pro: Cross-Stage Design Flow Automation for Efficient Deep Learning Acceleration", "categories": ["cs.AR", "cs.LG"], "comment": "28 pages, 20 figures", "summary": "This paper presents a unified framework for codifying and automating\noptimization strategies to efficiently deploy deep neural networks (DNNs) on\nresource-constrained hardware, such as FPGAs, while maintaining high\nperformance, accuracy, and resource efficiency. Deploying DNNs on such\nplatforms involves addressing the significant challenge of balancing\nperformance, resource usage (e.g., DSPs and LUTs), and inference accuracy,\nwhich often requires extensive manual effort and domain expertise. Our novel\napproach addresses two core key issues: (i)~encoding custom optimization\nstrategies and (ii)~enabling cross-stage optimization search. In particular,\nour proposed framework seamlessly integrates programmatic DNN optimization\ntechniques with high-level synthesis (HLS)-based metaprogramming, leveraging\nadvanced design space exploration (DSE) strategies like Bayesian optimization\nto automate both top-down and bottom-up design flows. Hence, we reduce the need\nfor manual intervention and domain expertise. In addition, the framework\nintroduces customizable optimization, transformation, and control blocks to\nenhance DNN accelerator performance and resource efficiency. Experimental\nresults demonstrate up to a 92\\% DSP and 89\\% LUT usage reduction for select\nnetworks, while preserving accuracy, along with a 15.6-fold reduction in\noptimization time compared to grid search. These results highlight the\npotential for automating the generation of resource-efficient DNN accelerator\ndesigns with minimum effort.", "AI": {"tldr": "A framework automates DNN deployment on resource-constrained hardware like FPGAs, balancing performance, accuracy, and efficiency with minimal manual effort.", "motivation": "Addressing the challenge of deploying DNNs on constrained hardware efficiently, reducing manual effort and expertise.", "method": "Integrates programmatic DNN optimization with HLS-based metaprogramming, using Bayesian optimization for design space exploration.", "result": "Achieves up to 92% DSP and 89% LUT reduction, maintains accuracy, and reduces optimization time by 15.6x.", "conclusion": "The framework enables efficient, automated DNN accelerator design with minimal manual intervention."}}
{"id": "2503.21686", "pdf": "https://arxiv.org/pdf/2503.21686", "abs": "https://arxiv.org/abs/2503.21686", "authors": ["Yuichi Kamata", "Quoc Hoan Tran", "Yasuhiro Endo", "Hirotaka Oshima"], "title": "Molecular Quantum Transformer", "categories": ["quant-ph", "cs.LG"], "comment": "14 pages, 8 figures; updated for refining results and discussion with\n  other FTQC implementations of Quantum Transformer", "summary": "The Transformer model, renowned for its powerful attention mechanism, has\nachieved state-of-the-art performance in various artificial intelligence tasks\nbut faces challenges such as high computational cost and memory usage.\nResearchers are exploring quantum computing to enhance the Transformer's\ndesign, though it still shows limited success with classical data. With a\ngrowing focus on leveraging quantum machine learning for quantum data,\nparticularly in quantum chemistry, we propose the Molecular Quantum Transformer\n(MQT) for modeling interactions in molecular quantum systems. By utilizing\nquantum circuits to implement the attention mechanism on the molecular\nconfigurations, MQT can efficiently calculate ground-state energies for all\nconfigurations. Numerical demonstrations show that in calculating ground-state\nenergies for H2, LiH, BeH2, and H4, MQT outperforms the classical Transformer,\nhighlighting the promise of quantum effects in Transformer structures.\nFurthermore, its pretraining capability on diverse molecular data facilitates\nthe efficient learning of new molecules, extending its applicability to complex\nmolecular systems with minimal additional effort. Our method offers an\nalternative to existing quantum algorithms for estimating ground-state\nenergies, opening new avenues in quantum chemistry and materials science.", "AI": {"tldr": "The paper introduces the Molecular Quantum Transformer (MQT), a quantum-enhanced Transformer model for efficiently calculating ground-state energies in molecular quantum systems, outperforming classical Transformers.", "motivation": "The Transformer model's high computational cost and memory usage, along with the potential of quantum computing, motivate the exploration of quantum-enhanced Transformers for quantum data, particularly in quantum chemistry.", "method": "MQT uses quantum circuits to implement the attention mechanism on molecular configurations, enabling efficient ground-state energy calculations.", "result": "MQT outperforms classical Transformers in calculating ground-state energies for molecules like H2, LiH, BeH2, and H4, demonstrating the promise of quantum effects in Transformers.", "conclusion": "MQT offers a novel approach for ground-state energy estimation, with pretraining capabilities for diverse molecular data, advancing quantum chemistry and materials science."}}
{"id": "2504.07742", "pdf": "https://arxiv.org/pdf/2504.07742", "abs": "https://arxiv.org/abs/2504.07742", "authors": ["Qiyu Wei", "Haowei Wang", "Zirui Cao", "Songhao Wang", "Richard Allmendinger", "Mauricio A \u00c1lvarez"], "title": "Gradient-based Sample Selection for Faster Bayesian Optimization", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Bayesian optimization (BO) is an effective technique for black-box\noptimization. However, its applicability is typically limited to\nmoderate-budget problems due to the cubic complexity in computing the Gaussian\nprocess (GP) surrogate model. In large-budget scenarios, directly employing the\nstandard GP model faces significant challenges in computational time and\nresource requirements. In this paper, we propose a novel approach,\ngradient-based sample selection Bayesian Optimization (GSSBO), to enhance the\ncomputational efficiency of BO. The GP model is constructed on a selected set\nof samples instead of the whole dataset. These samples are selected by\nleveraging gradient information to maintain diversity and representation. We\nprovide a theoretical analysis of the gradient-based sample selection strategy\nand obtain explicit sublinear regret bounds for our proposed framework.\nExtensive experiments on synthetic and real-world tasks demonstrate that our\napproach significantly reduces the computational cost of GP fitting in BO while\nmaintaining optimization performance comparable to baseline methods.", "AI": {"tldr": "GSSBO improves Bayesian optimization efficiency by using gradient-based sample selection for GP models, reducing computational costs while maintaining performance.", "motivation": "Standard GP models in Bayesian optimization are computationally expensive for large budgets, limiting their applicability.", "method": "Proposes GSSBO, which selects samples using gradient information to build GP models, ensuring diversity and representation.", "result": "Theoretical sublinear regret bounds are proven, and experiments show reduced computational costs with comparable optimization performance.", "conclusion": "GSSBO effectively addresses computational challenges in large-budget Bayesian optimization without sacrificing performance."}}
{"id": "2505.00526", "pdf": "https://arxiv.org/pdf/2505.00526", "abs": "https://arxiv.org/abs/2505.00526", "authors": ["Yanhao 'Max' Wei", "Zhenling Jiang"], "title": "Pre-Training Estimators for Structural Models: Application to Consumer Search", "categories": ["econ.EM", "cs.LG", "stat.CO", "G.3; J.4; I.2"], "comment": null, "summary": "We explore pretraining estimators for structural econometric models. The\nestimator is \"pretrained\" in the sense that the bulk of the computational cost\nand researcher effort occur during the construction of the estimator.\nSubsequent applications of the estimator to different datasets require little\ncomputational cost or researcher effort. The estimation leverages a neural net\nto recognize the structural model's parameter from data patterns. As an initial\ntrial, this paper builds a pretrained estimator for a sequential search model\nthat is known to be difficult to estimate. We evaluate the pretrained estimator\non 12 real datasets. The estimation takes seconds to run and shows high\naccuracy. We provide the estimator at pnnehome.github.io. More generally,\npretrained, off-the-shelf estimators can make structural models more accessible\nto researchers and practitioners.", "AI": {"tldr": "Pretrained estimators for structural econometric models reduce computational costs and researcher effort, leveraging neural nets for parameter recognition. Demonstrated on a sequential search model, the estimator shows high accuracy and speed.", "motivation": "To make structural econometric models more accessible by reducing computational and effort costs through pretrained estimators.", "method": "Uses a neural net to recognize structural model parameters from data patterns, pretraining the estimator for efficiency.", "result": "Evaluated on 12 real datasets, the estimator runs in seconds with high accuracy.", "conclusion": "Pretrained estimators can enhance accessibility and usability of structural models for researchers and practitioners."}}
{"id": "2505.07101", "pdf": "https://arxiv.org/pdf/2505.07101", "abs": "https://arxiv.org/abs/2505.07101", "authors": ["Haichen Hu", "David Simchi-Levi", "Navid Azizan"], "title": "Constrained Online Decision-Making: A Unified Framework", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Contextual online decision-making problems with constraints appear in various\nreal-world applications, such as personalized recommendation with resource\nlimits and dynamic pricing with fairness constraints. In this paper, we\ninvestigate a general formulation of sequential decision-making with stage-wise\nfeasibility constraints, where at each round, the learner must select an action\nbased on observed context while ensuring a problem-specific feasibility\ncriterion. We propose a unified algorithmic framework that captures many\nexisting constrained learning problems, including constrained bandits, stream\nactive learning, online hypothesis testing, and model calibration. Central to\nour approach is the concept of upper counterfactual confidence bound, which\nenables the design of practically efficient online algorithms using any offline\nconditional density estimation oracle. Technically, to handle feasibility\nconstraints, we introduce a generalized notion of the eluder dimension,\nextending it from the classical setting based on square loss to a broader class\nof metric-like probability divergences, which could capture the complexity of\nvarious density function classes and characterize the loss incurred due to\nfeasibility constraint uncertainty. Our result offers a principled foundation\nfor constrained sequential decision-making in both theory and practice.", "AI": {"tldr": "A unified framework for constrained sequential decision-making, using upper counterfactual confidence bounds and a generalized eluder dimension to handle feasibility constraints.", "motivation": "Addressing real-world problems like personalized recommendation and dynamic pricing with constraints, requiring efficient online algorithms.", "method": "Proposes a framework using offline conditional density estimation oracles and introduces a generalized eluder dimension for feasibility constraints.", "result": "Provides a principled foundation for constrained sequential decision-making, applicable to various problems like bandits and active learning.", "conclusion": "The approach offers theoretical and practical advancements for constrained online decision-making."}}
{"id": "2505.09364", "pdf": "https://arxiv.org/pdf/2505.09364", "abs": "https://arxiv.org/abs/2505.09364", "authors": ["Michael Benigni", "Maurizio Ferrari Dacrema", "Dietmar Jannach"], "title": "Diffusion Recommender Models and the Illusion of Progress: A Concerning Study of Reproducibility and a Conceptual Mismatch", "categories": ["cs.IR", "cs.LG", "cs.NE"], "comment": null, "summary": "Countless new machine learning models are published every year and are\nreported to significantly advance the state-of-the-art in \\emph{top-n}\nrecommendation. However, earlier reproducibility studies indicate that progress\nin this area may be quite limited. Specifically, various widespread\nmethodological issues, e.g., comparisons with untuned baseline models, have led\nto an \\emph{illusion of progress}. In this work, our goal is to examine whether\nthese problems persist in today's research. To this end, we aim to reproduce\nthe latest advancements reported from applying modern Denoising Diffusion\nProbabilistic Models to recommender systems, focusing on four models published\nat the top-ranked SIGIR conference in 2023 and 2024. Our findings are\nconcerning, revealing persistent methodological problems. Alarmingly, through\nexperiments, we find that the latest recommendation techniques based on\ndiffusion models, despite their computational complexity and substantial carbon\nfootprint, are consistently outperformed by simpler existing models.\nFurthermore, we identify key mismatches between the characteristics of\ndiffusion models and those of the traditional \\emph{top-n} recommendation task,\nraising doubts about their suitability for recommendation. We also note that,\nin the papers we analyze, the generative capabilities of these models are\nconstrained to a minimum. Overall, our results and continued methodological\nissues call for greater scientific rigor and a disruptive change in the\nresearch and publication culture in this area.", "AI": {"tldr": "The paper critiques the overstated progress in top-n recommendation systems, revealing persistent methodological flaws and questioning the suitability of diffusion models for this task.", "motivation": "To investigate whether methodological issues in machine learning research, such as untuned baselines, still persist, particularly in recent diffusion model-based recommender systems.", "method": "Reproduces and evaluates four state-of-the-art diffusion model-based recommender systems from SIGIR 2023 and 2024, comparing them with simpler models.", "result": "Finds that diffusion models are consistently outperformed by simpler models, with mismatches between their characteristics and the top-n recommendation task.", "conclusion": "Calls for greater scientific rigor and a shift in research culture to address ongoing methodological problems."}}
